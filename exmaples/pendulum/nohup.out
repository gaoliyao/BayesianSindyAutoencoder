2022-07-08 08:06:46.771698: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-07-08 08:06:46.922358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
totalMemory: 10.76GiB freeMemory: 10.60GiB
2022-07-08 08:06:46.922387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2022-07-08 08:06:47.116293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-08 08:06:47.116326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2022-07-08 08:06:47.116332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2022-07-08 08:06:47.116404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9917 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
(50000, 2601)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 2601, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 12, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 100, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'constant', 'loss_weight_decoder': 1.0, 'loss_weight_sindy_x': 0.005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [128, 64, 32], 'epoch_size': 50000, 'batch_size': 1000, 'learning_rate': 0.001, 'data_path': '/home/marsgao/BayesianSindyAutoencoder/exmaples/pendulum/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 3001, 'refinement_epochs': 1001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.0008, 'pi': 0.083, 'c_std': 3.0, 'epsilon': 0.05, 'decay': 0.05, 'sigma': 1.0, 'init_sigma': 0.0, 'cycle_sgld': 500}
TRAINING
=========================
[[0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]]
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.16923649609088898, (0.008053396, 0.0010320549, 29.929049, 0.011537801)
   validation loss 0.09609505534172058, (0.007518724, 0.0007464626, 15.4077, 0.011537801)
decoder loss ratio: 0.896390, decoder SINDy loss  ratio: 1.000000
=========================
[[0.73808914]
 [0.73725516]
 [0.2624407 ]
 [0.7380982 ]
 [0.26248825]
 [0.26244614]
 [0.4511613 ]
 [0.2624395 ]
 [0.26243854]
 [0.2624479 ]
 [0.73743147]
 [0.26244077]]
[[ 8.0049133e-01]
 [ 6.5192384e-01]
 [ 2.4214399e-04]
 [ 8.1167513e-01]
 [ 4.2206366e-03]
 [ 7.1633444e-04]
 [ 3.1559291e-01]
 [-1.4544470e-04]
 [ 6.2721840e-05]
 [ 8.6709438e-04]
 [ 6.6316968e-01]
 [ 2.5349495e-04]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.16905629634857178, (0.007877126, 0.026600061, 29.929049, 0.011532608)
   validation loss 0.0959816724061966, (0.0074099726, 0.01161298, 15.4077015, 0.011532608)
decoder loss ratio: 0.883425, decoder SINDy loss  ratio: 1.000000
=========================
[[0.7556198 ]
 [0.16263957]
 [0.15060455]
 [0.8502597 ]
 [0.15066123]
 [0.8497871 ]
 [0.17582208]
 [0.15049973]
 [0.8463985 ]
 [0.15043543]
 [0.32140565]
 [0.15045305]]
[[-0.42938617]
 [-0.13801524]
 [-0.01030322]
 [ 0.7535833 ]
 [ 0.01297359]
 [-0.6870279 ]
 [ 0.1738859 ]
 [-0.00495853]
 [-0.5947137 ]
 [ 0.0013722 ]
 [-0.2801134 ]
 [-0.00238034]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.1425507664680481, (0.009032073, 35.858383, 24.038666, 0.011532451)
   validation loss 0.08329606801271439, (0.0087925615, 22.749098, 12.36672, 0.011532451)
decoder loss ratio: 1.048259, decoder SINDy loss  ratio: 0.802632
=========================
[[0.6873722 ]
 [0.7924104 ]
 [0.08569107]
 [0.11659914]
 [0.08573569]
 [0.9147349 ]
 [0.08953674]
 [0.08570847]
 [0.9133609 ]
 [0.08567719]
 [0.8652778 ]
 [0.08569862]]
[[ 0.38514218]
 [-0.4241395 ]
 [-0.00222487]
 [ 0.17526478]
 [-0.00431911]
 [-0.6976043 ]
 [ 0.07967597]
 [-0.00305138]
 [-0.6387884 ]
 [ 0.00155259]
 [-0.47407335]
 [ 0.00258471]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0673297569155693, (0.007117222, 25.630697, 9.479731, 0.011532346)
   validation loss 0.03756048530340195, (0.0050571645, 13.848391, 4.055711, 0.011532346)
decoder loss ratio: 0.602921, decoder SINDy loss  ratio: 0.263226
=========================
[[0.564656  ]
 [0.92363167]
 [0.05298085]
 [0.05638732]
 [0.0527843 ]
 [0.94818825]
 [0.05394379]
 [0.0528051 ]
 [0.90024275]
 [0.05279303]
 [0.939538  ]
 [0.05281803]]
[[ 3.5098612e-01]
 [-5.1511550e-01]
 [-8.6609283e-03]
 [ 7.3716499e-02]
 [ 3.2595190e-04]
 [-7.8706968e-01]
 [ 3.6740392e-02]
 [-1.2754287e-03]
 [-4.8031679e-01]
 [ 7.2680751e-04]
 [-5.6793052e-01]
 [-1.8582573e-03]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.043115902692079544, (0.0055356524, 18.422802, 5.025359, 0.011532319)
   validation loss 0.024331368505954742, (0.0030780036, 8.505924, 1.8591503, 0.011532319)
decoder loss ratio: 0.366963, decoder SINDy loss  ratio: 0.120664
THRESHOLDING: 5 active coefficients
=========================
[[0.33317113]
 [0.8591858 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9686257 ]
 [0.        ]
 [0.        ]
 [0.7244513 ]
 [0.        ]
 [0.9542018 ]
 [0.        ]]
[[ 0.2991442 ]
 [-0.4378009 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.824609  ]
 [ 0.        ]
 [ 0.        ]
 [-0.38869533]
 [ 0.        ]
 [-0.5446826 ]
 [ 0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.03912866860628128, (0.004973736, 13.444411, 3.409288, 0.016436275)
   validation loss 0.024645306169986725, (0.0023239441, 5.7161913, 1.1198554, 0.016436275)
decoder loss ratio: 0.277063, decoder SINDy loss  ratio: 0.072682
=========================
[[0.17894328]
 [0.83531314]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97963697]
 [0.        ]
 [0.        ]
 [0.6333417 ]
 [0.        ]
 [0.965761  ]
 [0.        ]]
[[ 0.25535935]
 [-0.42314944]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.8107073 ]
 [ 0.        ]
 [ 0.        ]
 [-0.36503744]
 [ 0.        ]
 [-0.5477597 ]
 [-0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.03490123897790909, (0.004498964, 9.422031, 2.7213035, 0.016324654)
   validation loss 0.022377625107765198, (0.0018588704, 3.794679, 0.80087304, 0.016324654)
decoder loss ratio: 0.221617, decoder SINDy loss  ratio: 0.051979
=========================
[[0.10789251]
 [0.80410653]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98679894]
 [0.        ]
 [0.        ]
 [0.38013637]
 [0.        ]
 [0.97244877]
 [0.        ]]
[[ 0.22493042]
 [-0.409823  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.7754144 ]
 [ 0.        ]
 [-0.        ]
 [-0.31125817]
 [ 0.        ]
 [-0.54654306]
 [ 0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.031093645840883255, (0.0038545565, 7.6862736, 2.1441224, 0.016134163)
   validation loss 0.020693834871053696, (0.0014962924, 2.7415507, 0.58526015, 0.016134163)
decoder loss ratio: 0.178390, decoder SINDy loss  ratio: 0.037985
=========================
[[0.06768662]
 [0.78805524]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9907537 ]
 [0.        ]
 [0.        ]
 [0.15585308]
 [0.        ]
 [0.96975267]
 [0.        ]]
[[ 0.19852115]
 [-0.40381238]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.73518556]
 [ 0.        ]
 [-0.        ]
 [-0.24941212]
 [-0.        ]
 [-0.52723837]
 [-0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.02746754139661789, (0.0032618386, 6.1855917, 1.6901565, 0.015445641)
   validation loss 0.018895575776696205, (0.0011945232, 1.9661375, 0.43142086, 0.015445641)
decoder loss ratio: 0.142412, decoder SINDy loss  ratio: 0.028000
THRESHOLDING: 4 active coefficients
=========================
[[0.        ]
 [0.7323068 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9914872 ]
 [0.        ]
 [0.        ]
 [0.07082554]
 [0.        ]
 [0.92196006]
 [0.        ]]
[[ 0.        ]
 [-0.38758138]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.63648295]
 [-0.        ]
 [ 0.        ]
 [-0.20340578]
 [ 0.        ]
 [-0.46387625]
 [ 0.        ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.02098882384598255, (0.0029393174, 5.1978045, 1.3438824, 0.011070204)
   validation loss 0.013788901269435883, (0.001015429, 1.5092658, 0.32556093, 0.011070204)
decoder loss ratio: 0.121061, decoder SINDy loss  ratio: 0.021130
=========================
[[0.        ]
 [0.7547415 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9835209 ]
 [0.        ]
 [0.        ]
 [0.02777111]
 [0.        ]
 [0.8742525 ]
 [0.        ]]
[[ 0.        ]
 [-0.3933527 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.5563593 ]
 [-0.        ]
 [ 0.        ]
 [-0.15019941]
 [ 0.        ]
 [-0.4350961 ]
 [-0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.019065145403146744, (0.0026829434, 4.2635517, 1.1431582, 0.010453234)
   validation loss 0.01271275244653225, (0.0008913594, 1.0992603, 0.2626391, 0.010453234)
decoder loss ratio: 0.106269, decoder SINDy loss  ratio: 0.017046
=========================
[[0.        ]
 [0.79576254]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.949561  ]
 [0.        ]
 [0.        ]
 [0.01072722]
 [0.        ]
 [0.82293624]
 [0.        ]]
[[ 0.        ]
 [-0.40513858]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.48650432]
 [-0.        ]
 [-0.        ]
 [-0.09331755]
 [-0.        ]
 [-0.4140996 ]
 [ 0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.016952034085989, (0.002375818, 3.8710294, 0.919197, 0.0097866785)
   validation loss 0.011588867753744125, (0.00074994407, 0.90415937, 0.20140752, 0.0097866785)
decoder loss ratio: 0.089409, decoder SINDy loss  ratio: 0.013072
=========================
[[0.        ]
 [0.8198326 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85383546]
 [0.        ]
 [0.        ]
 [0.0053002 ]
 [0.        ]
 [0.75337803]
 [0.        ]]
[[ 0.        ]
 [-0.41284996]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.42552337]
 [-0.        ]
 [-0.        ]
 [-0.04652455]
 [ 0.        ]
 [-0.39269575]
 [-0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.015604129061102867, (0.0021583033, 3.1462398, 0.7464137, 0.009556445)
   validation loss 0.011015815660357475, (0.0006475469, 0.66643834, 0.1557002, 0.009556445)
decoder loss ratio: 0.077201, decoder SINDy loss  ratio: 0.010105
THRESHOLDING: 3 active coefficients
=========================
[[0.        ]
 [0.845687  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6500266 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.68019027]
 [0.        ]]
[[ 0.        ]
 [-0.4221211 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3675644 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.37438145]
 [ 0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01451442763209343, (0.001927879, 2.6349754, 0.6273163, 0.009318219)
   validation loss 0.010514880530536175, (0.0005382411, 0.5070879, 0.12661329, 0.009318219)
decoder loss ratio: 0.064170, decoder SINDy loss  ratio: 0.008218
=========================
[[0.       ]
 [0.843767 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4503054]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.600208 ]
 [0.       ]]
[[ 0.        ]
 [-0.42127827]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3264183 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.35684457]
 [-0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01426128949970007, (0.0016687955, 2.2928863, 0.5129628, 0.009913036)
   validation loss 0.01087227649986744, (0.00043360298, 0.40804276, 0.10104706, 0.009913036)
decoder loss ratio: 0.051695, decoder SINDy loss  ratio: 0.006558
=========================
[[0.        ]
 [0.83591235]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32454777]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5534692 ]
 [0.        ]]
[[ 0.        ]
 [-0.4182557 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.29964262]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3472114 ]
 [ 0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.013929355889558792, (0.0014962131, 1.9132311, 0.43903226, 0.01014232)
   validation loss 0.01095188595354557, (0.00036940223, 0.32558087, 0.08477693, 0.01014232)
decoder loss ratio: 0.044041, decoder SINDy loss  ratio: 0.005502
=========================
[[0.        ]
 [0.825803  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24974762]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5450582 ]
 [0.        ]]
[[ 0.        ]
 [-0.4145846 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.28123668]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.34550223]
 [-0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01362468209117651, (0.0013766255, 1.5854934, 0.39819667, 0.010177799)
   validation loss 0.010892478749155998, (0.00032497584, 0.2602218, 0.075338654, 0.010177799)
decoder loss ratio: 0.038744, decoder SINDy loss  ratio: 0.004890
THRESHOLDING: 3 active coefficients
=========================
[[0.        ]
 [0.8105949 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19960591]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.56028366]
 [0.        ]]
[[ 0.        ]
 [-0.40940586]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.26676276]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.34858862]
 [ 0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.013386414386332035, (0.0012777355, 1.3442574, 0.38190797, 0.010131926)
   validation loss 0.010810301639139652, (0.00028866855, 0.21409719, 0.07580045, 0.010131926)
decoder loss ratio: 0.034415, decoder SINDy loss  ratio: 0.004920
=========================
[[0.        ]
 [0.78999615]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1607411 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5882177 ]
 [0.        ]]
[[ 0.       ]
 [-0.402905 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.2535347]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.3543175]
 [-0.       ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.013064143247902393, (0.0011738922, 1.1645093, 0.35618463, 0.010051102)
   validation loss 0.010663392022252083, (0.0002540325, 0.18139008, 0.06983761, 0.010051102)
decoder loss ratio: 0.030286, decoder SINDy loss  ratio: 0.004533
=========================
[[0.       ]
 [0.7622134]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.130044 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6191215]
 [0.       ]]
[[-0.        ]
 [-0.3948556 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.24111806]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.36079365]
 [ 0.        ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.012632235884666443, (0.0010623628, 1.0260439, 0.31229824, 0.00995708)
   validation loss 0.010469984263181686, (0.0002223347, 0.15696818, 0.05654435, 0.00995708)
decoder loss ratio: 0.026507, decoder SINDy loss  ratio: 0.003670
=========================
[[0.        ]
 [0.7267026 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10760509]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.64698684]
 [0.        ]]
[[ 0.        ]
 [-0.38547006]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.23035446]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.3668071 ]
 [-0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.012294597923755646, (0.0009505457, 0.9023404, 0.28024095, 0.00989773)
   validation loss 0.010349823161959648, (0.0001940326, 0.1349387, 0.050262682, 0.00989773)
decoder loss ratio: 0.023133, decoder SINDy loss  ratio: 0.003262
THRESHOLDING: 3 active coefficients
=========================
[[0.        ]
 [0.81669223]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0946328 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.73030376]
 [0.        ]]
[[-0.        ]
 [-0.41135573]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.22320566]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.38637665]
 [ 0.        ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011451752856373787, (0.00083081156, 0.9306651, 0.25593078, 0.009294754)
   validation loss 0.009690460748970509, (0.00016160807, 0.1406181, 0.045413654, 0.009294754)
decoder loss ratio: 0.019267, decoder SINDy loss  ratio: 0.002947
=========================
[[0.        ]
 [0.7909803 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09070498]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.71676266]
 [0.        ]]
[[ 0.        ]
 [-0.40315714]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.22088103]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.38297674]
 [-0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011556304059922695, (0.00066608883, 0.58566225, 0.29932356, 0.009364314)
   validation loss 0.009951937012374401, (0.00014372537, 0.08570283, 0.08792245, 0.009364314)
decoder loss ratio: 0.017135, decoder SINDy loss  ratio: 0.005706
=========================
[[0.        ]
 [0.7723675 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07880221]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7536982 ]
 [0.        ]]
[[-0.        ]
 [-0.39767808]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.2131885 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3924984 ]
 [ 0.        ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01076842937618494, (0.00058329315, 0.52534235, 0.18145344, 0.009251602)
   validation loss 0.009550231508910656, (0.00012853065, 0.08105177, 0.033209197, 0.009251602)
decoder loss ratio: 0.015324, decoder SINDy loss  ratio: 0.002155
=========================
[[0.        ]
 [0.7237032 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06289009]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.78004295]
 [0.        ]]
[[ 0.        ]
 [-0.3846968 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.20102704]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.39988986]
 [-0.        ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.010331748053431511, (0.00049043173, 0.48793384, 0.138696, 0.00912344)
   validation loss 0.009383857250213623, (0.0001188742, 0.074697055, 0.02756165, 0.00912344)
decoder loss ratio: 0.014172, decoder SINDy loss  ratio: 0.001789
THRESHOLDING: 2 active coefficients
=========================
[[0.        ]
 [0.5740728 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84044516]
 [0.        ]]
[[ 0.        ]
 [-0.35139227]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.4197266 ]
 [ 0.        ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0073102498427033424, (0.00039470824, 0.40581414, 0.11203188, 0.0063350913)
   validation loss 0.006548400968313217, (9.803303e-05, 0.08021814, 0.022253107, 0.0063350913)
decoder loss ratio: 0.011688, decoder SINDy loss  ratio: 0.001444
=========================
[[0.        ]
 [0.44185427]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9045814 ]
 [0.        ]]
[[-0.        ]
 [-0.32472774]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.44920588]
 [-0.        ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007163702510297298, (0.00035850084, 0.3157348, 0.099878475, 0.0062900227)
   validation loss 0.006490318104624748, (9.164821e-05, 0.06910555, 0.021038344, 0.0062900227)
decoder loss ratio: 0.010926, decoder SINDy loss  ratio: 0.001365
=========================
[[0.        ]
 [0.32274172]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.947965  ]
 [0.        ]]
[[-0.        ]
 [-0.29929906]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.4819972 ]
 [ 0.        ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.006947771646082401, (0.00029688518, 0.26902574, 0.08572787, 0.006208796)
   validation loss 0.006371678784489632, (7.255999e-05, 0.060708, 0.017457485, 0.006208796)
decoder loss ratio: 0.008651, decoder SINDy loss  ratio: 0.001133
=========================
[[0.        ]
 [0.22070272]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9710458 ]
 [0.        ]]
[[ 0.        ]
 [-0.27323085]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5126677 ]
 [-0.        ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.006706184707581997, (0.00026928817, 0.2435726, 0.077048905, 0.006039473)
   validation loss 0.006191709078848362, (6.715884e-05, 0.055598, 0.016459407, 0.006039473)
decoder loss ratio: 0.008007, decoder SINDy loss  ratio: 0.001068
THRESHOLDING: 2 active coefficients
=========================
[[0.       ]
 [0.1520308]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9837866]
 [0.       ]]
[[-0.        ]
 [-0.25032955]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5425165 ]
 [ 0.        ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.006295252125710249, (0.00022369024, 0.22143552, 0.06723762, 0.005724302)
   validation loss 0.005850400775671005, (5.1599975e-05, 0.050436657, 0.01439536, 0.005724302)
decoder loss ratio: 0.006152, decoder SINDy loss  ratio: 0.000934
=========================
[[0.        ]
 [0.10338954]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9901223 ]
 [0.        ]]
[[ 0.       ]
 [-0.2282206]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5678459]
 [-0.       ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.005995612125843763, (0.00020540149, 0.20756564, 0.06022674, 0.0054786988)
   validation loss 0.005595666356384754, (4.730226e-05, 0.04686001, 0.013464502, 0.0054786988)
decoder loss ratio: 0.005639, decoder SINDy loss  ratio: 0.000874
=========================
[[0.        ]
 [0.07244827]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99374205]
 [0.        ]]
[[ 0.        ]
 [-0.20870566]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.59112036]
 [ 0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.005649904254823923, (0.00016651968, 0.19451162, 0.052690323, 0.0052102073)
   validation loss 0.00530632259324193, (3.3725144e-05, 0.042892482, 0.0120491395, 0.0052102073)
decoder loss ratio: 0.004021, decoder SINDy loss  ratio: 0.000782
=========================
[[0.        ]
 [0.05075829]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9957477 ]
 [0.        ]]
[[-0.        ]
 [-0.18972106]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.610839  ]
 [-0.        ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.005356232635676861, (0.00015254295, 0.18178396, 0.048775285, 0.004950724)
   validation loss 0.005041891243308783, (3.0236268e-05, 0.03980783, 0.011788098, 0.004950724)
decoder loss ratio: 0.003605, decoder SINDy loss  ratio: 0.000765
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99989355]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8471788]
 [ 0.       ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024240114726126194, (0.00012366711, 0.16862531, 0.046743, 0.002058198)
   validation loss 0.002136775990948081, (2.0408175e-05, 0.03648048, 0.011269148, 0.002058198)
decoder loss ratio: 0.002433, decoder SINDy loss  ratio: 0.000731
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99990803]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.86188096]
 [-0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002391236834228039, (0.000121772646, 0.1503499, 0.041979402, 0.0020520496)
   validation loss 0.0021251917351037264, (1.9987947e-05, 0.03278201, 0.010303034, 0.0020520496)
decoder loss ratio: 0.002383, decoder SINDy loss  ratio: 0.000669
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999124]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8611079]
 [ 0.       ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023558244574815035, (0.00010340689, 0.13423233, 0.041038983, 0.002040511)
   validation loss 0.002106443978846073, (1.4268676e-05, 0.030034812, 0.01003253, 0.002040511)
decoder loss ratio: 0.001701, decoder SINDy loss  ratio: 0.000651
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999915]
 [0.      ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8590531]
 [-0.       ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002321767620742321, (0.0001044516, 0.12199333, 0.03747325, 0.00202385)
   validation loss 0.0020870696753263474, (1.4830806e-05, 0.02771576, 0.009400617, 0.00202385)
decoder loss ratio: 0.001768, decoder SINDy loss  ratio: 0.000610
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99991757]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8577458]
 [ 0.       ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022421865724027157, (9.022835e-05, 0.110815115, 0.036985926, 0.0019614878)
   validation loss 0.0020187345799058676, (1.0525066e-05, 0.0257708, 0.009086615, 0.0019614878)
decoder loss ratio: 0.001255, decoder SINDy loss  ratio: 0.000590
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99991935]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8560118]
 [-0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002223443007096648, (9.168374e-05, 0.10236132, 0.033047162, 0.0019614054)
   validation loss 0.0020147161558270454, (1.1340434e-05, 0.024059396, 0.008153472, 0.0019614054)
decoder loss ratio: 0.001352, decoder SINDy loss  ratio: 0.000529
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999215]
 [0.       ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.85494983]
 [ 0.        ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022123060189187527, (8.157656e-05, 0.09451223, 0.032945298, 0.0019612773)
   validation loss 0.002010831842198968, (8.379427e-06, 0.022692956, 0.008008071, 0.0019612773)
decoder loss ratio: 0.000999, decoder SINDy loss  ratio: 0.000520
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99992275]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.85347193]
 [-0.        ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022037785965949297, (8.373462e-05, 0.08885443, 0.030878877, 0.0019612068)
   validation loss 0.002009828807786107, (9.353287e-06, 0.021583708, 0.007637928, 0.0019612068)
decoder loss ratio: 0.001115, decoder SINDy loss  ratio: 0.000496
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999495]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9192721]
 [ 0.       ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002292160177603364, (8.700896e-05, 0.18562597, 0.046105538, 0.0019653423)
   validation loss 0.002053729724138975, (1.558355e-05, 0.061479162, 0.013945982, 0.0019653423)
decoder loss ratio: 0.001858, decoder SINDy loss  ratio: 0.000905
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999549]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9483466]
 [-0.       ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023658007849007845, (0.000108336215, 0.19689196, 0.05588132, 0.0019682134)
   validation loss 0.002112111309543252, (5.16945e-05, 0.063062936, 0.017810045, 0.0019682134)
decoder loss ratio: 0.006163, decoder SINDy loss  ratio: 0.001156
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999589]
 [0.       ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.97302586]
 [ 0.        ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022287871688604355, (8.467538e-05, 0.16831791, 0.033123955, 0.0019700762)
   validation loss 0.002044647466391325, (3.0073079e-05, 0.050503094, 0.008394619, 0.0019700762)
decoder loss ratio: 0.003585, decoder SINDy loss  ratio: 0.000545
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999606]
 [0.       ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.98117465]
 [-0.        ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022170126903802156, (8.052657e-05, 0.1473188, 0.03166032, 0.0019708185)
   validation loss 0.002037354512140155, (2.5700032e-05, 0.0422833, 0.007744346, 0.0019708185)
decoder loss ratio: 0.003064, decoder SINDy loss  ratio: 0.000503
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999628]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9946347]
 [ 0.       ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002211034530773759, (7.338509e-05, 0.1412461, 0.03190073, 0.0019710835)
   validation loss 0.0020324087236076593, (1.9853604e-05, 0.040908583, 0.0078852605, 0.0019710835)
decoder loss ratio: 0.002367, decoder SINDy loss  ratio: 0.000512
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996465]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9996691]
 [-0.       ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002192739862948656, (7.044308e-05, 0.12757011, 0.028865473, 0.0019715908)
   validation loss 0.0020249749068170786, (1.7371816e-05, 0.036092144, 0.0068415436, 0.0019715908)
decoder loss ratio: 0.002071, decoder SINDy loss  ratio: 0.000444
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999661]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0039641]
 [ 0.       ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022418659646064043, (7.143781e-05, 0.1309299, 0.03833439, 0.0019722097)
   validation loss 0.0020530447363853455, (1.9344967e-05, 0.039142653, 0.011906617, 0.0019722097)
decoder loss ratio: 0.002306, decoder SINDy loss  ratio: 0.000773
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999669]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0077119]
 [-0.       ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021881628781557083, (6.4944055e-05, 0.10974298, 0.029076058, 0.0019723515)
   validation loss 0.002023248467594385, (1.4732267e-05, 0.031018939, 0.00692275, 0.0019723515)
decoder loss ratio: 0.001756, decoder SINDy loss  ratio: 0.000449
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999677]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.007418]
 [ 0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022312775254249573, (6.809098e-05, 0.10938502, 0.03718816, 0.0019717764)
   validation loss 0.0020437282510101795, (1.686889e-05, 0.03355192, 0.010681069, 0.0019717764)
decoder loss ratio: 0.002011, decoder SINDy loss  ratio: 0.000693
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999684]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0052832]
 [-0.       ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022287839092314243, (7.004909e-05, 0.10270504, 0.036395058, 0.0019716243)
   validation loss 0.002046052133664489, (1.904383e-05, 0.032115962, 0.01075563, 0.0019716243)
decoder loss ratio: 0.002270, decoder SINDy loss  ratio: 0.000698
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999692]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0069774]
 [ 0.       ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002151340479031205, (5.5604953e-05, 0.069581814, 0.02412967, 0.001971608)
   validation loss 0.0020086036529392004, (9.2772225e-06, 0.018719068, 0.0053565004, 0.001971608)
decoder loss ratio: 0.001106, decoder SINDy loss  ratio: 0.000348
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996984]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0065836]
 [-0.       ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002149523701518774, (5.3844877e-05, 0.06801452, 0.02413781, 0.001971589)
   validation loss 0.002009044401347637, (9.541167e-06, 0.019040685, 0.005392442, 0.001971589)
decoder loss ratio: 0.001138, decoder SINDy loss  ratio: 0.000350
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999706]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0026052]
 [ 0.       ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021998868323862553, (5.3300577e-05, 0.057747804, 0.034570754, 0.001970845)
   validation loss 0.0020380064379423857, (1.0834572e-05, 0.016384171, 0.011101529, 0.001970845)
decoder loss ratio: 0.001292, decoder SINDy loss  ratio: 0.000721
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999713]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0013613]
 [-0.       ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00214984267950058, (4.8993716e-05, 0.056191023, 0.025479587, 0.0019706415)
   validation loss 0.0020090092439204454, (7.839297e-06, 0.015611403, 0.005949564, 0.0019706415)
decoder loss ratio: 0.000935, decoder SINDy loss  ratio: 0.000386
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999718]
 [0.       ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.99864495]
 [ 0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002167578088119626, (4.686899e-05, 0.047859803, 0.02957711, 0.0019704306)
   validation loss 0.0020224631298333406, (8.155943e-06, 0.012856378, 0.008646771, 0.0019704306)
decoder loss ratio: 0.000972, decoder SINDy loss  ratio: 0.000561
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999724]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9960158]
 [-0.       ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021306260023266077, (4.3838365e-05, 0.044810157, 0.022880819, 0.001970143)
   validation loss 0.0020030594896525145, (5.810214e-06, 0.011570784, 0.005305538, 0.001970143)
decoder loss ratio: 0.000693, decoder SINDy loss  ratio: 0.000344
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999727]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9927697]
 [ 0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002116179559379816, (4.202522e-05, 0.040770415, 0.02051385, 0.0019695465)
   validation loss 0.0019976329058408737, (5.6862164e-06, 0.010364327, 0.004376389, 0.0019695465)
decoder loss ratio: 0.000678, decoder SINDy loss  ratio: 0.000284
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999732]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9898259]
 [-0.       ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021179215982556343, (3.9222065e-05, 0.03991165, 0.021486385, 0.001969272)
   validation loss 0.0019999907817691565, (4.409981e-06, 0.010167719, 0.0051600924, 0.001969272)
decoder loss ratio: 0.000526, decoder SINDy loss  ratio: 0.000335
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997383]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9858956]
 [ 0.       ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002122576581314206, (3.7694743e-05, 0.039691288, 0.022795679, 0.0019689188)
   validation loss 0.0020039186347275972, (4.762919e-06, 0.010446555, 0.0059428965, 0.0019689188)
decoder loss ratio: 0.000568, decoder SINDy loss  ratio: 0.000386
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999741]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.980558]
 [-0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021093867253512144, (3.53622e-05, 0.03504442, 0.02077427, 0.001968401)
   validation loss 0.002001069951802492, (4.4668686e-06, 0.009232949, 0.0055480674, 0.001968401)
decoder loss ratio: 0.000533, decoder SINDy loss  ratio: 0.000360
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999763]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1034054]
 [ 0.       ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002708995947614312, (6.22047e-05, 0.13705948, 0.13200134, 0.0019799315)
   validation loss 0.0022556143812835217, (2.8584265e-05, 0.04589281, 0.048960775, 0.0019799315)
decoder loss ratio: 0.003408, decoder SINDy loss  ratio: 0.003178
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999763]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1150227]
 [-0.       ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022270402405411005, (6.420612e-05, 0.12989956, 0.035019044, 0.001981244)
   validation loss 0.002065804786980152, (4.0744573e-05, 0.03946152, 0.008368629, 0.001981244)
decoder loss ratio: 0.004858, decoder SINDy loss  ratio: 0.000543
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1276376]
 [ 0.       ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021639843471348286, (5.6129113e-05, 0.1026313, 0.024061328, 0.001982417)
   validation loss 0.0020448025315999985, (3.3254e-05, 0.03166843, 0.0055096485, 0.001982417)
decoder loss ratio: 0.003965, decoder SINDy loss  ratio: 0.000358
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1267122]
 [-0.       ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002323007211089134, (5.450275e-05, 0.11697914, 0.056072377, 0.0019822936)
   validation loss 0.002113244030624628, (3.463509e-05, 0.034447163, 0.018918592, 0.0019822936)
decoder loss ratio: 0.004129, decoder SINDy loss  ratio: 0.001228
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1319194]
 [ 0.       ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002156237605959177, (4.894951e-05, 0.101077095, 0.02391959, 0.0019826363)
   validation loss 0.002042447915300727, (2.9726667e-05, 0.029899286, 0.005718021, 0.0019826363)
decoder loss ratio: 0.003544, decoder SINDy loss  ratio: 0.000371
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-1.12924]
 [-0.     ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002192139159888029, (4.5077664e-05, 0.12806472, 0.031628832, 0.001982514)
   validation loss 0.0020576256792992353, (2.8145609e-05, 0.042594295, 0.00896726, 0.001982514)
decoder loss ratio: 0.003356, decoder SINDy loss  ratio: 0.000582
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1237571]
 [ 0.       ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002167650731280446, (4.0139792e-05, 0.077573076, 0.028350385, 0.0019818803)
   validation loss 0.002049393951892853, (2.49093e-05, 0.02464129, 0.008274477, 0.0019818803)
decoder loss ratio: 0.002970, decoder SINDy loss  ratio: 0.000537
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1182841]
 [-0.       ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002246874151751399, (4.8816193e-05, 0.11171776, 0.042183, 0.001981557)
   validation loss 0.0020879660733044147, (2.9337414e-05, 0.041466683, 0.014999653, 0.001981557)
decoder loss ratio: 0.003498, decoder SINDy loss  ratio: 0.000974
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1155574]
 [ 0.       ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021155274007469416, (2.90875e-05, 0.068838775, 0.02042143, 0.0019808908)
   validation loss 0.002027080859988928, (1.7018565e-05, 0.02265277, 0.0056077973, 0.0019808908)
decoder loss ratio: 0.002029, decoder SINDy loss  ratio: 0.000364
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1120765]
 [-0.       ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020963961724191904, (2.3909479e-05, 0.06447959, 0.01774115, 0.0019805569)
   validation loss 0.0020166959147900343, (1.25159195e-05, 0.020440457, 0.0045202286, 0.0019805569)
decoder loss ratio: 0.001492, decoder SINDy loss  ratio: 0.000293
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1012075]
 [ 0.       ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002219037851318717, (2.9871862e-05, 0.090041615, 0.04099877, 0.00197967)
   validation loss 0.002065361710265279, (1.801455e-05, 0.03133616, 0.013222059, 0.00197967)
decoder loss ratio: 0.002148, decoder SINDy loss  ratio: 0.000858
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0990403]
 [-0.       ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020947351586073637, (1.9730951e-05, 0.056668866, 0.018587274, 0.0019792344)
   validation loss 0.0020191336516290903, (1.2281141e-05, 0.018775083, 0.0053358623, 0.0019792344)
decoder loss ratio: 0.001464, decoder SINDy loss  ratio: 0.000346
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0931237]
 [ 0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020704874768853188, (1.5718013e-05, 0.050606057, 0.014739848, 0.0019785399)
   validation loss 0.002007207367569208, (9.521984e-06, 0.016145779, 0.0036676384, 0.0019785399)
decoder loss ratio: 0.001135, decoder SINDy loss  ratio: 0.000238
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0897616]
 [-0.       ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00206826557405293, (1.5374942e-05, 0.047801685, 0.014463185, 0.0019781846)
   validation loss 0.0020080108661204576, (1.0551297e-05, 0.016116621, 0.003693819, 0.0019781846)
decoder loss ratio: 0.001258, decoder SINDy loss  ratio: 0.000240
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0878023]
 [ 0.       ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020820789504796267, (1.5155369e-05, 0.061013192, 0.017142685, 0.0019781594)
   validation loss 0.002014169469475746, (9.43151e-06, 0.021275733, 0.005102949, 0.0019781594)
decoder loss ratio: 0.001124, decoder SINDy loss  ratio: 0.000331
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0867875]
 [-0.       ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002065445529296994, (1.2251011e-05, 0.048683036, 0.014549168, 0.0019780146)
   validation loss 0.0020066662691533566, (7.4692007e-06, 0.016417176, 0.0040723435, 0.0019780146)
decoder loss ratio: 0.000890, decoder SINDy loss  ratio: 0.000264
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0829983]
 [ 0.       ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00211669085547328, (2.0535323e-05, 0.07890149, 0.022915699, 0.001977632)
   validation loss 0.002031236421316862, (1.2920291e-05, 0.031234821, 0.007824447, 0.001977632)
decoder loss ratio: 0.001540, decoder SINDy loss  ratio: 0.000508
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0802923]
 [-0.       ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002280752407386899, (1.9672138e-05, 0.06548576, 0.05610178, 0.001977297)
   validation loss 0.002100385492667556, (1.3798953e-05, 0.024216918, 0.021615745, 0.001977297)
decoder loss ratio: 0.001645, decoder SINDy loss  ratio: 0.001403
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0819957]
 [ 0.       ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020453762263059616, (8.452436e-06, 0.03364246, 0.011582434, 0.0019773296)
   validation loss 0.001998364459723234, (5.9907475e-06, 0.01037094, 0.002905114, 0.0019773296)
decoder loss ratio: 0.000714, decoder SINDy loss  ratio: 0.000189
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0804793]
 [-0.       ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002042601350694895, (7.7638815e-06, 0.031920712, 0.011209932, 0.0019771918)
   validation loss 0.001997342798858881, (5.639357e-06, 0.0096319355, 0.002806013, 0.0019771918)
decoder loss ratio: 0.000672, decoder SINDy loss  ratio: 0.000182
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1968496]
 [ 0.       ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021236096508800983, (2.9695384e-05, 0.09822877, 0.019993238, 0.0019890366)
   validation loss 0.002035175682976842, (1.346822e-05, 0.034550995, 0.0061886725, 0.0019890366)
decoder loss ratio: 0.001606, decoder SINDy loss  ratio: 0.000402
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2020373]
 [-0.       ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002203959273174405, (3.7593385e-05, 0.18336087, 0.0334267, 0.0019900643)
   validation loss 0.0020812139846384525, (3.1805444e-05, 0.06651914, 0.011203648, 0.0019900643)
decoder loss ratio: 0.003792, decoder SINDy loss  ratio: 0.000727
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2039714]
 [ 0.       ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021552261896431446, (3.1194013e-05, 0.13600872, 0.025456397, 0.0019899497)
   validation loss 0.0020669051446020603, (2.996127e-05, 0.04608891, 0.008937918, 0.0019899497)
decoder loss ratio: 0.003572, decoder SINDy loss  ratio: 0.000580
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2098055]
 [-0.       ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021422479767352343, (3.9931107e-05, 0.14090827, 0.020916248, 0.0019906901)
   validation loss 0.0020651591476053, (4.1567044e-05, 0.04540392, 0.0061263563, 0.0019906901)
decoder loss ratio: 0.004956, decoder SINDy loss  ratio: 0.000398
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2079027]
 [ 0.       ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00213378993794322, (2.5213398e-05, 0.12916273, 0.022332406, 0.0019904564)
   validation loss 0.0020535332150757313, (2.3080338e-05, 0.041924886, 0.007580039, 0.0019904564)
decoder loss ratio: 0.002752, decoder SINDy loss  ratio: 0.000492
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2031192]
 [-0.       ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022728522308170795, (3.3332624e-05, 0.12318172, 0.048697937, 0.0019898708)
   validation loss 0.002142093377187848, (3.8322298e-05, 0.044722725, 0.022332838, 0.0019898708)
decoder loss ratio: 0.004569, decoder SINDy loss  ratio: 0.001449
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2097888]
 [ 0.       ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021040174178779125, (1.9535379e-05, 0.10675369, 0.017721115, 0.0019905388)
   validation loss 0.0020375915337353945, (1.9824662e-05, 0.03382914, 0.005107324, 0.0019905388)
decoder loss ratio: 0.002364, decoder SINDy loss  ratio: 0.000331
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2104797]
 [-0.       ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021513644605875015, (1.8547737e-05, 0.1424896, 0.027015204, 0.0019906163)
   validation loss 0.0020587292965501547, (1.8374987e-05, 0.051304962, 0.009434564, 0.0019906163)
decoder loss ratio: 0.002191, decoder SINDy loss  ratio: 0.000612
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.210568]
 [ 0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002113295253366232, (2.4975174e-05, 0.12482392, 0.018283537, 0.0019906613)
   validation loss 0.0020408446434885263, (2.008846e-05, 0.043021403, 0.005588778, 0.0019906613)
decoder loss ratio: 0.002395, decoder SINDy loss  ratio: 0.000363
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-1.204433]
 [-0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022860527969896793, (3.2978285e-05, 0.16185513, 0.050987553, 0.001990044)
   validation loss 0.0021035815589129925, (2.5902747e-05, 0.06008112, 0.016926141, 0.001990044)
decoder loss ratio: 0.003088, decoder SINDy loss  ratio: 0.001099
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2106606]
 [ 0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002072363393381238, (1.1640011e-05, 0.08722215, 0.013140753, 0.0019906585)
   validation loss 0.002019996289163828, (8.885811e-06, 0.029059017, 0.0037998236, 0.0019906585)
decoder loss ratio: 0.001059, decoder SINDy loss  ratio: 0.000247
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2009012]
 [-0.       ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002131203655153513, (1.3722612e-05, 0.10156007, 0.0245273, 0.0019897665)
   validation loss 0.0020462600514292717, (1.11985455e-05, 0.03724755, 0.008686511, 0.0019897665)
decoder loss ratio: 0.001335, decoder SINDy loss  ratio: 0.000564
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1972102]
 [ 0.       ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002067928435280919, (1.3882044e-05, 0.07845223, 0.012194871, 0.0019891495)
   validation loss 0.002020328538492322, (1.1488973e-05, 0.027182978, 0.003666192, 0.0019891495)
decoder loss ratio: 0.001370, decoder SINDy loss  ratio: 0.000238
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1916097]
 [-0.       ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002062551211565733, (1.0596481e-05, 0.07053771, 0.011975743, 0.0019885493)
   validation loss 0.0020159976556897163, (9.1375105e-06, 0.024301788, 0.003419174, 0.0019885493)
decoder loss ratio: 0.001089, decoder SINDy loss  ratio: 0.000222
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-1.185515]
 [ 0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020699568558484316, (1.4608617e-05, 0.08539429, 0.01262167, 0.0019879702)
   validation loss 0.0020183585584163666, (1.0229283e-05, 0.030245807, 0.0037293704, 0.0019879702)
decoder loss ratio: 0.001220, decoder SINDy loss  ratio: 0.000242
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1826138]
 [-0.       ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002060344908386469, (9.264197e-06, 0.063626684, 0.01206444, 0.0019875772)
   validation loss 0.0020139426924288273, (7.4367576e-06, 0.022086235, 0.0035648793, 0.0019875772)
decoder loss ratio: 0.000887, decoder SINDy loss  ratio: 0.000231
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1812236]
 [ 0.       ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020564370788633823, (8.730169e-06, 0.06718986, 0.011387596, 0.0019874095)
   validation loss 0.00201216503046453, (6.7362025e-06, 0.023681384, 0.003367065, 0.0019874095)
decoder loss ratio: 0.000803, decoder SINDy loss  ratio: 0.000219
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1808958]
 [-0.       ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020602019503712654, (9.817304e-06, 0.0710303, 0.011888529, 0.0019873905)
   validation loss 0.002014135243371129, (7.291304e-06, 0.024618622, 0.0036445165, 0.0019873905)
decoder loss ratio: 0.000869, decoder SINDy loss  ratio: 0.000237
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1766591]
 [ 0.       ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002051951829344034, (8.880594e-06, 0.066978015, 0.010558148, 0.0019869315)
   validation loss 0.0020097855012863874, (6.0799352e-06, 0.023700288, 0.0031177816, 0.0019869315)
decoder loss ratio: 0.000725, decoder SINDy loss  ratio: 0.000202
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1720581]
 [-0.       ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021165977232158184, (1.5466378e-05, 0.07806291, 0.02213471, 0.0019865546)
   validation loss 0.002039605751633644, (1.0881534e-05, 0.030584617, 0.008128083, 0.0019865546)
decoder loss ratio: 0.001297, decoder SINDy loss  ratio: 0.000528
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2339542]
 [ 0.       ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022891229018568993, (6.158168e-05, 0.4334637, 0.042413387, 0.001993801)
   validation loss 0.0021051610819995403, (2.9383305e-05, 0.19251402, 0.014470225, 0.001993801)
decoder loss ratio: 0.003503, decoder SINDy loss  ratio: 0.000939
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2373995]
 [-0.       ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021412158384919167, (3.1679552e-05, 0.15336405, 0.021656364, 0.0019935863)
   validation loss 0.0020745955407619476, (3.364751e-05, 0.054746754, 0.008924876, 0.0019935863)
decoder loss ratio: 0.004011, decoder SINDy loss  ratio: 0.000579
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2458745]
 [ 0.       ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022786397021263838, (4.0464372e-05, 0.2843237, 0.04586115, 0.0019946534)
   validation loss 0.0021323219407349825, (3.4938395e-05, 0.108445324, 0.019461568, 0.0019946534)
decoder loss ratio: 0.004165, decoder SINDy loss  ratio: 0.001263
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2607001]
 [-0.       ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002524416195228696, (4.665364e-05, 0.35452977, 0.09273978, 0.0019963372)
   validation loss 0.002229672856628895, (3.9298804e-05, 0.13676515, 0.037439723, 0.0019963372)
decoder loss ratio: 0.004685, decoder SINDy loss  ratio: 0.002430
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-1.263857]
 [ 0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021784179843962193, (2.4916682e-05, 0.16495132, 0.029750722, 0.0019965002)
   validation loss 0.0020782705396413803, (2.4745475e-05, 0.054026294, 0.010864693, 0.0019965002)
decoder loss ratio: 0.002950, decoder SINDy loss  ratio: 0.000705
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2541561]
 [-0.       ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020961372647434473, (2.053533e-05, 0.16592821, 0.014382285, 0.001995394)
   validation loss 0.002043005544692278, (2.2141821e-05, 0.052656744, 0.0045673647, 0.001995394)
decoder loss ratio: 0.002640, decoder SINDy loss  ratio: 0.000296
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2542207]
 [ 0.       ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022468073293566704, (2.71159e-05, 0.20284021, 0.042824797, 0.0019954254)
   validation loss 0.002093994989991188, (2.2801172e-05, 0.0687443, 0.014466247, 0.0019954254)
decoder loss ratio: 0.002718, decoder SINDy loss  ratio: 0.000939
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2450498]
 [-0.       ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023732990957796574, (3.9746752e-05, 0.26451823, 0.0651199, 0.001994727)
   validation loss 0.002186715602874756, (3.0575648e-05, 0.11361541, 0.031146456, 0.001994727)
decoder loss ratio: 0.003645, decoder SINDy loss  ratio: 0.002021
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2458385]
 [ 0.       ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021695687901228666, (1.6701946e-05, 0.21772444, 0.029490693, 0.0019945272)
   validation loss 0.0020622110459953547, (1.532033e-05, 0.082706645, 0.009645641, 0.0019945272)
decoder loss ratio: 0.001827, decoder SINDy loss  ratio: 0.000626
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2416902]
 [-0.       ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021264911629259586, (2.5969923e-05, 0.1804157, 0.019445252, 0.0019942743)
   validation loss 0.002055749297142029, (1.8475368e-05, 0.070751086, 0.007892406, 0.0019942743)
decoder loss ratio: 0.002203, decoder SINDy loss  ratio: 0.000512
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2394117]
 [ 0.       ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021217167377471924, (1.746934e-05, 0.13216053, 0.02075423, 0.0019938683)
   validation loss 0.002043651882559061, (1.2758624e-05, 0.049377013, 0.006911239, 0.0019938683)
decoder loss ratio: 0.001521, decoder SINDy loss  ratio: 0.000449
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2312424]
 [-0.       ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002076900564134121, (1.62378e-05, 0.12131143, 0.012346403, 0.0019928652)
   validation loss 0.0020252850372344255, (1.0094078e-05, 0.04479089, 0.004017223, 0.0019928652)
decoder loss ratio: 0.001203, decoder SINDy loss  ratio: 0.000261
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2238392]
 [ 0.       ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021420654375106096, (1.7313325e-05, 0.13720104, 0.025144879, 0.0019921677)
   validation loss 0.002048137132078409, (1.09199145e-05, 0.052951667, 0.008480392, 0.0019921677)
decoder loss ratio: 0.001302, decoder SINDy loss  ratio: 0.000550
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2314848]
 [-0.       ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020915151108056307, (1.4274537e-05, 0.10792503, 0.015788767, 0.0019929004)
   validation loss 0.002032578457146883, (9.076793e-06, 0.043842588, 0.005681816, 0.0019929004)
decoder loss ratio: 0.001082, decoder SINDy loss  ratio: 0.000369
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2221417]
 [ 0.       ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021066057961434126, (1.4558127e-05, 0.117881045, 0.018836658, 0.0019919702)
   validation loss 0.002040102146565914, (1.0285426e-05, 0.045892164, 0.0071103675, 0.0019919702)
decoder loss ratio: 0.001226, decoder SINDy loss  ratio: 0.000461
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2126316]
 [-0.       ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021368979942053556, (1.8676015e-05, 0.13644683, 0.024086483, 0.0019909672)
   validation loss 0.0020527970045804977, (1.2161193e-05, 0.054776873, 0.009385946, 0.0019909672)
decoder loss ratio: 0.001450, decoder SINDy loss  ratio: 0.000609
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2073644]
 [ 0.       ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020619940478354692, (1.3146893e-05, 0.090407796, 0.0108315395, 0.001990169)
   validation loss 0.0020165047608315945, (7.697093e-06, 0.035187226, 0.003375828, 0.001990169)
decoder loss ratio: 0.000918, decoder SINDy loss  ratio: 0.000219
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-1.203442]
 [-0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020491566974669695, (8.2677325e-06, 0.08480829, 0.009381248, 0.0019897423)
   validation loss 0.0020115203224122524, (5.7480906e-06, 0.032212872, 0.0028838478, 0.0019897423)
decoder loss ratio: 0.000685, decoder SINDy loss  ratio: 0.000187
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-1.200484]
 [ 0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020503599662333727, (1.0744828e-05, 0.0852608, 0.009178427, 0.0019894599)
   validation loss 0.0020117731764912605, (6.19135e-06, 0.032633692, 0.0028980465, 0.0019894599)
decoder loss ratio: 0.000738, decoder SINDy loss  ratio: 0.000188
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1940744]
 [-0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021459502167999744, (1.5999649e-05, 0.117227644, 0.027031252, 0.001988933)
   validation loss 0.0020644727628678083, (1.0317396e-05, 0.051141392, 0.012533081, 0.001988933)
decoder loss ratio: 0.001230, decoder SINDy loss  ratio: 0.000813
THRESHOLDING: 1 active coefficients
REFINEMENT
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9.549719106871635e-05, (8.503671e-06, 0.1785115, 0.01561359, 0.001988949)
   validation loss 4.2508119804551825e-05, (5.452984e-06, 0.08735887, 0.006537439, 0.001988949)
decoder loss ratio: 0.000650, decoder SINDy loss  ratio: 0.000424
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6.385519372997805e-05, (7.455478e-06, 0.07586543, 0.01052129, 0.001988923)
   validation loss 2.689918619580567e-05, (4.7367325e-06, 0.029178463, 0.0041407063, 0.001988923)
decoder loss ratio: 0.000565, decoder SINDy loss  ratio: 0.000269
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5.326247264747508e-05, (8.435183e-06, 0.07126689, 0.008252789, 0.0019883343)
   validation loss 1.8476061086403206e-05, (4.230194e-06, 0.027486805, 0.0025743053, 0.0019883343)
decoder loss ratio: 0.000504, decoder SINDy loss  ratio: 0.000167
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5.200425221119076e-05, (5.5233218e-06, 0.06911552, 0.008605031, 0.0019879523)
   validation loss 1.8569364328868687e-05, (3.4834827e-06, 0.025780546, 0.0027593712, 0.0019879523)
decoder loss ratio: 0.000415, decoder SINDy loss  ratio: 0.000179
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9.086625505005941e-05, (8.032453e-06, 0.07126547, 0.015854107, 0.0019873735)
   validation loss 3.2064846891444176e-05, (3.7306374e-06, 0.028649056, 0.005380351, 0.0019873735)
decoder loss ratio: 0.000445, decoder SINDy loss  ratio: 0.000349
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5.5641892686253414e-05, (5.8596474e-06, 0.0683046, 0.009273403, 0.0019869343)
   validation loss 2.1092233509989455e-05, (3.3158876e-06, 0.02602645, 0.0032950048, 0.0019869343)
decoder loss ratio: 0.000395, decoder SINDy loss  ratio: 0.000214
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.477632319321856e-05, (4.7240546e-06, 0.058760222, 0.007422852, 0.0019865239)
   validation loss 1.4810926586505957e-05, (2.4490878e-06, 0.02220788, 0.002250289, 0.0019865239)
decoder loss ratio: 0.000292, decoder SINDy loss  ratio: 0.000146
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.4323802285362035e-05, (5.1213037e-06, 0.05850515, 0.007255448, 0.0019861488)
   validation loss 1.4384107998921536e-05, (2.394197e-06, 0.021915218, 0.00217883, 0.0019861488)
decoder loss ratio: 0.000285, decoder SINDy loss  ratio: 0.000141
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.152858673478477e-05, (4.286261e-06, 0.05401696, 0.0069082957, 0.0019857832)
   validation loss 1.3433564163278788e-05, (2.0747314e-06, 0.020180235, 0.0020699643, 0.0019857832)
decoder loss ratio: 0.000247, decoder SINDy loss  ratio: 0.000134
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.12082918046508e-05, (3.6617691e-06, 0.051634513, 0.0069929594, 0.0019854605)
   validation loss 1.3130221304891165e-05, (1.7686647e-06, 0.019285934, 0.002079452, 0.0019854605)
decoder loss ratio: 0.000211, decoder SINDy loss  ratio: 0.000135
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.011556666227989e-05, (3.4001162e-06, 0.05002857, 0.0068428046, 0.0019851744)
   validation loss 1.2800686818081886e-05, (1.7141953e-06, 0.018515164, 0.0020321466, 0.0019851744)
decoder loss ratio: 0.000204, decoder SINDy loss  ratio: 0.000132
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.09856038459111e-05, (3.2128426e-06, 0.049045365, 0.0070640985, 0.0019848763)
   validation loss 1.3813898476655595e-05, (1.5805342e-06, 0.018223973, 0.0022644333, 0.0019848763)
decoder loss ratio: 0.000188, decoder SINDy loss  ratio: 0.000147
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.865530379698612e-05, (3.3524993e-06, 0.047112618, 0.0065894346, 0.0019846295)
   validation loss 1.2092950782971457e-05, (1.5343271e-06, 0.017333385, 0.0019383909, 0.0019846295)
decoder loss ratio: 0.000183, decoder SINDy loss  ratio: 0.000126
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.856400871882215e-05, (3.0741935e-06, 0.04610808, 0.0066368827, 0.001984369)
   validation loss 1.1951569831580855e-05, (1.435353e-06, 0.016912356, 0.0019341198, 0.001984369)
decoder loss ratio: 0.000171, decoder SINDy loss  ratio: 0.000126
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.750618998310529e-05, (3.0146557e-06, 0.044555027, 0.006452757, 0.0019841227)
   validation loss 1.1510916920087766e-05, (1.3618766e-06, 0.016347868, 0.0018663295, 0.0019841227)
decoder loss ratio: 0.000162, decoder SINDy loss  ratio: 0.000121
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.7137913750484586e-05, (2.886013e-06, 0.0435673, 0.0064147078, 0.0019838985)
   validation loss 1.131044791691238e-05, (1.292269e-06, 0.015907355, 0.0018445622, 0.0019838985)
decoder loss ratio: 0.000154, decoder SINDy loss  ratio: 0.000120
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.660608854261227e-05, (2.8886654e-06, 0.042200662, 0.0063214777, 0.0019836898)
   validation loss 1.1085253390774596e-05, (1.2699968e-06, 0.015352866, 0.0018095226, 0.0019836898)
decoder loss ratio: 0.000151, decoder SINDy loss  ratio: 0.000117
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.6470984923653305e-05, (2.7986193e-06, 0.04141106, 0.006320363, 0.0019834982)
   validation loss 1.0941488653770648e-05, (1.2096307e-06, 0.01506212, 0.0017957505, 0.0019834982)
decoder loss ratio: 0.000144, decoder SINDy loss  ratio: 0.000117
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.61580059689004e-05, (2.7456274e-06, 0.040487364, 0.0062776026, 0.001983322)
   validation loss 1.0777146599139087e-05, (1.1689582e-06, 0.014693756, 0.0017747001, 0.001983322)
decoder loss ratio: 0.000139, decoder SINDy loss  ratio: 0.000115
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.587402170524001e-05, (2.6954774e-06, 0.039632566, 0.006239383, 0.0019831585)
   validation loss 1.0635005310177803e-05, (1.1343103e-06, 0.014354974, 0.0017565894, 0.0019831585)
decoder loss ratio: 0.000135, decoder SINDy loss  ratio: 0.000114
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.561182165867649e-05, (2.6623986e-06, 0.03879603, 0.0062019243, 0.001983007)
   validation loss 1.051498475135304e-05, (1.1098621e-06, 0.014033476, 0.0017406899, 0.001983007)
decoder loss ratio: 0.000132, decoder SINDy loss  ratio: 0.000113
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.944674608646892e-05, (4.7553103e-06, 0.041214872, 0.0065261386, 0.0019850691)
   validation loss 1.1964722943957895e-05, (1.900817e-06, 0.014600589, 0.0018667754, 0.0019850691)
decoder loss ratio: 0.000227, decoder SINDy loss  ratio: 0.000121
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5.074149157735519e-05, (7.678798e-06, 0.050944526, 0.008103094, 0.0019839485)
   validation loss 1.728240204101894e-05, (3.7202383e-06, 0.019509936, 0.0025173335, 0.0019839485)
decoder loss ratio: 0.000444, decoder SINDy loss  ratio: 0.000163
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00011390818690415472, (1.263354e-05, 0.053003315, 0.019724896, 0.001983578)
   validation loss 4.133052425459027e-05, (5.6610156e-06, 0.020764444, 0.0069262567, 0.001983578)
decoder loss ratio: 0.000675, decoder SINDy loss  ratio: 0.000450
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5.853774200659245e-05, (4.84851e-06, 0.04770868, 0.01026076, 0.0019834915)
   validation loss 2.077708995784633e-05, (2.8344696e-06, 0.01778334, 0.0034106907, 0.0019834915)
decoder loss ratio: 0.000338, decoder SINDy loss  ratio: 0.000221
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.674265099107288e-05, (4.0867844e-06, 0.03864699, 0.0061447034, 0.0019831664)
   validation loss 1.1331107089063153e-05, (2.0074926e-06, 0.013665627, 0.0017280667, 0.0019831664)
decoder loss ratio: 0.000239, decoder SINDy loss  ratio: 0.000112
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.690644007292576e-05, (4.491112e-06, 0.037224792, 0.0061108177, 0.001982944)
   validation loss 1.1430433005443774e-05, (1.9212446e-06, 0.013269461, 0.001769143, 0.001982944)
decoder loss ratio: 0.000229, decoder SINDy loss  ratio: 0.000115
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.960269896197133e-05, (4.3397476e-06, 0.03669471, 0.006685643, 0.0019826016)
   validation loss 1.2757358490489423e-05, (1.905178e-06, 0.01364621, 0.002033974, 0.0019826016)
decoder loss ratio: 0.000227, decoder SINDy loss  ratio: 0.000132
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.65313608199358e-05, (4.0401424e-06, 0.03635575, 0.006134686, 0.0019823813)
   validation loss 1.1096661182818934e-05, (1.7215363e-06, 0.012874145, 0.0017462836, 0.0019823813)
decoder loss ratio: 0.000205, decoder SINDy loss  ratio: 0.000113
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.33015741489362e-05, (3.1506745e-06, 0.032717876, 0.0057030013, 0.0019821785)
   validation loss 9.819499609875493e-06, (1.3216763e-06, 0.011565079, 0.001583914, 0.0019821785)
decoder loss ratio: 0.000158, decoder SINDy loss  ratio: 0.000103
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.499565355014056e-05, (3.727769e-06, 0.034901742, 0.0059045595, 0.0019819392)
   validation loss 1.0633673809934407e-05, (1.5566795e-06, 0.012648895, 0.00168891, 0.0019819392)
decoder loss ratio: 0.000186, decoder SINDy loss  ratio: 0.000110
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.245425978093408e-05, (2.7511214e-06, 0.03145356, 0.005626092, 0.0019817273)
   validation loss 9.430361387785524e-06, (1.1356143e-06, 0.011116703, 0.0015477826, 0.0019817273)
decoder loss ratio: 0.000135, decoder SINDy loss  ratio: 0.000100
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.209346323274076e-05, (2.801716e-06, 0.030410916, 0.0055542407, 0.0019815536)
   validation loss 9.258600584871601e-06, (1.1071782e-06, 0.010721023, 0.0015230742, 0.0019815536)
decoder loss ratio: 0.000132, decoder SINDy loss  ratio: 0.000099
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.129215838271193e-05, (2.549377e-06, 0.029374506, 0.0054548113, 0.0019813476)
   validation loss 8.97791233001044e-06, (1.0235943e-06, 0.010338048, 0.0014874832, 0.0019813476)
decoder loss ratio: 0.000122, decoder SINDy loss  ratio: 0.000097
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.0936611437937245e-05, (2.412642e-06, 0.028703734, 0.0054177567, 0.001981163)
   validation loss 8.82098356669303e-06, (9.447732e-07, 0.010065152, 0.0014745906, 0.001981163)
decoder loss ratio: 0.000113, decoder SINDy loss  ratio: 0.000096
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.101487527601421e-05, (2.3525708e-06, 0.028354753, 0.0054489137, 0.0019809972)
   validation loss 8.843560863169841e-06, (9.1986806e-07, 0.009947605, 0.0014852624, 0.0019809972)
decoder loss ratio: 0.000110, decoder SINDy loss  ratio: 0.000096
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.055702109122649e-05, (2.2924105e-06, 0.027720585, 0.0053757164, 0.0019808388)
   validation loss 8.657244507048745e-06, (8.8808997e-07, 0.009701644, 0.0014568146, 0.0019808388)
decoder loss ratio: 0.000106, decoder SINDy loss  ratio: 0.000095/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])

Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.0239381885621697e-05, (2.2311324e-06, 0.02722171, 0.005329433, 0.0019806905)
   validation loss 8.516409252479207e-06, (8.521095e-07, 0.00954118, 0.0014374482, 0.0019806905)
decoder loss ratio: 0.000102, decoder SINDy loss  ratio: 0.000093
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.9967348382342607e-05, (2.2034815e-06, 0.026461458, 0.005288159, 0.0019805548)
   validation loss 8.389873983105645e-06, (8.2606925e-07, 0.009277912, 0.0014199818, 0.0019805548)
decoder loss ratio: 0.000098, decoder SINDy loss  ratio: 0.000092
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.9705246561206877e-05, (2.147709e-06, 0.025899466, 0.005252513, 0.0019804265)
   validation loss 8.266804798040539e-06, (7.931159e-07, 0.009079053, 0.0014039474, 0.0019804265)
decoder loss ratio: 0.000095, decoder SINDy loss  ratio: 0.000091
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.949204463220667e-05, (2.0961413e-06, 0.02538781, 0.0052253027, 0.001980306)
   validation loss 8.16056490293704e-06, (7.631491e-07, 0.008885744, 0.0013906257, 0.001980306)
decoder loss ratio: 0.000091, decoder SINDy loss  ratio: 0.000090
params['save_name']
pendulum_2022_07_08_08_06_43_630676
2022-07-08 13:13:10.586823: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-07-08 13:13:10.721461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
totalMemory: 10.76GiB freeMemory: 10.60GiB
2022-07-08 13:13:10.721492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2022-07-08 13:13:10.932423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-08 13:13:10.932456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2022-07-08 13:13:10.932461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2022-07-08 13:13:10.932529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9917 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
(50000, 2601)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 2601, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 12, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 100, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'constant', 'loss_weight_decoder': 1.0, 'loss_weight_sindy_x': 0.005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [128, 64, 32], 'epoch_size': 50000, 'batch_size': 1000, 'learning_rate': 0.001, 'data_path': '/home/marsgao/BayesianSindyAutoencoder/exmaples/pendulum/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 3001, 'refinement_epochs': 1001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.0008, 'pi': 0.083, 'c_std': 3.0, 'epsilon': 0.05, 'decay': 0.05, 'sigma': 1.0, 'init_sigma': 0.0, 'cycle_sgld': 500}
TRAINING
=========================
[[0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]]
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.1001509577035904, (0.007803907, 0.00013844328, 16.161854, 0.011537777)
   validation loss 0.1503523588180542, (0.0077209095, 0.00020645285, 26.218733, 0.011537777)
decoder loss ratio: 0.920495, decoder SINDy loss  ratio: 1.000000
=========================
[[0.7379398 ]
 [0.726838  ]
 [0.2624415 ]
 [0.73698306]
 [0.26244932]
 [0.26244655]
 [0.40558246]
 [0.26243818]
 [0.26244715]
 [0.26244846]
 [0.72489876]
 [0.2624415 ]]
[[ 7.2760624e-01]
 [ 5.2275288e-01]
 [ 3.1409826e-04]
 [ 6.3836968e-01]
 [-9.9549512e-04]
 [ 7.5659971e-04]
 [ 2.9441345e-01]
 [ 3.0583935e-05]
 [ 8.1183756e-04]
 [ 9.1431680e-04]
 [ 5.1459837e-01]
 [ 3.1797701e-04]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09994320571422577, (0.007601052, 0.012467307, 16.161856, 0.011532248)
   validation loss 0.15042084455490112, (0.007794155, 0.01551852, 26.218733, 0.011532248)
decoder loss ratio: 0.929228, decoder SINDy loss  ratio: 1.000000
=========================
[[0.16564101]
 [0.66722524]
 [0.15041363]
 [0.848808  ]
 [0.15042639]
 [0.1508431 ]
 [0.15091495]
 [0.15042247]
 [0.15085843]
 [0.15042847]
 [0.687209  ]
 [0.150427  ]]
[[ 1.4857867e-01]
 [ 3.8847449e-01]
 [ 9.5975876e-05]
 [ 6.4055222e-01]
 [-8.4783731e-04]
 [-2.0690706e-02]
 [ 2.3442037e-02]
 [ 6.1653106e-04]
 [-2.1290774e-02]
 [ 9.7046862e-04]
 [ 3.9616007e-01]
 [ 8.8218361e-04]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0999135971069336, (0.0075391573, 0.6747972, 16.161812, 0.0115316445)
   validation loss 0.1503802090883255, (0.007716509, 0.77389175, 26.218672, 0.0115316445)
decoder loss ratio: 0.919971, decoder SINDy loss  ratio: 0.999998
=========================
[[0.24730118]
 [0.91445625]
 [0.08567541]
 [0.90376675]
 [0.08567122]
 [0.88056207]
 [0.10462668]
 [0.08572524]
 [0.91535074]
 [0.08565719]
 [0.915146  ]
 [0.08599767]]
[[ 2.6567927e-01]
 [-6.7892408e-01]
 [ 1.4651802e-03]
 [-5.4988056e-01]
 [ 1.2618710e-03]
 [-4.9330273e-01]
 [-1.5102270e-01]
 [-3.8365151e-03]
 [-9.8118722e-01]
 [-5.7208166e-04]
 [-7.5256711e-01]
 [-1.5116835e-02]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.06569471210241318, (0.006085359, 31.481083, 9.300458, 0.011533014)
   validation loss 0.08339846879243851, (0.006716572, 43.90453, 12.590732, 0.011533014)
decoder loss ratio: 0.800757, decoder SINDy loss  ratio: 0.480219
=========================
[[0.94792366]
 [0.8952343 ]
 [0.05295262]
 [0.946958  ]
 [0.05285465]
 [0.94790095]
 [0.05431507]
 [0.05283124]
 [0.9483006 ]
 [0.05279844]
 [0.9310132 ]
 [0.05337711]]
[[ 7.2628897e-01]
 [-4.7504988e-01]
 [-7.5457240e-03]
 [-6.6245931e-01]
 [-3.4702120e-03]
 [-7.2333276e-01]
 [-4.4417623e-02]
 [-2.4458473e-03]
 [-1.2153208e+00]
 [ 9.7305264e-04]
 [-5.3336871e-01]
 [-2.2155983e-02]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.04169818386435509, (0.0046550604, 15.003498, 4.9519305, 0.0115332985)
   validation loss 0.04788142070174217, (0.0053540203, 20.472431, 5.9940963, 0.0115332985)
decoder loss ratio: 0.638312, decoder SINDy loss  ratio: 0.228619
THRESHOLDING: 6 active coefficients
=========================
[[0.92990226]
 [0.41751578]
 [0.        ]
 [0.13164903]
 [0.        ]
 [0.9680161 ]
 [0.        ]
 [0.        ]
 [0.96868   ]
 [0.        ]
 [0.8545331 ]
 [0.        ]]
[[ 0.49394488]
 [-0.31861776]
 [-0.        ]
 [-0.23019764]
 [ 0.        ]
 [-0.6999837 ]
 [-0.        ]
 [ 0.        ]
 [-1.0106398 ]
 [ 0.        ]
 [-0.43543273]
 [-0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.03648001700639725, (0.0038312247, 8.787093, 2.5458958, 0.019479956)
   validation loss 0.038408853113651276, (0.0042951033, 10.832934, 2.8184292, 0.019479956)
decoder loss ratio: 0.512067, decoder SINDy loss  ratio: 0.107497
=========================
[[0.3426149 ]
 [0.3507119 ]
 [0.        ]
 [0.0288033 ]
 [0.        ]
 [0.9780634 ]
 [0.        ]
 [0.        ]
 [0.9794004 ]
 [0.        ]
 [0.91271013]
 [0.        ]]
[[ 0.30230623]
 [-0.3041894 ]
 [-0.        ]
 [-0.1003705 ]
 [-0.        ]
 [-0.6555483 ]
 [-0.        ]
 [ 0.        ]
 [-0.739252  ]
 [ 0.        ]
 [-0.46618468]
 [ 0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.030402209609746933, (0.003242843, 7.3766794, 1.8084396, 0.017748335)
   validation loss 0.03111841157078743, (0.003562379, 8.520985, 1.8763294, 0.017748335)
decoder loss ratio: 0.424711, decoder SINDy loss  ratio: 0.071564
=========================
[[0.0860825 ]
 [0.29463127]
 [0.        ]
 [0.01529523]
 [0.        ]
 [0.9831417 ]
 [0.        ]
 [0.        ]
 [0.9477641 ]
 [0.        ]
 [0.94592845]
 [0.        ]]
[[ 0.21062249]
 [-0.291375  ]
 [ 0.        ]
 [-0.03267784]
 [-0.        ]
 [-0.6141403 ]
 [ 0.        ]
 [-0.        ]
 [-0.4953946 ]
 [ 0.        ]
 [-0.49300098]
 [ 0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.025885941460728645, (0.0027936834, 6.1045985, 1.3913131, 0.015830463)
   validation loss 0.025953322649002075, (0.0029826828, 6.7021494, 1.3610141, 0.015830463)
decoder loss ratio: 0.355599, decoder SINDy loss  ratio: 0.051910
=========================
[[0.04432927]
 [0.3570176 ]
 [0.        ]
 [0.01053839]
 [0.        ]
 [0.9808311 ]
 [0.        ]
 [0.        ]
 [0.3813546 ]
 [0.        ]
 [0.9694992 ]
 [0.        ]]
[[ 0.17192574]
 [-0.30639896]
 [ 0.        ]
 [-0.01638719]
 [ 0.        ]
 [-0.56451523]
 [ 0.        ]
 [ 0.        ]
 [-0.31174377]
 [ 0.        ]
 [-0.526633  ]
 [-0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.023565195500850677, (0.0024785246, 4.7965217, 1.0312964, 0.015690362)
   validation loss 0.023249823600053787, (0.002525985, 4.809953, 0.9585959, 0.015690362)
decoder loss ratio: 0.301151, decoder SINDy loss  ratio: 0.036561
THRESHOLDING: 4 active coefficients
=========================
[[0.        ]
 [0.23982865]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92563546]
 [0.        ]
 [0.        ]
 [0.07375939]
 [0.        ]
 [0.94979787]
 [0.        ]]
[[ 0.        ]
 [-0.27777812]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.46670336]
 [-0.        ]
 [-0.        ]
 [-0.20578188]
 [-0.        ]
 [-0.48987874]
 [-0.        ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.018562184646725655, (0.0022588223, 3.4473257, 0.87326914, 0.01176465)
   validation loss 0.018017826601862907, (0.002182068, 3.3312688, 0.78090906, 0.01176465)
decoder loss ratio: 0.260149, decoder SINDy loss  ratio: 0.029784
=========================
[[0.        ]
 [0.2974539 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.69498986]
 [0.        ]
 [0.        ]
 [0.00826473]
 [0.        ]
 [0.9465911 ]
 [0.        ]]
[[ 0.        ]
 [-0.2929642 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.37809506]
 [ 0.        ]
 [ 0.        ]
 [-0.06016206]
 [-0.        ]
 [-0.48449218]
 [ 0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.015925275161862373, (0.0019876524, 2.970209, 0.67613167, 0.010408454)
   validation loss 0.01549038477241993, (0.0017640877, 2.64307, 0.63713795, 0.010408454)
decoder loss ratio: 0.210316, decoder SINDy loss  ratio: 0.024301
=========================
[[0.        ]
 [0.34448406]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34480405]
 [0.        ]
 [0.        ]
 [0.00547424]
 [0.        ]
 [0.9409566 ]
 [0.        ]]
[[ 0.        ]
 [-0.30399615]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3040676 ]
 [ 0.        ]
 [-0.        ]
 [ 0.03529459]
 [ 0.        ]
 [-0.47768053]
 [-0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.015215573832392693, (0.0017373658, 2.3802557, 0.53551984, 0.010681597)
   validation loss 0.01457166112959385, (0.0014751587, 2.0026402, 0.46295467, 0.010681597)
decoder loss ratio: 0.175870, decoder SINDy loss  ratio: 0.017657
=========================
[[0.        ]
 [0.3916783 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12423921]
 [0.        ]
 [0.        ]
 [0.01503216]
 [0.        ]
 [0.9323467 ]
 [0.        ]]
[[ 0.        ]
 [-0.3142776 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.2378403 ]
 [-0.        ]
 [ 0.        ]
 [ 0.11896271]
 [ 0.        ]
 [-0.46948352]
 [ 0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.015213923528790474, (0.0014873004, 1.9790044, 0.40815946, 0.011586876)
   validation loss 0.014548981562256813, (0.001213455, 1.568563, 0.3340445, 0.011586876)
decoder loss ratio: 0.144669, decoder SINDy loss  ratio: 0.012741
THRESHOLDING: 3 active coefficients
=========================
[[0.        ]
 [0.313596  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05793386]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9053924 ]
 [0.        ]]
[[ 0.        ]
 [-0.29705122]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.19540602]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.45041785]
 [ 0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01256837323307991, (0.0013341925, 1.5207547, 0.362128, 0.009347503)
   validation loss 0.011952894739806652, (0.0010812478, 1.1804726, 0.2930241, 0.009347503)
decoder loss ratio: 0.128908, decoder SINDy loss  ratio: 0.011176
=========================
[[0.        ]
 [0.28789446]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03045835]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.90428364]
 [0.        ]]
[[ 0.        ]
 [-0.2909395 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.16106766]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.4495776 ]
 [-0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011741481721401215, (0.0012015394, 1.3721722, 0.32404575, 0.008851105)
   validation loss 0.011240998283028603, (0.0009484054, 1.0499982, 0.2777976, 0.008851105)
decoder loss ratio: 0.113070, decoder SINDy loss  ratio: 0.010595
=========================
[[0.        ]
 [0.2615211 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.01897584]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9115872 ]
 [0.        ]]
[[ 0.        ]
 [-0.28431824]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.13627072]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4538598 ]
 [-0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.010855317115783691, (0.0010542633, 1.2249775, 0.25952166, 0.008442197)
   validation loss 0.01033096108585596, (0.0008119952, 0.9299829, 0.20605396, 0.008442197)
decoder loss ratio: 0.096807, decoder SINDy loss  ratio: 0.007859
=========================
[[0.        ]
 [0.21600826]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.01295127]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91411805]
 [0.        ]]
[[ 0.        ]
 [-0.271739  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.11639005]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.45536232]
 [ 0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.010165962390601635, (0.0009292639, 1.0395324, 0.22150521, 0.008077196)
   validation loss 0.00968440156430006, (0.0006961736, 0.78337926, 0.1743727, 0.008077196)
decoder loss ratio: 0.082999, decoder SINDy loss  ratio: 0.006651
THRESHOLDING: 2 active coefficients
=========================
[[0.        ]
 [0.16828173]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9224025 ]
 [0.        ]]
[[-0.        ]
 [-0.25626218]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.4608511 ]
 [-0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007905665785074234, (0.0008142214, 0.9047283, 0.1865597, 0.006113409)
   validation loss 0.007453343831002712, (0.0005893542, 0.670088, 0.14341524, 0.006113409)
decoder loss ratio: 0.070263, decoder SINDy loss  ratio: 0.005470
=========================
[[0.        ]
 [0.13062619]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9363813 ]
 [0.        ]]
[[-0.        ]
 [-0.24134497]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.4715669 ]
 [ 0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007523715496063232, (0.00072362734, 0.7855833, 0.16746525, 0.0059234826)
   validation loss 0.007143882568925619, (0.00051433686, 0.56339914, 0.13557865, 0.0059234826)
decoder loss ratio: 0.061320, decoder SINDy loss  ratio: 0.005171
=========================
[[0.       ]
 [0.109318 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9499496]
 [0.       ]]
[[ 0.        ]
 [-0.23121652]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.48433274]
 [ 0.        ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00722839031368494, (0.0006493108, 0.67611957, 0.15780815, 0.005756233)
   validation loss 0.006848322693258524, (0.00044616847, 0.47282, 0.124456085, 0.005756233)
decoder loss ratio: 0.053193, decoder SINDy loss  ratio: 0.004747
=========================
[[0.        ]
 [0.08832502]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95859593]
 [0.        ]]
[[-0.        ]
 [-0.21936424]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.49430364]
 [-0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.006867861840873957, (0.0005889231, 0.5729461, 0.13490587, 0.005575762)
   validation loss 0.006528317462652922, (0.00039856325, 0.39088187, 0.10688959, 0.005575762)
decoder loss ratio: 0.047517, decoder SINDy loss  ratio: 0.004077
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994614]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.752063]
 [-0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003175589721649885, (0.00045185385, 0.35575867, 0.11720323, 0.0021199319)
   validation loss 0.002947718370705843, (0.0003359535, 0.24549356, 0.09591166, 0.0021199319)
decoder loss ratio: 0.040053, decoder SINDy loss  ratio: 0.003658
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999517]
 [0.      ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7548535]
 [ 0.       ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0029273550026118755, (0.00030309238, 0.31631035, 0.10425167, 0.0020871887)
   validation loss 0.0029175321105867624, (0.00023710619, 0.21601152, 0.11648734, 0.0020871887)
decoder loss ratio: 0.028268, decoder SINDy loss  ratio: 0.004443
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99966115]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7851461]
 [ 0.       ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0029368337709456682, (0.00021914099, 0.24860092, 0.13130522, 0.0020487367)
   validation loss 0.0033127900678664446, (0.00018426208, 0.18305993, 0.21412767, 0.0020487367)
decoder loss ratio: 0.021968, decoder SINDy loss  ratio: 0.008167
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99969745]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.7886791]
 [-0.       ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0027411365881562233, (0.00014462012, 0.23644663, 0.11469292, 0.0020112295)
   validation loss 0.003142758272588253, (0.00013355097, 0.18963161, 0.19769926, 0.0020112295)
decoder loss ratio: 0.015922, decoder SINDy loss  ratio: 0.007540
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997237]
 [0.       ]]
[[-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.78969544]
 [-0.        ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00253114802762866, (9.6276075e-05, 0.21126987, 0.09123912, 0.001968113)
   validation loss 0.002876293146982789, (9.853322e-05, 0.18313095, 0.16009809, 0.001968113)
decoder loss ratio: 0.011747, decoder SINDy loss  ratio: 0.006106
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997491]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7928938]
 [ 0.       ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024493574164807796, (7.264316e-05, 0.18090923, 0.07986579, 0.0019683398)
   validation loss 0.0027683894149959087, (7.958347e-05, 0.16264974, 0.14246671, 0.0019683398)
decoder loss ratio: 0.009488, decoder SINDy loss  ratio: 0.005434
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997746]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.79722273]
 [-0.        ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002374128205701709, (5.842208e-05, 0.15346026, 0.067875765, 0.0019686543)
   validation loss 0.002643526764586568, (6.710348e-05, 0.13944396, 0.12015934, 0.0019686543)
decoder loss ratio: 0.008000, decoder SINDy loss  ratio: 0.004583
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997962]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8016576]
 [ 0.       ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002332359319552779, (4.9550898e-05, 0.13128893, 0.0614531, 0.0019689784)
   validation loss 0.002576859900727868, (5.8863858e-05, 0.1190685, 0.10861284, 0.0019689784)
decoder loss ratio: 0.007018, decoder SINDy loss  ratio: 0.004143
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998145]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.80553526]
 [ 0.        ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022817181888967752, (4.30306e-05, 0.11378016, 0.053989243, 0.0019630524)
   validation loss 0.002489838283509016, (5.2686148e-05, 0.10261804, 0.09379374, 0.0019630524)
decoder loss ratio: 0.006281, decoder SINDy loss  ratio: 0.003577
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99982905]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8087341]
 [-0.       ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022552928421646357, (3.893271e-05, 0.10036206, 0.049614802, 0.001963268)
   validation loss 0.0024435340892523527, (4.8766873e-05, 0.09030067, 0.08539682, 0.001963268)
decoder loss ratio: 0.005814, decoder SINDy loss  ratio: 0.003257
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99984133]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.81119263]
 [-0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022254029754549265, (3.5316698e-05, 0.08988266, 0.044430796, 0.0019634382)
   validation loss 0.0023868270218372345, (4.5245382e-05, 0.08056173, 0.07482308, 0.0019634382)
decoder loss ratio: 0.005394, decoder SINDy loss  ratio: 0.002854
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998504]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8130662]
 [ 0.       ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022073392756283283, (3.291298e-05, 0.08175901, 0.04135289, 0.001963574)
   validation loss 0.0023540148977190256, (4.2856736e-05, 0.07319879, 0.068784855, 0.001963574)
decoder loss ratio: 0.005109, decoder SINDy loss  ratio: 0.002624
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998588]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81439376]
 [-0.        ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00218233116902411, (3.0675455e-05, 0.07527761, 0.037512995, 0.001960327)
   validation loss 0.0023086159490048885, (4.0677944e-05, 0.067121886, 0.060851023, 0.001960327)
decoder loss ratio: 0.004850, decoder SINDy loss  ratio: 0.002321
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998652]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81529045]
 [ 0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021690737921744585, (2.9158315e-05, 0.070190735, 0.035203874, 0.0019603865)
   validation loss 0.0022841719910502434, (3.9165414e-05, 0.06240454, 0.056299947, 0.0019603865)
decoder loss ratio: 0.004669, decoder SINDy loss  ratio: 0.002147
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998706]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8158156]
 [ 0.       ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002152545377612114, (2.7609452e-05, 0.06607821, 0.03224206, 0.0019604217)
   validation loss 0.002251819707453251, (3.7591308e-05, 0.058435407, 0.050176974, 0.0019604217)
decoder loss ratio: 0.004482, decoder SINDy loss  ratio: 0.001914
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99987435]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81604016]
 [-0.        ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021422491408884525, (2.6451735e-05, 0.06289978, 0.030443111, 0.0019604368)
   validation loss 0.002232750179246068, (3.6369398e-05, 0.055406537, 0.04663471, 0.0019604368)
decoder loss ratio: 0.004336, decoder SINDy loss  ratio: 0.001779
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998779]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81601405]
 [-0.        ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002127197105437517, (2.5110408e-05, 0.060466263, 0.028111557, 0.0019585055)
   validation loss 0.002205373952165246, (3.4978846e-05, 0.05291926, 0.041848715, 0.0019585055)
decoder loss ratio: 0.004170, decoder SINDy loss  ratio: 0.001596
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99988073]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.81577104]
 [ 0.        ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002118995413184166, (2.4019431e-05, 0.058786258, 0.026709922, 0.001958487)
   validation loss 0.0021905044559389353, (3.381789e-05, 0.051161658, 0.039128266, 0.001958487)
decoder loss ratio: 0.004032, decoder SINDy loss  ratio: 0.001492
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998829]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8153116]
 [-0.       ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002108257496729493, (2.2830427e-05, 0.057721563, 0.024816757, 0.0019584573)
   validation loss 0.0021699373610317707, (3.255597e-05, 0.049838096, 0.035286453, 0.0019584573)
decoder loss ratio: 0.003881, decoder SINDy loss  ratio: 0.001346
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998838]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8146754]
 [ 0.       ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002101694233715534, (2.177056e-05, 0.057288464, 0.023728747, 0.0019584156)
   validation loss 0.0021584180649369955, (3.1409298e-05, 0.049134325, 0.03322727, 0.0019584156)
decoder loss ratio: 0.003745, decoder SINDy loss  ratio: 0.001267
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999424]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.89082146]
 [-0.        ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020826184190809727, (3.2056276e-05, 0.080766454, 0.016768437, 0.0019626815)
   validation loss 0.0020929218735545874, (4.2262374e-05, 0.072124496, 0.016874364, 0.0019626815)
decoder loss ratio: 0.005039, decoder SINDy loss  ratio: 0.000644
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994403]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8898089]
 [ 0.       ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020804335363209248, (3.197564e-05, 0.08385167, 0.016291553, 0.0019628075)
   validation loss 0.0020913518965244293, (4.2249954e-05, 0.074280374, 0.016516084, 0.0019628075)
decoder loss ratio: 0.005037, decoder SINDy loss  ratio: 0.000630
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999483]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.89882666]
 [-0.        ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020820742938667536, (2.7837064e-05, 0.09788094, 0.017147094, 0.0019636077)
   validation loss 0.0021024413872510195, (3.788881e-05, 0.09112721, 0.019277692, 0.0019636077)
decoder loss ratio: 0.004517, decoder SINDy loss  ratio: 0.000735
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999553]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9208993]
 [-0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023707086220383644, (3.6313988e-05, 0.10782232, 0.07271921, 0.0019654075)
   validation loss 0.002746506594121456, (4.635447e-05, 0.11396505, 0.1458093, 0.0019654075)
decoder loss ratio: 0.005526, decoder SINDy loss  ratio: 0.005561
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999575]
 [0.       ]]
[[ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.92955935]
 [ 0.        ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020769168622791767, (2.2725158e-05, 0.101729885, 0.01678291, 0.0019651907)
   validation loss 0.0020997999235987663, (3.1981177e-05, 0.09556658, 0.019569917, 0.0019651907)
decoder loss ratio: 0.003813, decoder SINDy loss  ratio: 0.000746
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999591]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9314314]
 [-0.       ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002079866360872984, (2.170498e-05, 0.09940619, 0.017567636, 0.0019653528)
   validation loss 0.00211160397157073, (3.1117193e-05, 0.093486145, 0.02209191, 0.0019653528)
decoder loss ratio: 0.003710, decoder SINDy loss  ratio: 0.000843
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999589]
 [0.       ]]
[[-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.92022556]
 [-0.        ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002045818604528904, (1.9862864e-05, 0.073353626, 0.011584231, 0.001964367)
   validation loss 0.0020485606510192156, (2.8872224e-05, 0.064147696, 0.0104228305, 0.001964367)
decoder loss ratio: 0.003442, decoder SINDy loss  ratio: 0.000398
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999586]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9147686]
 [ 0.       ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002041308907791972, (1.8217612e-05, 0.066205, 0.011153422, 0.001964014)
   validation loss 0.0020456635393202305, (2.735964e-05, 0.05743675, 0.010283585, 0.001964014)
decoder loss ratio: 0.003262, decoder SINDy loss  ratio: 0.000392
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995935]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.91219556]
 [-0.        ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002068082569167018, (1.7099099e-05, 0.058459055, 0.01696081, 0.0019632564)
   validation loss 0.0020983426366001368, (2.624637e-05, 0.05106254, 0.021257363, 0.0019632564)
decoder loss ratio: 0.003129, decoder SINDy loss  ratio: 0.000811
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996305]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.92992413]
 [-0.        ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020335570443421602, (1.3887015e-05, 0.057757083, 0.010431754, 0.0019646233)
   validation loss 0.0020407054107636213, (2.3138302e-05, 0.0507879, 0.010080853, 0.0019646233)
decoder loss ratio: 0.002759, decoder SINDy loss  ratio: 0.000384
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999627]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.92073876]
 [ 0.        ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002047658432275057, (1.790229e-05, 0.051362112, 0.012649834, 0.0019639388)
   validation loss 0.0020632322411984205, (2.7334469e-05, 0.048946455, 0.013902305, 0.0019639388)
decoder loss ratio: 0.003259, decoder SINDy loss  ratio: 0.000530
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999616]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9125917]
 [-0.       ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002035031793639064, (1.3830947e-05, 0.043800075, 0.011162606, 0.0019631977)
   validation loss 0.0020485154818743467, (2.3639946e-05, 0.041123148, 0.011924324, 0.0019631977)
decoder loss ratio: 0.002818, decoder SINDy loss  ratio: 0.000455
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996173]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9108676]
 [-0.       ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002031905809417367, (1.1750727e-05, 0.041098263, 0.011079514, 0.0019627025)
   validation loss 0.0020515124779194593, (2.0843796e-05, 0.039399512, 0.013199238, 0.0019627025)
decoder loss ratio: 0.002485, decoder SINDy loss  ratio: 0.000503
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999634]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9162065]
 [ 0.       ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002031046664342284, (1.136572e-05, 0.035976563, 0.010965756, 0.0019630534)
   validation loss 0.0020456332713365555, (2.081598e-05, 0.031955585, 0.01203322, 0.0019630534)
decoder loss ratio: 0.002482, decoder SINDy loss  ratio: 0.000459
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999641]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.91683203]
 [-0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020306911319494247, (1.114308e-05, 0.03649011, 0.010909798, 0.0019631747)
   validation loss 0.0020520819816738367, (2.105467e-05, 0.037640803, 0.013194134, 0.0019631747)
decoder loss ratio: 0.002510, decoder SINDy loss  ratio: 0.000503
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999654]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9220357]
 [-0.       ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020303193014115095, (1.1396234e-05, 0.031111035, 0.010763237, 0.0019635514)
   validation loss 0.0020527702290564775, (2.0666184e-05, 0.027937146, 0.013431159, 0.0019635514)
decoder loss ratio: 0.002464, decoder SINDy loss  ratio: 0.000512
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996597]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9217144]
 [ 0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002056533470749855, (1.0591508e-05, 0.030641744, 0.01621054, 0.0019633572)
   validation loss 0.0020950923208147287, (1.9817e-05, 0.028705966, 0.022096563, 0.0019633572)
decoder loss ratio: 0.002363, decoder SINDy loss  ratio: 0.000843
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996716]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.925261]
 [-0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002026716945692897, (1.0245605e-05, 0.028487906, 0.010302883, 0.0019635325)
   validation loss 0.0020497324876487255, (1.9524365e-05, 0.026363378, 0.013071486, 0.0019635325)
decoder loss ratio: 0.002328, decoder SINDy loss  ratio: 0.000499
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999968]
 [0.      ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9272907]
 [-0.       ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020122050773352385, (8.770366e-06, 0.026352067, 0.007674914, 0.0019637425)
   validation loss 0.002021247986704111, (1.7928161e-05, 0.02308157, 0.00768462, 0.0019637425)
decoder loss ratio: 0.002137, decoder SINDy loss  ratio: 0.000293
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996805]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9235557]
 [ 0.       ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002012023236602545, (8.175846e-06, 0.02547761, 0.0078094318, 0.0019635262)
   validation loss 0.0020228796638548374, (1.7744132e-05, 0.023722999, 0.008084627, 0.0019635262)
decoder loss ratio: 0.002115, decoder SINDy loss  ratio: 0.000308
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997455]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.98522514]
 [-0.        ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020938320085406303, (2.5508565e-05, 0.101434425, 0.018888364, 0.0019688099)
   validation loss 0.0021485842298716307, (3.8491493e-05, 0.121714756, 0.027039446, 0.0019688099)
decoder loss ratio: 0.004589, decoder SINDy loss  ratio: 0.001031
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997574]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0250847]
 [-0.       ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020581157878041267, (2.332291e-05, 0.14933069, 0.011011224, 0.0019722702)
   validation loss 0.0020690085366368294, (3.484469e-05, 0.14734584, 0.010905281, 0.0019722702)
decoder loss ratio: 0.004154, decoder SINDy loss  ratio: 0.000416
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999976]
 [0.      ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0427026]
 [ 0.       ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025763006415218115, (4.5878664e-05, 0.1960398, 0.10930307, 0.0019741047)
   validation loss 0.0031644529663026333, (5.8522473e-05, 0.30512363, 0.22331391, 0.0019741047)
decoder loss ratio: 0.006977, decoder SINDy loss  ratio: 0.008517
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999759]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0359174]
 [-0.       ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021621251944452524, (3.4394638e-05, 0.12142142, 0.0296897, 0.001973211)
   validation loss 0.0022289217449724674, (4.4297893e-05, 0.14754839, 0.040807053, 0.001973211)
decoder loss ratio: 0.005281, decoder SINDy loss  ratio: 0.001556
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999759]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-1.040035]
 [-0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002510904334485531, (3.9238752e-05, 0.14694011, 0.09813768, 0.0019736302)
   validation loss 0.0027814453933387995, (5.0738177e-05, 0.21278897, 0.1492875, 0.0019736302)
decoder loss ratio: 0.006049, decoder SINDy loss  ratio: 0.005694
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999753]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.011877]
 [ 0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020917081274092197, (2.2607217e-05, 0.06867035, 0.018956088, 0.001970887)
   validation loss 0.0021400817204266787, (3.233575e-05, 0.07186658, 0.026653145, 0.001970887)
decoder loss ratio: 0.003855, decoder SINDy loss  ratio: 0.001017
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997514]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0089953]
 [-0.       ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021540652960538864, (2.7541644e-05, 0.06839183, 0.030486183, 0.0019706732)
   validation loss 0.0022697511594742537, (3.7915095e-05, 0.0916682, 0.051315896, 0.0019706732)
decoder loss ratio: 0.004520, decoder SINDy loss  ratio: 0.001957
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997514]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0085008]
 [-0.       ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021705739200115204, (2.6385203e-05, 0.06431164, 0.03406209, 0.0019706627)
   validation loss 0.002279853681102395, (3.6827812e-05, 0.0870191, 0.05360243, 0.0019706627)
decoder loss ratio: 0.004391, decoder SINDy loss  ratio: 0.002044
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999751]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0074838]
 [ 0.       ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020819331984966993, (1.8591303e-05, 0.044021644, 0.018159153, 0.0019703452)
   validation loss 0.0021421853452920914, (2.8737928e-05, 0.05980106, 0.028022464, 0.0019703452)
decoder loss ratio: 0.003426, decoder SINDy loss  ratio: 0.001069
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999749]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0009785]
 [-0.       ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021810501348227262, (1.9758989e-05, 0.079948485, 0.03752033, 0.001969692)
   validation loss 0.0023531934712082148, (2.852262e-05, 0.13620721, 0.06963369, 0.001969692)
decoder loss ratio: 0.003400, decoder SINDy loss  ratio: 0.002656
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997526]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0181704]
 [-0.       ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020202158484607935, (1.3921795e-05, 0.032397144, 0.0066302055, 0.0019715233)
   validation loss 0.002029655734077096, (2.3647239e-05, 0.03380528, 0.006558993, 0.0019715233)
decoder loss ratio: 0.002819, decoder SINDy loss  ratio: 0.000250
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999757]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0291467]
 [ 0.       ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002201714552938938, (2.4108103e-05, 0.050619796, 0.04051388, 0.001972506)
   validation loss 0.002357189077883959, (3.5535963e-05, 0.08254278, 0.06900397, 0.001972506)
decoder loss ratio: 0.004237, decoder SINDy loss  ratio: 0.002632
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997574]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0297077]
 [-0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020183951128274202, (1.2080224e-05, 0.02570783, 0.0065529756, 0.0019722646)
   validation loss 0.0020315677393227816, (2.1435659e-05, 0.028078366, 0.0072926953, 0.0019722646)
decoder loss ratio: 0.002556, decoder SINDy loss  ratio: 0.000278
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999757]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0246049]
 [-0.       ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002063007792457938, (1.1842301e-05, 0.029520212, 0.015538969, 0.0019719945)
   validation loss 0.0021219784393906593, (2.1985647e-05, 0.035173643, 0.0252479, 0.0019719945)
decoder loss ratio: 0.002621, decoder SINDy loss  ratio: 0.000963
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997574]
 [0.        ]]
[[ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-1.03146]
 [ 0.     ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024494680110365152, (3.1774474e-05, 0.0793118, 0.08816479, 0.001972904)
   validation loss 0.002828426891937852, (4.4371212e-05, 0.13151123, 0.16091524, 0.001972904)
decoder loss ratio: 0.005290, decoder SINDy loss  ratio: 0.006137
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997586]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0383775]
 [-0.       ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002122465055435896, (1.6206108e-05, 0.036823325, 0.026256612, 0.0019731347)
   validation loss 0.0022720233537256718, (2.752787e-05, 0.058511004, 0.053687047, 0.0019731347)
decoder loss ratio: 0.003282, decoder SINDy loss  ratio: 0.002048
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997574]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0292706]
 [-0.       ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020195553079247475, (1.3459183e-05, 0.025125433, 0.0065561053, 0.0019720593)
   validation loss 0.002031215000897646, (2.218551e-05, 0.0280354, 0.0071136714, 0.0019720593)
decoder loss ratio: 0.002645, decoder SINDy loss  ratio: 0.000271
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997586]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0364568]
 [ 0.       ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002019882667809725, (1.2307974e-05, 0.022215812, 0.006746889, 0.0019727296)
   validation loss 0.0020333346910774708, (2.1328173e-05, 0.027623901, 0.0075791576, 0.0019727296)
decoder loss ratio: 0.002543, decoder SINDy loss  ratio: 0.000289
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997574]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0299748]
 [-0.       ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020080911926925182, (8.660835e-06, 0.016758498, 0.0052660354, 0.0019722623)
   validation loss 0.0020168558694422245, (1.7890421e-05, 0.017496709, 0.0051656663, 0.0019722623)
decoder loss ratio: 0.002133, decoder SINDy loss  ratio: 0.000197
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997544]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0199227]
 [-0.       ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002010498195886612, (1.0867358e-05, 0.017108012, 0.005430342, 0.0019716236)
   validation loss 0.0020201641600579023, (2.0420675e-05, 0.019887507, 0.0054250997, 0.0019716236)
decoder loss ratio: 0.002435, decoder SINDy loss  ratio: 0.000207
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0969615]
 [-0.       ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0026963166892528534, (6.0042596e-05, 0.18194465, 0.1297047, 0.0019786533)
   validation loss 0.003132769837975502, (8.89893e-05, 0.26132032, 0.21041228, 0.0019786533)
decoder loss ratio: 0.010609, decoder SINDy loss  ratio: 0.008025
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1010664]
 [-0.       ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003120753448456526, (7.98763e-05, 0.3270771, 0.2090673, 0.0019791867)
   validation loss 0.0044401865452528, (9.635324e-05, 0.5093816, 0.46783552, 0.0019791867)
decoder loss ratio: 0.011487, decoder SINDy loss  ratio: 0.017844
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1105646]
 [ 0.       ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025540192145854235, (6.4951055e-05, 0.24635711, 0.09930638, 0.0019802183)
   validation loss 0.0031452951952815056, (7.86647e-05, 0.3276601, 0.21400583, 0.0019802183)
decoder loss ratio: 0.009378, decoder SINDy loss  ratio: 0.008162
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1166445]
 [-0.       ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002491355873644352, (5.7831632e-05, 0.23221284, 0.088218436, 0.0019808214)
   validation loss 0.0030322554521262646, (7.166584e-05, 0.28827697, 0.19307086, 0.0019808214)
decoder loss ratio: 0.008544, decoder SINDy loss  ratio: 0.007364
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1198922]
 [-0.       ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023910370655357838, (4.9752598e-05, 0.22211675, 0.069815435, 0.0019811015)
   validation loss 0.0028144815005362034, (6.386197e-05, 0.2860912, 0.1510427, 0.0019811015)
decoder loss ratio: 0.007614, decoder SINDy loss  ratio: 0.005761
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1212119]
 [ 0.       ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023189466446638107, (3.958934e-05, 0.19912964, 0.05763563, 0.0019812225)
   validation loss 0.0026603401638567448, (5.37136e-05, 0.25224948, 0.12255834, 0.0019812225)
decoder loss ratio: 0.006404, decoder SINDy loss  ratio: 0.004674
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1222123]
 [-0.       ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002241378417238593, (3.7711525e-05, 0.15475407, 0.042916134, 0.0019813485)
   validation loss 0.0024652923457324505, (5.1231935e-05, 0.1902832, 0.08463954, 0.0019813485)
decoder loss ratio: 0.006108, decoder SINDy loss  ratio: 0.003228
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1240336]
 [-0.       ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021488419733941555, (2.8941042e-05, 0.1756038, 0.025892962, 0.0019816558)
   validation loss 0.00225503440015018, (3.878959e-05, 0.26470318, 0.044270776, 0.0019816558)
decoder loss ratio: 0.004625, decoder SINDy loss  ratio: 0.001689
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1291896]
 [ 0.       ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002189157996326685, (2.282417e-05, 0.111543015, 0.035784006, 0.0019818367)
   validation loss 0.0023364799562841654, (3.410418e-05, 0.13850667, 0.06272274, 0.0019818367)
decoder loss ratio: 0.004066, decoder SINDy loss  ratio: 0.002392
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1185898]
 [-0.       ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0027985444758087397, (6.3507905e-05, 0.2948655, 0.14786492, 0.0019809688)
   validation loss 0.0033774671610444784, (7.091316e-05, 0.4301192, 0.26081586, 0.0019809688)
decoder loss ratio: 0.008454, decoder SINDy loss  ratio: 0.009948
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1435323]
 [-0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002208608901128173, (2.9835748e-05, 0.16117233, 0.03747189, 0.001983355)
   validation loss 0.0024131429381668568, (4.2737567e-05, 0.23197202, 0.07509034, 0.001983355)
decoder loss ratio: 0.005095, decoder SINDy loss  ratio: 0.002864
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1410986]
 [ 0.       ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024257968179881573, (3.8747312e-05, 0.20078558, 0.07867598, 0.0019836305)
   validation loss 0.0025890590623021126, (4.823007e-05, 0.28462866, 0.10859344, 0.0019836305)
decoder loss ratio: 0.005750, decoder SINDy loss  ratio: 0.004142
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1390184]
 [-0.       ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002265762537717819, (2.665003e-05, 0.13975951, 0.049772438, 0.0019832624)
   validation loss 0.0023698387667536736, (3.532947e-05, 0.19109052, 0.06833849, 0.0019832624)
decoder loss ratio: 0.004212, decoder SINDy loss  ratio: 0.002606
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1393311]
 [-0.       ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002165835350751877, (1.9128904e-05, 0.09638997, 0.03179721, 0.001982901)
   validation loss 0.0023340596817433834, (2.9771827e-05, 0.14008443, 0.062876545, 0.001982901)
decoder loss ratio: 0.003549, decoder SINDy loss  ratio: 0.002398
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1441708]
 [ 0.       ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021456389222294092, (1.9241083e-05, 0.1069893, 0.027491884, 0.001983589)
   validation loss 0.002195030450820923, (2.6581585e-05, 0.15024538, 0.035469532, 0.001983589)
decoder loss ratio: 0.003169, decoder SINDy loss  ratio: 0.001353
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-1.138297]
 [-0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020768477115780115, (1.4595379e-05, 0.06940334, 0.015188789, 0.0019828381)
   validation loss 0.002140119206160307, (2.1558291e-05, 0.09391832, 0.026205355, 0.0019828381)
decoder loss ratio: 0.002570, decoder SINDy loss  ratio: 0.000999
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1380194]
 [-0.       ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002051355317234993, (1.5317362e-05, 0.0822748, 0.009799328, 0.0019829276)
   validation loss 0.002069740789011121, (2.0669248e-05, 0.11808274, 0.01204797, 0.0019829276)
decoder loss ratio: 0.002464, decoder SINDy loss  ratio: 0.000460
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1310935]
 [ 0.       ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020207150373607874, (1.0190482e-05, 0.04539549, 0.005238047, 0.0019820645)
   validation loss 0.0020242701284587383, (1.5216289e-05, 0.055690106, 0.004840991, 0.0019820645)
decoder loss ratio: 0.001814, decoder SINDy loss  ratio: 0.000185
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1306499]
 [-0.       ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020297071896493435, (8.687617e-06, 0.04854289, 0.0073071993, 0.0019820565)
   validation loss 0.002039962448179722, (1.3436709e-05, 0.06433722, 0.008250473, 0.0019820565)
decoder loss ratio: 0.001602, decoder SINDy loss  ratio: 0.000315
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1280206]
 [-0.       ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002017365302890539, (8.605636e-06, 0.04177566, 0.004988446, 0.0019817287)
   validation loss 0.0020204740576446056, (1.2763376e-05, 0.055309154, 0.00464328, 0.0019817287)
decoder loss ratio: 0.001522, decoder SINDy loss  ratio: 0.000177
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1751844]
 [ 0.       ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0031528309918940067, (7.045156e-05, 0.28434864, 0.21627483, 0.001986788)
   validation loss 0.004501367919147015, (0.00011629052, 0.45604366, 0.47509745, 0.001986788)
decoder loss ratio: 0.013864, decoder SINDy loss  ratio: 0.018121
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2299789]
 [-0.       ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0028740791603922844, (7.943102e-05, 0.3441201, 0.15693253, 0.0019927796)
   validation loss 0.0037838907446712255, (0.000104890125, 0.5408099, 0.33183613, 0.0019927796)
decoder loss ratio: 0.012505, decoder SINDy loss  ratio: 0.012656
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2285233]
 [-0.       ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025473881978541613, (7.516484e-05, 0.36829546, 0.0921725, 0.001992946)
   validation loss 0.0027124222833663225, (8.794322e-05, 0.52070373, 0.12109956, 0.001992946)
decoder loss ratio: 0.010485, decoder SINDy loss  ratio: 0.004619
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2299998]
 [ 0.       ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025425488129258156, (6.2510626e-05, 0.2926219, 0.09457708, 0.0019925218)
   validation loss 0.0031190745066851377, (7.8920755e-05, 0.4240666, 0.20528574, 0.0019925218)
decoder loss ratio: 0.009409, decoder SINDy loss  ratio: 0.007830
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2323924]
 [-0.       ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002543121576309204, (6.676515e-05, 0.36908457, 0.0928956, 0.0019934243)
   validation loss 0.00273064523935318, (7.711674e-05, 0.50879246, 0.12693293, 0.0019934243)
decoder loss ratio: 0.009194, decoder SINDy loss  ratio: 0.004841
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2341326]
 [-0.       ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002507843542844057, (4.7943413e-05, 0.27630985, 0.090606034, 0.0019930545)
   validation loss 0.0030308812856674194, (6.114409e-05, 0.39902702, 0.19134626, 0.0019930545)
decoder loss ratio: 0.007290, decoder SINDy loss  ratio: 0.007298
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2246665]
 [ 0.       ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023319630417972803, (4.6065263e-05, 0.25348592, 0.05617168, 0.001992365)
   validation loss 0.002422352321445942, (5.405669e-05, 0.3385069, 0.07180104, 0.001992365)
decoder loss ratio: 0.006445, decoder SINDy loss  ratio: 0.002739
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2188677]
 [-0.       ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023271888494491577, (3.640783e-05, 0.19961974, 0.05789373, 0.0019913313)
   validation loss 0.002666062442585826, (4.6712164e-05, 0.30136484, 0.12259013, 0.0019913313)
decoder loss ratio: 0.005569, decoder SINDy loss  ratio: 0.004676
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2104739]
 [-0.       ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022573512978851795, (3.694305e-05, 0.21512009, 0.043774214, 0.0019907812)
   validation loss 0.0023242556490004063, (4.2404932e-05, 0.3027748, 0.055186175, 0.0019907812)
decoder loss ratio: 0.005056, decoder SINDy loss  ratio: 0.002105
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2087462]
 [ 0.       ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002266460796818137, (2.8925564e-05, 0.1476264, 0.047980066, 0.0019902536)
   validation loss 0.0025406205095350742, (3.662073e-05, 0.21925405, 0.10055672, 0.0019902536)
decoder loss ratio: 0.004366, decoder SINDy loss  ratio: 0.003835
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2075791]
 [-0.       ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022274635266512632, (2.746476e-05, 0.19461216, 0.039979514, 0.0019903707)
   validation loss 0.002300048479810357, (3.1606025e-05, 0.27507308, 0.05286361, 0.0019903707)
decoder loss ratio: 0.003768, decoder SINDy loss  ratio: 0.002016
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2027966]
 [-0.       ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002231187652796507, (2.3066154e-05, 0.13294938, 0.042369124, 0.0019896284)
   validation loss 0.0024546226486563683, (2.9238598e-05, 0.19419123, 0.08520919, 0.0019896284)
decoder loss ratio: 0.003486, decoder SINDy loss  ratio: 0.003250
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1966134]
 [ 0.       ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021821772679686546, (2.3392115e-05, 0.13647509, 0.03256031, 0.0019891597)
   validation loss 0.0022361413575708866, (2.678486e-05, 0.17705373, 0.042268794, 0.0019891597)
decoder loss ratio: 0.003193, decoder SINDy loss  ratio: 0.001612
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1917993]
 [-0.       ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021777767688035965, (1.9186891e-05, 0.09907847, 0.033037797, 0.001988447)
   validation loss 0.0023513673804700375, (2.4213794e-05, 0.1448469, 0.066292845, 0.001988447)
decoder loss ratio: 0.002887, decoder SINDy loss  ratio: 0.002528
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1847878]
 [-0.       ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021263998933136463, (1.736577e-05, 0.11087888, 0.02312722, 0.001987854)
   validation loss 0.0021595454309135675, (2.0015601e-05, 0.14142315, 0.028920945, 0.001987854)
decoder loss ratio: 0.002386, decoder SINDy loss  ratio: 0.001103
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1794223]
 [ 0.       ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021269135177135468, (1.5532565e-05, 0.0827464, 0.024027098, 0.0019871083)
   validation loss 0.0022497777827084064, (1.9783854e-05, 0.118903466, 0.047388088, 0.0019871083)
decoder loss ratio: 0.002359, decoder SINDy loss  ratio: 0.001807
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1776856]
 [-0.       ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0020628117490559816, (1.2423332e-05, 0.08078525, 0.011874759, 0.0019869753)
   validation loss 0.0020764030050486326, (1.4363259e-05, 0.10947022, 0.013918204, 0.0019869753)
decoder loss ratio: 0.001712, decoder SINDy loss  ratio: 0.000531
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1733302]
 [-0.       ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021367305889725685, (1.5023843e-05, 0.081428334, 0.026233552, 0.0019864675)
   validation loss 0.002272989833727479, (1.9365732e-05, 0.123516016, 0.05219614, 0.0019864675)
decoder loss ratio: 0.002309, decoder SINDy loss  ratio: 0.001991
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1680082]
 [ 0.       ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0021143555641174316, (1.3291846e-05, 0.07930789, 0.022210656, 0.001986045)
   validation loss 0.002153861103579402, (1.5683363e-05, 0.10963425, 0.029330231, 0.001986045)
decoder loss ratio: 0.001870, decoder SINDy loss  ratio: 0.001119
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1635991]
 [-0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002052691765129566, (9.287113e-06, 0.055221986, 0.01104106, 0.0019854382)
   validation loss 0.0020856927148997784, (1.1530911e-05, 0.07558156, 0.016988913, 0.0019854382)
decoder loss ratio: 0.001375, decoder SINDy loss  ratio: 0.000648
THRESHOLDING: 1 active coefficients
REFINEMENT
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.747335333377123e-05, (5.361152e-06, 0.0558739, 0.007863701, 0.0019853287)
   validation loss 6.09295311733149e-05, (5.9735826e-06, 0.07468014, 0.010244388, 0.0019853287)
decoder loss ratio: 0.000712, decoder SINDy loss  ratio: 0.000391
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7.485469541279599e-05, (9.873302e-06, 0.06735982, 0.012322682, 0.0019848172)
   validation loss 0.00011882259423146024, (1.1658365e-05, 0.10193285, 0.020413518, 0.0019848172)
decoder loss ratio: 0.001390, decoder SINDy loss  ratio: 0.000779
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.8100322601385415e-05, (6.440267e-06, 0.04455058, 0.007886506, 0.0019843203)
   validation loss 6.0145910538267344e-05, (7.4056e-06, 0.05709297, 0.009977132, 0.0019843203)
decoder loss ratio: 0.000883, decoder SINDy loss  ratio: 0.000381
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00010426317749079317, (9.515069e-06, 0.062885076, 0.018320771, 0.0019840116)
   validation loss 0.0001296838599955663, (1.1011087e-05, 0.08538078, 0.022880746, 0.0019840116)
decoder loss ratio: 0.001313, decoder SINDy loss  ratio: 0.000873
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.1814757676329464e-05, (4.743054e-06, 0.04021951, 0.0050121457, 0.001983857)
   validation loss 3.764712164411321e-05, (5.9126723e-06, 0.055736206, 0.005789528, 0.001983857)
decoder loss ratio: 0.000705, decoder SINDy loss  ratio: 0.000221
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00010958872007904574, (8.478495e-06, 0.059390903, 0.019628135, 0.0019833222)
   validation loss 0.00015056172560434788, (1.02959175e-05, 0.080576204, 0.027247401, 0.0019833222)
decoder loss ratio: 0.001227, decoder SINDy loss  ratio: 0.001039
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.4713641323614866e-05, (3.803234e-06, 0.03299267, 0.0038521546, 0.001982805)
   validation loss 2.3575476006953977e-05, (4.5772595e-06, 0.042041752, 0.0033792257, 0.001982805)
decoder loss ratio: 0.000546, decoder SINDy loss  ratio: 0.000129
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.4131537429639138e-05, (3.5562769e-06, 0.032209463, 0.0037929574, 0.0019822377)
   validation loss 2.321421925444156e-05, (4.3363075e-06, 0.041782536, 0.0033577569, 0.0019822377)
decoder loss ratio: 0.000517, decoder SINDy loss  ratio: 0.000128
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.3059536033542827e-05, (3.3141903e-06, 0.029533861, 0.0036537307, 0.0019822503)
   validation loss 2.1489453501999378e-05, (4.048906e-06, 0.036610138, 0.0031220084, 0.0019822503)
decoder loss ratio: 0.000483, decoder SINDy loss  ratio: 0.000119
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.440546424826607e-05, (3.1135967e-06, 0.031505935, 0.005943314, 0.0019816812)
   validation loss 4.027898103231564e-05, (3.6085867e-06, 0.03893546, 0.006944724, 0.0019816812)
decoder loss ratio: 0.000430, decoder SINDy loss  ratio: 0.000265
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.2634507331531495e-05, (3.0875435e-06, 0.028324345, 0.0036261494, 0.0019818607)
   validation loss 2.144584505003877e-05, (3.7927975e-06, 0.03537754, 0.003176834, 0.0019818607)
decoder loss ratio: 0.000452, decoder SINDy loss  ratio: 0.000121
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.2231270122574642e-05, (3.069022e-06, 0.027516827, 0.003557281, 0.0019815192)
   validation loss 2.1083855244796723e-05, (3.7524067e-06, 0.03380461, 0.0031282434, 0.0019815192)
decoder loss ratio: 0.000447, decoder SINDy loss  ratio: 0.000119
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.2486596208182164e-05, (2.7472067e-06, 0.025486516, 0.0036930128, 0.001981246)
   validation loss 2.2097767214290798e-05, (3.1905854e-06, 0.030666446, 0.0034747717, 0.001981246)
decoder loss ratio: 0.000380, decoder SINDy loss  ratio: 0.000133
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.0998115360271186e-05, (2.7033257e-06, 0.024582552, 0.0034131324, 0.0019811578)
   validation loss 1.9189872546121478e-05, (3.1041366e-06, 0.029357087, 0.0029235762, 0.0019811578)
decoder loss ratio: 0.000370, decoder SINDy loss  ratio: 0.000112
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.196668356191367e-05, (2.8973407e-06, 0.025111858, 0.00356275, 0.0019809722)
   validation loss 2.114774724759627e-05, (3.4317447e-06, 0.030122332, 0.0032419772, 0.0019809722)
decoder loss ratio: 0.000409, decoder SINDy loss  ratio: 0.000124
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.0682029571617022e-05, (2.7875078e-06, 0.023687543, 0.003342029, 0.0019808356)
   validation loss 1.9084051018580794e-05, (3.2176022e-06, 0.028211936, 0.0028911706, 0.0019808356)
decoder loss ratio: 0.000384, decoder SINDy loss  ratio: 0.000110
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.0054558262927458e-05, (2.6445284e-06, 0.022649653, 0.0032555095, 0.001980621)
   validation loss 1.7900345483212732e-05, (2.902049e-06, 0.026540345, 0.0027342557, 0.001980621)
decoder loss ratio: 0.000346, decoder SINDy loss  ratio: 0.000104
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.9936855096602812e-05, (2.6623034e-06, 0.02236819, 0.0032312286, 0.0019804463)
   validation loss 1.7859414583654143e-05, (2.8915379e-06, 0.026127405, 0.0027323014, 0.0019804463)
decoder loss ratio: 0.000345, decoder SINDy loss  ratio: 0.000104
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.9869456082233228e-05, (2.59932e-06, 0.021500634, 0.0032390212, 0.0019803187)
   validation loss 1.7790289348340593e-05, (2.750824e-06, 0.02499217, 0.0027579714, 0.0019803187)
decoder loss ratio: 0.000328, decoder SINDy loss  ratio: 0.000105
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.9447161321295425e-05, (2.5979339e-06, 0.021021808, 0.0031596276, 0.0019801457)
   validation loss 1.7177455447381362e-05, (2.7612166e-06, 0.024252668, 0.0026407212, 0.0019801457)
decoder loss ratio: 0.000329, decoder SINDy loss  ratio: 0.000101
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.9295886886538938e-05, (2.5813085e-06, 0.020550068, 0.0031374153, 0.0019799995)
   validation loss 1.7035039491020143e-05, (2.721229e-06, 0.023596091, 0.0026268014, 0.0019799995)
decoder loss ratio: 0.000324, decoder SINDy loss  ratio: 0.000100
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.2080093913245946e-05, (3.918835e-06, 0.023384517, 0.0033984068, 0.0019813662)
   validation loss 2.0829691493418068e-05, (4.64741e-06, 0.03049795, 0.002931477, 0.0019813662)
decoder loss ratio: 0.000554, decoder SINDy loss  ratio: 0.000112
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.735046266228892e-05, (5.2025575e-06, 0.030742088, 0.0061221607, 0.001980457)
   validation loss 5.3963605751050636e-05, (5.8986693e-06, 0.044336073, 0.009169627, 0.001980457)
decoder loss ratio: 0.000703, decoder SINDy loss  ratio: 0.000350
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7.507038390031084e-05, (6.8223344e-06, 0.044715986, 0.01320245, 0.0019800472)
   validation loss 9.000457066576928e-05, (7.364476e-06, 0.05902091, 0.015937809, 0.0019800472)
decoder loss ratio: 0.000878, decoder SINDy loss  ratio: 0.000608
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7.193069905042648e-05, (6.4509127e-06, 0.03336437, 0.012762314, 0.0019808179)
   validation loss 0.00012825588055420667, (8.547169e-06, 0.04928594, 0.023448883, 0.0019808179)
decoder loss ratio: 0.001019, decoder SINDy loss  ratio: 0.000894
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9.7058349638246e-05, (7.702306e-06, 0.041545805, 0.017455751, 0.001980539)
   validation loss 0.00015226751565933228, (9.50403e-06, 0.059610143, 0.027956596, 0.001980539)
decoder loss ratio: 0.001133, decoder SINDy loss  ratio: 0.001066
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.953373612195719e-05, (3.4413072e-06, 0.018830659, 0.0030301793, 0.0019800065)
   validation loss 1.774996599124279e-05, (3.9992788e-06, 0.021608945, 0.002534048, 0.0019800065)
decoder loss ratio: 0.000477, decoder SINDy loss  ratio: 0.000097
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3.545830986695364e-05, (4.2810193e-06, 0.022290299, 0.006012555, 0.0019795473)
   validation loss 5.025306381867267e-05, (4.63288e-06, 0.028736416, 0.008836673, 0.0019795473)
decoder loss ratio: 0.000552, decoder SINDy loss  ratio: 0.000337
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.03117924684193e-05, (3.3971342e-06, 0.021978099, 0.0031631505, 0.00197943)
   validation loss 2.015633617702406e-05, (3.974441e-06, 0.029332088, 0.0029430583, 0.00197943)
decoder loss ratio: 0.000474, decoder SINDy loss  ratio: 0.000112
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4.0411927329842e-05, (3.4207947e-06, 0.025406962, 0.0071441564, 0.001979099)
   validation loss 4.6988050598884e-05, (3.9063293e-06, 0.03353766, 0.008280967, 0.001979099)
decoder loss ratio: 0.000466, decoder SINDy loss  ratio: 0.000316
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.2395301130018197e-05, (2.9675066e-06, 0.018162834, 0.0037039306, 0.0019792481)
   validation loss 2.2339481802191585e-05, (3.5625037e-06, 0.021198867, 0.003543407, 0.0019792481)
decoder loss ratio: 0.000425, decoder SINDy loss  ratio: 0.000135
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.368096829741262e-05, (2.850166e-06, 0.02015134, 0.003964647, 0.0019788384)
   validation loss 2.6274105039192364e-05, (3.508682e-06, 0.025507703, 0.0042980076, 0.0019788384)
decoder loss ratio: 0.000418, decoder SINDy loss  ratio: 0.000164
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2.7303831302560866e-05, (3.037175e-06, 0.020725893, 0.004646072, 0.001978789)
   validation loss 2.965742714877706e-05, (3.6053862e-06, 0.024887009, 0.004961538, 0.001978789)
decoder loss ratio: 0.000430, decoder SINDy loss  ratio: 0.000189
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.81687773874728e-05, (2.4270516e-06, 0.015259361, 0.0029957518, 0.0019785194)
   validation loss 1.7162117728730664e-05, (2.6948405e-06, 0.017163571, 0.0027218198, 0.0019785194)
decoder loss ratio: 0.000321, decoder SINDy loss  ratio: 0.000104
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.695707396720536e-05, (2.4823637e-06, 0.015164259, 0.0027432996, 0.0019785406)
   validation loss 1.4850395018584095e-05, (2.7402714e-06, 0.017127417, 0.0022507505, 0.0019785406)
decoder loss ratio: 0.000327, decoder SINDy loss  ratio: 0.000086
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.8085900592268445e-05, (2.568957e-06, 0.015360371, 0.002949785, 0.0019783843)
   validation loss 1.6914236766751856e-05, (2.8957193e-06, 0.017386688, 0.0026298366, 0.0019783843)
decoder loss ratio: 0.000345, decoder SINDy loss  ratio: 0.000100
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.7936194126377814e-05, (2.532369e-06, 0.015024256, 0.0029305224, 0.0019781687)/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])

   validation loss 1.7252737961825915e-05, (2.8518748e-06, 0.017258847, 0.0027075843, 0.0019781687)
decoder loss ratio: 0.000340, decoder SINDy loss  ratio: 0.000103
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.827191408665385e-05, (2.4736282e-06, 0.014721741, 0.00301244, 0.0019780206)
   validation loss 1.7218746506841853e-05, (2.6183006e-06, 0.016633864, 0.0027537504, 0.0019780206)
decoder loss ratio: 0.000312, decoder SINDy loss  ratio: 0.000105
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.7543557987664826e-05, (2.4812698e-06, 0.014446043, 0.0028679972, 0.001977931)
   validation loss 1.6689979020156898e-05, (2.7353244e-06, 0.01658377, 0.0026250933, 0.001977931)
decoder loss ratio: 0.000326, decoder SINDy loss  ratio: 0.000100
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.6848183804540895e-05, (2.4202939e-06, 0.01367058, 0.0027488722, 0.0019778041)
   validation loss 1.5250597243721131e-05, (2.5969503e-06, 0.015326654, 0.0023774628, 0.0019778041)
decoder loss ratio: 0.000310, decoder SINDy loss  ratio: 0.000091
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1.618979513295926e-05, (2.3568193e-06, 0.013096035, 0.0026356347, 0.0019776942)
   validation loss 1.3953873349237256e-05, (2.4405674e-06, 0.014335544, 0.0021593058, 0.0019776942)
decoder loss ratio: 0.000291, decoder SINDy loss  ratio: 0.000082
params['save_name']
pendulum_2022_07_08_13_13_07_153292
2022-07-11 15:20:23.691725: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-07-11 15:20:23.819921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
totalMemory: 10.76GiB freeMemory: 10.60GiB
2022-07-11 15:20:23.819949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2022-07-11 15:20:24.023103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-11 15:20:24.023139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2022-07-11 15:20:24.023144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2022-07-11 15:20:24.023212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9917 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
(50000, 2601)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 2601, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 12, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 100, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'constant', 'loss_weight_decoder': 1.0, 'loss_weight_sindy_x': 0.005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [128, 64, 32], 'epoch_size': 50000, 'batch_size': 1000, 'learning_rate': 0.001, 'data_path': '/home/marsgao/BayesianSindyAutoencoder/exmaples/pendulum/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 3001, 'refinement_epochs': 1001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.0008, 'pi': 0.083, 'c_std': 3.0, 'epsilon': 0.05, 'decay': 0.05, 'sigma': 1.0, 'init_sigma': 0.0, 'cycle_sgld': 500}
TRAINING
=========================
[[0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]]
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09459792822599411, (0.0075274156, 0.08386064, 15.105713, 0.011537762)
   validation loss 0.12442122399806976, (0.007719097, 0.09003106, 21.031973, 0.011537762)
decoder loss ratio: 0.920279, decoder SINDy loss  ratio: 1.000000
=========================
[[0.7381324 ]
 [0.7381333 ]
 [0.26245445]
 [0.7381333 ]
 [0.26244476]
 [0.26245198]
 [0.7381335 ]
 [0.26244792]
 [0.26244125]
 [0.2624488 ]
 [0.7381333 ]
 [0.26245448]]
[[ 9.5295960e-01]
 [ 9.7340119e-01]
 [-1.4309430e-03]
 [ 9.7528237e-01]
 [ 5.9773400e-04]
 [-1.2194449e-03]
 [ 9.8025322e-01]
 [ 8.7143551e-04]
 [ 2.9654929e-04]
 [ 9.4612077e-04]
 [ 9.6876878e-01]
 [-1.4321504e-03]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09447822719812393, (0.007415876, 0.0005708625, 15.105713, 0.011533759)
   validation loss 0.12427408248186111, (0.0075804014, 0.0011987748, 21.031973, 0.011533759)
decoder loss ratio: 0.903744, decoder SINDy loss  ratio: 1.000000
=========================
[[0.85042393]
 [0.85042644]
 [0.15041363]
 [0.8504274 ]
 [0.15041336]
 [0.15041287]
 [0.8504278 ]
 [0.15041281]
 [0.15041357]
 [0.15041296]
 [0.850425  ]
 [0.15041363]]
[[ 9.1696250e-01]
 [ 9.4033432e-01]
 [ 9.6298332e-05]
 [ 9.5354670e-01]
 [ 8.1103004e-05]
 [ 5.2197585e-05]
 [ 9.6130991e-01]
 [-4.8662852e-05]
 [ 9.3054907e-05]
 [ 5.4430879e-05]
 [ 9.2510378e-01]
 [ 9.5755982e-05]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09447284787893295, (0.007410574, 0.0015573342, 15.105713, 0.011533636)
   validation loss 0.12427261471748352, (0.00757896, 0.0032077965, 21.031973, 0.011533636)
decoder loss ratio: 0.903572, decoder SINDy loss  ratio: 1.000000
=========================
[[0.9153206 ]
 [0.91533643]
 [0.08564822]
 [0.91534483]
 [0.08564656]
 [0.08564644]
 [0.9153462 ]
 [0.08564627]
 [0.08564772]
 [0.08564613]
 [0.91532063]
 [0.0856469 ]]
[[ 8.4568793e-01]
 [ 8.7922591e-01]
 [-1.2496261e-04]
 [ 9.1612625e-01]
 [-4.0560299e-05]
 [ 3.6819456e-05]
 [ 9.2443293e-01]
 [-2.9126844e-05]
 [ 1.0130646e-04]
 [ 2.0562300e-05]
 [ 8.4592944e-01]
 [ 5.9045240e-05]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09447060525417328, (0.0074085025, 0.0026308314, 15.105713, 0.011533413)
   validation loss 0.12427127361297607, (0.007577758, 0.0048921006, 21.031973, 0.011533413)
decoder loss ratio: 0.903428, decoder SINDy loss  ratio: 1.000000
=========================
[[0.94782305]
 [0.9481605 ]
 [0.05277934]
 [0.94827175]
 [0.05277852]
 [0.05278049]
 [0.94827276]
 [0.05277762]
 [0.05277782]
 [0.05277828]
 [0.9478409 ]
 [0.05277878]]
[[ 7.1440041e-01]
 [ 7.7602810e-01]
 [-9.5501477e-05]
 [ 8.5539848e-01]
 [-5.8323403e-05]
 [-1.4831258e-04]
 [ 8.5703176e-01]
 [ 1.6334710e-05]
 [ 2.5878031e-05]
 [ 4.6295900e-05]
 [ 7.1632630e-01]
 [-6.9382324e-05]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09446839988231659, (0.007406585, 0.0040541664, 15.105713, 0.011533049)
   validation loss 0.1242707148194313, (0.007577448, 0.0070601404, 21.031973, 0.011533049)
decoder loss ratio: 0.903392, decoder SINDy loss  ratio: 1.000000
THRESHOLDING: 5 active coefficients
=========================
[[0.89444315]
 [0.9649765 ]
 [0.        ]
 [0.96851903]
 [0.        ]
 [0.        ]
 [0.9683292 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94757944]
 [0.        ]]
[[ 0.4593703 ]
 [ 0.61363995]
 [ 0.        ]
 [ 0.77081287]
 [ 0.        ]
 [ 0.        ]
 [ 0.7319453 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.5254342 ]
 [-0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.09875638782978058, (0.0074046347, 0.011106146, 15.105713, 0.015822634)
   validation loss 0.12856042385101318, (0.0075770705, 0.017083695, 21.031973, 0.015822634)
decoder loss ratio: 0.903347, decoder SINDy loss  ratio: 1.000000
=========================
[[0.9797107 ]
 [0.97970504]
 [0.        ]
 [0.02636739]
 [0.        ]
 [0.        ]
 [0.02314207]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9797117 ]
 [0.        ]]
[[-1.0102249 ]
 [-0.9298231 ]
 [ 0.        ]
 [-0.08338603]
 [ 0.        ]
 [ 0.        ]
 [-0.04539582]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0699167 ]
 [-0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0750163123011589, (0.007325239, 14.093563, 10.467768, 0.014647558)
   validation loss 0.09914933145046234, (0.0074595907, 20.080976, 15.207628, 0.014647558)
decoder loss ratio: 0.889340, decoder SINDy loss  ratio: 0.723072
=========================
[[0.9869511 ]
 [0.9869531 ]
 [0.        ]
 [0.91827875]
 [0.        ]
 [0.        ]
 [0.0241846 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9869531 ]
 [0.        ]]
[[-0.9933429 ]
 [-1.3071059 ]
 [ 0.        ]
 [-0.46566334]
 [ 0.        ]
 [-0.        ]
 [-0.11318096]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.449572  ]
 [-0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.06100565940141678, (0.0068457783, 9.214927, 7.2473526, 0.017462375)
   validation loss 0.08120336383581161, (0.0072130333, 12.331575, 11.182277, 0.017462375)
decoder loss ratio: 0.859946, decoder SINDy loss  ratio: 0.531680
=========================
[[0.9849748 ]
 [0.9910996 ]
 [0.        ]
 [0.9188872 ]
 [0.        ]
 [0.        ]
 [0.01713754]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9910996 ]
 [0.        ]]
[[-0.5906499 ]
 [-1.265929  ]
 [-0.        ]
 [-0.46340752]
 [-0.        ]
 [ 0.        ]
 [-0.0975104 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.3936317 ]
 [ 0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.04194760322570801, (0.0052576177, 11.767113, 3.9578304, 0.016312478)
   validation loss 0.05537150800228119, (0.005750267, 16.582043, 6.4959316, 0.016312478)
decoder loss ratio: 0.685553, decoder SINDy loss  ratio: 0.308860
THRESHOLDING: 4 active coefficients
=========================
[[0.09931102]
 [0.99395907]
 [0.        ]
 [0.00728287]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.993967  ]
 [0.        ]]
[[-0.22321603]
 [-0.92334193]
 [ 0.        ]
 [ 0.00257243]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0684887 ]
 [ 0.        ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.022512413561344147, (0.0038936338, 8.691662, 1.9721551, 0.008323423)
   validation loss 0.030543610453605652, (0.004451542, 14.161753, 3.412112, 0.008323423)
decoder loss ratio: 0.530718, decoder SINDy loss  ratio: 0.162235
=========================
[[0.00822909]
 [0.99349433]
 [0.        ]
 [0.00750516]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99564743]
 [0.        ]]
[[-0.05970789]
 [-0.64270973]
 [ 0.        ]
 [ 0.04946628]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.83712524]
 [-0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.013968752697110176, (0.0029447307, 5.031428, 0.88899547, 0.006327473)
   validation loss 0.020076511427760124, (0.0038664753, 8.940146, 1.8871114, 0.006327473)
decoder loss ratio: 0.460965, decoder SINDy loss  ratio: 0.089726
=========================
[[0.00469637]
 [0.9467188 ]
 [0.        ]
 [0.00603203]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99515873]
 [0.        ]]
[[ 0.01583627]
 [-0.48343307]
 [-0.        ]
 [ 0.04570663]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.65334576]
 [-0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011220555752515793, (0.0022462728, 3.0547523, 0.6153156, 0.005744968)
   validation loss 0.016675492748618126, (0.0034079168, 6.3706527, 1.440815, 0.005744968)
decoder loss ratio: 0.406296, decoder SINDy loss  ratio: 0.068506
=========================
[[0.0046653 ]
 [0.91895086]
 [0.        ]
 [0.00423849]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98816025]
 [0.        ]]
[[ 0.0347272 ]
 [-0.4594129 ]
 [-0.        ]
 [ 0.02488523]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.568774  ]
 [-0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.009636251255869865, (0.0016690621, 1.4051832, 0.41653368, 0.0058142613)
   validation loss 0.014509256929159164, (0.002922476, 3.6321907, 1.1181818, 0.0058142613)
decoder loss ratio: 0.348421, decoder SINDy loss  ratio: 0.053166
THRESHOLDING: 2 active coefficients
=========================
[[0.        ]
 [0.8945473 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94988185]
 [0.        ]]
[[ 0.        ]
 [-0.44427997]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.48548806]
 [-0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0072275688871741295, (0.00096428045, 1.0638824, 0.27041253, 0.0048580314)
   validation loss 0.011385122314095497, (0.0021910148, 3.1227198, 0.8359879, 0.0048580314)
decoder loss ratio: 0.261215, decoder SINDy loss  ratio: 0.039748
=========================
[[0.        ]
 [0.87326324]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85915   ]
 [0.        ]]
[[ 0.        ]
 [-0.43358713]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.4274258 ]
 [ 0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007072122767567635, (0.0007474923, 0.67327297, 0.19531137, 0.00531441)
   validation loss 0.010731270536780357, (0.0019305934, 2.1293995, 0.6759595, 0.00531441)
decoder loss ratio: 0.230167, decoder SINDy loss  ratio: 0.032140
=========================
[[0.        ]
 [0.85861045]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7879727 ]
 [0.        ]]
[[ 0.        ]
 [-0.42711046]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.40237853]
 [ 0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0072422390803694725, (0.0006654983, 0.5029583, 0.1867044, 0.0056180707)
   validation loss 0.01058906503021717, (0.0017779499, 1.740336, 0.6212057, 0.0056180707)
decoder loss ratio: 0.211969, decoder SINDy loss  ratio: 0.029536
=========================
[[0.        ]
 [0.82711196]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7200394 ]
 [0.        ]]
[[ 0.        ]
 [-0.41504383]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.38384837]
 [-0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007529905065894127, (0.00056381384, 0.41835907, 0.20112252, 0.0059395605)
   validation loss 0.010617775842547417, (0.0015765544, 1.593572, 0.6043965, 0.0059395605)
decoder loss ratio: 0.187959, decoder SINDy loss  ratio: 0.028737
THRESHOLDING: 2 active coefficients
=========================
[[0.       ]
 [0.7978368]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6619161]
 [0.       ]]
[[ 0.        ]
 [-0.40533298]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.370138  ]
 [ 0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007230045273900032, (0.0004477851, 0.37982556, 0.12130402, 0.0061567486)
   validation loss 0.009895483031868935, (0.0013738038, 1.5722216, 0.4572638, 0.0061567486)
decoder loss ratio: 0.163786, decoder SINDy loss  ratio: 0.021741
=========================
[[0.        ]
 [0.77524686]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6154081 ]
 [0.        ]]
[[ 0.        ]
 [-0.39855057]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.36001012]
 [ 0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007230447139590979, (0.00035001355, 0.30419254, 0.101739526, 0.006356526)
   validation loss 0.009646143764257431, (0.0012418213, 1.3735615, 0.3958236, 0.006356526)
decoder loss ratio: 0.148051, decoder SINDy loss  ratio: 0.018820
=========================
[[0.       ]
 [0.7446436]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5767109]
 [0.       ]]
[[ 0.        ]
 [-0.39010832]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.35194147]
 [-0.        ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.008084763772785664, (0.00030604692, 0.24390882, 0.24678794, 0.006532582)
   validation loss 0.010617369785904884, (0.0011538962, 1.1773266, 0.57440513, 0.006532582)
decoder loss ratio: 0.137569, decoder SINDy loss  ratio: 0.027311
=========================
[[0.       ]
 [0.7175086]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5607979]
 [0.       ]]
[[ 0.        ]
 [-0.38317186]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.3486864 ]
 [-0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.008399516344070435, (0.00027447793, 0.23826678, 0.29192954, 0.0066534774)
   validation loss 0.010855354368686676, (0.0010703513, 1.1222386, 0.6150828, 0.0066534774)
decoder loss ratio: 0.127608, decoder SINDy loss  ratio: 0.029245
THRESHOLDING: 2 active coefficients
=========================
[[0.        ]
 [0.69824857]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7255542 ]
 [0.        ]]
[[-0.        ]
 [-0.37849367]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.38517392]
 [ 0.        ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.007538355886936188, (0.00023999967, 0.1181306, 0.19748445, 0.0063050278)
   validation loss 0.009757010266184807, (0.0010191988, 0.91598946, 0.47739682, 0.0063050278)
decoder loss ratio: 0.121510, decoder SINDy loss  ratio: 0.022699
=========================
[[0.        ]
 [0.52594614]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7877167 ]
 [0.        ]]
[[ 0.        ]
 [-0.3416408 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.40217248]
 [-0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.006974006071686745, (0.00018768942, 0.094996065, 0.05676401, 0.006497747)
   validation loss 0.008502500131726265, (0.00083130633, 0.7461855, 02022-07-11 18:46:56.224375: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-07-11 18:46:56.388767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
totalMemory: 10.76GiB freeMemory: 10.60GiB
2022-07-11 18:46:56.388795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2022-07-11 18:46:56.592781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-11 18:46:56.592815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2022-07-11 18:46:56.592820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2022-07-11 18:46:56.592895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9917 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
(50000, 2601)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 2601, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 12, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 100, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'constant', 'loss_weight_decoder': 1.0, 'loss_weight_sindy_x': 0.005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [128, 64, 32], 'epoch_size': 50000, 'batch_size': 1000, 'learning_rate': 0.001, 'data_path': '/home/marsgao/BayesianSindyAutoencoder/exmaples/pendulum/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 3001, 'refinement_epochs': 1001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.0008, 'pi': 0.083, 'c_std': 3.0, 'epsilon': 0.05, 'decay': 0.05, 'sigma': 1.0, 'init_sigma': 0.0, 'cycle_sgld': 500}
TRAINING
=========================
[[0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]
 [0.5]]
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.1435336470603943, (0.008039293, 0.00035066117, 24.791302, 0.0115378145)
   validation loss 0.0964052751660347, (0.0075502363, 0.00027522587, 15.463444, 0.0115378145)
decoder loss ratio: 0.900147, decoder SINDy loss  ratio: 1.000000
=========================
[[0.7381298 ]
 [0.73811495]
 [0.26244023]
 [0.73813105]
 [0.2624424 ]
 [0.26244834]
 [0.7381199 ]
 [0.26244587]
 [0.26245022]
 [0.26244864]
 [0.73810416]
 [0.26244023]]
[[ 9.1133541e-01]
 [ 8.4244686e-01]
 [-2.0724544e-04]
 [ 9.2563510e-01]
 [ 3.9558840e-04]
 [ 9.1100909e-04]
 [ 8.5655856e-01]
 [ 6.9417414e-04]
 [ 1.0721671e-03]
 [ 9.3522907e-04]
 [ 8.2065588e-01]
 [-2.0679290e-04]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.14352631568908691, (0.008035444, 0.02011262, 24.791306, 0.011533354)
   validation loss 0.09625081717967987, (0.007400052, 0.0036889056, 15.463446, 0.011533354)
decoder loss ratio: 0.882242, decoder SINDy loss  ratio: 1.000000
=========================
[[0.84859884]
 [0.84857965]
 [0.15041399]
 [0.8503925 ]
 [0.1504137 ]
 [0.15041386]
 [0.81677765]
 [0.15041204]
 [0.15041247]
 [0.15041296]
 [0.8476314 ]
 [0.15041281]]
[[ 6.34455323e-01]
 [ 6.33931518e-01]
 [-1.17872034e-04]
 [ 8.29153001e-01]
 [-1.03401821e-04]
 [ 1.08779306e-04]
 [ 4.86126602e-01]
 [ 2.63119728e-06]
 [-2.79489905e-05]
 [ 5.72989375e-05]
 [ 6.13115132e-01]
 [ 4.57983842e-05]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.14349660277366638, (0.008006017, 0.030194087, 24.791306, 0.011532548)
   validation loss 0.09624823182821274, (0.007398034, 0.008576429, 15.463445, 0.011532548)
decoder loss ratio: 0.882002, decoder SINDy loss  ratio: 1.000000
=========================
[[0.69968665]
 [0.18314843]
 [0.08577397]
 [0.90884984]
 [0.08570942]
 [0.9140835 ]
 [0.10086296]
 [0.08567075]
 [0.9071076 ]
 [0.08565407]
 [0.70024306]
 [0.08566973]]
[[-3.8893804e-01]
 [-2.3597537e-01]
 [ 6.0500405e-03]
 [ 5.7915825e-01]
 [ 3.0966275e-03]
 [-6.6144508e-01]
 [ 1.4034635e-01]
 [ 1.2400328e-03]
 [-5.6714636e-01]
 [-4.1545430e-04]
 [-3.8911283e-01]
 [-1.1897634e-03]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.10581907629966736, (0.008981681, 34.240288, 16.718613, 0.011532323)
   validation loss 0.07020990550518036, (0.00793537, 21.84378, 9.930005, 0.011532323)
decoder loss ratio: 0.946063, decoder SINDy loss  ratio: 0.642160
=========================
[[0.23128694]
 [0.8207299 ]
 [0.05301743]
 [0.07354619]
 [0.05280701]
 [0.9336068 ]
 [0.05610831]
 [0.0529254 ]
 [0.94421494]
 [0.05278794]
 [0.929193  ]
 [0.05317218]]
[[ 2.6709673e-01]
 [-4.2644829e-01]
 [-1.0071644e-02]
 [ 1.5168966e-01]
 [ 1.3626764e-03]
 [-5.4166865e-01]
 [ 7.0631362e-02]
 [ 6.4474181e-03]
 [-6.0647094e-01]
 [ 4.9188174e-04]
 [-5.2824461e-01]
 [-1.5630551e-02]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.04594270884990692, (0.0069863154, 16.757383, 5.3172693, 0.011532181)
   validation loss 0.030251238495111465, (0.0044584377, 10.76192, 2.744505, 0.011532181)
decoder loss ratio: 0.531540, decoder SINDy loss  ratio: 0.177483
THRESHOLDING: 5 active coefficients
=========================
[[0.08491898]
 [0.37730858]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9493433 ]
 [0.        ]
 [0.        ]
 [0.9423863 ]
 [0.        ]
 [0.967613  ]
 [0.        ]]
[[ 0.19609529]
 [-0.30958453]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.529908  ]
 [ 0.        ]
 [ 0.        ]
 [-0.5141163 ]
 [ 0.        ]
 [-0.6761782 ]
 [-0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.03652928024530411, (0.0058149714, 12.068473, 2.939525, 0.015413263)
   validation loss 0.024992685765028, (0.0028599445, 6.612239, 1.277773, 0.015413263)
decoder loss ratio: 0.340966, decoder SINDy loss  ratio: 0.082632
=========================
[[0.03612039]
 [0.4197274 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95628077]
 [0.        ]
 [0.        ]
 [0.55698436]
 [0.        ]
 [0.9780936 ]
 [0.        ]]
[[ 0.13178663]
 [-0.31951135]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5212518 ]
 [ 0.        ]
 [-0.        ]
 [-0.34839255]
 [ 0.        ]
 [-0.656476  ]
 [-0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.02949950098991394, (0.004940012, 7.15751, 1.8175035, 0.015114097)
   validation loss 0.02036665380001068, (0.0018625119, 3.1831732, 0.64617753, 0.015114097)
decoder loss ratio: 0.222051, decoder SINDy loss  ratio: 0.041787
=========================
[[0.02280525]
 [0.4636998 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9412185 ]
 [0.        ]
 [0.        ]
 [0.29740572]
 [0.        ]
 [0.978038  ]
 [0.        ]]
[[ 0.10649458]
 [-0.32895234]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.48729804]
 [ 0.        ]
 [ 0.        ]
 [-0.29206714]
 [ 0.        ]
 [-0.5712468 ]
 [-0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.026585135608911514, (0.0045165503, 5.1718545, 1.4301685, 0.014659149)
   validation loss 0.018452752381563187, (0.0015030905, 1.8056598, 0.44004607, 0.014659149)
decoder loss ratio: 0.179200, decoder SINDy loss  ratio: 0.028457
=========================
[[0.01494705]
 [0.58545315]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8813084 ]
 [0.        ]
 [0.        ]
 [0.12208951]
 [0.        ]
 [0.960532  ]
 [0.        ]]
[[ 0.08193281]
 [-0.3540476 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.44029257]
 [ 0.        ]
 [ 0.        ]
 [-0.23435798]
 [-0.        ]
 [-0.508751  ]
 [ 0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.02382815256714821, (0.0042582783, 4.9427238, 1.0808924, 0.013918277)
   validation loss 0.016519438475370407, (0.0011914839, 1.4099641, 0.26783577, 0.013918277)
decoder loss ratio: 0.142050, decoder SINDy loss  ratio: 0.017321
THRESHOLDING: 4 active coefficients
=========================
[[0.        ]
 [0.69525325]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7459634 ]
 [0.        ]
 [0.        ]
 [0.04155926]
 [0.        ]
 [0.87199605]
 [0.        ]]
[[ 0.        ]
 [-0.37832144]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3912008 ]
 [ 0.        ]
 [-0.        ]
 [-0.17176664]
 [ 0.        ]
 [-0.43464768]
 [-0.        ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.020403718575835228, (0.0040020416, 3.895817, 0.91684574, 0.011622658)
   validation loss 0.013534164056181908, (0.00089968427, 0.85128367, 0.19385158, 0.011622658)
decoder loss ratio: 0.107261, decoder SINDy loss  ratio: 0.012536
=========================
[[0.        ]
 [0.7889527 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5794961 ]
 [0.        ]
 [0.        ]
 [0.01741705]
 [0.        ]
 [0.7298239 ]
 [0.        ]]
[[ 0.        ]
 [-0.40326026]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.3526426 ]
 [ 0.        ]
 [-0.        ]
 [-0.1205409 ]
 [ 0.        ]
 [-0.38672957]
 [-0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.019185395911335945, (0.003674917, 3.5034018, 0.7740999, 0.01146481)
   validation loss 0.012884076684713364, (0.0006853406, 0.6419876, 0.14036542, 0.01146481)
decoder loss ratio: 0.081707, decoder SINDy loss  ratio: 0.009077
=========================
[[0.        ]
 [0.8457578 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3879391 ]
 [0.        ]
 [0.        ]
 [0.00800882]
 [0.        ]
 [0.55610013]
 [0.        ]]
[[ 0.        ]
 [-0.42252138]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3134487 ]
 [ 0.        ]
 [ 0.        ]
 [-0.07129019]
 [-0.        ]
 [-0.34779352]
 [ 0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01819385588169098, (0.0034176752, 2.9713056, 0.69431293, 0.011156051)
   validation loss 0.012349827215075493, (0.0005358187, 0.42095834, 0.12738182, 0.011156051)
decoder loss ratio: 0.063881, decoder SINDy loss  ratio: 0.008238
=========================
[[0.        ]
 [0.8834122 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22490902]
 [0.        ]
 [0.        ]
 [0.00446138]
 [0.        ]
 [0.45433247]
 [0.        ]]
[[ 0.        ]
 [-0.4387674 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.27410382]
 [ 0.        ]
 [-0.        ]
 [-0.03026434]
 [-0.        ]
 [-0.32721654]
 [-0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.016904521733522415, (0.0032771688, 2.4189541, 0.5960193, 0.01052631)
   validation loss 0.011412504129111767, (0.0004545989, 0.26906234, 0.08362849, 0.01052631)
decoder loss ratio: 0.054198, decoder SINDy loss  ratio: 0.005408
THRESHOLDING: 3 active coefficients
=========================
[[0.        ]
 [0.89751977]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11327313]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.36401564]
 [0.        ]]
[[ 0.        ]
 [-0.44590324]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.23273185]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.30838647]
 [-0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.015877533704042435, (0.0031807583, 2.161423, 0.55822885, 0.009797561)
   validation loss 0.010601190850138664, (0.00040795965, 0.19505705, 0.07718353, 0.009797561)
decoder loss ratio: 0.048637, decoder SINDy loss  ratio: 0.004991
=========================
[[0.        ]
 [0.90289336]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07647113]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32698157]
 [0.        ]]
[[ 0.       ]
 [-0.4487677]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.210897 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.3001751]
 [ 0.       ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.015202934853732586, (0.0030739105, 2.0441422, 0.4952881, 0.009550377)
   validation loss 0.010196110233664513, (0.00035067069, 0.17048772, 0.05730774, 0.009550377)
decoder loss ratio: 0.041807, decoder SINDy loss  ratio: 0.003706
=========================
[[0.        ]
 [0.8959566 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06282165]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28836712]
 [0.        ]]
[[ 0.        ]
 [-0.44474673]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.20036134]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.29108676]
 [-0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01473938673734665, (0.002946521, 1.896989, 0.44978154, 0.0094491085)
   validation loss 0.00999366957694292, (0.00030245475, 0.1322855, 0.04709839, 0.0094491085)
decoder loss ratio: 0.036059, decoder SINDy loss  ratio: 0.003046
=========================
[[0.        ]
 [0.89365053]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05925836]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28213155]
 [0.        ]]
[[-0.        ]
 [-0.44342244]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.19736427]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.28957266]
 [-0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.014706989750266075, (0.002818766, 1.6883744, 0.4774748, 0.009416431)
   validation loss 0.010068200528621674, (0.00026240898, 0.10218688, 0.076850116, 0.009416431)
decoder loss ratio: 0.031285, decoder SINDy loss  ratio: 0.004970
THRESHOLDING: 2 active coefficients
=========================
[[0.        ]
 [0.8619486 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29779223]
 [0.        ]]
[[ 0.        ]
 [-0.42839804]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.29340744]
 [ 0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.01135068479925394, (0.0026907132, 1.45935, 0.39729497, 0.0066005294)
   validation loss 0.007008497603237629, (0.00022491359, 0.099304184, 0.03561787, 0.0066005294)
decoder loss ratio: 0.026814, decoder SINDy loss  ratio: 0.002303
=========================
[[0.       ]
 [0.8313848]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3452356]
 [0.       ]]
[[ 0.        ]
 [-0.41649577]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.30434027]
 [-0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011289965361356735, (0.0025918102, 1.2923669, 0.38575587, 0.006704757)
   validation loss 0.007084272801876068, (0.00019848866, 0.08240903, 0.035381354, 0.006704757)
decoder loss ratio: 0.023664, decoder SINDy loss  ratio: 0.002288
=========================
[[0.        ]
 [0.7937289 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40435946]
 [0.        ]]
[[-0.        ]
 [-0.4040252 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.31701627]
 [-0.        ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011541174724698067, (0.0025181007, 1.1716497, 0.43642992, 0.0067823417)
   validation loss 0.00735035166144371, (0.00018122558, 0.070678085, 0.07665006, 0.0067823417)
decoder loss ratio: 0.021606, decoder SINDy loss  ratio: 0.004957
=========================
[[0.        ]
 [0.73755664]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.46979252]
 [0.        ]]
[[ 0.        ]
 [-0.38824666]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.33037028]
 [ 0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.011067219078540802, (0.0023947626, 0.9837555, 0.3524486, 0.006861026)
   validation loss 0.007174008991569281, (0.00014553538, 0.06297648, 0.03285974, 0.006861026)
decoder loss ratio: 0.017351, decoder SINDy loss  ratio: 0.002125
THRESHOLDING: 2 active coefficients
=========================
[[0.        ]
 [0.51658845]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.69790965]
 [0.        ]]
[[-0.        ]
 [-0.33976164]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.37841302]
 [-0.        ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.010555697605013847, (0.0021591852, 1.0746669, 0.3197437, 0.00674406)
   validation loss 0.007010654546320438, (0.000117471674, 0.053621728, 0.029288298, 0.00674406)
decoder loss ratio: 0.014005, decoder SINDy loss  ratio: 0.001894
=========================
[[0.        ]
 [0.30536616]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8709897 ]
 [0.        ]]
[[ 0.        ]
 [-0.29524612]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.432207  ]
 [ 0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.009606944397091866, (0.0018064412, 1.1825105, 0.2619041, 0.006431857)
   validation loss 0.00663403095677495, (6.919414e-05, 0.04516481, 0.026144253, 0.006431857)
decoder loss ratio: 0.008249, decoder SINDy loss  ratio: 0.001691
=========================
[[0.        ]
 [0.14047179]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9549314 ]
 [0.        ]]
[[ 0.        ]
 [-0.24565679]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.48968   ]
 [-0.        ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.009044294245541096, (0.0016419105, 0.8235904, 0.3077236, 0.0058225864)
   validation loss 0.0062662106938660145, (6.84306e-05, 0.038210228, 0.07465666, 0.0058225864)
decoder loss ratio: 0.008158, decoder SINDy loss  ratio: 0.004828
=========================
[[0.        ]
 [0.06106746]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98712957]
 [0.        ]]
[[-0.        ]
 [-0.19945334]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.55466837]
 [-0.        ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.008127819746732712, (0.0015749343, 0.6191345, 0.28213188, 0.0051112687)
   validation loss 0.005503006279468536, (6.1596555e-05, 0.0337087, 0.06569114, 0.0051112687)
decoder loss ratio: 0.007344, decoder SINDy loss  ratio: 0.004248
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99977434]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81738687]
 [ 0.        ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004597715102136135, (0.0014941714, 0.6378117, 0.20116282, 0.0020658388)
   validation loss 0.0022040202748030424, (3.5759724e-05, 0.02837464, 0.020200625, 0.0020658388)
decoder loss ratio: 0.004263, decoder SINDy loss  ratio: 0.001306
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99979985]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8232335]
 [-0.       ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004514715634286404, (0.0014713869, 0.52402216, 0.19315074, 0.0020513737)
   validation loss 0.002172882668673992, (3.0605835e-05, 0.025196489, 0.017928654, 0.0020513737)
decoder loss ratio: 0.003649, decoder SINDy loss  ratio: 0.001159
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99981636]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8234085]
 [-0.       ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.005040910094976425, (0.0014742871, 0.43002716, 0.30288187, 0.0020307126)
   validation loss 0.002521023154258728, (5.2722888e-05, 0.024602287, 0.087271504, 0.0020307126)
decoder loss ratio: 0.006286, decoder SINDy loss  ratio: 0.005644
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998258]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8207174]
 [ 0.       ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0043989382684230804, (0.0014165672, 0.42755017, 0.19097175, 0.002006135)
   validation loss 0.0021467809565365314, (2.8913671e-05, 0.021885296, 0.022127595, 0.002006135)
decoder loss ratio: 0.003447, decoder SINDy loss  ratio: 0.001431
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99983317]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8175511]
 [-0.       ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004287671763449907, (0.0013808664, 0.39959046, 0.18459412, 0.0019638552)
   validation loss 0.002092803828418255, (2.7029047e-05, 0.020945828, 0.020174464, 0.0019638552)
decoder loss ratio: 0.003222, decoder SINDy loss  ratio: 0.001305
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99983895]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.81527567]
 [-0.        ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004233130253851414, (0.0013502793, 0.36776936, 0.18015218, 0.0019637018)
   validation loss 0.002085692947730422, (2.534492e-05, 0.0199772, 0.019129494, 0.0019637018)
decoder loss ratio: 0.003022, decoder SINDy loss  ratio: 0.001237
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99984884]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81619895]
 [ 0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0041731190867722034, (0.0013269691, 0.33786425, 0.1730989, 0.001963762)
   validation loss 0.0020675226114690304, (2.2451502e-05, 0.018939916, 0.016072413, 0.001963762)
decoder loss ratio: 0.002677, decoder SINDy loss  ratio: 0.001039
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998541]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8153641]
 [-0.       ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004140498116612434, (0.0013086675, 0.31635267, 0.17045578, 0.001963734)
   validation loss 0.0020628981292247772, (2.0854595e-05, 0.017932061, 0.015482615, 0.001963734)
decoder loss ratio: 0.002486, decoder SINDy loss  ratio: 0.001001
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998608]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8157174]
 [-0.       ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004112116061151028, (0.0012939342, 0.29920533, 0.16855745, 0.0019604345)
   validation loss 0.00205615465529263, (1.9437362e-05, 0.017069384, 0.01508589, 0.0019604345)
decoder loss ratio: 0.002317, decoder SINDy loss  ratio: 0.000976
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99986905]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.81852704]
 [ 0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004090852104127407, (0.0012841148, 0.27428496, 0.16648188, 0.0019606135)
   validation loss 0.0020518964156508446, (1.8506693e-05, 0.016195493, 0.014393269, 0.0019606135)
decoder loss ratio: 0.002206, decoder SINDy loss  ratio: 0.000931
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998755]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8196112]
 [-0.       ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004074180033057928, (0.0012730272, 0.27128565, 0.16538179, 0.0019606797)
   validation loss 0.0020524836145341396, (1.8416387e-05, 0.015600565, 0.014521517, 0.0019606797)
decoder loss ratio: 0.002196, decoder SINDy loss  ratio: 0.000939
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998823]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.82193327]
 [-0.        ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00431443564593792, (0.0012769003, 0.25077787, 0.21280748, 0.0019609595)
   validation loss 0.0022185305133461952, (2.883554e-05, 0.014844794, 0.045598656, 0.0019609595)
decoder loss ratio: 0.003438, decoder SINDy loss  ratio: 0.002949
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998914]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8266724]
 [ 0.       ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004057819955050945, (0.0012570487, 0.256373, 0.16575147, 0.0019591954)
   validation loss 0.0020556377712637186, (1.7158554e-05, 0.014614359, 0.015710648, 0.0019591954)
decoder loss ratio: 0.002046, decoder SINDy loss  ratio: 0.001016
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998947]
 [0.       ]]
[[ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.82704586]
 [-0.        ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004163765348494053, (0.0012549422, 0.24282221, 0.1874769, 0.0019592973)
   validation loss 0.0021259363275021315, (1.9307114e-05, 0.01435827, 0.029322777, 0.0019592973)
decoder loss ratio: 0.002302, decoder SINDy loss  ratio: 0.001896
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998994]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8288695]
 [-0.       ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004056498873978853, (0.0012451145, 0.24408345, 0.16796438, 0.0019593583)
   validation loss 0.0020669354125857353, (1.6784004e-05, 0.0137880845, 0.018020725, 0.0019593583)
decoder loss ratio: 0.002001, decoder SINDy loss  ratio: 0.001165
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999029]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8301053]
 [ 0.       ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004017151426523924, (0.0012393426, 0.23803475, 0.16128755, 0.0019594694)
   validation loss 0.0020462702959775925, (1.5857133e-05, 0.013362155, 0.014055109, 0.0019594694)
decoder loss ratio: 0.001891, decoder SINDy loss  ratio: 0.000909
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999374]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.87716424]
 [-0.        ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004118446260690689, (0.0012807833, 0.2887849, 0.17220405, 0.0019622033)
   validation loss 0.0020990886259824038, (3.5161982e-05, 0.019404614, 0.020150613, 0.0019622033)
decoder loss ratio: 0.004192, decoder SINDy loss  ratio: 0.001303
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994296]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.88635796]
 [-0.        ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004037575796246529, (0.0012601522, 0.2943635, 0.1600472, 0.0019624694)
   validation loss 0.0020621209405362606, (2.7579606e-05, 0.017953597, 0.0142348595, 0.0019624694)
decoder loss ratio: 0.003288, decoder SINDy loss  ratio: 0.000921
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999471]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8941099]
 [ 0.       ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004021468572318554, (0.0012455587, 0.2971578, 0.15959705, 0.0019630669)
   validation loss 0.002056831493973732, (2.2863866e-05, 0.017832553, 0.014001811, 0.0019630669)
decoder loss ratio: 0.002726, decoder SINDy loss  ratio: 0.000905
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999494]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8970865]
 [-0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004007289186120033, (0.0012339811, 0.294516, 0.1590412, 0.0019633763)
   validation loss 0.0020565916784107685, (2.010914e-05, 0.016840274, 0.014452861, 0.0019633763)
decoder loss ratio: 0.002397, decoder SINDy loss  ratio: 0.000935
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995255]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.90080374]
 [-0.        ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004114543553441763, (0.0012324608, 0.27531424, 0.18110879, 0.001962773)
   validation loss 0.0021308145951479673, (2.6759311e-05, 0.019330611, 0.028063156, 0.001962773)
decoder loss ratio: 0.003190, decoder SINDy loss  ratio: 0.001815
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999541]
 [0.       ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.90399784]
 [ 0.        ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004025181755423546, (0.0012192392, 0.27509174, 0.16580606, 0.001963158)
   validation loss 0.002079182770103216, (1.9594696e-05, 0.01568008, 0.019129254, 0.001963158)
decoder loss ratio: 0.002336, decoder SINDy loss  ratio: 0.001237
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995595]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.90743047]
 [-0.        ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003970828372985125, (0.0012119277, 0.2698831, 0.15640298, 0.0019633917)
   validation loss 0.0020528980530798435, (1.8625657e-05, 0.015156726, 0.014024556, 0.0019633917)
decoder loss ratio: 0.002221, decoder SINDy loss  ratio: 0.000907
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995714]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9082336]
 [-0.       ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0039548492059111595, (0.0012043965, 0.25535125, 0.15484893, 0.0019634403)
   validation loss 0.0020492614712566137, (1.6998814e-05, 0.014138559, 0.013623081, 0.0019634403)
decoder loss ratio: 0.002027, decoder SINDy loss  ratio: 0.000881
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995863]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9093069]
 [ 0.       ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004144427366554737, (0.0012095115, 0.23329929, 0.19206688, 0.0019629165)
   validation loss 0.002181188901886344, (2.7617516e-05, 0.020028811, 0.037930686, 0.0019629165)
decoder loss ratio: 0.003293, decoder SINDy loss  ratio: 0.002453
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.99996]
 [0.     ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9107067]
 [-0.       ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003938259556889534, (0.0011937367, 0.24227396, 0.15385647, 0.0019631272)
   validation loss 0.0020496449433267117, (1.6412447e-05, 0.014546495, 0.013875608, 0.0019631272)
decoder loss ratio: 0.001957, decoder SINDy loss  ratio: 0.000897
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999606]
 [0.       ]]
[[-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.91007924]
 [-0.        ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003925083205103874, (0.0011879113, 0.23204365, 0.15250553, 0.001963042)
   validation loss 0.002044572727754712, (1.4856785e-05, 0.012189327, 0.013212922, 0.001963042)
decoder loss ratio: 0.001771, decoder SINDy loss  ratio: 0.000854
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999611]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9106604]
 [ 0.       ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003944544121623039, (0.0011879099, 0.24239086, 0.15626495, 0.00196319)
   validation loss 0.002058689948171377, (1.7952027e-05, 0.014503824, 0.015364526, 0.00196319)
decoder loss ratio: 0.002140, decoder SINDy loss  ratio: 0.000994
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996173]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9111912]
 [-0.       ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038987137377262115, (0.0011787176, 0.22567472, 0.14919427, 0.0019627411)
   validation loss 0.0020356089808046818, (1.365471e-05, 0.0106238, 0.011736392, 0.0019627411)
decoder loss ratio: 0.001628, decoder SINDy loss  ratio: 0.000759
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996257]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9125116]
 [-0.       ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038916890043765306, (0.0011745541, 0.21762948, 0.1486812, 0.0019628475)
   validation loss 0.002036886289715767, (1.3331992e-05, 0.0097242985, 0.012044103, 0.0019628475)
decoder loss ratio: 0.001589, decoder SINDy loss  ratio: 0.000779
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999631]
 [0.       ]]
[[ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.91228956]
 [ 0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038787468802183867, (0.0011699685, 0.21570425, 0.14703374, 0.0019628245)
   validation loss 0.0020328406244516373, (1.23284335e-05, 0.009389545, 0.011443622, 0.0019628245)
decoder loss ratio: 0.001470, decoder SINDy loss  ratio: 0.000740
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999639]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9126714]
 [-0.       ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003877924755215645, (0.0011667894, 0.21228576, 0.14753014, 0.0019628704)
   validation loss 0.0020360799971967936, (1.2425836e-05, 0.008890384, 0.012067855, 0.0019628704)
decoder loss ratio: 0.001481, decoder SINDy loss  ratio: 0.000780
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999644]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9125702]
 [-0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003948860801756382, (0.0011669194, 0.20918894, 0.16179125, 0.0019625258)
   validation loss 0.002087799832224846, (1.6714414e-05, 0.010424588, 0.021607697, 0.0019625258)
decoder loss ratio: 0.001993, decoder SINDy loss  ratio: 0.001397
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999651]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9128466]
 [ 0.       ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038541550748050213, (0.0011590766, 0.21186878, 0.14438234, 0.0019625733)
   validation loss 0.0020294070709496737, (1.1471811e-05, 0.008284069, 0.010989562, 0.0019625733)
decoder loss ratio: 0.001368, decoder SINDy loss  ratio: 0.000711
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999656]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9130176]
 [-0.       ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0039022844284772873, (0.00116113, 0.21066968, 0.15359716, 0.0019626352)
   validation loss 0.002064433414489031, (1.586711e-05, 0.011642406, 0.017069785, 0.0019626352)
decoder loss ratio: 0.001892, decoder SINDy loss  ratio: 0.001104
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996585]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.91251487]
 [-0.        ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038460632786154747, (0.0011536068, 0.20894235, 0.14388478, 0.0019625854)
   validation loss 0.002031706739217043, (1.1825638e-05, 0.00763706, 0.011382783, 0.0019625854)
decoder loss ratio: 0.001410, decoder SINDy loss  ratio: 0.000736
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999692]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9269195]
 [-0.       ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004131190944463015, (0.0011942922, 0.2173667, 0.19251047, 0.001963478)
   validation loss 0.0021961014717817307, (3.0241277e-05, 0.02455603, 0.040230896, 0.001963478)
decoder loss ratio: 0.003605, decoder SINDy loss  ratio: 0.002602
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999719]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9480186]
 [-0.       ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003960943780839443, (0.0011868792, 0.2559614, 0.15920155, 0.0019652585)
   validation loss 0.002102554775774479, (3.0553463e-05, 0.016214889, 0.021186428, 0.0019652585)
decoder loss ratio: 0.003643, decoder SINDy loss  ratio: 0.001370
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997336]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.96504337]
 [ 0.        ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0039498405531048775, (0.0011784644, 0.32493538, 0.15767321, 0.0019667633)
   validation loss 0.002102150581777096, (2.9334142e-05, 0.025491655, 0.02095572, 0.0019667633)
decoder loss ratio: 0.003497, decoder SINDy loss  ratio: 0.001355
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999736]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.96961385]
 [-0.        ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003858407726511359, (0.0011622114, 0.35289457, 0.14227884, 0.0019671575)
   validation loss 0.0020515182986855507, (2.239096e-05, 0.016187586, 0.012232103, 0.0019671575)
decoder loss ratio: 0.002669, decoder SINDy loss  ratio: 0.000791
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997395]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.97431046]
 [-0.        ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.004434605129063129, (0.0011743634, 0.39771324, 0.2545712, 0.0019675002)
   validation loss 0.0024175287690013647, (4.162553e-05, 0.0579338, 0.08110126, 0.0019675002)
decoder loss ratio: 0.004963, decoder SINDy loss  ratio: 0.005245
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997413]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9794988]
 [ 0.       ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003897910239174962, (0.001143008, 0.37558424, 0.15363748, 0.0019679356)
   validation loss 0.0020970467012375593, (2.2303195e-05, 0.025966268, 0.02110191, 0.0019679356)
decoder loss ratio: 0.002659, decoder SINDy loss  ratio: 0.001365
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999742]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.981396]
 [-0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003831819398328662, (0.0011240182, 0.36183462, 0.14432521, 0.0019680834)
   validation loss 0.00206950050778687, (1.7615981e-05, 0.016084047, 0.016599383, 0.0019680834)
decoder loss ratio: 0.002100, decoder SINDy loss  ratio: 0.001073
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997437]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9872747]
 [-0.       ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038104176055639982, (0.0011081176, 0.37795436, 0.1429528, 0.0019686383)
   validation loss 0.002071392722427845, (1.7304019e-05, 0.019364763, 0.016896453, 0.0019686383)
decoder loss ratio: 0.002063, decoder SINDy loss  ratio: 0.001093
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997437]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.987546]
 [ 0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0037780199199914932, (0.0010875138, 0.38238516, 0.14054655, 0.0019686543)
   validation loss 0.002072511473670602, (2.0097812e-05, 0.028707331, 0.016464783, 0.0019686543)
decoder loss ratio: 0.002396, decoder SINDy loss  ratio: 0.001065
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997437]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9891317]
 [-0.       ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003687001299113035, (0.0010547702, 0.37004137, 0.12901253, 0.0019686664)
   validation loss 0.00204376014880836, (1.2868453e-05, 0.013135605, 0.0123137, 0.0019686664)
decoder loss ratio: 0.001534, decoder SINDy loss  ratio: 0.000796
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999746]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.99319506]
 [-0.        ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0036276387982070446, (0.0010212966, 0.37486625, 0.12372156, 0.001968991)
   validation loss 0.0020357961766421795, (1.0168749e-05, 0.012684553, 0.011200418, 0.001968991)
decoder loss ratio: 0.001212, decoder SINDy loss  ratio: 0.000724
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999745]
 [0.       ]]
[[-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.99211365]
 [ 0.        ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0035726423375308514, (0.0009858048, 0.36524957, 0.11991639, 0.001968993)
   validation loss 0.0020364064257591963, (1.0468175e-05, 0.011738751, 0.011271619, 0.001968993)
decoder loss ratio: 0.001248, decoder SINDy loss  ratio: 0.000729
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999745]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9910235]
 [-0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0035384742077440023, (0.00094967533, 0.35894173, 0.12041275, 0.001968788)
   validation loss 0.0020522938575595617, (1.2373841e-05, 0.013174849, 0.014094649, 0.001968788)
decoder loss ratio: 0.001475, decoder SINDy loss  ratio: 0.000911
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999745]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9910913]
 [-0.       ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.003713006153702736, (0.00090597256, 0.3566978, 0.16409028, 0.0019687475)
   validation loss 0.0022120291832834482, (1.882132e-05, 0.029360278, 0.044598468, 0.0019687475)
decoder loss ratio: 0.002244, decoder SINDy loss  ratio: 0.002884
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999745]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9912388]
 [ 0.       ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0032880031503736973, (0.000781256, 0.3708532, 0.1038868, 0.0019687705)
   validation loss 0.0020262065809220076, (6.5460745e-06, 0.009244792, 0.010085532, 0.0019687705)
decoder loss ratio: 0.000780, decoder SINDy loss  ratio: 0.000652
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999743]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.98833823]
 [-0.        ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0032126717269420624, (0.00068765774, 0.4466878, 0.10680768, 0.0019686413)
   validation loss 0.002050715498626232, (9.367119e-06, 0.017750086, 0.014363921, 0.0019686413)
decoder loss ratio: 0.001117, decoder SINDy loss  ratio: 0.000929
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997425]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.98604894]
 [-0.        ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0030559988226741552, (0.00058036146, 0.5939095, 0.09553859, 0.001968249)
   validation loss 0.0020320252515375614, (8.532891e-06, 0.011636278, 0.010932302, 0.001968249)
decoder loss ratio: 0.001017, decoder SINDy loss  ratio: 0.000707
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997413]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9829488]
 [ 0.       ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0029374868609011173, (0.0004831018, 0.6527208, 0.09075721, 0.001967963)
   validation loss 0.0020249702502042055, (4.387451e-06, 0.009384639, 0.010430118, 0.001967963)
decoder loss ratio: 0.000523, decoder SINDy loss  ratio: 0.000675
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999741]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.98097813]
 [-0.        ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0029140315018594265, (0.00042571727, 0.6338805, 0.0977663, 0.0019677887)
   validation loss 0.0020584044978022575, (8.2904535e-06, 0.014066736, 0.016324412, 0.0019677887)
decoder loss ratio: 0.000988, decoder SINDy loss  ratio: 0.001056
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997395]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.97931516]
 [-0.        ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002799468580633402, (0.00037848979, 0.61068594, 0.08455848, 0.0019676522)
   validation loss 0.0020215411204844713, (5.6181057e-06, 0.0090073235, 0.009564104, 0.0019676522)
decoder loss ratio: 0.000670, decoder SINDy loss  ratio: 0.000618
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0718858]
 [-0.       ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.006345808040350676, (0.00056499447, 0.9814074, 0.7509692, 0.0019768975)
   validation loss 0.004088032990694046, (0.000113935195, 0.14521381, 0.397988, 0.0019768975)
decoder loss ratio: 0.013583, decoder SINDy loss  ratio: 0.025737
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0746614]
 [-0.       ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0038116590585559607, (0.00042485903, 1.0015728, 0.27198163, 0.0019768132)
   validation loss 0.002647413406521082, (7.7719465e-05, 0.15555866, 0.11702057, 0.0019768132)
decoder loss ratio: 0.009266, decoder SINDy loss  ratio: 0.007568
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-1.094664]
 [ 0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.005220165476202965, (0.00040833853, 0.93186784, 0.5573015, 0.0019787257)
   validation loss 0.003623378463089466, (0.00010694829, 0.12296209, 0.3063113, 0.0019787257)
decoder loss ratio: 0.012750, decoder SINDy loss  ratio: 0.019809
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1032014]
 [-0.       ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0027539615985006094, (0.0002717805, 0.79758793, 0.09255419, 0.0019795308)
   validation loss 0.0021112861577421427, (2.2124064e-05, 0.04181838, 0.021508094, 0.0019795308)
decoder loss ratio: 0.002638, decoder SINDy loss  ratio: 0.001391
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1035802]
 [-0.       ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0028592986054718494, (0.00021316447, 0.78802377, 0.12546222, 0.0019794218)
   validation loss 0.0022176974453032017, (2.132957e-05, 0.092593394, 0.042463258, 0.0019794218)
decoder loss ratio: 0.002543, decoder SINDy loss  ratio: 0.002746
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1063516]
 [ 0.       ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002528579207137227, (0.00016888867, 0.66272885, 0.06937942, 0.001979657)
   validation loss 0.002064269734546542, (1.9331088e-05, 0.04044742, 0.012651851, 0.001979657)
decoder loss ratio: 0.002305, decoder SINDy loss  ratio: 0.000818
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1087501]
 [-0.       ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0028848149813711643, (0.00015021469, 0.69469464, 0.14396492, 0.001980041)
   validation loss 0.0022938097827136517, (2.1789094e-05, 0.09838961, 0.057412058, 0.001980041)
decoder loss ratio: 0.002598, decoder SINDy loss  ratio: 0.003713
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1116271]
 [-0.       ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002433577086776495, (0.00012385251, 0.58978593, 0.060001887, 0.0019802258)
   validation loss 0.0020495285280048847, (1.5880187e-05, 0.039925165, 0.010285281, 0.0019802258)
decoder loss ratio: 0.001893, decoder SINDy loss  ratio: 0.000665
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-1.112663]
 [ 0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024860685225576162, (0.00011147168, 0.52240986, 0.07362586, 0.001980347)
   validation loss 0.002086527645587921, (1.0217541e-05, 0.03940685, 0.018798532, 0.001980347)
decoder loss ratio: 0.001218, decoder SINDy loss  ratio: 0.001216
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1132458]
 [-0.       ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002378709614276886, (0.0001041667, 0.46213928, 0.054225046, 0.0019803108)
   validation loss 0.0020374413579702377, (1.0680176e-05, 0.025987973, 0.009030189, 0.0019803108)
decoder loss ratio: 0.001273, decoder SINDy loss  ratio: 0.000584
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1122507]
 [-0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0026014246977865696, (0.000103747014, 0.44888416, 0.09898572, 0.001980305)
   validation loss 0.0021723683457821608, (1.1940465e-05, 0.0687412, 0.035337187, 0.001980305)
decoder loss ratio: 0.001424, decoder SINDy loss  ratio: 0.002285
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1123148]
 [ 0.       ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023503489792346954, (9.640584e-05, 0.3547225, 0.051195994, 0.001980227)
   validation loss 0.0020321712363511324, (8.027766e-06, 0.024860328, 0.008534723, 0.001980227)
decoder loss ratio: 0.000957, decoder SINDy loss  ratio: 0.000552
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1104565]
 [-0.       ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025080102495849133, (9.824365e-05, 0.3393008, 0.082540005, 0.0019801015)
   validation loss 0.002126820385456085, (1.0049954e-05, 0.052399218, 0.026809799, 0.0019801015)
decoder loss ratio: 0.001198, decoder SINDy loss  ratio: 0.001734
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1099926]
 [-0.       ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023326806258410215, (9.442937e-05, 0.2786084, 0.048869923, 0.0019799713)
   validation loss 0.00202895887196064, (7.6254087e-06, 0.023724154, 0.00803519, 0.0019799713)
decoder loss ratio: 0.000909, decoder SINDy loss  ratio: 0.000520
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1085567]
 [ 0.       ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023299832828342915, (9.335045e-05, 0.23620102, 0.048996802, 0.0019798388)
   validation loss 0.002027988899499178, (5.760243e-06, 0.018804407, 0.008289925, 0.0019798388)
decoder loss ratio: 0.000687, decoder SINDy loss  ratio: 0.000536
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1069189]
 [-0.       ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002334314864128828, (9.2663715e-05, 0.20882806, 0.05030416, 0.0019796889)
   validation loss 0.0020316278096288443, (4.503787e-06, 0.02236473, 0.009263379, 0.0019796889)
decoder loss ratio: 0.000537, decoder SINDy loss  ratio: 0.000599
THRESHOLDING: 1 active coefficients
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1043842]
 [-0.       ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023369493428617716, (9.302539e-05, 0.18457907, 0.051054623, 0.0019794218)
   validation loss 0.0020346171222627163, (4.3860055e-06, 0.019385561, 0.009967997, 0.0019794218)
decoder loss ratio: 0.000523, decoder SINDy loss  ratio: 0.000645
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1031237]
 [ 0.       ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023219517897814512, (9.467473e-05, 0.17479289, 0.047852606, 0.0019792744)
   validation loss 0.0020288543310016394, (5.8980645e-06, 0.018959457, 0.008546786, 0.0019792744)
decoder loss ratio: 0.000703, decoder SINDy loss  ratio: 0.000553
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1012528]
 [-0.       ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024102837778627872, (9.858189e-05, 0.21514696, 0.06434564, 0.0019792162)
   validation loss 0.002080154838040471, (8.321681e-06, 0.053354353, 0.017989846, 0.0019792162)
decoder loss ratio: 0.000992, decoder SINDy loss  ratio: 0.001163
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999762]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0998001]
 [-0.       ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0022954142186790705, (9.446195e-05, 0.1445437, 0.042958297, 0.0019789336)
   validation loss 0.002013480057939887, (3.523391e-06, 0.014696901, 0.0060576387, 0.0019789336)
decoder loss ratio: 0.000420, decoder SINDy loss  ratio: 0.000392
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1665585]
 [ 0.       ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00428739283233881, (0.00021551352, 0.6569845, 0.41061422, 0.001985959)
   validation loss 0.0031901360489428043, (0.00010199461, 0.29359734, 0.21750052, 0.001985959)
decoder loss ratio: 0.012160, decoder SINDy loss  ratio: 0.014065
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1784656]
 [-0.       ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025323652662336826, (0.00014821095, 0.43384567, 0.07504782, 0.0019872228)
   validation loss 0.00218165828846395, (6.600539e-05, 0.1287026, 0.024398997, 0.0019872228)
decoder loss ratio: 0.007869, decoder SINDy loss  ratio: 0.001578
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1847838]
 [-0.       ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0031232035253196955, (0.00016100686, 0.6021398, 0.1888388, 0.0019878957)
   validation loss 0.0025171928573399782, (7.211965e-05, 0.20774959, 0.08935802, 0.0019878957)
decoder loss ratio: 0.008598, decoder SINDy loss  ratio: 0.005779
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1889219]
 [ 0.       ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0024575479328632355, (0.0001378443, 0.4838024, 0.061456334, 0.001988232)
   validation loss 0.0021390733309090137, (5.4235283e-05, 0.10500925, 0.018271139, 0.001988232)
decoder loss ratio: 0.006466, decoder SINDy loss  ratio: 0.001182
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1903937]
 [-0.       ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00281440163962543, (0.0001462186, 0.58069885, 0.13013676, 0.0019884643)
   validation loss 0.002331069903448224, (5.372029e-05, 0.1629485, 0.056147598, 0.0019884643)
decoder loss ratio: 0.006405, decoder SINDy loss  ratio: 0.003631
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1910031]
 [-0.       ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002419683849439025, (0.00013346586, 0.3974827, 0.055578914, 0.0019884494)
   validation loss 0.0021102563478052616, (4.4049117e-05, 0.07293576, 0.014822216, 0.0019884494)
decoder loss ratio: 0.005252, decoder SINDy loss  ratio: 0.000959
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1895071]
 [ 0.       ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002730259671807289, (0.00013900238, 0.4625152, 0.11595331, 0.001988365)
   validation loss 0.0022799791768193245, (4.186269e-05, 0.13198215, 0.04863047, 0.001988365)
decoder loss ratio: 0.004991, decoder SINDy loss  ratio: 0.003145
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1888157]
 [-0.       ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023848609998822212, (0.00012805799, 0.32522556, 0.050467465, 0.0019882044)
   validation loss 0.002083975588902831, (3.2810203e-05, 0.06541348, 0.011938059, 0.0019882044)
decoder loss ratio: 0.003912, decoder SINDy loss  ratio: 0.000772
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-1.18583]
 [-0.     ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002643733285367489, (0.00013395213, 0.37141412, 0.10065236, 0.0019879488)
   validation loss 0.002226992277428508, (3.233476e-05, 0.11050364, 0.040236693, 0.0019879488)
decoder loss ratio: 0.003855, decoder SINDy loss  ratio: 0.002602
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1833584]
 [ 0.       ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023553387727588415, (0.00012549723, 0.24403445, 0.046009917, 0.0019875902)
   validation loss 0.0020628601778298616, (2.563058e-05, 0.044434085, 0.0094835125, 0.0019875902)
decoder loss ratio: 0.003056, decoder SINDy loss  ratio: 0.000613
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1795983]
 [-0.       ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0025139683857560158, (0.00012823934, 0.284211, 0.07685034, 0.0019872668)
   validation loss 0.0021487469784915447, (2.3952372e-05, 0.07959885, 0.026709564, 0.0019872668)
decoder loss ratio: 0.002856, decoder SINDy loss  ratio: 0.001727
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1771514]
 [-0.       ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023715803399682045, (0.00012338148, 0.2198745, 0.050048254, 0.001986964)
   validation loss 0.002064898842945695, (1.6811564e-05, 0.049143776, 0.011733218, 0.001986964)
decoder loss ratio: 0.002004, decoder SINDy loss  ratio: 0.000759
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997663]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1733387]
 [ 0.       ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.002357002580538392, (0.00012875455, 0.23290613, 0.046017677, 0.0019865143)
   validation loss 0.0020624594762921333, (2.2834442e-05, 0.07045546, 0.009917576, 0.0019865143)
decoder loss ratio: 0.002722, decoder SINDy loss  ratio: 0.000641
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1710198]
 [-0.       ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023389398120343685, (0.00012166103, 0.19269589, 0.044286057, 0.0019862137)
   validation loss 0.002047815825790167, (1.4465229e-05, 0.052289844, 0.008904479, 0.0019862137)
decoder loss ratio: 0.001725, decoder SINDy loss  ratio: 0.000576
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1668091]
 [-0.       ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00241239950992167, (0.00012419722, 0.18747534, 0.05857866, 0.0019859353)
   validation loss 0.0020862817764282227, (1.4115938e-05, 0.050450135, 0.016741598, 0.0019859353)
decoder loss ratio: 0.001683, decoder SINDy loss  ratio: 0.001083
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1638314]
 [ 0.       ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023180569987744093, (0.00012265242, 0.1436291, 0.040552933, 0.0019854584)
   validation loss 0.002032228745520115, (1.2387029e-05, 0.030688873, 0.0065697622, 0.0019854584)
decoder loss ratio: 0.001477, decoder SINDy loss  ratio: 0.000425
THRESHOLDING: 1 active coefficients
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1593746]
 [-0.       ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023864402901381254, (0.00012321946, 0.15722391, 0.054049432, 0.0019851124)
   validation loss 0.0020702816545963287, (1.02421745e-05, 0.04518418, 0.014533582, 0.0019851124)
decoder loss ratio: 0.001221, decoder SINDy loss  ratio: 0.000940
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.156215]
 [-0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023081910330802202, (0.0001222764, 0.119917065, 0.03905243, 0.0019846566)
   validation loss 0.0020246352069079876, (9.352014e-06, 0.025843875, 0.005866889, 0.0019846566)
decoder loss ratio: 0.001115, decoder SINDy loss  ratio: 0.000379
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1518222]
 [ 0.       ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023525787983089685, (0.00012330174, 0.12250743, 0.047768444, 0.0019843094)
   validation loss 0.0020483341068029404, (8.193087e-06, 0.03170759, 0.010849261, 0.0019843094)
decoder loss ratio: 0.000977, decoder SINDy loss  ratio: 0.000702
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997646]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1487726]
 [-0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0023028734140098095, (0.00012292397, 0.10475285, 0.03816681, 0.0019838777)
   validation loss 0.0020206153858453035, (7.797514e-06, 0.024302196, 0.005545016, 0.0019838777)
decoder loss ratio: 0.000930, decoder SINDy loss  ratio: 0.000359
THRESHOLDING: 1 active coefficients
REFINEMENT
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00037650333251804113, (0.00012538403, 0.1257878, 0.04896598, 0.0019840186)
   validation loss 6.34532407275401e-05, (5.4269317e-06, 0.039632875, 0.011208933, 0.0019840186)
decoder loss ratio: 0.000647, decoder SINDy loss  ratio: 0.000725
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00032590614864602685, (0.00012174846, 0.09568137, 0.03987473, 0.0019837094)
   validation loss 3.8030382711440325e-05, (4.4170633e-06, 0.023601452, 0.006486649, 0.0019837094)
decoder loss ratio: 0.000527, decoder SINDy loss  ratio: 0.000419
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00030994860571809113, (0.00012186841, 0.08613618, 0.03675468, 0.0019832922)
   validation loss 2.9359540349105373e-05, (4.334699e-06, 0.019421512, 0.0048107533, 0.0019832922)
decoder loss ratio: 0.000517, decoder SINDy loss  ratio: 0.000311
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00032477761851623654, (0.00012178959, 0.08182216, 0.039779387, 0.0019829334)
   validation loss 3.68186374544166e-05, (3.164199e-06, 0.020331843, 0.006527569, 0.0019829334)
decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.000422
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00030557531863451004, (0.000121690166, 0.07461404, 0.03603089, 0.0019825196)
   validation loss 2.620586019475013e-05, (2.9549708e-06, 0.016703617, 0.004483142, 0.0019825196)
decoder loss ratio: 0.000352, decoder SINDy loss  ratio: 0.000290
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0003112860140390694, (0.000121685196, 0.06774198, 0.037242748, 0.0019821904)
   validation loss 2.853145997505635e-05, (2.165553e-06, 0.015289085, 0.005120291, 0.0019821904)
decoder loss ratio: 0.000258, decoder SINDy loss  ratio: 0.000331
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0003022492164745927, (0.0001218525, 0.065301515, 0.03542633, 0.0019818388)
   validation loss 2.383281935181003e-05, (2.1989538e-06, 0.01419912, 0.004184782, 0.0019818388)
decoder loss ratio: 0.000262, decoder SINDy loss  ratio: 0.000271
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.0003055320412386209, (0.000121842524, 0.05999085, 0.036137998, 0.0019815334)
   validation loss 2.5046863811439835e-05, (1.6266829e-06, 0.013220486, 0.0045518316, 0.0019815334)
decoder loss ratio: 0.000194, decoder SINDy loss  ratio: 0.000294
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00029965414432808757, (0.0001220411, 0.05785209, 0.034944087, 0.0019812207)
   validation loss 2.2118894776212983e-05, (1.6684033e-06, 0.01217767, 0.0039683217, 0.0019812207)
decoder loss ratio: 0.000199, decoder SINDy loss  ratio: 0.000257
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00030127959325909615, (0.00012206753, 0.054180767, 0.0353006, 0.0019809422)
   validation loss 2.2565398467122577e-05, (1.3128445e-06, 0.01165505, 0.0041339607, 0.0019809422)
decoder loss ratio: 0.000157, decoder SINDy loss  ratio: 0.000267
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00029779988108202815, (0.00012224194, 0.052458037, 0.03458701, 0.0019806626)
   validation loss 2.0860294171143323e-05, (1.3458931e-06, 0.010785507, 0.0037950254, 0.0019806626)
decoder loss ratio: 0.000160, decoder SINDy loss  ratio: 0.000245
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00029835954774171114, (0.00012226422, 0.049622886, 0.034722835, 0.0019804111)
   validation loss 2.082170067296829e-05, (1.0819768e-06, 0.010278509, 0.0038451594, 0.0019804111)
decoder loss ratio: 0.000129, decoder SINDy loss  ratio: 0.000249
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00029642516165040433, (0.00012244054, 0.0482629, 0.034314297, 0.0019801583)
   validation loss 1.9988092390121892e-05, (1.1340306e-06, 0.009679382, 0.0036740184, 0.0019801583)
decoder loss ratio: 0.000135, decoder SINDy loss  ratio: 0.000238
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 0.00029642169829458, (0.00012245019, 0.04612235, 0.034333076, 0.0019799285)