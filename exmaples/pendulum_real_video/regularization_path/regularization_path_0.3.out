nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 02:25:41.179279: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 02:25:41.186584: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 02:25:41.188523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562ac029c180 executing computations on platform Host. Devices:
2023-10-25 02:25:41.188550: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 02:25:41.190529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 02:25:41.321858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562ac040f810 executing computations on platform CUDA. Devices:
2023-10-25 02:25:41.321922: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 02:25:41.322898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-25 02:25:41.323481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 02:25:41.328262: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 02:25:41.332103: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 02:25:41.332866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 02:25:41.336782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 02:25:41.338599: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 02:25:41.345182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 02:25:41.346143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 02:25:41.346198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 02:25:41.346667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 02:25:41.346681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 02:25:41.346689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 02:25:41.347470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-25 02:25:42.414417: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.3, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8415243625640869 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 106911.859375, (101860.41, 0.010749174, 5033.4917, 2.5317805)
   validation loss 90841.3984375, (89622.68, 0.009702665, 1200.7583, 2.5317805)
decoder loss ratio: 3472138.202908, decoder SINDy loss  ratio: 2.592006
--- 0.2704308032989502 seconds for one epoch ---
--- 0.3262665271759033 seconds for one epoch ---
--- 0.33432579040527344 seconds for one epoch ---
--- 0.3248260021209717 seconds for one epoch ---
--- 0.32909488677978516 seconds for one epoch ---
--- 0.32207155227661133 seconds for one epoch ---
--- 0.33594775199890137 seconds for one epoch ---
--- 0.32468485832214355 seconds for one epoch ---
--- 0.3290517330169678 seconds for one epoch ---
--- 0.33130502700805664 seconds for one epoch ---
--- 0.33536314964294434 seconds for one epoch ---
--- 0.32572221755981445 seconds for one epoch ---
--- 0.34103870391845703 seconds for one epoch ---
--- 0.32561612129211426 seconds for one epoch ---
--- 0.3311479091644287 seconds for one epoch ---
--- 0.31888699531555176 seconds for one epoch ---
--- 0.3571360111236572 seconds for one epoch ---
--- 0.3223452568054199 seconds for one epoch ---
--- 0.34612154960632324 seconds for one epoch ---
--- 0.3254265785217285 seconds for one epoch ---
--- 0.33139538764953613 seconds for one epoch ---
--- 0.32182765007019043 seconds for one epoch ---
--- 0.3530764579772949 seconds for one epoch ---
--- 0.3238694667816162 seconds for one epoch ---
=========================
[[0.77282894]
 [0.77771425]
 [0.8235362 ]
 [0.78553796]
 [0.7723717 ]
 [0.8525523 ]
 [0.7886313 ]
 [0.7726727 ]
 [0.7723722 ]
 [0.9476354 ]
 [0.7760149 ]]
[[-0.11127418]
 [ 0.5425852 ]
 [-1.2466078 ]
 [-0.793331  ]
 [-0.00789308]
 [-1.4359825 ]
 [ 0.8571236 ]
 [-0.07971141]
 [ 0.00804184]
 [-1.9903024 ]
 [ 0.44823137]]
--- 0.27118659019470215 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 81669.2421875, (76093.266, 10.223114, 5528.7983, 2.5317867)
   validation loss 68928.0, (67686.36, 2.6215217, 1202.0596, 2.5317867)
decoder loss ratio: 2622287.070875, decoder SINDy loss  ratio: 2.594815
--- 0.3231520652770996 seconds for one epoch ---
--- 0.34218692779541016 seconds for one epoch ---
--- 0.3210880756378174 seconds for one epoch ---
--- 0.33838582038879395 seconds for one epoch ---
--- 0.33595752716064453 seconds for one epoch ---
--- 0.34436821937561035 seconds for one epoch ---
--- 0.3231806755065918 seconds for one epoch ---
--- 0.3412964344024658 seconds for one epoch ---
--- 0.33557558059692383 seconds for one epoch ---
--- 0.3413701057434082 seconds for one epoch ---
--- 0.32578253746032715 seconds for one epoch ---
--- 0.3447384834289551 seconds for one epoch ---
--- 0.3241770267486572 seconds for one epoch ---
--- 0.35381031036376953 seconds for one epoch ---
--- 0.32600927352905273 seconds for one epoch ---
--- 0.348358154296875 seconds for one epoch ---
--- 0.3224670886993408 seconds for one epoch ---
--- 0.3467373847961426 seconds for one epoch ---
--- 0.3288588523864746 seconds for one epoch ---
--- 0.3475027084350586 seconds for one epoch ---
--- 0.3187143802642822 seconds for one epoch ---
--- 0.33478450775146484 seconds for one epoch ---
--- 0.32315969467163086 seconds for one epoch ---
--- 0.34841227531433105 seconds for one epoch ---
=========================
[[0.61985254]
 [0.6137953 ]
 [0.7728466 ]
 [0.61968505]
 [0.61103636]
 [0.8298819 ]
 [0.6202328 ]
 [0.6117107 ]
 [0.6105607 ]
 [0.6432881 ]
 [0.61601007]]
[[ 0.5466222 ]
 [ 0.3071765 ]
 [-1.518673  ]
 [-0.54195046]
 [ 0.07398976]
 [-1.6983247 ]
 [ 0.5570109 ]
 [ 0.14922105]
 [ 0.00676613]
 [-0.9075416 ]
 [ 0.41680196]]
--- 0.3023684024810791 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 49565.875, (42933.625, 24.146788, 6557.369, 2.531761)
   validation loss 47302.16796875, (46053.992, 6.6217184, 1190.8213, 2.531761)
decoder loss ratio: 1784211.610590, decoder SINDy loss  ratio: 2.570555
--- 0.28164196014404297 seconds for one epoch ---
--- 0.31714677810668945 seconds for one epoch ---
--- 0.34993863105773926 seconds for one epoch ---
--- 0.32858824729919434 seconds for one epoch ---
--- 0.36918020248413086 seconds for one epoch ---
--- 0.32291698455810547 seconds for one epoch ---
--- 0.34893274307250977 seconds for one epoch ---
--- 0.3350508213043213 seconds for one epoch ---
--- 0.3462374210357666 seconds for one epoch ---
--- 0.323162317276001 seconds for one epoch ---
--- 0.35031628608703613 seconds for one epoch ---
--- 0.3134024143218994 seconds for one epoch ---
--- 0.3606693744659424 seconds for one epoch ---
--- 0.3247530460357666 seconds for one epoch ---
--- 0.3508305549621582 seconds for one epoch ---
--- 0.42352294921875 seconds for one epoch ---
--- 0.3398153781890869 seconds for one epoch ---
--- 0.328859806060791 seconds for one epoch ---
--- 0.3460426330566406 seconds for one epoch ---
--- 0.32602763175964355 seconds for one epoch ---
--- 0.3687291145324707 seconds for one epoch ---
--- 0.3236238956451416 seconds for one epoch ---
--- 0.3710322380065918 seconds for one epoch ---
--- 0.3272969722747803 seconds for one epoch ---
=========================
[[0.50812685]
 [0.47507542]
 [0.7504962 ]
 [0.48164156]
 [0.47595438]
 [0.9050416 ]
 [0.48082188]
 [0.47690195]
 [0.47498953]
 [0.47905263]
 [0.4807294 ]]
[[ 8.1905317e-01]
 [ 1.1981418e-02]
 [-1.6510494e+00]
 [-3.9319482e-01]
 [ 9.9383622e-02]
 [-2.0831456e+00]
 [ 3.6453792e-01]
 [ 1.7198300e-01]
 [ 1.9502532e-03]
 [-2.9193223e-01]
 [ 3.6114079e-01]]
--- 0.2672698497772217 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 48370.22265625, (42463.61, 7.556134, 5830.8667, 2.531767)
   validation loss 33306.703125, (32091.945, 5.155185, 1141.4114, 2.531767)
decoder loss ratio: 1243297.675473, decoder SINDy loss  ratio: 2.463897
--- 0.3289763927459717 seconds for one epoch ---
--- 0.35486817359924316 seconds for one epoch ---
--- 0.32683467864990234 seconds for one epoch ---
--- 0.35662031173706055 seconds for one epoch ---
--- 0.31679749488830566 seconds for one epoch ---
--- 0.372283935546875 seconds for one epoch ---
--- 0.3263266086578369 seconds for one epoch ---
--- 0.3595709800720215 seconds for one epoch ---
--- 0.32361578941345215 seconds for one epoch ---
--- 0.3689844608306885 seconds for one epoch ---
--- 0.32500219345092773 seconds for one epoch ---
--- 0.3771326541900635 seconds for one epoch ---
--- 0.32529687881469727 seconds for one epoch ---
--- 0.35374903678894043 seconds for one epoch ---
--- 0.32302308082580566 seconds for one epoch ---
--- 0.3644077777862549 seconds for one epoch ---
--- 0.3402070999145508 seconds for one epoch ---
--- 0.3558785915374756 seconds for one epoch ---
--- 0.3365325927734375 seconds for one epoch ---
--- 0.3779006004333496 seconds for one epoch ---
--- 0.3322408199310303 seconds for one epoch ---
--- 0.3663613796234131 seconds for one epoch ---
--- 0.3283700942993164 seconds for one epoch ---
--- 0.366497278213501 seconds for one epoch ---
=========================
[[0.44597095]
 [0.37943077]
 [0.78305143]
 [0.3817411 ]
 [0.37989768]
 [0.9405347 ]
 [0.38180244]
 [0.38095114]
 [0.3780471 ]
 [0.37910503]
 [0.3816209 ]]
[[ 9.91422772e-01]
 [-1.16503194e-01]
 [-1.81137908e+00]
 [-2.44891271e-01]
 [ 1.47131369e-01]
 [-2.30990672e+00]
 [ 2.47652590e-01]
 [ 2.06732541e-01]
 [ 2.00133841e-03]
 [ 9.31647941e-02]
 [ 2.39388272e-01]]
--- 0.31502366065979004 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 35771.26171875, (25647.768, 4.318202, 10035.983, 2.531783)
   validation loss 13855.39453125, (12716.337, 0.6727133, 1055.1917, 2.531783)
decoder loss ratio: 492652.968583, decoder SINDy loss  ratio: 2.277780
--- 0.27677178382873535 seconds for one epoch ---
--- 0.32356977462768555 seconds for one epoch ---
--- 0.3592038154602051 seconds for one epoch ---
--- 0.32093358039855957 seconds for one epoch ---
--- 0.3836047649383545 seconds for one epoch ---
--- 0.32067036628723145 seconds for one epoch ---
--- 0.3628203868865967 seconds for one epoch ---
--- 0.3220951557159424 seconds for one epoch ---
--- 0.3620483875274658 seconds for one epoch ---
--- 0.3251152038574219 seconds for one epoch ---
--- 0.36449670791625977 seconds for one epoch ---
--- 0.3264944553375244 seconds for one epoch ---
--- 0.3699800968170166 seconds for one epoch ---
--- 0.32793641090393066 seconds for one epoch ---
--- 0.3721354007720947 seconds for one epoch ---
--- 0.33017444610595703 seconds for one epoch ---
--- 0.36260414123535156 seconds for one epoch ---
--- 0.3210599422454834 seconds for one epoch ---
--- 0.3702847957611084 seconds for one epoch ---
--- 0.3295323848724365 seconds for one epoch ---
--- 0.3727602958679199 seconds for one epoch ---
--- 0.31516599655151367 seconds for one epoch ---
--- 0.37839198112487793 seconds for one epoch ---
--- 0.3278470039367676 seconds for one epoch ---
=========================
[[0.34077767]
 [0.30170867]
 [0.8403734 ]
 [0.2978708 ]
 [0.2981325 ]
 [0.97022945]
 [0.2984266 ]
 [0.30056357]
 [0.29633462]
 [0.2966814 ]
 [0.30005702]]
[[ 8.1914061e-01]
 [-2.8884119e-01]
 [-1.9958166e+00]
 [-1.1356989e-01]
 [ 1.2928133e-01]
 [-2.5794985e+00]
 [ 1.4602143e-01]
 [ 2.4612784e-01]
 [-3.3297591e-04]
 [ 2.9815001e-02]
 [ 2.2517446e-01]]
--- 0.26619434356689453 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 19007.154296875, (11754.805, 0.76036257, 7154.867, 2.5317998)
   validation loss 8649.0234375, (7541.446, 0.350292, 1010.50555, 2.5317998)
decoder loss ratio: 292168.702848, decoder SINDy loss  ratio: 2.181318
--- 0.3290891647338867 seconds for one epoch ---
--- 0.36865854263305664 seconds for one epoch ---
--- 0.32811427116394043 seconds for one epoch ---
--- 0.36484456062316895 seconds for one epoch ---
--- 0.3272974491119385 seconds for one epoch ---
--- 0.3728370666503906 seconds for one epoch ---
--- 0.32219767570495605 seconds for one epoch ---
--- 0.36783576011657715 seconds for one epoch ---
--- 0.33115410804748535 seconds for one epoch ---
--- 0.3715336322784424 seconds for one epoch ---
--- 0.31810522079467773 seconds for one epoch ---
--- 0.3692505359649658 seconds for one epoch ---
--- 0.32452940940856934 seconds for one epoch ---
--- 0.3746786117553711 seconds for one epoch ---
--- 0.33004140853881836 seconds for one epoch ---
--- 0.37673091888427734 seconds for one epoch ---
--- 0.32083892822265625 seconds for one epoch ---
--- 0.37636637687683105 seconds for one epoch ---
--- 0.3248014450073242 seconds for one epoch ---
--- 0.3947446346282959 seconds for one epoch ---
--- 0.3262808322906494 seconds for one epoch ---
--- 0.3686516284942627 seconds for one epoch ---
--- 0.3254227638244629 seconds for one epoch ---
--- 0.37304019927978516 seconds for one epoch ---
=========================
[[0.25321507]
 [0.24688348]
 [0.8757488 ]
 [0.2396517 ]
 [0.2394225 ]
 [0.9873511 ]
 [0.23999897]
 [0.2421273 ]
 [0.23754941]
 [0.24160114]
 [0.24276529]]
[[ 5.0740832e-01]
 [-3.8512364e-01]
 [-2.1218376e+00]
 [-1.3745971e-01]
 [ 1.2517896e-01]
 [-2.8780422e+00]
 [ 1.5519753e-01]
 [ 2.4594904e-01]
 [-2.9124200e-04]
 [-2.2587477e-01]
 [ 2.6865923e-01]]
--- 0.31867456436157227 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11325.8134765625, (7075.3037, 36.12861, 4105.3657, 2.5318215)
   validation loss 5991.44287109375, (4922.511, 0.23961681, 959.6763, 2.5318215)
decoder loss ratio: 190706.630924, decoder SINDy loss  ratio: 2.071596
--- 0.2810368537902832 seconds for one epoch ---
--- 0.32699155807495117 seconds for one epoch ---
--- 0.37883806228637695 seconds for one epoch ---
--- 0.3206334114074707 seconds for one epoch ---
--- 0.3969759941101074 seconds for one epoch ---
--- 0.31972169876098633 seconds for one epoch ---
--- 0.38260459899902344 seconds for one epoch ---
--- 0.33194470405578613 seconds for one epoch ---
--- 0.3818936347961426 seconds for one epoch ---
--- 0.32586073875427246 seconds for one epoch ---
--- 0.39664220809936523 seconds for one epoch ---
--- 0.3275125026702881 seconds for one epoch ---
--- 0.390702486038208 seconds for one epoch ---
--- 0.3212110996246338 seconds for one epoch ---
--- 0.38811421394348145 seconds for one epoch ---
--- 0.32083582878112793 seconds for one epoch ---
--- 0.38165926933288574 seconds for one epoch ---
--- 0.3370225429534912 seconds for one epoch ---
--- 0.38391876220703125 seconds for one epoch ---
--- 0.32539868354797363 seconds for one epoch ---
--- 0.38881993293762207 seconds for one epoch ---
--- 0.3210256099700928 seconds for one epoch ---
--- 0.40007519721984863 seconds for one epoch ---
--- 0.33008456230163574 seconds for one epoch ---
=========================
[[0.19087413]
 [0.20023705]
 [0.9234247 ]
 [0.19120823]
 [0.18918222]
 [0.99317557]
 [0.18961582]
 [0.19289058]
 [0.1877786 ]
 [0.20779409]
 [0.19382465]]
[[ 0.17964247]
 [-0.43753007]
 [-2.3147056 ]
 [-0.19367768]
 [ 0.09658772]
 [-3.0922847 ]
 [ 0.12011192]
 [ 0.25602725]
 [-0.00492072]
 [-0.5546807 ]
 [ 0.2858775 ]]
--- 0.2806570529937744 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11985.095703125, (6663.439, 3.5493963, 5198.7363, 2.5318463)
   validation loss 4803.86474609375, (3884.509, 0.18955053, 799.79584, 2.5318463)
decoder loss ratio: 150492.623751, decoder SINDy loss  ratio: 1.726472
--- 0.3262484073638916 seconds for one epoch ---
--- 0.38763904571533203 seconds for one epoch ---
--- 0.3198719024658203 seconds for one epoch ---
--- 0.3908257484436035 seconds for one epoch ---
--- 0.324862003326416 seconds for one epoch ---
--- 0.41311144828796387 seconds for one epoch ---
--- 0.32680177688598633 seconds for one epoch ---
--- 0.38518786430358887 seconds for one epoch ---
--- 0.3250739574432373 seconds for one epoch ---
--- 0.39006996154785156 seconds for one epoch ---
--- 0.32251501083374023 seconds for one epoch ---
--- 0.40281057357788086 seconds for one epoch ---
--- 0.32378625869750977 seconds for one epoch ---
--- 0.39687108993530273 seconds for one epoch ---
--- 0.32378578186035156 seconds for one epoch ---
--- 0.40951013565063477 seconds for one epoch ---
--- 0.3266408443450928 seconds for one epoch ---
--- 0.4127371311187744 seconds for one epoch ---
--- 0.3360111713409424 seconds for one epoch ---
--- 0.41332387924194336 seconds for one epoch ---
--- 0.32816267013549805 seconds for one epoch ---
--- 0.39258551597595215 seconds for one epoch ---
--- 0.33150768280029297 seconds for one epoch ---
--- 0.40021634101867676 seconds for one epoch ---
=========================
[[0.15389618]
 [0.16714454]
 [0.94496655]
 [0.15547684]
 [0.15309814]
 [0.99607545]
 [0.15387174]
 [0.15784721]
 [0.151652  ]
 [0.2196551 ]
 [0.15841353]]
[[-1.3302620e-01]
 [-4.7822803e-01]
 [-2.4399457e+00]
 [-2.0073469e-01]
 [ 9.2171282e-02]
 [-3.2795973e+00]
 [ 1.3185360e-01]
 [ 2.8055599e-01]
 [ 4.2367933e-04]
 [-8.9237356e-01]
 [ 2.9692999e-01]]
--- 0.3062465190887451 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9124.4443359375, (4683.5117, 0.53624, 4309.5664, 2.5318735)
   validation loss 3761.67626953125, (2921.416, 0.119901136, 709.31067, 2.5318735)
decoder loss ratio: 113180.728247, decoder SINDy loss  ratio: 1.531147
--- 0.2758519649505615 seconds for one epoch ---
--- 0.3343489170074463 seconds for one epoch ---
--- 0.40294885635375977 seconds for one epoch ---
--- 0.3358778953552246 seconds for one epoch ---
--- 0.394329309463501 seconds for one epoch ---
--- 0.33089494705200195 seconds for one epoch ---
--- 0.3932476043701172 seconds for one epoch ---
--- 0.3243110179901123 seconds for one epoch ---
--- 0.4001200199127197 seconds for one epoch ---
--- 0.32892584800720215 seconds for one epoch ---
--- 0.40318942070007324 seconds for one epoch ---
--- 0.32835936546325684 seconds for one epoch ---
--- 0.4243464469909668 seconds for one epoch ---
--- 0.3325381278991699 seconds for one epoch ---
--- 0.3982694149017334 seconds for one epoch ---
--- 0.42862749099731445 seconds for one epoch ---
--- 0.4027531147003174 seconds for one epoch ---
--- 0.33426642417907715 seconds for one epoch ---
--- 0.40712571144104004 seconds for one epoch ---
--- 0.3240833282470703 seconds for one epoch ---
--- 0.39969968795776367 seconds for one epoch ---
--- 0.32515573501586914 seconds for one epoch ---
--- 0.407473087310791 seconds for one epoch ---
--- 0.3373069763183594 seconds for one epoch ---
=========================
[[0.13081017]
 [0.14284141]
 [0.96687776]
 [0.12509762]
 [0.12180334]
 [0.9968478 ]
 [0.12340025]
 [0.12680152]
 [0.12094701]
 [0.2869824 ]
 [0.1275933 ]]
[[-0.3672001 ]
 [-0.5572466 ]
 [-2.6168718 ]
 [-0.20925881]
 [ 0.05889688]
 [-3.3595085 ]
 [ 0.14095731]
 [ 0.26532263]
 [-0.00368938]
 [-1.1809925 ]
 [ 0.2882728 ]]
--- 0.26761674880981445 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6511.3466796875, (3371.768, 20.486025, 2979.2673, 2.5319011)
   validation loss 2436.662841796875, (1711.7034, 0.096173726, 585.0378, 2.5319011)
decoder loss ratio: 66314.360168, decoder SINDy loss  ratio: 1.262886
--- 0.32439494132995605 seconds for one epoch ---
--- 0.39522314071655273 seconds for one epoch ---
--- 0.3227419853210449 seconds for one epoch ---
--- 0.4146082401275635 seconds for one epoch ---
--- 0.32337212562561035 seconds for one epoch ---
--- 0.40768957138061523 seconds for one epoch ---
--- 0.3335545063018799 seconds for one epoch ---
--- 0.4065690040588379 seconds for one epoch ---
--- 0.32422852516174316 seconds for one epoch ---
--- 0.4088761806488037 seconds for one epoch ---
--- 0.3312249183654785 seconds for one epoch ---
--- 0.4063878059387207 seconds for one epoch ---
--- 0.3272440433502197 seconds for one epoch ---
--- 0.41649389266967773 seconds for one epoch ---
--- 0.32649827003479004 seconds for one epoch ---
--- 0.4138305187225342 seconds for one epoch ---
--- 0.3267941474914551 seconds for one epoch ---
--- 0.40665292739868164 seconds for one epoch ---
--- 0.3170437812805176 seconds for one epoch ---
--- 0.41352295875549316 seconds for one epoch ---
--- 0.3230419158935547 seconds for one epoch ---
--- 0.41522812843322754 seconds for one epoch ---
--- 0.3275740146636963 seconds for one epoch ---
--- 0.40570664405822754 seconds for one epoch ---
=========================
[[0.11987668]
 [0.12406222]
 [0.978871  ]
 [0.10242786]
 [0.09933838]
 [0.9968428 ]
 [0.1008471 ]
 [0.10462449]
 [0.09860861]
 [0.4077437 ]
 [0.10623895]]
[[-0.5437615 ]
 [-0.5907993 ]
 [-2.768566  ]
 [-0.19518554]
 [ 0.05293898]
 [-3.3668644 ]
 [ 0.13061762]
 [ 0.26702285]
 [-0.00682208]
 [-1.4235758 ]
 [ 0.31086683]]
--- 0.3058352470397949 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7876.947265625, (4146.5684, 1.782508, 3581.2822, 2.5319216)
   validation loss 2187.963134765625, (1497.1372, 0.07690212, 543.43475, 2.5319216)
decoder loss ratio: 58001.694545, decoder SINDy loss  ratio: 1.173080
--- 0.2722749710083008 seconds for one epoch ---
--- 0.3222064971923828 seconds for one epoch ---
--- 0.40696096420288086 seconds for one epoch ---
--- 0.3222498893737793 seconds for one epoch ---
--- 0.40746378898620605 seconds for one epoch ---
--- 0.32390689849853516 seconds for one epoch ---
--- 0.40979862213134766 seconds for one epoch ---
--- 0.32298874855041504 seconds for one epoch ---
--- 0.4122481346130371 seconds for one epoch ---
--- 0.3172891139984131 seconds for one epoch ---
--- 0.4156811237335205 seconds for one epoch ---
--- 0.3242197036743164 seconds for one epoch ---
--- 0.42441654205322266 seconds for one epoch ---
--- 0.32483839988708496 seconds for one epoch ---
--- 0.4338560104370117 seconds for one epoch ---
--- 0.333052396774292 seconds for one epoch ---
--- 0.42141175270080566 seconds for one epoch ---
--- 0.3259849548339844 seconds for one epoch ---
--- 0.4150698184967041 seconds for one epoch ---
--- 0.3264012336730957 seconds for one epoch ---
--- 0.43445658683776855 seconds for one epoch ---
--- 0.3283267021179199 seconds for one epoch ---
--- 0.4287688732147217 seconds for one epoch ---
--- 0.3254544734954834 seconds for one epoch ---
=========================
[[0.11406504]
 [0.10553893]
 [0.9857605 ]
 [0.08420916]
 [0.08042809]
 [0.99638677]
 [0.08309501]
 [0.08515668]
 [0.07934534]
 [0.53662807]
 [0.08802544]]
[[-6.6920567e-01]
 [-5.9208649e-01]
 [-2.9001837e+00]
 [-2.2574890e-01]
 [ 6.7808308e-02]
 [-3.3312035e+00]
 [ 1.8703012e-01]
 [ 2.5523618e-01]
 [-1.9788817e-03]
 [-1.6168224e+00]
 [ 3.3045447e-01]]
--- 0.26355957984924316 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6856.11376953125, (3457.5254, 1.8582177, 3243.8533, 2.531938)
   validation loss 2059.185791015625, (1365.5679, 0.086150184, 540.65485, 2.531938)
decoder loss ratio: 52904.470056, decoder SINDy loss  ratio: 1.167080
--- 0.33377528190612793 seconds for one epoch ---
--- 0.4140627384185791 seconds for one epoch ---
--- 0.32631468772888184 seconds for one epoch ---
--- 0.42203474044799805 seconds for one epoch ---
--- 0.3324882984161377 seconds for one epoch ---
--- 0.437854528427124 seconds for one epoch ---
--- 0.3259406089782715 seconds for one epoch ---
--- 0.4460594654083252 seconds for one epoch ---
--- 0.31694841384887695 seconds for one epoch ---
--- 0.435044527053833 seconds for one epoch ---
--- 0.3232896327972412 seconds for one epoch ---
--- 0.424910306930542 seconds for one epoch ---
--- 0.3350405693054199 seconds for one epoch ---
--- 0.43058109283447266 seconds for one epoch ---
--- 0.3238260746002197 seconds for one epoch ---
--- 0.43904614448547363 seconds for one epoch ---
--- 0.3245270252227783 seconds for one epoch ---
--- 0.43047547340393066 seconds for one epoch ---
--- 0.3268284797668457 seconds for one epoch ---
--- 0.43334221839904785 seconds for one epoch ---
--- 0.3266282081604004 seconds for one epoch ---
--- 0.4322056770324707 seconds for one epoch ---
--- 0.3293008804321289 seconds for one epoch ---
--- 0.4280252456665039 seconds for one epoch ---
=========================
[[0.1175053 ]
 [0.09681345]
 [0.9897319 ]
 [0.06999502]
 [0.06641809]
 [0.9956221 ]
 [0.06885254]
 [0.07092357]
 [0.06544028]
 [0.6692999 ]
 [0.07694566]]
[[-0.7824868 ]
 [-0.6381516 ]
 [-3.007987  ]
 [-0.21797533]
 [ 0.0690548 ]
 [-3.2757134 ]
 [ 0.17776886]
 [ 0.24717712]
 [-0.01149352]
 [-1.8046896 ]
 [ 0.3895569 ]]
--- 0.297884464263916 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4821.8427734375, (2805.0686, 15.559048, 1843.6526, 2.5319526)
   validation loss 1783.284423828125, (1144.8473, 0.10321145, 480.7709, 2.5319526)
decoder loss ratio: 44353.371558, decoder SINDy loss  ratio: 1.037812
--- 0.27676987648010254 seconds for one epoch ---
--- 0.3302145004272461 seconds for one epoch ---
--- 0.4351634979248047 seconds for one epoch ---
--- 0.333357572555542 seconds for one epoch ---
--- 0.4409503936767578 seconds for one epoch ---
--- 0.32760047912597656 seconds for one epoch ---
--- 0.4333457946777344 seconds for one epoch ---
--- 0.3289322853088379 seconds for one epoch ---
--- 0.4333958625793457 seconds for one epoch ---
--- 0.3392925262451172 seconds for one epoch ---
--- 0.43898916244506836 seconds for one epoch ---
--- 0.32393574714660645 seconds for one epoch ---
--- 0.4609677791595459 seconds for one epoch ---
--- 0.32141995429992676 seconds for one epoch ---
--- 0.42973828315734863 seconds for one epoch ---
--- 0.32831883430480957 seconds for one epoch ---
--- 0.42579221725463867 seconds for one epoch ---
--- 0.3265395164489746 seconds for one epoch ---
--- 0.44014859199523926 seconds for one epoch ---
--- 0.32839131355285645 seconds for one epoch ---
--- 0.4629662036895752 seconds for one epoch ---
--- 0.33597278594970703 seconds for one epoch ---
--- 0.4429819583892822 seconds for one epoch ---
--- 0.33403611183166504 seconds for one epoch ---
=========================
[[0.12630986]
 [0.08597746]
 [0.9921146 ]
 [0.05771767]
 [0.05432951]
 [0.9943297 ]
 [0.05712849]
 [0.05932261]
 [0.05324116]
 [0.78223634]
 [0.06603288]]
[[-0.880879  ]
 [-0.645545  ]
 [-3.095041  ]
 [-0.21053283]
 [ 0.06953404]
 [-3.1986055 ]
 [ 0.19021691]
 [ 0.2599019 ]
 [-0.00577306]
 [-1.9903502 ]
 [ 0.40861166]]
--- 0.2640080451965332 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5534.8115234375, (2581.1323, 0.4181625, 2791.3193, 2.531964)
   validation loss 1612.92578125, (1025.6448, 0.08283396, 425.2567, 2.531964)
decoder loss ratio: 39735.259196, decoder SINDy loss  ratio: 0.917976
--- 0.3269944190979004 seconds for one epoch ---
--- 0.45950913429260254 seconds for one epoch ---
--- 0.33130526542663574 seconds for one epoch ---
--- 0.45282435417175293 seconds for one epoch ---
--- 0.3310670852661133 seconds for one epoch ---
--- 0.4425621032714844 seconds for one epoch ---
--- 0.32916808128356934 seconds for one epoch ---
--- 0.4457666873931885 seconds for one epoch ---
--- 0.3232288360595703 seconds for one epoch ---
--- 0.4568605422973633 seconds for one epoch ---
--- 0.3237912654876709 seconds for one epoch ---
--- 0.4674561023712158 seconds for one epoch ---
--- 0.32498788833618164 seconds for one epoch ---
--- 0.44325733184814453 seconds for one epoch ---
--- 0.3302276134490967 seconds for one epoch ---
--- 0.4633359909057617 seconds for one epoch ---
--- 0.32813072204589844 seconds for one epoch ---
--- 0.46191883087158203 seconds for one epoch ---
--- 0.3254587650299072 seconds for one epoch ---
--- 0.46789026260375977 seconds for one epoch ---
--- 0.33193540573120117 seconds for one epoch ---
--- 0.44263458251953125 seconds for one epoch ---
--- 0.3233335018157959 seconds for one epoch ---
--- 0.4493222236633301 seconds for one epoch ---
=========================
[[0.15620837]
 [0.08299573]
 [0.99304837]
 [0.04887101]
 [0.04523315]
 [0.9939261 ]
 [0.04822104]
 [0.05067017]
 [0.04424926]
 [0.8705805 ]
 [0.06106771]]
[[-1.0145084e+00]
 [-6.8943447e-01]
 [-3.1375961e+00]
 [-2.1137749e-01]
 [ 5.9308693e-02]
 [-3.1799693e+00]
 [ 1.8917270e-01]
 [ 2.6561376e-01]
 [ 7.3404954e-04]
 [-2.1887941e+00]
 [ 4.6926573e-01]]
--- 0.3027207851409912 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5096.6181640625, (2089.2524, 1.7913321, 2839.3708, 2.5319803)
   validation loss 1805.9759521484375, (1202.5215, 0.0815213, 437.16913, 2.5319803)
decoder loss ratio: 46587.769974, decoder SINDy loss  ratio: 0.943691
--- 0.27280330657958984 seconds for one epoch ---
--- 0.3214569091796875 seconds for one epoch ---
--- 0.4467136859893799 seconds for one epoch ---
--- 0.3203577995300293 seconds for one epoch ---
--- 0.44661927223205566 seconds for one epoch ---
--- 0.32759928703308105 seconds for one epoch ---
--- 0.4557344913482666 seconds for one epoch ---
--- 0.3283848762512207 seconds for one epoch ---
--- 0.45581769943237305 seconds for one epoch ---
--- 0.32295775413513184 seconds for one epoch ---
--- 0.46350526809692383 seconds for one epoch ---
--- 0.33885669708251953 seconds for one epoch ---
--- 0.47090649604797363 seconds for one epoch ---
--- 0.3361523151397705 seconds for one epoch ---
--- 0.46466732025146484 seconds for one epoch ---
--- 0.3359105587005615 seconds for one epoch ---
--- 0.46514129638671875 seconds for one epoch ---
--- 0.3368494510650635 seconds for one epoch ---
--- 0.4781644344329834 seconds for one epoch ---
--- 0.3367183208465576 seconds for one epoch ---
--- 0.4785118103027344 seconds for one epoch ---
--- 0.3299069404602051 seconds for one epoch ---
--- 0.4648926258087158 seconds for one epoch ---
--- 0.3351914882659912 seconds for one epoch ---
=========================
[[0.1923606 ]
 [0.08105014]
 [0.994252  ]
 [0.04058541]
 [0.037586  ]
 [0.9929711 ]
 [0.04005919]
 [0.04283446]
 [0.03653221]
 [0.9232717 ]
 [0.05621374]]
[[-1.1249924e+00]
 [-7.2691226e-01]
 [-3.1997895e+00]
 [-1.9125284e-01]
 [ 6.3152790e-02]
 [-3.1366553e+00]
 [ 1.7231146e-01]
 [ 2.6118022e-01]
 [ 1.3857491e-03]
 [-2.3717062e+00]
 [ 5.0616843e-01]]
--- 0.2800884246826172 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5396.40478515625, (2510.219, 0.4687826, 2715.376, 2.5319955)
   validation loss 1476.125, (901.2404, 0.07073441, 404.47293, 2.5319955)
decoder loss ratio: 34915.618395, decoder SINDy loss  ratio: 0.873112
--- 0.3321402072906494 seconds for one epoch ---
--- 0.47609543800354004 seconds for one epoch ---
--- 0.3153953552246094 seconds for one epoch ---
--- 0.4606742858886719 seconds for one epoch ---
--- 0.3321988582611084 seconds for one epoch ---
--- 0.46071290969848633 seconds for one epoch ---
--- 0.3281996250152588 seconds for one epoch ---
--- 0.4709153175354004 seconds for one epoch ---
--- 0.3228909969329834 seconds for one epoch ---
--- 0.46731042861938477 seconds for one epoch ---
--- 0.31940364837646484 seconds for one epoch ---
--- 0.48094797134399414 seconds for one epoch ---
--- 0.32977938652038574 seconds for one epoch ---
--- 0.47005534172058105 seconds for one epoch ---
--- 0.32323670387268066 seconds for one epoch ---
--- 0.48191046714782715 seconds for one epoch ---
--- 0.32550764083862305 seconds for one epoch ---
--- 0.48569679260253906 seconds for one epoch ---
--- 0.3247559070587158 seconds for one epoch ---
--- 0.48462557792663574 seconds for one epoch ---
--- 0.3238651752471924 seconds for one epoch ---
--- 0.47589802742004395 seconds for one epoch ---
--- 0.32527995109558105 seconds for one epoch ---
--- 0.47655510902404785 seconds for one epoch ---
=========================
[[0.24308655]
 [0.08196591]
 [0.995148  ]
 [0.03512038]
 [0.03141155]
 [0.9920387 ]
 [0.03428008]
 [0.0368723 ]
 [0.03087378]
 [0.955338  ]
 [0.05692833]]
[[-1.236489  ]
 [-0.76568085]
 [-3.254819  ]
 [-0.19908038]
 [ 0.03769547]
 [-3.099373  ]
 [ 0.16925392]
 [ 0.25328407]
 [-0.00518786]
 [-2.5518346 ]
 [ 0.57752573]]
--- 0.4314723014831543 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4842.85693359375, (2297.593, 0.8452124, 2369.9785, 2.5320115)
   validation loss 1329.106689453125, (769.80536, 0.09152005, 384.77002, 2.5320115)
decoder loss ratio: 29823.596044, decoder SINDy loss  ratio: 0.830580
--- 0.27124595642089844 seconds for one epoch ---
--- 0.3315150737762451 seconds for one epoch ---
--- 0.48477697372436523 seconds for one epoch ---
--- 0.3209853172302246 seconds for one epoch ---
--- 0.45948362350463867 seconds for one epoch ---
--- 0.31662631034851074 seconds for one epoch ---
--- 0.47034549713134766 seconds for one epoch ---
--- 0.3190610408782959 seconds for one epoch ---
--- 0.4754476547241211 seconds for one epoch ---
--- 0.3327445983886719 seconds for one epoch ---
--- 0.46910762786865234 seconds for one epoch ---
--- 0.3273317813873291 seconds for one epoch ---
--- 0.4802894592285156 seconds for one epoch ---
--- 0.32940149307250977 seconds for one epoch ---
--- 0.4906184673309326 seconds for one epoch ---
--- 0.3278183937072754 seconds for one epoch ---
--- 0.48137474060058594 seconds for one epoch ---
--- 0.3248000144958496 seconds for one epoch ---
--- 0.4734058380126953 seconds for one epoch ---
--- 0.32274961471557617 seconds for one epoch ---
--- 0.4927864074707031 seconds for one epoch ---
--- 0.31895017623901367 seconds for one epoch ---
--- 0.47563886642456055 seconds for one epoch ---
--- 0.31865596771240234 seconds for one epoch ---
=========================
[[0.3052815 ]
 [0.07916135]
 [0.9951044 ]
 [0.03072082]
 [0.02672246]
 [0.99147904]
 [0.0298754 ]
 [0.03188564]
 [0.02590051]
 [0.97342855]
 [0.05817809]]
[[-1.3448449 ]
 [-0.77646786]
 [-3.2536457 ]
 [-0.21736822]
 [ 0.05376841]
 [-3.079653  ]
 [ 0.18931651]
 [ 0.25225794]
 [-0.00569104]
 [-2.7203174 ]
 [ 0.6338341 ]]
--- 0.2704284191131592 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6145.36181640625, (3341.0925, 0.5226919, 2625.445, 2.532025)
   validation loss 2980.37744140625, (2436.6055, 0.089225605, 365.38177, 2.532025)
decoder loss ratio: 94398.325992, decoder SINDy loss  ratio: 0.788728
--- 0.32285094261169434 seconds for one epoch ---
--- 0.4975614547729492 seconds for one epoch ---
--- 0.3417930603027344 seconds for one epoch ---
--- 0.4811670780181885 seconds for one epoch ---
--- 0.336794376373291 seconds for one epoch ---
--- 0.5016636848449707 seconds for one epoch ---
--- 0.32283449172973633 seconds for one epoch ---
--- 0.4723033905029297 seconds for one epoch ---
--- 0.3242645263671875 seconds for one epoch ---
--- 0.4968242645263672 seconds for one epoch ---
--- 0.32150983810424805 seconds for one epoch ---
--- 0.48755836486816406 seconds for one epoch ---
--- 0.33124780654907227 seconds for one epoch ---
--- 0.4932727813720703 seconds for one epoch ---
--- 0.32776379585266113 seconds for one epoch ---
--- 0.48964571952819824 seconds for one epoch ---
--- 0.31994128227233887 seconds for one epoch ---
--- 0.47836899757385254 seconds for one epoch ---
--- 0.32451844215393066 seconds for one epoch ---
--- 0.511561393737793 seconds for one epoch ---
--- 0.3238821029663086 seconds for one epoch ---
--- 0.5006189346313477 seconds for one epoch ---
--- 0.3254828453063965 seconds for one epoch ---
--- 0.4831564426422119 seconds for one epoch ---
=========================
[[0.36214137]
 [0.07958641]
 [0.9954457 ]
 [0.02650722]
 [0.02316047]
 [0.99017704]
 [0.02613975]
 [0.02839098]
 [0.02215224]
 [0.9833512 ]
 [0.06010446]]
[[-1.4298598e+00]
 [-7.9752201e-01]
 [-3.2774985e+00]
 [-2.0025283e-01]
 [ 6.1213713e-02]
 [-3.0361474e+00]
 [ 1.8772627e-01]
 [ 2.5750434e-01]
 [-2.9425221e-03]
 [-2.8698564e+00]
 [ 6.7738193e-01]]
--- 0.30460572242736816 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3605.75048828125, (2016.5632, 3.1908324, 1404.2468, 2.5320375)
   validation loss 1922.4228515625, (1351.1333, 0.06813715, 389.47195, 2.5320375)
decoder loss ratio: 52345.249743, decoder SINDy loss  ratio: 0.840730
--- 0.27076005935668945 seconds for one epoch ---
--- 0.3269045352935791 seconds for one epoch ---
--- 0.4804520606994629 seconds for one epoch ---
--- 0.3209223747253418 seconds for one epoch ---
--- 0.49458742141723633 seconds for one epoch ---
--- 0.32442641258239746 seconds for one epoch ---
--- 0.5123438835144043 seconds for one epoch ---
--- 0.3222832679748535 seconds for one epoch ---
--- 0.49957704544067383 seconds for one epoch ---
--- 0.3277573585510254 seconds for one epoch ---
--- 0.5044846534729004 seconds for one epoch ---
--- 0.3262217044830322 seconds for one epoch ---
--- 0.5005147457122803 seconds for one epoch ---
--- 0.3311767578125 seconds for one epoch ---
--- 0.5153946876525879 seconds for one epoch ---
--- 0.3255801200866699 seconds for one epoch ---
--- 0.49450206756591797 seconds for one epoch ---
--- 0.3240954875946045 seconds for one epoch ---
--- 0.5092453956604004 seconds for one epoch ---
--- 0.3349933624267578 seconds for one epoch ---
--- 0.49974846839904785 seconds for one epoch ---
--- 0.32820677757263184 seconds for one epoch ---
--- 0.502047061920166 seconds for one epoch ---
--- 0.3248169422149658 seconds for one epoch ---
=========================
[[0.43731996]
 [0.07394104]
 [0.9956814 ]
 [0.02289299]
 [0.01985433]
 [0.9893591 ]
 [0.02281761]
 [0.02525411]
 [0.01887105]
 [0.98997074]
 [0.06290294]]
[[-1.5307786e+00]
 [-7.8382087e-01]
 [-3.2952251e+00]
 [-1.8719098e-01]
 [ 5.7789564e-02]
 [-3.0120230e+00]
 [ 1.8456219e-01]
 [ 2.5989997e-01]
 [-6.0933724e-04]
 [-3.0306492e+00]
 [ 7.1843952e-01]]
--- 0.27809619903564453 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4698.7734375, (2890.787, 6.00797, 1616.8984, 2.5320508)
   validation loss 2415.7392578125, (1863.4674, 0.100050636, 367.09174, 2.5320508)
decoder loss ratio: 72193.962478, decoder SINDy loss  ratio: 0.792419
--- 0.33213186264038086 seconds for one epoch ---
--- 0.4924643039703369 seconds for one epoch ---
--- 0.32977771759033203 seconds for one epoch ---
--- 0.49381399154663086 seconds for one epoch ---
--- 0.33280301094055176 seconds for one epoch ---
--- 0.49160337448120117 seconds for one epoch ---
--- 0.3378758430480957 seconds for one epoch ---
--- 0.5053870677947998 seconds for one epoch ---
--- 0.32862377166748047 seconds for one epoch ---
--- 0.5061979293823242 seconds for one epoch ---
--- 0.3261423110961914 seconds for one epoch ---
--- 0.5046699047088623 seconds for one epoch ---
--- 0.31817030906677246 seconds for one epoch ---
--- 0.5032341480255127 seconds for one epoch ---
--- 0.33098888397216797 seconds for one epoch ---
--- 0.5089304447174072 seconds for one epoch ---
--- 0.31677961349487305 seconds for one epoch ---
--- 0.5003507137298584 seconds for one epoch ---
--- 0.31577038764953613 seconds for one epoch ---
--- 0.5236203670501709 seconds for one epoch ---
--- 0.33574962615966797 seconds for one epoch ---
--- 0.5003008842468262 seconds for one epoch ---
--- 0.3313865661621094 seconds for one epoch ---
--- 0.520211935043335 seconds for one epoch ---
=========================
[[0.50529695]
 [0.07458602]
 [0.995705  ]
 [0.02108341]
 [0.0177924 ]
 [0.9883568 ]
 [0.0201853 ]
 [0.0224022 ]
 [0.01650352]
 [0.9936936 ]
 [0.06745923]]
[[-1.6172136 ]
 [-0.7992586 ]
 [-3.2977118 ]
 [-0.20750518]
 [ 0.07632068]
 [-2.9844604 ]
 [ 0.17690144]
 [ 0.247557  ]
 [-0.00429005]
 [-3.177161  ]
 [ 0.760496  ]]
--- 0.3048577308654785 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4815.65576171875, (1819.7606, 0.56097776, 2807.1392, 2.5320635)
   validation loss 1691.427001953125, (1166.4354, 0.12433342, 336.67252, 2.5320635)
decoder loss ratio: 45189.733378, decoder SINDy loss  ratio: 0.726755
THRESHOLDING: 4 active coefficients
--- 0.49239063262939453 seconds for one epoch ---
--- 0.33458614349365234 seconds for one epoch ---
--- 0.5066874027252197 seconds for one epoch ---
--- 0.3301389217376709 seconds for one epoch ---
--- 0.5099673271179199 seconds for one epoch ---
--- 0.329470157623291 seconds for one epoch ---
--- 0.5077202320098877 seconds for one epoch ---
--- 0.3133070468902588 seconds for one epoch ---
--- 0.5349693298339844 seconds for one epoch ---
--- 0.3198425769805908 seconds for one epoch ---
--- 0.5180597305297852 seconds for one epoch ---
--- 0.3218417167663574 seconds for one epoch ---
--- 0.5376524925231934 seconds for one epoch ---
--- 0.3245532512664795 seconds for one epoch ---
--- 0.5302801132202148 seconds for one epoch ---
--- 0.32889819145202637 seconds for one epoch ---
--- 0.5316236019134521 seconds for one epoch ---
--- 0.32862091064453125 seconds for one epoch ---
--- 0.536801815032959 seconds for one epoch ---
--- 0.32205915451049805 seconds for one epoch ---
--- 0.5291798114776611 seconds for one epoch ---
--- 0.32116031646728516 seconds for one epoch ---
--- 0.5307295322418213 seconds for one epoch ---
--- 0.33530712127685547 seconds for one epoch ---
=========================
[[0.11521301]
 [0.        ]
 [0.99693143]
 [0.        ]
 [0.        ]
 [0.84221816]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9791037 ]
 [0.        ]]
[[-0.9702494]
 [-0.       ]
 [-3.403898 ]
 [-0.       ]
 [ 0.       ]
 [-2.1284034]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8004348]
 [ 0.       ]]
--- 0.26906371116638184 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2859.36376953125, (1494.5471, 1.1670262, 1362.8428, 0.8070043)
   validation loss 1588.4334716796875, (1240.7372, 0.10791054, 346.78134, 0.8070043)
decoder loss ratio: 48068.312469, decoder SINDy loss  ratio: 0.748576
--- 0.3109755516052246 seconds for one epoch ---
--- 0.5227766036987305 seconds for one epoch ---
--- 0.3239786624908447 seconds for one epoch ---
--- 0.5243730545043945 seconds for one epoch ---
--- 0.3191390037536621 seconds for one epoch ---
--- 0.520775556564331 seconds for one epoch ---
--- 0.33198118209838867 seconds for one epoch ---
--- 0.5237264633178711 seconds for one epoch ---
--- 0.32401490211486816 seconds for one epoch ---
--- 0.514279842376709 seconds for one epoch ---
--- 0.3243398666381836 seconds for one epoch ---
--- 0.5520250797271729 seconds for one epoch ---
--- 0.3268570899963379 seconds for one epoch ---
--- 0.5422875881195068 seconds for one epoch ---
--- 0.3262200355529785 seconds for one epoch ---
--- 0.5427463054656982 seconds for one epoch ---
--- 0.32320547103881836 seconds for one epoch ---
--- 0.5399172306060791 seconds for one epoch ---
--- 0.33077049255371094 seconds for one epoch ---
--- 0.5378322601318359 seconds for one epoch ---
--- 0.3287384510040283 seconds for one epoch ---
--- 0.5222029685974121 seconds for one epoch ---
--- 0.3190288543701172 seconds for one epoch ---
--- 0.5278322696685791 seconds for one epoch ---
=========================
[[0.05630295]
 [0.        ]
 [0.99469316]
 [0.        ]
 [0.        ]
 [0.64502996]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.964769  ]
 [0.        ]]
[[-0.7137809]
 [-0.       ]
 [-3.2325208]
 [-0.       ]
 [ 0.       ]
 [-1.7970337]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.6343462]
 [ 0.       ]]
--- 0.3002281188964844 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4102.24462890625, (1580.7081, 0.6007302, 2520.1821, 0.75328153)
   validation loss 1077.3245849609375, (753.7278, 0.15808205, 322.6855, 0.75328153)
decoder loss ratio: 29200.722850, decoder SINDy loss  ratio: 0.696562
--- 0.28078627586364746 seconds for one epoch ---
--- 0.33254456520080566 seconds for one epoch ---
--- 0.536501407623291 seconds for one epoch ---
--- 0.3248147964477539 seconds for one epoch ---
--- 0.5464906692504883 seconds for one epoch ---
--- 0.32973694801330566 seconds for one epoch ---
--- 0.5289785861968994 seconds for one epoch ---
--- 0.3279609680175781 seconds for one epoch ---
--- 0.5334336757659912 seconds for one epoch ---
--- 0.33931589126586914 seconds for one epoch ---
--- 0.5479505062103271 seconds for one epoch ---
--- 0.32303738594055176 seconds for one epoch ---
--- 0.5469036102294922 seconds for one epoch ---
--- 0.33812928199768066 seconds for one epoch ---
--- 0.526892900466919 seconds for one epoch ---
--- 0.3236575126647949 seconds for one epoch ---
--- 0.5329277515411377 seconds for one epoch ---
--- 0.32116055488586426 seconds for one epoch ---
--- 0.5510079860687256 seconds for one epoch ---
--- 0.32943010330200195 seconds for one epoch ---
--- 0.5420119762420654 seconds for one epoch ---
--- 0.3280189037322998 seconds for one epoch ---
--- 0.5361301898956299 seconds for one epoch ---
--- 0.3310413360595703 seconds for one epoch ---
=========================
[[0.03651661]
 [0.        ]
 [0.98963517]
 [0.        ]
 [0.        ]
 [0.49824667]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9520232 ]
 [0.        ]]
[[-0.56305665]
 [-0.        ]
 [-3.0227163 ]
 [-0.        ]
 [ 0.        ]
 [-1.6117237 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5350611 ]
 [ 0.        ]]
--- 0.2556450366973877 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3263.77783203125, (1764.9688, 1.3671811, 1496.7268, 0.7151666)
   validation loss 1254.6715087890625, (922.07544, 0.10512809, 331.7758, 0.7151666)
decoder loss ratio: 35722.803318, decoder SINDy loss  ratio: 0.716185
--- 0.3281245231628418 seconds for one epoch ---
--- 0.55759596824646 seconds for one epoch ---
--- 0.32178187370300293 seconds for one epoch ---
--- 0.5410854816436768 seconds for one epoch ---
--- 0.32372331619262695 seconds for one epoch ---
--- 0.5361430644989014 seconds for one epoch ---
--- 0.3265421390533447 seconds for one epoch ---
--- 0.5462534427642822 seconds for one epoch ---
--- 0.3258247375488281 seconds for one epoch ---
--- 0.5631294250488281 seconds for one epoch ---
--- 0.327045202255249 seconds for one epoch ---
--- 0.562751293182373 seconds for one epoch ---
--- 0.31968021392822266 seconds for one epoch ---
--- 0.5400252342224121 seconds for one epoch ---
--- 0.33179426193237305 seconds for one epoch ---
--- 0.5534968376159668 seconds for one epoch ---
--- 0.32816052436828613 seconds for one epoch ---
--- 0.5523877143859863 seconds for one epoch ---
--- 0.3234221935272217 seconds for one epoch ---
--- 0.5472667217254639 seconds for one epoch ---
--- 0.33007240295410156 seconds for one epoch ---
--- 0.5601112842559814 seconds for one epoch ---
--- 0.32835888862609863 seconds for one epoch ---
--- 0.5777881145477295 seconds for one epoch ---
=========================
[[0.03112281]
 [0.        ]
 [0.9779333 ]
 [0.        ]
 [0.        ]
 [0.42420566]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9491777 ]
 [0.        ]]
[[-0.5144023]
 [-0.       ]
 [-2.7844558]
 [-0.       ]
 [ 0.       ]
 [-1.5205288]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.5166533]
 [ 0.       ]]
--- 0.30784106254577637 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4400.35693359375, (1851.7961, 1.2877991, 2546.5789, 0.69393754)
   validation loss 1349.1473388671875, (1029.7081, 0.16783108, 318.57742, 0.69393754)
decoder loss ratio: 39892.680604, decoder SINDy loss  ratio: 0.687694
--- 0.281080961227417 seconds for one epoch ---
--- 0.3292102813720703 seconds for one epoch ---
--- 0.5505099296569824 seconds for one epoch ---
--- 0.3315243721008301 seconds for one epoch ---
--- 0.5568630695343018 seconds for one epoch ---
--- 0.3227670192718506 seconds for one epoch ---
--- 0.5562343597412109 seconds for one epoch ---
--- 0.33217573165893555 seconds for one epoch ---
--- 0.5792114734649658 seconds for one epoch ---
--- 0.33374762535095215 seconds for one epoch ---
--- 0.5614244937896729 seconds for one epoch ---
--- 0.3217909336090088 seconds for one epoch ---
--- 0.5731580257415771 seconds for one epoch ---
--- 0.3281080722808838 seconds for one epoch ---
--- 0.5579984188079834 seconds for one epoch ---
--- 0.33152294158935547 seconds for one epoch ---
--- 0.5542798042297363 seconds for one epoch ---
--- 0.3268301486968994 seconds for one epoch ---
--- 0.5682179927825928 seconds for one epoch ---
--- 0.31659460067749023 seconds for one epoch ---
--- 0.5711855888366699 seconds for one epoch ---
--- 0.3244349956512451 seconds for one epoch ---
--- 0.5622251033782959 seconds for one epoch ---
--- 0.3286440372467041 seconds for one epoch ---
=========================
[[0.02891877]
 [0.        ]
 [0.9571831 ]
 [0.        ]
 [0.        ]
 [0.38040242]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95026195]
 [0.        ]]
[[-0.49866113]
 [-0.        ]
 [-2.57262   ]
 [-0.        ]
 [ 0.        ]
 [-1.4651567 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5239918 ]
 [ 0.        ]]
--- 0.26888322830200195 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3819.340576171875, (1888.6632, 1.6584902, 1928.3364, 0.6824226)
   validation loss 1120.402587890625, (791.1256, 0.16706257, 328.42758, 0.6824226)
decoder loss ratio: 30649.579599, decoder SINDy loss  ratio: 0.708957
--- 0.32916760444641113 seconds for one epoch ---
--- 0.5602462291717529 seconds for one epoch ---
--- 0.45892834663391113 seconds for one epoch ---
--- 0.5508773326873779 seconds for one epoch ---
--- 0.3214292526245117 seconds for one epoch ---
--- 0.5786323547363281 seconds for one epoch ---
--- 0.3271169662475586 seconds for one epoch ---
--- 0.5748414993286133 seconds for one epoch ---
--- 0.32944679260253906 seconds for one epoch ---
--- 0.5919275283813477 seconds for one epoch ---
--- 0.3347022533416748 seconds for one epoch ---
--- 0.5694417953491211 seconds for one epoch ---
--- 0.3309898376464844 seconds for one epoch ---
--- 0.5733222961425781 seconds for one epoch ---
--- 0.3302571773529053 seconds for one epoch ---
--- 0.581371545791626 seconds for one epoch ---
--- 0.32393527030944824 seconds for one epoch ---
--- 0.5739519596099854 seconds for one epoch ---
--- 0.32793283462524414 seconds for one epoch ---
--- 0.5923528671264648 seconds for one epoch ---
--- 0.3265073299407959 seconds for one epoch ---
--- 0.5687627792358398 seconds for one epoch ---
--- 0.3322443962097168 seconds for one epoch ---
--- 0.5819213390350342 seconds for one epoch ---
=========================
[[0.02762505]
 [0.        ]
 [0.93301207]
 [0.        ]
 [0.        ]
 [0.33277607]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.955013  ]
 [0.        ]]
[[-0.49114177]
 [-0.        ]
 [-2.4264863 ]
 [-0.        ]
 [ 0.        ]
 [-1.4018692 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5568454 ]
 [ 0.        ]]
--- 0.31965065002441406 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4532.27978515625, (2048.1423, 0.87821054, 2482.5894, 0.66981494)
   validation loss 1449.3919677734375, (1125.5969, 0.19129556, 322.93393, 0.66981494)
decoder loss ratio: 43607.578951, decoder SINDy loss  ratio: 0.697098
--- 0.27304935455322266 seconds for one epoch ---
--- 0.3357045650482178 seconds for one epoch ---
--- 0.5851390361785889 seconds for one epoch ---
--- 0.31537795066833496 seconds for one epoch ---
--- 0.5825221538543701 seconds for one epoch ---
--- 0.3310086727142334 seconds for one epoch ---
--- 0.5893068313598633 seconds for one epoch ---
--- 0.3189430236816406 seconds for one epoch ---
--- 0.5659005641937256 seconds for one epoch ---
--- 0.3241579532623291 seconds for one epoch ---
--- 0.6056551933288574 seconds for one epoch ---
--- 0.3323214054107666 seconds for one epoch ---
--- 0.582404375076294 seconds for one epoch ---
--- 0.3211054801940918 seconds for one epoch ---
--- 0.6017627716064453 seconds for one epoch ---
--- 0.32116007804870605 seconds for one epoch ---
--- 0.5813493728637695 seconds for one epoch ---
--- 0.32637977600097656 seconds for one epoch ---
--- 0.5627446174621582 seconds for one epoch ---
--- 0.32643675804138184 seconds for one epoch ---
--- 0.6089498996734619 seconds for one epoch ---
--- 0.3303546905517578 seconds for one epoch ---
--- 0.5866127014160156 seconds for one epoch ---
--- 0.3290979862213135 seconds for one epoch ---
=========================
[[0.02588648]
 [0.        ]
 [0.88872653]
 [0.        ]
 [0.        ]
 [0.31465203]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95290506]
 [0.        ]]
[[-0.4764592]
 [-0.       ]
 [-2.2549963]
 [-0.       ]
 [ 0.       ]
 [-1.3770393]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.5421972]
 [ 0.       ]]
--- 0.2719712257385254 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4735.27197265625, (2251.9976, 2.321661, 2480.2942, 0.6585517)
   validation loss 1611.4044189453125, (1233.259, 0.14735235, 377.33954, 0.6585517)
decoder loss ratio: 47778.595978, decoder SINDy loss  ratio: 0.814540
--- 0.32641124725341797 seconds for one epoch ---
--- 0.5969250202178955 seconds for one epoch ---
--- 0.3240480422973633 seconds for one epoch ---
--- 0.5837037563323975 seconds for one epoch ---
--- 0.3223001956939697 seconds for one epoch ---
--- 0.6019132137298584 seconds for one epoch ---
--- 0.3277742862701416 seconds for one epoch ---
--- 0.5890510082244873 seconds for one epoch ---
--- 0.3336918354034424 seconds for one epoch ---
--- 0.5888669490814209 seconds for one epoch ---
--- 0.32787322998046875 seconds for one epoch ---
--- 0.6046149730682373 seconds for one epoch ---
--- 0.31955671310424805 seconds for one epoch ---
--- 0.5911617279052734 seconds for one epoch ---
--- 0.31896042823791504 seconds for one epoch ---
--- 0.5968847274780273 seconds for one epoch ---
--- 0.31594300270080566 seconds for one epoch ---
--- 0.5896100997924805 seconds for one epoch ---
--- 0.3279447555541992 seconds for one epoch ---
--- 0.6072990894317627 seconds for one epoch ---
--- 0.32461047172546387 seconds for one epoch ---
--- 0.601294994354248 seconds for one epoch ---
--- 0.3287177085876465 seconds for one epoch ---
--- 0.5992465019226074 seconds for one epoch ---
=========================
[[0.02496407]
 [0.        ]
 [0.83200854]
 [0.        ]
 [0.        ]
 [0.28403395]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95459056]
 [0.        ]]
[[-0.47042224]
 [-0.        ]
 [-2.1078892 ]
 [-0.        ]
 [ 0.        ]
 [-1.3326948 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.554186  ]
 [ 0.        ]]
--- 0.28763365745544434 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4608.146484375, (2117.623, 1.6733984, 2488.2056, 0.64452976)
   validation loss 1453.23974609375, (1113.8922, 0.14467746, 338.55838, 0.64452976)
decoder loss ratio: 43154.118091, decoder SINDy loss  ratio: 0.730826
--- 0.28354310989379883 seconds for one epoch ---
--- 0.3280222415924072 seconds for one epoch ---
--- 0.6108734607696533 seconds for one epoch ---
--- 0.32120680809020996 seconds for one epoch ---
--- 0.6069912910461426 seconds for one epoch ---
--- 0.32224369049072266 seconds for one epoch ---
--- 0.612748384475708 seconds for one epoch ---
--- 0.3295552730560303 seconds for one epoch ---
--- 0.606978178024292 seconds for one epoch ---
--- 0.3160572052001953 seconds for one epoch ---
--- 0.6214807033538818 seconds for one epoch ---
--- 0.327955961227417 seconds for one epoch ---
--- 0.6219437122344971 seconds for one epoch ---
--- 0.3213162422180176 seconds for one epoch ---
--- 0.6048462390899658 seconds for one epoch ---
--- 0.32388973236083984 seconds for one epoch ---
--- 0.6139113903045654 seconds for one epoch ---
--- 0.32611894607543945 seconds for one epoch ---
--- 0.6022875308990479 seconds for one epoch ---
--- 0.31684160232543945 seconds for one epoch ---
--- 0.6254653930664062 seconds for one epoch ---
--- 0.3273301124572754 seconds for one epoch ---
--- 0.6085758209228516 seconds for one epoch ---
--- 0.3380570411682129 seconds for one epoch ---
=========================
[[0.0265416 ]
 [0.        ]
 [0.76372445]
 [0.        ]
 [0.        ]
 [0.2670195 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9615946 ]
 [0.        ]]
[[-0.49704817]
 [-0.        ]
 [-1.9767474 ]
 [-0.        ]
 [ 0.        ]
 [-1.3070313 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6084619 ]
 [ 0.        ]]
--- 0.2685704231262207 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3304.706787109375, (1442.1354, 1.0901791, 1860.8494, 0.631782)
   validation loss 1711.595458984375, (1307.8785, 0.16407236, 402.92105, 0.631782)
decoder loss ratio: 50669.485218, decoder SINDy loss  ratio: 0.869762
--- 0.3257758617401123 seconds for one epoch ---
--- 0.5908291339874268 seconds for one epoch ---
--- 0.3237643241882324 seconds for one epoch ---
--- 0.607367753982544 seconds for one epoch ---
--- 0.322620153427124 seconds for one epoch ---
--- 0.5939986705780029 seconds for one epoch ---
--- 0.32567667961120605 seconds for one epoch ---
--- 0.6252684593200684 seconds for one epoch ---
--- 0.3260929584503174 seconds for one epoch ---
--- 0.6224076747894287 seconds for one epoch ---
--- 0.3249998092651367 seconds for one epoch ---
--- 0.6017704010009766 seconds for one epoch ---
--- 0.3268313407897949 seconds for one epoch ---
--- 0.6128597259521484 seconds for one epoch ---
--- 0.32598400115966797 seconds for one epoch ---
--- 0.6288464069366455 seconds for one epoch ---
--- 0.3419790267944336 seconds for one epoch ---
--- 0.6034111976623535 seconds for one epoch ---
--- 0.3301835060119629 seconds for one epoch ---
--- 0.6335048675537109 seconds for one epoch ---
--- 0.3267214298248291 seconds for one epoch ---
--- 0.6187000274658203 seconds for one epoch ---
--- 0.3323540687561035 seconds for one epoch ---
--- 0.6107866764068604 seconds for one epoch ---
=========================
[[0.02664843]
 [0.        ]
 [0.68321484]
 [0.        ]
 [0.        ]
 [0.24813542]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9645581 ]
 [0.        ]]
[[-0.50254995]
 [-0.        ]
 [-1.8525538 ]
 [-0.        ]
 [ 0.        ]
 [-1.2771552 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6344006 ]
 [ 0.        ]]
--- 0.30184054374694824 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4891.7646484375, (2298.4897, 0.3072764, 2592.351, 0.6160839)
   validation loss 1901.5216064453125, (1536.7286, 0.20602942, 363.97076, 0.6160839)
decoder loss ratio: 59535.535303, decoder SINDy loss  ratio: 0.785682
--- 0.28065061569213867 seconds for one epoch ---
--- 0.32897281646728516 seconds for one epoch ---
--- 0.6347959041595459 seconds for one epoch ---
--- 0.3307228088378906 seconds for one epoch ---
--- 0.6068315505981445 seconds for one epoch ---
--- 0.3245580196380615 seconds for one epoch ---
--- 0.6074910163879395 seconds for one epoch ---
--- 0.32727742195129395 seconds for one epoch ---
--- 0.6098618507385254 seconds for one epoch ---
--- 0.33518528938293457 seconds for one epoch ---
--- 0.6300346851348877 seconds for one epoch ---
--- 0.3312249183654785 seconds for one epoch ---
--- 0.6339726448059082 seconds for one epoch ---
--- 0.32945919036865234 seconds for one epoch ---
--- 0.6222898960113525 seconds for one epoch ---
--- 0.32889342308044434 seconds for one epoch ---
--- 0.6373052597045898 seconds for one epoch ---
--- 0.3294076919555664 seconds for one epoch ---
--- 0.6299655437469482 seconds for one epoch ---
--- 0.3310694694519043 seconds for one epoch ---
--- 0.6162548065185547 seconds for one epoch ---
--- 0.32575249671936035 seconds for one epoch ---
--- 0.6214795112609863 seconds for one epoch ---
--- 0.326627254486084 seconds for one epoch ---
=========================
[[0.02843465]
 [0.        ]
 [0.6364655 ]
 [0.        ]
 [0.        ]
 [0.23185019]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9694256 ]
 [0.        ]]
[[-0.5275528]
 [-0.       ]
 [-1.7886832]
 [-0.       ]
 [ 0.       ]
 [-1.2501903]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.6818383]
 [ 0.       ]]
--- 0.2806997299194336 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3371.181884765625, (1725.2023, 1.4373975, 1643.9352, 0.6071726)
   validation loss 1249.941650390625, (893.7543, 0.23453024, 355.34558, 0.6071726)
decoder loss ratio: 34625.592141, decoder SINDy loss  ratio: 0.767063
--- 0.33106112480163574 seconds for one epoch ---
--- 0.6270060539245605 seconds for one epoch ---
--- 0.33367371559143066 seconds for one epoch ---
--- 0.6331691741943359 seconds for one epoch ---
--- 0.3474235534667969 seconds for one epoch ---
--- 0.6326074600219727 seconds for one epoch ---
--- 0.3293159008026123 seconds for one epoch ---
--- 0.6474201679229736 seconds for one epoch ---
--- 0.32457900047302246 seconds for one epoch ---
--- 0.6539919376373291 seconds for one epoch ---
--- 0.32953310012817383 seconds for one epoch ---
--- 0.6298134326934814 seconds for one epoch ---
--- 0.33234310150146484 seconds for one epoch ---
--- 0.6538596153259277 seconds for one epoch ---
--- 0.33522462844848633 seconds for one epoch ---
--- 0.6623671054840088 seconds for one epoch ---
--- 0.3371922969818115 seconds for one epoch ---
--- 0.6509354114532471 seconds for one epoch ---
--- 0.33434319496154785 seconds for one epoch ---
--- 0.6673600673675537 seconds for one epoch ---
--- 0.3290250301361084 seconds for one epoch ---
--- 0.6459305286407471 seconds for one epoch ---
--- 0.320056676864624 seconds for one epoch ---
--- 0.6561436653137207 seconds for one epoch ---
=========================
[[0.02749644]
 [0.        ]
 [0.6009855 ]
 [0.        ]
 [0.        ]
 [0.20220098]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9712373 ]
 [0.        ]]
[[-0.5192456]
 [-0.       ]
 [-1.742636 ]
 [-0.       ]
 [ 0.       ]
 [-1.1970513]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7014332]
 [ 0.       ]]
--- 0.3001248836517334 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2546.427490234375, (1131.8042, 1.0023832, 1413.0264, 0.59445846)
   validation loss 1287.16650390625, (991.49, 0.30492207, 294.77713, 0.59445846)
decoder loss ratio: 38412.043524, decoder SINDy loss  ratio: 0.636318
--- 0.2733175754547119 seconds for one epoch ---
--- 0.3274955749511719 seconds for one epoch ---
--- 0.6398625373840332 seconds for one epoch ---
--- 0.3321974277496338 seconds for one epoch ---
--- 0.6542105674743652 seconds for one epoch ---
--- 0.3316161632537842 seconds for one epoch ---
--- 0.6487360000610352 seconds for one epoch ---
--- 0.32175159454345703 seconds for one epoch ---
--- 0.6571269035339355 seconds for one epoch ---
--- 0.3285844326019287 seconds for one epoch ---
--- 0.6448822021484375 seconds for one epoch ---
--- 0.33594655990600586 seconds for one epoch ---
--- 0.6498024463653564 seconds for one epoch ---
--- 0.3252444267272949 seconds for one epoch ---
--- 0.6629006862640381 seconds for one epoch ---
--- 0.3365447521209717 seconds for one epoch ---
--- 0.6500470638275146 seconds for one epoch ---
--- 0.3261854648590088 seconds for one epoch ---
--- 0.6752126216888428 seconds for one epoch ---
--- 0.3363065719604492 seconds for one epoch ---
--- 0.6624205112457275 seconds for one epoch ---
--- 0.3245253562927246 seconds for one epoch ---
--- 0.6474595069885254 seconds for one epoch ---
--- 0.33055543899536133 seconds for one epoch ---
=========================
[[0.03024901]
 [0.        ]
 [0.5213913 ]
 [0.        ]
 [0.        ]
 [0.21298005]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97342044]
 [0.        ]]
[[-0.55250025]
 [-0.        ]
 [-1.6434556 ]
 [-0.        ]
 [ 0.        ]
 [-1.2174081 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7266798 ]
 [ 0.        ]]
--- 0.26787543296813965 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3574.210693359375, (2331.8767, 1.6085956, 1240.1403, 0.5852131)
   validation loss 881.92529296875, (572.2262, 0.27246287, 308.84146, 0.5852131)
decoder loss ratio: 22169.036273, decoder SINDy loss  ratio: 0.666678
--- 0.3321714401245117 seconds for one epoch ---
--- 0.6445744037628174 seconds for one epoch ---
--- 0.3353874683380127 seconds for one epoch ---
--- 0.649240255355835 seconds for one epoch ---
--- 0.3299674987792969 seconds for one epoch ---
--- 0.6488490104675293 seconds for one epoch ---
--- 0.3415093421936035 seconds for one epoch ---
--- 0.6689379215240479 seconds for one epoch ---
--- 0.3336350917816162 seconds for one epoch ---
--- 0.6470737457275391 seconds for one epoch ---
--- 0.33063364028930664 seconds for one epoch ---
--- 0.6650710105895996 seconds for one epoch ---
--- 0.3439052104949951 seconds for one epoch ---
--- 0.6682453155517578 seconds for one epoch ---
--- 0.3338947296142578 seconds for one epoch ---
--- 0.6878829002380371 seconds for one epoch ---
--- 0.33888912200927734 seconds for one epoch ---
--- 0.6571023464202881 seconds for one epoch ---
--- 0.3345763683319092 seconds for one epoch ---
--- 0.6676316261291504 seconds for one epoch ---
--- 0.3220531940460205 seconds for one epoch ---
--- 0.6791884899139404 seconds for one epoch ---
--- 0.33109402656555176 seconds for one epoch ---
--- 0.6651887893676758 seconds for one epoch ---
=========================
[[0.03124745]
 [0.        ]
 [0.4754223 ]
 [0.        ]
 [0.        ]
 [0.19315097]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9760767 ]
 [0.        ]]
[[-0.5646216]
 [-0.       ]
 [-1.587204 ]
 [-0.       ]
 [ 0.       ]
 [-1.1801829]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7602322]
 [ 0.       ]]
--- 0.31012463569641113 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5622.50048828125, (1937.0563, 4.164935, 3680.7056, 0.5738768)
   validation loss 988.0938720703125, (689.9834, 0.31693032, 297.21967, 0.5738768)
decoder loss ratio: 26731.154719, decoder SINDy loss  ratio: 0.641590
--- 0.2775242328643799 seconds for one epoch ---
--- 0.33437395095825195 seconds for one epoch ---
--- 0.6567373275756836 seconds for one epoch ---
--- 0.3239166736602783 seconds for one epoch ---
--- 0.6531360149383545 seconds for one epoch ---
--- 0.325930118560791 seconds for one epoch ---
--- 0.6511421203613281 seconds for one epoch ---
--- 0.32933640480041504 seconds for one epoch ---
--- 0.6732666492462158 seconds for one epoch ---
--- 0.33288097381591797 seconds for one epoch ---
--- 0.67643141746521 seconds for one epoch ---
--- 0.3268625736236572 seconds for one epoch ---
--- 0.6753833293914795 seconds for one epoch ---
--- 0.319016695022583 seconds for one epoch ---
--- 0.6733927726745605 seconds for one epoch ---
--- 0.333676815032959 seconds for one epoch ---
--- 0.6666686534881592 seconds for one epoch ---
--- 0.32830309867858887 seconds for one epoch ---
--- 0.6884384155273438 seconds for one epoch ---
--- 0.3234291076660156 seconds for one epoch ---
--- 0.6833875179290771 seconds for one epoch ---
--- 0.3228285312652588 seconds for one epoch ---
--- 0.6834709644317627 seconds for one epoch ---
--- 0.33754611015319824 seconds for one epoch ---
=========================
[[0.03511529]
 [0.        ]
 [0.45389134]
 [0.        ]
 [0.        ]
 [0.18387501]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9801554 ]
 [0.        ]]
[[-0.60343945]
 [-0.        ]
 [-1.5608039 ]
 [-0.        ]
 [ 0.        ]
 [-1.1618999 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8196006 ]
 [ 0.        ]]
--- 0.26589155197143555 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2763.490478515625, (1312.8424, 1.3954552, 1448.6832, 0.5693195)
   validation loss 958.857177734375, (650.7206, 0.3141581, 307.2531, 0.5693195)
decoder loss ratio: 25210.045011, decoder SINDy loss  ratio: 0.663249
--- 0.3264472484588623 seconds for one epoch ---
--- 0.6639125347137451 seconds for one epoch ---
--- 0.32593584060668945 seconds for one epoch ---
--- 0.6706035137176514 seconds for one epoch ---
--- 0.32000279426574707 seconds for one epoch ---
--- 0.6904275417327881 seconds for one epoch ---
--- 0.3275783061981201 seconds for one epoch ---
--- 0.6627676486968994 seconds for one epoch ---
--- 0.3298654556274414 seconds for one epoch ---
--- 0.686596155166626 seconds for one epoch ---
--- 0.3289036750793457 seconds for one epoch ---
--- 0.6786413192749023 seconds for one epoch ---
--- 0.32462000846862793 seconds for one epoch ---
--- 0.6881377696990967 seconds for one epoch ---
--- 0.3312859535217285 seconds for one epoch ---
--- 0.6741940975189209 seconds for one epoch ---
--- 0.332979679107666 seconds for one epoch ---
--- 0.681248664855957 seconds for one epoch ---
--- 0.326815128326416 seconds for one epoch ---
--- 0.6871213912963867 seconds for one epoch ---
--- 0.3239157199859619 seconds for one epoch ---
--- 0.6746723651885986 seconds for one epoch ---
--- 0.32009005546569824 seconds for one epoch ---
--- 0.6821770668029785 seconds for one epoch ---
=========================
[[0.03751564]
 [0.        ]
 [0.39854473]
 [0.        ]
 [0.        ]
 [0.17116778]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9829885 ]
 [0.        ]]
[[-0.6255736]
 [-0.       ]
 [-1.4915774]
 [-0.       ]
 [ 0.       ]
 [-1.1355226]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8683755]
 [ 0.       ]]
--- 0.3139498233795166 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3723.375244140625, (2108.7822, 1.3828485, 1612.6512, 0.55872166)
   validation loss 1346.0025634765625, (1029.4978, 0.34436148, 315.60175, 0.55872166)
decoder loss ratio: 39884.532165, decoder SINDy loss  ratio: 0.681271
--- 0.2759420871734619 seconds for one epoch ---
--- 0.3284940719604492 seconds for one epoch ---
--- 0.6805882453918457 seconds for one epoch ---
--- 0.31945371627807617 seconds for one epoch ---
--- 0.6846137046813965 seconds for one epoch ---
--- 0.3280680179595947 seconds for one epoch ---
--- 0.6938748359680176 seconds for one epoch ---
--- 0.31793761253356934 seconds for one epoch ---
--- 0.6991403102874756 seconds for one epoch ---
--- 0.35134410858154297 seconds for one epoch ---
--- 0.6801283359527588 seconds for one epoch ---
--- 0.32355713844299316 seconds for one epoch ---
--- 0.6842637062072754 seconds for one epoch ---
--- 0.4893670082092285 seconds for one epoch ---
--- 0.6774985790252686 seconds for one epoch ---
--- 0.3255329132080078 seconds for one epoch ---
--- 0.717047929763794 seconds for one epoch ---
--- 0.32541584968566895 seconds for one epoch ---
--- 0.6992583274841309 seconds for one epoch ---
--- 0.32784271240234375 seconds for one epoch ---
--- 0.7104952335357666 seconds for one epoch ---
--- 0.32662510871887207 seconds for one epoch ---
--- 0.6882750988006592 seconds for one epoch ---
--- 0.3396162986755371 seconds for one epoch ---
=========================
[[0.03965192]
 [0.        ]
 [0.37326705]
 [0.        ]
 [0.        ]
 [0.15781334]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9851186 ]
 [0.        ]]
[[-0.6441039]
 [-0.       ]
 [-1.4590422]
 [-0.       ]
 [ 0.       ]
 [-1.1060592]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9106588]
 [ 0.       ]]
--- 0.27591586112976074 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2448.077880859375, (1313.9325, 1.0676346, 1132.5278, 0.5501026)
   validation loss 1421.8363037109375, (1094.455, 0.26369703, 326.5676, 0.5501026)
decoder loss ratio: 42401.085055, decoder SINDy loss  ratio: 0.704942
--- 0.33441853523254395 seconds for one epoch ---
--- 0.6897311210632324 seconds for one epoch ---
--- 0.32456374168395996 seconds for one epoch ---
--- 0.687800407409668 seconds for one epoch ---
--- 0.3316333293914795 seconds for one epoch ---
--- 0.7126317024230957 seconds for one epoch ---
--- 0.3358030319213867 seconds for one epoch ---
--- 0.7000761032104492 seconds for one epoch ---
--- 0.33389830589294434 seconds for one epoch ---
--- 0.700533390045166 seconds for one epoch ---
--- 0.34579920768737793 seconds for one epoch ---
--- 0.703434944152832 seconds for one epoch ---
--- 0.3328518867492676 seconds for one epoch ---
--- 0.7017006874084473 seconds for one epoch ---
--- 0.32384586334228516 seconds for one epoch ---
--- 0.7012994289398193 seconds for one epoch ---
--- 0.3309791088104248 seconds for one epoch ---
--- 0.7266857624053955 seconds for one epoch ---
--- 0.3163902759552002 seconds for one epoch ---
--- 0.7168378829956055 seconds for one epoch ---
--- 0.32545042037963867 seconds for one epoch ---
--- 0.6961686611175537 seconds for one epoch ---
--- 0.32741761207580566 seconds for one epoch ---
--- 0.6876101493835449 seconds for one epoch ---
=========================
[[0.04545036]
 [0.        ]
 [0.3591515 ]
 [0.        ]
 [0.        ]
 [0.16036725]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98735183]
 [0.        ]]
[[-0.68833464]
 [-0.        ]
 [-1.4405233 ]
 [-0.        ]
 [ 0.        ]
 [-1.1120372 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9619508 ]
 [ 0.        ]]
--- 0.2950308322906494 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4391.94921875, (1733.33, 1.6946931, 2656.3733, 0.551416)
   validation loss 1130.2545166015625, (810.5354, 0.3802228, 318.78745, 0.551416)
decoder loss ratio: 31401.548562, decoder SINDy loss  ratio: 0.688148
--- 0.27304935455322266 seconds for one epoch ---
--- 0.32773327827453613 seconds for one epoch ---
--- 0.7118709087371826 seconds for one epoch ---
--- 0.3242790699005127 seconds for one epoch ---
--- 0.7041583061218262 seconds for one epoch ---
--- 0.32382869720458984 seconds for one epoch ---
--- 0.7054243087768555 seconds for one epoch ---
--- 0.32021141052246094 seconds for one epoch ---
--- 0.7241497039794922 seconds for one epoch ---
--- 0.3344917297363281 seconds for one epoch ---
--- 0.7066640853881836 seconds for one epoch ---
--- 0.32616686820983887 seconds for one epoch ---
--- 0.7226433753967285 seconds for one epoch ---
--- 0.32937002182006836 seconds for one epoch ---
--- 0.7192051410675049 seconds for one epoch ---
--- 0.3146336078643799 seconds for one epoch ---
--- 0.7151436805725098 seconds for one epoch ---
--- 0.3281264305114746 seconds for one epoch ---
--- 0.7124292850494385 seconds for one epoch ---
--- 0.3231642246246338 seconds for one epoch ---
--- 0.7014133930206299 seconds for one epoch ---
--- 0.33996152877807617 seconds for one epoch ---
--- 0.7116637229919434 seconds for one epoch ---
--- 0.332622766494751 seconds for one epoch ---
=========================
[[0.0493343 ]
 [0.        ]
 [0.33154467]
 [0.        ]
 [0.        ]
 [0.15778676]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9883587 ]
 [0.        ]]
[[-0.7151045]
 [-0.       ]
 [-1.4032725]
 [-0.       ]
 [ 0.       ]
 [-1.1063005]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9880955]
 [ 0.       ]]
--- 0.25695371627807617 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2805.2578125, (1545.597, 0.91346455, 1258.2014, 0.54583305)
   validation loss 1114.02587890625, (765.43835, 0.32283837, 347.7189, 0.54583305)
decoder loss ratio: 29654.410712, decoder SINDy loss  ratio: 0.750600
--- 0.3310832977294922 seconds for one epoch ---
--- 0.7088165283203125 seconds for one epoch ---
--- 0.3260979652404785 seconds for one epoch ---
--- 0.6972815990447998 seconds for one epoch ---
--- 0.3302578926086426 seconds for one epoch ---
--- 0.7027041912078857 seconds for one epoch ---
--- 0.32626867294311523 seconds for one epoch ---
--- 0.7370996475219727 seconds for one epoch ---
--- 0.33190441131591797 seconds for one epoch ---
--- 0.7370004653930664 seconds for one epoch ---
--- 0.32726311683654785 seconds for one epoch ---
--- 0.7388663291931152 seconds for one epoch ---
--- 0.32688283920288086 seconds for one epoch ---
--- 0.7137112617492676 seconds for one epoch ---
--- 0.3284173011779785 seconds for one epoch ---
--- 0.7362987995147705 seconds for one epoch ---
--- 0.32742977142333984 seconds for one epoch ---
--- 0.736189603805542 seconds for one epoch ---
--- 0.3283238410949707 seconds for one epoch ---
--- 0.7279064655303955 seconds for one epoch ---
--- 0.33849644660949707 seconds for one epoch ---
--- 0.7312901020050049 seconds for one epoch ---
--- 0.32805681228637695 seconds for one epoch ---
--- 0.7417869567871094 seconds for one epoch ---
=========================
[[0.05573199]
 [0.        ]
 [0.3160077 ]
 [0.        ]
 [0.        ]
 [0.1493989 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9904594 ]
 [0.        ]]
[[-0.75467664]
 [-0.        ]
 [-1.3816559 ]
 [-0.        ]
 [ 0.        ]
 [-1.0867547 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0506868 ]
 [ 0.        ]]
--- 0.31704115867614746 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5225.86865234375, (2505.7708, 3.1108422, 2716.4446, 0.54241526)
   validation loss 947.1178588867188, (630.9663, 0.4054502, 315.20367, 0.54241526)
decoder loss ratio: 24444.730201, decoder SINDy loss  ratio: 0.680411
THRESHOLDING: 3 active coefficients
--- 0.7283875942230225 seconds for one epoch ---
--- 0.332714319229126 seconds for one epoch ---
--- 0.7282886505126953 seconds for one epoch ---
--- 0.3250441551208496 seconds for one epoch ---
--- 0.7414178848266602 seconds for one epoch ---
--- 0.3368496894836426 seconds for one epoch ---
--- 0.7324340343475342 seconds for one epoch ---
--- 0.35004401206970215 seconds for one epoch ---
--- 0.7430860996246338 seconds for one epoch ---
--- 0.3431360721588135 seconds for one epoch ---
--- 0.7516734600067139 seconds for one epoch ---
--- 0.3395047187805176 seconds for one epoch ---
--- 0.7283058166503906 seconds for one epoch ---
--- 0.3242762088775635 seconds for one epoch ---
--- 0.7433764934539795 seconds for one epoch ---
--- 0.33530569076538086 seconds for one epoch ---
--- 0.7489664554595947 seconds for one epoch ---
--- 0.3174600601196289 seconds for one epoch ---
--- 0.7479972839355469 seconds for one epoch ---
--- 0.3346829414367676 seconds for one epoch ---
--- 0.7515029907226562 seconds for one epoch ---
--- 0.3275413513183594 seconds for one epoch ---
--- 0.7380082607269287 seconds for one epoch ---
--- 0.3535294532775879 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.29286733]
 [0.        ]
 [0.        ]
 [0.17340966]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9929739 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3483421]
 [-0.       ]
 [ 0.       ]
 [-1.1409765]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.146842 ]
 [ 0.       ]]
--- 0.2710247039794922 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4067.5732421875, (1779.1781, 0.88449043, 2287.0398, 0.4707068)
   validation loss 1110.0751953125, (781.3927, 0.43595442, 327.77588, 0.4707068)
decoder loss ratio: 30272.509763, decoder SINDy loss  ratio: 0.707550
--- 0.3073394298553467 seconds for one epoch ---
--- 0.7381594181060791 seconds for one epoch ---
--- 0.3402111530303955 seconds for one epoch ---
--- 0.7486457824707031 seconds for one epoch ---
--- 0.3298070430755615 seconds for one epoch ---
--- 0.7369866371154785 seconds for one epoch ---
--- 0.3345339298248291 seconds for one epoch ---
--- 0.738856315612793 seconds for one epoch ---
--- 0.33711886405944824 seconds for one epoch ---
--- 0.7374238967895508 seconds for one epoch ---
--- 0.32825779914855957 seconds for one epoch ---
--- 0.7611861228942871 seconds for one epoch ---
--- 0.33209824562072754 seconds for one epoch ---
--- 0.7466366291046143 seconds for one epoch ---
--- 0.32482123374938965 seconds for one epoch ---
--- 0.7607603073120117 seconds for one epoch ---
--- 0.33106231689453125 seconds for one epoch ---
--- 0.749168872833252 seconds for one epoch ---
--- 0.3270094394683838 seconds for one epoch ---
--- 0.7388665676116943 seconds for one epoch ---
--- 0.33907079696655273 seconds for one epoch ---
--- 0.7597401142120361 seconds for one epoch ---
--- 0.32242608070373535 seconds for one epoch ---
--- 0.7426447868347168 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2964531 ]
 [0.        ]
 [0.        ]
 [0.16638605]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99492145]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.353651 ]
 [-0.       ]
 [ 0.       ]
 [-1.1258821]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2487822]
 [ 0.       ]]
--- 0.31410980224609375 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1990.5322265625, (1154.2494, 0.32919422, 835.48303, 0.47055736)
   validation loss 1110.7908935546875, (733.7335, 0.39282328, 376.19403, 0.47055736)
decoder loss ratio: 28426.110402, decoder SINDy loss  ratio: 0.812068
--- 0.276792049407959 seconds for one epoch ---
--- 0.33389902114868164 seconds for one epoch ---
--- 0.7503807544708252 seconds for one epoch ---
--- 0.3569798469543457 seconds for one epoch ---
--- 0.7486929893493652 seconds for one epoch ---
--- 0.33101868629455566 seconds for one epoch ---
--- 0.7621986865997314 seconds for one epoch ---
--- 0.3318307399749756 seconds for one epoch ---
--- 0.7708947658538818 seconds for one epoch ---
--- 0.32561373710632324 seconds for one epoch ---
--- 0.7505407333374023 seconds for one epoch ---
--- 0.3290727138519287 seconds for one epoch ---
--- 0.7659645080566406 seconds for one epoch ---
--- 0.3328742980957031 seconds for one epoch ---
--- 0.7449831962585449 seconds for one epoch ---
--- 0.3281674385070801 seconds for one epoch ---
--- 0.7698574066162109 seconds for one epoch ---
--- 0.338759183883667 seconds for one epoch ---
--- 0.7533743381500244 seconds for one epoch ---
--- 0.3532381057739258 seconds for one epoch ---
--- 0.7703924179077148 seconds for one epoch ---
--- 0.3342108726501465 seconds for one epoch ---
--- 0.7516179084777832 seconds for one epoch ---
--- 0.328960657119751 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.26459023]
 [0.        ]
 [0.        ]
 [0.17072995]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9967429 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3054936]
 [-0.       ]
 [ 0.       ]
 [-1.1353908]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3881776]
 [ 0.       ]]
--- 0.2644612789154053 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1926.8800048828125, (940.7876, 2.0350912, 983.59216, 0.46520114)
   validation loss 1028.2313232421875, (697.58386, 0.61788565, 329.56445, 0.46520114)
decoder loss ratio: 27025.609885, decoder SINDy loss  ratio: 0.711411
--- 0.33136653900146484 seconds for one epoch ---
--- 0.7507655620574951 seconds for one epoch ---
--- 0.32542943954467773 seconds for one epoch ---
--- 0.7444045543670654 seconds for one epoch ---
--- 0.32590723037719727 seconds for one epoch ---
--- 0.7565650939941406 seconds for one epoch ---
--- 0.32735347747802734 seconds for one epoch ---
--- 0.7735660076141357 seconds for one epoch ---
--- 0.3302178382873535 seconds for one epoch ---
--- 0.7590417861938477 seconds for one epoch ---
--- 0.3310220241546631 seconds for one epoch ---
--- 0.7505862712860107 seconds for one epoch ---
--- 0.3274390697479248 seconds for one epoch ---
--- 0.7571697235107422 seconds for one epoch ---
--- 0.33847689628601074 seconds for one epoch ---
--- 0.7823526859283447 seconds for one epoch ---
--- 0.33615899085998535 seconds for one epoch ---
--- 0.7586483955383301 seconds for one epoch ---
--- 0.3385739326477051 seconds for one epoch ---
--- 0.7577652931213379 seconds for one epoch ---
--- 0.32463955879211426 seconds for one epoch ---
--- 0.790128231048584 seconds for one epoch ---
--- 0.3323860168457031 seconds for one epoch ---
--- 0.78605055809021 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.26274437]
 [0.        ]
 [0.        ]
 [0.16904476]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9975047 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3026294]
 [-0.       ]
 [ 0.       ]
 [-1.1318074]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4717996]
 [-0.       ]]
--- 0.3190031051635742 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4118.08544921875, (2069.5696, 0.9073708, 2047.1434, 0.46491805)
   validation loss 1564.62109375, (1193.1595, 0.51053244, 370.48608, 0.46491805)
decoder loss ratio: 46225.072224, decoder SINDy loss  ratio: 0.799746
--- 0.27368712425231934 seconds for one epoch ---
--- 0.32759618759155273 seconds for one epoch ---
--- 0.7890844345092773 seconds for one epoch ---
--- 0.32625436782836914 seconds for one epoch ---
--- 0.7878232002258301 seconds for one epoch ---
--- 0.3222696781158447 seconds for one epoch ---
--- 0.7691595554351807 seconds for one epoch ---
--- 0.31917572021484375 seconds for one epoch ---
--- 0.7654039859771729 seconds for one epoch ---
--- 0.33144521713256836 seconds for one epoch ---
--- 0.7667856216430664 seconds for one epoch ---
--- 0.322481632232666 seconds for one epoch ---
--- 0.7915792465209961 seconds for one epoch ---
--- 0.3194091320037842 seconds for one epoch ---
--- 0.7883429527282715 seconds for one epoch ---
--- 0.3338894844055176 seconds for one epoch ---
--- 0.7671761512756348 seconds for one epoch ---
--- 0.3258538246154785 seconds for one epoch ---
--- 0.8017621040344238 seconds for one epoch ---
--- 0.3166215419769287 seconds for one epoch ---
--- 0.7953181266784668 seconds for one epoch ---
--- 0.33330774307250977 seconds for one epoch ---
--- 0.7791087627410889 seconds for one epoch ---
--- 0.3296656608581543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24991587]
 [0.        ]
 [0.        ]
 [0.15745457]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.998001  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.282141 ]
 [-0.       ]
 [ 0.       ]
 [-1.1060249]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5414402]
 [-0.       ]]
--- 0.2719731330871582 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3434.227783203125, (1684.6814, 0.98443514, 1748.1025, 0.45940802)
   validation loss 1006.5691528320312, (664.55664, 0.511346, 341.04172, 0.45940802)
decoder loss ratio: 25746.077979, decoder SINDy loss  ratio: 0.736187
--- 0.3494384288787842 seconds for one epoch ---
--- 0.78043532371521 seconds for one epoch ---
--- 0.3618295192718506 seconds for one epoch ---
--- 0.781029224395752 seconds for one epoch ---
--- 0.34439706802368164 seconds for one epoch ---
--- 0.7764561176300049 seconds for one epoch ---
--- 0.33232688903808594 seconds for one epoch ---
--- 0.793889045715332 seconds for one epoch ---
--- 0.3362259864807129 seconds for one epoch ---
--- 0.7852675914764404 seconds for one epoch ---
--- 0.3348197937011719 seconds for one epoch ---
--- 0.7760913372039795 seconds for one epoch ---
--- 0.33648252487182617 seconds for one epoch ---
--- 0.7738451957702637 seconds for one epoch ---
--- 0.3224906921386719 seconds for one epoch ---
--- 0.787867546081543 seconds for one epoch ---
--- 0.3257932662963867 seconds for one epoch ---
--- 0.8015470504760742 seconds for one epoch ---
--- 0.3385801315307617 seconds for one epoch ---
--- 0.7863397598266602 seconds for one epoch ---
--- 0.33658647537231445 seconds for one epoch ---
--- 0.7844293117523193 seconds for one epoch ---
--- 0.32717204093933105 seconds for one epoch ---
--- 0.7887823581695557 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24893402]
 [0.        ]
 [0.        ]
 [0.15115157]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99847186]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2805696]
 [-0.       ]
 [ 0.       ]
 [-1.09137  ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.62575  ]
 [-0.       ]]
--- 0.31003665924072266 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7945.892578125, (1612.5409, 5.6386333, 6327.2554, 0.4576799)
   validation loss 1652.8822021484375, (1315.277, 0.56096494, 336.58664, 0.4576799)
decoder loss ratio: 50956.113531, decoder SINDy loss  ratio: 0.726570
--- 0.27803635597229004 seconds for one epoch ---
--- 0.3401331901550293 seconds for one epoch ---
--- 0.7751469612121582 seconds for one epoch ---
--- 0.3223586082458496 seconds for one epoch ---
--- 0.8007864952087402 seconds for one epoch ---
--- 0.3176858425140381 seconds for one epoch ---
--- 0.7757468223571777 seconds for one epoch ---
--- 0.3247964382171631 seconds for one epoch ---
--- 0.810157060623169 seconds for one epoch ---
--- 0.3293766975402832 seconds for one epoch ---
--- 0.7974834442138672 seconds for one epoch ---
--- 0.3229854106903076 seconds for one epoch ---
--- 0.7938926219940186 seconds for one epoch ---
--- 0.32720947265625 seconds for one epoch ---
--- 0.8002209663391113 seconds for one epoch ---
--- 0.3164370059967041 seconds for one epoch ---
--- 0.8009796142578125 seconds for one epoch ---
--- 0.32606029510498047 seconds for one epoch ---
--- 0.8061919212341309 seconds for one epoch ---
--- 0.3329918384552002 seconds for one epoch ---
--- 0.7898175716400146 seconds for one epoch ---
--- 0.3265702724456787 seconds for one epoch ---
--- 0.7977151870727539 seconds for one epoch ---
--- 0.3238658905029297 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22733271]
 [0.        ]
 [0.        ]
 [0.15470035]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99892193]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2442915]
 [-0.       ]
 [ 0.       ]
 [-1.0997462]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7354589]
 [-0.       ]]
--- 0.27320051193237305 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2014.9593505859375, (1108.5665, 1.2343051, 904.7046, 0.45398775)
   validation loss 1365.6243896484375, (938.62366, 0.46692583, 426.0798, 0.45398775)
decoder loss ratio: 36363.910003, decoder SINDy loss  ratio: 0.919753
--- 0.31272101402282715 seconds for one epoch ---
--- 0.7751979827880859 seconds for one epoch ---
--- 0.3276209831237793 seconds for one epoch ---
--- 0.8022975921630859 seconds for one epoch ---
--- 0.3270289897918701 seconds for one epoch ---
--- 0.8160650730133057 seconds for one epoch ---
--- 0.33493542671203613 seconds for one epoch ---
--- 0.8048787117004395 seconds for one epoch ---
--- 0.32214999198913574 seconds for one epoch ---
--- 0.7957725524902344 seconds for one epoch ---
--- 0.3322582244873047 seconds for one epoch ---
--- 0.81461501121521 seconds for one epoch ---
--- 0.32689428329467773 seconds for one epoch ---
--- 0.8271992206573486 seconds for one epoch ---
--- 0.32001590728759766 seconds for one epoch ---
--- 0.8014633655548096 seconds for one epoch ---
--- 0.3285188674926758 seconds for one epoch ---
--- 0.7973325252532959 seconds for one epoch ---
--- 0.32538866996765137 seconds for one epoch ---
--- 0.8056936264038086 seconds for one epoch ---
--- 0.3294944763183594 seconds for one epoch ---
--- 0.8039851188659668 seconds for one epoch ---
--- 0.33371448516845703 seconds for one epoch ---
--- 0.8120393753051758 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.21876957]
 [0.        ]
 [0.        ]
 [0.15476628]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99926364]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2292587]
 [ 0.       ]
 [ 0.       ]
 [-1.0999321]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.8554993]
 [-0.       ]]
--- 0.31723618507385254 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3424.481201171875, (1379.2994, 0.6816864, 2044.0466, 0.45337105)
   validation loss 1313.507080078125, (937.9654, 0.60231036, 374.48605, 0.45337105)
decoder loss ratio: 36338.407707, decoder SINDy loss  ratio: 0.808381
--- 0.2726140022277832 seconds for one epoch ---
--- 0.32460880279541016 seconds for one epoch ---
--- 0.7985148429870605 seconds for one epoch ---
--- 0.3293020725250244 seconds for one epoch ---
--- 0.816007137298584 seconds for one epoch ---
--- 0.3260660171508789 seconds for one epoch ---
--- 0.8357224464416504 seconds for one epoch ---
--- 0.3351762294769287 seconds for one epoch ---
--- 0.8051700592041016 seconds for one epoch ---
--- 0.3220498561859131 seconds for one epoch ---
--- 0.8304495811462402 seconds for one epoch ---
--- 0.3209102153778076 seconds for one epoch ---
--- 0.8025271892547607 seconds for one epoch ---
--- 0.3197181224822998 seconds for one epoch ---
--- 0.8263139724731445 seconds for one epoch ---
--- 0.3324713706970215 seconds for one epoch ---
--- 0.8055024147033691 seconds for one epoch ---
--- 0.31694960594177246 seconds for one epoch ---
--- 0.8174788951873779 seconds for one epoch ---
--- 0.3277432918548584 seconds for one epoch ---
--- 0.8251485824584961 seconds for one epoch ---
--- 0.3259551525115967 seconds for one epoch ---
--- 0.8130512237548828 seconds for one epoch ---
--- 0.32233309745788574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22732121]
 [0.        ]
 [0.        ]
 [0.15389255]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9995165 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.244314 ]
 [ 0.       ]
 [ 0.       ]
 [-1.0979259]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.9880688]
 [-0.       ]]
--- 0.2716865539550781 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2790.91259765625, (1439.7808, 1.1181377, 1349.5575, 0.45593786)
   validation loss 970.7008056640625, (646.33875, 0.4878792, 323.41827, 0.45593786)
decoder loss ratio: 25040.285079, decoder SINDy loss  ratio: 0.698144
--- 0.33353447914123535 seconds for one epoch ---
--- 0.8191707134246826 seconds for one epoch ---
--- 0.3308756351470947 seconds for one epoch ---
--- 0.8186342716217041 seconds for one epoch ---
--- 0.3315541744232178 seconds for one epoch ---
--- 0.8167121410369873 seconds for one epoch ---
--- 0.3222973346710205 seconds for one epoch ---
--- 0.8268208503723145 seconds for one epoch ---
--- 0.3253357410430908 seconds for one epoch ---
--- 0.8322358131408691 seconds for one epoch ---
--- 0.32898640632629395 seconds for one epoch ---
--- 0.8298494815826416 seconds for one epoch ---
--- 0.3144054412841797 seconds for one epoch ---
--- 0.8255126476287842 seconds for one epoch ---
--- 0.34416675567626953 seconds for one epoch ---
--- 0.8283388614654541 seconds for one epoch ---
--- 0.3255770206451416 seconds for one epoch ---
--- 0.8212087154388428 seconds for one epoch ---
--- 0.3263881206512451 seconds for one epoch ---
--- 0.8354687690734863 seconds for one epoch ---
--- 0.34017229080200195 seconds for one epoch ---
--- 0.8424713611602783 seconds for one epoch ---
--- 0.32725071907043457 seconds for one epoch ---
--- 0.8490018844604492 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22051845]
 [0.        ]
 [0.        ]
 [0.14820804]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99967945]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2324052]
 [ 0.       ]
 [-0.       ]
 [-1.0844668]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.1178584]
 [-0.       ]]
--- 0.3084440231323242 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2922.557861328125, (1518.7018, 1.0296184, 1402.3733, 0.4531231)
   validation loss 1014.3443603515625, (682.9785, 0.53944963, 330.37332, 0.4531231)
decoder loss ratio: 26459.773398, decoder SINDy loss  ratio: 0.713157
--- 0.27791333198547363 seconds for one epoch ---
--- 0.32068538665771484 seconds for one epoch ---
--- 0.8232300281524658 seconds for one epoch ---
--- 0.33315253257751465 seconds for one epoch ---
--- 0.8130888938903809 seconds for one epoch ---
--- 0.32454848289489746 seconds for one epoch ---
--- 0.8186891078948975 seconds for one epoch ---
--- 0.3292725086212158 seconds for one epoch ---
--- 0.8527026176452637 seconds for one epoch ---
--- 0.3273963928222656 seconds for one epoch ---
--- 0.8607063293457031 seconds for one epoch ---
--- 0.32642483711242676 seconds for one epoch ---
--- 0.8238022327423096 seconds for one epoch ---
--- 0.32622361183166504 seconds for one epoch ---
--- 0.8329880237579346 seconds for one epoch ---
--- 0.3267064094543457 seconds for one epoch ---
--- 0.8407196998596191 seconds for one epoch ---
--- 0.4967930316925049 seconds for one epoch ---
--- 0.8435053825378418 seconds for one epoch ---
--- 0.3233644962310791 seconds for one epoch ---
--- 0.8510317802429199 seconds for one epoch ---
--- 0.31792473793029785 seconds for one epoch ---
--- 0.8733313083648682 seconds for one epoch ---
--- 0.3258075714111328 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2169039 ]
 [0.        ]
 [0.        ]
 [0.14821742]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999738  ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.2259783]
 [ 0.       ]
 [-0.       ]
 [-1.0845131]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.1823378]
 [-0.       ]]
--- 0.27008867263793945 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4036.84130859375, (1717.6697, 1.6409675, 2317.0786, 0.45205817)
   validation loss 1153.43017578125, (795.493, 0.58931285, 356.89584, 0.45205817)
decoder loss ratio: 30818.779119, decoder SINDy loss  ratio: 0.770410
--- 0.3221752643585205 seconds for one epoch ---
--- 0.8550655841827393 seconds for one epoch ---
--- 0.30811119079589844 seconds for one epoch ---
--- 0.8533871173858643 seconds for one epoch ---
--- 0.3230016231536865 seconds for one epoch ---
--- 0.8446335792541504 seconds for one epoch ---
--- 0.3306267261505127 seconds for one epoch ---
--- 0.8483538627624512 seconds for one epoch ---
--- 0.33161020278930664 seconds for one epoch ---
--- 0.843134880065918 seconds for one epoch ---
--- 0.32938694953918457 seconds for one epoch ---
--- 0.8585355281829834 seconds for one epoch ---
--- 0.33586788177490234 seconds for one epoch ---
--- 0.8534793853759766 seconds for one epoch ---
--- 0.32951951026916504 seconds for one epoch ---
--- 0.8570845127105713 seconds for one epoch ---
--- 0.3344261646270752 seconds for one epoch ---
--- 0.8416759967803955 seconds for one epoch ---
--- 0.331423282623291 seconds for one epoch ---
--- 0.871401309967041 seconds for one epoch ---
--- 0.32129931449890137 seconds for one epoch ---
--- 0.8447842597961426 seconds for one epoch ---
--- 0.33104872703552246 seconds for one epoch ---
--- 0.8648262023925781 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.21737172]
 [0.        ]
 [0.        ]
 [0.14584911]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998043 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2268292]
 [-0.       ]
 [ 0.       ]
 [-1.0787895]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.2755356]
 [-0.       ]]
--- 0.31067395210266113 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3846.1484375, (1256.5854, 0.9183968, 2588.1917, 0.45292988)
   validation loss 1506.64501953125, (1029.5135, 0.48724335, 476.19147, 0.45292988)
decoder loss ratio: 39885.142234, decoder SINDy loss  ratio: 1.027926
--- 0.2768421173095703 seconds for one epoch ---
--- 0.3302583694458008 seconds for one epoch ---
--- 0.8325629234313965 seconds for one epoch ---
--- 0.3148317337036133 seconds for one epoch ---
--- 0.8341279029846191 seconds for one epoch ---
--- 0.3318047523498535 seconds for one epoch ---
--- 0.8397786617279053 seconds for one epoch ---
--- 0.32680201530456543 seconds for one epoch ---
--- 0.8571004867553711 seconds for one epoch ---
--- 0.32514357566833496 seconds for one epoch ---
--- 0.8619763851165771 seconds for one epoch ---
--- 0.3309013843536377 seconds for one epoch ---
--- 0.8631744384765625 seconds for one epoch ---
--- 0.3278200626373291 seconds for one epoch ---
--- 0.8751249313354492 seconds for one epoch ---
--- 0.3127593994140625 seconds for one epoch ---
--- 0.858147144317627 seconds for one epoch ---
--- 0.32418370246887207 seconds for one epoch ---
--- 0.8576304912567139 seconds for one epoch ---
--- 0.3183290958404541 seconds for one epoch ---
--- 0.8747224807739258 seconds for one epoch ---
--- 0.3200111389160156 seconds for one epoch ---
--- 0.869049072265625 seconds for one epoch ---
--- 0.3346238136291504 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.20065764]
 [0.        ]
 [0.        ]
 [0.14636154]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999855  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1960444]
 [-0.       ]
 [ 0.       ]
 [-1.0800557]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.3673906]
 [-0.       ]]
--- 0.2744872570037842 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3172.310791015625, (817.72485, 6.4286637, 2347.7073, 0.4499445)
   validation loss 888.7413330078125, (556.0919, 0.5797889, 331.61966, 0.4499445)
decoder loss ratio: 21543.966358, decoder SINDy loss  ratio: 0.715848
--- 0.3199601173400879 seconds for one epoch ---
--- 0.8634970188140869 seconds for one epoch ---
--- 0.3326137065887451 seconds for one epoch ---
--- 0.8800606727600098 seconds for one epoch ---
--- 0.3314497470855713 seconds for one epoch ---
--- 0.8598806858062744 seconds for one epoch ---
--- 0.3372023105621338 seconds for one epoch ---
--- 0.8525979518890381 seconds for one epoch ---
--- 0.3203718662261963 seconds for one epoch ---
--- 0.8652584552764893 seconds for one epoch ---
--- 0.3209209442138672 seconds for one epoch ---
--- 0.8612980842590332 seconds for one epoch ---
--- 0.3263282775878906 seconds for one epoch ---
--- 0.8749330043792725 seconds for one epoch ---
--- 0.322009801864624 seconds for one epoch ---
--- 0.8790044784545898 seconds for one epoch ---
--- 0.32564854621887207 seconds for one epoch ---
--- 0.8781044483184814 seconds for one epoch ---
--- 0.32395315170288086 seconds for one epoch ---
--- 0.8808248043060303 seconds for one epoch ---
--- 0.3223609924316406 seconds for one epoch ---
--- 0.863445520401001 seconds for one epoch ---
--- 0.3292703628540039 seconds for one epoch ---
--- 0.8864977359771729 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.20579141]
 [0.        ]
 [0.        ]
 [0.14377287]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998916 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.2057074]
 [ 0.       ]
 [-0.       ]
 [-1.0737247]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.464584 ]
 [-0.       ]]
--- 0.30997204780578613 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1924.701416015625, (860.3696, 0.29862353, 1063.5824, 0.45063224)
   validation loss 1138.24462890625, (804.96686, 0.54705465, 332.2801, 0.45063224)
decoder loss ratio: 31185.813559, decoder SINDy loss  ratio: 0.717273
--- 0.2750089168548584 seconds for one epoch ---
--- 0.32912635803222656 seconds for one epoch ---
--- 0.8789896965026855 seconds for one epoch ---
--- 0.31784725189208984 seconds for one epoch ---
--- 0.859722375869751 seconds for one epoch ---
--- 0.32781195640563965 seconds for one epoch ---
--- 0.8547248840332031 seconds for one epoch ---
--- 0.3223392963409424 seconds for one epoch ---
--- 0.8807201385498047 seconds for one epoch ---
--- 0.3235633373260498 seconds for one epoch ---
--- 0.8619565963745117 seconds for one epoch ---
--- 0.32538771629333496 seconds for one epoch ---
--- 0.889028787612915 seconds for one epoch ---
--- 0.32439708709716797 seconds for one epoch ---
--- 0.9037907123565674 seconds for one epoch ---
--- 0.32422304153442383 seconds for one epoch ---
--- 0.8780734539031982 seconds for one epoch ---
--- 0.3264343738555908 seconds for one epoch ---
--- 0.9176862239837646 seconds for one epoch ---
--- 0.3286116123199463 seconds for one epoch ---
--- 0.882800817489624 seconds for one epoch ---
--- 0.3339073657989502 seconds for one epoch ---
--- 0.8837523460388184 seconds for one epoch ---
--- 0.32439589500427246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19989727]
 [0.        ]
 [0.        ]
 [0.14062974]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999118 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.194619 ]
 [ 0.       ]
 [-0.       ]
 [-1.0659045]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.527641 ]
 [-0.       ]]
--- 0.274198055267334 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2676.16015625, (1506.0194, 1.5941844, 1168.0975, 0.4488761)
   validation loss 1495.40869140625, (1129.1919, 0.5237696, 365.24414, 0.4488761)
decoder loss ratio: 43746.854357, decoder SINDy loss  ratio: 0.788431
--- 0.3258218765258789 seconds for one epoch ---
--- 0.8800089359283447 seconds for one epoch ---
--- 0.34152722358703613 seconds for one epoch ---
--- 0.8712656497955322 seconds for one epoch ---
--- 0.32745957374572754 seconds for one epoch ---
--- 0.9064962863922119 seconds for one epoch ---
--- 0.3341209888458252 seconds for one epoch ---
--- 0.8944687843322754 seconds for one epoch ---
--- 0.3375585079193115 seconds for one epoch ---
--- 0.9219393730163574 seconds for one epoch ---
--- 0.33614540100097656 seconds for one epoch ---
--- 0.8915688991546631 seconds for one epoch ---
--- 0.32611870765686035 seconds for one epoch ---
--- 0.9072306156158447 seconds for one epoch ---
--- 0.3252241611480713 seconds for one epoch ---
--- 0.8910887241363525 seconds for one epoch ---
--- 0.3336513042449951 seconds for one epoch ---
--- 0.8854303359985352 seconds for one epoch ---
--- 0.33202385902404785 seconds for one epoch ---
--- 0.9003887176513672 seconds for one epoch ---
--- 0.32829904556274414 seconds for one epoch ---
--- 0.9040031433105469 seconds for one epoch ---
--- 0.34262847900390625 seconds for one epoch ---
--- 0.9001522064208984 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19362052]
 [0.        ]
 [0.        ]
 [0.14462419]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999356 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1825377]
 [-0.       ]
 [ 0.       ]
 [-1.075846 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.637688 ]
 [-0.       ]]
--- 0.31172847747802734 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3329.08544921875, (1710.6509, 1.0246907, 1616.9615, 0.4482933)
   validation loss 1105.415771484375, (745.1892, 0.614216, 359.16412, 0.4482933)
decoder loss ratio: 28869.923661, decoder SINDy loss  ratio: 0.775306
--- 0.273374080657959 seconds for one epoch ---
--- 0.32545900344848633 seconds for one epoch ---
--- 0.8932015895843506 seconds for one epoch ---
--- 0.33034586906433105 seconds for one epoch ---
--- 0.8773982524871826 seconds for one epoch ---
--- 0.3255906105041504 seconds for one epoch ---
--- 0.9103856086730957 seconds for one epoch ---
--- 0.33299875259399414 seconds for one epoch ---
--- 0.9024367332458496 seconds for one epoch ---
--- 0.33147668838500977 seconds for one epoch ---
--- 0.9013824462890625 seconds for one epoch ---
--- 0.33322668075561523 seconds for one epoch ---
--- 0.9120302200317383 seconds for one epoch ---
--- 0.3281211853027344 seconds for one epoch ---
--- 0.8979921340942383 seconds for one epoch ---
--- 0.3297414779663086 seconds for one epoch ---
--- 0.9211010932922363 seconds for one epoch ---
--- 0.33281564712524414 seconds for one epoch ---
--- 0.920013427734375 seconds for one epoch ---
--- 0.323868989944458 seconds for one epoch ---
--- 0.8963086605072021 seconds for one epoch ---
--- 0.33620500564575195 seconds for one epoch ---
--- 0.9076318740844727 seconds for one epoch ---
--- 0.3284337520599365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19100425]
 [0.        ]
 [0.        ]
 [0.13528991]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999522 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.1774188]
 [-0.       ]
 [ 0.       ]
 [-1.0522789]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7345643]
 [-0.       ]]
--- 0.2712061405181885 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2322.440185546875, (1271.9111, 0.8017832, 1049.2815, 0.44573894)
   validation loss 1650.0794677734375, (1283.8136, 0.66969, 365.15045, 0.44573894)
decoder loss ratio: 49737.167609, decoder SINDy loss  ratio: 0.788229
--- 0.33274006843566895 seconds for one epoch ---
--- 0.9099292755126953 seconds for one epoch ---
--- 0.3418560028076172 seconds for one epoch ---
--- 0.9227261543273926 seconds for one epoch ---
--- 0.33792638778686523 seconds for one epoch ---
--- 0.9168939590454102 seconds for one epoch ---
--- 0.3335709571838379 seconds for one epoch ---
--- 0.9478332996368408 seconds for one epoch ---
--- 0.32822227478027344 seconds for one epoch ---
--- 0.911879301071167 seconds for one epoch ---
--- 0.3328742980957031 seconds for one epoch ---
--- 0.9242560863494873 seconds for one epoch ---
--- 0.3333923816680908 seconds for one epoch ---
--- 0.9282166957855225 seconds for one epoch ---
--- 0.3325376510620117 seconds for one epoch ---
--- 0.9243001937866211 seconds for one epoch ---
--- 0.3255031108856201 seconds for one epoch ---
--- 0.939690113067627 seconds for one epoch ---
--- 0.33956050872802734 seconds for one epoch ---
--- 0.9395265579223633 seconds for one epoch ---
--- 0.33766961097717285 seconds for one epoch ---
--- 0.9301397800445557 seconds for one epoch ---
--- 0.3365299701690674 seconds for one epoch ---
--- 0.9279241561889648 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.18720275]
 [0.        ]
 [0.        ]
 [0.1319091 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999666 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1698806]
 [ 0.       ]
 [-0.       ]
 [-1.0434113]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.8452854]
 [-0.       ]]
--- 0.3168778419494629 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3102.434814453125, (1390.5404, 1.4541326, 1709.9968, 0.44358975)
   validation loss 1280.819091796875, (936.58936, 0.63747245, 343.14868, 0.44358975)
decoder loss ratio: 36285.097621, decoder SINDy loss  ratio: 0.740735
--- 0.28092169761657715 seconds for one epoch ---
--- 0.33179163932800293 seconds for one epoch ---
--- 0.9140710830688477 seconds for one epoch ---
--- 0.32997560501098633 seconds for one epoch ---
--- 0.9324119091033936 seconds for one epoch ---
--- 0.3374183177947998 seconds for one epoch ---
--- 0.9601538181304932 seconds for one epoch ---
--- 0.34117889404296875 seconds for one epoch ---
--- 0.9191219806671143 seconds for one epoch ---
--- 0.32795095443725586 seconds for one epoch ---
--- 0.908538818359375 seconds for one epoch ---
--- 0.31914353370666504 seconds for one epoch ---
--- 0.9308867454528809 seconds for one epoch ---
--- 0.32130885124206543 seconds for one epoch ---
--- 0.9399416446685791 seconds for one epoch ---
--- 0.32909655570983887 seconds for one epoch ---
--- 0.9249222278594971 seconds for one epoch ---
--- 0.3265869617462158 seconds for one epoch ---
--- 0.9375514984130859 seconds for one epoch ---
--- 0.33120131492614746 seconds for one epoch ---
--- 0.9324343204498291 seconds for one epoch ---
--- 0.3375558853149414 seconds for one epoch ---
--- 0.9480712413787842 seconds for one epoch ---
--- 0.3260354995727539 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1845915 ]
 [0.        ]
 [0.        ]
 [0.1333147 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997115]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.164636 ]
 [ 0.       ]
 [-0.       ]
 [-1.0471336]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.9289513]
 [-0.       ]]
--- 0.2785964012145996 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4694.13134765625, (1568.7983, 0.3969239, 3124.4934, 0.44288722)
   validation loss 933.7015380859375, (595.9689, 0.61162335, 336.6782, 0.44288722)
decoder loss ratio: 23088.868751, decoder SINDy loss  ratio: 0.726767
--- 0.3236818313598633 seconds for one epoch ---
--- 0.9231204986572266 seconds for one epoch ---
--- 0.3318805694580078 seconds for one epoch ---
--- 0.9308323860168457 seconds for one epoch ---
--- 0.3307669162750244 seconds for one epoch ---
--- 0.9404075145721436 seconds for one epoch ---
--- 0.32460737228393555 seconds for one epoch ---
--- 0.9181852340698242 seconds for one epoch ---
--- 0.32839345932006836 seconds for one epoch ---
--- 0.9376676082611084 seconds for one epoch ---
--- 0.3289463520050049 seconds for one epoch ---
--- 0.9482846260070801 seconds for one epoch ---
--- 0.32898926734924316 seconds for one epoch ---
--- 0.9316461086273193 seconds for one epoch ---
--- 0.3343510627746582 seconds for one epoch ---
--- 0.9520208835601807 seconds for one epoch ---
--- 0.32106876373291016 seconds for one epoch ---
--- 0.9487748146057129 seconds for one epoch ---
--- 0.33176207542419434 seconds for one epoch ---
--- 0.9720292091369629 seconds for one epoch ---
--- 0.337937593460083 seconds for one epoch ---
--- 0.9339454174041748 seconds for one epoch ---
--- 0.3284456729888916 seconds for one epoch ---
--- 0.937551736831665 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1875583 ]
 [0.        ]
 [0.        ]
 [0.13134196]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998116]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.1706017]
 [-0.       ]
 [ 0.       ]
 [-1.0419192]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.034082 ]
 [-0.       ]]
--- 0.3174905776977539 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2414.848388671875, (1239.3622, 0.7264798, 1174.3162, 0.44360954)
   validation loss 1138.3515625, (805.53076, 0.5767512, 331.8004, 0.44360954)
decoder loss ratio: 31207.660172, decoder SINDy loss  ratio: 0.716238
THRESHOLDING: 3 active coefficients
--- 0.26732540130615234 seconds for one epoch ---
--- 0.33640217781066895 seconds for one epoch ---
--- 0.923936128616333 seconds for one epoch ---
--- 0.32674431800842285 seconds for one epoch ---
--- 0.9619948863983154 seconds for one epoch ---
--- 0.32332468032836914 seconds for one epoch ---
--- 0.9445700645446777 seconds for one epoch ---
--- 0.3386859893798828 seconds for one epoch ---
--- 0.9531610012054443 seconds for one epoch ---
--- 0.32155847549438477 seconds for one epoch ---
--- 0.9396171569824219 seconds for one epoch ---
--- 0.331453800201416 seconds for one epoch ---
--- 0.9375243186950684 seconds for one epoch ---
--- 0.32628870010375977 seconds for one epoch ---
--- 0.9513847827911377 seconds for one epoch ---
--- 0.3277122974395752 seconds for one epoch ---
--- 0.966278076171875 seconds for one epoch ---
--- 0.32993006706237793 seconds for one epoch ---
--- 0.9561691284179688 seconds for one epoch ---
--- 0.3298623561859131 seconds for one epoch ---
--- 0.9474685192108154 seconds for one epoch ---
--- 0.32425522804260254 seconds for one epoch ---
--- 0.9422495365142822 seconds for one epoch ---
--- 0.3263363838195801 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.183595  ]
 [0.        ]
 [0.        ]
 [0.13473716]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999982  ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.1626267]
 [-0.       ]
 [ 0.       ]
 [-1.0508709]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.136294 ]
 [-0.       ]]
--- 0.2709462642669678 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3163.4609375, (1565.1584, 1.5770035, 1596.29, 0.43553576)
   validation loss 1339.1278076171875, (958.5452, 0.5082523, 379.63876, 0.43553576)
decoder loss ratio: 37135.706204, decoder SINDy loss  ratio: 0.819504
--- 0.31599903106689453 seconds for one epoch ---
--- 0.9342234134674072 seconds for one epoch ---
--- 0.33338093757629395 seconds for one epoch ---
--- 0.9471147060394287 seconds for one epoch ---
--- 0.33016109466552734 seconds for one epoch ---
--- 0.9561877250671387 seconds for one epoch ---
--- 0.32666802406311035 seconds for one epoch ---
--- 0.9378132820129395 seconds for one epoch ---
--- 0.31789541244506836 seconds for one epoch ---
--- 0.9458680152893066 seconds for one epoch ---
--- 0.32099270820617676 seconds for one epoch ---
--- 0.9655942916870117 seconds for one epoch ---
--- 0.3376040458679199 seconds for one epoch ---
--- 0.9517109394073486 seconds for one epoch ---
--- 0.33399462699890137 seconds for one epoch ---
--- 0.9567475318908691 seconds for one epoch ---
--- 0.32889819145202637 seconds for one epoch ---
--- 0.9626483917236328 seconds for one epoch ---
--- 0.34113049507141113 seconds for one epoch ---
--- 0.9759349822998047 seconds for one epoch ---
--- 0.335604190826416 seconds for one epoch ---
--- 0.9697108268737793 seconds for one epoch ---
--- 0.33722400665283203 seconds for one epoch ---
--- 0.9802553653717041 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.17085308]
 [0.        ]
 [0.        ]
 [0.1313132 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1360372]
 [ 0.       ]
 [-0.       ]
 [-1.0418547]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.212555 ]
 [-0.       ]]
--- 0.32581663131713867 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2520.93310546875, (1275.0302, 0.37626234, 1245.0947, 0.43207523)
   validation loss 1008.5877075195312, (670.7447, 0.5459863, 336.86502, 0.43207523)
decoder loss ratio: 25985.813752, decoder SINDy loss  ratio: 0.727171
--- 0.2810821533203125 seconds for one epoch ---
--- 0.33336663246154785 seconds for one epoch ---
--- 0.9268019199371338 seconds for one epoch ---
--- 0.3396022319793701 seconds for one epoch ---
--- 0.9667747020721436 seconds for one epoch ---
--- 0.32817673683166504 seconds for one epoch ---
--- 0.9809737205505371 seconds for one epoch ---
--- 0.3336036205291748 seconds for one epoch ---
--- 0.9619584083557129 seconds for one epoch ---
--- 0.33139705657958984 seconds for one epoch ---
--- 0.9830014705657959 seconds for one epoch ---
--- 0.3241117000579834 seconds for one epoch ---
--- 0.9843292236328125 seconds for one epoch ---
--- 0.3285343647003174 seconds for one epoch ---
--- 0.987957239151001 seconds for one epoch ---
--- 0.3452579975128174 seconds for one epoch ---
--- 0.9761323928833008 seconds for one epoch ---
--- 0.34053683280944824 seconds for one epoch ---
--- 0.983673095703125 seconds for one epoch ---
--- 0.3291587829589844 seconds for one epoch ---
--- 0.9874758720397949 seconds for one epoch ---
--- 0.33635711669921875 seconds for one epoch ---
--- 0.9604558944702148 seconds for one epoch ---
--- 0.338442325592041 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.17135683]
 [0.        ]
 [0.        ]
 [0.13348357]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999935 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.1371214]
 [ 0.       ]
 [-0.       ]
 [-1.0476011]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.320338 ]
 [-0.       ]]
--- 0.2777853012084961 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3568.951171875, (1938.1066, 1.304293, 1629.1072, 0.43317887)
   validation loss 1070.52490234375, (734.86414, 0.6264216, 334.60114, 0.43317887)
decoder loss ratio: 28469.912399, decoder SINDy loss  ratio: 0.722284
--- 0.33422160148620605 seconds for one epoch ---
--- 0.9703445434570312 seconds for one epoch ---
--- 0.344527006149292 seconds for one epoch ---
--- 1.0011160373687744 seconds for one epoch ---
--- 0.32495737075805664 seconds for one epoch ---
--- 1.0024967193603516 seconds for one epoch ---
--- 0.32692551612854004 seconds for one epoch ---
--- 0.9995288848876953 seconds for one epoch ---
--- 0.3424265384674072 seconds for one epoch ---
--- 0.9967606067657471 seconds for one epoch ---
--- 0.33481836318969727 seconds for one epoch ---
--- 1.008777141571045 seconds for one epoch ---
--- 0.33713507652282715 seconds for one epoch ---
--- 0.9706623554229736 seconds for one epoch ---
--- 0.3340444564819336 seconds for one epoch ---
--- 0.9859602451324463 seconds for one epoch ---
--- 0.3383195400238037 seconds for one epoch ---
--- 0.9888186454772949 seconds for one epoch ---
--- 0.33542895317077637 seconds for one epoch ---
--- 0.9707634449005127 seconds for one epoch ---
--- 0.3227097988128662 seconds for one epoch ---
--- 0.9958038330078125 seconds for one epoch ---
--- 0.3368494510650635 seconds for one epoch ---
--- 0.9775960445404053 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1703249 ]
 [0.        ]
 [0.        ]
 [0.12860304]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999934 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1349088]
 [-0.       ]
 [ 0.       ]
 [-1.0345819]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.4121246]
 [-0.       ]]
--- 0.31206655502319336 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2366.019775390625, (1164.7806, 0.51678973, 1200.2905, 0.431895)
   validation loss 1144.8299560546875, (774.6154, 0.5141591, 369.26846, 0.431895)
decoder loss ratio: 30009.946065, decoder SINDy loss  ratio: 0.797118
--- 0.2758350372314453 seconds for one epoch ---
--- 0.336397647857666 seconds for one epoch ---
--- 1.0119614601135254 seconds for one epoch ---
--- 0.3335764408111572 seconds for one epoch ---
--- 0.9759664535522461 seconds for one epoch ---
--- 0.3364276885986328 seconds for one epoch ---
--- 0.9774281978607178 seconds for one epoch ---
--- 0.3239779472351074 seconds for one epoch ---
--- 0.9699320793151855 seconds for one epoch ---
--- 0.32833027839660645 seconds for one epoch ---
--- 1.0157365798950195 seconds for one epoch ---
--- 0.33243608474731445 seconds for one epoch ---
--- 0.9862570762634277 seconds for one epoch ---
--- 0.32894110679626465 seconds for one epoch ---
--- 1.0206363201141357 seconds for one epoch ---
--- 0.3254234790802002 seconds for one epoch ---
--- 0.9836838245391846 seconds for one epoch ---
--- 0.3292248249053955 seconds for one epoch ---
--- 0.9918239116668701 seconds for one epoch ---
--- 0.3264129161834717 seconds for one epoch ---
--- 0.9950973987579346 seconds for one epoch ---
--- 0.3172757625579834 seconds for one epoch ---
--- 1.0014214515686035 seconds for one epoch ---
--- 0.3328859806060791 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.15813597]
 [0.        ]
 [0.        ]
 [0.1294936 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999933 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1078953]
 [-0.       ]
 [ 0.       ]
 [-1.0369927]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.5081015]
 [-0.       ]]
--- 0.2734544277191162 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2467.125, (1166.692, 2.3740993, 1297.629, 0.42970845)
   validation loss 1266.45263671875, (902.947, 0.59954363, 362.4764, 0.42970845)
decoder loss ratio: 34981.735197, decoder SINDy loss  ratio: 0.782456
--- 0.32720470428466797 seconds for one epoch ---
--- 0.9924969673156738 seconds for one epoch ---
--- 0.3318653106689453 seconds for one epoch ---
--- 0.9837691783905029 seconds for one epoch ---
--- 0.3398895263671875 seconds for one epoch ---
--- 1.0176661014556885 seconds for one epoch ---
--- 0.3338019847869873 seconds for one epoch ---
--- 0.9812321662902832 seconds for one epoch ---
--- 0.33543992042541504 seconds for one epoch ---
--- 1.0080928802490234 seconds for one epoch ---
--- 0.33774685859680176 seconds for one epoch ---
--- 1.025554895401001 seconds for one epoch ---
--- 0.3367795944213867 seconds for one epoch ---
--- 0.9935290813446045 seconds for one epoch ---
--- 0.3286933898925781 seconds for one epoch ---
--- 0.9953453540802002 seconds for one epoch ---
--- 0.3368520736694336 seconds for one epoch ---
--- 1.0029714107513428 seconds for one epoch ---
--- 0.3271973133087158 seconds for one epoch ---
--- 1.0114507675170898 seconds for one epoch ---
--- 0.33562278747558594 seconds for one epoch ---
--- 1.0082602500915527 seconds for one epoch ---
--- 0.3207664489746094 seconds for one epoch ---
--- 1.0361604690551758 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.16110763]
 [0.        ]
 [0.        ]
 [0.12624434]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999326]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-1.114634 ]
 [ 0.       ]
 [-0.       ]
 [-1.0281444]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.5922384]
 [-0.       ]]
--- 0.3170945644378662 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2800.45849609375, (1506.5403, 2.0003967, 1291.4883, 0.42974758)
   validation loss 1925.5712890625, (1548.6583, 0.61208886, 375.87125, 0.42974758)
decoder loss ratio: 59997.712107, decoder SINDy loss  ratio: 0.811371
--- 0.2790236473083496 seconds for one epoch ---
--- 0.33178019523620605 seconds for one epoch ---
--- 0.9996728897094727 seconds for one epoch ---
--- 0.314084529876709 seconds for one epoch ---
--- 0.9876947402954102 seconds for one epoch ---
--- 0.3276364803314209 seconds for one epoch ---
--- 0.9766123294830322 seconds for one epoch ---
--- 0.3281099796295166 seconds for one epoch ---
--- 1.0280015468597412 seconds for one epoch ---
--- 0.32697415351867676 seconds for one epoch ---
--- 1.0146057605743408 seconds for one epoch ---
--- 0.3385813236236572 seconds for one epoch ---
--- 1.0095922946929932 seconds for one epoch ---
--- 0.3241422176361084 seconds for one epoch ---
--- 1.000631332397461 seconds for one epoch ---
--- 0.3254828453063965 seconds for one epoch ---
--- 1.021761417388916 seconds for one epoch ---
--- 0.3286459445953369 seconds for one epoch ---
--- 1.0188653469085693 seconds for one epoch ---
--- 0.33110761642456055 seconds for one epoch ---
--- 1.0208206176757812 seconds for one epoch ---
--- 0.3253672122955322 seconds for one epoch ---
--- 1.0225281715393066 seconds for one epoch ---
--- 0.3326725959777832 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1612978 ]
 [0.        ]
 [0.        ]
 [0.12116048]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999326]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.1150647]
 [ 0.       ]
 [-0.       ]
 [-1.0139004]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.6869082]
 [-0.       ]]
--- 0.2704041004180908 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2410.0849609375, (1172.7426, 0.31082258, 1236.602, 0.42965785)
   validation loss 1205.2340087890625, (853.72327, 0.5376466, 350.5434, 0.42965785)
decoder loss ratio: 33074.721477, decoder SINDy loss  ratio: 0.756697
--- 0.32058191299438477 seconds for one epoch ---
--- 0.9929625988006592 seconds for one epoch ---
--- 0.33576536178588867 seconds for one epoch ---
--- 1.0073051452636719 seconds for one epoch ---
--- 0.32596898078918457 seconds for one epoch ---
--- 1.008716344833374 seconds for one epoch ---
--- 0.3316304683685303 seconds for one epoch ---
--- 1.0035533905029297 seconds for one epoch ---
--- 0.33215904235839844 seconds for one epoch ---
--- 1.0308101177215576 seconds for one epoch ---
--- 0.32864952087402344 seconds for one epoch ---
--- 1.0301165580749512 seconds for one epoch ---
--- 0.34299397468566895 seconds for one epoch ---
--- 1.016230583190918 seconds for one epoch ---
--- 0.3238868713378906 seconds for one epoch ---
--- 1.0175282955169678 seconds for one epoch ---
--- 0.33059144020080566 seconds for one epoch ---
--- 1.030642032623291 seconds for one epoch ---
--- 0.3344767093658447 seconds for one epoch ---
--- 1.0439398288726807 seconds for one epoch ---
--- 0.32348108291625977 seconds for one epoch ---
--- 1.0369515419006348 seconds for one epoch ---
--- 0.34477996826171875 seconds for one epoch ---
--- 1.047579050064087 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.15660381]
 [0.        ]
 [0.        ]
 [0.11908191]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999315]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.1043893]
 [-0.       ]
 [ 0.       ]
 [-1.0079302]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.786815 ]
 [-0.       ]]
--- 0.31296420097351074 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3969.606689453125, (2563.1665, 0.54197466, 1405.4694, 0.42896014)
   validation loss 1119.620849609375, (786.45703, 0.6163778, 332.1185, 0.42896014)
decoder loss ratio: 30468.710740, decoder SINDy loss  ratio: 0.716924
--- 0.2714059352874756 seconds for one epoch ---
--- 0.3200533390045166 seconds for one epoch ---
--- 1.0252227783203125 seconds for one epoch ---
--- 0.32552075386047363 seconds for one epoch ---
--- 1.0326123237609863 seconds for one epoch ---
--- 0.328662633895874 seconds for one epoch ---
--- 1.0122919082641602 seconds for one epoch ---
--- 0.3270394802093506 seconds for one epoch ---
--- 1.0588314533233643 seconds for one epoch ---
--- 0.32791733741760254 seconds for one epoch ---
--- 1.0428435802459717 seconds for one epoch ---
--- 0.5571272373199463 seconds for one epoch ---
--- 1.0412635803222656 seconds for one epoch ---
--- 0.33133459091186523 seconds for one epoch ---
--- 1.046888828277588 seconds for one epoch ---
--- 0.32805562019348145 seconds for one epoch ---
--- 1.0476443767547607 seconds for one epoch ---
--- 0.3274672031402588 seconds for one epoch ---
--- 1.0342540740966797 seconds for one epoch ---
--- 0.32714366912841797 seconds for one epoch ---
--- 1.0372471809387207 seconds for one epoch ---
--- 0.31963181495666504 seconds for one epoch ---
--- 1.0593788623809814 seconds for one epoch ---
--- 0.3278467655181885 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14876756]
 [0.        ]
 [0.        ]
 [0.12583782]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999993  ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-1.0859741]
 [-0.       ]
 [ 0.       ]
 [-1.0270317]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.878655 ]
 [-0.       ]]
--- 0.2778744697570801 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2949.57568359375, (1176.623, 3.808974, 1768.7148, 0.4286897)
   validation loss 1190.1934814453125, (833.1081, 0.6920464, 355.9647, 0.4286897)
decoder loss ratio: 32276.053872, decoder SINDy loss  ratio: 0.768400
--- 0.3239104747772217 seconds for one epoch ---
--- 1.0445117950439453 seconds for one epoch ---
--- 0.33803415298461914 seconds for one epoch ---
--- 1.0329008102416992 seconds for one epoch ---
--- 0.31795358657836914 seconds for one epoch ---
--- 1.02742600440979 seconds for one epoch ---
--- 0.32730770111083984 seconds for one epoch ---
--- 1.023555040359497 seconds for one epoch ---
--- 0.3287932872772217 seconds for one epoch ---
--- 1.0596230030059814 seconds for one epoch ---
--- 0.32605695724487305 seconds for one epoch ---
--- 1.0558979511260986 seconds for one epoch ---
--- 0.32842159271240234 seconds for one epoch ---
--- 1.0458261966705322 seconds for one epoch ---
--- 0.3266181945800781 seconds for one epoch ---
--- 1.038961410522461 seconds for one epoch ---
--- 0.3211352825164795 seconds for one epoch ---
--- 1.068099021911621 seconds for one epoch ---
--- 0.3273448944091797 seconds for one epoch ---
--- 1.0622591972351074 seconds for one epoch ---
--- 0.3291513919830322 seconds for one epoch ---
--- 1.0392427444458008 seconds for one epoch ---
--- 0.3331601619720459 seconds for one epoch ---
--- 1.0661628246307373 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.15100291]
 [0.        ]
 [0.        ]
 [0.1191971 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999929 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.0913086]
 [ 0.       ]
 [-0.       ]
 [-1.0082686]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.9765596]
 [-0.       ]]
--- 0.31670618057250977 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2738.5771484375, (1378.3254, 1.0684856, 1358.7548, 0.42840824)
   validation loss 1150.48193359375, (813.304, 0.6903668, 336.05902, 0.42840824)
decoder loss ratio: 31508.809542, decoder SINDy loss  ratio: 0.725431
--- 0.2726263999938965 seconds for one epoch ---
--- 0.3380708694458008 seconds for one epoch ---
--- 1.0580692291259766 seconds for one epoch ---
--- 0.33057284355163574 seconds for one epoch ---
--- 1.052518606185913 seconds for one epoch ---
--- 0.3314189910888672 seconds for one epoch ---
--- 1.0441930294036865 seconds for one epoch ---
--- 0.34071874618530273 seconds for one epoch ---
--- 1.0730490684509277 seconds for one epoch ---
--- 0.3386728763580322 seconds for one epoch ---
--- 1.0841150283813477 seconds for one epoch ---
--- 0.3325920104980469 seconds for one epoch ---
--- 1.0818250179290771 seconds for one epoch ---
--- 0.3316524028778076 seconds for one epoch ---
--- 1.0517234802246094 seconds for one epoch ---
--- 0.32016515731811523 seconds for one epoch ---
--- 1.0736167430877686 seconds for one epoch ---
--- 0.3276708126068115 seconds for one epoch ---
--- 1.0877153873443604 seconds for one epoch ---
--- 0.32316136360168457 seconds for one epoch ---
--- 1.094780445098877 seconds for one epoch ---
--- 0.3291435241699219 seconds for one epoch ---
--- 1.0609138011932373 seconds for one epoch ---
--- 0.32258152961730957 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14911938]
 [0.        ]
 [0.        ]
 [0.12222371]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999297]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-1.0868213]
 [ 0.       ]
 [-0.       ]
 [-1.0169313]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.073283 ]
 [-0.       ]]
--- 0.2731022834777832 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2802.089599609375, (1281.2965, 1.3911994, 1518.9722, 0.42974052)
   validation loss 986.8377075195312, (640.5507, 0.518702, 345.3386, 0.42974052)
decoder loss ratio: 24816.046946, decoder SINDy loss  ratio: 0.745462
--- 0.3357722759246826 seconds for one epoch ---
--- 1.0472667217254639 seconds for one epoch ---
--- 0.330211877822876 seconds for one epoch ---
--- 1.0636744499206543 seconds for one epoch ---
--- 0.33048510551452637 seconds for one epoch ---
--- 1.0789084434509277 seconds for one epoch ---
--- 0.3352017402648926 seconds for one epoch ---
--- 1.0617523193359375 seconds for one epoch ---
--- 0.34061264991760254 seconds for one epoch ---
--- 1.069354772567749 seconds for one epoch ---
--- 0.3253457546234131 seconds for one epoch ---
--- 1.0619232654571533 seconds for one epoch ---
--- 0.32732677459716797 seconds for one epoch ---
--- 1.0797972679138184 seconds for one epoch ---
--- 0.336092472076416 seconds for one epoch ---
--- 1.0939083099365234 seconds for one epoch ---
--- 0.33585453033447266 seconds for one epoch ---
--- 1.077625036239624 seconds for one epoch ---
--- 0.3314664363861084 seconds for one epoch ---
--- 1.1006686687469482 seconds for one epoch ---
--- 0.34766292572021484 seconds for one epoch ---
--- 1.094895601272583 seconds for one epoch ---
--- 0.329164981842041 seconds for one epoch ---
--- 1.1014196872711182 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14724627]
 [0.        ]
 [0.        ]
 [0.12520139]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.0823115]
 [-0.       ]
 [ 0.       ]
 [-1.0252763]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.1675634]
 [-0.       ]]
--- 0.317471981048584 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2825.718505859375, (1274.8019, 1.1106563, 1549.3756, 0.4305164)
   validation loss 1389.7047119140625, (1020.55994, 0.6220784, 368.09213, 0.4305164)
decoder loss ratio: 39538.263711, decoder SINDy loss  ratio: 0.794579
--- 0.27887439727783203 seconds for one epoch ---
--- 0.3331460952758789 seconds for one epoch ---
--- 1.0662872791290283 seconds for one epoch ---
--- 0.3229360580444336 seconds for one epoch ---
--- 1.064903736114502 seconds for one epoch ---
--- 0.3307077884674072 seconds for one epoch ---
--- 1.0600111484527588 seconds for one epoch ---
--- 0.32468652725219727 seconds for one epoch ---
--- 1.1002800464630127 seconds for one epoch ---
--- 0.33005595207214355 seconds for one epoch ---
--- 1.0931921005249023 seconds for one epoch ---
--- 0.32480382919311523 seconds for one epoch ---
--- 1.0757782459259033 seconds for one epoch ---
--- 0.3030109405517578 seconds for one epoch ---
--- 1.0842509269714355 seconds for one epoch ---
--- 0.3248777389526367 seconds for one epoch ---
--- 1.071425199508667 seconds for one epoch ---
--- 0.3247537612915039 seconds for one epoch ---
--- 1.0932135581970215 seconds for one epoch ---
--- 0.31873345375061035 seconds for one epoch ---
--- 1.0723187923431396 seconds for one epoch ---
--- 0.33078455924987793 seconds for one epoch ---
--- 1.1242544651031494 seconds for one epoch ---
--- 0.32663607597351074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14396988]
 [0.        ]
 [0.        ]
 [0.12199236]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999964 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.0743078]
 [-0.       ]
 [ 0.       ]
 [-1.0162793]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.267063 ]
 [-0.       ]]
--- 0.267423152923584 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2613.88525390625, (1226.1641, 2.7349608, 1384.5563, 0.42986393)
   validation loss 1211.5892333984375, (910.84467, 0.6931285, 299.62164, 0.42986393)
decoder loss ratio: 35287.703638, decoder SINDy loss  ratio: 0.646775
--- 0.31462860107421875 seconds for one epoch ---
--- 1.100452184677124 seconds for one epoch ---
--- 0.33286476135253906 seconds for one epoch ---
--- 1.0992803573608398 seconds for one epoch ---
--- 0.3267982006072998 seconds for one epoch ---
--- 1.0996203422546387 seconds for one epoch ---
--- 0.32822275161743164 seconds for one epoch ---
--- 1.0967180728912354 seconds for one epoch ---
--- 0.3265962600708008 seconds for one epoch ---
--- 1.100539207458496 seconds for one epoch ---
--- 0.32738685607910156 seconds for one epoch ---
--- 1.1161201000213623 seconds for one epoch ---
--- 0.327350378036499 seconds for one epoch ---
--- 1.0970213413238525 seconds for one epoch ---
--- 0.3275716304779053 seconds for one epoch ---
--- 1.1027252674102783 seconds for one epoch ---
--- 0.3252995014190674 seconds for one epoch ---
--- 1.1135597229003906 seconds for one epoch ---
--- 0.3240082263946533 seconds for one epoch ---
--- 1.1141071319580078 seconds for one epoch ---
--- 0.327603816986084 seconds for one epoch ---
--- 1.120208978652954 seconds for one epoch ---
--- 0.32712459564208984 seconds for one epoch ---
--- 1.1216490268707275 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14435902]
 [0.        ]
 [0.        ]
 [0.12109321]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-1.075268]
 [ 0.      ]
 [-0.      ]
 [-1.013723]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.35913 ]
 [-0.      ]]
--- 0.3041701316833496 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1372.64013671875, (751.4718, 4.284712, 616.45294, 0.43064785)
   validation loss 1533.207763671875, (1173.4066, 0.5756493, 358.79477, 0.43064785)
decoder loss ratio: 45459.809435, decoder SINDy loss  ratio: 0.774509
--- 0.2736382484436035 seconds for one epoch ---
--- 0.32212376594543457 seconds for one epoch ---
--- 1.1062235832214355 seconds for one epoch ---
--- 0.32888364791870117 seconds for one epoch ---
--- 1.0954184532165527 seconds for one epoch ---
--- 0.33081769943237305 seconds for one epoch ---
--- 1.1175425052642822 seconds for one epoch ---
--- 0.32830357551574707 seconds for one epoch ---
--- 1.1170761585235596 seconds for one epoch ---
--- 0.3241138458251953 seconds for one epoch ---
--- 1.096975564956665 seconds for one epoch ---
--- 0.33682823181152344 seconds for one epoch ---
--- 1.100846767425537 seconds for one epoch ---
--- 0.3267552852630615 seconds for one epoch ---
--- 1.0995006561279297 seconds for one epoch ---
--- 0.32555198669433594 seconds for one epoch ---
--- 1.1222620010375977 seconds for one epoch ---
--- 0.3244156837463379 seconds for one epoch ---
--- 1.0942866802215576 seconds for one epoch ---
--- 0.3311469554901123 seconds for one epoch ---
--- 1.1185188293457031 seconds for one epoch ---
--- 0.3307762145996094 seconds for one epoch ---
--- 1.1248581409454346 seconds for one epoch ---
--- 0.32916736602783203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14145279]
 [0.        ]
 [0.        ]
 [0.12141293]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.068058 ]
 [ 0.       ]
 [-0.       ]
 [-1.0146358]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.4400578]
 [-0.       ]]
--- 0.2736690044403076 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2875.2138671875, (1042.595, 3.1756363, 1829.013, 0.4301803)
   validation loss 1061.98681640625, (736.1158, 0.6348383, 324.80597, 0.4301803)
decoder loss ratio: 28518.403413, decoder SINDy loss  ratio: 0.701139
--- 0.32253408432006836 seconds for one epoch ---
--- 1.078019618988037 seconds for one epoch ---
--- 0.33852553367614746 seconds for one epoch ---
--- 1.1027121543884277 seconds for one epoch ---
--- 0.33462095260620117 seconds for one epoch ---
--- 1.089336633682251 seconds for one epoch ---
--- 0.33443307876586914 seconds for one epoch ---
--- 1.1123342514038086 seconds for one epoch ---
--- 0.3351857662200928 seconds for one epoch ---
--- 1.1101484298706055 seconds for one epoch ---
--- 0.31833839416503906 seconds for one epoch ---
--- 1.1119883060455322 seconds for one epoch ---
--- 0.3349730968475342 seconds for one epoch ---
--- 1.1268162727355957 seconds for one epoch ---
--- 0.32926177978515625 seconds for one epoch ---
--- 1.1266860961914062 seconds for one epoch ---
--- 0.32503604888916016 seconds for one epoch ---
--- 1.1200969219207764 seconds for one epoch ---
--- 0.3308982849121094 seconds for one epoch ---
--- 1.1194355487823486 seconds for one epoch ---
--- 0.3333170413970947 seconds for one epoch ---
--- 1.1101560592651367 seconds for one epoch ---
--- 0.323742151260376 seconds for one epoch ---
--- 1.148850440979004 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14028305]
 [0.        ]
 [0.        ]
 [0.11801562]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-1.0651212]
 [-0.       ]
 [ 0.       ]
 [-1.004846 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.530399 ]
 [-0.       ]]
--- 0.31379175186157227 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4427.77001953125, (1751.4989, 1.808078, 2674.033, 0.4300823)
   validation loss 1318.89404296875, (945.8911, 0.63324326, 371.9396, 0.4300823)
decoder loss ratio: 36645.463868, decoder SINDy loss  ratio: 0.802884
--- 0.2762467861175537 seconds for one epoch ---
--- 0.33885860443115234 seconds for one epoch ---
--- 1.1076927185058594 seconds for one epoch ---
--- 0.34032487869262695 seconds for one epoch ---
--- 1.0965576171875 seconds for one epoch ---
--- 0.3464951515197754 seconds for one epoch ---
--- 1.108306646347046 seconds for one epoch ---
--- 0.33054518699645996 seconds for one epoch ---
--- 1.1565885543823242 seconds for one epoch ---
--- 0.3562896251678467 seconds for one epoch ---
--- 1.127803087234497 seconds for one epoch ---
--- 0.34443068504333496 seconds for one epoch ---
--- 1.1444313526153564 seconds for one epoch ---
--- 0.3303055763244629 seconds for one epoch ---
--- 1.1419017314910889 seconds for one epoch ---
--- 0.3374969959259033 seconds for one epoch ---
--- 1.122990608215332 seconds for one epoch ---
--- 0.32932496070861816 seconds for one epoch ---
--- 1.1503679752349854 seconds for one epoch ---
--- 0.325702428817749 seconds for one epoch ---
--- 1.1413371562957764 seconds for one epoch ---
--- 0.32144689559936523 seconds for one epoch ---
--- 1.1194112300872803 seconds for one epoch ---
--- 0.32828712463378906 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.137816  ]
 [0.        ]
 [0.        ]
 [0.12412383]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-1.0588598]
 [-0.       ]
 [ 0.       ]
 [-1.0222832]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.621151 ]
 [-0.       ]]
--- 0.2719688415527344 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3346.688720703125, (1350.5773, 1.2284052, 1994.451, 0.43188468)
   validation loss 2159.5927734375, (1752.1375, 0.6704646, 406.35306, 0.43188468)
decoder loss ratio: 67880.846703, decoder SINDy loss  ratio: 0.877170
--- 0.34007787704467773 seconds for one epoch ---
--- 1.1094961166381836 seconds for one epoch ---
--- 0.32465672492980957 seconds for one epoch ---
--- 1.1329326629638672 seconds for one epoch ---
--- 0.3252871036529541 seconds for one epoch ---
--- 1.1113574504852295 seconds for one epoch ---
--- 0.32946252822875977 seconds for one epoch ---
--- 1.1449778079986572 seconds for one epoch ---
--- 0.32943010330200195 seconds for one epoch ---
--- 1.143423318862915 seconds for one epoch ---
--- 0.33020639419555664 seconds for one epoch ---
--- 1.1554474830627441 seconds for one epoch ---
--- 0.32209134101867676 seconds for one epoch ---
--- 1.1410324573516846 seconds for one epoch ---
--- 0.32834839820861816 seconds for one epoch ---
--- 1.1522064208984375 seconds for one epoch ---
--- 0.32317423820495605 seconds for one epoch ---
--- 1.1602632999420166 seconds for one epoch ---
--- 0.32358717918395996 seconds for one epoch ---
--- 1.1556241512298584 seconds for one epoch ---
--- 0.33003830909729004 seconds for one epoch ---
--- 1.1607797145843506 seconds for one epoch ---
--- 0.33224987983703613 seconds for one epoch ---
--- 1.1374197006225586 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.14176944]
 [0.        ]
 [0.        ]
 [0.1185042 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.0688515]
 [ 0.       ]
 [-0.       ]
 [-1.006271 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.704088 ]
 [-0.       ]]
--- 0.3055720329284668 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3233.501708984375, (1262.8055, 3.8907838, 1966.3732, 0.4323001)
   validation loss 975.8005981445312, (658.5517, 0.5643519, 316.25223, 0.4323001)
decoder loss ratio: 25513.436029, decoder SINDy loss  ratio: 0.682675
--- 0.27985048294067383 seconds for one epoch ---
--- 0.32859349250793457 seconds for one epoch ---
--- 1.1333770751953125 seconds for one epoch ---
--- 0.3261754512786865 seconds for one epoch ---
--- 1.1452932357788086 seconds for one epoch ---
--- 0.33152294158935547 seconds for one epoch ---
--- 1.1671180725097656 seconds for one epoch ---
--- 0.32741785049438477 seconds for one epoch ---
--- 1.1540517807006836 seconds for one epoch ---
--- 0.32706427574157715 seconds for one epoch ---
--- 1.1756131649017334 seconds for one epoch ---
--- 0.3232541084289551 seconds for one epoch ---
--- 1.1355171203613281 seconds for one epoch ---
--- 0.32787656784057617 seconds for one epoch ---
--- 1.1416785717010498 seconds for one epoch ---
--- 0.3320760726928711 seconds for one epoch ---
--- 1.1613130569458008 seconds for one epoch ---
--- 0.3247363567352295 seconds for one epoch ---
--- 1.1451115608215332 seconds for one epoch ---
--- 0.32614707946777344 seconds for one epoch ---
--- 1.158249855041504 seconds for one epoch ---
--- 0.3291480541229248 seconds for one epoch ---
--- 1.173069715499878 seconds for one epoch ---
--- 0.3237571716308594 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1348775 ]
 [0.        ]
 [0.        ]
 [0.11811264]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.0512786]
 [ 0.       ]
 [-0.       ]
 [-1.0051317]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.782262 ]
 [-0.       ]]
--- 0.27194952964782715 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2534.843994140625, (1022.0926, 1.0701295, 1511.251, 0.4305314)
   validation loss 1033.02294921875, (693.33777, 0.49259785, 338.76202, 0.4305314)
decoder loss ratio: 26861.108841, decoder SINDy loss  ratio: 0.731265
--- 0.3385050296783447 seconds for one epoch ---
--- 1.1417675018310547 seconds for one epoch ---
--- 0.3386261463165283 seconds for one epoch ---
--- 1.1340911388397217 seconds for one epoch ---
--- 0.3215157985687256 seconds for one epoch ---
--- 1.1398344039916992 seconds for one epoch ---
--- 0.3312342166900635 seconds for one epoch ---
--- 1.157639503479004 seconds for one epoch ---
--- 0.34403347969055176 seconds for one epoch ---
--- 1.1541895866394043 seconds for one epoch ---
--- 0.34306764602661133 seconds for one epoch ---
--- 1.1677749156951904 seconds for one epoch ---
--- 0.33788013458251953 seconds for one epoch ---
--- 1.1778736114501953 seconds for one epoch ---
--- 0.336289644241333 seconds for one epoch ---
--- 1.19677734375 seconds for one epoch ---
--- 0.34546875953674316 seconds for one epoch ---
--- 1.170088768005371 seconds for one epoch ---
--- 0.3329808712005615 seconds for one epoch ---
--- 1.1621575355529785 seconds for one epoch ---
--- 0.33387017250061035 seconds for one epoch ---
--- 1.1645030975341797 seconds for one epoch ---
--- 0.3459956645965576 seconds for one epoch ---
--- 1.1515941619873047 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.13540766]
 [0.        ]
 [0.        ]
 [0.11513574]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-1.0526575]
 [-0.       ]
 [ 0.       ]
 [-0.996358 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.8640165]
 [-0.       ]]
--- 0.32369017601013184 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2469.5107421875, (1119.509, 0.7946594, 1348.7766, 0.4305137)
   validation loss 799.4497680664062, (494.51935, 0.49004656, 304.00983, 0.4305137)
decoder loss ratio: 19158.538070, decoder SINDy loss  ratio: 0.656248
THRESHOLDING: 3 active coefficients
--- 1.149749755859375 seconds for one epoch ---
--- 0.3303210735321045 seconds for one epoch ---
--- 1.1636173725128174 seconds for one epoch ---
--- 0.3307919502258301 seconds for one epoch ---
--- 1.1979615688323975 seconds for one epoch ---
--- 0.32535719871520996 seconds for one epoch ---
--- 1.1840620040893555 seconds for one epoch ---
--- 0.3396797180175781 seconds for one epoch ---
--- 1.1719179153442383 seconds for one epoch ---
--- 0.33463144302368164 seconds for one epoch ---
--- 1.1743888854980469 seconds for one epoch ---
--- 0.34253382682800293 seconds for one epoch ---
--- 1.1789991855621338 seconds for one epoch ---
--- 0.338604211807251 seconds for one epoch ---
--- 1.170135498046875 seconds for one epoch ---
--- 0.32701945304870605 seconds for one epoch ---
--- 1.1810345649719238 seconds for one epoch ---
--- 0.33519434928894043 seconds for one epoch ---
--- 1.1781866550445557 seconds for one epoch ---
--- 0.3460824489593506 seconds for one epoch ---
--- 1.2097983360290527 seconds for one epoch ---
--- 0.3291347026824951 seconds for one epoch ---
--- 1.1748602390289307 seconds for one epoch ---
--- 0.3281540870666504 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12879355]
 [0.        ]
 [0.        ]
 [0.1188712 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-1.0351282]
 [-0.       ]
 [ 0.       ]
 [-1.0073385]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.934586 ]
 [-0.       ]]
--- 0.2711005210876465 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6080.9677734375, (1910.2135, 0.2728839, 4170.051, 0.43090415)
   validation loss 1049.7542724609375, (714.64404, 0.5015526, 334.17776, 0.43090415)
decoder loss ratio: 27686.550901, decoder SINDy loss  ratio: 0.721370
--- 0.3129706382751465 seconds for one epoch ---
--- 1.2027082443237305 seconds for one epoch ---
--- 0.3398704528808594 seconds for one epoch ---
--- 1.1951439380645752 seconds for one epoch ---
--- 0.3329284191131592 seconds for one epoch ---
--- 1.1679637432098389 seconds for one epoch ---
--- 0.3358311653137207 seconds for one epoch ---
--- 1.1831047534942627 seconds for one epoch ---
--- 0.3331642150878906 seconds for one epoch ---
--- 1.1654131412506104 seconds for one epoch ---
--- 0.34429931640625 seconds for one epoch ---
--- 1.1977698802947998 seconds for one epoch ---
--- 0.34204840660095215 seconds for one epoch ---
--- 1.1748242378234863 seconds for one epoch ---
--- 0.3295605182647705 seconds for one epoch ---
--- 1.1783087253570557 seconds for one epoch ---
--- 0.3353464603424072 seconds for one epoch ---
--- 1.187718391418457 seconds for one epoch ---
--- 0.33537817001342773 seconds for one epoch ---
--- 1.2106983661651611 seconds for one epoch ---
--- 0.33106040954589844 seconds for one epoch ---
--- 1.1848876476287842 seconds for one epoch ---
--- 0.33247852325439453 seconds for one epoch ---
--- 1.2156085968017578 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12861404]
 [0.        ]
 [0.        ]
 [0.1156485 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.034642 ]
 [ 0.       ]
 [-0.       ]
 [-0.9978846]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.0239677]
 [-0.       ]]
--- 0.3113269805908203 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2857.1748046875, (1118.3394, 2.016437, 1736.3889, 0.43023786)
   validation loss 909.3091430664062, (598.4587, 0.57233644, 309.84787, 0.43023786)
decoder loss ratio: 23185.328202, decoder SINDy loss  ratio: 0.668850
--- 0.2826099395751953 seconds for one epoch ---
--- 0.3171985149383545 seconds for one epoch ---
--- 1.1625211238861084 seconds for one epoch ---
--- 0.33173346519470215 seconds for one epoch ---
--- 1.2003297805786133 seconds for one epoch ---
--- 0.3311648368835449 seconds for one epoch ---
--- 1.1843507289886475 seconds for one epoch ---
--- 0.315518856048584 seconds for one epoch ---
--- 1.2213857173919678 seconds for one epoch ---
--- 0.33516764640808105 seconds for one epoch ---
--- 1.1987297534942627 seconds for one epoch ---
--- 0.3368868827819824 seconds for one epoch ---
--- 1.1949644088745117 seconds for one epoch ---
--- 0.32309699058532715 seconds for one epoch ---
--- 1.2240278720855713 seconds for one epoch ---
--- 0.3332996368408203 seconds for one epoch ---
--- 1.2005949020385742 seconds for one epoch ---
--- 0.33475208282470703 seconds for one epoch ---
--- 1.210578441619873 seconds for one epoch ---
--- 0.3355541229248047 seconds for one epoch ---
--- 1.232558012008667 seconds for one epoch ---
--- 0.336104154586792 seconds for one epoch ---
--- 1.1913518905639648 seconds for one epoch ---
--- 0.33505916595458984 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.1278267]
 [0.       ]
 [0.       ]
 [0.1157525]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-1.0325036]
 [ 0.       ]
 [-0.       ]
 [-0.9981939]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-7.077748 ]
 [-0.       ]]
--- 0.2739555835723877 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2999.919921875, (1332.3065, 0.9853868, 1666.197, 0.43116108)
   validation loss 949.8526000976562, (637.47943, 0.4876925, 311.45435, 0.43116108)
decoder loss ratio: 24697.059876, decoder SINDy loss  ratio: 0.672318
--- 0.32741594314575195 seconds for one epoch ---
--- 1.1965627670288086 seconds for one epoch ---
--- 0.3326883316040039 seconds for one epoch ---
--- 1.1917026042938232 seconds for one epoch ---
--- 0.33303356170654297 seconds for one epoch ---
--- 1.2097949981689453 seconds for one epoch ---
--- 0.32337164878845215 seconds for one epoch ---
--- 1.1801984310150146 seconds for one epoch ---
--- 0.3293571472167969 seconds for one epoch ---
--- 1.2119920253753662 seconds for one epoch ---
--- 0.33452296257019043 seconds for one epoch ---
--- 1.1970014572143555 seconds for one epoch ---
--- 0.3277397155761719 seconds for one epoch ---
--- 1.2027316093444824 seconds for one epoch ---
--- 0.32778024673461914 seconds for one epoch ---
--- 1.1932079792022705 seconds for one epoch ---
--- 0.3379967212677002 seconds for one epoch ---
--- 1.193389892578125 seconds for one epoch ---
--- 0.3299732208251953 seconds for one epoch ---
--- 1.2084600925445557 seconds for one epoch ---
--- 0.3391740322113037 seconds for one epoch ---
--- 1.1986205577850342 seconds for one epoch ---
--- 0.33597254753112793 seconds for one epoch ---
--- 1.2188518047332764 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12966253]
 [0.        ]
 [0.        ]
 [0.11804805]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.0374756]
 [-0.       ]
 [ 0.       ]
 [-1.0049468]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-7.1456327]
 [-0.       ]]
--- 0.3203856945037842 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2868.078369140625, (1537.7367, 1.7288489, 1328.1802, 0.4326872)
   validation loss 938.8187255859375, (627.6072, 0.41069195, 310.36816, 0.4326872)
decoder loss ratio: 24314.591639, decoder SINDy loss  ratio: 0.669973
--- 0.26978468894958496 seconds for one epoch ---
--- 0.33120131492614746 seconds for one epoch ---
--- 1.2234184741973877 seconds for one epoch ---
--- 0.3374907970428467 seconds for one epoch ---
--- 1.2102947235107422 seconds for one epoch ---
--- 0.3314692974090576 seconds for one epoch ---
--- 1.2087018489837646 seconds for one epoch ---
--- 0.33013081550598145 seconds for one epoch ---
--- 1.23246431350708 seconds for one epoch ---
--- 0.33388590812683105 seconds for one epoch ---
--- 1.2137315273284912 seconds for one epoch ---
--- 0.32338595390319824 seconds for one epoch ---
--- 1.2172541618347168 seconds for one epoch ---
--- 0.33266782760620117 seconds for one epoch ---
--- 1.228011131286621 seconds for one epoch ---
--- 0.3221421241760254 seconds for one epoch ---
--- 1.2236735820770264 seconds for one epoch ---
--- 0.331676721572876 seconds for one epoch ---
--- 1.232116937637329 seconds for one epoch ---
--- 0.3300004005432129 seconds for one epoch ---
--- 1.2110693454742432 seconds for one epoch ---
--- 0.3408331871032715 seconds for one epoch ---
--- 1.2358624935150146 seconds for one epoch ---
--- 0.3528439998626709 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12383601]
 [0.        ]
 [0.        ]
 [0.11626375]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-1.0214837]
 [-0.       ]
 [ 0.       ]
 [-0.9997087]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.199221 ]
 [-0.       ]]
--- 0.27570605278015137 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1882.732177734375, (1004.94196, 0.7256788, 876.63367, 0.43096218)
   validation loss 1091.1971435546875, (737.13654, 0.64275855, 352.98697, 0.43096218)
decoder loss ratio: 28557.949116, decoder SINDy loss  ratio: 0.761972
--- 0.32997751235961914 seconds for one epoch ---
--- 1.2296648025512695 seconds for one epoch ---
--- 0.3310534954071045 seconds for one epoch ---
--- 1.2111945152282715 seconds for one epoch ---
--- 0.3288700580596924 seconds for one epoch ---
--- 1.2358567714691162 seconds for one epoch ---
--- 0.3299403190612793 seconds for one epoch ---
--- 1.247314214706421 seconds for one epoch ---
--- 0.32889723777770996 seconds for one epoch ---
--- 1.2354249954223633 seconds for one epoch ---
--- 0.3206338882446289 seconds for one epoch ---
--- 1.2314457893371582 seconds for one epoch ---
--- 0.3297114372253418 seconds for one epoch ---
--- 1.2339587211608887 seconds for one epoch ---
--- 0.3307371139526367 seconds for one epoch ---
--- 1.221487045288086 seconds for one epoch ---
--- 0.32848644256591797 seconds for one epoch ---
--- 1.2486608028411865 seconds for one epoch ---
--- 0.3307352066040039 seconds for one epoch ---
--- 1.2344565391540527 seconds for one epoch ---
--- 0.330594539642334 seconds for one epoch ---
--- 1.2459077835083008 seconds for one epoch ---
--- 0.3309147357940674 seconds for one epoch ---
--- 1.2478158473968506 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12168838]
 [0.        ]
 [0.        ]
 [0.11636771]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.0154272]
 [ 0.       ]
 [-0.       ]
 [-1.0000163]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.2740674]
 [-0.       ]]
--- 0.3175036907196045 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2228.201904296875, (1155.6425, 1.7252635, 1070.4034, 0.43091115)
   validation loss 1428.2894287109375, (1072.2766, 0.57709396, 355.00473, 0.43091115)
decoder loss ratio: 41541.857477, decoder SINDy loss  ratio: 0.766328
--- 0.2696199417114258 seconds for one epoch ---
--- 0.3231334686279297 seconds for one epoch ---
--- 1.2582252025604248 seconds for one epoch ---
--- 0.34374189376831055 seconds for one epoch ---
--- 1.2484323978424072 seconds for one epoch ---
--- 0.330172061920166 seconds for one epoch ---
--- 1.238692283630371 seconds for one epoch ---
--- 0.33322811126708984 seconds for one epoch ---
--- 1.2580244541168213 seconds for one epoch ---
--- 0.32140088081359863 seconds for one epoch ---
--- 1.222233772277832 seconds for one epoch ---
--- 0.32920408248901367 seconds for one epoch ---
--- 1.2277271747589111 seconds for one epoch ---
--- 0.327373743057251 seconds for one epoch ---
--- 1.2512474060058594 seconds for one epoch ---
--- 0.3276224136352539 seconds for one epoch ---
--- 1.231945514678955 seconds for one epoch ---
--- 0.3282339572906494 seconds for one epoch ---
--- 1.2532308101654053 seconds for one epoch ---
--- 0.31876540184020996 seconds for one epoch ---
--- 1.226668357849121 seconds for one epoch ---
--- 0.31859254837036133 seconds for one epoch ---
--- 1.2304270267486572 seconds for one epoch ---
--- 0.352588415145874 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12384966]
 [0.        ]
 [0.        ]
 [0.11523093]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.0215225]
 [ 0.       ]
 [-0.       ]
 [-0.9966453]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-7.324601 ]
 [-0.       ]]
--- 0.2670619487762451 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2522.02880859375, (1372.5249, 0.93685776, 1148.1355, 0.43171045)
   validation loss 913.5407104492188, (624.2043, 0.5220905, 288.38263, 0.43171045)
decoder loss ratio: 24182.757654, decoder SINDy loss  ratio: 0.622514
--- 0.32493066787719727 seconds for one epoch ---
--- 1.2642738819122314 seconds for one epoch ---
--- 0.3381519317626953 seconds for one epoch ---
--- 1.2567980289459229 seconds for one epoch ---
--- 0.32851576805114746 seconds for one epoch ---
--- 1.2687129974365234 seconds for one epoch ---
--- 0.33528590202331543 seconds for one epoch ---
--- 1.2607769966125488 seconds for one epoch ---
--- 0.33092761039733887 seconds for one epoch ---
--- 1.2642207145690918 seconds for one epoch ---
--- 0.32968664169311523 seconds for one epoch ---
--- 1.2727024555206299 seconds for one epoch ---
--- 0.33466219902038574 seconds for one epoch ---
--- 1.2827637195587158 seconds for one epoch ---
--- 0.3280797004699707 seconds for one epoch ---
--- 1.2654378414154053 seconds for one epoch ---
--- 0.32311153411865234 seconds for one epoch ---
--- 1.2691872119903564 seconds for one epoch ---
--- 0.3413517475128174 seconds for one epoch ---
--- 1.244443655014038 seconds for one epoch ---
--- 0.3285837173461914 seconds for one epoch ---
--- 1.235112190246582 seconds for one epoch ---
--- 0.33175039291381836 seconds for one epoch ---
--- 1.2710726261138916 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12039884]
 [0.        ]
 [0.        ]
 [0.11595774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-1.0117469 ]
 [-0.        ]
 [ 0.        ]
 [-0.99880457]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-7.384616  ]
 [-0.        ]]
--- 0.3156564235687256 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2195.978271484375, (976.1039, 1.3868054, 1218.0564, 0.43115863)
   validation loss 912.2603149414062, (626.60443, 0.57673514, 284.648, 0.43115863)
decoder loss ratio: 24275.743496, decoder SINDy loss  ratio: 0.614453
--- 0.286083459854126 seconds for one epoch ---
--- 0.3255164623260498 seconds for one epoch ---
--- 1.290867567062378 seconds for one epoch ---
--- 0.35826730728149414 seconds for one epoch ---
--- 1.294567346572876 seconds for one epoch ---
--- 0.3262462615966797 seconds for one epoch ---
--- 1.2788524627685547 seconds for one epoch ---
--- 0.32892632484436035 seconds for one epoch ---
--- 1.2687263488769531 seconds for one epoch ---
--- 0.3302795886993408 seconds for one epoch ---
--- 1.254460096359253 seconds for one epoch ---
--- 0.3347339630126953 seconds for one epoch ---
--- 1.2820279598236084 seconds for one epoch ---
--- 0.3383162021636963 seconds for one epoch ---
--- 1.2879111766815186 seconds for one epoch ---
--- 0.3346116542816162 seconds for one epoch ---
--- 1.28566575050354 seconds for one epoch ---
--- 0.34654855728149414 seconds for one epoch ---
--- 1.283390760421753 seconds for one epoch ---
--- 0.33756566047668457 seconds for one epoch ---
--- 1.3039884567260742 seconds for one epoch ---
--- 0.3337373733520508 seconds for one epoch ---
--- 1.277768850326538 seconds for one epoch ---
--- 0.33658623695373535 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11767013]
 [0.        ]
 [0.        ]
 [0.11243132]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-1.0038446 ]
 [-0.        ]
 [ 0.        ]
 [-0.98821914]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.4198623 ]
 [-0.        ]]
--- 0.2909989356994629 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2053.280029296875, (1384.713, 0.851807, 667.2853, 0.42993912)
   validation loss 1049.414306640625, (739.8902, 0.5795845, 308.51453, 0.42993912)
decoder loss ratio: 28664.630767, decoder SINDy loss  ratio: 0.665972
--- 0.3394606113433838 seconds for one epoch ---
--- 1.2596635818481445 seconds for one epoch ---
--- 0.34727978706359863 seconds for one epoch ---
--- 1.2690846920013428 seconds for one epoch ---
--- 0.3375067710876465 seconds for one epoch ---
--- 1.2991747856140137 seconds for one epoch ---
--- 0.33359432220458984 seconds for one epoch ---
--- 1.2716925144195557 seconds for one epoch ---
--- 0.33440065383911133 seconds for one epoch ---
--- 1.2824053764343262 seconds for one epoch ---
--- 0.33540964126586914 seconds for one epoch ---
--- 1.2649364471435547 seconds for one epoch ---
--- 0.33368492126464844 seconds for one epoch ---
--- 1.300567626953125 seconds for one epoch ---
--- 0.3323333263397217 seconds for one epoch ---
--- 1.2862420082092285 seconds for one epoch ---
--- 0.3259596824645996 seconds for one epoch ---
--- 1.2821166515350342 seconds for one epoch ---
--- 0.3252987861633301 seconds for one epoch ---
--- 1.2886836528778076 seconds for one epoch ---
--- 0.3298037052154541 seconds for one epoch ---
--- 1.2836835384368896 seconds for one epoch ---
--- 0.3316972255706787 seconds for one epoch ---
--- 1.304621934890747 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12032148]
 [0.        ]
 [0.        ]
 [0.11154778]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-1.0115255 ]
 [ 0.        ]
 [-0.        ]
 [-0.98552233]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.483653  ]
 [-0.        ]]
--- 0.3111155033111572 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3675.58056640625, (1977.0941, 1.9462175, 1696.1093, 0.4311431)
   validation loss 1065.8538818359375, (754.1222, 0.45289335, 310.84766, 0.4311431)
decoder loss ratio: 29216.002947, decoder SINDy loss  ratio: 0.671008
--- 0.2735116481781006 seconds for one epoch ---
--- 0.3317995071411133 seconds for one epoch ---
--- 1.2696104049682617 seconds for one epoch ---
--- 0.341336727142334 seconds for one epoch ---
--- 1.2717022895812988 seconds for one epoch ---
--- 0.33196330070495605 seconds for one epoch ---
--- 1.2920048236846924 seconds for one epoch ---
--- 0.33118677139282227 seconds for one epoch ---
--- 1.2598059177398682 seconds for one epoch ---
--- 0.5820169448852539 seconds for one epoch ---
--- 1.3033978939056396 seconds for one epoch ---
--- 0.3339529037475586 seconds for one epoch ---
--- 1.2877309322357178 seconds for one epoch ---
--- 0.34116244316101074 seconds for one epoch ---
--- 1.2764933109283447 seconds for one epoch ---
--- 0.3329653739929199 seconds for one epoch ---
--- 1.2839090824127197 seconds for one epoch ---
--- 0.3332188129425049 seconds for one epoch ---
--- 1.3013439178466797 seconds for one epoch ---
--- 0.3320591449737549 seconds for one epoch ---
--- 1.2981653213500977 seconds for one epoch ---
--- 0.32934141159057617 seconds for one epoch ---
--- 1.2933201789855957 seconds for one epoch ---
--- 0.3303546905517578 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11501889]
 [0.        ]
 [0.        ]
 [0.11144346]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.99601454]
 [ 0.        ]
 [-0.        ]
 [-0.9852025 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-7.537123  ]
 [-0.        ]]
--- 0.2788374423980713 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3269.290771484375, (1561.6522, 0.65842575, 1706.5494, 0.4307599)
   validation loss 1304.2642822265625, (943.56104, 0.42914897, 359.84326, 0.4307599)
decoder loss ratio: 36555.192596, decoder SINDy loss  ratio: 0.776772
--- 0.32231855392456055 seconds for one epoch ---
--- 1.3097190856933594 seconds for one epoch ---
--- 0.3333308696746826 seconds for one epoch ---
--- 1.2933886051177979 seconds for one epoch ---
--- 0.3311605453491211 seconds for one epoch ---
--- 1.2764394283294678 seconds for one epoch ---
--- 0.3338444232940674 seconds for one epoch ---
--- 1.3143317699432373 seconds for one epoch ---
--- 0.3327794075012207 seconds for one epoch ---
--- 1.2935938835144043 seconds for one epoch ---
--- 0.3229808807373047 seconds for one epoch ---
--- 1.323821783065796 seconds for one epoch ---
--- 0.33237361907958984 seconds for one epoch ---
--- 1.2765145301818848 seconds for one epoch ---
--- 0.3419928550720215 seconds for one epoch ---
--- 1.2920770645141602 seconds for one epoch ---
--- 0.3279433250427246 seconds for one epoch ---
--- 1.3176915645599365 seconds for one epoch ---
--- 0.3301706314086914 seconds for one epoch ---
--- 1.311903715133667 seconds for one epoch ---
--- 0.3256983757019043 seconds for one epoch ---
--- 1.3256721496582031 seconds for one epoch ---
--- 0.32999706268310547 seconds for one epoch ---
--- 1.3191683292388916 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1155179 ]
 [0.        ]
 [0.        ]
 [0.11410797]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.9975005]
 [-0.       ]
 [ 0.       ]
 [-0.9932883]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-7.602269 ]
 [-0.       ]]
--- 0.31446075439453125 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2555.351806640625, (1233.1929, 1.1121264, 1320.615, 0.43196258)
   validation loss 1021.2506103515625, (711.67084, 0.50766313, 308.64014, 0.43196258)
decoder loss ratio: 27571.363756, decoder SINDy loss  ratio: 0.666243
--- 0.28365468978881836 seconds for one epoch ---
--- 0.33190107345581055 seconds for one epoch ---
--- 1.321770429611206 seconds for one epoch ---
--- 0.33063387870788574 seconds for one epoch ---
--- 1.286909580230713 seconds for one epoch ---
--- 0.34500575065612793 seconds for one epoch ---
--- 1.3216133117675781 seconds for one epoch ---
--- 0.3304929733276367 seconds for one epoch ---
--- 1.3141930103302002 seconds for one epoch ---
--- 0.32622814178466797 seconds for one epoch ---
--- 1.3136301040649414 seconds for one epoch ---
--- 0.341536283493042 seconds for one epoch ---
--- 1.3034424781799316 seconds for one epoch ---
--- 0.3216738700866699 seconds for one epoch ---
--- 1.2965741157531738 seconds for one epoch ---
--- 0.3351123332977295 seconds for one epoch ---
--- 1.3041350841522217 seconds for one epoch ---
--- 0.3354051113128662 seconds for one epoch ---
--- 1.3489599227905273 seconds for one epoch ---
--- 0.3406236171722412 seconds for one epoch ---
--- 1.3092453479766846 seconds for one epoch ---
--- 0.331265926361084 seconds for one epoch ---
--- 1.3272113800048828 seconds for one epoch ---
--- 0.3357670307159424 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11541672]
 [0.        ]
 [0.        ]
 [0.10973969]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.99719995]
 [-0.        ]
 [ 0.        ]
 [-0.97994447]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.6507916 ]
 [-0.        ]]
--- 0.2729630470275879 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2879.13671875, (1421.4583, 0.85108286, 1456.3962, 0.4312714)
   validation loss 1241.8243408203125, (944.8789, 0.57614654, 295.938, 0.4312714)
decoder loss ratio: 36606.249210, decoder SINDy loss  ratio: 0.638824
--- 0.3305830955505371 seconds for one epoch ---
--- 1.3187665939331055 seconds for one epoch ---
--- 0.35436224937438965 seconds for one epoch ---
--- 1.309635877609253 seconds for one epoch ---
--- 0.33716773986816406 seconds for one epoch ---
--- 1.3018758296966553 seconds for one epoch ---
--- 0.3398010730743408 seconds for one epoch ---
--- 1.3206212520599365 seconds for one epoch ---
--- 0.34201931953430176 seconds for one epoch ---
--- 1.3378114700317383 seconds for one epoch ---
--- 0.32680726051330566 seconds for one epoch ---
--- 1.3068146705627441 seconds for one epoch ---
--- 0.32695817947387695 seconds for one epoch ---
--- 1.3224198818206787 seconds for one epoch ---
--- 0.344149112701416 seconds for one epoch ---
--- 1.30519700050354 seconds for one epoch ---
--- 0.32717132568359375 seconds for one epoch ---
--- 1.3238320350646973 seconds for one epoch ---
--- 0.33327746391296387 seconds for one epoch ---
--- 1.335007905960083 seconds for one epoch ---
--- 0.33307480812072754 seconds for one epoch ---
--- 1.3038578033447266 seconds for one epoch ---
--- 0.3462810516357422 seconds for one epoch ---
--- 1.3421125411987305 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11609245]
 [0.        ]
 [0.        ]
 [0.11099535]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.9992041]
 [ 0.       ]
 [-0.       ]
 [-0.9838268]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.7164803]
 [-0.       ]]
--- 0.30536437034606934 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1818.5701904296875, (608.45795, 1.3498611, 1208.3296, 0.4326943)
   validation loss 942.7909545898438, (636.6217, 0.57584184, 305.16074, 0.4326943)
decoder loss ratio: 24663.830041, decoder SINDy loss  ratio: 0.658732
--- 0.2749481201171875 seconds for one epoch ---
--- 0.337054967880249 seconds for one epoch ---
--- 1.3657948970794678 seconds for one epoch ---
--- 0.3406226634979248 seconds for one epoch ---
--- 1.3425235748291016 seconds for one epoch ---
--- 0.3384220600128174 seconds for one epoch ---
--- 1.3280882835388184 seconds for one epoch ---
--- 0.330059289932251 seconds for one epoch ---
--- 1.3416824340820312 seconds for one epoch ---
--- 0.34047627449035645 seconds for one epoch ---
--- 1.3147637844085693 seconds for one epoch ---
--- 0.3342323303222656 seconds for one epoch ---
--- 1.332031488418579 seconds for one epoch ---
--- 0.3259150981903076 seconds for one epoch ---
--- 1.345188856124878 seconds for one epoch ---
--- 0.3439345359802246 seconds for one epoch ---
--- 1.3346796035766602 seconds for one epoch ---
--- 0.32826948165893555 seconds for one epoch ---
--- 1.3216664791107178 seconds for one epoch ---
--- 0.33920931816101074 seconds for one epoch ---
--- 1.3375725746154785 seconds for one epoch ---
--- 0.3345179557800293 seconds for one epoch ---
--- 1.330826997756958 seconds for one epoch ---
--- 0.32950639724731445 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11801335]
 [0.        ]
 [0.        ]
 [0.113148  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-1.0048484]
 [ 0.       ]
 [-0.       ]
 [-0.9903946]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-7.793029 ]
 [-0.       ]]
--- 0.27962279319763184 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3307.353271484375, (1594.7242, 2.0348055, 1710.1598, 0.4344146)
   validation loss 1189.4051513671875, (873.86456, 0.55593836, 314.5502, 0.4344146)
decoder loss ratio: 33855.030266, decoder SINDy loss  ratio: 0.679001
--- 0.32200098037719727 seconds for one epoch ---
--- 1.3316357135772705 seconds for one epoch ---
--- 0.32762646675109863 seconds for one epoch ---
--- 1.3507881164550781 seconds for one epoch ---
--- 0.3362693786621094 seconds for one epoch ---
--- 1.365135669708252 seconds for one epoch ---
--- 0.33492183685302734 seconds for one epoch ---
--- 1.3317747116088867 seconds for one epoch ---
--- 0.33277225494384766 seconds for one epoch ---
--- 1.3410708904266357 seconds for one epoch ---
--- 0.33523106575012207 seconds for one epoch ---
--- 1.3678545951843262 seconds for one epoch ---
--- 0.33359313011169434 seconds for one epoch ---
--- 1.3435139656066895 seconds for one epoch ---
--- 0.3358914852142334 seconds for one epoch ---
--- 1.3782174587249756 seconds for one epoch ---
--- 0.33109188079833984 seconds for one epoch ---
--- 1.3416736125946045 seconds for one epoch ---
--- 0.3329925537109375 seconds for one epoch ---
--- 1.362511157989502 seconds for one epoch ---
--- 0.33296823501586914 seconds for one epoch ---
--- 1.3411309719085693 seconds for one epoch ---
--- 0.3272833824157715 seconds for one epoch ---
--- 1.3564658164978027 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11302154]
 [0.        ]
 [0.        ]
 [0.11240593]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.99001205]
 [-0.        ]
 [ 0.        ]
 [-0.9881434 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-7.841271  ]
 [-0.        ]]
--- 0.3212301731109619 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2942.62744140625, (1357.4872, 1.4008193, 1583.3065, 0.43296704)
   validation loss 1110.5399169921875, (805.7295, 0.39973423, 303.97778, 0.43296704)
decoder loss ratio: 31215.359335, decoder SINDy loss  ratio: 0.656179
--- 0.2799816131591797 seconds for one epoch ---
--- 0.33368372917175293 seconds for one epoch ---
--- 1.3372266292572021 seconds for one epoch ---
--- 0.331190824508667 seconds for one epoch ---
--- 1.3328020572662354 seconds for one epoch ---
--- 0.3264305591583252 seconds for one epoch ---
--- 1.3630483150482178 seconds for one epoch ---
--- 0.3280940055847168 seconds for one epoch ---
--- 1.3526978492736816 seconds for one epoch ---
--- 0.33192896842956543 seconds for one epoch ---
--- 1.3317265510559082 seconds for one epoch ---
--- 0.3160996437072754 seconds for one epoch ---
--- 1.352818250656128 seconds for one epoch ---
--- 0.3320729732513428 seconds for one epoch ---
--- 1.364060401916504 seconds for one epoch ---
--- 0.32756590843200684 seconds for one epoch ---
--- 1.3671314716339111 seconds for one epoch ---
--- 0.3367176055908203 seconds for one epoch ---
--- 1.3374381065368652 seconds for one epoch ---
--- 0.3193998336791992 seconds for one epoch ---
--- 1.360656499862671 seconds for one epoch ---
--- 0.329301118850708 seconds for one epoch ---
--- 1.3596320152282715 seconds for one epoch ---
--- 0.3401529788970947 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11120867]
 [0.        ]
 [0.        ]
 [0.11262637]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.9844829]
 [-0.       ]
 [ 0.       ]
 [-0.9888137]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.909178 ]
 [-0.       ]]
--- 0.26767683029174805 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3213.47705078125, (1037.5532, 1.0644356, 2174.426, 0.4334158)
   validation loss 1200.605712890625, (838.82965, 0.4190577, 360.92355, 0.4334158)
decoder loss ratio: 32497.716947, decoder SINDy loss  ratio: 0.779104
--- 0.32610034942626953 seconds for one epoch ---
--- 1.358764886856079 seconds for one epoch ---
--- 0.32859015464782715 seconds for one epoch ---
--- 1.3453037738800049 seconds for one epoch ---
--- 0.3450324535369873 seconds for one epoch ---
--- 1.3565802574157715 seconds for one epoch ---
--- 0.3350398540496826 seconds for one epoch ---
--- 1.364912509918213 seconds for one epoch ---
--- 0.32660794258117676 seconds for one epoch ---
--- 1.3585312366485596 seconds for one epoch ---
--- 0.3307375907897949 seconds for one epoch ---
--- 1.3504443168640137 seconds for one epoch ---
--- 0.32985877990722656 seconds for one epoch ---
--- 1.348362684249878 seconds for one epoch ---
--- 0.32616543769836426 seconds for one epoch ---
--- 1.3832454681396484 seconds for one epoch ---
--- 0.33283448219299316 seconds for one epoch ---
--- 1.3690977096557617 seconds for one epoch ---
--- 0.3288593292236328 seconds for one epoch ---
--- 1.3697917461395264 seconds for one epoch ---
--- 0.3318769931793213 seconds for one epoch ---
--- 1.3711016178131104 seconds for one epoch ---
--- 0.3353767395019531 seconds for one epoch ---
--- 1.3645439147949219 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11278637]
 [0.        ]
 [0.        ]
 [0.1119625 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.98929936]
 [ 0.        ]
 [-0.        ]
 [-0.98679197]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.9619336 ]
 [-0.        ]]
--- 0.30289626121520996 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2014.4794921875, (1060.3535, 0.2644069, 953.42694, 0.43459797)
   validation loss 1057.1744384765625, (729.8176, 0.38801488, 326.53427, 0.43459797)
decoder loss ratio: 28274.401887, decoder SINDy loss  ratio: 0.704870
--- 0.28257298469543457 seconds for one epoch ---
--- 0.3296842575073242 seconds for one epoch ---
--- 1.3949980735778809 seconds for one epoch ---
--- 0.33324408531188965 seconds for one epoch ---
--- 1.3625903129577637 seconds for one epoch ---
--- 0.3394033908843994 seconds for one epoch ---
--- 1.3600385189056396 seconds for one epoch ---
--- 0.32952880859375 seconds for one epoch ---
--- 1.363116979598999 seconds for one epoch ---
--- 0.32970571517944336 seconds for one epoch ---
--- 1.4004950523376465 seconds for one epoch ---
--- 0.33091139793395996 seconds for one epoch ---
--- 1.3950259685516357 seconds for one epoch ---
--- 0.32244420051574707 seconds for one epoch ---
--- 1.3852458000183105 seconds for one epoch ---
--- 0.3418724536895752 seconds for one epoch ---
--- 1.3627147674560547 seconds for one epoch ---
--- 0.33126282691955566 seconds for one epoch ---
--- 1.3630797863006592 seconds for one epoch ---
--- 0.3314628601074219 seconds for one epoch ---
--- 1.4007070064544678 seconds for one epoch ---
--- 0.33400797843933105 seconds for one epoch ---
--- 1.390667200088501 seconds for one epoch ---
--- 0.3294565677642822 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11222165]
 [0.        ]
 [0.        ]
 [0.1108333 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.9875827 ]
 [ 0.        ]
 [-0.        ]
 [-0.98332894]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-8.022506  ]
 [-0.        ]]
--- 0.2812795639038086 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2911.32177734375, (1366.7712, 0.80232173, 1543.3137, 0.43459064)
   validation loss 988.348876953125, (677.74554, 0.40342593, 309.76532, 0.43459064)
decoder loss ratio: 26257.039009, decoder SINDy loss  ratio: 0.668672
--- 0.33043599128723145 seconds for one epoch ---
--- 1.3871986865997314 seconds for one epoch ---
--- 0.35233569145202637 seconds for one epoch ---
--- 1.3929896354675293 seconds for one epoch ---
--- 0.3389015197753906 seconds for one epoch ---
--- 1.3949799537658691 seconds for one epoch ---
--- 0.3370077610015869 seconds for one epoch ---
--- 1.3890976905822754 seconds for one epoch ---
--- 0.33772706985473633 seconds for one epoch ---
--- 1.4142248630523682 seconds for one epoch ---
--- 0.34697794914245605 seconds for one epoch ---
--- 1.3851196765899658 seconds for one epoch ---
--- 0.33133864402770996 seconds for one epoch ---
--- 1.3737142086029053 seconds for one epoch ---
--- 0.33156895637512207 seconds for one epoch ---
--- 1.3963119983673096 seconds for one epoch ---
--- 0.3325209617614746 seconds for one epoch ---
--- 1.38480806350708 seconds for one epoch ---
--- 0.3344540596008301 seconds for one epoch ---
--- 1.3847026824951172 seconds for one epoch ---
--- 0.33658909797668457 seconds for one epoch ---
--- 1.417719841003418 seconds for one epoch ---
--- 0.3241431713104248 seconds for one epoch ---
--- 1.4041037559509277 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10891311]
 [0.        ]
 [0.        ]
 [0.11032765]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.9773686]
 [-0.       ]
 [ 0.       ]
 [-0.9817684]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-8.072103 ]
 [-0.       ]]
--- 0.306903600692749 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3186.715576171875, (1646.3795, 0.60533446, 1539.2966, 0.4340415)
   validation loss 951.3211669921875, (670.9416, 0.4077324, 279.53784, 0.4340415)
decoder loss ratio: 25993.441977, decoder SINDy loss  ratio: 0.603422
THRESHOLDING: 3 active coefficients
--- 1.3751466274261475 seconds for one epoch ---
--- 0.3320014476776123 seconds for one epoch ---
--- 1.3998744487762451 seconds for one epoch ---
--- 0.3356761932373047 seconds for one epoch ---
--- 1.386704683303833 seconds for one epoch ---
--- 0.3177683353424072 seconds for one epoch ---
--- 1.388066291809082 seconds for one epoch ---
--- 0.3275315761566162 seconds for one epoch ---
--- 1.4200899600982666 seconds for one epoch ---
--- 0.3429863452911377 seconds for one epoch ---
--- 1.3870468139648438 seconds for one epoch ---
--- 0.3289923667907715 seconds for one epoch ---
--- 1.41391921043396 seconds for one epoch ---
--- 0.3273031711578369 seconds for one epoch ---
--- 1.412318468093872 seconds for one epoch ---
--- 0.31737542152404785 seconds for one epoch ---
--- 1.3850500583648682 seconds for one epoch ---
--- 0.3457612991333008 seconds for one epoch ---
--- 1.3866682052612305 seconds for one epoch ---
--- 0.33303260803222656 seconds for one epoch ---
--- 1.4036273956298828 seconds for one epoch ---
--- 0.3352365493774414 seconds for one epoch ---
--- 1.3777198791503906 seconds for one epoch ---
--- 0.335162878036499 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10293557]
 [0.        ]
 [0.        ]
 [0.11165316]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.9582065]
 [-0.       ]
 [ 0.       ]
 [-0.9858465]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-8.117633 ]
 [-0.       ]]
--- 0.26418447494506836 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1645.899169921875, (736.45654, 1.3929328, 907.61694, 0.43272066)
   validation loss 936.556396484375, (639.84955, 0.46966952, 295.80444, 0.43272066)
decoder loss ratio: 24788.882330, decoder SINDy loss  ratio: 0.638535
--- 0.32683515548706055 seconds for one epoch ---
--- 1.3762638568878174 seconds for one epoch ---
--- 0.3333890438079834 seconds for one epoch ---
--- 1.3841934204101562 seconds for one epoch ---
--- 0.3338160514831543 seconds for one epoch ---
--- 1.4198904037475586 seconds for one epoch ---
--- 0.3332788944244385 seconds for one epoch ---
--- 1.3985905647277832 seconds for one epoch ---
--- 0.32924365997314453 seconds for one epoch ---
--- 1.396576166152954 seconds for one epoch ---
--- 0.32485222816467285 seconds for one epoch ---
--- 1.3899896144866943 seconds for one epoch ---
--- 0.33568429946899414 seconds for one epoch ---
--- 1.3989348411560059 seconds for one epoch ---
--- 0.3312711715698242 seconds for one epoch ---
--- 1.4176418781280518 seconds for one epoch ---
--- 0.33116674423217773 seconds for one epoch ---
--- 1.43111252784729 seconds for one epoch ---
--- 0.3317434787750244 seconds for one epoch ---
--- 1.4135499000549316 seconds for one epoch ---
--- 0.3313789367675781 seconds for one epoch ---
--- 1.3999121189117432 seconds for one epoch ---
--- 0.3277599811553955 seconds for one epoch ---
--- 1.39849853515625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10499395]
 [0.        ]
 [0.        ]
 [0.11116968]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.964913  ]
 [ 0.        ]
 [-0.        ]
 [-0.98436415]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.163075  ]
 [-0.        ]]
--- 0.3158900737762451 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2064.72119140625, (1070.1014, 0.40065277, 993.7849, 0.43403006)
   validation loss 894.47509765625, (598.4683, 0.52163106, 295.05115, 0.43403006)
decoder loss ratio: 23185.701810, decoder SINDy loss  ratio: 0.636909
--- 0.27385926246643066 seconds for one epoch ---
--- 0.32882237434387207 seconds for one epoch ---
--- 1.4279396533966064 seconds for one epoch ---
--- 0.34827184677124023 seconds for one epoch ---
--- 1.410548448562622 seconds for one epoch ---
--- 0.3352169990539551 seconds for one epoch ---
--- 1.4257392883300781 seconds for one epoch ---
--- 0.3366544246673584 seconds for one epoch ---
--- 1.4273879528045654 seconds for one epoch ---
--- 0.33876800537109375 seconds for one epoch ---
--- 1.4283077716827393 seconds for one epoch ---
--- 0.33803820610046387 seconds for one epoch ---
--- 1.4139325618743896 seconds for one epoch ---
--- 0.34132909774780273 seconds for one epoch ---
--- 1.4193658828735352 seconds for one epoch ---
--- 0.34920477867126465 seconds for one epoch ---
--- 1.4107179641723633 seconds for one epoch ---
--- 0.33858585357666016 seconds for one epoch ---
--- 1.432741403579712 seconds for one epoch ---
--- 0.33097076416015625 seconds for one epoch ---
--- 1.437464952468872 seconds for one epoch ---
--- 0.3359239101409912 seconds for one epoch ---
--- 1.4355721473693848 seconds for one epoch ---
--- 0.32840681076049805 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1071258 ]
 [0.        ]
 [0.        ]
 [0.11101847]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.9717383 ]
 [ 0.        ]
 [-0.        ]
 [-0.98389953]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-8.212306  ]
 [-0.        ]]
--- 0.2811105251312256 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2563.66064453125, (1225.3995, 1.104927, 1336.7211, 0.43506113)
   validation loss 998.2208251953125, (681.9473, 0.41698533, 315.42145, 0.43506113)
decoder loss ratio: 26419.823347, decoder SINDy loss  ratio: 0.680882
--- 0.3220844268798828 seconds for one epoch ---
--- 1.4344239234924316 seconds for one epoch ---
--- 0.34824395179748535 seconds for one epoch ---
--- 1.425086498260498 seconds for one epoch ---
--- 0.34483790397644043 seconds for one epoch ---
--- 1.4282145500183105 seconds for one epoch ---
--- 0.3523142337799072 seconds for one epoch ---
--- 1.4341514110565186 seconds for one epoch ---
--- 0.3338606357574463 seconds for one epoch ---
--- 1.4197473526000977 seconds for one epoch ---
--- 0.3238649368286133 seconds for one epoch ---
--- 1.4305410385131836 seconds for one epoch ---
--- 0.3390641212463379 seconds for one epoch ---
--- 1.4503352642059326 seconds for one epoch ---
--- 0.3361692428588867 seconds for one epoch ---
--- 1.4474544525146484 seconds for one epoch ---
--- 0.3374042510986328 seconds for one epoch ---
--- 1.4401097297668457 seconds for one epoch ---
--- 0.32634806632995605 seconds for one epoch ---
--- 1.4563751220703125 seconds for one epoch ---
--- 0.33861255645751953 seconds for one epoch ---
--- 1.4427413940429688 seconds for one epoch ---
--- 0.3302929401397705 seconds for one epoch ---
--- 1.4275221824645996 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10634585]
 [0.        ]
 [0.        ]
 [0.10956707]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.96925485]
 [-0.        ]
 [ 0.        ]
 [-0.97940946]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-8.266465  ]
 [-0.        ]]
--- 0.3147244453430176 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3672.912841796875, (2433.263, 3.101281, 1236.1133, 0.43533832)
   validation loss 1082.6370849609375, (788.8466, 0.49788642, 292.8573, 0.43533832)
decoder loss ratio: 30561.287505, decoder SINDy loss  ratio: 0.632174
--- 0.2829916477203369 seconds for one epoch ---
--- 0.33814215660095215 seconds for one epoch ---
--- 1.434640884399414 seconds for one epoch ---
--- 0.33222246170043945 seconds for one epoch ---
--- 1.4377415180206299 seconds for one epoch ---
--- 0.32957935333251953 seconds for one epoch ---
--- 1.4421136379241943 seconds for one epoch ---
--- 0.3246736526489258 seconds for one epoch ---
--- 1.4333984851837158 seconds for one epoch ---
--- 0.33648681640625 seconds for one epoch ---
--- 1.4252591133117676 seconds for one epoch ---
--- 0.3307840824127197 seconds for one epoch ---
--- 1.4686617851257324 seconds for one epoch ---
--- 0.32858705520629883 seconds for one epoch ---
--- 1.4557123184204102 seconds for one epoch ---
--- 0.33101987838745117 seconds for one epoch ---
--- 1.4722962379455566 seconds for one epoch ---
--- 0.3327479362487793 seconds for one epoch ---
--- 1.4357941150665283 seconds for one epoch ---
--- 0.3312864303588867 seconds for one epoch ---
--- 1.4412610530853271 seconds for one epoch ---
--- 0.34465527534484863 seconds for one epoch ---
--- 1.4808096885681152 seconds for one epoch ---
--- 0.3484196662902832 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10446147]
 [0.        ]
 [0.        ]
 [0.10646825]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.9631898]
 [-0.       ]
 [ 0.       ]
 [-0.9696458]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-8.316571 ]
 [-0.       ]]
--- 0.28163719177246094 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2888.914794921875, (1202.3201, 0.6955826, 1685.4651, 0.4341159)
   validation loss 1425.2921142578125, (1063.8923, 0.6054128, 360.3602, 0.4341159)
decoder loss ratio: 41217.036017, decoder SINDy loss  ratio: 0.777888
--- 0.326885461807251 seconds for one epoch ---
--- 1.4599933624267578 seconds for one epoch ---
--- 0.34383225440979004 seconds for one epoch ---
--- 1.441011667251587 seconds for one epoch ---
--- 0.33977699279785156 seconds for one epoch ---
--- 1.4769279956817627 seconds for one epoch ---
--- 0.3434336185455322 seconds for one epoch ---
--- 1.438645601272583 seconds for one epoch ---
--- 0.33118629455566406 seconds for one epoch ---
--- 1.4592230319976807 seconds for one epoch ---
--- 0.33485960960388184 seconds for one epoch ---
--- 1.4314920902252197 seconds for one epoch ---
--- 0.3373100757598877 seconds for one epoch ---
--- 1.445030689239502 seconds for one epoch ---
--- 0.33928370475769043 seconds for one epoch ---
--- 1.4467365741729736 seconds for one epoch ---
--- 0.3278965950012207 seconds for one epoch ---
--- 1.4668619632720947 seconds for one epoch ---
--- 0.33345556259155273 seconds for one epoch ---
--- 1.4638426303863525 seconds for one epoch ---
--- 0.3487563133239746 seconds for one epoch ---
--- 1.4749417304992676 seconds for one epoch ---
--- 0.3314666748046875 seconds for one epoch ---
--- 1.4845304489135742 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10625675]
 [0.        ]
 [0.        ]
 [0.10879841]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.9689707]
 [ 0.       ]
 [-0.       ]
 [-0.9770103]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-8.355138 ]
 [-0.       ]]
--- 0.3095512390136719 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3383.2978515625, (2008.826, 4.3172917, 1369.7188, 0.43578506)
   validation loss 1020.2415771484375, (722.37036, 0.47215378, 296.9633, 0.43578506)
decoder loss ratio: 27985.881888, decoder SINDy loss  ratio: 0.641037
--- 0.27768898010253906 seconds for one epoch ---
--- 0.3363478183746338 seconds for one epoch ---
--- 1.4588358402252197 seconds for one epoch ---
--- 0.3386695384979248 seconds for one epoch ---
--- 1.4629552364349365 seconds for one epoch ---
--- 0.3347451686859131 seconds for one epoch ---
--- 1.478522539138794 seconds for one epoch ---
--- 0.32736754417419434 seconds for one epoch ---
--- 1.4654254913330078 seconds for one epoch ---
--- 0.3317866325378418 seconds for one epoch ---
--- 1.444711685180664 seconds for one epoch ---
--- 0.3274505138397217 seconds for one epoch ---
--- 1.4665472507476807 seconds for one epoch ---
--- 0.33893609046936035 seconds for one epoch ---
--- 1.4528899192810059 seconds for one epoch ---
--- 0.32899904251098633 seconds for one epoch ---
--- 1.4742381572723389 seconds for one epoch ---
--- 0.32898902893066406 seconds for one epoch ---
--- 1.464632272720337 seconds for one epoch ---
--- 0.33329129219055176 seconds for one epoch ---
--- 1.4905059337615967 seconds for one epoch ---
--- 0.3320333957672119 seconds for one epoch ---
--- 1.5043656826019287 seconds for one epoch ---
--- 0.3329346179962158 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10540488]
 [0.        ]
 [0.        ]
 [0.10848851]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.9662383 ]
 [ 0.        ]
 [-0.        ]
 [-0.97603923]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-8.399353  ]
 [-0.        ]]
--- 0.2684199810028076 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4322.85009765625, (1263.7164, 3.888171, 3054.8096, 0.43599963)
   validation loss 1181.734375, (871.4412, 0.6172308, 309.23993, 0.43599963)
decoder loss ratio: 33761.145873, decoder SINDy loss  ratio: 0.667538
--- 0.33131837844848633 seconds for one epoch ---
--- 1.4775950908660889 seconds for one epoch ---
--- 0.3287489414215088 seconds for one epoch ---
--- 1.4533729553222656 seconds for one epoch ---
--- 0.3381524085998535 seconds for one epoch ---
--- 1.4916863441467285 seconds for one epoch ---
--- 0.3307979106903076 seconds for one epoch ---
--- 1.5004265308380127 seconds for one epoch ---
--- 0.33115458488464355 seconds for one epoch ---
--- 1.4828791618347168 seconds for one epoch ---
--- 0.33420610427856445 seconds for one epoch ---
--- 1.4819495677947998 seconds for one epoch ---
--- 0.3347649574279785 seconds for one epoch ---
--- 1.4638221263885498 seconds for one epoch ---
--- 0.3401310443878174 seconds for one epoch ---
--- 1.459200382232666 seconds for one epoch ---
--- 0.33181071281433105 seconds for one epoch ---
--- 1.4574894905090332 seconds for one epoch ---
--- 0.33097267150878906 seconds for one epoch ---
--- 1.4782869815826416 seconds for one epoch ---
--- 0.34032750129699707 seconds for one epoch ---
--- 1.4618675708770752 seconds for one epoch ---
--- 0.33376288414001465 seconds for one epoch ---
--- 1.5031938552856445 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10379643]
 [0.        ]
 [0.        ]
 [0.11048954]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.96102625]
 [-0.        ]
 [ 0.        ]
 [-0.9822692 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-8.435542  ]
 [-0.        ]]
--- 0.32198286056518555 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3167.51953125, (1394.7515, 2.6018376, 1769.7297, 0.43651223)
   validation loss 998.7042236328125, (665.38043, 0.52589774, 332.3614, 0.43651223)
decoder loss ratio: 25777.993092, decoder SINDy loss  ratio: 0.717449
--- 0.2776296138763428 seconds for one epoch ---
--- 0.3231363296508789 seconds for one epoch ---
--- 1.4755194187164307 seconds for one epoch ---
--- 0.3543412685394287 seconds for one epoch ---
--- 1.4942402839660645 seconds for one epoch ---
--- 0.3316934108734131 seconds for one epoch ---
--- 1.4890480041503906 seconds for one epoch ---
--- 0.33419251441955566 seconds for one epoch ---
--- 1.4946496486663818 seconds for one epoch ---
--- 0.33815979957580566 seconds for one epoch ---
--- 1.4962279796600342 seconds for one epoch ---
--- 0.3308537006378174 seconds for one epoch ---
--- 1.4733750820159912 seconds for one epoch ---
--- 0.33310413360595703 seconds for one epoch ---
--- 1.4927828311920166 seconds for one epoch ---
--- 0.3253765106201172 seconds for one epoch ---
--- 1.5195205211639404 seconds for one epoch ---
--- 0.3335301876068115 seconds for one epoch ---
--- 1.4853520393371582 seconds for one epoch ---
--- 0.3334779739379883 seconds for one epoch ---
--- 1.480311632156372 seconds for one epoch ---
--- 0.3422560691833496 seconds for one epoch ---
--- 1.485614538192749 seconds for one epoch ---
--- 0.3379552364349365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1053496 ]
 [0.        ]
 [0.        ]
 [0.10982974]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.96606034]
 [-0.        ]
 [ 0.        ]
 [-0.98022616]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-8.482038  ]
 [-0.        ]]
--- 0.26613664627075195 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1937.4810791015625, (840.2305, 0.22276884, 1096.5903, 0.43736345)
   validation loss 839.1366577148438, (558.6362, 0.64730895, 279.4157, 0.43736345)
decoder loss ratio: 21642.537404, decoder SINDy loss  ratio: 0.603158
--- 0.32428550720214844 seconds for one epoch ---
--- 1.502363920211792 seconds for one epoch ---
--- 0.3374176025390625 seconds for one epoch ---
--- 1.5197267532348633 seconds for one epoch ---
--- 0.3211641311645508 seconds for one epoch ---
--- 1.4946906566619873 seconds for one epoch ---
--- 0.3367338180541992 seconds for one epoch ---
--- 1.4824776649475098 seconds for one epoch ---
--- 0.33823537826538086 seconds for one epoch ---
--- 1.4800727367401123 seconds for one epoch ---
--- 0.32985925674438477 seconds for one epoch ---
--- 1.5006325244903564 seconds for one epoch ---
--- 0.34008026123046875 seconds for one epoch ---
--- 1.503098487854004 seconds for one epoch ---
--- 0.33483362197875977 seconds for one epoch ---
--- 1.4873788356781006 seconds for one epoch ---
--- 0.32637977600097656 seconds for one epoch ---
--- 1.4962363243103027 seconds for one epoch ---
--- 0.32378125190734863 seconds for one epoch ---
--- 1.5162391662597656 seconds for one epoch ---
--- 0.3347012996673584 seconds for one epoch ---
--- 1.5122742652893066 seconds for one epoch ---
--- 0.336406946182251 seconds for one epoch ---
--- 1.4934520721435547 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10745913]
 [0.        ]
 [0.        ]
 [0.10843316]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.97279483]
 [ 0.        ]
 [-0.        ]
 [-0.9758652 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.522964  ]
 [-0.        ]]
--- 0.3123359680175781 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5257.92529296875, (1388.5084, 2.4305897, 3866.5486, 0.43813)
   validation loss 906.6676025390625, (614.7538, 0.7272668, 290.7484, 0.43813)
decoder loss ratio: 23816.628859, decoder SINDy loss  ratio: 0.627621
--- 0.27525854110717773 seconds for one epoch ---
--- 0.336745023727417 seconds for one epoch ---
--- 1.4911227226257324 seconds for one epoch ---
--- 0.3402059078216553 seconds for one epoch ---
--- 1.5143282413482666 seconds for one epoch ---
--- 0.3302452564239502 seconds for one epoch ---
--- 1.4886291027069092 seconds for one epoch ---
--- 0.32489824295043945 seconds for one epoch ---
--- 1.5345072746276855 seconds for one epoch ---
--- 0.3236658573150635 seconds for one epoch ---
--- 1.5344929695129395 seconds for one epoch ---
--- 0.33552074432373047 seconds for one epoch ---
--- 1.5282206535339355 seconds for one epoch ---
--- 0.32267332077026367 seconds for one epoch ---
--- 1.510753870010376 seconds for one epoch ---
--- 0.3291945457458496 seconds for one epoch ---
--- 1.5075829029083252 seconds for one epoch ---
--- 0.32235050201416016 seconds for one epoch ---
--- 1.492990255355835 seconds for one epoch ---
--- 0.33026766777038574 seconds for one epoch ---
--- 1.5303089618682861 seconds for one epoch ---
--- 0.32567405700683594 seconds for one epoch ---
--- 1.533984899520874 seconds for one epoch ---
--- 0.324230432510376 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10383945]
 [0.        ]
 [0.        ]
 [0.10834102]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.9611666]
 [ 0.       ]
 [-0.       ]
 [-0.9755761]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-8.572887 ]
 [-0.       ]]
--- 0.27141809463500977 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3336.408203125, (1931.9827, 0.57934505, 1403.4086, 0.43741474)
   validation loss 1224.28857421875, (899.7493, 0.7475364, 323.3543, 0.43741474)
decoder loss ratio: 34857.851024, decoder SINDy loss  ratio: 0.698006
--- 0.3347299098968506 seconds for one epoch ---
--- 1.529883861541748 seconds for one epoch ---
--- 0.3426365852355957 seconds for one epoch ---
--- 1.5277724266052246 seconds for one epoch ---
--- 0.3419821262359619 seconds for one epoch ---
--- 1.5457656383514404 seconds for one epoch ---
--- 0.3364379405975342 seconds for one epoch ---
--- 1.5077779293060303 seconds for one epoch ---
--- 0.3366880416870117 seconds for one epoch ---
--- 1.5116782188415527 seconds for one epoch ---
--- 0.3384826183319092 seconds for one epoch ---
--- 1.5371801853179932 seconds for one epoch ---
--- 0.338914155960083 seconds for one epoch ---
--- 1.5156824588775635 seconds for one epoch ---
--- 0.335695743560791 seconds for one epoch ---
--- 1.5565788745880127 seconds for one epoch ---
--- 0.3392658233642578 seconds for one epoch ---
--- 1.5215227603912354 seconds for one epoch ---
--- 0.34438586235046387 seconds for one epoch ---
--- 1.5237219333648682 seconds for one epoch ---
--- 0.33086514472961426 seconds for one epoch ---
--- 1.5297422409057617 seconds for one epoch ---
--- 0.343703031539917 seconds for one epoch ---
--- 1.54630708694458 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10499755]
 [0.        ]
 [0.        ]
 [0.11044496]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.96492547]
 [-0.        ]
 [ 0.        ]
 [-0.982132  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-8.6139145 ]
 [-0.        ]]
--- 0.3080739974975586 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1629.2041015625, (731.45044, 1.7972277, 895.5173, 0.43919787)
   validation loss 898.5597534179688, (614.88965, 0.6121192, 282.61877, 0.43919787)
decoder loss ratio: 23821.892476, decoder SINDy loss  ratio: 0.610072
--- 0.2800180912017822 seconds for one epoch ---
--- 0.3344995975494385 seconds for one epoch ---
--- 1.5160293579101562 seconds for one epoch ---
--- 0.3366429805755615 seconds for one epoch ---
--- 1.5328938961029053 seconds for one epoch ---
--- 0.338085412979126 seconds for one epoch ---
--- 1.5275695323944092 seconds for one epoch ---
--- 0.32952237129211426 seconds for one epoch ---
--- 1.536738634109497 seconds for one epoch ---
--- 0.3247237205505371 seconds for one epoch ---
--- 1.5259196758270264 seconds for one epoch ---
--- 0.3428456783294678 seconds for one epoch ---
--- 1.5315282344818115 seconds for one epoch ---
--- 0.3476536273956299 seconds for one epoch ---
--- 1.5398402214050293 seconds for one epoch ---
--- 0.33579516410827637 seconds for one epoch ---
--- 1.5370850563049316 seconds for one epoch ---
--- 0.32744383811950684 seconds for one epoch ---
--- 1.5406556129455566 seconds for one epoch ---
--- 0.32770419120788574 seconds for one epoch ---
--- 1.5136749744415283 seconds for one epoch ---
--- 0.3415212631225586 seconds for one epoch ---
--- 1.5204863548278809 seconds for one epoch ---
--- 0.34044933319091797 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10427089]
 [0.        ]
 [0.        ]
 [0.11095461]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.9625713 ]
 [-0.        ]
 [ 0.        ]
 [-0.98370355]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.660571  ]
 [-0.        ]]
--- 0.27059435844421387 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5775.23046875, (2561.1902, 0.6436441, 3212.9568, 0.4397566)
   validation loss 708.3839111328125, (438.66788, 0.5855719, 268.6907, 0.4397566)
decoder loss ratio: 16994.755124, decoder SINDy loss  ratio: 0.580007
--- 0.3352632522583008 seconds for one epoch ---
--- 1.5375983715057373 seconds for one epoch ---
--- 0.33799171447753906 seconds for one epoch ---
--- 1.539989948272705 seconds for one epoch ---
--- 0.33212852478027344 seconds for one epoch ---
--- 1.540503740310669 seconds for one epoch ---
--- 0.33456873893737793 seconds for one epoch ---
--- 1.5295791625976562 seconds for one epoch ---
--- 0.3270440101623535 seconds for one epoch ---
--- 1.5105652809143066 seconds for one epoch ---
--- 0.33579444885253906 seconds for one epoch ---
--- 1.5331602096557617 seconds for one epoch ---
--- 0.37631940841674805 seconds for one epoch ---
--- 1.5168447494506836 seconds for one epoch ---
--- 0.3353545665740967 seconds for one epoch ---
--- 1.5590941905975342 seconds for one epoch ---
--- 0.32529449462890625 seconds for one epoch ---
--- 1.529714822769165 seconds for one epoch ---
--- 0.3371243476867676 seconds for one epoch ---
--- 1.5650618076324463 seconds for one epoch ---
--- 0.3349921703338623 seconds for one epoch ---
--- 1.5511932373046875 seconds for one epoch ---
--- 0.33266448974609375 seconds for one epoch ---
--- 1.538712739944458 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10088456]
 [0.        ]
 [0.        ]
 [0.11032524]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.9514069 ]
 [ 0.        ]
 [-0.        ]
 [-0.98176205]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.6926985 ]
 [-0.        ]]
--- 0.32824063301086426 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6075.55615234375, (1628.5457, 2.1409516, 4444.431, 0.43868414)
   validation loss 1013.1196899414062, (753.5524, 0.6396887, 258.4889, 0.43868414)
decoder loss ratio: 29193.929332, decoder SINDy loss  ratio: 0.557985
--- 0.28237056732177734 seconds for one epoch ---
--- 0.33744096755981445 seconds for one epoch ---
--- 1.5322940349578857 seconds for one epoch ---
--- 0.33368802070617676 seconds for one epoch ---
--- 1.5704293251037598 seconds for one epoch ---
--- 0.334486722946167 seconds for one epoch ---
--- 1.5383453369140625 seconds for one epoch ---
--- 0.33943724632263184 seconds for one epoch ---
--- 1.545888900756836 seconds for one epoch ---
--- 0.3301827907562256 seconds for one epoch ---
--- 1.5845470428466797 seconds for one epoch ---
--- 0.3341255187988281 seconds for one epoch ---
--- 1.557105302810669 seconds for one epoch ---
--- 0.33538079261779785 seconds for one epoch ---
--- 1.544752597808838 seconds for one epoch ---
--- 0.3359346389770508 seconds for one epoch ---
--- 1.5423898696899414 seconds for one epoch ---
--- 0.3355400562286377 seconds for one epoch ---
--- 1.5519886016845703 seconds for one epoch ---
--- 0.32991957664489746 seconds for one epoch ---
--- 1.5586349964141846 seconds for one epoch ---
--- 0.3229696750640869 seconds for one epoch ---
--- 1.5694122314453125 seconds for one epoch ---
--- 0.33335065841674805 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10127069]
 [0.        ]
 [0.        ]
 [0.1074272 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.9526961]
 [ 0.       ]
 [-0.       ]
 [-0.9726943]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-8.749624 ]
 [-0.       ]]
--- 0.27801942825317383 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3495.5810546875, (1695.2699, 1.236862, 1798.6361, 0.43827668)
   validation loss 1201.3916015625, (914.28125, 0.73109186, 285.94107, 0.43827668)
decoder loss ratio: 35420.842887, decoder SINDy loss  ratio: 0.617244
--- 0.32343411445617676 seconds for one epoch ---
--- 1.5484561920166016 seconds for one epoch ---
--- 0.33647584915161133 seconds for one epoch ---
--- 1.556713581085205 seconds for one epoch ---
--- 0.33298516273498535 seconds for one epoch ---
--- 1.5987954139709473 seconds for one epoch ---
--- 0.32764768600463867 seconds for one epoch ---
--- 1.5995750427246094 seconds for one epoch ---
--- 0.3235163688659668 seconds for one epoch ---
--- 1.5587310791015625 seconds for one epoch ---
--- 0.3321506977081299 seconds for one epoch ---
--- 1.578021764755249 seconds for one epoch ---
--- 0.3317885398864746 seconds for one epoch ---
--- 1.5880892276763916 seconds for one epoch ---
--- 0.32762646675109863 seconds for one epoch ---
--- 1.6009292602539062 seconds for one epoch ---
--- 0.33274126052856445 seconds for one epoch ---
--- 1.6051580905914307 seconds for one epoch ---
--- 0.3362245559692383 seconds for one epoch ---
--- 1.5926198959350586 seconds for one epoch ---
--- 0.33681631088256836 seconds for one epoch ---
--- 1.5669748783111572 seconds for one epoch ---
--- 0.332489013671875 seconds for one epoch ---
--- 1.5534696578979492 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10059112]
 [0.        ]
 [0.        ]
 [0.10762801]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.9504238 ]
 [-0.        ]
 [ 0.        ]
 [-0.97332937]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-8.775687  ]
 [-0.        ]]
--- 0.3140556812286377 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3357.978515625, (1897.6438, 3.1926334, 1456.703, 0.43884498)
   validation loss 931.5384521484375, (652.75195, 0.6978493, 277.6498, 0.43884498)
decoder loss ratio: 25288.743891, decoder SINDy loss  ratio: 0.599346
--- 0.2802708148956299 seconds for one epoch ---
--- 0.337238073348999 seconds for one epoch ---
--- 1.560148000717163 seconds for one epoch ---
--- 0.33852696418762207 seconds for one epoch ---
--- 1.5550894737243652 seconds for one epoch ---
--- 0.33623695373535156 seconds for one epoch ---
--- 1.5897002220153809 seconds for one epoch ---
--- 0.332751989364624 seconds for one epoch ---
--- 1.5588643550872803 seconds for one epoch ---
--- 0.33606386184692383 seconds for one epoch ---
--- 1.5776340961456299 seconds for one epoch ---
--- 0.32993459701538086 seconds for one epoch ---
--- 1.5858056545257568 seconds for one epoch ---
--- 0.3355534076690674 seconds for one epoch ---
--- 1.5884082317352295 seconds for one epoch ---
--- 0.3294210433959961 seconds for one epoch ---
--- 1.593188762664795 seconds for one epoch ---
--- 0.3236393928527832 seconds for one epoch ---
--- 1.5918059349060059 seconds for one epoch ---
--- 0.3409404754638672 seconds for one epoch ---
--- 1.6156091690063477 seconds for one epoch ---
--- 0.3290739059448242 seconds for one epoch ---
--- 1.5982306003570557 seconds for one epoch ---
--- 0.3349118232727051 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10102075]
 [0.        ]
 [0.        ]
 [0.10748878]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.9518621 ]
 [-0.        ]
 [ 0.        ]
 [-0.97288924]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.807734  ]
 [-0.        ]]
--- 0.27328944206237793 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3378.1533203125, (1018.1462, 2.1628883, 2357.4048, 0.43949476)
   validation loss 1153.805908203125, (847.99396, 0.7464259, 304.62607, 0.43949476)
decoder loss ratio: 32852.758097, decoder SINDy loss  ratio: 0.657578
--- 0.3278930187225342 seconds for one epoch ---
--- 1.5732345581054688 seconds for one epoch ---
--- 0.3366203308105469 seconds for one epoch ---
--- 1.6181883811950684 seconds for one epoch ---
--- 0.3431661128997803 seconds for one epoch ---
--- 1.570927381515503 seconds for one epoch ---
--- 0.33960676193237305 seconds for one epoch ---
--- 1.6001131534576416 seconds for one epoch ---
--- 0.33229684829711914 seconds for one epoch ---
--- 1.5766842365264893 seconds for one epoch ---
--- 0.3396148681640625 seconds for one epoch ---
--- 1.6197443008422852 seconds for one epoch ---
--- 0.3443410396575928 seconds for one epoch ---
--- 1.5762708187103271 seconds for one epoch ---
--- 0.3381619453430176 seconds for one epoch ---
--- 1.5732743740081787 seconds for one epoch ---
--- 0.33107686042785645 seconds for one epoch ---
--- 1.5867304801940918 seconds for one epoch ---
--- 0.6390476226806641 seconds for one epoch ---
--- 1.5751211643218994 seconds for one epoch ---
--- 0.32913899421691895 seconds for one epoch ---
--- 1.6360163688659668 seconds for one epoch ---
--- 0.3188607692718506 seconds for one epoch ---
--- 1.5787887573242188 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10149874]
 [0.        ]
 [0.        ]
 [0.10881575]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.9534556]
 [ 0.       ]
 [-0.       ]
 [-0.9770651]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-8.854484 ]
 [-0.       ]]
--- 0.3234550952911377 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4356.7734375, (1114.36, 2.4693499, 3239.5037, 0.44047442)
   validation loss 772.9752807617188, (500.28873, 0.71183854, 271.5342, 0.44047442)
decoder loss ratio: 19382.053816, decoder SINDy loss  ratio: 0.586145
--- 0.2697324752807617 seconds for one epoch ---
--- 0.3262646198272705 seconds for one epoch ---
--- 1.6115012168884277 seconds for one epoch ---
--- 0.330350399017334 seconds for one epoch ---
--- 1.6193161010742188 seconds for one epoch ---
--- 0.33286237716674805 seconds for one epoch ---
--- 1.6119375228881836 seconds for one epoch ---
--- 0.33098387718200684 seconds for one epoch ---
--- 1.608884572982788 seconds for one epoch ---
--- 0.33455491065979004 seconds for one epoch ---
--- 1.612273931503296 seconds for one epoch ---
--- 0.3348090648651123 seconds for one epoch ---
--- 1.5795607566833496 seconds for one epoch ---
--- 0.33034777641296387 seconds for one epoch ---
--- 1.581594467163086 seconds for one epoch ---
--- 0.33471202850341797 seconds for one epoch ---
--- 1.6150646209716797 seconds for one epoch ---
--- 0.32971787452697754 seconds for one epoch ---
--- 1.599799394607544 seconds for one epoch ---
--- 0.3262944221496582 seconds for one epoch ---
--- 1.588235855102539 seconds for one epoch ---
--- 0.3259119987487793 seconds for one epoch ---
--- 1.5904908180236816 seconds for one epoch ---
--- 0.33176231384277344 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10064971]
 [0.        ]
 [0.        ]
 [0.10644229]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.9506198]
 [ 0.       ]
 [-0.       ]
 [-0.969564 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-8.875833 ]
 [-0.       ]]
--- 0.27532482147216797 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2718.854736328125, (1578.4009, 0.19574201, 1139.8186, 0.4394133)
   validation loss 911.45751953125, (639.6789, 0.5685688, 270.7707, 0.4394133)
decoder loss ratio: 24782.270887, decoder SINDy loss  ratio: 0.584497
--- 0.31987667083740234 seconds for one epoch ---
--- 1.578237533569336 seconds for one epoch ---
--- 0.3313772678375244 seconds for one epoch ---
--- 1.5842621326446533 seconds for one epoch ---
--- 0.3428804874420166 seconds for one epoch ---
--- 1.5991272926330566 seconds for one epoch ---
--- 0.3291468620300293 seconds for one epoch ---
--- 1.6429460048675537 seconds for one epoch ---
--- 0.33100056648254395 seconds for one epoch ---
--- 1.6239542961120605 seconds for one epoch ---
--- 0.3357863426208496 seconds for one epoch ---
--- 1.6281592845916748 seconds for one epoch ---
--- 0.33632540702819824 seconds for one epoch ---
--- 1.6014385223388672 seconds for one epoch ---
--- 0.33768463134765625 seconds for one epoch ---
--- 1.6174819469451904 seconds for one epoch ---
--- 0.3319830894470215 seconds for one epoch ---
--- 1.6265161037445068 seconds for one epoch ---
--- 0.3351612091064453 seconds for one epoch ---
--- 1.633622169494629 seconds for one epoch ---
--- 0.32659268379211426 seconds for one epoch ---
--- 1.631843090057373 seconds for one epoch ---
--- 0.32422661781311035 seconds for one epoch ---
--- 1.6005499362945557 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09994207]
 [0.        ]
 [0.        ]
 [0.10667426]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.94824016]
 [-0.        ]
 [ 0.        ]
 [-0.97030365]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-8.912003  ]
 [-0.        ]]
--- 0.3137826919555664 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2312.586669921875, (1466.0776, 1.7771281, 844.29224, 0.4397181)
   validation loss 1002.323974609375, (685.5957, 0.6156114, 315.67294, 0.4397181)
decoder loss ratio: 26561.167786, decoder SINDy loss  ratio: 0.681424
THRESHOLDING: 2 active coefficients
--- 0.27185702323913574 seconds for one epoch ---
--- 0.3313314914703369 seconds for one epoch ---
--- 1.6464569568634033 seconds for one epoch ---
--- 0.3360280990600586 seconds for one epoch ---
--- 1.6049411296844482 seconds for one epoch ---
--- 0.3333094120025635 seconds for one epoch ---
--- 1.6317861080169678 seconds for one epoch ---
--- 0.3436276912689209 seconds for one epoch ---
--- 1.611375331878662 seconds for one epoch ---
--- 0.3333909511566162 seconds for one epoch ---
--- 1.631303071975708 seconds for one epoch ---
--- 0.3345201015472412 seconds for one epoch ---
--- 1.6107063293457031 seconds for one epoch ---
--- 0.331099271774292 seconds for one epoch ---
--- 1.6381053924560547 seconds for one epoch ---
--- 0.34125542640686035 seconds for one epoch ---
--- 1.6168360710144043 seconds for one epoch ---
--- 0.3299529552459717 seconds for one epoch ---
--- 1.6051759719848633 seconds for one epoch ---
--- 0.3318474292755127 seconds for one epoch ---
--- 1.6650559902191162 seconds for one epoch ---
--- 0.34035444259643555 seconds for one epoch ---
--- 1.617729663848877 seconds for one epoch ---
--- 0.3349151611328125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08279905]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.88543683]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-8.987555  ]
 [-0.        ]]
--- 0.2744886875152588 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3705.10791015625, (1657.9182, 2.557627, 2044.2521, 0.37994733)
   validation loss 887.0549926757812, (602.051, 0.63274527, 283.9913, 0.37994733)
decoder loss ratio: 23324.501930, decoder SINDy loss  ratio: 0.613035
--- 0.3132288455963135 seconds for one epoch ---
--- 1.5979652404785156 seconds for one epoch ---
--- 0.3394660949707031 seconds for one epoch ---
--- 1.629018783569336 seconds for one epoch ---
--- 0.3349020481109619 seconds for one epoch ---
--- 1.6344451904296875 seconds for one epoch ---
--- 0.33374476432800293 seconds for one epoch ---
--- 1.6351218223571777 seconds for one epoch ---
--- 0.33580827713012695 seconds for one epoch ---
--- 1.6167607307434082 seconds for one epoch ---
--- 0.3447244167327881 seconds for one epoch ---
--- 1.6224734783172607 seconds for one epoch ---
--- 0.34201645851135254 seconds for one epoch ---
--- 1.6321327686309814 seconds for one epoch ---
--- 0.33428430557250977 seconds for one epoch ---
--- 1.65175461769104 seconds for one epoch ---
--- 0.3358454704284668 seconds for one epoch ---
--- 1.6407318115234375 seconds for one epoch ---
--- 0.3335611820220947 seconds for one epoch ---
--- 1.6709811687469482 seconds for one epoch ---
--- 0.3376624584197998 seconds for one epoch ---
--- 1.648932933807373 seconds for one epoch ---
--- 0.32892274856567383 seconds for one epoch ---
--- 1.6503336429595947 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07450397]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8507049]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.047758 ]
 [-0.       ]]
--- 0.3085777759552002 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2331.510498046875, (1217.2013, 1.4444003, 1112.487, 0.37771866)
   validation loss 834.4359130859375, (546.5979, 0.5728142, 286.88745, 0.37771866)
decoder loss ratio: 21176.151597, decoder SINDy loss  ratio: 0.619287
--- 0.2819063663482666 seconds for one epoch ---
--- 0.339505672454834 seconds for one epoch ---
--- 1.6330268383026123 seconds for one epoch ---
--- 0.3372366428375244 seconds for one epoch ---
--- 1.6528232097625732 seconds for one epoch ---
--- 0.33947229385375977 seconds for one epoch ---
--- 1.638460397720337 seconds for one epoch ---
--- 0.33354830741882324 seconds for one epoch ---
--- 1.6693806648254395 seconds for one epoch ---
--- 0.32991576194763184 seconds for one epoch ---
--- 1.6793632507324219 seconds for one epoch ---
--- 0.33842039108276367 seconds for one epoch ---
--- 1.6583037376403809 seconds for one epoch ---
--- 0.3516237735748291 seconds for one epoch ---
--- 1.6424098014831543 seconds for one epoch ---
--- 0.3317117691040039 seconds for one epoch ---
--- 1.6626167297363281 seconds for one epoch ---
--- 0.3428623676300049 seconds for one epoch ---
--- 1.6700704097747803 seconds for one epoch ---
--- 0.3375415802001953 seconds for one epoch ---
--- 1.668642282485962 seconds for one epoch ---
--- 0.3373880386352539 seconds for one epoch ---
--- 1.6679413318634033 seconds for one epoch ---
--- 0.3315238952636719 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0725633]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8420705]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-9.110378 ]
 [-0.       ]]
--- 0.28493738174438477 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2608.923828125, (1121.8882, 1.6101964, 1485.0481, 0.37735227)
   validation loss 806.7555541992188, (534.3043, 0.66563445, 271.4082, 0.37735227)
decoder loss ratio: 20699.877000, decoder SINDy loss  ratio: 0.585873
--- 0.31430673599243164 seconds for one epoch ---
--- 1.6552927494049072 seconds for one epoch ---
--- 0.3471031188964844 seconds for one epoch ---
--- 1.6809463500976562 seconds for one epoch ---
--- 0.3553638458251953 seconds for one epoch ---
--- 1.6904187202453613 seconds for one epoch ---
--- 0.3371548652648926 seconds for one epoch ---
--- 1.6747767925262451 seconds for one epoch ---
--- 0.32633304595947266 seconds for one epoch ---
--- 1.6463632583618164 seconds for one epoch ---
--- 0.32483363151550293 seconds for one epoch ---
--- 1.691089153289795 seconds for one epoch ---
--- 0.3328893184661865 seconds for one epoch ---
--- 1.6640369892120361 seconds for one epoch ---
--- 0.35048508644104004 seconds for one epoch ---
--- 1.6414144039154053 seconds for one epoch ---
--- 0.3436121940612793 seconds for one epoch ---
--- 1.660557508468628 seconds for one epoch ---
--- 0.34868550300598145 seconds for one epoch ---
--- 1.6555883884429932 seconds for one epoch ---
--- 0.334301233291626 seconds for one epoch ---
--- 1.7071294784545898 seconds for one epoch ---
--- 0.33806443214416504 seconds for one epoch ---
--- 1.6834602355957031 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07082427]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.83415186]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-9.177007  ]
 [-0.        ]]
--- 0.3155670166015625 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2721.907470703125, (1376.9001, 0.60418314, 1344.0254, 0.37764397)
   validation loss 930.3138427734375, (638.7752, 0.73322266, 290.4278, 0.37764397)
decoder loss ratio: 24747.260502, decoder SINDy loss  ratio: 0.626929
--- 0.27681827545166016 seconds for one epoch ---
--- 0.3436548709869385 seconds for one epoch ---
--- 1.6520400047302246 seconds for one epoch ---
--- 0.3477306365966797 seconds for one epoch ---
--- 1.6434390544891357 seconds for one epoch ---
--- 0.33574748039245605 seconds for one epoch ---
--- 1.6694250106811523 seconds for one epoch ---
--- 0.3236706256866455 seconds for one epoch ---
--- 1.6738154888153076 seconds for one epoch ---
--- 0.3371734619140625 seconds for one epoch ---
--- 1.657923936843872 seconds for one epoch ---
--- 0.3351571559906006 seconds for one epoch ---
--- 1.6771917343139648 seconds for one epoch ---
--- 0.33684325218200684 seconds for one epoch ---
--- 1.662588357925415 seconds for one epoch ---
--- 0.3385612964630127 seconds for one epoch ---
--- 1.6800158023834229 seconds for one epoch ---
--- 0.3454914093017578 seconds for one epoch ---
--- 1.6633098125457764 seconds for one epoch ---
--- 0.32819318771362305 seconds for one epoch ---
--- 1.6480367183685303 seconds for one epoch ---
--- 0.3306419849395752 seconds for one epoch ---
--- 1.6671018600463867 seconds for one epoch ---
--- 0.3316035270690918 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07178602]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.838553]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.232558]
 [-0.      ]]
--- 0.2775118350982666 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4672.4111328125, (1366.0288, 0.6746441, 3305.3289, 0.37886187)
   validation loss 891.439208984375, (610.1149, 0.7165209, 280.22894, 0.37886187)
decoder loss ratio: 23636.911563, decoder SINDy loss  ratio: 0.604914
--- 0.33332228660583496 seconds for one epoch ---
--- 1.6596131324768066 seconds for one epoch ---
--- 0.3318512439727783 seconds for one epoch ---
--- 1.6614387035369873 seconds for one epoch ---
--- 0.3406500816345215 seconds for one epoch ---
--- 1.6729309558868408 seconds for one epoch ---
--- 0.3304622173309326 seconds for one epoch ---
--- 1.686023473739624 seconds for one epoch ---
--- 0.342205286026001 seconds for one epoch ---
--- 1.6897575855255127 seconds for one epoch ---
--- 0.3330395221710205 seconds for one epoch ---
--- 1.6815345287322998 seconds for one epoch ---
--- 0.3315274715423584 seconds for one epoch ---
--- 1.698622465133667 seconds for one epoch ---
--- 0.33399033546447754 seconds for one epoch ---
--- 1.6741833686828613 seconds for one epoch ---
--- 0.3273744583129883 seconds for one epoch ---
--- 1.7083237171173096 seconds for one epoch ---
--- 0.32710862159729004 seconds for one epoch ---
--- 1.704355001449585 seconds for one epoch ---
--- 0.3231658935546875 seconds for one epoch ---
--- 1.648108720779419 seconds for one epoch ---
--- 0.33442139625549316 seconds for one epoch ---
--- 1.6988632678985596 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07169832]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8381541]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.306179 ]
 [-0.       ]]
--- 0.31396913528442383 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3024.222412109375, (1297.2006, 0.70441973, 1725.9376, 0.37961903)
   validation loss 967.9545288085938, (656.20044, 0.6983369, 310.6761, 0.37961903)
decoder loss ratio: 25422.344238, decoder SINDy loss  ratio: 0.670638
--- 0.28268957138061523 seconds for one epoch ---
--- 0.3488759994506836 seconds for one epoch ---
--- 1.69636869430542 seconds for one epoch ---
--- 0.32727837562561035 seconds for one epoch ---
--- 1.6876335144042969 seconds for one epoch ---
--- 0.3341188430786133 seconds for one epoch ---
--- 1.7176828384399414 seconds for one epoch ---
--- 0.33225512504577637 seconds for one epoch ---
--- 1.6920661926269531 seconds for one epoch ---
--- 0.3446371555328369 seconds for one epoch ---
--- 1.6692802906036377 seconds for one epoch ---
--- 0.3508429527282715 seconds for one epoch ---
--- 1.6833202838897705 seconds for one epoch ---
--- 0.33520936965942383 seconds for one epoch ---
--- 1.7278425693511963 seconds for one epoch ---
--- 0.33585357666015625 seconds for one epoch ---
--- 1.679488182067871 seconds for one epoch ---
--- 0.3401176929473877 seconds for one epoch ---
--- 1.697136640548706 seconds for one epoch ---
--- 0.33418965339660645 seconds for one epoch ---
--- 1.6948018074035645 seconds for one epoch ---
--- 0.347916841506958 seconds for one epoch ---
--- 1.6722173690795898 seconds for one epoch ---
--- 0.3307936191558838 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07107593]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8353086]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-9.365087 ]
 [-0.       ]]
--- 0.283815860748291 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3038.41015625, (1939.8417, 0.6926294, 1097.4955, 0.3804444)
   validation loss 955.3179321289062, (686.32806, 0.6851783, 267.92422, 0.3804444)
decoder loss ratio: 26589.540716, decoder SINDy loss  ratio: 0.578352
--- 0.3084592819213867 seconds for one epoch ---
--- 1.672640085220337 seconds for one epoch ---
--- 0.33861565589904785 seconds for one epoch ---
--- 1.710907220840454 seconds for one epoch ---
--- 0.3416762351989746 seconds for one epoch ---
--- 1.6973698139190674 seconds for one epoch ---
--- 0.34216737747192383 seconds for one epoch ---
--- 1.68050217628479 seconds for one epoch ---
--- 0.32871484756469727 seconds for one epoch ---
--- 1.744396686553955 seconds for one epoch ---
--- 0.3274416923522949 seconds for one epoch ---
--- 1.7111718654632568 seconds for one epoch ---
--- 0.3491077423095703 seconds for one epoch ---
--- 1.7079806327819824 seconds for one epoch ---
--- 0.3337712287902832 seconds for one epoch ---
--- 1.7017035484313965 seconds for one epoch ---
--- 0.3266289234161377 seconds for one epoch ---
--- 1.7297747135162354 seconds for one epoch ---
--- 0.3327174186706543 seconds for one epoch ---
--- 1.7186789512634277 seconds for one epoch ---
--- 0.3355214595794678 seconds for one epoch ---
--- 1.7337167263031006 seconds for one epoch ---
--- 0.33441781997680664 seconds for one epoch ---
--- 1.7207095623016357 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07104374]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8351612]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-9.424119 ]
 [-0.       ]]
--- 0.31903076171875 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3258.514404296875, (959.57806, 4.133968, 2294.4211, 0.38109943)
   validation loss 1145.7802734375, (832.03094, 0.7672249, 312.601, 0.38109943)
decoder loss ratio: 32234.323272, decoder SINDy loss  ratio: 0.674793
--- 0.27907896041870117 seconds for one epoch ---
--- 0.3444852828979492 seconds for one epoch ---
--- 1.7006075382232666 seconds for one epoch ---
--- 0.33075833320617676 seconds for one epoch ---
--- 1.7127416133880615 seconds for one epoch ---
--- 0.33356332778930664 seconds for one epoch ---
--- 1.7200860977172852 seconds for one epoch ---
--- 0.33087849617004395 seconds for one epoch ---
--- 1.7335700988769531 seconds for one epoch ---
--- 0.351240873336792 seconds for one epoch ---
--- 1.694061040878296 seconds for one epoch ---
--- 0.3391728401184082 seconds for one epoch ---
--- 1.6927242279052734 seconds for one epoch ---
--- 0.33294177055358887 seconds for one epoch ---
--- 1.697706937789917 seconds for one epoch ---
--- 0.3307063579559326 seconds for one epoch ---
--- 1.6879045963287354 seconds for one epoch ---
--- 0.3360464572906494 seconds for one epoch ---
--- 1.6970939636230469 seconds for one epoch ---
--- 0.33313870429992676 seconds for one epoch ---
--- 1.7507164478302002 seconds for one epoch ---
--- 0.34859442710876465 seconds for one epoch ---
--- 1.7392101287841797 seconds for one epoch ---
--- 0.336395263671875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06903286]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8258056]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.490331 ]
 [-0.       ]]
--- 0.27127599716186523 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3549.965576171875, (1711.2605, 3.0224442, 1835.3016, 0.38114065)
   validation loss 917.97607421875, (623.867, 0.7192497, 293.00867, 0.38114065)
decoder loss ratio: 24169.690831, decoder SINDy loss  ratio: 0.632500
--- 0.33486294746398926 seconds for one epoch ---
--- 1.7367668151855469 seconds for one epoch ---
--- 0.3338909149169922 seconds for one epoch ---
--- 1.7313041687011719 seconds for one epoch ---
--- 0.3448648452758789 seconds for one epoch ---
--- 1.6915321350097656 seconds for one epoch ---
--- 0.33429765701293945 seconds for one epoch ---
--- 1.7398333549499512 seconds for one epoch ---
--- 0.3311197757720947 seconds for one epoch ---
--- 1.6963214874267578 seconds for one epoch ---
--- 0.3312804698944092 seconds for one epoch ---
--- 1.716372013092041 seconds for one epoch ---
--- 0.33573436737060547 seconds for one epoch ---
--- 1.7525444030761719 seconds for one epoch ---
--- 0.3416867256164551 seconds for one epoch ---
--- 1.7065906524658203 seconds for one epoch ---
--- 0.3378322124481201 seconds for one epoch ---
--- 1.7212982177734375 seconds for one epoch ---
--- 0.33321428298950195 seconds for one epoch ---
--- 1.7715370655059814 seconds for one epoch ---
--- 0.33256959915161133 seconds for one epoch ---
--- 1.7366364002227783 seconds for one epoch ---
--- 0.33241868019104004 seconds for one epoch ---
--- 1.7181527614593506 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06980476]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8294256]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-9.556225 ]
 [-0.       ]]
--- 0.3107142448425293 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3167.242431640625, (1293.6921, 1.4560165, 1871.7118, 0.3825104)
   validation loss 970.5516967773438, (672.32275, 0.715341, 297.13113, 0.3825104)
decoder loss ratio: 26046.950690, decoder SINDy loss  ratio: 0.641399
--- 0.28200411796569824 seconds for one epoch ---
--- 0.33623361587524414 seconds for one epoch ---
--- 1.7378737926483154 seconds for one epoch ---
--- 0.3395562171936035 seconds for one epoch ---
--- 1.734436273574829 seconds for one epoch ---
--- 0.33228540420532227 seconds for one epoch ---
--- 1.7399344444274902 seconds for one epoch ---
--- 0.3329744338989258 seconds for one epoch ---
--- 1.7387115955352783 seconds for one epoch ---
--- 0.33662962913513184 seconds for one epoch ---
--- 1.7480998039245605 seconds for one epoch ---
--- 0.3334357738494873 seconds for one epoch ---
--- 1.7624783515930176 seconds for one epoch ---
--- 0.3335247039794922 seconds for one epoch ---
--- 1.7143032550811768 seconds for one epoch ---
--- 0.34542179107666016 seconds for one epoch ---
--- 1.7520482540130615 seconds for one epoch ---
--- 0.3319206237792969 seconds for one epoch ---
--- 1.7488858699798584 seconds for one epoch ---
--- 0.34151268005371094 seconds for one epoch ---
--- 1.7222623825073242 seconds for one epoch ---
--- 0.330951452255249 seconds for one epoch ---
--- 1.7456574440002441 seconds for one epoch ---
--- 0.3361961841583252 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07116232]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8357056]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-9.611753 ]
 [-0.       ]]
--- 0.29238033294677734 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2330.7509765625, (1152.6969, 1.0003299, 1176.6698, 0.3837802)
   validation loss 756.8189086914062, (489.27002, 0.65820396, 266.5069, 0.3837802)
decoder loss ratio: 18955.169967, decoder SINDy loss  ratio: 0.575293
--- 0.32390928268432617 seconds for one epoch ---
--- 1.743605375289917 seconds for one epoch ---
--- 0.3361363410949707 seconds for one epoch ---
--- 1.714301347732544 seconds for one epoch ---
--- 0.3400745391845703 seconds for one epoch ---
--- 1.7725706100463867 seconds for one epoch ---
--- 0.3370034694671631 seconds for one epoch ---
--- 1.736238718032837 seconds for one epoch ---
--- 0.3270711898803711 seconds for one epoch ---
--- 1.7567598819732666 seconds for one epoch ---
--- 0.34079837799072266 seconds for one epoch ---
--- 1.7593631744384766 seconds for one epoch ---
--- 0.3328549861907959 seconds for one epoch ---
--- 1.7750887870788574 seconds for one epoch ---
--- 0.3292503356933594 seconds for one epoch ---
--- 1.7619645595550537 seconds for one epoch ---
--- 0.3324007987976074 seconds for one epoch ---
--- 1.7666687965393066 seconds for one epoch ---
--- 0.3344132900238037 seconds for one epoch ---
--- 1.7792108058929443 seconds for one epoch ---
--- 0.3459312915802002 seconds for one epoch ---
--- 1.7583866119384766 seconds for one epoch ---
--- 0.33162784576416016 seconds for one epoch ---
--- 1.7428581714630127 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07137872]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8366959]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-9.670649 ]
 [-0.       ]]
--- 0.31708836555480957 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2431.89892578125, (1461.3505, 1.2985827, 968.86536, 0.38460976)
   validation loss 806.7931518554688, (525.3462, 0.76107603, 280.3013, 0.38460976)
decoder loss ratio: 20352.823496, decoder SINDy loss  ratio: 0.605070
--- 0.28041672706604004 seconds for one epoch ---
--- 0.3380298614501953 seconds for one epoch ---
--- 1.7605068683624268 seconds for one epoch ---
--- 0.34147024154663086 seconds for one epoch ---
--- 1.7482738494873047 seconds for one epoch ---
--- 0.3315308094024658 seconds for one epoch ---
--- 1.7628998756408691 seconds for one epoch ---
--- 0.3359229564666748 seconds for one epoch ---
--- 1.7636899948120117 seconds for one epoch ---
--- 0.338559627532959 seconds for one epoch ---
--- 1.742396354675293 seconds for one epoch ---
--- 0.3284912109375 seconds for one epoch ---
--- 1.785975694656372 seconds for one epoch ---
--- 0.341383695602417 seconds for one epoch ---
--- 1.7431862354278564 seconds for one epoch ---
--- 0.3334465026855469 seconds for one epoch ---
--- 1.7655985355377197 seconds for one epoch ---
--- 0.32929062843322754 seconds for one epoch ---
--- 1.7755963802337646 seconds for one epoch ---
--- 0.3337545394897461 seconds for one epoch ---
--- 1.7713327407836914 seconds for one epoch ---
--- 0.3204822540283203 seconds for one epoch ---
--- 1.7500267028808594 seconds for one epoch ---
--- 0.32744932174682617 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0701867]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.83120394]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-9.729183  ]
 [-0.        ]]
--- 0.28206777572631836 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3609.879150390625, (1698.1151, 2.7264621, 1908.6526, 0.3849958)
   validation loss 998.4852905273438, (688.5637, 0.7258865, 308.81067, 0.3849958)
decoder loss ratio: 26676.153939, decoder SINDy loss  ratio: 0.666611
--- 0.3378419876098633 seconds for one epoch ---
--- 1.7568867206573486 seconds for one epoch ---
--- 0.3388407230377197 seconds for one epoch ---
--- 1.7790274620056152 seconds for one epoch ---
--- 0.33490419387817383 seconds for one epoch ---
--- 1.7528934478759766 seconds for one epoch ---
--- 0.340435266494751 seconds for one epoch ---
--- 1.7513089179992676 seconds for one epoch ---
--- 0.33704376220703125 seconds for one epoch ---
--- 1.7547497749328613 seconds for one epoch ---
--- 0.34100914001464844 seconds for one epoch ---
--- 1.7528948783874512 seconds for one epoch ---
--- 0.32930469512939453 seconds for one epoch ---
--- 1.782940149307251 seconds for one epoch ---
--- 0.33758974075317383 seconds for one epoch ---
--- 1.7887170314788818 seconds for one epoch ---
--- 0.32692718505859375 seconds for one epoch ---
--- 1.7702746391296387 seconds for one epoch ---
--- 0.3441050052642822 seconds for one epoch ---
--- 1.750643014907837 seconds for one epoch ---
--- 0.3208010196685791 seconds for one epoch ---
--- 1.772146463394165 seconds for one epoch ---
--- 0.3317298889160156 seconds for one epoch ---
--- 1.7930254936218262 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07138029]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8367035]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.782069 ]
 [-0.       ]]
--- 0.31751227378845215 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1935.3907470703125, (1027.9473, 0.98666924, 906.07056, 0.38619122)
   validation loss 1035.9140625, (776.3578, 0.7257666, 258.4443, 0.38619122)
decoder loss ratio: 30077.448527, decoder SINDy loss  ratio: 0.557888
--- 0.2796318531036377 seconds for one epoch ---
--- 0.3361837863922119 seconds for one epoch ---
--- 1.7798221111297607 seconds for one epoch ---
--- 0.3411846160888672 seconds for one epoch ---
--- 1.7566044330596924 seconds for one epoch ---
--- 0.3299906253814697 seconds for one epoch ---
--- 1.7834343910217285 seconds for one epoch ---
--- 0.3289017677307129 seconds for one epoch ---
--- 1.7547342777252197 seconds for one epoch ---
--- 0.3326592445373535 seconds for one epoch ---
--- 1.7903027534484863 seconds for one epoch ---
--- 0.33524656295776367 seconds for one epoch ---
--- 1.7615647315979004 seconds for one epoch ---
--- 0.3344440460205078 seconds for one epoch ---
--- 1.7851271629333496 seconds for one epoch ---
--- 0.34303951263427734 seconds for one epoch ---
--- 1.7634084224700928 seconds for one epoch ---
--- 0.33809399604797363 seconds for one epoch ---
--- 1.7909762859344482 seconds for one epoch ---
--- 0.3323683738708496 seconds for one epoch ---
--- 1.794860601425171 seconds for one epoch ---
--- 0.3383784294128418 seconds for one epoch ---
--- 1.8025920391082764 seconds for one epoch ---
--- 0.33003973960876465 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07171255]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8382185]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-9.838091 ]
 [-0.       ]]
--- 0.2763526439666748 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2678.38720703125, (994.87854, 1.1858578, 1681.9358, 0.3870282)
   validation loss 834.3782348632812, (578.0362, 0.69420916, 255.26079, 0.3870282)
decoder loss ratio: 22394.125665, decoder SINDy loss  ratio: 0.551016
--- 0.3404819965362549 seconds for one epoch ---
--- 1.7567245960235596 seconds for one epoch ---
--- 0.33484840393066406 seconds for one epoch ---
--- 1.7687184810638428 seconds for one epoch ---
--- 0.3415215015411377 seconds for one epoch ---
--- 1.7957167625427246 seconds for one epoch ---
--- 0.3280360698699951 seconds for one epoch ---
--- 1.8007676601409912 seconds for one epoch ---
--- 0.3312187194824219 seconds for one epoch ---
--- 1.7710366249084473 seconds for one epoch ---
--- 0.3335866928100586 seconds for one epoch ---
--- 1.791686773300171 seconds for one epoch ---
--- 0.34559202194213867 seconds for one epoch ---
--- 1.7742667198181152 seconds for one epoch ---
--- 0.33687257766723633 seconds for one epoch ---
--- 1.8062663078308105 seconds for one epoch ---
--- 0.34586310386657715 seconds for one epoch ---
--- 1.792065143585205 seconds for one epoch ---
--- 0.3338801860809326 seconds for one epoch ---
--- 1.7793378829956055 seconds for one epoch ---
--- 0.333050012588501 seconds for one epoch ---
--- 1.8073627948760986 seconds for one epoch ---
--- 0.338284969329834 seconds for one epoch ---
--- 1.8127000331878662 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07194027]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.83925396]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-9.892878  ]
 [-0.        ]]
--- 0.3075733184814453 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2060.7216796875, (1025.2318, 2.7995057, 1032.302, 0.38807485)
   validation loss 929.0523681640625, (634.6622, 0.700597, 293.3015, 0.38807485)
decoder loss ratio: 24587.914304, decoder SINDy loss  ratio: 0.633133
--- 0.2768683433532715 seconds for one epoch ---
--- 0.33458423614501953 seconds for one epoch ---
--- 1.7780747413635254 seconds for one epoch ---
--- 0.34107112884521484 seconds for one epoch ---
--- 1.8127920627593994 seconds for one epoch ---
--- 0.3290746212005615 seconds for one epoch ---
--- 1.8032114505767822 seconds for one epoch ---
--- 0.33307957649230957 seconds for one epoch ---
--- 1.8097212314605713 seconds for one epoch ---
--- 0.3354337215423584 seconds for one epoch ---
--- 1.806018590927124 seconds for one epoch ---
--- 0.3359720706939697 seconds for one epoch ---
--- 1.7842228412628174 seconds for one epoch ---
--- 0.3368847370147705 seconds for one epoch ---
--- 1.8231773376464844 seconds for one epoch ---
--- 0.3294529914855957 seconds for one epoch ---
--- 1.7811052799224854 seconds for one epoch ---
--- 0.33183932304382324 seconds for one epoch ---
--- 1.8307960033416748 seconds for one epoch ---
--- 0.34240198135375977 seconds for one epoch ---
--- 1.8003859519958496 seconds for one epoch ---
--- 0.33391499519348145 seconds for one epoch ---
--- 1.8222484588623047 seconds for one epoch ---
--- 0.3358035087585449 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07251697]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.84186184]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-9.946197  ]
 [-0.        ]]
--- 0.2841911315917969 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3023.260986328125, (1408.0637, 0.92921823, 1613.879, 0.3889603)
   validation loss 794.8850708007812, (524.3105, 0.71511316, 269.47052, 0.3889603)
decoder loss ratio: 20312.698464, decoder SINDy loss  ratio: 0.581690
--- 0.33357882499694824 seconds for one epoch ---
--- 1.7930917739868164 seconds for one epoch ---
--- 0.34282994270324707 seconds for one epoch ---
--- 1.7868082523345947 seconds for one epoch ---
--- 0.3375859260559082 seconds for one epoch ---
--- 1.801462173461914 seconds for one epoch ---
--- 0.3381342887878418 seconds for one epoch ---
--- 1.8327174186706543 seconds for one epoch ---
--- 0.34069252014160156 seconds for one epoch ---
--- 1.8289780616760254 seconds for one epoch ---
--- 0.34572744369506836 seconds for one epoch ---
--- 1.787104606628418 seconds for one epoch ---
--- 0.33682775497436523 seconds for one epoch ---
--- 1.8328311443328857 seconds for one epoch ---
--- 0.3358485698699951 seconds for one epoch ---
--- 1.789210319519043 seconds for one epoch ---
--- 0.3417785167694092 seconds for one epoch ---
--- 1.8446476459503174 seconds for one epoch ---
--- 0.3386991024017334 seconds for one epoch ---
--- 1.834519863128662 seconds for one epoch ---
--- 0.3369894027709961 seconds for one epoch ---
--- 1.8268837928771973 seconds for one epoch ---
--- 0.3335576057434082 seconds for one epoch ---
--- 1.8416669368743896 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07227346]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8407637]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.996102 ]
 [-0.       ]]
--- 0.31234145164489746 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2719.652099609375, (1083.8545, 5.093346, 1630.3148, 0.38952094)
   validation loss 814.26953125, (539.5089, 0.80182236, 273.56927, 0.38952094)
decoder loss ratio: 20901.511846, decoder SINDy loss  ratio: 0.590538
--- 0.278334379196167 seconds for one epoch ---
--- 0.33418917655944824 seconds for one epoch ---
--- 1.8025174140930176 seconds for one epoch ---
--- 0.33112502098083496 seconds for one epoch ---
--- 1.8367438316345215 seconds for one epoch ---
--- 0.3367190361022949 seconds for one epoch ---
--- 1.8241791725158691 seconds for one epoch ---
--- 0.3302803039550781 seconds for one epoch ---
--- 1.8131237030029297 seconds for one epoch ---
--- 0.3230173587799072 seconds for one epoch ---
--- 1.809633493423462 seconds for one epoch ---
--- 0.3361201286315918 seconds for one epoch ---
--- 1.8140974044799805 seconds for one epoch ---
--- 0.33402347564697266 seconds for one epoch ---
--- 1.8147847652435303 seconds for one epoch ---
--- 0.3291809558868408 seconds for one epoch ---
--- 1.8530077934265137 seconds for one epoch ---
--- 0.3365817070007324 seconds for one epoch ---
--- 1.8421909809112549 seconds for one epoch ---
--- 0.3306565284729004 seconds for one epoch ---
--- 1.8133997917175293 seconds for one epoch ---
--- 0.33564281463623047 seconds for one epoch ---
--- 1.8229641914367676 seconds for one epoch ---
--- 0.3332090377807617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07235216]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.8411183]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [-10.044771 ]
 [ -0.       ]]
--- 0.274188756942749 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2316.840087890625, (1007.2269, 2.1545076, 1307.069, 0.38967904)
   validation loss 865.8515625, (577.63275, 0.8018044, 287.02728, 0.38967904)
decoder loss ratio: 22378.495606, decoder SINDy loss  ratio: 0.619589
--- 0.31372618675231934 seconds for one epoch ---
--- 1.8327038288116455 seconds for one epoch ---
--- 0.3335704803466797 seconds for one epoch ---
--- 1.872683048248291 seconds for one epoch ---
--- 0.3330714702606201 seconds for one epoch ---
--- 1.8409950733184814 seconds for one epoch ---
--- 0.3226346969604492 seconds for one epoch ---
--- 1.8108301162719727 seconds for one epoch ---
--- 0.32814788818359375 seconds for one epoch ---
--- 1.8399934768676758 seconds for one epoch ---
--- 0.3286862373352051 seconds for one epoch ---
--- 1.818877935409546 seconds for one epoch ---
--- 0.3320949077606201 seconds for one epoch ---
--- 1.8118431568145752 seconds for one epoch ---
--- 0.3314487934112549 seconds for one epoch ---
--- 1.8502936363220215 seconds for one epoch ---
--- 0.33122777938842773 seconds for one epoch ---
--- 1.8188037872314453 seconds for one epoch ---
--- 0.3326702117919922 seconds for one epoch ---
--- 1.8513779640197754 seconds for one epoch ---
--- 0.3327639102935791 seconds for one epoch ---
--- 1.8786451816558838 seconds for one epoch ---
--- 0.3360574245452881 seconds for one epoch ---
--- 1.863215446472168 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07144558]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [  0.        ]
 [ -0.83700144]
 [  0.        ]
 [ -0.        ]
 [ -0.        ]
 [-10.081189  ]
 [ -0.        ]]
--- 0.31436657905578613 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1869.7303466796875, (977.5727, 0.5822029, 891.186, 0.38948092)
   validation loss 959.3637084960938, (666.7664, 1.0989603, 291.1089, 0.38948092)
decoder loss ratio: 25831.688608, decoder SINDy loss  ratio: 0.628399
THRESHOLDING: 1 active coefficients
--- 1.7924537658691406 seconds for one epoch ---
--- 0.3327944278717041 seconds for one epoch ---
--- 1.8517627716064453 seconds for one epoch ---
--- 0.34400057792663574 seconds for one epoch ---
--- 1.8350698947906494 seconds for one epoch ---
--- 0.32744336128234863 seconds for one epoch ---
--- 1.8168222904205322 seconds for one epoch ---
--- 0.3374330997467041 seconds for one epoch ---
--- 1.8616316318511963 seconds for one epoch ---
--- 0.3526475429534912 seconds for one epoch ---
--- 1.8243722915649414 seconds for one epoch ---
--- 0.33921217918395996 seconds for one epoch ---
--- 1.8770158290863037 seconds for one epoch ---
--- 0.32268786430358887 seconds for one epoch ---
--- 1.819617509841919 seconds for one epoch ---
--- 0.34102678298950195 seconds for one epoch ---
--- 1.834214687347412 seconds for one epoch ---
--- 0.3270530700683594 seconds for one epoch ---
--- 1.864349126815796 seconds for one epoch ---
--- 0.3403434753417969 seconds for one epoch ---
--- 1.86574387550354 seconds for one epoch ---
--- 0.33463597297668457 seconds for one epoch ---
--- 1.8892912864685059 seconds for one epoch ---
--- 0.3340184688568115 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.139049]
 [ -0.      ]]
--- 0.2758607864379883 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2954.3935546875, (1311.3446, 1.0509088, 1641.6768, 0.32137713)
   validation loss 962.478271484375, (656.27325, 1.1489447, 304.73474, 0.32137713)
decoder loss ratio: 25425.165216, decoder SINDy loss  ratio: 0.657813
--- 0.31853747367858887 seconds for one epoch ---
--- 1.848684310913086 seconds for one epoch ---
--- 0.32510900497436523 seconds for one epoch ---
--- 1.8731131553649902 seconds for one epoch ---
--- 0.36797189712524414 seconds for one epoch ---
--- 1.8574421405792236 seconds for one epoch ---
--- 0.33411550521850586 seconds for one epoch ---
--- 1.8531639575958252 seconds for one epoch ---
--- 0.332935094833374 seconds for one epoch ---
--- 1.8662164211273193 seconds for one epoch ---
--- 0.33873605728149414 seconds for one epoch ---
--- 1.8726568222045898 seconds for one epoch ---
--- 0.33084821701049805 seconds for one epoch ---
--- 1.9174296855926514 seconds for one epoch ---
--- 0.3358027935028076 seconds for one epoch ---
--- 1.8916795253753662 seconds for one epoch ---
--- 0.3300302028656006 seconds for one epoch ---
--- 1.8734264373779297 seconds for one epoch ---
--- 0.33739781379699707 seconds for one epoch ---
--- 1.8943898677825928 seconds for one epoch ---
--- 0.3307015895843506 seconds for one epoch ---
--- 1.8657758235931396 seconds for one epoch ---
--- 0.33460140228271484 seconds for one epoch ---
--- 1.903644323348999 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.203101]
 [ -0.      ]]
--- 0.31399011611938477 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2499.00244140625, (1088.3016, 2.2229233, 1408.1558, 0.32233813)
   validation loss 903.36181640625, (610.0625, 0.91630566, 292.06067, 0.32233813)
decoder loss ratio: 23634.880365, decoder SINDy loss  ratio: 0.630454
--- 0.2877836227416992 seconds for one epoch ---
--- 0.33203554153442383 seconds for one epoch ---
--- 1.8859143257141113 seconds for one epoch ---
--- 0.3385913372039795 seconds for one epoch ---
--- 1.8985357284545898 seconds for one epoch ---
--- 0.33757829666137695 seconds for one epoch ---
--- 1.8807942867279053 seconds for one epoch ---
--- 0.3292226791381836 seconds for one epoch ---
--- 1.904879093170166 seconds for one epoch ---
--- 0.33521032333374023 seconds for one epoch ---
--- 1.8844714164733887 seconds for one epoch ---
--- 0.33396077156066895 seconds for one epoch ---
--- 1.900156021118164 seconds for one epoch ---
--- 0.33160400390625 seconds for one epoch ---
--- 1.879059076309204 seconds for one epoch ---
--- 0.33797407150268555 seconds for one epoch ---
--- 1.8801569938659668 seconds for one epoch ---
--- 0.33318662643432617 seconds for one epoch ---
--- 1.880220890045166 seconds for one epoch ---
--- 0.3375523090362549 seconds for one epoch ---
--- 1.882472038269043 seconds for one epoch ---
--- 0.3323490619659424 seconds for one epoch ---
--- 1.9041152000427246 seconds for one epoch ---
--- 0.3409392833709717 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.263095]
 [ -0.      ]]
--- 0.2747068405151367 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3095.44482421875, (1244.2821, 4.065009, 1846.7743, 0.3232377)
   validation loss 788.15771484375, (514.1614, 0.85702574, 272.81604, 0.3232377)
decoder loss ratio: 19919.504367, decoder SINDy loss  ratio: 0.588912
--- 0.3188502788543701 seconds for one epoch ---
--- 1.892209768295288 seconds for one epoch ---
--- 0.34885621070861816 seconds for one epoch ---
--- 1.883319616317749 seconds for one epoch ---
--- 0.33299708366394043 seconds for one epoch ---
--- 1.8848707675933838 seconds for one epoch ---
--- 0.34293484687805176 seconds for one epoch ---
--- 1.8918862342834473 seconds for one epoch ---
--- 0.3377993106842041 seconds for one epoch ---
--- 1.9095733165740967 seconds for one epoch ---
--- 0.33460187911987305 seconds for one epoch ---
--- 1.9194138050079346 seconds for one epoch ---
--- 0.3276355266571045 seconds for one epoch ---
--- 1.890272855758667 seconds for one epoch ---
--- 0.34409332275390625 seconds for one epoch ---
--- 1.9163200855255127 seconds for one epoch ---
--- 0.34810662269592285 seconds for one epoch ---
--- 1.8853280544281006 seconds for one epoch ---
--- 0.32437896728515625 seconds for one epoch ---
--- 1.8803281784057617 seconds for one epoch ---
--- 0.3377692699432373 seconds for one epoch ---
--- 1.9224107265472412 seconds for one epoch ---
--- 0.34026241302490234 seconds for one epoch ---
--- 1.9067103862762451 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.319119]
 [ -0.      ]]
--- 0.31885242462158203 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2735.2734375, (1189.2047, 0.9573291, 1544.7875, 0.324081)
   validation loss 848.3157958984375, (573.3659, 0.8413085, 273.78445, 0.324081)
decoder loss ratio: 22213.190596, decoder SINDy loss  ratio: 0.591002
--- 0.2848930358886719 seconds for one epoch ---
--- 0.3419761657714844 seconds for one epoch ---
--- 1.9176712036132812 seconds for one epoch ---
--- 0.33550333976745605 seconds for one epoch ---
--- 1.9198310375213623 seconds for one epoch ---
--- 0.3351261615753174 seconds for one epoch ---
--- 1.8869178295135498 seconds for one epoch ---
--- 0.3352658748626709 seconds for one epoch ---
--- 1.8872525691986084 seconds for one epoch ---
--- 0.33812475204467773 seconds for one epoch ---
--- 1.928788661956787 seconds for one epoch ---
--- 0.3399937152862549 seconds for one epoch ---
--- 1.9134535789489746 seconds for one epoch ---
--- 0.3365957736968994 seconds for one epoch ---
--- 1.908825159072876 seconds for one epoch ---
--- 0.3322477340698242 seconds for one epoch ---
--- 1.9020113945007324 seconds for one epoch ---
--- 0.3313415050506592 seconds for one epoch ---
--- 1.8973371982574463 seconds for one epoch ---
--- 0.3374600410461426 seconds for one epoch ---
--- 1.950075626373291 seconds for one epoch ---
--- 0.3275315761566162 seconds for one epoch ---
--- 1.931112289428711 seconds for one epoch ---
--- 0.3290596008300781 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.378781]
 [ -0.      ]]
--- 0.28209948539733887 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10337.939453125, (4818.8374, 18.118612, 5500.658, 0.3249862)
   validation loss 1016.2581787109375, (707.81696, 0.7963769, 307.31982, 0.3249862)
decoder loss ratio: 27422.057683, decoder SINDy loss  ratio: 0.663393
--- 0.32688236236572266 seconds for one epoch ---
--- 1.904581069946289 seconds for one epoch ---
--- 0.3542623519897461 seconds for one epoch ---
--- 1.906466007232666 seconds for one epoch ---
--- 0.3287672996520996 seconds for one epoch ---
--- 1.9415287971496582 seconds for one epoch ---
--- 0.33733034133911133 seconds for one epoch ---
--- 1.9321184158325195 seconds for one epoch ---
--- 0.33217906951904297 seconds for one epoch ---
--- 1.9513943195343018 seconds for one epoch ---
--- 0.3349132537841797 seconds for one epoch ---
--- 1.9096605777740479 seconds for one epoch ---
--- 0.3320603370666504 seconds for one epoch ---
--- 1.9173429012298584 seconds for one epoch ---
--- 0.33675384521484375 seconds for one epoch ---
--- 1.9471008777618408 seconds for one epoch ---
--- 0.3275332450866699 seconds for one epoch ---
--- 1.9126646518707275 seconds for one epoch ---
--- 0.34510111808776855 seconds for one epoch ---
--- 1.9308257102966309 seconds for one epoch ---
--- 0.33370280265808105 seconds for one epoch ---
--- 1.946547031402588 seconds for one epoch ---
--- 0.3318662643432617 seconds for one epoch ---
--- 1.9167518615722656 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.429224]
 [ -0.      ]]
--- 0.32894039154052734 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3009.71337890625, (2061.5183, 3.3988395, 944.47046, 0.3257812)
   validation loss 871.2236328125, (570.27484, 0.8546418, 299.76834, 0.3257812)
decoder loss ratio: 22093.437393, decoder SINDy loss  ratio: 0.647092
--- 0.27692079544067383 seconds for one epoch ---
--- 0.3442347049713135 seconds for one epoch ---
--- 1.9188191890716553 seconds for one epoch ---
--- 0.3440718650817871 seconds for one epoch ---
--- 1.939908742904663 seconds for one epoch ---
--- 0.3482241630554199 seconds for one epoch ---
--- 1.9178781509399414 seconds for one epoch ---
--- 0.33869075775146484 seconds for one epoch ---
--- 1.9102203845977783 seconds for one epoch ---
--- 0.3440239429473877 seconds for one epoch ---
--- 1.9125950336456299 seconds for one epoch ---
--- 0.33217573165893555 seconds for one epoch ---
--- 1.936734914779663 seconds for one epoch ---
--- 0.3336632251739502 seconds for one epoch ---
--- 1.926866054534912 seconds for one epoch ---
--- 0.3334465026855469 seconds for one epoch ---
--- 1.94899582862854 seconds for one epoch ---
--- 0.33530592918395996 seconds for one epoch ---
--- 1.953493595123291 seconds for one epoch ---
--- 0.34346604347229004 seconds for one epoch ---
--- 1.9245145320892334 seconds for one epoch ---
--- 0.33675074577331543 seconds for one epoch ---
--- 1.9523630142211914 seconds for one epoch ---
--- 0.3442826271057129 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.494172]
 [ -0.      ]]
--- 0.27939605712890625 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2496.42724609375, (1240.2715, 0.727866, 1255.1012, 0.326768)
   validation loss 841.35400390625, (563.38654, 0.80638915, 276.83426, 0.326768)
decoder loss ratio: 21826.572473, decoder SINDy loss  ratio: 0.597586
--- 0.31949687004089355 seconds for one epoch ---
--- 1.9379935264587402 seconds for one epoch ---
--- 0.34195709228515625 seconds for one epoch ---
--- 1.9509329795837402 seconds for one epoch ---
--- 0.34001994132995605 seconds for one epoch ---
--- 1.947343111038208 seconds for one epoch ---
--- 0.3279240131378174 seconds for one epoch ---
--- 1.9469642639160156 seconds for one epoch ---
--- 0.3390471935272217 seconds for one epoch ---
--- 1.9659249782562256 seconds for one epoch ---
--- 0.3367350101470947 seconds for one epoch ---
--- 1.9858424663543701 seconds for one epoch ---
--- 0.32963085174560547 seconds for one epoch ---
--- 1.9787614345550537 seconds for one epoch ---
--- 0.33268117904663086 seconds for one epoch ---
--- 1.9353668689727783 seconds for one epoch ---
--- 0.3326094150543213 seconds for one epoch ---
--- 1.9785442352294922 seconds for one epoch ---
--- 0.32935190200805664 seconds for one epoch ---
--- 1.9721770286560059 seconds for one epoch ---
--- 0.33288097381591797 seconds for one epoch ---
--- 1.952754020690918 seconds for one epoch ---
--- 0.33908557891845703 seconds for one epoch ---
--- 1.9848268032073975 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.553943]
 [ -0.      ]]
--- 0.3066251277923584 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4918.68212890625, (2434.2246, 1.1350312, 2482.9946, 0.3277346)
   validation loss 858.278564453125, (570.86206, 0.8231826, 286.2656, 0.3277346)
decoder loss ratio: 22116.187286, decoder SINDy loss  ratio: 0.617945
--- 0.2845313549041748 seconds for one epoch ---
--- 0.32444190979003906 seconds for one epoch ---
--- 1.9415934085845947 seconds for one epoch ---
--- 0.34334301948547363 seconds for one epoch ---
--- 1.9247138500213623 seconds for one epoch ---
--- 0.3365755081176758 seconds for one epoch ---
--- 1.9604320526123047 seconds for one epoch ---
--- 0.33472681045532227 seconds for one epoch ---
--- 1.956040620803833 seconds for one epoch ---
--- 0.3358800411224365 seconds for one epoch ---
--- 1.9652645587921143 seconds for one epoch ---
--- 0.3324165344238281 seconds for one epoch ---
--- 1.9943201541900635 seconds for one epoch ---
--- 0.31760621070861816 seconds for one epoch ---
--- 1.9660115242004395 seconds for one epoch ---
--- 0.33937573432922363 seconds for one epoch ---
--- 1.95766019821167 seconds for one epoch ---
--- 0.3210740089416504 seconds for one epoch ---
--- 1.9396579265594482 seconds for one epoch ---
--- 0.3314852714538574 seconds for one epoch ---
--- 1.9234824180603027 seconds for one epoch ---
--- 0.32497143745422363 seconds for one epoch ---
--- 1.9727122783660889 seconds for one epoch ---
--- 0.32949376106262207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.621525]
 [ -0.      ]]
--- 0.28014540672302246 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2017.8387451171875, (1258.3943, 0.44280648, 758.67303, 0.32873517)
   validation loss 1061.6839599609375, (770.2248, 0.8324156, 290.29807, 0.32873517)
decoder loss ratio: 29839.845630, decoder SINDy loss  ratio: 0.626649
--- 0.32761716842651367 seconds for one epoch ---
--- 1.9477014541625977 seconds for one epoch ---
--- 0.32496166229248047 seconds for one epoch ---
--- 1.9502239227294922 seconds for one epoch ---
--- 0.3321828842163086 seconds for one epoch ---
--- 1.9600293636322021 seconds for one epoch ---
--- 0.34175539016723633 seconds for one epoch ---
--- 1.9545960426330566 seconds for one epoch ---
--- 0.32811403274536133 seconds for one epoch ---
--- 1.992948293685913 seconds for one epoch ---
--- 0.33913278579711914 seconds for one epoch ---
--- 1.9663500785827637 seconds for one epoch ---
--- 0.33628201484680176 seconds for one epoch ---
--- 1.9572014808654785 seconds for one epoch ---
--- 0.3416414260864258 seconds for one epoch ---
--- 1.9888105392456055 seconds for one epoch ---
--- 0.32707929611206055 seconds for one epoch ---
--- 1.9634959697723389 seconds for one epoch ---
--- 0.33317017555236816 seconds for one epoch ---
--- 2.0199432373046875 seconds for one epoch ---
--- 0.3338022232055664 seconds for one epoch ---
--- 2.001272201538086 seconds for one epoch ---
--- 0.32583093643188477 seconds for one epoch ---
--- 1.9774651527404785 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.687028]
 [ -0.      ]]
--- 0.31061720848083496 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1779.8873291015625, (955.55505, 1.150677, 822.8518, 0.32970512)
   validation loss 984.074951171875, (692.5266, 0.9928167, 290.22583, 0.32970512)
decoder loss ratio: 26829.683202, decoder SINDy loss  ratio: 0.626493
--- 0.2732057571411133 seconds for one epoch ---
--- 0.3397696018218994 seconds for one epoch ---
--- 1.9620625972747803 seconds for one epoch ---
--- 0.33350205421447754 seconds for one epoch ---
--- 1.9735500812530518 seconds for one epoch ---
--- 0.34508562088012695 seconds for one epoch ---
--- 1.9738051891326904 seconds for one epoch ---
--- 0.3257331848144531 seconds for one epoch ---
--- 1.9849584102630615 seconds for one epoch ---
--- 0.3323488235473633 seconds for one epoch ---
--- 1.9702894687652588 seconds for one epoch ---
--- 0.33338403701782227 seconds for one epoch ---
--- 2.0064258575439453 seconds for one epoch ---
--- 0.35035276412963867 seconds for one epoch ---
--- 2.016552448272705 seconds for one epoch ---
--- 0.3404402732849121 seconds for one epoch ---
--- 2.019761800765991 seconds for one epoch ---
--- 0.3351757526397705 seconds for one epoch ---
--- 2.0018439292907715 seconds for one epoch ---
--- 0.33353209495544434 seconds for one epoch ---
--- 2.0071005821228027 seconds for one epoch ---
--- 0.3388087749481201 seconds for one epoch ---
--- 2.019232988357544 seconds for one epoch ---
--- 0.34293508529663086 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.749774]
 [ -0.      ]]
--- 0.2716708183288574 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4332.14013671875, (1782.6783, 2.0795329, 2547.0515, 0.330679)
   validation loss 954.6918334960938, (671.7061, 0.8453079, 281.8097, 0.330679)
decoder loss ratio: 26023.061056, decoder SINDy loss  ratio: 0.608326
--- 0.3262615203857422 seconds for one epoch ---
--- 1.9902591705322266 seconds for one epoch ---
--- 0.334273099899292 seconds for one epoch ---
--- 2.0112924575805664 seconds for one epoch ---
--- 0.3417658805847168 seconds for one epoch ---
--- 1.9821887016296387 seconds for one epoch ---
--- 0.32523417472839355 seconds for one epoch ---
--- 2.0019025802612305 seconds for one epoch ---
--- 0.3261268138885498 seconds for one epoch ---
--- 2.0328261852264404 seconds for one epoch ---
--- 0.33459997177124023 seconds for one epoch ---
--- 2.0027642250061035 seconds for one epoch ---
--- 0.3296825885772705 seconds for one epoch ---
--- 1.997314453125 seconds for one epoch ---
--- 0.3260788917541504 seconds for one epoch ---
--- 2.0098187923431396 seconds for one epoch ---
--- 0.3286912441253662 seconds for one epoch ---
--- 1.997474193572998 seconds for one epoch ---
--- 0.3399388790130615 seconds for one epoch ---
--- 2.026327133178711 seconds for one epoch ---
--- 0.33818793296813965 seconds for one epoch ---
--- 2.025949478149414 seconds for one epoch ---
--- 0.7067868709564209 seconds for one epoch ---
--- 2.0079638957977295 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-10.8022375]
 [ -0.       ]]
--- 0.31888294219970703 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4237.6708984375, (1497.6318, 1.8411541, 2737.8662, 0.3314716)
   validation loss 910.7269897460938, (615.4124, 0.8745078, 294.10858, 0.3314716)
decoder loss ratio: 23842.145343, decoder SINDy loss  ratio: 0.634875
--- 0.26900625228881836 seconds for one epoch ---
--- 0.3454759120941162 seconds for one epoch ---
--- 1.981703519821167 seconds for one epoch ---
--- 0.3320591449737549 seconds for one epoch ---
--- 1.9816076755523682 seconds for one epoch ---
--- 0.332561731338501 seconds for one epoch ---
--- 1.9882166385650635 seconds for one epoch ---
--- 0.3382704257965088 seconds for one epoch ---
--- 1.9891741275787354 seconds for one epoch ---
--- 0.33411335945129395 seconds for one epoch ---
--- 2.0296449661254883 seconds for one epoch ---
--- 0.31557774543762207 seconds for one epoch ---
--- 2.0267202854156494 seconds for one epoch ---
--- 0.3349156379699707 seconds for one epoch ---
--- 2.0021541118621826 seconds for one epoch ---
--- 0.32872486114501953 seconds for one epoch ---
--- 2.036931276321411 seconds for one epoch ---
--- 0.33696556091308594 seconds for one epoch ---
--- 2.0245490074157715 seconds for one epoch ---
--- 0.3452444076538086 seconds for one epoch ---
--- 2.000684976577759 seconds for one epoch ---
--- 0.3305933475494385 seconds for one epoch ---
--- 2.0397305488586426 seconds for one epoch ---
--- 0.3337702751159668 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-10.8593445]
 [ -0.       ]]
--- 0.27031588554382324 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2178.133056640625, (790.2827, 1.1404248, 1386.3777, 0.33237615)
   validation loss 856.999755859375, (585.2138, 0.7958379, 270.6577, 0.33237615)
decoder loss ratio: 22672.198826, decoder SINDy loss  ratio: 0.584253
--- 0.32683372497558594 seconds for one epoch ---
--- 2.0039966106414795 seconds for one epoch ---
--- 0.3237459659576416 seconds for one epoch ---
--- 2.028796434402466 seconds for one epoch ---
--- 0.3311960697174072 seconds for one epoch ---
--- 2.028742790222168 seconds for one epoch ---
--- 0.3314018249511719 seconds for one epoch ---
--- 2.0016119480133057 seconds for one epoch ---
--- 0.33150458335876465 seconds for one epoch ---
--- 2.05157470703125 seconds for one epoch ---
--- 0.34889817237854004 seconds for one epoch ---
--- 2.0391929149627686 seconds for one epoch ---
--- 0.34135866165161133 seconds for one epoch ---
--- 2.012990951538086 seconds for one epoch ---
--- 0.3403325080871582 seconds for one epoch ---
--- 2.008117198944092 seconds for one epoch ---
--- 0.33176183700561523 seconds for one epoch ---
--- 2.012275457382202 seconds for one epoch ---
--- 0.3279595375061035 seconds for one epoch ---
--- 2.0254311561584473 seconds for one epoch ---
--- 0.330608606338501 seconds for one epoch ---
--- 2.046717643737793 seconds for one epoch ---
--- 0.34268999099731445 seconds for one epoch ---
--- 2.0245399475097656 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.919906]
 [ -0.      ]]
--- 0.3232278823852539 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2259.141845703125, (1117.4076, 2.700765, 1138.7003, 0.3333539)
   validation loss 730.4832153320312, (452.97836, 0.64720553, 276.52426, 0.3333539)
decoder loss ratio: 17549.168189, decoder SINDy loss  ratio: 0.596917
--- 0.28241419792175293 seconds for one epoch ---
--- 0.3331737518310547 seconds for one epoch ---
--- 2.051405668258667 seconds for one epoch ---
--- 0.31549715995788574 seconds for one epoch ---
--- 2.0149664878845215 seconds for one epoch ---
--- 0.33739161491394043 seconds for one epoch ---
--- 2.0704538822174072 seconds for one epoch ---
--- 0.34143781661987305 seconds for one epoch ---
--- 2.0152671337127686 seconds for one epoch ---
--- 0.32866454124450684 seconds for one epoch ---
--- 2.0484235286712646 seconds for one epoch ---
--- 0.33565521240234375 seconds for one epoch ---
--- 2.061056137084961 seconds for one epoch ---
--- 0.33437013626098633 seconds for one epoch ---
--- 2.0196118354797363 seconds for one epoch ---
--- 0.3313136100769043 seconds for one epoch ---
--- 2.0601556301116943 seconds for one epoch ---
--- 0.33321404457092285 seconds for one epoch ---
--- 2.0284271240234375 seconds for one epoch ---
--- 0.342958927154541 seconds for one epoch ---
--- 2.0158371925354004 seconds for one epoch ---
--- 0.33167505264282227 seconds for one epoch ---
--- 2.064115285873413 seconds for one epoch ---
--- 0.3417816162109375 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.979424]
 [ -0.      ]]
--- 0.27997589111328125 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4380.45751953125, (2194.1672, 5.313036, 2180.643, 0.33428553)
   validation loss 844.2371826171875, (554.3245, 0.7073189, 288.87103, 0.33428553)
decoder loss ratio: 21475.494407, decoder SINDy loss  ratio: 0.623569
--- 0.33200764656066895 seconds for one epoch ---
--- 2.0111303329467773 seconds for one epoch ---
--- 0.34131836891174316 seconds for one epoch ---
--- 2.0726118087768555 seconds for one epoch ---
--- 0.3250439167022705 seconds for one epoch ---
--- 2.057555913925171 seconds for one epoch ---
--- 0.3297908306121826 seconds for one epoch ---
--- 2.034349203109741 seconds for one epoch ---
--- 0.321779727935791 seconds for one epoch ---
--- 2.0550553798675537 seconds for one epoch ---
--- 0.3399338722229004 seconds for one epoch ---
--- 2.071462869644165 seconds for one epoch ---
--- 0.3386847972869873 seconds for one epoch ---
--- 2.0534420013427734 seconds for one epoch ---
--- 0.3150289058685303 seconds for one epoch ---
--- 2.0626020431518555 seconds for one epoch ---
--- 0.35138607025146484 seconds for one epoch ---
--- 2.040719509124756 seconds for one epoch ---
--- 0.33720970153808594 seconds for one epoch ---
--- 2.0722506046295166 seconds for one epoch ---
--- 0.3358311653137207 seconds for one epoch ---
--- 2.0329527854919434 seconds for one epoch ---
--- 0.3443434238433838 seconds for one epoch ---
--- 2.0739307403564453 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.041905]
 [ -0.      ]]
--- 0.3206634521484375 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3607.801025390625, (1524.1357, 1.2925005, 2082.0376, 0.33529577)
   validation loss 1054.5421142578125, (755.8309, 0.71401954, 297.66196, 0.33529577)
decoder loss ratio: 29282.200145, decoder SINDy loss  ratio: 0.642545
--- 0.9765217304229736 seconds for one epoch ---
--- 0.32885122299194336 seconds for one epoch ---
--- 2.040020227432251 seconds for one epoch ---
--- 0.3353438377380371 seconds for one epoch ---
--- 2.10292387008667 seconds for one epoch ---
--- 0.3345069885253906 seconds for one epoch ---
--- 2.032984733581543 seconds for one epoch ---
--- 0.33400845527648926 seconds for one epoch ---
--- 2.0605616569519043 seconds for one epoch ---
--- 0.326596736907959 seconds for one epoch ---
--- 2.083920955657959 seconds for one epoch ---
--- 0.3435981273651123 seconds for one epoch ---
--- 2.0460305213928223 seconds for one epoch ---
--- 0.3420071601867676 seconds for one epoch ---
--- 2.068408727645874 seconds for one epoch ---
--- 0.3416774272918701 seconds for one epoch ---
--- 2.0782716274261475 seconds for one epoch ---
--- 0.3412909507751465 seconds for one epoch ---
--- 2.0426888465881348 seconds for one epoch ---
--- 0.3494424819946289 seconds for one epoch ---
--- 2.04767107963562 seconds for one epoch ---
--- 0.3430659770965576 seconds for one epoch ---
--- 2.0396533012390137 seconds for one epoch ---
--- 0.3421938419342041 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.100453]
 [ -0.      ]]
--- 0.28259849548339844 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2474.023681640625, (829.55566, 1.8863386, 1642.2456, 0.3362114)
   validation loss 1272.8856201171875, (995.5743, 0.6854786, 276.28967, 0.3362114)
decoder loss ratio: 38570.275992, decoder SINDy loss  ratio: 0.596410
--- 0.32074666023254395 seconds for one epoch ---
--- 2.052701473236084 seconds for one epoch ---
--- 0.3347294330596924 seconds for one epoch ---
--- 2.0675711631774902 seconds for one epoch ---
--- 0.34401655197143555 seconds for one epoch ---
--- 2.0745601654052734 seconds for one epoch ---
--- 0.33217811584472656 seconds for one epoch ---
--- 2.045982599258423 seconds for one epoch ---
--- 0.34413862228393555 seconds for one epoch ---
--- 2.0918567180633545 seconds for one epoch ---
--- 0.34148645401000977 seconds for one epoch ---
--- 2.0633530616760254 seconds for one epoch ---
--- 0.34258294105529785 seconds for one epoch ---
--- 2.091196060180664 seconds for one epoch ---
--- 0.34992218017578125 seconds for one epoch ---
--- 2.0536065101623535 seconds for one epoch ---
--- 0.354337215423584 seconds for one epoch ---
--- 2.065049886703491 seconds for one epoch ---
--- 0.32965660095214844 seconds for one epoch ---
--- 2.105644941329956 seconds for one epoch ---
--- 0.3403310775756836 seconds for one epoch ---
--- 2.0745840072631836 seconds for one epoch ---
--- 0.35864758491516113 seconds for one epoch ---
--- 2.1134865283966064 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.157806]
 [ -0.      ]]
--- 0.31412768363952637 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3661.301513671875, (1564.9084, 6.1128464, 2089.943, 0.33713746)
   validation loss 936.1973876953125, (644.75476, 0.8052856, 290.30014, 0.33713746)
decoder loss ratio: 24978.918775, decoder SINDy loss  ratio: 0.626654
--- 0.2813713550567627 seconds for one epoch ---
--- 0.32851386070251465 seconds for one epoch ---
--- 2.108078718185425 seconds for one epoch ---
--- 0.3365621566772461 seconds for one epoch ---
--- 2.062296152114868 seconds for one epoch ---
--- 0.3342297077178955 seconds for one epoch ---
--- 2.083677053451538 seconds for one epoch ---
--- 0.3337748050689697 seconds for one epoch ---
--- 2.075984239578247 seconds for one epoch ---
--- 0.3366544246673584 seconds for one epoch ---
--- 2.0887391567230225 seconds for one epoch ---
--- 0.34129881858825684 seconds for one epoch ---
--- 2.052717447280884 seconds for one epoch ---
--- 0.3292403221130371 seconds for one epoch ---
--- 2.0699405670166016 seconds for one epoch ---
--- 0.3373758792877197 seconds for one epoch ---
--- 2.0859711170196533 seconds for one epoch ---
--- 0.3372480869293213 seconds for one epoch ---
--- 2.0667524337768555 seconds for one epoch ---
--- 0.33856797218322754 seconds for one epoch ---
--- 2.069037675857544 seconds for one epoch ---
--- 0.3281533718109131 seconds for one epoch ---
--- 2.0779471397399902 seconds for one epoch ---
--- 0.33288002014160156 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.216358]
 [ -0.      ]]
--- 0.27785205841064453 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2217.7919921875, (1247.7114, 0.96917605, 968.7735, 0.33799884)
   validation loss 928.87353515625, (666.34393, 0.79926693, 261.39233, 0.33799884)
decoder loss ratio: 25815.320792, decoder SINDy loss  ratio: 0.564252
--- 0.3192884922027588 seconds for one epoch ---
--- 2.0722010135650635 seconds for one epoch ---
--- 0.33696842193603516 seconds for one epoch ---
--- 2.121342897415161 seconds for one epoch ---
--- 0.33414411544799805 seconds for one epoch ---
--- 2.0906753540039062 seconds for one epoch ---
--- 0.3341984748840332 seconds for one epoch ---
--- 2.115957498550415 seconds for one epoch ---
--- 0.33139777183532715 seconds for one epoch ---
--- 2.0653910636901855 seconds for one epoch ---
--- 0.3332347869873047 seconds for one epoch ---
--- 2.0774223804473877 seconds for one epoch ---
--- 0.3314988613128662 seconds for one epoch ---
--- 2.078033924102783 seconds for one epoch ---
--- 0.33571648597717285 seconds for one epoch ---
--- 2.080648899078369 seconds for one epoch ---
--- 0.33133625984191895 seconds for one epoch ---
--- 2.101382255554199 seconds for one epoch ---
--- 0.33728694915771484 seconds for one epoch ---
--- 2.1246182918548584 seconds for one epoch ---
--- 0.33289074897766113 seconds for one epoch ---
--- 2.097027063369751 seconds for one epoch ---
--- 0.32822179794311523 seconds for one epoch ---
--- 2.0907702445983887 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.270433]
 [ -0.      ]]
--- 0.31629157066345215 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2793.8466796875, (1121.7196, 2.4740186, 1669.3143, 0.33881575)
   validation loss 828.2319946289062, (564.16064, 0.7796094, 262.95294, 0.33881575)
decoder loss ratio: 21856.562795, decoder SINDy loss  ratio: 0.567621
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.272668]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1244.7769775390625, (626.08636, 0.8011292, 617.88947, 0.32260218)
   validation loss 810.142822265625, (542.6116, 0.947984, 266.58328, 0.32260218)
decoder loss ratio: 21021.714325, decoder SINDy loss  ratio: 0.575458
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.355967]
 [ -0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1070.613525390625, (496.62143, 0.58079, 573.4114, 0.32471043)
   validation loss 616.2771606445312, (368.0314, 0.2588252, 247.98695, 0.32471043)
decoder loss ratio: 14258.175467, decoder SINDy loss  ratio: 0.535315
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.389625]
 [ -0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 919.353271484375, (404.19406, 0.35719842, 514.802, 0.3259603)
   validation loss 622.692138671875, (380.7011, 0.23147388, 241.75955, 0.3259603)
decoder loss ratio: 14749.021960, decoder SINDy loss  ratio: 0.521872
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.529761]
 [ -0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 854.1005859375, (345.70032, 0.31259203, 508.08765, 0.32690477)
   validation loss 537.4763793945312, (298.5919, 0.21879204, 238.66571, 0.32690477)
decoder loss ratio: 11567.968136, decoder SINDy loss  ratio: 0.515194
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.512749]
 [  0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1514.3870849609375, (912.95337, 0.3252002, 601.1085, 0.32771644)
   validation loss 1060.936767578125, (792.8986, 0.19568372, 267.84247, 0.32771644)
decoder loss ratio: 30718.269095, decoder SINDy loss  ratio: 0.578176
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.648375]
 [  0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 982.9569091796875, (490.75128, 0.26052198, 491.9451, 0.3285894)
   validation loss 702.191650390625, (461.03705, 0.19096693, 240.96364, 0.3285894)
decoder loss ratio: 17861.375648, decoder SINDy loss  ratio: 0.520154
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [-11.6902895]
 [ -0.       ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 842.7520751953125, (321.83484, 0.26626617, 520.651, 0.32941148)
   validation loss 498.87890625, (260.14645, 0.18273187, 238.5497, 0.32941148)
decoder loss ratio: 10078.525257, decoder SINDy loss  ratio: 0.514943
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.776678]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.2416381835938, (343.6011, 0.27062416, 489.3699, 0.33039504)
   validation loss 530.7240600585938, (295.45303, 0.18090639, 235.0901, 0.33039504)
decoder loss ratio: 11446.363445, decoder SINDy loss  ratio: 0.507475
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.826179]
 [  0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.578125, (263.2507, 0.272805, 501.05463, 0.33141357)
   validation loss 440.3389892578125, (206.49716, 0.18081957, 233.661, 0.33141357)
decoder loss ratio: 8000.058545, decoder SINDy loss  ratio: 0.504390
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.933561]
 [  0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 789.457275390625, (301.47217, 0.2724985, 487.71265, 0.33261752)
   validation loss 478.47906494140625, (244.99086, 0.18436757, 233.30382, 0.33261752)
decoder loss ratio: 9491.371239, decoder SINDy loss  ratio: 0.503619
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.942227]
 [ -0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.3597412109375, (278.83868, 0.31168044, 488.2094, 0.3339021)
   validation loss 447.16986083984375, (216.38647, 0.17045403, 230.61292, 0.3339021)
decoder loss ratio: 8383.187690, decoder SINDy loss  ratio: 0.497810
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.003548]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1552.11376953125, (953.5636, 0.3639274, 598.1862, 0.3351905)
   validation loss 1109.307861328125, (846.0118, 0.13804138, 263.15802, 0.3351905)
decoder loss ratio: 32775.965090, decoder SINDy loss  ratio: 0.568064
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.063372]
 [  0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1058.6805419921875, (578.4169, 0.29511365, 479.96854, 0.33649555)
   validation loss 744.583740234375, (504.85748, 0.1740234, 239.55228, 0.33649555)
decoder loss ratio: 19559.055359, decoder SINDy loss  ratio: 0.517107
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.218949]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.6566162109375, (260.10083, 0.2867428, 497.269, 0.33786234)
   validation loss 435.8017578125, (204.40877, 0.17637536, 231.21661, 0.33786234)
decoder loss ratio: 7919.150530, decoder SINDy loss  ratio: 0.499114
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.275806]
 [ -0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.1292724609375, (257.6775, 0.2858636, 487.1659, 0.3392758)
   validation loss 428.6092224121094, (198.66203, 0.18002734, 229.76717, 0.3392758)
decoder loss ratio: 7696.512054, decoder SINDy loss  ratio: 0.495985
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.304335]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.4785766601562, (254.05502, 0.2916123, 484.13196, 0.34080783)
   validation loss 422.65020751953125, (193.92886, 0.17919292, 228.54213, 0.34080783)
decoder loss ratio: 7513.140848, decoder SINDy loss  ratio: 0.493340
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.352146]
 [  0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1710.679931640625, (1127.8309, 0.30554608, 582.5435, 0.3423155)
   validation loss 1339.7586669921875, (1073.324, 0.15540124, 266.27927, 0.3423155)
decoder loss ratio: 41582.434149, decoder SINDy loss  ratio: 0.574801
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.440286]
 [ -0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 998.407470703125, (525.7975, 0.29300916, 472.317, 0.34389263)
   validation loss 699.1697998046875, (463.55386, 0.17935528, 235.43658, 0.34389263)
decoder loss ratio: 17958.881438, decoder SINDy loss  ratio: 0.508223
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.614658]
 [ -0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.740478515625, (347.81946, 0.29654717, 473.6245, 0.3453413)
   validation loss 513.3386840820312, (283.65695, 0.17756641, 229.50417, 0.3453413)
decoder loss ratio: 10989.362767, decoder SINDy loss  ratio: 0.495417
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-12.73485]
 [ -0.     ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.1278686523438, (259.93793, 0.2849712, 479.90497, 0.34690705)
   validation loss 427.59014892578125, (199.6235, 0.18140216, 227.78523, 0.34690705)
decoder loss ratio: 7733.761131, decoder SINDy loss  ratio: 0.491706
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.761137]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.9295654296875, (271.14105, 0.2894248, 477.49908, 0.34856185)
   validation loss 442.48553466796875, (214.6092, 0.17326316, 227.70305, 0.34856185)
decoder loss ratio: 8314.333263, decoder SINDy loss  ratio: 0.491529
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.812671]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.9737548828125, (470.72006, 0.3010499, 469.95264, 0.35008)
   validation loss 625.8133544921875, (394.05725, 0.17695267, 231.5792, 0.35008)
decoder loss ratio: 15266.462016, decoder SINDy loss  ratio: 0.499896
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-12.8782835]
 [ -0.       ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1377.523193359375, (812.34216, 0.32008082, 564.86096, 0.3517168)
   validation loss 988.9404296875, (736.3477, 0.15133184, 252.4414, 0.3517168)
decoder loss ratio: 28527.388923, decoder SINDy loss  ratio: 0.544930
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.023145]
 [  0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.7758178710938, (248.96637, 0.29366407, 478.51578, 0.35325906)
   validation loss 418.75341796875, (192.27214, 0.17556868, 226.30573, 0.35325906)
decoder loss ratio: 7448.956522, decoder SINDy loss  ratio: 0.488513
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.061472]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.4876708984375, (289.40878, 0.3078465, 494.77103, 0.35484043)
   validation loss 458.4966125488281, (230.62569, 0.16148832, 227.70944, 0.35484043)
decoder loss ratio: 8934.839484, decoder SINDy loss  ratio: 0.491543
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.167353]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.12646484375, (395.04004, 0.27676782, 466.8097, 0.3564025)
   validation loss 554.889404296875, (323.77597, 0.18701911, 230.92639, 0.3564025)
decoder loss ratio: 12543.643195, decoder SINDy loss  ratio: 0.498487
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.201068]
 [ -0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.1905517578125, (258.47522, 0.28438073, 485.4309, 0.35791197)
   validation loss 428.24224853515625, (201.05075, 0.17847371, 227.01302, 0.35791197)
decoder loss ratio: 7789.055123, decoder SINDy loss  ratio: 0.490040
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-13.23338]
 [  0.     ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.1143798828125, (249.4013, 0.2906747, 472.4224, 0.35946152)
   validation loss 412.8392333984375, (187.58139, 0.17933439, 225.0785, 0.35946152)
decoder loss ratio: 7267.228719, decoder SINDy loss  ratio: 0.485864
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.393485]
 [ -0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.9057006835938, (263.96335, 0.28345507, 469.6589, 0.36108443)
   validation loss 426.37103271484375, (200.73665, 0.17625986, 225.45813, 0.36108443)
decoder loss ratio: 7776.886259, decoder SINDy loss  ratio: 0.486683
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.529558]
 [  0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.5146484375, (244.81863, 0.28497916, 475.411, 0.36262462)
   validation loss 411.1827087402344, (185.79272, 0.18005373, 225.20993, 0.36262462)
decoder loss ratio: 7197.932702, decoder SINDy loss  ratio: 0.486147
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-13.52482]
 [  0.     ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.3162841796875, (264.39313, 0.29455918, 482.62857, 0.36424717)
   validation loss 436.04693603515625, (210.2173, 0.16649508, 225.66316, 0.36424717)
decoder loss ratio: 8144.183171, decoder SINDy loss  ratio: 0.487126
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.625364]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.8829956054688, (285.43115, 0.2786667, 465.1732, 0.36584818)
   validation loss 444.695556640625, (219.03499, 0.1839246, 225.47662, 0.36584818)
decoder loss ratio: 8485.795712, decoder SINDy loss  ratio: 0.486723
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.816829]
 [  0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.5146484375, (257.98056, 0.29332528, 471.24075, 0.36747396)
   validation loss 418.16363525390625, (194.61041, 0.16750342, 223.38571, 0.36747396)
decoder loss ratio: 7539.545243, decoder SINDy loss  ratio: 0.482209
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.740054]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1261.399658203125, (715.3231, 0.29910648, 545.7774, 0.36906454)
   validation loss 880.248779296875, (637.0096, 0.1547812, 243.0844, 0.36906454)
decoder loss ratio: 24678.857124, decoder SINDy loss  ratio: 0.524732
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.908198]
 [ -0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.0084228515625, (263.27765, 0.29066372, 466.4401, 0.3706534)
   validation loss 424.0120849609375, (200.204, 0.16924803, 223.63882, 0.3706534)
decoder loss ratio: 7756.250326, decoder SINDy loss  ratio: 0.482756
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.967626]
 [  0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1029.413330078125, (568.7596, 0.28764006, 460.3661, 0.37226638)
   validation loss 723.165283203125, (489.08194, 0.17987455, 233.90347, 0.37226638)
decoder loss ratio: 18947.883427, decoder SINDy loss  ratio: 0.504914
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.093901]
 [ -0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1011.9266357421875, (497.20908, 0.27698216, 514.4406, 0.37392336)
   validation loss 668.2708740234375, (433.31693, 0.1666502, 234.78726, 0.37392336)
decoder loss ratio: 16787.449948, decoder SINDy loss  ratio: 0.506821
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.133235]
 [ -0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 826.6260986328125, (333.91147, 0.28244454, 492.43222, 0.3755255)
   validation loss 505.72100830078125, (277.74637, 0.17117457, 227.80345, 0.3755255)
decoder loss ratio: 10760.376501, decoder SINDy loss  ratio: 0.491746
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.2060375]
 [  0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.564208984375, (245.48378, 0.2832849, 470.79712, 0.37717164)
   validation loss 412.79888916015625, (189.41652, 0.1663977, 223.21597, 0.37717164)
decoder loss ratio: 7338.324794, decoder SINDy loss  ratio: 0.481843
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-14.3335]
 [  0.    ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.2637329101562, (242.01762, 0.27200335, 466.9741, 0.37877908)
   validation loss 406.77252197265625, (183.31499, 0.17717804, 223.28036, 0.37877908)
decoder loss ratio: 7101.940852, decoder SINDy loss  ratio: 0.481982
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.360596]
 [ -0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1093.721435546875, (632.8136, 0.27040052, 460.6375, 0.38038203)
   validation loss 775.2561645507812, (538.64795, 0.18010323, 236.42812, 0.38038203)
decoder loss ratio: 20868.156687, decoder SINDy loss  ratio: 0.510363
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.436728]
 [ -0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.013916015625, (246.64236, 0.2762006, 472.09537, 0.3819139)
   validation loss 412.89129638671875, (189.26018, 0.17321867, 223.45792, 0.3819139)
decoder loss ratio: 7332.267851, decoder SINDy loss  ratio: 0.482365
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.510667]
 [  0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.3310546875, (329.99933, 0.2698329, 456.0619, 0.3835174)
   validation loss 487.3340759277344, (261.6486, 0.17911889, 225.50638, 0.3835174)
decoder loss ratio: 10136.720622, decoder SINDy loss  ratio: 0.486787
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.617885]
 [  0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.6556396484375, (238.63899, 0.27968365, 461.73694, 0.38513294)
   validation loss 399.65093994140625, (178.1323, 0.17271234, 221.34593, 0.38513294)
decoder loss ratio: 6901.154309, decoder SINDy loss  ratio: 0.477806
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.5808525]
 [  0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1322.86962890625, (858.18726, 0.267547, 464.41486, 0.38674003)
   validation loss 996.990234375, (750.02783, 0.18504004, 246.77736, 0.38674003)
decoder loss ratio: 29057.380318, decoder SINDy loss  ratio: 0.532704
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.72865]
 [ -0.     ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.7808837890625, (251.3162, 0.27956623, 457.18515, 0.38831854)
   validation loss 408.23333740234375, (187.06621, 0.1716363, 220.99551, 0.38831854)
decoder loss ratio: 7247.269655, decoder SINDy loss  ratio: 0.477050
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.825892]
 [ -0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.5257568359375, (233.9798, 0.28912959, 462.2568, 0.38985506)
   validation loss 396.24462890625, (176.55457, 0.15992807, 219.53015, 0.38985506)
decoder loss ratio: 6840.030377, decoder SINDy loss  ratio: 0.473887
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.918485]
 [  0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1249.2557373046875, (725.81305, 0.2793579, 523.1633, 0.39132395)
   validation loss 909.20166015625, (669.45013, 0.15620734, 239.59532, 0.39132395)
decoder loss ratio: 25935.660418, decoder SINDy loss  ratio: 0.517200
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.93591]
 [  0.     ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 752.643798828125, (300.0093, 0.26717362, 452.36734, 0.3927977)
   validation loss 461.41705322265625, (237.36497, 0.17181152, 223.88026, 0.3927977)
decoder loss ratio: 9195.931214, decoder SINDy loss  ratio: 0.483277
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.016503]
 [ -0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.6846923828125, (252.89363, 0.26380563, 455.52725, 0.3942432)
   validation loss 414.84869384765625, (192.4996, 0.17294917, 222.17616, 0.3942432)
decoder loss ratio: 7457.768825, decoder SINDy loss  ratio: 0.479598
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.090085]
 [ -0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.167236328125, (262.39062, 0.26988998, 453.50668, 0.3956154)
   validation loss 419.23675537109375, (197.5356, 0.17211403, 221.52904, 0.3956154)
decoder loss ratio: 7652.872033, decoder SINDy loss  ratio: 0.478202
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.1194105]
 [  0.       ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.5060424804688, (238.59752, 0.28025186, 454.62827, 0.39702153)
   validation loss 395.72845458984375, (176.60678, 0.16518761, 218.95648, 0.39702153)
decoder loss ratio: 6842.053299, decoder SINDy loss  ratio: 0.472648
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.167089]
 [ -0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1068.31005859375, (555.5251, 0.32094678, 512.4641, 0.39835146)
   validation loss 722.1694946289062, (493.49963, 0.12994958, 228.53993, 0.39835146)
decoder loss ratio: 19119.032566, decoder SINDy loss  ratio: 0.493336
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.28395]
 [ -0.     ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.517333984375, (240.9224, 0.2689701, 461.326, 0.3995838)
   validation loss 404.16943359375, (182.8027, 0.16556248, 221.20117, 0.3995838)
decoder loss ratio: 7082.094107, decoder SINDy loss  ratio: 0.477494
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.334811]
 [  0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 807.2770385742188, (358.47635, 0.26261055, 448.5381, 0.40081483)
   validation loss 511.8800048828125, (286.99393, 0.1725867, 224.71352, 0.40081483)
decoder loss ratio: 11118.642975, decoder SINDy loss  ratio: 0.485076
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.3966875]
 [ -0.       ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.8623046875, (266.26172, 0.26011217, 450.34048, 0.4020383)
   validation loss 421.70684814453125, (200.44023, 0.17155434, 221.09505, 0.4020383)
decoder loss ratio: 7765.402541, decoder SINDy loss  ratio: 0.477265
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.378579]
 [ -0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.1248779296875, (247.05592, 0.26842365, 450.8005, 0.4031993)
   validation loss 403.60711669921875, (184.18008, 0.16878657, 219.25822, 0.4031993)
decoder loss ratio: 7135.456214, decoder SINDy loss  ratio: 0.473300
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.499346]
 [ -0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 987.0545654296875, (486.24146, 0.30655742, 500.50653, 0.40437427)
   validation loss 652.5809326171875, (426.1855, 0.14006262, 226.25534, 0.40437427)
decoder loss ratio: 16511.165612, decoder SINDy loss  ratio: 0.488404
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.521388]
 [  0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1273.041259765625, (747.5961, 0.28166875, 525.1634, 0.4054647)
   validation loss 915.398681640625, (679.477, 0.13634437, 235.78532, 0.4054647)
decoder loss ratio: 26324.118207, decoder SINDy loss  ratio: 0.508976
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.545445]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2079.554443359375, (1507.8821, 0.2855881, 571.3868, 0.40643597)
   validation loss 1723.123291015625, (1459.9663, 0.13916785, 263.01785, 0.40643597)
decoder loss ratio: 56561.629408, decoder SINDy loss  ratio: 0.567761
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.612638]
 [  0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1211.642822265625, (757.26807, 0.24343254, 454.13138, 0.40754268)
   validation loss 888.6600341796875, (645.8869, 0.17986712, 242.59323, 0.40754268)
decoder loss ratio: 25022.779887, decoder SINDy loss  ratio: 0.523672
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.667807]
 [ -0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.04296875, (320.28375, 0.25650752, 444.50272, 0.4084838)
   validation loss 472.83251953125, (250.13948, 0.16771984, 222.52531, 0.4084838)
decoder loss ratio: 9690.837739, decoder SINDy loss  ratio: 0.480352
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.73997]
 [  0.     ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.220947265625, (232.62843, 0.25271767, 451.33978, 0.40943298)
   validation loss 396.75048828125, (176.6333, 0.16209675, 219.95508, 0.40943298)
decoder loss ratio: 6843.080721, decoder SINDy loss  ratio: 0.474804
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.751204]
 [  0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.3597412109375, (360.96167, 0.2560134, 443.1421, 0.410333)
   validation loss 510.4846496582031, (286.98148, 0.16797401, 223.3352, 0.410333)
decoder loss ratio: 11118.160595, decoder SINDy loss  ratio: 0.482100
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.815866]
 [  0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.7322998046875, (233.04745, 0.2530574, 447.43176, 0.41120872)
   validation loss 393.7335205078125, (175.13725, 0.16548812, 218.43077, 0.41120872)
decoder loss ratio: 6785.121225, decoder SINDy loss  ratio: 0.471514
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.780541]
 [  0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.73974609375, (304.04565, 0.24815424, 442.4459, 0.41207695)
   validation loss 456.4561767578125, (235.10129, 0.16923, 221.18567, 0.41207695)
decoder loss ratio: 9108.232045, decoder SINDy loss  ratio: 0.477460
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.895943]
 [ -0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.4031372070312, (226.19647, 0.25971442, 449.94696, 0.41280994)
   validation loss 387.00225830078125, (170.24794, 0.16137561, 216.59294, 0.41280994)
decoder loss ratio: 6595.700761, decoder SINDy loss  ratio: 0.467546
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.846806]
 [ -0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.971435546875, (223.80728, 0.26224446, 447.90192, 0.41360483)
   validation loss 384.6551513671875, (169.10614, 0.15619782, 215.39279, 0.41360483)
decoder loss ratio: 6551.465450, decoder SINDy loss  ratio: 0.464956
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.906554]
 [ -0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.0127563476562, (357.5899, 0.27927998, 472.1436, 0.41435787)
   validation loss 523.64013671875, (304.31332, 0.13732365, 219.18951, 0.41435787)
decoder loss ratio: 11789.626482, decoder SINDy loss  ratio: 0.473151
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.92845]
 [ -0.     ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 993.58154296875, (499.27457, 0.28491804, 494.02203, 0.4150961)
   validation loss 656.4910888671875, (433.36423, 0.13152342, 222.99536, 0.4150961)
decoder loss ratio: 16789.282519, decoder SINDy loss  ratio: 0.481367
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.978515]
 [  0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.92333984375, (331.12592, 0.24976882, 438.5477, 0.4157457)
   validation loss 486.7647705078125, (265.35168, 0.16594622, 221.24715, 0.4157457)
decoder loss ratio: 10280.184931, decoder SINDy loss  ratio: 0.477593
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.916631]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.864990234375, (261.76743, 0.24867563, 440.84885, 0.4164962)
   validation loss 412.2875671386719, (195.06607, 0.15494932, 217.06654, 0.4164962)
decoder loss ratio: 7557.198223, decoder SINDy loss  ratio: 0.468569
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.039814]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1442.302734375, (985.49146, 0.23394792, 456.57727, 0.41716728)
   validation loss 1092.3814697265625, (843.752, 0.17119205, 248.45828, 0.41716728)
decoder loss ratio: 32688.417846, decoder SINDy loss  ratio: 0.536332
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.101295]
 [  0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.3652954101562, (252.5, 0.2589093, 437.60638, 0.41782022)
   validation loss 401.9442138671875, (187.06404, 0.16124888, 214.71892, 0.41782022)
decoder loss ratio: 7247.185711, decoder SINDy loss  ratio: 0.463501
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.115652]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 843.0083618164062, (372.11185, 0.2519976, 470.64453, 0.41839847)
   validation loss 545.1568603515625, (324.84735, 0.1485317, 220.16095, 0.41839847)
decoder loss ratio: 12585.150340, decoder SINDy loss  ratio: 0.475248
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.141312]
 [ -0.      ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.8391723632812, (286.18198, 0.24341904, 436.4138, 0.41900632)
   validation loss 435.81988525390625, (218.22554, 0.15531617, 217.43901, 0.41900632)
decoder loss ratio: 8454.436282, decoder SINDy loss  ratio: 0.469373
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.131393]
 [ -0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.7117919921875, (459.836, 0.23642164, 436.63934, 0.4195722)
   validation loss 592.1288452148438, (367.29117, 0.16141699, 224.67628, 0.4195722)
decoder loss ratio: 14229.497502, decoder SINDy loss  ratio: 0.484995
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.20049]
 [  0.     ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 772.8682861328125, (339.3753, 0.23909067, 433.25388, 0.42009267)
   validation loss 485.3171691894531, (265.78015, 0.16129525, 219.37573, 0.42009267)
decoder loss ratio: 10296.784479, decoder SINDy loss  ratio: 0.473553
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.122334]
 [  0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.4144897460938, (226.89282, 0.24186628, 436.2798, 0.4205554)
   validation loss 385.92230224609375, (171.4536, 0.15554066, 214.31314, 0.4205554)
decoder loss ratio: 6642.410044, decoder SINDy loss  ratio: 0.462625
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.215778]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 815.27392578125, (383.1062, 0.24551105, 431.92224, 0.42099)
   validation loss 523.1539916992188, (303.51617, 0.15865728, 219.47914, 0.42099)
decoder loss ratio: 11758.743520, decoder SINDy loss  ratio: 0.473777
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.134308]
 [  0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.9853515625, (227.65735, 0.24654067, 444.08145, 0.4213778)
   validation loss 392.6034240722656, (179.5447, 0.15109144, 212.90764, 0.4213778)
decoder loss ratio: 6955.873110, decoder SINDy loss  ratio: 0.459591
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.30392]
 [ -0.     ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.154052734375, (306.11343, 0.23864348, 429.802, 0.42186865)
   validation loss 453.0576171875, (237.02095, 0.15894473, 215.87772, 0.42186865)
decoder loss ratio: 9182.603102, decoder SINDy loss  ratio: 0.466002
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.294973]
 [ -0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.5267333984375, (216.39406, 0.24658622, 436.88608, 0.42229518)
   validation loss 375.7968444824219, (164.97449, 0.15284401, 210.66951, 0.42229518)
decoder loss ratio: 6391.398046, decoder SINDy loss  ratio: 0.454760
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.185896]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 928.375244140625, (497.5797, 0.22393057, 430.57162, 0.42273924)
   validation loss 626.5706787109375, (401.13443, 0.15859944, 225.27766, 0.42273924)
decoder loss ratio: 15540.644216, decoder SINDy loss  ratio: 0.486294
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.335682]
 [ -0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.099609375, (218.50894, 0.23702328, 436.35367, 0.4231197)
   validation loss 379.21673583984375, (168.23158, 0.14808528, 210.83707, 0.4231197)
decoder loss ratio: 6517.583574, decoder SINDy loss  ratio: 0.455121
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.296854]
 [ -0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.2105712890625, (227.4232, 0.23769955, 429.54968, 0.42351517)
   validation loss 380.5594482421875, (169.73291, 0.15188786, 210.67467, 0.42351517)
decoder loss ratio: 6575.747609, decoder SINDy loss  ratio: 0.454771
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.334713]
 [  0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.2193603515625, (217.42717, 0.2468302, 431.54535, 0.42387113)
   validation loss 371.0699462890625, (162.31818, 0.15145771, 208.60031, 0.42387113)
decoder loss ratio: 6288.487945, decoder SINDy loss  ratio: 0.450293
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.29831]
 [  0.     ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.892822265625, (213.75694, 0.2599655, 430.8759, 0.42420775)
   validation loss 366.40869140625, (159.73647, 0.14564347, 206.52658, 0.42420775)
decoder loss ratio: 6188.467986, decoder SINDy loss  ratio: 0.445817
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.401114]
 [ -0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1709.286865234375, (1187.1414, 0.2585894, 521.887, 0.42443228)
   validation loss 1415.186767578125, (1173.3474, 0.12691781, 241.71242, 0.42443228)
decoder loss ratio: 45457.515766, decoder SINDy loss  ratio: 0.521770
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.354553]
 [  0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.8458251953125, (268.54135, 0.23988102, 444.06458, 0.42488128)
   validation loss 434.5232238769531, (223.5588, 0.13131374, 210.8331, 0.42488128)
decoder loss ratio: 8661.056313, decoder SINDy loss  ratio: 0.455113
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.37535]
 [ -0.     ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.2511596679688, (364.39972, 0.22785017, 421.6236, 0.42520657)
   validation loss 499.851806640625, (284.18365, 0.14619833, 215.52193, 0.42520657)
decoder loss ratio: 11009.768151, decoder SINDy loss  ratio: 0.465234
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.392134]
 [  0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.8840942382812, (285.11395, 0.23364021, 446.5365, 0.4255024)
   validation loss 455.01055908203125, (243.83846, 0.1358267, 211.03629, 0.4255024)
decoder loss ratio: 9446.725077, decoder SINDy loss  ratio: 0.455552
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.455526]
 [  0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.505126953125, (248.29535, 0.2211625, 420.98865, 0.42582867)
   validation loss 399.83587646484375, (188.89633, 0.14232197, 210.79723, 0.42582867)
decoder loss ratio: 7318.171832, decoder SINDy loss  ratio: 0.455035
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.413784]
 [ -0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 635.57861328125, (210.08469, 0.23007777, 425.26382, 0.42606297)
   validation loss 365.9516296386719, (158.36346, 0.1395744, 207.4486, 0.42606297)
decoder loss ratio: 6135.275540, decoder SINDy loss  ratio: 0.447807
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.43634]
 [  0.     ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.655029296875, (239.30219, 0.23352449, 420.11935, 0.42632905)
   validation loss 385.00250244140625, (177.49942, 0.14119533, 207.36188, 0.42632905)
decoder loss ratio: 6876.635690, decoder SINDy loss  ratio: 0.447620
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.48709]
 [  0.     ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.9423828125, (219.52205, 0.2427464, 421.17758, 0.42662302)
   validation loss 367.08721923828125, (162.44716, 0.14361049, 204.49643, 0.42662302)
decoder loss ratio: 6293.484953, decoder SINDy loss  ratio: 0.441434
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.49648]
 [ -0.     ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 635.8041381835938, (214.78546, 0.23154563, 420.78714, 0.42683822)
   validation loss 364.89227294921875, (159.50922, 0.1391532, 205.24388, 0.42683822)
decoder loss ratio: 6179.663960, decoder SINDy loss  ratio: 0.443048
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.363617]
 [  0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.3887939453125, (209.06383, 0.24230492, 423.08267, 0.42703143)
   validation loss 359.44415283203125, (156.3254, 0.1354178, 202.98334, 0.42703143)
decoder loss ratio: 6056.317144, decoder SINDy loss  ratio: 0.438168
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.465199]
 [  0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1202.034423828125, (724.1561, 0.2439241, 477.6344, 0.42716303)
   validation loss 929.641845703125, (707.7815, 0.1223336, 221.738, 0.42716303)
decoder loss ratio: 27420.683846, decoder SINDy loss  ratio: 0.478653
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.464079]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.3455810546875, (386.95844, 0.21041088, 413.1767, 0.42753488)
   validation loss 512.2377319335938, (298.54224, 0.13873369, 213.55678, 0.42753488)
decoder loss ratio: 11566.044527, decoder SINDy loss  ratio: 0.460992
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.535767]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.9562377929688, (229.59409, 0.2150311, 414.14713, 0.42769238)
   validation loss 379.12701416015625, (172.1758, 0.13305528, 206.81815, 0.42769238)
decoder loss ratio: 6670.389267, decoder SINDy loss  ratio: 0.446446
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.471426]
 [ -0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.5234375, (232.16405, 0.22011276, 413.13928, 0.42790207)
   validation loss 377.96484375, (172.49423, 0.13412625, 205.33649, 0.42790207)
decoder loss ratio: 6682.726018, decoder SINDy loss  ratio: 0.443248
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.527012]
 [  0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1297.164794921875, (798.16736, 0.23567231, 498.76175, 0.42812595)
   validation loss 976.04150390625, (747.7623, 0.119191475, 228.15997, 0.42812595)
decoder loss ratio: 28969.610802, decoder SINDy loss  ratio: 0.492515
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.543873]
 [ -0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 992.7762451171875, (526.40894, 0.23512499, 466.13217, 0.42833677)
   validation loss 693.083251953125, (479.23926, 0.11616064, 213.72783, 0.42833677)
decoder loss ratio: 18566.560844, decoder SINDy loss  ratio: 0.461362
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.50189]
 [  0.     ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 829.1728515625, (421.12964, 0.20819907, 407.83502, 0.42851153)
   validation loss 557.4798583984375, (343.5685, 0.13358684, 213.7778, 0.42851153)
decoder loss ratio: 13310.440615, decoder SINDy loss  ratio: 0.461469
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.460712]
 [ -0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1217.6884765625, (730.3456, 0.23583898, 487.10706, 0.4287191)
   validation loss 899.2210693359375, (676.8334, 0.11444775, 222.27327, 0.4287191)
decoder loss ratio: 26221.699944, decoder SINDy loss  ratio: 0.479808
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.577408]
 [  0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1592.1082763671875, (1160.2941, 0.1992639, 431.61496, 0.42889434)
   validation loss 1238.78466796875, (993.88904, 0.13384824, 244.76183, 0.42889434)
decoder loss ratio: 38504.986803, decoder SINDy loss  ratio: 0.528353
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.536228]
 [  0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.9000854492188, (210.94217, 0.20971349, 409.7482, 0.42910534)
   validation loss 360.50360107421875, (157.67728, 0.12874338, 202.6976, 0.42910534)
decoder loss ratio: 6108.691436, decoder SINDy loss  ratio: 0.437551
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.556164]
 [  0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.072509765625, (267.83484, 0.20692047, 405.03076, 0.4293116)
   validation loss 407.12921142578125, (201.88182, 0.12882434, 205.11858, 0.4293116)
decoder loss ratio: 7821.252215, decoder SINDy loss  ratio: 0.442777
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.516497]
 [ -0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.79296875, (243.44562, 0.23428899, 426.11307, 0.4295058)
   validation loss 401.41400146484375, (199.48071, 0.12717736, 201.80612, 0.4295058)
decoder loss ratio: 7728.229131, decoder SINDy loss  ratio: 0.435627
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.499626]
 [  0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.6105346679688, (364.77924, 0.22502615, 441.60626, 0.42963955)
   validation loss 537.5382690429688, (328.816, 0.11698434, 208.60529, 0.42963955)
decoder loss ratio: 12738.903059, decoder SINDy loss  ratio: 0.450304
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.605034]
 [ -0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 613.60009765625, (204.71126, 0.21522473, 408.67358, 0.429811)
   validation loss 355.7724609375, (154.94862, 0.12697673, 200.69685, 0.429811)
decoder loss ratio: 6002.978683, decoder SINDy loss  ratio: 0.433232
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.540075]
 [  0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.322998046875, (314.90494, 0.21313176, 431.2049, 0.42993823)
   validation loss 490.2229919433594, (284.2427, 0.11820732, 205.86209, 0.42993823)
decoder loss ratio: 11012.055909, decoder SINDy loss  ratio: 0.444382
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.557447]
 [ -0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.316162109375, (330.0964, 0.20216167, 400.01758, 0.43010852)
   validation loss 462.3653259277344, (255.5266, 0.12550901, 206.71323, 0.43010852)
decoder loss ratio: 9899.543945, decoder SINDy loss  ratio: 0.446220
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.56598]
 [ -0.     ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.4915771484375, (209.49269, 0.2102735, 411.7886, 0.430226)
   validation loss 369.9447021484375, (169.91133, 0.12147237, 199.91188, 0.430226)
decoder loss ratio: 6582.659949, decoder SINDy loss  ratio: 0.431538
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.615435]
 [  0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.4249267578125, (275.32364, 0.20323335, 398.898, 0.4303344)
   validation loss 408.5306701660156, (205.78879, 0.12425326, 202.61763, 0.4303344)
decoder loss ratio: 7972.614906, decoder SINDy loss  ratio: 0.437379
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.485376]
 [ -0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.7550048828125, (214.00233, 0.18979721, 401.56284, 0.43047735)
   validation loss 361.9889221191406, (160.88103, 0.11897424, 200.98892, 0.43047735)
decoder loss ratio: 6232.810296, decoder SINDy loss  ratio: 0.433863
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.631351]
 [  0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.56640625, (301.17703, 0.19601585, 397.1934, 0.4305726)
   validation loss 430.2047119140625, (226.33997, 0.12175074, 203.74301, 0.4305726)
decoder loss ratio: 8768.803219, decoder SINDy loss  ratio: 0.439808
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.64664]
 [ -0.     ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.3651123046875, (202.04604, 0.20693107, 403.11215, 0.43065053)
   validation loss 351.45477294921875, (153.06836, 0.12194459, 198.26448, 0.43065053)
decoder loss ratio: 5930.133981, decoder SINDy loss  ratio: 0.427982
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.562586]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 627.928955078125, (230.21924, 0.19059859, 397.5191, 0.43078303)
   validation loss 373.31170654296875, (172.83133, 0.118635215, 200.36172, 0.43078303)
decoder loss ratio: 6695.785747, decoder SINDy loss  ratio: 0.432509
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.597466]
 [ -0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.7666015625, (234.61443, 0.20660245, 414.94556, 0.4308362)
   validation loss 396.19183349609375, (196.76537, 0.11985175, 199.3066, 0.4308362)
decoder loss ratio: 7623.031863, decoder SINDy loss  ratio: 0.430231
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.600935]
 [  0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 801.9577026367188, (363.48886, 0.22900476, 438.23984, 0.43101928)
   validation loss 529.224609375, (327.1919, 0.11722001, 201.91551, 0.43101928)
decoder loss ratio: 12675.982024, decoder SINDy loss  ratio: 0.435863
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.627752]
 [ -0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.1432495117188, (359.4601, 0.18767905, 393.49545, 0.43105522)
   validation loss 493.61553955078125, (288.35022, 0.11520686, 205.1501, 0.43105522)
decoder loss ratio: 11171.188110, decoder SINDy loss  ratio: 0.442845
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.623589]
 [  0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1598.66259765625, (1179.1306, 0.15610133, 419.3758, 0.43113968)
   validation loss 1247.6961669921875, (1002.0658, 0.11549709, 245.51494, 0.43113968)
decoder loss ratio: 38821.768596, decoder SINDy loss  ratio: 0.529979
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.551382]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.4134521484375, (229.58195, 0.1820342, 394.64944, 0.4312873)
   validation loss 374.07708740234375, (173.3786, 0.11252078, 200.58598, 0.4312873)
decoder loss ratio: 6716.988004, decoder SINDy loss  ratio: 0.432993
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.594427]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.1072998046875, (476.3797, 0.1789918, 390.54858, 0.4314333)
   validation loss 597.3898315429688, (387.10522, 0.11961162, 210.165, 0.4314333)
decoder loss ratio: 14997.128446, decoder SINDy loss  ratio: 0.453671
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.740295]
 [  0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.017333984375, (357.0101, 0.20594887, 430.80127, 0.43157145)
   validation loss 522.8444213867188, (319.65686, 0.112196356, 203.07536, 0.43157145)
decoder loss ratio: 12384.061719, decoder SINDy loss  ratio: 0.438367
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.643524]
 [  0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 934.1021728515625, (486.9787, 0.20952128, 446.9139, 0.43168345)
   validation loss 666.1807250976562, (455.338, 0.1080857, 210.73463, 0.43168345)
decoder loss ratio: 17640.585113, decoder SINDy loss  ratio: 0.454900
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.774736]
 [ -0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1242.0623779296875, (764.726, 0.2107965, 477.12558, 0.43180656)
   validation loss 946.3847045898438, (724.56433, 0.107301585, 221.71309, 0.43180656)
decoder loss ratio: 28070.880084, decoder SINDy loss  ratio: 0.478599
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.68457]
 [ -0.     ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1115.06298828125, (651.4967, 0.21356936, 463.35275, 0.43188915)
   validation loss 838.793701171875, (620.53296, 0.10589946, 218.15483, 0.43188915)
decoder loss ratio: 24040.524124, decoder SINDy loss  ratio: 0.470918
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.625875]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1478.260009765625, (990.0776, 0.21013518, 487.97226, 0.43193945)
   validation loss 1198.244384765625, (970.454, 0.10793762, 227.68246, 0.43193945)
decoder loss ratio: 37597.071948, decoder SINDy loss  ratio: 0.491485
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.674448]
 [  0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.6279907226562, (348.77115, 0.17663603, 386.6802, 0.43205205)
   validation loss 478.83087158203125, (275.36542, 0.11459697, 203.35086, 0.43205205)
decoder loss ratio: 10668.134329, decoder SINDy loss  ratio: 0.438961
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.683435]
 [ -0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.6884765625, (221.198, 0.18678696, 403.3037, 0.43217525)
   validation loss 383.82550048828125, (187.31905, 0.10946618, 196.397, 0.43217525)
decoder loss ratio: 7257.065043, decoder SINDy loss  ratio: 0.423951
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.71157]
 [  0.     ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.5648193359375, (296.45908, 0.17360447, 385.93213, 0.43224522)
   validation loss 427.60162353515625, (226.66646, 0.11056965, 200.82458, 0.43224522)
decoder loss ratio: 8781.452098, decoder SINDy loss  ratio: 0.433508
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.701046]
 [ -0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 591.0874633789062, (199.04279, 0.17509788, 391.86957, 0.43228728)
   validation loss 348.58837890625, (151.83783, 0.10817063, 196.64238, 0.43228728)
decoder loss ratio: 5882.461120, decoder SINDy loss  ratio: 0.424480
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.641714]
 [  0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.0037231445312, (378.0433, 0.16614361, 383.79428, 0.43241173)
   validation loss 499.05670166015625, (294.90445, 0.11142255, 204.04082, 0.43241173)
decoder loss ratio: 11425.110349, decoder SINDy loss  ratio: 0.440451
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.60439]
 [ -0.     ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 598.3856201171875, (201.50253, 0.17458192, 396.7085, 0.43238956)
   validation loss 356.10791015625, (159.14941, 0.111502536, 196.84698, 0.43238956)
decoder loss ratio: 6165.724596, decoder SINDy loss  ratio: 0.424922
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.643253]
 [ -0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 872.4295654296875, (488.739, 0.16331032, 383.52728, 0.43243918)
   validation loss 613.6077880859375, (402.71948, 0.110357806, 210.77798, 0.43243918)
decoder loss ratio: 15602.051901, decoder SINDy loss  ratio: 0.454994
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.669327]
 [ -0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 808.423095703125, (425.38785, 0.1674592, 382.8678, 0.43254566)
   validation loss 545.0130615234375, (338.45557, 0.1104796, 206.44702, 0.43254566)
decoder loss ratio: 13112.356227, decoder SINDy loss  ratio: 0.445645
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.694098]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.86083984375, (243.57594, 0.16079915, 383.12408, 0.43261805)
   validation loss 386.3841552734375, (186.43364, 0.106345735, 199.84416, 0.43261805)
decoder loss ratio: 7222.762858, decoder SINDy loss  ratio: 0.431392
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.66065]
 [  0.     ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 585.8697509765625, (198.67438, 0.16540436, 387.03, 0.4327043)
   validation loss 348.34320068359375, (151.15672, 0.10676028, 197.07973, 0.4327043)
decoder loss ratio: 5856.073870, decoder SINDy loss  ratio: 0.425424
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.704466]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.667724609375, (423.14816, 0.15741423, 380.36215, 0.43285352)
   validation loss 546.515380859375, (339.47113, 0.10982168, 206.93439, 0.43285352)
decoder loss ratio: 13151.700938, decoder SINDy loss  ratio: 0.446697
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.69466]
 [  0.     ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 587.048583984375, (198.54652, 0.1648638, 388.33716, 0.43286583)
   validation loss 348.10272216796875, (150.72653, 0.10751621, 197.26869, 0.43286583)
decoder loss ratio: 5839.407522, decoder SINDy loss  ratio: 0.425832
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.721685]
 [ -0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 943.002197265625, (560.8928, 0.1499243, 381.9595, 0.43303582)
   validation loss 674.9801025390625, (461.1329, 0.11085769, 213.7363, 0.43303582)
decoder loss ratio: 17865.089265, decoder SINDy loss  ratio: 0.461380
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.667414]
 [ -0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 592.6660766601562, (200.23962, 0.17615119, 392.2503, 0.4330844)
   validation loss 353.61065673828125, (157.58319, 0.11193659, 195.91554, 0.4330844)
decoder loss ratio: 6105.046393, decoder SINDy loss  ratio: 0.422911
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.73166]
 [ -0.     ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1368.21240234375, (977.6165, 0.14430521, 390.45154, 0.43321124)
   validation loss 1086.6693115234375, (856.0885, 0.10628271, 230.47455, 0.43321124)
decoder loss ratio: 33166.354763, decoder SINDy loss  ratio: 0.497512
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.810276]
 [ -0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.545654296875, (405.79968, 0.15995038, 378.58603, 0.4333012)
   validation loss 529.277099609375, (323.73947, 0.10889944, 205.42876, 0.4333012)
decoder loss ratio: 12542.229160, decoder SINDy loss  ratio: 0.443447
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.666996]
 [ -0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 590.06396484375, (200.40324, 0.17524473, 389.48544, 0.4334526)
   validation loss 354.51519775390625, (160.71399, 0.109240845, 193.69196, 0.4334526)
decoder loss ratio: 6226.338956, decoder SINDy loss  ratio: 0.418111
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.698948]
 [ -0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 587.1320190429688, (199.07758, 0.15986075, 387.8946, 0.43351975)
   validation loss 353.9488525390625, (157.75888, 0.10326392, 196.0867, 0.43351975)
decoder loss ratio: 6111.852916, decoder SINDy loss  ratio: 0.423281
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.713833]
 [ -0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 953.4190673828125, (511.40518, 0.17316948, 441.84076, 0.4337266)
   validation loss 683.3002319335938, (471.9062, 0.10636663, 211.2877, 0.4337266)
decoder loss ratio: 18282.465026, decoder SINDy loss  ratio: 0.456094
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.722754]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 582.9449462890625, (197.28404, 0.17297803, 385.48795, 0.43384868)
   validation loss 343.43304443359375, (149.66028, 0.11303994, 193.65974, 0.43384868)
decoder loss ratio: 5798.099004, decoder SINDy loss  ratio: 0.418042
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.801537]
 [  0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.8958740234375, (379.49176, 0.18618213, 425.21796, 0.4339647)
   validation loss 543.2627563476562, (341.2553, 0.11058298, 201.89685, 0.4339647)
decoder loss ratio: 13220.823157, decoder SINDy loss  ratio: 0.435823
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.726433]
 [ -0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1244.1129150390625, (772.30194, 0.19056952, 471.62045, 0.4339647)
   validation loss 945.4993896484375, (722.46014, 0.10611442, 222.9331, 0.4339647)
decoder loss ratio: 27989.360226, decoder SINDy loss  ratio: 0.481232
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.73331]
 [ -0.     ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1858.4954833984375, (1356.5416, 0.18805794, 501.76578, 0.43398857)
   validation loss 1593.2569580078125, (1352.0221, 0.10230737, 241.13254, 0.43398857)
decoder loss ratio: 52379.683163, decoder SINDy loss  ratio: 0.520518
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.780548]
 [  0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.80078125, (282.93906, 0.15725388, 376.7045, 0.4340963)
   validation loss 413.51568603515625, (214.83551, 0.10373887, 198.57643, 0.4340963)
decoder loss ratio: 8323.100638, decoder SINDy loss  ratio: 0.428655
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.729866]
 [ -0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 586.895263671875, (200.41428, 0.1570598, 386.32394, 0.43415138)
   validation loss 353.6793518066406, (159.39998, 0.101371676, 194.17801, 0.43415138)
decoder loss ratio: 6175.431903, decoder SINDy loss  ratio: 0.419161
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.719584]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 591.9786376953125, (212.82181, 0.15536068, 379.00143, 0.43418416)
   validation loss 356.305419921875, (161.36243, 0.10227484, 194.8407, 0.43418416)
decoder loss ratio: 6251.460550, decoder SINDy loss  ratio: 0.420591
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.798466]
 [ -0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.77001953125, (297.13214, 0.13937356, 373.49854, 0.43420354)
   validation loss 432.66510009765625, (232.04767, 0.10009768, 200.51732, 0.43420354)
decoder loss ratio: 8989.929528, decoder SINDy loss  ratio: 0.432845
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.75719]
 [ -0.     ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 583.7052001953125, (205.34203, 0.15218274, 378.21097, 0.43430135)
   validation loss 348.34716796875, (154.55925, 0.10320786, 193.68471, 0.43430135)
decoder loss ratio: 5987.893667, decoder SINDy loss  ratio: 0.418096
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.80157]
 [ -0.     ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 582.9049682617188, (203.88077, 0.15981203, 378.86438, 0.43440914)
   validation loss 348.248779296875, (154.72069, 0.10516782, 193.42291, 0.43440914)
decoder loss ratio: 5994.148055, decoder SINDy loss  ratio: 0.417531
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.772783]
 [  0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.147216796875, (240.74379, 0.14048357, 374.26297, 0.434474)
   validation loss 378.83984375, (181.88754, 0.10023279, 196.85205, 0.434474)
decoder loss ratio: 7046.639176, decoder SINDy loss  ratio: 0.424933
params['save_name']
pendulum_2023_10_25_02_25_39_233517
