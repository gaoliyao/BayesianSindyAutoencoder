nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 23:23:45.750465: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 23:23:45.757862: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 23:23:45.760821: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8bf635670 executing computations on platform Host. Devices:
2023-10-25 23:23:45.760886: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 23:23:45.765622: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 23:23:45.918747: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8bf767630 executing computations on platform CUDA. Devices:
2023-10-25 23:23:45.918807: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 23:23:45.919804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2023-10-25 23:23:45.920394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 23:23:45.925194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 23:23:45.929019: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 23:23:45.929801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 23:23:45.933313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 23:23:45.935137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 23:23:45.941641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 23:23:45.942454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 23:23:45.942504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 23:23:45.942959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 23:23:45.942972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 23:23:45.942980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 23:23:45.943738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2023-10-25 23:23:47.046540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 2.5, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8538765907287598 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 110141.828125, (101466.86, 0.0059500365, 8658.216, 2.5317824)
   validation loss 94054.609375, (92837.11, 0.0015673101, 1200.755, 2.5317824)
decoder loss ratio: 3596670.789497, decoder SINDy loss  ratio: 2.591999
--- 0.25139427185058594 seconds for one epoch ---
--- 0.3246307373046875 seconds for one epoch ---
--- 0.32961201667785645 seconds for one epoch ---
--- 0.32799506187438965 seconds for one epoch ---
--- 0.33499670028686523 seconds for one epoch ---
--- 0.33687591552734375 seconds for one epoch ---
--- 0.3566410541534424 seconds for one epoch ---
--- 0.31924939155578613 seconds for one epoch ---
--- 0.3337690830230713 seconds for one epoch ---
--- 0.3215343952178955 seconds for one epoch ---
--- 0.34418177604675293 seconds for one epoch ---
--- 0.32268619537353516 seconds for one epoch ---
--- 0.33337950706481934 seconds for one epoch ---
--- 0.33380126953125 seconds for one epoch ---
--- 0.328615665435791 seconds for one epoch ---
--- 0.31621217727661133 seconds for one epoch ---
--- 0.3279993534088135 seconds for one epoch ---
--- 0.32072019577026367 seconds for one epoch ---
--- 0.33983397483825684 seconds for one epoch ---
--- 0.32109713554382324 seconds for one epoch ---
--- 0.3477163314819336 seconds for one epoch ---
--- 0.3120865821838379 seconds for one epoch ---
--- 0.3341395854949951 seconds for one epoch ---
--- 0.3216080665588379 seconds for one epoch ---
=========================
[[0.7810625 ]
 [0.78194267]
 [0.7836983 ]
 [0.7826386 ]
 [0.7806722 ]
 [0.7845663 ]
 [0.7823934 ]
 [0.78036165]
 [0.7800676 ]
 [0.7879795 ]
 [0.78087777]]
[[ 0.29204667]
 [ 0.526538  ]
 [-0.95903075]
 [-0.70303166]
 [-0.1835139 ]
 [-1.1586995 ]
 [ 0.64166445]
 [-0.09496596]
 [ 0.009177  ]
 [-1.8784761 ]
 [ 0.24121204]]
--- 0.268047571182251 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 67961.7578125, (60087.492, 27.360327, 7813.181, 2.531758)
   validation loss 38911.046875, (37612.836, 16.24937, 1248.233, 2.531758)
decoder loss ratio: 1457186.562974, decoder SINDy loss  ratio: 2.694487
--- 0.32198023796081543 seconds for one epoch ---
--- 0.34345483779907227 seconds for one epoch ---
--- 0.3244283199310303 seconds for one epoch ---
--- 0.33681464195251465 seconds for one epoch ---
--- 0.31426000595092773 seconds for one epoch ---
--- 0.3282897472381592 seconds for one epoch ---
--- 0.3242363929748535 seconds for one epoch ---
--- 0.343672513961792 seconds for one epoch ---
--- 0.3266029357910156 seconds for one epoch ---
--- 0.33939313888549805 seconds for one epoch ---
--- 0.31041646003723145 seconds for one epoch ---
--- 0.36423707008361816 seconds for one epoch ---
--- 0.3122684955596924 seconds for one epoch ---
--- 0.3445320129394531 seconds for one epoch ---
--- 0.32792043685913086 seconds for one epoch ---
--- 0.3385429382324219 seconds for one epoch ---
--- 0.31353044509887695 seconds for one epoch ---
--- 0.34267354011535645 seconds for one epoch ---
--- 0.31870388984680176 seconds for one epoch ---
--- 0.3418426513671875 seconds for one epoch ---
--- 0.32359838485717773 seconds for one epoch ---
--- 0.3495945930480957 seconds for one epoch ---
--- 0.3254575729370117 seconds for one epoch ---
--- 0.35010814666748047 seconds for one epoch ---
=========================
[[0.629652  ]
 [0.62608933]
 [0.6282093 ]
 [0.6248315 ]
 [0.6239584 ]
 [0.63480216]
 [0.6266694 ]
 [0.6244691 ]
 [0.6237032 ]
 [0.62887007]
 [0.6248181 ]]
[[ 0.9184804 ]
 [ 0.3953832 ]
 [-0.71410704]
 [-0.19390742]
 [-0.04757569]
 [-1.5852178 ]
 [ 0.48506948]
 [ 0.13382822]
 [ 0.00377958]
 [-0.8088812 ]
 [ 0.19168825]]
--- 0.30774903297424316 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 44938.1640625, (36106.82, 10.209014, 8768.764, 2.5317292)
   validation loss 42593.75390625, (41332.03, 16.262733, 1193.092, 2.5317292)
decoder loss ratio: 1601274.646187, decoder SINDy loss  ratio: 2.575457
--- 0.2776334285736084 seconds for one epoch ---
--- 0.32357287406921387 seconds for one epoch ---
--- 0.3475034236907959 seconds for one epoch ---
--- 0.3169841766357422 seconds for one epoch ---
--- 0.3427584171295166 seconds for one epoch ---
--- 0.32184457778930664 seconds for one epoch ---
--- 0.3469069004058838 seconds for one epoch ---
--- 0.3258490562438965 seconds for one epoch ---
--- 0.35073089599609375 seconds for one epoch ---
--- 0.31770944595336914 seconds for one epoch ---
--- 0.3532118797302246 seconds for one epoch ---
--- 0.32412195205688477 seconds for one epoch ---
--- 0.34665966033935547 seconds for one epoch ---
--- 0.3305060863494873 seconds for one epoch ---
--- 0.34920787811279297 seconds for one epoch ---
--- 0.4159064292907715 seconds for one epoch ---
--- 0.3545222282409668 seconds for one epoch ---
--- 0.32405662536621094 seconds for one epoch ---
--- 0.3330965042114258 seconds for one epoch ---
--- 0.3176753520965576 seconds for one epoch ---
--- 0.3528594970703125 seconds for one epoch ---
--- 0.31218647956848145 seconds for one epoch ---
--- 0.37897610664367676 seconds for one epoch ---
--- 0.3247241973876953 seconds for one epoch ---
=========================
[[0.50271946]
 [0.49453402]
 [0.49729717]
 [0.4932173 ]
 [0.4927722 ]
 [0.51220816]
 [0.49558043]
 [0.4944958 ]
 [0.4927293 ]
 [0.49433947]
 [0.49357995]]
[[ 1.1151391e+00]
 [ 2.2623305e-01]
 [-5.4717052e-01]
 [ 6.3656114e-02]
 [-7.0718061e-03]
 [-1.9787090e+00]
 [ 3.5081062e-01]
 [ 2.2163922e-01]
 [ 1.5832271e-03]
 [-2.0264952e-01]
 [ 1.0914332e-01]]
--- 0.2679586410522461 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 29944.53515625, (24226.719, 30.50999, 5618.0137, 2.531731)
   validation loss 19815.458984375, (18680.406, 1.0737268, 1064.686, 2.531731)
decoder loss ratio: 723711.368736, decoder SINDy loss  ratio: 2.298275
--- 0.3282620906829834 seconds for one epoch ---
--- 0.3631727695465088 seconds for one epoch ---
--- 0.339022159576416 seconds for one epoch ---
--- 0.34865474700927734 seconds for one epoch ---
--- 0.3264017105102539 seconds for one epoch ---
--- 0.3606598377227783 seconds for one epoch ---
--- 0.3312253952026367 seconds for one epoch ---
--- 0.35596370697021484 seconds for one epoch ---
--- 0.32950377464294434 seconds for one epoch ---
--- 0.37943315505981445 seconds for one epoch ---
--- 0.32323765754699707 seconds for one epoch ---
--- 0.37632250785827637 seconds for one epoch ---
--- 0.32347989082336426 seconds for one epoch ---
--- 0.365633487701416 seconds for one epoch ---
--- 0.3222529888153076 seconds for one epoch ---
--- 0.35016775131225586 seconds for one epoch ---
--- 0.3296334743499756 seconds for one epoch ---
--- 0.36142396926879883 seconds for one epoch ---
--- 0.3254849910736084 seconds for one epoch ---
--- 0.3632204532623291 seconds for one epoch ---
--- 0.32268810272216797 seconds for one epoch ---
--- 0.3531978130340576 seconds for one epoch ---
--- 0.3260829448699951 seconds for one epoch ---
--- 0.38155150413513184 seconds for one epoch ---
=========================
[[0.40777877]
 [0.40043864]
 [0.40241206]
 [0.4000838 ]
 [0.3993239 ]
 [0.4291996 ]
 [0.40179157]
 [0.40161493]
 [0.39908004]
 [0.40011454]
 [0.40021688]]
[[ 0.84822565]
 [ 0.14777803]
 [-0.34808856]
 [ 0.11064421]
 [-0.02983972]
 [-2.4674084 ]
 [ 0.28615317]
 [ 0.26840442]
 [-0.00353674]
 [-0.11385167]
 [ 0.12456898]]
--- 0.2730257511138916 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 29078.142578125, (20937.348, 1.6202264, 8053.0396, 2.5317428)
   validation loss 10135.7607421875, (9191.05, 0.6328691, 857.94257, 2.5317428)
decoder loss ratio: 356077.225798, decoder SINDy loss  ratio: 1.851990
--- 0.25513768196105957 seconds for one epoch ---
--- 0.2943267822265625 seconds for one epoch ---
--- 0.3429243564605713 seconds for one epoch ---
--- 0.29749536514282227 seconds for one epoch ---
--- 0.34178853034973145 seconds for one epoch ---
--- 0.3072934150695801 seconds for one epoch ---
--- 0.3420698642730713 seconds for one epoch ---
--- 0.29621458053588867 seconds for one epoch ---
--- 0.3454101085662842 seconds for one epoch ---
--- 0.2764143943786621 seconds for one epoch ---
--- 0.34102773666381836 seconds for one epoch ---
--- 0.29400062561035156 seconds for one epoch ---
--- 0.3493335247039795 seconds for one epoch ---
--- 0.32192397117614746 seconds for one epoch ---
--- 0.36244773864746094 seconds for one epoch ---
--- 0.2953684329986572 seconds for one epoch ---
--- 0.38607335090637207 seconds for one epoch ---
--- 0.29822683334350586 seconds for one epoch ---
--- 0.4004678726196289 seconds for one epoch ---
--- 0.3197333812713623 seconds for one epoch ---
--- 0.39080357551574707 seconds for one epoch ---
--- 0.3264467716217041 seconds for one epoch ---
--- 0.38326311111450195 seconds for one epoch ---
--- 0.2974741458892822 seconds for one epoch ---
=========================
[[0.32540008]
 [0.32106265]
 [0.3216331 ]
 [0.32138538]
 [0.32027727]
 [0.3613441 ]
 [0.32288808]
 [0.32305202]
 [0.32011402]
 [0.32333702]
 [0.3219723 ]]
[[ 4.7568199e-01]
 [ 8.9934349e-02]
 [-1.4287744e-01]
 [ 1.1996702e-01]
 [ 1.5779737e-02]
 [-2.8803620e+00]
 [ 2.5688690e-01]
 [ 2.7152771e-01]
 [-1.9725121e-04]
 [-2.9685631e-01]
 [ 1.7400779e-01]]
--- 0.28278493881225586 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14646.39453125, (9942.075, 1.626998, 4602.069, 2.531758)
   validation loss 5970.79296875, (5112.3506, 0.384054, 757.43616, 2.531758)
decoder loss ratio: 198061.337130, decoder SINDy loss  ratio: 1.635032
--- 0.32617712020874023 seconds for one epoch ---
--- 0.3933134078979492 seconds for one epoch ---
--- 0.3250877857208252 seconds for one epoch ---
--- 0.3754849433898926 seconds for one epoch ---
--- 0.3206596374511719 seconds for one epoch ---
--- 0.3877677917480469 seconds for one epoch ---
--- 0.31932687759399414 seconds for one epoch ---
--- 0.3976430892944336 seconds for one epoch ---
--- 0.31449103355407715 seconds for one epoch ---
--- 0.36319398880004883 seconds for one epoch ---
--- 0.32476115226745605 seconds for one epoch ---
--- 0.3713247776031494 seconds for one epoch ---
--- 0.318500280380249 seconds for one epoch ---
--- 0.3955979347229004 seconds for one epoch ---
--- 0.32968592643737793 seconds for one epoch ---
--- 0.3956577777862549 seconds for one epoch ---
--- 0.3092050552368164 seconds for one epoch ---
--- 0.3932762145996094 seconds for one epoch ---
--- 0.33852052688598633 seconds for one epoch ---
--- 0.399507999420166 seconds for one epoch ---
--- 0.33561277389526367 seconds for one epoch ---
--- 0.3904991149902344 seconds for one epoch ---
--- 0.3306875228881836 seconds for one epoch ---
--- 0.3675107955932617 seconds for one epoch ---
=========================
[[0.26501903]
 [0.2633145 ]
 [0.26395234]
 [0.26528648]
 [0.26347575]
 [0.3144125 ]
 [0.2660033 ]
 [0.266692  ]
 [0.2633392 ]
 [0.269449  ]
 [0.2655245 ]]
[[ 1.4775062e-01]
 [ 7.7887860e-05]
 [-5.6026481e-02]
 [ 1.7041786e-01]
 [ 1.4290736e-02]
 [-3.2127409e+00]
 [ 2.3048955e-01]
 [ 2.8734165e-01]
 [-2.2676405e-03]
 [-5.0730097e-01]
 [ 1.9047028e-01]]
--- 0.31183433532714844 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14562.36328125, (11586.572, 2.5302055, 2861.0227, 2.5317767)
   validation loss 5390.0, (4657.8545, 0.20006211, 619.7069, 2.5317767)
decoder loss ratio: 180453.369418, decoder SINDy loss  ratio: 1.337725
--- 0.27292847633361816 seconds for one epoch ---
--- 0.33243417739868164 seconds for one epoch ---
--- 0.4001307487487793 seconds for one epoch ---
--- 0.33121514320373535 seconds for one epoch ---
--- 0.40758180618286133 seconds for one epoch ---
--- 0.3347666263580322 seconds for one epoch ---
--- 0.41120076179504395 seconds for one epoch ---
--- 0.32596278190612793 seconds for one epoch ---
--- 0.39731478691101074 seconds for one epoch ---
--- 0.3270256519317627 seconds for one epoch ---
--- 0.3982067108154297 seconds for one epoch ---
--- 0.2946767807006836 seconds for one epoch ---
--- 0.3722972869873047 seconds for one epoch ---
--- 0.34433531761169434 seconds for one epoch ---
--- 0.3907003402709961 seconds for one epoch ---
--- 0.3291950225830078 seconds for one epoch ---
--- 0.38641905784606934 seconds for one epoch ---
--- 0.33909082412719727 seconds for one epoch ---
--- 0.3925178050994873 seconds for one epoch ---
--- 0.3469052314758301 seconds for one epoch ---
--- 0.40909743309020996 seconds for one epoch ---
--- 0.3302028179168701 seconds for one epoch ---
--- 0.39725208282470703 seconds for one epoch ---
--- 0.31821727752685547 seconds for one epoch ---
=========================
[[0.21712017]
 [0.21619114]
 [0.21523212]
 [0.21718241]
 [0.21542454]
 [0.27522463]
 [0.21772484]
 [0.21893217]
 [0.21524292]
 [0.225276  ]
 [0.21796721]]
[[-0.15868026]
 [-0.08406384]
 [-0.00546078]
 [ 0.16362523]
 [ 0.02138377]
 [-3.480203  ]
 [ 0.20647009]
 [ 0.30019888]
 [-0.00636932]
 [-0.7601736 ]
 [ 0.225468  ]]
--- 0.29290175437927246 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9477.1123046875, (4463.8975, 3.636301, 4886.979, 2.531802)
   validation loss 3133.766845703125, (2451.453, 0.12038984, 559.5944, 2.531802)
decoder loss ratio: 94973.540514, decoder SINDy loss  ratio: 1.207963
--- 0.33423542976379395 seconds for one epoch ---
--- 0.38216614723205566 seconds for one epoch ---
--- 0.328871488571167 seconds for one epoch ---
--- 0.40511488914489746 seconds for one epoch ---
--- 0.3311424255371094 seconds for one epoch ---
--- 0.38361406326293945 seconds for one epoch ---
--- 0.3256227970123291 seconds for one epoch ---
--- 0.40060949325561523 seconds for one epoch ---
--- 0.3311183452606201 seconds for one epoch ---
--- 0.3914046287536621 seconds for one epoch ---
--- 0.317227840423584 seconds for one epoch ---
--- 0.4065666198730469 seconds for one epoch ---
--- 0.313934326171875 seconds for one epoch ---
--- 0.4002363681793213 seconds for one epoch ---
--- 0.3268413543701172 seconds for one epoch ---
--- 0.41364121437072754 seconds for one epoch ---
--- 0.3198890686035156 seconds for one epoch ---
--- 0.38994550704956055 seconds for one epoch ---
--- 0.32702207565307617 seconds for one epoch ---
--- 0.39641547203063965 seconds for one epoch ---
--- 0.33440256118774414 seconds for one epoch ---
--- 0.38326072692871094 seconds for one epoch ---
--- 0.3128049373626709 seconds for one epoch ---
--- 0.39032983779907227 seconds for one epoch ---
=========================
[[0.1856766 ]
 [0.18199152]
 [0.18100996]
 [0.18218346]
 [0.18082389]
 [0.24769863]
 [0.18313755]
 [0.184184  ]
 [0.18041152]
 [0.19423291]
 [0.18475303]]
[[-0.40357888]
 [-0.13066432]
 [ 0.05460705]
 [ 0.14536756]
 [ 0.04001573]
 [-3.689839  ]
 [ 0.21758643]
 [ 0.29530767]
 [-0.00748651]
 [-0.97601086]
 [ 0.33692855]]
--- 0.31059694290161133 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6983.9892578125, (4306.942, 2.4758737, 2544.7039, 2.531829)
   validation loss 2634.396240234375, (1983.8536, 0.05687074, 520.6185, 2.531829)
decoder loss ratio: 76857.934046, decoder SINDy loss  ratio: 1.123828
--- 0.2598452568054199 seconds for one epoch ---
--- 0.34721899032592773 seconds for one epoch ---
--- 0.40227603912353516 seconds for one epoch ---
--- 0.3371446132659912 seconds for one epoch ---
--- 0.4029853343963623 seconds for one epoch ---
--- 0.33806586265563965 seconds for one epoch ---
--- 0.41811347007751465 seconds for one epoch ---
--- 0.29649996757507324 seconds for one epoch ---
--- 0.415726900100708 seconds for one epoch ---
--- 0.304213285446167 seconds for one epoch ---
--- 0.43041276931762695 seconds for one epoch ---
--- 0.3154947757720947 seconds for one epoch ---
--- 0.4042167663574219 seconds for one epoch ---
--- 0.3121335506439209 seconds for one epoch ---
--- 0.4249732494354248 seconds for one epoch ---
--- 0.4118366241455078 seconds for one epoch ---
--- 0.3968086242675781 seconds for one epoch ---
--- 0.3006095886230469 seconds for one epoch ---
--- 0.4004249572753906 seconds for one epoch ---
--- 0.32780933380126953 seconds for one epoch ---
--- 0.4041121006011963 seconds for one epoch ---
--- 0.32584166526794434 seconds for one epoch ---
--- 0.4131591320037842 seconds for one epoch ---
--- 0.33310413360595703 seconds for one epoch ---
=========================
[[0.1586293 ]
 [0.15315737]
 [0.15099381]
 [0.15286368]
 [0.15118107]
 [0.22186537]
 [0.15306608]
 [0.15466776]
 [0.15071073]
 [0.16817868]
 [0.15669343]]
[[-0.57080907]
 [-0.19069517]
 [ 0.02965535]
 [ 0.16922674]
 [ 0.04388093]
 [-3.7519217 ]
 [ 0.18402974]
 [ 0.2992396 ]
 [-0.00808156]
 [-1.1634946 ]
 [ 0.4403424 ]]
--- 0.2483978271484375 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7977.953125, (4429.253, 5.787614, 3405.801, 2.531844)
   validation loss 2326.1103515625, (1700.4463, 0.03162592, 488.5212, 2.531844)
decoder loss ratio: 65878.241343, decoder SINDy loss  ratio: 1.054542
--- 0.3380856513977051 seconds for one epoch ---
--- 0.4045231342315674 seconds for one epoch ---
--- 0.34792518615722656 seconds for one epoch ---
--- 0.3964536190032959 seconds for one epoch ---
--- 0.3306233882904053 seconds for one epoch ---
--- 0.3925914764404297 seconds for one epoch ---
--- 0.278059720993042 seconds for one epoch ---
--- 0.4164760112762451 seconds for one epoch ---
--- 0.3350942134857178 seconds for one epoch ---
--- 0.4257795810699463 seconds for one epoch ---
--- 0.3013269901275635 seconds for one epoch ---
--- 0.42745184898376465 seconds for one epoch ---
--- 0.32016515731811523 seconds for one epoch ---
--- 0.41098523139953613 seconds for one epoch ---
--- 0.30582547187805176 seconds for one epoch ---
--- 0.40674662590026855 seconds for one epoch ---
--- 0.3160576820373535 seconds for one epoch ---
--- 0.40462756156921387 seconds for one epoch ---
--- 0.3143007755279541 seconds for one epoch ---
--- 0.4303295612335205 seconds for one epoch ---
--- 0.32117652893066406 seconds for one epoch ---
--- 0.4258713722229004 seconds for one epoch ---
--- 0.29439258575439453 seconds for one epoch ---
--- 0.42374134063720703 seconds for one epoch ---
=========================
[[0.13897984]
 [0.13238955]
 [0.12913577]
 [0.13184175]
 [0.12921871]
 [0.20165125]
 [0.13123521]
 [0.1332473 ]
 [0.12901163]
 [0.14972751]
 [0.13552135]]
[[-6.8417269e-01]
 [-2.4686179e-01]
 [ 1.1899321e-02]
 [ 2.0830381e-01]
 [ 1.8089378e-02]
 [-3.7350793e+00]
 [ 1.6515017e-01]
 [ 3.0650282e-01]
 [-2.6427009e-03]
 [-1.3165106e+00]
 [ 4.6045190e-01]]
--- 0.3176276683807373 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6667.642578125, (2291.907, 0.4114079, 4231.9336, 2.5318508)
   validation loss 2207.3720703125, (1570.2411, 0.028732488, 493.71164, 2.5318508)
decoder loss ratio: 60833.865841, decoder SINDy loss  ratio: 1.065746
--- 0.25991392135620117 seconds for one epoch ---
--- 0.30972981452941895 seconds for one epoch ---
--- 0.46189141273498535 seconds for one epoch ---
--- 0.31577563285827637 seconds for one epoch ---
--- 0.4230363368988037 seconds for one epoch ---
--- 0.31227564811706543 seconds for one epoch ---
--- 0.44731736183166504 seconds for one epoch ---
--- 0.3304908275604248 seconds for one epoch ---
--- 0.4347071647644043 seconds for one epoch ---
--- 0.3425726890563965 seconds for one epoch ---
--- 0.4271211624145508 seconds for one epoch ---
--- 0.32812952995300293 seconds for one epoch ---
--- 0.43392062187194824 seconds for one epoch ---
--- 0.3314208984375 seconds for one epoch ---
--- 0.43845510482788086 seconds for one epoch ---
--- 0.32630372047424316 seconds for one epoch ---
--- 0.444291353225708 seconds for one epoch ---
--- 0.3330564498901367 seconds for one epoch ---
--- 0.45911240577697754 seconds for one epoch ---
--- 0.3327336311340332 seconds for one epoch ---
--- 0.4333033561706543 seconds for one epoch ---
--- 0.3172898292541504 seconds for one epoch ---
--- 0.44559764862060547 seconds for one epoch ---
--- 0.32573938369750977 seconds for one epoch ---
=========================
[[0.12201367]
 [0.11451405]
 [0.11059535]
 [0.11364373]
 [0.11078994]
 [0.18310629]
 [0.11261041]
 [0.11475452]
 [0.11055666]
 [0.13413969]
 [0.11799817]]
[[-0.76764405]
 [-0.28756735]
 [ 0.01197079]
 [ 0.2280385 ]
 [ 0.02613897]
 [-3.6711674 ]
 [ 0.15615305]
 [ 0.30385378]
 [-0.00914222]
 [-1.4508039 ]
 [ 0.5174379 ]]
--- 0.2640092372894287 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7317.31494140625, (4747.764, 2.930701, 2418.3904, 2.5318544)
   validation loss 1908.2822265625, (1271.7911, 0.032594375, 488.22824, 2.5318544)
decoder loss ratio: 49271.396601, decoder SINDy loss  ratio: 1.053909
--- 0.31299924850463867 seconds for one epoch ---
--- 0.4272310733795166 seconds for one epoch ---
--- 0.28322649002075195 seconds for one epoch ---
--- 0.42729926109313965 seconds for one epoch ---
--- 0.328263521194458 seconds for one epoch ---
--- 0.4330625534057617 seconds for one epoch ---
--- 0.32138657569885254 seconds for one epoch ---
--- 0.4441821575164795 seconds for one epoch ---
--- 0.33742666244506836 seconds for one epoch ---
--- 0.42495250701904297 seconds for one epoch ---
--- 0.3599715232849121 seconds for one epoch ---
--- 0.42683863639831543 seconds for one epoch ---
--- 0.32941317558288574 seconds for one epoch ---
--- 0.452181339263916 seconds for one epoch ---
--- 0.3321676254272461 seconds for one epoch ---
--- 0.4266805648803711 seconds for one epoch ---
--- 0.33679771423339844 seconds for one epoch ---
--- 0.4383206367492676 seconds for one epoch ---
--- 0.3394954204559326 seconds for one epoch ---
--- 0.4371225833892822 seconds for one epoch ---
--- 0.3346409797668457 seconds for one epoch ---
--- 0.4448060989379883 seconds for one epoch ---
--- 0.3255457878112793 seconds for one epoch ---
--- 0.4442903995513916 seconds for one epoch ---
=========================
[[0.11026319]
 [0.10172192]
 [0.09700058]
 [0.10091468]
 [0.09714889]
 [0.16893922]
 [0.09917293]
 [0.10121118]
 [0.0968831 ]
 [0.12398035]
 [0.10507868]]
[[-8.6490107e-01]
 [-3.3548138e-01]
 [ 1.0384202e-02]
 [ 2.8179094e-01]
 [ 2.1033067e-02]
 [-3.6018226e+00]
 [ 1.6337334e-01]
 [ 3.0158910e-01]
 [-1.9301672e-03]
 [-1.6072775e+00]
 [ 5.5144596e-01]]
--- 0.3092532157897949 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5642.271484375, (3364.6665, 1.0877291, 2123.0837, 2.5318584)
   validation loss 1992.341552734375, (1362.0541, 0.028728252, 476.8249, 2.5318584)
decoder loss ratio: 52768.339579, decoder SINDy loss  ratio: 1.029294
--- 0.2661001682281494 seconds for one epoch ---
--- 0.2945723533630371 seconds for one epoch ---
--- 0.44190049171447754 seconds for one epoch ---
--- 0.3181302547454834 seconds for one epoch ---
--- 0.44734859466552734 seconds for one epoch ---
--- 0.30284976959228516 seconds for one epoch ---
--- 0.4584391117095947 seconds for one epoch ---
--- 0.32089948654174805 seconds for one epoch ---
--- 0.45340657234191895 seconds for one epoch ---
--- 0.3088381290435791 seconds for one epoch ---
--- 0.43741655349731445 seconds for one epoch ---
--- 0.32961201667785645 seconds for one epoch ---
--- 0.4345371723175049 seconds for one epoch ---
--- 0.3042490482330322 seconds for one epoch ---
--- 0.44498324394226074 seconds for one epoch ---
--- 0.31844305992126465 seconds for one epoch ---
--- 0.44974184036254883 seconds for one epoch ---
--- 0.32644104957580566 seconds for one epoch ---
--- 0.43366503715515137 seconds for one epoch ---
--- 0.2936244010925293 seconds for one epoch ---
--- 0.4526798725128174 seconds for one epoch ---
--- 0.3195066452026367 seconds for one epoch ---
--- 0.460357666015625 seconds for one epoch ---
--- 0.3113386631011963 seconds for one epoch ---
=========================
[[0.10039973]
 [0.09075045]
 [0.08537568]
 [0.08912414]
 [0.08557326]
 [0.15638217]
 [0.08789018]
 [0.08930597]
 [0.08532322]
 [0.1157291 ]
 [0.09498686]]
[[-0.95996535]
 [-0.37887344]
 [ 0.01581833]
 [ 0.27253652]
 [ 0.02979343]
 [-3.5296493 ]
 [ 0.18990579]
 [ 0.28456745]
 [-0.01210392]
 [-1.7599894 ]
 [ 0.64359623]]
--- 0.2515842914581299 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8977.4990234375, (6457.5845, 1.3427459, 2361.7656, 2.5318646)
   validation loss 1689.8162841796875, (1096.9868, 0.03928948, 435.98434, 2.5318646)
decoder loss ratio: 42499.173720, decoder SINDy loss  ratio: 0.941134
--- 0.29066014289855957 seconds for one epoch ---
--- 0.4466094970703125 seconds for one epoch ---
--- 0.31591224670410156 seconds for one epoch ---
--- 0.4918696880340576 seconds for one epoch ---
--- 0.3171968460083008 seconds for one epoch ---
--- 0.46072864532470703 seconds for one epoch ---
--- 0.3194260597229004 seconds for one epoch ---
--- 0.45982909202575684 seconds for one epoch ---
--- 0.3217153549194336 seconds for one epoch ---
--- 0.45075011253356934 seconds for one epoch ---
--- 0.31041526794433594 seconds for one epoch ---
--- 0.45638346672058105 seconds for one epoch ---
--- 0.31400346755981445 seconds for one epoch ---
--- 0.4703047275543213 seconds for one epoch ---
--- 0.3173329830169678 seconds for one epoch ---
--- 0.45110344886779785 seconds for one epoch ---
--- 0.3246617317199707 seconds for one epoch ---
--- 0.4386570453643799 seconds for one epoch ---
--- 0.3117516040802002 seconds for one epoch ---
--- 0.5145423412322998 seconds for one epoch ---
--- 0.3171510696411133 seconds for one epoch ---
--- 0.4805481433868408 seconds for one epoch ---
--- 0.2931993007659912 seconds for one epoch ---
--- 0.4804036617279053 seconds for one epoch ---
=========================
[[0.09347837]
 [0.08212177]
 [0.07694998]
 [0.08057348]
 [0.07682133]
 [0.14651027]
 [0.07957789]
 [0.08074658]
 [0.07660701]
 [0.11046468]
 [0.08769202]]
[[-1.0458668 ]
 [-0.37457365]
 [ 0.02887039]
 [ 0.27424464]
 [ 0.01986068]
 [-3.452262  ]
 [ 0.20836572]
 [ 0.28558975]
 [-0.00479867]
 [-1.9058155 ]
 [ 0.7165848 ]]
--- 0.3171257972717285 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5790.595703125, (3038.9912, 2.7808747, 2587.6626, 2.5318694)
   validation loss 2265.639892578125, (1647.5135, 0.038506065, 456.92633, 2.5318694)
decoder loss ratio: 63827.535129, decoder SINDy loss  ratio: 0.986340
--- 0.2638089656829834 seconds for one epoch ---
--- 0.33227086067199707 seconds for one epoch ---
--- 0.4884624481201172 seconds for one epoch ---
--- 0.3454883098602295 seconds for one epoch ---
--- 0.45050048828125 seconds for one epoch ---
--- 0.3293452262878418 seconds for one epoch ---
--- 0.4800832271575928 seconds for one epoch ---
--- 0.3208189010620117 seconds for one epoch ---
--- 0.5000715255737305 seconds for one epoch ---
--- 0.33130645751953125 seconds for one epoch ---
--- 0.4844632148742676 seconds for one epoch ---
--- 0.31783127784729004 seconds for one epoch ---
--- 0.46141529083251953 seconds for one epoch ---
--- 0.3171827793121338 seconds for one epoch ---
--- 0.4763782024383545 seconds for one epoch ---
--- 0.3100128173828125 seconds for one epoch ---
--- 0.4582505226135254 seconds for one epoch ---
--- 0.32363009452819824 seconds for one epoch ---
--- 0.514622688293457 seconds for one epoch ---
--- 0.29877233505249023 seconds for one epoch ---
--- 0.4533267021179199 seconds for one epoch ---
--- 0.30993127822875977 seconds for one epoch ---
--- 0.48932409286499023 seconds for one epoch ---
--- 0.2752695083618164 seconds for one epoch ---
=========================
[[0.0880928 ]
 [0.07499798]
 [0.06940747]
 [0.07292837]
 [0.06913413]
 [0.13766779]
 [0.07191665]
 [0.07329206]
 [0.06918975]
 [0.10696566]
 [0.08207226]]
[[-1.1506846 ]
 [-0.39338735]
 [ 0.02333113]
 [ 0.26044047]
 [ 0.00429379]
 [-3.3746483 ]
 [ 0.19378941]
 [ 0.28412625]
 [-0.00817052]
 [-2.0761476 ]
 [ 0.81822944]]
--- 0.25298619270324707 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6615.55078125, (3752.3096, 0.83616316, 2697.603, 2.5318763)
   validation loss 1929.180419921875, (1261.8949, 0.061131436, 502.42236, 2.5318763)
decoder loss ratio: 48887.999074, decoder SINDy loss  ratio: 1.084549
--- 0.31319165229797363 seconds for one epoch ---
--- 0.4830291271209717 seconds for one epoch ---
--- 0.33100390434265137 seconds for one epoch ---
--- 0.46856117248535156 seconds for one epoch ---
--- 0.3199272155761719 seconds for one epoch ---
--- 0.4806063175201416 seconds for one epoch ---
--- 0.33197808265686035 seconds for one epoch ---
--- 0.49497246742248535 seconds for one epoch ---
--- 0.3243722915649414 seconds for one epoch ---
--- 0.46378016471862793 seconds for one epoch ---
--- 0.32999634742736816 seconds for one epoch ---
--- 0.47778987884521484 seconds for one epoch ---
--- 0.3304405212402344 seconds for one epoch ---
--- 0.4830305576324463 seconds for one epoch ---
--- 0.3363199234008789 seconds for one epoch ---
--- 0.49710941314697266 seconds for one epoch ---
--- 0.32990050315856934 seconds for one epoch ---
--- 0.49899744987487793 seconds for one epoch ---
--- 0.3242316246032715 seconds for one epoch ---
--- 0.5141899585723877 seconds for one epoch ---
--- 0.3307332992553711 seconds for one epoch ---
--- 0.49946141242980957 seconds for one epoch ---
--- 0.2971005439758301 seconds for one epoch ---
--- 0.4743492603302002 seconds for one epoch ---
=========================
[[0.08441748]
 [0.06986839]
 [0.06404424]
 [0.06795339]
 [0.06383305]
 [0.13062336]
 [0.06642187]
 [0.06758812]
 [0.06356879]
 [0.10504416]
 [0.07755938]]
[[-1.2419721e+00]
 [-4.1592023e-01]
 [ 3.4317758e-02]
 [ 2.9448998e-01]
 [ 1.9740898e-02]
 [-3.2977548e+00]
 [ 1.9464034e-01]
 [ 2.7090719e-01]
 [-1.4282791e-03]
 [-2.2275457e+00]
 [ 8.7108165e-01]]
--- 0.4323244094848633 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6957.01123046875, (2233.7249, 3.687964, 4551.104, 2.5318837)
   validation loss 1518.4688720703125, (936.7026, 0.059177198, 413.21216, 2.5318837)
decoder loss ratio: 36289.483969, decoder SINDy loss  ratio: 0.891977
--- 0.2642662525177002 seconds for one epoch ---
--- 0.3223738670349121 seconds for one epoch ---
--- 0.46245622634887695 seconds for one epoch ---
--- 0.3211171627044678 seconds for one epoch ---
--- 0.49836206436157227 seconds for one epoch ---
--- 0.34187865257263184 seconds for one epoch ---
--- 0.4958760738372803 seconds for one epoch ---
--- 0.304659366607666 seconds for one epoch ---
--- 0.4637792110443115 seconds for one epoch ---
--- 0.31673741340637207 seconds for one epoch ---
--- 0.5004251003265381 seconds for one epoch ---
--- 0.31318116188049316 seconds for one epoch ---
--- 0.4765310287475586 seconds for one epoch ---
--- 0.32416224479675293 seconds for one epoch ---
--- 0.501338005065918 seconds for one epoch ---
--- 0.3282482624053955 seconds for one epoch ---
--- 0.5057857036590576 seconds for one epoch ---
--- 0.34009838104248047 seconds for one epoch ---
--- 0.5107276439666748 seconds for one epoch ---
--- 0.3398571014404297 seconds for one epoch ---
--- 0.5113468170166016 seconds for one epoch ---
--- 0.31537580490112305 seconds for one epoch ---
--- 0.4771697521209717 seconds for one epoch ---
--- 0.3315417766571045 seconds for one epoch ---
=========================
[[0.08073512]
 [0.06550745]
 [0.05928503]
 [0.06272492]
 [0.05898488]
 [0.12324452]
 [0.0614756 ]
 [0.06287626]
 [0.05876852]
 [0.10312204]
 [0.07339153]]
[[-1.2947677e+00]
 [-4.4193122e-01]
 [ 3.7846070e-02]
 [ 2.6634914e-01]
 [ 1.7240949e-02]
 [-3.1815202e+00]
 [ 1.8492211e-01]
 [ 2.7610108e-01]
 [-2.3162242e-03]
 [-2.3448477e+00]
 [ 9.0305632e-01]]
--- 0.2529318332672119 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5010.04736328125, (2398.0342, 2.423662, 2437.4607, 2.5318847)
   validation loss 3906.181884765625, (3259.119, 0.062262457, 474.8719, 2.5318847)
decoder loss ratio: 126263.924129, decoder SINDy loss  ratio: 1.025078
--- 0.33036351203918457 seconds for one epoch ---
--- 0.4822204113006592 seconds for one epoch ---
--- 0.3193795680999756 seconds for one epoch ---
--- 0.4963352680206299 seconds for one epoch ---
--- 0.3162658214569092 seconds for one epoch ---
--- 0.4898509979248047 seconds for one epoch ---
--- 0.3263130187988281 seconds for one epoch ---
--- 0.5033414363861084 seconds for one epoch ---
--- 0.3180267810821533 seconds for one epoch ---
--- 0.5059494972229004 seconds for one epoch ---
--- 0.3137531280517578 seconds for one epoch ---
--- 0.4935770034790039 seconds for one epoch ---
--- 0.32363271713256836 seconds for one epoch ---
--- 0.504662036895752 seconds for one epoch ---
--- 0.3280513286590576 seconds for one epoch ---
--- 0.5093374252319336 seconds for one epoch ---
--- 0.33467698097229004 seconds for one epoch ---
--- 0.5244863033294678 seconds for one epoch ---
--- 0.30118608474731445 seconds for one epoch ---
--- 0.5032200813293457 seconds for one epoch ---
--- 0.29889440536499023 seconds for one epoch ---
--- 0.5269215106964111 seconds for one epoch ---
--- 0.3047666549682617 seconds for one epoch ---
--- 0.5093302726745605 seconds for one epoch ---
=========================
[[0.07869724]
 [0.062092  ]
 [0.05607469]
 [0.05868017]
 [0.05538561]
 [0.11809345]
 [0.05793301]
 [0.05917849]
 [0.05524091]
 [0.10270733]
 [0.07130229]]
[[-1.3688048 ]
 [-0.45046932]
 [ 0.06283288]
 [ 0.23539105]
 [ 0.01585666]
 [-3.108789  ]
 [ 0.18669236]
 [ 0.26753685]
 [-0.00591682]
 [-2.473622  ]
 [ 0.9818207 ]]
--- 0.28877925872802734 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3654.423095703125, (1835.2036, 0.4663624, 1644.5537, 2.5318906)
   validation loss 5348.353515625, (4656.633, 0.049126573, 517.4722, 2.5318906)
decoder loss ratio: 180406.039426, decoder SINDy loss  ratio: 1.117037
--- 0.2740147113800049 seconds for one epoch ---
--- 0.30218076705932617 seconds for one epoch ---
--- 0.5087604522705078 seconds for one epoch ---
--- 0.3107945919036865 seconds for one epoch ---
--- 0.5056912899017334 seconds for one epoch ---
--- 0.30438971519470215 seconds for one epoch ---
--- 0.4922482967376709 seconds for one epoch ---
--- 0.30750489234924316 seconds for one epoch ---
--- 0.5034873485565186 seconds for one epoch ---
--- 0.31966328620910645 seconds for one epoch ---
--- 0.5057053565979004 seconds for one epoch ---
--- 0.30409860610961914 seconds for one epoch ---
--- 0.5141558647155762 seconds for one epoch ---
--- 0.3105309009552002 seconds for one epoch ---
--- 0.5193099975585938 seconds for one epoch ---
--- 0.3241398334503174 seconds for one epoch ---
--- 0.5043408870697021 seconds for one epoch ---
--- 0.3008716106414795 seconds for one epoch ---
--- 0.5049393177032471 seconds for one epoch ---
--- 0.2894876003265381 seconds for one epoch ---
--- 0.5239393711090088 seconds for one epoch ---
--- 0.3230268955230713 seconds for one epoch ---
--- 0.5380594730377197 seconds for one epoch ---
--- 0.32135915756225586 seconds for one epoch ---
=========================
[[0.0768998 ]
 [0.05861265]
 [0.05312387]
 [0.05591528]
 [0.05204354]
 [0.11334073]
 [0.05539254]
 [0.05584447]
 [0.05213951]
 [0.10236817]
 [0.06932672]]
[[-1.4317217e+00]
 [-4.2792451e-01]
 [ 7.5051203e-02]
 [ 2.5846490e-01]
 [-1.6210926e-03]
 [-3.0354950e+00]
 [ 2.2477055e-01]
 [ 2.5391442e-01]
 [-8.2042553e-03]
 [-2.5850518e+00]
 [ 1.0414501e+00]]
--- 0.24579405784606934 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3427.638671875, (1612.2012, 0.6475409, 1638.554, 2.5318954)
   validation loss 1843.9351806640625, (1256.1982, 0.05511497, 411.44617, 2.5318954)
decoder loss ratio: 48667.300758, decoder SINDy loss  ratio: 0.888164
--- 0.3093602657318115 seconds for one epoch ---
--- 0.501166820526123 seconds for one epoch ---
--- 0.3141767978668213 seconds for one epoch ---
--- 0.5299093723297119 seconds for one epoch ---
--- 0.3179056644439697 seconds for one epoch ---
--- 0.5206782817840576 seconds for one epoch ---
--- 0.32517051696777344 seconds for one epoch ---
--- 0.5366604328155518 seconds for one epoch ---
--- 0.3221771717071533 seconds for one epoch ---
--- 0.5224094390869141 seconds for one epoch ---
--- 0.3135366439819336 seconds for one epoch ---
--- 0.5201051235198975 seconds for one epoch ---
--- 0.32297778129577637 seconds for one epoch ---
--- 0.54274582862854 seconds for one epoch ---
--- 0.314716100692749 seconds for one epoch ---
--- 0.5229072570800781 seconds for one epoch ---
--- 0.29642629623413086 seconds for one epoch ---
--- 0.5093784332275391 seconds for one epoch ---
--- 0.2945125102996826 seconds for one epoch ---
--- 0.5258383750915527 seconds for one epoch ---
--- 0.29769015312194824 seconds for one epoch ---
--- 0.5400617122650146 seconds for one epoch ---
--- 0.297696590423584 seconds for one epoch ---
--- 0.5527000427246094 seconds for one epoch ---
=========================
[[0.07558516]
 [0.05646138]
 [0.05111465]
 [0.05356795]
 [0.04982413]
 [0.10893752]
 [0.05288016]
 [0.0534708 ]
 [0.04970476]
 [0.10241883]
 [0.06729488]]
[[-1.4794466e+00]
 [-4.3871886e-01]
 [ 9.7252801e-02]
 [ 2.5761369e-01]
 [ 1.0112825e-02]
 [-2.9464133e+00]
 [ 2.1331884e-01]
 [ 2.5138274e-01]
 [ 1.9487351e-03]
 [-2.6796198e+00]
 [ 1.0558056e+00]]
--- 0.301837682723999 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3805.193359375, (1547.0486, 0.9591972, 2078.7803, 2.531898)
   validation loss 2031.45068359375, (1463.6276, 0.06282469, 389.35526, 2.531898)
decoder loss ratio: 56703.472778, decoder SINDy loss  ratio: 0.840478
THRESHOLDING: 2 active coefficients
--- 0.5079801082611084 seconds for one epoch ---
--- 0.3044278621673584 seconds for one epoch ---
--- 0.5328474044799805 seconds for one epoch ---
--- 0.3306746482849121 seconds for one epoch ---
--- 0.5063097476959229 seconds for one epoch ---
--- 0.3102407455444336 seconds for one epoch ---
--- 0.5211515426635742 seconds for one epoch ---
--- 0.3037223815917969 seconds for one epoch ---
--- 0.5238125324249268 seconds for one epoch ---
--- 0.3353393077850342 seconds for one epoch ---
--- 0.5321588516235352 seconds for one epoch ---
--- 0.29596614837646484 seconds for one epoch ---
--- 0.5152931213378906 seconds for one epoch ---
--- 0.2892298698425293 seconds for one epoch ---
--- 0.532968282699585 seconds for one epoch ---
--- 0.33336472511291504 seconds for one epoch ---
--- 0.5398242473602295 seconds for one epoch ---
--- 0.3342905044555664 seconds for one epoch ---
--- 0.5432865619659424 seconds for one epoch ---
--- 0.33750486373901367 seconds for one epoch ---
--- 0.5488564968109131 seconds for one epoch ---
--- 0.33712220191955566 seconds for one epoch ---
--- 0.5718050003051758 seconds for one epoch ---
--- 0.34140777587890625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08578455]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09488579]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.0495746]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.445654 ]
 [ 0.       ]]
--- 0.2605316638946533 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3083.44873046875, (2255.2256, 0.3400665, 827.6978, 0.18526664)
   validation loss 1461.376953125, (1054.2234, 0.08909624, 406.8792, 0.18526664)
decoder loss ratio: 40842.444289, decoder SINDy loss  ratio: 0.878306
--- 0.29416465759277344 seconds for one epoch ---
--- 0.5274145603179932 seconds for one epoch ---
--- 0.29753971099853516 seconds for one epoch ---
--- 0.5417687892913818 seconds for one epoch ---
--- 0.3083789348602295 seconds for one epoch ---
--- 0.5249161720275879 seconds for one epoch ---
--- 0.2992231845855713 seconds for one epoch ---
--- 0.5301399230957031 seconds for one epoch ---
--- 0.3050241470336914 seconds for one epoch ---
--- 0.521477460861206 seconds for one epoch ---
--- 0.3307046890258789 seconds for one epoch ---
--- 0.5421216487884521 seconds for one epoch ---
--- 0.31915712356567383 seconds for one epoch ---
--- 0.5176537036895752 seconds for one epoch ---
--- 0.3327944278717041 seconds for one epoch ---
--- 0.5251002311706543 seconds for one epoch ---
--- 0.3138115406036377 seconds for one epoch ---
--- 0.5324866771697998 seconds for one epoch ---
--- 0.3037755489349365 seconds for one epoch ---
--- 0.5280623435974121 seconds for one epoch ---
--- 0.2984139919281006 seconds for one epoch ---
--- 0.5450272560119629 seconds for one epoch ---
--- 0.2993006706237793 seconds for one epoch ---
--- 0.5640180110931396 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07554824]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09209762]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.6470633]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3897135]
 [ 0.       ]]
--- 0.3105344772338867 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4482.9365234375, (2677.2505, 0.58071, 1804.9248, 0.18062107)
   validation loss 1086.9718017578125, (688.96924, 0.105199836, 397.7167, 0.18062107)
decoder loss ratio: 26691.864394, decoder SINDy loss  ratio: 0.858527
--- 0.287992000579834 seconds for one epoch ---
--- 0.3230898380279541 seconds for one epoch ---
--- 0.5611579418182373 seconds for one epoch ---
--- 0.29441380500793457 seconds for one epoch ---
--- 0.555333137512207 seconds for one epoch ---
--- 0.28159546852111816 seconds for one epoch ---
--- 0.5785768032073975 seconds for one epoch ---
--- 0.31907033920288086 seconds for one epoch ---
--- 0.5609989166259766 seconds for one epoch ---
--- 0.3124256134033203 seconds for one epoch ---
--- 0.5758512020111084 seconds for one epoch ---
--- 0.30764245986938477 seconds for one epoch ---
--- 0.5428643226623535 seconds for one epoch ---
--- 0.3039999008178711 seconds for one epoch ---
--- 0.546118974685669 seconds for one epoch ---
--- 0.31194090843200684 seconds for one epoch ---
--- 0.5780487060546875 seconds for one epoch ---
--- 0.30837368965148926 seconds for one epoch ---
--- 0.5437881946563721 seconds for one epoch ---
--- 0.3116722106933594 seconds for one epoch ---
--- 0.5773348808288574 seconds for one epoch ---
--- 0.30495405197143555 seconds for one epoch ---
--- 0.5521240234375 seconds for one epoch ---
--- 0.32401490211486816 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06993686]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09025156]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4401202]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3665855]
 [ 0.       ]]
--- 0.27097034454345703 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3803.166015625, (1570.4891, 0.7186728, 2231.78, 0.17824647)
   validation loss 4312.04638671875, (3850.8223, 0.092577726, 460.95316, 0.17824647)
decoder loss ratio: 149187.539892, decoder SINDy loss  ratio: 0.995032
--- 0.31087613105773926 seconds for one epoch ---
--- 0.5445692539215088 seconds for one epoch ---
--- 0.28794264793395996 seconds for one epoch ---
--- 0.5492768287658691 seconds for one epoch ---
--- 0.29734206199645996 seconds for one epoch ---
--- 0.5426340103149414 seconds for one epoch ---
--- 0.3041212558746338 seconds for one epoch ---
--- 0.5503699779510498 seconds for one epoch ---
--- 0.2902991771697998 seconds for one epoch ---
--- 0.5548038482666016 seconds for one epoch ---
--- 0.33107519149780273 seconds for one epoch ---
--- 0.5632565021514893 seconds for one epoch ---
--- 0.3366682529449463 seconds for one epoch ---
--- 0.5498003959655762 seconds for one epoch ---
--- 0.3354949951171875 seconds for one epoch ---
--- 0.5809648036956787 seconds for one epoch ---
--- 0.34184813499450684 seconds for one epoch ---
--- 0.5878806114196777 seconds for one epoch ---
--- 0.3340108394622803 seconds for one epoch ---
--- 0.5696306228637695 seconds for one epoch ---
--- 0.31975317001342773 seconds for one epoch ---
--- 0.5870342254638672 seconds for one epoch ---
--- 0.33977413177490234 seconds for one epoch ---
--- 0.5815157890319824 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06744035]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08990081]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3664073]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3936105]
 [ 0.       ]]
--- 0.30596494674682617 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5730.935546875, (3184.733, 0.27267233, 2545.7522, 0.17792605)
   validation loss 1573.7911376953125, (1133.1808, 0.1687857, 440.26352, 0.17792605)
decoder loss ratio: 43901.390943, decoder SINDy loss  ratio: 0.950371
--- 0.2607898712158203 seconds for one epoch ---
--- 0.3279571533203125 seconds for one epoch ---
--- 0.5724382400512695 seconds for one epoch ---
--- 0.29651713371276855 seconds for one epoch ---
--- 0.5698339939117432 seconds for one epoch ---
--- 0.2887563705444336 seconds for one epoch ---
--- 0.5750541687011719 seconds for one epoch ---
--- 0.3196241855621338 seconds for one epoch ---
--- 0.5732681751251221 seconds for one epoch ---
--- 0.29055237770080566 seconds for one epoch ---
--- 0.5780885219573975 seconds for one epoch ---
--- 0.2859616279602051 seconds for one epoch ---
--- 0.5501656532287598 seconds for one epoch ---
--- 0.29506969451904297 seconds for one epoch ---
--- 0.5749974250793457 seconds for one epoch ---
--- 0.31557297706604004 seconds for one epoch ---
--- 0.574124813079834 seconds for one epoch ---
--- 0.32623839378356934 seconds for one epoch ---
--- 0.5868728160858154 seconds for one epoch ---
--- 0.3196284770965576 seconds for one epoch ---
--- 0.5802536010742188 seconds for one epoch ---
--- 0.32538533210754395 seconds for one epoch ---
--- 0.605687141418457 seconds for one epoch ---
--- 0.3298213481903076 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06592185]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08991768]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3353281]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4314082]
 [ 0.       ]]
--- 0.23385310173034668 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3330.34228515625, (1335.4509, 0.23909025, 1994.4745, 0.17777698)
   validation loss 1318.275146484375, (937.67267, 0.13853902, 380.28613, 0.17777698)
decoder loss ratio: 36327.067047, decoder SINDy loss  ratio: 0.820901
--- 0.327239990234375 seconds for one epoch ---
--- 0.5894284248352051 seconds for one epoch ---
--- 0.44309473037719727 seconds for one epoch ---
--- 0.5828139781951904 seconds for one epoch ---
--- 0.3296525478363037 seconds for one epoch ---
--- 0.5958397388458252 seconds for one epoch ---
--- 0.31040024757385254 seconds for one epoch ---
--- 0.5805768966674805 seconds for one epoch ---
--- 0.3047647476196289 seconds for one epoch ---
--- 0.5837526321411133 seconds for one epoch ---
--- 0.30144357681274414 seconds for one epoch ---
--- 0.5854499340057373 seconds for one epoch ---
--- 0.32225823402404785 seconds for one epoch ---
--- 0.597308874130249 seconds for one epoch ---
--- 0.31277036666870117 seconds for one epoch ---
--- 0.6069295406341553 seconds for one epoch ---
--- 0.3148341178894043 seconds for one epoch ---
--- 0.5912570953369141 seconds for one epoch ---
--- 0.32964181900024414 seconds for one epoch ---
--- 0.6190953254699707 seconds for one epoch ---
--- 0.33763575553894043 seconds for one epoch ---
--- 0.5929768085479736 seconds for one epoch ---
--- 0.33071041107177734 seconds for one epoch ---
--- 0.6252052783966064 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06474978]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0896616 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3106581]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4485738]
 [ 0.       ]]
--- 0.3279232978820801 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2321.579833984375, (1432.9401, 1.0329653, 887.4287, 0.1780145)
   validation loss 1431.1900634765625, (1060.627, 0.119731784, 370.26535, 0.1780145)
decoder loss ratio: 41090.529493, decoder SINDy loss  ratio: 0.799270
--- 0.25732994079589844 seconds for one epoch ---
--- 0.3389298915863037 seconds for one epoch ---
--- 0.5778031349182129 seconds for one epoch ---
--- 0.3215517997741699 seconds for one epoch ---
--- 0.6112723350524902 seconds for one epoch ---
--- 0.30220556259155273 seconds for one epoch ---
--- 0.5991227626800537 seconds for one epoch ---
--- 0.30116724967956543 seconds for one epoch ---
--- 0.578413724899292 seconds for one epoch ---
--- 0.30875253677368164 seconds for one epoch ---
--- 0.5869824886322021 seconds for one epoch ---
--- 0.30231285095214844 seconds for one epoch ---
--- 0.6010241508483887 seconds for one epoch ---
--- 0.2940096855163574 seconds for one epoch ---
--- 0.5997467041015625 seconds for one epoch ---
--- 0.30083322525024414 seconds for one epoch ---
--- 0.5961530208587646 seconds for one epoch ---
--- 0.2902791500091553 seconds for one epoch ---
--- 0.6602156162261963 seconds for one epoch ---
--- 0.3020148277282715 seconds for one epoch ---
--- 0.5850727558135986 seconds for one epoch ---
--- 0.29302287101745605 seconds for one epoch ---
--- 0.5988836288452148 seconds for one epoch ---
--- 0.3055276870727539 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06349415]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09010833]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2779919]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4922204]
 [ 0.       ]]
--- 0.2872922420501709 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3451.944580078125, (2007.4077, 0.71066546, 1443.6482, 0.1779778)
   validation loss 1995.5985107421875, (1582.8575, 0.1674241, 412.3955, 0.1779778)
decoder loss ratio: 61322.649214, decoder SINDy loss  ratio: 0.890214
--- 0.30727481842041016 seconds for one epoch ---
--- 0.6179571151733398 seconds for one epoch ---
--- 0.30530881881713867 seconds for one epoch ---
--- 0.6257007122039795 seconds for one epoch ---
--- 0.29259395599365234 seconds for one epoch ---
--- 0.6078002452850342 seconds for one epoch ---
--- 0.2918729782104492 seconds for one epoch ---
--- 0.6018812656402588 seconds for one epoch ---
--- 0.3042480945587158 seconds for one epoch ---
--- 0.6331138610839844 seconds for one epoch ---
--- 0.31548261642456055 seconds for one epoch ---
--- 0.612943172454834 seconds for one epoch ---
--- 0.32338380813598633 seconds for one epoch ---
--- 0.6173896789550781 seconds for one epoch ---
--- 0.30355048179626465 seconds for one epoch ---
--- 0.6218068599700928 seconds for one epoch ---
--- 0.3123750686645508 seconds for one epoch ---
--- 0.6403558254241943 seconds for one epoch ---
--- 0.31202244758605957 seconds for one epoch ---
--- 0.6213994026184082 seconds for one epoch ---
--- 0.29008936882019043 seconds for one epoch ---
--- 0.6193158626556396 seconds for one epoch ---
--- 0.3167457580566406 seconds for one epoch ---
--- 0.6190183162689209 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06294888]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09177925]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2738317]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.5806983]
 [ 0.       ]]
--- 0.29279446601867676 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3452.187255859375, (1509.3806, 0.8150685, 1941.8126, 0.17898026)
   validation loss 1364.44970703125, (979.3491, 0.09627329, 384.82535, 0.17898026)
decoder loss ratio: 37941.685176, decoder SINDy loss  ratio: 0.830700
--- 0.26661133766174316 seconds for one epoch ---
--- 0.30014657974243164 seconds for one epoch ---
--- 0.6260240077972412 seconds for one epoch ---
--- 0.292147159576416 seconds for one epoch ---
--- 0.6128849983215332 seconds for one epoch ---
--- 0.29749059677124023 seconds for one epoch ---
--- 0.6042540073394775 seconds for one epoch ---
--- 0.32557106018066406 seconds for one epoch ---
--- 0.6186783313751221 seconds for one epoch ---
--- 0.3179912567138672 seconds for one epoch ---
--- 0.61029052734375 seconds for one epoch ---
--- 0.30644679069519043 seconds for one epoch ---
--- 0.6065232753753662 seconds for one epoch ---
--- 0.31688642501831055 seconds for one epoch ---
--- 0.6183505058288574 seconds for one epoch ---
--- 0.3104538917541504 seconds for one epoch ---
--- 0.6171014308929443 seconds for one epoch ---
--- 0.3206062316894531 seconds for one epoch ---
--- 0.6528699398040771 seconds for one epoch ---
--- 0.317781925201416 seconds for one epoch ---
--- 0.6142594814300537 seconds for one epoch ---
--- 0.3270082473754883 seconds for one epoch ---
--- 0.6435666084289551 seconds for one epoch ---
--- 0.3219919204711914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06300975]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09279807]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2978384]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.639485 ]
 [ 0.       ]]
--- 0.2616860866546631 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5011.9453125, (2394.3438, 1.5940647, 2615.8281, 0.1798985)
   validation loss 1130.8028564453125, (776.38354, 0.10405915, 354.1353, 0.1798985)
decoder loss ratio: 30078.446391, decoder SINDy loss  ratio: 0.764451
--- 0.2950260639190674 seconds for one epoch ---
--- 0.6029062271118164 seconds for one epoch ---
--- 0.30342984199523926 seconds for one epoch ---
--- 0.6161463260650635 seconds for one epoch ---
--- 0.29996800422668457 seconds for one epoch ---
--- 0.6117138862609863 seconds for one epoch ---
--- 0.31120824813842773 seconds for one epoch ---
--- 0.6578543186187744 seconds for one epoch ---
--- 0.3088381290435791 seconds for one epoch ---
--- 0.6532371044158936 seconds for one epoch ---
--- 0.3003857135772705 seconds for one epoch ---
--- 0.6669962406158447 seconds for one epoch ---
--- 0.3140850067138672 seconds for one epoch ---
--- 0.6298129558563232 seconds for one epoch ---
--- 0.31390976905822754 seconds for one epoch ---
--- 0.6313290596008301 seconds for one epoch ---
--- 0.3130621910095215 seconds for one epoch ---
--- 0.6348822116851807 seconds for one epoch ---
--- 0.29982662200927734 seconds for one epoch ---
--- 0.6750442981719971 seconds for one epoch ---
--- 0.2969498634338379 seconds for one epoch ---
--- 0.669295072555542 seconds for one epoch ---
--- 0.2945210933685303 seconds for one epoch ---
--- 0.63374924659729 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06207754]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09465773]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2668333]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.7284057]
 [ 0.       ]]
--- 0.2903604507446289 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4001.30517578125, (1660.5292, 0.49797377, 2340.0974, 0.18061875)
   validation loss 972.4180908203125, (676.9963, 0.15399879, 295.08722, 0.18061875)
decoder loss ratio: 26228.011083, decoder SINDy loss  ratio: 0.636987
--- 0.2607736587524414 seconds for one epoch ---
--- 0.2816329002380371 seconds for one epoch ---
--- 0.6173839569091797 seconds for one epoch ---
--- 0.29193735122680664 seconds for one epoch ---
--- 0.6374866962432861 seconds for one epoch ---
--- 0.3291478157043457 seconds for one epoch ---
--- 0.626457929611206 seconds for one epoch ---
--- 0.3255906105041504 seconds for one epoch ---
--- 0.6722111701965332 seconds for one epoch ---
--- 0.3411674499511719 seconds for one epoch ---
--- 0.6356852054595947 seconds for one epoch ---
--- 0.33601808547973633 seconds for one epoch ---
--- 0.6633281707763672 seconds for one epoch ---
--- 0.3284931182861328 seconds for one epoch ---
--- 0.6519744396209717 seconds for one epoch ---
--- 0.3175528049468994 seconds for one epoch ---
--- 0.6434869766235352 seconds for one epoch ---
--- 0.337970495223999 seconds for one epoch ---
--- 0.649956464767456 seconds for one epoch ---
--- 0.34556055068969727 seconds for one epoch ---
--- 0.664177417755127 seconds for one epoch ---
--- 0.3175945281982422 seconds for one epoch ---
--- 0.6660990715026855 seconds for one epoch ---
--- 0.327193021774292 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06218063]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09688254]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2864866]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8300343]
 [ 0.       ]]
--- 0.2506132125854492 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4089.656494140625, (1491.7789, 0.2320209, 2597.4634, 0.18202893)
   validation loss 1036.817626953125, (711.5716, 0.118122704, 324.94595, 0.18202893)
decoder loss ratio: 27567.518903, decoder SINDy loss  ratio: 0.701442
--- 0.2922666072845459 seconds for one epoch ---
--- 0.6469194889068604 seconds for one epoch ---
--- 0.2841377258300781 seconds for one epoch ---
--- 0.6252470016479492 seconds for one epoch ---
--- 0.2981576919555664 seconds for one epoch ---
--- 0.6557412147521973 seconds for one epoch ---
--- 0.2956221103668213 seconds for one epoch ---
--- 0.6495506763458252 seconds for one epoch ---
--- 0.2855653762817383 seconds for one epoch ---
--- 0.6608736515045166 seconds for one epoch ---
--- 0.3040459156036377 seconds for one epoch ---
--- 0.6524341106414795 seconds for one epoch ---
--- 0.3043398857116699 seconds for one epoch ---
--- 0.647108793258667 seconds for one epoch ---
--- 0.30782270431518555 seconds for one epoch ---
--- 0.6704378128051758 seconds for one epoch ---
--- 0.2907135486602783 seconds for one epoch ---
--- 0.6485328674316406 seconds for one epoch ---
--- 0.2963545322418213 seconds for one epoch ---
--- 0.6621348857879639 seconds for one epoch ---
--- 0.29844188690185547 seconds for one epoch ---
--- 0.6493926048278809 seconds for one epoch ---
--- 0.3030383586883545 seconds for one epoch ---
--- 0.6743817329406738 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06146677]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09843926]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2615393]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.901305 ]
 [ 0.       ]]
--- 0.2892637252807617 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4901.12890625, (2427.6057, 0.70270807, 2472.638, 0.18249263)
   validation loss 1668.6304931640625, (1301.269, 0.10067377, 367.0783, 0.18249263)
decoder loss ratio: 50413.421827, decoder SINDy loss  ratio: 0.792390
--- 0.2601172924041748 seconds for one epoch ---
--- 0.3020286560058594 seconds for one epoch ---
--- 0.6762170791625977 seconds for one epoch ---
--- 0.33101963996887207 seconds for one epoch ---
--- 0.6897356510162354 seconds for one epoch ---
--- 0.32674121856689453 seconds for one epoch ---
--- 0.6970455646514893 seconds for one epoch ---
--- 0.31395530700683594 seconds for one epoch ---
--- 0.661898136138916 seconds for one epoch ---
--- 0.3237590789794922 seconds for one epoch ---
--- 0.693535566329956 seconds for one epoch ---
--- 0.328355073928833 seconds for one epoch ---
--- 0.7003893852233887 seconds for one epoch ---
--- 0.3240060806274414 seconds for one epoch ---
--- 0.6837658882141113 seconds for one epoch ---
--- 0.3281581401824951 seconds for one epoch ---
--- 0.7006893157958984 seconds for one epoch ---
--- 0.3316059112548828 seconds for one epoch ---
--- 0.6992101669311523 seconds for one epoch ---
--- 0.3183140754699707 seconds for one epoch ---
--- 0.72135329246521 seconds for one epoch ---
--- 0.308837890625 seconds for one epoch ---
--- 0.6951076984405518 seconds for one epoch ---
--- 0.31005382537841797 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06094505]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10048363]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2451794]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.990743 ]
 [ 0.       ]]
--- 0.24146127700805664 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3973.27685546875, (1585.9208, 0.8159232, 2386.3567, 0.1834781)
   validation loss 1041.1011962890625, (713.07324, 0.07456207, 327.76984, 0.1834781)
decoder loss ratio: 27625.695352, decoder SINDy loss  ratio: 0.707537
--- 0.29451704025268555 seconds for one epoch ---
--- 0.6569180488586426 seconds for one epoch ---
--- 0.3057706356048584 seconds for one epoch ---
--- 0.6721036434173584 seconds for one epoch ---
--- 0.3065986633300781 seconds for one epoch ---
--- 0.6645033359527588 seconds for one epoch ---
--- 0.31239962577819824 seconds for one epoch ---
--- 0.703819751739502 seconds for one epoch ---
--- 0.3093278408050537 seconds for one epoch ---
--- 0.6632819175720215 seconds for one epoch ---
--- 0.3087797164916992 seconds for one epoch ---
--- 0.6902413368225098 seconds for one epoch ---
--- 0.30333757400512695 seconds for one epoch ---
--- 0.6952321529388428 seconds for one epoch ---
--- 0.32680368423461914 seconds for one epoch ---
--- 0.6784584522247314 seconds for one epoch ---
--- 0.3294644355773926 seconds for one epoch ---
--- 0.6790597438812256 seconds for one epoch ---
--- 0.32511281967163086 seconds for one epoch ---
--- 0.6790862083435059 seconds for one epoch ---
--- 0.34584522247314453 seconds for one epoch ---
--- 0.6687791347503662 seconds for one epoch ---
--- 0.32232236862182617 seconds for one epoch ---
--- 0.6728932857513428 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06078588]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1029148 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2448955]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0930738]
 [ 0.       ]]
--- 0.29285693168640137 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4204.9599609375, (1364.8928, 0.8278754, 2839.0544, 0.18452874)
   validation loss 2469.64794921875, (2137.1746, 0.27171734, 332.01706, 0.18452874)
decoder loss ratio: 82797.852774, decoder SINDy loss  ratio: 0.716706
--- 0.27344512939453125 seconds for one epoch ---
--- 0.30338478088378906 seconds for one epoch ---
--- 0.6947441101074219 seconds for one epoch ---
--- 0.3046724796295166 seconds for one epoch ---
--- 0.6723546981811523 seconds for one epoch ---
--- 0.30106329917907715 seconds for one epoch ---
--- 0.6770241260528564 seconds for one epoch ---
--- 0.3170912265777588 seconds for one epoch ---
--- 0.7143568992614746 seconds for one epoch ---
--- 0.2990124225616455 seconds for one epoch ---
--- 0.6864936351776123 seconds for one epoch ---
--- 0.3138546943664551 seconds for one epoch ---
--- 0.7000219821929932 seconds for one epoch ---
--- 0.2960240840911865 seconds for one epoch ---
--- 0.6925549507141113 seconds for one epoch ---
--- 0.3058781623840332 seconds for one epoch ---
--- 0.7042078971862793 seconds for one epoch ---
--- 0.2968771457672119 seconds for one epoch ---
--- 0.6963310241699219 seconds for one epoch ---
--- 0.30381321907043457 seconds for one epoch ---
--- 0.7326247692108154 seconds for one epoch ---
--- 0.29671502113342285 seconds for one epoch ---
--- 0.7093241214752197 seconds for one epoch ---
--- 0.2954425811767578 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06043513]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10488447]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2341629]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1759448]
 [ 0.       ]]
--- 0.2489933967590332 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4035.164794921875, (1706.7957, 0.5927932, 2327.591, 0.18538754)
   validation loss 1280.68994140625, (965.2996, 0.30854082, 314.89633, 0.18538754)
decoder loss ratio: 37397.383174, decoder SINDy loss  ratio: 0.679748
--- 0.3093235492706299 seconds for one epoch ---
--- 0.7237787246704102 seconds for one epoch ---
--- 0.2948112487792969 seconds for one epoch ---
--- 0.6906890869140625 seconds for one epoch ---
--- 0.3091268539428711 seconds for one epoch ---
--- 0.702707052230835 seconds for one epoch ---
--- 0.29691362380981445 seconds for one epoch ---
--- 0.7051730155944824 seconds for one epoch ---
--- 0.2920064926147461 seconds for one epoch ---
--- 0.7163639068603516 seconds for one epoch ---
--- 0.3162212371826172 seconds for one epoch ---
--- 0.6934301853179932 seconds for one epoch ---
--- 0.3048439025878906 seconds for one epoch ---
--- 0.707467794418335 seconds for one epoch ---
--- 0.29561543464660645 seconds for one epoch ---
--- 0.712411642074585 seconds for one epoch ---
--- 0.30684351921081543 seconds for one epoch ---
--- 0.7121717929840088 seconds for one epoch ---
--- 0.32840442657470703 seconds for one epoch ---
--- 0.7064757347106934 seconds for one epoch ---
--- 0.3192405700683594 seconds for one epoch ---
--- 0.7150115966796875 seconds for one epoch ---
--- 0.3053610324859619 seconds for one epoch ---
--- 0.7148303985595703 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06031083]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10713814]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2333393]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2682405]
 [ 0.       ]]
--- 0.3263077735900879 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4499.93896484375, (1729.7557, 0.4743242, 2769.523, 0.18624225)
   validation loss 1170.6246337890625, (862.7593, 0.12455647, 307.5545, 0.18624225)
decoder loss ratio: 33424.792220, decoder SINDy loss  ratio: 0.663900
--- 0.2736482620239258 seconds for one epoch ---
--- 0.3168506622314453 seconds for one epoch ---
--- 0.6974127292633057 seconds for one epoch ---
--- 0.315340518951416 seconds for one epoch ---
--- 0.6960444450378418 seconds for one epoch ---
--- 0.31596803665161133 seconds for one epoch ---
--- 0.7267470359802246 seconds for one epoch ---
--- 0.3451879024505615 seconds for one epoch ---
--- 0.7143480777740479 seconds for one epoch ---
--- 0.3171508312225342 seconds for one epoch ---
--- 0.7135214805603027 seconds for one epoch ---
--- 0.32514429092407227 seconds for one epoch ---
--- 0.72823166847229 seconds for one epoch ---
--- 0.46076059341430664 seconds for one epoch ---
--- 0.7077963352203369 seconds for one epoch ---
--- 0.30831265449523926 seconds for one epoch ---
--- 0.7247240543365479 seconds for one epoch ---
--- 0.30878376960754395 seconds for one epoch ---
--- 0.71238112449646 seconds for one epoch ---
--- 0.31094956398010254 seconds for one epoch ---
--- 0.7304868698120117 seconds for one epoch ---
--- 0.3127126693725586 seconds for one epoch ---
--- 0.7100698947906494 seconds for one epoch ---
--- 0.2934145927429199 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05980469]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10929814]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2125702]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3559914]
 [ 0.       ]]
--- 0.24726128578186035 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4868.82373046875, (1399.4454, 0.72907156, 3468.4624, 0.18680497)
   validation loss 1001.5087280273438, (720.442, 0.14232573, 280.73758, 0.18680497)
decoder loss ratio: 27911.174465, decoder SINDy loss  ratio: 0.606012
--- 0.2955009937286377 seconds for one epoch ---
--- 0.7125105857849121 seconds for one epoch ---
--- 0.3246273994445801 seconds for one epoch ---
--- 0.7145047187805176 seconds for one epoch ---
--- 0.31987547874450684 seconds for one epoch ---
--- 0.7103836536407471 seconds for one epoch ---
--- 0.3109705448150635 seconds for one epoch ---
--- 0.729771614074707 seconds for one epoch ---
--- 0.32181382179260254 seconds for one epoch ---
--- 0.7330443859100342 seconds for one epoch ---
--- 0.33069682121276855 seconds for one epoch ---
--- 0.7188513278961182 seconds for one epoch ---
--- 0.3166029453277588 seconds for one epoch ---
--- 0.7491171360015869 seconds for one epoch ---
--- 0.3177194595336914 seconds for one epoch ---
--- 0.7513642311096191 seconds for one epoch ---
--- 0.31664395332336426 seconds for one epoch ---
--- 0.7321398258209229 seconds for one epoch ---
--- 0.35179734230041504 seconds for one epoch ---
--- 0.7169845104217529 seconds for one epoch ---
--- 0.33098340034484863 seconds for one epoch ---
--- 0.73826003074646 seconds for one epoch ---
--- 0.2889373302459717 seconds for one epoch ---
--- 0.7251842021942139 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05962091]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11219489]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2071047]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.470944 ]
 [ 0.       ]]
--- 0.2833669185638428 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3578.565185546875, (2004.2799, 0.8958458, 1573.2018, 0.18783836)
   validation loss 1023.2591552734375, (709.88525, 0.1432313, 313.04276, 0.18783836)
decoder loss ratio: 27502.187151, decoder SINDy loss  ratio: 0.675747
--- 0.2790985107421875 seconds for one epoch ---
--- 0.29366445541381836 seconds for one epoch ---
--- 0.757997989654541 seconds for one epoch ---
--- 0.295548677444458 seconds for one epoch ---
--- 0.7457759380340576 seconds for one epoch ---
--- 0.29686999320983887 seconds for one epoch ---
--- 0.728935956954956 seconds for one epoch ---
--- 0.2964181900024414 seconds for one epoch ---
--- 0.7464885711669922 seconds for one epoch ---
--- 0.30316591262817383 seconds for one epoch ---
--- 0.7400245666503906 seconds for one epoch ---
--- 0.28770995140075684 seconds for one epoch ---
--- 0.7351541519165039 seconds for one epoch ---
--- 0.2916996479034424 seconds for one epoch ---
--- 0.7363231182098389 seconds for one epoch ---
--- 0.2980332374572754 seconds for one epoch ---
--- 0.7315380573272705 seconds for one epoch ---
--- 0.29767704010009766 seconds for one epoch ---
--- 0.7293758392333984 seconds for one epoch ---
--- 0.2883157730102539 seconds for one epoch ---
--- 0.7294821739196777 seconds for one epoch ---
--- 0.289320707321167 seconds for one epoch ---
--- 0.7151317596435547 seconds for one epoch ---
--- 0.2917468547821045 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05950972]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11384511]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2050118]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5370865]
 [ 0.       ]]
--- 0.2529418468475342 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1973.26708984375, (974.0047, 0.16848871, 998.90564, 0.18817611)
   validation loss 883.8678588867188, (592.9912, 0.16265887, 290.5258, 0.18817611)
decoder loss ratio: 22973.508990, decoder SINDy loss  ratio: 0.627141
--- 0.31350255012512207 seconds for one epoch ---
--- 0.7170703411102295 seconds for one epoch ---
--- 0.29901981353759766 seconds for one epoch ---
--- 0.7396378517150879 seconds for one epoch ---
--- 0.2916910648345947 seconds for one epoch ---
--- 0.7351250648498535 seconds for one epoch ---
--- 0.3019437789916992 seconds for one epoch ---
--- 0.7220730781555176 seconds for one epoch ---
--- 0.31580018997192383 seconds for one epoch ---
--- 0.7592566013336182 seconds for one epoch ---
--- 0.2861056327819824 seconds for one epoch ---
--- 0.7336869239807129 seconds for one epoch ---
--- 0.2998080253601074 seconds for one epoch ---
--- 0.7357261180877686 seconds for one epoch ---
--- 0.31009912490844727 seconds for one epoch ---
--- 0.7294549942016602 seconds for one epoch ---
--- 0.2996249198913574 seconds for one epoch ---
--- 0.7437200546264648 seconds for one epoch ---
--- 0.3052523136138916 seconds for one epoch ---
--- 0.7383413314819336 seconds for one epoch ---
--- 0.2957143783569336 seconds for one epoch ---
--- 0.7481696605682373 seconds for one epoch ---
--- 0.3000602722167969 seconds for one epoch ---
--- 0.733842134475708 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05908174]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11582895]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1859014]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.6152625]
 [ 0.       ]]
--- 0.3013160228729248 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2986.858154296875, (1541.3545, 0.60369617, 1444.7117, 0.18825181)
   validation loss 1531.6114501953125, (1160.0504, 0.14289925, 371.22986, 0.18825181)
decoder loss ratio: 44942.367015, decoder SINDy loss  ratio: 0.801352
THRESHOLDING: 1 active coefficients
--- 0.7419407367706299 seconds for one epoch ---
--- 0.32936859130859375 seconds for one epoch ---
--- 0.7453570365905762 seconds for one epoch ---
--- 0.33828234672546387 seconds for one epoch ---
--- 0.7636549472808838 seconds for one epoch ---
--- 0.32877635955810547 seconds for one epoch ---
--- 0.7540278434753418 seconds for one epoch ---
--- 0.33286142349243164 seconds for one epoch ---
--- 0.7525858879089355 seconds for one epoch ---
--- 0.33889222145080566 seconds for one epoch ---
--- 0.7894148826599121 seconds for one epoch ---
--- 0.31332874298095703 seconds for one epoch ---
--- 0.7580389976501465 seconds for one epoch ---
--- 0.31034064292907715 seconds for one epoch ---
--- 0.7604110240936279 seconds for one epoch ---
--- 0.30969858169555664 seconds for one epoch ---
--- 0.7657861709594727 seconds for one epoch ---
--- 0.28728318214416504 seconds for one epoch ---
--- 0.7734978199005127 seconds for one epoch ---
--- 0.2915208339691162 seconds for one epoch ---
--- 0.7793543338775635 seconds for one epoch ---
--- 0.2866334915161133 seconds for one epoch ---
--- 0.7881841659545898 seconds for one epoch ---
--- 0.3017449378967285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12642615]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.020851]
 [ 0.      ]]
--- 0.2667996883392334 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2350.663818359375, (1589.8364, 4.460402, 756.29706, 0.069723986)
   validation loss 1007.9822998046875, (676.5348, 0.19396307, 331.1838, 0.069723986)
decoder loss ratio: 26210.132282, decoder SINDy loss  ratio: 0.714907
--- 0.30158114433288574 seconds for one epoch ---
--- 0.7410225868225098 seconds for one epoch ---
--- 0.29553961753845215 seconds for one epoch ---
--- 0.741654634475708 seconds for one epoch ---
--- 0.3102073669433594 seconds for one epoch ---
--- 0.7507548332214355 seconds for one epoch ---
--- 0.2919285297393799 seconds for one epoch ---
--- 0.7890114784240723 seconds for one epoch ---
--- 0.31758666038513184 seconds for one epoch ---
--- 0.8140549659729004 seconds for one epoch ---
--- 0.30119848251342773 seconds for one epoch ---
--- 0.7828505039215088 seconds for one epoch ---
--- 0.294630765914917 seconds for one epoch ---
--- 0.7900073528289795 seconds for one epoch ---
--- 0.3082618713378906 seconds for one epoch ---
--- 0.8133909702301025 seconds for one epoch ---
--- 0.3005244731903076 seconds for one epoch ---
--- 0.7835965156555176 seconds for one epoch ---
--- 0.30007314682006836 seconds for one epoch ---
--- 0.7903594970703125 seconds for one epoch ---
--- 0.30341100692749023 seconds for one epoch ---
--- 0.7686874866485596 seconds for one epoch ---
--- 0.31488513946533203 seconds for one epoch ---
--- 0.7759912014007568 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13629402]
 [0.        ]]
[[-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-4.39644]
 [ 0.     ]]
--- 0.300537109375 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5333.7578125, (1875.872, 0.4256783, 3457.3862, 0.07436883)
   validation loss 1371.8131103515625, (1021.305, 0.21947604, 350.21423, 0.07436883)
decoder loss ratio: 39567.128480, decoder SINDy loss  ratio: 0.755987
--- 0.25578880310058594 seconds for one epoch ---
--- 0.2839179039001465 seconds for one epoch ---
--- 0.7735631465911865 seconds for one epoch ---
--- 0.2917158603668213 seconds for one epoch ---
--- 0.7493674755096436 seconds for one epoch ---
--- 0.2935943603515625 seconds for one epoch ---
--- 0.777529239654541 seconds for one epoch ---
--- 0.2964761257171631 seconds for one epoch ---
--- 0.7761554718017578 seconds for one epoch ---
--- 0.28580379486083984 seconds for one epoch ---
--- 0.7773051261901855 seconds for one epoch ---
--- 0.28729820251464844 seconds for one epoch ---
--- 0.800786018371582 seconds for one epoch ---
--- 0.2828235626220703 seconds for one epoch ---
--- 0.8008263111114502 seconds for one epoch ---
--- 0.3186790943145752 seconds for one epoch ---
--- 0.7852704524993896 seconds for one epoch ---
--- 0.3289012908935547 seconds for one epoch ---
--- 0.7840979099273682 seconds for one epoch ---
--- 0.3351130485534668 seconds for one epoch ---
--- 0.7790639400482178 seconds for one epoch ---
--- 0.3432445526123047 seconds for one epoch ---
--- 0.7992892265319824 seconds for one epoch ---
--- 0.3307633399963379 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14559299]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.752253]
 [ 0.      ]]
--- 0.28760480880737305 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3604.2177734375, (1639.7778, 0.6920726, 1963.6691, 0.07889571)
   validation loss 856.0799560546875, (567.0823, 0.19175927, 288.727, 0.07889571)
decoder loss ratio: 21969.751847, decoder SINDy loss  ratio: 0.623258
--- 0.2991039752960205 seconds for one epoch ---
--- 0.7977018356323242 seconds for one epoch ---
--- 0.316133975982666 seconds for one epoch ---
--- 0.8053970336914062 seconds for one epoch ---
--- 0.31682753562927246 seconds for one epoch ---
--- 0.7733304500579834 seconds for one epoch ---
--- 0.3089315891265869 seconds for one epoch ---
--- 0.7808616161346436 seconds for one epoch ---
--- 0.2951622009277344 seconds for one epoch ---
--- 0.7782728672027588 seconds for one epoch ---
--- 0.3006563186645508 seconds for one epoch ---
--- 0.7504172325134277 seconds for one epoch ---
--- 0.2898736000061035 seconds for one epoch ---
--- 0.7744100093841553 seconds for one epoch ---
--- 0.29038572311401367 seconds for one epoch ---
--- 0.7700486183166504 seconds for one epoch ---
--- 0.29203033447265625 seconds for one epoch ---
--- 0.7714831829071045 seconds for one epoch ---
--- 0.290494441986084 seconds for one epoch ---
--- 0.7822320461273193 seconds for one epoch ---
--- 0.29169774055480957 seconds for one epoch ---
--- 0.8007321357727051 seconds for one epoch ---
--- 0.29229068756103516 seconds for one epoch ---
--- 0.7471826076507568 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15454555]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-5.099601]
 [ 0.      ]]
--- 0.29297471046447754 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4889.53369140625, (1388.0587, 1.1544192, 3500.2375, 0.083250456)
   validation loss 1007.6024780273438, (704.44385, 0.29694754, 302.77844, 0.083250456)
decoder loss ratio: 27291.377627, decoder SINDy loss  ratio: 0.653590
--- 0.2630889415740967 seconds for one epoch ---
--- 0.3125033378601074 seconds for one epoch ---
--- 0.7966070175170898 seconds for one epoch ---
--- 0.30702853202819824 seconds for one epoch ---
--- 0.8319988250732422 seconds for one epoch ---
--- 0.3025033473968506 seconds for one epoch ---
--- 0.8139593601226807 seconds for one epoch ---
--- 0.3101627826690674 seconds for one epoch ---
--- 0.7989387512207031 seconds for one epoch ---
--- 0.3035094738006592 seconds for one epoch ---
--- 0.8112070560455322 seconds for one epoch ---
--- 0.30553388595581055 seconds for one epoch ---
--- 0.8591489791870117 seconds for one epoch ---
--- 0.2935662269592285 seconds for one epoch ---
--- 0.7918591499328613 seconds for one epoch ---
--- 0.3016483783721924 seconds for one epoch ---
--- 0.7810063362121582 seconds for one epoch ---
--- 0.2944905757904053 seconds for one epoch ---
--- 0.7851333618164062 seconds for one epoch ---
--- 0.29920530319213867 seconds for one epoch ---
--- 0.7850282192230225 seconds for one epoch ---
--- 0.30132079124450684 seconds for one epoch ---
--- 0.8226332664489746 seconds for one epoch ---
--- 0.30554914474487305 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16231191]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.4077177]
 [ 0.       ]]
--- 0.2636096477508545 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3186.167724609375, (1487.7465, 0.67950267, 1697.6547, 0.08725446)
   validation loss 1221.6929931640625, (887.88763, 0.26309368, 333.45496, 0.08725446)
decoder loss ratio: 34398.308393, decoder SINDy loss  ratio: 0.719809
--- 0.31348562240600586 seconds for one epoch ---
--- 0.8134188652038574 seconds for one epoch ---
--- 0.31734704971313477 seconds for one epoch ---
--- 0.7834169864654541 seconds for one epoch ---
--- 0.31551313400268555 seconds for one epoch ---
--- 0.783867597579956 seconds for one epoch ---
--- 0.31755828857421875 seconds for one epoch ---
--- 0.8131539821624756 seconds for one epoch ---
--- 0.31978940963745117 seconds for one epoch ---
--- 0.8439362049102783 seconds for one epoch ---
--- 0.32121825218200684 seconds for one epoch ---
--- 0.8068115711212158 seconds for one epoch ---
--- 0.30535411834716797 seconds for one epoch ---
--- 0.8180737495422363 seconds for one epoch ---
--- 0.295513391494751 seconds for one epoch ---
--- 0.8148596286773682 seconds for one epoch ---
--- 0.296889066696167 seconds for one epoch ---
--- 0.8134706020355225 seconds for one epoch ---
--- 0.2898108959197998 seconds for one epoch ---
--- 0.8369925022125244 seconds for one epoch ---
--- 0.29395151138305664 seconds for one epoch ---
--- 0.7935276031494141 seconds for one epoch ---
--- 0.32349658012390137 seconds for one epoch ---
--- 0.8045804500579834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17018431]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.7291923]
 [-0.       ]]
--- 0.2962491512298584 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3005.03564453125, (1602.505, 3.4631886, 1398.9763, 0.09129155)
   validation loss 1003.4392700195312, (657.3888, 0.14228214, 345.8169, 0.09129155)
decoder loss ratio: 25468.383155, decoder SINDy loss  ratio: 0.746494
--- 0.28842687606811523 seconds for one epoch ---
--- 0.2948293685913086 seconds for one epoch ---
--- 0.8291511535644531 seconds for one epoch ---
--- 0.30019474029541016 seconds for one epoch ---
--- 0.8264040946960449 seconds for one epoch ---
--- 0.299638032913208 seconds for one epoch ---
--- 0.8474912643432617 seconds for one epoch ---
--- 0.3154740333557129 seconds for one epoch ---
--- 0.8646271228790283 seconds for one epoch ---
--- 0.3179311752319336 seconds for one epoch ---
--- 0.8405284881591797 seconds for one epoch ---
--- 0.2931978702545166 seconds for one epoch ---
--- 0.824371337890625 seconds for one epoch ---
--- 0.31041574478149414 seconds for one epoch ---
--- 0.8253116607666016 seconds for one epoch ---
--- 0.2979552745819092 seconds for one epoch ---
--- 0.8221182823181152 seconds for one epoch ---
--- 0.29685354232788086 seconds for one epoch ---
--- 0.830280065536499 seconds for one epoch ---
--- 0.30586743354797363 seconds for one epoch ---
--- 0.8149740695953369 seconds for one epoch ---
--- 0.31607985496520996 seconds for one epoch ---
--- 0.84765625 seconds for one epoch ---
--- 0.32541966438293457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17709924]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.0222683]
 [-0.       ]]
--- 0.26235246658325195 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4702.87939453125, (1730.0715, 1.1083535, 2971.6047, 0.09492014)
   validation loss 1082.4405517578125, (801.9377, 0.2428953, 280.16498, 0.09492014)
decoder loss ratio: 31068.458069, decoder SINDy loss  ratio: 0.604776
--- 0.2852809429168701 seconds for one epoch ---
--- 0.8064541816711426 seconds for one epoch ---
--- 0.28650498390197754 seconds for one epoch ---
--- 0.8157577514648438 seconds for one epoch ---
--- 0.29348230361938477 seconds for one epoch ---
--- 0.8250453472137451 seconds for one epoch ---
--- 0.29352331161499023 seconds for one epoch ---
--- 0.8065969944000244 seconds for one epoch ---
--- 0.2833092212677002 seconds for one epoch ---
--- 0.8184189796447754 seconds for one epoch ---
--- 0.30330371856689453 seconds for one epoch ---
--- 0.838808536529541 seconds for one epoch ---
--- 0.2915976047515869 seconds for one epoch ---
--- 0.8489186763763428 seconds for one epoch ---
--- 0.2976090908050537 seconds for one epoch ---
--- 0.83203125 seconds for one epoch ---
--- 0.2905914783477783 seconds for one epoch ---
--- 0.852400541305542 seconds for one epoch ---
--- 0.29521894454956055 seconds for one epoch ---
--- 0.8273565769195557 seconds for one epoch ---
--- 0.304243803024292 seconds for one epoch ---
--- 0.8165905475616455 seconds for one epoch ---
--- 0.28005385398864746 seconds for one epoch ---
--- 0.8386118412017822 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1837427]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.316262]
 [ 0.      ]]
--- 0.32936644554138184 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4188.67529296875, (1447.9342, 1.5053194, 2739.1372, 0.09850969)
   validation loss 1690.7081298828125, (1333.9034, 0.1766914, 356.5295, 0.09850969)
decoder loss ratio: 51677.735116, decoder SINDy loss  ratio: 0.769619
--- 0.26262688636779785 seconds for one epoch ---
--- 0.3321657180786133 seconds for one epoch ---
--- 0.8358824253082275 seconds for one epoch ---
--- 0.3388345241546631 seconds for one epoch ---
--- 0.8445854187011719 seconds for one epoch ---
--- 0.33841490745544434 seconds for one epoch ---
--- 0.8551335334777832 seconds for one epoch ---
--- 0.32193994522094727 seconds for one epoch ---
--- 0.848515510559082 seconds for one epoch ---
--- 0.3449077606201172 seconds for one epoch ---
--- 0.849694013595581 seconds for one epoch ---
--- 0.3125607967376709 seconds for one epoch ---
--- 0.8373980522155762 seconds for one epoch ---
--- 0.2936239242553711 seconds for one epoch ---
--- 0.8371031284332275 seconds for one epoch ---
--- 0.2926158905029297 seconds for one epoch ---
--- 0.8615412712097168 seconds for one epoch ---
--- 0.2936573028564453 seconds for one epoch ---
--- 0.8301444053649902 seconds for one epoch ---
--- 0.2897777557373047 seconds for one epoch ---
--- 0.8242876529693604 seconds for one epoch ---
--- 0.3029606342315674 seconds for one epoch ---
--- 0.8772335052490234 seconds for one epoch ---
--- 0.30109310150146484 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19028835]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.6218266]
 [ 0.       ]]
--- 0.28401970863342285 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3468.2255859375, (1673.9833, 1.982835, 1792.1573, 0.10215979)
   validation loss 1451.2235107421875, (1130.0149, 0.2061703, 320.9003, 0.10215979)
decoder loss ratio: 43778.738731, decoder SINDy loss  ratio: 0.692708
--- 0.30517005920410156 seconds for one epoch ---
--- 0.8507091999053955 seconds for one epoch ---
--- 0.3003726005554199 seconds for one epoch ---
--- 0.8570706844329834 seconds for one epoch ---
--- 0.2958102226257324 seconds for one epoch ---
--- 0.8490695953369141 seconds for one epoch ---
--- 0.2987382411956787 seconds for one epoch ---
--- 0.8576931953430176 seconds for one epoch ---
--- 0.3019695281982422 seconds for one epoch ---
--- 0.8616926670074463 seconds for one epoch ---
--- 0.3284621238708496 seconds for one epoch ---
--- 0.8665025234222412 seconds for one epoch ---
--- 0.2897469997406006 seconds for one epoch ---
--- 0.857205867767334 seconds for one epoch ---
--- 0.2990903854370117 seconds for one epoch ---
--- 0.8466260433197021 seconds for one epoch ---
--- 0.29402923583984375 seconds for one epoch ---
--- 0.8573777675628662 seconds for one epoch ---
--- 0.28666019439697266 seconds for one epoch ---
--- 0.858954668045044 seconds for one epoch ---
--- 0.32026124000549316 seconds for one epoch ---
--- 0.8505637645721436 seconds for one epoch ---
--- 0.30527234077453613 seconds for one epoch ---
--- 0.8862674236297607 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19621617]
 [0.        ]]
[[-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-6.91667]
 [ 0.     ]]
--- 0.2861621379852295 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2525.73681640625, (1097.7743, 1.7089369, 1426.1478, 0.10575908)
   validation loss 1144.6099853515625, (837.07166, 0.23687243, 307.19577, 0.10575908)
decoder loss ratio: 32429.609146, decoder SINDy loss  ratio: 0.663125
--- 0.2600982189178467 seconds for one epoch ---
--- 0.30498838424682617 seconds for one epoch ---
--- 0.8518505096435547 seconds for one epoch ---
--- 0.3022165298461914 seconds for one epoch ---
--- 0.8522121906280518 seconds for one epoch ---
--- 0.29290771484375 seconds for one epoch ---
--- 0.847752571105957 seconds for one epoch ---
--- 0.29882144927978516 seconds for one epoch ---
--- 0.8792724609375 seconds for one epoch ---
--- 0.28935933113098145 seconds for one epoch ---
--- 0.8585057258605957 seconds for one epoch ---
--- 0.2813749313354492 seconds for one epoch ---
--- 0.830803394317627 seconds for one epoch ---
--- 0.2842698097229004 seconds for one epoch ---
--- 0.8664376735687256 seconds for one epoch ---
--- 0.29813623428344727 seconds for one epoch ---
--- 0.83109450340271 seconds for one epoch ---
--- 0.45490479469299316 seconds for one epoch ---
--- 0.883237361907959 seconds for one epoch ---
--- 0.30440258979797363 seconds for one epoch ---
--- 0.8820493221282959 seconds for one epoch ---
--- 0.32707738876342773 seconds for one epoch ---
--- 0.9007439613342285 seconds for one epoch ---
--- 0.3015785217285156 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20106307]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.174933]
 [ 0.      ]]
--- 0.25562596321105957 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3746.7216796875, (1443.1033, 2.3489485, 2301.1606, 0.1088348)
   validation loss 1487.256591796875, (1127.957, 0.16146778, 359.02924, 0.1088348)
decoder loss ratio: 43699.013610, decoder SINDy loss  ratio: 0.775015
--- 0.3314175605773926 seconds for one epoch ---
--- 0.8581926822662354 seconds for one epoch ---
--- 0.3431391716003418 seconds for one epoch ---
--- 0.8854830265045166 seconds for one epoch ---
--- 0.3124227523803711 seconds for one epoch ---
--- 0.8679594993591309 seconds for one epoch ---
--- 0.3327348232269287 seconds for one epoch ---
--- 0.868279218673706 seconds for one epoch ---
--- 0.32180285453796387 seconds for one epoch ---
--- 0.8809671401977539 seconds for one epoch ---
--- 0.2841007709503174 seconds for one epoch ---
--- 0.8850555419921875 seconds for one epoch ---
--- 0.2922358512878418 seconds for one epoch ---
--- 0.8654637336730957 seconds for one epoch ---
--- 0.29488468170166016 seconds for one epoch ---
--- 0.8879780769348145 seconds for one epoch ---
--- 0.28719401359558105 seconds for one epoch ---
--- 0.8805129528045654 seconds for one epoch ---
--- 0.304736852645874 seconds for one epoch ---
--- 0.8730347156524658 seconds for one epoch ---
--- 0.31026244163513184 seconds for one epoch ---
--- 0.8877885341644287 seconds for one epoch ---
--- 0.29883360862731934 seconds for one epoch ---
--- 0.9005770683288574 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2058169]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.448223]
 [-0.      ]]
--- 0.2989833354949951 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3185.853271484375, (1156.1616, 1.5880213, 2027.9917, 0.11202543)
   validation loss 875.0075073242188, (580.4333, 0.18874966, 294.27353, 0.11202543)
decoder loss ratio: 22486.993276, decoder SINDy loss  ratio: 0.635231
--- 0.30489182472229004 seconds for one epoch ---
--- 0.302440881729126 seconds for one epoch ---
--- 0.8936746120452881 seconds for one epoch ---
--- 0.3032402992248535 seconds for one epoch ---
--- 0.8853185176849365 seconds for one epoch ---
--- 0.31042933464050293 seconds for one epoch ---
--- 0.8989956378936768 seconds for one epoch ---
--- 0.31116151809692383 seconds for one epoch ---
--- 0.8773243427276611 seconds for one epoch ---
--- 0.3001720905303955 seconds for one epoch ---
--- 0.8818211555480957 seconds for one epoch ---
--- 0.3031013011932373 seconds for one epoch ---
--- 0.8888125419616699 seconds for one epoch ---
--- 0.28824806213378906 seconds for one epoch ---
--- 0.9105448722839355 seconds for one epoch ---
--- 0.2919929027557373 seconds for one epoch ---
--- 0.8924193382263184 seconds for one epoch ---
--- 0.3117258548736572 seconds for one epoch ---
--- 0.8831496238708496 seconds for one epoch ---
--- 0.30840158462524414 seconds for one epoch ---
--- 0.8787369728088379 seconds for one epoch ---
--- 0.2876317501068115 seconds for one epoch ---
--- 0.8927164077758789 seconds for one epoch ---
--- 0.29784560203552246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20976563]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.695691]
 [-0.      ]]
--- 0.25070953369140625 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2841.509765625, (1357.1017, 0.5287543, 1483.7643, 0.114907406)
   validation loss 1104.9501953125, (821.027, 0.27787387, 283.5305, 0.114907406)
decoder loss ratio: 31808.010475, decoder SINDy loss  ratio: 0.612040
--- 0.28363656997680664 seconds for one epoch ---
--- 0.905909538269043 seconds for one epoch ---
--- 0.28632140159606934 seconds for one epoch ---
--- 0.8701629638671875 seconds for one epoch ---
--- 0.2906014919281006 seconds for one epoch ---
--- 0.906226396560669 seconds for one epoch ---
--- 0.31443119049072266 seconds for one epoch ---
--- 0.8953156471252441 seconds for one epoch ---
--- 0.2924306392669678 seconds for one epoch ---
--- 0.9209625720977783 seconds for one epoch ---
--- 0.2950460910797119 seconds for one epoch ---
--- 0.9031436443328857 seconds for one epoch ---
--- 0.29609203338623047 seconds for one epoch ---
--- 0.9108655452728271 seconds for one epoch ---
--- 0.30579495429992676 seconds for one epoch ---
--- 0.888627290725708 seconds for one epoch ---
--- 0.29857730865478516 seconds for one epoch ---
--- 0.9095122814178467 seconds for one epoch ---
--- 0.3432488441467285 seconds for one epoch ---
--- 0.9006805419921875 seconds for one epoch ---
--- 0.33124256134033203 seconds for one epoch ---
--- 0.912212610244751 seconds for one epoch ---
--- 0.32871055603027344 seconds for one epoch ---
--- 0.9296557903289795 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21315935]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.9286857]
 [-0.       ]]
--- 0.31678295135498047 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2372.918212890625, (1319.7372, 1.402541, 1051.6611, 0.11747608)
   validation loss 979.0874633789062, (686.98096, 0.15626897, 291.83276, 0.11747608)
decoder loss ratio: 26614.834927, decoder SINDy loss  ratio: 0.629962
--- 0.2694072723388672 seconds for one epoch ---
--- 0.33322620391845703 seconds for one epoch ---
--- 0.9139976501464844 seconds for one epoch ---
--- 0.3277702331542969 seconds for one epoch ---
--- 0.9291074275970459 seconds for one epoch ---
--- 0.3231043815612793 seconds for one epoch ---
--- 0.9203126430511475 seconds for one epoch ---
--- 0.2799360752105713 seconds for one epoch ---
--- 0.8902056217193604 seconds for one epoch ---
--- 0.2968456745147705 seconds for one epoch ---
--- 0.919689416885376 seconds for one epoch ---
--- 0.29335880279541016 seconds for one epoch ---
--- 0.8955793380737305 seconds for one epoch ---
--- 0.3011622428894043 seconds for one epoch ---
--- 0.8883700370788574 seconds for one epoch ---
--- 0.30355191230773926 seconds for one epoch ---
--- 0.9238767623901367 seconds for one epoch ---
--- 0.2898538112640381 seconds for one epoch ---
--- 0.9215531349182129 seconds for one epoch ---
--- 0.29497623443603516 seconds for one epoch ---
--- 0.9104440212249756 seconds for one epoch ---
--- 0.2955048084259033 seconds for one epoch ---
--- 0.9275212287902832 seconds for one epoch ---
--- 0.2974815368652344 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21595807]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.140334]
 [-0.      ]]
--- 0.23723077774047852 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3596.330322265625, (1308.9694, 0.8304086, 2286.4106, 0.119832374)
   validation loss 1343.535400390625, (997.3279, 0.10811891, 345.97955, 0.119832374)
decoder loss ratio: 38638.213542, decoder SINDy loss  ratio: 0.746846
--- 0.28237128257751465 seconds for one epoch ---
--- 0.8995938301086426 seconds for one epoch ---
--- 0.28446245193481445 seconds for one epoch ---
--- 0.9209213256835938 seconds for one epoch ---
--- 0.2978386878967285 seconds for one epoch ---
--- 0.9023392200469971 seconds for one epoch ---
--- 0.2798268795013428 seconds for one epoch ---
--- 0.9287533760070801 seconds for one epoch ---
--- 0.29031825065612793 seconds for one epoch ---
--- 0.9211258888244629 seconds for one epoch ---
--- 0.2940356731414795 seconds for one epoch ---
--- 0.9153673648834229 seconds for one epoch ---
--- 0.2941617965698242 seconds for one epoch ---
--- 0.9320154190063477 seconds for one epoch ---
--- 0.27681851387023926 seconds for one epoch ---
--- 0.9292631149291992 seconds for one epoch ---
--- 0.3121774196624756 seconds for one epoch ---
--- 0.922544002532959 seconds for one epoch ---
--- 0.325253963470459 seconds for one epoch ---
--- 0.9449493885040283 seconds for one epoch ---
--- 0.3236997127532959 seconds for one epoch ---
--- 0.9631814956665039 seconds for one epoch ---
--- 0.32958436012268066 seconds for one epoch ---
--- 0.9459688663482666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21870154]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.371956]
 [-0.      ]]
--- 0.30187392234802246 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4944.24951171875, (1586.2607, 2.006163, 3355.86, 0.12236681)
   validation loss 883.7516479492188, (590.8172, 0.18662134, 292.6254, 0.12236681)
decoder loss ratio: 22889.284020, decoder SINDy loss  ratio: 0.631673
--- 0.26723337173461914 seconds for one epoch ---
--- 0.32442569732666016 seconds for one epoch ---
--- 0.926978349685669 seconds for one epoch ---
--- 0.3169527053833008 seconds for one epoch ---
--- 0.9312829971313477 seconds for one epoch ---
--- 0.2954580783843994 seconds for one epoch ---
--- 0.9203259944915771 seconds for one epoch ---
--- 0.28444743156433105 seconds for one epoch ---
--- 0.9159924983978271 seconds for one epoch ---
--- 0.2902989387512207 seconds for one epoch ---
--- 0.927865743637085 seconds for one epoch ---
--- 0.2988266944885254 seconds for one epoch ---
--- 0.8943140506744385 seconds for one epoch ---
--- 0.28382301330566406 seconds for one epoch ---
--- 0.9506590366363525 seconds for one epoch ---
--- 0.3008391857147217 seconds for one epoch ---
--- 0.9426009654998779 seconds for one epoch ---
--- 0.3175625801086426 seconds for one epoch ---
--- 0.9653434753417969 seconds for one epoch ---
--- 0.3161776065826416 seconds for one epoch ---
--- 0.9576122760772705 seconds for one epoch ---
--- 0.3126342296600342 seconds for one epoch ---
--- 0.9577984809875488 seconds for one epoch ---
--- 0.3185608386993408 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.220848]
 [0.      ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.577526]
 [ 0.      ]]
--- 0.25391268730163574 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3002.869873046875, (1350.5411, 2.6771016, 1649.5271, 0.12450621)
   validation loss 1208.035400390625, (918.5584, 0.17422757, 289.17825, 0.12450621)
decoder loss ratio: 35586.547516, decoder SINDy loss  ratio: 0.624232
--- 0.27936506271362305 seconds for one epoch ---
--- 0.9702000617980957 seconds for one epoch ---
--- 0.2895512580871582 seconds for one epoch ---
--- 0.9414377212524414 seconds for one epoch ---
--- 0.28834009170532227 seconds for one epoch ---
--- 0.9247028827667236 seconds for one epoch ---
--- 0.28920745849609375 seconds for one epoch ---
--- 0.9367966651916504 seconds for one epoch ---
--- 0.2865896224975586 seconds for one epoch ---
--- 0.9456465244293213 seconds for one epoch ---
--- 0.296262264251709 seconds for one epoch ---
--- 0.9381330013275146 seconds for one epoch ---
--- 0.30974316596984863 seconds for one epoch ---
--- 0.9537911415100098 seconds for one epoch ---
--- 0.30982398986816406 seconds for one epoch ---
--- 0.9261214733123779 seconds for one epoch ---
--- 0.292452335357666 seconds for one epoch ---
--- 0.948906421661377 seconds for one epoch ---
--- 0.28066420555114746 seconds for one epoch ---
--- 0.9592640399932861 seconds for one epoch ---
--- 0.30291032791137695 seconds for one epoch ---
--- 0.9672741889953613 seconds for one epoch ---
--- 0.2906351089477539 seconds for one epoch ---
--- 0.9627840518951416 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22251794]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.759627]
 [ 0.      ]]
--- 0.32144618034362793 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3843.376953125, (1304.7247, 3.5394292, 2534.9863, 0.12637556)
   validation loss 1162.827392578125, (884.61304, 0.22748037, 277.86057, 0.12637556)
decoder loss ratio: 34271.444813, decoder SINDy loss  ratio: 0.599801
--- 0.26050400733947754 seconds for one epoch ---
--- 0.33066868782043457 seconds for one epoch ---
--- 0.9884636402130127 seconds for one epoch ---
--- 0.299269437789917 seconds for one epoch ---
--- 0.9583456516265869 seconds for one epoch ---
--- 0.3011784553527832 seconds for one epoch ---
--- 0.9620561599731445 seconds for one epoch ---
--- 0.29010629653930664 seconds for one epoch ---
--- 0.9481077194213867 seconds for one epoch ---
--- 0.29887986183166504 seconds for one epoch ---
--- 0.9659464359283447 seconds for one epoch ---
--- 0.2896888256072998 seconds for one epoch ---
--- 0.9522669315338135 seconds for one epoch ---
--- 0.31089305877685547 seconds for one epoch ---
--- 0.9696149826049805 seconds for one epoch ---
--- 0.3316831588745117 seconds for one epoch ---
--- 0.9650816917419434 seconds for one epoch ---
--- 0.33244824409484863 seconds for one epoch ---
--- 1.0125081539154053 seconds for one epoch ---
--- 0.3318347930908203 seconds for one epoch ---
--- 0.9771151542663574 seconds for one epoch ---
--- 0.3417541980743408 seconds for one epoch ---
--- 0.9724180698394775 seconds for one epoch ---
--- 0.3413403034210205 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22419067]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.972611]
 [-0.      ]]
--- 0.26228928565979004 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2020.8184814453125, (888.2009, 1.1757884, 1131.3131, 0.12861453)
   validation loss 998.9150390625, (667.7524, 0.13860415, 330.89545, 0.12861453)
decoder loss ratio: 25869.886485, decoder SINDy loss  ratio: 0.714284
--- 0.2843341827392578 seconds for one epoch ---
--- 0.9361693859100342 seconds for one epoch ---
--- 0.29259753227233887 seconds for one epoch ---
--- 0.946474552154541 seconds for one epoch ---
--- 0.2894752025604248 seconds for one epoch ---
--- 0.9621317386627197 seconds for one epoch ---
--- 0.2969813346862793 seconds for one epoch ---
--- 0.94671630859375 seconds for one epoch ---
--- 0.29776430130004883 seconds for one epoch ---
--- 0.9747424125671387 seconds for one epoch ---
--- 0.29764628410339355 seconds for one epoch ---
--- 0.9347879886627197 seconds for one epoch ---
--- 0.2840454578399658 seconds for one epoch ---
--- 0.961082935333252 seconds for one epoch ---
--- 0.32413148880004883 seconds for one epoch ---
--- 0.9959220886230469 seconds for one epoch ---
--- 0.3159182071685791 seconds for one epoch ---
--- 1.0072932243347168 seconds for one epoch ---
--- 0.310230016708374 seconds for one epoch ---
--- 0.9958593845367432 seconds for one epoch ---
--- 0.3363463878631592 seconds for one epoch ---
--- 0.9841701984405518 seconds for one epoch ---
--- 0.32855987548828125 seconds for one epoch ---
--- 0.9825026988983154 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22545461]
 [0.        ]]
[[-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-9.16801]
 [-0.     ]]
--- 0.2910289764404297 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4977.330078125, (1791.8954, 0.9609059, 3184.3435, 0.13045934)
   validation loss 859.4641723632812, (595.6671, 0.23895736, 263.42767, 0.13045934)
decoder loss ratio: 23077.178130, decoder SINDy loss  ratio: 0.568646
THRESHOLDING: 1 active coefficients
--- 0.271198034286499 seconds for one epoch ---
--- 0.28412795066833496 seconds for one epoch ---
--- 0.9532666206359863 seconds for one epoch ---
--- 0.29648613929748535 seconds for one epoch ---
--- 0.9719333648681641 seconds for one epoch ---
--- 0.2908589839935303 seconds for one epoch ---
--- 0.9707920551300049 seconds for one epoch ---
--- 0.29863667488098145 seconds for one epoch ---
--- 0.9877026081085205 seconds for one epoch ---
--- 0.2983112335205078 seconds for one epoch ---
--- 0.9820077419281006 seconds for one epoch ---
--- 0.2946484088897705 seconds for one epoch ---
--- 1.018092155456543 seconds for one epoch ---
--- 0.29731082916259766 seconds for one epoch ---
--- 1.0059449672698975 seconds for one epoch ---
--- 0.30216240882873535 seconds for one epoch ---
--- 0.9826080799102783 seconds for one epoch ---
--- 0.2930164337158203 seconds for one epoch ---
--- 0.9891107082366943 seconds for one epoch ---
--- 0.2879326343536377 seconds for one epoch ---
--- 0.9877870082855225 seconds for one epoch ---
--- 0.3038649559020996 seconds for one epoch ---
--- 0.979423999786377 seconds for one epoch ---
--- 0.2947373390197754 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22629535]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.328349]
 [ 0.      ]]
--- 0.25258708000183105 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4693.265625, (2183.8745, 7.1104703, 2502.1616, 0.11893927)
   validation loss 738.2515869140625, (457.69342, 0.20550244, 280.2337, 0.11893927)
decoder loss ratio: 17731.837697, decoder SINDy loss  ratio: 0.604924
--- 0.2974660396575928 seconds for one epoch ---
--- 0.9949722290039062 seconds for one epoch ---
--- 0.28922605514526367 seconds for one epoch ---
--- 1.0630824565887451 seconds for one epoch ---
--- 0.30208301544189453 seconds for one epoch ---
--- 0.9997837543487549 seconds for one epoch ---
--- 0.2995338439941406 seconds for one epoch ---
--- 1.0099506378173828 seconds for one epoch ---
--- 0.2955820560455322 seconds for one epoch ---
--- 1.0126826763153076 seconds for one epoch ---
--- 0.28934550285339355 seconds for one epoch ---
--- 0.9729840755462646 seconds for one epoch ---
--- 0.2977578639984131 seconds for one epoch ---
--- 0.968799352645874 seconds for one epoch ---
--- 0.2948775291442871 seconds for one epoch ---
--- 0.987443208694458 seconds for one epoch ---
--- 0.27378106117248535 seconds for one epoch ---
--- 1.0019922256469727 seconds for one epoch ---
--- 0.3069267272949219 seconds for one epoch ---
--- 0.9653592109680176 seconds for one epoch ---
--- 0.28771185874938965 seconds for one epoch ---
--- 0.9719111919403076 seconds for one epoch ---
--- 0.307736873626709 seconds for one epoch ---
--- 0.9933090209960938 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22704223]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.5125675]
 [ 0.       ]]
--- 0.29410362243652344 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4281.37939453125, (2365.2585, 1.9025439, 1914.0975, 0.120687746)
   validation loss 1337.6204833984375, (1025.4249, 0.23836513, 311.8364, 0.120687746)
decoder loss ratio: 39726.741879, decoder SINDy loss  ratio: 0.673143
--- 0.25833916664123535 seconds for one epoch ---
--- 0.29752540588378906 seconds for one epoch ---
--- 0.9676945209503174 seconds for one epoch ---
--- 0.2979416847229004 seconds for one epoch ---
--- 0.9841625690460205 seconds for one epoch ---
--- 0.29241490364074707 seconds for one epoch ---
--- 0.970958948135376 seconds for one epoch ---
--- 0.2942485809326172 seconds for one epoch ---
--- 0.9966354370117188 seconds for one epoch ---
--- 0.2998926639556885 seconds for one epoch ---
--- 1.014897108078003 seconds for one epoch ---
--- 0.29361939430236816 seconds for one epoch ---
--- 1.0265161991119385 seconds for one epoch ---
--- 0.2924771308898926 seconds for one epoch ---
--- 1.005889892578125 seconds for one epoch ---
--- 0.29654717445373535 seconds for one epoch ---
--- 1.0062005519866943 seconds for one epoch ---
--- 0.2911078929901123 seconds for one epoch ---
--- 1.036015272140503 seconds for one epoch ---
--- 0.29295992851257324 seconds for one epoch ---
--- 1.0201022624969482 seconds for one epoch ---
--- 0.2866542339324951 seconds for one epoch ---
--- 1.0005769729614258 seconds for one epoch ---
--- 0.3078153133392334 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22751732]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-9.6808405]
 [ 0.       ]]
--- 0.24839138984680176 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2772.469970703125, (1413.0553, 1.0606917, 1358.2316, 0.12229357)
   validation loss 1482.255859375, (1164.8638, 0.2371176, 317.03265, 0.12229357)
decoder loss ratio: 45128.844724, decoder SINDy loss  ratio: 0.684360
--- 0.3045928478240967 seconds for one epoch ---
--- 0.9802520275115967 seconds for one epoch ---
--- 0.2856605052947998 seconds for one epoch ---
--- 0.9753811359405518 seconds for one epoch ---
--- 0.29329919815063477 seconds for one epoch ---
--- 1.0094366073608398 seconds for one epoch ---
--- 0.2967708110809326 seconds for one epoch ---
--- 1.0197572708129883 seconds for one epoch ---
--- 0.29608988761901855 seconds for one epoch ---
--- 1.0124728679656982 seconds for one epoch ---
--- 0.3070220947265625 seconds for one epoch ---
--- 0.9937624931335449 seconds for one epoch ---
--- 0.3181777000427246 seconds for one epoch ---
--- 1.0413627624511719 seconds for one epoch ---
--- 0.3254115581512451 seconds for one epoch ---
--- 1.0224144458770752 seconds for one epoch ---
--- 0.3147237300872803 seconds for one epoch ---
--- 1.013322353363037 seconds for one epoch ---
--- 0.32405686378479004 seconds for one epoch ---
--- 1.0207350254058838 seconds for one epoch ---
--- 0.3054084777832031 seconds for one epoch ---
--- 1.0408148765563965 seconds for one epoch ---
--- 0.31326937675476074 seconds for one epoch ---
--- 1.0457868576049805 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22779489]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.850101]
 [ 0.      ]]
--- 0.29175496101379395 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4500.3134765625, (1184.2649, 1.5016803, 3314.4229, 0.12388688)
   validation loss 1307.1007080078125, (1015.7003, 0.22385502, 291.05258, 0.12388688)
decoder loss ratio: 39349.993629, decoder SINDy loss  ratio: 0.628278
--- 0.24918437004089355 seconds for one epoch ---
--- 0.29718923568725586 seconds for one epoch ---
--- 1.0248136520385742 seconds for one epoch ---
--- 0.2976553440093994 seconds for one epoch ---
--- 1.0085468292236328 seconds for one epoch ---
--- 0.3013637065887451 seconds for one epoch ---
--- 1.0299172401428223 seconds for one epoch ---
--- 0.2848396301269531 seconds for one epoch ---
--- 1.0059797763824463 seconds for one epoch ---
--- 0.29685473442077637 seconds for one epoch ---
--- 1.0260982513427734 seconds for one epoch ---
--- 0.3026909828186035 seconds for one epoch ---
--- 1.0313184261322021 seconds for one epoch ---
--- 0.27756428718566895 seconds for one epoch ---
--- 1.0071864128112793 seconds for one epoch ---
--- 0.293626070022583 seconds for one epoch ---
--- 1.037015676498413 seconds for one epoch ---
--- 0.31351280212402344 seconds for one epoch ---
--- 1.0126135349273682 seconds for one epoch ---
--- 0.30251169204711914 seconds for one epoch ---
--- 1.028329849243164 seconds for one epoch ---
--- 0.30452394485473633 seconds for one epoch ---
--- 1.020961046218872 seconds for one epoch ---
--- 0.29135775566101074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22786747]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-10.03822]
 [ -0.     ]]
--- 0.2528679370880127 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5402.421875, (1149.2758, 1.6874552, 4251.333, 0.1255517)
   validation loss 1125.2520751953125, (854.3706, 0.30910078, 270.4468, 0.1255517)
decoder loss ratio: 33099.800508, decoder SINDy loss  ratio: 0.583797
--- 0.3040032386779785 seconds for one epoch ---
--- 1.032318115234375 seconds for one epoch ---
--- 0.2929706573486328 seconds for one epoch ---
--- 1.0273149013519287 seconds for one epoch ---
--- 0.2876622676849365 seconds for one epoch ---
--- 1.0101313591003418 seconds for one epoch ---
--- 0.3046407699584961 seconds for one epoch ---
--- 0.9947278499603271 seconds for one epoch ---
--- 0.311598539352417 seconds for one epoch ---
--- 1.0159211158752441 seconds for one epoch ---
--- 0.3252532482147217 seconds for one epoch ---
--- 1.0421042442321777 seconds for one epoch ---
--- 0.3019709587097168 seconds for one epoch ---
--- 1.046476125717163 seconds for one epoch ---
--- 0.29555511474609375 seconds for one epoch ---
--- 1.055471420288086 seconds for one epoch ---
--- 0.3105173110961914 seconds for one epoch ---
--- 1.0496842861175537 seconds for one epoch ---
--- 0.29451942443847656 seconds for one epoch ---
--- 1.0467665195465088 seconds for one epoch ---
--- 0.318983793258667 seconds for one epoch ---
--- 1.0343823432922363 seconds for one epoch ---
--- 0.30840563774108887 seconds for one epoch ---
--- 1.0562829971313477 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22772315]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.205432]
 [ -0.      ]]
--- 0.27284860610961914 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3812.204833984375, (1208.6509, 2.6974695, 2600.7295, 0.12699796)
   validation loss 1305.1644287109375, (968.3418, 0.23685554, 336.4588, 0.12699796)
decoder loss ratio: 37515.242326, decoder SINDy loss  ratio: 0.726294
--- 0.2571263313293457 seconds for one epoch ---
--- 0.3014554977416992 seconds for one epoch ---
--- 1.0272252559661865 seconds for one epoch ---
--- 0.3000624179840088 seconds for one epoch ---
--- 1.0704519748687744 seconds for one epoch ---
--- 0.29879045486450195 seconds for one epoch ---
--- 1.0002546310424805 seconds for one epoch ---
--- 0.2963440418243408 seconds for one epoch ---
--- 1.0350310802459717 seconds for one epoch ---
--- 0.3149752616882324 seconds for one epoch ---
--- 1.049997091293335 seconds for one epoch ---
--- 0.3452301025390625 seconds for one epoch ---
--- 1.0595917701721191 seconds for one epoch ---
--- 0.33396315574645996 seconds for one epoch ---
--- 1.051694631576538 seconds for one epoch ---
--- 0.3307952880859375 seconds for one epoch ---
--- 1.0401768684387207 seconds for one epoch ---
--- 0.3449978828430176 seconds for one epoch ---
--- 1.050255298614502 seconds for one epoch ---
--- 0.3510725498199463 seconds for one epoch ---
--- 1.071561574935913 seconds for one epoch ---
--- 0.3275606632232666 seconds for one epoch ---
--- 1.032855749130249 seconds for one epoch ---
--- 0.3176889419555664 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22742279]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.356864]
 [ -0.      ]]
--- 0.2522411346435547 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2698.041748046875, (1275.7926, 1.579741, 1420.5413, 0.12828282)
   validation loss 1738.5548095703125, (1372.007, 0.16296272, 366.25653, 0.12828282)
decoder loss ratio: 53153.931462, decoder SINDy loss  ratio: 0.790616
--- 0.2831847667694092 seconds for one epoch ---
--- 1.0182106494903564 seconds for one epoch ---
--- 0.2882201671600342 seconds for one epoch ---
--- 1.0411322116851807 seconds for one epoch ---
--- 0.28562331199645996 seconds for one epoch ---
--- 1.0529520511627197 seconds for one epoch ---
--- 0.2932724952697754 seconds for one epoch ---
--- 0.9926755428314209 seconds for one epoch ---
--- 0.2924792766571045 seconds for one epoch ---
--- 1.0524842739105225 seconds for one epoch ---
--- 0.32164573669433594 seconds for one epoch ---
--- 1.0648939609527588 seconds for one epoch ---
--- 0.3424866199493408 seconds for one epoch ---
--- 1.056474208831787 seconds for one epoch ---
--- 0.3389291763305664 seconds for one epoch ---
--- 1.054042100906372 seconds for one epoch ---
--- 0.32288098335266113 seconds for one epoch ---
--- 1.049910545349121 seconds for one epoch ---
--- 0.34315943717956543 seconds for one epoch ---
--- 1.0882337093353271 seconds for one epoch ---
--- 0.33078479766845703 seconds for one epoch ---
--- 1.0785682201385498 seconds for one epoch ---
--- 0.32581281661987305 seconds for one epoch ---
--- 1.0528934001922607 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22692579]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.518344]
 [ -0.      ]]
--- 0.2819960117340088 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2576.446533203125, (1167.1053, 1.5122701, 1407.6993, 0.1296499)
   validation loss 950.410888671875, (686.8347, 0.2652118, 263.18137, 0.1296499)
decoder loss ratio: 26609.169326, decoder SINDy loss  ratio: 0.568114
--- 0.24527955055236816 seconds for one epoch ---
--- 0.29460978507995605 seconds for one epoch ---
--- 1.083369493484497 seconds for one epoch ---
--- 0.2936062812805176 seconds for one epoch ---
--- 1.0780858993530273 seconds for one epoch ---
--- 0.29851651191711426 seconds for one epoch ---
--- 1.0378363132476807 seconds for one epoch ---
--- 0.292405366897583 seconds for one epoch ---
--- 1.0882956981658936 seconds for one epoch ---
--- 0.2979114055633545 seconds for one epoch ---
--- 1.099318027496338 seconds for one epoch ---
--- 0.5268476009368896 seconds for one epoch ---
--- 1.0949106216430664 seconds for one epoch ---
--- 0.2889394760131836 seconds for one epoch ---
--- 1.0979087352752686 seconds for one epoch ---
--- 0.2893376350402832 seconds for one epoch ---
--- 1.0872220993041992 seconds for one epoch ---
--- 0.3006472587585449 seconds for one epoch ---
--- 1.0807645320892334 seconds for one epoch ---
--- 0.3040013313293457 seconds for one epoch ---
--- 1.0656402111053467 seconds for one epoch ---
--- 0.30255842208862305 seconds for one epoch ---
--- 1.0960009098052979 seconds for one epoch ---
--- 0.2978484630584717 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2262672]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.675552]
 [ -0.      ]]
--- 0.24277353286743164 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3673.82080078125, (1329.2467, 2.3657465, 2342.0776, 0.13087045)
   validation loss 1971.6160888671875, (1629.6202, 0.19787475, 341.66714, 0.13087045)
decoder loss ratio: 63134.317214, decoder SINDy loss  ratio: 0.737537
--- 0.2978241443634033 seconds for one epoch ---
--- 1.0803167819976807 seconds for one epoch ---
--- 0.29482460021972656 seconds for one epoch ---
--- 1.1039679050445557 seconds for one epoch ---
--- 0.2943897247314453 seconds for one epoch ---
--- 1.0439121723175049 seconds for one epoch ---
--- 0.28220176696777344 seconds for one epoch ---
--- 1.0579702854156494 seconds for one epoch ---
--- 0.3238081932067871 seconds for one epoch ---
--- 1.092064619064331 seconds for one epoch ---
--- 0.3253049850463867 seconds for one epoch ---
--- 1.0893678665161133 seconds for one epoch ---
--- 0.3257722854614258 seconds for one epoch ---
--- 1.1003475189208984 seconds for one epoch ---
--- 0.3433539867401123 seconds for one epoch ---
--- 1.1064834594726562 seconds for one epoch ---
--- 0.3552560806274414 seconds for one epoch ---
--- 1.1004576683044434 seconds for one epoch ---
--- 0.3191819190979004 seconds for one epoch ---
--- 1.1101858615875244 seconds for one epoch ---
--- 0.33694934844970703 seconds for one epoch ---
--- 1.0974478721618652 seconds for one epoch ---
--- 0.3336672782897949 seconds for one epoch ---
--- 1.130162239074707 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22556487]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.810511]
 [  0.      ]]
--- 0.2894563674926758 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2975.719482421875, (1069.5702, 2.8475266, 1903.1697, 0.1320033)
   validation loss 766.3182983398438, (497.78122, 0.26023975, 268.14478, 0.1320033)
decoder loss ratio: 19284.908629, decoder SINDy loss  ratio: 0.578828
--- 0.25894665718078613 seconds for one epoch ---
--- 0.2966461181640625 seconds for one epoch ---
--- 1.0769681930541992 seconds for one epoch ---
--- 0.2984201908111572 seconds for one epoch ---
--- 1.05918288230896 seconds for one epoch ---
--- 0.29936695098876953 seconds for one epoch ---
--- 1.094240427017212 seconds for one epoch ---
--- 0.29331135749816895 seconds for one epoch ---
--- 1.1170437335968018 seconds for one epoch ---
--- 0.29537153244018555 seconds for one epoch ---
--- 1.1166551113128662 seconds for one epoch ---
--- 0.2954432964324951 seconds for one epoch ---
--- 1.107469081878662 seconds for one epoch ---
--- 0.3015892505645752 seconds for one epoch ---
--- 1.114884614944458 seconds for one epoch ---
--- 0.3028891086578369 seconds for one epoch ---
--- 1.1267940998077393 seconds for one epoch ---
--- 0.2903168201446533 seconds for one epoch ---
--- 1.1187419891357422 seconds for one epoch ---
--- 0.2918858528137207 seconds for one epoch ---
--- 1.1339967250823975 seconds for one epoch ---
--- 0.2905399799346924 seconds for one epoch ---
--- 1.1059801578521729 seconds for one epoch ---
--- 0.295299768447876 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2246511]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-10.95848]
 [  0.     ]]
--- 0.2501974105834961 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2071.446533203125, (1355.7932, 0.68061453, 714.83954, 0.13310292)
   validation loss 1273.567138671875, (1011.17206, 0.34754974, 261.9145, 0.13310292)
decoder loss ratio: 39174.561003, decoder SINDy loss  ratio: 0.565379
--- 0.29005002975463867 seconds for one epoch ---
--- 1.0972838401794434 seconds for one epoch ---
--- 0.3067922592163086 seconds for one epoch ---
--- 1.0593676567077637 seconds for one epoch ---
--- 0.29466676712036133 seconds for one epoch ---
--- 1.0972719192504883 seconds for one epoch ---
--- 0.289050817489624 seconds for one epoch ---
--- 1.0868067741394043 seconds for one epoch ---
--- 0.30016422271728516 seconds for one epoch ---
--- 1.1284124851226807 seconds for one epoch ---
--- 0.2841975688934326 seconds for one epoch ---
--- 1.1156723499298096 seconds for one epoch ---
--- 0.29788875579833984 seconds for one epoch ---
--- 1.1038777828216553 seconds for one epoch ---
--- 0.29468560218811035 seconds for one epoch ---
--- 1.1132237911224365 seconds for one epoch ---
--- 0.28866028785705566 seconds for one epoch ---
--- 1.1107332706451416 seconds for one epoch ---
--- 0.2985858917236328 seconds for one epoch ---
--- 1.1003749370574951 seconds for one epoch ---
--- 0.2924809455871582 seconds for one epoch ---
--- 1.1044223308563232 seconds for one epoch ---
--- 0.2970292568206787 seconds for one epoch ---
--- 1.110487699508667 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2239621]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.056653]
 [ -0.      ]]
--- 0.2822263240814209 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3221.22412109375, (1853.2285, 3.3041515, 1364.5576, 0.13386552)
   validation loss 740.9148559570312, (486.6781, 0.3277857, 253.7751, 0.13386552)
decoder loss ratio: 18854.754527, decoder SINDy loss  ratio: 0.547809
--- 0.26426243782043457 seconds for one epoch ---
--- 0.29607701301574707 seconds for one epoch ---
--- 1.059175729751587 seconds for one epoch ---
--- 0.2879974842071533 seconds for one epoch ---
--- 1.092977523803711 seconds for one epoch ---
--- 0.3002619743347168 seconds for one epoch ---
--- 1.1119532585144043 seconds for one epoch ---
--- 0.2950727939605713 seconds for one epoch ---
--- 1.1256394386291504 seconds for one epoch ---
--- 0.29892563819885254 seconds for one epoch ---
--- 1.1403872966766357 seconds for one epoch ---
--- 0.29346656799316406 seconds for one epoch ---
--- 1.127356767654419 seconds for one epoch ---
--- 0.29216957092285156 seconds for one epoch ---
--- 1.1361277103424072 seconds for one epoch ---
--- 0.289412260055542 seconds for one epoch ---
--- 1.11771821975708 seconds for one epoch ---
--- 0.29146361351013184 seconds for one epoch ---
--- 1.1246232986450195 seconds for one epoch ---
--- 0.2971186637878418 seconds for one epoch ---
--- 1.1426010131835938 seconds for one epoch ---
--- 0.28589606285095215 seconds for one epoch ---
--- 1.1125984191894531 seconds for one epoch ---
--- 0.2935948371887207 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2228858]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.194395]
 [ -0.      ]]
--- 0.24912476539611816 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2807.85009765625, (1496.3048, 2.1288898, 1309.2816, 0.13488379)
   validation loss 1011.7724609375, (753.20416, 0.3693672, 258.064, 0.13488379)
decoder loss ratio: 29180.436879, decoder SINDy loss  ratio: 0.557067
--- 0.2889261245727539 seconds for one epoch ---
--- 1.149348497390747 seconds for one epoch ---
--- 0.29212474822998047 seconds for one epoch ---
--- 1.0766122341156006 seconds for one epoch ---
--- 0.28551387786865234 seconds for one epoch ---
--- 1.1139583587646484 seconds for one epoch ---
--- 0.30173683166503906 seconds for one epoch ---
--- 1.1575274467468262 seconds for one epoch ---
--- 0.30642008781433105 seconds for one epoch ---
--- 1.1307542324066162 seconds for one epoch ---
--- 0.3197593688964844 seconds for one epoch ---
--- 1.128779649734497 seconds for one epoch ---
--- 0.30626821517944336 seconds for one epoch ---
--- 1.1530177593231201 seconds for one epoch ---
--- 0.3064734935760498 seconds for one epoch ---
--- 1.1321985721588135 seconds for one epoch ---
--- 0.30780935287475586 seconds for one epoch ---
--- 1.1902031898498535 seconds for one epoch ---
--- 0.3206303119659424 seconds for one epoch ---
--- 1.145704746246338 seconds for one epoch ---
--- 0.32798147201538086 seconds for one epoch ---
--- 1.1403725147247314 seconds for one epoch ---
--- 0.31049680709838867 seconds for one epoch ---
--- 1.1487555503845215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22174913]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.324823]
 [  0.      ]]
--- 0.30314064025878906 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4823.30078125, (1319.7782, 7.810586, 3495.5762, 0.13584551)
   validation loss 754.4159545898438, (479.62875, 0.2833833, 274.36795, 0.13584551)
decoder loss ratio: 18581.650589, decoder SINDy loss  ratio: 0.592262
--- 0.24425983428955078 seconds for one epoch ---
--- 0.29346585273742676 seconds for one epoch ---
--- 1.1160330772399902 seconds for one epoch ---
--- 0.2927074432373047 seconds for one epoch ---
--- 1.1701264381408691 seconds for one epoch ---
--- 0.28554391860961914 seconds for one epoch ---
--- 1.1522433757781982 seconds for one epoch ---
--- 0.3060033321380615 seconds for one epoch ---
--- 1.171980381011963 seconds for one epoch ---
--- 0.2891426086425781 seconds for one epoch ---
--- 1.1960563659667969 seconds for one epoch ---
--- 0.3042004108428955 seconds for one epoch ---
--- 1.1443421840667725 seconds for one epoch ---
--- 0.3058347702026367 seconds for one epoch ---
--- 1.1690263748168945 seconds for one epoch ---
--- 0.30513644218444824 seconds for one epoch ---
--- 1.1773242950439453 seconds for one epoch ---
--- 0.313525915145874 seconds for one epoch ---
--- 1.1621968746185303 seconds for one epoch ---
--- 0.31172895431518555 seconds for one epoch ---
--- 1.185765266418457 seconds for one epoch ---
--- 0.307279109954834 seconds for one epoch ---
--- 1.1790752410888672 seconds for one epoch ---
--- 0.30705881118774414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22031613]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.473507]
 [  0.      ]]
--- 0.25225830078125 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4368.443359375, (1743.7316, 0.66276354, 2623.9126, 0.13685782)
   validation loss 841.4144287109375, (585.6466, 0.3725332, 255.25845, 0.13685782)
decoder loss ratio: 22688.966261, decoder SINDy loss  ratio: 0.551011
--- 0.29979395866394043 seconds for one epoch ---
--- 1.1291205883026123 seconds for one epoch ---
--- 0.2951924800872803 seconds for one epoch ---
--- 1.1454761028289795 seconds for one epoch ---
--- 0.29572224617004395 seconds for one epoch ---
--- 1.139021873474121 seconds for one epoch ---
--- 0.29870057106018066 seconds for one epoch ---
--- 1.1604948043823242 seconds for one epoch ---
--- 0.30597496032714844 seconds for one epoch ---
--- 1.1397652626037598 seconds for one epoch ---
--- 0.29712915420532227 seconds for one epoch ---
--- 1.1627461910247803 seconds for one epoch ---
--- 0.29111647605895996 seconds for one epoch ---
--- 1.1585142612457275 seconds for one epoch ---
--- 0.29862189292907715 seconds for one epoch ---
--- 1.139854907989502 seconds for one epoch ---
--- 0.30069470405578613 seconds for one epoch ---
--- 1.1688246726989746 seconds for one epoch ---
--- 0.29575419425964355 seconds for one epoch ---
--- 1.2005088329315186 seconds for one epoch ---
--- 0.29364967346191406 seconds for one epoch ---
--- 1.1809837818145752 seconds for one epoch ---
--- 0.29633045196533203 seconds for one epoch ---
--- 1.176030158996582 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21906918]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.592105]
 [  0.      ]]
--- 0.29916810989379883 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2573.04296875, (1387.0724, 0.31793368, 1185.5148, 0.13765994)
   validation loss 857.0215454101562, (586.9246, 0.37234026, 269.58694, 0.13765994)
decoder loss ratio: 22738.478786, decoder SINDy loss  ratio: 0.581941
--- 0.25513482093811035 seconds for one epoch ---
--- 0.2870340347290039 seconds for one epoch ---
--- 1.142934799194336 seconds for one epoch ---
--- 0.29440951347351074 seconds for one epoch ---
--- 1.1494882106781006 seconds for one epoch ---
--- 0.31839823722839355 seconds for one epoch ---
--- 1.1582212448120117 seconds for one epoch ---
--- 0.3191249370574951 seconds for one epoch ---
--- 1.1831321716308594 seconds for one epoch ---
--- 0.32808446884155273 seconds for one epoch ---
--- 1.1796526908874512 seconds for one epoch ---
--- 0.3198888301849365 seconds for one epoch ---
--- 1.1862437725067139 seconds for one epoch ---
--- 0.33432960510253906 seconds for one epoch ---
--- 1.1756136417388916 seconds for one epoch ---
--- 0.3274729251861572 seconds for one epoch ---
--- 1.1441292762756348 seconds for one epoch ---
--- 0.3010420799255371 seconds for one epoch ---
--- 1.1934468746185303 seconds for one epoch ---
--- 0.321103572845459 seconds for one epoch ---
--- 1.1891956329345703 seconds for one epoch ---
--- 0.3206455707550049 seconds for one epoch ---
--- 1.1909379959106445 seconds for one epoch ---
--- 0.3380560874938965 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2175695]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.724555]
 [  0.      ]]
--- 0.24804210662841797 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5066.2548828125, (2201.4304, 1.1644204, 2863.5212, 0.13853757)
   validation loss 1108.5281982421875, (853.1691, 0.35677046, 254.86374, 0.13853757)
decoder loss ratio: 33053.253202, decoder SINDy loss  ratio: 0.550159
--- 0.2845747470855713 seconds for one epoch ---
--- 1.0990424156188965 seconds for one epoch ---
--- 0.27628326416015625 seconds for one epoch ---
--- 1.1566195487976074 seconds for one epoch ---
--- 0.2847766876220703 seconds for one epoch ---
--- 1.1425952911376953 seconds for one epoch ---
--- 0.315563440322876 seconds for one epoch ---
--- 1.1672885417938232 seconds for one epoch ---
--- 0.31740379333496094 seconds for one epoch ---
--- 1.2088844776153564 seconds for one epoch ---
--- 0.33111023902893066 seconds for one epoch ---
--- 1.1919851303100586 seconds for one epoch ---
--- 0.31938815116882324 seconds for one epoch ---
--- 1.1909420490264893 seconds for one epoch ---
--- 0.3328824043273926 seconds for one epoch ---
--- 1.205195665359497 seconds for one epoch ---
--- 0.3267052173614502 seconds for one epoch ---
--- 1.1817448139190674 seconds for one epoch ---
--- 0.31200265884399414 seconds for one epoch ---
--- 1.1876707077026367 seconds for one epoch ---
--- 0.3338499069213867 seconds for one epoch ---
--- 1.1926231384277344 seconds for one epoch ---
--- 0.3202779293060303 seconds for one epoch ---
--- 1.191295862197876 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21610615]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.845223]
 [ -0.      ]]
--- 0.2858128547668457 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2473.026123046875, (977.5737, 1.4055393, 1493.9076, 0.13930754)
   validation loss 719.5591430664062, (464.30438, 0.326993, 254.78848, 0.13930754)
decoder loss ratio: 17987.957839, decoder SINDy loss  ratio: 0.549997
--- 0.2594313621520996 seconds for one epoch ---
--- 0.303302526473999 seconds for one epoch ---
--- 1.19557523727417 seconds for one epoch ---
--- 0.2846364974975586 seconds for one epoch ---
--- 1.200760841369629 seconds for one epoch ---
--- 0.2991008758544922 seconds for one epoch ---
--- 1.250267505645752 seconds for one epoch ---
--- 0.29239797592163086 seconds for one epoch ---
--- 1.1933255195617676 seconds for one epoch ---
--- 0.30629897117614746 seconds for one epoch ---
--- 1.2028234004974365 seconds for one epoch ---
--- 0.28980374336242676 seconds for one epoch ---
--- 1.1950187683105469 seconds for one epoch ---
--- 0.29820775985717773 seconds for one epoch ---
--- 1.1852173805236816 seconds for one epoch ---
--- 0.29003167152404785 seconds for one epoch ---
--- 1.1832880973815918 seconds for one epoch ---
--- 0.2930326461791992 seconds for one epoch ---
--- 1.1929543018341064 seconds for one epoch ---
--- 0.29474925994873047 seconds for one epoch ---
--- 1.1965031623840332 seconds for one epoch ---
--- 0.2963254451751709 seconds for one epoch ---
--- 1.1891069412231445 seconds for one epoch ---
--- 0.2970695495605469 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21484454]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.943704]
 [ -0.      ]]
--- 0.25374817848205566 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3498.582275390625, (2178.2793, 1.0067793, 1319.1564, 0.13992657)
   validation loss 1453.39990234375, (1105.7509, 0.24723217, 347.262, 0.13992657)
decoder loss ratio: 42838.707771, decoder SINDy loss  ratio: 0.749614
--- 0.2968282699584961 seconds for one epoch ---
--- 1.1810414791107178 seconds for one epoch ---
--- 0.3031456470489502 seconds for one epoch ---
--- 1.1920220851898193 seconds for one epoch ---
--- 0.29848337173461914 seconds for one epoch ---
--- 1.1924490928649902 seconds for one epoch ---
--- 0.30060529708862305 seconds for one epoch ---
--- 1.1963284015655518 seconds for one epoch ---
--- 0.29162073135375977 seconds for one epoch ---
--- 1.2076854705810547 seconds for one epoch ---
--- 0.29839420318603516 seconds for one epoch ---
--- 1.2227277755737305 seconds for one epoch ---
--- 0.29959774017333984 seconds for one epoch ---
--- 1.19730544090271 seconds for one epoch ---
--- 0.2944960594177246 seconds for one epoch ---
--- 1.2253141403198242 seconds for one epoch ---
--- 0.2956504821777344 seconds for one epoch ---
--- 1.1948082447052002 seconds for one epoch ---
--- 0.29276227951049805 seconds for one epoch ---
--- 1.2141101360321045 seconds for one epoch ---
--- 0.28844118118286133 seconds for one epoch ---
--- 1.2109203338623047 seconds for one epoch ---
--- 0.27376627922058105 seconds for one epoch ---
--- 1.2066459655761719 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21343797]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-12.04836]
 [ -0.     ]]
--- 0.24979257583618164 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4935.177734375, (1199.2332, 0.37769845, 3735.4265, 0.14057755)
   validation loss 1100.4754638671875, (791.63934, 0.34159872, 308.35385, 0.14057755)
decoder loss ratio: 30669.482504, decoder SINDy loss  ratio: 0.665625
THRESHOLDING: 1 active coefficients
--- 1.1947124004364014 seconds for one epoch ---
--- 0.3008849620819092 seconds for one epoch ---
--- 1.2160208225250244 seconds for one epoch ---
--- 0.3171968460083008 seconds for one epoch ---
--- 1.2180540561676025 seconds for one epoch ---
--- 0.30553150177001953 seconds for one epoch ---
--- 1.2183210849761963 seconds for one epoch ---
--- 0.31394147872924805 seconds for one epoch ---
--- 1.2168703079223633 seconds for one epoch ---
--- 0.2984180450439453 seconds for one epoch ---
--- 1.2076442241668701 seconds for one epoch ---
--- 0.2966735363006592 seconds for one epoch ---
--- 1.1978569030761719 seconds for one epoch ---
--- 0.2824704647064209 seconds for one epoch ---
--- 1.2195651531219482 seconds for one epoch ---
--- 0.30214643478393555 seconds for one epoch ---
--- 1.1982622146606445 seconds for one epoch ---
--- 0.30300259590148926 seconds for one epoch ---
--- 1.2166430950164795 seconds for one epoch ---
--- 0.3032963275909424 seconds for one epoch ---
--- 1.2175335884094238 seconds for one epoch ---
--- 0.3020317554473877 seconds for one epoch ---
--- 1.185234546661377 seconds for one epoch ---
--- 0.2952847480773926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21177873]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.165951]
 [ -0.      ]]
--- 0.25877952575683594 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4326.09912109375, (1406.4694, 2.2198102, 2917.269, 0.14130569)
   validation loss 777.210205078125, (533.06726, 0.33209, 243.66954, 0.14130569)
decoder loss ratio: 20651.951127, decoder SINDy loss  ratio: 0.525995
--- 0.29682374000549316 seconds for one epoch ---
--- 1.2371411323547363 seconds for one epoch ---
--- 0.301100492477417 seconds for one epoch ---
--- 1.187443733215332 seconds for one epoch ---
--- 0.2989006042480469 seconds for one epoch ---
--- 1.21156644821167 seconds for one epoch ---
--- 0.2980959415435791 seconds for one epoch ---
--- 1.2109730243682861 seconds for one epoch ---
--- 0.2971072196960449 seconds for one epoch ---
--- 1.2274162769317627 seconds for one epoch ---
--- 0.2924160957336426 seconds for one epoch ---
--- 1.2294011116027832 seconds for one epoch ---
--- 0.29927563667297363 seconds for one epoch ---
--- 1.2252848148345947 seconds for one epoch ---
--- 0.2724027633666992 seconds for one epoch ---
--- 1.2039000988006592 seconds for one epoch ---
--- 0.302659273147583 seconds for one epoch ---
--- 1.23822021484375 seconds for one epoch ---
--- 0.29114866256713867 seconds for one epoch ---
--- 1.195723056793213 seconds for one epoch ---
--- 0.29132866859436035 seconds for one epoch ---
--- 1.210791826248169 seconds for one epoch ---
--- 0.3112144470214844 seconds for one epoch ---
--- 1.2591590881347656 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21037495]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.261142]
 [ -0.      ]]
--- 0.28629493713378906 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5521.75732421875, (1628.0393, 0.5011194, 3893.0747, 0.1418566)
   validation loss 947.7310791015625, (684.4505, 0.36912143, 262.76956, 0.1418566)
decoder loss ratio: 26516.800647, decoder SINDy loss  ratio: 0.567225
--- 0.25352954864501953 seconds for one epoch ---
--- 0.2912483215332031 seconds for one epoch ---
--- 1.2395141124725342 seconds for one epoch ---
--- 0.2923264503479004 seconds for one epoch ---
--- 1.2468578815460205 seconds for one epoch ---
--- 0.2912302017211914 seconds for one epoch ---
--- 1.1978349685668945 seconds for one epoch ---
--- 0.29216885566711426 seconds for one epoch ---
--- 1.2352356910705566 seconds for one epoch ---
--- 0.2963724136352539 seconds for one epoch ---
--- 1.2477490901947021 seconds for one epoch ---
--- 0.2888936996459961 seconds for one epoch ---
--- 1.2414755821228027 seconds for one epoch ---
--- 0.3007547855377197 seconds for one epoch ---
--- 1.2221808433532715 seconds for one epoch ---
--- 0.30380892753601074 seconds for one epoch ---
--- 1.2420639991760254 seconds for one epoch ---
--- 0.29003119468688965 seconds for one epoch ---
--- 1.2039127349853516 seconds for one epoch ---
--- 0.2840301990509033 seconds for one epoch ---
--- 1.2367887496948242 seconds for one epoch ---
--- 0.29822444915771484 seconds for one epoch ---
--- 1.274075984954834 seconds for one epoch ---
--- 0.29870080947875977 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20883286]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.361789]
 [  0.      ]]
--- 0.2572786808013916 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4537.3955078125, (1425.2136, 1.5112073, 3110.528, 0.14241433)
   validation loss 761.7915649414062, (496.841, 0.30500442, 264.50314, 0.14241433)
decoder loss ratio: 19248.483026, decoder SINDy loss  ratio: 0.570967
--- 0.2870335578918457 seconds for one epoch ---
--- 1.2425601482391357 seconds for one epoch ---
--- 0.2856903076171875 seconds for one epoch ---
--- 1.201341152191162 seconds for one epoch ---
--- 0.28815340995788574 seconds for one epoch ---
--- 1.2461328506469727 seconds for one epoch ---
--- 0.27602124214172363 seconds for one epoch ---
--- 1.2407989501953125 seconds for one epoch ---
--- 0.3079073429107666 seconds for one epoch ---
--- 1.2706847190856934 seconds for one epoch ---
--- 0.29825806617736816 seconds for one epoch ---
--- 1.269820213317871 seconds for one epoch ---
--- 0.29306483268737793 seconds for one epoch ---
--- 1.2724690437316895 seconds for one epoch ---
--- 0.29149341583251953 seconds for one epoch ---
--- 1.2451131343841553 seconds for one epoch ---
--- 0.299426794052124 seconds for one epoch ---
--- 1.2405157089233398 seconds for one epoch ---
--- 0.2991971969604492 seconds for one epoch ---
--- 1.245774269104004 seconds for one epoch ---
--- 0.29706358909606934 seconds for one epoch ---
--- 1.2593209743499756 seconds for one epoch ---
--- 0.2988753318786621 seconds for one epoch ---
--- 1.2901997566223145 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20714232]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.468021]
 [  0.      ]]
--- 0.3019857406616211 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4105.20361328125, (1671.0186, 2.3093717, 2431.7327, 0.1430075)
   validation loss 1104.680419921875, (816.6356, 0.3375089, 287.56415, 0.1430075)
decoder loss ratio: 31637.881665, decoder SINDy loss  ratio: 0.620748
--- 0.2596933841705322 seconds for one epoch ---
--- 0.3375988006591797 seconds for one epoch ---
--- 1.2734041213989258 seconds for one epoch ---
--- 0.3167424201965332 seconds for one epoch ---
--- 1.2540996074676514 seconds for one epoch ---
--- 0.32079505920410156 seconds for one epoch ---
--- 1.2668311595916748 seconds for one epoch ---
--- 0.3204216957092285 seconds for one epoch ---
--- 1.255946159362793 seconds for one epoch ---
--- 0.3373072147369385 seconds for one epoch ---
--- 1.251222848892212 seconds for one epoch ---
--- 0.32845449447631836 seconds for one epoch ---
--- 1.2802135944366455 seconds for one epoch ---
--- 0.32533931732177734 seconds for one epoch ---
--- 1.2900516986846924 seconds for one epoch ---
--- 0.32778120040893555 seconds for one epoch ---
--- 1.261564016342163 seconds for one epoch ---
--- 0.3396339416503906 seconds for one epoch ---
--- 1.25307297706604 seconds for one epoch ---
--- 0.3269331455230713 seconds for one epoch ---
--- 1.2690515518188477 seconds for one epoch ---
--- 0.33498573303222656 seconds for one epoch ---
--- 1.2992439270019531 seconds for one epoch ---
--- 0.32709217071533203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20517002]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.587223]
 [ -0.      ]]
--- 0.2578084468841553 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4477.36474609375, (1514.7795, 0.18265398, 2962.259, 0.14366138)
   validation loss 1441.798583984375, (1135.7684, 0.3937974, 305.49265, 0.14366138)
decoder loss ratio: 44001.640860, decoder SINDy loss  ratio: 0.659449
--- 0.29612302780151367 seconds for one epoch ---
--- 1.2589001655578613 seconds for one epoch ---
--- 0.29821228981018066 seconds for one epoch ---
--- 1.286435604095459 seconds for one epoch ---
--- 0.29732346534729004 seconds for one epoch ---
--- 1.2899689674377441 seconds for one epoch ---
--- 0.2960834503173828 seconds for one epoch ---
--- 1.2827508449554443 seconds for one epoch ---
--- 0.30087876319885254 seconds for one epoch ---
--- 1.2704949378967285 seconds for one epoch ---
--- 0.3019430637359619 seconds for one epoch ---
--- 1.2908909320831299 seconds for one epoch ---
--- 0.3013324737548828 seconds for one epoch ---
--- 1.2670085430145264 seconds for one epoch ---
--- 0.2982659339904785 seconds for one epoch ---
--- 1.261298418045044 seconds for one epoch ---
--- 0.2923753261566162 seconds for one epoch ---
--- 1.2866337299346924 seconds for one epoch ---
--- 0.28852152824401855 seconds for one epoch ---
--- 1.2905313968658447 seconds for one epoch ---
--- 0.2956976890563965 seconds for one epoch ---
--- 1.2782189846038818 seconds for one epoch ---
--- 0.2919948101043701 seconds for one epoch ---
--- 1.2800099849700928 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20336848]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.692202]
 [ -0.      ]]
--- 0.29081130027770996 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3272.061767578125, (1162.4431, 1.8257732, 2107.6484, 0.1441797)
   validation loss 942.0465087890625, (656.74304, 0.29514736, 284.86414, 0.1441797)
decoder loss ratio: 25443.365603, decoder SINDy loss  ratio: 0.614919
--- 0.262955904006958 seconds for one epoch ---
--- 0.31789159774780273 seconds for one epoch ---
--- 1.277735948562622 seconds for one epoch ---
--- 0.3132472038269043 seconds for one epoch ---
--- 1.2857038974761963 seconds for one epoch ---
--- 0.3088514804840088 seconds for one epoch ---
--- 1.3184218406677246 seconds for one epoch ---
--- 0.30477166175842285 seconds for one epoch ---
--- 1.3017351627349854 seconds for one epoch ---
--- 0.30133914947509766 seconds for one epoch ---
--- 1.2940101623535156 seconds for one epoch ---
--- 0.31412768363952637 seconds for one epoch ---
--- 1.2922251224517822 seconds for one epoch ---
--- 0.3095717430114746 seconds for one epoch ---
--- 1.291769027709961 seconds for one epoch ---
--- 0.31017518043518066 seconds for one epoch ---
--- 1.2804203033447266 seconds for one epoch ---
--- 0.3023664951324463 seconds for one epoch ---
--- 1.287353754043579 seconds for one epoch ---
--- 0.2991204261779785 seconds for one epoch ---
--- 1.2862849235534668 seconds for one epoch ---
--- 0.30666184425354004 seconds for one epoch ---
--- 1.2800617218017578 seconds for one epoch ---
--- 0.29567670822143555 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20167296]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-12.78797]
 [  0.     ]]
--- 0.25331568717956543 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4980.552734375, (1556.1543, 1.992672, 3422.2612, 0.14466704)
   validation loss 1815.3878173828125, (1475.6157, 0.3322918, 339.2952, 0.14466704)
decoder loss ratio: 57167.914877, decoder SINDy loss  ratio: 0.732416
--- 0.30883240699768066 seconds for one epoch ---
--- 1.2909796237945557 seconds for one epoch ---
--- 0.31065821647644043 seconds for one epoch ---
--- 1.2817883491516113 seconds for one epoch ---
--- 0.2923862934112549 seconds for one epoch ---
--- 1.3516924381256104 seconds for one epoch ---
--- 0.29254627227783203 seconds for one epoch ---
--- 1.2732675075531006 seconds for one epoch ---
--- 0.29914379119873047 seconds for one epoch ---
--- 1.33821439743042 seconds for one epoch ---
--- 0.29436779022216797 seconds for one epoch ---
--- 1.3065814971923828 seconds for one epoch ---
--- 0.30344128608703613 seconds for one epoch ---
--- 1.304344892501831 seconds for one epoch ---
--- 0.30565428733825684 seconds for one epoch ---
--- 1.299767255783081 seconds for one epoch ---
--- 0.2951953411102295 seconds for one epoch ---
--- 1.2939698696136475 seconds for one epoch ---
--- 0.3105201721191406 seconds for one epoch ---
--- 1.2973036766052246 seconds for one epoch ---
--- 0.31052470207214355 seconds for one epoch ---
--- 1.3120217323303223 seconds for one epoch ---
--- 0.2975771427154541 seconds for one epoch ---
--- 1.30588960647583 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20000798]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.879471]
 [  0.      ]]
--- 0.29462552070617676 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4999.32275390625, (2109.5886, 2.155108, 2887.4343, 0.1451112)
   validation loss 724.9718627929688, (460.12378, 0.3945736, 264.30838, 0.1451112)
decoder loss ratio: 17825.994020, decoder SINDy loss  ratio: 0.570547
--- 0.26210927963256836 seconds for one epoch ---
--- 0.3136436939239502 seconds for one epoch ---
--- 1.289726972579956 seconds for one epoch ---
--- 0.3156564235687256 seconds for one epoch ---
--- 1.3150522708892822 seconds for one epoch ---
--- 0.28867316246032715 seconds for one epoch ---
--- 1.296947956085205 seconds for one epoch ---
--- 0.3006775379180908 seconds for one epoch ---
--- 1.3172054290771484 seconds for one epoch ---
--- 0.29245758056640625 seconds for one epoch ---
--- 1.3373243808746338 seconds for one epoch ---
--- 0.3074464797973633 seconds for one epoch ---
--- 1.3302500247955322 seconds for one epoch ---
--- 0.29084014892578125 seconds for one epoch ---
--- 1.3206825256347656 seconds for one epoch ---
--- 0.32341790199279785 seconds for one epoch ---
--- 1.3128077983856201 seconds for one epoch ---
--- 0.2987794876098633 seconds for one epoch ---
--- 1.3251490592956543 seconds for one epoch ---
--- 0.30155158042907715 seconds for one epoch ---
--- 1.323045253753662 seconds for one epoch ---
--- 0.28460264205932617 seconds for one epoch ---
--- 1.310596227645874 seconds for one epoch ---
--- 0.2828233242034912 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19827768]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.972191]
 [  0.      ]]
--- 0.2616541385650635 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4545.65234375, (1971.0748, 0.9752565, 2573.457, 0.14555444)
   validation loss 1249.28369140625, (926.2613, 0.39254418, 322.4843, 0.14555444)
decoder loss ratio: 35884.970493, decoder SINDy loss  ratio: 0.696128
--- 0.2999272346496582 seconds for one epoch ---
--- 1.3385586738586426 seconds for one epoch ---
--- 0.30184197425842285 seconds for one epoch ---
--- 1.3492918014526367 seconds for one epoch ---
--- 0.3059990406036377 seconds for one epoch ---
--- 1.333282232284546 seconds for one epoch ---
--- 0.2842373847961426 seconds for one epoch ---
--- 1.3371565341949463 seconds for one epoch ---
--- 0.3096892833709717 seconds for one epoch ---
--- 1.3252134323120117 seconds for one epoch ---
--- 0.3004648685455322 seconds for one epoch ---
--- 1.337404489517212 seconds for one epoch ---
--- 0.2995171546936035 seconds for one epoch ---
--- 1.345996379852295 seconds for one epoch ---
--- 0.3091776371002197 seconds for one epoch ---
--- 1.349928379058838 seconds for one epoch ---
--- 0.3047785758972168 seconds for one epoch ---
--- 1.3453583717346191 seconds for one epoch ---
--- 0.30745768547058105 seconds for one epoch ---
--- 1.3364698886871338 seconds for one epoch ---
--- 0.32184600830078125 seconds for one epoch ---
--- 1.3467144966125488 seconds for one epoch ---
--- 0.3163130283355713 seconds for one epoch ---
--- 1.3523578643798828 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19637522]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.071548]
 [  0.      ]]
--- 0.28557515144348145 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5172.646484375, (1440.3916, 1.3190104, 3730.7898, 0.14601171)
   validation loss 875.638671875, (615.21814, 0.4938369, 259.78067, 0.14601171)
decoder loss ratio: 23834.618796, decoder SINDy loss  ratio: 0.560773
--- 0.2817955017089844 seconds for one epoch ---
--- 0.30149412155151367 seconds for one epoch ---
--- 1.3443715572357178 seconds for one epoch ---
--- 0.2962305545806885 seconds for one epoch ---
--- 1.342989444732666 seconds for one epoch ---
--- 0.2897665500640869 seconds for one epoch ---
--- 1.3271095752716064 seconds for one epoch ---
--- 0.29509949684143066 seconds for one epoch ---
--- 1.3551979064941406 seconds for one epoch ---
--- 0.5655884742736816 seconds for one epoch ---
--- 1.3416392803192139 seconds for one epoch ---
--- 0.2998640537261963 seconds for one epoch ---
--- 1.3596827983856201 seconds for one epoch ---
--- 0.30376458168029785 seconds for one epoch ---
--- 1.3575639724731445 seconds for one epoch ---
--- 0.2927851676940918 seconds for one epoch ---
--- 1.4061195850372314 seconds for one epoch ---
--- 0.2818162441253662 seconds for one epoch ---
--- 1.376699447631836 seconds for one epoch ---
--- 0.3093702793121338 seconds for one epoch ---
--- 1.3312900066375732 seconds for one epoch ---
--- 0.3037300109863281 seconds for one epoch ---
--- 1.3485207557678223 seconds for one epoch ---
--- 0.30872511863708496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19433607]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.175381]
 [ -0.      ]]
--- 0.2447957992553711 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1978.2164306640625, (998.2825, 0.24195737, 979.54553, 0.1464682)
   validation loss 733.3819580078125, (474.0504, 0.38288707, 258.80215, 0.1464682)
decoder loss ratio: 18365.536066, decoder SINDy loss  ratio: 0.558661
--- 0.2914247512817383 seconds for one epoch ---
--- 1.3385794162750244 seconds for one epoch ---
--- 0.29570841789245605 seconds for one epoch ---
--- 1.3361930847167969 seconds for one epoch ---
--- 0.29560303688049316 seconds for one epoch ---
--- 1.330984354019165 seconds for one epoch ---
--- 0.29752039909362793 seconds for one epoch ---
--- 1.318298101425171 seconds for one epoch ---
--- 0.3034400939941406 seconds for one epoch ---
--- 1.343782663345337 seconds for one epoch ---
--- 0.293900728225708 seconds for one epoch ---
--- 1.345332145690918 seconds for one epoch ---
--- 0.29708313941955566 seconds for one epoch ---
--- 1.355971097946167 seconds for one epoch ---
--- 0.2964804172515869 seconds for one epoch ---
--- 1.3570959568023682 seconds for one epoch ---
--- 0.2734699249267578 seconds for one epoch ---
--- 1.3421568870544434 seconds for one epoch ---
--- 0.30442380905151367 seconds for one epoch ---
--- 1.3307487964630127 seconds for one epoch ---
--- 0.30712270736694336 seconds for one epoch ---
--- 1.336296796798706 seconds for one epoch ---
--- 0.2896761894226074 seconds for one epoch ---
--- 1.3485240936279297 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19259986]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-13.26179]
 [ -0.     ]]
--- 0.2891268730163574 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7495.5810546875, (1750.9637, 8.807714, 5735.6626, 0.1468575)
   validation loss 1094.5418701171875, (790.7512, 0.43968135, 303.20407, 0.1468575)
decoder loss ratio: 30635.075095, decoder SINDy loss  ratio: 0.654509
--- 0.25022363662719727 seconds for one epoch ---
--- 0.299652099609375 seconds for one epoch ---
--- 1.3331711292266846 seconds for one epoch ---
--- 0.2992370128631592 seconds for one epoch ---
--- 1.349705696105957 seconds for one epoch ---
--- 0.2926137447357178 seconds for one epoch ---
--- 1.337174654006958 seconds for one epoch ---
--- 0.28766679763793945 seconds for one epoch ---
--- 1.360889196395874 seconds for one epoch ---
--- 0.29367733001708984 seconds for one epoch ---
--- 1.3406660556793213 seconds for one epoch ---
--- 0.2902393341064453 seconds for one epoch ---
--- 1.3778917789459229 seconds for one epoch ---
--- 0.2997877597808838 seconds for one epoch ---
--- 1.3683221340179443 seconds for one epoch ---
--- 0.2992579936981201 seconds for one epoch ---
--- 1.3495326042175293 seconds for one epoch ---
--- 0.28727078437805176 seconds for one epoch ---
--- 1.3341026306152344 seconds for one epoch ---
--- 0.30132341384887695 seconds for one epoch ---
--- 1.3693835735321045 seconds for one epoch ---
--- 0.300748348236084 seconds for one epoch ---
--- 1.3843660354614258 seconds for one epoch ---
--- 0.28650379180908203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19089898]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.344852]
 [ -0.      ]]
--- 0.2520906925201416 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4369.12841796875, (1828.8304, 0.8250211, 2539.3262, 0.14720558)
   validation loss 1084.6778564453125, (796.9366, 0.47375354, 287.1203, 0.14720558)
decoder loss ratio: 30874.706825, decoder SINDy loss  ratio: 0.619790
--- 0.3077049255371094 seconds for one epoch ---
--- 1.3852858543395996 seconds for one epoch ---
--- 0.3031759262084961 seconds for one epoch ---
--- 1.3567614555358887 seconds for one epoch ---
--- 0.31533312797546387 seconds for one epoch ---
--- 1.3708734512329102 seconds for one epoch ---
--- 0.3133828639984131 seconds for one epoch ---
--- 1.3789050579071045 seconds for one epoch ---
--- 0.3055844306945801 seconds for one epoch ---
--- 1.359044075012207 seconds for one epoch ---
--- 0.30907106399536133 seconds for one epoch ---
--- 1.3665046691894531 seconds for one epoch ---
--- 0.3083817958831787 seconds for one epoch ---
--- 1.383066177368164 seconds for one epoch ---
--- 0.32540130615234375 seconds for one epoch ---
--- 1.3771095275878906 seconds for one epoch ---
--- 0.31211233139038086 seconds for one epoch ---
--- 1.3804357051849365 seconds for one epoch ---
--- 0.2983825206756592 seconds for one epoch ---
--- 1.3906145095825195 seconds for one epoch ---
--- 0.3105499744415283 seconds for one epoch ---
--- 1.384087324142456 seconds for one epoch ---
--- 0.30026721954345703 seconds for one epoch ---
--- 1.3840973377227783 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18880442]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-13.44513]
 [ -0.     ]]
--- 0.28910064697265625 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3618.817626953125, (1736.421, 0.59151936, 1881.6573, 0.1476078)
   validation loss 814.481689453125, (515.6676, 0.43385184, 298.23267, 0.1476078)
decoder loss ratio: 19977.858161, decoder SINDy loss  ratio: 0.643777
--- 0.27316808700561523 seconds for one epoch ---
--- 0.28897809982299805 seconds for one epoch ---
--- 1.3909013271331787 seconds for one epoch ---
--- 0.30063652992248535 seconds for one epoch ---
--- 1.3967678546905518 seconds for one epoch ---
--- 0.29323673248291016 seconds for one epoch ---
--- 1.3925061225891113 seconds for one epoch ---
--- 0.29370808601379395 seconds for one epoch ---
--- 1.3969626426696777 seconds for one epoch ---
--- 0.29768943786621094 seconds for one epoch ---
--- 1.3948991298675537 seconds for one epoch ---
--- 0.3049774169921875 seconds for one epoch ---
--- 1.3979623317718506 seconds for one epoch ---
--- 0.3036506175994873 seconds for one epoch ---
--- 1.4124114513397217 seconds for one epoch ---
--- 0.3026411533355713 seconds for one epoch ---
--- 1.3804562091827393 seconds for one epoch ---
--- 0.29992175102233887 seconds for one epoch ---
--- 1.4196066856384277 seconds for one epoch ---
--- 0.3176305294036865 seconds for one epoch ---
--- 1.3804831504821777 seconds for one epoch ---
--- 0.3004152774810791 seconds for one epoch ---
--- 1.3795557022094727 seconds for one epoch ---
--- 0.2916405200958252 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18696855]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.531363]
 [ -0.      ]]
--- 0.25200963020324707 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2714.244140625, (1273.8351, 1.0838296, 1439.1771, 0.14795776)
   validation loss 1191.79443359375, (861.77875, 0.37049204, 329.4972, 0.14795776)
decoder loss ratio: 33386.804794, decoder SINDy loss  ratio: 0.711266
--- 0.2905912399291992 seconds for one epoch ---
--- 1.3835780620574951 seconds for one epoch ---
--- 0.29723119735717773 seconds for one epoch ---
--- 1.3835318088531494 seconds for one epoch ---
--- 0.28412866592407227 seconds for one epoch ---
--- 1.3995356559753418 seconds for one epoch ---
--- 0.29192042350769043 seconds for one epoch ---
--- 1.368520975112915 seconds for one epoch ---
--- 0.28318023681640625 seconds for one epoch ---
--- 1.3898634910583496 seconds for one epoch ---
--- 0.28847193717956543 seconds for one epoch ---
--- 1.3999228477478027 seconds for one epoch ---
--- 0.2906937599182129 seconds for one epoch ---
--- 1.3912076950073242 seconds for one epoch ---
--- 0.29578208923339844 seconds for one epoch ---
--- 1.3796272277832031 seconds for one epoch ---
--- 0.2820556163787842 seconds for one epoch ---
--- 1.3927443027496338 seconds for one epoch ---
--- 0.2924165725708008 seconds for one epoch ---
--- 1.3659272193908691 seconds for one epoch ---
--- 0.2937934398651123 seconds for one epoch ---
--- 1.4149463176727295 seconds for one epoch ---
--- 0.28556203842163086 seconds for one epoch ---
--- 1.4115486145019531 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18480903]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.630984]
 [  0.      ]]
--- 0.30277204513549805 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3586.03857421875, (1937.8307, 1.6883566, 1646.3712, 0.1483248)
   validation loss 803.52490234375, (533.5018, 0.34811738, 269.52667, 0.1483248)
decoder loss ratio: 20668.784770, decoder SINDy loss  ratio: 0.581811
--- 0.2522423267364502 seconds for one epoch ---
--- 0.3213045597076416 seconds for one epoch ---
--- 1.4121735095977783 seconds for one epoch ---
--- 0.3196232318878174 seconds for one epoch ---
--- 1.4093120098114014 seconds for one epoch ---
--- 0.3202931880950928 seconds for one epoch ---
--- 1.3938100337982178 seconds for one epoch ---
--- 0.3167438507080078 seconds for one epoch ---
--- 1.3971271514892578 seconds for one epoch ---
--- 0.3136136531829834 seconds for one epoch ---
--- 1.3935015201568604 seconds for one epoch ---
--- 0.33391332626342773 seconds for one epoch ---
--- 1.421424150466919 seconds for one epoch ---
--- 0.3140420913696289 seconds for one epoch ---
--- 1.407526969909668 seconds for one epoch ---
--- 0.31976938247680664 seconds for one epoch ---
--- 1.3974614143371582 seconds for one epoch ---
--- 0.3066713809967041 seconds for one epoch ---
--- 1.4136285781860352 seconds for one epoch ---
--- 0.2982187271118164 seconds for one epoch ---
--- 1.4083402156829834 seconds for one epoch ---
--- 0.294283390045166 seconds for one epoch ---
--- 1.4100162982940674 seconds for one epoch ---
--- 0.2911198139190674 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18328401]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.700239]
 [  0.      ]]
--- 0.2588655948638916 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6114.48291015625, (1488.8895, 1.0563581, 4624.3887, 0.14858802)
   validation loss 709.7932739257812, (457.8506, 0.59776586, 251.19637, 0.14858802)
decoder loss ratio: 17737.926563, decoder SINDy loss  ratio: 0.542243
--- 0.32169055938720703 seconds for one epoch ---
--- 1.4306936264038086 seconds for one epoch ---
--- 0.32492923736572266 seconds for one epoch ---
--- 1.4206719398498535 seconds for one epoch ---
--- 0.3188138008117676 seconds for one epoch ---
--- 1.4221725463867188 seconds for one epoch ---
--- 0.32894396781921387 seconds for one epoch ---
--- 1.4270694255828857 seconds for one epoch ---
--- 0.333864688873291 seconds for one epoch ---
--- 1.4355995655059814 seconds for one epoch ---
--- 0.3271028995513916 seconds for one epoch ---
--- 1.4334537982940674 seconds for one epoch ---
--- 0.3308722972869873 seconds for one epoch ---
--- 1.389890432357788 seconds for one epoch ---
--- 0.3216383457183838 seconds for one epoch ---
--- 1.4141921997070312 seconds for one epoch ---
--- 0.33231234550476074 seconds for one epoch ---
--- 1.4271740913391113 seconds for one epoch ---
--- 0.32514286041259766 seconds for one epoch ---
--- 1.429211139678955 seconds for one epoch ---
--- 0.2965812683105469 seconds for one epoch ---
--- 1.4393551349639893 seconds for one epoch ---
--- 0.28030848503112793 seconds for one epoch ---
--- 1.4277215003967285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18138555]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.785295]
 [ -0.      ]]
--- 0.29720520973205566 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2167.47314453125, (1272.475, 0.74108857, 894.1083, 0.148896)
   validation loss 729.524658203125, (472.12213, 0.4176785, 256.83594, 0.148896)
decoder loss ratio: 18290.831008, decoder SINDy loss  ratio: 0.554416
--- 0.2629225254058838 seconds for one epoch ---
--- 0.2938239574432373 seconds for one epoch ---
--- 1.4290194511413574 seconds for one epoch ---
--- 0.29262566566467285 seconds for one epoch ---
--- 1.4221882820129395 seconds for one epoch ---
--- 0.30745959281921387 seconds for one epoch ---
--- 1.4307029247283936 seconds for one epoch ---
--- 0.2991807460784912 seconds for one epoch ---
--- 1.4312617778778076 seconds for one epoch ---
--- 0.30071306228637695 seconds for one epoch ---
--- 1.4298269748687744 seconds for one epoch ---
--- 0.2993779182434082 seconds for one epoch ---
--- 1.4384765625 seconds for one epoch ---
--- 0.30795741081237793 seconds for one epoch ---
--- 1.4250502586364746 seconds for one epoch ---
--- 0.30168890953063965 seconds for one epoch ---
--- 1.4519617557525635 seconds for one epoch ---
--- 0.2966928482055664 seconds for one epoch ---
--- 1.4559738636016846 seconds for one epoch ---
--- 0.2940547466278076 seconds for one epoch ---
--- 1.425502061843872 seconds for one epoch ---
--- 0.298506498336792 seconds for one epoch ---
--- 1.4162750244140625 seconds for one epoch ---
--- 0.29098081588745117 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17948362]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.869298]
 [ -0.      ]]
--- 0.2645246982574463 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2097.818115234375, (1036.1118, 0.64293045, 1060.9143, 0.14917944)
   validation loss 1052.72021484375, (727.85376, 0.37015688, 324.34708, 0.14917944)
decoder loss ratio: 28198.318263, decoder SINDy loss  ratio: 0.700149
--- 0.2886321544647217 seconds for one epoch ---
--- 1.4337849617004395 seconds for one epoch ---
--- 0.2918093204498291 seconds for one epoch ---
--- 1.4427969455718994 seconds for one epoch ---
--- 0.29479193687438965 seconds for one epoch ---
--- 1.440580129623413 seconds for one epoch ---
--- 0.29183340072631836 seconds for one epoch ---
--- 1.4367482662200928 seconds for one epoch ---
--- 0.29338693618774414 seconds for one epoch ---
--- 1.4631822109222412 seconds for one epoch ---
--- 0.29639267921447754 seconds for one epoch ---
--- 1.4343092441558838 seconds for one epoch ---
--- 0.2943594455718994 seconds for one epoch ---
--- 1.4173951148986816 seconds for one epoch ---
--- 0.29007720947265625 seconds for one epoch ---
--- 1.4192702770233154 seconds for one epoch ---
--- 0.29201292991638184 seconds for one epoch ---
--- 1.4456403255462646 seconds for one epoch ---
--- 0.2942066192626953 seconds for one epoch ---
--- 1.4097437858581543 seconds for one epoch ---
--- 0.291323184967041 seconds for one epoch ---
--- 1.4211618900299072 seconds for one epoch ---
--- 0.2900400161743164 seconds for one epoch ---
--- 1.439337968826294 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1778041]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.942555]
 [  0.      ]]
--- 0.2940070629119873 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3187.02099609375, (1354.6733, 2.571095, 1829.6271, 0.14943704)
   validation loss 771.6617431640625, (498.74847, 0.37414795, 272.38974, 0.14943704)
decoder loss ratio: 19322.381753, decoder SINDy loss  ratio: 0.587992
THRESHOLDING: 1 active coefficients
--- 1.4502685070037842 seconds for one epoch ---
--- 0.29001879692077637 seconds for one epoch ---
--- 1.4400601387023926 seconds for one epoch ---
--- 0.3094351291656494 seconds for one epoch ---
--- 1.4682965278625488 seconds for one epoch ---
--- 0.2956817150115967 seconds for one epoch ---
--- 1.461731195449829 seconds for one epoch ---
--- 0.2991371154785156 seconds for one epoch ---
--- 1.4604544639587402 seconds for one epoch ---
--- 0.3011443614959717 seconds for one epoch ---
--- 1.4658787250518799 seconds for one epoch ---
--- 0.28609275817871094 seconds for one epoch ---
--- 1.4419329166412354 seconds for one epoch ---
--- 0.3014943599700928 seconds for one epoch ---
--- 1.4341609477996826 seconds for one epoch ---
--- 0.2991924285888672 seconds for one epoch ---
--- 1.4254062175750732 seconds for one epoch ---
--- 0.31990766525268555 seconds for one epoch ---
--- 1.4541876316070557 seconds for one epoch ---
--- 0.31215882301330566 seconds for one epoch ---
--- 1.4718947410583496 seconds for one epoch ---
--- 0.30447936058044434 seconds for one epoch ---
--- 1.4679176807403564 seconds for one epoch ---
--- 0.3154463768005371 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17586291]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.02623]
 [  0.     ]]
--- 0.25904202461242676 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2536.752197265625, (996.2406, 2.1302621, 1538.2318, 0.14971498)
   validation loss 810.6223754882812, (536.146, 0.4235954, 273.90305, 0.14971498)
decoder loss ratio: 20771.226679, decoder SINDy loss  ratio: 0.591258
--- 0.2903451919555664 seconds for one epoch ---
--- 1.4650647640228271 seconds for one epoch ---
--- 0.29035282135009766 seconds for one epoch ---
--- 1.456939935684204 seconds for one epoch ---
--- 0.30735182762145996 seconds for one epoch ---
--- 1.4650170803070068 seconds for one epoch ---
--- 0.29595494270324707 seconds for one epoch ---
--- 1.4254448413848877 seconds for one epoch ---
--- 0.2956395149230957 seconds for one epoch ---
--- 1.4294593334197998 seconds for one epoch ---
--- 0.2763936519622803 seconds for one epoch ---
--- 1.429861068725586 seconds for one epoch ---
--- 0.33885788917541504 seconds for one epoch ---
--- 1.44612717628479 seconds for one epoch ---
--- 0.33399391174316406 seconds for one epoch ---
--- 1.4709010124206543 seconds for one epoch ---
--- 0.33053112030029297 seconds for one epoch ---
--- 1.4543824195861816 seconds for one epoch ---
--- 0.34590816497802734 seconds for one epoch ---
--- 1.455244541168213 seconds for one epoch ---
--- 0.3228468894958496 seconds for one epoch ---
--- 1.4860234260559082 seconds for one epoch ---
--- 0.32976794242858887 seconds for one epoch ---
--- 1.4439408779144287 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17411321]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.10079]
 [  0.     ]]
--- 0.2881801128387451 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3941.162109375, (1684.1368, 3.4375265, 2253.4377, 0.14995067)
   validation loss 860.3317260742188, (591.95325, 0.3740796, 267.85446, 0.14995067)
decoder loss ratio: 22933.296468, decoder SINDy loss  ratio: 0.578202
--- 0.2704906463623047 seconds for one epoch ---
--- 0.29961204528808594 seconds for one epoch ---
--- 1.464958906173706 seconds for one epoch ---
--- 0.29663896560668945 seconds for one epoch ---
--- 1.4809117317199707 seconds for one epoch ---
--- 0.2905001640319824 seconds for one epoch ---
--- 1.4312663078308105 seconds for one epoch ---
--- 0.3091416358947754 seconds for one epoch ---
--- 1.4217722415924072 seconds for one epoch ---
--- 0.30011749267578125 seconds for one epoch ---
--- 1.4659461975097656 seconds for one epoch ---
--- 0.30107545852661133 seconds for one epoch ---
--- 1.5058133602142334 seconds for one epoch ---
--- 0.2921745777130127 seconds for one epoch ---
--- 1.491011619567871 seconds for one epoch ---
--- 0.29473137855529785 seconds for one epoch ---
--- 1.486680030822754 seconds for one epoch ---
--- 0.29737305641174316 seconds for one epoch ---
--- 1.4856541156768799 seconds for one epoch ---
--- 0.28826212882995605 seconds for one epoch ---
--- 1.4908745288848877 seconds for one epoch ---
--- 0.28695130348205566 seconds for one epoch ---
--- 1.4822213649749756 seconds for one epoch ---
--- 0.3040883541107178 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17284048]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.154559]
 [  0.      ]]
--- 0.24385666847229004 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3382.753173828125, (1349.5656, 2.0975127, 2030.9398, 0.15012066)
   validation loss 915.7669067382812, (637.44653, 0.34562817, 277.8246, 0.15012066)
decoder loss ratio: 24695.785352, decoder SINDy loss  ratio: 0.599723
--- 0.31913018226623535 seconds for one epoch ---
--- 1.5292277336120605 seconds for one epoch ---
--- 0.31320786476135254 seconds for one epoch ---
--- 1.449951171875 seconds for one epoch ---
--- 0.31400394439697266 seconds for one epoch ---
--- 1.4871516227722168 seconds for one epoch ---
--- 0.31918931007385254 seconds for one epoch ---
--- 1.5225813388824463 seconds for one epoch ---
--- 0.32085180282592773 seconds for one epoch ---
--- 1.505293369293213 seconds for one epoch ---
--- 0.32050561904907227 seconds for one epoch ---
--- 1.5246212482452393 seconds for one epoch ---
--- 0.29947471618652344 seconds for one epoch ---
--- 1.490281581878662 seconds for one epoch ---
--- 0.34036684036254883 seconds for one epoch ---
--- 1.4945223331451416 seconds for one epoch ---
--- 0.297473669052124 seconds for one epoch ---
--- 1.47530198097229 seconds for one epoch ---
--- 0.2990915775299072 seconds for one epoch ---
--- 1.4799473285675049 seconds for one epoch ---
--- 0.2943084239959717 seconds for one epoch ---
--- 1.4943795204162598 seconds for one epoch ---
--- 0.2950160503387451 seconds for one epoch ---
--- 1.4971883296966553 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17132604]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.218039]
 [ -0.      ]]
--- 0.30382370948791504 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3748.0537109375, (2381.2896, 1.556883, 1365.057, 0.1503119)
   validation loss 1080.600341796875, (775.23224, 0.57980585, 304.638, 0.1503119)
decoder loss ratio: 30033.842792, decoder SINDy loss  ratio: 0.657604
--- 0.25955939292907715 seconds for one epoch ---
--- 0.2957947254180908 seconds for one epoch ---
--- 1.5054872035980225 seconds for one epoch ---
--- 0.3206648826599121 seconds for one epoch ---
--- 1.4920170307159424 seconds for one epoch ---
--- 0.3098158836364746 seconds for one epoch ---
--- 1.4816133975982666 seconds for one epoch ---
--- 0.31104350090026855 seconds for one epoch ---
--- 1.5151667594909668 seconds for one epoch ---
--- 0.31939077377319336 seconds for one epoch ---
--- 1.4887845516204834 seconds for one epoch ---
--- 0.3146326541900635 seconds for one epoch ---
--- 1.486039400100708 seconds for one epoch ---
--- 0.2832045555114746 seconds for one epoch ---
--- 1.4886484146118164 seconds for one epoch ---
--- 0.30414891242980957 seconds for one epoch ---
--- 1.4788243770599365 seconds for one epoch ---
--- 0.29791831970214844 seconds for one epoch ---
--- 1.4848096370697021 seconds for one epoch ---
--- 0.286945104598999 seconds for one epoch ---
--- 1.4808368682861328 seconds for one epoch ---
--- 0.29320621490478516 seconds for one epoch ---
--- 1.4947590827941895 seconds for one epoch ---
--- 0.30884480476379395 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16977796]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.282401]
 [ -0.      ]]
--- 0.2593543529510498 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1583.9068603515625, (847.9757, 0.56294996, 735.2178, 0.15050144)
   validation loss 813.4520874023438, (517.24896, 0.41472962, 295.63788, 0.15050144)
decoder loss ratio: 20039.122787, decoder SINDy loss  ratio: 0.638176
--- 0.2923259735107422 seconds for one epoch ---
--- 1.4877874851226807 seconds for one epoch ---
--- 0.2971639633178711 seconds for one epoch ---
--- 1.519411563873291 seconds for one epoch ---
--- 0.2998785972595215 seconds for one epoch ---
--- 1.4995110034942627 seconds for one epoch ---
--- 0.29546213150024414 seconds for one epoch ---
--- 1.5062427520751953 seconds for one epoch ---
--- 0.2918877601623535 seconds for one epoch ---
--- 1.5131924152374268 seconds for one epoch ---
--- 0.3019106388092041 seconds for one epoch ---
--- 1.5024731159210205 seconds for one epoch ---
--- 0.2920095920562744 seconds for one epoch ---
--- 1.5250706672668457 seconds for one epoch ---
--- 0.3009157180786133 seconds for one epoch ---
--- 1.519627571105957 seconds for one epoch ---
--- 0.2982478141784668 seconds for one epoch ---
--- 1.533273458480835 seconds for one epoch ---
--- 0.2956366539001465 seconds for one epoch ---
--- 1.5275352001190186 seconds for one epoch ---
--- 0.2982332706451416 seconds for one epoch ---
--- 1.5188958644866943 seconds for one epoch ---
--- 0.29630470275878906 seconds for one epoch ---
--- 1.5510873794555664 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16827042]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.34462]
 [ -0.     ]]
--- 0.30089831352233887 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2773.154541015625, (1153.2157, 2.000636, 1617.7877, 0.15068726)
   validation loss 803.4246215820312, (543.3247, 0.53343207, 259.41574, 0.15068726)
decoder loss ratio: 21049.342404, decoder SINDy loss  ratio: 0.559985
--- 0.27657413482666016 seconds for one epoch ---
--- 0.3187079429626465 seconds for one epoch ---
--- 1.5260982513427734 seconds for one epoch ---
--- 0.3149685859680176 seconds for one epoch ---
--- 1.5388031005859375 seconds for one epoch ---
--- 0.30202817916870117 seconds for one epoch ---
--- 1.5319244861602783 seconds for one epoch ---
--- 0.3102898597717285 seconds for one epoch ---
--- 1.5241138935089111 seconds for one epoch ---
--- 0.3200514316558838 seconds for one epoch ---
--- 1.5185081958770752 seconds for one epoch ---
--- 0.3279850482940674 seconds for one epoch ---
--- 1.5563714504241943 seconds for one epoch ---
--- 0.3305072784423828 seconds for one epoch ---
--- 1.5225257873535156 seconds for one epoch ---
--- 0.2943694591522217 seconds for one epoch ---
--- 1.541799783706665 seconds for one epoch ---
--- 0.29836368560791016 seconds for one epoch ---
--- 1.523146390914917 seconds for one epoch ---
--- 0.30911993980407715 seconds for one epoch ---
--- 1.5602893829345703 seconds for one epoch ---
--- 0.29952311515808105 seconds for one epoch ---
--- 1.5549497604370117 seconds for one epoch ---
--- 0.2980384826660156 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16654462]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.41529]
 [ -0.     ]]
--- 0.2561023235321045 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3481.1708984375, (2294.3074, 0.47820824, 1186.2345, 0.1508836)
   validation loss 779.8699951171875, (502.63446, 0.40325424, 276.68143, 0.1508836)
decoder loss ratio: 19472.931610, decoder SINDy loss  ratio: 0.597256
--- 0.29296183586120605 seconds for one epoch ---
--- 1.528458595275879 seconds for one epoch ---
--- 0.30399441719055176 seconds for one epoch ---
--- 1.526771068572998 seconds for one epoch ---
--- 0.3055918216705322 seconds for one epoch ---
--- 1.5364947319030762 seconds for one epoch ---
--- 0.2904531955718994 seconds for one epoch ---
--- 1.543745517730713 seconds for one epoch ---
--- 0.2915956974029541 seconds for one epoch ---
--- 1.5283913612365723 seconds for one epoch ---
--- 0.289003849029541 seconds for one epoch ---
--- 1.533402919769287 seconds for one epoch ---
--- 0.2970728874206543 seconds for one epoch ---
--- 1.5534052848815918 seconds for one epoch ---
--- 0.2920403480529785 seconds for one epoch ---
--- 1.5445551872253418 seconds for one epoch ---
--- 0.29367852210998535 seconds for one epoch ---
--- 1.5360000133514404 seconds for one epoch ---
--- 0.2872598171234131 seconds for one epoch ---
--- 1.5400314331054688 seconds for one epoch ---
--- 0.2980687618255615 seconds for one epoch ---
--- 1.5632731914520264 seconds for one epoch ---
--- 0.29791975021362305 seconds for one epoch ---
--- 1.518660545349121 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16494828]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.480171]
 [ -0.      ]]
--- 0.29556751251220703 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2713.867431640625, (1643.0569, 0.8694148, 1069.79, 0.15105963)
   validation loss 1134.7977294921875, (837.62744, 0.4083662, 296.6109, 0.15105963)
decoder loss ratio: 32451.141265, decoder SINDy loss  ratio: 0.640276
--- 0.2918875217437744 seconds for one epoch ---
--- 0.29914259910583496 seconds for one epoch ---
--- 1.5464117527008057 seconds for one epoch ---
--- 0.30424976348876953 seconds for one epoch ---
--- 1.5900280475616455 seconds for one epoch ---
--- 0.3044753074645996 seconds for one epoch ---
--- 1.5653955936431885 seconds for one epoch ---
--- 0.3054630756378174 seconds for one epoch ---
--- 1.5198180675506592 seconds for one epoch ---
--- 0.304349422454834 seconds for one epoch ---
--- 1.5645158290863037 seconds for one epoch ---
--- 0.31649351119995117 seconds for one epoch ---
--- 1.5172457695007324 seconds for one epoch ---
--- 0.28880858421325684 seconds for one epoch ---
--- 1.5407946109771729 seconds for one epoch ---
--- 0.28357481956481934 seconds for one epoch ---
--- 1.5233683586120605 seconds for one epoch ---
--- 0.29660773277282715 seconds for one epoch ---
--- 1.5371336936950684 seconds for one epoch ---
--- 0.28671956062316895 seconds for one epoch ---
--- 1.5444860458374023 seconds for one epoch ---
--- 0.2937917709350586 seconds for one epoch ---
--- 1.5574333667755127 seconds for one epoch ---
--- 0.28182482719421387 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1633483]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.544783]
 [  0.      ]]
--- 0.24303364753723145 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2412.165771484375, (1313.2666, 1.1467057, 1097.6012, 0.15122949)
   validation loss 760.63134765625, (480.37238, 0.32918143, 279.7785, 0.15122949)
decoder loss ratio: 18610.459790, decoder SINDy loss  ratio: 0.603941
--- 0.31667470932006836 seconds for one epoch ---
--- 1.5656704902648926 seconds for one epoch ---
--- 0.3381998538970947 seconds for one epoch ---
--- 1.5562245845794678 seconds for one epoch ---
--- 0.33378171920776367 seconds for one epoch ---
--- 1.5353641510009766 seconds for one epoch ---
--- 0.31801509857177734 seconds for one epoch ---
--- 1.557276725769043 seconds for one epoch ---
--- 0.32374095916748047 seconds for one epoch ---
--- 1.5418224334716797 seconds for one epoch ---
--- 0.3142063617706299 seconds for one epoch ---
--- 1.5649936199188232 seconds for one epoch ---
--- 0.3270149230957031 seconds for one epoch ---
--- 1.5611817836761475 seconds for one epoch ---
--- 0.29431867599487305 seconds for one epoch ---
--- 1.5405254364013672 seconds for one epoch ---
--- 0.2986173629760742 seconds for one epoch ---
--- 1.5155596733093262 seconds for one epoch ---
--- 0.2891879081726074 seconds for one epoch ---
--- 1.5368244647979736 seconds for one epoch ---
--- 0.29092955589294434 seconds for one epoch ---
--- 1.5527739524841309 seconds for one epoch ---
--- 0.30165672302246094 seconds for one epoch ---
--- 1.5338294506072998 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16200393]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.598754]
 [  0.      ]]
--- 0.2946648597717285 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2787.02392578125, (859.69037, 2.8245344, 1924.3575, 0.15136862)
   validation loss 997.540771484375, (727.92944, 0.39718553, 269.06277, 0.15136862)
decoder loss ratio: 28201.250377, decoder SINDy loss  ratio: 0.580810
--- 0.2615375518798828 seconds for one epoch ---
--- 0.2966887950897217 seconds for one epoch ---
--- 1.5701568126678467 seconds for one epoch ---
--- 0.2978644371032715 seconds for one epoch ---
--- 1.590052604675293 seconds for one epoch ---
--- 0.2986612319946289 seconds for one epoch ---
--- 1.5475695133209229 seconds for one epoch ---
--- 0.3018021583557129 seconds for one epoch ---
--- 1.5777075290679932 seconds for one epoch ---
--- 0.29068779945373535 seconds for one epoch ---
--- 1.543025255203247 seconds for one epoch ---
--- 0.30260705947875977 seconds for one epoch ---
--- 1.543931007385254 seconds for one epoch ---
--- 0.2928018569946289 seconds for one epoch ---
--- 1.5698797702789307 seconds for one epoch ---
--- 0.2866373062133789 seconds for one epoch ---
--- 1.5472614765167236 seconds for one epoch ---
--- 0.2884352207183838 seconds for one epoch ---
--- 1.556901216506958 seconds for one epoch ---
--- 0.2941455841064453 seconds for one epoch ---
--- 1.554757833480835 seconds for one epoch ---
--- 0.28611135482788086 seconds for one epoch ---
--- 1.583726406097412 seconds for one epoch ---
--- 0.302473783493042 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16071042]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.650424]
 [ -0.      ]]
--- 0.25966763496398926 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4368.677734375, (1439.1302, 1.2863238, 2928.1096, 0.15150383)
   validation loss 828.6930541992188, (559.9266, 0.43872812, 268.17627, 0.15150383)
decoder loss ratio: 21692.527579, decoder SINDy loss  ratio: 0.578896
--- 0.28867673873901367 seconds for one epoch ---
--- 1.563814401626587 seconds for one epoch ---
--- 0.3008155822753906 seconds for one epoch ---
--- 1.6086044311523438 seconds for one epoch ---
--- 0.29634547233581543 seconds for one epoch ---
--- 1.5542917251586914 seconds for one epoch ---
--- 0.28839802742004395 seconds for one epoch ---
--- 1.5709564685821533 seconds for one epoch ---
--- 0.30617213249206543 seconds for one epoch ---
--- 1.5879111289978027 seconds for one epoch ---
--- 0.3026764392852783 seconds for one epoch ---
--- 1.5841124057769775 seconds for one epoch ---
--- 0.2953319549560547 seconds for one epoch ---
--- 1.582484245300293 seconds for one epoch ---
--- 0.2931084632873535 seconds for one epoch ---
--- 1.593369483947754 seconds for one epoch ---
--- 0.2962191104888916 seconds for one epoch ---
--- 1.5731940269470215 seconds for one epoch ---
--- 0.29857778549194336 seconds for one epoch ---
--- 1.5859923362731934 seconds for one epoch ---
--- 0.29497671127319336 seconds for one epoch ---
--- 1.6215670108795166 seconds for one epoch ---
--- 0.30136704444885254 seconds for one epoch ---
--- 1.5759756565093994 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15903151]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.717152]
 [ -0.      ]]
--- 0.30875349044799805 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2760.614013671875, (1121.8297, 2.0867903, 1636.5458, 0.1516736)
   validation loss 738.1458129882812, (450.99008, 0.5024214, 286.50165, 0.1516736)
decoder loss ratio: 17472.138722, decoder SINDy loss  ratio: 0.618454
--- 0.276294469833374 seconds for one epoch ---
--- 0.2990231513977051 seconds for one epoch ---
--- 1.5963363647460938 seconds for one epoch ---
--- 0.2937033176422119 seconds for one epoch ---
--- 1.6003527641296387 seconds for one epoch ---
--- 0.31316280364990234 seconds for one epoch ---
--- 1.6199548244476318 seconds for one epoch ---
--- 0.2920808792114258 seconds for one epoch ---
--- 1.6251592636108398 seconds for one epoch ---
--- 0.3088114261627197 seconds for one epoch ---
--- 1.5838723182678223 seconds for one epoch ---
--- 0.295515775680542 seconds for one epoch ---
--- 1.5941569805145264 seconds for one epoch ---
--- 0.28310155868530273 seconds for one epoch ---
--- 1.604442834854126 seconds for one epoch ---
--- 0.2943301200866699 seconds for one epoch ---
--- 1.5916013717651367 seconds for one epoch ---
--- 0.29506349563598633 seconds for one epoch ---
--- 1.6161503791809082 seconds for one epoch ---
--- 0.29041218757629395 seconds for one epoch ---
--- 1.6190404891967773 seconds for one epoch ---
--- 0.30112147331237793 seconds for one epoch ---
--- 1.5907564163208008 seconds for one epoch ---
--- 0.2930152416229248 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15771917]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.769038]
 [  0.      ]]
--- 0.2428884506225586 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3107.84619140625, (1113.3258, 0.4335118, 1993.935, 0.15180247)
   validation loss 771.31005859375, (509.44238, 0.61552256, 261.10037, 0.15180247)
decoder loss ratio: 19736.682341, decoder SINDy loss  ratio: 0.563622
--- 0.29601025581359863 seconds for one epoch ---
--- 1.6050021648406982 seconds for one epoch ---
--- 0.29405879974365234 seconds for one epoch ---
--- 1.5800635814666748 seconds for one epoch ---
--- 0.29619884490966797 seconds for one epoch ---
--- 1.6178739070892334 seconds for one epoch ---
--- 0.3085317611694336 seconds for one epoch ---
--- 1.5976238250732422 seconds for one epoch ---
--- 0.3016831874847412 seconds for one epoch ---
--- 1.605205774307251 seconds for one epoch ---
--- 0.2969703674316406 seconds for one epoch ---
--- 1.6037535667419434 seconds for one epoch ---
--- 0.32959723472595215 seconds for one epoch ---
--- 1.6110434532165527 seconds for one epoch ---
--- 0.315105676651001 seconds for one epoch ---
--- 1.622682809829712 seconds for one epoch ---
--- 0.28806042671203613 seconds for one epoch ---
--- 1.6088428497314453 seconds for one epoch ---
--- 0.30276989936828613 seconds for one epoch ---
--- 1.632378339767456 seconds for one epoch ---
--- 0.29816722869873047 seconds for one epoch ---
--- 1.5713250637054443 seconds for one epoch ---
--- 0.3039572238922119 seconds for one epoch ---
--- 1.5981762409210205 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15600325]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.836566]
 [  0.      ]]
--- 0.29457664489746094 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3501.255126953125, (1134.0762, 3.3660092, 2363.6611, 0.15195368)
   validation loss 667.6143798828125, (405.39047, 0.53186464, 261.5401, 0.15195368)
decoder loss ratio: 15705.530690, decoder SINDy loss  ratio: 0.564571
--- 0.2556486129760742 seconds for one epoch ---
--- 0.2858753204345703 seconds for one epoch ---
--- 1.595824956893921 seconds for one epoch ---
--- 0.30578017234802246 seconds for one epoch ---
--- 1.616088628768921 seconds for one epoch ---
--- 0.28788113594055176 seconds for one epoch ---
--- 1.6171159744262695 seconds for one epoch ---
--- 0.2892589569091797 seconds for one epoch ---
--- 1.6314847469329834 seconds for one epoch ---
--- 0.3019866943359375 seconds for one epoch ---
--- 1.5964937210083008 seconds for one epoch ---
--- 0.3014793395996094 seconds for one epoch ---
--- 1.6165499687194824 seconds for one epoch ---
--- 0.3014352321624756 seconds for one epoch ---
--- 1.627363681793213 seconds for one epoch ---
--- 0.29901838302612305 seconds for one epoch ---
--- 1.6091601848602295 seconds for one epoch ---
--- 0.28542470932006836 seconds for one epoch ---
--- 1.6198537349700928 seconds for one epoch ---
--- 0.3000204563140869 seconds for one epoch ---
--- 1.6295545101165771 seconds for one epoch ---
--- 0.29478001594543457 seconds for one epoch ---
--- 1.5807044506072998 seconds for one epoch ---
--- 0.28658056259155273 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15439752]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.899469]
 [  0.      ]]
--- 0.27170705795288086 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2627.3955078125, (1608.5979, 1.6042086, 1017.0412, 0.15209334)
   validation loss 741.0009155273438, (480.28116, 0.6168719, 259.95078, 0.15209334)
decoder loss ratio: 18606.925883, decoder SINDy loss  ratio: 0.561140
--- 0.29301977157592773 seconds for one epoch ---
--- 1.645792007446289 seconds for one epoch ---
--- 0.29854345321655273 seconds for one epoch ---
--- 1.6332452297210693 seconds for one epoch ---
--- 0.2973775863647461 seconds for one epoch ---
--- 1.667726993560791 seconds for one epoch ---
--- 0.29094552993774414 seconds for one epoch ---
--- 1.6255857944488525 seconds for one epoch ---
--- 0.29450130462646484 seconds for one epoch ---
--- 1.6347479820251465 seconds for one epoch ---
--- 0.2953455448150635 seconds for one epoch ---
--- 1.6219446659088135 seconds for one epoch ---
--- 0.2961440086364746 seconds for one epoch ---
--- 1.6140623092651367 seconds for one epoch ---
--- 0.3137996196746826 seconds for one epoch ---
--- 1.6500813961029053 seconds for one epoch ---
--- 0.3008589744567871 seconds for one epoch ---
--- 1.6429598331451416 seconds for one epoch ---
--- 0.2986488342285156 seconds for one epoch ---
--- 1.6668660640716553 seconds for one epoch ---
--- 0.29198694229125977 seconds for one epoch ---
--- 1.5693156719207764 seconds for one epoch ---
--- 0.2868483066558838 seconds for one epoch ---
--- 1.6045536994934082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15286836]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.959111]
 [  0.      ]]
--- 0.29414796829223633 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2400.0087890625, (1071.6143, 0.2669309, 1327.9751, 0.15222605)
   validation loss 767.57080078125, (488.334, 0.47579092, 278.6088, 0.15222605)
decoder loss ratio: 18918.907522, decoder SINDy loss  ratio: 0.601416
--- 0.2693369388580322 seconds for one epoch ---
--- 0.30175042152404785 seconds for one epoch ---
--- 1.6524906158447266 seconds for one epoch ---
--- 0.2908914089202881 seconds for one epoch ---
--- 1.6623072624206543 seconds for one epoch ---
--- 0.29158782958984375 seconds for one epoch ---
--- 1.62809419631958 seconds for one epoch ---
--- 0.2825331687927246 seconds for one epoch ---
--- 1.6873321533203125 seconds for one epoch ---
--- 0.30060267448425293 seconds for one epoch ---
--- 1.6292445659637451 seconds for one epoch ---
--- 0.29822683334350586 seconds for one epoch ---
--- 1.6507558822631836 seconds for one epoch ---
--- 0.2917897701263428 seconds for one epoch ---
--- 1.6264500617980957 seconds for one epoch ---
--- 0.3020942211151123 seconds for one epoch ---
--- 1.632620096206665 seconds for one epoch ---
--- 0.2890963554382324 seconds for one epoch ---
--- 1.628563404083252 seconds for one epoch ---
--- 0.29506492614746094 seconds for one epoch ---
--- 1.6553175449371338 seconds for one epoch ---
--- 0.29583239555358887 seconds for one epoch ---
--- 1.5729060173034668 seconds for one epoch ---
--- 0.28913187980651855 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15117393]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.024936]
 [ -0.      ]]
--- 0.27254700660705566 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1679.3369140625, (918.9741, 0.8395178, 759.371, 0.1523708)
   validation loss 983.3355102539062, (689.20105, 0.6795301, 293.3026, 0.1523708)
decoder loss ratio: 26700.845175, decoder SINDy loss  ratio: 0.633135
--- 0.3185844421386719 seconds for one epoch ---
--- 1.703639268875122 seconds for one epoch ---
--- 0.3164849281311035 seconds for one epoch ---
--- 1.674391269683838 seconds for one epoch ---
--- 0.3194148540496826 seconds for one epoch ---
--- 1.6787867546081543 seconds for one epoch ---
--- 0.3334219455718994 seconds for one epoch ---
--- 1.676478385925293 seconds for one epoch ---
--- 0.3329792022705078 seconds for one epoch ---
--- 1.688575267791748 seconds for one epoch ---
--- 0.28147196769714355 seconds for one epoch ---
--- 1.6736657619476318 seconds for one epoch ---
--- 0.28191351890563965 seconds for one epoch ---
--- 1.669053077697754 seconds for one epoch ---
--- 0.2893967628479004 seconds for one epoch ---
--- 1.649850845336914 seconds for one epoch ---
--- 0.2937741279602051 seconds for one epoch ---
--- 1.6814227104187012 seconds for one epoch ---
--- 0.60776686668396 seconds for one epoch ---
--- 1.6967668533325195 seconds for one epoch ---
--- 0.29456043243408203 seconds for one epoch ---
--- 1.6270546913146973 seconds for one epoch ---
--- 0.29764628410339355 seconds for one epoch ---
--- 1.6441853046417236 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14976907]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.079325]
 [ -0.      ]]
--- 0.28537988662719727 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3159.481201171875, (1143.2009, 2.418878, 2013.709, 0.15248746)
   validation loss 836.0201416015625, (579.25037, 0.6452872, 255.97205, 0.15248746)
decoder loss ratio: 22441.164810, decoder SINDy loss  ratio: 0.552552
--- 0.2540771961212158 seconds for one epoch ---
--- 0.3262953758239746 seconds for one epoch ---
--- 1.6541612148284912 seconds for one epoch ---
--- 0.31983375549316406 seconds for one epoch ---
--- 1.655383586883545 seconds for one epoch ---
--- 0.28943967819213867 seconds for one epoch ---
--- 1.6910064220428467 seconds for one epoch ---
--- 0.3032674789428711 seconds for one epoch ---
--- 1.657472848892212 seconds for one epoch ---
--- 0.30103206634521484 seconds for one epoch ---
--- 1.678527593612671 seconds for one epoch ---
--- 0.29027771949768066 seconds for one epoch ---
--- 1.6443736553192139 seconds for one epoch ---
--- 0.30200862884521484 seconds for one epoch ---
--- 1.6601355075836182 seconds for one epoch ---
--- 0.29441165924072266 seconds for one epoch ---
--- 1.658813238143921 seconds for one epoch ---
--- 0.2918860912322998 seconds for one epoch ---
--- 1.6588327884674072 seconds for one epoch ---
--- 0.31062841415405273 seconds for one epoch ---
--- 1.6185405254364014 seconds for one epoch ---
--- 0.290236234664917 seconds for one epoch ---
--- 1.6409270763397217 seconds for one epoch ---
--- 0.28588175773620605 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14832857]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.134929]
 [ -0.      ]]
--- 0.258847713470459 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2546.242919921875, (1317.7412, 0.6293811, 1227.7197, 0.15259497)
   validation loss 869.953125, (601.905, 0.54476607, 267.3508, 0.15259497)
decoder loss ratio: 23318.845788, decoder SINDy loss  ratio: 0.577114
--- 0.29100942611694336 seconds for one epoch ---
--- 1.6596415042877197 seconds for one epoch ---
--- 0.2991347312927246 seconds for one epoch ---
--- 1.6887531280517578 seconds for one epoch ---
--- 0.29091477394104004 seconds for one epoch ---
--- 1.6696522235870361 seconds for one epoch ---
--- 0.30058956146240234 seconds for one epoch ---
--- 1.685875654220581 seconds for one epoch ---
--- 0.3009359836578369 seconds for one epoch ---
--- 1.6621313095092773 seconds for one epoch ---
--- 0.2943742275238037 seconds for one epoch ---
--- 1.6637930870056152 seconds for one epoch ---
--- 0.2955935001373291 seconds for one epoch ---
--- 1.667513370513916 seconds for one epoch ---
--- 0.29645466804504395 seconds for one epoch ---
--- 1.6686875820159912 seconds for one epoch ---
--- 0.29250431060791016 seconds for one epoch ---
--- 1.6875569820404053 seconds for one epoch ---
--- 0.2972116470336914 seconds for one epoch ---
--- 1.68977952003479 seconds for one epoch ---
--- 0.2953674793243408 seconds for one epoch ---
--- 1.6286559104919434 seconds for one epoch ---
--- 0.2895998954772949 seconds for one epoch ---
--- 1.6546003818511963 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1471602]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.179899]
 [ -0.      ]]
--- 0.28966689109802246 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2385.725341796875, (1124.9888, 3.3160944, 1257.268, 0.15268679)
   validation loss 820.3551025390625, (564.7317, 0.73138946, 254.7393, 0.15268679)
decoder loss ratio: 21878.686067, decoder SINDy loss  ratio: 0.549891
THRESHOLDING: 1 active coefficients
--- 0.2672722339630127 seconds for one epoch ---
--- 0.2905089855194092 seconds for one epoch ---
--- 1.6665618419647217 seconds for one epoch ---
--- 0.29626035690307617 seconds for one epoch ---
--- 1.6305527687072754 seconds for one epoch ---
--- 0.28589463233947754 seconds for one epoch ---
--- 1.6263208389282227 seconds for one epoch ---
--- 0.29375696182250977 seconds for one epoch ---
--- 1.640787124633789 seconds for one epoch ---
--- 0.2951505184173584 seconds for one epoch ---
--- 1.7229418754577637 seconds for one epoch ---
--- 0.32093262672424316 seconds for one epoch ---
--- 1.7210884094238281 seconds for one epoch ---
--- 0.33295202255249023 seconds for one epoch ---
--- 1.6929981708526611 seconds for one epoch ---
--- 0.32842183113098145 seconds for one epoch ---
--- 1.6947734355926514 seconds for one epoch ---
--- 0.33611536026000977 seconds for one epoch ---
--- 1.7015750408172607 seconds for one epoch ---
--- 0.3380906581878662 seconds for one epoch ---
--- 1.708709478378296 seconds for one epoch ---
--- 0.34662604331970215 seconds for one epoch ---
--- 1.6981139183044434 seconds for one epoch ---
--- 0.3282132148742676 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14579551]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.232319]
 [ -0.      ]]
--- 0.2625887393951416 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2571.822998046875, (1294.5905, 0.89557654, 1276.1841, 0.15278997)
   validation loss 740.138916015625, (469.84143, 0.59751904, 269.54718, 0.15278997)
decoder loss ratio: 18202.472705, decoder SINDy loss  ratio: 0.581856
--- 0.29395341873168945 seconds for one epoch ---
--- 1.5970699787139893 seconds for one epoch ---
--- 0.29646944999694824 seconds for one epoch ---
--- 1.6577377319335938 seconds for one epoch ---
--- 0.29662036895751953 seconds for one epoch ---
--- 1.6526806354522705 seconds for one epoch ---
--- 0.2898902893066406 seconds for one epoch ---
--- 1.698314905166626 seconds for one epoch ---
--- 0.2981531620025635 seconds for one epoch ---
--- 1.713343858718872 seconds for one epoch ---
--- 0.2938516139984131 seconds for one epoch ---
--- 1.7001831531524658 seconds for one epoch ---
--- 0.28778934478759766 seconds for one epoch ---
--- 1.6815998554229736 seconds for one epoch ---
--- 0.3002331256866455 seconds for one epoch ---
--- 1.7159216403961182 seconds for one epoch ---
--- 0.3198261260986328 seconds for one epoch ---
--- 1.751668930053711 seconds for one epoch ---
--- 0.31079721450805664 seconds for one epoch ---
--- 1.7068712711334229 seconds for one epoch ---
--- 0.29827260971069336 seconds for one epoch ---
--- 1.6964378356933594 seconds for one epoch ---
--- 0.29493021965026855 seconds for one epoch ---
--- 1.7205255031585693 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14463526]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.276792]
 [  0.      ]]
--- 0.29287004470825195 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3800.980712890625, (1406.634, 1.5771139, 2392.6167, 0.1528701)
   validation loss 849.6102905273438, (578.29877, 0.5593228, 270.59933, 0.1528701)
decoder loss ratio: 22404.298208, decoder SINDy loss  ratio: 0.584127
--- 0.25904202461242676 seconds for one epoch ---
--- 0.29021239280700684 seconds for one epoch ---
--- 1.6376769542694092 seconds for one epoch ---
--- 0.29618215560913086 seconds for one epoch ---
--- 1.7164435386657715 seconds for one epoch ---
--- 0.3152737617492676 seconds for one epoch ---
--- 1.7059085369110107 seconds for one epoch ---
--- 0.28784847259521484 seconds for one epoch ---
--- 1.6984517574310303 seconds for one epoch ---
--- 0.29341673851013184 seconds for one epoch ---
--- 1.7009053230285645 seconds for one epoch ---
--- 0.29415130615234375 seconds for one epoch ---
--- 1.7033460140228271 seconds for one epoch ---
--- 0.3094315528869629 seconds for one epoch ---
--- 1.6834526062011719 seconds for one epoch ---
--- 0.2884790897369385 seconds for one epoch ---
--- 1.7170734405517578 seconds for one epoch ---
--- 0.29962825775146484 seconds for one epoch ---
--- 1.7173616886138916 seconds for one epoch ---
--- 0.2954752445220947 seconds for one epoch ---
--- 1.7183895111083984 seconds for one epoch ---
--- 0.2933509349822998 seconds for one epoch ---
--- 1.6633219718933105 seconds for one epoch ---
--- 0.2989637851715088 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1431905]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.332057]
 [  0.      ]]
--- 0.2510042190551758 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2918.555419921875, (1280.2203, 1.8060163, 1636.3759, 0.15297987)
   validation loss 807.965087890625, (518.2092, 0.48613656, 289.11676, 0.15297987)
decoder loss ratio: 20076.325163, decoder SINDy loss  ratio: 0.624099
--- 0.3304879665374756 seconds for one epoch ---
--- 1.7551531791687012 seconds for one epoch ---
--- 0.34337711334228516 seconds for one epoch ---
--- 1.742053747177124 seconds for one epoch ---
--- 0.3415248394012451 seconds for one epoch ---
--- 1.7199549674987793 seconds for one epoch ---
--- 0.33355712890625 seconds for one epoch ---
--- 1.724236011505127 seconds for one epoch ---
--- 0.32080578804016113 seconds for one epoch ---
--- 1.7267909049987793 seconds for one epoch ---
--- 0.3250010013580322 seconds for one epoch ---
--- 1.7482504844665527 seconds for one epoch ---
--- 0.2895066738128662 seconds for one epoch ---
--- 1.742746353149414 seconds for one epoch ---
--- 0.30532050132751465 seconds for one epoch ---
--- 1.7405588626861572 seconds for one epoch ---
--- 0.3057832717895508 seconds for one epoch ---
--- 1.750906229019165 seconds for one epoch ---
--- 0.30303239822387695 seconds for one epoch ---
--- 1.7769253253936768 seconds for one epoch ---
--- 0.3005352020263672 seconds for one epoch ---
--- 1.6984491348266602 seconds for one epoch ---
--- 0.2966189384460449 seconds for one epoch ---
--- 1.704524278640747 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14203672]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.376115]
 [ -0.      ]]
--- 0.3027768135070801 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3102.865478515625, (1784.6553, 1.199046, 1316.858, 0.15305725)
   validation loss 773.216064453125, (509.99295, 0.5343099, 262.5357, 0.15305725)
decoder loss ratio: 19758.012287, decoder SINDy loss  ratio: 0.566720
--- 0.25153422355651855 seconds for one epoch ---
--- 0.29405951499938965 seconds for one epoch ---
--- 1.755312442779541 seconds for one epoch ---
--- 0.3051795959472656 seconds for one epoch ---
--- 1.7487871646881104 seconds for one epoch ---
--- 0.30270910263061523 seconds for one epoch ---
--- 1.7372174263000488 seconds for one epoch ---
--- 0.30062198638916016 seconds for one epoch ---
--- 1.7293658256530762 seconds for one epoch ---
--- 0.29501914978027344 seconds for one epoch ---
--- 1.762866497039795 seconds for one epoch ---
--- 0.30022215843200684 seconds for one epoch ---
--- 1.7540454864501953 seconds for one epoch ---
--- 0.29023289680480957 seconds for one epoch ---
--- 1.7328441143035889 seconds for one epoch ---
--- 0.2973799705505371 seconds for one epoch ---
--- 1.7216153144836426 seconds for one epoch ---
--- 0.29898905754089355 seconds for one epoch ---
--- 1.7539045810699463 seconds for one epoch ---
--- 0.3007066249847412 seconds for one epoch ---
--- 1.7587320804595947 seconds for one epoch ---
--- 0.2859611511230469 seconds for one epoch ---
--- 1.7119495868682861 seconds for one epoch ---
--- 0.2919118404388428 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14107537]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.41278]
 [ -0.     ]]
--- 0.26091766357421875 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2528.486083984375, (996.069, 0.97205937, 1531.2921, 0.15312667)
   validation loss 669.1001586914062, (410.8764, 0.5608011, 257.50986, 0.15312667)
decoder loss ratio: 15918.065196, decoder SINDy loss  ratio: 0.555871
--- 0.31679463386535645 seconds for one epoch ---
--- 1.7291579246520996 seconds for one epoch ---
--- 0.3379819393157959 seconds for one epoch ---
--- 1.7469632625579834 seconds for one epoch ---
--- 0.343397855758667 seconds for one epoch ---
--- 1.7167670726776123 seconds for one epoch ---
--- 0.3292820453643799 seconds for one epoch ---
--- 1.758596420288086 seconds for one epoch ---
--- 0.3252894878387451 seconds for one epoch ---
--- 1.7829363346099854 seconds for one epoch ---
--- 0.2978343963623047 seconds for one epoch ---
--- 1.7505452632904053 seconds for one epoch ---
--- 0.2976517677307129 seconds for one epoch ---
--- 1.754737377166748 seconds for one epoch ---
--- 0.29688310623168945 seconds for one epoch ---
--- 1.756652593612671 seconds for one epoch ---
--- 0.29695868492126465 seconds for one epoch ---
--- 1.7773125171661377 seconds for one epoch ---
--- 0.30347132682800293 seconds for one epoch ---
--- 1.7618658542633057 seconds for one epoch ---
--- 0.28610920906066895 seconds for one epoch ---
--- 1.717456579208374 seconds for one epoch ---
--- 0.2946772575378418 seconds for one epoch ---
--- 1.7345623970031738 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13989389]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.457787]
 [  0.      ]]
--- 0.3006880283355713 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3277.08740234375, (1696.7302, 4.4318485, 1575.7719, 0.15320498)
   validation loss 810.9810180664062, (557.8812, 0.53777987, 252.40883, 0.15320498)
decoder loss ratio: 21613.287204, decoder SINDy loss  ratio: 0.544860
--- 0.26767826080322266 seconds for one epoch ---
--- 0.29761600494384766 seconds for one epoch ---
--- 1.758255958557129 seconds for one epoch ---
--- 0.29697203636169434 seconds for one epoch ---
--- 1.7873249053955078 seconds for one epoch ---
--- 0.2905752658843994 seconds for one epoch ---
--- 1.7547540664672852 seconds for one epoch ---
--- 0.2961905002593994 seconds for one epoch ---
--- 1.7665095329284668 seconds for one epoch ---
--- 0.29167938232421875 seconds for one epoch ---
--- 1.7422699928283691 seconds for one epoch ---
--- 0.29799342155456543 seconds for one epoch ---
--- 1.7444965839385986 seconds for one epoch ---
--- 0.29704737663269043 seconds for one epoch ---
--- 1.7475788593292236 seconds for one epoch ---
--- 0.28756165504455566 seconds for one epoch ---
--- 1.7603833675384521 seconds for one epoch ---
--- 0.29463982582092285 seconds for one epoch ---
--- 1.734412670135498 seconds for one epoch ---
--- 0.30067896842956543 seconds for one epoch ---
--- 1.6942546367645264 seconds for one epoch ---
--- 0.29038023948669434 seconds for one epoch ---
--- 1.6954550743103027 seconds for one epoch ---
--- 0.2976243495941162 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13847655]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.511703]
 [  0.      ]]
--- 0.2637820243835449 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3235.46728515625, (1926.0792, 0.23131847, 1309.0034, 0.15329626)
   validation loss 774.029052734375, (488.23352, 0.54963946, 285.0926, 0.15329626)
decoder loss ratio: 18915.014195, decoder SINDy loss  ratio: 0.615412
--- 0.3144984245300293 seconds for one epoch ---
--- 1.7804725170135498 seconds for one epoch ---
--- 0.32735753059387207 seconds for one epoch ---
--- 1.768622875213623 seconds for one epoch ---
--- 0.3335390090942383 seconds for one epoch ---
--- 1.8097493648529053 seconds for one epoch ---
--- 0.3189535140991211 seconds for one epoch ---
--- 1.792813777923584 seconds for one epoch ---
--- 0.3002970218658447 seconds for one epoch ---
--- 1.7721803188323975 seconds for one epoch ---
--- 0.29807162284851074 seconds for one epoch ---
--- 1.780273675918579 seconds for one epoch ---
--- 0.29264354705810547 seconds for one epoch ---
--- 1.7735333442687988 seconds for one epoch ---
--- 0.2825498580932617 seconds for one epoch ---
--- 1.7880632877349854 seconds for one epoch ---
--- 0.2983849048614502 seconds for one epoch ---
--- 1.8182449340820312 seconds for one epoch ---
--- 0.2845628261566162 seconds for one epoch ---
--- 1.7406384944915771 seconds for one epoch ---
--- 0.2962455749511719 seconds for one epoch ---
--- 1.7329928874969482 seconds for one epoch ---
--- 0.2879314422607422 seconds for one epoch ---
--- 1.7635390758514404 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13741991]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.551857]
 [  0.      ]]
--- 0.2939479351043701 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3087.18798828125, (1290.7634, 0.6485698, 1795.6226, 0.15336232)
   validation loss 767.2041625976562, (511.31927, 0.61115634, 255.12039, 0.15336232)
decoder loss ratio: 19809.396399, decoder SINDy loss  ratio: 0.550713
--- 0.26641011238098145 seconds for one epoch ---
--- 0.29645323753356934 seconds for one epoch ---
--- 1.7947211265563965 seconds for one epoch ---
--- 0.3199582099914551 seconds for one epoch ---
--- 1.8033459186553955 seconds for one epoch ---
--- 0.2995903491973877 seconds for one epoch ---
--- 1.7877867221832275 seconds for one epoch ---
--- 0.2940943241119385 seconds for one epoch ---
--- 1.805981159210205 seconds for one epoch ---
--- 0.2991776466369629 seconds for one epoch ---
--- 1.8060777187347412 seconds for one epoch ---
--- 0.2955920696258545 seconds for one epoch ---
--- 1.792083501815796 seconds for one epoch ---
--- 0.29485201835632324 seconds for one epoch ---
--- 1.8074800968170166 seconds for one epoch ---
--- 0.2998645305633545 seconds for one epoch ---
--- 1.8005561828613281 seconds for one epoch ---
--- 0.2937619686126709 seconds for one epoch ---
--- 1.7676091194152832 seconds for one epoch ---
--- 0.29700636863708496 seconds for one epoch ---
--- 1.7557590007781982 seconds for one epoch ---
--- 0.2974419593811035 seconds for one epoch ---
--- 1.7781882286071777 seconds for one epoch ---
--- 0.29296302795410156 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13620508]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.597993]
 [  0.      ]]
--- 0.2507333755493164 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5064.69140625, (2258.2258, 1.0132945, 2805.2993, 0.15344167)
   validation loss 963.1485595703125, (660.55896, 0.63136035, 301.80484, 0.15344167)
decoder loss ratio: 25591.200890, decoder SINDy loss  ratio: 0.651488
--- 0.29541492462158203 seconds for one epoch ---
--- 1.782557487487793 seconds for one epoch ---
--- 0.2917943000793457 seconds for one epoch ---
--- 1.7845091819763184 seconds for one epoch ---
--- 0.2929964065551758 seconds for one epoch ---
--- 1.786757469177246 seconds for one epoch ---
--- 0.29813218116760254 seconds for one epoch ---
--- 1.7759251594543457 seconds for one epoch ---
--- 0.30188417434692383 seconds for one epoch ---
--- 1.757688045501709 seconds for one epoch ---
--- 0.29520392417907715 seconds for one epoch ---
--- 1.7830286026000977 seconds for one epoch ---
--- 0.2934722900390625 seconds for one epoch ---
--- 1.78446364402771 seconds for one epoch ---
--- 0.300504207611084 seconds for one epoch ---
--- 1.7942206859588623 seconds for one epoch ---
--- 0.3009021282196045 seconds for one epoch ---
--- 1.7199101448059082 seconds for one epoch ---
--- 0.29067564010620117 seconds for one epoch ---
--- 1.762481927871704 seconds for one epoch ---
--- 0.29451942443847656 seconds for one epoch ---
--- 1.7387793064117432 seconds for one epoch ---
--- 0.2939126491546631 seconds for one epoch ---
--- 1.7599828243255615 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13521422]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.635597]
 [ -0.      ]]
--- 0.33708977699279785 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3029.385986328125, (1016.17255, 0.89715654, 2012.1626, 0.15350285)
   validation loss 691.4293823242188, (425.44067, 0.644241, 265.19098, 0.15350285)
decoder loss ratio: 16482.310302, decoder SINDy loss  ratio: 0.572452
--- 0.28470587730407715 seconds for one epoch ---
--- 0.31152915954589844 seconds for one epoch ---
--- 1.7967405319213867 seconds for one epoch ---
--- 0.3335433006286621 seconds for one epoch ---
--- 1.7919425964355469 seconds for one epoch ---
--- 0.33791637420654297 seconds for one epoch ---
--- 1.8218863010406494 seconds for one epoch ---
--- 0.3013138771057129 seconds for one epoch ---
--- 1.781480073928833 seconds for one epoch ---
--- 0.30161118507385254 seconds for one epoch ---
--- 1.8298346996307373 seconds for one epoch ---
--- 0.30362606048583984 seconds for one epoch ---
--- 1.8209075927734375 seconds for one epoch ---
--- 0.29530882835388184 seconds for one epoch ---
--- 1.814542531967163 seconds for one epoch ---
--- 0.3003056049346924 seconds for one epoch ---
--- 1.8421101570129395 seconds for one epoch ---
--- 0.28734326362609863 seconds for one epoch ---
--- 1.7736835479736328 seconds for one epoch ---
--- 0.29317736625671387 seconds for one epoch ---
--- 1.7950677871704102 seconds for one epoch ---
--- 0.29561781883239746 seconds for one epoch ---
--- 1.7862062454223633 seconds for one epoch ---
--- 0.2858595848083496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13407479]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.678815]
 [ -0.      ]]
--- 0.2619636058807373 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2687.713623046875, (1249.3619, 0.30632567, 1437.892, 0.1535676)
   validation loss 776.4761962890625, (512.5518, 0.5747038, 263.19608, 0.1535676)
decoder loss ratio: 19857.147291, decoder SINDy loss  ratio: 0.568146
--- 0.29561758041381836 seconds for one epoch ---
--- 1.8252532482147217 seconds for one epoch ---
--- 0.29842233657836914 seconds for one epoch ---
--- 1.8061292171478271 seconds for one epoch ---
--- 0.29987287521362305 seconds for one epoch ---
--- 1.81209397315979 seconds for one epoch ---
--- 0.2740814685821533 seconds for one epoch ---
--- 1.8122594356536865 seconds for one epoch ---
--- 0.2946147918701172 seconds for one epoch ---
--- 1.8263232707977295 seconds for one epoch ---
--- 0.2975764274597168 seconds for one epoch ---
--- 1.8079028129577637 seconds for one epoch ---
--- 0.30686140060424805 seconds for one epoch ---
--- 1.8260385990142822 seconds for one epoch ---
--- 0.30500030517578125 seconds for one epoch ---
--- 1.8431932926177979 seconds for one epoch ---
--- 0.3020467758178711 seconds for one epoch ---
--- 1.757045030593872 seconds for one epoch ---
--- 0.28952932357788086 seconds for one epoch ---
--- 1.793881893157959 seconds for one epoch ---
--- 0.2933628559112549 seconds for one epoch ---
--- 1.7712657451629639 seconds for one epoch ---
--- 0.29277515411376953 seconds for one epoch ---
--- 1.8258178234100342 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1330792]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.71655]
 [ -0.     ]]
--- 0.3040199279785156 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3454.570068359375, (1219.7246, 3.843939, 2230.848, 0.15362738)
   validation loss 760.8369140625, (493.022, 0.5867726, 267.07452, 0.15362738)
decoder loss ratio: 19100.528327, decoder SINDy loss  ratio: 0.576518
--- 0.26988887786865234 seconds for one epoch ---
--- 0.29694414138793945 seconds for one epoch ---
--- 1.8217835426330566 seconds for one epoch ---
--- 0.29532527923583984 seconds for one epoch ---
--- 1.8070485591888428 seconds for one epoch ---
--- 0.29732704162597656 seconds for one epoch ---
--- 1.8207688331604004 seconds for one epoch ---
--- 0.30544304847717285 seconds for one epoch ---
--- 1.8143293857574463 seconds for one epoch ---
--- 0.2978990077972412 seconds for one epoch ---
--- 1.827106237411499 seconds for one epoch ---
--- 0.29103589057922363 seconds for one epoch ---
--- 1.7971317768096924 seconds for one epoch ---
--- 0.30121898651123047 seconds for one epoch ---
--- 1.8243443965911865 seconds for one epoch ---
--- 0.29660558700561523 seconds for one epoch ---
--- 1.850437879562378 seconds for one epoch ---
--- 0.30188798904418945 seconds for one epoch ---
--- 1.7623934745788574 seconds for one epoch ---
--- 0.2922985553741455 seconds for one epoch ---
--- 1.7929739952087402 seconds for one epoch ---
--- 0.28882265090942383 seconds for one epoch ---
--- 1.7948665618896484 seconds for one epoch ---
--- 0.3000760078430176 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.132055]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.755371]
 [ -0.      ]]
--- 0.26879119873046875 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5485.05810546875, (1330.4471, 0.49517742, 4153.962, 0.15368848)
   validation loss 1051.4110107421875, (758.0823, 0.81654197, 292.35846, 0.15368848)
decoder loss ratio: 29369.423437, decoder SINDy loss  ratio: 0.631097
--- 0.2946634292602539 seconds for one epoch ---
--- 1.8531701564788818 seconds for one epoch ---
--- 0.3010125160217285 seconds for one epoch ---
--- 1.854963779449463 seconds for one epoch ---
--- 0.292447566986084 seconds for one epoch ---
--- 1.8487629890441895 seconds for one epoch ---
--- 0.2938807010650635 seconds for one epoch ---
--- 1.8412718772888184 seconds for one epoch ---
--- 0.30162906646728516 seconds for one epoch ---
--- 1.8501791954040527 seconds for one epoch ---
--- 0.29085350036621094 seconds for one epoch ---
--- 1.849289894104004 seconds for one epoch ---
--- 0.2928898334503174 seconds for one epoch ---
--- 1.8489723205566406 seconds for one epoch ---
--- 0.29805827140808105 seconds for one epoch ---
--- 1.8696916103363037 seconds for one epoch ---
--- 0.2978675365447998 seconds for one epoch ---
--- 1.8326940536499023 seconds for one epoch ---
--- 0.2912609577178955 seconds for one epoch ---
--- 1.8179371356964111 seconds for one epoch ---
--- 0.2885317802429199 seconds for one epoch ---
--- 1.8227660655975342 seconds for one epoch ---
--- 0.28670763969421387 seconds for one epoch ---
--- 1.8412351608276367 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13097322]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.796364]
 [ -0.      ]]
--- 0.2983219623565674 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2021.00244140625, (1052.5894, 1.1128552, 967.14636, 0.1537478)
   validation loss 768.9216918945312, (505.4966, 0.7649291, 262.50644, 0.1537478)
decoder loss ratio: 19583.816351, decoder SINDy loss  ratio: 0.566657
--- 0.25058960914611816 seconds for one epoch ---
--- 0.30765819549560547 seconds for one epoch ---
--- 1.8414897918701172 seconds for one epoch ---
--- 0.2819201946258545 seconds for one epoch ---
--- 1.826343059539795 seconds for one epoch ---
--- 0.29263782501220703 seconds for one epoch ---
--- 1.8195061683654785 seconds for one epoch ---
--- 0.29671692848205566 seconds for one epoch ---
--- 1.8345308303833008 seconds for one epoch ---
--- 0.2741577625274658 seconds for one epoch ---
--- 1.8253955841064453 seconds for one epoch ---
--- 0.2904183864593506 seconds for one epoch ---
--- 1.8220407962799072 seconds for one epoch ---
--- 0.29575300216674805 seconds for one epoch ---
--- 1.8248639106750488 seconds for one epoch ---
--- 0.2932286262512207 seconds for one epoch ---
--- 1.8536875247955322 seconds for one epoch ---
--- 0.28995227813720703 seconds for one epoch ---
--- 1.8309917449951172 seconds for one epoch ---
--- 0.2867465019226074 seconds for one epoch ---
--- 1.8089079856872559 seconds for one epoch ---
--- 0.29166412353515625 seconds for one epoch ---
--- 1.7859375476837158 seconds for one epoch ---
--- 0.3002908229827881 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12995379]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.834994]
 [  0.      ]]
--- 0.2535867691040039 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1748.09716796875, (976.1096, 2.3358724, 769.4979, 0.15380786)
   validation loss 1211.763916015625, (904.35876, 0.6441648, 306.60724, 0.15380786)
decoder loss ratio: 35036.428578, decoder SINDy loss  ratio: 0.661855
--- 0.28670597076416016 seconds for one epoch ---
--- 1.8791861534118652 seconds for one epoch ---
--- 0.2977030277252197 seconds for one epoch ---
--- 1.8668293952941895 seconds for one epoch ---
--- 0.2920722961425781 seconds for one epoch ---
--- 1.876465082168579 seconds for one epoch ---
--- 0.2955608367919922 seconds for one epoch ---
--- 1.8640713691711426 seconds for one epoch ---
--- 0.29529905319213867 seconds for one epoch ---
--- 1.872382402420044 seconds for one epoch ---
--- 0.29976344108581543 seconds for one epoch ---
--- 1.8701753616333008 seconds for one epoch ---
--- 0.2993912696838379 seconds for one epoch ---
--- 1.8784828186035156 seconds for one epoch ---
--- 0.3007645606994629 seconds for one epoch ---
--- 1.89707350730896 seconds for one epoch ---
--- 0.29401278495788574 seconds for one epoch ---
--- 1.827845573425293 seconds for one epoch ---
--- 0.2979156970977783 seconds for one epoch ---
--- 1.8439817428588867 seconds for one epoch ---
--- 0.2971181869506836 seconds for one epoch ---
--- 1.849226474761963 seconds for one epoch ---
--- 0.2971968650817871 seconds for one epoch ---
--- 1.8255088329315186 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12890396]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.874772]
 [  0.      ]]
--- 0.29850316047668457 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2804.5244140625, (1363.4108, 0.7775459, 1440.1821, 0.15386663)
   validation loss 988.4953002929688, (701.3642, 0.78381395, 286.1934, 0.15386663)
decoder loss ratio: 27172.066605, decoder SINDy loss  ratio: 0.617789
--- 0.2704014778137207 seconds for one epoch ---
--- 0.2947225570678711 seconds for one epoch ---
--- 1.8840255737304688 seconds for one epoch ---
--- 0.2968313694000244 seconds for one epoch ---
--- 1.8773565292358398 seconds for one epoch ---
--- 0.29233741760253906 seconds for one epoch ---
--- 1.8896033763885498 seconds for one epoch ---
--- 0.2927675247192383 seconds for one epoch ---
--- 1.8496017456054688 seconds for one epoch ---
--- 0.3033018112182617 seconds for one epoch ---
--- 1.9082551002502441 seconds for one epoch ---
--- 0.27956533432006836 seconds for one epoch ---
--- 1.8906686305999756 seconds for one epoch ---
--- 0.3009934425354004 seconds for one epoch ---
--- 1.9083366394042969 seconds for one epoch ---
--- 0.29460716247558594 seconds for one epoch ---
--- 1.8349835872650146 seconds for one epoch ---
--- 0.29097914695739746 seconds for one epoch ---
--- 1.8402106761932373 seconds for one epoch ---
--- 0.28882503509521484 seconds for one epoch ---
--- 1.8490307331085205 seconds for one epoch ---
--- 0.29639625549316406 seconds for one epoch ---
--- 1.868189811706543 seconds for one epoch ---
--- 0.2886836528778076 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12780891]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.916282]
 [ -0.      ]]
--- 0.26087164878845215 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3407.68359375, (1379.4999, 1.3875091, 2026.6423, 0.15392396)
   validation loss 1431.0526123046875, (1122.6683, 0.73003393, 307.5004, 0.15392396)
decoder loss ratio: 43494.120334, decoder SINDy loss  ratio: 0.663783
--- 0.297940731048584 seconds for one epoch ---
--- 1.921555995941162 seconds for one epoch ---
--- 0.29720211029052734 seconds for one epoch ---
--- 1.8682520389556885 seconds for one epoch ---
--- 0.3002455234527588 seconds for one epoch ---
--- 1.8798117637634277 seconds for one epoch ---
--- 0.29883480072021484 seconds for one epoch ---
--- 1.862572431564331 seconds for one epoch ---
--- 0.2939443588256836 seconds for one epoch ---
--- 1.8734626770019531 seconds for one epoch ---
--- 0.2894296646118164 seconds for one epoch ---
--- 1.8702430725097656 seconds for one epoch ---
--- 0.29940342903137207 seconds for one epoch ---
--- 1.8944203853607178 seconds for one epoch ---
--- 0.2944512367248535 seconds for one epoch ---
--- 1.8380670547485352 seconds for one epoch ---
--- 0.2980377674102783 seconds for one epoch ---
--- 1.8497810363769531 seconds for one epoch ---
--- 0.2895975112915039 seconds for one epoch ---
--- 1.8136374950408936 seconds for one epoch ---
--- 0.2949821949005127 seconds for one epoch ---
--- 1.8297615051269531 seconds for one epoch ---
--- 0.28603696823120117 seconds for one epoch ---
--- 1.9012644290924072 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1268038]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.954398]
 [ -0.      ]]
--- 0.2946755886077881 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9634.037109375, (2051.4707, 22.593052, 7559.819, 0.15397668)
   validation loss 787.2409057617188, (518.1216, 0.7256891, 268.23962, 0.15397668)
decoder loss ratio: 20072.929587, decoder SINDy loss  ratio: 0.579033
--- 0.25362563133239746 seconds for one epoch ---
--- 0.29399657249450684 seconds for one epoch ---
--- 1.9074394702911377 seconds for one epoch ---
--- 0.29127073287963867 seconds for one epoch ---
--- 1.9265127182006836 seconds for one epoch ---
--- 0.3000638484954834 seconds for one epoch ---
--- 1.9165863990783691 seconds for one epoch ---
--- 0.2993025779724121 seconds for one epoch ---
--- 1.9147632122039795 seconds for one epoch ---
--- 0.2992897033691406 seconds for one epoch ---
--- 1.9041333198547363 seconds for one epoch ---
--- 0.29668354988098145 seconds for one epoch ---
--- 1.9121434688568115 seconds for one epoch ---
--- 0.3053750991821289 seconds for one epoch ---
--- 1.9127600193023682 seconds for one epoch ---
--- 0.29079723358154297 seconds for one epoch ---
--- 1.8848741054534912 seconds for one epoch ---
--- 0.29538559913635254 seconds for one epoch ---
--- 1.8824231624603271 seconds for one epoch ---
--- 0.2870187759399414 seconds for one epoch ---
--- 1.870359182357788 seconds for one epoch ---
--- 0.28193140029907227 seconds for one epoch ---
--- 1.9169447422027588 seconds for one epoch ---
--- 0.29315829277038574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12604406]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.983194]
 [  0.      ]]
--- 0.24187660217285156 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2514.624755859375, (915.7774, 1.6446393, 1597.0487, 0.15401937)
   validation loss 753.4277954101562, (487.2684, 0.64464, 265.36072, 0.15401937)
decoder loss ratio: 18877.623832, decoder SINDy loss  ratio: 0.572818
--- 0.28583264350891113 seconds for one epoch ---
--- 1.9247832298278809 seconds for one epoch ---
--- 0.2888209819793701 seconds for one epoch ---
--- 1.9211788177490234 seconds for one epoch ---
--- 0.2909212112426758 seconds for one epoch ---
--- 1.9115097522735596 seconds for one epoch ---
--- 0.2925879955291748 seconds for one epoch ---
--- 1.9200506210327148 seconds for one epoch ---
--- 0.29816341400146484 seconds for one epoch ---
--- 1.9446148872375488 seconds for one epoch ---
--- 0.2862892150878906 seconds for one epoch ---
--- 1.9317903518676758 seconds for one epoch ---
--- 0.303239107131958 seconds for one epoch ---
--- 1.8881895542144775 seconds for one epoch ---
--- 0.2885255813598633 seconds for one epoch ---
--- 1.8658757209777832 seconds for one epoch ---
--- 0.2927379608154297 seconds for one epoch ---
--- 1.8652267456054688 seconds for one epoch ---
--- 0.2910490036010742 seconds for one epoch ---
--- 1.8576688766479492 seconds for one epoch ---
--- 0.29689693450927734 seconds for one epoch ---
--- 1.8895864486694336 seconds for one epoch ---
--- 0.2959885597229004 seconds for one epoch ---
--- 1.9069619178771973 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12521195]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.014788]
 [  0.      ]]
--- 0.2972571849822998 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1804.2060546875, (901.23474, 0.44045293, 902.37683, 0.15406127)
   validation loss 920.4224853515625, (633.16046, 0.72069484, 286.38727, 0.15406127)
decoder loss ratio: 24529.735491, decoder SINDy loss  ratio: 0.618207
THRESHOLDING: 1 active coefficients
--- 1.898097038269043 seconds for one epoch ---
--- 0.2990148067474365 seconds for one epoch ---
--- 1.9210946559906006 seconds for one epoch ---
--- 0.29515576362609863 seconds for one epoch ---
--- 1.926002025604248 seconds for one epoch ---
--- 0.2983436584472656 seconds for one epoch ---
--- 1.9203946590423584 seconds for one epoch ---
--- 0.2950427532196045 seconds for one epoch ---
--- 1.9391143321990967 seconds for one epoch ---
--- 0.29482007026672363 seconds for one epoch ---
--- 1.9235591888427734 seconds for one epoch ---
--- 0.2928340435028076 seconds for one epoch ---
--- 1.9345052242279053 seconds for one epoch ---
--- 0.295393705368042 seconds for one epoch ---
--- 1.9234678745269775 seconds for one epoch ---
--- 0.28704190254211426 seconds for one epoch ---
--- 1.9294543266296387 seconds for one epoch ---
--- 0.29610610008239746 seconds for one epoch ---
--- 1.952927827835083 seconds for one epoch ---
--- 0.29053783416748047 seconds for one epoch ---
--- 1.9652204513549805 seconds for one epoch ---
--- 0.2924652099609375 seconds for one epoch ---
--- 1.9671952724456787 seconds for one epoch ---
--- 0.29537081718444824 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12446827]
 [0.        ]]
[[ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [  0.   ]
 [  0.   ]
 [ -0.   ]
 [  0.   ]
 [ -0.   ]
 [ -0.   ]
 [-16.043]
 [  0.   ]]
--- 0.25372886657714844 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3388.7001953125, (1310.4236, 5.814977, 2072.3076, 0.15409993)
   validation loss 757.6154174804688, (496.05618, 0.71840495, 260.6867, 0.15409993)
decoder loss ratio: 19218.077715, decoder SINDy loss  ratio: 0.562729
--- 0.29093384742736816 seconds for one epoch ---
--- 1.941887378692627 seconds for one epoch ---
--- 0.31049060821533203 seconds for one epoch ---
--- 1.9355733394622803 seconds for one epoch ---
--- 0.30406999588012695 seconds for one epoch ---
--- 1.9447886943817139 seconds for one epoch ---
--- 0.30298590660095215 seconds for one epoch ---
--- 1.9819777011871338 seconds for one epoch ---
--- 0.3214554786682129 seconds for one epoch ---
--- 1.9640226364135742 seconds for one epoch ---
--- 0.31659388542175293 seconds for one epoch ---
--- 1.9658501148223877 seconds for one epoch ---
--- 0.33661770820617676 seconds for one epoch ---
--- 1.9964451789855957 seconds for one epoch ---
--- 0.3208620548248291 seconds for one epoch ---
--- 1.9691972732543945 seconds for one epoch ---
--- 0.3163003921508789 seconds for one epoch ---
--- 1.95871901512146 seconds for one epoch ---
--- 0.3265058994293213 seconds for one epoch ---
--- 1.973923683166504 seconds for one epoch ---
--- 0.2936060428619385 seconds for one epoch ---
--- 1.9843864440917969 seconds for one epoch ---
--- 0.2991204261779785 seconds for one epoch ---
--- 1.9659786224365234 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1236821]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.072847]
 [  0.      ]]
--- 0.2934298515319824 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9692.7177734375, (1047.7803, 2.5021136, 8642.281, 0.15414058)
   validation loss 1120.5599365234375, (805.1893, 0.49411982, 314.72238, 0.15414058)
decoder loss ratio: 31194.430191, decoder SINDy loss  ratio: 0.679373
--- 0.2581613063812256 seconds for one epoch ---
--- 0.3039112091064453 seconds for one epoch ---
--- 1.9725399017333984 seconds for one epoch ---
--- 0.3035447597503662 seconds for one epoch ---
--- 1.9698455333709717 seconds for one epoch ---
--- 0.29756760597229004 seconds for one epoch ---
--- 2.0056307315826416 seconds for one epoch ---
--- 0.29865121841430664 seconds for one epoch ---
--- 1.9765207767486572 seconds for one epoch ---
--- 0.2978041172027588 seconds for one epoch ---
--- 1.9828765392303467 seconds for one epoch ---
--- 0.30061936378479004 seconds for one epoch ---
--- 1.9157111644744873 seconds for one epoch ---
--- 0.2983078956604004 seconds for one epoch ---
--- 1.9240500926971436 seconds for one epoch ---
--- 0.29256606101989746 seconds for one epoch ---
--- 1.9236202239990234 seconds for one epoch ---
--- 0.2943720817565918 seconds for one epoch ---
--- 1.9278509616851807 seconds for one epoch ---
--- 0.2928647994995117 seconds for one epoch ---
--- 1.9946365356445312 seconds for one epoch ---
--- 0.2977914810180664 seconds for one epoch ---
--- 1.9704666137695312 seconds for one epoch ---
--- 0.3289163112640381 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12300952]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.098404]
 [ -0.      ]]
--- 0.2518460750579834 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4815.3984375, (1701.9891, 0.6700022, 3112.5852, 0.15417491)
   validation loss 727.6448974609375, (455.97864, 0.63652086, 270.87558, 0.15417491)
decoder loss ratio: 17665.404038, decoder SINDy loss  ratio: 0.584723
--- 0.29654383659362793 seconds for one epoch ---
--- 1.975562334060669 seconds for one epoch ---
--- 0.29043149948120117 seconds for one epoch ---
--- 1.9719254970550537 seconds for one epoch ---
--- 0.2976233959197998 seconds for one epoch ---
--- 1.9742190837860107 seconds for one epoch ---
--- 0.29714226722717285 seconds for one epoch ---
--- 1.9725921154022217 seconds for one epoch ---
--- 0.3124377727508545 seconds for one epoch ---
--- 1.993238925933838 seconds for one epoch ---
--- 0.31287121772766113 seconds for one epoch ---
--- 1.9300956726074219 seconds for one epoch ---
--- 0.307297945022583 seconds for one epoch ---
--- 1.9417238235473633 seconds for one epoch ---
--- 0.2967369556427002 seconds for one epoch ---
--- 1.9253458976745605 seconds for one epoch ---
--- 0.2928004264831543 seconds for one epoch ---
--- 1.9578630924224854 seconds for one epoch ---
--- 0.31092357635498047 seconds for one epoch ---
--- 1.9630305767059326 seconds for one epoch ---
--- 0.292583703994751 seconds for one epoch ---
--- 1.9665546417236328 seconds for one epoch ---
--- 0.28967714309692383 seconds for one epoch ---
--- 1.9652657508850098 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1219467]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.138807]
 [ -0.      ]]
--- 0.2916417121887207 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2195.413818359375, (1194.7646, 0.22854473, 1000.2663, 0.15422523)
   validation loss 822.9239501953125, (550.4532, 0.61882997, 271.6977, 0.15422523)
decoder loss ratio: 21325.512056, decoder SINDy loss  ratio: 0.586498
--- 0.2609410285949707 seconds for one epoch ---
--- 0.3035390377044678 seconds for one epoch ---
--- 1.9972670078277588 seconds for one epoch ---
--- 0.30997586250305176 seconds for one epoch ---
--- 1.9543883800506592 seconds for one epoch ---
--- 0.3005492687225342 seconds for one epoch ---
--- 1.9832782745361328 seconds for one epoch ---
--- 0.31351494789123535 seconds for one epoch ---
--- 1.9840948581695557 seconds for one epoch ---
--- 0.2934715747833252 seconds for one epoch ---
--- 2.0091097354888916 seconds for one epoch ---
--- 0.2947733402252197 seconds for one epoch ---
--- 1.9378812313079834 seconds for one epoch ---
--- 0.2980160713195801 seconds for one epoch ---
--- 1.9239673614501953 seconds for one epoch ---
--- 0.29642367362976074 seconds for one epoch ---
--- 1.9433562755584717 seconds for one epoch ---
--- 0.29113173484802246 seconds for one epoch ---
--- 1.955658197402954 seconds for one epoch ---
--- 0.2925875186920166 seconds for one epoch ---
--- 1.976365089416504 seconds for one epoch ---
--- 0.30106258392333984 seconds for one epoch ---
--- 2.0011606216430664 seconds for one epoch ---
--- 0.326946496963501 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12127753]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.164274]
 [ -0.      ]]
--- 0.26314783096313477 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4593.5732421875, (1794.4521, 3.708793, 2795.2578, 0.15426004)
   validation loss 931.3810424804688, (622.67914, 0.721941, 307.82578, 0.15426004)
decoder loss ratio: 24123.670832, decoder SINDy loss  ratio: 0.664485
--- 0.28206372261047363 seconds for one epoch ---
--- 2.018735408782959 seconds for one epoch ---
--- 0.2963130474090576 seconds for one epoch ---
--- 2.0107650756835938 seconds for one epoch ---
--- 0.2952868938446045 seconds for one epoch ---
--- 2.011279344558716 seconds for one epoch ---
--- 0.3151073455810547 seconds for one epoch ---
--- 2.0087661743164062 seconds for one epoch ---
--- 0.30031776428222656 seconds for one epoch ---
--- 2.04524302482605 seconds for one epoch ---
--- 0.2928023338317871 seconds for one epoch ---
--- 1.9879398345947266 seconds for one epoch ---
--- 0.28697776794433594 seconds for one epoch ---
--- 1.9866056442260742 seconds for one epoch ---
--- 0.29391956329345703 seconds for one epoch ---
--- 1.969825029373169 seconds for one epoch ---
--- 0.30078673362731934 seconds for one epoch ---
--- 1.9895617961883545 seconds for one epoch ---
--- 0.28159213066101074 seconds for one epoch ---
--- 2.0162265300750732 seconds for one epoch ---
--- 0.30185937881469727 seconds for one epoch ---
--- 2.0218074321746826 seconds for one epoch ---
--- 0.284285306930542 seconds for one epoch ---
--- 2.000730276107788 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12041484]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.19711]
 [ -0.     ]]
--- 0.29464268684387207 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3836.53955078125, (1347.5575, 1.7712008, 2487.0566, 0.15430161)
   validation loss 826.2240600585938, (542.7551, 0.7252929, 282.58936, 0.15430161)
decoder loss ratio: 21027.275883, decoder SINDy loss  ratio: 0.610009
--- 0.25902390480041504 seconds for one epoch ---
--- 0.2914144992828369 seconds for one epoch ---
--- 2.039680004119873 seconds for one epoch ---
--- 0.2981739044189453 seconds for one epoch ---
--- 2.0280723571777344 seconds for one epoch ---
--- 0.2972393035888672 seconds for one epoch ---
--- 2.0209388732910156 seconds for one epoch ---
--- 0.29120397567749023 seconds for one epoch ---
--- 2.036865711212158 seconds for one epoch ---
--- 0.29872655868530273 seconds for one epoch ---
--- 2.015589714050293 seconds for one epoch ---
--- 0.2947957515716553 seconds for one epoch ---
--- 1.976759672164917 seconds for one epoch ---
--- 0.29400634765625 seconds for one epoch ---
--- 2.002246618270874 seconds for one epoch ---
--- 0.3040022850036621 seconds for one epoch ---
--- 1.980119228363037 seconds for one epoch ---
--- 0.300325870513916 seconds for one epoch ---
--- 2.0170180797576904 seconds for one epoch ---
--- 0.30371594429016113 seconds for one epoch ---
--- 2.033189535140991 seconds for one epoch ---
--- 0.29723548889160156 seconds for one epoch ---
--- 2.0503058433532715 seconds for one epoch ---
--- 0.3000025749206543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11952668]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.230959]
 [ -0.      ]]
--- 0.2578854560852051 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3743.6396484375, (1454.0529, 2.2150602, 2287.2175, 0.15434574)
   validation loss 865.4534301757812, (555.18256, 0.746184, 309.37033, 0.15434574)
decoder loss ratio: 21508.736065, decoder SINDy loss  ratio: 0.667819
--- 0.29387331008911133 seconds for one epoch ---
--- 2.0039515495300293 seconds for one epoch ---
--- 0.298206090927124 seconds for one epoch ---
--- 2.033332347869873 seconds for one epoch ---
--- 0.29630303382873535 seconds for one epoch ---
--- 2.0167276859283447 seconds for one epoch ---
--- 0.3005855083465576 seconds for one epoch ---
--- 2.0496182441711426 seconds for one epoch ---
--- 0.3028087615966797 seconds for one epoch ---
--- 2.004708766937256 seconds for one epoch ---
--- 0.2982470989227295 seconds for one epoch ---
--- 1.992516279220581 seconds for one epoch ---
--- 0.286090612411499 seconds for one epoch ---
--- 1.9768671989440918 seconds for one epoch ---
--- 0.2955598831176758 seconds for one epoch ---
--- 2.00201678276062 seconds for one epoch ---
--- 0.29221034049987793 seconds for one epoch ---
--- 2.006143093109131 seconds for one epoch ---
--- 0.29358553886413574 seconds for one epoch ---
--- 2.0574800968170166 seconds for one epoch ---
--- 0.2896232604980469 seconds for one epoch ---
--- 2.0594418048858643 seconds for one epoch ---
--- 0.31241440773010254 seconds for one epoch ---
--- 2.0347392559051514 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11879297]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.258945]
 [  0.      ]]
--- 0.30388879776000977 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2654.348388671875, (935.46173, 1.75961, 1716.9728, 0.15437858)
   validation loss 800.4221801757812, (509.29178, 0.69969034, 290.27634, 0.15437858)
decoder loss ratio: 19730.847671, decoder SINDy loss  ratio: 0.626602
--- 0.26834845542907715 seconds for one epoch ---
--- 0.3035862445831299 seconds for one epoch ---
--- 2.040431499481201 seconds for one epoch ---
--- 0.30349302291870117 seconds for one epoch ---
--- 2.0256237983703613 seconds for one epoch ---
--- 0.3029782772064209 seconds for one epoch ---
--- 2.065538167953491 seconds for one epoch ---
--- 0.3024711608886719 seconds for one epoch ---
--- 2.033001661300659 seconds for one epoch ---
--- 0.29115986824035645 seconds for one epoch ---
--- 2.000101089477539 seconds for one epoch ---
--- 0.297900915145874 seconds for one epoch ---
--- 1.98860502243042 seconds for one epoch ---
--- 0.30004358291625977 seconds for one epoch ---
--- 2.009202003479004 seconds for one epoch ---
--- 0.2932145595550537 seconds for one epoch ---
--- 2.0175273418426514 seconds for one epoch ---
--- 0.3100881576538086 seconds for one epoch ---
--- 2.0775904655456543 seconds for one epoch ---
--- 0.29210805892944336 seconds for one epoch ---
--- 2.0426025390625 seconds for one epoch ---
--- 0.32935237884521484 seconds for one epoch ---
--- 2.03930926322937 seconds for one epoch ---
--- 0.3321259021759033 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11815503]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.283289]
 [  0.      ]]
--- 0.26082396507263184 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3680.610595703125, (1538.5593, 2.0004916, 2139.8965, 0.1544137)
   validation loss 744.179443359375, (470.6788, 0.58958495, 272.7566, 0.1544137)
decoder loss ratio: 18234.913943, decoder SINDy loss  ratio: 0.588783
--- 0.29245710372924805 seconds for one epoch ---
--- 2.0491626262664795 seconds for one epoch ---
--- 0.3073916435241699 seconds for one epoch ---
--- 2.04500412940979 seconds for one epoch ---
--- 0.2901885509490967 seconds for one epoch ---
--- 2.056210994720459 seconds for one epoch ---
--- 0.2953522205352783 seconds for one epoch ---
--- 2.062155246734619 seconds for one epoch ---
--- 0.29903411865234375 seconds for one epoch ---
--- 1.9845807552337646 seconds for one epoch ---
--- 0.29855775833129883 seconds for one epoch ---
--- 1.9993455410003662 seconds for one epoch ---
--- 0.30471110343933105 seconds for one epoch ---
--- 2.022681474685669 seconds for one epoch ---
--- 0.29225897789001465 seconds for one epoch ---
--- 2.0252034664154053 seconds for one epoch ---
--- 0.2819385528564453 seconds for one epoch ---
--- 2.036142587661743 seconds for one epoch ---
--- 0.2939133644104004 seconds for one epoch ---
--- 2.0583016872406006 seconds for one epoch ---
--- 0.2950735092163086 seconds for one epoch ---
--- 2.0635123252868652 seconds for one epoch ---
--- 0.30588793754577637 seconds for one epoch ---
--- 2.0755300521850586 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11750457]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.30814]
 [ -0.     ]]
--- 0.2977757453918457 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5417.3466796875, (1912.6555, 1.3114232, 3503.2256, 0.15443794)
   validation loss 948.5390625, (670.8298, 0.6637235, 276.89114, 0.15443794)
decoder loss ratio: 25989.110016, decoder SINDy loss  ratio: 0.597708
--- 0.24412083625793457 seconds for one epoch ---
--- 0.2963297367095947 seconds for one epoch ---
--- 2.0692760944366455 seconds for one epoch ---
--- 0.3028585910797119 seconds for one epoch ---
--- 2.029090404510498 seconds for one epoch ---
--- 0.29856204986572266 seconds for one epoch ---
--- 2.0308947563171387 seconds for one epoch ---
--- 0.27246904373168945 seconds for one epoch ---
--- 2.0734851360321045 seconds for one epoch ---
--- 0.2954576015472412 seconds for one epoch ---
--- 2.0205719470977783 seconds for one epoch ---
--- 0.28904008865356445 seconds for one epoch ---
--- 2.0224404335021973 seconds for one epoch ---
--- 0.2902092933654785 seconds for one epoch ---
--- 2.0321991443634033 seconds for one epoch ---
--- 0.3082723617553711 seconds for one epoch ---
--- 2.0143110752105713 seconds for one epoch ---
--- 0.2926361560821533 seconds for one epoch ---
--- 2.0133252143859863 seconds for one epoch ---
--- 0.2953205108642578 seconds for one epoch ---
--- 2.089169979095459 seconds for one epoch ---
--- 0.2902567386627197 seconds for one epoch ---
--- 2.1122982501983643 seconds for one epoch ---
--- 0.29189085960388184 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11671181]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.338451]
 [ -0.      ]]
--- 0.2595555782318115 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2802.572509765625, (1231.0789, 0.792355, 1570.5469, 0.15447609)
   validation loss 721.6100463867188, (456.83426, 0.715156, 263.90613, 0.15447609)
decoder loss ratio: 17698.552294, decoder SINDy loss  ratio: 0.569678
--- 0.2848336696624756 seconds for one epoch ---
--- 2.0746846199035645 seconds for one epoch ---
--- 0.2924008369445801 seconds for one epoch ---
--- 2.0920090675354004 seconds for one epoch ---
--- 0.2902998924255371 seconds for one epoch ---
--- 2.10378360748291 seconds for one epoch ---
--- 0.30759525299072266 seconds for one epoch ---
--- 2.1116652488708496 seconds for one epoch ---
--- 0.2886385917663574 seconds for one epoch ---
--- 2.0616044998168945 seconds for one epoch ---
--- 0.29419445991516113 seconds for one epoch ---
--- 2.04711651802063 seconds for one epoch ---
--- 0.29243016242980957 seconds for one epoch ---
--- 2.0493457317352295 seconds for one epoch ---
--- 0.3002798557281494 seconds for one epoch ---
--- 2.0596394538879395 seconds for one epoch ---
--- 0.2795224189758301 seconds for one epoch ---
--- 2.107037305831909 seconds for one epoch ---
--- 0.30898022651672363 seconds for one epoch ---
--- 2.0977699756622314 seconds for one epoch ---
--- 0.31241607666015625 seconds for one epoch ---
--- 2.0736031532287598 seconds for one epoch ---
--- 0.6678109169006348 seconds for one epoch ---
--- 2.0702919960021973 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11592348]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.36864]
 [  0.     ]]
--- 0.2837376594543457 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2664.63134765625, (1409.7738, 1.7761519, 1252.9269, 0.15451494)
   validation loss 892.0537109375, (610.4388, 0.7426666, 280.71768, 0.15451494)
decoder loss ratio: 23649.458173, decoder SINDy loss  ratio: 0.605969
--- 0.2553234100341797 seconds for one epoch ---
--- 0.29869556427001953 seconds for one epoch ---
--- 2.065995931625366 seconds for one epoch ---
--- 0.2896718978881836 seconds for one epoch ---
--- 2.0688838958740234 seconds for one epoch ---
--- 0.2984893321990967 seconds for one epoch ---
--- 2.1010615825653076 seconds for one epoch ---
--- 0.2956998348236084 seconds for one epoch ---
--- 2.05759859085083 seconds for one epoch ---
--- 0.2900209426879883 seconds for one epoch ---
--- 2.046339750289917 seconds for one epoch ---
--- 0.2922041416168213 seconds for one epoch ---
--- 2.0464344024658203 seconds for one epoch ---
--- 0.2938880920410156 seconds for one epoch ---
--- 2.0613834857940674 seconds for one epoch ---
--- 0.2961149215698242 seconds for one epoch ---
--- 2.0378928184509277 seconds for one epoch ---
--- 0.2978181838989258 seconds for one epoch ---
--- 2.1028006076812744 seconds for one epoch ---
--- 0.30287861824035645 seconds for one epoch ---
--- 2.1062376499176025 seconds for one epoch ---
--- 0.3040659427642822 seconds for one epoch ---
--- 2.1292619705200195 seconds for one epoch ---
--- 0.29270434379577637 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11525017]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.394436]
 [  0.      ]]
--- 0.25490236282348633 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2975.803466796875, (1344.2296, 1.722715, 1629.6965, 0.15454517)
   validation loss 801.7928466796875, (520.53644, 0.7584762, 280.3434, 0.15454517)
decoder loss ratio: 20166.485299, decoder SINDy loss  ratio: 0.605161
--- 0.30164575576782227 seconds for one epoch ---
--- 2.0908946990966797 seconds for one epoch ---
--- 0.2876930236816406 seconds for one epoch ---
--- 2.117899179458618 seconds for one epoch ---
--- 0.29206132888793945 seconds for one epoch ---
--- 2.128458023071289 seconds for one epoch ---
--- 0.3017575740814209 seconds for one epoch ---
--- 2.1054208278656006 seconds for one epoch ---
--- 0.2827122211456299 seconds for one epoch ---
--- 2.081512689590454 seconds for one epoch ---
--- 0.2973673343658447 seconds for one epoch ---
--- 2.069528818130493 seconds for one epoch ---
--- 0.2889068126678467 seconds for one epoch ---
--- 2.0785605907440186 seconds for one epoch ---
--- 0.3018064498901367 seconds for one epoch ---
--- 2.080690622329712 seconds for one epoch ---
--- 0.2901899814605713 seconds for one epoch ---
--- 2.102896213531494 seconds for one epoch ---
--- 0.31694984436035156 seconds for one epoch ---
--- 2.1369285583496094 seconds for one epoch ---
--- 0.3427605628967285 seconds for one epoch ---
--- 2.174292802810669 seconds for one epoch ---
--- 0.3231344223022461 seconds for one epoch ---
--- 2.16930890083313 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11461923]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.41864]
 [  0.     ]]
--- 0.29168033599853516 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3747.762939453125, (2012.09, 1.9857404, 1733.5326, 0.15457407)
   validation loss 753.0480346679688, (482.5157, 0.77385753, 269.60385, 0.15457407)
decoder loss ratio: 18693.495361, decoder SINDy loss  ratio: 0.581978
--- 0.2539050579071045 seconds for one epoch ---
--- 0.314361572265625 seconds for one epoch ---
--- 2.096762180328369 seconds for one epoch ---
--- 0.29442691802978516 seconds for one epoch ---
--- 2.0933890342712402 seconds for one epoch ---
--- 0.29665470123291016 seconds for one epoch ---
--- 2.1344316005706787 seconds for one epoch ---
--- 0.29941534996032715 seconds for one epoch ---
--- 2.060068368911743 seconds for one epoch ---
--- 0.2925913333892822 seconds for one epoch ---
--- 2.069777011871338 seconds for one epoch ---
--- 0.29566359519958496 seconds for one epoch ---
--- 2.0687735080718994 seconds for one epoch ---
--- 0.292527437210083 seconds for one epoch ---
--- 2.0529487133026123 seconds for one epoch ---
--- 0.2953755855560303 seconds for one epoch ---
--- 2.092683792114258 seconds for one epoch ---
--- 0.2943885326385498 seconds for one epoch ---
--- 2.120093584060669 seconds for one epoch ---
--- 0.2923591136932373 seconds for one epoch ---
--- 2.12460994720459 seconds for one epoch ---
--- 0.29535531997680664 seconds for one epoch ---
--- 2.1125872135162354 seconds for one epoch ---
--- 0.29081106185913086 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11386792]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.447489]
 [  0.      ]]
--- 0.2608678340911865 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2595.896240234375, (1298.5204, 1.2770026, 1295.9445, 0.15460558)
   validation loss 728.712646484375, (446.60593, 0.79491, 281.1572, 0.15460558)
decoder loss ratio: 17302.288935, decoder SINDy loss  ratio: 0.606917
--- 0.3011441230773926 seconds for one epoch ---
--- 2.1273906230926514 seconds for one epoch ---
--- 0.3049759864807129 seconds for one epoch ---
--- 2.1642494201660156 seconds for one epoch ---
--- 0.29586195945739746 seconds for one epoch ---
--- 2.151564836502075 seconds for one epoch ---
--- 0.2915229797363281 seconds for one epoch ---
--- 2.1001572608947754 seconds for one epoch ---
--- 0.29700350761413574 seconds for one epoch ---
--- 2.078071355819702 seconds for one epoch ---
--- 0.30037856101989746 seconds for one epoch ---
--- 2.112022638320923 seconds for one epoch ---
--- 0.306713342666626 seconds for one epoch ---
--- 2.0927252769470215 seconds for one epoch ---
--- 0.29537463188171387 seconds for one epoch ---
--- 2.161107063293457 seconds for one epoch ---
--- 0.298429012298584 seconds for one epoch ---
--- 2.1247308254241943 seconds for one epoch ---
--- 0.3005249500274658 seconds for one epoch ---
--- 2.1382672786712646 seconds for one epoch ---
--- 0.2851276397705078 seconds for one epoch ---
--- 2.1254618167877197 seconds for one epoch ---
--- 0.2983829975128174 seconds for one epoch ---
--- 2.154750347137451 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11338717]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.465977]
 [ -0.      ]]
--- 0.2930605411529541 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2135.2607421875, (1253.6278, 0.6325589, 880.84576, 0.15462588)
   validation loss 1083.994140625, (750.43616, 0.7715873, 332.6317, 0.15462588)
decoder loss ratio: 29073.199545, decoder SINDy loss  ratio: 0.718032
--- 0.9773437976837158 seconds for one epoch ---
--- 0.28836536407470703 seconds for one epoch ---
--- 2.159533977508545 seconds for one epoch ---
--- 0.2978386878967285 seconds for one epoch ---
--- 2.1659884452819824 seconds for one epoch ---
--- 0.2942321300506592 seconds for one epoch ---
--- 2.0978121757507324 seconds for one epoch ---
--- 0.28475379943847656 seconds for one epoch ---
--- 2.1243691444396973 seconds for one epoch ---
--- 0.2950747013092041 seconds for one epoch ---
--- 2.0878162384033203 seconds for one epoch ---
--- 0.29062581062316895 seconds for one epoch ---
--- 2.106734275817871 seconds for one epoch ---
--- 0.29607272148132324 seconds for one epoch ---
--- 2.106182336807251 seconds for one epoch ---
--- 0.30196261405944824 seconds for one epoch ---
--- 2.1260986328125 seconds for one epoch ---
--- 0.28769540786743164 seconds for one epoch ---
--- 2.124798059463501 seconds for one epoch ---
--- 0.2987830638885498 seconds for one epoch ---
--- 2.1225626468658447 seconds for one epoch ---
--- 0.27752208709716797 seconds for one epoch ---
--- 2.1486785411834717 seconds for one epoch ---
--- 0.29877138137817383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11289517]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.484903]
 [ -0.      ]]
--- 0.2558019161224365 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4188.0517578125, (1591.4685, 4.619809, 2591.8088, 0.15465064)
   validation loss 731.96435546875, (452.0239, 0.72510916, 279.06067, 0.15465064)
decoder loss ratio: 17512.190451, decoder SINDy loss  ratio: 0.602392
--- 0.29665541648864746 seconds for one epoch ---
--- 2.2002511024475098 seconds for one epoch ---
--- 0.295823335647583 seconds for one epoch ---
--- 2.124326467514038 seconds for one epoch ---
--- 0.28946352005004883 seconds for one epoch ---
--- 2.1302340030670166 seconds for one epoch ---
--- 0.3022334575653076 seconds for one epoch ---
--- 2.107419967651367 seconds for one epoch ---
--- 0.29579949378967285 seconds for one epoch ---
--- 2.1384880542755127 seconds for one epoch ---
--- 0.3197002410888672 seconds for one epoch ---
--- 2.151170492172241 seconds for one epoch ---
--- 0.2892639636993408 seconds for one epoch ---
--- 2.17864990234375 seconds for one epoch ---
--- 0.286224365234375 seconds for one epoch ---
--- 2.1515731811523438 seconds for one epoch ---
--- 0.2968478202819824 seconds for one epoch ---
--- 2.180290460586548 seconds for one epoch ---
--- 0.3205711841583252 seconds for one epoch ---
--- 2.1704869270324707 seconds for one epoch ---
--- 0.3218512535095215 seconds for one epoch ---
--- 2.1710054874420166 seconds for one epoch ---
--- 0.32587361335754395 seconds for one epoch ---
--- 2.139404535293579 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11234556]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.506067]
 [ -0.      ]]
--- 0.2792165279388428 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2803.95703125, (827.9509, 0.8382738, 1975.0131, 0.15467405)
   validation loss 757.421630859375, (484.80017, 0.7941444, 271.67267, 0.15467405)
decoder loss ratio: 18782.000271, decoder SINDy loss  ratio: 0.586444
--- 0.2552628517150879 seconds for one epoch ---
--- 0.2739107608795166 seconds for one epoch ---
--- 2.177253484725952 seconds for one epoch ---
--- 0.3040802478790283 seconds for one epoch ---
--- 2.1364150047302246 seconds for one epoch ---
--- 0.28839540481567383 seconds for one epoch ---
--- 2.109358310699463 seconds for one epoch ---
--- 0.291914701461792 seconds for one epoch ---
--- 2.098511219024658 seconds for one epoch ---
--- 0.2951374053955078 seconds for one epoch ---
--- 2.104369878768921 seconds for one epoch ---
--- 0.30291152000427246 seconds for one epoch ---
--- 2.0853002071380615 seconds for one epoch ---
--- 0.29659056663513184 seconds for one epoch ---
--- 2.1386971473693848 seconds for one epoch ---
--- 0.2991321086883545 seconds for one epoch ---
--- 2.150791883468628 seconds for one epoch ---
--- 0.30091023445129395 seconds for one epoch ---
--- 2.183284282684326 seconds for one epoch ---
--- 0.3000307083129883 seconds for one epoch ---
--- 2.158109188079834 seconds for one epoch ---
--- 0.29218459129333496 seconds for one epoch ---
--- 2.1994731426239014 seconds for one epoch ---
--- 0.2992405891418457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11181516]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.526514]
 [ -0.      ]]
--- 0.24594616889953613 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2240.05517578125, (1143.8445, 0.6168243, 1095.4392, 0.15470023)
   validation loss 733.9284057617188, (462.24634, 0.97145593, 270.55588, 0.15470023)
decoder loss ratio: 17908.225625, decoder SINDy loss  ratio: 0.584033
--- 0.30942320823669434 seconds for one epoch ---
--- 2.2021939754486084 seconds for one epoch ---
--- 0.30644798278808594 seconds for one epoch ---
--- 2.158083200454712 seconds for one epoch ---
--- 0.2888662815093994 seconds for one epoch ---
--- 2.1016461849212646 seconds for one epoch ---
--- 0.3004603385925293 seconds for one epoch ---
--- 2.1357905864715576 seconds for one epoch ---
--- 0.30242156982421875 seconds for one epoch ---
--- 2.1298165321350098 seconds for one epoch ---
--- 0.29079532623291016 seconds for one epoch ---
--- 2.127539873123169 seconds for one epoch ---
--- 0.2849843502044678 seconds for one epoch ---
--- 2.187305450439453 seconds for one epoch ---
--- 0.3076310157775879 seconds for one epoch ---
--- 2.182654619216919 seconds for one epoch ---
--- 0.2915186882019043 seconds for one epoch ---
--- 2.163613796234131 seconds for one epoch ---
--- 0.2989513874053955 seconds for one epoch ---
--- 2.166863441467285 seconds for one epoch ---
--- 0.30637311935424805 seconds for one epoch ---
--- 2.2017812728881836 seconds for one epoch ---
--- 0.2857170104980469 seconds for one epoch ---
--- 2.203855037689209 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11122052]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.549467]
 [ -0.      ]]
--- 0.2939603328704834 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3968.43505859375, (1225.3488, 1.3595529, 2741.572, 0.15472552)
   validation loss 713.4772338867188, (439.03827, 1.0481522, 273.2361, 0.15472552)
decoder loss ratio: 17009.104747, decoder SINDy loss  ratio: 0.589819
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11119044]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.550623]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1345.59130859375, (641.81946, 0.46202514, 703.30975, 0.15472774)
   validation loss 726.0936279296875, (461.3633, 0.61252505, 264.11783, 0.15472774)
decoder loss ratio: 17874.015660, decoder SINDy loss  ratio: 0.570135
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11026543]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.568293]
 [  0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 998.5047607421875, (466.07462, 1.0166363, 531.4135, 0.15476556)
   validation loss 538.9049682617188, (304.59665, 0.20170398, 234.10664, 0.15476556)
decoder loss ratio: 11800.602992, decoder SINDy loss  ratio: 0.505352
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11193261]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.470251]
 [ -0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3591.639892578125, (2959.201, 0.6319268, 631.8071, 0.15468594)
   validation loss 3094.8515625, (2806.6462, 0.09982635, 288.1054, 0.15468594)
decoder loss ratio: 108734.347899, decoder SINDy loss  ratio: 0.621916
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11460246]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.408636]
 [  0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.58642578125, (276.07117, 0.5153908, 474.9999, 0.15456818)
   validation loss 439.2740478515625, (217.64851, 0.08807752, 221.53748, 0.15456818)
decoder loss ratio: 8432.081279, decoder SINDy loss  ratio: 0.478220
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11744903]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.212645]
 [ -0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.457275390625, (281.95392, 0.496724, 472.0066, 0.1544362)
   validation loss 439.67596435546875, (221.50987, 0.08851387, 218.07758, 0.1544362)
decoder loss ratio: 8581.677016, decoder SINDy loss  ratio: 0.470751
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12021258]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.134533]
 [ -0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.0047607421875, (263.11942, 0.48452142, 467.40085, 0.15430446)
   validation loss 422.7706298828125, (205.22737, 0.09194854, 217.45131, 0.15430446)
decoder loss ratio: 7950.864651, decoder SINDy loss  ratio: 0.469399
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12296435]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.051964]
 [ -0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.3912353515625, (319.01712, 0.64805263, 470.72607, 0.15417233)
   validation loss 452.4889221191406, (234.30237, 0.06626335, 218.12029, 0.15417233)
decoder loss ratio: 9077.280509, decoder SINDy loss  ratio: 0.470843
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12542352]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.058632]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.1945190429688, (257.11816, 0.43314028, 459.64322, 0.15404391)
   validation loss 410.5335693359375, (194.73006, 0.090992, 215.71251, 0.15404391)
decoder loss ratio: 7544.180465, decoder SINDy loss  ratio: 0.465646
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12765819]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.950951]
 [  0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.5906982421875, (250.8235, 0.42275086, 458.34448, 0.1539264)
   validation loss 407.9039306640625, (191.59239, 0.093155436, 216.21837, 0.1539264)
decoder loss ratio: 7422.621884, decoder SINDy loss  ratio: 0.466738
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12964515]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.767728]
 [  0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.163818359375, (256.3788, 0.4202286, 459.36478, 0.1538174)
   validation loss 416.18560791015625, (201.32562, 0.09212953, 214.76785, 0.1538174)
decoder loss ratio: 7799.704135, decoder SINDy loss  ratio: 0.463607
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13136809]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.767808]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.5033569335938, (246.98555, 0.41493887, 456.10287, 0.1537211)
   validation loss 403.371337890625, (188.3413, 0.09519515, 214.93486, 0.1537211)
decoder loss ratio: 7296.668679, decoder SINDy loss  ratio: 0.463967
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1330055]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.65754]
 [  0.     ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.4962158203125, (345.62476, 0.37161356, 451.49985, 0.15362765)
   validation loss 491.4533386230469, (271.9397, 0.09492308, 219.41873, 0.15362765)
decoder loss ratio: 10535.415980, decoder SINDy loss  ratio: 0.473646
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13432467]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.720714]
 [  0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.267578125, (311.35547, 0.37356722, 465.53854, 0.15354918)
   validation loss 459.5767822265625, (244.87122, 0.093025684, 214.61255, 0.15354918)
decoder loss ratio: 9486.736016, decoder SINDy loss  ratio: 0.463271
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13547437]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.677995]
 [  0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.10107421875, (246.09837, 0.35897464, 451.6437, 0.15347934)
   validation loss 399.22161865234375, (184.11304, 0.10107211, 215.0075, 0.15347934)
decoder loss ratio: 7132.858692, decoder SINDy loss  ratio: 0.464124
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13649328]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.584719]
 [ -0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.3486938476562, (240.5009, 0.36780366, 451.48, 0.15341575)
   validation loss 397.7259521484375, (183.6715, 0.10228519, 213.95218, 0.15341575)
decoder loss ratio: 7115.752527, decoder SINDy loss  ratio: 0.461846
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13733521]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.538369]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1638.2197265625, (1091.5775, 0.45227212, 546.1899, 0.15336514)
   validation loss 1205.7484130859375, (961.72906, 0.065459214, 243.9539, 0.15336514)
decoder loss ratio: 37259.053611, decoder SINDy loss  ratio: 0.526609
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13808447]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.577302]
 [  0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.9405517578125, (250.12889, 0.32134566, 449.49033, 0.15331458)
   validation loss 409.0736083984375, (195.45868, 0.10305655, 213.51189, 0.15331458)
decoder loss ratio: 7572.408563, decoder SINDy loss  ratio: 0.460895
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1386069]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.557242]
 [  0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.5481567382812, (277.02863, 0.33432826, 456.1852, 0.15328197)
   validation loss 437.1031494140625, (223.78516, 0.10370183, 213.21428, 0.15328197)
decoder loss ratio: 8669.825461, decoder SINDy loss  ratio: 0.460253
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13902262]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.463889]
 [ -0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.384033203125, (240.61823, 0.32701737, 447.4388, 0.15325534)
   validation loss 393.0867919921875, (179.37704, 0.10939094, 213.60037, 0.15325534)
decoder loss ratio: 6949.378123, decoder SINDy loss  ratio: 0.461086
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13937566]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.46588]
 [ -0.     ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.4901123046875, (240.43423, 0.33931255, 446.71658, 0.15323298)
   validation loss 396.25506591796875, (183.60051, 0.10930704, 212.54526, 0.15323298)
decoder loss ratio: 7113.002488, decoder SINDy loss  ratio: 0.458809
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1397492]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.459436]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 927.1962890625, (478.54007, 0.31597963, 448.3402, 0.15321389)
   validation loss 601.4241333007812, (376.56525, 0.11295437, 224.74596, 0.15321389)
decoder loss ratio: 14588.791399, decoder SINDy loss  ratio: 0.485146
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13977173]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.440353]
 [  0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.845703125, (240.18663, 0.3159087, 444.34314, 0.15320729)
   validation loss 393.8044128417969, (180.6011, 0.11361213, 213.08969, 0.15320729)
decoder loss ratio: 6996.800335, decoder SINDy loss  ratio: 0.459984
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.13979]
 [0.     ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.534489]
 [  0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.3496704101562, (334.94284, 0.38368428, 464.02313, 0.1532079)
   validation loss 497.04864501953125, (282.80383, 0.09065184, 214.15419, 0.1532079)
decoder loss ratio: 10956.311460, decoder SINDy loss  ratio: 0.462282
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1398871]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.429535]
 [ -0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1057.70458984375, (607.7829, 0.2848299, 449.6369, 0.1532003)
   validation loss 723.4868774414062, (493.2043, 0.12490436, 230.15764, 0.1532003)
decoder loss ratio: 19107.591411, decoder SINDy loss  ratio: 0.496828
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13982233]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.481419]
 [  0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.5399169921875, (261.852, 0.29391396, 440.394, 0.1532043)
   validation loss 406.64532470703125, (192.02182, 0.11757374, 214.50592, 0.1532043)
decoder loss ratio: 7439.258674, decoder SINDy loss  ratio: 0.463041
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13956282]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.509152]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.461669921875, (258.48346, 0.30896413, 439.66928, 0.15322119)
   validation loss 402.7016906738281, (189.60733, 0.118378915, 212.97598, 0.15322119)
decoder loss ratio: 7345.717149, decoder SINDy loss  ratio: 0.459739
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13934147]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.489916]
 [  0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.7666015625, (286.01172, 0.40153727, 448.35333, 0.1532359)
   validation loss 441.2672424316406, (229.48541, 0.090319715, 211.69151, 0.1532359)
decoder loss ratio: 8890.663288, decoder SINDy loss  ratio: 0.456966
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13921799]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.447095]
 [ -0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.0862426757812, (258.46753, 0.2864458, 437.33228, 0.15324493)
   validation loss 402.01556396484375, (188.02676, 0.118915, 213.86987, 0.15324493)
decoder loss ratio: 7284.483263, decoder SINDy loss  ratio: 0.461668
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13895214]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.550266]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.5230712890625, (260.56503, 0.2975152, 445.66052, 0.15326197)
   validation loss 422.21734619140625, (210.37877, 0.11284499, 211.72572, 0.15326197)
decoder loss ratio: 8150.438742, decoder SINDy loss  ratio: 0.457040
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13854544]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.544923]
 [  0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.395751953125, (236.75919, 0.30150887, 437.33508, 0.15328887)
   validation loss 388.0346374511719, (176.51569, 0.11940793, 211.39954, 0.15328887)
decoder loss ratio: 6838.524122, decoder SINDy loss  ratio: 0.456336
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1381315]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.529684]
 [ -0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 937.2882080078125, (501.03177, 0.29555508, 435.96085, 0.15331766)
   validation loss 622.3956909179688, (401.72565, 0.11751479, 220.55254, 0.15331766)
decoder loss ratio: 15563.548990, decoder SINDy loss  ratio: 0.476094
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13772315]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.544957]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.398193359375, (239.83931, 0.28558382, 440.27332, 0.15334181)
   validation loss 395.3265075683594, (184.10962, 0.11334736, 211.10355, 0.15334181)
decoder loss ratio: 7132.726274, decoder SINDy loss  ratio: 0.455697
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13716316]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.606117]
 [ -0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.8344116210938, (241.24364, 0.28678763, 434.304, 0.15337777)
   validation loss 388.12939453125, (176.58781, 0.118889704, 211.42268, 0.15337777)
decoder loss ratio: 6841.318497, decoder SINDy loss  ratio: 0.456386
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13681455]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.578231]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2157.75537109375, (1595.6862, 0.34830466, 561.72107, 0.15340276)
   validation loss 1745.0142822265625, (1488.3003, 0.080664165, 256.63333, 0.15340276)
decoder loss ratio: 57659.337153, decoder SINDy loss  ratio: 0.553979
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13632688]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.572735]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.8740234375, (247.48209, 0.2852626, 439.1067, 0.15343092)
   validation loss 395.0460205078125, (183.26797, 0.110827535, 211.66724, 0.15343092)
decoder loss ratio: 7100.119513, decoder SINDy loss  ratio: 0.456914
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13574727]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.648531]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.8805541992188, (234.96396, 0.28463316, 435.63196, 0.15346543)
   validation loss 391.912841796875, (182.23228, 0.11236955, 209.5682, 0.15346543)
decoder loss ratio: 7059.995072, decoder SINDy loss  ratio: 0.452382
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13512446]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.653377]
 [ -0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.85400390625, (228.9708, 0.31765172, 432.56555, 0.15350364)
   validation loss 384.48248291015625, (176.73933, 0.114206076, 207.62894, 0.15350364)
decoder loss ratio: 6847.188636, decoder SINDy loss  ratio: 0.448196
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1346739]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.646563]
 [ -0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1046.884033203125, (578.98, 0.2980694, 467.60602, 0.15353332)
   validation loss 768.566650390625, (548.7163, 0.10010549, 219.75026, 0.15353332)
decoder loss ratio: 21258.222408, decoder SINDy loss  ratio: 0.474362
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13404644]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.62041]
 [ -0.     ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.3058471679688, (230.95453, 0.27794063, 431.07336, 0.1535688)
   validation loss 377.56451416015625, (167.51703, 0.11257318, 209.93489, 0.1535688)
decoder loss ratio: 6489.900518, decoder SINDy loss  ratio: 0.453174
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13323106]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.722745]
 [ -0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.33251953125, (226.99644, 0.31632805, 430.01974, 0.15361793)
   validation loss 378.4675598144531, (170.3825, 0.117669955, 207.96738, 0.15361793)
decoder loss ratio: 6600.914131, decoder SINDy loss  ratio: 0.448927
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1327931]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.734773]
 [  0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1364.5640869140625, (897.1389, 0.2874076, 467.1378, 0.15364479)
   validation loss 1160.104248046875, (937.3045, 0.09784056, 222.70192, 0.15364479)
decoder loss ratio: 36312.803732, decoder SINDy loss  ratio: 0.480733
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13210525]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.768474]
 [ -0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.7240600585938, (231.19423, 0.27456778, 430.25528, 0.15368333)
   validation loss 382.4189453125, (173.1275, 0.105576806, 209.18588, 0.15368333)
decoder loss ratio: 6707.260007, decoder SINDy loss  ratio: 0.451557
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1313166]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.777244]
 [ -0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.0460205078125, (225.89139, 0.28175, 425.8729, 0.15372913)
   validation loss 377.79345703125, (169.43126, 0.11435742, 208.24785, 0.15372913)
decoder loss ratio: 6564.061125, decoder SINDy loss  ratio: 0.449532
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13069361]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.848541]
 [ -0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4293.0810546875, (3644.1702, 0.3137454, 648.5969, 0.15376031)
   validation loss 3932.99755859375, (3621.45, 0.078278475, 311.46915, 0.15376031)
decoder loss ratio: 140301.258222, decoder SINDy loss  ratio: 0.672350
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13013135]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.819486]
 [  0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.9251098632812, (258.056, 0.2861641, 433.58295, 0.15379596)
   validation loss 407.6257019042969, (198.32549, 0.103322946, 209.1969, 0.15379596)
decoder loss ratio: 7683.473606, decoder SINDy loss  ratio: 0.451581
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12932882]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.81994]
 [  0.     ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.1295166015625, (264.2564, 0.27725098, 422.59583, 0.15384106)
   validation loss 398.09930419921875, (189.00139, 0.114871435, 208.98303, 0.15384106)
decoder loss ratio: 7322.241913, decoder SINDy loss  ratio: 0.451119
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1285957]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-15.88101]
 [ -0.     ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.0491943359375, (225.08727, 0.30035937, 423.66156, 0.15388115)
   validation loss 374.47247314453125, (167.95473, 0.112835996, 206.4049, 0.15388115)
decoder loss ratio: 6506.857713, decoder SINDy loss  ratio: 0.445554
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12814473]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.921453]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1302.0758056640625, (834.29224, 0.29170316, 467.49188, 0.1539078)
   validation loss 1055.6826171875, (828.7176, 0.09846234, 226.86658, 0.1539078)
decoder loss ratio: 32105.958166, decoder SINDy loss  ratio: 0.489723
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1274705]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.931775]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.9501342773438, (233.23659, 0.28198066, 425.43155, 0.15394203)
   validation loss 379.45855712890625, (172.11955, 0.102218285, 207.23679, 0.15394203)
decoder loss ratio: 6668.210281, decoder SINDy loss  ratio: 0.447350
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12690777]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.891418]
 [ -0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 976.9588623046875, (552.12555, 0.25698978, 424.57626, 0.15397225)
   validation loss 661.7064208984375, (440.4751, 0.110190526, 221.12111, 0.15397225)
decoder loss ratio: 17064.769982, decoder SINDy loss  ratio: 0.477321
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12628675]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.937292]
 [  0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.299072265625, (257.2427, 0.27954748, 425.77686, 0.15400395)
   validation loss 426.3118896484375, (220.17589, 0.10306777, 206.03294, 0.15400395)
decoder loss ratio: 8529.996146, decoder SINDy loss  ratio: 0.444751
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12572923]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.993811]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 858.3298950195312, (408.34064, 0.29874784, 449.69052, 0.15403447)
   validation loss 551.7762451171875, (338.59058, 0.093464315, 213.09221, 0.15403447)
decoder loss ratio: 13117.586740, decoder SINDy loss  ratio: 0.459990
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12514044]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.998642]
 [ -0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.2720336914062, (251.11986, 0.28411773, 425.86804, 0.15406522)
   validation loss 396.6930847167969, (189.60918, 0.094913766, 206.989, 0.15406522)
decoder loss ratio: 7345.788679, decoder SINDy loss  ratio: 0.446815
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12453305]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.999376]
 [ -0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 828.2977294921875, (411.05463, 0.25849697, 416.98465, 0.15409613)
   validation loss 532.2574462890625, (317.18527, 0.10264199, 214.96953, 0.15409613)
decoder loss ratio: 12288.308104, decoder SINDy loss  ratio: 0.464042
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12387062]
 [0.        ]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.0217]
 [ -0.    ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.2314453125, (221.39198, 0.27507493, 415.56436, 0.15413049)
   validation loss 370.36663818359375, (165.00223, 0.1057706, 205.25865, 0.15413049)
decoder loss ratio: 6392.472761, decoder SINDy loss  ratio: 0.443080
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12317467]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.150291]
 [  0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.4031982421875, (216.91891, 0.3182104, 420.16605, 0.15416482)
   validation loss 374.7767028808594, (171.91484, 0.10100322, 202.76086, 0.15416482)
decoder loss ratio: 6660.279386, decoder SINDy loss  ratio: 0.437688
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12267837]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.12436]
 [  0.     ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.2791748046875, (252.14607, 0.27101335, 414.8621, 0.15418947)
   validation loss 384.78533935546875, (178.39838, 0.106869355, 206.28008, 0.15418947)
decoder loss ratio: 6911.462817, decoder SINDy loss  ratio: 0.445285
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1220785]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.111952]
 [  0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.3308715820312, (224.15584, 0.28386846, 414.89114, 0.15421918)
   validation loss 364.75689697265625, (160.18558, 0.09445104, 204.47687, 0.15421918)
decoder loss ratio: 6205.867363, decoder SINDy loss  ratio: 0.441392
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12151343]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.24919]
 [ -0.     ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.214599609375, (385.2269, 0.25461152, 413.7331, 0.15424734)
   validation loss 501.583251953125, (289.67932, 0.09499476, 211.80894, 0.15424734)
decoder loss ratio: 11222.679812, decoder SINDy loss  ratio: 0.457219
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12100676]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.20484]
 [  0.     ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 638.646240234375, (222.10406, 0.29207736, 416.25012, 0.15427318)
   validation loss 386.94964599609375, (184.33359, 0.09647893, 202.51959, 0.15427318)
decoder loss ratio: 7141.403203, decoder SINDy loss  ratio: 0.437167
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12055901]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.200634]
 [ -0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1873.15478515625, (1437.0475, 0.28117645, 435.82614, 0.15429848)
   validation loss 1529.7115478515625, (1283.3353, 0.1073122, 246.26889, 0.15429848)
decoder loss ratio: 49718.638542, decoder SINDy loss  ratio: 0.531606
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11998109]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.263935]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 884.1263427734375, (469.14783, 0.27312034, 414.7054, 0.15432253)
   validation loss 576.5479125976562, (362.0024, 0.10243677, 214.44307, 0.15432253)
decoder loss ratio: 14024.601862, decoder SINDy loss  ratio: 0.462906
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11931074]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.220402]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.0267333984375, (222.32407, 0.28563288, 409.41705, 0.15435472)
   validation loss 361.01654052734375, (158.4059, 0.0961832, 202.51448, 0.15435472)
decoder loss ratio: 6136.919534, decoder SINDy loss  ratio: 0.437156
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11873841]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.249905]
 [ -0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.3375854492188, (211.67946, 0.3014556, 411.35666, 0.15438227)
   validation loss 366.6409606933594, (165.67714, 0.09772234, 200.8661, 0.15438227)
decoder loss ratio: 6418.620004, decoder SINDy loss  ratio: 0.433598
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11822466]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.23674]
 [  0.     ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1968.522705078125, (1469.4935, 0.29572737, 498.73334, 0.154403)
   validation loss 1691.1646728515625, (1456.6196, 0.07419696, 234.47083, 0.154403)
decoder loss ratio: 56431.973227, decoder SINDy loss  ratio: 0.506138
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11785266]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.297264]
 [  0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.0123901367188, (422.617, 0.277743, 412.11765, 0.15442331)
   validation loss 527.6986694335938, (316.21054, 0.095863916, 211.39226, 0.15442331)
decoder loss ratio: 12250.545315, decoder SINDy loss  ratio: 0.456320
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11729363]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.278805]
 [ -0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.0534057617188, (263.67987, 0.2877153, 406.08582, 0.15445004)
   validation loss 388.45745849609375, (185.2294, 0.09248088, 203.13557, 0.15445004)
decoder loss ratio: 7176.108553, decoder SINDy loss  ratio: 0.438497
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11679722]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.325745]
 [ -0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.055908203125, (223.4756, 0.2936684, 406.28665, 0.15447351)
   validation loss 360.7250671386719, (159.78249, 0.09215897, 200.85042, 0.15447351)
decoder loss ratio: 6190.250901, decoder SINDy loss  ratio: 0.433564
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1164261]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.399818]
 [  0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 617.4407348632812, (209.99847, 0.29207546, 407.1502, 0.1544899)
   validation loss 362.06768798828125, (162.27022, 0.08748483, 199.71, 0.1544899)
decoder loss ratio: 6286.629955, decoder SINDy loss  ratio: 0.431102
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11606267]
 [0.        ]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [-16.4122]
 [  0.    ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1041.0401611328125, (604.371, 0.2825499, 436.38666, 0.15450743)
   validation loss 817.9448852539062, (607.2573, 0.07761124, 210.60991, 0.15450743)
decoder loss ratio: 23526.202985, decoder SINDy loss  ratio: 0.454631
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11566918]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.366982]
 [ -0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3505.54345703125, (2911.8264, 0.28396595, 593.4332, 0.15452655)
   validation loss 3177.22607421875, (2874.4563, 0.05746335, 302.71243, 0.15452655)
decoder loss ratio: 111361.427292, decoder SINDy loss  ratio: 0.653447
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11515197]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.416967]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.7685546875, (377.24362, 0.28004327, 406.24493, 0.15454845)
   validation loss 482.5914306640625, (275.72806, 0.09240095, 206.77098, 0.15454845)
decoder loss ratio: 10682.183647, decoder SINDy loss  ratio: 0.446344
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11476392]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.336134]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 629.848388671875, (226.69609, 0.29133916, 402.86096, 0.15456581)
   validation loss 358.52398681640625, (158.12328, 0.08287649, 200.31783, 0.15456581)
decoder loss ratio: 6125.970217, decoder SINDy loss  ratio: 0.432414
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11440477]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.391632]
 [ -0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.91748046875, (225.03433, 0.3056699, 407.57745, 0.15458232)
   validation loss 385.62457275390625, (186.86906, 0.08363143, 198.67189, 0.15458232)
decoder loss ratio: 7239.631971, decoder SINDy loss  ratio: 0.428861
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11393762]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.452484]
 [  0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 971.31396484375, (528.0356, 0.3551235, 442.92325, 0.15460502)
   validation loss 721.37060546875, (510.36133, 0.07962384, 210.92966, 0.15460502)
decoder loss ratio: 19772.283878, decoder SINDy loss  ratio: 0.455321
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11363856]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.41769]
 [ -0.     ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1070.646240234375, (626.8928, 0.3165357, 443.43695, 0.15461737)
   validation loss 821.62548828125, (607.3631, 0.06886053, 214.19356, 0.15461737)
decoder loss ratio: 23530.300851, decoder SINDy loss  ratio: 0.462367
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11320803]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.425312]
 [ -0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.7213745117188, (215.89848, 0.30217603, 403.52072, 0.15463652)
   validation loss 353.48175048828125, (154.75555, 0.07633801, 198.64984, 0.15463652)
decoder loss ratio: 5995.498837, decoder SINDy loss  ratio: 0.428814
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11272804]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.418089]
 [ -0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.9063720703125, (276.20682, 0.30310467, 400.39648, 0.15465789)
   validation loss 392.51190185546875, (192.52602, 0.08402037, 199.90186, 0.15465789)
decoder loss ratio: 7458.792109, decoder SINDy loss  ratio: 0.431516
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11230226]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.553036]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.7031860351562, (233.65594, 0.343281, 411.70395, 0.15467727)
   validation loss 396.10595703125, (198.78165, 0.08212679, 197.2422, 0.15467727)
decoder loss ratio: 7701.146094, decoder SINDy loss  ratio: 0.425775
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11202873]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.525223]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.9478149414062, (329.2547, 0.31611207, 420.377, 0.1546889)
   validation loss 485.66009521484375, (281.80865, 0.07457843, 203.77684, 0.1546889)
decoder loss ratio: 10917.756528, decoder SINDy loss  ratio: 0.439881
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11172923]
 [0.        ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [-16.5108]
 [ -0.    ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.4793701171875, (218.64616, 0.3090388, 401.5242, 0.15470207)
   validation loss 351.294189453125, (153.15181, 0.07212989, 198.07024, 0.15470207)
decoder loss ratio: 5933.366991, decoder SINDy loss  ratio: 0.427562
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11137113]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.571938]
 [ -0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.5150146484375, (367.0499, 0.286646, 399.17847, 0.15471764)
   validation loss 471.48504638671875, (267.83322, 0.07677923, 203.57506, 0.15471764)
decoder loss ratio: 10376.323977, decoder SINDy loss  ratio: 0.439445
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1110592]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.480478]
 [ -0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.5518798828125, (262.2597, 0.31003964, 407.98212, 0.15473077)
   validation loss 431.63885498046875, (233.39018, 0.07426185, 198.17442, 0.15473077)
decoder loss ratio: 9041.940853, decoder SINDy loss  ratio: 0.427787
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11077306]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.549856]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 979.2429809570312, (545.9623, 0.30244225, 432.97827, 0.15474592)
   validation loss 754.28369140625, (542.81055, 0.061599106, 211.41156, 0.15474592)
decoder loss ratio: 21029.422946, decoder SINDy loss  ratio: 0.456362
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11054593]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.629072]
 [ -0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1323.82373046875, (916.62384, 0.30938533, 406.89053, 0.15475526)
   validation loss 1010.94189453125, (787.87616, 0.077815026, 222.9879, 0.15475526)
decoder loss ratio: 30523.690239, decoder SINDy loss  ratio: 0.481351
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11017342]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.623856]
 [  0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.553955078125, (282.80322, 0.30533624, 397.44537, 0.15477012)
   validation loss 397.4241943359375, (197.63268, 0.07235934, 199.71916, 0.15477012)
decoder loss ratio: 7656.632942, decoder SINDy loss  ratio: 0.431122
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1099542]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.585169]
 [  0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 872.8928833007812, (474.69803, 0.30729392, 397.88757, 0.15478009)
   validation loss 576.5426025390625, (369.20172, 0.071838014, 207.26903, 0.15478009)
decoder loss ratio: 14303.515641, decoder SINDy loss  ratio: 0.447419
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10955871]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.653694]
 [  0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.9555053710938, (433.82913, 0.30797356, 399.8184, 0.15479718)
   validation loss 530.7161865234375, (325.68448, 0.07488391, 204.9568, 0.15479718)
decoder loss ratio: 12617.582120, decoder SINDy loss  ratio: 0.442428
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10920496]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.625967]
 [ -0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.294921875, (238.16106, 0.3217216, 403.81216, 0.15481238)
   validation loss 384.81512451171875, (187.37473, 0.064986475, 197.37543, 0.15481238)
decoder loss ratio: 7259.222157, decoder SINDy loss  ratio: 0.426063
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10889654]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.637886]
 [  0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.1835327148438, (313.8504, 0.3189049, 397.01422, 0.15482585)
   validation loss 420.64971923828125, (220.88348, 0.06984406, 199.6964, 0.15482585)
decoder loss ratio: 8557.409636, decoder SINDy loss  ratio: 0.431073
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10862154]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.641079]
 [  0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.7554931640625, (226.43015, 0.3247762, 397.00055, 0.15483801)
   validation loss 353.49566650390625, (157.53741, 0.07003834, 195.88823, 0.15483801)
decoder loss ratio: 6103.272937, decoder SINDy loss  ratio: 0.422852
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10839456]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.648626]
 [  0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 617.4239501953125, (219.36845, 0.3306694, 397.72482, 0.15484834)
   validation loss 353.6456298828125, (158.00899, 0.068746425, 195.56792, 0.15484834)
decoder loss ratio: 6121.542489, decoder SINDy loss  ratio: 0.422161
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10810708]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.637407]
 [  0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 607.2894287109375, (207.07838, 0.34184688, 399.86923, 0.15485989)
   validation loss 355.0860900878906, (161.13412, 0.071591176, 193.88037, 0.15485989)
decoder loss ratio: 6242.615734, decoder SINDy loss  ratio: 0.418518
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10788506]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.68293]
 [  0.     ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1016.8671875, (577.8296, 0.36766285, 438.66995, 0.15487096)
   validation loss 787.3822021484375, (574.1832, 0.06002849, 213.13895, 0.15487096)
decoder loss ratio: 22244.855061, decoder SINDy loss  ratio: 0.460090
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10769013]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.703882]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1450.247802734375, (993.43036, 0.3165322, 456.50095, 0.15487818)
   validation loss 1227.59814453125, (1002.37024, 0.055251196, 225.1726, 0.15487818)
decoder loss ratio: 38833.563260, decoder SINDy loss  ratio: 0.486067
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1074338]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.708897]
 [  0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1312.323974609375, (888.77155, 0.3157929, 423.23666, 0.15489033)
   validation loss 934.611083984375, (709.6519, 0.07147211, 224.8877, 0.15489033)
decoder loss ratio: 27493.147255, decoder SINDy loss  ratio: 0.485452
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10721301]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.70279]
 [ -0.     ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.9675903320312, (304.07562, 0.3089503, 397.583, 0.15489888)
   validation loss 414.84228515625, (215.00551, 0.061982043, 199.77481, 0.15489888)
decoder loss ratio: 8329.686662, decoder SINDy loss  ratio: 0.431242
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10679667]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.721748]
 [  0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.2984619140625, (222.7647, 0.33802295, 401.19577, 0.15491548)
   validation loss 376.2802734375, (181.51573, 0.06586497, 194.69867, 0.15491548)
decoder loss ratio: 7032.234576, decoder SINDy loss  ratio: 0.420284
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10660341]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.762785]
 [ -0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.5401611328125, (259.04572, 0.33565557, 396.15878, 0.15492463)
   validation loss 375.14813232421875, (179.45644, 0.0662535, 195.62544, 0.15492463)
decoder loss ratio: 6952.453887, decoder SINDy loss  ratio: 0.422285
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10647014]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.803608]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.360107421875, (240.41182, 0.32375842, 401.6245, 0.15492885)
   validation loss 395.7597961425781, (200.55774, 0.057497557, 195.14456, 0.15492885)
decoder loss ratio: 7769.955002, decoder SINDy loss  ratio: 0.421247
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10630275]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.718287]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.6425170898438, (281.2092, 0.31150115, 394.12183, 0.15493692)
   validation loss 390.88897705078125, (193.33145, 0.062027983, 197.4955, 0.15493692)
decoder loss ratio: 7489.996066, decoder SINDy loss  ratio: 0.426322
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10609518]
 [0.        ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.7161]
 [  0.    ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 611.5213012695312, (214.73697, 0.32630315, 396.458, 0.15494576)
   validation loss 346.7937316894531, (152.14563, 0.05977916, 194.58832, 0.15494576)
decoder loss ratio: 5894.385838, decoder SINDy loss  ratio: 0.420046
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10593596]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.717176]
 [ -0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.0006103515625, (306.60437, 0.33682132, 396.05945, 0.15495269)
   validation loss 411.99737548828125, (214.43756, 0.06187888, 197.49792, 0.15495269)
decoder loss ratio: 8307.683394, decoder SINDy loss  ratio: 0.426327
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10565905]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.743612]
 [ -0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.9630737304688, (245.5045, 0.3397375, 396.11884, 0.1549639)
   validation loss 361.62396240234375, (167.08102, 0.064792596, 194.47816, 0.1549639)
decoder loss ratio: 6473.008942, decoder SINDy loss  ratio: 0.419808
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10551181]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.793324]
 [  0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1344.006103515625, (887.66064, 0.33081216, 456.0146, 0.15497176)
   validation loss 1132.814697265625, (905.6833, 0.04372003, 227.08774, 0.15497176)
decoder loss ratio: 35087.742935, decoder SINDy loss  ratio: 0.490201
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1052978]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.787996]
 [  0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1230.675537109375, (801.17395, 0.33861738, 429.1629, 0.1549788)
   validation loss 1062.0120849609375, (853.7844, 0.046416335, 208.18132, 0.1549788)
decoder loss ratio: 33077.090814, decoder SINDy loss  ratio: 0.449389
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10505914]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.783922]
 [ -0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 945.0631103515625, (521.2127, 0.32071412, 423.52963, 0.15499039)
   validation loss 739.1492919921875, (533.2482, 0.048085693, 205.85294, 0.15499039)
decoder loss ratio: 20658.962189, decoder SINDy loss  ratio: 0.444363
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10473792]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.833582]
 [ -0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.577392578125, (297.5821, 0.33782437, 408.65747, 0.15500313)
   validation loss 466.23040771484375, (269.04443, 0.054824036, 197.13116, 0.15500313)
decoder loss ratio: 10423.248439, decoder SINDy loss  ratio: 0.425535
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10457259]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.809683]
 [  0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 962.0570068359375, (562.08636, 0.32954463, 399.64114, 0.15501072)
   validation loss 640.0265502929688, (433.8776, 0.06316541, 206.0858, 0.15501072)
decoder loss ratio: 16809.171236, decoder SINDy loss  ratio: 0.444865
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10443589]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.79039]
 [  0.     ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.968505859375, (292.69223, 0.32937714, 395.94687, 0.15501522)
   validation loss 396.2574768066406, (199.67981, 0.056146055, 196.52151, 0.15501522)
decoder loss ratio: 7735.942482, decoder SINDy loss  ratio: 0.424219
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10431713]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.770145]
 [ -0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.7381591796875, (319.01694, 0.33108327, 398.39017, 0.15502216)
   validation loss 417.8703918457031, (220.87344, 0.05600736, 196.94095, 0.15502216)
decoder loss ratio: 8557.020658, decoder SINDy loss  ratio: 0.425125
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10414699]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.83108]
 [ -0.     ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.8278198242188, (255.79971, 0.33449125, 396.6936, 0.1550275)
   validation loss 367.3050231933594, (173.08615, 0.058419958, 194.16045, 0.1550275)
decoder loss ratio: 6705.657985, decoder SINDy loss  ratio: 0.419123
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1040279]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.829824]
 [ -0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.222900390625, (267.01996, 0.35537356, 410.8476, 0.15503387)
   validation loss 442.19354248046875, (246.0509, 0.055952404, 196.0867, 0.15503387)
decoder loss ratio: 9532.439158, decoder SINDy loss  ratio: 0.423281
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10384922]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.828835]
 [ -0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.0571899414062, (210.24036, 0.37823933, 404.4386, 0.15504058)
   validation loss 359.64794921875, (168.38614, 0.061700225, 191.2001, 0.15504058)
decoder loss ratio: 6523.571353, decoder SINDy loss  ratio: 0.412732
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10375502]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.855907]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 876.4251098632812, (473.2661, 0.32727984, 402.83173, 0.15504496)
   validation loss 557.69921875, (354.0413, 0.056904722, 203.60101, 0.15504496)
decoder loss ratio: 13716.174228, decoder SINDy loss  ratio: 0.439501
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10363326]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.860064]
 [  0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.950439453125, (219.30862, 0.3349864, 400.30685, 0.15504985)
   validation loss 348.84686279296875, (154.9425, 0.052003637, 193.85234, 0.15504985)
decoder loss ratio: 6002.741631, decoder SINDy loss  ratio: 0.418458
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10349892]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.837994]
 [ -0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.2503662109375, (363.024, 0.32974854, 399.8966, 0.1550557)
   validation loss 456.9282531738281, (258.57843, 0.0539061, 198.29593, 0.1550557)
decoder loss ratio: 10017.777297, decoder SINDy loss  ratio: 0.428050
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10336361]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.859928]
 [ -0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 613.0662231445312, (212.27264, 0.33039498, 400.4632, 0.15506072)
   validation loss 344.7686767578125, (152.22643, 0.051580675, 192.49069, 0.15506072)
decoder loss ratio: 5897.515988, decoder SINDy loss  ratio: 0.415518
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10327784]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.888292]
 [ -0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.7467651367188, (350.33798, 0.3179339, 399.09085, 0.15506428)
   validation loss 447.27099609375, (249.23398, 0.05501104, 197.982, 0.15506428)
decoder loss ratio: 9655.757007, decoder SINDy loss  ratio: 0.427372
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10316143]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.872423]
 [  0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.9581298828125, (216.19937, 0.32428408, 402.43448, 0.15506929)
   validation loss 353.65594482421875, (160.61018, 0.049506217, 192.99625, 0.15506929)
decoder loss ratio: 6222.317349, decoder SINDy loss  ratio: 0.416610
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10303451]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.788485]
 [  0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.689697265625, (360.48682, 0.32339936, 400.87946, 0.15507561)
   validation loss 455.35791015625, (256.58804, 0.052416313, 198.71742, 0.15507561)
decoder loss ratio: 9940.666251, decoder SINDy loss  ratio: 0.428960
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10293398]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.86791]
 [  0.     ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.763671875, (221.03722, 0.31946918, 404.40695, 0.15507841)
   validation loss 366.65478515625, (173.88135, 0.04886376, 192.7246, 0.15507841)
decoder loss ratio: 6736.465279, decoder SINDy loss  ratio: 0.416023
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10281281]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.86926]
 [  0.     ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.5999755859375, (285.5119, 0.3314575, 401.7566, 0.15508483)
   validation loss 389.34820556640625, (195.1713, 0.05411571, 194.12279, 0.15508483)
decoder loss ratio: 7561.274807, decoder SINDy loss  ratio: 0.419041
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10274746]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.863577]
 [  0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.2452392578125, (241.3292, 0.33356178, 409.58246, 0.15508655)
   validation loss 403.10565185546875, (209.35991, 0.048195194, 193.69754, 0.15508655)
decoder loss ratio: 8110.966342, decoder SINDy loss  ratio: 0.418123
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10263782]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.88559]
 [ -0.     ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.7683715820312, (429.70746, 0.36478743, 432.69614, 0.15509279)
   validation loss 626.416015625, (423.09268, 0.050803337, 203.27252, 0.15509279)
decoder loss ratio: 16391.345017, decoder SINDy loss  ratio: 0.438792
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10257545]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.895866]
 [  0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2602.6259765625, (2081.3018, 0.30942035, 521.0149, 0.15509197)
   validation loss 2366.42919921875, (2100.4348, 0.040438432, 265.95374, 0.15509197)
decoder loss ratio: 81374.491227, decoder SINDy loss  ratio: 0.574099
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10252368]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.88329]
 [  0.     ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.71142578125, (274.6981, 0.31615704, 404.6972, 0.1550964)
   validation loss 382.5398254394531, (187.9611, 0.048720233, 194.53, 0.1550964)
decoder loss ratio: 7281.939536, decoder SINDy loss  ratio: 0.419920
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10248268]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.817465]
 [ -0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.6260986328125, (222.89444, 0.31894314, 409.41272, 0.15510097)
   validation loss 372.3025207519531, (177.7006, 0.04150009, 194.56041, 0.15510097)
decoder loss ratio: 6884.430029, decoder SINDy loss  ratio: 0.419986
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10230029]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.945831]
 [ -0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 823.8914794921875, (414.45602, 0.31029183, 409.12518, 0.15510705)
   validation loss 498.8796081542969, (298.52307, 0.04906876, 200.30746, 0.15510705)
decoder loss ratio: 11565.302041, decoder SINDy loss  ratio: 0.432392
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10222726]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.917665]
 [ -0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.70947265625, (352.9597, 0.3180468, 404.4317, 0.15510891)
   validation loss 446.91387939453125, (249.673, 0.05200471, 197.18889, 0.15510891)
decoder loss ratio: 9672.765632, decoder SINDy loss  ratio: 0.425660
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10211806]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.906118]
 [ -0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.2720336914062, (221.09872, 0.30660254, 408.8667, 0.15511325)
   validation loss 358.54425048828125, (165.99474, 0.046495512, 192.503, 0.15511325)
decoder loss ratio: 6430.924241, decoder SINDy loss  ratio: 0.415545
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10207474]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.946716]
 [  0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.3038330078125, (357.23895, 0.30623582, 407.7586, 0.1551153)
   validation loss 448.7500305175781, (251.38542, 0.04816547, 197.31644, 0.1551153)
decoder loss ratio: 9739.107663, decoder SINDy loss  ratio: 0.425935
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10193547]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.84646]
 [  0.     ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 628.63037109375, (219.82726, 0.30314755, 408.49997, 0.15512042)
   validation loss 345.54803466796875, (153.90456, 0.046672497, 191.59682, 0.15512042)
decoder loss ratio: 5962.529700, decoder SINDy loss  ratio: 0.413589
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10183869]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.831463]
 [  0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1020.4103393554688, (604.6377, 0.29747, 415.47516, 0.15512574)
   validation loss 666.8143920898438, (459.82736, 0.052503143, 206.93454, 0.15512574)
decoder loss ratio: 17814.510302, decoder SINDy loss  ratio: 0.446697
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10172565]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.916378]
 [  0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 627.7763671875, (217.1191, 0.29313865, 410.36417, 0.15512948)
   validation loss 343.84027099609375, (152.67007, 0.04578157, 191.12442, 0.15512948)
decoder loss ratio: 5914.703732, decoder SINDy loss  ratio: 0.412569
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1015828]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [-16.8561]
 [ -0.    ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 910.910400390625, (496.3999, 0.2939685, 414.2165, 0.1551361)
   validation loss 566.9034423828125, (365.7512, 0.051351696, 201.10092, 0.1551361)
decoder loss ratio: 14169.836080, decoder SINDy loss  ratio: 0.434105
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10157324]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.943378]
 [  0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.6536865234375, (256.8071, 0.28802687, 419.55853, 0.15513578)
   validation loss 421.3017883300781, (227.85127, 0.041190643, 193.40933, 0.15513578)
decoder loss ratio: 8827.353867, decoder SINDy loss  ratio: 0.417501
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10150174]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.959166]
 [  0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.5732421875, (269.44415, 0.3150569, 425.81406, 0.1551403)
   validation loss 440.5736999511719, (247.22957, 0.04530128, 193.29883, 0.1551403)
decoder loss ratio: 9578.102692, decoder SINDy loss  ratio: 0.417263
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10146602]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.876764]
 [  0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 957.1468505859375, (520.254, 0.26651987, 436.62628, 0.15514018)
   validation loss 724.0576171875, (521.2059, 0.039844584, 202.81186, 0.15514018)
decoder loss ratio: 20192.420318, decoder SINDy loss  ratio: 0.437798
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10141861]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.992176]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.9820556640625, (264.38776, 0.26077834, 422.33353, 0.15514368)
   validation loss 436.1650085449219, (241.47649, 0.03867323, 194.64986, 0.15514368)
decoder loss ratio: 9355.218297, decoder SINDy loss  ratio: 0.420179
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10125445]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.90911]
 [ -0.     ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 638.5000610351562, (218.499, 0.30302718, 419.69806, 0.15514956)
   validation loss 354.20281982421875, (165.50844, 0.045288596, 188.64908, 0.15514956)
decoder loss ratio: 6412.084228, decoder SINDy loss  ratio: 0.407226
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10120787]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.940607]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1336.251220703125, (901.5187, 0.27435827, 434.4582, 0.15515213)
   validation loss 946.799072265625, (724.1435, 0.05178879, 222.60379, 0.15515213)
decoder loss ratio: 28054.576112, decoder SINDy loss  ratio: 0.480522
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1011593]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.936804]
 [  0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.7799072265625, (230.89244, 0.27472684, 416.61273, 0.15515329)
   validation loss 350.292236328125, (158.18025, 0.04403739, 192.06796, 0.15515329)
decoder loss ratio: 6128.177578, decoder SINDy loss  ratio: 0.414606
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1010381]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.01194]
 [ -0.     ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.88623046875, (380.8682, 0.2728479, 417.74515, 0.1551594)
   validation loss 468.6007385253906, (270.26474, 0.04726412, 198.28873, 0.1551594)
decoder loss ratio: 10470.525227, decoder SINDy loss  ratio: 0.428034
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1009461]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.028551]
 [  0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.3110961914062, (242.79997, 0.25654766, 424.25458, 0.15516227)
   validation loss 393.586669921875, (201.79668, 0.04086717, 191.74913, 0.15516227)
decoder loss ratio: 7817.953587, decoder SINDy loss  ratio: 0.413917
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10091228]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.948889]
 [  0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.056640625, (336.839, 0.26259133, 418.95505, 0.1551638)
   validation loss 432.1406555175781, (235.45073, 0.04772653, 196.6422, 0.1551638)
decoder loss ratio: 9121.770016, decoder SINDy loss  ratio: 0.424480
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10080815]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.943708]
 [  0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.7449951171875, (254.78738, 0.2520177, 427.7056, 0.1551674)
   validation loss 407.97161865234375, (216.0231, 0.040003892, 191.90851, 0.1551674)
decoder loss ratio: 8369.109997, decoder SINDy loss  ratio: 0.414262
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10073792]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.978298]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.9492797851562, (329.8313, 0.2577635, 421.86023, 0.15517135)
   validation loss 423.70831298828125, (227.53632, 0.044142827, 196.12784, 0.15517135)
decoder loss ratio: 8815.151899, decoder SINDy loss  ratio: 0.423370
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10065837]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.003649]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.6734008789062, (251.15364, 0.24341074, 429.27634, 0.15517393)
   validation loss 401.68438720703125, (209.92514, 0.04103226, 191.71822, 0.15517393)
decoder loss ratio: 8132.864384, decoder SINDy loss  ratio: 0.413851
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10061777]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.002441]
 [  0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.0466918945312, (338.11737, 0.24893309, 423.6804, 0.15517645)
   validation loss 432.2388916015625, (235.3845, 0.046817426, 196.80757, 0.15517645)
decoder loss ratio: 9119.204417, decoder SINDy loss  ratio: 0.424837
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10058948]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.971745]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.6539916992188, (228.96219, 0.2413693, 430.45044, 0.15517762)
   validation loss 380.33929443359375, (189.60374, 0.03847973, 190.69707, 0.15517762)
decoder loss ratio: 7345.578229, decoder SINDy loss  ratio: 0.411646
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10046163]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.954391]
 [ -0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.1412353515625, (225.93915, 0.2519491, 432.9501, 0.15518361)
   validation loss 378.48211669921875, (188.74033, 0.039624885, 189.70216, 0.15518361)
decoder loss ratio: 7312.127894, decoder SINDy loss  ratio: 0.409499
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10041973]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.022043]
 [  0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1147.0035400390625, (683.4573, 0.21992226, 463.3264, 0.15518256)
   validation loss 898.7275390625, (690.9331, 0.042088356, 207.75232, 0.15518256)
decoder loss ratio: 26767.948018, decoder SINDy loss  ratio: 0.448463
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10035782]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.017128]
 [ -0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 914.004150390625, (485.44376, 0.2548518, 428.3055, 0.15518802)
   validation loss 557.3006591796875, (357.89374, 0.0577125, 199.34924, 0.15518802)
decoder loss ratio: 13865.424733, decoder SINDy loss  ratio: 0.430323
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10031565]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.003231]
 [  0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.5912475585938, (353.24356, 0.23868288, 430.109, 0.15518917)
   validation loss 442.3161926269531, (245.35693, 0.044968575, 196.91429, 0.15518917)
decoder loss ratio: 9505.553566, decoder SINDy loss  ratio: 0.425067
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10021853]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.020737]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.8304443359375, (239.67259, 0.22578944, 431.93204, 0.1551938)
   validation loss 358.9810791015625, (165.57628, 0.0400378, 193.36475, 0.1551938)
decoder loss ratio: 6414.712489, decoder SINDy loss  ratio: 0.417405
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10009661]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.000906]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.5082397460938, (251.53911, 0.2227574, 439.74637, 0.15519767)
   validation loss 410.115966796875, (219.7325, 0.038402658, 190.34506, 0.15519767)
decoder loss ratio: 8512.818451, decoder SINDy loss  ratio: 0.410887
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10005104]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.96045]
 [ -0.     ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1270.318603515625, (787.52344, 0.20943576, 482.5858, 0.15519844)
   validation loss 1008.0657348632812, (792.9217, 0.047193225, 215.09685, 0.15519844)
decoder loss ratio: 30719.162917, decoder SINDy loss  ratio: 0.464317
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09996258]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.968344]
 [ -0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.07958984375, (301.75638, 0.2275499, 435.0957, 0.15520506)
   validation loss 396.5538635253906, (203.04477, 0.057667937, 193.45143, 0.15520506)
decoder loss ratio: 7866.306863, decoder SINDy loss  ratio: 0.417592
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0998719]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.943947]
 [ -0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1006.2548217773438, (542.3134, 0.19627887, 463.74512, 0.1552088)
   validation loss 756.2784423828125, (552.0825, 0.032294877, 204.16364, 0.1552088)
decoder loss ratio: 21388.635264, decoder SINDy loss  ratio: 0.440716
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09966926]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.01046]
 [ -0.     ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.94921875, (400.66797, 0.2020702, 457.07922, 0.15521535)
   validation loss 582.818359375, (386.12244, 0.041487206, 196.65442, 0.15521535)
decoder loss ratio: 14959.053529, decoder SINDy loss  ratio: 0.424506
params['save_name']
pendulum_2023_10_25_23_23_43_764624
