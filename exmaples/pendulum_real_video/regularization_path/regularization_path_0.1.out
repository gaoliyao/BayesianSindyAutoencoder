nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-11-07 07:49:19.798875: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-11-07 07:49:19.807116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-11-07 07:49:19.808686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5614d3181420 executing computations on platform Host. Devices:
2023-11-07 07:49:19.808732: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-11-07 07:49:19.810894: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-11-07 07:49:19.929667: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5614d3291b60 executing computations on platform CUDA. Devices:
2023-11-07 07:49:19.929705: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-11-07 07:49:19.930188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-11-07 07:49:19.931684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-07 07:49:19.938475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-11-07 07:49:19.942555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-11-07 07:49:19.945289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-11-07 07:49:19.950393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-11-07 07:49:19.952382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-11-07 07:49:19.959446: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-11-07 07:49:19.960180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-11-07 07:49:19.960221: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-07 07:49:19.960610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-11-07 07:49:19.960622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-11-07 07:49:19.960629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-11-07 07:49:19.961278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-11-07 07:49:21.232139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.1, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8228492736816406 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 108858.859375, (100659.695, 0.0048225066, 8181.4976, 2.5317795)
   validation loss 84288.8046875, (83070.39, 0.0016341147, 1200.7561, 2.5317795)
decoder loss ratio: 3218291.149353, decoder SINDy loss  ratio: 2.592001
--- 0.1550126075744629 seconds for one epoch ---
--- 0.2091975212097168 seconds for one epoch ---
--- 0.23676061630249023 seconds for one epoch ---
--- 0.18602442741394043 seconds for one epoch ---
--- 0.2131345272064209 seconds for one epoch ---
--- 0.2086961269378662 seconds for one epoch ---
--- 0.25302553176879883 seconds for one epoch ---
--- 0.1856238842010498 seconds for one epoch ---
--- 0.20789051055908203 seconds for one epoch ---
--- 0.16871261596679688 seconds for one epoch ---
--- 0.23038196563720703 seconds for one epoch ---
--- 0.1665022373199463 seconds for one epoch ---
--- 0.24178123474121094 seconds for one epoch ---
--- 0.1822350025177002 seconds for one epoch ---
--- 0.26390695571899414 seconds for one epoch ---
--- 0.2113049030303955 seconds for one epoch ---
--- 0.20364880561828613 seconds for one epoch ---
--- 0.17749953269958496 seconds for one epoch ---
--- 0.22209668159484863 seconds for one epoch ---
--- 0.19678473472595215 seconds for one epoch ---
--- 0.21969866752624512 seconds for one epoch ---
--- 0.20704078674316406 seconds for one epoch ---
--- 0.23460698127746582 seconds for one epoch ---
--- 0.20084023475646973 seconds for one epoch ---
=========================
[[0.80475396]
 [0.8169595 ]
 [0.9982755 ]
 [0.8381204 ]
 [0.77172947]
 [0.9936796 ]
 [0.8896139 ]
 [0.7727901 ]
 [0.7716888 ]
 [0.999997  ]
 [0.78710383]]
[[ 0.46810356]
 [ 0.5056981 ]
 [-1.1345266 ]
 [-0.5561365 ]
 [-0.02700457]
 [-1.002024  ]
 [ 0.6517562 ]
 [-0.14446093]
 [ 0.0180802 ]
 [-1.8006002 ]
 [ 0.38447556]]
--- 0.1774914264678955 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 60170.375, (49129.8, 62.73339, 10941.154, 2.5317562)
   validation loss 42563.69921875, (41252.62, 21.074738, 1253.3165, 2.5317562)
decoder loss ratio: 1598198.158872, decoder SINDy loss  ratio: 2.705460
--- 0.16772198677062988 seconds for one epoch ---
--- 0.23592066764831543 seconds for one epoch ---
--- 0.23551464080810547 seconds for one epoch ---
--- 0.1976161003112793 seconds for one epoch ---
--- 0.1780691146850586 seconds for one epoch ---
--- 0.2195448875427246 seconds for one epoch ---
--- 0.1867682933807373 seconds for one epoch ---
--- 0.2514364719390869 seconds for one epoch ---
--- 0.19581198692321777 seconds for one epoch ---
--- 0.2362828254699707 seconds for one epoch ---
--- 0.20201992988586426 seconds for one epoch ---
--- 0.24130868911743164 seconds for one epoch ---
--- 0.1837773323059082 seconds for one epoch ---
--- 0.22191667556762695 seconds for one epoch ---
--- 0.17862629890441895 seconds for one epoch ---
--- 0.25504255294799805 seconds for one epoch ---
--- 0.1978287696838379 seconds for one epoch ---
--- 0.24753260612487793 seconds for one epoch ---
--- 0.21357059478759766 seconds for one epoch ---
--- 0.24748516082763672 seconds for one epoch ---
--- 0.19998645782470703 seconds for one epoch ---
--- 0.2573275566101074 seconds for one epoch ---
--- 0.17917346954345703 seconds for one epoch ---
--- 0.26515913009643555 seconds for one epoch ---
=========================
[[0.9975293 ]
 [0.6116571 ]
 [0.985483  ]
 [0.6571746 ]
 [0.61019033]
 [0.9997491 ]
 [0.64600885]
 [0.6122718 ]
 [0.60928494]
 [0.926972  ]
 [0.6309748 ]]
[[ 1.1524699 ]
 [ 0.15783414]
 [-0.97146726]
 [-0.44881418]
 [ 0.09046093]
 [-1.3830599 ]
 [ 0.41940662]
 [ 0.17660272]
 [ 0.00143715]
 [-0.7924073 ]
 [ 0.3636702 ]]
--- 0.21948790550231934 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 38789.859375, (31890.35, 89.33511, 6755.2134, 2.5317378)
   validation loss 36293.6484375, (35063.55, 5.054466, 1170.0815, 2.5317378)
decoder loss ratio: 1358422.830267, decoder SINDy loss  ratio: 2.525786
--- 0.2396104335784912 seconds for one epoch ---
--- 0.27285218238830566 seconds for one epoch ---
--- 0.2586956024169922 seconds for one epoch ---
--- 0.19400572776794434 seconds for one epoch ---
--- 0.25475430488586426 seconds for one epoch ---
--- 0.18513917922973633 seconds for one epoch ---
--- 0.27945423126220703 seconds for one epoch ---
--- 0.1841261386871338 seconds for one epoch ---
--- 0.24406170845031738 seconds for one epoch ---
--- 0.18211793899536133 seconds for one epoch ---
--- 0.2834587097167969 seconds for one epoch ---
--- 0.1930093765258789 seconds for one epoch ---
--- 0.257352352142334 seconds for one epoch ---
--- 0.19739961624145508 seconds for one epoch ---
--- 0.26859474182128906 seconds for one epoch ---
--- 0.25357770919799805 seconds for one epoch ---
--- 0.24505996704101562 seconds for one epoch ---
--- 0.16575026512145996 seconds for one epoch ---
--- 0.23247075080871582 seconds for one epoch ---
--- 0.17737197875976562 seconds for one epoch ---
--- 0.2420659065246582 seconds for one epoch ---
--- 0.19658684730529785 seconds for one epoch ---
--- 0.23661017417907715 seconds for one epoch ---
--- 0.2078237533569336 seconds for one epoch ---
=========================
[[0.999517  ]
 [0.47463655]
 [0.99104744]
 [0.53205174]
 [0.47484428]
 [0.99999434]
 [0.5456866 ]
 [0.48064524]
 [0.47331616]
 [0.48227042]
 [0.47955346]]
[[ 1.3471195 ]
 [ 0.09544655]
 [-1.0520653 ]
 [-0.43823466]
 [ 0.10459329]
 [-1.789553  ]
 [ 0.46183825]
 [ 0.22904597]
 [ 0.00208787]
 [-0.24747802]
 [ 0.21450932]]
--- 0.18301177024841309 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 30648.4375, (21737.785, 12.899874, 8828.119, 2.53175)
   validation loss 23714.09375, (22584.15, 0.65161276, 1059.6583, 2.53175)
decoder loss ratio: 874949.193942, decoder SINDy loss  ratio: 2.287422
--- 0.18865561485290527 seconds for one epoch ---
--- 0.26531362533569336 seconds for one epoch ---
--- 0.16578984260559082 seconds for one epoch ---
--- 0.2710847854614258 seconds for one epoch ---
--- 0.16951417922973633 seconds for one epoch ---
--- 0.23430943489074707 seconds for one epoch ---
--- 0.1855630874633789 seconds for one epoch ---
--- 0.262218713760376 seconds for one epoch ---
--- 0.1949920654296875 seconds for one epoch ---
--- 0.2662391662597656 seconds for one epoch ---
--- 0.18356585502624512 seconds for one epoch ---
--- 0.24679017066955566 seconds for one epoch ---
--- 0.1901226043701172 seconds for one epoch ---
--- 0.272266149520874 seconds for one epoch ---
--- 0.18694257736206055 seconds for one epoch ---
--- 0.24884772300720215 seconds for one epoch ---
--- 0.15711331367492676 seconds for one epoch ---
--- 0.27869749069213867 seconds for one epoch ---
--- 0.1860039234161377 seconds for one epoch ---
--- 0.2557046413421631 seconds for one epoch ---
--- 0.21304559707641602 seconds for one epoch ---
--- 0.2669520378112793 seconds for one epoch ---
--- 0.22096490859985352 seconds for one epoch ---
--- 0.2641928195953369 seconds for one epoch ---
=========================
[[0.9980357 ]
 [0.37736717]
 [0.99891555]
 [0.46167907]
 [0.37786075]
 [1.        ]
 [0.42523125]
 [0.39011028]
 [0.37605503]
 [0.376544  ]
 [0.39711592]]
[[ 1.2228628e+00]
 [ 8.4740385e-02]
 [-1.2827549e+00]
 [-4.6167848e-01]
 [ 1.0411146e-01]
 [-2.2849457e+00]
 [ 4.0042555e-01]
 [ 2.7398115e-01]
 [-1.1738609e-03]
 [-4.0786128e-02]
 [ 3.1337428e-01]]
--- 0.19934701919555664 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 23361.87109375, (17857.838, 32.702923, 5385.197, 2.531775)
   validation loss 8601.380859375, (7515.049, 0.6191669, 999.57825, 2.531775)
decoder loss ratio: 291146.038300, decoder SINDy loss  ratio: 2.157730
--- 0.15538811683654785 seconds for one epoch ---
--- 0.2152242660522461 seconds for one epoch ---
--- 0.29614925384521484 seconds for one epoch ---
--- 0.20381999015808105 seconds for one epoch ---
--- 0.2701263427734375 seconds for one epoch ---
--- 0.17186427116394043 seconds for one epoch ---
--- 0.2819838523864746 seconds for one epoch ---
--- 0.19991827011108398 seconds for one epoch ---
--- 0.28500962257385254 seconds for one epoch ---
--- 0.22757887840270996 seconds for one epoch ---
--- 0.261462926864624 seconds for one epoch ---
--- 0.1965024471282959 seconds for one epoch ---
--- 0.31346750259399414 seconds for one epoch ---
--- 0.21538233757019043 seconds for one epoch ---
--- 0.26287269592285156 seconds for one epoch ---
--- 0.1916980743408203 seconds for one epoch ---
--- 0.27793145179748535 seconds for one epoch ---
--- 0.19786381721496582 seconds for one epoch ---
--- 0.27323293685913086 seconds for one epoch ---
--- 0.19898104667663574 seconds for one epoch ---
--- 0.256375789642334 seconds for one epoch ---
--- 0.19945430755615234 seconds for one epoch ---
--- 0.26825642585754395 seconds for one epoch ---
--- 0.17432069778442383 seconds for one epoch ---
=========================
[[0.94733816]
 [0.29449788]
 [0.99983525]
 [0.38606998]
 [0.29521456]
 [1.        ]
 [0.32748166]
 [0.31136918]
 [0.29414937]
 [0.2981742 ]
 [0.32285494]]
[[ 0.8975201 ]
 [ 0.03118289]
 [-1.4849449 ]
 [-0.4557371 ]
 [ 0.06951375]
 [-2.7401407 ]
 [ 0.34723085]
 [ 0.28191125]
 [-0.00545022]
 [-0.1537747 ]
 [ 0.33213574]]
--- 0.1499311923980713 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 22342.806640625, (15311.529, 2.112628, 6930.935, 2.5317976)
   validation loss 8118.93603515625, (7130.2437, 0.3286474, 890.13403, 2.5317976)
decoder loss ratio: 276238.017739, decoder SINDy loss  ratio: 1.921480
--- 0.18137907981872559 seconds for one epoch ---
--- 0.2650749683380127 seconds for one epoch ---
--- 0.19907140731811523 seconds for one epoch ---
--- 0.30904507637023926 seconds for one epoch ---
--- 0.20798802375793457 seconds for one epoch ---
--- 0.28020191192626953 seconds for one epoch ---
--- 0.209122896194458 seconds for one epoch ---
--- 0.27599263191223145 seconds for one epoch ---
--- 0.1786501407623291 seconds for one epoch ---
--- 0.28409671783447266 seconds for one epoch ---
--- 0.20119619369506836 seconds for one epoch ---
--- 0.25858330726623535 seconds for one epoch ---
--- 0.19594049453735352 seconds for one epoch ---
--- 0.28936290740966797 seconds for one epoch ---
--- 0.1931753158569336 seconds for one epoch ---
--- 0.25368309020996094 seconds for one epoch ---
--- 0.17826128005981445 seconds for one epoch ---
--- 0.281447172164917 seconds for one epoch ---
--- 0.17869901657104492 seconds for one epoch ---
--- 0.257343053817749 seconds for one epoch ---
--- 0.1770927906036377 seconds for one epoch ---
--- 0.2907238006591797 seconds for one epoch ---
--- 0.17190217971801758 seconds for one epoch ---
--- 0.3168308734893799 seconds for one epoch ---
=========================
[[0.521158  ]
 [0.23536986]
 [0.9999502 ]
 [0.3047025 ]
 [0.23595625]
 [1.        ]
 [0.2600362 ]
 [0.2602633 ]
 [0.23516312]
 [0.26982892]
 [0.33012617]]
[[ 0.5935386 ]
 [-0.01906731]
 [-1.6125652 ]
 [-0.41584322]
 [ 0.05256413]
 [-3.1163921 ]
 [ 0.30982548]
 [ 0.3107221 ]
 [ 0.00396596]
 [-0.3430142 ]
 [ 0.45030516]]
--- 0.21365880966186523 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13563.7822265625, (7189.702, 1.233547, 6262.7783, 2.5318224)
   validation loss 8297.0078125, (7436.4097, 0.18484296, 750.3452, 2.5318224)
decoder loss ratio: 288099.420712, decoder SINDy loss  ratio: 1.619726
--- 0.1754915714263916 seconds for one epoch ---
--- 0.18453216552734375 seconds for one epoch ---
--- 0.2682032585144043 seconds for one epoch ---
--- 0.17896556854248047 seconds for one epoch ---
--- 0.31769466400146484 seconds for one epoch ---
--- 0.1889171600341797 seconds for one epoch ---
--- 0.3112969398498535 seconds for one epoch ---
--- 0.16810917854309082 seconds for one epoch ---
--- 0.2958869934082031 seconds for one epoch ---
--- 0.19511103630065918 seconds for one epoch ---
--- 0.28432512283325195 seconds for one epoch ---
--- 0.178009033203125 seconds for one epoch ---
--- 0.2660701274871826 seconds for one epoch ---
--- 0.18452811241149902 seconds for one epoch ---
--- 0.29244041442871094 seconds for one epoch ---
--- 0.1992475986480713 seconds for one epoch ---
--- 0.3011040687561035 seconds for one epoch ---
--- 0.20416641235351562 seconds for one epoch ---
--- 0.2950139045715332 seconds for one epoch ---
--- 0.23019671440124512 seconds for one epoch ---
--- 0.2866802215576172 seconds for one epoch ---
--- 0.21173644065856934 seconds for one epoch ---
--- 0.3107740879058838 seconds for one epoch ---
--- 0.23790383338928223 seconds for one epoch ---
=========================
[[0.21611784]
 [0.18971704]
 [0.9999706 ]
 [0.23568791]
 [0.18562889]
 [1.        ]
 [0.19741036]
 [0.21599783]
 [0.18517885]
 [0.38048404]
 [0.33392096]]
[[ 0.3252116 ]
 [-0.15165973]
 [-1.673621  ]
 [-0.37518138]
 [ 0.03288694]
 [-3.4550989 ]
 [ 0.23618402]
 [ 0.32482326]
 [-0.00420301]
 [-0.52974635]
 [ 0.49540985]]
--- 0.15151524543762207 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13664.3603515625, (8733.038, 4.11883, 4805.4717, 2.531847)
   validation loss 4983.38623046875, (3992.454, 0.26153773, 868.9398, 2.531847)
decoder loss ratio: 154674.603100, decoder SINDy loss  ratio: 1.875729
--- 0.2220911979675293 seconds for one epoch ---
--- 0.310866117477417 seconds for one epoch ---
--- 0.1686851978302002 seconds for one epoch ---
--- 0.3006002902984619 seconds for one epoch ---
--- 0.15958523750305176 seconds for one epoch ---
--- 0.2796797752380371 seconds for one epoch ---
--- 0.1692061424255371 seconds for one epoch ---
--- 0.28898119926452637 seconds for one epoch ---
--- 0.15689754486083984 seconds for one epoch ---
--- 0.2739071846008301 seconds for one epoch ---
--- 0.1580641269683838 seconds for one epoch ---
--- 0.31516337394714355 seconds for one epoch ---
--- 0.18163251876831055 seconds for one epoch ---
--- 0.36531734466552734 seconds for one epoch ---
--- 0.21743249893188477 seconds for one epoch ---
--- 0.33449506759643555 seconds for one epoch ---
--- 0.18692564964294434 seconds for one epoch ---
--- 0.31462860107421875 seconds for one epoch ---
--- 0.1870589256286621 seconds for one epoch ---
--- 0.2966344356536865 seconds for one epoch ---
--- 0.18261146545410156 seconds for one epoch ---
--- 0.3047199249267578 seconds for one epoch ---
--- 0.17631244659423828 seconds for one epoch ---
--- 0.29480481147766113 seconds for one epoch ---
=========================
[[0.15028828]
 [0.15514693]
 [0.9999832 ]
 [0.17817941]
 [0.1495612 ]
 [1.        ]
 [0.15855789]
 [0.18352196]
 [0.14897715]
 [0.76362765]
 [0.35466582]]
[[ 6.9048740e-02]
 [-1.7244482e-01]
 [-1.7261701e+00]
 [-3.1507289e-01]
 [ 3.7691452e-02]
 [-3.7273734e+00]
 [ 2.1009010e-01]
 [ 3.3183888e-01]
 [-2.6727912e-03]
 [-7.4081916e-01]
 [ 5.3082985e-01]]
--- 0.20849347114562988 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6249.84326171875, (3261.4785, 0.39409348, 2857.9673, 2.53187)
   validation loss 4436.78515625, (3640.3752, 0.20257482, 666.2037, 2.53187)
decoder loss ratio: 141034.456927, decoder SINDy loss  ratio: 1.438094
--- 0.1737840175628662 seconds for one epoch ---
--- 0.22628283500671387 seconds for one epoch ---
--- 0.33858585357666016 seconds for one epoch ---
--- 0.2107234001159668 seconds for one epoch ---
--- 0.3020751476287842 seconds for one epoch ---
--- 0.19008588790893555 seconds for one epoch ---
--- 0.343109130859375 seconds for one epoch ---
--- 0.18053889274597168 seconds for one epoch ---
--- 0.3042142391204834 seconds for one epoch ---
--- 0.16555142402648926 seconds for one epoch ---
--- 0.3085644245147705 seconds for one epoch ---
--- 0.1805405616760254 seconds for one epoch ---
--- 0.29991698265075684 seconds for one epoch ---
--- 0.18244433403015137 seconds for one epoch ---
--- 0.29224205017089844 seconds for one epoch ---
--- 0.28670668601989746 seconds for one epoch ---
--- 0.30785322189331055 seconds for one epoch ---
--- 0.2008800506591797 seconds for one epoch ---
--- 0.310727596282959 seconds for one epoch ---
--- 0.17674899101257324 seconds for one epoch ---
--- 0.2850165367126465 seconds for one epoch ---
--- 0.18683242797851562 seconds for one epoch ---
--- 0.3277926445007324 seconds for one epoch ---
--- 0.1844496726989746 seconds for one epoch ---
=========================
[[0.12276763]
 [0.13142835]
 [0.9999833 ]
 [0.1550788 ]
 [0.11836927]
 [1.        ]
 [0.12462301]
 [0.15239567]
 [0.11813956]
 [0.9545075 ]
 [0.34349957]]
[[-1.4688866e-01]
 [-2.3645705e-01]
 [-1.7364243e+00]
 [-3.3502778e-01]
 [ 1.8072274e-02]
 [-3.9127915e+00]
 [ 1.7373081e-01]
 [ 3.2745644e-01]
 [ 3.4188067e-03]
 [-9.3701214e-01]
 [ 5.3823173e-01]]
--- 0.19510459899902344 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9469.703125, (4746.417, 3.7803254, 4581.6084, 2.5318906)
   validation loss 2684.943115234375, (2039.7739, 0.1270165, 507.1454, 2.5318906)
decoder loss ratio: 79024.383088, decoder SINDy loss  ratio: 1.094745
--- 0.21474933624267578 seconds for one epoch ---
--- 0.3365778923034668 seconds for one epoch ---
--- 0.19490742683410645 seconds for one epoch ---
--- 0.35472607612609863 seconds for one epoch ---
--- 0.19786739349365234 seconds for one epoch ---
--- 0.3321211338043213 seconds for one epoch ---
--- 0.18146681785583496 seconds for one epoch ---
--- 0.3410680294036865 seconds for one epoch ---
--- 0.18021512031555176 seconds for one epoch ---
--- 0.3224928379058838 seconds for one epoch ---
--- 0.17261385917663574 seconds for one epoch ---
--- 0.32524871826171875 seconds for one epoch ---
--- 0.20562148094177246 seconds for one epoch ---
--- 0.30687475204467773 seconds for one epoch ---
--- 0.1946544647216797 seconds for one epoch ---
--- 0.3179323673248291 seconds for one epoch ---
--- 0.1877298355102539 seconds for one epoch ---
--- 0.3560819625854492 seconds for one epoch ---
--- 0.20185327529907227 seconds for one epoch ---
--- 0.32271361351013184 seconds for one epoch ---
--- 0.19447898864746094 seconds for one epoch ---
--- 0.3279581069946289 seconds for one epoch ---
--- 0.1869955062866211 seconds for one epoch ---
--- 0.3394303321838379 seconds for one epoch ---
=========================
[[0.12453138]
 [0.11903133]
 [0.9999528 ]
 [0.13493493]
 [0.09586149]
 [1.        ]
 [0.09989457]
 [0.12985042]
 [0.09568871]
 [0.9903014 ]
 [0.4199118 ]]
[[-3.0789760e-01]
 [-2.8724688e-01]
 [-1.6342534e+00]
 [-3.3861360e-01]
 [ 1.4654688e-02]
 [-4.0204883e+00]
 [ 1.3785788e-01]
 [ 3.2468086e-01]
 [-3.7291730e-03]
 [-1.0989475e+00]
 [ 5.8690548e-01]]
--- 0.21172738075256348 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9609.701171875, (5615.633, 1.0628428, 3848.601, 2.531904)
   validation loss 4271.2607421875, (3669.3508, 0.10503514, 457.4009, 2.531904)
decoder loss ratio: 142157.021430, decoder SINDy loss  ratio: 0.987364
--- 0.1505117416381836 seconds for one epoch ---
--- 0.18686842918395996 seconds for one epoch ---
--- 0.3673691749572754 seconds for one epoch ---
--- 0.19549012184143066 seconds for one epoch ---
--- 0.3163139820098877 seconds for one epoch ---
--- 0.1736893653869629 seconds for one epoch ---
--- 0.32430195808410645 seconds for one epoch ---
--- 0.21567726135253906 seconds for one epoch ---
--- 0.3194310665130615 seconds for one epoch ---
--- 0.17963624000549316 seconds for one epoch ---
--- 0.37501072883605957 seconds for one epoch ---
--- 0.1997830867767334 seconds for one epoch ---
--- 0.3755350112915039 seconds for one epoch ---
--- 0.1948564052581787 seconds for one epoch ---
--- 0.3486907482147217 seconds for one epoch ---
--- 0.18727970123291016 seconds for one epoch ---
--- 0.3614475727081299 seconds for one epoch ---
--- 0.20367121696472168 seconds for one epoch ---
--- 0.38832926750183105 seconds for one epoch ---
--- 0.17371201515197754 seconds for one epoch ---
--- 0.37079811096191406 seconds for one epoch ---
--- 0.17116832733154297 seconds for one epoch ---
--- 0.3497581481933594 seconds for one epoch ---
--- 0.21591782569885254 seconds for one epoch ---
=========================
[[0.16110934]
 [0.11391752]
 [0.9998657 ]
 [0.11630892]
 [0.07645701]
 [1.        ]
 [0.08113413]
 [0.11111752]
 [0.07652932]
 [0.9972986 ]
 [0.58230895]]
[[-0.41674247]
 [-0.33186027]
 [-1.5321013 ]
 [-0.33808818]
 [ 0.00513248]
 [-4.0417695 ]
 [ 0.14459977]
 [ 0.3240873 ]
 [-0.00969232]
 [-1.2302744 ]
 [ 0.6642694 ]]
--- 0.17192459106445312 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5915.962890625, (3551.0515, 5.0098505, 2209.801, 2.531909)
   validation loss 5131.736328125, (4503.991, 0.12065293, 477.5246, 2.531909)
decoder loss ratio: 174492.438784, decoder SINDy loss  ratio: 1.030804
--- 0.2302398681640625 seconds for one epoch ---
--- 0.36032986640930176 seconds for one epoch ---
--- 0.1739788055419922 seconds for one epoch ---
--- 0.35713791847229004 seconds for one epoch ---
--- 0.19551777839660645 seconds for one epoch ---
--- 0.35462284088134766 seconds for one epoch ---
--- 0.21469473838806152 seconds for one epoch ---
--- 0.37575197219848633 seconds for one epoch ---
--- 0.20122361183166504 seconds for one epoch ---
--- 0.4040696620941162 seconds for one epoch ---
--- 0.19886469841003418 seconds for one epoch ---
--- 0.3912942409515381 seconds for one epoch ---
--- 0.19028568267822266 seconds for one epoch ---
--- 0.3823831081390381 seconds for one epoch ---
--- 0.19203877449035645 seconds for one epoch ---
--- 0.35611820220947266 seconds for one epoch ---
--- 0.1862807273864746 seconds for one epoch ---
--- 0.35628604888916016 seconds for one epoch ---
--- 0.20299363136291504 seconds for one epoch ---
--- 0.3538036346435547 seconds for one epoch ---
--- 0.20130467414855957 seconds for one epoch ---
--- 0.37265586853027344 seconds for one epoch ---
--- 0.20836210250854492 seconds for one epoch ---
--- 0.3369009494781494 seconds for one epoch ---
=========================
[[0.2974175 ]
 [0.11633144]
 [0.9997182 ]
 [0.09708802]
 [0.06272581]
 [1.        ]
 [0.06679855]
 [0.1013988 ]
 [0.06231633]
 [0.99935544]
 [0.6140974 ]]
[[-5.3567785e-01]
 [-3.6751118e-01]
 [-1.4590600e+00]
 [-3.2276186e-01]
 [ 2.5871184e-02]
 [-4.0633988e+00]
 [ 1.3948491e-01]
 [ 3.3447722e-01]
 [ 2.1123036e-03]
 [-1.3759781e+00]
 [ 6.8089068e-01]]
--- 0.20060467720031738 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4774.1689453125, (3308.4236, 0.62932205, 1310.2318, 2.5319164)
   validation loss 5638.685546875, (5027.043, 0.10833987, 456.65005, 2.5319164)
decoder loss ratio: 194756.371940, decoder SINDy loss  ratio: 0.985743
--- 0.25214409828186035 seconds for one epoch ---
--- 0.17154455184936523 seconds for one epoch ---
--- 0.37166690826416016 seconds for one epoch ---
--- 0.17950153350830078 seconds for one epoch ---
--- 0.3980703353881836 seconds for one epoch ---
--- 0.2034444808959961 seconds for one epoch ---
--- 0.3674771785736084 seconds for one epoch ---
--- 0.18822193145751953 seconds for one epoch ---
--- 0.38782286643981934 seconds for one epoch ---
--- 0.20642805099487305 seconds for one epoch ---
--- 0.40139007568359375 seconds for one epoch ---
--- 0.1953895092010498 seconds for one epoch ---
--- 0.3531913757324219 seconds for one epoch ---
--- 0.19681286811828613 seconds for one epoch ---
--- 0.36930036544799805 seconds for one epoch ---
--- 0.18396735191345215 seconds for one epoch ---
--- 0.404721736907959 seconds for one epoch ---
--- 0.2095484733581543 seconds for one epoch ---
--- 0.39708495140075684 seconds for one epoch ---
--- 0.20493435859680176 seconds for one epoch ---
--- 0.38904333114624023 seconds for one epoch ---
--- 0.20019221305847168 seconds for one epoch ---
--- 0.3846454620361328 seconds for one epoch ---
--- 0.22381806373596191 seconds for one epoch ---
=========================
[[0.5408118 ]
 [0.14141127]
 [0.99966663]
 [0.0908265 ]
 [0.05047158]
 [1.        ]
 [0.05410855]
 [0.08471525]
 [0.05019221]
 [0.99985874]
 [0.585907  ]]
[[-6.5172118e-01]
 [-4.2179674e-01]
 [-1.4433841e+00]
 [-3.3717144e-01]
 [ 2.0172637e-02]
 [-4.0585451e+00]
 [ 1.2909564e-01]
 [ 3.2084066e-01]
 [-3.8342082e-03]
 [-1.5301116e+00]
 [ 6.7087483e-01]]
--- 0.1773078441619873 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4791.66650390625, (3322.1973, 5.3052926, 1303.6091, 2.531923)
   validation loss 2145.849609375, (1588.7767, 0.062280454, 396.4555, 2.531923)
decoder loss ratio: 61551.968890, decoder SINDy loss  ratio: 0.855805
--- 0.19437265396118164 seconds for one epoch ---
--- 0.41332578659057617 seconds for one epoch ---
--- 0.20361328125 seconds for one epoch ---
--- 0.37150025367736816 seconds for one epoch ---
--- 0.18081331253051758 seconds for one epoch ---
--- 0.3884549140930176 seconds for one epoch ---
--- 0.19276762008666992 seconds for one epoch ---
--- 0.37623071670532227 seconds for one epoch ---
--- 0.22847199440002441 seconds for one epoch ---
--- 0.40374040603637695 seconds for one epoch ---
--- 0.1693134307861328 seconds for one epoch ---
--- 0.3678610324859619 seconds for one epoch ---
--- 0.18862485885620117 seconds for one epoch ---
--- 0.40543675422668457 seconds for one epoch ---
--- 0.21082568168640137 seconds for one epoch ---
--- 0.3877546787261963 seconds for one epoch ---
--- 0.2044219970703125 seconds for one epoch ---
--- 0.39966678619384766 seconds for one epoch ---
--- 0.19575977325439453 seconds for one epoch ---
--- 0.40256285667419434 seconds for one epoch ---
--- 0.1664876937866211 seconds for one epoch ---
--- 0.4096512794494629 seconds for one epoch ---
--- 0.20717597007751465 seconds for one epoch ---
--- 0.39118123054504395 seconds for one epoch ---
=========================
[[0.7041391 ]
 [0.14634307]
 [0.9994123 ]
 [0.07153761]
 [0.04161326]
 [1.        ]
 [0.04528254]
 [0.07262766]
 [0.04119012]
 [0.9999603 ]
 [0.658818  ]]
[[-7.2589570e-01]
 [-4.3634653e-01]
 [-1.3875712e+00]
 [-3.0696371e-01]
 [ 2.4482572e-02]
 [-3.9869370e+00]
 [ 1.3054442e-01]
 [ 3.1044748e-01]
 [-5.4518896e-05]
 [-1.6537508e+00]
 [ 7.0451736e-01]]
--- 0.19687914848327637 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3616.380615234375, (2098.7388, 0.29954135, 1352.2377, 2.531922)
   validation loss 1758.338623046875, (1189.3994, 0.058045108, 403.77643, 2.531922)
decoder loss ratio: 46079.398189, decoder SINDy loss  ratio: 0.871608
--- 0.19841265678405762 seconds for one epoch ---
--- 0.22330069541931152 seconds for one epoch ---
--- 0.39774012565612793 seconds for one epoch ---
--- 0.1906888484954834 seconds for one epoch ---
--- 0.3895151615142822 seconds for one epoch ---
--- 0.22756624221801758 seconds for one epoch ---
--- 0.41263294219970703 seconds for one epoch ---
--- 0.19414877891540527 seconds for one epoch ---
--- 0.4066610336303711 seconds for one epoch ---
--- 0.18979144096374512 seconds for one epoch ---
--- 0.3864283561706543 seconds for one epoch ---
--- 0.21350598335266113 seconds for one epoch ---
--- 0.3910536766052246 seconds for one epoch ---
--- 0.18751740455627441 seconds for one epoch ---
--- 0.3978602886199951 seconds for one epoch ---
--- 0.1975555419921875 seconds for one epoch ---
--- 0.4146764278411865 seconds for one epoch ---
--- 0.20428085327148438 seconds for one epoch ---
--- 0.45949268341064453 seconds for one epoch ---
--- 0.2043004035949707 seconds for one epoch ---
--- 0.4051530361175537 seconds for one epoch ---
--- 0.20216989517211914 seconds for one epoch ---
--- 0.40399837493896484 seconds for one epoch ---
--- 0.20069408416748047 seconds for one epoch ---
=========================
[[0.8183229 ]
 [0.16455439]
 [0.9991101 ]
 [0.06431042]
 [0.03359257]
 [1.        ]
 [0.03833352]
 [0.06263385]
 [0.03343896]
 [0.99998915]
 [0.79160213]]
[[-7.9171079e-01]
 [-4.6033695e-01]
 [-1.3466574e+00]
 [-3.0785981e-01]
 [ 9.5918858e-03]
 [-3.9144042e+00]
 [ 1.4336024e-01]
 [ 3.0236351e-01]
 [ 9.9655292e-05]
 [-1.7668246e+00]
 [ 7.7447838e-01]]
--- 0.17496013641357422 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5668.53759765625, (2286.741, 0.48246902, 3211.7769, 2.531922)
   validation loss 1682.6849365234375, (1111.8107, 0.057773728, 401.27856, 2.531922)
decoder loss ratio: 43073.475503, decoder SINDy loss  ratio: 0.866216
--- 0.26589274406433105 seconds for one epoch ---
--- 0.4684603214263916 seconds for one epoch ---
--- 0.21874547004699707 seconds for one epoch ---
--- 0.45534181594848633 seconds for one epoch ---
--- 0.1931617259979248 seconds for one epoch ---
--- 0.3889462947845459 seconds for one epoch ---
--- 0.21981167793273926 seconds for one epoch ---
--- 0.40744781494140625 seconds for one epoch ---
--- 0.17718005180358887 seconds for one epoch ---
--- 0.4645378589630127 seconds for one epoch ---
--- 0.19896769523620605 seconds for one epoch ---
--- 0.3972048759460449 seconds for one epoch ---
--- 0.20998501777648926 seconds for one epoch ---
--- 0.437091588973999 seconds for one epoch ---
--- 0.2167198657989502 seconds for one epoch ---
--- 0.3878366947174072 seconds for one epoch ---
--- 0.219254732131958 seconds for one epoch ---
--- 0.40680980682373047 seconds for one epoch ---
--- 0.16454410552978516 seconds for one epoch ---
--- 0.41826677322387695 seconds for one epoch ---
--- 0.1533513069152832 seconds for one epoch ---
--- 0.4232757091522217 seconds for one epoch ---
--- 0.19023728370666504 seconds for one epoch ---
--- 0.4178347587585449 seconds for one epoch ---
=========================
[[0.8546453 ]
 [0.18935357]
 [0.9983212 ]
 [0.06294563]
 [0.02773236]
 [1.        ]
 [0.0327076 ]
 [0.06352842]
 [0.02777099]
 [0.9999963 ]
 [0.8427743 ]]
[[-8.1931621e-01]
 [-4.8411635e-01]
 [-1.2833467e+00]
 [-3.2040408e-01]
 [ 1.9725300e-03]
 [-3.7988527e+00]
 [ 1.4461201e-01]
 [ 3.2203978e-01]
 [-4.3862951e-03]
 [-1.8523483e+00]
 [ 8.0999225e-01]]
--- 0.3682389259338379 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5052.90185546875, (1909.3542, 1.217235, 2969.1162, 2.5319173)
   validation loss 1620.5784912109375, (1073.375, 0.06658678, 373.92252, 2.5319173)
decoder loss ratio: 41584.410961, decoder SINDy loss  ratio: 0.807164
--- 0.1528482437133789 seconds for one epoch ---
--- 0.20903348922729492 seconds for one epoch ---
--- 0.4010775089263916 seconds for one epoch ---
--- 0.18330669403076172 seconds for one epoch ---
--- 0.4645082950592041 seconds for one epoch ---
--- 0.17713642120361328 seconds for one epoch ---
--- 0.435046911239624 seconds for one epoch ---
--- 0.20116925239562988 seconds for one epoch ---
--- 0.40373659133911133 seconds for one epoch ---
--- 0.17104887962341309 seconds for one epoch ---
--- 0.40561985969543457 seconds for one epoch ---
--- 0.20456647872924805 seconds for one epoch ---
--- 0.41693711280822754 seconds for one epoch ---
--- 0.22052550315856934 seconds for one epoch ---
--- 0.4516735076904297 seconds for one epoch ---
--- 0.1695539951324463 seconds for one epoch ---
--- 0.4056267738342285 seconds for one epoch ---
--- 0.23302483558654785 seconds for one epoch ---
--- 0.4021730422973633 seconds for one epoch ---
--- 0.18172287940979004 seconds for one epoch ---
--- 0.45525312423706055 seconds for one epoch ---
--- 0.17183828353881836 seconds for one epoch ---
--- 0.4532132148742676 seconds for one epoch ---
--- 0.16720843315124512 seconds for one epoch ---
=========================
[[0.9301489 ]
 [0.18137065]
 [0.99708307]
 [0.05085956]
 [0.02281718]
 [1.        ]
 [0.02901255]
 [0.04841742]
 [0.02281316]
 [0.99999636]
 [0.89712834]]
[[-0.9021568 ]
 [-0.48128992]
 [-1.2282339 ]
 [-0.29772317]
 [ 0.00701455]
 [-3.7367468 ]
 [ 0.16245554]
 [ 0.28888053]
 [-0.0067734 ]
 [-1.986737  ]
 [ 0.85959417]]
--- 0.15437674522399902 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4153.4560546875, (1931.6627, 0.16672139, 2045.8444, 2.5319183)
   validation loss 2084.353271484375, (1532.102, 0.06457996, 376.40445, 2.5319183)
decoder loss ratio: 59356.293293, decoder SINDy loss  ratio: 0.812522
--- 0.20767927169799805 seconds for one epoch ---
--- 0.44362545013427734 seconds for one epoch ---
--- 0.23137617111206055 seconds for one epoch ---
--- 0.447831392288208 seconds for one epoch ---
--- 0.18279647827148438 seconds for one epoch ---
--- 0.3945190906524658 seconds for one epoch ---
--- 0.21004962921142578 seconds for one epoch ---
--- 0.4144017696380615 seconds for one epoch ---
--- 0.1820530891418457 seconds for one epoch ---
--- 0.49579668045043945 seconds for one epoch ---
--- 0.1683516502380371 seconds for one epoch ---
--- 0.4262545108795166 seconds for one epoch ---
--- 0.20662307739257812 seconds for one epoch ---
--- 0.4605445861816406 seconds for one epoch ---
--- 0.20276808738708496 seconds for one epoch ---
--- 0.42466068267822266 seconds for one epoch ---
--- 0.20547080039978027 seconds for one epoch ---
--- 0.45217251777648926 seconds for one epoch ---
--- 0.19251155853271484 seconds for one epoch ---
--- 0.45507216453552246 seconds for one epoch ---
--- 0.20232892036437988 seconds for one epoch ---
--- 0.47768568992614746 seconds for one epoch ---
--- 0.2100982666015625 seconds for one epoch ---
--- 0.43992185592651367 seconds for one epoch ---
=========================
[[0.95942175]
 [0.21872593]
 [0.9949681 ]
 [0.0433055 ]
 [0.01918112]
 [1.        ]
 [0.02623898]
 [0.04583896]
 [0.01900068]
 [0.99999845]
 [0.9248116 ]]
[[-9.6025300e-01]
 [-5.0883800e-01]
 [-1.1736134e+00]
 [-2.8311166e-01]
 [ 1.1706266e-02]
 [-3.6395566e+00]
 [ 1.7356853e-01]
 [ 2.9272512e-01]
 [-8.8297279e-04]
 [-2.1055286e+00]
 [ 8.9458907e-01]]
--- 0.19696736335754395 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5461.82275390625, (3158.3518, 0.99914247, 2123.4265, 2.5319178)
   validation loss 1539.7860107421875, (960.00543, 0.063797005, 400.67126, 2.5319178)
decoder loss ratio: 37192.277083, decoder SINDy loss  ratio: 0.864905
--- 0.15900540351867676 seconds for one epoch ---
--- 0.19831252098083496 seconds for one epoch ---
--- 0.44849395751953125 seconds for one epoch ---
--- 0.18600177764892578 seconds for one epoch ---
--- 0.4795351028442383 seconds for one epoch ---
--- 0.2166767120361328 seconds for one epoch ---
--- 0.42874789237976074 seconds for one epoch ---
--- 0.19817709922790527 seconds for one epoch ---
--- 0.4291689395904541 seconds for one epoch ---
--- 0.20548319816589355 seconds for one epoch ---
--- 0.4488821029663086 seconds for one epoch ---
--- 0.16814661026000977 seconds for one epoch ---
--- 0.439896821975708 seconds for one epoch ---
--- 0.1945173740386963 seconds for one epoch ---
--- 0.46639108657836914 seconds for one epoch ---
--- 0.19911623001098633 seconds for one epoch ---
--- 0.4572584629058838 seconds for one epoch ---
--- 0.19943547248840332 seconds for one epoch ---
--- 0.4550480842590332 seconds for one epoch ---
--- 0.200592041015625 seconds for one epoch ---
--- 0.48497915267944336 seconds for one epoch ---
--- 0.20311689376831055 seconds for one epoch ---
--- 0.4135406017303467 seconds for one epoch ---
--- 0.1957380771636963 seconds for one epoch ---
=========================
[[0.9785245 ]
 [0.2509011 ]
 [0.9905243 ]
 [0.04426921]
 [0.0159539 ]
 [1.        ]
 [0.02435474]
 [0.04271917]
 [0.01579856]
 [1.        ]
 [0.9205809 ]]
[[-1.0264952 ]
 [-0.52930015]
 [-1.1099031 ]
 [-0.29834557]
 [ 0.01323774]
 [-3.5522814 ]
 [ 0.18788415]
 [ 0.29289195]
 [-0.00416625]
 [-2.2290697 ]
 [ 0.8889875 ]]
--- 0.169234037399292 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4219.73291015625, (1871.356, 22.166767, 2144.0105, 2.5319188)
   validation loss 1481.19970703125, (976.0782, 0.07466011, 322.84735, 2.5319188)
decoder loss ratio: 37814.963473, decoder SINDy loss  ratio: 0.696911
--- 0.20572829246520996 seconds for one epoch ---
--- 0.4306013584136963 seconds for one epoch ---
--- 0.1829969882965088 seconds for one epoch ---
--- 0.4305562973022461 seconds for one epoch ---
--- 0.17911624908447266 seconds for one epoch ---
--- 0.42296528816223145 seconds for one epoch ---
--- 0.20217227935791016 seconds for one epoch ---
--- 0.4628632068634033 seconds for one epoch ---
--- 0.20568013191223145 seconds for one epoch ---
--- 0.44284605979919434 seconds for one epoch ---
--- 0.18446779251098633 seconds for one epoch ---
--- 0.44359326362609863 seconds for one epoch ---
--- 0.22688508033752441 seconds for one epoch ---
--- 0.4574878215789795 seconds for one epoch ---
--- 0.1631631851196289 seconds for one epoch ---
--- 0.4926121234893799 seconds for one epoch ---
--- 0.30152368545532227 seconds for one epoch ---
--- 0.49074244499206543 seconds for one epoch ---
--- 0.21169233322143555 seconds for one epoch ---
--- 0.4312739372253418 seconds for one epoch ---
--- 0.1857907772064209 seconds for one epoch ---
--- 0.4851067066192627 seconds for one epoch ---
--- 0.22549223899841309 seconds for one epoch ---
--- 0.4759256839752197 seconds for one epoch ---
=========================
[[0.988364  ]
 [0.2725512 ]
 [0.9868965 ]
 [0.03893593]
 [0.01376375]
 [1.        ]
 [0.02230422]
 [0.04040066]
 [0.01333545]
 [1.        ]
 [0.9422683 ]]
[[-1.0893031e+00]
 [-5.4194957e-01]
 [-1.0772249e+00]
 [-2.8766385e-01]
 [ 2.5914835e-02]
 [-3.4761558e+00]
 [ 1.9139956e-01]
 [ 2.9306510e-01]
 [ 2.3266624e-03]
 [-2.3440087e+00]
 [ 9.2363274e-01]]
--- 0.19742655754089355 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3323.8857421875, (1506.5112, 1.1152539, 1631.8676, 2.5319214)
   validation loss 1499.3603515625, (1003.3324, 0.07555957, 311.56082, 2.5319214)
decoder loss ratio: 38870.838939, decoder SINDy loss  ratio: 0.672548
THRESHOLDING: 6 active coefficients
--- 0.49585866928100586 seconds for one epoch ---
--- 0.16644740104675293 seconds for one epoch ---
--- 0.46509361267089844 seconds for one epoch ---
--- 0.20659947395324707 seconds for one epoch ---
--- 0.5055251121520996 seconds for one epoch ---
--- 0.21696853637695312 seconds for one epoch ---
--- 0.4561192989349365 seconds for one epoch ---
--- 0.1776597499847412 seconds for one epoch ---
--- 0.45014023780822754 seconds for one epoch ---
--- 0.21967411041259766 seconds for one epoch ---
--- 0.4799842834472656 seconds for one epoch ---
--- 0.22805452346801758 seconds for one epoch ---
--- 0.5094873905181885 seconds for one epoch ---
--- 0.16974353790283203 seconds for one epoch ---
--- 0.5490999221801758 seconds for one epoch ---
--- 0.2183246612548828 seconds for one epoch ---
--- 0.4436311721801758 seconds for one epoch ---
--- 0.1881859302520752 seconds for one epoch ---
--- 0.46600985527038574 seconds for one epoch ---
--- 0.1819920539855957 seconds for one epoch ---
--- 0.48381471633911133 seconds for one epoch ---
--- 0.1914823055267334 seconds for one epoch ---
--- 0.504218339920044 seconds for one epoch ---
--- 0.2291553020477295 seconds for one epoch ---
=========================
[[0.11188111]
 [0.4452698 ]
 [0.9812716 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999962 ]
 [0.9261255 ]]
[[-0.42818078]
 [-0.6205456 ]
 [-1.0409983 ]
 [-0.        ]
 [ 0.        ]
 [-2.467316  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.9605751 ]
 [ 0.8973655 ]]
--- 0.16928410530090332 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5527.92138671875, (1976.7529, 2.0976887, 3547.883, 1.1881348)
   validation loss 1999.8262939453125, (1680.9547, 0.061280675, 317.62222, 1.1881348)
decoder loss ratio: 65123.103805, decoder SINDy loss  ratio: 0.685632
--- 0.20237302780151367 seconds for one epoch ---
--- 0.4891808032989502 seconds for one epoch ---
--- 0.19571137428283691 seconds for one epoch ---
--- 0.466994047164917 seconds for one epoch ---
--- 0.2084794044494629 seconds for one epoch ---
--- 0.4747958183288574 seconds for one epoch ---
--- 0.2268204689025879 seconds for one epoch ---
--- 0.4798119068145752 seconds for one epoch ---
--- 0.1779346466064453 seconds for one epoch ---
--- 0.5118944644927979 seconds for one epoch ---
--- 0.17342877388000488 seconds for one epoch ---
--- 0.504248857498169 seconds for one epoch ---
--- 0.19457173347473145 seconds for one epoch ---
--- 0.47772717475891113 seconds for one epoch ---
--- 0.1952669620513916 seconds for one epoch ---
--- 0.4517862796783447 seconds for one epoch ---
--- 0.19025969505310059 seconds for one epoch ---
--- 0.45708489418029785 seconds for one epoch ---
--- 0.179640531539917 seconds for one epoch ---
--- 0.527155876159668 seconds for one epoch ---
--- 0.17471718788146973 seconds for one epoch ---
--- 0.5005908012390137 seconds for one epoch ---
--- 0.20853328704833984 seconds for one epoch ---
--- 0.4530820846557617 seconds for one epoch ---
=========================
[[0.01435061]
 [0.63295424]
 [0.9650587 ]
 [0.        ]
 [0.        ]
 [0.9999961 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999106]
 [0.9549266 ]]
[[-0.14002876]
 [-0.6981294 ]
 [-0.9768605 ]
 [-0.        ]
 [ 0.        ]
 [-1.9962672 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.8219671 ]
 [ 0.95023245]]
--- 0.15147066116333008 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5364.08349609375, (1911.129, 1.2206055, 3450.5762, 1.157635)
   validation loss 2186.42578125, (1782.9398, 0.04065263, 402.28748, 1.157635)
decoder loss ratio: 69074.183921, decoder SINDy loss  ratio: 0.868394
--- 0.15941762924194336 seconds for one epoch ---
--- 0.21335124969482422 seconds for one epoch ---
--- 0.5366151332855225 seconds for one epoch ---
--- 0.20194697380065918 seconds for one epoch ---
--- 0.5191452503204346 seconds for one epoch ---
--- 0.20431017875671387 seconds for one epoch ---
--- 0.4897115230560303 seconds for one epoch ---
--- 0.1797046661376953 seconds for one epoch ---
--- 0.5732526779174805 seconds for one epoch ---
--- 0.17406368255615234 seconds for one epoch ---
--- 0.5137820243835449 seconds for one epoch ---
--- 0.17524242401123047 seconds for one epoch ---
--- 0.5827431678771973 seconds for one epoch ---
--- 0.16892147064208984 seconds for one epoch ---
--- 0.4808695316314697 seconds for one epoch ---
--- 0.16091132164001465 seconds for one epoch ---
--- 0.5307047367095947 seconds for one epoch ---
--- 0.16972970962524414 seconds for one epoch ---
--- 0.5173113346099854 seconds for one epoch ---
--- 0.20397400856018066 seconds for one epoch ---
--- 0.5457167625427246 seconds for one epoch ---
--- 0.24544286727905273 seconds for one epoch ---
--- 0.4667370319366455 seconds for one epoch ---
--- 0.2177729606628418 seconds for one epoch ---
=========================
[[0.00926004]
 [0.6987312 ]
 [0.94562405]
 [0.        ]
 [0.        ]
 [0.9999802 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999996  ]
 [0.930266  ]]
[[-0.05411735]
 [-0.72817624]
 [-0.9305599 ]
 [-0.        ]
 [ 0.        ]
 [-1.7396145 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.8392754 ]
 [ 0.9039369 ]]
--- 0.17175507545471191 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3829.155517578125, (1997.8938, 1.3388515, 1828.7749, 1.1479019)
   validation loss 1104.4307861328125, (802.03815, 0.08006415, 301.1646, 1.1479019)
decoder loss ratio: 31072.350213, decoder SINDy loss  ratio: 0.650106
--- 0.2127683162689209 seconds for one epoch ---
--- 0.4674403667449951 seconds for one epoch ---
--- 0.2573566436767578 seconds for one epoch ---
--- 0.4987621307373047 seconds for one epoch ---
--- 0.1957533359527588 seconds for one epoch ---
--- 0.5482044219970703 seconds for one epoch ---
--- 0.1952047348022461 seconds for one epoch ---
--- 0.5105671882629395 seconds for one epoch ---
--- 0.19012236595153809 seconds for one epoch ---
--- 0.512232780456543 seconds for one epoch ---
--- 0.20911097526550293 seconds for one epoch ---
--- 0.5307056903839111 seconds for one epoch ---
--- 0.22237586975097656 seconds for one epoch ---
--- 0.5212361812591553 seconds for one epoch ---
--- 0.22969913482666016 seconds for one epoch ---
--- 0.5062401294708252 seconds for one epoch ---
--- 0.1765885353088379 seconds for one epoch ---
--- 0.5988302230834961 seconds for one epoch ---
--- 0.19951272010803223 seconds for one epoch ---
--- 0.5304772853851318 seconds for one epoch ---
--- 0.2194509506225586 seconds for one epoch ---
--- 0.500401496887207 seconds for one epoch ---
--- 0.2093949317932129 seconds for one epoch ---
--- 0.49589085578918457 seconds for one epoch ---
=========================
[[0.00811402]
 [0.6510886 ]
 [0.90249455]
 [0.        ]
 [0.        ]
 [0.9999206 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999595]
 [0.9368265 ]]
[[-0.05137745]
 [-0.70646787]
 [-0.8673529 ]
 [-0.        ]
 [ 0.        ]
 [-1.5943756 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.9047406 ]
 [ 0.9146795 ]]
--- 0.19282913208007812 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2769.425537109375, (1795.529, 0.92073804, 971.83514, 1.1407447)
   validation loss 2005.0389404296875, (1691.5548, 0.17240657, 312.17105, 1.1407447)
decoder loss ratio: 65533.769991, decoder SINDy loss  ratio: 0.673865
--- 0.16674518585205078 seconds for one epoch ---
--- 0.1583700180053711 seconds for one epoch ---
--- 0.5293416976928711 seconds for one epoch ---
--- 0.17464971542358398 seconds for one epoch ---
--- 0.5648698806762695 seconds for one epoch ---
--- 0.218153715133667 seconds for one epoch ---
--- 0.5077300071716309 seconds for one epoch ---
--- 0.22290277481079102 seconds for one epoch ---
--- 0.5075368881225586 seconds for one epoch ---
--- 0.1704998016357422 seconds for one epoch ---
--- 0.5568652153015137 seconds for one epoch ---
--- 0.18834733963012695 seconds for one epoch ---
--- 0.559884786605835 seconds for one epoch ---
--- 0.2242116928100586 seconds for one epoch ---
--- 0.5761995315551758 seconds for one epoch ---
--- 0.22045063972473145 seconds for one epoch ---
--- 0.5243105888366699 seconds for one epoch ---
--- 0.20116257667541504 seconds for one epoch ---
--- 0.5000834465026855 seconds for one epoch ---
--- 0.18084168434143066 seconds for one epoch ---
--- 0.5883824825286865 seconds for one epoch ---
--- 0.2457261085510254 seconds for one epoch ---
--- 0.5183110237121582 seconds for one epoch ---
--- 0.18549704551696777 seconds for one epoch ---
=========================
[[0.00970504]
 [0.6769698 ]
 [0.8817639 ]
 [0.        ]
 [0.        ]
 [0.99986386]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999595]
 [0.89734095]]
[[-0.11893335]
 [-0.71828157]
 [-0.8457718 ]
 [-0.        ]
 [ 0.        ]
 [-1.5388448 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.0093157 ]
 [ 0.8617139 ]]
--- 0.19738388061523438 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6184.03759765625, (4002.7266, 1.3781145, 2178.7815, 1.1512353)
   validation loss 1276.194091796875, (974.449, 0.104043946, 300.48978, 1.1512353)
decoder loss ratio: 37751.844994, decoder SINDy loss  ratio: 0.648649
--- 0.18835687637329102 seconds for one epoch ---
--- 0.5255293846130371 seconds for one epoch ---
--- 0.30020666122436523 seconds for one epoch ---
--- 0.5610768795013428 seconds for one epoch ---
--- 0.22313380241394043 seconds for one epoch ---
--- 0.5546355247497559 seconds for one epoch ---
--- 0.18398332595825195 seconds for one epoch ---
--- 0.5169730186462402 seconds for one epoch ---
--- 0.2720146179199219 seconds for one epoch ---
--- 0.5389518737792969 seconds for one epoch ---
--- 0.18758130073547363 seconds for one epoch ---
--- 0.5171358585357666 seconds for one epoch ---
--- 0.16801214218139648 seconds for one epoch ---
--- 0.5286602973937988 seconds for one epoch ---
--- 0.2052755355834961 seconds for one epoch ---
--- 0.5205821990966797 seconds for one epoch ---
--- 0.21202874183654785 seconds for one epoch ---
--- 0.6038675308227539 seconds for one epoch ---
--- 0.1695880889892578 seconds for one epoch ---
--- 0.5896129608154297 seconds for one epoch ---
--- 0.20069074630737305 seconds for one epoch ---
--- 0.5486705303192139 seconds for one epoch ---
--- 0.19246578216552734 seconds for one epoch ---
--- 0.536698579788208 seconds for one epoch ---
=========================
[[0.01330574]
 [0.6716077 ]
 [0.8763015 ]
 [0.        ]
 [0.        ]
 [0.9997994 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.9104561 ]]
[[-0.17990638]
 [-0.7159366 ]
 [-0.84069705]
 [-0.        ]
 [ 0.        ]
 [-1.4995711 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.0983508 ]
 [ 0.87697315]]
--- 0.21410059928894043 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3713.630615234375, (1764.3733, 1.0962086, 1947.0056, 1.1554397)
   validation loss 1342.93359375, (1020.7077, 0.08642059, 320.98407, 1.1554397)
decoder loss ratio: 39543.988427, decoder SINDy loss  ratio: 0.692889
--- 0.16645431518554688 seconds for one epoch ---
--- 0.19401025772094727 seconds for one epoch ---
--- 0.5586786270141602 seconds for one epoch ---
--- 0.17600536346435547 seconds for one epoch ---
--- 0.5552263259887695 seconds for one epoch ---
--- 0.21953797340393066 seconds for one epoch ---
--- 0.5424215793609619 seconds for one epoch ---
--- 0.1925218105316162 seconds for one epoch ---
--- 0.5470540523529053 seconds for one epoch ---
--- 0.20246624946594238 seconds for one epoch ---
--- 0.5179691314697266 seconds for one epoch ---
--- 0.20469284057617188 seconds for one epoch ---
--- 0.5245146751403809 seconds for one epoch ---
--- 0.1982724666595459 seconds for one epoch ---
--- 0.5359694957733154 seconds for one epoch ---
--- 0.19147658348083496 seconds for one epoch ---
--- 0.5403895378112793 seconds for one epoch ---
--- 0.18720293045043945 seconds for one epoch ---
--- 0.6132900714874268 seconds for one epoch ---
--- 0.20423436164855957 seconds for one epoch ---
--- 0.5345063209533691 seconds for one epoch ---
--- 0.15851235389709473 seconds for one epoch ---
--- 0.517160177230835 seconds for one epoch ---
--- 0.17836213111877441 seconds for one epoch ---
=========================
[[0.02347366]
 [0.801781  ]
 [0.8566957 ]
 [0.        ]
 [0.        ]
 [0.9996886 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.8444655 ]]
[[-0.2568992 ]
 [-0.78451514]
 [-0.82373124]
 [-0.        ]
 [ 0.        ]
 [-1.4554616 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2115674 ]
 [ 0.8140671 ]]
--- 0.14696383476257324 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4585.779296875, (2148.674, 0.5072905, 2435.4172, 1.1805995)
   validation loss 4885.97021484375, (4316.9717, 0.103207834, 567.71466, 1.1805995)
decoder loss ratio: 167246.977464, decoder SINDy loss  ratio: 1.225492
--- 0.16710543632507324 seconds for one epoch ---
--- 0.518951416015625 seconds for one epoch ---
--- 0.19172883033752441 seconds for one epoch ---
--- 0.5377347469329834 seconds for one epoch ---
--- 0.20351576805114746 seconds for one epoch ---
--- 0.5388424396514893 seconds for one epoch ---
--- 0.22112751007080078 seconds for one epoch ---
--- 0.5682084560394287 seconds for one epoch ---
--- 0.1491990089416504 seconds for one epoch ---
--- 0.5562839508056641 seconds for one epoch ---
--- 0.16346025466918945 seconds for one epoch ---
--- 0.540424108505249 seconds for one epoch ---
--- 0.20772981643676758 seconds for one epoch ---
--- 0.6280224323272705 seconds for one epoch ---
--- 0.20842885971069336 seconds for one epoch ---
--- 0.5494480133056641 seconds for one epoch ---
--- 0.21132659912109375 seconds for one epoch ---
--- 0.5774633884429932 seconds for one epoch ---
--- 0.20057916641235352 seconds for one epoch ---
--- 0.5892014503479004 seconds for one epoch ---
--- 0.21816515922546387 seconds for one epoch ---
--- 0.5609526634216309 seconds for one epoch ---
--- 0.20099329948425293 seconds for one epoch ---
--- 0.5772602558135986 seconds for one epoch ---
=========================
[[0.03594682]
 [0.8690935 ]
 [0.89300394]
 [0.        ]
 [0.        ]
 [0.9994986 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.8680415 ]]
[[-0.30756518]
 [-0.8343143 ]
 [-0.85728335]
 [-0.        ]
 [ 0.        ]
 [-1.4073688 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2911596 ]
 [ 0.83338916]]
--- 0.17723965644836426 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3077.101318359375, (1313.9452, 0.2065494, 1761.746, 1.2036371)
   validation loss 1314.3583984375, (996.75916, 0.09030428, 316.30527, 1.2036371)
decoder loss ratio: 38616.180125, decoder SINDy loss  ratio: 0.682789
--- 0.14976143836975098 seconds for one epoch ---
--- 0.18093061447143555 seconds for one epoch ---
--- 0.5892837047576904 seconds for one epoch ---
--- 0.18153119087219238 seconds for one epoch ---
--- 0.6288204193115234 seconds for one epoch ---
--- 0.2087867259979248 seconds for one epoch ---
--- 0.5351181030273438 seconds for one epoch ---
--- 0.21086430549621582 seconds for one epoch ---
--- 0.612910270690918 seconds for one epoch ---
--- 0.21112060546875 seconds for one epoch ---
--- 0.576148271560669 seconds for one epoch ---
--- 0.18788433074951172 seconds for one epoch ---
--- 0.580369234085083 seconds for one epoch ---
--- 0.19393157958984375 seconds for one epoch ---
--- 0.5858004093170166 seconds for one epoch ---
--- 0.17772340774536133 seconds for one epoch ---
--- 0.6149997711181641 seconds for one epoch ---
--- 0.1845862865447998 seconds for one epoch ---
--- 0.6001412868499756 seconds for one epoch ---
--- 0.21232128143310547 seconds for one epoch ---
--- 0.5887372493743896 seconds for one epoch ---
--- 0.17407870292663574 seconds for one epoch ---
--- 0.5653913021087646 seconds for one epoch ---
--- 0.18681955337524414 seconds for one epoch ---
=========================
[[0.06505432]
 [0.68178517]
 [0.8540312 ]
 [0.        ]
 [0.        ]
 [0.999266  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.8825673 ]]
[[-0.37423807]
 [-0.7208445 ]
 [-0.82168007]
 [-0.        ]
 [ 0.        ]
 [-1.3690844 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3890884 ]
 [ 0.8468113 ]]
--- 0.15930390357971191 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5095.47412109375, (2750.692, 3.660461, 2339.925, 1.1969417)
   validation loss 1310.5811767578125, (939.89514, 0.12257635, 369.36652, 1.1969417)
decoder loss ratio: 36413.169515, decoder SINDy loss  ratio: 0.797330
--- 0.19858241081237793 seconds for one epoch ---
--- 0.5759866237640381 seconds for one epoch ---
--- 0.20511698722839355 seconds for one epoch ---
--- 0.6935770511627197 seconds for one epoch ---
--- 0.17520380020141602 seconds for one epoch ---
--- 0.5554721355438232 seconds for one epoch ---
--- 0.20343494415283203 seconds for one epoch ---
--- 0.5697286128997803 seconds for one epoch ---
--- 0.1898646354675293 seconds for one epoch ---
--- 0.6163413524627686 seconds for one epoch ---
--- 0.17703509330749512 seconds for one epoch ---
--- 0.59226393699646 seconds for one epoch ---
--- 0.17062616348266602 seconds for one epoch ---
--- 0.6333024501800537 seconds for one epoch ---
--- 0.18729567527770996 seconds for one epoch ---
--- 0.5733799934387207 seconds for one epoch ---
--- 0.18184804916381836 seconds for one epoch ---
--- 0.587343692779541 seconds for one epoch ---
--- 0.15478801727294922 seconds for one epoch ---
--- 0.5661637783050537 seconds for one epoch ---
--- 0.16163945198059082 seconds for one epoch ---
--- 0.5791692733764648 seconds for one epoch ---
--- 0.16750407218933105 seconds for one epoch ---
--- 0.5686118602752686 seconds for one epoch ---
=========================
[[0.12775835]
 [0.6776081 ]
 [0.8673103 ]
 [0.        ]
 [0.        ]
 [0.9991902 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.880666  ]]
[[-0.4507732 ]
 [-0.7189685 ]
 [-0.83284014]
 [-0.        ]
 [ 0.        ]
 [-1.3592672 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.4820619 ]
 [ 0.84502155]]
--- 0.2085113525390625 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6651.3876953125, (2415.069, 1.334187, 4233.7705, 1.2138156)
   validation loss 1769.6142578125, (1441.2844, 0.066821754, 327.04926, 1.2138156)
decoder loss ratio: 55837.860759, decoder SINDy loss  ratio: 0.705982
--- 0.14845633506774902 seconds for one epoch ---
--- 0.1920790672302246 seconds for one epoch ---
--- 0.6019477844238281 seconds for one epoch ---
--- 0.21892523765563965 seconds for one epoch ---
--- 0.5684869289398193 seconds for one epoch ---
--- 0.17963242530822754 seconds for one epoch ---
--- 0.5583620071411133 seconds for one epoch ---
--- 0.22170114517211914 seconds for one epoch ---
--- 0.5985562801361084 seconds for one epoch ---
--- 0.18952703475952148 seconds for one epoch ---
--- 0.6327764987945557 seconds for one epoch ---
--- 0.19161725044250488 seconds for one epoch ---
--- 0.5972692966461182 seconds for one epoch ---
--- 0.18445515632629395 seconds for one epoch ---
--- 0.5715968608856201 seconds for one epoch ---
--- 0.20851397514343262 seconds for one epoch ---
--- 0.5888392925262451 seconds for one epoch ---
--- 0.19351601600646973 seconds for one epoch ---
--- 0.6550490856170654 seconds for one epoch ---
--- 0.18492817878723145 seconds for one epoch ---
--- 0.6575014591217041 seconds for one epoch ---
--- 0.19820451736450195 seconds for one epoch ---
--- 0.6084020137786865 seconds for one epoch ---
--- 0.17580580711364746 seconds for one epoch ---
=========================
[[0.20286353]
 [0.62301457]
 [0.8381945 ]
 [0.        ]
 [0.        ]
 [0.9990616 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.95793694]]
[[-0.50682235]
 [-0.6948815 ]
 [-0.80954003]
 [-0.        ]
 [ 0.        ]
 [-1.3444586 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5503476 ]
 [ 0.95816547]]
--- 0.17787551879882812 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5107.10693359375, (3073.939, 0.2750612, 2031.6643, 1.2284334)
   validation loss 1549.19970703125, (1169.2115, 0.08398586, 378.67575, 1.2284334)
decoder loss ratio: 45297.285204, decoder SINDy loss  ratio: 0.817425
--- 0.21719789505004883 seconds for one epoch ---
--- 0.6609377861022949 seconds for one epoch ---
--- 0.1720597743988037 seconds for one epoch ---
--- 0.6296584606170654 seconds for one epoch ---
--- 0.14989089965820312 seconds for one epoch ---
--- 0.6023774147033691 seconds for one epoch ---
--- 0.21824193000793457 seconds for one epoch ---
--- 0.5858311653137207 seconds for one epoch ---
--- 0.16264033317565918 seconds for one epoch ---
--- 0.6398053169250488 seconds for one epoch ---
--- 0.20953893661499023 seconds for one epoch ---
--- 0.6080954074859619 seconds for one epoch ---
--- 0.2210240364074707 seconds for one epoch ---
--- 0.6136689186096191 seconds for one epoch ---
--- 0.2000114917755127 seconds for one epoch ---
--- 0.6427741050720215 seconds for one epoch ---
--- 0.18754243850708008 seconds for one epoch ---
--- 0.6533737182617188 seconds for one epoch ---
--- 0.2110147476196289 seconds for one epoch ---
--- 0.6779155731201172 seconds for one epoch ---
--- 0.18579316139221191 seconds for one epoch ---
--- 0.6066722869873047 seconds for one epoch ---
--- 0.1919264793395996 seconds for one epoch ---
--- 0.6211163997650146 seconds for one epoch ---
=========================
[[0.24866751]
 [0.6248778 ]
 [0.84256995]
 [0.        ]
 [0.        ]
 [0.998517  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.96014196]]
[[-0.53339106]
 [-0.6957159 ]
 [-0.8128417 ]
 [-0.        ]
 [ 0.        ]
 [-1.2984233 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5928967 ]
 [ 0.9638268 ]]
--- 0.20334792137145996 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7653.8642578125, (2511.5676, 1.1430868, 5139.91, 1.2431216)
   validation loss 3796.40966796875, (3198.0352, 0.14694023, 596.98425, 1.2431216)
decoder loss ratio: 123897.433986, decoder SINDy loss  ratio: 1.288674
--- 0.15812993049621582 seconds for one epoch ---
--- 0.15903210639953613 seconds for one epoch ---
--- 0.6277916431427002 seconds for one epoch ---
--- 0.18375730514526367 seconds for one epoch ---
--- 0.5689456462860107 seconds for one epoch ---
--- 0.2448282241821289 seconds for one epoch ---
--- 0.6166603565216064 seconds for one epoch ---
--- 0.1910080909729004 seconds for one epoch ---
--- 0.6198647022247314 seconds for one epoch ---
--- 0.17447614669799805 seconds for one epoch ---
--- 0.6187901496887207 seconds for one epoch ---
--- 0.18975830078125 seconds for one epoch ---
--- 0.6259136199951172 seconds for one epoch ---
--- 0.2005620002746582 seconds for one epoch ---
--- 0.6363551616668701 seconds for one epoch ---
--- 0.20441722869873047 seconds for one epoch ---
--- 0.6285886764526367 seconds for one epoch ---
--- 0.20968294143676758 seconds for one epoch ---
--- 0.6345555782318115 seconds for one epoch ---
--- 0.179656982421875 seconds for one epoch ---
--- 0.6390726566314697 seconds for one epoch ---
--- 0.19342947006225586 seconds for one epoch ---
--- 0.6456248760223389 seconds for one epoch ---
--- 0.19683194160461426 seconds for one epoch ---
=========================
[[0.3731476 ]
 [0.63535345]
 [0.7778117 ]
 [0.        ]
 [0.        ]
 [0.99828875]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.97082126]]
[[-0.59245914]
 [-0.7002605 ]
 [-0.77026933]
 [-0.        ]
 [ 0.        ]
 [-1.2840328 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6622722 ]
 [ 0.9962705 ]]
--- 0.14431166648864746 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5683.82763671875, (1512.4196, 1.7834666, 4168.361, 1.2634887)
   validation loss 3187.798095703125, (2758.1226, 0.13539787, 428.27655, 1.2634887)
decoder loss ratio: 106854.456231, decoder SINDy loss  ratio: 0.924495
--- 0.18305182456970215 seconds for one epoch ---
--- 0.6843452453613281 seconds for one epoch ---
--- 0.16929244995117188 seconds for one epoch ---
--- 0.6040685176849365 seconds for one epoch ---
--- 0.2204303741455078 seconds for one epoch ---
--- 0.6124172210693359 seconds for one epoch ---
--- 0.16751670837402344 seconds for one epoch ---
--- 0.5989603996276855 seconds for one epoch ---
--- 0.20192599296569824 seconds for one epoch ---
--- 0.6590888500213623 seconds for one epoch ---
--- 0.19489145278930664 seconds for one epoch ---
--- 0.6469709873199463 seconds for one epoch ---
--- 0.18611454963684082 seconds for one epoch ---
--- 0.6691389083862305 seconds for one epoch ---
--- 0.18351101875305176 seconds for one epoch ---
--- 0.6577801704406738 seconds for one epoch ---
--- 0.1841740608215332 seconds for one epoch ---
--- 0.6218099594116211 seconds for one epoch ---
--- 0.17977190017700195 seconds for one epoch ---
--- 0.6217198371887207 seconds for one epoch ---
--- 0.19405531883239746 seconds for one epoch ---
--- 0.6163656711578369 seconds for one epoch ---
--- 0.19357013702392578 seconds for one epoch ---
--- 0.6883752346038818 seconds for one epoch ---
=========================
[[0.45604625]
 [0.53865415]
 [0.80466664]
 [0.        ]
 [0.        ]
 [0.99778533]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.97596   ]]
[[-0.62688005]
 [-0.66011745]
 [-0.78662163]
 [-0.        ]
 [ 0.        ]
 [-1.2580647 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.704985  ]
 [ 1.0162685 ]]
--- 0.21949505805969238 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2065.307861328125, (1073.7858, 1.1447283, 989.11285, 1.264436)
   validation loss 1507.9298095703125, (1157.8191, 0.08574326, 348.7606, 1.264436)
decoder loss ratio: 44855.921679, decoder SINDy loss  ratio: 0.752849
--- 0.16557812690734863 seconds for one epoch ---
--- 0.21938657760620117 seconds for one epoch ---
--- 0.6169459819793701 seconds for one epoch ---
--- 0.20144367218017578 seconds for one epoch ---
--- 0.6789844036102295 seconds for one epoch ---
--- 0.209367036819458 seconds for one epoch ---
--- 0.6843786239624023 seconds for one epoch ---
--- 0.21070003509521484 seconds for one epoch ---
--- 0.6830148696899414 seconds for one epoch ---
--- 0.2116405963897705 seconds for one epoch ---
--- 0.6628868579864502 seconds for one epoch ---
--- 0.16971135139465332 seconds for one epoch ---
--- 0.6242916584014893 seconds for one epoch ---
--- 0.19431638717651367 seconds for one epoch ---
--- 0.6548576354980469 seconds for one epoch ---
--- 0.18512725830078125 seconds for one epoch ---
--- 0.6484830379486084 seconds for one epoch ---
--- 0.19266629219055176 seconds for one epoch ---
--- 0.6414155960083008 seconds for one epoch ---
--- 0.18123936653137207 seconds for one epoch ---
--- 0.682328462600708 seconds for one epoch ---
--- 0.21271038055419922 seconds for one epoch ---
--- 0.6944830417633057 seconds for one epoch ---
--- 0.18142080307006836 seconds for one epoch ---
=========================
[[0.58645475]
 [0.558491  ]
 [0.8218186 ]
 [0.        ]
 [0.        ]
 [0.9969796 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.96508276]]
[[-0.6796498 ]
 [-0.668183  ]
 [-0.79797786]
 [-0.        ]
 [ 0.        ]
 [-1.226798  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7728584 ]
 [ 0.97768074]]
--- 0.2008686065673828 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2897.63232421875, (1550.394, 0.30567786, 1345.6405, 1.2920605)
   validation loss 1263.8321533203125, (912.6113, 0.16650108, 349.76215, 1.2920605)
decoder loss ratio: 35356.147215, decoder SINDy loss  ratio: 0.755011
--- 0.19460558891296387 seconds for one epoch ---
--- 0.6463322639465332 seconds for one epoch ---
--- 0.20873355865478516 seconds for one epoch ---
--- 0.6486876010894775 seconds for one epoch ---
--- 0.19171571731567383 seconds for one epoch ---
--- 0.7001290321350098 seconds for one epoch ---
--- 0.17464733123779297 seconds for one epoch ---
--- 0.6962106227874756 seconds for one epoch ---
--- 0.19782781600952148 seconds for one epoch ---
--- 0.722156286239624 seconds for one epoch ---
--- 0.17719602584838867 seconds for one epoch ---
--- 0.6561691761016846 seconds for one epoch ---
--- 0.15265154838562012 seconds for one epoch ---
--- 0.7235488891601562 seconds for one epoch ---
--- 0.22747588157653809 seconds for one epoch ---
--- 0.6736431121826172 seconds for one epoch ---
--- 0.18628191947937012 seconds for one epoch ---
--- 0.6942219734191895 seconds for one epoch ---
--- 0.24334049224853516 seconds for one epoch ---
--- 0.6291849613189697 seconds for one epoch ---
--- 0.16972708702087402 seconds for one epoch ---
--- 0.7102923393249512 seconds for one epoch ---
--- 0.251279354095459 seconds for one epoch ---
--- 0.6782135963439941 seconds for one epoch ---
=========================
[[0.68195343]
 [0.7016819 ]
 [0.8289873 ]
 [0.        ]
 [0.        ]
 [0.9962145 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.96887046]]
[[-0.7211456 ]
 [-0.73043114]
 [-0.80298305]
 [-0.        ]
 [ 0.        ]
 [-1.2040498 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8190498 ]
 [ 0.9896153 ]]
--- 0.18294405937194824 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4699.31689453125, (2260.975, 1.1379989, 2435.8772, 1.3267334)
   validation loss 802.3851928710938, (500.80972, 0.10917922, 300.13956, 1.3267334)
decoder loss ratio: 19402.238109, decoder SINDy loss  ratio: 0.647893
--- 0.15847396850585938 seconds for one epoch ---
--- 0.18540000915527344 seconds for one epoch ---
--- 0.7349350452423096 seconds for one epoch ---
--- 0.17888212203979492 seconds for one epoch ---
--- 0.6377408504486084 seconds for one epoch ---
--- 0.18799424171447754 seconds for one epoch ---
--- 0.6287353038787842 seconds for one epoch ---
--- 0.2038099765777588 seconds for one epoch ---
--- 0.7012953758239746 seconds for one epoch ---
--- 0.20327138900756836 seconds for one epoch ---
--- 0.6364874839782715 seconds for one epoch ---
--- 0.18668198585510254 seconds for one epoch ---
--- 0.6589255332946777 seconds for one epoch ---
--- 0.3364858627319336 seconds for one epoch ---
--- 0.6456336975097656 seconds for one epoch ---
--- 0.18761062622070312 seconds for one epoch ---
--- 0.7173376083374023 seconds for one epoch ---
--- 0.19963788986206055 seconds for one epoch ---
--- 0.6486217975616455 seconds for one epoch ---
--- 0.2000269889831543 seconds for one epoch ---
--- 0.7014398574829102 seconds for one epoch ---
--- 0.21116352081298828 seconds for one epoch ---
--- 0.6721844673156738 seconds for one epoch ---
--- 0.21621441841125488 seconds for one epoch ---
=========================
[[0.7835567 ]
 [0.592613  ]
 [0.82624674]
 [0.        ]
 [0.        ]
 [0.9953925 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.97060776]]
[[-0.77370447]
 [-0.68224025]
 [-0.8010684 ]
 [-0.        ]
 [ 0.        ]
 [-1.1842315 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8857455 ]
 [ 0.9955708 ]]
--- 0.17407631874084473 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3853.705322265625, (1591.8116, 0.75999737, 2259.8105, 1.3230355)
   validation loss 2665.118408203125, (2386.1606, 0.15753005, 277.47726, 1.3230355)
decoder loss ratio: 92444.005926, decoder SINDy loss  ratio: 0.598974
--- 0.20725584030151367 seconds for one epoch ---
--- 0.6524984836578369 seconds for one epoch ---
--- 0.21396374702453613 seconds for one epoch ---
--- 0.6734268665313721 seconds for one epoch ---
--- 0.18584895133972168 seconds for one epoch ---
--- 0.6488287448883057 seconds for one epoch ---
--- 0.18026447296142578 seconds for one epoch ---
--- 0.705751895904541 seconds for one epoch ---
--- 0.19002676010131836 seconds for one epoch ---
--- 0.7130701541900635 seconds for one epoch ---
--- 0.2109370231628418 seconds for one epoch ---
--- 0.7067532539367676 seconds for one epoch ---
--- 0.15433359146118164 seconds for one epoch ---
--- 0.6682381629943848 seconds for one epoch ---
--- 0.19952821731567383 seconds for one epoch ---
--- 0.6541640758514404 seconds for one epoch ---
--- 0.16821551322937012 seconds for one epoch ---
--- 0.6707136631011963 seconds for one epoch ---
--- 0.20998787879943848 seconds for one epoch ---
--- 0.6718714237213135 seconds for one epoch ---
--- 0.17540240287780762 seconds for one epoch ---
--- 0.7087981700897217 seconds for one epoch ---
--- 0.1947307586669922 seconds for one epoch ---
--- 0.6688988208770752 seconds for one epoch ---
=========================
[[0.83949155]
 [0.66278565]
 [0.7995774 ]
 [0.        ]
 [0.        ]
 [0.99449635]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9635725 ]]
[[-0.81063   ]
 [-0.71244276]
 [-0.7834606 ]
 [-0.        ]
 [ 0.        ]
 [-1.1662748 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9167614 ]
 [ 0.97330564]]
--- 0.15273761749267578 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4708.939453125, (2091.6165, 1.9952714, 2613.991, 1.3367184)
   validation loss 1197.2366943359375, (834.20874, 0.1114319, 361.57983, 1.3367184)
decoder loss ratio: 32318.694847, decoder SINDy loss  ratio: 0.780521
--- 0.15192532539367676 seconds for one epoch ---
--- 0.17584967613220215 seconds for one epoch ---
--- 0.6699297428131104 seconds for one epoch ---
--- 0.19505548477172852 seconds for one epoch ---
--- 0.8032138347625732 seconds for one epoch ---
--- 0.21425652503967285 seconds for one epoch ---
--- 0.6559829711914062 seconds for one epoch ---
--- 0.1924135684967041 seconds for one epoch ---
--- 0.6941156387329102 seconds for one epoch ---
--- 0.19163727760314941 seconds for one epoch ---
--- 0.7412042617797852 seconds for one epoch ---
--- 0.2076737880706787 seconds for one epoch ---
--- 0.6850004196166992 seconds for one epoch ---
--- 0.20972466468811035 seconds for one epoch ---
--- 0.7087533473968506 seconds for one epoch ---
--- 0.16336822509765625 seconds for one epoch ---
--- 0.6678750514984131 seconds for one epoch ---
--- 0.21118569374084473 seconds for one epoch ---
--- 0.6950867176055908 seconds for one epoch ---
--- 0.18828964233398438 seconds for one epoch ---
--- 0.6806149482727051 seconds for one epoch ---
--- 0.17825889587402344 seconds for one epoch ---
--- 0.7207751274108887 seconds for one epoch ---
--- 0.1779022216796875 seconds for one epoch ---
=========================
[[0.877451  ]
 [0.6335545 ]
 [0.82927537]
 [0.        ]
 [0.        ]
 [0.99343014]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9527147 ]]
[[-0.84215117]
 [-0.69959116]
 [-0.8032188 ]
 [-0.        ]
 [ 0.        ]
 [-1.1483922 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9473484 ]
 [ 0.9459876 ]]
--- 0.14976263046264648 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3508.436279296875, (1891.0165, 0.67523396, 1615.4083, 1.3362836)
   validation loss 1448.1397705078125, (1054.3447, 0.159447, 392.29938, 1.3362836)
decoder loss ratio: 40847.145130, decoder SINDy loss  ratio: 0.846833
--- 0.21017146110534668 seconds for one epoch ---
--- 0.7082891464233398 seconds for one epoch ---
--- 0.20637202262878418 seconds for one epoch ---
--- 0.6639084815979004 seconds for one epoch ---
--- 0.2092301845550537 seconds for one epoch ---
--- 0.682666540145874 seconds for one epoch ---
--- 0.23123741149902344 seconds for one epoch ---
--- 0.6586477756500244 seconds for one epoch ---
--- 0.1919567584991455 seconds for one epoch ---
--- 0.6945624351501465 seconds for one epoch ---
--- 0.19031357765197754 seconds for one epoch ---
--- 0.6619095802307129 seconds for one epoch ---
--- 0.17673993110656738 seconds for one epoch ---
--- 0.6893908977508545 seconds for one epoch ---
--- 0.1750473976135254 seconds for one epoch ---
--- 0.70731520652771 seconds for one epoch ---
--- 0.2079176902770996 seconds for one epoch ---
--- 0.7274878025054932 seconds for one epoch ---
--- 0.18031978607177734 seconds for one epoch ---
--- 0.7562644481658936 seconds for one epoch ---
--- 0.159407377243042 seconds for one epoch ---
--- 0.6976685523986816 seconds for one epoch ---
--- 0.17450881004333496 seconds for one epoch ---
--- 0.7200798988342285 seconds for one epoch ---
=========================
[[0.91083145]
 [0.6634937 ]
 [0.79628694]
 [0.        ]
 [0.        ]
 [0.9936259 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9267879 ]]
[[-0.8778137 ]
 [-0.712781  ]
 [-0.78142995]
 [-0.        ]
 [ 0.        ]
 [-1.151461  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9661677 ]
 [ 0.8993445 ]]
--- 0.182450532913208 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3221.22607421875, (1178.4165, 1.4621927, 2040.008, 1.3393469)
   validation loss 1115.6007080078125, (750.5945, 0.19301079, 363.4739, 1.3393469)
decoder loss ratio: 29079.333338, decoder SINDy loss  ratio: 0.784610
THRESHOLDING: 6 active coefficients
--- 0.7292008399963379 seconds for one epoch ---
--- 0.20239043235778809 seconds for one epoch ---
--- 0.7414257526397705 seconds for one epoch ---
--- 0.20975351333618164 seconds for one epoch ---
--- 0.7113296985626221 seconds for one epoch ---
--- 0.1848595142364502 seconds for one epoch ---
--- 0.7270534038543701 seconds for one epoch ---
--- 0.16380071640014648 seconds for one epoch ---
--- 0.7373490333557129 seconds for one epoch ---
--- 0.19843769073486328 seconds for one epoch ---
--- 0.7482073307037354 seconds for one epoch ---
--- 0.2022542953491211 seconds for one epoch ---
--- 0.8242635726928711 seconds for one epoch ---
--- 0.15780878067016602 seconds for one epoch ---
--- 0.7802445888519287 seconds for one epoch ---
--- 0.20045971870422363 seconds for one epoch ---
--- 0.691650390625 seconds for one epoch ---
--- 0.18412351608276367 seconds for one epoch ---
--- 0.7588846683502197 seconds for one epoch ---
--- 0.1852860450744629 seconds for one epoch ---
--- 0.6748075485229492 seconds for one epoch ---
--- 0.18257856369018555 seconds for one epoch ---
--- 0.7079813480377197 seconds for one epoch ---
--- 0.18251609802246094 seconds for one epoch ---
=========================
[[0.9299235 ]
 [0.6274512 ]
 [0.75606656]
 [0.        ]
 [0.        ]
 [0.991779  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9083754 ]]
[[-0.90408224]
 [-0.696981  ]
 [-0.7581611 ]
 [-0.        ]
 [ 0.        ]
 [-1.1257164 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9941068 ]
 [ 0.87482136]]
--- 0.16124224662780762 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2003.4002685546875, (805.14777, 0.4135572, 1196.5227, 1.3163003)
   validation loss 847.639892578125, (531.5984, 0.1896384, 314.53558, 1.3163003)
decoder loss ratio: 20595.044473, decoder SINDy loss  ratio: 0.678969
--- 0.19097638130187988 seconds for one epoch ---
--- 0.7571890354156494 seconds for one epoch ---
--- 0.16663622856140137 seconds for one epoch ---
--- 0.6796140670776367 seconds for one epoch ---
--- 0.18352746963500977 seconds for one epoch ---
--- 0.7918214797973633 seconds for one epoch ---
--- 0.18745088577270508 seconds for one epoch ---
--- 0.7234346866607666 seconds for one epoch ---
--- 0.20476579666137695 seconds for one epoch ---
--- 0.8415164947509766 seconds for one epoch ---
--- 0.17924737930297852 seconds for one epoch ---
--- 0.711108922958374 seconds for one epoch ---
--- 0.1980905532836914 seconds for one epoch ---
--- 0.7347695827484131 seconds for one epoch ---
--- 0.17161202430725098 seconds for one epoch ---
--- 0.7080018520355225 seconds for one epoch ---
--- 0.1919562816619873 seconds for one epoch ---
--- 0.7850384712219238 seconds for one epoch ---
--- 0.1677720546722412 seconds for one epoch ---
--- 0.7113749980926514 seconds for one epoch ---
--- 0.19985175132751465 seconds for one epoch ---
--- 0.8061573505401611 seconds for one epoch ---
--- 0.18378758430480957 seconds for one epoch ---
--- 0.8223490715026855 seconds for one epoch ---
=========================
[[0.94987404]
 [0.59439164]
 [0.7339332 ]
 [0.        ]
 [0.        ]
 [0.99062586]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.8739454 ]]
[[-0.9398483 ]
 [-0.6830322 ]
 [-0.74647415]
 [-0.        ]
 [ 0.        ]
 [-1.1124144 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.0242887 ]
 [ 0.83893687]]
--- 0.18211078643798828 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5802.16162109375, (1597.8914, 1.0589648, 4201.9062, 1.3051797)
   validation loss 1857.0599365234375, (1546.611, 0.20539242, 308.93835, 1.3051797)
decoder loss ratio: 59918.393699, decoder SINDy loss  ratio: 0.666887
--- 0.1656818389892578 seconds for one epoch ---
--- 0.20972871780395508 seconds for one epoch ---
--- 0.743971586227417 seconds for one epoch ---
--- 0.20371437072753906 seconds for one epoch ---
--- 0.745734691619873 seconds for one epoch ---
--- 0.20882391929626465 seconds for one epoch ---
--- 0.8703353404998779 seconds for one epoch ---
--- 0.18716835975646973 seconds for one epoch ---
--- 0.7167465686798096 seconds for one epoch ---
--- 0.21024513244628906 seconds for one epoch ---
--- 0.7397701740264893 seconds for one epoch ---
--- 0.18540692329406738 seconds for one epoch ---
--- 0.7190389633178711 seconds for one epoch ---
--- 0.16223645210266113 seconds for one epoch ---
--- 0.7605819702148438 seconds for one epoch ---
--- 0.17158865928649902 seconds for one epoch ---
--- 0.7260944843292236 seconds for one epoch ---
--- 0.18380236625671387 seconds for one epoch ---
--- 0.804013729095459 seconds for one epoch ---
--- 0.20366215705871582 seconds for one epoch ---
--- 0.8011138439178467 seconds for one epoch ---
--- 0.21461939811706543 seconds for one epoch ---
--- 0.8404417037963867 seconds for one epoch ---
--- 0.17627429962158203 seconds for one epoch ---
=========================
[[0.9624823 ]
 [0.5338911 ]
 [0.7200122 ]
 [0.        ]
 [0.        ]
 [0.9892905 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.84593934]]
[[-0.97025716]
 [-0.6583303 ]
 [-0.7394434 ]
 [-0.        ]
 [ 0.        ]
 [-1.0989096 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.0526893 ]
 [ 0.8155425 ]]
--- 0.16552996635437012 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4396.1806640625, (1238.7213, 2.040872, 3154.1216, 1.2966669)
   validation loss 961.6416625976562, (700.1016, 0.18310994, 260.0602, 1.2966669)
decoder loss ratio: 27123.152326, decoder SINDy loss  ratio: 0.561377
--- 0.18508601188659668 seconds for one epoch ---
--- 0.7537481784820557 seconds for one epoch ---
--- 0.15044069290161133 seconds for one epoch ---
--- 0.7797834873199463 seconds for one epoch ---
--- 0.16948771476745605 seconds for one epoch ---
--- 0.7452754974365234 seconds for one epoch ---
--- 0.22531342506408691 seconds for one epoch ---
--- 0.745574951171875 seconds for one epoch ---
--- 0.17795014381408691 seconds for one epoch ---
--- 0.7446446418762207 seconds for one epoch ---
--- 0.19099068641662598 seconds for one epoch ---
--- 0.7264909744262695 seconds for one epoch ---
--- 0.1659705638885498 seconds for one epoch ---
--- 0.7377369403839111 seconds for one epoch ---
--- 0.1796889305114746 seconds for one epoch ---
--- 0.7408263683319092 seconds for one epoch ---
--- 0.21846890449523926 seconds for one epoch ---
--- 0.7596414089202881 seconds for one epoch ---
--- 0.19429302215576172 seconds for one epoch ---
--- 0.7566351890563965 seconds for one epoch ---
--- 0.2081308364868164 seconds for one epoch ---
--- 0.7975046634674072 seconds for one epoch ---
--- 0.17515921592712402 seconds for one epoch ---
--- 0.7909276485443115 seconds for one epoch ---
=========================
[[0.9668665 ]
 [0.5145108 ]
 [0.71925175]
 [0.        ]
 [0.        ]
 [0.9865704 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.8210081 ]]
[[-0.9831932 ]
 [-0.65054303]
 [-0.73906946]
 [-0.        ]
 [ 0.        ]
 [-1.0759063 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.057616  ]
 [ 0.79749656]]
--- 0.22716021537780762 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4080.417236328125, (1593.4998, 1.3091694, 2484.3176, 1.2906798)
   validation loss 918.47412109375, (608.326, 0.14837278, 308.70908, 1.2906798)
decoder loss ratio: 23567.604905, decoder SINDy loss  ratio: 0.666392
--- 0.17176151275634766 seconds for one epoch ---
--- 0.20032954216003418 seconds for one epoch ---
--- 0.8094174861907959 seconds for one epoch ---
--- 0.204087495803833 seconds for one epoch ---
--- 0.756446123123169 seconds for one epoch ---
--- 0.18155360221862793 seconds for one epoch ---
--- 0.7324638366699219 seconds for one epoch ---
--- 0.18931269645690918 seconds for one epoch ---
--- 0.7758042812347412 seconds for one epoch ---
--- 0.1696033477783203 seconds for one epoch ---
--- 0.8224678039550781 seconds for one epoch ---
--- 0.2012183666229248 seconds for one epoch ---
--- 0.7698907852172852 seconds for one epoch ---
--- 0.19319677352905273 seconds for one epoch ---
--- 0.7384095191955566 seconds for one epoch ---
--- 0.20794248580932617 seconds for one epoch ---
--- 0.7745463848114014 seconds for one epoch ---
--- 0.17287302017211914 seconds for one epoch ---
--- 0.7184913158416748 seconds for one epoch ---
--- 0.1681220531463623 seconds for one epoch ---
--- 0.7687740325927734 seconds for one epoch ---
--- 0.18433713912963867 seconds for one epoch ---
--- 0.7415838241577148 seconds for one epoch ---
--- 0.1888597011566162 seconds for one epoch ---
=========================
[[0.9817204 ]
 [0.5158947 ]
 [0.6762082 ]
 [0.        ]
 [0.        ]
 [0.98872876]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.6698681 ]]
[[-1.0444461]
 [-0.651104 ]
 [-0.7185769]
 [-0.       ]
 [ 0.       ]
 [-1.0937247]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1020107]
 [ 0.7156872]]
--- 0.1637253761291504 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2189.492431640625, (1095.3884, 0.3796877, 1092.4614, 1.2628595)
   validation loss 1596.892822265625, (1265.7278, 0.14000797, 329.76224, 1.2628595)
decoder loss ratio: 49036.491721, decoder SINDy loss  ratio: 0.711838
--- 0.21249961853027344 seconds for one epoch ---
--- 0.8197414875030518 seconds for one epoch ---
--- 0.22334671020507812 seconds for one epoch ---
--- 0.8123419284820557 seconds for one epoch ---
--- 0.19580364227294922 seconds for one epoch ---
--- 0.7641749382019043 seconds for one epoch ---
--- 0.19987893104553223 seconds for one epoch ---
--- 0.7488307952880859 seconds for one epoch ---
--- 0.20808148384094238 seconds for one epoch ---
--- 0.7701907157897949 seconds for one epoch ---
--- 0.22245287895202637 seconds for one epoch ---
--- 0.8827474117279053 seconds for one epoch ---
--- 0.17982244491577148 seconds for one epoch ---
--- 0.7650589942932129 seconds for one epoch ---
--- 0.2163381576538086 seconds for one epoch ---
--- 0.8549230098724365 seconds for one epoch ---
--- 0.2143537998199463 seconds for one epoch ---
--- 0.7864067554473877 seconds for one epoch ---
--- 0.19007086753845215 seconds for one epoch ---
--- 0.7917513847351074 seconds for one epoch ---
--- 0.19420790672302246 seconds for one epoch ---
--- 0.732473611831665 seconds for one epoch ---
--- 0.17447829246520996 seconds for one epoch ---
--- 0.8221621513366699 seconds for one epoch ---
=========================
[[0.9860536 ]
 [0.71248144]
 [0.7050934 ]
 [0.        ]
 [0.        ]
 [0.9853909 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.56123155]]
[[-1.0720618 ]
 [-0.7357379 ]
 [-0.73214775]
 [-0.        ]
 [ 0.        ]
 [-1.0673337 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1332047 ]
 [ 0.66941524]]
--- 0.20348072052001953 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2959.048583984375, (1086.2114, 0.42345488, 1871.1353, 1.2785889)
   validation loss 1179.307861328125, (770.4034, 0.21817163, 407.4077, 1.2785889)
decoder loss ratio: 29846.764472, decoder SINDy loss  ratio: 0.879447
--- 0.16914796829223633 seconds for one epoch ---
--- 0.22435688972473145 seconds for one epoch ---
--- 0.7688090801239014 seconds for one epoch ---
--- 0.18476486206054688 seconds for one epoch ---
--- 0.7712898254394531 seconds for one epoch ---
--- 0.21423935890197754 seconds for one epoch ---
--- 0.7742226123809814 seconds for one epoch ---
--- 0.20237135887145996 seconds for one epoch ---
--- 0.8196301460266113 seconds for one epoch ---
--- 0.18359613418579102 seconds for one epoch ---
--- 0.7828879356384277 seconds for one epoch ---
--- 0.19642066955566406 seconds for one epoch ---
--- 0.768125057220459 seconds for one epoch ---
--- 0.16742467880249023 seconds for one epoch ---
--- 0.7815015316009521 seconds for one epoch ---
--- 0.17455410957336426 seconds for one epoch ---
--- 0.7696535587310791 seconds for one epoch ---
--- 0.17557144165039062 seconds for one epoch ---
--- 0.7675735950469971 seconds for one epoch ---
--- 0.17298293113708496 seconds for one epoch ---
--- 0.8121652603149414 seconds for one epoch ---
--- 0.17920923233032227 seconds for one epoch ---
--- 0.8260326385498047 seconds for one epoch ---
--- 0.20716476440429688 seconds for one epoch ---
=========================
[[0.9914707 ]
 [0.6689712 ]
 [0.66597885]
 [0.        ]
 [0.        ]
 [0.98656106]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.55832356]]
[[-1.1220065 ]
 [-0.7152873 ]
 [-0.7139349 ]
 [-0.        ]
 [ 0.        ]
 [-1.0758445 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.1611533 ]
 [ 0.66823584]]
--- 0.1778116226196289 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3880.370849609375, (2101.659, 0.7844814, 1776.6547, 1.2727053)
   validation loss 966.1464233398438, (606.0201, 0.23729973, 358.61633, 1.2727053)
decoder loss ratio: 23478.270018, decoder SINDy loss  ratio: 0.774124
--- 0.1895289421081543 seconds for one epoch ---
--- 0.779973030090332 seconds for one epoch ---
--- 0.17185068130493164 seconds for one epoch ---
--- 0.8359324932098389 seconds for one epoch ---
--- 0.24190735816955566 seconds for one epoch ---
--- 0.8516845703125 seconds for one epoch ---
--- 0.19364690780639648 seconds for one epoch ---
--- 0.8560523986816406 seconds for one epoch ---
--- 0.17244195938110352 seconds for one epoch ---
--- 0.8724822998046875 seconds for one epoch ---
--- 0.17644667625427246 seconds for one epoch ---
--- 0.9514377117156982 seconds for one epoch ---
--- 0.17187142372131348 seconds for one epoch ---
--- 0.8523564338684082 seconds for one epoch ---
--- 0.19782471656799316 seconds for one epoch ---
--- 0.7907652854919434 seconds for one epoch ---
--- 0.26230573654174805 seconds for one epoch ---
--- 0.793508768081665 seconds for one epoch ---
--- 0.17167329788208008 seconds for one epoch ---
--- 0.7962663173675537 seconds for one epoch ---
--- 0.21517276763916016 seconds for one epoch ---
--- 0.8227427005767822 seconds for one epoch ---
--- 0.1622624397277832 seconds for one epoch ---
--- 0.8905336856842041 seconds for one epoch ---
=========================
[[0.99352586]
 [0.61755246]
 [0.6742838 ]
 [0.        ]
 [0.        ]
 [0.98404247]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.5574319 ]]
[[-1.1499151 ]
 [-0.69278854]
 [-0.7177056 ]
 [ 0.        ]
 [-0.        ]
 [-1.0583352 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1776462 ]
 [ 0.66787595]]
--- 0.18838953971862793 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4287.8017578125, (1545.8938, 2.5394492, 2738.101, 1.2676681)
   validation loss 1028.49658203125, (630.39655, 0.20399645, 396.62833, 1.2676681)
decoder loss ratio: 24422.656586, decoder SINDy loss  ratio: 0.856178
--- 0.15460801124572754 seconds for one epoch ---
--- 0.1884760856628418 seconds for one epoch ---
--- 0.8368570804595947 seconds for one epoch ---
--- 0.17500734329223633 seconds for one epoch ---
--- 0.8518445491790771 seconds for one epoch ---
--- 0.20267987251281738 seconds for one epoch ---
--- 0.7689108848571777 seconds for one epoch ---
--- 0.17747163772583008 seconds for one epoch ---
--- 0.8039264678955078 seconds for one epoch ---
--- 0.18233084678649902 seconds for one epoch ---
--- 0.8030626773834229 seconds for one epoch ---
--- 0.19009709358215332 seconds for one epoch ---
--- 0.7929160594940186 seconds for one epoch ---
--- 0.19215941429138184 seconds for one epoch ---
--- 0.8097171783447266 seconds for one epoch ---
--- 0.16781973838806152 seconds for one epoch ---
--- 0.8226315975189209 seconds for one epoch ---
--- 0.2143573760986328 seconds for one epoch ---
--- 0.8564486503601074 seconds for one epoch ---
--- 0.18155479431152344 seconds for one epoch ---
--- 0.8191282749176025 seconds for one epoch ---
--- 0.17181921005249023 seconds for one epoch ---
--- 0.8066058158874512 seconds for one epoch ---
--- 0.1887962818145752 seconds for one epoch ---
=========================
[[0.99519444]
 [0.5981602 ]
 [0.68896943]
 [0.        ]
 [0.        ]
 [0.9811113 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.6658517 ]]
[[-1.1800225 ]
 [-0.68463117]
 [-0.72449565]
 [-0.        ]
 [-0.        ]
 [-1.0410981 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2021391 ]
 [ 0.7138825 ]]
--- 0.14783287048339844 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2062.228271484375, (1405.6954, 2.0072184, 653.24615, 1.2794385)
   validation loss 1463.6192626953125, (1082.5288, 0.1736417, 379.63748, 1.2794385)
decoder loss ratio: 41939.045398, decoder SINDy loss  ratio: 0.819501
--- 0.20392680168151855 seconds for one epoch ---
--- 0.8027708530426025 seconds for one epoch ---
--- 0.1861255168914795 seconds for one epoch ---
--- 0.8018171787261963 seconds for one epoch ---
--- 0.20744824409484863 seconds for one epoch ---
--- 0.7788405418395996 seconds for one epoch ---
--- 0.15965485572814941 seconds for one epoch ---
--- 0.8690552711486816 seconds for one epoch ---
--- 0.1536877155303955 seconds for one epoch ---
--- 0.789158821105957 seconds for one epoch ---
--- 0.19711875915527344 seconds for one epoch ---
--- 0.9851493835449219 seconds for one epoch ---
--- 0.21576142311096191 seconds for one epoch ---
--- 0.7994327545166016 seconds for one epoch ---
--- 0.24196672439575195 seconds for one epoch ---
--- 0.8363826274871826 seconds for one epoch ---
--- 0.16652393341064453 seconds for one epoch ---
--- 0.8075606822967529 seconds for one epoch ---
--- 0.17792582511901855 seconds for one epoch ---
--- 0.7923381328582764 seconds for one epoch ---
--- 0.17309856414794922 seconds for one epoch ---
--- 0.8318452835083008 seconds for one epoch ---
--- 0.19882965087890625 seconds for one epoch ---
--- 0.8258459568023682 seconds for one epoch ---
=========================
[[0.9966516 ]
 [0.66071635]
 [0.6622623 ]
 [0.        ]
 [0.        ]
 [0.97734445]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.5284579 ]]
[[-1.2164775 ]
 [-0.71157795]
 [-0.7122708 ]
 [ 0.        ]
 [-0.        ]
 [-1.0224571 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2376578 ]
 [ 0.65616995]]
--- 0.17871737480163574 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4454.90625, (1239.646, 4.4607053, 3209.5317, 1.2676686)
   validation loss 2352.09033203125, (1831.4324, 0.10940363, 519.28107, 1.2676686)
decoder loss ratio: 70952.869638, decoder SINDy loss  ratio: 1.120941
--- 0.18443536758422852 seconds for one epoch ---
--- 0.20418882369995117 seconds for one epoch ---
--- 0.8382351398468018 seconds for one epoch ---
--- 0.21632909774780273 seconds for one epoch ---
--- 0.934706449508667 seconds for one epoch ---
--- 0.16496706008911133 seconds for one epoch ---
--- 0.8432714939117432 seconds for one epoch ---
--- 0.1698291301727295 seconds for one epoch ---
--- 0.8332524299621582 seconds for one epoch ---
--- 0.16826486587524414 seconds for one epoch ---
--- 0.9452426433563232 seconds for one epoch ---
--- 0.20360827445983887 seconds for one epoch ---
--- 0.7884674072265625 seconds for one epoch ---
--- 0.16586542129516602 seconds for one epoch ---
--- 0.8354072570800781 seconds for one epoch ---
--- 0.18394851684570312 seconds for one epoch ---
--- 0.8222870826721191 seconds for one epoch ---
--- 0.37651801109313965 seconds for one epoch ---
--- 0.8577075004577637 seconds for one epoch ---
--- 0.20360970497131348 seconds for one epoch ---
--- 0.8145532608032227 seconds for one epoch ---
--- 0.18618440628051758 seconds for one epoch ---
--- 0.819669246673584 seconds for one epoch ---
--- 0.21293997764587402 seconds for one epoch ---
=========================
[[0.9978956 ]
 [0.66627145]
 [0.639981  ]
 [0.        ]
 [0.        ]
 [0.9791643 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.4900415 ]]
[[-1.2633157 ]
 [-0.71407527]
 [-0.70243305]
 [-0.        ]
 [ 0.        ]
 [-1.031053  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2652776 ]
 [ 0.6407516 ]]
--- 0.15551114082336426 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3091.06298828125, (1130.0173, 0.44872063, 1959.3394, 1.257564)
   validation loss 844.413330078125, (546.26196, 0.20920151, 296.68454, 1.257564)
decoder loss ratio: 21163.136795, decoder SINDy loss  ratio: 0.640435
--- 0.16556143760681152 seconds for one epoch ---
--- 0.8484549522399902 seconds for one epoch ---
--- 0.22149419784545898 seconds for one epoch ---
--- 0.8008015155792236 seconds for one epoch ---
--- 0.20647287368774414 seconds for one epoch ---
--- 0.8337316513061523 seconds for one epoch ---
--- 0.19077038764953613 seconds for one epoch ---
--- 0.9372801780700684 seconds for one epoch ---
--- 0.2338552474975586 seconds for one epoch ---
--- 0.9106473922729492 seconds for one epoch ---
--- 0.16420960426330566 seconds for one epoch ---
--- 0.8336772918701172 seconds for one epoch ---
--- 0.17522573471069336 seconds for one epoch ---
--- 0.8566286563873291 seconds for one epoch ---
--- 0.201308012008667 seconds for one epoch ---
--- 0.852013349533081 seconds for one epoch ---
--- 0.1743175983428955 seconds for one epoch ---
--- 0.8688662052154541 seconds for one epoch ---
--- 0.19301128387451172 seconds for one epoch ---
--- 0.8759183883666992 seconds for one epoch ---
--- 0.21432900428771973 seconds for one epoch ---
--- 0.8457612991333008 seconds for one epoch ---
--- 0.1694200038909912 seconds for one epoch ---
--- 0.8397855758666992 seconds for one epoch ---
=========================
[[0.9983282 ]
 [0.5004058 ]
 [0.63274175]
 [0.        ]
 [0.        ]
 [0.97838044]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.40981975]]
[[-1.286469  ]
 [-0.64491063]
 [-0.69929725]
 [ 0.        ]
 [-0.        ]
 [-1.0272673 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.2643933 ]
 [ 0.6081822 ]]
--- 0.19959044456481934 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3437.34326171875, (1452.1716, 0.5857758, 1983.359, 1.2268428)
   validation loss 1263.825927734375, (906.7383, 0.26409087, 355.5967, 1.2268428)
decoder loss ratio: 35128.615183, decoder SINDy loss  ratio: 0.767606
--- 0.14727139472961426 seconds for one epoch ---
--- 0.17623019218444824 seconds for one epoch ---
--- 0.852623462677002 seconds for one epoch ---
--- 0.17662906646728516 seconds for one epoch ---
--- 0.8639473915100098 seconds for one epoch ---
--- 0.16072344779968262 seconds for one epoch ---
--- 0.8393363952636719 seconds for one epoch ---
--- 0.1612389087677002 seconds for one epoch ---
--- 0.8463099002838135 seconds for one epoch ---
--- 0.19083380699157715 seconds for one epoch ---
--- 0.8582744598388672 seconds for one epoch ---
--- 0.19047021865844727 seconds for one epoch ---
--- 0.8574776649475098 seconds for one epoch ---
--- 0.19984674453735352 seconds for one epoch ---
--- 0.8492631912231445 seconds for one epoch ---
--- 0.16196060180664062 seconds for one epoch ---
--- 0.8553168773651123 seconds for one epoch ---
--- 0.1932814121246338 seconds for one epoch ---
--- 0.8538119792938232 seconds for one epoch ---
--- 0.21874737739562988 seconds for one epoch ---
--- 0.8998153209686279 seconds for one epoch ---
--- 0.21435761451721191 seconds for one epoch ---
--- 0.9321057796478271 seconds for one epoch ---
--- 0.20329594612121582 seconds for one epoch ---
=========================
[[0.99879754]
 [0.5262712 ]
 [0.64305955]
 [0.        ]
 [0.        ]
 [0.9728333 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.43586743]]
[[-1.3196526]
 [-0.6552958]
 [-0.7037783]
 [ 0.       ]
 [ 0.       ]
 [-1.0037609]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.3020682]
 [ 0.6188873]]
--- 0.14211344718933105 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3052.18896484375, (1102.9025, 0.8901961, 1947.1655, 1.2309158)
   validation loss 1324.1357421875, (1020.07404, 0.3104047, 302.52026, 1.2309158)
decoder loss ratio: 39519.439067, decoder SINDy loss  ratio: 0.653033
--- 0.2026205062866211 seconds for one epoch ---
--- 0.8376836776733398 seconds for one epoch ---
--- 0.18636250495910645 seconds for one epoch ---
--- 0.8507499694824219 seconds for one epoch ---
--- 0.18405771255493164 seconds for one epoch ---
--- 0.8853180408477783 seconds for one epoch ---
--- 0.2101140022277832 seconds for one epoch ---
--- 0.896324634552002 seconds for one epoch ---
--- 0.1848306655883789 seconds for one epoch ---
--- 0.9112036228179932 seconds for one epoch ---
--- 0.17757511138916016 seconds for one epoch ---
--- 0.8411257266998291 seconds for one epoch ---
--- 0.15591812133789062 seconds for one epoch ---
--- 0.8864004611968994 seconds for one epoch ---
--- 0.1739943027496338 seconds for one epoch ---
--- 0.8516976833343506 seconds for one epoch ---
--- 0.18466472625732422 seconds for one epoch ---
--- 0.8536121845245361 seconds for one epoch ---
--- 0.1946086883544922 seconds for one epoch ---
--- 0.8616988658905029 seconds for one epoch ---
--- 0.21184086799621582 seconds for one epoch ---
--- 0.8680462837219238 seconds for one epoch ---
--- 0.19563722610473633 seconds for one epoch ---
--- 0.9383952617645264 seconds for one epoch ---
=========================
[[0.9992695 ]
 [0.5273715 ]
 [0.6408438 ]
 [0.        ]
 [0.        ]
 [0.9737855 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.33010897]]
[[-1.3697828 ]
 [-0.65573996]
 [-0.7028124 ]
 [-0.        ]
 [ 0.        ]
 [-1.0074433 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.3396478 ]
 [ 0.5738035 ]]
--- 0.16108083724975586 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2808.8896484375, (1633.73, 1.1319858, 1172.8105, 1.217364)
   validation loss 769.1536254882812, (492.54684, 0.30251276, 275.08688, 1.217364)
decoder loss ratio: 19082.119854, decoder SINDy loss  ratio: 0.593814
--- 0.15778660774230957 seconds for one epoch ---
--- 0.18468666076660156 seconds for one epoch ---
--- 0.935535192489624 seconds for one epoch ---
--- 0.16585564613342285 seconds for one epoch ---
--- 0.9334495067596436 seconds for one epoch ---
--- 0.19774079322814941 seconds for one epoch ---
--- 0.9121918678283691 seconds for one epoch ---
--- 0.22014474868774414 seconds for one epoch ---
--- 0.87066650390625 seconds for one epoch ---
--- 0.19584345817565918 seconds for one epoch ---
--- 0.8843863010406494 seconds for one epoch ---
--- 0.18486618995666504 seconds for one epoch ---
--- 0.8606653213500977 seconds for one epoch ---
--- 0.17733430862426758 seconds for one epoch ---
--- 0.9392905235290527 seconds for one epoch ---
--- 0.22225403785705566 seconds for one epoch ---
--- 1.0675814151763916 seconds for one epoch ---
--- 0.21105313301086426 seconds for one epoch ---
--- 0.8600881099700928 seconds for one epoch ---
--- 0.22493982315063477 seconds for one epoch ---
--- 0.8907079696655273 seconds for one epoch ---
--- 0.20442748069763184 seconds for one epoch ---
--- 0.9751002788543701 seconds for one epoch ---
--- 0.20068812370300293 seconds for one epoch ---
=========================
[[0.99942863]
 [0.52815354]
 [0.6130581 ]
 [0.        ]
 [0.        ]
 [0.96922076]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.33113098]]
[[-1.3945539 ]
 [-0.65605557]
 [-0.69089586]
 [-0.        ]
 [-0.        ]
 [-0.9908519 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3565857 ]
 [ 0.5742683 ]]
--- 0.14136266708374023 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2848.674072265625, (1237.7843, 0.82940114, 1608.8495, 1.2110499)
   validation loss 854.4035034179688, (556.58777, 0.2612782, 296.34338, 1.2110499)
decoder loss ratio: 21563.176433, decoder SINDy loss  ratio: 0.639699
--- 0.16622400283813477 seconds for one epoch ---
--- 0.8858458995819092 seconds for one epoch ---
--- 0.20644855499267578 seconds for one epoch ---
--- 0.869455099105835 seconds for one epoch ---
--- 0.1812455654144287 seconds for one epoch ---
--- 0.9391951560974121 seconds for one epoch ---
--- 0.191802978515625 seconds for one epoch ---
--- 0.8844773769378662 seconds for one epoch ---
--- 0.1751716136932373 seconds for one epoch ---
--- 0.8568696975708008 seconds for one epoch ---
--- 0.18901658058166504 seconds for one epoch ---
--- 0.9725251197814941 seconds for one epoch ---
--- 0.18880724906921387 seconds for one epoch ---
--- 0.9299345016479492 seconds for one epoch ---
--- 0.19275474548339844 seconds for one epoch ---
--- 0.9160513877868652 seconds for one epoch ---
--- 0.17578721046447754 seconds for one epoch ---
--- 0.9425137042999268 seconds for one epoch ---
--- 0.17153024673461914 seconds for one epoch ---
--- 0.9255363941192627 seconds for one epoch ---
--- 0.18239665031433105 seconds for one epoch ---
--- 0.9367156028747559 seconds for one epoch ---
--- 0.19514679908752441 seconds for one epoch ---
--- 0.9808371067047119 seconds for one epoch ---
=========================
[[0.9996407 ]
 [0.57795477]
 [0.573951  ]
 [0.        ]
 [0.        ]
 [0.9646051 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.25142908]]
[[-1.4412777 ]
 [-0.676276  ]
 [-0.6746321 ]
 [ 0.        ]
 [ 0.        ]
 [-0.97634524]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.4039886 ]
 [ 0.53538656]]
--- 0.18344736099243164 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2942.219970703125, (1236.7571, 1.2618903, 1703.0035, 1.1974502)
   validation loss 1018.0234985351562, (684.0026, 0.21846354, 332.60498, 1.1974502)
decoder loss ratio: 26499.449154, decoder SINDy loss  ratio: 0.717975
--- 0.13428544998168945 seconds for one epoch ---
--- 0.15886449813842773 seconds for one epoch ---
--- 0.9709510803222656 seconds for one epoch ---
--- 0.19074082374572754 seconds for one epoch ---
--- 0.9584054946899414 seconds for one epoch ---
--- 0.16615629196166992 seconds for one epoch ---
--- 0.8920180797576904 seconds for one epoch ---
--- 0.18097710609436035 seconds for one epoch ---
--- 0.8919267654418945 seconds for one epoch ---
--- 0.16422152519226074 seconds for one epoch ---
--- 0.9198479652404785 seconds for one epoch ---
--- 0.17444491386413574 seconds for one epoch ---
--- 0.9587781429290771 seconds for one epoch ---
--- 0.21855545043945312 seconds for one epoch ---
--- 1.125049352645874 seconds for one epoch ---
--- 0.17966985702514648 seconds for one epoch ---
--- 0.9815759658813477 seconds for one epoch ---
--- 0.16494441032409668 seconds for one epoch ---
--- 1.0106806755065918 seconds for one epoch ---
--- 0.1845226287841797 seconds for one epoch ---
--- 1.0413427352905273 seconds for one epoch ---
--- 0.16643762588500977 seconds for one epoch ---
--- 1.0113213062286377 seconds for one epoch ---
--- 0.22037363052368164 seconds for one epoch ---
=========================
[[0.9997709 ]
 [0.69130063]
 [0.51973   ]
 [0.        ]
 [0.        ]
 [0.9676125 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.17101766]]
[[-1.4867357 ]
 [-0.7255986 ]
 [-0.6526712 ]
 [ 0.        ]
 [-0.        ]
 [-0.9855752 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.4255567 ]
 [ 0.48653954]]
--- 0.14212298393249512 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3564.976318359375, (1685.5919, 2.3005445, 1875.8976, 1.1862018)
   validation loss 869.1876831054688, (609.20886, 0.23949721, 258.55307, 1.1862018)
decoder loss ratio: 23601.808959, decoder SINDy loss  ratio: 0.558123
--- 0.2127685546875 seconds for one epoch ---
--- 1.0039405822753906 seconds for one epoch ---
--- 0.18891596794128418 seconds for one epoch ---
--- 0.8735558986663818 seconds for one epoch ---
--- 0.19027948379516602 seconds for one epoch ---
--- 0.9227592945098877 seconds for one epoch ---
--- 0.2229783535003662 seconds for one epoch ---
--- 0.8872387409210205 seconds for one epoch ---
--- 0.1904280185699463 seconds for one epoch ---
--- 0.9093809127807617 seconds for one epoch ---
--- 0.2097179889678955 seconds for one epoch ---
--- 0.9241766929626465 seconds for one epoch ---
--- 0.20555567741394043 seconds for one epoch ---
--- 0.977989912033081 seconds for one epoch ---
--- 0.21131181716918945 seconds for one epoch ---
--- 0.9844973087310791 seconds for one epoch ---
--- 0.16820120811462402 seconds for one epoch ---
--- 0.9317824840545654 seconds for one epoch ---
--- 0.18292021751403809 seconds for one epoch ---
--- 0.880497932434082 seconds for one epoch ---
--- 0.17232489585876465 seconds for one epoch ---
--- 0.8994801044464111 seconds for one epoch ---
--- 0.20132803916931152 seconds for one epoch ---
--- 0.9641640186309814 seconds for one epoch ---
=========================
[[0.99983907]
 [0.62368643]
 [0.52902657]
 [0.        ]
 [0.        ]
 [0.96186006]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.10390292]]
[[-1.5227733 ]
 [-0.69541454]
 [-0.6564095 ]
 [-0.        ]
 [-0.        ]
 [-0.96856326]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.4585533 ]
 [ 0.42880803]]
--- 0.21263623237609863 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3235.896728515625, (1361.1002, 0.54340875, 1873.0953, 1.1577753)
   validation loss 995.9876098632812, (710.4038, 0.26924023, 284.15683, 1.1577753)
decoder loss ratio: 27522.276860, decoder SINDy loss  ratio: 0.613392
--- 0.1498270034790039 seconds for one epoch ---
--- 0.18750905990600586 seconds for one epoch ---
--- 0.9064061641693115 seconds for one epoch ---
--- 0.18274235725402832 seconds for one epoch ---
--- 0.935049295425415 seconds for one epoch ---
--- 0.19497060775756836 seconds for one epoch ---
--- 0.9315993785858154 seconds for one epoch ---
--- 0.16488122940063477 seconds for one epoch ---
--- 0.9027626514434814 seconds for one epoch ---
--- 0.19433975219726562 seconds for one epoch ---
--- 0.9136683940887451 seconds for one epoch ---
--- 0.17932915687561035 seconds for one epoch ---
--- 0.9701485633850098 seconds for one epoch ---
--- 0.22178411483764648 seconds for one epoch ---
--- 0.9001076221466064 seconds for one epoch ---
--- 0.18177580833435059 seconds for one epoch ---
--- 0.9226377010345459 seconds for one epoch ---
--- 0.17416977882385254 seconds for one epoch ---
--- 0.930558443069458 seconds for one epoch ---
--- 0.17738080024719238 seconds for one epoch ---
--- 0.9004299640655518 seconds for one epoch ---
--- 0.20628881454467773 seconds for one epoch ---
--- 0.9404861927032471 seconds for one epoch ---
--- 0.15200424194335938 seconds for one epoch ---
=========================
[[0.99990696]
 [0.50138676]
 [0.5378278 ]
 [0.        ]
 [0.        ]
 [0.95921355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.07874563]]
[[-1.5776708 ]
 [-0.6453119 ]
 [-0.6599558 ]
 [ 0.        ]
 [-0.        ]
 [-0.9615518 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.510099  ]
 [ 0.39826033]]
--- 0.15716052055358887 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2164.515625, (1242.1849, 1.8585181, 919.33685, 1.1352794)
   validation loss 1358.525390625, (1045.1245, 0.28902617, 311.97656, 1.1352794)
decoder loss ratio: 40489.938000, decoder SINDy loss  ratio: 0.673445
--- 0.17833995819091797 seconds for one epoch ---
--- 0.9637913703918457 seconds for one epoch ---
--- 0.1874840259552002 seconds for one epoch ---
--- 0.965933084487915 seconds for one epoch ---
--- 0.1852421760559082 seconds for one epoch ---
--- 0.948509931564331 seconds for one epoch ---
--- 0.19039559364318848 seconds for one epoch ---
--- 0.9069743156433105 seconds for one epoch ---
--- 0.15295696258544922 seconds for one epoch ---
--- 1.0254194736480713 seconds for one epoch ---
--- 0.28554797172546387 seconds for one epoch ---
--- 1.0676600933074951 seconds for one epoch ---
--- 0.17813634872436523 seconds for one epoch ---
--- 0.9342670440673828 seconds for one epoch ---
--- 0.20805859565734863 seconds for one epoch ---
--- 0.9393768310546875 seconds for one epoch ---
--- 0.19651412963867188 seconds for one epoch ---
--- 0.961862325668335 seconds for one epoch ---
--- 0.22401022911071777 seconds for one epoch ---
--- 0.9641199111938477 seconds for one epoch ---
--- 0.20462870597839355 seconds for one epoch ---
--- 0.9702601432800293 seconds for one epoch ---
--- 0.161240816116333 seconds for one epoch ---
--- 0.9413597583770752 seconds for one epoch ---
=========================
[[0.9999342 ]
 [0.5474223 ]
 [0.5462841 ]
 [0.        ]
 [0.        ]
 [0.9534049 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.06658882]]
[[-1.6156286 ]
 [-0.6638328 ]
 [-0.66337234]
 [-0.        ]
 [ 0.        ]
 [-0.947577  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.5506454 ]
 [ 0.3801507 ]]
--- 0.22110414505004883 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3683.8134765625, (1854.8558, 1.6790757, 1826.1354, 1.1430218)
   validation loss 893.0982666015625, (567.2904, 0.30851838, 324.35632, 1.1430218)
decoder loss ratio: 21977.815160, decoder SINDy loss  ratio: 0.700169
THRESHOLDING: 5 active coefficients
--- 0.15715527534484863 seconds for one epoch ---
--- 0.19912505149841309 seconds for one epoch ---
--- 0.9499309062957764 seconds for one epoch ---
--- 0.17371749877929688 seconds for one epoch ---
--- 0.9631280899047852 seconds for one epoch ---
--- 0.2176194190979004 seconds for one epoch ---
--- 0.9602923393249512 seconds for one epoch ---
--- 0.19653558731079102 seconds for one epoch ---
--- 0.9614284038543701 seconds for one epoch ---
--- 0.22322702407836914 seconds for one epoch ---
--- 0.9653606414794922 seconds for one epoch ---
--- 0.19925665855407715 seconds for one epoch ---
--- 0.978384256362915 seconds for one epoch ---
--- 0.19004297256469727 seconds for one epoch ---
--- 1.0220496654510498 seconds for one epoch ---
--- 0.17833542823791504 seconds for one epoch ---
--- 0.9624330997467041 seconds for one epoch ---
--- 0.22346186637878418 seconds for one epoch ---
--- 1.0163013935089111 seconds for one epoch ---
--- 0.17982172966003418 seconds for one epoch ---
--- 0.954988956451416 seconds for one epoch ---
--- 0.18501901626586914 seconds for one epoch ---
--- 1.0486335754394531 seconds for one epoch ---
--- 0.2061145305633545 seconds for one epoch ---
=========================
[[0.9999556 ]
 [0.59964883]
 [0.5362003 ]
 [0.        ]
 [0.        ]
 [0.9510748 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.6568315 ]
 [-0.6852658 ]
 [-0.6593006 ]
 [-0.        ]
 [-0.        ]
 [-0.94243324]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.5865726 ]
 [ 0.        ]]
--- 0.16684865951538086 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2888.987548828125, (1139.9054, 2.5623846, 1745.4385, 1.081336)
   validation loss 1027.5643310546875, (682.2547, 0.2832372, 343.9451, 1.081336)
decoder loss ratio: 26431.731513, decoder SINDy loss  ratio: 0.742454
--- 0.2021944522857666 seconds for one epoch ---
--- 1.0552730560302734 seconds for one epoch ---
--- 0.21036314964294434 seconds for one epoch ---
--- 0.966637134552002 seconds for one epoch ---
--- 0.18561458587646484 seconds for one epoch ---
--- 0.946890115737915 seconds for one epoch ---
--- 0.1896665096282959 seconds for one epoch ---
--- 0.9421000480651855 seconds for one epoch ---
--- 0.1725616455078125 seconds for one epoch ---
--- 0.9429922103881836 seconds for one epoch ---
--- 0.18421626091003418 seconds for one epoch ---
--- 0.9632036685943604 seconds for one epoch ---
--- 0.18639802932739258 seconds for one epoch ---
--- 0.9501793384552002 seconds for one epoch ---
--- 0.1983201503753662 seconds for one epoch ---
--- 0.9964942932128906 seconds for one epoch ---
--- 0.16643810272216797 seconds for one epoch ---
--- 1.0145142078399658 seconds for one epoch ---
--- 0.21729755401611328 seconds for one epoch ---
--- 0.9455790519714355 seconds for one epoch ---
--- 0.1908557415008545 seconds for one epoch ---
--- 1.0135622024536133 seconds for one epoch ---
--- 0.16815948486328125 seconds for one epoch ---
--- 0.9627351760864258 seconds for one epoch ---
=========================
[[0.9999681 ]
 [0.55825096]
 [0.52977335]
 [0.        ]
 [0.        ]
 [0.9524865 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.6952432]
 [-0.6682258]
 [-0.6567121]
 [ 0.       ]
 [ 0.       ]
 [-0.9455219]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.609791 ]
 [ 0.       ]]
--- 0.19454193115234375 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3689.750244140625, (1321.8625, 1.0101775, 2365.8, 1.0774276)
   validation loss 903.9954833984375, (615.56854, 0.36306554, 286.98645, 1.0774276)
decoder loss ratio: 23848.194010, decoder SINDy loss  ratio: 0.619501
--- 0.16715693473815918 seconds for one epoch ---
--- 0.22879242897033691 seconds for one epoch ---
--- 0.9288332462310791 seconds for one epoch ---
--- 0.17181730270385742 seconds for one epoch ---
--- 0.9463281631469727 seconds for one epoch ---
--- 0.2104649543762207 seconds for one epoch ---
--- 1.0014894008636475 seconds for one epoch ---
--- 0.2001502513885498 seconds for one epoch ---
--- 1.044936180114746 seconds for one epoch ---
--- 0.1654832363128662 seconds for one epoch ---
--- 0.9756937026977539 seconds for one epoch ---
--- 0.1555795669555664 seconds for one epoch ---
--- 0.9473683834075928 seconds for one epoch ---
--- 0.1772754192352295 seconds for one epoch ---
--- 1.0047402381896973 seconds for one epoch ---
--- 0.1929788589477539 seconds for one epoch ---
--- 1.000082015991211 seconds for one epoch ---
--- 0.15761137008666992 seconds for one epoch ---
--- 0.9780571460723877 seconds for one epoch ---
--- 0.16147351264953613 seconds for one epoch ---
--- 1.1026976108551025 seconds for one epoch ---
--- 0.1882798671722412 seconds for one epoch ---
--- 0.9557828903198242 seconds for one epoch ---
--- 0.15982699394226074 seconds for one epoch ---
=========================
[[0.99997795]
 [0.49022564]
 [0.5013499 ]
 [0.        ]
 [0.        ]
 [0.9444462 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.7227479 ]
 [-0.64083755]
 [-0.6452993 ]
 [-0.        ]
 [ 0.        ]
 [-0.9289786 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.6375318 ]
 [ 0.        ]]
--- 0.16538643836975098 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3041.49072265625, (1753.8492, 1.6183138, 1284.9629, 1.0601839)
   validation loss 864.98046875, (549.9959, 0.27507347, 313.64932, 1.0601839)
decoder loss ratio: 21307.796413, decoder SINDy loss  ratio: 0.677056
--- 0.168717622756958 seconds for one epoch ---
--- 0.9667525291442871 seconds for one epoch ---
--- 0.1691741943359375 seconds for one epoch ---
--- 0.9986214637756348 seconds for one epoch ---
--- 0.17472314834594727 seconds for one epoch ---
--- 1.0053186416625977 seconds for one epoch ---
--- 0.16714715957641602 seconds for one epoch ---
--- 0.9965362548828125 seconds for one epoch ---
--- 0.18493342399597168 seconds for one epoch ---
--- 1.034346342086792 seconds for one epoch ---
--- 0.17371463775634766 seconds for one epoch ---
--- 0.9823358058929443 seconds for one epoch ---
--- 0.19883251190185547 seconds for one epoch ---
--- 1.0125188827514648 seconds for one epoch ---
--- 0.15758371353149414 seconds for one epoch ---
--- 1.0228242874145508 seconds for one epoch ---
--- 0.19056129455566406 seconds for one epoch ---
--- 0.9950740337371826 seconds for one epoch ---
--- 0.17838501930236816 seconds for one epoch ---
--- 0.9590778350830078 seconds for one epoch ---
--- 0.18027472496032715 seconds for one epoch ---
--- 1.019904613494873 seconds for one epoch ---
--- 0.1771409511566162 seconds for one epoch ---
--- 1.0661132335662842 seconds for one epoch ---
=========================
[[0.99998105]
 [0.53977597]
 [0.48011512]
 [0.        ]
 [0.        ]
 [0.94239366]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.7680236 ]
 [-0.66074437]
 [-0.6367796 ]
 [ 0.        ]
 [-0.        ]
 [-0.9251174 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6715305 ]
 [ 0.        ]]
--- 0.18807625770568848 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2168.010986328125, (1394.937, 0.51493657, 771.49316, 1.0658966)
   validation loss 1141.1483154296875, (786.19037, 0.30102798, 353.591, 1.0658966)
decoder loss ratio: 30458.379768, decoder SINDy loss  ratio: 0.763276
--- 0.1719808578491211 seconds for one epoch ---
--- 0.19051456451416016 seconds for one epoch ---
--- 1.0053303241729736 seconds for one epoch ---
--- 0.20097613334655762 seconds for one epoch ---
--- 1.0317611694335938 seconds for one epoch ---
--- 0.19947123527526855 seconds for one epoch ---
--- 0.9550776481628418 seconds for one epoch ---
--- 0.1887509822845459 seconds for one epoch ---
--- 1.1290628910064697 seconds for one epoch ---
--- 0.18169617652893066 seconds for one epoch ---
--- 1.0236132144927979 seconds for one epoch ---
--- 0.20233535766601562 seconds for one epoch ---
--- 0.9959750175476074 seconds for one epoch ---
--- 0.24222159385681152 seconds for one epoch ---
--- 1.0244503021240234 seconds for one epoch ---
--- 0.18534612655639648 seconds for one epoch ---
--- 0.9985194206237793 seconds for one epoch ---
--- 0.1729581356048584 seconds for one epoch ---
--- 1.0327086448669434 seconds for one epoch ---
--- 0.1891162395477295 seconds for one epoch ---
--- 0.9760303497314453 seconds for one epoch ---
--- 0.17871880531311035 seconds for one epoch ---
--- 1.0213046073913574 seconds for one epoch ---
--- 0.17300629615783691 seconds for one epoch ---
=========================
[[0.9999932 ]
 [0.50357544]
 [0.50298923]
 [0.        ]
 [0.        ]
 [0.93546355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.807419 ]
 [-0.6461923]
 [-0.6459575]
 [-0.       ]
 [ 0.       ]
 [-0.9129769]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7128022]
 [ 0.       ]]
--- 0.1690380573272705 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2809.5556640625, (1452.9233, 0.33472493, 1355.2379, 1.0596778)
   validation loss 870.9869384765625, (544.4984, 0.4393013, 324.9895, 1.0596778)
decoder loss ratio: 21094.813814, decoder SINDy loss  ratio: 0.701536
--- 0.22526192665100098 seconds for one epoch ---
--- 1.0142486095428467 seconds for one epoch ---
--- 0.1762247085571289 seconds for one epoch ---
--- 1.0638763904571533 seconds for one epoch ---
--- 0.22495412826538086 seconds for one epoch ---
--- 0.9806737899780273 seconds for one epoch ---
--- 0.22204375267028809 seconds for one epoch ---
--- 1.0207064151763916 seconds for one epoch ---
--- 0.17472028732299805 seconds for one epoch ---
--- 1.0187935829162598 seconds for one epoch ---
--- 0.1658613681793213 seconds for one epoch ---
--- 1.009150743484497 seconds for one epoch ---
--- 0.152083158493042 seconds for one epoch ---
--- 1.0181035995483398 seconds for one epoch ---
--- 0.19600415229797363 seconds for one epoch ---
--- 1.0123333930969238 seconds for one epoch ---
--- 0.19906234741210938 seconds for one epoch ---
--- 0.9848191738128662 seconds for one epoch ---
--- 0.17195463180541992 seconds for one epoch ---
--- 1.1416304111480713 seconds for one epoch ---
--- 0.18114447593688965 seconds for one epoch ---
--- 1.0014586448669434 seconds for one epoch ---
--- 0.17247438430786133 seconds for one epoch ---
--- 1.0729506015777588 seconds for one epoch ---
=========================
[[0.99999326]
 [0.5208942 ]
 [0.4699671 ]
 [0.        ]
 [0.        ]
 [0.9221227 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.831978  ]
 [-0.6531432 ]
 [-0.63270026]
 [ 0.        ]
 [-0.        ]
 [-0.8926759 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7338953 ]
 [ 0.        ]]
--- 0.18856143951416016 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3739.41162109375, (1542.527, 1.0421995, 2194.782, 1.0605735)
   validation loss 914.2891845703125, (601.61865, 0.38132915, 311.22867, 1.0605735)
decoder loss ratio: 23307.751048, decoder SINDy loss  ratio: 0.671831
--- 0.16366171836853027 seconds for one epoch ---
--- 0.18328094482421875 seconds for one epoch ---
--- 1.0841398239135742 seconds for one epoch ---
--- 0.1997673511505127 seconds for one epoch ---
--- 1.0390443801879883 seconds for one epoch ---
--- 0.1903996467590332 seconds for one epoch ---
--- 0.9785523414611816 seconds for one epoch ---
--- 0.1993722915649414 seconds for one epoch ---
--- 1.0217366218566895 seconds for one epoch ---
--- 0.2134416103363037 seconds for one epoch ---
--- 1.0448698997497559 seconds for one epoch ---
--- 0.17064523696899414 seconds for one epoch ---
--- 1.0239999294281006 seconds for one epoch ---
--- 0.19701337814331055 seconds for one epoch ---
--- 1.166900873184204 seconds for one epoch ---
--- 0.1938471794128418 seconds for one epoch ---
--- 1.0333778858184814 seconds for one epoch ---
--- 0.22465038299560547 seconds for one epoch ---
--- 1.0168261528015137 seconds for one epoch ---
--- 0.19645333290100098 seconds for one epoch ---
--- 0.995067834854126 seconds for one epoch ---
--- 0.17775249481201172 seconds for one epoch ---
--- 1.106954574584961 seconds for one epoch ---
--- 0.1640911102294922 seconds for one epoch ---
=========================
[[0.99999315]
 [0.39928365]
 [0.4405114 ]
 [0.        ]
 [0.        ]
 [0.92726123]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.8604329 ]
 [-0.60381114]
 [-0.6207896 ]
 [ 0.        ]
 [-0.        ]
 [-0.9000846 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.743225  ]
 [ 0.        ]]
--- 0.16553211212158203 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3923.531005859375, (1792.0737, 1.4901994, 2128.931, 1.0360698)
   validation loss 1729.0277099609375, (1285.4398, 0.41348568, 442.1384, 1.0360698)
decoder loss ratio: 49800.170223, decoder SINDy loss  ratio: 0.954418
--- 0.17994427680969238 seconds for one epoch ---
--- 1.1129882335662842 seconds for one epoch ---
--- 0.2059028148651123 seconds for one epoch ---
--- 1.1327259540557861 seconds for one epoch ---
--- 0.19856667518615723 seconds for one epoch ---
--- 1.0499587059020996 seconds for one epoch ---
--- 0.1682910919189453 seconds for one epoch ---
--- 1.073470115661621 seconds for one epoch ---
--- 0.17373061180114746 seconds for one epoch ---
--- 1.022758960723877 seconds for one epoch ---
--- 0.20483040809631348 seconds for one epoch ---
--- 1.048062801361084 seconds for one epoch ---
--- 0.16511225700378418 seconds for one epoch ---
--- 1.0155112743377686 seconds for one epoch ---
--- 0.18089699745178223 seconds for one epoch ---
--- 1.0267205238342285 seconds for one epoch ---
--- 0.1952974796295166 seconds for one epoch ---
--- 1.0451412200927734 seconds for one epoch ---
--- 0.1957261562347412 seconds for one epoch ---
--- 1.0563325881958008 seconds for one epoch ---
--- 0.192657470703125 seconds for one epoch ---
--- 1.0523619651794434 seconds for one epoch ---
--- 0.16472554206848145 seconds for one epoch ---
--- 1.0389254093170166 seconds for one epoch ---
=========================
[[0.999993  ]
 [0.38964444]
 [0.46133953]
 [0.        ]
 [0.        ]
 [0.9250921 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.9004654 ]
 [-0.599766  ]
 [-0.62922436]
 [-0.        ]
 [-0.        ]
 [-0.8969007 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7773778 ]
 [ 0.        ]]
--- 0.41306161880493164 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3352.050048828125, (1286.9413, 0.47067523, 2063.6018, 1.0363656)
   validation loss 859.7119140625, (561.24396, 0.47326243, 296.9583, 1.0363656)
decoder loss ratio: 21743.565277, decoder SINDy loss  ratio: 0.641026
--- 0.16714262962341309 seconds for one epoch ---
--- 0.16619467735290527 seconds for one epoch ---
--- 1.1209583282470703 seconds for one epoch ---
--- 0.1960468292236328 seconds for one epoch ---
--- 1.069103479385376 seconds for one epoch ---
--- 0.18876218795776367 seconds for one epoch ---
--- 1.0742409229278564 seconds for one epoch ---
--- 0.14990448951721191 seconds for one epoch ---
--- 1.2177009582519531 seconds for one epoch ---
--- 0.17995667457580566 seconds for one epoch ---
--- 1.0314230918884277 seconds for one epoch ---
--- 0.19826292991638184 seconds for one epoch ---
--- 1.031567096710205 seconds for one epoch ---
--- 0.17253541946411133 seconds for one epoch ---
--- 1.0626294612884521 seconds for one epoch ---
--- 0.1971442699432373 seconds for one epoch ---
--- 1.0672760009765625 seconds for one epoch ---
--- 0.1740550994873047 seconds for one epoch ---
--- 1.0992732048034668 seconds for one epoch ---
--- 0.22456073760986328 seconds for one epoch ---
--- 1.1245615482330322 seconds for one epoch ---
--- 0.21800541877746582 seconds for one epoch ---
--- 1.0490055084228516 seconds for one epoch ---
--- 0.1832902431488037 seconds for one epoch ---
=========================
[[0.999993  ]
 [0.3223049 ]
 [0.45309788]
 [0.        ]
 [0.        ]
 [0.916364  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.9288902 ]
 [-0.57025754]
 [-0.625895  ]
 [-0.        ]
 [ 0.        ]
 [-0.88488895]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.8010561 ]
 [ 0.        ]]
--- 0.14145374298095703 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3744.1455078125, (1640.7401, 7.4135485, 2094.9666, 1.0254618)
   validation loss 879.1321411132812, (573.6495, 0.5294959, 303.92776, 1.0254618)
decoder loss ratio: 22224.176565, decoder SINDy loss  ratio: 0.656071
--- 0.16863751411437988 seconds for one epoch ---
--- 1.0964157581329346 seconds for one epoch ---
--- 0.19773125648498535 seconds for one epoch ---
--- 1.043607234954834 seconds for one epoch ---
--- 0.20897412300109863 seconds for one epoch ---
--- 1.0790314674377441 seconds for one epoch ---
--- 0.21569228172302246 seconds for one epoch ---
--- 1.0286176204681396 seconds for one epoch ---
--- 0.17811846733093262 seconds for one epoch ---
--- 1.0674946308135986 seconds for one epoch ---
--- 0.18686866760253906 seconds for one epoch ---
--- 1.0558269023895264 seconds for one epoch ---
--- 0.17900729179382324 seconds for one epoch ---
--- 1.0383501052856445 seconds for one epoch ---
--- 0.17423415184020996 seconds for one epoch ---
--- 1.1075806617736816 seconds for one epoch ---
--- 0.1712322235107422 seconds for one epoch ---
--- 1.060014009475708 seconds for one epoch ---
--- 0.20787835121154785 seconds for one epoch ---
--- 1.4216103553771973 seconds for one epoch ---
--- 0.20038080215454102 seconds for one epoch ---
--- 1.2007415294647217 seconds for one epoch ---
--- 0.18845844268798828 seconds for one epoch ---
--- 1.044142246246338 seconds for one epoch ---
=========================
[[0.9999929 ]
 [0.4247174 ]
 [0.46360198]
 [0.        ]
 [0.        ]
 [0.9183521 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.954475 ]
 [-0.6143392]
 [-0.6301372]
 [ 0.       ]
 [-0.       ]
 [-0.8875203]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.8085093]
 [ 0.       ]]
--- 0.18325233459472656 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3225.268310546875, (1280.0786, 0.84910274, 1943.2954, 1.0451802)
   validation loss 1002.7835693359375, (684.4926, 0.45648476, 316.78934, 1.0451802)
decoder loss ratio: 26518.432227, decoder SINDy loss  ratio: 0.683834
--- 0.154343843460083 seconds for one epoch ---
--- 0.1975383758544922 seconds for one epoch ---
--- 1.1067490577697754 seconds for one epoch ---
--- 0.1931753158569336 seconds for one epoch ---
--- 1.1470725536346436 seconds for one epoch ---
--- 0.20376038551330566 seconds for one epoch ---
--- 1.1128697395324707 seconds for one epoch ---
--- 0.2159714698791504 seconds for one epoch ---
--- 1.1774139404296875 seconds for one epoch ---
--- 0.1864478588104248 seconds for one epoch ---
--- 1.0554938316345215 seconds for one epoch ---
--- 0.17333102226257324 seconds for one epoch ---
--- 1.0844810009002686 seconds for one epoch ---
--- 0.19562363624572754 seconds for one epoch ---
--- 1.2506992816925049 seconds for one epoch ---
--- 0.1745896339416504 seconds for one epoch ---
--- 1.2040798664093018 seconds for one epoch ---
--- 0.17343878746032715 seconds for one epoch ---
--- 1.0952463150024414 seconds for one epoch ---
--- 0.22458195686340332 seconds for one epoch ---
--- 1.186708688735962 seconds for one epoch ---
--- 0.1964719295501709 seconds for one epoch ---
--- 1.1173129081726074 seconds for one epoch ---
--- 0.1753389835357666 seconds for one epoch ---
=========================
[[0.9999928 ]
 [0.3927191 ]
 [0.44021988]
 [0.        ]
 [0.        ]
 [0.90425557]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-1.9818969 ]
 [-0.60106087]
 [-0.62067175]
 [ 0.        ]
 [ 0.        ]
 [-0.8699856 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.838411  ]
 [ 0.        ]]
--- 0.16452765464782715 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3389.8583984375, (1616.294, 0.9833825, 1771.5493, 1.0317122)
   validation loss 1324.808837890625, (1021.294, 0.43665794, 302.04642, 1.0317122)
decoder loss ratio: 39566.702850, decoder SINDy loss  ratio: 0.652010
--- 0.17800521850585938 seconds for one epoch ---
--- 1.1552925109863281 seconds for one epoch ---
--- 0.20538115501403809 seconds for one epoch ---
--- 1.0411043167114258 seconds for one epoch ---
--- 0.14854764938354492 seconds for one epoch ---
--- 1.065753698348999 seconds for one epoch ---
--- 0.19066715240478516 seconds for one epoch ---
--- 1.0792005062103271 seconds for one epoch ---
--- 0.21118617057800293 seconds for one epoch ---
--- 1.217970609664917 seconds for one epoch ---
--- 0.2012500762939453 seconds for one epoch ---
--- 1.1729803085327148 seconds for one epoch ---
--- 0.18651795387268066 seconds for one epoch ---
--- 1.0962152481079102 seconds for one epoch ---
--- 0.18102073669433594 seconds for one epoch ---
--- 1.1425442695617676 seconds for one epoch ---
--- 0.18622422218322754 seconds for one epoch ---
--- 1.067962884902954 seconds for one epoch ---
--- 0.15632009506225586 seconds for one epoch ---
--- 1.160383939743042 seconds for one epoch ---
--- 0.17450833320617676 seconds for one epoch ---
--- 1.17197847366333 seconds for one epoch ---
--- 0.18199563026428223 seconds for one epoch ---
--- 1.0829026699066162 seconds for one epoch ---
=========================
[[0.9999928 ]
 [0.33226237]
 [0.4102617 ]
 [0.        ]
 [0.        ]
 [0.89925766]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.007629 ]
 [-0.5747917]
 [-0.6083802]
 [-0.       ]
 [ 0.       ]
 [-0.8643229]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.853922 ]
 [ 0.       ]]
--- 0.19870710372924805 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3580.881103515625, (1533.6724, 1.1928118, 2044.9951, 1.0206875)
   validation loss 907.3753051757812, (615.0031, 0.46833515, 290.88315, 1.0206875)
decoder loss ratio: 23826.288282, decoder SINDy loss  ratio: 0.627912
--- 0.16115927696228027 seconds for one epoch ---
--- 0.19986557960510254 seconds for one epoch ---
--- 1.1404857635498047 seconds for one epoch ---
--- 0.1613461971282959 seconds for one epoch ---
--- 1.0549986362457275 seconds for one epoch ---
--- 0.19010472297668457 seconds for one epoch ---
--- 1.142529010772705 seconds for one epoch ---
--- 0.15471482276916504 seconds for one epoch ---
--- 1.2054531574249268 seconds for one epoch ---
--- 0.15328478813171387 seconds for one epoch ---
--- 1.141181230545044 seconds for one epoch ---
--- 0.19534778594970703 seconds for one epoch ---
--- 1.0920617580413818 seconds for one epoch ---
--- 0.20400214195251465 seconds for one epoch ---
--- 1.1785433292388916 seconds for one epoch ---
--- 0.19278979301452637 seconds for one epoch ---
--- 1.1375985145568848 seconds for one epoch ---
--- 0.16951465606689453 seconds for one epoch ---
--- 1.11930251121521 seconds for one epoch ---
--- 0.19273877143859863 seconds for one epoch ---
--- 1.215730905532837 seconds for one epoch ---
--- 0.22375941276550293 seconds for one epoch ---
--- 1.224269151687622 seconds for one epoch ---
--- 0.18047428131103516 seconds for one epoch ---
=========================
[[0.99999297]
 [0.32793957]
 [0.3989324 ]
 [0.        ]
 [0.        ]
 [0.89242953]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.0603578 ]
 [-0.5728327 ]
 [-0.60366565]
 [ 0.        ]
 [-0.        ]
 [-0.85697764]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.9116514 ]
 [ 0.        ]]
--- 0.1741328239440918 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4634.63671875, (1477.9701, 0.51913285, 3155.1348, 1.0126182)
   validation loss 813.5819702148438, (517.3726, 0.5133085, 294.68338, 1.0126182)
decoder loss ratio: 20043.913483, decoder SINDy loss  ratio: 0.636116
--- 0.19468951225280762 seconds for one epoch ---
--- 1.1070101261138916 seconds for one epoch ---
--- 0.16870331764221191 seconds for one epoch ---
--- 1.144493818283081 seconds for one epoch ---
--- 0.1570427417755127 seconds for one epoch ---
--- 1.1354639530181885 seconds for one epoch ---
--- 0.16413187980651855 seconds for one epoch ---
--- 1.1093568801879883 seconds for one epoch ---
--- 0.19525551795959473 seconds for one epoch ---
--- 1.0941636562347412 seconds for one epoch ---
--- 0.16375946998596191 seconds for one epoch ---
--- 1.0972323417663574 seconds for one epoch ---
--- 0.18776941299438477 seconds for one epoch ---
--- 1.107405424118042 seconds for one epoch ---
--- 0.1646125316619873 seconds for one epoch ---
--- 1.245215654373169 seconds for one epoch ---
--- 0.19671964645385742 seconds for one epoch ---
--- 1.1299912929534912 seconds for one epoch ---
--- 0.18236279487609863 seconds for one epoch ---
--- 1.1191401481628418 seconds for one epoch ---
--- 0.19831180572509766 seconds for one epoch ---
--- 1.1721365451812744 seconds for one epoch ---
--- 0.16255569458007812 seconds for one epoch ---
--- 1.1635801792144775 seconds for one epoch ---
=========================
[[0.99999475]
 [0.36295494]
 [0.36893725]
 [0.        ]
 [0.        ]
 [0.8794876 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.0966704 ]
 [-0.5883646 ]
 [-0.5909491 ]
 [-0.        ]
 [ 0.        ]
 [-0.84411323]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.9529126 ]
 [ 0.        ]]
--- 0.27898716926574707 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3285.587890625, (1369.2352, 2.3150585, 1913.0199, 1.0175012)
   validation loss 924.7217407226562, (623.4507, 0.5260572, 299.72748, 1.0175012)
decoder loss ratio: 24153.561840, decoder SINDy loss  ratio: 0.647004
--- 0.240494966506958 seconds for one epoch ---
--- 0.30800485610961914 seconds for one epoch ---
--- 1.137181282043457 seconds for one epoch ---
--- 0.300750732421875 seconds for one epoch ---
--- 1.1603381633758545 seconds for one epoch ---
--- 0.302562952041626 seconds for one epoch ---
--- 1.1696836948394775 seconds for one epoch ---
--- 0.30736374855041504 seconds for one epoch ---
--- 1.1656558513641357 seconds for one epoch ---
--- 0.2966930866241455 seconds for one epoch ---
--- 1.145195722579956 seconds for one epoch ---
--- 0.30803394317626953 seconds for one epoch ---
--- 1.1971626281738281 seconds for one epoch ---
--- 0.3004601001739502 seconds for one epoch ---
--- 1.1592042446136475 seconds for one epoch ---
--- 0.3096427917480469 seconds for one epoch ---
--- 1.150665521621704 seconds for one epoch ---
--- 0.3001258373260498 seconds for one epoch ---
--- 1.227107286453247 seconds for one epoch ---
--- 0.3022451400756836 seconds for one epoch ---
--- 1.1602888107299805 seconds for one epoch ---
--- 0.2878994941711426 seconds for one epoch ---
--- 1.1587402820587158 seconds for one epoch ---
--- 0.29499077796936035 seconds for one epoch ---
=========================
[[0.9999964 ]
 [0.442164  ]
 [0.32681015]
 [0.        ]
 [0.        ]
 [0.8861401 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.1327035 ]
 [-0.6214628 ]
 [-0.5723189 ]
 [-0.        ]
 [-0.        ]
 [-0.85056716]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.972268  ]
 [ 0.        ]]
--- 0.2630479335784912 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2410.275146484375, (1072.2146, 0.8584486, 1336.1815, 1.0208735)
   validation loss 838.8685302734375, (526.1623, 0.51983, 311.1655, 1.0208735)
decoder loss ratio: 20384.440669, decoder SINDy loss  ratio: 0.671694
--- 0.30198025703430176 seconds for one epoch ---
--- 1.1233429908752441 seconds for one epoch ---
--- 0.2980349063873291 seconds for one epoch ---
--- 1.1649205684661865 seconds for one epoch ---
--- 0.30377674102783203 seconds for one epoch ---
--- 1.1412532329559326 seconds for one epoch ---
--- 0.3184075355529785 seconds for one epoch ---
--- 1.1535441875457764 seconds for one epoch ---
--- 0.2982757091522217 seconds for one epoch ---
--- 1.1111047267913818 seconds for one epoch ---
--- 0.2767345905303955 seconds for one epoch ---
--- 1.1593501567840576 seconds for one epoch ---
--- 0.31991100311279297 seconds for one epoch ---
--- 1.1645054817199707 seconds for one epoch ---
--- 0.3420577049255371 seconds for one epoch ---
--- 1.1562275886535645 seconds for one epoch ---
--- 0.3243114948272705 seconds for one epoch ---
--- 1.1776108741760254 seconds for one epoch ---
--- 0.31164002418518066 seconds for one epoch ---
--- 1.1616110801696777 seconds for one epoch ---
--- 0.33057665824890137 seconds for one epoch ---
--- 1.2204859256744385 seconds for one epoch ---
--- 0.3394503593444824 seconds for one epoch ---
--- 1.194305419921875 seconds for one epoch ---
=========================
[[0.99999845]
 [0.39106745]
 [0.34622586]
 [0.        ]
 [0.        ]
 [0.8847603 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.1609538 ]
 [-0.60036683]
 [-0.58103675]
 [ 0.        ]
 [-0.        ]
 [-0.84920204]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.9936273 ]
 [ 0.        ]]
--- 0.3034324645996094 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2792.799560546875, (1109.275, 3.3326292, 1679.1791, 1.0129853)
   validation loss 813.4899291992188, (530.6874, 0.47306272, 281.31644, 1.0129853)
decoder loss ratio: 20559.750335, decoder SINDy loss  ratio: 0.607261
--- 0.26230549812316895 seconds for one epoch ---
--- 0.30161523818969727 seconds for one epoch ---
--- 1.1606431007385254 seconds for one epoch ---
--- 0.29297542572021484 seconds for one epoch ---
--- 1.1835517883300781 seconds for one epoch ---
--- 0.298506498336792 seconds for one epoch ---
--- 1.162343978881836 seconds for one epoch ---
--- 0.2922632694244385 seconds for one epoch ---
--- 1.145531177520752 seconds for one epoch ---
--- 0.2884514331817627 seconds for one epoch ---
--- 1.179914951324463 seconds for one epoch ---
--- 0.29910922050476074 seconds for one epoch ---
--- 1.1687772274017334 seconds for one epoch ---
--- 0.30063867568969727 seconds for one epoch ---
--- 1.1851074695587158 seconds for one epoch ---
--- 0.29685139656066895 seconds for one epoch ---
--- 1.1757831573486328 seconds for one epoch ---
--- 0.29799628257751465 seconds for one epoch ---
--- 1.1637365818023682 seconds for one epoch ---
--- 0.3052051067352295 seconds for one epoch ---
--- 1.2057504653930664 seconds for one epoch ---
--- 0.28450632095336914 seconds for one epoch ---
--- 1.1812303066253662 seconds for one epoch ---
--- 0.29662060737609863 seconds for one epoch ---
=========================
[[0.99999845]
 [0.40493175]
 [0.35725725]
 [0.        ]
 [0.        ]
 [0.87263674]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.1825209 ]
 [-0.60616815]
 [-0.5858866 ]
 [-0.        ]
 [-0.        ]
 [-0.83778065]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.010226  ]
 [ 0.        ]]
--- 0.26915836334228516 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3798.6865234375, (1904.1626, 1.3128208, 1892.1926, 1.0186652)
   validation loss 710.908447265625, (428.31784, 0.57488596, 280.99704, 1.0186652)
decoder loss ratio: 16593.776736, decoder SINDy loss  ratio: 0.606572
--- 0.30475687980651855 seconds for one epoch ---
--- 1.1571896076202393 seconds for one epoch ---
--- 0.3007087707519531 seconds for one epoch ---
--- 1.1818573474884033 seconds for one epoch ---
--- 0.3061668872833252 seconds for one epoch ---
--- 1.1616942882537842 seconds for one epoch ---
--- 0.2972877025604248 seconds for one epoch ---
--- 1.1508357524871826 seconds for one epoch ---
--- 0.29575657844543457 seconds for one epoch ---
--- 1.2103149890899658 seconds for one epoch ---
--- 0.29871535301208496 seconds for one epoch ---
--- 1.2138867378234863 seconds for one epoch ---
--- 0.2974417209625244 seconds for one epoch ---
--- 1.2008118629455566 seconds for one epoch ---
--- 0.2970576286315918 seconds for one epoch ---
--- 1.188049077987671 seconds for one epoch ---
--- 0.2961575984954834 seconds for one epoch ---
--- 1.1822004318237305 seconds for one epoch ---
--- 0.30074620246887207 seconds for one epoch ---
--- 1.2011187076568604 seconds for one epoch ---
--- 0.3030531406402588 seconds for one epoch ---
--- 1.1915957927703857 seconds for one epoch ---
--- 0.29462385177612305 seconds for one epoch ---
--- 1.1914355754852295 seconds for one epoch ---
=========================
[[0.9999995]
 [0.4065756]
 [0.3764856]
 [0.       ]
 [0.       ]
 [0.8661022]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.2115374 ]
 [-0.6068516 ]
 [-0.5941857 ]
 [ 0.        ]
 [ 0.        ]
 [-0.83200675]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.028648  ]
 [ 0.        ]]
--- 0.2893404960632324 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2687.20654296875, (1170.2869, 1.7782454, 1514.1221, 1.0196393)
   validation loss 1276.838623046875, (946.8622, 0.7030066, 328.25378, 1.0196393)
decoder loss ratio: 36683.084780, decoder SINDy loss  ratio: 0.708582
--- 0.25376343727111816 seconds for one epoch ---
--- 0.304335355758667 seconds for one epoch ---
--- 1.2004468441009521 seconds for one epoch ---
--- 0.30457091331481934 seconds for one epoch ---
--- 1.1585311889648438 seconds for one epoch ---
--- 0.2964787483215332 seconds for one epoch ---
--- 1.1804211139678955 seconds for one epoch ---
--- 0.28946518898010254 seconds for one epoch ---
--- 1.1895389556884766 seconds for one epoch ---
--- 0.2904813289642334 seconds for one epoch ---
--- 1.1964340209960938 seconds for one epoch ---
--- 0.3116183280944824 seconds for one epoch ---
--- 1.204946517944336 seconds for one epoch ---
--- 0.31666088104248047 seconds for one epoch ---
--- 1.195566177368164 seconds for one epoch ---
--- 0.3346109390258789 seconds for one epoch ---
--- 1.2145841121673584 seconds for one epoch ---
--- 0.32385945320129395 seconds for one epoch ---
--- 1.2247698307037354 seconds for one epoch ---
--- 0.3337411880493164 seconds for one epoch ---
--- 1.21351957321167 seconds for one epoch ---
--- 0.33410167694091797 seconds for one epoch ---
--- 1.2378532886505127 seconds for one epoch ---
--- 0.32084083557128906 seconds for one epoch ---
=========================
[[0.9999995 ]
 [0.5078803 ]
 [0.37133792]
 [0.        ]
 [0.        ]
 [0.87651587]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.2464457]
 [-0.647921 ]
 [-0.5919819]
 [-0.       ]
 [-0.       ]
 [-0.8413295]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.0460625]
 [ 0.       ]]
--- 0.25969862937927246 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3546.0419921875, (1484.3169, 0.52306783, 2060.164, 1.0380812)
   validation loss 850.38623046875, (555.3872, 0.7919115, 293.16898, 1.0380812)
decoder loss ratio: 21516.664595, decoder SINDy loss  ratio: 0.632846
--- 0.3003370761871338 seconds for one epoch ---
--- 1.200329065322876 seconds for one epoch ---
--- 0.3026916980743408 seconds for one epoch ---
--- 1.1771581172943115 seconds for one epoch ---
--- 0.2954244613647461 seconds for one epoch ---
--- 1.217529296875 seconds for one epoch ---
--- 0.30026960372924805 seconds for one epoch ---
--- 1.1774277687072754 seconds for one epoch ---
--- 0.2894597053527832 seconds for one epoch ---
--- 1.2109854221343994 seconds for one epoch ---
--- 0.29039525985717773 seconds for one epoch ---
--- 1.1914761066436768 seconds for one epoch ---
--- 0.3000807762145996 seconds for one epoch ---
--- 1.190406084060669 seconds for one epoch ---
--- 0.2940406799316406 seconds for one epoch ---
--- 1.2100703716278076 seconds for one epoch ---
--- 0.2963123321533203 seconds for one epoch ---
--- 1.200404405593872 seconds for one epoch ---
--- 0.2951934337615967 seconds for one epoch ---
--- 1.209944486618042 seconds for one epoch ---
--- 0.30240726470947266 seconds for one epoch ---
--- 1.2165822982788086 seconds for one epoch ---
--- 0.295703649520874 seconds for one epoch ---
--- 1.1959834098815918 seconds for one epoch ---
=========================
[[0.9999995 ]
 [0.45352516]
 [0.35191926]
 [0.        ]
 [0.        ]
 [0.8601549 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.258119  ]
 [-0.6260694 ]
 [-0.58354884]
 [ 0.        ]
 [ 0.        ]
 [-0.82695496]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0490074 ]
 [ 0.        ]]
--- 0.2912623882293701 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3657.86962890625, (1433.6102, 0.9555132, 2222.2861, 1.0174655)
   validation loss 945.1159057617188, (653.147, 0.811484, 290.14, 1.0174655)
decoder loss ratio: 25304.047634, decoder SINDy loss  ratio: 0.626308
THRESHOLDING: 5 active coefficients
--- 1.205387830734253 seconds for one epoch ---
--- 0.3039109706878662 seconds for one epoch ---
--- 1.234464406967163 seconds for one epoch ---
--- 0.3029820919036865 seconds for one epoch ---
--- 1.209693431854248 seconds for one epoch ---
--- 0.2990531921386719 seconds for one epoch ---
--- 1.2212650775909424 seconds for one epoch ---
--- 0.30179333686828613 seconds for one epoch ---
--- 1.2196471691131592 seconds for one epoch ---
--- 0.29747962951660156 seconds for one epoch ---
--- 1.210890769958496 seconds for one epoch ---
--- 0.3044314384460449 seconds for one epoch ---
--- 1.2381386756896973 seconds for one epoch ---
--- 0.2956886291503906 seconds for one epoch ---
--- 1.2114531993865967 seconds for one epoch ---
--- 0.2959287166595459 seconds for one epoch ---
--- 1.2252018451690674 seconds for one epoch ---
--- 0.30145859718322754 seconds for one epoch ---
--- 1.2451636791229248 seconds for one epoch ---
--- 0.3026266098022461 seconds for one epoch ---
--- 1.2195627689361572 seconds for one epoch ---
--- 0.29991745948791504 seconds for one epoch ---
--- 1.2213139533996582 seconds for one epoch ---
--- 0.3045225143432617 seconds for one epoch ---
=========================
[[0.9999995 ]
 [0.44322437]
 [0.35459736]
 [0.        ]
 [0.        ]
 [0.85337144]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.2903879 ]
 [-0.62189436]
 [-0.58472395]
 [ 0.        ]
 [ 0.        ]
 [-0.82140905]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.078123  ]
 [ 0.        ]]
--- 0.25428152084350586 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6632.91357421875, (1646.8208, 0.5287521, 4984.5557, 1.0081897)
   validation loss 888.7576293945312, (579.4609, 0.7212811, 307.56732, 1.0081897)
decoder loss ratio: 22449.320343, decoder SINDy loss  ratio: 0.663927
--- 0.3038828372955322 seconds for one epoch ---
--- 1.2136378288269043 seconds for one epoch ---
--- 0.2956991195678711 seconds for one epoch ---
--- 1.2106056213378906 seconds for one epoch ---
--- 0.30025744438171387 seconds for one epoch ---
--- 1.2230865955352783 seconds for one epoch ---
--- 0.3120415210723877 seconds for one epoch ---
--- 1.178518533706665 seconds for one epoch ---
--- 0.3019294738769531 seconds for one epoch ---
--- 1.1894876956939697 seconds for one epoch ---
--- 0.2987339496612549 seconds for one epoch ---
--- 1.2504329681396484 seconds for one epoch ---
--- 0.3089923858642578 seconds for one epoch ---
--- 1.2359349727630615 seconds for one epoch ---
--- 0.29682040214538574 seconds for one epoch ---
--- 1.2242538928985596 seconds for one epoch ---
--- 0.30755066871643066 seconds for one epoch ---
--- 1.2392401695251465 seconds for one epoch ---
--- 0.3107583522796631 seconds for one epoch ---
--- 1.2417893409729004 seconds for one epoch ---
--- 0.31531238555908203 seconds for one epoch ---
--- 1.2584195137023926 seconds for one epoch ---
--- 0.3008995056152344 seconds for one epoch ---
--- 1.1873698234558105 seconds for one epoch ---
=========================
[[1.        ]
 [0.44769552]
 [0.3300847 ]
 [0.        ]
 [0.        ]
 [0.8572458 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.3184159 ]
 [-0.62370896]
 [-0.5738075 ]
 [-0.        ]
 [-0.        ]
 [-0.8245498 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.0862803 ]
 [ 0.        ]]
--- 0.2963409423828125 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1848.259765625, (1166.3146, 0.34536877, 680.59375, 1.0061152)
   validation loss 828.8487548828125, (505.4941, 0.68951327, 321.65906, 1.0061152)
decoder loss ratio: 19583.719402, decoder SINDy loss  ratio: 0.694346
--- 0.26732397079467773 seconds for one epoch ---
--- 0.3081934452056885 seconds for one epoch ---
--- 1.2335245609283447 seconds for one epoch ---
--- 0.3031275272369385 seconds for one epoch ---
--- 1.215958595275879 seconds for one epoch ---
--- 0.3058605194091797 seconds for one epoch ---
--- 1.247741937637329 seconds for one epoch ---
--- 0.31644225120544434 seconds for one epoch ---
--- 1.2671349048614502 seconds for one epoch ---
--- 0.3134124279022217 seconds for one epoch ---
--- 1.2479970455169678 seconds for one epoch ---
--- 0.2946751117706299 seconds for one epoch ---
--- 1.2600057125091553 seconds for one epoch ---
--- 0.29814791679382324 seconds for one epoch ---
--- 1.2560932636260986 seconds for one epoch ---
--- 0.2992708683013916 seconds for one epoch ---
--- 1.2406997680664062 seconds for one epoch ---
--- 0.30561280250549316 seconds for one epoch ---
--- 1.2767043113708496 seconds for one epoch ---
--- 0.30129456520080566 seconds for one epoch ---
--- 1.2159490585327148 seconds for one epoch ---
--- 0.29487013816833496 seconds for one epoch ---
--- 1.2090563774108887 seconds for one epoch ---
--- 0.3048872947692871 seconds for one epoch ---
=========================
[[1.        ]
 [0.4467912 ]
 [0.35246623]
 [0.        ]
 [0.        ]
 [0.84748566]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.3340561 ]
 [-0.6233422 ]
 [-0.5837893 ]
 [-0.        ]
 [ 0.        ]
 [-0.81676555]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0907483 ]
 [ 0.        ]]
--- 0.25607848167419434 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3235.5263671875, (1801.2164, 1.8607273, 1431.4368, 1.0123457)
   validation loss 1813.1697998046875, (1437.2592, 0.54802155, 374.35034, 1.0123457)
decoder loss ratio: 55681.914867, decoder SINDy loss  ratio: 0.808088
--- 0.2932579517364502 seconds for one epoch ---
--- 1.1986134052276611 seconds for one epoch ---
--- 0.2838125228881836 seconds for one epoch ---
--- 1.248255968093872 seconds for one epoch ---
--- 0.3207366466522217 seconds for one epoch ---
--- 1.2501182556152344 seconds for one epoch ---
--- 0.31508445739746094 seconds for one epoch ---
--- 1.235792875289917 seconds for one epoch ---
--- 0.31681227684020996 seconds for one epoch ---
--- 1.27838134765625 seconds for one epoch ---
--- 0.3180418014526367 seconds for one epoch ---
--- 1.2964472770690918 seconds for one epoch ---
--- 0.3283505439758301 seconds for one epoch ---
--- 1.2788488864898682 seconds for one epoch ---
--- 0.3122878074645996 seconds for one epoch ---
--- 1.2857353687286377 seconds for one epoch ---
--- 0.28792834281921387 seconds for one epoch ---
--- 1.2768168449401855 seconds for one epoch ---
--- 0.29199886322021484 seconds for one epoch ---
--- 1.274064302444458 seconds for one epoch ---
--- 0.29419898986816406 seconds for one epoch ---
--- 1.270315170288086 seconds for one epoch ---
--- 0.29854464530944824 seconds for one epoch ---
--- 1.264611005783081 seconds for one epoch ---
=========================
[[1.        ]
 [0.49364185]
 [0.41396388]
 [0.        ]
 [0.        ]
 [0.8281033 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.3472033 ]
 [-0.6422111 ]
 [-0.60991323]
 [ 0.        ]
 [-0.        ]
 [-0.8024422 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.096942  ]
 [-0.        ]]
--- 0.2965428829193115 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2292.270263671875, (1079.4866, 0.514767, 1211.2445, 1.0244378)
   validation loss 795.245849609375, (494.75323, 0.75502, 298.7132, 1.0244378)
decoder loss ratio: 19167.599248, decoder SINDy loss  ratio: 0.644814
--- 0.267925500869751 seconds for one epoch ---
--- 0.30797910690307617 seconds for one epoch ---
--- 1.2771666049957275 seconds for one epoch ---
--- 0.3308539390563965 seconds for one epoch ---
--- 1.2501945495605469 seconds for one epoch ---
--- 0.32778143882751465 seconds for one epoch ---
--- 1.3030586242675781 seconds for one epoch ---
--- 0.346693754196167 seconds for one epoch ---
--- 1.2821800708770752 seconds for one epoch ---
--- 0.34067368507385254 seconds for one epoch ---
--- 1.2755374908447266 seconds for one epoch ---
--- 0.3374760150909424 seconds for one epoch ---
--- 1.2567803859710693 seconds for one epoch ---
--- 0.330916166305542 seconds for one epoch ---
--- 1.283385992050171 seconds for one epoch ---
--- 0.3208193778991699 seconds for one epoch ---
--- 1.2743492126464844 seconds for one epoch ---
--- 0.3214139938354492 seconds for one epoch ---
--- 1.2932589054107666 seconds for one epoch ---
--- 0.3307149410247803 seconds for one epoch ---
--- 1.3111176490783691 seconds for one epoch ---
--- 0.30445075035095215 seconds for one epoch ---
--- 1.2964417934417725 seconds for one epoch ---
--- 0.3086528778076172 seconds for one epoch ---
=========================
[[1.        ]
 [0.4917524 ]
 [0.35487938]
 [0.        ]
 [0.        ]
 [0.841583  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.3783696]
 [-0.6414533]
 [-0.5848476]
 [ 0.       ]
 [-0.       ]
 [-0.8122544]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.1138196]
 [ 0.       ]]
--- 0.2617917060852051 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2800.706298828125, (1154.3116, 0.9383261, 1644.4413, 1.0147785)
   validation loss 853.87841796875, (528.01465, 0.6471055, 324.2019, 1.0147785)
decoder loss ratio: 20456.204154, decoder SINDy loss  ratio: 0.699835
--- 0.30440211296081543 seconds for one epoch ---
--- 1.2651658058166504 seconds for one epoch ---
--- 0.27678489685058594 seconds for one epoch ---
--- 1.2996480464935303 seconds for one epoch ---
--- 0.3011476993560791 seconds for one epoch ---
--- 1.2535443305969238 seconds for one epoch ---
--- 0.29555368423461914 seconds for one epoch ---
--- 1.2657499313354492 seconds for one epoch ---
--- 0.29366445541381836 seconds for one epoch ---
--- 1.266301155090332 seconds for one epoch ---
--- 0.3011047840118408 seconds for one epoch ---
--- 1.287100076675415 seconds for one epoch ---
--- 0.3093080520629883 seconds for one epoch ---
--- 1.272204875946045 seconds for one epoch ---
--- 0.3023252487182617 seconds for one epoch ---
--- 1.3099324703216553 seconds for one epoch ---
--- 0.3008902072906494 seconds for one epoch ---
--- 1.276698112487793 seconds for one epoch ---
--- 0.2943863868713379 seconds for one epoch ---
--- 1.2934751510620117 seconds for one epoch ---
--- 0.29067015647888184 seconds for one epoch ---
--- 1.2880094051361084 seconds for one epoch ---
--- 0.2950315475463867 seconds for one epoch ---
--- 1.3032894134521484 seconds for one epoch ---
=========================
[[1.        ]
 [0.46795   ]
 [0.34242278]
 [0.        ]
 [0.        ]
 [0.83565795]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.413907  ]
 [-0.63189065]
 [-0.57934916]
 [-0.        ]
 [-0.        ]
 [-0.8078625 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.153819  ]
 [ 0.        ]]
--- 0.3109867572784424 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2716.274658203125, (1448.9725, 3.1849864, 1263.1088, 1.008577)
   validation loss 962.6310424804688, (642.0193, 0.5058197, 319.09738, 1.008577)
decoder loss ratio: 24872.941777, decoder SINDy loss  ratio: 0.688817
--- 0.2709617614746094 seconds for one epoch ---
--- 0.3001084327697754 seconds for one epoch ---
--- 1.307607650756836 seconds for one epoch ---
--- 0.30660128593444824 seconds for one epoch ---
--- 1.2833809852600098 seconds for one epoch ---
--- 0.3287644386291504 seconds for one epoch ---
--- 1.3107757568359375 seconds for one epoch ---
--- 0.3049187660217285 seconds for one epoch ---
--- 1.2969145774841309 seconds for one epoch ---
--- 0.3141200542449951 seconds for one epoch ---
--- 1.3002374172210693 seconds for one epoch ---
--- 0.30065131187438965 seconds for one epoch ---
--- 1.2952749729156494 seconds for one epoch ---
--- 0.30684852600097656 seconds for one epoch ---
--- 1.3252232074737549 seconds for one epoch ---
--- 0.30105018615722656 seconds for one epoch ---
--- 1.3060574531555176 seconds for one epoch ---
--- 0.2987358570098877 seconds for one epoch ---
--- 1.3204360008239746 seconds for one epoch ---
--- 0.2995491027832031 seconds for one epoch ---
--- 1.3123257160186768 seconds for one epoch ---
--- 0.2999756336212158 seconds for one epoch ---
--- 1.3153398036956787 seconds for one epoch ---
--- 0.3040909767150879 seconds for one epoch ---
=========================
[[1.        ]
 [0.53403664]
 [0.32974648]
 [0.        ]
 [0.        ]
 [0.8227688 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.4302592 ]
 [-0.6584324 ]
 [-0.5736544 ]
 [ 0.        ]
 [ 0.        ]
 [-0.79872775]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.163399  ]
 [-0.        ]]
--- 0.2645137310028076 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4436.5458984375, (1878.1978, 1.5412002, 2555.7888, 1.0179191)
   validation loss 1189.09228515625, (879.6274, 0.7613061, 307.68564, 1.0179191)
decoder loss ratio: 34078.291816, decoder SINDy loss  ratio: 0.664183
--- 0.29428911209106445 seconds for one epoch ---
--- 1.2988221645355225 seconds for one epoch ---
--- 0.30182743072509766 seconds for one epoch ---
--- 1.3075919151306152 seconds for one epoch ---
--- 0.30112481117248535 seconds for one epoch ---
--- 1.317054271697998 seconds for one epoch ---
--- 0.28340697288513184 seconds for one epoch ---
--- 1.3232243061065674 seconds for one epoch ---
--- 0.3049049377441406 seconds for one epoch ---
--- 1.2995553016662598 seconds for one epoch ---
--- 0.30378103256225586 seconds for one epoch ---
--- 1.2874579429626465 seconds for one epoch ---
--- 0.2838327884674072 seconds for one epoch ---
--- 1.3014206886291504 seconds for one epoch ---
--- 0.29942846298217773 seconds for one epoch ---
--- 1.3157579898834229 seconds for one epoch ---
--- 0.29659199714660645 seconds for one epoch ---
--- 1.295989990234375 seconds for one epoch ---
--- 0.30004405975341797 seconds for one epoch ---
--- 1.28920316696167 seconds for one epoch ---
--- 0.2927076816558838 seconds for one epoch ---
--- 1.3221328258514404 seconds for one epoch ---
--- 0.3066139221191406 seconds for one epoch ---
--- 1.3261449337005615 seconds for one epoch ---
=========================
[[1.        ]
 [0.53318787]
 [0.30311373]
 [0.        ]
 [0.        ]
 [0.82580465]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.450959  ]
 [-0.6580903 ]
 [-0.5613081 ]
 [-0.        ]
 [-0.        ]
 [-0.80083066]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.171104  ]
 [-0.        ]]
--- 0.3152353763580322 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5648.4677734375, (2678.6567, 5.017653, 2963.7786, 1.014525)
   validation loss 1101.1666259765625, (787.6493, 0.78184956, 311.721, 1.014525)
decoder loss ratio: 30514.900991, decoder SINDy loss  ratio: 0.672894
--- 0.27682995796203613 seconds for one epoch ---
--- 0.32312917709350586 seconds for one epoch ---
--- 1.3142054080963135 seconds for one epoch ---
--- 0.3169124126434326 seconds for one epoch ---
--- 1.3271732330322266 seconds for one epoch ---
--- 0.3115050792694092 seconds for one epoch ---
--- 1.3230204582214355 seconds for one epoch ---
--- 0.32625746726989746 seconds for one epoch ---
--- 1.298478126525879 seconds for one epoch ---
--- 0.3174893856048584 seconds for one epoch ---
--- 1.3355278968811035 seconds for one epoch ---
--- 0.3175191879272461 seconds for one epoch ---
--- 1.3465611934661865 seconds for one epoch ---
--- 0.30463099479675293 seconds for one epoch ---
--- 1.335606336593628 seconds for one epoch ---
--- 0.3042612075805664 seconds for one epoch ---
--- 1.3418223857879639 seconds for one epoch ---
--- 0.29915833473205566 seconds for one epoch ---
--- 1.3263211250305176 seconds for one epoch ---
--- 0.3026766777038574 seconds for one epoch ---
--- 1.3291232585906982 seconds for one epoch ---
--- 0.30139684677124023 seconds for one epoch ---
--- 1.3173882961273193 seconds for one epoch ---
--- 0.29856252670288086 seconds for one epoch ---
=========================
[[1.        ]
 [0.52552843]
 [0.29728138]
 [0.        ]
 [0.        ]
 [0.8047799 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.4684901]
 [-0.6550081]
 [-0.5585255]
 [-0.       ]
 [ 0.       ]
 [-0.7868119]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.189963 ]
 [-0.       ]]
--- 0.26271772384643555 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3397.73046875, (1321.2693, 0.4543973, 2074.9983, 1.0085791)
   validation loss 907.3710327148438, (586.63196, 0.8759552, 318.85446, 1.0085791)
decoder loss ratio: 22727.140491, decoder SINDy loss  ratio: 0.688292
--- 0.3097553253173828 seconds for one epoch ---
--- 1.328768014907837 seconds for one epoch ---
--- 0.29725122451782227 seconds for one epoch ---
--- 1.3532617092132568 seconds for one epoch ---
--- 0.3024468421936035 seconds for one epoch ---
--- 1.3158621788024902 seconds for one epoch ---
--- 0.30454325675964355 seconds for one epoch ---
--- 1.3196768760681152 seconds for one epoch ---
--- 0.29868412017822266 seconds for one epoch ---
--- 1.3385205268859863 seconds for one epoch ---
--- 0.3040492534637451 seconds for one epoch ---
--- 1.3149867057800293 seconds for one epoch ---
--- 0.29625558853149414 seconds for one epoch ---
--- 1.3210279941558838 seconds for one epoch ---
--- 0.3002450466156006 seconds for one epoch ---
--- 1.3538751602172852 seconds for one epoch ---
--- 0.29538917541503906 seconds for one epoch ---
--- 1.3249080181121826 seconds for one epoch ---
--- 0.304534912109375 seconds for one epoch ---
--- 1.3073179721832275 seconds for one epoch ---
--- 0.30361270904541016 seconds for one epoch ---
--- 1.3214435577392578 seconds for one epoch ---
--- 0.5464737415313721 seconds for one epoch ---
--- 1.3369109630584717 seconds for one epoch ---
=========================
[[1.        ]
 [0.54556847]
 [0.2605197 ]
 [0.        ]
 [0.        ]
 [0.81142056]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.4977033 ]
 [-0.66308695]
 [-0.5401862 ]
 [ 0.        ]
 [ 0.        ]
 [-0.7911083 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.2118154 ]
 [ 0.        ]]
--- 0.29984474182128906 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2837.735107421875, (1530.1133, 0.25098416, 1306.3654, 1.0057354)
   validation loss 1046.5135498046875, (727.1862, 0.88325506, 317.4383, 1.0057354)
decoder loss ratio: 28172.456546, decoder SINDy loss  ratio: 0.685235
--- 0.26932859420776367 seconds for one epoch ---
--- 0.3308906555175781 seconds for one epoch ---
--- 1.3186814785003662 seconds for one epoch ---
--- 0.3158416748046875 seconds for one epoch ---
--- 1.3264555931091309 seconds for one epoch ---
--- 0.31508898735046387 seconds for one epoch ---
--- 1.3208799362182617 seconds for one epoch ---
--- 0.3363230228424072 seconds for one epoch ---
--- 1.3289356231689453 seconds for one epoch ---
--- 0.31288933753967285 seconds for one epoch ---
--- 1.369065523147583 seconds for one epoch ---
--- 0.3287947177886963 seconds for one epoch ---
--- 1.3706738948822021 seconds for one epoch ---
--- 0.3589644432067871 seconds for one epoch ---
--- 1.3414883613586426 seconds for one epoch ---
--- 0.32560062408447266 seconds for one epoch ---
--- 1.331749677658081 seconds for one epoch ---
--- 0.3398613929748535 seconds for one epoch ---
--- 1.3714041709899902 seconds for one epoch ---
--- 0.3266453742980957 seconds for one epoch ---
--- 1.3591351509094238 seconds for one epoch ---
--- 0.3008749485015869 seconds for one epoch ---
--- 1.3548226356506348 seconds for one epoch ---
--- 0.28965067863464355 seconds for one epoch ---
=========================
[[1.        ]
 [0.5444144 ]
 [0.25711802]
 [0.        ]
 [0.        ]
 [0.802879  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.5204377 ]
 [-0.6626203 ]
 [-0.53840894]
 [-0.        ]
 [-0.        ]
 [-0.7856028 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.227886  ]
 [ 0.        ]]
--- 0.2732987403869629 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2487.764892578125, (916.77057, 1.7335621, 1568.2559, 1.0049425)
   validation loss 1112.3314208984375, (743.2816, 0.8849342, 367.16, 1.0049425)
decoder loss ratio: 28796.020206, decoder SINDy loss  ratio: 0.792567
--- 0.3188612461090088 seconds for one epoch ---
--- 1.353633165359497 seconds for one epoch ---
--- 0.33954906463623047 seconds for one epoch ---
--- 1.3623831272125244 seconds for one epoch ---
--- 0.3260982036590576 seconds for one epoch ---
--- 1.3545219898223877 seconds for one epoch ---
--- 0.3050370216369629 seconds for one epoch ---
--- 1.3737750053405762 seconds for one epoch ---
--- 0.31557250022888184 seconds for one epoch ---
--- 1.340385913848877 seconds for one epoch ---
--- 0.332486629486084 seconds for one epoch ---
--- 1.3909854888916016 seconds for one epoch ---
--- 0.3259730339050293 seconds for one epoch ---
--- 1.334411382675171 seconds for one epoch ---
--- 0.3166513442993164 seconds for one epoch ---
--- 1.38350510597229 seconds for one epoch ---
--- 0.3179798126220703 seconds for one epoch ---
--- 1.343421220779419 seconds for one epoch ---
--- 0.3069601058959961 seconds for one epoch ---
--- 1.3352265357971191 seconds for one epoch ---
--- 0.30489301681518555 seconds for one epoch ---
--- 1.3591060638427734 seconds for one epoch ---
--- 0.3030514717102051 seconds for one epoch ---
--- 1.3543620109558105 seconds for one epoch ---
=========================
[[1.        ]
 [0.57805616]
 [0.2545029 ]
 [0.        ]
 [0.        ]
 [0.8139018 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.5539186 ]
 [-0.67632484]
 [-0.5370325 ]
 [ 0.        ]
 [ 0.        ]
 [-0.7927438 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.249083  ]
 [-0.        ]]
--- 0.29528117179870605 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1814.4417724609375, (980.1818, 0.34982666, 832.9019, 1.0082346)
   validation loss 1050.3594970703125, (735.6998, 1.0907611, 312.56067, 1.0082346)
decoder loss ratio: 28502.288610, decoder SINDy loss  ratio: 0.674706
--- 0.25751543045043945 seconds for one epoch ---
--- 0.30240607261657715 seconds for one epoch ---
--- 1.339156150817871 seconds for one epoch ---
--- 0.30081701278686523 seconds for one epoch ---
--- 1.3595020771026611 seconds for one epoch ---
--- 0.29790306091308594 seconds for one epoch ---
--- 1.3506414890289307 seconds for one epoch ---
--- 0.28604817390441895 seconds for one epoch ---
--- 1.3662307262420654 seconds for one epoch ---
--- 0.29990339279174805 seconds for one epoch ---
--- 1.356658697128296 seconds for one epoch ---
--- 0.30083608627319336 seconds for one epoch ---
--- 1.38616943359375 seconds for one epoch ---
--- 0.2965049743652344 seconds for one epoch ---
--- 1.376680612564087 seconds for one epoch ---
--- 0.2956063747406006 seconds for one epoch ---
--- 1.3584747314453125 seconds for one epoch ---
--- 0.29306554794311523 seconds for one epoch ---
--- 1.333369255065918 seconds for one epoch ---
--- 0.29506516456604004 seconds for one epoch ---
--- 1.3662805557250977 seconds for one epoch ---
--- 0.30217719078063965 seconds for one epoch ---
--- 1.3448278903961182 seconds for one epoch ---
--- 0.2841508388519287 seconds for one epoch ---
=========================
[[1.        ]
 [0.5782268 ]
 [0.24850497]
 [0.        ]
 [0.        ]
 [0.82073486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.5847635 ]
 [-0.67639494]
 [-0.5338394 ]
 [-0.        ]
 [-0.        ]
 [-0.79733425]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.269299  ]
 [-0.        ]]
--- 0.2589428424835205 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2495.921630859375, (1380.2891, 0.5025856, 1114.1216, 1.0086495)
   validation loss 983.48095703125, (673.5965, 0.9548156, 307.92093, 1.0086495)
decoder loss ratio: 26096.297693, decoder SINDy loss  ratio: 0.664691
--- 0.3081653118133545 seconds for one epoch ---
--- 1.3782029151916504 seconds for one epoch ---
--- 0.30437183380126953 seconds for one epoch ---
--- 1.3719909191131592 seconds for one epoch ---
--- 0.3035757541656494 seconds for one epoch ---
--- 1.380277395248413 seconds for one epoch ---
--- 0.30418968200683594 seconds for one epoch ---
--- 1.373560905456543 seconds for one epoch ---
--- 0.3035275936126709 seconds for one epoch ---
--- 1.368281602859497 seconds for one epoch ---
--- 0.31556081771850586 seconds for one epoch ---
--- 1.3790109157562256 seconds for one epoch ---
--- 0.3063216209411621 seconds for one epoch ---
--- 1.3813464641571045 seconds for one epoch ---
--- 0.314100980758667 seconds for one epoch ---
--- 1.3636384010314941 seconds for one epoch ---
--- 0.3158879280090332 seconds for one epoch ---
--- 1.3634066581726074 seconds for one epoch ---
--- 0.30588579177856445 seconds for one epoch ---
--- 1.4018921852111816 seconds for one epoch ---
--- 0.29710841178894043 seconds for one epoch ---
--- 1.381725788116455 seconds for one epoch ---
--- 0.2974128723144531 seconds for one epoch ---
--- 1.3931496143341064 seconds for one epoch ---
=========================
[[1.        ]
 [0.553959  ]
 [0.26006633]
 [0.        ]
 [0.        ]
 [0.80396986]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.6046543 ]
 [-0.666486  ]
 [-0.53995025]
 [ 0.        ]
 [-0.        ]
 [-0.7862952 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.2824254 ]
 [ 0.        ]]
--- 0.2999691963195801 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3235.681884765625, (1332.9893, 2.4275682, 1899.2592, 1.0059341)
   validation loss 1460.8245849609375, (1116.4426, 1.0260749, 342.3499, 1.0059341)
decoder loss ratio: 43252.925598, decoder SINDy loss  ratio: 0.739010
--- 0.28125596046447754 seconds for one epoch ---
--- 0.30986452102661133 seconds for one epoch ---
--- 1.3834733963012695 seconds for one epoch ---
--- 0.29580140113830566 seconds for one epoch ---
--- 1.3830857276916504 seconds for one epoch ---
--- 0.29387402534484863 seconds for one epoch ---
--- 1.3838443756103516 seconds for one epoch ---
--- 0.3097538948059082 seconds for one epoch ---
--- 1.389326572418213 seconds for one epoch ---
--- 0.3014490604400635 seconds for one epoch ---
--- 1.3721892833709717 seconds for one epoch ---
--- 0.31114649772644043 seconds for one epoch ---
--- 1.392587661743164 seconds for one epoch ---
--- 0.298112154006958 seconds for one epoch ---
--- 1.3980014324188232 seconds for one epoch ---
--- 0.30756640434265137 seconds for one epoch ---
--- 1.3886620998382568 seconds for one epoch ---
--- 0.2876904010772705 seconds for one epoch ---
--- 1.4210219383239746 seconds for one epoch ---
--- 0.30106258392333984 seconds for one epoch ---
--- 1.4021682739257812 seconds for one epoch ---
--- 0.304152250289917 seconds for one epoch ---
--- 1.3913731575012207 seconds for one epoch ---
--- 0.3140709400177002 seconds for one epoch ---
=========================
[[1.        ]
 [0.47489437]
 [0.2689212 ]
 [0.        ]
 [0.        ]
 [0.7985726 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.635589  ]
 [-0.6346847 ]
 [-0.54451233]
 [ 0.        ]
 [-0.        ]
 [-0.7828952 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.312702  ]
 [ 0.        ]]
--- 0.26410675048828125 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3372.0693359375, (1948.267, 1.2913916, 1421.5139, 0.99705344)
   validation loss 915.8994140625, (619.7258, 1.0648186, 294.1117, 0.99705344)
decoder loss ratio: 24009.254549, decoder SINDy loss  ratio: 0.634881
--- 0.3195230960845947 seconds for one epoch ---
--- 1.4073233604431152 seconds for one epoch ---
--- 0.3265957832336426 seconds for one epoch ---
--- 1.3913395404815674 seconds for one epoch ---
--- 0.3524916172027588 seconds for one epoch ---
--- 1.3930246829986572 seconds for one epoch ---
--- 0.31638336181640625 seconds for one epoch ---
--- 1.4239099025726318 seconds for one epoch ---
--- 0.32646608352661133 seconds for one epoch ---
--- 1.4192862510681152 seconds for one epoch ---
--- 0.3389256000518799 seconds for one epoch ---
--- 1.4326715469360352 seconds for one epoch ---
--- 0.33631420135498047 seconds for one epoch ---
--- 1.4120659828186035 seconds for one epoch ---
--- 0.34674644470214844 seconds for one epoch ---
--- 1.4317693710327148 seconds for one epoch ---
--- 0.31076860427856445 seconds for one epoch ---
--- 1.4329915046691895 seconds for one epoch ---
--- 0.30242347717285156 seconds for one epoch ---
--- 1.4009122848510742 seconds for one epoch ---
--- 0.2991926670074463 seconds for one epoch ---
--- 1.404414415359497 seconds for one epoch ---
--- 0.31328606605529785 seconds for one epoch ---
--- 1.4072136878967285 seconds for one epoch ---
=========================
[[1.        ]
 [0.4582856 ]
 [0.27389494]
 [0.        ]
 [0.        ]
 [0.78806496]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.65455   ]
 [-0.6279938 ]
 [-0.54703313]
 [-0.        ]
 [ 0.        ]
 [-0.7764657 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.3216825 ]
 [-0.        ]]
--- 0.30088329315185547 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2898.89013671875, (1151.4479, 1.3470697, 1745.1013, 0.993807)
   validation loss 872.5897827148438, (579.29407, 1.1132603, 291.18863, 0.993807)
decoder loss ratio: 22442.857869, decoder SINDy loss  ratio: 0.628572
--- 0.2581202983856201 seconds for one epoch ---
--- 0.3040962219238281 seconds for one epoch ---
--- 1.4258251190185547 seconds for one epoch ---
--- 0.3025202751159668 seconds for one epoch ---
--- 1.3893699645996094 seconds for one epoch ---
--- 0.3076186180114746 seconds for one epoch ---
--- 1.384441614151001 seconds for one epoch ---
--- 0.30515527725219727 seconds for one epoch ---
--- 1.4098939895629883 seconds for one epoch ---
--- 0.3100571632385254 seconds for one epoch ---
--- 1.4031760692596436 seconds for one epoch ---
--- 0.29543113708496094 seconds for one epoch ---
--- 1.3939363956451416 seconds for one epoch ---
--- 0.29340147972106934 seconds for one epoch ---
--- 1.4141387939453125 seconds for one epoch ---
--- 0.29655957221984863 seconds for one epoch ---
--- 1.4274401664733887 seconds for one epoch ---
--- 0.2993905544281006 seconds for one epoch ---
--- 1.4217824935913086 seconds for one epoch ---
--- 0.3018050193786621 seconds for one epoch ---
--- 1.4151906967163086 seconds for one epoch ---
--- 0.2913343906402588 seconds for one epoch ---
--- 1.4331135749816895 seconds for one epoch ---
--- 0.30390167236328125 seconds for one epoch ---
=========================
[[1.        ]
 [0.45218784]
 [0.2771172 ]
 [0.        ]
 [0.        ]
 [0.8044042 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.6905923]
 [-0.625529 ]
 [-0.548651 ]
 [-0.       ]
 [-0.       ]
 [-0.7865727]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.342127 ]
 [-0.       ]]
--- 0.2662186622619629 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3261.85400390625, (1206.1067, 1.4776845, 2053.2761, 0.9936488)
   validation loss 1061.464111328125, (767.63794, 1.1614124, 291.67105, 0.9936488)
decoder loss ratio: 29739.626452, decoder SINDy loss  ratio: 0.629613
--- 0.3218343257904053 seconds for one epoch ---
--- 1.4364957809448242 seconds for one epoch ---
--- 0.31812238693237305 seconds for one epoch ---
--- 1.4057321548461914 seconds for one epoch ---
--- 0.3307502269744873 seconds for one epoch ---
--- 1.4193546772003174 seconds for one epoch ---
--- 0.33881068229675293 seconds for one epoch ---
--- 1.4155628681182861 seconds for one epoch ---
--- 0.34565258026123047 seconds for one epoch ---
--- 1.464395523071289 seconds for one epoch ---
--- 0.3325204849243164 seconds for one epoch ---
--- 1.4175634384155273 seconds for one epoch ---
--- 0.31931042671203613 seconds for one epoch ---
--- 1.4124846458435059 seconds for one epoch ---
--- 0.30659031867980957 seconds for one epoch ---
--- 1.423738956451416 seconds for one epoch ---
--- 0.2951681613922119 seconds for one epoch ---
--- 1.413853406906128 seconds for one epoch ---
--- 0.29572367668151855 seconds for one epoch ---
--- 1.4075279235839844 seconds for one epoch ---
--- 0.2878119945526123 seconds for one epoch ---
--- 1.414830207824707 seconds for one epoch ---
--- 0.29549098014831543 seconds for one epoch ---
--- 1.4482395648956299 seconds for one epoch ---
=========================
[[1.        ]
 [0.48332855]
 [0.26319146]
 [0.        ]
 [0.        ]
 [0.7803565 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.687186  ]
 [-0.63807315]
 [-0.5415717 ]
 [ 0.        ]
 [ 0.        ]
 [-0.7718962 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3268056 ]
 [ 0.        ]]
--- 0.34034061431884766 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2441.762451171875, (1288.5337, 1.7302828, 1150.5035, 0.99491215)
   validation loss 997.0534057617188, (668.2799, 1.0705398, 326.708, 0.99491215)
decoder loss ratio: 25890.323791, decoder SINDy loss  ratio: 0.705245
--- 0.28217506408691406 seconds for one epoch ---
--- 0.33028149604797363 seconds for one epoch ---
--- 1.4325730800628662 seconds for one epoch ---
--- 0.3351938724517822 seconds for one epoch ---
--- 1.444429636001587 seconds for one epoch ---
--- 0.3144800662994385 seconds for one epoch ---
--- 1.4354844093322754 seconds for one epoch ---
--- 0.3293743133544922 seconds for one epoch ---
--- 1.4443519115447998 seconds for one epoch ---
--- 0.3213486671447754 seconds for one epoch ---
--- 1.4509437084197998 seconds for one epoch ---
--- 0.31008291244506836 seconds for one epoch ---
--- 1.4457809925079346 seconds for one epoch ---
--- 0.3165171146392822 seconds for one epoch ---
--- 1.4153857231140137 seconds for one epoch ---
--- 0.29984116554260254 seconds for one epoch ---
--- 1.4189653396606445 seconds for one epoch ---
--- 0.2923121452331543 seconds for one epoch ---
--- 1.4078779220581055 seconds for one epoch ---
--- 0.28839921951293945 seconds for one epoch ---
--- 1.4066569805145264 seconds for one epoch ---
--- 0.29764652252197266 seconds for one epoch ---
--- 1.443993091583252 seconds for one epoch ---
--- 0.3027491569519043 seconds for one epoch ---
=========================
[[1.        ]
 [0.54790944]
 [0.251234  ]
 [0.        ]
 [0.        ]
 [0.78318155]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.707994  ]
 [-0.6640346 ]
 [-0.53529865]
 [ 0.        ]
 [ 0.        ]
 [-0.7735572 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.3337126 ]
 [ 0.        ]]
--- 0.28195905685424805 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3576.4287109375, (1383.9457, 1.5169004, 2189.9648, 1.001362)
   validation loss 977.6849365234375, (615.23804, 1.1407175, 360.30484, 1.001362)
decoder loss ratio: 23835.389658, decoder SINDy loss  ratio: 0.777769
--- 0.2915916442871094 seconds for one epoch ---
--- 1.4785034656524658 seconds for one epoch ---
--- 0.31293320655822754 seconds for one epoch ---
--- 1.4318499565124512 seconds for one epoch ---
--- 0.3100731372833252 seconds for one epoch ---
--- 1.4751121997833252 seconds for one epoch ---
--- 0.3052022457122803 seconds for one epoch ---
--- 1.4582195281982422 seconds for one epoch ---
--- 0.3079559803009033 seconds for one epoch ---
--- 1.4481818675994873 seconds for one epoch ---
--- 0.30242323875427246 seconds for one epoch ---
--- 1.454671859741211 seconds for one epoch ---
--- 0.3038015365600586 seconds for one epoch ---
--- 1.4512512683868408 seconds for one epoch ---
--- 0.2981705665588379 seconds for one epoch ---
--- 1.4491875171661377 seconds for one epoch ---
--- 0.3021857738494873 seconds for one epoch ---
--- 1.4547481536865234 seconds for one epoch ---
--- 0.3134608268737793 seconds for one epoch ---
--- 1.4326057434082031 seconds for one epoch ---
--- 0.28644490242004395 seconds for one epoch ---
--- 1.4505136013031006 seconds for one epoch ---
--- 0.3017466068267822 seconds for one epoch ---
--- 1.4355990886688232 seconds for one epoch ---
=========================
[[1.        ]
 [0.5779638 ]
 [0.24552429]
 [0.        ]
 [0.        ]
 [0.78567153]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.724863  ]
 [-0.67628646]
 [-0.5322336 ]
 [-0.        ]
 [-0.        ]
 [-0.7750344 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.3360767 ]
 [-0.        ]]
--- 0.3013436794281006 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3703.163818359375, (1545.7966, 0.53039795, 2155.8333, 1.0036075)
   validation loss 955.8803100585938, (642.77673, 1.1388983, 310.96106, 1.0036075)
decoder loss ratio: 24902.286561, decoder SINDy loss  ratio: 0.671253
THRESHOLDING: 5 active coefficients
--- 1.46051025390625 seconds for one epoch ---
--- 0.3087935447692871 seconds for one epoch ---
--- 1.453256607055664 seconds for one epoch ---
--- 0.3038778305053711 seconds for one epoch ---
--- 1.4481439590454102 seconds for one epoch ---
--- 0.30825281143188477 seconds for one epoch ---
--- 1.4909837245941162 seconds for one epoch ---
--- 0.30775952339172363 seconds for one epoch ---
--- 1.4229581356048584 seconds for one epoch ---
--- 0.3176710605621338 seconds for one epoch ---
--- 1.4210519790649414 seconds for one epoch ---
--- 0.2712852954864502 seconds for one epoch ---
--- 1.4712259769439697 seconds for one epoch ---
--- 0.3114438056945801 seconds for one epoch ---
--- 1.4813101291656494 seconds for one epoch ---
--- 0.30728936195373535 seconds for one epoch ---
--- 1.4356622695922852 seconds for one epoch ---
--- 0.2964320182800293 seconds for one epoch ---
--- 1.455453634262085 seconds for one epoch ---
--- 0.3160843849182129 seconds for one epoch ---
--- 1.4628019332885742 seconds for one epoch ---
--- 0.3104372024536133 seconds for one epoch ---
--- 1.4979164600372314 seconds for one epoch ---
--- 0.31774282455444336 seconds for one epoch ---
=========================
[[1.        ]
 [0.62940794]
 [0.2554301 ]
 [0.        ]
 [0.        ]
 [0.7632639 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.7379591 ]
 [-0.6978718 ]
 [-0.53752184]
 [ 0.        ]
 [ 0.        ]
 [-0.7621575 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.343394  ]
 [-0.        ]]
--- 0.25307679176330566 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5055.60888671875, (2261.695, 2.255039, 2790.6467, 1.0123278)
   validation loss 838.8575439453125, (506.8009, 1.179544, 329.86478, 1.0123278)
decoder loss ratio: 19634.346840, decoder SINDy loss  ratio: 0.712060
--- 0.30429601669311523 seconds for one epoch ---
--- 1.4215621948242188 seconds for one epoch ---
--- 0.3041548728942871 seconds for one epoch ---
--- 1.4311363697052002 seconds for one epoch ---
--- 0.29793667793273926 seconds for one epoch ---
--- 1.4569833278656006 seconds for one epoch ---
--- 0.30210065841674805 seconds for one epoch ---
--- 1.461592197418213 seconds for one epoch ---
--- 0.2947995662689209 seconds for one epoch ---
--- 1.453214168548584 seconds for one epoch ---
--- 0.2974405288696289 seconds for one epoch ---
--- 1.4520628452301025 seconds for one epoch ---
--- 0.3060905933380127 seconds for one epoch ---
--- 1.4592335224151611 seconds for one epoch ---
--- 0.31255173683166504 seconds for one epoch ---
--- 1.4842867851257324 seconds for one epoch ---
--- 0.2971329689025879 seconds for one epoch ---
--- 1.4749252796173096 seconds for one epoch ---
--- 0.3036990165710449 seconds for one epoch ---
--- 1.4552195072174072 seconds for one epoch ---
--- 0.30352330207824707 seconds for one epoch ---
--- 1.448667049407959 seconds for one epoch ---
--- 0.30980515480041504 seconds for one epoch ---
--- 1.452096700668335 seconds for one epoch ---
=========================
[[1.        ]
 [0.6586142 ]
 [0.26089057]
 [0.        ]
 [0.        ]
 [0.756966  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.762099 ]
 [-0.7106525]
 [-0.5403794]
 [-0.       ]
 [-0.       ]
 [-0.7586931]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.3635654]
 [ 0.       ]]
--- 0.28992295265197754 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3222.513671875, (1317.5023, 3.5037172, 1900.4886, 1.0189699)
   validation loss 1061.4632568359375, (694.6818, 1.2596917, 364.50278, 1.0189699)
decoder loss ratio: 26913.179872, decoder SINDy loss  ratio: 0.786831
--- 0.254256010055542 seconds for one epoch ---
--- 0.29815006256103516 seconds for one epoch ---
--- 1.437612533569336 seconds for one epoch ---
--- 0.3056516647338867 seconds for one epoch ---
--- 1.4960167407989502 seconds for one epoch ---
--- 0.2911224365234375 seconds for one epoch ---
--- 1.49692702293396 seconds for one epoch ---
--- 0.29901957511901855 seconds for one epoch ---
--- 1.4667425155639648 seconds for one epoch ---
--- 0.290071964263916 seconds for one epoch ---
--- 1.4688968658447266 seconds for one epoch ---
--- 0.29401588439941406 seconds for one epoch ---
--- 1.464170217514038 seconds for one epoch ---
--- 0.2935624122619629 seconds for one epoch ---
--- 1.480196237564087 seconds for one epoch ---
--- 0.30038905143737793 seconds for one epoch ---
--- 1.4920358657836914 seconds for one epoch ---
--- 0.30298280715942383 seconds for one epoch ---
--- 1.4648728370666504 seconds for one epoch ---
--- 0.3001523017883301 seconds for one epoch ---
--- 1.45784330368042 seconds for one epoch ---
--- 0.3059842586517334 seconds for one epoch ---
--- 1.4176146984100342 seconds for one epoch ---
--- 0.2961583137512207 seconds for one epoch ---
=========================
[[1.        ]
 [0.68352747]
 [0.27215195]
 [0.        ]
 [0.        ]
 [0.74230266]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.7723773 ]
 [-0.7219755 ]
 [-0.5461531 ]
 [-0.        ]
 [-0.        ]
 [-0.75085443]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.3701415 ]
 [ 0.        ]]
--- 0.2858293056488037 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1835.090087890625, (801.9272, 2.1473773, 1029.9956, 1.0198499)
   validation loss 1122.4727783203125, (804.5173, 1.1225121, 315.81308, 1.0198499)
decoder loss ratio: 31168.395857, decoder SINDy loss  ratio: 0.681727
--- 0.3020646572113037 seconds for one epoch ---
--- 1.5007848739624023 seconds for one epoch ---
--- 0.295149564743042 seconds for one epoch ---
--- 1.4958429336547852 seconds for one epoch ---
--- 0.3017599582672119 seconds for one epoch ---
--- 1.5226945877075195 seconds for one epoch ---
--- 0.30164122581481934 seconds for one epoch ---
--- 1.4986634254455566 seconds for one epoch ---
--- 0.2984426021575928 seconds for one epoch ---
--- 1.5114672183990479 seconds for one epoch ---
--- 0.3016681671142578 seconds for one epoch ---
--- 1.514946460723877 seconds for one epoch ---
--- 0.29874110221862793 seconds for one epoch ---
--- 1.502960443496704 seconds for one epoch ---
--- 0.30290889739990234 seconds for one epoch ---
--- 1.5012247562408447 seconds for one epoch ---
--- 0.29404115676879883 seconds for one epoch ---
--- 1.531151294708252 seconds for one epoch ---
--- 0.2994379997253418 seconds for one epoch ---
--- 1.4614663124084473 seconds for one epoch ---
--- 0.28709936141967773 seconds for one epoch ---
--- 1.4815773963928223 seconds for one epoch ---
--- 0.2914254665374756 seconds for one epoch ---
--- 1.5233323574066162 seconds for one epoch ---
=========================
[[1.        ]
 [0.62683177]
 [0.25457045]
 [0.        ]
 [0.        ]
 [0.74943334]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.7947435 ]
 [-0.6967659 ]
 [-0.53706825]
 [ 0.        ]
 [-0.        ]
 [-0.75462794]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3819976 ]
 [-0.        ]]
--- 0.2954986095428467 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5117.86328125, (1419.8934, 4.7595625, 3692.2, 1.0101023)
   validation loss 732.1451416015625, (430.7467, 1.399531, 298.98877, 1.0101023)
decoder loss ratio: 16687.875126, decoder SINDy loss  ratio: 0.645409
--- 0.26992321014404297 seconds for one epoch ---
--- 0.31758832931518555 seconds for one epoch ---
--- 1.5067031383514404 seconds for one epoch ---
--- 0.30642151832580566 seconds for one epoch ---
--- 1.502305269241333 seconds for one epoch ---
--- 0.3002207279205322 seconds for one epoch ---
--- 1.4950904846191406 seconds for one epoch ---
--- 0.3014824390411377 seconds for one epoch ---
--- 1.5039446353912354 seconds for one epoch ---
--- 0.3005647659301758 seconds for one epoch ---
--- 1.526090383529663 seconds for one epoch ---
--- 0.2985267639160156 seconds for one epoch ---
--- 1.4891364574432373 seconds for one epoch ---
--- 0.3014559745788574 seconds for one epoch ---
--- 1.514073371887207 seconds for one epoch ---
--- 0.295363187789917 seconds for one epoch ---
--- 1.5290398597717285 seconds for one epoch ---
--- 0.2975044250488281 seconds for one epoch ---
--- 1.4864351749420166 seconds for one epoch ---
--- 0.2898385524749756 seconds for one epoch ---
--- 1.4773240089416504 seconds for one epoch ---
--- 0.294191837310791 seconds for one epoch ---
--- 1.491074562072754 seconds for one epoch ---
--- 0.3009457588195801 seconds for one epoch ---
=========================
[[1.        ]
 [0.5875768 ]
 [0.23313129]
 [0.        ]
 [0.        ]
 [0.74271685]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8158445 ]
 [-0.6802511 ]
 [-0.5254106 ]
 [-0.        ]
 [ 0.        ]
 [-0.75107217]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.4021273 ]
 [-0.        ]]
--- 0.26238346099853516 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3288.92822265625, (1645.7291, 0.76047814, 1641.4415, 0.99715215)
   validation loss 961.646240234375, (641.4277, 1.2904955, 317.93097, 0.99715215)
decoder loss ratio: 24850.021633, decoder SINDy loss  ratio: 0.686299
--- 0.32511401176452637 seconds for one epoch ---
--- 1.5007517337799072 seconds for one epoch ---
--- 0.33222484588623047 seconds for one epoch ---
--- 1.4932971000671387 seconds for one epoch ---
--- 0.3271145820617676 seconds for one epoch ---
--- 1.5472099781036377 seconds for one epoch ---
--- 0.3102536201477051 seconds for one epoch ---
--- 1.5276117324829102 seconds for one epoch ---
--- 0.30130553245544434 seconds for one epoch ---
--- 1.5172641277313232 seconds for one epoch ---
--- 0.29354000091552734 seconds for one epoch ---
--- 1.5075526237487793 seconds for one epoch ---
--- 0.28386473655700684 seconds for one epoch ---
--- 1.5166614055633545 seconds for one epoch ---
--- 0.2983229160308838 seconds for one epoch ---
--- 1.5546772480010986 seconds for one epoch ---
--- 0.2931184768676758 seconds for one epoch ---
--- 1.4839541912078857 seconds for one epoch ---
--- 0.2963550090789795 seconds for one epoch ---
--- 1.5033776760101318 seconds for one epoch ---
--- 0.29755353927612305 seconds for one epoch ---
--- 1.5787642002105713 seconds for one epoch ---
--- 0.31662750244140625 seconds for one epoch ---
--- 1.520059585571289 seconds for one epoch ---
=========================
[[1.        ]
 [0.5483324 ]
 [0.2376499 ]
 [0.        ]
 [0.        ]
 [0.76509565]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8448565 ]
 [-0.66420585]
 [-0.52792656]
 [ 0.        ]
 [-0.        ]
 [-0.76317686]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.4177713 ]
 [ 0.        ]]
--- 0.28864359855651855 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3968.78515625, (1467.8071, 3.2360766, 2496.7449, 0.9970889)
   validation loss 1350.50537109375, (1034.6539, 1.1548312, 313.69962, 0.9970889)
decoder loss ratio: 40084.289512, decoder SINDy loss  ratio: 0.677165
--- 0.28233957290649414 seconds for one epoch ---
--- 0.29238343238830566 seconds for one epoch ---
--- 1.5262999534606934 seconds for one epoch ---
--- 0.2974214553833008 seconds for one epoch ---
--- 1.5252888202667236 seconds for one epoch ---
--- 0.3043360710144043 seconds for one epoch ---
--- 1.5239336490631104 seconds for one epoch ---
--- 0.30535316467285156 seconds for one epoch ---
--- 1.5044877529144287 seconds for one epoch ---
--- 0.30011463165283203 seconds for one epoch ---
--- 1.4998164176940918 seconds for one epoch ---
--- 0.2986922264099121 seconds for one epoch ---
--- 1.532580852508545 seconds for one epoch ---
--- 0.3027331829071045 seconds for one epoch ---
--- 1.5407602787017822 seconds for one epoch ---
--- 0.3020436763763428 seconds for one epoch ---
--- 1.5126454830169678 seconds for one epoch ---
--- 0.2991597652435303 seconds for one epoch ---
--- 1.494936466217041 seconds for one epoch ---
--- 0.2912614345550537 seconds for one epoch ---
--- 1.4946660995483398 seconds for one epoch ---
--- 0.29387497901916504 seconds for one epoch ---
--- 1.5042481422424316 seconds for one epoch ---
--- 0.3092789649963379 seconds for one epoch ---
=========================
[[1.        ]
 [0.5164776 ]
 [0.22444762]
 [0.        ]
 [0.        ]
 [0.7536426 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.852372  ]
 [-0.65137196]
 [-0.52047837]
 [-0.        ]
 [ 0.        ]
 [-0.75688964]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.4135966 ]
 [ 0.        ]]
--- 0.2621641159057617 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3678.996826171875, (1825.7043, 1.9040687, 1850.3981, 0.99054205)
   validation loss 876.122802734375, (555.5102, 1.3415892, 318.28046, 0.99054205)
decoder loss ratio: 21521.429280, decoder SINDy loss  ratio: 0.687053
--- 0.29469895362854004 seconds for one epoch ---
--- 1.5318756103515625 seconds for one epoch ---
--- 0.29791998863220215 seconds for one epoch ---
--- 1.537492036819458 seconds for one epoch ---
--- 0.2955207824707031 seconds for one epoch ---
--- 1.5176680088043213 seconds for one epoch ---
--- 0.2930722236633301 seconds for one epoch ---
--- 1.5406429767608643 seconds for one epoch ---
--- 0.29947614669799805 seconds for one epoch ---
--- 1.5156598091125488 seconds for one epoch ---
--- 0.29117846488952637 seconds for one epoch ---
--- 1.5282809734344482 seconds for one epoch ---
--- 0.2888164520263672 seconds for one epoch ---
--- 1.5486681461334229 seconds for one epoch ---
--- 0.30243515968322754 seconds for one epoch ---
--- 1.5405735969543457 seconds for one epoch ---
--- 0.3113863468170166 seconds for one epoch ---
--- 1.4657509326934814 seconds for one epoch ---
--- 0.29340195655822754 seconds for one epoch ---
--- 1.483001470565796 seconds for one epoch ---
--- 0.2997243404388428 seconds for one epoch ---
--- 1.5197160243988037 seconds for one epoch ---
--- 0.30156564712524414 seconds for one epoch ---
--- 1.5217747688293457 seconds for one epoch ---
=========================
[[1.        ]
 [0.56945646]
 [0.22893484]
 [0.        ]
 [0.        ]
 [0.7296516 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8578358 ]
 [-0.67279875]
 [-0.52304333]
 [ 0.        ]
 [ 0.        ]
 [-0.7443238 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.4164968 ]
 [-0.        ]]
--- 0.2910442352294922 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4024.59619140625, (1498.321, 2.444594, 2522.8342, 0.99637794)
   validation loss 912.1311645507812, (588.10986, 1.2424701, 321.78238, 0.99637794)
decoder loss ratio: 22784.397107, decoder SINDy loss  ratio: 0.694613
--- 0.257617712020874 seconds for one epoch ---
--- 0.29738545417785645 seconds for one epoch ---
--- 1.5354416370391846 seconds for one epoch ---
--- 0.30148816108703613 seconds for one epoch ---
--- 1.5490243434906006 seconds for one epoch ---
--- 0.3039555549621582 seconds for one epoch ---
--- 1.5238010883331299 seconds for one epoch ---
--- 0.30602431297302246 seconds for one epoch ---
--- 1.5328776836395264 seconds for one epoch ---
--- 0.29903674125671387 seconds for one epoch ---
--- 1.5490000247955322 seconds for one epoch ---
--- 0.30858445167541504 seconds for one epoch ---
--- 1.5301949977874756 seconds for one epoch ---
--- 0.31362414360046387 seconds for one epoch ---
--- 1.5633394718170166 seconds for one epoch ---
--- 0.28691935539245605 seconds for one epoch ---
--- 1.5399019718170166 seconds for one epoch ---
--- 0.3008084297180176 seconds for one epoch ---
--- 1.5075960159301758 seconds for one epoch ---
--- 0.29033613204956055 seconds for one epoch ---
--- 1.5150909423828125 seconds for one epoch ---
--- 0.2887418270111084 seconds for one epoch ---
--- 1.558178186416626 seconds for one epoch ---
--- 0.2994093894958496 seconds for one epoch ---
=========================
[[1.        ]
 [0.55841845]
 [0.23662376]
 [0.        ]
 [0.        ]
 [0.7604362 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8912525]
 [-0.6682976]
 [-0.5273581]
 [ 0.       ]
 [-0.       ]
 [-0.7605937]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.433263 ]
 [-0.       ]]
--- 0.25986456871032715 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3170.378662109375, (1278.2723, 3.492923, 1887.6135, 0.9996629)
   validation loss 900.505859375, (582.7861, 1.4350892, 315.28503, 0.9996629)
decoder loss ratio: 22578.144182, decoder SINDy loss  ratio: 0.680587
--- 0.2983973026275635 seconds for one epoch ---
--- 1.5536212921142578 seconds for one epoch ---
--- 0.2879638671875 seconds for one epoch ---
--- 1.5329031944274902 seconds for one epoch ---
--- 0.28199219703674316 seconds for one epoch ---
--- 1.553091287612915 seconds for one epoch ---
--- 0.29748010635375977 seconds for one epoch ---
--- 1.5313596725463867 seconds for one epoch ---
--- 0.30159640312194824 seconds for one epoch ---
--- 1.5557918548583984 seconds for one epoch ---
--- 0.30614256858825684 seconds for one epoch ---
--- 1.5598342418670654 seconds for one epoch ---
--- 0.3041388988494873 seconds for one epoch ---
--- 1.5574665069580078 seconds for one epoch ---
--- 0.30168843269348145 seconds for one epoch ---
--- 1.512634515762329 seconds for one epoch ---
--- 0.29790306091308594 seconds for one epoch ---
--- 1.4957048892974854 seconds for one epoch ---
--- 0.2970457077026367 seconds for one epoch ---
--- 1.524207353591919 seconds for one epoch ---
--- 0.30875158309936523 seconds for one epoch ---
--- 1.5379736423492432 seconds for one epoch ---
--- 0.3097403049468994 seconds for one epoch ---
--- 1.5912482738494873 seconds for one epoch ---
=========================
[[1.        ]
 [0.4971494 ]
 [0.22689429]
 [0.        ]
 [0.        ]
 [0.743232  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9028425]
 [-0.6436183]
 [-0.5218814]
 [-0.       ]
 [ 0.       ]
 [-0.7513425]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.4400125]
 [ 0.       ]]
--- 0.3008260726928711 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3030.9765625, (1342.2466, 5.555795, 1682.1879, 0.9864047)
   validation loss 758.9078369140625, (457.01147, 1.3831825, 299.5268, 0.9864047)
decoder loss ratio: 17705.417933, decoder SINDy loss  ratio: 0.646571
--- 0.2632133960723877 seconds for one epoch ---
--- 0.30858945846557617 seconds for one epoch ---
--- 1.569110631942749 seconds for one epoch ---
--- 0.31171536445617676 seconds for one epoch ---
--- 1.5940351486206055 seconds for one epoch ---
--- 0.2931942939758301 seconds for one epoch ---
--- 1.5972275733947754 seconds for one epoch ---
--- 0.2937450408935547 seconds for one epoch ---
--- 1.5710387229919434 seconds for one epoch ---
--- 0.2941298484802246 seconds for one epoch ---
--- 1.5804443359375 seconds for one epoch ---
--- 0.3004889488220215 seconds for one epoch ---
--- 1.5886273384094238 seconds for one epoch ---
--- 0.3174452781677246 seconds for one epoch ---
--- 1.6160888671875 seconds for one epoch ---
--- 0.2942349910736084 seconds for one epoch ---
--- 1.5388619899749756 seconds for one epoch ---
--- 0.303922176361084 seconds for one epoch ---
--- 1.5621421337127686 seconds for one epoch ---
--- 0.29033374786376953 seconds for one epoch ---
--- 1.5920634269714355 seconds for one epoch ---
--- 0.3042128086090088 seconds for one epoch ---
--- 1.5985262393951416 seconds for one epoch ---
--- 0.3006937503814697 seconds for one epoch ---
=========================
[[1.        ]
 [0.5618229 ]
 [0.22040239]
 [0.        ]
 [0.        ]
 [0.727605  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.909043 ]
 [-0.6696834]
 [-0.5181345]
 [-0.       ]
 [-0.       ]
 [-0.7432857]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.4397473]
 [ 0.       ]]
--- 0.26514482498168945 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4373.39453125, (1328.171, 4.7026258, 3039.5276, 0.9929808)
   validation loss 1136.7852783203125, (804.40295, 1.4048828, 329.9845, 0.9929808)
decoder loss ratio: 31163.966947, decoder SINDy loss  ratio: 0.712318
--- 0.2933487892150879 seconds for one epoch ---
--- 1.5828123092651367 seconds for one epoch ---
--- 0.30425453186035156 seconds for one epoch ---
--- 1.5721876621246338 seconds for one epoch ---
--- 0.30220675468444824 seconds for one epoch ---
--- 1.5579633712768555 seconds for one epoch ---
--- 0.29422688484191895 seconds for one epoch ---
--- 1.559981107711792 seconds for one epoch ---
--- 0.3092062473297119 seconds for one epoch ---
--- 1.5498533248901367 seconds for one epoch ---
--- 0.2956819534301758 seconds for one epoch ---
--- 1.5802943706512451 seconds for one epoch ---
--- 0.2873687744140625 seconds for one epoch ---
--- 1.5572571754455566 seconds for one epoch ---
--- 0.29419732093811035 seconds for one epoch ---
--- 1.5166559219360352 seconds for one epoch ---
--- 0.31248950958251953 seconds for one epoch ---
--- 1.5327093601226807 seconds for one epoch ---
--- 0.30222582817077637 seconds for one epoch ---
--- 1.5927584171295166 seconds for one epoch ---
--- 0.29329681396484375 seconds for one epoch ---
--- 1.5798931121826172 seconds for one epoch ---
--- 0.30355238914489746 seconds for one epoch ---
--- 1.6012523174285889 seconds for one epoch ---
=========================
[[1.        ]
 [0.569745  ]
 [0.20435715]
 [0.        ]
 [0.        ]
 [0.74592745]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9341211 ]
 [-0.67291653]
 [-0.5085189 ]
 [ 0.        ]
 [-0.        ]
 [-0.7527641 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.44806   ]
 [-0.        ]]
--- 0.3150510787963867 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2145.97802734375, (1051.2664, 1.5172225, 1092.2028, 0.99178904)
   validation loss 904.6984252929688, (575.0666, 1.3303188, 327.30975, 0.99178904)
decoder loss ratio: 22279.078031, decoder SINDy loss  ratio: 0.706544
--- 0.2790656089782715 seconds for one epoch ---
--- 0.32570600509643555 seconds for one epoch ---
--- 1.5887551307678223 seconds for one epoch ---
--- 0.3087925910949707 seconds for one epoch ---
--- 1.6040353775024414 seconds for one epoch ---
--- 0.29628610610961914 seconds for one epoch ---
--- 1.596928358078003 seconds for one epoch ---
--- 0.2876431941986084 seconds for one epoch ---
--- 1.5944476127624512 seconds for one epoch ---
--- 0.2967398166656494 seconds for one epoch ---
--- 1.6188061237335205 seconds for one epoch ---
--- 0.307666540145874 seconds for one epoch ---
--- 1.6082282066345215 seconds for one epoch ---
--- 0.29801130294799805 seconds for one epoch ---
--- 1.5744378566741943 seconds for one epoch ---
--- 0.28874707221984863 seconds for one epoch ---
--- 1.5698528289794922 seconds for one epoch ---
--- 0.2913949489593506 seconds for one epoch ---
--- 1.6303348541259766 seconds for one epoch ---
--- 0.30355238914489746 seconds for one epoch ---
--- 1.618955373764038 seconds for one epoch ---
--- 0.3069329261779785 seconds for one epoch ---
--- 1.6304967403411865 seconds for one epoch ---
--- 0.29100799560546875 seconds for one epoch ---
=========================
[[1.       ]
 [0.5825088]
 [0.2141239]
 [0.       ]
 [0.       ]
 [0.718964 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.9392734]
 [-0.6781578]
 [-0.5144349]
 [ 0.       ]
 [-0.       ]
 [-0.7389549]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.452299 ]
 [-0.       ]]
--- 0.2641019821166992 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1920.92822265625, (1058.3744, 0.9698851, 860.5914, 0.9926381)
   validation loss 858.0745849609375, (530.28467, 1.4908113, 325.30652, 0.9926381)
decoder loss ratio: 20544.148652, decoder SINDy loss  ratio: 0.702220
--- 0.299893856048584 seconds for one epoch ---
--- 1.6094415187835693 seconds for one epoch ---
--- 0.29188060760498047 seconds for one epoch ---
--- 1.6117744445800781 seconds for one epoch ---
--- 0.3072202205657959 seconds for one epoch ---
--- 1.579789400100708 seconds for one epoch ---
--- 0.31430578231811523 seconds for one epoch ---
--- 1.5963809490203857 seconds for one epoch ---
--- 0.30730700492858887 seconds for one epoch ---
--- 1.610356330871582 seconds for one epoch ---
--- 0.3119790554046631 seconds for one epoch ---
--- 1.5561833381652832 seconds for one epoch ---
--- 0.3174586296081543 seconds for one epoch ---
--- 1.5627081394195557 seconds for one epoch ---
--- 0.3002619743347168 seconds for one epoch ---
--- 1.553079605102539 seconds for one epoch ---
--- 0.30036354064941406 seconds for one epoch ---
--- 1.6163184642791748 seconds for one epoch ---
--- 0.32602906227111816 seconds for one epoch ---
--- 1.6396126747131348 seconds for one epoch ---
--- 0.34319090843200684 seconds for one epoch ---
--- 1.6776602268218994 seconds for one epoch ---
--- 0.33109593391418457 seconds for one epoch ---
--- 1.629655361175537 seconds for one epoch ---
=========================
[[1.        ]
 [0.5710334 ]
 [0.23224846]
 [0.        ]
 [0.        ]
 [0.7226685 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9651225 ]
 [-0.67344373]
 [-0.5249152 ]
 [-0.        ]
 [ 0.        ]
 [-0.7408012 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.474198  ]
 [ 0.        ]]
--- 0.32235240936279297 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3588.239013671875, (1370.6385, 1.5362043, 2215.0696, 0.99458915)
   validation loss 918.3499145507812, (597.80347, 1.3556408, 318.1962, 0.99458915)
decoder loss ratio: 23159.944136, decoder SINDy loss  ratio: 0.686871
--- 0.28229594230651855 seconds for one epoch ---
--- 0.30697035789489746 seconds for one epoch ---
--- 1.6314802169799805 seconds for one epoch ---
--- 0.3160390853881836 seconds for one epoch ---
--- 1.6484112739562988 seconds for one epoch ---
--- 0.30892086029052734 seconds for one epoch ---
--- 1.6247730255126953 seconds for one epoch ---
--- 0.2991006374359131 seconds for one epoch ---
--- 1.6447727680206299 seconds for one epoch ---
--- 0.2983827590942383 seconds for one epoch ---
--- 1.6169569492340088 seconds for one epoch ---
--- 0.30320000648498535 seconds for one epoch ---
--- 1.6041998863220215 seconds for one epoch ---
--- 0.3006439208984375 seconds for one epoch ---
--- 1.5832595825195312 seconds for one epoch ---
--- 0.30200982093811035 seconds for one epoch ---
--- 1.6303064823150635 seconds for one epoch ---
--- 0.2969090938568115 seconds for one epoch ---
--- 1.6505892276763916 seconds for one epoch ---
--- 0.3063619136810303 seconds for one epoch ---
--- 1.6440963745117188 seconds for one epoch ---
--- 0.30133914947509766 seconds for one epoch ---
--- 1.6181375980377197 seconds for one epoch ---
--- 0.29077935218811035 seconds for one epoch ---
=========================
[[1.        ]
 [0.6161481 ]
 [0.20946681]
 [0.        ]
 [0.        ]
 [0.722271  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.974697  ]
 [-0.6922114 ]
 [-0.51163924]
 [ 0.        ]
 [-0.        ]
 [-0.7406026 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.4713116 ]
 [ 0.        ]]
--- 0.26041388511657715 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2622.46875, (824.64874, 0.8605275, 1795.9634, 0.9961466)
   validation loss 845.3416137695312, (522.91284, 1.7196174, 319.713, 0.9961466)
decoder loss ratio: 20258.551308, decoder SINDy loss  ratio: 0.690146
--- 0.30155372619628906 seconds for one epoch ---
--- 1.6474204063415527 seconds for one epoch ---
--- 0.30810546875 seconds for one epoch ---
--- 1.6405003070831299 seconds for one epoch ---
--- 0.3018767833709717 seconds for one epoch ---
--- 1.6459927558898926 seconds for one epoch ---
--- 0.30377197265625 seconds for one epoch ---
--- 1.6642181873321533 seconds for one epoch ---
--- 0.3051645755767822 seconds for one epoch ---
--- 1.6131155490875244 seconds for one epoch ---
--- 0.3036808967590332 seconds for one epoch ---
--- 1.6056909561157227 seconds for one epoch ---
--- 0.29236745834350586 seconds for one epoch ---
--- 1.6105506420135498 seconds for one epoch ---
--- 0.3018171787261963 seconds for one epoch ---
--- 1.6060798168182373 seconds for one epoch ---
--- 0.3039419651031494 seconds for one epoch ---
--- 1.6570050716400146 seconds for one epoch ---
--- 0.3202826976776123 seconds for one epoch ---
--- 1.6173336505889893 seconds for one epoch ---
--- 0.33954858779907227 seconds for one epoch ---
--- 1.6550545692443848 seconds for one epoch ---
--- 0.345503568649292 seconds for one epoch ---
--- 1.6773536205291748 seconds for one epoch ---
=========================
[[1.        ]
 [0.642146  ]
 [0.22824568]
 [0.        ]
 [0.        ]
 [0.7051357 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9796565 ]
 [-0.7033888 ]
 [-0.522652  ]
 [-0.        ]
 [ 0.        ]
 [-0.73218966]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.46953   ]
 [-0.        ]]
--- 0.30173182487487793 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1815.449951171875, (854.3406, 1.1240274, 958.98193, 1.0033908)
   validation loss 1185.29296875, (824.36884, 1.7996956, 358.12097, 1.0033908)
decoder loss ratio: 31937.479853, decoder SINDy loss  ratio: 0.773054
--- 0.2650275230407715 seconds for one epoch ---
--- 0.2965412139892578 seconds for one epoch ---
--- 1.6644997596740723 seconds for one epoch ---
--- 0.30136823654174805 seconds for one epoch ---
--- 1.6587059497833252 seconds for one epoch ---
--- 0.2903439998626709 seconds for one epoch ---
--- 1.6677184104919434 seconds for one epoch ---
--- 0.30449962615966797 seconds for one epoch ---
--- 1.625819444656372 seconds for one epoch ---
--- 0.3062920570373535 seconds for one epoch ---
--- 1.630974292755127 seconds for one epoch ---
--- 0.3017103672027588 seconds for one epoch ---
--- 1.6158678531646729 seconds for one epoch ---
--- 0.3045370578765869 seconds for one epoch ---
--- 1.6164705753326416 seconds for one epoch ---
--- 0.3074812889099121 seconds for one epoch ---
--- 1.6324982643127441 seconds for one epoch ---
--- 0.2939305305480957 seconds for one epoch ---
--- 1.6351308822631836 seconds for one epoch ---
--- 0.29348158836364746 seconds for one epoch ---
--- 1.6298627853393555 seconds for one epoch ---
--- 0.2978847026824951 seconds for one epoch ---
--- 1.6391997337341309 seconds for one epoch ---
--- 0.30213427543640137 seconds for one epoch ---
=========================
[[1.        ]
 [0.64464605]
 [0.22942162]
 [0.        ]
 [0.        ]
 [0.7081982 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9975142 ]
 [-0.70448136]
 [-0.5233196 ]
 [-0.        ]
 [ 0.        ]
 [-0.73367107]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.479957  ]
 [-0.        ]]
--- 0.2651634216308594 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2975.008056640625, (1300.487, 3.101301, 1670.4158, 1.0038389)
   validation loss 912.5442504882812, (581.32965, 1.7692496, 328.44156, 1.0038389)
decoder loss ratio: 22521.719908, decoder SINDy loss  ratio: 0.708987
--- 0.2998697757720947 seconds for one epoch ---
--- 1.6703345775604248 seconds for one epoch ---
--- 0.31108975410461426 seconds for one epoch ---
--- 1.6504344940185547 seconds for one epoch ---
--- 0.3027024269104004 seconds for one epoch ---
--- 1.69002103805542 seconds for one epoch ---
--- 0.5965094566345215 seconds for one epoch ---
--- 1.6255762577056885 seconds for one epoch ---
--- 0.3110005855560303 seconds for one epoch ---
--- 1.6295104026794434 seconds for one epoch ---
--- 0.29852819442749023 seconds for one epoch ---
--- 1.6527392864227295 seconds for one epoch ---
--- 0.2872731685638428 seconds for one epoch ---
--- 1.6818232536315918 seconds for one epoch ---
--- 0.294705867767334 seconds for one epoch ---
--- 1.6752073764801025 seconds for one epoch ---
--- 0.29390883445739746 seconds for one epoch ---
--- 1.6858046054840088 seconds for one epoch ---
--- 0.30254626274108887 seconds for one epoch ---
--- 1.6612472534179688 seconds for one epoch ---
--- 0.3027334213256836 seconds for one epoch ---
--- 1.6836655139923096 seconds for one epoch ---
--- 0.28803539276123047 seconds for one epoch ---
--- 1.6834042072296143 seconds for one epoch ---
=========================
[[1.        ]
 [0.6477162 ]
 [0.22367302]
 [0.        ]
 [0.        ]
 [0.7053227 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0078163 ]
 [-0.70582813]
 [-0.52003187]
 [ 0.        ]
 [-0.        ]
 [-0.7322797 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.480102  ]
 [ 0.        ]]
--- 0.2916874885559082 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2756.064697265625, (1715.4722, 1.0629873, 1038.5276, 1.001924)
   validation loss 1160.9765625, (840.3071, 1.6798255, 317.9877, 1.001924)
decoder loss ratio: 32554.957011, decoder SINDy loss  ratio: 0.686421
--- 0.2615842819213867 seconds for one epoch ---
--- 0.3013575077056885 seconds for one epoch ---
--- 1.660400390625 seconds for one epoch ---
--- 0.2952275276184082 seconds for one epoch ---
--- 1.6710457801818848 seconds for one epoch ---
--- 0.3049910068511963 seconds for one epoch ---
--- 1.6046204566955566 seconds for one epoch ---
--- 0.2971827983856201 seconds for one epoch ---
--- 1.6187400817871094 seconds for one epoch ---
--- 0.29625391960144043 seconds for one epoch ---
--- 1.6251142024993896 seconds for one epoch ---
--- 0.30394458770751953 seconds for one epoch ---
--- 1.6422348022460938 seconds for one epoch ---
--- 0.30380678176879883 seconds for one epoch ---
--- 1.668410301208496 seconds for one epoch ---
--- 0.3045539855957031 seconds for one epoch ---
--- 1.6720550060272217 seconds for one epoch ---
--- 0.3035087585449219 seconds for one epoch ---
--- 1.6527304649353027 seconds for one epoch ---
--- 0.29555559158325195 seconds for one epoch ---
--- 1.648488998413086 seconds for one epoch ---
--- 0.30132269859313965 seconds for one epoch ---
--- 1.6641039848327637 seconds for one epoch ---
--- 0.29241418838500977 seconds for one epoch ---
=========================
[[1.       ]
 [0.6087382]
 [0.2198683]
 [0.       ]
 [0.       ]
 [0.7245687]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.0284624 ]
 [-0.6890806 ]
 [-0.5178228 ]
 [-0.        ]
 [ 0.        ]
 [-0.74175406]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.4848332 ]
 [ 0.        ]]
--- 0.2681148052215576 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3167.559814453125, (1348.0294, 1.5598062, 1816.9706, 0.99990195)
   validation loss 826.0074462890625, (498.0238, 1.6594287, 325.32437, 0.99990195)
decoder loss ratio: 19294.306763, decoder SINDy loss  ratio: 0.702258
--- 0.2969810962677002 seconds for one epoch ---
--- 1.700124740600586 seconds for one epoch ---
--- 0.3045036792755127 seconds for one epoch ---
--- 1.7104196548461914 seconds for one epoch ---
--- 0.3043665885925293 seconds for one epoch ---
--- 1.6461327075958252 seconds for one epoch ---
--- 0.2993638515472412 seconds for one epoch ---
--- 1.645174264907837 seconds for one epoch ---
--- 0.2887547016143799 seconds for one epoch ---
--- 1.6548585891723633 seconds for one epoch ---
--- 0.3016488552093506 seconds for one epoch ---
--- 1.6632778644561768 seconds for one epoch ---
--- 0.3002767562866211 seconds for one epoch ---
--- 1.6620252132415771 seconds for one epoch ---
--- 0.30589938163757324 seconds for one epoch ---
--- 1.6981065273284912 seconds for one epoch ---
--- 0.3265714645385742 seconds for one epoch ---
--- 1.6822221279144287 seconds for one epoch ---
--- 0.3220949172973633 seconds for one epoch ---
--- 1.6718339920043945 seconds for one epoch ---
--- 0.3118247985839844 seconds for one epoch ---
--- 1.6701228618621826 seconds for one epoch ---
--- 0.32680559158325195 seconds for one epoch ---
--- 1.6903667449951172 seconds for one epoch ---
=========================
[[1.        ]
 [0.5680754 ]
 [0.20389937]
 [0.        ]
 [0.        ]
 [0.72198415]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0469568]
 [-0.672234 ]
 [-0.5082366]
 [ 0.       ]
 [-0.       ]
 [-0.740459 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.4957075]
 [-0.       ]]
--- 0.29755473136901855 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3364.33740234375, (1477.9685, 4.173585, 1881.2072, 0.9882889)
   validation loss 1058.8985595703125, (750.1154, 1.6330206, 306.1619, 0.9882889)
decoder loss ratio: 29060.773531, decoder SINDy loss  ratio: 0.660894
THRESHOLDING: 5 active coefficients
--- 0.2726171016693115 seconds for one epoch ---
--- 0.3319225311279297 seconds for one epoch ---
--- 1.69468355178833 seconds for one epoch ---
--- 0.33664917945861816 seconds for one epoch ---
--- 1.706094741821289 seconds for one epoch ---
--- 0.34340739250183105 seconds for one epoch ---
--- 1.7188546657562256 seconds for one epoch ---
--- 0.3372628688812256 seconds for one epoch ---
--- 1.728691816329956 seconds for one epoch ---
--- 0.3351564407348633 seconds for one epoch ---
--- 1.7152631282806396 seconds for one epoch ---
--- 0.3241086006164551 seconds for one epoch ---
--- 1.7065341472625732 seconds for one epoch ---
--- 0.31540656089782715 seconds for one epoch ---
--- 1.7152833938598633 seconds for one epoch ---
--- 0.32480788230895996 seconds for one epoch ---
--- 1.7316267490386963 seconds for one epoch ---
--- 0.32113027572631836 seconds for one epoch ---
--- 1.7065768241882324 seconds for one epoch ---
--- 0.30690574645996094 seconds for one epoch ---
--- 1.6869032382965088 seconds for one epoch ---
--- 0.298872709274292 seconds for one epoch ---
--- 1.6795096397399902 seconds for one epoch ---
--- 0.30052685737609863 seconds for one epoch ---
=========================
[[1.        ]
 [0.5442664 ]
 [0.21397696]
 [0.        ]
 [0.        ]
 [0.69476503]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0551155 ]
 [-0.66256094]
 [-0.51434714]
 [-0.        ]
 [-0.        ]
 [-0.7272369 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5074816 ]
 [-0.        ]]
--- 0.2531561851501465 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2141.592041015625, (859.6628, 0.41277283, 1280.5306, 0.98589724)
   validation loss 1016.95458984375, (674.27686, 1.7466109, 339.94525, 0.98589724)
decoder loss ratio: 26122.655977, decoder SINDy loss  ratio: 0.733820
--- 0.3130064010620117 seconds for one epoch ---
--- 1.6857984066009521 seconds for one epoch ---
--- 0.3196382522583008 seconds for one epoch ---
--- 1.7016088962554932 seconds for one epoch ---
--- 0.3078005313873291 seconds for one epoch ---
--- 1.6973495483398438 seconds for one epoch ---
--- 0.2980971336364746 seconds for one epoch ---
--- 1.6834514141082764 seconds for one epoch ---
--- 0.294628381729126 seconds for one epoch ---
--- 1.6899287700653076 seconds for one epoch ---
--- 0.3022623062133789 seconds for one epoch ---
--- 1.697371006011963 seconds for one epoch ---
--- 0.2890772819519043 seconds for one epoch ---
--- 1.6694550514221191 seconds for one epoch ---
--- 0.29413819313049316 seconds for one epoch ---
--- 1.7192745208740234 seconds for one epoch ---
--- 0.2981441020965576 seconds for one epoch ---
--- 1.691230058670044 seconds for one epoch ---
--- 0.30048465728759766 seconds for one epoch ---
--- 1.7116496562957764 seconds for one epoch ---
--- 0.29146909713745117 seconds for one epoch ---
--- 1.6917750835418701 seconds for one epoch ---
--- 0.30310606956481934 seconds for one epoch ---
--- 1.724562406539917 seconds for one epoch ---
=========================
[[1.        ]
 [0.55188036]
 [0.21971968]
 [0.        ]
 [0.        ]
 [0.6831062 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0750818]
 [-0.6656431]
 [-0.5177359]
 [ 0.       ]
 [-0.       ]
 [-0.7217803]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5339565]
 [ 0.       ]]
--- 0.3063199520111084 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2012.1956787109375, (807.7834, 2.9129262, 1200.5103, 0.98909855)
   validation loss 981.9248657226562, (660.4249, 1.5187374, 318.9921, 0.98909855)
decoder loss ratio: 25586.008211, decoder SINDy loss  ratio: 0.688589
--- 0.2619624137878418 seconds for one epoch ---
--- 0.3100016117095947 seconds for one epoch ---
--- 1.7018818855285645 seconds for one epoch ---
--- 0.3040440082550049 seconds for one epoch ---
--- 1.707115888595581 seconds for one epoch ---
--- 0.31285619735717773 seconds for one epoch ---
--- 1.6811091899871826 seconds for one epoch ---
--- 0.2977437973022461 seconds for one epoch ---
--- 1.657029151916504 seconds for one epoch ---
--- 0.29713869094848633 seconds for one epoch ---
--- 1.6689982414245605 seconds for one epoch ---
--- 0.30375218391418457 seconds for one epoch ---
--- 1.6685547828674316 seconds for one epoch ---
--- 0.30380940437316895 seconds for one epoch ---
--- 1.7140007019042969 seconds for one epoch ---
--- 0.2996227741241455 seconds for one epoch ---
--- 1.7539451122283936 seconds for one epoch ---
--- 0.3497798442840576 seconds for one epoch ---
--- 1.772979497909546 seconds for one epoch ---
--- 0.34550976753234863 seconds for one epoch ---
--- 1.771866798400879 seconds for one epoch ---
--- 0.32835865020751953 seconds for one epoch ---
--- 1.74969482421875 seconds for one epoch ---
--- 0.32683515548706055 seconds for one epoch ---
=========================
[[1.        ]
 [0.5021874 ]
 [0.21676368]
 [0.        ]
 [0.        ]
 [0.67369413]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0849183 ]
 [-0.64563864]
 [-0.5159997 ]
 [ 0.        ]
 [ 0.        ]
 [-0.71745354]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.538668  ]
 [ 0.        ]]
--- 0.2673313617706299 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3070.128662109375, (1024.624, 4.384774, 2040.1407, 0.9792963)
   validation loss 983.2272338867188, (646.804, 1.5491694, 333.89468, 0.9792963)
decoder loss ratio: 25058.310485, decoder SINDy loss  ratio: 0.720759
--- 0.2979919910430908 seconds for one epoch ---
--- 1.6994538307189941 seconds for one epoch ---
--- 0.2990376949310303 seconds for one epoch ---
--- 1.7042486667633057 seconds for one epoch ---
--- 0.3048973083496094 seconds for one epoch ---
--- 1.7001352310180664 seconds for one epoch ---
--- 0.30258917808532715 seconds for one epoch ---
--- 1.694493293762207 seconds for one epoch ---
--- 0.30355381965637207 seconds for one epoch ---
--- 1.6841013431549072 seconds for one epoch ---
--- 0.296985387802124 seconds for one epoch ---
--- 1.6698338985443115 seconds for one epoch ---
--- 0.2842893600463867 seconds for one epoch ---
--- 1.734673261642456 seconds for one epoch ---
--- 0.32393670082092285 seconds for one epoch ---
--- 1.7208561897277832 seconds for one epoch ---
--- 0.3377509117126465 seconds for one epoch ---
--- 1.750382661819458 seconds for one epoch ---
--- 0.34271955490112305 seconds for one epoch ---
--- 1.7659709453582764 seconds for one epoch ---
--- 0.34656834602355957 seconds for one epoch ---
--- 1.7270746231079102 seconds for one epoch ---
--- 0.33512377738952637 seconds for one epoch ---
--- 1.7692809104919434 seconds for one epoch ---
=========================
[[1.        ]
 [0.52702487]
 [0.21779504]
 [0.        ]
 [0.        ]
 [0.68710434]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1003015 ]
 [-0.65561   ]
 [-0.51660746]
 [-0.        ]
 [-0.        ]
 [-0.72363853]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.538241  ]
 [-0.        ]]
--- 0.2996490001678467 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3119.113525390625, (884.87054, 1.683075, 2231.5771, 0.9825614)
   validation loss 951.8162231445312, (627.84534, 1.5243071, 321.46405, 0.9825614)
decoder loss ratio: 24323.818339, decoder SINDy loss  ratio: 0.693925
--- 0.2539327144622803 seconds for one epoch ---
--- 0.29618358612060547 seconds for one epoch ---
--- 1.7047944068908691 seconds for one epoch ---
--- 0.30764198303222656 seconds for one epoch ---
--- 1.7374122142791748 seconds for one epoch ---
--- 0.30556297302246094 seconds for one epoch ---
--- 1.7070825099945068 seconds for one epoch ---
--- 0.3090043067932129 seconds for one epoch ---
--- 1.7040624618530273 seconds for one epoch ---
--- 0.3065636157989502 seconds for one epoch ---
--- 1.7002580165863037 seconds for one epoch ---
--- 0.29667115211486816 seconds for one epoch ---
--- 1.6902246475219727 seconds for one epoch ---
--- 0.2855668067932129 seconds for one epoch ---
--- 1.7511868476867676 seconds for one epoch ---
--- 0.2936115264892578 seconds for one epoch ---
--- 1.729576587677002 seconds for one epoch ---
--- 0.2995946407318115 seconds for one epoch ---
--- 1.7640776634216309 seconds for one epoch ---
--- 0.31284093856811523 seconds for one epoch ---
--- 1.7659387588500977 seconds for one epoch ---
--- 0.2866475582122803 seconds for one epoch ---
--- 1.732900857925415 seconds for one epoch ---
--- 0.28296875953674316 seconds for one epoch ---
=========================
[[1.        ]
 [0.517316  ]
 [0.19918013]
 [0.        ]
 [0.        ]
 [0.69977665]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1191425 ]
 [-0.6517085 ]
 [-0.50529796]
 [-0.        ]
 [ 0.        ]
 [-0.729618  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.5439744 ]
 [-0.        ]]
--- 0.25762462615966797 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3115.3779296875, (1298.2714, 0.81448174, 1815.3148, 0.9772987)
   validation loss 809.0556030273438, (485.68314, 1.7597997, 320.63538, 0.9772987)
decoder loss ratio: 18816.207871, decoder SINDy loss  ratio: 0.692137
--- 0.28279590606689453 seconds for one epoch ---
--- 1.7701151371002197 seconds for one epoch ---
--- 0.30359816551208496 seconds for one epoch ---
--- 1.7888259887695312 seconds for one epoch ---
--- 0.30874109268188477 seconds for one epoch ---
--- 1.749793529510498 seconds for one epoch ---
--- 0.3074343204498291 seconds for one epoch ---
--- 1.7228813171386719 seconds for one epoch ---
--- 0.3183627128601074 seconds for one epoch ---
--- 1.73427414894104 seconds for one epoch ---
--- 0.306751012802124 seconds for one epoch ---
--- 1.7420744895935059 seconds for one epoch ---
--- 0.3005256652832031 seconds for one epoch ---
--- 1.7672700881958008 seconds for one epoch ---
--- 0.29702019691467285 seconds for one epoch ---
--- 1.7710707187652588 seconds for one epoch ---
--- 0.30661487579345703 seconds for one epoch ---
--- 1.7622520923614502 seconds for one epoch ---
--- 0.28884339332580566 seconds for one epoch ---
--- 1.782358169555664 seconds for one epoch ---
--- 0.29378700256347656 seconds for one epoch ---
--- 1.750237226486206 seconds for one epoch ---
--- 0.3068854808807373 seconds for one epoch ---
--- 1.7596619129180908 seconds for one epoch ---
=========================
[[1.        ]
 [0.5090091 ]
 [0.19924138]
 [0.        ]
 [0.        ]
 [0.6772679 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1258614 ]
 [-0.6483751 ]
 [-0.5053364 ]
 [ 0.        ]
 [ 0.        ]
 [-0.71908855]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.5517516 ]
 [ 0.        ]]
--- 0.30914759635925293 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4297.9697265625, (1451.4441, 2.273005, 2843.2766, 0.9761326)
   validation loss 1317.256103515625, (988.1462, 1.7360148, 326.39783, 0.9761326)
decoder loss ratio: 38282.498479, decoder SINDy loss  ratio: 0.704576
--- 0.25377988815307617 seconds for one epoch ---
--- 0.2936711311340332 seconds for one epoch ---
--- 1.7859418392181396 seconds for one epoch ---
--- 0.29817676544189453 seconds for one epoch ---
--- 1.7689952850341797 seconds for one epoch ---
--- 0.3034207820892334 seconds for one epoch ---
--- 1.7307713031768799 seconds for one epoch ---
--- 0.29544997215270996 seconds for one epoch ---
--- 1.7373316287994385 seconds for one epoch ---
--- 0.30040740966796875 seconds for one epoch ---
--- 1.7423100471496582 seconds for one epoch ---
--- 0.31014466285705566 seconds for one epoch ---
--- 1.8089258670806885 seconds for one epoch ---
--- 0.31160950660705566 seconds for one epoch ---
--- 1.7985553741455078 seconds for one epoch ---
--- 0.34185147285461426 seconds for one epoch ---
--- 1.7716870307922363 seconds for one epoch ---
--- 0.33284926414489746 seconds for one epoch ---
--- 1.7918977737426758 seconds for one epoch ---
--- 0.3315272331237793 seconds for one epoch ---
--- 1.8046214580535889 seconds for one epoch ---
--- 0.3214602470397949 seconds for one epoch ---
--- 1.7922978401184082 seconds for one epoch ---
--- 0.3211240768432617 seconds for one epoch ---
=========================
[[1.        ]
 [0.48384875]
 [0.20210007]
 [0.        ]
 [0.        ]
 [0.68218076]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.14405   ]
 [-0.63828194]
 [-0.5071223 ]
 [ 0.        ]
 [-0.        ]
 [-0.72135156]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.564135  ]
 [ 0.        ]]
--- 0.2745327949523926 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4463.212890625, (1247.4205, 2.137379, 3212.6812, 0.9736659)
   validation loss 960.42724609375, (654.40814, 1.6442418, 303.40118, 0.9736659)
decoder loss ratio: 25352.907527, decoder SINDy loss  ratio: 0.654934
--- 0.31327080726623535 seconds for one epoch ---
--- 1.7712533473968506 seconds for one epoch ---
--- 0.3068201541900635 seconds for one epoch ---
--- 1.7533018589019775 seconds for one epoch ---
--- 0.2987194061279297 seconds for one epoch ---
--- 1.7285573482513428 seconds for one epoch ---
--- 0.2983725070953369 seconds for one epoch ---
--- 1.736168384552002 seconds for one epoch ---
--- 0.2971489429473877 seconds for one epoch ---
--- 1.7469298839569092 seconds for one epoch ---
--- 0.3028414249420166 seconds for one epoch ---
--- 1.7509989738464355 seconds for one epoch ---
--- 0.3264005184173584 seconds for one epoch ---
--- 1.7716872692108154 seconds for one epoch ---
--- 0.3451669216156006 seconds for one epoch ---
--- 1.809870719909668 seconds for one epoch ---
--- 0.3347475528717041 seconds for one epoch ---
--- 1.7938287258148193 seconds for one epoch ---
--- 0.33211660385131836 seconds for one epoch ---
--- 1.8025641441345215 seconds for one epoch ---
--- 0.32901453971862793 seconds for one epoch ---
--- 1.8063874244689941 seconds for one epoch ---
--- 0.3188910484313965 seconds for one epoch ---
--- 1.8149940967559814 seconds for one epoch ---
=========================
[[1.        ]
 [0.4795801 ]
 [0.20520915]
 [0.        ]
 [0.        ]
 [0.67893153]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1594443]
 [-0.636568 ]
 [-0.5090433]
 [-0.       ]
 [ 0.       ]
 [-0.719853 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5737705]
 [-0.       ]]
--- 0.29773712158203125 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2461.162841796875, (1118.8359, 2.9988203, 1338.3558, 0.9723732)
   validation loss 904.6792602539062, (584.3027, 1.5320057, 317.87225, 0.9723732)
decoder loss ratio: 22636.899959, decoder SINDy loss  ratio: 0.686172
--- 0.2635610103607178 seconds for one epoch ---
--- 0.3090684413909912 seconds for one epoch ---
--- 1.8134069442749023 seconds for one epoch ---
--- 0.2915661334991455 seconds for one epoch ---
--- 1.7586054801940918 seconds for one epoch ---
--- 0.30580973625183105 seconds for one epoch ---
--- 1.7688429355621338 seconds for one epoch ---
--- 0.30376672744750977 seconds for one epoch ---
--- 1.7580153942108154 seconds for one epoch ---
--- 0.2823219299316406 seconds for one epoch ---
--- 1.784294843673706 seconds for one epoch ---
--- 0.3004300594329834 seconds for one epoch ---
--- 1.7921984195709229 seconds for one epoch ---
--- 0.3018190860748291 seconds for one epoch ---
--- 1.82588529586792 seconds for one epoch ---
--- 0.3083982467651367 seconds for one epoch ---
--- 1.8779664039611816 seconds for one epoch ---
--- 0.28606367111206055 seconds for one epoch ---
--- 1.8065681457519531 seconds for one epoch ---
--- 0.29497361183166504 seconds for one epoch ---
--- 1.8215482234954834 seconds for one epoch ---
--- 0.30755186080932617 seconds for one epoch ---
--- 1.7930991649627686 seconds for one epoch ---
--- 0.3086662292480469 seconds for one epoch ---
=========================
[[1.        ]
 [0.54039633]
 [0.1950252 ]
 [0.        ]
 [0.        ]
 [0.6680075 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1637304 ]
 [-0.66099745]
 [-0.5026671 ]
 [ 0.        ]
 [-0.        ]
 [-0.7148709 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5701838 ]
 [-0.        ]]
--- 0.2602405548095703 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2995.966064453125, (1368.0673, 1.7417316, 1625.1776, 0.9794304)
   validation loss 853.8255615234375, (542.3415, 1.6454241, 308.8592, 0.9794304)
decoder loss ratio: 21011.250935, decoder SINDy loss  ratio: 0.666716
--- 0.3006885051727295 seconds for one epoch ---
--- 1.7931857109069824 seconds for one epoch ---
--- 0.2987689971923828 seconds for one epoch ---
--- 1.7446565628051758 seconds for one epoch ---
--- 0.3000364303588867 seconds for one epoch ---
--- 1.7464864253997803 seconds for one epoch ---
--- 0.300307035446167 seconds for one epoch ---
--- 1.7635228633880615 seconds for one epoch ---
--- 0.30283045768737793 seconds for one epoch ---
--- 1.7812697887420654 seconds for one epoch ---
--- 0.30279088020324707 seconds for one epoch ---
--- 1.7916710376739502 seconds for one epoch ---
--- 0.2956409454345703 seconds for one epoch ---
--- 1.7989530563354492 seconds for one epoch ---
--- 0.3015861511230469 seconds for one epoch ---
--- 1.7725708484649658 seconds for one epoch ---
--- 0.30377984046936035 seconds for one epoch ---
--- 1.8252689838409424 seconds for one epoch ---
--- 0.3014192581176758 seconds for one epoch ---
--- 1.7825303077697754 seconds for one epoch ---
--- 0.2933211326599121 seconds for one epoch ---
--- 1.7824485301971436 seconds for one epoch ---
--- 0.2984893321990967 seconds for one epoch ---
--- 1.817047119140625 seconds for one epoch ---
=========================
[[1.        ]
 [0.55329293]
 [0.1984481 ]
 [0.        ]
 [0.        ]
 [0.6709822 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1751218 ]
 [-0.6662163 ]
 [-0.50483763]
 [-0.        ]
 [-0.        ]
 [-0.7162186 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.569351  ]
 [ 0.        ]]
--- 0.30484771728515625 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3575.288330078125, (1360.737, 0.79340345, 2212.778, 0.9797656)
   validation loss 919.6134033203125, (610.08575, 1.6446187, 306.90335, 0.9797656)
decoder loss ratio: 23635.781281, decoder SINDy loss  ratio: 0.662494
--- 0.2598884105682373 seconds for one epoch ---
--- 0.32108569145202637 seconds for one epoch ---
--- 1.7739484310150146 seconds for one epoch ---
--- 0.309002161026001 seconds for one epoch ---
--- 1.774153470993042 seconds for one epoch ---
--- 0.30339622497558594 seconds for one epoch ---
--- 1.7875213623046875 seconds for one epoch ---
--- 0.30320262908935547 seconds for one epoch ---
--- 1.8133552074432373 seconds for one epoch ---
--- 0.30519676208496094 seconds for one epoch ---
--- 1.836228847503662 seconds for one epoch ---
--- 0.3018021583557129 seconds for one epoch ---
--- 1.8361234664916992 seconds for one epoch ---
--- 0.30385494232177734 seconds for one epoch ---
--- 1.817671775817871 seconds for one epoch ---
--- 0.29810476303100586 seconds for one epoch ---
--- 1.8283381462097168 seconds for one epoch ---
--- 0.3068735599517822 seconds for one epoch ---
--- 1.8256566524505615 seconds for one epoch ---
--- 0.3077354431152344 seconds for one epoch ---
--- 1.8267648220062256 seconds for one epoch ---
--- 0.3057701587677002 seconds for one epoch ---
--- 1.869157075881958 seconds for one epoch ---
--- 0.30399513244628906 seconds for one epoch ---
=========================
[[1.        ]
 [0.5890007 ]
 [0.1955255 ]
 [0.        ]
 [0.        ]
 [0.65609425]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1747992 ]
 [-0.6808407 ]
 [-0.50298613]
 [-0.        ]
 [-0.        ]
 [-0.70953107]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.562639  ]
 [ 0.        ]]
--- 0.24585509300231934 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2110.33984375, (803.45654, 0.710906, 1305.1897, 0.98270464)
   validation loss 901.6463623046875, (590.0635, 1.5980624, 309.00208, 0.98270464)
decoder loss ratio: 22860.083477, decoder SINDy loss  ratio: 0.667024
--- 0.30980634689331055 seconds for one epoch ---
--- 1.7887144088745117 seconds for one epoch ---
--- 0.2972829341888428 seconds for one epoch ---
--- 1.794461965560913 seconds for one epoch ---
--- 0.3075520992279053 seconds for one epoch ---
--- 1.8145596981048584 seconds for one epoch ---
--- 0.2940700054168701 seconds for one epoch ---
--- 1.8444092273712158 seconds for one epoch ---
--- 0.3242332935333252 seconds for one epoch ---
--- 1.8170890808105469 seconds for one epoch ---
--- 0.3025989532470703 seconds for one epoch ---
--- 1.8155391216278076 seconds for one epoch ---
--- 0.30213236808776855 seconds for one epoch ---
--- 1.810051679611206 seconds for one epoch ---
--- 0.2941300868988037 seconds for one epoch ---
--- 1.8478870391845703 seconds for one epoch ---
--- 0.31545257568359375 seconds for one epoch ---
--- 1.8231008052825928 seconds for one epoch ---
--- 0.30407047271728516 seconds for one epoch ---
--- 1.8503384590148926 seconds for one epoch ---
--- 0.2790529727935791 seconds for one epoch ---
--- 1.8395698070526123 seconds for one epoch ---
--- 0.29892945289611816 seconds for one epoch ---
--- 1.8496265411376953 seconds for one epoch ---
=========================
[[1.        ]
 [0.5958895 ]
 [0.18351352]
 [0.        ]
 [0.        ]
 [0.6728378 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1920161 ]
 [-0.6837012 ]
 [-0.49514827]
 [ 0.        ]
 [ 0.        ]
 [-0.71706337]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.56636   ]
 [-0.        ]]
--- 0.29711151123046875 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3348.2412109375, (1544.9012, 2.6685183, 1799.6855, 0.98574907)
   validation loss 833.3357543945312, (517.0853, 1.6733944, 313.59128, 0.98574907)
decoder loss ratio: 20032.783273, decoder SINDy loss  ratio: 0.676931
--- 0.26466798782348633 seconds for one epoch ---
--- 0.30767130851745605 seconds for one epoch ---
--- 1.7905521392822266 seconds for one epoch ---
--- 0.2982504367828369 seconds for one epoch ---
--- 1.7809040546417236 seconds for one epoch ---
--- 0.30403590202331543 seconds for one epoch ---
--- 1.843733787536621 seconds for one epoch ---
--- 0.32518434524536133 seconds for one epoch ---
--- 1.8052759170532227 seconds for one epoch ---
--- 0.33647775650024414 seconds for one epoch ---
--- 1.8276336193084717 seconds for one epoch ---
--- 0.32420945167541504 seconds for one epoch ---
--- 1.8410754203796387 seconds for one epoch ---
--- 0.3393678665161133 seconds for one epoch ---
--- 1.8125789165496826 seconds for one epoch ---
--- 0.3174571990966797 seconds for one epoch ---
--- 1.836493968963623 seconds for one epoch ---
--- 0.3384518623352051 seconds for one epoch ---
--- 1.8539562225341797 seconds for one epoch ---
--- 0.3436238765716553 seconds for one epoch ---
--- 1.8537282943725586 seconds for one epoch ---
--- 0.3303985595703125 seconds for one epoch ---
--- 1.896608591079712 seconds for one epoch ---
--- 0.2946934700012207 seconds for one epoch ---
=========================
[[1.        ]
 [0.5899538 ]
 [0.18188412]
 [0.        ]
 [0.        ]
 [0.6648613 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1940157 ]
 [-0.6812362 ]
 [-0.49405468]
 [-0.        ]
 [-0.        ]
 [-0.71345145]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5573397 ]
 [-0.        ]]
--- 0.25286340713500977 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3759.093505859375, (1076.6747, 4.744119, 2676.6946, 0.98034143)
   validation loss 1171.9656982421875, (843.0491, 1.6625232, 326.2738, 0.98034143)
decoder loss ratio: 32661.184657, decoder SINDy loss  ratio: 0.704308
--- 0.26670026779174805 seconds for one epoch ---
--- 1.8021819591522217 seconds for one epoch ---
--- 0.30364036560058594 seconds for one epoch ---
--- 1.865144968032837 seconds for one epoch ---
--- 0.2994880676269531 seconds for one epoch ---
--- 1.8657920360565186 seconds for one epoch ---
--- 0.30380702018737793 seconds for one epoch ---
--- 1.8574450016021729 seconds for one epoch ---
--- 0.2948415279388428 seconds for one epoch ---
--- 1.8502612113952637 seconds for one epoch ---
--- 0.2938542366027832 seconds for one epoch ---
--- 1.8739211559295654 seconds for one epoch ---
--- 0.2998776435852051 seconds for one epoch ---
--- 1.8555712699890137 seconds for one epoch ---
--- 0.29155659675598145 seconds for one epoch ---
--- 1.8350555896759033 seconds for one epoch ---
--- 0.2989027500152588 seconds for one epoch ---
--- 1.886831521987915 seconds for one epoch ---
--- 0.28914427757263184 seconds for one epoch ---
--- 1.8528809547424316 seconds for one epoch ---
--- 0.2975330352783203 seconds for one epoch ---
--- 1.8794965744018555 seconds for one epoch ---
--- 0.30637335777282715 seconds for one epoch ---
--- 1.83900785446167 seconds for one epoch ---
=========================
[[1.        ]
 [0.5525314 ]
 [0.18663098]
 [0.        ]
 [0.        ]
 [0.65364575]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2048573 ]
 [-0.6659072 ]
 [-0.49721932]
 [ 0.        ]
 [ 0.        ]
 [-0.7084441 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.5648274 ]
 [ 0.        ]]
--- 0.29640960693359375 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1677.352294921875, (903.6884, 1.0107639, 771.67773, 0.97538203)
   validation loss 970.6050415039062, (651.6701, 1.6971134, 316.2624, 0.97538203)
decoder loss ratio: 25246.831216, decoder SINDy loss  ratio: 0.682697
--- 0.2615506649017334 seconds for one epoch ---
--- 0.28721141815185547 seconds for one epoch ---
--- 1.8394238948822021 seconds for one epoch ---
--- 0.2935779094696045 seconds for one epoch ---
--- 1.8742568492889404 seconds for one epoch ---
--- 0.2986621856689453 seconds for one epoch ---
--- 1.8983502388000488 seconds for one epoch ---
--- 0.2946054935455322 seconds for one epoch ---
--- 1.8698861598968506 seconds for one epoch ---
--- 0.29151463508605957 seconds for one epoch ---
--- 1.876295804977417 seconds for one epoch ---
--- 0.306751012802124 seconds for one epoch ---
--- 1.8612911701202393 seconds for one epoch ---
--- 0.30552101135253906 seconds for one epoch ---
--- 1.869377851486206 seconds for one epoch ---
--- 0.30143117904663086 seconds for one epoch ---
--- 1.8222131729125977 seconds for one epoch ---
--- 0.30178117752075195 seconds for one epoch ---
--- 1.8563873767852783 seconds for one epoch ---
--- 0.30068516731262207 seconds for one epoch ---
--- 1.8592512607574463 seconds for one epoch ---
--- 0.29985976219177246 seconds for one epoch ---
--- 1.863210678100586 seconds for one epoch ---
--- 0.29184484481811523 seconds for one epoch ---
=========================
[[1.        ]
 [0.5465034 ]
 [0.20102255]
 [0.        ]
 [0.        ]
 [0.6440882 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2121837 ]
 [-0.663466  ]
 [-0.50645137]
 [-0.        ]
 [ 0.        ]
 [-0.70423687]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5671573 ]
 [ 0.        ]]
--- 0.25225281715393066 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1716.4683837890625, (683.1895, 1.0049647, 1031.2968, 0.9772094)
   validation loss 941.2062377929688, (628.4919, 1.5328332, 310.2043, 0.9772094)
decoder loss ratio: 24348.866631, decoder SINDy loss  ratio: 0.669620
--- 0.29186439514160156 seconds for one epoch ---
--- 1.801238775253296 seconds for one epoch ---
--- 0.30372071266174316 seconds for one epoch ---
--- 1.8686797618865967 seconds for one epoch ---
--- 0.2992532253265381 seconds for one epoch ---
--- 1.8848371505737305 seconds for one epoch ---
--- 0.2883763313293457 seconds for one epoch ---
--- 1.8936967849731445 seconds for one epoch ---
--- 0.3032536506652832 seconds for one epoch ---
--- 1.8935513496398926 seconds for one epoch ---
--- 0.31011343002319336 seconds for one epoch ---
--- 1.8688616752624512 seconds for one epoch ---
--- 0.3006000518798828 seconds for one epoch ---
--- 1.8677713871002197 seconds for one epoch ---
--- 0.30771398544311523 seconds for one epoch ---
--- 1.8421838283538818 seconds for one epoch ---
--- 0.296292781829834 seconds for one epoch ---
--- 1.8637363910675049 seconds for one epoch ---
--- 0.30237555503845215 seconds for one epoch ---
--- 1.8695268630981445 seconds for one epoch ---
--- 0.2983860969543457 seconds for one epoch ---
--- 1.8690593242645264 seconds for one epoch ---
--- 0.29857468605041504 seconds for one epoch ---
--- 1.8701896667480469 seconds for one epoch ---
=========================
[[1.        ]
 [0.5219337 ]
 [0.19581994]
 [0.        ]
 [0.        ]
 [0.6497159 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2210352 ]
 [-0.65356326]
 [-0.50317365]
 [ 0.        ]
 [-0.        ]
 [-0.706708  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.5638065 ]
 [-0.        ]]
--- 0.2922794818878174 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2708.76123046875, (1136.6161, 1.8821799, 1569.2898, 0.97305566)
   validation loss 910.8367309570312, (606.71796, 1.5312508, 301.6144, 0.97305566)
decoder loss ratio: 23505.306945, decoder SINDy loss  ratio: 0.651077
--- 0.2523653507232666 seconds for one epoch ---
--- 0.30570411682128906 seconds for one epoch ---
--- 1.8435139656066895 seconds for one epoch ---
--- 0.30906009674072266 seconds for one epoch ---
--- 1.8842720985412598 seconds for one epoch ---
--- 0.32502150535583496 seconds for one epoch ---
--- 1.9279046058654785 seconds for one epoch ---
--- 0.32567453384399414 seconds for one epoch ---
--- 1.8921804428100586 seconds for one epoch ---
--- 0.3128237724304199 seconds for one epoch ---
--- 1.873939037322998 seconds for one epoch ---
--- 0.3072013854980469 seconds for one epoch ---
--- 1.9131278991699219 seconds for one epoch ---
--- 0.30454206466674805 seconds for one epoch ---
--- 1.896822214126587 seconds for one epoch ---
--- 0.30822086334228516 seconds for one epoch ---
--- 1.8898963928222656 seconds for one epoch ---
--- 0.29648923873901367 seconds for one epoch ---
--- 1.866527795791626 seconds for one epoch ---
--- 0.2996375560760498 seconds for one epoch ---
--- 1.8655197620391846 seconds for one epoch ---
--- 0.30510807037353516 seconds for one epoch ---
--- 1.8723173141479492 seconds for one epoch ---
--- 0.30729222297668457 seconds for one epoch ---
=========================
[[1.        ]
 [0.5164977 ]
 [0.17581931]
 [0.        ]
 [0.        ]
 [0.64419234]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2312589 ]
 [-0.65138036]
 [-0.48991656]
 [ 0.        ]
 [ 0.        ]
 [-0.704283  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.569507  ]
 [-0.        ]]
--- 0.2570974826812744 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4084.8564453125, (1682.991, 1.8194857, 2399.079, 0.9667721)
   validation loss 863.134521484375, (547.8467, 1.5871938, 312.73383, 0.9667721)
decoder loss ratio: 21224.531475, decoder SINDy loss  ratio: 0.675080
--- 0.27559852600097656 seconds for one epoch ---
--- 1.8704869747161865 seconds for one epoch ---
--- 0.2952253818511963 seconds for one epoch ---
--- 1.8727281093597412 seconds for one epoch ---
--- 0.29469847679138184 seconds for one epoch ---
--- 1.8667724132537842 seconds for one epoch ---
--- 0.3000495433807373 seconds for one epoch ---
--- 1.8965404033660889 seconds for one epoch ---
--- 0.30068492889404297 seconds for one epoch ---
--- 1.863553524017334 seconds for one epoch ---
--- 0.29872655868530273 seconds for one epoch ---
--- 1.859391689300537 seconds for one epoch ---
--- 0.2926056385040283 seconds for one epoch ---
--- 1.8618261814117432 seconds for one epoch ---
--- 0.3104367256164551 seconds for one epoch ---
--- 1.8844714164733887 seconds for one epoch ---
--- 0.3117561340332031 seconds for one epoch ---
--- 1.9130735397338867 seconds for one epoch ---
--- 0.30217981338500977 seconds for one epoch ---
--- 1.9157421588897705 seconds for one epoch ---
--- 0.2918701171875 seconds for one epoch ---
--- 1.910780429840088 seconds for one epoch ---
--- 0.30864739418029785 seconds for one epoch ---
--- 1.9105095863342285 seconds for one epoch ---
=========================
[[1.        ]
 [0.5329762 ]
 [0.17739706]
 [0.        ]
 [0.        ]
 [0.64505124]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.245277  ]
 [-0.6580057 ]
 [-0.49100384]
 [-0.        ]
 [-0.        ]
 [-0.7046583 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.579806  ]
 [ 0.        ]]
--- 0.2966132164001465 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3679.190673828125, (1315.577, 3.2571125, 2359.3862, 0.97054243)
   validation loss 912.3346557617188, (605.0291, 1.7313695, 304.6036, 0.97054243)
decoder loss ratio: 23439.878244, decoder SINDy loss  ratio: 0.657530
--- 0.2621448040008545 seconds for one epoch ---
--- 0.3064262866973877 seconds for one epoch ---
--- 1.862306833267212 seconds for one epoch ---
--- 0.2966275215148926 seconds for one epoch ---
--- 1.8872957229614258 seconds for one epoch ---
--- 0.30788326263427734 seconds for one epoch ---
--- 1.8961434364318848 seconds for one epoch ---
--- 0.28526997566223145 seconds for one epoch ---
--- 1.8714025020599365 seconds for one epoch ---
--- 0.29313063621520996 seconds for one epoch ---
--- 1.915328025817871 seconds for one epoch ---
--- 0.30153346061706543 seconds for one epoch ---
--- 1.9206082820892334 seconds for one epoch ---
--- 0.306013822555542 seconds for one epoch ---
--- 1.9281768798828125 seconds for one epoch ---
--- 0.30576038360595703 seconds for one epoch ---
--- 1.9209740161895752 seconds for one epoch ---
--- 0.3052554130554199 seconds for one epoch ---
--- 1.9138469696044922 seconds for one epoch ---
--- 0.30074477195739746 seconds for one epoch ---
--- 1.9336719512939453 seconds for one epoch ---
--- 0.31255054473876953 seconds for one epoch ---
--- 1.9677081108093262 seconds for one epoch ---
--- 0.30437660217285156 seconds for one epoch ---
=========================
[[1.        ]
 [0.46154433]
 [0.17602628]
 [0.        ]
 [0.        ]
 [0.63367057]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2497666 ]
 [-0.6293095 ]
 [-0.49005973]
 [-0.        ]
 [-0.        ]
 [-0.6997087 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.577561  ]
 [ 0.        ]]
--- 0.26024675369262695 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2028.3216552734375, (1127.0814, 0.6814702, 899.60004, 0.9585741)
   validation loss 1091.278564453125, (766.75214, 1.674675, 321.89313, 0.9585741)
decoder loss ratio: 29705.308898, decoder SINDy loss  ratio: 0.694852
--- 0.2941603660583496 seconds for one epoch ---
--- 1.919227123260498 seconds for one epoch ---
--- 0.31139683723449707 seconds for one epoch ---
--- 1.8948769569396973 seconds for one epoch ---
--- 0.3038501739501953 seconds for one epoch ---
--- 1.8768470287322998 seconds for one epoch ---
--- 0.29906225204467773 seconds for one epoch ---
--- 1.919252872467041 seconds for one epoch ---
--- 0.3055431842803955 seconds for one epoch ---
--- 1.9370369911193848 seconds for one epoch ---
--- 0.3041493892669678 seconds for one epoch ---
--- 1.9535319805145264 seconds for one epoch ---
--- 0.3028862476348877 seconds for one epoch ---
--- 1.9411320686340332 seconds for one epoch ---
--- 0.28670287132263184 seconds for one epoch ---
--- 1.948559284210205 seconds for one epoch ---
--- 0.31803131103515625 seconds for one epoch ---
--- 1.9377541542053223 seconds for one epoch ---
--- 0.29735374450683594 seconds for one epoch ---
--- 1.9527623653411865 seconds for one epoch ---
--- 0.2972874641418457 seconds for one epoch ---
--- 1.9278647899627686 seconds for one epoch ---
--- 0.30989766120910645 seconds for one epoch ---
--- 1.9098174571990967 seconds for one epoch ---
=========================
[[1.        ]
 [0.4449002 ]
 [0.17657214]
 [0.        ]
 [0.        ]
 [0.62405753]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2621067 ]
 [-0.6225754 ]
 [-0.49043626]
 [ 0.        ]
 [-0.        ]
 [-0.6955783 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.5901775 ]
 [-0.        ]]
--- 0.304990291595459 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2900.606689453125, (1146.3256, 0.6608238, 1752.6682, 0.95213586)
   validation loss 1054.24560546875, (719.437, 1.6257533, 332.23065, 0.95213586)
decoder loss ratio: 27872.238832, decoder SINDy loss  ratio: 0.717167
THRESHOLDING: 5 active coefficients
--- 1.9047975540161133 seconds for one epoch ---
--- 0.3034636974334717 seconds for one epoch ---
--- 1.914564847946167 seconds for one epoch ---
--- 0.2964460849761963 seconds for one epoch ---
--- 1.909611701965332 seconds for one epoch ---
--- 0.28185558319091797 seconds for one epoch ---
--- 1.9130439758300781 seconds for one epoch ---
--- 0.2996487617492676 seconds for one epoch ---
--- 1.9226469993591309 seconds for one epoch ---
--- 0.2945265769958496 seconds for one epoch ---
--- 1.897646427154541 seconds for one epoch ---
--- 0.298412561416626 seconds for one epoch ---
--- 1.9246711730957031 seconds for one epoch ---
--- 0.28284192085266113 seconds for one epoch ---
--- 1.919816255569458 seconds for one epoch ---
--- 0.293468713760376 seconds for one epoch ---
--- 1.9284489154815674 seconds for one epoch ---
--- 0.30480337142944336 seconds for one epoch ---
--- 1.8851120471954346 seconds for one epoch ---
--- 0.2912614345550537 seconds for one epoch ---
--- 1.9490423202514648 seconds for one epoch ---
--- 0.3027174472808838 seconds for one epoch ---
--- 1.9424481391906738 seconds for one epoch ---
--- 0.2983121871948242 seconds for one epoch ---
=========================
[[1.        ]
 [0.47956583]
 [0.17186421]
 [0.        ]
 [0.        ]
 [0.6377592 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2821765 ]
 [-0.6365622 ]
 [-0.48715746]
 [ 0.        ]
 [ 0.        ]
 [-0.70147926]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.604155  ]
 [-0.        ]]
--- 0.25432634353637695 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2771.7568359375, (1319.8934, 2.6104507, 1448.2921, 0.9610055)
   validation loss 807.1546020507812, (480.7961, 1.8338406, 323.56366, 0.9610055)
decoder loss ratio: 18626.876080, decoder SINDy loss  ratio: 0.698458
--- 0.3067970275878906 seconds for one epoch ---
--- 2.0522143840789795 seconds for one epoch ---
--- 0.30651092529296875 seconds for one epoch ---
--- 1.963735818862915 seconds for one epoch ---
--- 0.29809021949768066 seconds for one epoch ---
--- 1.9538369178771973 seconds for one epoch ---
--- 0.29266881942749023 seconds for one epoch ---
--- 1.9932079315185547 seconds for one epoch ---
--- 0.29723548889160156 seconds for one epoch ---
--- 1.9266407489776611 seconds for one epoch ---
--- 0.30327343940734863 seconds for one epoch ---
--- 1.9327023029327393 seconds for one epoch ---
--- 0.2994191646575928 seconds for one epoch ---
--- 1.9432144165039062 seconds for one epoch ---
--- 0.3008437156677246 seconds for one epoch ---
--- 2.0625829696655273 seconds for one epoch ---
--- 0.3070380687713623 seconds for one epoch ---
--- 2.0078799724578857 seconds for one epoch ---
--- 0.3232147693634033 seconds for one epoch ---
--- 1.980151891708374 seconds for one epoch ---
--- 0.30149245262145996 seconds for one epoch ---
--- 1.9781484603881836 seconds for one epoch ---
--- 0.2962367534637451 seconds for one epoch ---
--- 2.0104129314422607 seconds for one epoch ---
=========================
[[1.        ]
 [0.50107574]
 [0.17356545]
 [0.        ]
 [0.        ]
 [0.63284487]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2919042 ]
 [-0.6451924 ]
 [-0.48835042]
 [-0.        ]
 [-0.        ]
 [-0.69935185]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6128545 ]
 [ 0.        ]]
--- 0.31157517433166504 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3436.296630859375, (1265.6351, 2.9110942, 2166.7876, 0.9627356)
   validation loss 1398.5318603515625, (1079.7621, 1.8860253, 315.92096, 0.9627356)
decoder loss ratio: 41831.857721, decoder SINDy loss  ratio: 0.681960
--- 0.2595493793487549 seconds for one epoch ---
--- 0.3021240234375 seconds for one epoch ---
--- 2.0000550746917725 seconds for one epoch ---
--- 0.2988440990447998 seconds for one epoch ---
--- 1.9937324523925781 seconds for one epoch ---
--- 0.3023200035095215 seconds for one epoch ---
--- 1.9864540100097656 seconds for one epoch ---
--- 0.299755334854126 seconds for one epoch ---
--- 1.9627695083618164 seconds for one epoch ---
--- 0.2970266342163086 seconds for one epoch ---
--- 2.042106866836548 seconds for one epoch ---
--- 0.30644869804382324 seconds for one epoch ---
--- 2.0221292972564697 seconds for one epoch ---
--- 0.3057081699371338 seconds for one epoch ---
--- 2.0439279079437256 seconds for one epoch ---
--- 0.26822328567504883 seconds for one epoch ---
--- 1.9994683265686035 seconds for one epoch ---
--- 0.3013436794281006 seconds for one epoch ---
--- 1.9815683364868164 seconds for one epoch ---
--- 0.311765193939209 seconds for one epoch ---
--- 1.9857971668243408 seconds for one epoch ---
--- 0.3019533157348633 seconds for one epoch ---
--- 1.9843196868896484 seconds for one epoch ---
--- 0.30557918548583984 seconds for one epoch ---
=========================
[[1.        ]
 [0.54377145]
 [0.17221174]
 [0.        ]
 [0.        ]
 [0.63760006]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3040667 ]
 [-0.66236097]
 [-0.48740196]
 [ 0.        ]
 [ 0.        ]
 [-0.70141035]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.6176395 ]
 [ 0.        ]]
--- 0.29654669761657715 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2422.520751953125, (1733.0984, 0.6862957, 687.7664, 0.9698209)
   validation loss 981.8431396484375, (667.4496, 1.8251424, 311.5986, 0.9698209)
decoder loss ratio: 25858.155665, decoder SINDy loss  ratio: 0.672629
--- 0.2850320339202881 seconds for one epoch ---
--- 1.9896209239959717 seconds for one epoch ---
--- 0.3053100109100342 seconds for one epoch ---
--- 1.9837942123413086 seconds for one epoch ---
--- 0.32288384437561035 seconds for one epoch ---
--- 1.984973430633545 seconds for one epoch ---
--- 0.3035001754760742 seconds for one epoch ---
--- 1.9877338409423828 seconds for one epoch ---
--- 0.3072974681854248 seconds for one epoch ---
--- 2.000912666320801 seconds for one epoch ---
--- 0.29706716537475586 seconds for one epoch ---
--- 1.9678239822387695 seconds for one epoch ---
--- 0.29221177101135254 seconds for one epoch ---
--- 1.9620881080627441 seconds for one epoch ---
--- 0.29435086250305176 seconds for one epoch ---
--- 1.9756693840026855 seconds for one epoch ---
--- 0.3013947010040283 seconds for one epoch ---
--- 1.9918701648712158 seconds for one epoch ---
--- 0.3039734363555908 seconds for one epoch ---
--- 1.9745686054229736 seconds for one epoch ---
--- 0.29995155334472656 seconds for one epoch ---
--- 2.0079662799835205 seconds for one epoch ---
--- 0.2986938953399658 seconds for one epoch ---
--- 1.988227367401123 seconds for one epoch ---
=========================
[[1.        ]
 [0.52146924]
 [0.17456281]
 [0.        ]
 [0.        ]
 [0.6162977 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3069632 ]
 [-0.6533769 ]
 [-0.48904544]
 [-0.        ]
 [ 0.        ]
 [-0.69227475]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6199746 ]
 [-0.        ]]
--- 0.2929208278656006 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3301.386474609375, (1077.8715, 0.6297184, 2221.9216, 0.9636163)
   validation loss 864.555419921875, (568.02094, 1.8530023, 293.71783, 0.9636163)
decoder loss ratio: 22006.117152, decoder SINDy loss  ratio: 0.634031
--- 0.26664185523986816 seconds for one epoch ---
--- 0.2973442077636719 seconds for one epoch ---
--- 2.0147173404693604 seconds for one epoch ---
--- 0.3104984760284424 seconds for one epoch ---
--- 2.007357597351074 seconds for one epoch ---
--- 0.3220996856689453 seconds for one epoch ---
--- 2.031705856323242 seconds for one epoch ---
--- 0.31867146492004395 seconds for one epoch ---
--- 1.9845139980316162 seconds for one epoch ---
--- 0.31641125679016113 seconds for one epoch ---
--- 1.9794564247131348 seconds for one epoch ---
--- 0.3236806392669678 seconds for one epoch ---
--- 2.0222487449645996 seconds for one epoch ---
--- 0.34368109703063965 seconds for one epoch ---
--- 1.9701528549194336 seconds for one epoch ---
--- 0.3417978286743164 seconds for one epoch ---
--- 1.9872722625732422 seconds for one epoch ---
--- 0.3315577507019043 seconds for one epoch ---
--- 2.016575336456299 seconds for one epoch ---
--- 0.3447904586791992 seconds for one epoch ---
--- 2.0376389026641846 seconds for one epoch ---
--- 0.34374380111694336 seconds for one epoch ---
--- 2.01619815826416 seconds for one epoch ---
--- 0.327533483505249 seconds for one epoch ---
=========================
[[1.        ]
 [0.5177318 ]
 [0.18096456]
 [0.        ]
 [0.        ]
 [0.607257  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3096437 ]
 [-0.6518759 ]
 [-0.49343434]
 [-0.        ]
 [-0.        ]
 [-0.68845785]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.614043  ]
 [-0.        ]]
--- 0.258319616317749 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2729.318115234375, (877.24426, 2.6558008, 1848.4539, 0.9642313)
   validation loss 1224.3189697265625, (886.9412, 1.7146859, 334.69882, 0.9642313)
decoder loss ratio: 34361.642782, decoder SINDy loss  ratio: 0.722494
--- 0.29302382469177246 seconds for one epoch ---
--- 1.9900503158569336 seconds for one epoch ---
--- 0.3083620071411133 seconds for one epoch ---
--- 2.0006563663482666 seconds for one epoch ---
--- 0.29608893394470215 seconds for one epoch ---
--- 1.981567621231079 seconds for one epoch ---
--- 0.29956793785095215 seconds for one epoch ---
--- 2.0032050609588623 seconds for one epoch ---
--- 0.2996947765350342 seconds for one epoch ---
--- 2.042869806289673 seconds for one epoch ---
--- 0.2951643466949463 seconds for one epoch ---
--- 1.975442886352539 seconds for one epoch ---
--- 0.3050689697265625 seconds for one epoch ---
--- 1.9924485683441162 seconds for one epoch ---
--- 0.3050534725189209 seconds for one epoch ---
--- 1.9867265224456787 seconds for one epoch ---
--- 0.29238224029541016 seconds for one epoch ---
--- 1.9919681549072266 seconds for one epoch ---
--- 0.3040440082550049 seconds for one epoch ---
--- 2.004307270050049 seconds for one epoch ---
--- 0.28296542167663574 seconds for one epoch ---
--- 2.0071277618408203 seconds for one epoch ---
--- 0.2948472499847412 seconds for one epoch ---
--- 2.011479139328003 seconds for one epoch ---
=========================
[[1.        ]
 [0.49563122]
 [0.17469333]
 [0.        ]
 [0.        ]
 [0.61251056]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3206835 ]
 [-0.64300936]
 [-0.48913616]
 [ 0.        ]
 [ 0.        ]
 [-0.6906717 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.6181655 ]
 [ 0.        ]]
--- 0.3074796199798584 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1605.140625, (840.8648, 0.19649768, 763.11865, 0.9607498)
   validation loss 1526.485107421875, (1170.3383, 1.8081933, 353.378, 0.9607498)
decoder loss ratio: 45340.935866, decoder SINDy loss  ratio: 0.762816
--- 0.26601505279541016 seconds for one epoch ---
--- 0.308582067489624 seconds for one epoch ---
--- 2.0419890880584717 seconds for one epoch ---
--- 0.3032841682434082 seconds for one epoch ---
--- 2.0210087299346924 seconds for one epoch ---
--- 0.30353426933288574 seconds for one epoch ---
--- 2.0158121585845947 seconds for one epoch ---
--- 0.31452322006225586 seconds for one epoch ---
--- 1.9928545951843262 seconds for one epoch ---
--- 0.30229997634887695 seconds for one epoch ---
--- 2.045363426208496 seconds for one epoch ---
--- 0.3005373477935791 seconds for one epoch ---
--- 2.0299203395843506 seconds for one epoch ---
--- 0.3007090091705322 seconds for one epoch ---
--- 2.0536673069000244 seconds for one epoch ---
--- 0.30284857749938965 seconds for one epoch ---
--- 1.9950587749481201 seconds for one epoch ---
--- 0.3043220043182373 seconds for one epoch ---
--- 2.001289129257202 seconds for one epoch ---
--- 0.3077201843261719 seconds for one epoch ---
--- 2.029299736022949 seconds for one epoch ---
--- 0.2997462749481201 seconds for one epoch ---
--- 2.044306755065918 seconds for one epoch ---
--- 0.30322980880737305 seconds for one epoch ---
=========================
[[1.        ]
 [0.50009763]
 [0.18306829]
 [0.        ]
 [0.        ]
 [0.60495245]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3258681 ]
 [-0.64479995]
 [-0.49485007]
 [-0.        ]
 [-0.        ]
 [-0.6874891 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6183467 ]
 [ 0.        ]]
--- 0.27164316177368164 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4235.21630859375, (1864.4338, 3.449819, 2366.3706, 0.96197176)
   validation loss 929.731689453125, (616.44196, 1.9116046, 310.41614, 0.96197176)
decoder loss ratio: 23882.031549, decoder SINDy loss  ratio: 0.670077
--- 0.29082536697387695 seconds for one epoch ---
--- 2.05102276802063 seconds for one epoch ---
--- 0.29810333251953125 seconds for one epoch ---
--- 2.0030455589294434 seconds for one epoch ---
--- 0.2980232238769531 seconds for one epoch ---
--- 2.014580726623535 seconds for one epoch ---
--- 0.3009452819824219 seconds for one epoch ---
--- 2.028988838195801 seconds for one epoch ---
--- 0.29186272621154785 seconds for one epoch ---
--- 2.0111048221588135 seconds for one epoch ---
--- 0.29812145233154297 seconds for one epoch ---
--- 2.028961420059204 seconds for one epoch ---
--- 0.3031768798828125 seconds for one epoch ---
--- 2.0455923080444336 seconds for one epoch ---
--- 0.3135237693786621 seconds for one epoch ---
--- 2.0322604179382324 seconds for one epoch ---
--- 0.30365490913391113 seconds for one epoch ---
--- 2.0594112873077393 seconds for one epoch ---
--- 0.30298471450805664 seconds for one epoch ---
--- 2.0513458251953125 seconds for one epoch ---
--- 0.3047006130218506 seconds for one epoch ---
--- 2.075700521469116 seconds for one epoch ---
--- 0.29992246627807617 seconds for one epoch ---
--- 2.0531227588653564 seconds for one epoch ---
=========================
[[1.        ]
 [0.52534485]
 [0.19064586]
 [0.        ]
 [0.        ]
 [0.60767657]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3361077]
 [-0.6549346]
 [-0.4998477]
 [ 0.       ]
 [-0.       ]
 [-0.688634 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.6221066]
 [-0.       ]]
--- 0.2993197441101074 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2469.02783203125, (1078.9636, 1.3851029, 1387.7107, 0.96815807)
   validation loss 859.2440795898438, (545.33923, 1.9359719, 311.00073, 0.96815807)
decoder loss ratio: 21127.388652, decoder SINDy loss  ratio: 0.671339
--- 0.26665449142456055 seconds for one epoch ---
--- 0.33374762535095215 seconds for one epoch ---
--- 2.073026180267334 seconds for one epoch ---
--- 0.3177218437194824 seconds for one epoch ---
--- 2.0185635089874268 seconds for one epoch ---
--- 0.31749677658081055 seconds for one epoch ---
--- 2.034407138824463 seconds for one epoch ---
--- 0.3186147212982178 seconds for one epoch ---
--- 2.082831382751465 seconds for one epoch ---
--- 0.30651092529296875 seconds for one epoch ---
--- 2.0353548526763916 seconds for one epoch ---
--- 0.3141460418701172 seconds for one epoch ---
--- 2.0699801445007324 seconds for one epoch ---
--- 0.3058333396911621 seconds for one epoch ---
--- 2.0673725605010986 seconds for one epoch ---
--- 0.2925746440887451 seconds for one epoch ---
--- 2.0282375812530518 seconds for one epoch ---
--- 0.30588507652282715 seconds for one epoch ---
--- 2.0754573345184326 seconds for one epoch ---
--- 0.29537415504455566 seconds for one epoch ---
--- 2.0593392848968506 seconds for one epoch ---
--- 0.3017423152923584 seconds for one epoch ---
--- 2.080584764480591 seconds for one epoch ---
--- 0.2992825508117676 seconds for one epoch ---
=========================
[[1.        ]
 [0.51922584]
 [0.19421056]
 [0.        ]
 [0.        ]
 [0.61470973]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.355672  ]
 [-0.65247554]
 [-0.5021461 ]
 [-0.        ]
 [-0.        ]
 [-0.6916018 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.640835  ]
 [-0.        ]]
--- 0.2663304805755615 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2223.518310546875, (1272.8582, 0.805678, 948.88586, 0.9685009)
   validation loss 983.3614501953125, (664.0258, 1.9746822, 316.39243, 0.9685009)
decoder loss ratio: 25725.512984, decoder SINDy loss  ratio: 0.682978
--- 0.3069026470184326 seconds for one epoch ---
--- 2.037870168685913 seconds for one epoch ---
--- 0.31162428855895996 seconds for one epoch ---
--- 2.093306064605713 seconds for one epoch ---
--- 0.32071375846862793 seconds for one epoch ---
--- 2.0369958877563477 seconds for one epoch ---
--- 0.33707714080810547 seconds for one epoch ---
--- 2.059687614440918 seconds for one epoch ---
--- 0.31708669662475586 seconds for one epoch ---
--- 2.045551061630249 seconds for one epoch ---
--- 0.3416602611541748 seconds for one epoch ---
--- 2.0810599327087402 seconds for one epoch ---
--- 0.33416056632995605 seconds for one epoch ---
--- 2.1203129291534424 seconds for one epoch ---
--- 0.33980870246887207 seconds for one epoch ---
--- 2.0737926959991455 seconds for one epoch ---
--- 0.3412048816680908 seconds for one epoch ---
--- 2.118643045425415 seconds for one epoch ---
--- 0.33942246437072754 seconds for one epoch ---
--- 2.0906505584716797 seconds for one epoch ---
--- 0.33510518074035645 seconds for one epoch ---
--- 2.081753969192505 seconds for one epoch ---
--- 0.3186306953430176 seconds for one epoch ---
--- 2.091975450515747 seconds for one epoch ---
=========================
[[1.        ]
 [0.52155477]
 [0.1822614 ]
 [0.        ]
 [0.        ]
 [0.6116359 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3652458 ]
 [-0.65341103]
 [-0.49430865]
 [ 0.        ]
 [ 0.        ]
 [-0.6903025 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6478906 ]
 [ 0.        ]]
--- 0.29137086868286133 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5029.85546875, (1631.0007, 1.8229624, 3396.0647, 0.9668442)
   validation loss 958.4977416992188, (648.0424, 2.2071888, 307.28125, 0.9668442)
decoder loss ratio: 25106.288380, decoder SINDy loss  ratio: 0.663310
--- 0.26133012771606445 seconds for one epoch ---
--- 0.32326316833496094 seconds for one epoch ---
--- 2.0445263385772705 seconds for one epoch ---
--- 0.3018157482147217 seconds for one epoch ---
--- 2.0263450145721436 seconds for one epoch ---
--- 0.2862987518310547 seconds for one epoch ---
--- 2.0758697986602783 seconds for one epoch ---
--- 0.3092203140258789 seconds for one epoch ---
--- 2.0521678924560547 seconds for one epoch ---
--- 0.31497836112976074 seconds for one epoch ---
--- 2.072664260864258 seconds for one epoch ---
--- 0.29697108268737793 seconds for one epoch ---
--- 2.065842390060425 seconds for one epoch ---
--- 0.2999246120452881 seconds for one epoch ---
--- 2.054028272628784 seconds for one epoch ---
--- 0.2970137596130371 seconds for one epoch ---
--- 2.082124710083008 seconds for one epoch ---
--- 0.3025987148284912 seconds for one epoch ---
--- 2.0951738357543945 seconds for one epoch ---
--- 0.30535888671875 seconds for one epoch ---
--- 2.0886733531951904 seconds for one epoch ---
--- 0.332627534866333 seconds for one epoch ---
--- 2.1019108295440674 seconds for one epoch ---
--- 0.3271512985229492 seconds for one epoch ---
=========================
[[1.        ]
 [0.49480307]
 [0.17267269]
 [0.        ]
 [0.        ]
 [0.6250477 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3796237 ]
 [-0.64267725]
 [-0.48772547]
 [ 0.        ]
 [-0.        ]
 [-0.6960016 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6528273 ]
 [ 0.        ]]
--- 0.26190662384033203 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3650.708740234375, (1586.0776, 1.3288785, 2062.3394, 0.96283)
   validation loss 870.9847412109375, (567.76776, 2.1118667, 300.14227, 0.96283)
decoder loss ratio: 21996.308758, decoder SINDy loss  ratio: 0.647899
--- 0.2976100444793701 seconds for one epoch ---
--- 2.0839672088623047 seconds for one epoch ---
--- 0.30072832107543945 seconds for one epoch ---
--- 2.1147971153259277 seconds for one epoch ---
--- 0.30261945724487305 seconds for one epoch ---
--- 2.10284423828125 seconds for one epoch ---
--- 0.294708251953125 seconds for one epoch ---
--- 2.1152188777923584 seconds for one epoch ---
--- 0.29590773582458496 seconds for one epoch ---
--- 2.076456069946289 seconds for one epoch ---
--- 0.29692673683166504 seconds for one epoch ---
--- 2.061250686645508 seconds for one epoch ---
--- 0.6662280559539795 seconds for one epoch ---
--- 2.0570273399353027 seconds for one epoch ---
--- 0.3071446418762207 seconds for one epoch ---
--- 2.109565258026123 seconds for one epoch ---
--- 0.31223154067993164 seconds for one epoch ---
--- 2.105473756790161 seconds for one epoch ---
--- 0.3003120422363281 seconds for one epoch ---
--- 2.106309413909912 seconds for one epoch ---
--- 0.2910337448120117 seconds for one epoch ---
--- 2.101597785949707 seconds for one epoch ---
--- 0.30794501304626465 seconds for one epoch ---
--- 2.108254909515381 seconds for one epoch ---
=========================
[[1.        ]
 [0.51388633]
 [0.17839298]
 [0.        ]
 [0.        ]
 [0.61161   ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3860958 ]
 [-0.6503318 ]
 [-0.49168622]
 [-0.        ]
 [ 0.        ]
 [-0.69029135]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.6582723 ]
 [-0.        ]]
--- 0.29277634620666504 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2981.990966796875, (998.84406, 3.9576073, 1978.2244, 0.9650861)
   validation loss 936.0704345703125, (629.3046, 2.1514695, 303.6492, 0.9650861)
decoder loss ratio: 24380.353750, decoder SINDy loss  ratio: 0.655470
--- 0.2698042392730713 seconds for one epoch ---
--- 0.30761003494262695 seconds for one epoch ---
--- 2.0852103233337402 seconds for one epoch ---
--- 0.29909753799438477 seconds for one epoch ---
--- 2.0885767936706543 seconds for one epoch ---
--- 0.2991642951965332 seconds for one epoch ---
--- 2.117586612701416 seconds for one epoch ---
--- 0.31337475776672363 seconds for one epoch ---
--- 2.1137049198150635 seconds for one epoch ---
--- 0.3149878978729248 seconds for one epoch ---
--- 2.1267049312591553 seconds for one epoch ---
--- 0.27898406982421875 seconds for one epoch ---
--- 2.116184949874878 seconds for one epoch ---
--- 0.30469393730163574 seconds for one epoch ---
--- 2.0950756072998047 seconds for one epoch ---
--- 0.30469274520874023 seconds for one epoch ---
--- 2.1137611865997314 seconds for one epoch ---
--- 0.30512499809265137 seconds for one epoch ---
--- 2.0971055030822754 seconds for one epoch ---
--- 0.2859375476837158 seconds for one epoch ---
--- 2.1146135330200195 seconds for one epoch ---
--- 0.30202627182006836 seconds for one epoch ---
--- 2.1499955654144287 seconds for one epoch ---
--- 0.30246758460998535 seconds for one epoch ---
=========================
[[1.        ]
 [0.53518873]
 [0.17866217]
 [0.        ]
 [0.        ]
 [0.6137541 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3963716 ]
 [-0.65889746]
 [-0.49187005]
 [-0.        ]
 [ 0.        ]
 [-0.6911976 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.662544  ]
 [-0.        ]]
--- 0.26929354667663574 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2952.226806640625, (1406.0134, 5.2874265, 1539.9581, 0.9678564)
   validation loss 836.4529418945312, (528.812, 2.0852368, 304.58786, 0.9678564)
decoder loss ratio: 20487.095392, decoder SINDy loss  ratio: 0.657496
--- 0.3264780044555664 seconds for one epoch ---
--- 2.1155219078063965 seconds for one epoch ---
--- 0.330080509185791 seconds for one epoch ---
--- 2.087777614593506 seconds for one epoch ---
--- 0.3148646354675293 seconds for one epoch ---
--- 2.092971086502075 seconds for one epoch ---
--- 0.32323455810546875 seconds for one epoch ---
--- 2.1225473880767822 seconds for one epoch ---
--- 0.3311460018157959 seconds for one epoch ---
--- 2.1190361976623535 seconds for one epoch ---
--- 0.34409523010253906 seconds for one epoch ---
--- 2.102989435195923 seconds for one epoch ---
--- 0.35378074645996094 seconds for one epoch ---
--- 2.1319212913513184 seconds for one epoch ---
--- 0.3462517261505127 seconds for one epoch ---
--- 2.1117782592773438 seconds for one epoch ---
--- 0.34124016761779785 seconds for one epoch ---
--- 2.1574623584747314 seconds for one epoch ---
--- 0.34038853645324707 seconds for one epoch ---
--- 2.1583101749420166 seconds for one epoch ---
--- 0.3231241703033447 seconds for one epoch ---
--- 2.1656484603881836 seconds for one epoch ---
--- 0.31823134422302246 seconds for one epoch ---
--- 2.1301350593566895 seconds for one epoch ---
=========================
[[1.        ]
 [0.5553032 ]
 [0.18300441]
 [0.        ]
 [0.        ]
 [0.599559  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4036555]
 [-0.667032 ]
 [-0.4948073]
 [ 0.       ]
 [-0.       ]
 [-0.6852319]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.670478 ]
 [ 0.       ]]
--- 0.2849388122558594 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2541.43701171875, (755.23645, 0.94855195, 1784.282, 0.9700865)
   validation loss 895.8172607421875, (589.29517, 2.2025213, 303.34946, 0.9700865)
decoder loss ratio: 22830.317793, decoder SINDy loss  ratio: 0.654822
--- 0.2692873477935791 seconds for one epoch ---
--- 0.29825472831726074 seconds for one epoch ---
--- 2.1075217723846436 seconds for one epoch ---
--- 0.3053402900695801 seconds for one epoch ---
--- 2.098663091659546 seconds for one epoch ---
--- 0.30391860008239746 seconds for one epoch ---
--- 2.1325998306274414 seconds for one epoch ---
--- 0.2993903160095215 seconds for one epoch ---
--- 2.1387603282928467 seconds for one epoch ---
--- 0.2951014041900635 seconds for one epoch ---
--- 2.094348669052124 seconds for one epoch ---
--- 0.29392457008361816 seconds for one epoch ---
--- 2.1056935787200928 seconds for one epoch ---
--- 0.31094932556152344 seconds for one epoch ---
--- 2.0860559940338135 seconds for one epoch ---
--- 0.3050093650817871 seconds for one epoch ---
--- 2.139511823654175 seconds for one epoch ---
--- 0.298830509185791 seconds for one epoch ---
--- 2.119096040725708 seconds for one epoch ---
--- 0.29070019721984863 seconds for one epoch ---
--- 2.145432710647583 seconds for one epoch ---
--- 0.29880714416503906 seconds for one epoch ---
--- 2.1629955768585205 seconds for one epoch ---
--- 0.2895500659942627 seconds for one epoch ---
=========================
[[1.        ]
 [0.54156244]
 [0.17928907]
 [0.        ]
 [0.        ]
 [0.6076077 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.411799  ]
 [-0.66146857]
 [-0.49229753]
 [ 0.        ]
 [ 0.        ]
 [-0.68860483]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.667901  ]
 [ 0.        ]]
--- 0.27501964569091797 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2302.894775390625, (807.8474, 4.036159, 1490.0424, 0.96892196)
   validation loss 925.7686157226562, (606.9042, 2.2165167, 315.67902, 0.96892196)
decoder loss ratio: 23512.521364, decoder SINDy loss  ratio: 0.681438
--- 0.299152135848999 seconds for one epoch ---
--- 2.1526741981506348 seconds for one epoch ---
--- 0.3011915683746338 seconds for one epoch ---
--- 2.1550090312957764 seconds for one epoch ---
--- 0.3029756546020508 seconds for one epoch ---
--- 2.1451213359832764 seconds for one epoch ---
--- 0.2947566509246826 seconds for one epoch ---
--- 2.1574606895446777 seconds for one epoch ---
--- 0.2916417121887207 seconds for one epoch ---
--- 2.1461424827575684 seconds for one epoch ---
--- 0.3005635738372803 seconds for one epoch ---
--- 2.1426477432250977 seconds for one epoch ---
--- 0.29967737197875977 seconds for one epoch ---
--- 2.141289234161377 seconds for one epoch ---
--- 0.30411696434020996 seconds for one epoch ---
--- 2.144911289215088 seconds for one epoch ---
--- 0.3020951747894287 seconds for one epoch ---
--- 2.1711249351501465 seconds for one epoch ---
--- 0.2988743782043457 seconds for one epoch ---
--- 2.1574761867523193 seconds for one epoch ---
--- 0.2978503704071045 seconds for one epoch ---
--- 2.153585910797119 seconds for one epoch ---
--- 0.30251383781433105 seconds for one epoch ---
--- 2.1602487564086914 seconds for one epoch ---
=========================
[[1.        ]
 [0.5444026 ]
 [0.17653662]
 [0.        ]
 [0.        ]
 [0.5968883 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4193609 ]
 [-0.6626159 ]
 [-0.49041197]
 [-0.        ]
 [-0.        ]
 [-0.68411803]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.675671  ]
 [-0.        ]]
--- 0.2929110527038574 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2681.84912109375, (1572.0079, 0.75055516, 1108.1244, 0.96621)
   validation loss 898.0484008789062, (570.74506, 2.2727175, 324.06445, 0.96621)
decoder loss ratio: 22111.654332, decoder SINDy loss  ratio: 0.699539
--- 0.9874618053436279 seconds for one epoch ---
--- 0.29915475845336914 seconds for one epoch ---
--- 2.118645668029785 seconds for one epoch ---
--- 0.31102943420410156 seconds for one epoch ---
--- 2.122648000717163 seconds for one epoch ---
--- 0.30422544479370117 seconds for one epoch ---
--- 2.10526967048645 seconds for one epoch ---
--- 0.3043704032897949 seconds for one epoch ---
--- 2.1402816772460938 seconds for one epoch ---
--- 0.29968786239624023 seconds for one epoch ---
--- 2.1395883560180664 seconds for one epoch ---
--- 0.3115963935852051 seconds for one epoch ---
--- 2.127171516418457 seconds for one epoch ---
--- 0.3002750873565674 seconds for one epoch ---
--- 2.1471924781799316 seconds for one epoch ---
--- 0.30162835121154785 seconds for one epoch ---
--- 2.1207752227783203 seconds for one epoch ---
--- 0.30147361755371094 seconds for one epoch ---
--- 2.1449999809265137 seconds for one epoch ---
--- 0.30542945861816406 seconds for one epoch ---
--- 2.1703288555145264 seconds for one epoch ---
--- 0.3189811706542969 seconds for one epoch ---
--- 2.1680243015289307 seconds for one epoch ---
--- 0.2947518825531006 seconds for one epoch ---
=========================
[[1.        ]
 [0.55084896]
 [0.17634594]
 [0.        ]
 [0.        ]
 [0.5968675 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4287562 ]
 [-0.665225  ]
 [-0.49028063]
 [ 0.        ]
 [-0.        ]
 [-0.6841094 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.680273  ]
 [-0.        ]]
--- 0.2677571773529053 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3614.1904296875, (1413.0443, 3.5615377, 2196.6162, 0.9683342)
   validation loss 975.4959106445312, (654.92365, 2.1743064, 317.4296, 0.9683342)
decoder loss ratio: 25372.879006, decoder SINDy loss  ratio: 0.685216
--- 0.28971409797668457 seconds for one epoch ---
--- 2.145289897918701 seconds for one epoch ---
--- 0.30400800704956055 seconds for one epoch ---
--- 2.125887870788574 seconds for one epoch ---
--- 0.3077237606048584 seconds for one epoch ---
--- 2.1290597915649414 seconds for one epoch ---
--- 0.3115255832672119 seconds for one epoch ---
--- 2.175001382827759 seconds for one epoch ---
--- 0.3074355125427246 seconds for one epoch ---
--- 2.170170545578003 seconds for one epoch ---
--- 0.30684995651245117 seconds for one epoch ---
--- 2.170663595199585 seconds for one epoch ---
--- 0.3046138286590576 seconds for one epoch ---
--- 2.1774227619171143 seconds for one epoch ---
--- 0.295682430267334 seconds for one epoch ---
--- 2.118136405944824 seconds for one epoch ---
--- 0.29853153228759766 seconds for one epoch ---
--- 2.137162685394287 seconds for one epoch ---
--- 0.3028247356414795 seconds for one epoch ---
--- 2.1692230701446533 seconds for one epoch ---
--- 0.3116893768310547 seconds for one epoch ---
--- 2.162311553955078 seconds for one epoch ---
--- 0.3105792999267578 seconds for one epoch ---
--- 2.1609582901000977 seconds for one epoch ---
=========================
[[1.        ]
 [0.5485833 ]
 [0.18616721]
 [0.        ]
 [0.        ]
 [0.5823448 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4378526 ]
 [-0.66430736]
 [-0.49691272]
 [-0.        ]
 [-0.        ]
 [-0.67809004]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.692577  ]
 [ 0.        ]]
--- 0.3027949333190918 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2524.9228515625, (1375.83, 0.4512707, 1147.6744, 0.9672438)
   validation loss 992.1069946289062, (667.59454, 2.0249114, 321.5203, 0.9672438)
decoder loss ratio: 25863.771609, decoder SINDy loss  ratio: 0.694047
--- 0.26082301139831543 seconds for one epoch ---
--- 0.2983112335205078 seconds for one epoch ---
--- 2.1636974811553955 seconds for one epoch ---
--- 0.3011047840118408 seconds for one epoch ---
--- 2.1704139709472656 seconds for one epoch ---
--- 0.29692840576171875 seconds for one epoch ---
--- 2.1684670448303223 seconds for one epoch ---
--- 0.30844807624816895 seconds for one epoch ---
--- 2.1802804470062256 seconds for one epoch ---
--- 0.3030726909637451 seconds for one epoch ---
--- 2.194167137145996 seconds for one epoch ---
--- 0.2953453063964844 seconds for one epoch ---
--- 2.147974729537964 seconds for one epoch ---
--- 0.3001384735107422 seconds for one epoch ---
--- 2.149381399154663 seconds for one epoch ---
--- 0.29353857040405273 seconds for one epoch ---
--- 2.1966545581817627 seconds for one epoch ---
--- 0.2964754104614258 seconds for one epoch ---
--- 2.175771713256836 seconds for one epoch ---
--- 0.29988765716552734 seconds for one epoch ---
--- 2.1828274726867676 seconds for one epoch ---
--- 0.3048214912414551 seconds for one epoch ---
--- 2.1802334785461426 seconds for one epoch ---
--- 0.29892849922180176 seconds for one epoch ---
=========================
[[1.        ]
 [0.5562122 ]
 [0.18106636]
 [0.        ]
 [0.        ]
 [0.58418405]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4451923 ]
 [-0.6674012 ]
 [-0.49350312]
 [-0.        ]
 [ 0.        ]
 [-0.67884916]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.694399  ]
 [ 0.        ]]
--- 0.2636692523956299 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6414.5302734375, (2011.1697, 1.0379958, 4401.355, 0.9675779)
   validation loss 885.2999877929688, (570.28375, 2.1282437, 311.9204, 0.9675779)
decoder loss ratio: 22093.782626, decoder SINDy loss  ratio: 0.673324
--- 0.3019075393676758 seconds for one epoch ---
--- 2.187950611114502 seconds for one epoch ---
--- 0.30260157585144043 seconds for one epoch ---
--- 2.203831195831299 seconds for one epoch ---
--- 0.29193949699401855 seconds for one epoch ---
--- 2.1822614669799805 seconds for one epoch ---
--- 0.30402565002441406 seconds for one epoch ---
--- 2.2019941806793213 seconds for one epoch ---
--- 0.3079719543457031 seconds for one epoch ---
--- 2.1958866119384766 seconds for one epoch ---
--- 0.3008418083190918 seconds for one epoch ---
--- 2.1831271648406982 seconds for one epoch ---
--- 0.3089327812194824 seconds for one epoch ---
--- 2.172154664993286 seconds for one epoch ---
--- 0.30187153816223145 seconds for one epoch ---
--- 2.1616222858428955 seconds for one epoch ---
--- 0.31348133087158203 seconds for one epoch ---
--- 2.189868211746216 seconds for one epoch ---
--- 0.29989194869995117 seconds for one epoch ---
--- 2.159262180328369 seconds for one epoch ---
--- 0.3033616542816162 seconds for one epoch ---
--- 2.180690288543701 seconds for one epoch ---
--- 0.30701446533203125 seconds for one epoch ---
--- 2.1663389205932617 seconds for one epoch ---
=========================
[[1.        ]
 [0.5572572 ]
 [0.17630559]
 [0.        ]
 [0.        ]
 [0.5759115 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.450638  ]
 [-0.6678259 ]
 [-0.49025285]
 [ 0.        ]
 [-0.        ]
 [-0.6754439 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6974907 ]
 [-0.        ]]
--- 0.2997264862060547 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2672.39990234375, (888.02765, 0.6428832, 1782.7637, 0.9657914)
   validation loss 1039.530029296875, (725.1897, 2.042897, 311.3316, 0.9657914)
decoder loss ratio: 28095.107857, decoder SINDy loss  ratio: 0.672053
THRESHOLDING: 5 active coefficients
REFINEMENT
=========================
[[1.        ]
 [0.55714715]
 [0.1769882 ]
 [0.        ]
 [0.        ]
 [0.5731064 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4495277]
 [-0.6677814]
 [-0.4907228]
 [ 0.       ]
 [ 0.       ]
 [-0.6742929]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6967897]
 [-0.       ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1283.800048828125, (636.6926, 1.452162, 645.6553, 0.9659401)
   validation loss 830.8539428710938, (535.01276, 1.7244351, 294.11676, 0.9659401)
decoder loss ratio: 20727.323004, decoder SINDy loss  ratio: 0.634892
=========================
[[1.        ]
 [0.54747564]
 [0.16679975]
 [0.        ]
 [0.        ]
 [0.5804413 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.443682  ]
 [-0.6862996 ]
 [-0.58554834]
 [ 0.        ]
 [-0.        ]
 [-0.7451797 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.617324  ]
 [ 0.        ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 823.084716796875, (326.14917, 0.90131795, 496.03427, 0.961253)
   validation loss 486.37701416015625, (246.39104, 0.2423575, 239.74362, 0.961253)
decoder loss ratio: 9545.616527, decoder SINDy loss  ratio: 0.517520
=========================
[[1.        ]
 [0.35596   ]
 [0.18697006]
 [0.        ]
 [0.        ]
 [0.5183495 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3281949]
 [-0.6197244]
 [-0.59675  ]
 [ 0.       ]
 [ 0.       ]
 [-0.706182 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5855265]
 [ 0.       ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.3828735351562, (286.17126, 0.52429235, 482.68732, 0.92607254)
   validation loss 450.63134765625, (219.17162, 0.17261605, 231.28711, 0.92607254)
decoder loss ratio: 8491.088887, decoder SINDy loss  ratio: 0.499266
=========================
[[1.        ]
 [0.22052956]
 [0.20805706]
 [0.        ]
 [0.        ]
 [0.48873234]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3400595 ]
 [-0.53182393]
 [-0.5277408 ]
 [ 0.        ]
 [ 0.        ]
 [-0.6007117 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.359777  ]
 [-0.        ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.8859252929688, (298.57623, 0.3730318, 480.93665, 0.8995587)
   validation loss 459.0021667480469, (231.31067, 0.15086745, 227.54063, 0.8995587)
decoder loss ratio: 8961.376888, decoder SINDy loss  ratio: 0.491178
=========================
[[1.        ]
 [0.15543719]
 [0.20696534]
 [0.        ]
 [0.        ]
 [0.5005591 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.250962  ]
 [-0.44864553]
 [-0.50169367]
 [ 0.        ]
 [-0.        ]
 [-0.67283934]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3337264 ]
 [-0.        ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 771.3695068359375, (307.77493, 0.28404155, 463.31055, 0.8853384)
   validation loss 486.1832275390625, (259.54178, 0.110830694, 226.53061, 0.8853384)
decoder loss ratio: 10055.099086, decoder SINDy loss  ratio: 0.488998
=========================
[[1.        ]
 [0.13817143]
 [0.19663951]
 [0.        ]
 [0.        ]
 [0.5158988 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2134838 ]
 [-0.4486596 ]
 [-0.46199828]
 [ 0.        ]
 [ 0.        ]
 [-0.6552293 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.1524067 ]
 [ 0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.221923828125, (237.77377, 0.24078073, 466.20737, 0.88001406)
   validation loss 404.5178527832031, (181.93861, 0.11139105, 222.46785, 0.88001406)
decoder loss ratio: 7048.617761, decoder SINDy loss  ratio: 0.480228
=========================
[[1.        ]
 [0.1314472 ]
 [0.19201466]
 [0.        ]
 [0.        ]
 [0.5189839 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2407517 ]
 [-0.44327933]
 [-0.3799312 ]
 [ 0.        ]
 [-0.        ]
 [-0.5274028 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.0756803 ]
 [-0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.2465209960938, (238.30016, 0.21704917, 458.7293, 0.8756321)
   validation loss 404.2135009765625, (182.76007, 0.11049658, 221.34294, 0.8756321)
decoder loss ratio: 7080.442428, decoder SINDy loss  ratio: 0.477800
=========================
[[1.        ]
 [0.1192711 ]
 [0.19386983]
 [0.        ]
 [0.        ]
 [0.52676815]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1649692 ]
 [-0.4750315 ]
 [-0.4468708 ]
 [ 0.        ]
 [ 0.        ]
 [-0.64657784]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.9305587 ]
 [-0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.2994384765625, (317.12906, 0.21239872, 476.95795, 0.8725179)
   validation loss 491.6142578125, (267.13983, 0.11253591, 224.3619, 0.8725179)
decoder loss ratio: 10349.460849, decoder SINDy loss  ratio: 0.484317
=========================
[[1.        ]
 [0.11967271]
 [0.1962614 ]
 [0.        ]
 [0.        ]
 [0.533564  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.081778  ]
 [-0.4037205 ]
 [-0.57083875]
 [-0.        ]
 [-0.        ]
 [-0.66874033]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.7656295 ]
 [ 0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.5501098632812, (267.35968, 0.20002437, 464.99042, 0.87415993)
   validation loss 443.08831787109375, (221.04758, 0.11482187, 221.92592, 0.87415993)
decoder loss ratio: 8563.766885, decoder SINDy loss  ratio: 0.479058
=========================
[[1.        ]
 [0.11778055]
 [0.20246038]
 [0.        ]
 [0.        ]
 [0.534037  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.164     ]
 [-0.4640032 ]
 [-0.57461065]
 [-0.        ]
 [ 0.        ]
 [-0.63706076]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7216794 ]
 [ 0.        ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 977.4642333984375, (484.99597, 0.20257671, 492.26566, 0.8736108)
   validation loss 668.5801391601562, (437.71082, 0.11642651, 230.75288, 0.8736108)
decoder loss ratio: 16957.676889, decoder SINDy loss  ratio: 0.498113
=========================
[[1.        ]
 [0.1178795 ]
 [0.20480764]
 [0.        ]
 [0.        ]
 [0.5424767 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1998248 ]
 [-0.5267629 ]
 [-0.52394074]
 [ 0.        ]
 [ 0.        ]
 [-0.64740705]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.6400313 ]
 [ 0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.5888671875, (293.4501, 0.20192753, 450.93683, 0.87648547)
   validation loss 442.9222717285156, (221.91142, 0.11253803, 220.89832, 0.87648547)
decoder loss ratio: 8597.233772, decoder SINDy loss  ratio: 0.476840
=========================
[[1.        ]
 [0.11950357]
 [0.21085182]
 [0.        ]
 [0.        ]
 [0.5376506 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.057999  ]
 [-0.4308201 ]
 [-0.49934682]
 [ 0.        ]
 [ 0.        ]
 [-0.58659667]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.616138  ]
 [-0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.725830078125, (272.40408, 0.19780353, 465.12396, 0.8762793)
   validation loss 452.36212158203125, (229.51598, 0.115166724, 222.73099, 0.8762793)
decoder loss ratio: 8891.847366, decoder SINDy loss  ratio: 0.480796
=========================
[[1.        ]
 [0.12358604]
 [0.21325639]
 [0.        ]
 [0.        ]
 [0.5525211 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.049885  ]
 [-0.449717  ]
 [-0.575403  ]
 [ 0.        ]
 [-0.        ]
 [-0.73532903]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.5136542 ]
 [ 0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 845.0433349609375, (393.60297, 0.2082849, 451.2321, 0.88137054)
   validation loss 523.2322998046875, (300.37094, 0.11933049, 222.742, 0.88137054)
decoder loss ratio: 11636.891728, decoder SINDy loss  ratio: 0.480820
=========================
[[1.        ]
 [0.12979501]
 [0.21757162]
 [0.        ]
 [0.        ]
 [0.55344725]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0610862 ]
 [-0.3793554 ]
 [-0.5521172 ]
 [ 0.        ]
 [-0.        ]
 [-0.63549656]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.470947  ]
 [-0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1005.0372314453125, (513.7465, 0.20843518, 491.08224, 0.8818151)
   validation loss 711.617431640625, (478.46335, 0.12496928, 233.02908, 0.8818151)
decoder loss ratio: 18536.500765, decoder SINDy loss  ratio: 0.503026
=========================
[[1.        ]
 [0.13311766]
 [0.21658225]
 [0.        ]
 [0.        ]
 [0.5586851 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9618495 ]
 [-0.44113284]
 [-0.5418199 ]
 [ 0.        ]
 [-0.        ]
 [-0.62666446]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3458998 ]
 [ 0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.7384033203125, (376.3841, 0.21347505, 451.14087, 0.8849152)
   validation loss 499.37042236328125, (277.10562, 0.12426734, 222.14053, 0.8849152)
decoder loss ratio: 10735.552847, decoder SINDy loss  ratio: 0.479522
=========================
[[1.        ]
 [0.13716365]
 [0.22277322]
 [0.        ]
 [0.        ]
 [0.55416703]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0177464 ]
 [-0.47593096]
 [-0.48607838]
 [-0.        ]
 [ 0.        ]
 [-0.56534356]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.259744  ]
 [-0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 848.089111328125, (369.95508, 0.20830446, 477.92572, 0.884569)
   validation loss 558.4470825195312, (330.2689, 0.12971619, 228.04848, 0.884569)
decoder loss ratio: 12795.190185, decoder SINDy loss  ratio: 0.492275
=========================
[[1.        ]
 [0.13997883]
 [0.22302057]
 [0.        ]
 [0.        ]
 [0.56022173]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0392587 ]
 [-0.59400886]
 [-0.5304335 ]
 [ 0.        ]
 [-0.        ]
 [-0.6739844 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1991537 ]
 [-0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.525634765625, (298.5171, 0.20575517, 445.80283, 0.8873278)
   validation loss 443.37823486328125, (222.95895, 0.13225313, 220.28702, 0.8873278)
decoder loss ratio: 8637.816946, decoder SINDy loss  ratio: 0.475521
=========================
[[1.        ]
 [0.14883219]
 [0.22495675]
 [0.        ]
 [0.        ]
 [0.5634594 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0038452 ]
 [-0.49635428]
 [-0.55161786]
 [ 0.        ]
 [-0.        ]
 [-0.7005326 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.2464309 ]
 [ 0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 891.6646118164062, (412.44928, 0.20826013, 479.00708, 0.8889427)
   validation loss 606.751220703125, (377.05148, 0.13835517, 229.56139, 0.8889427)
decoder loss ratio: 14607.629048, decoder SINDy loss  ratio: 0.495541
=========================
[[1.        ]
 [0.14957315]
 [0.22565138]
 [0.        ]
 [0.        ]
 [0.5648954 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1665137 ]
 [-0.47758216]
 [-0.4663998 ]
 [ 0.        ]
 [ 0.        ]
 [-0.6067312 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1947932 ]
 [ 0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.087890625, (224.86038, 0.2134632, 448.01407, 0.89042777)
   validation loss 387.11737060546875, (167.81876, 0.13863765, 219.15996, 0.89042777)
decoder loss ratio: 6501.589958, decoder SINDy loss  ratio: 0.473088
=========================
[[1.        ]
 [0.15800539]
 [0.2260155 ]
 [0.        ]
 [0.        ]
 [0.5693804 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.057623  ]
 [-0.42531312]
 [-0.58737034]
 [ 0.        ]
 [-0.        ]
 [-0.7056772 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.0962203 ]
 [ 0.        ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1137.0859375, (637.31415, 0.21392609, 499.55783, 0.8917019)
   validation loss 839.322998046875, (600.72253, 0.14621592, 238.45422, 0.8917019)
decoder loss ratio: 23273.033874, decoder SINDy loss  ratio: 0.514737
=========================
[[1.        ]
 [0.15810753]
 [0.22812364]
 [0.        ]
 [0.        ]
 [0.5675781 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.010445  ]
 [-0.4347743 ]
 [-0.49274674]
 [-0.        ]
 [-0.        ]
 [-0.6383097 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.078786  ]
 [-0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.1512451171875, (260.77512, 0.23263462, 447.14352, 0.89449674)
   validation loss 411.17352294921875, (191.52876, 0.14899604, 219.49577, 0.89449674)
decoder loss ratio: 7420.156780, decoder SINDy loss  ratio: 0.473813
=========================
[[1.        ]
 [0.1642868 ]
 [0.22813123]
 [0.        ]
 [0.        ]
 [0.5670817 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0255299 ]
 [-0.48714617]
 [-0.47729176]
 [ 0.        ]
 [ 0.        ]
 [-0.6678361 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.0494    ]
 [ 0.        ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.0891723632812, (217.71872, 0.22447202, 450.146, 0.8937605)
   validation loss 386.2005615234375, (166.14244, 0.14665511, 219.91147, 0.8937605)
decoder loss ratio: 6436.646592, decoder SINDy loss  ratio: 0.474710
=========================
[[1.        ]
 [0.16602446]
 [0.2251038 ]
 [0.        ]
 [0.        ]
 [0.56860197]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0389962]
 [-0.3964002]
 [-0.5142758]
 [-0.       ]
 [-0.       ]
 [-0.7504523]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.9660995]
 [-0.       ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.9373168945312, (419.13287, 0.21803981, 443.5864, 0.894358)
   validation loss 550.9464721679688, (327.94116, 0.14895706, 222.85637, 0.894358)
decoder loss ratio: 12705.009951, decoder SINDy loss  ratio: 0.481067
=========================
[[1.        ]
 [0.16930929]
 [0.22435759]
 [0.        ]
 [0.        ]
 [0.56596875]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1084828 ]
 [-0.50387657]
 [-0.5600573 ]
 [ 0.        ]
 [ 0.        ]
 [-0.6654159 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.9601889 ]
 [-0.        ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1083.82080078125, (589.5442, 0.22104517, 494.0555, 0.8931576)
   validation loss 791.6767578125, (554.34094, 0.15386842, 237.18196, 0.8931576)
decoder loss ratio: 21476.130486, decoder SINDy loss  ratio: 0.511991
=========================
[[1.        ]
 [0.16679375]
 [0.22479424]
 [0.        ]
 [0.        ]
 [0.5608926 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0609531]
 [-0.4952098]
 [-0.5314186]
 [ 0.       ]
 [ 0.       ]
 [-0.6972991]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.969048 ]
 [-0.       ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.5909423828125, (315.41623, 0.23795617, 445.93677, 0.89476126)
   validation loss 452.7115783691406, (232.14178, 0.15658233, 220.41321, 0.89476126)
decoder loss ratio: 8993.575754, decoder SINDy loss  ratio: 0.475793
=========================
[[1.        ]
 [0.17471187]
 [0.22321376]
 [0.        ]
 [0.        ]
 [0.5603561 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.056717  ]
 [-0.42543504]
 [-0.59175026]
 [ 0.        ]
 [-0.        ]
 [-0.6541874 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9912236 ]
 [-0.        ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.094970703125, (216.60474, 0.22979741, 448.2604, 0.8939726)
   validation loss 384.90130615234375, (164.74086, 0.15330683, 220.00714, 0.8939726)
decoder loss ratio: 6382.346919, decoder SINDy loss  ratio: 0.474916
=========================
[[1.        ]
 [0.17560373]
 [0.21942733]
 [0.        ]
 [0.        ]
 [0.56001484]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1333704 ]
 [-0.47360313]
 [-0.53610235]
 [ 0.        ]
 [-0.        ]
 [-0.5442652 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.959908  ]
 [-0.        ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 847.588623046875, (405.1405, 0.22143628, 442.2267, 0.89393437)
   validation loss 537.2257080078125, (314.5396, 0.15639678, 222.52968, 0.89393437)
decoder loss ratio: 12185.810627, decoder SINDy loss  ratio: 0.480362
=========================
[[1.        ]
 [0.17841989]
 [0.21770689]
 [0.        ]
 [0.        ]
 [0.55570346]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0538027 ]
 [-0.49155948]
 [-0.58070225]
 [-0.        ]
 [-0.        ]
 [-0.6287524 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9375503 ]
 [ 0.        ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1078.47509765625, (586.31134, 0.22786123, 491.9359, 0.8922319)
   validation loss 791.541259765625, (553.83856, 0.15783888, 237.54486, 0.8922319)
decoder loss ratio: 21456.667398, decoder SINDy loss  ratio: 0.512774
=========================
[[1.        ]
 [0.17628239]
 [0.2172386 ]
 [0.        ]
 [0.        ]
 [0.5498557 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1212528 ]
 [-0.5332744 ]
 [-0.57025814]
 [ 0.        ]
 [-0.        ]
 [-0.63920283]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8396993 ]
 [-0.        ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.9237060546875, (334.5814, 0.24128988, 445.101, 0.8936057)
   validation loss 468.08001708984375, (247.05656, 0.16167924, 220.86179, 0.8936057)
decoder loss ratio: 9571.400211, decoder SINDy loss  ratio: 0.476761
=========================
[[1.        ]
 [0.18398125]
 [0.21493563]
 [0.        ]
 [0.        ]
 [0.54793626]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1283617 ]
 [-0.487437  ]
 [-0.5938209 ]
 [ 0.        ]
 [ 0.        ]
 [-0.69308364]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8556018 ]
 [ 0.        ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.6235961914062, (216.27995, 0.23285513, 448.11078, 0.8922327)
   validation loss 386.481689453125, (165.91154, 0.15663704, 220.41351, 0.8922327)
decoder loss ratio: 6427.701281, decoder SINDy loss  ratio: 0.475794
=========================
[[1.        ]
 [0.1837892 ]
 [0.21039979]
 [0.        ]
 [0.        ]
 [0.5463511 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0701609 ]
 [-0.52978706]
 [-0.5431798 ]
 [-0.        ]
 [ 0.        ]
 [-0.5854947 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8607094 ]
 [ 0.        ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 843.775390625, (402.33957, 0.22376144, 441.21204, 0.8918056)
   validation loss 534.8427734375, (312.16068, 0.16053678, 222.52156, 0.8918056)
decoder loss ratio: 12093.646486, decoder SINDy loss  ratio: 0.480344
=========================
[[1.        ]
 [0.18654454]
 [0.2082339 ]
 [0.        ]
 [0.        ]
 [0.54109895]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.130856  ]
 [-0.49012867]
 [-0.5012897 ]
 [-0.        ]
 [ 0.        ]
 [-0.5849353 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7613716 ]
 [ 0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1066.5845947265625, (576.68304, 0.23306891, 489.66843, 0.88986)
   validation loss 783.310546875, (545.7073, 0.15940966, 237.44382, 0.88986)
decoder loss ratio: 21141.647238, decoder SINDy loss  ratio: 0.512556
=========================
[[1.       ]
 [0.1838125]
 [0.2068924]
 [0.       ]
 [0.       ]
 [0.5343035]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.1279058 ]
 [-0.4706087 ]
 [-0.5258163 ]
 [-0.        ]
 [-0.        ]
 [-0.66627264]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.793348  ]
 [-0.        ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.5882568359375, (342.13956, 0.2437204, 444.20502, 0.89071864)
   validation loss 472.92303466796875, (251.80972, 0.16450083, 220.94879, 0.89071864)
decoder loss ratio: 9755.545826, decoder SINDy loss  ratio: 0.476949
=========================
[[1.        ]
 [0.19152483]
 [0.20443472]
 [0.        ]
 [0.        ]
 [0.5309454 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1698728 ]
 [-0.51121473]
 [-0.48332268]
 [-0.        ]
 [ 0.        ]
 [-0.6313697 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7118125 ]
 [-0.        ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.666748046875, (217.31491, 0.235352, 448.1165, 0.8890514)
   validation loss 389.37139892578125, (168.44746, 0.15766062, 220.76628, 0.8890514)
decoder loss ratio: 6525.947193, decoder SINDy loss  ratio: 0.476555
=========================
[[1.        ]
 [0.19032876]
 [0.19928703]
 [0.        ]
 [0.        ]
 [0.52872115]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.088488  ]
 [-0.54101306]
 [-0.4759128 ]
 [ 0.        ]
 [ 0.        ]
 [-0.60858107]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6603756 ]
 [ 0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 832.2997436523438, (391.92328, 0.2259463, 440.1505, 0.8882578)
   validation loss 523.5696411132812, (301.2517, 0.16265659, 222.15527, 0.8882578)
decoder loss ratio: 11671.014202, decoder SINDy loss  ratio: 0.479553
=========================
[[1.        ]
 [0.19290863]
 [0.19689162]
 [0.        ]
 [0.        ]
 [0.5222773 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1548138 ]
 [-0.5391629 ]
 [-0.51109755]
 [-0.        ]
 [ 0.        ]
 [-0.63516515]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7946038 ]
 [-0.        ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1091.283203125, (600.60895, 0.23866403, 490.43564, 0.8860264)
   validation loss 810.698486328125, (571.96173, 0.1592247, 238.57755, 0.8860264)
decoder loss ratio: 22158.790427, decoder SINDy loss  ratio: 0.515003
=========================
[[1.        ]
 [0.18996906]
 [0.19476846]
 [0.        ]
 [0.        ]
 [0.5148454 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2024872 ]
 [-0.5212395 ]
 [-0.44195193]
 [ 0.        ]
 [ 0.        ]
 [-0.64222914]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6441953 ]
 [-0.        ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 802.383056640625, (358.38763, 0.24578412, 443.74963, 0.8865701)
   validation loss 485.48712158203125, (264.13135, 0.16558684, 221.19019, 0.8865701)
decoder loss ratio: 10232.906960, decoder SINDy loss  ratio: 0.477470
=========================
[[1.        ]
 [0.1973465 ]
 [0.19194707]
 [0.        ]
 [0.        ]
 [0.5105566 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.218168  ]
 [-0.48169014]
 [-0.5131467 ]
 [-0.        ]
 [ 0.        ]
 [-0.70801234]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6568742 ]
 [ 0.        ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.0753173828125, (218.80177, 0.23744455, 448.03607, 0.88453037)
   validation loss 392.36822509765625, (171.25336, 0.15732758, 220.95753, 0.88453037)
decoder loss ratio: 6634.652357, decoder SINDy loss  ratio: 0.476968
=========================
[[1.        ]
 [0.19578947]
 [0.18639052]
 [0.        ]
 [0.        ]
 [0.50739473]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1620152]
 [-0.4867919]
 [-0.5276245]
 [-0.       ]
 [ 0.       ]
 [-0.6926517]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.7604313]
 [ 0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.973388671875, (388.47452, 0.22659208, 439.2723, 0.8834629)
   validation loss 520.5670166015625, (298.4035, 0.16293785, 222.00058, 0.8834629)
decoder loss ratio: 11560.669774, decoder SINDy loss  ratio: 0.479219
=========================
[[1.        ]
 [0.19845493]
 [0.18386438]
 [0.        ]
 [0.        ]
 [0.49996752]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2821472 ]
 [-0.48299545]
 [-0.5055224 ]
 [ 0.        ]
 [-0.        ]
 [-0.64381385]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7498767 ]
 [-0.        ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1088.3839111328125, (598.9064, 0.24183097, 489.23572, 0.88107425)
   validation loss 808.6882934570312, (570.04663, 0.15772529, 238.48395, 0.88107425)
decoder loss ratio: 22084.596124, decoder SINDy loss  ratio: 0.514801
=========================
[[1.        ]
 [0.1957401 ]
 [0.18111922]
 [0.        ]
 [0.        ]
 [0.49173096]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.267425  ]
 [-0.45044264]
 [-0.5045266 ]
 [-0.        ]
 [-0.        ]
 [-0.58280814]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6496885 ]
 [ 0.        ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.623291015625, (356.5377, 0.245682, 442.8399, 0.88127583)
   validation loss 482.6958312988281, (261.56784, 0.16528557, 220.9627, 0.88127583)
decoder loss ratio: 10133.592246, decoder SINDy loss  ratio: 0.476979
=========================
[[1.        ]
 [0.20297123]
 [0.17787963]
 [0.        ]
 [0.        ]
 [0.48657966]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3402665 ]
 [-0.5726538 ]
 [-0.44915178]
 [-0.        ]
 [ 0.        ]
 [-0.6511436 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.6638184 ]
 [-0.        ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.774658203125, (218.46387, 0.23619577, 447.0746, 0.87899524)
   validation loss 391.33477783203125, (170.30841, 0.15580563, 220.87057, 0.87899524)
decoder loss ratio: 6598.043497, decoder SINDy loss  ratio: 0.476780
=========================
[[1.        ]
 [0.20146406]
 [0.17202875]
 [0.        ]
 [0.        ]
 [0.4826957 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.2875695 ]
 [-0.4920262 ]
 [-0.48469707]
 [ 0.        ]
 [ 0.        ]
 [-0.63500005]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7803583 ]
 [ 0.        ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.5670166015625, (371.2151, 0.22569375, 438.12622, 0.87769336)
   validation loss 504.71380615234375, (283.0868, 0.16193095, 221.46507, 0.87769336)
decoder loss ratio: 10967.273782, decoder SINDy loss  ratio: 0.478064
=========================
[[1.        ]
 [0.2042567 ]
 [0.1685844 ]
 [0.        ]
 [0.        ]
 [0.47509348]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3397102]
 [-0.5009926]
 [-0.5213741]
 [ 0.       ]
 [ 0.       ]
 [-0.6173067]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.5887928]
 [ 0.       ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1053.864501953125, (567.8074, 0.24196047, 485.81516, 0.8750839)
   validation loss 776.9847412109375, (539.5862, 0.15597634, 237.24257, 0.8750839)
decoder loss ratio: 20904.505440, decoder SINDy loss  ratio: 0.512121
=========================
[[1.        ]
 [0.20153406]
 [0.16548833]
 [0.        ]
 [0.        ]
 [0.46638134]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3679366 ]
 [-0.47456637]
 [-0.491408  ]
 [-0.        ]
 [ 0.        ]
 [-0.6596696 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6127353 ]
 [ 0.        ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.4703369140625, (320.17242, 0.24435876, 441.0536, 0.87489146)
   validation loss 452.860107421875, (232.69888, 0.16389087, 219.99734, 0.87489146)
decoder loss ratio: 9015.158713, decoder SINDy loss  ratio: 0.474895
=========================
[[1.        ]
 [0.20790108]
 [0.16153553]
 [0.        ]
 [0.        ]
 [0.4610256 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.313355  ]
 [-0.54956114]
 [-0.496206  ]
 [ 0.        ]
 [-0.        ]
 [-0.6058643 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.579407  ]
 [-0.        ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.199951171875, (215.98325, 0.23559809, 444.98108, 0.8724925)
   validation loss 387.8851013183594, (167.41664, 0.15472825, 220.31374, 0.8724925)
decoder loss ratio: 6486.011330, decoder SINDy loss  ratio: 0.475578
=========================
[[1.        ]
 [0.2068437 ]
 [0.15533893]
 [0.        ]
 [0.        ]
 [0.4569492 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3645513 ]
 [-0.4608794 ]
 [-0.51110023]
 [ 0.        ]
 [-0.        ]
 [-0.6638291 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5950077 ]
 [-0.        ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.7119140625, (429.04306, 0.22364631, 438.44525, 0.8709574)
   validation loss 555.603515625, (332.8681, 0.16069002, 222.57474, 0.8709574)
decoder loss ratio: 12895.888196, decoder SINDy loss  ratio: 0.480459
=========================
[[1.        ]
 [0.20983401]
 [0.15121105]
 [0.        ]
 [0.        ]
 [0.4489008 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.392735  ]
 [-0.53454834]
 [-0.44288352]
 [-0.        ]
 [-0.        ]
 [-0.5877555 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.58738   ]
 [-0.        ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1022.8515625, (539.44104, 0.24046881, 483.17004, 0.8679902)
   validation loss 744.526123046875, (508.46457, 0.15352573, 235.90802, 0.8679902)
decoder loss ratio: 19698.800140, decoder SINDy loss  ratio: 0.509241
=========================
[[1.        ]
 [0.20651108]
 [0.14782709]
 [0.        ]
 [0.        ]
 [0.4396124 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.45036   ]
 [-0.47192508]
 [-0.4878559 ]
 [-0.        ]
 [-0.        ]
 [-0.65244234]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.6132343 ]
 [ 0.        ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.3792114257812, (278.20938, 0.24536796, 439.92447, 0.8673956)
   validation loss 420.39276123046875, (201.19337, 0.16182196, 219.03757, 0.8673956)
decoder loss ratio: 7794.580620, decoder SINDy loss  ratio: 0.472823
=========================
[[1.        ]
 [0.21247691]
 [0.14344797]
 [0.        ]
 [0.        ]
 [0.4339012 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4298573]
 [-0.5300277]
 [-0.4985775]
 [-0.       ]
 [-0.       ]
 [-0.6538474]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.5784655]
 [-0.       ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.3236083984375, (216.64702, 0.23663706, 444.43997, 0.86490315)
   validation loss 389.42352294921875, (169.26826, 0.15332621, 220.00194, 0.86490315)
decoder loss ratio: 6557.746440, decoder SINDy loss  ratio: 0.474905
=========================
[[1.        ]
 [0.21204397]
 [0.13702391]
 [0.        ]
 [0.        ]
 [0.42920417]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4969618 ]
 [-0.5616625 ]
 [-0.49247393]
 [-0.        ]
 [ 0.        ]
 [-0.6082932 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.619918  ]
 [-0.        ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 927.453125, (487.79315, 0.22188163, 439.4381, 0.8631441)
   validation loss 607.403076171875, (383.5259, 0.15910868, 223.71806, 0.8631441)
decoder loss ratio: 14858.459561, decoder SINDy loss  ratio: 0.482927
=========================
[[1.        ]
 [0.21552452]
 [0.1325241 ]
 [0.        ]
 [0.        ]
 [0.4206843 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.532502  ]
 [-0.493919  ]
 [-0.50698483]
 [ 0.        ]
 [ 0.        ]
 [-0.75094485]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.5681045 ]
 [-0.        ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1005.6565551757812, (524.2161, 0.23908849, 481.20135, 0.85987806)
   validation loss 728.2640380859375, (493.2109, 0.15070681, 234.90242, 0.85987806)
decoder loss ratio: 19107.846788, decoder SINDy loss  ratio: 0.507070
=========================
[[1.        ]
 [0.21213073]
 [0.12882122]
 [0.        ]
 [0.        ]
 [0.41096985]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.461335  ]
 [-0.45259154]
 [-0.4328641 ]
 [ 0.        ]
 [-0.        ]
 [-0.54719216]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6374478 ]
 [ 0.        ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.569091796875, (262.12186, 0.2440686, 439.20316, 0.8589458)
   validation loss 408.13958740234375, (189.49281, 0.15922382, 218.48756, 0.8589458)
decoder loss ratio: 7341.280554, decoder SINDy loss  ratio: 0.471636
=========================
[[1.        ]
 [0.21800488]
 [0.12420282]
 [0.        ]
 [0.        ]
 [0.40459096]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.525542  ]
 [-0.51692665]
 [-0.4779611 ]
 [-0.        ]
 [-0.        ]
 [-0.5341057 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5524864 ]
 [-0.        ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.5924072265625, (216.83821, 0.23463495, 443.51953, 0.856262)
   validation loss 389.28765869140625, (169.5888, 0.15078035, 219.54808, 0.856262)
decoder loss ratio: 6570.164769, decoder SINDy loss  ratio: 0.473925
=========================
[[1.        ]
 [0.21800715]
 [0.11790857]
 [0.        ]
 [0.        ]
 [0.3990749 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5409994]
 [-0.5398204]
 [-0.3436666]
 [ 0.       ]
 [-0.       ]
 [-0.6192653]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.615925 ]
 [ 0.       ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 952.156005859375, (512.4532, 0.21915124, 439.48364, 0.8543215)
   validation loss 628.8988037109375, (404.7897, 0.15660341, 223.95245, 0.8543215)
decoder loss ratio: 15682.255854, decoder SINDy loss  ratio: 0.483433
=========================
[[1.        ]
 [0.2219362 ]
 [0.11333423]
 [0.        ]
 [0.        ]
 [0.3899715 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6013627 ]
 [-0.47830072]
 [-0.4669778 ]
 [ 0.        ]
 [-0.        ]
 [-0.6154711 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5640428 ]
 [ 0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1036.360107421875, (553.20276, 0.2392987, 482.91797, 0.8508717)
   validation loss 757.6260375976562, (521.8974, 0.14756386, 235.58107, 0.8508717)
decoder loss ratio: 20219.211326, decoder SINDy loss  ratio: 0.508535
=========================
[[1.        ]
 [0.21901533]
 [0.10951319]
 [0.        ]
 [0.        ]
 [0.37980443]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5959384 ]
 [-0.4830446 ]
 [-0.47691548]
 [-0.        ]
 [ 0.        ]
 [-0.5981966 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6758568 ]
 [ 0.        ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.8983154296875, (251.30809, 0.24597631, 439.34427, 0.849867)
   validation loss 400.8372802734375, (182.59534, 0.15657888, 218.08537, 0.849867)
decoder loss ratio: 7074.060351, decoder SINDy loss  ratio: 0.470768
=========================
[[1.        ]
 [0.22567423]
 [0.10503823]
 [0.        ]
 [0.        ]
 [0.37324238]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6142044]
 [-0.4452638]
 [-0.436885 ]
 [-0.       ]
 [ 0.       ]
 [-0.7247014]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.6140788]
 [-0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.34619140625, (222.50546, 0.23603591, 444.6047, 0.84726125)
   validation loss 397.2412414550781, (177.54924, 0.14837773, 219.54362, 0.84726125)
decoder loss ratio: 6878.565801, decoder SINDy loss  ratio: 0.473916
=========================
[[1.        ]
 [0.2266588 ]
 [0.09880835]
 [0.        ]
 [0.        ]
 [0.36843973]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6341414 ]
 [-0.52953625]
 [-0.42664352]
 [-0.        ]
 [-0.        ]
 [-0.56077564]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5968723 ]
 [-0.        ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1012.4136962890625, (570.5782, 0.21745504, 441.61804, 0.8454952)
   validation loss 679.1758422851562, (453.8793, 0.15442197, 225.1421, 0.8454952)
decoder loss ratio: 17584.072167, decoder SINDy loss  ratio: 0.486001
=========================
[[1.        ]
 [0.23222783]
 [0.09426132]
 [0.        ]
 [0.        ]
 [0.3599586 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.705452  ]
 [-0.51989573]
 [-0.33064145]
 [-0.        ]
 [ 0.        ]
 [-0.6223884 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6338663 ]
 [ 0.        ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 868.7161865234375, (401.54202, 0.23150754, 466.94266, 0.84206486)
   validation loss 596.3950805664062, (367.8056, 0.14411518, 228.44539, 0.84206486)
decoder loss ratio: 14249.427600, decoder SINDy loss  ratio: 0.493132
=========================
[[1.        ]
 [0.22952801]
 [0.09054488]
 [0.        ]
 [0.        ]
 [0.34958607]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5813046 ]
 [-0.49493888]
 [-0.3652499 ]
 [ 0.        ]
 [-0.        ]
 [-0.6784178 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.645292  ]
 [ 0.        ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.4786376953125, (261.1882, 0.23664808, 437.0538, 0.8406779)
   validation loss 406.2967224121094, (188.69588, 0.15243329, 217.44841, 0.8406779)
decoder loss ratio: 7310.405868, decoder SINDy loss  ratio: 0.469393
=========================
[[1.        ]
 [0.23591569]
 [0.08630688]
 [0.        ]
 [0.        ]
 [0.34273663]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6835027 ]
 [-0.4229875 ]
 [-0.36168244]
 [ 0.        ]
 [ 0.        ]
 [-0.55990165]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5392442 ]
 [ 0.        ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.3853759765625, (216.09032, 0.23202287, 441.06305, 0.8381956)
   validation loss 386.0010986328125, (167.54922, 0.14550558, 218.30638, 0.8381956)
decoder loss ratio: 6491.147849, decoder SINDy loss  ratio: 0.471245
=========================
[[1.        ]
 [0.23802891]
 [0.08089484]
 [0.        ]
 [0.        ]
 [0.3367524 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7281048 ]
 [-0.5483446 ]
 [-0.33526772]
 [ 0.        ]
 [-0.        ]
 [-0.5708811 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5678682 ]
 [ 0.        ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1056.0765380859375, (613.3434, 0.21246919, 442.5207, 0.83634245)
   validation loss 718.150634765625, (491.933, 0.15078343, 226.0668, 0.83634245)
decoder loss ratio: 19058.338992, decoder SINDy loss  ratio: 0.487997
=========================
[[1.        ]
 [0.2443352 ]
 [0.07682164]
 [0.        ]
 [0.        ]
 [0.3272886 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.708321  ]
 [-0.54302496]
 [-0.4551197 ]
 [-0.        ]
 [ 0.        ]
 [-0.5682778 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6136312 ]
 [ 0.        ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 919.2725830078125, (448.89062, 0.23165299, 470.1503, 0.8328142)
   validation loss 644.8917236328125, (414.91782, 0.14031328, 229.8336, 0.8328142)
decoder loss ratio: 16074.636527, decoder SINDy loss  ratio: 0.496128
=========================
[[1.        ]
 [0.2428799 ]
 [0.07361485]
 [0.        ]
 [0.        ]
 [0.31737548]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7671044 ]
 [-0.5502275 ]
 [-0.38379484]
 [ 0.        ]
 [ 0.        ]
 [-0.6033464 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6760397 ]
 [ 0.        ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.2913818359375, (256.45685, 0.23614001, 436.59842, 0.8318693)
   validation loss 403.73919677734375, (186.61797, 0.14878567, 216.97243, 0.8318693)
decoder loss ratio: 7229.903974, decoder SINDy loss  ratio: 0.468366
=========================
[[1.        ]
 [0.25138998]
 [0.06983005]
 [0.        ]
 [0.        ]
 [0.310763  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7387128]
 [-0.6316767]
 [-0.3265955]
 [ 0.       ]
 [-0.       ]
 [-0.61898  ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.6080644]
 [-0.       ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.1226196289062, (215.46338, 0.22554365, 438.4337, 0.8295353)
   validation loss 382.36309814453125, (164.75108, 0.14122929, 217.47078, 0.8295353)
decoder loss ratio: 6382.742990, decoder SINDy loss  ratio: 0.469441
=========================
[[1.        ]
 [0.25479215]
 [0.06531399]
 [0.        ]
 [0.        ]
 [0.30481383]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8110754 ]
 [-0.5817418 ]
 [-0.39197028]
 [ 0.        ]
 [-0.        ]
 [-0.55905527]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6596694 ]
 [-0.        ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1091.3447265625, (648.034, 0.20741203, 443.10327, 0.8280514)
   validation loss 753.3397216796875, (526.1019, 0.14679568, 227.091, 0.8280514)
decoder loss ratio: 20382.102071, decoder SINDy loss  ratio: 0.490208
=========================
[[1.        ]
 [0.26289684]
 [0.06190721]
 [0.        ]
 [0.        ]
 [0.29613262]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7859933 ]
 [-0.5227153 ]
 [-0.44065624]
 [-0.        ]
 [ 0.        ]
 [-0.5970732 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6018214 ]
 [-0.        ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 881.69873046875, (416.50153, 0.22867739, 464.9685, 0.82499564)
   validation loss 607.861572265625, (379.86688, 0.13682714, 227.85785, 0.82499564)
decoder loss ratio: 14716.702499, decoder SINDy loss  ratio: 0.491863
=========================
[[1.        ]
 [0.26255906]
 [0.05921753]
 [0.        ]
 [0.        ]
 [0.286803  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8084314 ]
 [-0.5364607 ]
 [-0.30993968]
 [-0.        ]
 [ 0.        ]
 [-0.5338062 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5696952 ]
 [-0.        ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.9888305664062, (275.50424, 0.23116645, 435.25342, 0.8244335)
   validation loss 418.1531677246094, (201.18158, 0.14535777, 216.82623, 0.8244335)
decoder loss ratio: 7794.123660, decoder SINDy loss  ratio: 0.468050
=========================
[[1.        ]
 [0.27297905]
 [0.05610422]
 [0.        ]
 [0.        ]
 [0.28082228]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7709131 ]
 [-0.56396157]
 [-0.26496708]
 [ 0.        ]
 [-0.        ]
 [-0.55937517]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6279407 ]
 [-0.        ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.9315185546875, (218.26794, 0.22054887, 435.443, 0.8225116)
   validation loss 380.9866638183594, (163.95969, 0.1380655, 216.88892, 0.8225116)
decoder loss ratio: 6352.082893, decoder SINDy loss  ratio: 0.468185
=========================
[[1.        ]
 [0.27766964]
 [0.05250205]
 [0.        ]
 [0.        ]
 [0.27515897]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.799282  ]
 [-0.49940822]
 [-0.32279688]
 [-0.        ]
 [-0.        ]
 [-0.5482556 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6781316 ]
 [ 0.        ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1112.069091796875, (668.3776, 0.20367594, 443.48776, 0.82142204)
   validation loss 776.1575927734375, (548.1083, 0.14358965, 227.9057, 0.82142204)
decoder loss ratio: 21234.666184, decoder SINDy loss  ratio: 0.491967
=========================
[[1.        ]
 [0.287367  ]
 [0.04980896]
 [0.        ]
 [0.        ]
 [0.2671205 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8472774 ]
 [-0.57169855]
 [-0.33639592]
 [-0.        ]
 [-0.        ]
 [-0.5583735 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6191595 ]
 [-0.        ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.1853637695312, (380.0562, 0.22653788, 458.90262, 0.8187804)
   validation loss 566.2814331054688, (340.27972, 0.13409226, 225.86763, 0.8187804)
decoder loss ratio: 13183.027264, decoder SINDy loss  ratio: 0.487567
=========================
[[1.        ]
 [0.28795856]
 [0.04773914]
 [0.        ]
 [0.        ]
 [0.25885072]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9013438]
 [-0.598525 ]
 [-0.320802 ]
 [-0.       ]
 [ 0.       ]
 [-0.5633653]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.6672351]
 [ 0.       ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.472900390625, (301.9, 0.22739424, 434.34552, 0.81873304)
   validation loss 441.4171142578125, (224.0637, 0.14284936, 217.21057, 0.81873304)
decoder loss ratio: 8680.616941, decoder SINDy loss  ratio: 0.468880
=========================
[[1.        ]
 [0.3001356 ]
 [0.04534958]
 [0.        ]
 [0.        ]
 [0.25350434]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8938403 ]
 [-0.49549723]
 [-0.31385848]
 [-0.        ]
 [-0.        ]
 [-0.55914754]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6913617 ]
 [-0.        ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.869384765625, (222.32834, 0.21777602, 433.3233, 0.8171713)
   validation loss 383.26617431640625, (166.288, 0.13576612, 216.84242, 0.8171713)
decoder loss ratio: 6442.285591, decoder SINDy loss  ratio: 0.468085
=========================
[[1.        ]
 [0.30534437]
 [0.04261272]
 [0.        ]
 [0.        ]
 [0.24860118]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9561975 ]
 [-0.54829264]
 [-0.2803534 ]
 [ 0.        ]
 [ 0.        ]
 [-0.53867364]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6533153 ]
 [ 0.        ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1114.199951171875, (670.819, 0.20207319, 443.1789, 0.81655055)
   validation loss 782.2132568359375, (553.79645, 0.14159939, 228.27522, 0.81655055)
decoder loss ratio: 21455.035819, decoder SINDy loss  ratio: 0.492764
=========================
[[1.        ]
 [0.31589836]
 [0.04062981]
 [0.        ]
 [0.        ]
 [0.24160185]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.974426  ]
 [-0.5127957 ]
 [-0.28786558]
 [ 0.        ]
 [-0.        ]
 [-0.51881737]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7182221 ]
 [-0.        ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.1044921875, (358.86444, 0.22748505, 455.0126, 0.81429625)
   validation loss 541.2273559570312, (316.0936, 0.13253237, 225.00124, 0.81429625)
decoder loss ratio: 12246.014726, decoder SINDy loss  ratio: 0.485697
=========================
[[1.        ]
 [0.31652635]
 [0.039148  ]
 [0.        ]
 [0.        ]
 [0.23446679]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.944799  ]
 [-0.46464768]
 [-0.25336808]
 [-0.        ]
 [-0.        ]
 [-0.55926317]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6508436 ]
 [ 0.        ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.5578002929688, (324.55762, 0.22663556, 433.77356, 0.81467026)
   validation loss 462.4437255859375, (244.48148, 0.14160228, 217.82063, 0.81467026)
decoder loss ratio: 9471.636812, decoder SINDy loss  ratio: 0.470196
=========================
[[1.        ]
 [0.32917136]
 [0.03747274]
 [0.        ]
 [0.        ]
 [0.22984158]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9321556 ]
 [-0.57535183]
 [-0.2359915 ]
 [ 0.        ]
 [-0.        ]
 [-0.50817305]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7430873 ]
 [ 0.        ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.6959838867188, (223.37363, 0.21873708, 432.1036, 0.8133647)
   validation loss 384.5846862792969, (167.37021, 0.13463327, 217.07985, 0.8133647)
decoder loss ratio: 6484.212454, decoder SINDy loss  ratio: 0.468597
=========================
[[1.        ]
 [0.3335598 ]
 [0.03547816]
 [0.        ]
 [0.        ]
 [0.22581974]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.095791  ]
 [-0.5622896 ]
 [-0.31486964]
 [ 0.        ]
 [-0.        ]
 [-0.53524625]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6840029 ]
 [ 0.        ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1107.18017578125, (664.5515, 0.20260623, 442.42603, 0.81305754)
   validation loss 779.0665283203125, (550.7037, 0.14080305, 228.22202, 0.81305754)
decoder loss ratio: 21335.216407, decoder SINDy loss  ratio: 0.492649
=========================
[[1.        ]
 [0.343769  ]
 [0.03411688]
 [0.        ]
 [0.        ]
 [0.21983413]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0845165 ]
 [-0.5512083 ]
 [-0.28807944]
 [-0.        ]
 [ 0.        ]
 [-0.58078194]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7523193 ]
 [-0.        ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.1469116210938, (359.80786, 0.23159398, 454.10745, 0.8109852)
   validation loss 540.5370483398438, (315.03143, 0.1316827, 225.37395, 0.8109852)
decoder loss ratio: 12204.864637, decoder SINDy loss  ratio: 0.486501
=========================
[[1.        ]
 [0.34277537]
 [0.03316735]
 [0.        ]
 [0.        ]
 [0.21373206]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.029807  ]
 [-0.63064533]
 [-0.30650073]
 [-0.        ]
 [-0.        ]
 [-0.49917138]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7967951 ]
 [-0.        ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.8630981445312, (311.06778, 0.23003009, 432.56528, 0.811539)
   validation loss 452.22735595703125, (234.414, 0.14084823, 217.67249, 0.811539)
decoder loss ratio: 9081.605377, decoder SINDy loss  ratio: 0.469877
=========================
[[1.        ]
 [0.35430747]
 [0.03210172]
 [0.        ]
 [0.        ]
 [0.2097979 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.041855  ]
 [-0.5549278 ]
 [-0.27053702]
 [-0.        ]
 [-0.        ]
 [-0.4775392 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7855797 ]
 [ 0.        ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.829345703125, (217.40648, 0.22366899, 432.19922, 0.8103394)
   validation loss 381.0201416015625, (163.48291, 0.13417333, 217.40305, 0.8103394)
decoder loss ratio: 6333.611758, decoder SINDy loss  ratio: 0.469295
=========================
[[1.        ]
 [0.35681152]
 [0.03068717]
 [0.        ]
 [0.        ]
 [0.20665537]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.118947  ]
 [-0.49581742]
 [-0.30255154]
 [ 0.        ]
 [ 0.        ]
 [-0.547767  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6834426 ]
 [-0.        ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1118.7266845703125, (676.0613, 0.20432249, 442.4611, 0.81021404)
   validation loss 789.7357788085938, (561.2137, 0.14095956, 228.38116, 0.81021404)
decoder loss ratio: 21742.392431, decoder SINDy loss  ratio: 0.492993
=========================
[[1.        ]
 [0.36569118]
 [0.02980615]
 [0.        ]
 [0.        ]
 [0.20166057]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.079436  ]
 [-0.5435424 ]
 [-0.26053002]
 [ 0.        ]
 [ 0.        ]
 [-0.49564213]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.778584  ]
 [-0.        ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.51025390625, (363.8984, 0.23631023, 454.37558, 0.8080761)
   validation loss 544.516845703125, (318.43613, 0.13125227, 225.9495, 0.8080761)
decoder loss ratio: 12336.768378, decoder SINDy loss  ratio: 0.487744
=========================
[[1.        ]
 [0.3614654 ]
 [0.02924931]
 [0.        ]
 [0.        ]
 [0.19659795]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1913943 ]
 [-0.5995928 ]
 [-0.31742004]
 [ 0.        ]
 [ 0.        ]
 [-0.5060311 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7956908 ]
 [ 0.        ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.060302734375, (267.57092, 0.23715976, 431.2522, 0.8085045)
   validation loss 416.297119140625, (199.09842, 0.14006746, 217.05862, 0.8085045)
decoder loss ratio: 7713.418409, decoder SINDy loss  ratio: 0.468552
=========================
[[1.        ]
 [0.3699795 ]
 [0.02860705]
 [0.        ]
 [0.        ]
 [0.19345155]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.129709  ]
 [-0.58067393]
 [-0.25698423]
 [ 0.        ]
 [ 0.        ]
 [-0.4891481 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7763069 ]
 [ 0.        ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.69921875, (214.8729, 0.23433815, 434.59195, 0.80731124)
   validation loss 382.2476806640625, (163.94055, 0.13453735, 218.1726, 0.80731124)
decoder loss ratio: 6351.341588, decoder SINDy loss  ratio: 0.470956
=========================
[[1.        ]
 [0.37018245]
 [0.02761789]
 [0.        ]
 [0.        ]
 [0.19065605]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.175701 ]
 [-0.6318088]
 [-0.3182173]
 [-0.       ]
 [ 0.       ]
 [-0.5821626]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.818381 ]
 [ 0.       ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1144.3505859375, (701.02405, 0.2078976, 443.1186, 0.80709887)
   validation loss 808.6739501953125, (580.0557, 0.14186895, 228.47641, 0.80709887)
decoder loss ratio: 22472.365811, decoder SINDy loss  ratio: 0.493198
=========================
[[1.        ]
 [0.3758587 ]
 [0.02721778]
 [0.        ]
 [0.        ]
 [0.18585794]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2076836 ]
 [-0.6219276 ]
 [-0.31683314]
 [-0.        ]
 [-0.        ]
 [-0.48709148]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7459266 ]
 [ 0.        ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.7550048828125, (268.0394, 0.23721772, 443.47836, 0.8049391)
   validation loss 445.654296875, (224.00578, 0.1311961, 221.51733, 0.8049391)
decoder loss ratio: 8678.372928, decoder SINDy loss  ratio: 0.478176
=========================
[[1.        ]
 [0.3809362 ]
 [0.02763368]
 [0.        ]
 [0.        ]
 [0.17899129]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2202616 ]
 [-0.56292945]
 [-0.2930536 ]
 [ 0.        ]
 [-0.        ]
 [-0.5162301 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8253875 ]
 [-0.        ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.1355590820312, (221.06898, 0.23941371, 430.82718, 0.806036)
   validation loss 383.8586730957031, (166.46254, 0.13950269, 217.25664, 0.806036)
decoder loss ratio: 6449.047779, decoder SINDy loss  ratio: 0.468979
=========================
[[1.        ]
 [0.36846823]
 [0.0252632 ]
 [0.        ]
 [0.        ]
 [0.17887005]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2314463 ]
 [-0.6503396 ]
 [-0.23798108]
 [-0.        ]
 [-0.        ]
 [-0.51365155]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8726208 ]
 [-0.        ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.9515991210938, (267.80988, 0.24558713, 443.89615, 0.80075026)
   validation loss 444.94110107421875, (223.38292, 0.12997313, 221.42819, 0.80075026)
decoder loss ratio: 8654.242104, decoder SINDy loss  ratio: 0.477984
=========================
[[1.        ]
 [0.3706013 ]
 [0.02732437]
 [0.        ]
 [0.        ]
 [0.17767654]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.244839  ]
 [-0.57762665]
 [-0.30223152]
 [-0.        ]
 [-0.        ]
 [-0.45420778]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8135977 ]
 [ 0.        ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.9134521484375, (217.3888, 0.26013085, 436.2645, 0.803425)
   validation loss 391.80126953125, (173.4177, 0.13984519, 218.24371, 0.803425)
decoder loss ratio: 6718.502535, decoder SINDy loss  ratio: 0.471110
=========================
[[1.        ]
 [0.36737067]
 [0.02439337]
 [0.        ]
 [0.        ]
 [0.17550167]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2174654 ]
 [-0.6251933 ]
 [-0.27109945]
 [-0.        ]
 [-0.        ]
 [-0.500577  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.838009  ]
 [-0.        ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 973.52978515625, (536.75653, 0.22908136, 436.54416, 0.8009373)
   validation loss 649.3092651367188, (427.12253, 0.14075278, 222.046, 0.8009373)
decoder loss ratio: 16547.468255, decoder SINDy loss  ratio: 0.479318
=========================
[[1.        ]
 [0.3709497 ]
 [0.02538257]
 [0.        ]
 [0.        ]
 [0.1682449 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.329205  ]
 [-0.5979441 ]
 [-0.29482237]
 [ 0.        ]
 [ 0.        ]
 [-0.5646349 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.804037  ]
 [-0.        ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.7979736328125, (216.59258, 0.22334443, 429.9821, 0.7992441)
   validation loss 379.3948974609375, (162.26717, 0.13178565, 216.99594, 0.7992441)
decoder loss ratio: 6286.511724, decoder SINDy loss  ratio: 0.468416
=========================
[[1.        ]
 [0.38586244]
 [0.02642846]
 [0.        ]
 [0.        ]
 [0.1616449 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.262315  ]
 [-0.5426982 ]
 [-0.28359497]
 [-0.        ]
 [ 0.        ]
 [-0.4920666 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8515809 ]
 [ 0.        ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 759.4693603515625, (330.8906, 0.22128473, 428.35745, 0.8026461)
   validation loss 468.11578369140625, (250.46971, 0.13991527, 217.50618, 0.8026461)
decoder loss ratio: 9703.631450, decoder SINDy loss  ratio: 0.469518
=========================
[[1.        ]
 [0.37593296]
 [0.02469627]
 [0.        ]
 [0.        ]
 [0.16164808]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3155184 ]
 [-0.643905  ]
 [-0.29360804]
 [ 0.        ]
 [ 0.        ]
 [-0.552031  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8324893 ]
 [ 0.        ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.6845092773438, (221.95366, 0.23956625, 435.4913, 0.7977587)
   validation loss 391.6314697265625, (173.0532, 0.13071838, 218.44756, 0.7977587)
decoder loss ratio: 6704.381688, decoder SINDy loss  ratio: 0.471550
=========================
[[1.        ]
 [0.3750217 ]
 [0.02553435]
 [0.        ]
 [0.        ]
 [0.16126618]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3726306 ]
 [-0.5173955 ]
 [-0.3481077 ]
 [-0.        ]
 [-0.        ]
 [-0.51026064]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8407023 ]
 [ 0.        ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1078.4056396484375, (640.31494, 0.19622277, 437.8945, 0.7987416)
   validation loss 750.8663330078125, (523.2006, 0.13869157, 227.52707, 0.7987416)
decoder loss ratio: 20269.700434, decoder SINDy loss  ratio: 0.491149
=========================
[[1.        ]
 [0.3819758 ]
 [0.027495  ]
 [0.        ]
 [0.        ]
 [0.16583166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3315754 ]
 [-0.68706053]
 [-0.32894766]
 [ 0.        ]
 [-0.        ]
 [-0.4079618 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.899836  ]
 [-0.        ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.932861328125, (240.73116, 0.28570288, 431.91602, 0.80324423)
   validation loss 402.941650390625, (188.65195, 0.14419906, 214.14552, 0.80324423)
decoder loss ratio: 7308.703942, decoder SINDy loss  ratio: 0.462263
=========================
[[1.        ]
 [0.40848404]
 [0.02514645]
 [0.        ]
 [0.        ]
 [0.15483114]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3273964 ]
 [-0.59966147]
 [-0.28868866]
 [-0.        ]
 [-0.        ]
 [-0.46746737]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7977762 ]
 [ 0.        ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 650.216064453125, (219.50008, 0.23858866, 430.4774, 0.8033752)
   validation loss 383.4034118652344, (166.392, 0.13879272, 216.87262, 0.8033752)
decoder loss ratio: 6446.314883, decoder SINDy loss  ratio: 0.468150
=========================
[[1.        ]
 [0.38661218]
 [0.0239362 ]
 [0.        ]
 [0.        ]
 [0.1565002 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.377739  ]
 [-0.6698443 ]
 [-0.32487458]
 [ 0.        ]
 [-0.        ]
 [-0.5118427 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9038    ]
 [ 0.        ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 752.1170654296875, (308.37112, 0.22982292, 443.51614, 0.7970216)
   validation loss 492.775634765625, (270.81784, 0.13090755, 221.82689, 0.7970216)
decoder loss ratio: 10491.953304, decoder SINDy loss  ratio: 0.478845
=========================
[[1.        ]
 [0.38615686]
 [0.02538019]
 [0.        ]
 [0.        ]
 [0.15255742]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2932777 ]
 [-0.58034337]
 [-0.36986625]
 [ 0.        ]
 [-0.        ]
 [-0.5062739 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8748217 ]
 [ 0.        ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 846.4456787109375, (418.91467, 0.20685044, 427.32413, 0.79925936)
   validation loss 555.8812255859375, (335.3491, 0.13911621, 220.39304, 0.79925936)
decoder loss ratio: 12992.005961, decoder SINDy loss  ratio: 0.475749
=========================
[[1.        ]
 [0.41618574]
 [0.02634075]
 [0.        ]
 [0.        ]
 [0.14827731]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.284733  ]
 [-0.6118478 ]
 [-0.25961077]
 [ 0.        ]
 [ 0.        ]
 [-0.50440776]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9054358 ]
 [ 0.        ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.3048095703125, (231.05852, 0.24013285, 437.00613, 0.80332434)
   validation loss 407.75, (187.71611, 0.1396309, 219.89427, 0.80332434)
decoder loss ratio: 7272.448000, decoder SINDy loss  ratio: 0.474673
=========================
[[1.        ]
 [0.38656798]
 [0.02421992]
 [0.        ]
 [0.        ]
 [0.14906229]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.4050674 ]
 [-0.60318774]
 [-0.27832216]
 [ 0.        ]
 [ 0.        ]
 [-0.54833966]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8581424 ]
 [-0.        ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.1558227539062, (321.01367, 0.24216838, 427.9, 0.7984992)
   validation loss 454.1387939453125, (237.58476, 0.14314674, 216.41089, 0.7984992)
decoder loss ratio: 9204.446167, decoder SINDy loss  ratio: 0.467153
=========================
[[1.        ]
 [0.38241917]
 [0.02561582]
 [0.        ]
 [0.        ]
 [0.14594802]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.343447  ]
 [-0.6620199 ]
 [-0.27927932]
 [-0.        ]
 [ 0.        ]
 [-0.43291828]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.937311  ]
 [ 0.        ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.7073974609375, (251.8315, 0.2131154, 424.66278, 0.79653627)
   validation loss 406.7156982421875, (189.67957, 0.13399431, 216.90213, 0.79653627)
decoder loss ratio: 7348.515663, decoder SINDy loss  ratio: 0.468214
=========================
[[1.        ]
 [0.3807372 ]
 [0.02846066]
 [0.        ]
 [0.        ]
 [0.1538356 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.487932  ]
 [-0.5909019 ]
 [-0.337455  ]
 [-0.        ]
 [ 0.        ]
 [-0.48557144]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8697302 ]
 [ 0.        ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.940185546875, (215.52557, 0.2595393, 432.1551, 0.80110973)
   validation loss 390.0829772949219, (173.67491, 0.13905439, 216.26901, 0.80110973)
decoder loss ratio: 6728.467584, decoder SINDy loss  ratio: 0.466847
=========================
[[1.        ]
 [0.4053857 ]
 [0.02491921]
 [0.        ]
 [0.        ]
 [0.149097  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3607254 ]
 [-0.6004303 ]
 [-0.24696304]
 [ 0.        ]
 [-0.        ]
 [-0.41701794]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.869544  ]
 [-0.        ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.4912109375, (310.96576, 0.22543132, 427.30002, 0.8018112)
   validation loss 447.3727722167969, (230.30112, 0.14351846, 216.92813, 0.8018112)
decoder loss ratio: 8922.265091, decoder SINDy loss  ratio: 0.468270
=========================
[[1.        ]
 [0.38825214]
 [0.02444394]
 [0.        ]
 [0.        ]
 [0.14630793]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.4636846 ]
 [-0.51831824]
 [-0.32722062]
 [ 0.        ]
 [-0.        ]
 [-0.51974547]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.9114914 ]
 [-0.        ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.0341796875, (217.19458, 0.2246674, 428.61496, 0.796935)
   validation loss 379.7389831542969, (162.73001, 0.13673107, 216.87224, 0.796935)
decoder loss ratio: 6304.443137, decoder SINDy loss  ratio: 0.468149
=========================
[[1.        ]
 [0.41191024]
 [0.02604078]
 [0.        ]
 [0.        ]
 [0.13771006]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.510739  ]
 [-0.6368996 ]
 [-0.31557128]
 [ 0.        ]
 [-0.        ]
 [-0.42084566]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.877004  ]
 [-0.        ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.8484497070312, (246.83653, 0.2372021, 438.77472, 0.7997691)
   validation loss 422.30255126953125, (201.41983, 0.13701835, 220.74571, 0.7997691)
decoder loss ratio: 7803.353907, decoder SINDy loss  ratio: 0.476511
=========================
[[1.        ]
 [0.38721156]
 [0.0251214 ]
 [0.        ]
 [0.        ]
 [0.14068678]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5213666 ]
 [-0.53514534]
 [-0.3107003 ]
 [-0.        ]
 [-0.        ]
 [-0.5166475 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.825546  ]
 [-0.        ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 836.965576171875, (408.1337, 0.22005656, 428.61185, 0.79761237)
   validation loss 529.6610107421875, (311.12726, 0.14411975, 218.38963, 0.79761237)
decoder loss ratio: 12053.610127, decoder SINDy loss  ratio: 0.471425
=========================
[[1.        ]
 [0.38030678]
 [0.02586926]
 [0.        ]
 [0.        ]
 [0.14051963]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3997416 ]
 [-0.57970804]
 [-0.25487825]
 [ 0.        ]
 [-0.        ]
 [-0.48777506]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7816846 ]
 [ 0.        ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 980.0535278320312, (518.0724, 0.24474946, 461.7364, 0.7944867)
   validation loss 722.196533203125, (491.35352, 0.13142058, 230.71161, 0.7944867)
decoder loss ratio: 19035.888223, decoder SINDy loss  ratio: 0.498023
=========================
[[1.        ]
 [0.41742215]
 [0.02705075]
 [0.        ]
 [0.        ]
 [0.1350216 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.4161   ]
 [-0.5516337]
 [-0.2991532]
 [ 0.       ]
 [ 0.       ]
 [-0.4796323]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.852026 ]
 [ 0.       ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.5555419921875, (349.9168, 0.24443525, 453.39426, 0.8004919)
   validation loss 536.8087158203125, (310.21808, 0.13690296, 226.45375, 0.8004919)
decoder loss ratio: 12018.386928, decoder SINDy loss  ratio: 0.488832
=========================
[[1.        ]
 [0.3854711 ]
 [0.02545973]
 [0.        ]
 [0.        ]
 [0.13668   ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5076084 ]
 [-0.57639444]
 [-0.30007276]
 [ 0.        ]
 [-0.        ]
 [-0.5220227 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.783094  ]
 [ 0.        ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1132.4189453125, (694.9637, 0.21503603, 437.24017, 0.7964902)
   validation loss 797.362548828125, (571.2106, 0.14748858, 226.00449, 0.7964902)
decoder loss ratio: 22129.689197, decoder SINDy loss  ratio: 0.487862
=========================
[[1.        ]
 [0.3890326 ]
 [0.02778871]
 [0.        ]
 [0.        ]
 [0.13734223]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.470112  ]
 [-0.5604104 ]
 [-0.28906685]
 [ 0.        ]
 [-0.        ]
 [-0.49642244]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.84492   ]
 [-0.        ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.8008422851562, (210.06041, 0.24268565, 431.49774, 0.79853725)
   validation loss 383.60406494140625, (165.7435, 0.14603952, 217.71454, 0.79853725)
decoder loss ratio: 6421.190924, decoder SINDy loss  ratio: 0.469967
=========================
[[1.        ]
 [0.39439863]
 [0.02546957]
 [0.        ]
 [0.        ]
 [0.13835095]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.541941  ]
 [-0.6076709 ]
 [-0.2541376 ]
 [ 0.        ]
 [ 0.        ]
 [-0.45341557]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8433    ]
 [ 0.        ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.686767578125, (252.16907, 0.23803703, 440.27966, 0.7961507)
   validation loss 428.5323791503906, (207.59676, 0.13663921, 220.79898, 0.7961507)
decoder loss ratio: 8042.658731, decoder SINDy loss  ratio: 0.476626
=========================
[[1.        ]
 [0.36800647]
 [0.02662559]
 [0.        ]
 [0.        ]
 [0.13357008]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.4441895 ]
 [-0.65081894]
 [-0.29876864]
 [-0.        ]
 [ 0.        ]
 [-0.3980646 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8098457 ]
 [ 0.        ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.1842041015625, (258.7858, 0.22738495, 425.17105, 0.79440737)
   validation loss 405.69012451171875, (189.96123, 0.14289293, 215.58598, 0.79440737)
decoder loss ratio: 7359.427737, decoder SINDy loss  ratio: 0.465373
=========================
[[1.        ]
 [0.3758059 ]
 [0.02903974]
 [0.        ]
 [0.        ]
 [0.13029772]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.454588  ]
 [-0.5865806 ]
 [-0.27911994]
 [ 0.        ]
 [-0.        ]
 [-0.43954915]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8503115 ]
 [-0.        ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1200.8758544921875, (719.33984, 0.24552202, 481.29047, 0.79368126)
   validation loss 924.1962890625, (684.00586, 0.13179967, 240.05867, 0.79368126)
decoder loss ratio: 26499.574479, decoder SINDy loss  ratio: 0.518200
=========================
[[1.        ]
 [0.41434622]
 [0.02828701]
 [0.        ]
 [0.        ]
 [0.1295922 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5249233 ]
 [-0.57257664]
 [-0.27634105]
 [-0.        ]
 [-0.        ]
 [-0.39638516]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7676635 ]
 [-0.        ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.177734375, (267.83466, 0.23040026, 442.11267, 0.8001055)
   validation loss 448.56787109375, (226.06921, 0.1363092, 222.36235, 0.8001055)
decoder loss ratio: 8758.313819, decoder SINDy loss  ratio: 0.480000
=========================
[[1.        ]
 [0.38721943]
 [0.02641326]
 [0.        ]
 [0.        ]
 [0.13307156]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5425215 ]
 [-0.6270374 ]
 [-0.2935391 ]
 [ 0.        ]
 [-0.        ]
 [-0.46139288]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8281567 ]
 [ 0.        ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1187.77294921875, (750.4794, 0.20217183, 437.09146, 0.7966113)
   validation loss 846.3296508789062, (618.9733, 0.1480521, 227.20825, 0.7966113)
decoder loss ratio: 23980.101298, decoder SINDy loss  ratio: 0.490461
=========================
[[1.        ]
 [0.38823444]
 [0.02787916]
 [0.        ]
 [0.        ]
 [0.13037229]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.509455 ]
 [-0.5338615]
 [-0.2339268]
 [-0.       ]
 [-0.       ]
 [-0.4590357]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8051863]
 [-0.       ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.5057373046875, (279.5885, 0.22234882, 438.6949, 0.7949033)
   validation loss 463.83831787109375, (242.76344, 0.13244408, 220.94241, 0.7949033)
decoder loss ratio: 9405.077237, decoder SINDy loss  ratio: 0.476935
=========================
[[1.        ]
 [0.39373946]
 [0.03062448]
 [0.        ]
 [0.        ]
 [0.13053295]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.501221  ]
 [-0.59294355]
 [-0.3412793 ]
 [ 0.        ]
 [-0.        ]
 [-0.4078516 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.8124633 ]
 [-0.        ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.4633178710938, (237.416, 0.2407238, 437.8066, 0.79946566)
   validation loss 418.1990966796875, (197.63066, 0.1438146, 220.42462, 0.79946566)
decoder loss ratio: 7656.554909, decoder SINDy loss  ratio: 0.475818
=========================
[[1.       ]
 [0.4073169]
 [0.0266354]
 [0.       ]
 [0.       ]
 [0.1348335]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.52104   ]
 [-0.6325093 ]
 [-0.29224828]
 [-0.        ]
 [ 0.        ]
 [-0.3412607 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7759287 ]
 [ 0.        ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1106.979248046875, (674.77344, 0.21015559, 431.9956, 0.79976875)
   validation loss 788.6213989257812, (563.4203, 0.14640903, 225.0547, 0.79976875)
decoder loss ratio: 21827.880101, decoder SINDy loss  ratio: 0.485812
=========================
[[1.        ]
 [0.38625166]
 [0.02764214]
 [0.        ]
 [0.        ]
 [0.12894571]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5716867 ]
 [-0.62260264]
 [-0.31351262]
 [ 0.        ]
 [ 0.        ]
 [-0.46139735]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7766516 ]
 [-0.        ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.749755859375, (216.30954, 0.21876667, 431.22144, 0.7949657)
   validation loss 387.73968505859375, (169.57663, 0.13594879, 218.0271, 0.7949657)
decoder loss ratio: 6569.693030, decoder SINDy loss  ratio: 0.470642
=========================
[[1.        ]
 [0.38558346]
 [0.03014941]
 [0.        ]
 [0.        ]
 [0.12251677]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.554919  ]
 [-0.6271837 ]
 [-0.36370105]
 [ 0.        ]
 [-0.        ]
 [-0.4562453 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7911181 ]
 [-0.        ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 979.44970703125, (546.9617, 0.19824575, 432.28983, 0.797049)
   validation loss 649.830322265625, (427.09833, 0.14391501, 222.58804, 0.797049)
decoder loss ratio: 16546.530688, decoder SINDy loss  ratio: 0.480488
=========================
[[1.        ]
 [0.4189796 ]
 [0.03019233]
 [0.        ]
 [0.        ]
 [0.12367851]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5409684 ]
 [-0.6151215 ]
 [-0.29939717]
 [ 0.        ]
 [-0.        ]
 [-0.47985443]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.746912  ]
 [ 0.        ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.1218872070312, (279.4327, 0.21245183, 423.4767, 0.80201876)
   validation loss 420.73992919921875, (204.2754, 0.14363214, 216.3209, 0.80201876)
decoder loss ratio: 7913.983862, decoder SINDy loss  ratio: 0.466959
=========================
[[1.        ]
 [0.3959362 ]
 [0.02741782]
 [0.        ]
 [0.        ]
 [0.12689365]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5867815 ]
 [-0.5604822 ]
 [-0.3335864 ]
 [ 0.        ]
 [ 0.        ]
 [-0.40293422]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7700636 ]
 [ 0.        ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 908.92529296875, (448.23093, 0.2474505, 460.44693, 0.7948763)
   validation loss 648.2507934570312, (417.92737, 0.13434348, 230.1891, 0.7948763)
decoder loss ratio: 16191.231796, decoder SINDy loss  ratio: 0.496896
=========================
[[1.        ]
 [0.38237584]
 [0.02880087]
 [0.        ]
 [0.        ]
 [0.12486568]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6169176 ]
 [-0.5603402 ]
 [-0.23410815]
 [-0.        ]
 [-0.        ]
 [-0.43813384]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7383804 ]
 [ 0.        ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1111.3951416015625, (677.40466, 0.19411153, 433.7964, 0.7954984)
   validation loss 775.0470581054688, (549.11304, 0.14738445, 225.78664, 0.7954984)
decoder loss ratio: 21273.592360, decoder SINDy loss  ratio: 0.487392
=========================
[[1.        ]
 [0.38046902]
 [0.03029156]
 [0.        ]
 [0.        ]
 [0.1267788 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.526359  ]
 [-0.6210185 ]
 [-0.21926692]
 [-0.        ]
 [ 0.        ]
 [-0.44060406]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8117    ]
 [-0.        ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2232.91943359375, (1639.478, 0.3118784, 593.1295, 0.7973016)
   validation loss 1791.5927734375, (1497.3707, 0.14472412, 294.07724, 0.7973016)
decoder loss ratio: 58010.741535, decoder SINDy loss  ratio: 0.634807
=========================
[[1.        ]
 [0.41527826]
 [0.03030959]
 [0.        ]
 [0.        ]
 [0.11979711]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5867915 ]
 [-0.6342333 ]
 [-0.17304876]
 [-0.        ]
 [-0.        ]
 [-0.3979079 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7565804 ]
 [-0.        ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.9283447265625, (268.81094, 0.2133977, 422.90396, 0.8002262)
   validation loss 411.5455322265625, (195.28267, 0.1392111, 216.12364, 0.8002262)
decoder loss ratio: 7565.589625, decoder SINDy loss  ratio: 0.466533
=========================
[[1.        ]
 [0.38754928]
 [0.02844578]
 [0.        ]
 [0.        ]
 [0.12353092]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.512307  ]
 [-0.59303993]
 [-0.32169583]
 [ 0.        ]
 [-0.        ]
 [-0.46401116]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7892368 ]
 [ 0.        ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.8878173828125, (223.72684, 0.21867658, 431.9423, 0.7937714)
   validation loss 397.84869384765625, (179.39398, 0.13430724, 218.32039, 0.7937714)
decoder loss ratio: 6950.034302, decoder SINDy loss  ratio: 0.471275
=========================
[[1.        ]
 [0.3799848 ]
 [0.02961992]
 [0.        ]
 [0.        ]
 [0.12189856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6844773 ]
 [-0.5897831 ]
 [-0.27155808]
 [-0.        ]
 [-0.        ]
 [-0.39730084]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.6137755 ]
 [-0.        ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1123.6480712890625, (690.5979, 0.19435167, 432.85587, 0.79467624)
   validation loss 790.20263671875, (563.86633, 0.14681064, 226.18954, 0.79467624)
decoder loss ratio: 21845.160656, decoder SINDy loss  ratio: 0.488262
=========================
[[1.        ]
 [0.3827991 ]
 [0.03256414]
 [0.        ]
 [0.        ]
 [0.11827207]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6410246 ]
 [-0.6043023 ]
 [-0.3308921 ]
 [-0.        ]
 [-0.        ]
 [-0.48722747]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7111826 ]
 [-0.        ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1148.7081298828125, (647.85864, 0.32699433, 500.52255, 0.7974416)
   validation loss 804.4873046875, (558.3801, 0.14956647, 245.95767, 0.7974416)
decoder loss ratio: 21632.615509, decoder SINDy loss  ratio: 0.530934
=========================
[[1.        ]
 [0.40774643]
 [0.03104386]
 [0.        ]
 [0.        ]
 [0.12220133]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.595632  ]
 [-0.6193259 ]
 [-0.24253027]
 [ 0.        ]
 [-0.        ]
 [-0.37316638]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.6405537 ]
 [-0.        ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1117.2044677734375, (636.5414, 0.2591547, 480.4039, 0.7988025)
   validation loss 843.8583374023438, (603.81494, 0.14021741, 239.90318, 0.7988025)
decoder loss ratio: 23392.839099, decoder SINDy loss  ratio: 0.517865
=========================
[[1.        ]
 [0.38410285]
 [0.029121  ]
 [0.        ]
 [0.        ]
 [0.1201541 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.681838  ]
 [-0.58266824]
 [-0.34362623]
 [ 0.        ]
 [-0.        ]
 [-0.43774116]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7559977 ]
 [ 0.        ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 891.3218994140625, (464.4886, 0.21872416, 426.6146, 0.7946128)
   validation loss 581.4918212890625, (361.80927, 0.14546691, 219.53705, 0.7946128)
decoder loss ratio: 14017.119060, decoder SINDy loss  ratio: 0.473902
=========================
[[1.        ]
 [0.37403798]
 [0.03191418]
 [0.        ]
 [0.        ]
 [0.12182336]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6823754 ]
 [-0.63131905]
 [-0.28918535]
 [-0.        ]
 [ 0.        ]
 [-0.35939822]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6486042 ]
 [-0.        ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.7919311523438, (232.71423, 0.25187147, 436.82584, 0.79479563)
   validation loss 414.3246154785156, (194.34566, 0.14986171, 219.8291, 0.79479563)
decoder loss ratio: 7529.288165, decoder SINDy loss  ratio: 0.474532
=========================
[[1.        ]
 [0.39237893]
 [0.02971868]
 [0.        ]
 [0.        ]
 [0.12143207]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6107945]
 [-0.6193011]
 [-0.2765076]
 [ 0.       ]
 [ 0.       ]
 [-0.4926437]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.646419 ]
 [ 0.       ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.0604248046875, (331.56265, 0.21977653, 425.278, 0.7969536)
   validation loss 460.7266845703125, (243.88435, 0.14614016, 216.6962, 0.7969536)
decoder loss ratio: 9448.503262, decoder SINDy loss  ratio: 0.467769
=========================
[[1.        ]
 [0.37581977]
 [0.0306943 ]
 [0.        ]
 [0.        ]
 [0.11725274]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6589055 ]
 [-0.6348774 ]
 [-0.3359468 ]
 [ 0.        ]
 [-0.        ]
 [-0.47759178]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6471922 ]
 [-0.        ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.1575927734375, (214.90553, 0.21428774, 426.03778, 0.7923523)
   validation loss 376.9965515136719, (160.29959, 0.13906994, 216.55789, 0.7923523)
decoder loss ratio: 6210.284450, decoder SINDy loss  ratio: 0.467471
=========================
[[1.        ]
 [0.36611694]
 [0.03274153]
 [0.        ]
 [0.        ]
 [0.11400859]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6649504]
 [-0.637658 ]
 [-0.3076995]
 [ 0.       ]
 [-0.       ]
 [-0.459372 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.5793936]
 [ 0.       ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.8455810546875, (472.57364, 0.19508286, 424.07684, 0.7926753)
   validation loss 603.5462646484375, (382.6603, 0.14296135, 220.743, 0.7926753)
decoder loss ratio: 14824.924692, decoder SINDy loss  ratio: 0.476505
=========================
[[1.        ]
 [0.4007984 ]
 [0.03432676]
 [0.        ]
 [0.        ]
 [0.1130624 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6533837 ]
 [-0.6030863 ]
 [-0.31588745]
 [-0.        ]
 [ 0.        ]
 [-0.41648474]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.5192554 ]
 [ 0.        ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.69482421875, (236.91061, 0.23455378, 437.54968, 0.7983379)
   validation loss 416.8998718261719, (195.92438, 0.14793363, 220.82756, 0.7983379)
decoder loss ratio: 7590.450522, decoder SINDy loss  ratio: 0.476687
=========================
[[1.        ]
 [0.39005268]
 [0.03042608]
 [0.        ]
 [0.        ]
 [0.11602606]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7216396 ]
 [-0.5927283 ]
 [-0.3635258 ]
 [-0.        ]
 [ 0.        ]
 [-0.38121337]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.5691137 ]
 [ 0.        ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1137.715576171875, (704.1024, 0.21427843, 433.3989, 0.79539835)
   validation loss 798.2601928710938, (572.961, 0.1486547, 225.15051, 0.79539835)
decoder loss ratio: 22197.503787, decoder SINDy loss  ratio: 0.486019
=========================
[[1.        ]
 [0.36850244]
 [0.03197869]
 [0.        ]
 [0.        ]
 [0.1211054 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.696098  ]
 [-0.59657466]
 [-0.26230106]
 [ 0.        ]
 [ 0.        ]
 [-0.4223406 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.526425  ]
 [ 0.        ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.5151977539062, (216.39227, 0.27357653, 432.84933, 0.79395455)
   validation loss 388.6280517578125, (171.47533, 0.1500819, 217.00266, 0.79395455)
decoder loss ratio: 6643.251844, decoder SINDy loss  ratio: 0.468431
=========================
[[1.        ]
 [0.3847169 ]
 [0.03077426]
 [0.        ]
 [0.        ]
 [0.11764956]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.750381  ]
 [-0.6204943 ]
 [-0.31210643]
 [ 0.        ]
 [-0.        ]
 [-0.42536354]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5797088 ]
 [-0.        ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.1710205078125, (238.26291, 0.24325226, 434.66483, 0.796169)
   validation loss 406.87359619140625, (187.4265, 0.14806624, 219.29904, 0.796169)
decoder loss ratio: 7261.227935, decoder SINDy loss  ratio: 0.473388
=========================
[[1.        ]
 [0.3950166 ]
 [0.03147756]
 [0.        ]
 [0.        ]
 [0.11346889]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7527666 ]
 [-0.5636011 ]
 [-0.3182899 ]
 [-0.        ]
 [ 0.        ]
 [-0.44358143]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5796525 ]
 [ 0.        ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.373046875, (307.61032, 0.24101488, 446.52173, 0.79436696)
   validation loss 499.70013427734375, (275.554, 0.14093952, 224.00523, 0.79436696)
decoder loss ratio: 10675.439785, decoder SINDy loss  ratio: 0.483547
=========================
[[1.        ]
 [0.37774742]
 [0.03353404]
 [0.        ]
 [0.        ]
 [0.11132223]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7206316]
 [-0.5580674]
 [-0.2425645]
 [-0.       ]
 [ 0.       ]
 [-0.4116964]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.5892024]
 [ 0.       ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.43359375, (220.77254, 0.23996411, 434.42108, 0.7936112)
   validation loss 400.0339050292969, (180.85193, 0.15224646, 219.02972, 0.7936112)
decoder loss ratio: 7006.517691, decoder SINDy loss  ratio: 0.472806
=========================
[[1.        ]
 [0.37409723]
 [0.03063282]
 [0.        ]
 [0.        ]
 [0.11445162]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.765565  ]
 [-0.5466772 ]
 [-0.3454858 ]
 [-0.        ]
 [-0.        ]
 [-0.41905323]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.4770255 ]
 [ 0.        ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 928.1293334960938, (499.58408, 0.2214382, 428.32382, 0.79239887)
   validation loss 600.6358032226562, (381.14325, 0.14828417, 219.34425, 0.79239887)
decoder loss ratio: 14766.151180, decoder SINDy loss  ratio: 0.473485
=========================
[[1.        ]
 [0.35744843]
 [0.03189795]
 [0.        ]
 [0.        ]
 [0.11035769]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7280354]
 [-0.6430852]
 [-0.3176875]
 [ 0.       ]
 [ 0.       ]
 [-0.4502144]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.614584 ]
 [-0.       ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.7343139648438, (212.25731, 0.21652475, 427.26047, 0.7874703)
   validation loss 379.72015380859375, (163.12646, 0.13930957, 216.45438, 0.7874703)
decoder loss ratio: 6319.802448, decoder SINDy loss  ratio: 0.467247
=========================
[[1.        ]
 [0.35065502]
 [0.03533267]
 [0.        ]
 [0.        ]
 [0.10513224]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7031994 ]
 [-0.6083944 ]
 [-0.35614547]
 [-0.        ]
 [-0.        ]
 [-0.38845262]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5228324 ]
 [ 0.        ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 842.5543212890625, (418.35605, 0.19413535, 424.00415, 0.78998804)
   validation loss 535.7559814453125, (317.13663, 0.14427361, 218.47508, 0.78998804)
decoder loss ratio: 12286.423511, decoder SINDy loss  ratio: 0.471609
=========================
[[1.        ]
 [0.3921661 ]
 [0.03604682]
 [0.        ]
 [0.        ]
 [0.10609393]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.715052  ]
 [-0.5899039 ]
 [-0.29001704]
 [-0.        ]
 [ 0.        ]
 [-0.41652757]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5403028 ]
 [ 0.        ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.65087890625, (214.98662, 0.21479581, 425.44946, 0.7966864)
   validation loss 378.39996337890625, (161.60078, 0.1475944, 216.65157, 0.7966864)
decoder loss ratio: 6260.694935, decoder SINDy loss  ratio: 0.467673
=========================
[[1.        ]
 [0.38705575]
 [0.03190957]
 [0.        ]
 [0.        ]
 [0.11036704]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7419405 ]
 [-0.6223093 ]
 [-0.3251832 ]
 [-0.        ]
 [-0.        ]
 [-0.45329696]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.548721  ]
 [-0.        ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.1117553710938, (213.47552, 0.22464408, 427.4116, 0.7930743)
   validation loss 380.4444274902344, (163.54123, 0.13938561, 216.76381, 0.7930743)
decoder loss ratio: 6335.871141, decoder SINDy loss  ratio: 0.467915
=========================
[[1.        ]
 [0.36174744]
 [0.03264249]
 [0.        ]
 [0.        ]
 [0.10775088]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8197827 ]
 [-0.6355423 ]
 [-0.2383167 ]
 [ 0.        ]
 [ 0.        ]
 [-0.40932512]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.47667   ]
 [ 0.        ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.3499145507812, (277.1996, 0.21488474, 421.93546, 0.79087585)
   validation loss 416.5104064941406, (201.10785, 0.1462959, 215.25626, 0.79087585)
decoder loss ratio: 7791.267214, decoder SINDy loss  ratio: 0.464661
=========================
[[1.        ]
 [0.3704801 ]
 [0.03591587]
 [0.        ]
 [0.        ]
 [0.10300903]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.755031  ]
 [-0.6082822 ]
 [-0.3482768 ]
 [ 0.        ]
 [ 0.        ]
 [-0.43891126]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.4714248 ]
 [ 0.        ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 906.1534423828125, (482.49066, 0.19647898, 423.46634, 0.79212254)
   validation loss 606.9849243164062, (385.53668, 0.14357416, 221.30466, 0.79212254)
decoder loss ratio: 14936.360387, decoder SINDy loss  ratio: 0.477717
=========================
[[1.        ]
 [0.39781582]
 [0.03667482]
 [0.        ]
 [0.        ]
 [0.10669076]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7663264 ]
 [-0.6131055 ]
 [-0.2766285 ]
 [ 0.        ]
 [-0.        ]
 [-0.44821748]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.4378483 ]
 [-0.        ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.5138549804688, (228.96516, 0.23359811, 435.3151, 0.7977538)
   validation loss 410.0848388671875, (189.64236, 0.1514416, 220.29105, 0.7977538)
decoder loss ratio: 7347.074434, decoder SINDy loss  ratio: 0.475529
=========================
[[1.        ]
 [0.4150477 ]
 [0.03182139]
 [0.        ]
 [0.        ]
 [0.11344284]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.773975  ]
 [-0.605674  ]
 [-0.3169505 ]
 [-0.        ]
 [-0.        ]
 [-0.45238072]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.4879029 ]
 [ 0.        ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.86181640625, (269.4393, 0.22878852, 425.19373, 0.7999627)
   validation loss 413.0501708984375, (196.20142, 0.15036492, 216.69841, 0.7999627)
decoder loss ratio: 7601.183477, decoder SINDy loss  ratio: 0.467774
=========================
[[1.        ]
 [0.39019528]
 [0.03178534]
 [0.        ]
 [0.        ]
 [0.10712611]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.771223  ]
 [-0.6286768 ]
 [-0.18396322]
 [ 0.        ]
 [ 0.        ]
 [-0.43033803]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.403806  ]
 [-0.        ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.0836181640625, (292.1766, 0.22682643, 442.68018, 0.79156965)
   validation loss 479.0964050292969, (256.08493, 0.13880926, 222.87265, 0.79156965)
decoder loss ratio: 9921.174787, decoder SINDy loss  ratio: 0.481102
=========================
[[1.        ]
 [0.36958587]
 [0.03370656]
 [0.        ]
 [0.        ]
 [0.10382645]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8288083 ]
 [-0.5708498 ]
 [-0.30948097]
 [-0.        ]
 [ 0.        ]
 [-0.4719787 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3441362 ]
 [-0.        ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.8775634765625, (229.64064, 0.21436359, 423.02258, 0.79133254)
   validation loss 385.4303283691406, (169.5855, 0.14366041, 215.70117, 0.79133254)
decoder loss ratio: 6570.036489, decoder SINDy loss  ratio: 0.465621
=========================
[[1.        ]
 [0.37370667]
 [0.03688125]
 [0.        ]
 [0.        ]
 [0.11266154]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7977204 ]
 [-0.60156465]
 [-0.34364167]
 [-0.        ]
 [-0.        ]
 [-0.4143173 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.3499563 ]
 [-0.        ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.1839599609375, (221.75688, 0.24611716, 429.18094, 0.79522246)
   validation loss 396.5296630859375, (179.89024, 0.14697483, 216.49245, 0.79522246)
decoder loss ratio: 6969.260338, decoder SINDy loss  ratio: 0.467329
=========================
[[1.        ]
 [0.41209358]
 [0.0338318 ]
 [0.        ]
 [0.        ]
 [0.10570821]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7063293 ]
 [-0.60159624]
 [-0.31493852]
 [ 0.        ]
 [-0.        ]
 [-0.418643  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3773875 ]
 [ 0.        ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.9430541992188, (347.0779, 0.23490849, 450.63025, 0.7968721)
   validation loss 542.0416259765625, (314.79208, 0.1424182, 227.10712, 0.7968721)
decoder loss ratio: 12195.591827, decoder SINDy loss  ratio: 0.490243
=========================
[[1.        ]
 [0.37318373]
 [0.03179034]
 [0.        ]
 [0.        ]
 [0.10583461]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8533516 ]
 [-0.6366115 ]
 [-0.35740155]
 [ 0.        ]
 [-0.        ]
 [-0.4316759 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.3159716 ]
 [-0.        ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1074.5211181640625, (646.0821, 0.21440007, 428.22464, 0.79065067)
   validation loss 750.11962890625, (526.76166, 0.15272947, 223.20529, 0.79065067)
decoder loss ratio: 20407.661118, decoder SINDy loss  ratio: 0.481820
=========================
[[1.        ]
 [0.3988673 ]
 [0.03532667]
 [0.        ]
 [0.        ]
 [0.10015921]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8075247 ]
 [-0.59700215]
 [-0.24417284]
 [ 0.        ]
 [ 0.        ]
 [-0.4279357 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.322003  ]
 [-0.        ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 650.4417724609375, (226.05849, 0.22430556, 424.15897, 0.7954008)
   validation loss 383.53900146484375, (166.9824, 0.15038416, 216.4062, 0.7954008)
decoder loss ratio: 6469.188327, decoder SINDy loss  ratio: 0.467143
=========================
[[1.        ]
 [0.3879282 ]
 [0.03305431]
 [0.        ]
 [0.        ]
 [0.10359649]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7796745 ]
 [-0.6375393 ]
 [-0.30888447]
 [-0.        ]
 [ 0.        ]
 [-0.44380403]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3751106 ]
 [-0.        ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.97802734375, (240.77591, 0.22915058, 435.97296, 0.7911596)
   validation loss 419.38592529296875, (199.31955, 0.1407939, 219.9256, 0.7911596)
decoder loss ratio: 7721.985384, decoder SINDy loss  ratio: 0.474740
=========================
[[1.        ]
 [0.36205208]
 [0.03414978]
 [0.        ]
 [0.        ]
 [0.100377  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.814215  ]
 [-0.6173884 ]
 [-0.27555835]
 [-0.        ]
 [ 0.        ]
 [-0.3965163 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.3082259 ]
 [ 0.        ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1015.847412109375, (587.2612, 0.20505737, 428.3811, 0.78928894)
   validation loss 684.8287353515625, (462.35132, 0.15106936, 222.32639, 0.78928894)
decoder loss ratio: 17912.292750, decoder SINDy loss  ratio: 0.479923
=========================
[[1.        ]
 [0.35605305]
 [0.03710061]
 [0.        ]
 [0.        ]
 [0.09792837]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-4.92518   ]
 [-0.5802165 ]
 [-0.40162027]
 [ 0.        ]
 [-0.        ]
 [-0.42346874]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.276829  ]
 [ 0.        ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.7135620117188, (414.37238, 0.2030799, 421.1381, 0.78876245)
   validation loss 546.1364135742188, (326.45288, 0.14227559, 219.54128, 0.78876245)
decoder loss ratio: 12647.351352, decoder SINDy loss  ratio: 0.473911
=========================
[[1.        ]
 [0.4020964 ]
 [0.03764894]
 [0.        ]
 [0.        ]
 [0.09704466]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-4.8663077 ]
 [-0.65595585]
 [-0.3398818 ]
 [ 0.        ]
 [-0.        ]
 [-0.40345582]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.2471185 ]
 [ 0.        ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.2166137695312, (215.15997, 0.21794313, 424.8387, 0.796476)
   validation loss 378.270751953125, (161.07832, 0.14666669, 217.04578, 0.796476)
decoder loss ratio: 6240.453891, decoder SINDy loss  ratio: 0.468524
params['save_name']
pendulum_2023_11_07_07_49_17_501640
