nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-27 08:43:18.452861: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-27 08:43:18.460200: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-27 08:43:18.462029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5640e39bba80 executing computations on platform Host. Devices:
2023-10-27 08:43:18.462057: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-27 08:43:18.463973: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-27 08:43:18.581315: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5640e39cb900 executing computations on platform CUDA. Devices:
2023-10-27 08:43:18.581374: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-27 08:43:18.582367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-27 08:43:18.582968: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-27 08:43:18.587766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-27 08:43:18.591587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-27 08:43:18.592358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-27 08:43:18.596297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-27 08:43:18.598022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-27 08:43:18.604497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-27 08:43:18.605283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-27 08:43:18.605332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-27 08:43:18.605778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-27 08:43:18.605792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-27 08:43:18.605799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-27 08:43:18.606529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-27 08:43:19.734898: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.05, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8352177143096924 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 102459.4921875, (97033.82, 0.011092395, 5407.191, 2.53178)
   validation loss 99497.25, (98278.0, 0.014814624, 1200.756, 2.53178)
decoder loss ratio: 3807460.338111, decoder SINDy loss  ratio: 2.592001
--- 0.27457737922668457 seconds for one epoch ---
--- 0.32550597190856934 seconds for one epoch ---
--- 0.3265867233276367 seconds for one epoch ---
--- 0.3205385208129883 seconds for one epoch ---
--- 0.31896281242370605 seconds for one epoch ---
--- 0.33062195777893066 seconds for one epoch ---
--- 0.34346532821655273 seconds for one epoch ---
--- 0.3243112564086914 seconds for one epoch ---
--- 0.3342478275299072 seconds for one epoch ---
--- 0.32348012924194336 seconds for one epoch ---
--- 0.3445091247558594 seconds for one epoch ---
--- 0.32380056381225586 seconds for one epoch ---
--- 0.3303191661834717 seconds for one epoch ---
--- 0.2831692695617676 seconds for one epoch ---
--- 0.33377909660339355 seconds for one epoch ---
--- 0.323838472366333 seconds for one epoch ---
--- 0.32515597343444824 seconds for one epoch ---
--- 0.3125760555267334 seconds for one epoch ---
--- 0.31732749938964844 seconds for one epoch ---
--- 0.322023868560791 seconds for one epoch ---
--- 0.32776737213134766 seconds for one epoch ---
--- 0.31511735916137695 seconds for one epoch ---
--- 0.33615660667419434 seconds for one epoch ---
--- 0.3159959316253662 seconds for one epoch ---
=========================
[[0.99917996]
 [0.9772302 ]
 [0.99999726]
 [0.98411953]
 [0.7720805 ]
 [0.9999989 ]
 [0.9992304 ]
 [0.7715194 ]
 [0.7714684 ]
 [1.        ]
 [0.81489664]]
[[ 0.63841623]
 [ 0.46695724]
 [-0.93605274]
 [-0.48663864]
 [-0.07579143]
 [-0.9907629 ]
 [ 0.64158666]
 [-0.01914262]
 [ 0.00856278]
 [-1.5450994 ]
 [ 0.28446206]]
--- 0.2657315731048584 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 61934.84765625, (54839.99, 35.73071, 7015.2085, 2.531738)
   validation loss 50718.24609375, (49394.92, 12.353768, 1267.0487, 2.531738)
decoder loss ratio: 1913645.026793, decoder SINDy loss  ratio: 2.735103
--- 0.32486701011657715 seconds for one epoch ---
--- 0.332258939743042 seconds for one epoch ---
--- 0.3315448760986328 seconds for one epoch ---
--- 0.3404684066772461 seconds for one epoch ---
--- 0.30341219902038574 seconds for one epoch ---
--- 0.33347511291503906 seconds for one epoch ---
--- 0.31462717056274414 seconds for one epoch ---
--- 0.34477925300598145 seconds for one epoch ---
--- 0.31937217712402344 seconds for one epoch ---
--- 0.3345973491668701 seconds for one epoch ---
--- 0.3353383541107178 seconds for one epoch ---
--- 0.3450620174407959 seconds for one epoch ---
--- 0.3198108673095703 seconds for one epoch ---
--- 0.3385758399963379 seconds for one epoch ---
--- 0.31950950622558594 seconds for one epoch ---
--- 0.355541467666626 seconds for one epoch ---
--- 0.31406617164611816 seconds for one epoch ---
--- 0.34420251846313477 seconds for one epoch ---
--- 0.3286607265472412 seconds for one epoch ---
--- 0.35013270378112793 seconds for one epoch ---
--- 0.31508517265319824 seconds for one epoch ---
--- 0.33338022232055664 seconds for one epoch ---
--- 0.32476091384887695 seconds for one epoch ---
--- 0.34821510314941406 seconds for one epoch ---
=========================
[[1.        ]
 [0.61077565]
 [0.99997705]
 [0.7682066 ]
 [0.6091663 ]
 [1.        ]
 [0.90145016]
 [0.6160506 ]
 [0.6090133 ]
 [0.9930997 ]
 [0.6234215 ]]
[[ 1.2084696 ]
 [ 0.09608452]
 [-0.84459424]
 [-0.33806363]
 [-0.02499837]
 [-1.4585874 ]
 [ 0.41123757]
 [ 0.1591893 ]
 [ 0.00734298]
 [-0.5579474 ]
 [ 0.19473307]]
--- 0.29030632972717285 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 51283.37890625, (44063.414, 14.245412, 7144.455, 2.531727)
   validation loss 38707.9765625, (37480.496, 4.2516084, 1161.9678, 2.531727)
decoder loss ratio: 1452059.487675, decoder SINDy loss  ratio: 2.508271
--- 0.2644522190093994 seconds for one epoch ---
--- 0.32753849029541016 seconds for one epoch ---
--- 0.347698450088501 seconds for one epoch ---
--- 0.3173098564147949 seconds for one epoch ---
--- 0.34069323539733887 seconds for one epoch ---
--- 0.31643223762512207 seconds for one epoch ---
--- 0.3719496726989746 seconds for one epoch ---
--- 0.3188936710357666 seconds for one epoch ---
--- 0.35292768478393555 seconds for one epoch ---
--- 0.3216409683227539 seconds for one epoch ---
--- 0.3369565010070801 seconds for one epoch ---
--- 0.31886959075927734 seconds for one epoch ---
--- 0.34844160079956055 seconds for one epoch ---
--- 0.3213164806365967 seconds for one epoch ---
--- 0.35566139221191406 seconds for one epoch ---
--- 0.4230353832244873 seconds for one epoch ---
--- 0.33167457580566406 seconds for one epoch ---
--- 0.3197159767150879 seconds for one epoch ---
--- 0.3690199851989746 seconds for one epoch ---
--- 0.31443023681640625 seconds for one epoch ---
--- 0.3504812717437744 seconds for one epoch ---
--- 0.31792140007019043 seconds for one epoch ---
--- 0.3449721336364746 seconds for one epoch ---
--- 0.3320128917694092 seconds for one epoch ---
=========================
[[1.        ]
 [0.47479436]
 [0.99979913]
 [0.56847894]
 [0.47412136]
 [1.        ]
 [0.6303868 ]
 [0.50003755]
 [0.4728813 ]
 [0.47392073]
 [0.47598746]]
[[ 1.36559701e+00]
 [-8.58883858e-02]
 [-7.50887573e-01]
 [-2.81564623e-01]
 [-6.88512325e-02]
 [-1.84947717e+00]
 [ 3.14205796e-01]
 [ 2.11796388e-01]
 [ 3.78544355e-04]
 [-6.24069311e-02]
 [ 1.06628716e-01]]
--- 0.2741360664367676 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 33574.78125, (27645.47, 6.9237804, 5844.2773, 2.5317361)
   validation loss 17963.447265625, (16795.271, 0.46919334, 1089.5983, 2.5317361)
decoder loss ratio: 650677.975178, decoder SINDy loss  ratio: 2.352051
--- 0.3244931697845459 seconds for one epoch ---
--- 0.3531970977783203 seconds for one epoch ---
--- 0.321458101272583 seconds for one epoch ---
--- 0.35660862922668457 seconds for one epoch ---
--- 0.3284785747528076 seconds for one epoch ---
--- 0.36175036430358887 seconds for one epoch ---
--- 0.32399988174438477 seconds for one epoch ---
--- 0.371107816696167 seconds for one epoch ---
--- 0.32477855682373047 seconds for one epoch ---
--- 0.36281800270080566 seconds for one epoch ---
--- 0.31349706649780273 seconds for one epoch ---
--- 0.3763918876647949 seconds for one epoch ---
--- 0.3099548816680908 seconds for one epoch ---
--- 0.3360319137573242 seconds for one epoch ---
--- 0.3301723003387451 seconds for one epoch ---
--- 0.35741281509399414 seconds for one epoch ---
--- 0.3197619915008545 seconds for one epoch ---
--- 0.3636312484741211 seconds for one epoch ---
--- 0.3180274963378906 seconds for one epoch ---
--- 0.35027503967285156 seconds for one epoch ---
--- 0.32590413093566895 seconds for one epoch ---
--- 0.3637070655822754 seconds for one epoch ---
--- 0.3265523910522461 seconds for one epoch ---
--- 0.36057305335998535 seconds for one epoch ---
=========================
[[1.        ]
 [0.37973866]
 [0.8270742 ]
 [0.44755802]
 [0.37724906]
 [1.        ]
 [0.43621245]
 [0.41962788]
 [0.3755492 ]
 [0.37558323]
 [0.38030764]]
[[ 1.19155288e+00]
 [-1.12424962e-01]
 [-4.04830307e-01]
 [-2.55157262e-01]
 [-7.43999854e-02]
 [-2.21276450e+00]
 [ 2.45628253e-01]
 [ 2.28357062e-01]
 [-4.10780834e-04]
 [ 3.66977579e-03]
 [ 1.18193075e-01]]
--- 0.29303693771362305 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 24414.708984375, (19061.293, 2.3116066, 5256.872, 2.531739)
   validation loss 11221.646484375, (10201.101, 0.2670746, 926.04565, 2.531739)
decoder loss ratio: 395208.346589, decoder SINDy loss  ratio: 1.999000
--- 0.28153109550476074 seconds for one epoch ---
--- 0.32236671447753906 seconds for one epoch ---
--- 0.3580291271209717 seconds for one epoch ---
--- 0.3232564926147461 seconds for one epoch ---
--- 0.3794522285461426 seconds for one epoch ---
--- 0.29868245124816895 seconds for one epoch ---
--- 0.3577108383178711 seconds for one epoch ---
--- 0.3056955337524414 seconds for one epoch ---
--- 0.37392711639404297 seconds for one epoch ---
--- 0.3183751106262207 seconds for one epoch ---
--- 0.36592769622802734 seconds for one epoch ---
--- 0.31694817543029785 seconds for one epoch ---
--- 0.37742042541503906 seconds for one epoch ---
--- 0.3228881359100342 seconds for one epoch ---
--- 0.3911936283111572 seconds for one epoch ---
--- 0.32593679428100586 seconds for one epoch ---
--- 0.3939812183380127 seconds for one epoch ---
--- 0.3228721618652344 seconds for one epoch ---
--- 0.35756683349609375 seconds for one epoch ---
--- 0.311861515045166 seconds for one epoch ---
--- 0.38619518280029297 seconds for one epoch ---
--- 0.3205695152282715 seconds for one epoch ---
--- 0.3669545650482178 seconds for one epoch ---
--- 0.3250560760498047 seconds for one epoch ---
=========================
[[0.9999856 ]
 [0.29866314]
 [0.29396388]
 [0.31296378]
 [0.29431117]
 [1.        ]
 [0.33774188]
 [0.36756706]
 [0.2935368 ]
 [0.30107102]
 [0.33756524]]
[[ 8.9745522e-01]
 [-1.1604996e-01]
 [-2.8911615e-02]
 [-1.7983572e-01]
 [-4.3762911e-02]
 [-2.5368216e+00]
 [ 2.2198060e-01]
 [ 2.4981876e-01]
 [-1.2218497e-03]
 [-1.3383308e-01]
 [ 2.2176993e-01]]
--- 0.25933218002319336 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13530.498046875, (10304.672, 2.6796463, 3114.796, 2.5317447)
   validation loss 7235.60302734375, (6334.078, 0.26574007, 792.90894, 2.5317447)
decoder loss ratio: 245393.183006, decoder SINDy loss  ratio: 1.711605
--- 0.32442164421081543 seconds for one epoch ---
--- 0.37552380561828613 seconds for one epoch ---
--- 0.322831392288208 seconds for one epoch ---
--- 0.3666954040527344 seconds for one epoch ---
--- 0.321840763092041 seconds for one epoch ---
--- 0.36740732192993164 seconds for one epoch ---
--- 0.3284494876861572 seconds for one epoch ---
--- 0.3703885078430176 seconds for one epoch ---
--- 0.30559515953063965 seconds for one epoch ---
--- 0.36023521423339844 seconds for one epoch ---
--- 0.3214695453643799 seconds for one epoch ---
--- 0.3594636917114258 seconds for one epoch ---
--- 0.32065796852111816 seconds for one epoch ---
--- 0.3747720718383789 seconds for one epoch ---
--- 0.3166825771331787 seconds for one epoch ---
--- 0.37073612213134766 seconds for one epoch ---
--- 0.32215142250061035 seconds for one epoch ---
--- 0.36428022384643555 seconds for one epoch ---
--- 0.31220030784606934 seconds for one epoch ---
--- 0.3745899200439453 seconds for one epoch ---
--- 0.32805728912353516 seconds for one epoch ---
--- 0.37850356101989746 seconds for one epoch ---
--- 0.3217651844024658 seconds for one epoch ---
--- 0.3818683624267578 seconds for one epoch ---
=========================
[[0.9950505 ]
 [0.2556952 ]
 [0.28491068]
 [0.23790738]
 [0.2350494 ]
 [1.        ]
 [0.26199165]
 [0.28920183]
 [0.2345046 ]
 [0.40581575]
 [0.30510765]]
[[ 6.0877717e-01]
 [-1.8013553e-01]
 [ 2.2466215e-01]
 [-9.4339609e-02]
 [-3.1947535e-02]
 [-2.8713887e+00]
 [ 1.9325003e-01]
 [ 2.2900321e-01]
 [-1.0405225e-04]
 [-2.9470241e-01]
 [ 2.4277909e-01]]
--- 0.3120453357696533 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13351.73828125, (5913.6943, 28.268167, 7288.0464, 2.5317612)
   validation loss 4889.76708984375, (4136.2964, 0.22232419, 631.51953, 2.5317612)
decoder loss ratio: 160247.302948, decoder SINDy loss  ratio: 1.363224
--- 0.2781360149383545 seconds for one epoch ---
--- 0.32050061225891113 seconds for one epoch ---
--- 0.3881816864013672 seconds for one epoch ---
--- 0.319439172744751 seconds for one epoch ---
--- 0.3740396499633789 seconds for one epoch ---
--- 0.31374669075012207 seconds for one epoch ---
--- 0.3537883758544922 seconds for one epoch ---
--- 0.31703662872314453 seconds for one epoch ---
--- 0.37889695167541504 seconds for one epoch ---
--- 0.30141305923461914 seconds for one epoch ---
--- 0.37319517135620117 seconds for one epoch ---
--- 0.32666873931884766 seconds for one epoch ---
--- 0.37415122985839844 seconds for one epoch ---
--- 0.31717896461486816 seconds for one epoch ---
--- 0.3752319812774658 seconds for one epoch ---
--- 0.32577061653137207 seconds for one epoch ---
--- 0.3807942867279053 seconds for one epoch ---
--- 0.3101017475128174 seconds for one epoch ---
--- 0.3871300220489502 seconds for one epoch ---
--- 0.3243706226348877 seconds for one epoch ---
--- 0.3844428062438965 seconds for one epoch ---
--- 0.3158740997314453 seconds for one epoch ---
--- 0.399686336517334 seconds for one epoch ---
--- 0.309356689453125 seconds for one epoch ---
=========================
[[0.82724655]
 [0.28948432]
 [0.8950321 ]
 [0.1871047 ]
 [0.18498425]
 [1.        ]
 [0.20860131]
 [0.2612947 ]
 [0.18449879]
 [0.8381273 ]
 [0.5439112 ]]
[[ 4.2254800e-01]
 [-2.6140389e-01]
 [ 4.5249271e-01]
 [-8.1039086e-02]
 [-2.9011352e-02]
 [-3.0535672e+00]
 [ 1.8346761e-01]
 [ 2.4393363e-01]
 [ 1.9566724e-03]
 [-4.2664257e-01]
 [ 3.4492469e-01]]
--- 0.2743103504180908 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10492.2431640625, (6348.415, 3.8784451, 4009.8137, 2.5317774)
   validation loss 5652.65673828125, (4973.273, 0.23615922, 549.012, 2.5317774)
decoder loss ratio: 192673.228034, decoder SINDy loss  ratio: 1.185120
--- 0.3146827220916748 seconds for one epoch ---
--- 0.35716700553894043 seconds for one epoch ---
--- 0.3123598098754883 seconds for one epoch ---
--- 0.3818380832672119 seconds for one epoch ---
--- 0.3193213939666748 seconds for one epoch ---
--- 0.3899974822998047 seconds for one epoch ---
--- 0.32221364974975586 seconds for one epoch ---
--- 0.36348843574523926 seconds for one epoch ---
--- 0.3144032955169678 seconds for one epoch ---
--- 0.3883230686187744 seconds for one epoch ---
--- 0.3285975456237793 seconds for one epoch ---
--- 0.3976931571960449 seconds for one epoch ---
--- 0.30855536460876465 seconds for one epoch ---
--- 0.40529608726501465 seconds for one epoch ---
--- 0.3155517578125 seconds for one epoch ---
--- 0.3844141960144043 seconds for one epoch ---
--- 0.318692684173584 seconds for one epoch ---
--- 0.39264488220214844 seconds for one epoch ---
--- 0.3374190330505371 seconds for one epoch ---
--- 0.38750314712524414 seconds for one epoch ---
--- 0.32263684272766113 seconds for one epoch ---
--- 0.4028360843658447 seconds for one epoch ---
--- 0.32105517387390137 seconds for one epoch ---
--- 0.39081549644470215 seconds for one epoch ---
=========================
[[0.32964146]
 [0.4607901 ]
 [0.999019  ]
 [0.14874913]
 [0.14836389]
 [1.        ]
 [0.18121763]
 [0.20793028]
 [0.14847708]
 [0.98378724]
 [0.7027083 ]]
[[ 0.29153368]
 [-0.32956946]
 [ 0.6953933 ]
 [-0.0270799 ]
 [-0.0070571 ]
 [-3.1258254 ]
 [ 0.19705181]
 [ 0.22794962]
 [-0.01381336]
 [-0.55408233]
 [ 0.38799715]]
--- 0.30330801010131836 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 16331.3681640625, (13007.174, 12.282277, 3173.038, 2.5317879)
   validation loss 2746.79638671875, (2118.8, 0.18763342, 488.93454, 2.5317879)
decoder loss ratio: 82085.992290, decoder SINDy loss  ratio: 1.055434
--- 0.2719748020172119 seconds for one epoch ---
--- 0.3268420696258545 seconds for one epoch ---
--- 0.39885783195495605 seconds for one epoch ---
--- 0.32236170768737793 seconds for one epoch ---
--- 0.3909268379211426 seconds for one epoch ---
--- 0.304171085357666 seconds for one epoch ---
--- 0.3869798183441162 seconds for one epoch ---
--- 0.31161928176879883 seconds for one epoch ---
--- 0.38434791564941406 seconds for one epoch ---
--- 0.30741333961486816 seconds for one epoch ---
--- 0.3901638984680176 seconds for one epoch ---
--- 0.33536362648010254 seconds for one epoch ---
--- 0.3908994197845459 seconds for one epoch ---
--- 0.3256375789642334 seconds for one epoch ---
--- 0.39670705795288086 seconds for one epoch ---
--- 0.4266672134399414 seconds for one epoch ---
--- 0.3758256435394287 seconds for one epoch ---
--- 0.3159637451171875 seconds for one epoch ---
--- 0.3833496570587158 seconds for one epoch ---
--- 0.3100748062133789 seconds for one epoch ---
--- 0.39761877059936523 seconds for one epoch ---
--- 0.3168954849243164 seconds for one epoch ---
--- 0.40264391899108887 seconds for one epoch ---
--- 0.29974865913391113 seconds for one epoch ---
=========================
[[0.13808528]
 [0.48684543]
 [0.99994665]
 [0.11851948]
 [0.1175497 ]
 [1.        ]
 [0.15074755]
 [0.20405176]
 [0.11745593]
 [0.9988301 ]
 [0.9004596 ]]
[[ 0.17187148]
 [-0.3404066 ]
 [ 0.8424571 ]
 [ 0.04796917]
 [-0.01039636]
 [-3.1696928 ]
 [ 0.19585721]
 [ 0.2462138 ]
 [-0.00467125]
 [-0.6883767 ]
 [ 0.46001193]]
--- 0.25068140029907227 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8373.4111328125, (5446.232, 0.45533752, 2779.2607, 2.5317972)
   validation loss 2205.05712890625, (1614.3281, 0.12164533, 443.1447, 2.5317972)
decoder loss ratio: 62541.874159, decoder SINDy loss  ratio: 0.956590
--- 0.31089091300964355 seconds for one epoch ---
--- 0.39983558654785156 seconds for one epoch ---
--- 0.31957364082336426 seconds for one epoch ---
--- 0.3968076705932617 seconds for one epoch ---
--- 0.2966175079345703 seconds for one epoch ---
--- 0.4039027690887451 seconds for one epoch ---
--- 0.3132193088531494 seconds for one epoch ---
--- 0.40011096000671387 seconds for one epoch ---
--- 0.2890791893005371 seconds for one epoch ---
--- 0.399029016494751 seconds for one epoch ---
--- 0.3183615207672119 seconds for one epoch ---
--- 0.3778083324432373 seconds for one epoch ---
--- 0.3088221549987793 seconds for one epoch ---
--- 0.4128108024597168 seconds for one epoch ---
--- 0.3259882926940918 seconds for one epoch ---
--- 0.42764925956726074 seconds for one epoch ---
--- 0.3163411617279053 seconds for one epoch ---
--- 0.42647576332092285 seconds for one epoch ---
--- 0.3109018802642822 seconds for one epoch ---
--- 0.39121341705322266 seconds for one epoch ---
--- 0.3203868865966797 seconds for one epoch ---
--- 0.4160754680633545 seconds for one epoch ---
--- 0.30098676681518555 seconds for one epoch ---
--- 0.3916609287261963 seconds for one epoch ---
=========================
[[0.09596385]
 [0.7074429 ]
 [0.99999523]
 [0.09704205]
 [0.09533688]
 [1.        ]
 [0.1090654 ]
 [0.1870431 ]
 [0.09502709]
 [0.99993086]
 [0.948138  ]]
[[ 0.04496383]
 [-0.39378327]
 [ 0.9489185 ]
 [ 0.06876382]
 [-0.02313472]
 [-3.2134426 ]
 [ 0.15202011]
 [ 0.24820152]
 [-0.00738737]
 [-0.83093184]
 [ 0.49693367]]
--- 0.2904086112976074 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6493.4990234375, (3090.8726, 0.507798, 3247.6492, 2.531806)
   validation loss 2631.323486328125, (2055.417, 0.076069824, 421.36093, 2.531806)
decoder loss ratio: 79630.422638, decoder SINDy loss  ratio: 0.909567
--- 0.2658536434173584 seconds for one epoch ---
--- 0.33498167991638184 seconds for one epoch ---
--- 0.4226865768432617 seconds for one epoch ---
--- 0.32644224166870117 seconds for one epoch ---
--- 0.4322524070739746 seconds for one epoch ---
--- 0.3312869071960449 seconds for one epoch ---
--- 0.43015217781066895 seconds for one epoch ---
--- 0.3067185878753662 seconds for one epoch ---
--- 0.3917562961578369 seconds for one epoch ---
--- 0.3118152618408203 seconds for one epoch ---
--- 0.4098224639892578 seconds for one epoch ---
--- 0.32781267166137695 seconds for one epoch ---
--- 0.4074280261993408 seconds for one epoch ---
--- 0.3250563144683838 seconds for one epoch ---
--- 0.39345479011535645 seconds for one epoch ---
--- 0.3141624927520752 seconds for one epoch ---
--- 0.41240882873535156 seconds for one epoch ---
--- 0.3094944953918457 seconds for one epoch ---
--- 0.4398672580718994 seconds for one epoch ---
--- 0.29880762100219727 seconds for one epoch ---
--- 0.43740081787109375 seconds for one epoch ---
--- 0.3216822147369385 seconds for one epoch ---
--- 0.41441941261291504 seconds for one epoch ---
--- 0.31078052520751953 seconds for one epoch ---
=========================
[[0.07880986]
 [0.8601373 ]
 [0.9999966 ]
 [0.08428123]
 [0.07596099]
 [1.        ]
 [0.08710782]
 [0.18550128]
 [0.07568077]
 [0.9999966 ]
 [0.9744203 ]]
[[-8.3470792e-02]
 [-4.4308481e-01]
 [ 1.0171705e+00]
 [ 1.2756810e-01]
 [-1.7962525e-02]
 [-3.2294691e+00]
 [ 1.4089957e-01]
 [ 2.5685453e-01]
 [-2.5420454e-03]
 [-9.8640966e-01]
 [ 5.3491163e-01]]
--- 0.2553272247314453 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7359.9482421875, (2693.3972, 0.5897322, 4504.528, 2.531815)
   validation loss 1639.912353515625, (1029.8652, 0.07043406, 448.54282, 2.531815)
decoder loss ratio: 39898.767104, decoder SINDy loss  ratio: 0.968243
--- 0.3124837875366211 seconds for one epoch ---
--- 0.4198465347290039 seconds for one epoch ---
--- 0.31900787353515625 seconds for one epoch ---
--- 0.4157137870788574 seconds for one epoch ---
--- 0.307750940322876 seconds for one epoch ---
--- 0.40317225456237793 seconds for one epoch ---
--- 0.32901859283447266 seconds for one epoch ---
--- 0.42351293563842773 seconds for one epoch ---
--- 0.33074021339416504 seconds for one epoch ---
--- 0.4256157875061035 seconds for one epoch ---
--- 0.3204777240753174 seconds for one epoch ---
--- 0.439023494720459 seconds for one epoch ---
--- 0.3197154998779297 seconds for one epoch ---
--- 0.41750073432922363 seconds for one epoch ---
--- 0.3208632469177246 seconds for one epoch ---
--- 0.43266916275024414 seconds for one epoch ---
--- 0.3267991542816162 seconds for one epoch ---
--- 0.42044949531555176 seconds for one epoch ---
--- 0.3208596706390381 seconds for one epoch ---
--- 0.4324789047241211 seconds for one epoch ---
--- 0.3134005069732666 seconds for one epoch ---
--- 0.40549206733703613 seconds for one epoch ---
--- 0.32564282417297363 seconds for one epoch ---
--- 0.42470550537109375 seconds for one epoch ---
=========================
[[0.087972  ]
 [0.8469974 ]
 [0.9999975 ]
 [0.08293011]
 [0.06188871]
 [1.        ]
 [0.06944656]
 [0.16400146]
 [0.06162596]
 [0.9999999 ]
 [0.99127483]]
[[-0.18100587]
 [-0.4386531 ]
 [ 1.0556    ]
 [ 0.17046973]
 [-0.01929918]
 [-3.192884  ]
 [ 0.12278467]
 [ 0.2520953 ]
 [-0.00567339]
 [-1.1202954 ]
 [ 0.5904434 ]]
--- 0.30420398712158203 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4036.7470703125, (3096.578, 0.36239946, 772.33374, 2.53182)
   validation loss 1674.150390625, (1079.7513, 0.09888215, 426.8271, 2.53182)
decoder loss ratio: 41831.441550, decoder SINDy loss  ratio: 0.921366
--- 0.2644472122192383 seconds for one epoch ---
--- 0.3205113410949707 seconds for one epoch ---
--- 0.4480321407318115 seconds for one epoch ---
--- 0.32366037368774414 seconds for one epoch ---
--- 0.4297957420349121 seconds for one epoch ---
--- 0.2970411777496338 seconds for one epoch ---
--- 0.4082779884338379 seconds for one epoch ---
--- 0.3114809989929199 seconds for one epoch ---
--- 0.4416067600250244 seconds for one epoch ---
--- 0.31255078315734863 seconds for one epoch ---
--- 0.4302642345428467 seconds for one epoch ---
--- 0.3188951015472412 seconds for one epoch ---
--- 0.44621825218200684 seconds for one epoch ---
--- 0.31900477409362793 seconds for one epoch ---
--- 0.41907501220703125 seconds for one epoch ---
--- 0.32277870178222656 seconds for one epoch ---
--- 0.439655065536499 seconds for one epoch ---
--- 0.30018091201782227 seconds for one epoch ---
--- 0.43318891525268555 seconds for one epoch ---
--- 0.32436561584472656 seconds for one epoch ---
--- 0.4364933967590332 seconds for one epoch ---
--- 0.3244755268096924 seconds for one epoch ---
--- 0.439800500869751 seconds for one epoch ---
--- 0.3093719482421875 seconds for one epoch ---
=========================
[[0.35594934]
 [0.8779808 ]
 [0.9999989 ]
 [0.09773882]
 [0.04994694]
 [1.        ]
 [0.05777691]
 [0.14551619]
 [0.04949124]
 [1.        ]
 [0.9977989 ]]
[[-0.31973246]
 [-0.45265132]
 [ 1.1011139 ]
 [ 0.21113834]
 [-0.02810549]
 [-3.1697798 ]
 [ 0.12497486]
 [ 0.24784316]
 [-0.00712663]
 [-1.3058952 ]
 [ 0.66038024]]
--- 0.2715001106262207 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5016.7509765625, (2015.5007, 0.40479267, 2828.3586, 2.5318294)
   validation loss 1615.8662109375, (1063.164, 0.056912363, 380.1585, 2.5318294)
decoder loss ratio: 41188.816786, decoder SINDy loss  ratio: 0.820626
--- 0.32319116592407227 seconds for one epoch ---
--- 0.445711612701416 seconds for one epoch ---
--- 0.30673837661743164 seconds for one epoch ---
--- 0.4336388111114502 seconds for one epoch ---
--- 0.30407118797302246 seconds for one epoch ---
--- 0.42682504653930664 seconds for one epoch ---
--- 0.3161916732788086 seconds for one epoch ---
--- 0.4369630813598633 seconds for one epoch ---
--- 0.31945133209228516 seconds for one epoch ---
--- 0.44580554962158203 seconds for one epoch ---
--- 0.3132028579711914 seconds for one epoch ---
--- 0.43482327461242676 seconds for one epoch ---
--- 0.32358503341674805 seconds for one epoch ---
--- 0.4428062438964844 seconds for one epoch ---
--- 0.31769514083862305 seconds for one epoch ---
--- 0.436553955078125 seconds for one epoch ---
--- 0.31975889205932617 seconds for one epoch ---
--- 0.46596765518188477 seconds for one epoch ---
--- 0.31773996353149414 seconds for one epoch ---
--- 0.4367239475250244 seconds for one epoch ---
--- 0.3054080009460449 seconds for one epoch ---
--- 0.4489455223083496 seconds for one epoch ---
--- 0.3073556423187256 seconds for one epoch ---
--- 0.4556901454925537 seconds for one epoch ---
=========================
[[0.77283895]
 [0.94728065]
 [1.        ]
 [0.08376352]
 [0.04109417]
 [1.        ]
 [0.04747346]
 [0.17139855]
 [0.0404597 ]
 [1.        ]
 [0.9991405 ]]
[[-4.1538161e-01]
 [-4.9916375e-01]
 [ 1.1503147e+00]
 [ 2.0498045e-01]
 [-3.1448573e-02]
 [-3.0947559e+00]
 [ 1.1648838e-01]
 [ 2.6474744e-01]
 [-2.2786260e-03]
 [-1.4683620e+00]
 [ 7.0806617e-01]]
--- 0.30217552185058594 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5254.931640625, (2156.5789, 1.4531753, 2919.7874, 2.5318353)
   validation loss 2083.537109375, (1535.4922, 0.061153643, 370.8714, 2.5318353)
decoder loss ratio: 59487.633075, decoder SINDy loss  ratio: 0.800578
--- 0.2707250118255615 seconds for one epoch ---
--- 0.3159489631652832 seconds for one epoch ---
--- 0.43067026138305664 seconds for one epoch ---
--- 0.3160734176635742 seconds for one epoch ---
--- 0.44713783264160156 seconds for one epoch ---
--- 0.3381161689758301 seconds for one epoch ---
--- 0.4417750835418701 seconds for one epoch ---
--- 0.3172414302825928 seconds for one epoch ---
--- 0.45931196212768555 seconds for one epoch ---
--- 0.31863880157470703 seconds for one epoch ---
--- 0.44961023330688477 seconds for one epoch ---
--- 0.3177609443664551 seconds for one epoch ---
--- 0.4533722400665283 seconds for one epoch ---
--- 0.31184959411621094 seconds for one epoch ---
--- 0.4618713855743408 seconds for one epoch ---
--- 0.31397533416748047 seconds for one epoch ---
--- 0.4673905372619629 seconds for one epoch ---
--- 0.3233647346496582 seconds for one epoch ---
--- 0.45511412620544434 seconds for one epoch ---
--- 0.2947237491607666 seconds for one epoch ---
--- 0.43792223930358887 seconds for one epoch ---
--- 0.31035423278808594 seconds for one epoch ---
--- 0.4523451328277588 seconds for one epoch ---
--- 0.32762718200683594 seconds for one epoch ---
=========================
[[0.980469  ]
 [0.98505294]
 [1.        ]
 [0.1043285 ]
 [0.03321973]
 [1.        ]
 [0.03782928]
 [0.15345563]
 [0.03267258]
 [1.        ]
 [0.99949527]]
[[-5.5107492e-01]
 [-5.6470376e-01]
 [ 1.1970009e+00]
 [ 2.3093161e-01]
 [-2.7049731e-02]
 [-3.0672343e+00]
 [ 1.0222501e-01]
 [ 2.5965294e-01]
 [ 4.2452911e-04]
 [-1.6603545e+00]
 [ 7.3509556e-01]]
--- 0.26576972007751465 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7795.40234375, (3153.0115, 2.959307, 4458.341, 2.5318468)
   validation loss 2540.907958984375, (2009.3966, 0.0549439, 350.36545, 2.5318468)
decoder loss ratio: 77847.513000, decoder SINDy loss  ratio: 0.756313
--- 0.3232235908508301 seconds for one epoch ---
--- 0.4508523941040039 seconds for one epoch ---
--- 0.31565308570861816 seconds for one epoch ---
--- 0.4622797966003418 seconds for one epoch ---
--- 0.3146235942840576 seconds for one epoch ---
--- 0.4545884132385254 seconds for one epoch ---
--- 0.3177056312561035 seconds for one epoch ---
--- 0.44956398010253906 seconds for one epoch ---
--- 0.3209259510040283 seconds for one epoch ---
--- 0.4576408863067627 seconds for one epoch ---
--- 0.32088232040405273 seconds for one epoch ---
--- 0.4634706974029541 seconds for one epoch ---
--- 0.3230292797088623 seconds for one epoch ---
--- 0.4699118137359619 seconds for one epoch ---
--- 0.3141176700592041 seconds for one epoch ---
--- 0.46537017822265625 seconds for one epoch ---
--- 0.3269944190979004 seconds for one epoch ---
--- 0.46210789680480957 seconds for one epoch ---
--- 0.31940412521362305 seconds for one epoch ---
--- 0.45522546768188477 seconds for one epoch ---
--- 0.33626484870910645 seconds for one epoch ---
--- 0.4652266502380371 seconds for one epoch ---
--- 0.32636094093322754 seconds for one epoch ---
--- 0.4560580253601074 seconds for one epoch ---
=========================
[[0.9971539 ]
 [0.9942125 ]
 [1.        ]
 [0.10772294]
 [0.02787881]
 [1.        ]
 [0.03353574]
 [0.12960856]
 [0.02693741]
 [1.        ]
 [0.99915606]]
[[-6.4865839e-01]
 [-6.1297351e-01]
 [ 1.2201318e+00]
 [ 2.3706572e-01]
 [-4.0074404e-02]
 [-2.9951079e+00]
 [ 1.1294276e-01]
 [ 2.5019726e-01]
 [-7.6085812e-04]
 [-1.8269023e+00]
 [ 7.0964950e-01]]
--- 0.4255359172821045 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4514.09912109375, (2378.145, 0.24411061, 1950.1459, 2.531852)
   validation loss 2559.39892578125, (2005.7245, 0.04927085, 368.06116, 2.531852)
decoder loss ratio: 77705.248729, decoder SINDy loss  ratio: 0.794512
--- 0.27992963790893555 seconds for one epoch ---
--- 0.32814955711364746 seconds for one epoch ---
--- 0.46786952018737793 seconds for one epoch ---
--- 0.3227658271789551 seconds for one epoch ---
--- 0.4684453010559082 seconds for one epoch ---
--- 0.3110206127166748 seconds for one epoch ---
--- 0.4621920585632324 seconds for one epoch ---
--- 0.3182685375213623 seconds for one epoch ---
--- 0.4838724136352539 seconds for one epoch ---
--- 0.3280303478240967 seconds for one epoch ---
--- 0.4708750247955322 seconds for one epoch ---
--- 0.3017137050628662 seconds for one epoch ---
--- 0.4429960250854492 seconds for one epoch ---
--- 0.30847978591918945 seconds for one epoch ---
--- 0.47029781341552734 seconds for one epoch ---
--- 0.3204488754272461 seconds for one epoch ---
--- 0.46936559677124023 seconds for one epoch ---
--- 0.32531309127807617 seconds for one epoch ---
--- 0.4711596965789795 seconds for one epoch ---
--- 0.3085036277770996 seconds for one epoch ---
--- 0.49256253242492676 seconds for one epoch ---
--- 0.3272092342376709 seconds for one epoch ---
--- 0.4738297462463379 seconds for one epoch ---
--- 0.32091546058654785 seconds for one epoch ---
=========================
[[0.9993467 ]
 [0.99577194]
 [1.        ]
 [0.10304607]
 [0.0225703 ]
 [1.        ]
 [0.03635922]
 [0.11342274]
 [0.02193756]
 [1.        ]
 [0.9996717 ]]
[[-7.2276950e-01]
 [-6.2903243e-01]
 [ 1.2646610e+00]
 [ 2.3700532e-01]
 [-3.0176178e-02]
 [-2.9223487e+00]
 [ 1.4922786e-01]
 [ 2.4355470e-01]
 [-8.6285651e-04]
 [-1.9603779e+00]
 [ 7.5734311e-01]]
--- 0.263216495513916 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5133.27001953125, (1907.9554, 3.0233142, 3033.1052, 2.5318577)
   validation loss 2124.34619140625, (1564.9059, 0.04848016, 370.20578, 2.5318577)
decoder loss ratio: 60627.170734, decoder SINDy loss  ratio: 0.799141
--- 0.3258352279663086 seconds for one epoch ---
--- 0.4898991584777832 seconds for one epoch ---
--- 0.31534290313720703 seconds for one epoch ---
--- 0.4772160053253174 seconds for one epoch ---
--- 0.3204648494720459 seconds for one epoch ---
--- 0.4774456024169922 seconds for one epoch ---
--- 0.3199479579925537 seconds for one epoch ---
--- 0.4540524482727051 seconds for one epoch ---
--- 0.3255431652069092 seconds for one epoch ---
--- 0.4849412441253662 seconds for one epoch ---
--- 0.30414438247680664 seconds for one epoch ---
--- 0.4849264621734619 seconds for one epoch ---
--- 0.30800962448120117 seconds for one epoch ---
--- 0.4643564224243164 seconds for one epoch ---
--- 0.30664682388305664 seconds for one epoch ---
--- 0.47844886779785156 seconds for one epoch ---
--- 0.3119242191314697 seconds for one epoch ---
--- 0.49845194816589355 seconds for one epoch ---
--- 0.3092503547668457 seconds for one epoch ---
--- 0.48129844665527344 seconds for one epoch ---
--- 0.2975282669067383 seconds for one epoch ---
--- 0.4729037284851074 seconds for one epoch ---
--- 0.3083622455596924 seconds for one epoch ---
--- 0.4964611530303955 seconds for one epoch ---
=========================
[[0.9999142 ]
 [0.99673426]
 [1.        ]
 [0.10573082]
 [0.01880116]
 [1.        ]
 [0.02689046]
 [0.11269853]
 [0.01825899]
 [1.        ]
 [0.9998667 ]]
[[-0.8240033 ]
 [-0.6422008 ]
 [ 1.2585219 ]
 [ 0.24092337]
 [-0.02834413]
 [-2.855142  ]
 [ 0.12502405]
 [ 0.24511369]
 [-0.0033983 ]
 [-2.1326187 ]
 [ 0.8029206 ]]
--- 0.29671764373779297 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7833.9140625, (2689.7188, 3.8672132, 4947.9272, 2.5318642)
   validation loss 1442.347412109375, (858.5284, 0.059918158, 391.35788, 2.5318642)
decoder loss ratio: 33260.879964, decoder SINDy loss  ratio: 0.844801
--- 0.2598397731781006 seconds for one epoch ---
--- 0.3191094398498535 seconds for one epoch ---
--- 0.47524023056030273 seconds for one epoch ---
--- 0.3181345462799072 seconds for one epoch ---
--- 0.4787735939025879 seconds for one epoch ---
--- 0.3190140724182129 seconds for one epoch ---
--- 0.5087792873382568 seconds for one epoch ---
--- 0.3274810314178467 seconds for one epoch ---
--- 0.4896061420440674 seconds for one epoch ---
--- 0.32511401176452637 seconds for one epoch ---
--- 0.4715242385864258 seconds for one epoch ---
--- 0.326810359954834 seconds for one epoch ---
--- 0.49859023094177246 seconds for one epoch ---
--- 0.29698801040649414 seconds for one epoch ---
--- 0.5016961097717285 seconds for one epoch ---
--- 0.32370972633361816 seconds for one epoch ---
--- 0.4961433410644531 seconds for one epoch ---
--- 0.31444859504699707 seconds for one epoch ---
--- 0.4789869785308838 seconds for one epoch ---
--- 0.32082653045654297 seconds for one epoch ---
--- 0.49543261528015137 seconds for one epoch ---
--- 0.3347814083099365 seconds for one epoch ---
--- 0.49103403091430664 seconds for one epoch ---
--- 0.32285451889038086 seconds for one epoch ---
=========================
[[0.9999887 ]
 [0.99766976]
 [1.        ]
 [0.06633107]
 [0.01570072]
 [1.        ]
 [0.02517935]
 [0.10584898]
 [0.01504043]
 [1.        ]
 [0.99994683]]
[[-0.9321683 ]
 [-0.6593144 ]
 [ 1.2496603 ]
 [ 0.21243846]
 [-0.03365932]
 [-2.7955487 ]
 [ 0.13251267]
 [ 0.2428081 ]
 [-0.00566106]
 [-2.3071873 ]
 [ 0.84966916]]
--- 0.27140355110168457 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3088.8896484375, (1261.302, 0.60232216, 1632.5116, 2.5318737)
   validation loss 2110.17138671875, (1586.3151, 0.048048228, 329.33472, 2.5318737)
decoder loss ratio: 61456.599523, decoder SINDy loss  ratio: 0.710915
--- 0.3276097774505615 seconds for one epoch ---
--- 0.5226864814758301 seconds for one epoch ---
--- 0.3380458354949951 seconds for one epoch ---
--- 0.49147915840148926 seconds for one epoch ---
--- 0.32674574851989746 seconds for one epoch ---
--- 0.48404431343078613 seconds for one epoch ---
--- 0.31574082374572754 seconds for one epoch ---
--- 0.4865703582763672 seconds for one epoch ---
--- 0.31546998023986816 seconds for one epoch ---
--- 0.5164783000946045 seconds for one epoch ---
--- 0.3238518238067627 seconds for one epoch ---
--- 0.4894742965698242 seconds for one epoch ---
--- 0.33087682723999023 seconds for one epoch ---
--- 0.5170457363128662 seconds for one epoch ---
--- 0.32070040702819824 seconds for one epoch ---
--- 0.5100290775299072 seconds for one epoch ---
--- 0.3185241222381592 seconds for one epoch ---
--- 0.5140597820281982 seconds for one epoch ---
--- 0.33642077445983887 seconds for one epoch ---
--- 0.5032484531402588 seconds for one epoch ---
--- 0.331498384475708 seconds for one epoch ---
--- 0.5181727409362793 seconds for one epoch ---
--- 0.306593656539917 seconds for one epoch ---
--- 0.5034315586090088 seconds for one epoch ---
=========================
[[0.9999963 ]
 [0.9982398 ]
 [1.        ]
 [0.06783389]
 [0.0135673 ]
 [1.        ]
 [0.02142964]
 [0.0902699 ]
 [0.01255873]
 [1.        ]
 [0.99997365]]
[[-1.0320572 ]
 [-0.6735136 ]
 [ 1.2338235 ]
 [ 0.21616077]
 [-0.04254708]
 [-2.7504835 ]
 [ 0.12597854]
 [ 0.23420513]
 [-0.00294408]
 [-2.4589338 ]
 [ 0.8873739 ]]
--- 0.28951287269592285 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4148.49462890625, (2256.7239, 2.5683281, 1691.6674, 2.5318813)
   validation loss 1519.2916259765625, (942.9579, 0.05841466, 378.74045, 2.5318813)
decoder loss ratio: 36531.825541, decoder SINDy loss  ratio: 0.817565
THRESHOLDING: 6 active coefficients
--- 0.49608635902404785 seconds for one epoch ---
--- 0.32208895683288574 seconds for one epoch ---
--- 0.5108046531677246 seconds for one epoch ---
--- 0.3266754150390625 seconds for one epoch ---
--- 0.4975771903991699 seconds for one epoch ---
--- 0.3380775451660156 seconds for one epoch ---
--- 0.521160364151001 seconds for one epoch ---
--- 0.3388066291809082 seconds for one epoch ---
--- 0.5099005699157715 seconds for one epoch ---
--- 0.2919151782989502 seconds for one epoch ---
--- 0.5299782752990723 seconds for one epoch ---
--- 0.3147544860839844 seconds for one epoch ---
--- 0.5142252445220947 seconds for one epoch ---
--- 0.3221628665924072 seconds for one epoch ---
--- 0.5178256034851074 seconds for one epoch ---
--- 0.3265984058380127 seconds for one epoch ---
--- 0.5076968669891357 seconds for one epoch ---
--- 0.31543827056884766 seconds for one epoch ---
--- 0.5229537487030029 seconds for one epoch ---
--- 0.32769155502319336 seconds for one epoch ---
--- 0.4789164066314697 seconds for one epoch ---
--- 0.33991265296936035 seconds for one epoch ---
--- 0.5186500549316406 seconds for one epoch ---
--- 0.31222105026245117 seconds for one epoch ---
=========================
[[0.35868624]
 [0.9970304 ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9999731 ]]
[[-0.3263221 ]
 [-0.64737606]
 [ 1.1393554 ]
 [ 0.        ]
 [-0.        ]
 [-1.7163488 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.1043575 ]
 [ 0.88591045]]
--- 0.2668447494506836 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2530.3505859375, (1177.1324, 3.1878982, 1348.6831, 1.3471051)
   validation loss 1756.4136962890625, (1364.2618, 0.063145235, 390.74176, 1.3471051)
decoder loss ratio: 52853.872176, decoder SINDy loss  ratio: 0.843471
--- 0.30974245071411133 seconds for one epoch ---
--- 0.5169706344604492 seconds for one epoch ---
--- 0.32248830795288086 seconds for one epoch ---
--- 0.5103254318237305 seconds for one epoch ---
--- 0.30831027030944824 seconds for one epoch ---
--- 0.5006303787231445 seconds for one epoch ---
--- 0.3187427520751953 seconds for one epoch ---
--- 0.5140926837921143 seconds for one epoch ---
--- 0.3169698715209961 seconds for one epoch ---
--- 0.5170807838439941 seconds for one epoch ---
--- 0.3239107131958008 seconds for one epoch ---
--- 0.5019917488098145 seconds for one epoch ---
--- 0.33809852600097656 seconds for one epoch ---
--- 0.5174391269683838 seconds for one epoch ---
--- 0.3228132724761963 seconds for one epoch ---
--- 0.5217070579528809 seconds for one epoch ---
--- 0.31920623779296875 seconds for one epoch ---
--- 0.5160260200500488 seconds for one epoch ---
--- 0.3026430606842041 seconds for one epoch ---
--- 0.5295517444610596 seconds for one epoch ---
--- 0.319566011428833 seconds for one epoch ---
--- 0.5129861831665039 seconds for one epoch ---
--- 0.32245635986328125 seconds for one epoch ---
--- 0.5383696556091309 seconds for one epoch ---
=========================
[[0.01868043]
 [0.99708915]
 [0.9999961 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99999607]]
[[-0.13077441]
 [-0.64845514]
 [ 1.010235  ]
 [ 0.        ]
 [-0.        ]
 [-1.3941289 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.0232499 ]
 [ 0.96152836]]
--- 0.2962162494659424 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2118.04345703125, (1132.1055, 0.73787785, 983.9503, 1.249845)
   validation loss 1205.6810302734375, (853.99976, 0.091796696, 350.33957, 1.249845)
decoder loss ratio: 33085.433151, decoder SINDy loss  ratio: 0.756257
--- 0.2783653736114502 seconds for one epoch ---
--- 0.32372450828552246 seconds for one epoch ---
--- 0.5299320220947266 seconds for one epoch ---
--- 0.3226656913757324 seconds for one epoch ---
--- 0.5375514030456543 seconds for one epoch ---
--- 0.32055044174194336 seconds for one epoch ---
--- 0.5338568687438965 seconds for one epoch ---
--- 0.32286882400512695 seconds for one epoch ---
--- 0.5326273441314697 seconds for one epoch ---
--- 0.3217804431915283 seconds for one epoch ---
--- 0.5247395038604736 seconds for one epoch ---
--- 0.31374144554138184 seconds for one epoch ---
--- 0.5361108779907227 seconds for one epoch ---
--- 0.31138181686401367 seconds for one epoch ---
--- 0.5415306091308594 seconds for one epoch ---
--- 0.3228769302368164 seconds for one epoch ---
--- 0.5308566093444824 seconds for one epoch ---
--- 0.3225986957550049 seconds for one epoch ---
--- 0.5359525680541992 seconds for one epoch ---
--- 0.3313591480255127 seconds for one epoch ---
--- 0.5385410785675049 seconds for one epoch ---
--- 0.314450740814209 seconds for one epoch ---
--- 0.5469892024993896 seconds for one epoch ---
--- 0.32798099517822266 seconds for one epoch ---
=========================
[[0.01261315]
 [0.99839884]
 [0.9999433 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9999856 ]]
[[-0.10206529]
 [-0.678522  ]
 [ 0.847527  ]
 [ 0.        ]
 [-0.        ]
 [-1.2848797 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.0275376 ]
 [ 0.9118884 ]]
--- 0.26442480087280273 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4301.6904296875, (1421.4387, 2.8081806, 2876.2021, 1.2414466)
   validation loss 1614.2940673828125, (1282.057, 0.109687544, 330.88586, 1.2414466)
decoder loss ratio: 49669.114194, decoder SINDy loss  ratio: 0.714264
--- 0.3134431838989258 seconds for one epoch ---
--- 0.5117497444152832 seconds for one epoch ---
--- 0.3127155303955078 seconds for one epoch ---
--- 0.5306167602539062 seconds for one epoch ---
--- 0.3059680461883545 seconds for one epoch ---
--- 0.5348620414733887 seconds for one epoch ---
--- 0.3124871253967285 seconds for one epoch ---
--- 0.5638518333435059 seconds for one epoch ---
--- 0.327195405960083 seconds for one epoch ---
--- 0.5360074043273926 seconds for one epoch ---
--- 0.2932567596435547 seconds for one epoch ---
--- 0.5418853759765625 seconds for one epoch ---
--- 0.31787872314453125 seconds for one epoch ---
--- 0.533808708190918 seconds for one epoch ---
--- 0.32160234451293945 seconds for one epoch ---
--- 0.5327963829040527 seconds for one epoch ---
--- 0.333676815032959 seconds for one epoch ---
--- 0.5650346279144287 seconds for one epoch ---
--- 0.3316316604614258 seconds for one epoch ---
--- 0.5686509609222412 seconds for one epoch ---
--- 0.31926798820495605 seconds for one epoch ---
--- 0.5728099346160889 seconds for one epoch ---
--- 0.31739068031311035 seconds for one epoch ---
--- 0.5565226078033447 seconds for one epoch ---
=========================
[[0.01169084]
 [0.9988868 ]
 [0.9997077 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9999723 ]]
[[-0.10326539]
 [-0.69680643]
 [ 0.7638081 ]
 [ 0.        ]
 [-0.        ]
 [-1.1854198 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.0732965 ]
 [ 0.886787  ]]
--- 0.3171548843383789 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3728.6708984375, (1360.1812, 0.9816184, 2366.267, 1.2410955)
   validation loss 1567.4376220703125, (1169.4583, 0.13457759, 396.60376, 1.2410955)
decoder loss ratio: 45306.842949, decoder SINDy loss  ratio: 0.856125
--- 0.25433969497680664 seconds for one epoch ---
--- 0.31949496269226074 seconds for one epoch ---
--- 0.5607385635375977 seconds for one epoch ---
--- 0.32546567916870117 seconds for one epoch ---
--- 0.5460190773010254 seconds for one epoch ---
--- 0.31177783012390137 seconds for one epoch ---
--- 0.5598816871643066 seconds for one epoch ---
--- 0.30462169647216797 seconds for one epoch ---
--- 0.5808212757110596 seconds for one epoch ---
--- 0.3134267330169678 seconds for one epoch ---
--- 0.5672829151153564 seconds for one epoch ---
--- 0.31837964057922363 seconds for one epoch ---
--- 0.5418710708618164 seconds for one epoch ---
--- 0.3217582702636719 seconds for one epoch ---
--- 0.5497550964355469 seconds for one epoch ---
--- 0.30946874618530273 seconds for one epoch ---
--- 0.5608282089233398 seconds for one epoch ---
--- 0.3141164779663086 seconds for one epoch ---
--- 0.5536766052246094 seconds for one epoch ---
--- 0.31307363510131836 seconds for one epoch ---
--- 0.5682075023651123 seconds for one epoch ---
--- 0.3169543743133545 seconds for one epoch ---
--- 0.5765137672424316 seconds for one epoch ---
--- 0.31348395347595215 seconds for one epoch ---
=========================
[[0.02335502]
 [0.9987787 ]
 [0.99788094]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9999501 ]]
[[-0.15925466]
 [-0.6922129 ]
 [ 0.66456884]
 [ 0.        ]
 [-0.        ]
 [-1.167325  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.1426418 ]
 [ 0.8545435 ]]
--- 0.2695000171661377 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4741.287109375, (1658.7281, 0.59892875, 3080.7031, 1.2569292)
   validation loss 1536.3546142578125, (1210.7189, 0.13753727, 324.24115, 1.2569292)
decoder loss ratio: 46905.351004, decoder SINDy loss  ratio: 0.699920
--- 0.32936549186706543 seconds for one epoch ---
--- 0.5525579452514648 seconds for one epoch ---
--- 0.460895299911499 seconds for one epoch ---
--- 0.5330319404602051 seconds for one epoch ---
--- 0.32129526138305664 seconds for one epoch ---
--- 0.5647876262664795 seconds for one epoch ---
--- 0.3244922161102295 seconds for one epoch ---
--- 0.5743093490600586 seconds for one epoch ---
--- 0.3058595657348633 seconds for one epoch ---
--- 0.5525212287902832 seconds for one epoch ---
--- 0.322904109954834 seconds for one epoch ---
--- 0.5740995407104492 seconds for one epoch ---
--- 0.3170356750488281 seconds for one epoch ---
--- 0.5605189800262451 seconds for one epoch ---
--- 0.32277989387512207 seconds for one epoch ---
--- 0.5861737728118896 seconds for one epoch ---
--- 0.32207512855529785 seconds for one epoch ---
--- 0.5801610946655273 seconds for one epoch ---
--- 0.32268738746643066 seconds for one epoch ---
--- 0.5943000316619873 seconds for one epoch ---
--- 0.32134199142456055 seconds for one epoch ---
--- 0.5777566432952881 seconds for one epoch ---
--- 0.31892919540405273 seconds for one epoch ---
--- 0.5967354774475098 seconds for one epoch ---
=========================
[[0.06570605]
 [0.99887633]
 [0.9896464 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99978256]]
[[-0.22097465]
 [-0.6964214 ]
 [ 0.5847732 ]
 [ 0.        ]
 [-0.        ]
 [-1.1467164 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.2168157 ]
 [ 0.77881444]]
--- 0.29904842376708984 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4080.1083984375, (1381.644, 1.5607462, 2695.6162, 1.287411)
   validation loss 1652.421630859375, (1255.8905, 0.14018117, 395.10364, 1.287411)
decoder loss ratio: 48655.378405, decoder SINDy loss  ratio: 0.852887
--- 0.263089656829834 seconds for one epoch ---
--- 0.33031773567199707 seconds for one epoch ---
--- 0.5757975578308105 seconds for one epoch ---
--- 0.3161661624908447 seconds for one epoch ---
--- 0.5845479965209961 seconds for one epoch ---
--- 0.3249332904815674 seconds for one epoch ---
--- 0.5645205974578857 seconds for one epoch ---
--- 0.32288146018981934 seconds for one epoch ---
--- 0.5794389247894287 seconds for one epoch ---
--- 0.31980323791503906 seconds for one epoch ---
--- 0.5715944766998291 seconds for one epoch ---
--- 0.3177518844604492 seconds for one epoch ---
--- 0.5782585144042969 seconds for one epoch ---
--- 0.31954097747802734 seconds for one epoch ---
--- 0.5733704566955566 seconds for one epoch ---
--- 0.3138916492462158 seconds for one epoch ---
--- 0.5642232894897461 seconds for one epoch ---
--- 0.31557607650756836 seconds for one epoch ---
--- 0.5937943458557129 seconds for one epoch ---
--- 0.3225395679473877 seconds for one epoch ---
--- 0.5847609043121338 seconds for one epoch ---
--- 0.3155703544616699 seconds for one epoch ---
--- 0.5858969688415527 seconds for one epoch ---
--- 0.3132760524749756 seconds for one epoch ---
=========================
[[0.2331067 ]
 [0.9985497 ]
 [0.93692464]
 [0.        ]
 [0.        ]
 [0.99999964]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9997543 ]]
[[-0.29649004]
 [-0.68366516]
 [ 0.4916099 ]
 [ 0.        ]
 [-0.        ]
 [-1.1283089 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.315966  ]
 [ 0.77268475]]
--- 0.25937986373901367 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3324.881591796875, (1579.531, 0.4756727, 1743.5488, 1.326009)
   validation loss 989.1630249023438, (628.45184, 0.15313147, 359.23206, 1.326009)
decoder loss ratio: 24347.315448, decoder SINDy loss  ratio: 0.775453
--- 0.29398608207702637 seconds for one epoch ---
--- 0.5801963806152344 seconds for one epoch ---
--- 0.3152039051055908 seconds for one epoch ---
--- 0.5932793617248535 seconds for one epoch ---
--- 0.3056814670562744 seconds for one epoch ---
--- 0.5691683292388916 seconds for one epoch ---
--- 0.3075840473175049 seconds for one epoch ---
--- 0.5798394680023193 seconds for one epoch ---
--- 0.3284318447113037 seconds for one epoch ---
--- 0.5772354602813721 seconds for one epoch ---
--- 0.31836581230163574 seconds for one epoch ---
--- 0.6056842803955078 seconds for one epoch ---
--- 0.30867815017700195 seconds for one epoch ---
--- 0.5907883644104004 seconds for one epoch ---
--- 0.32163000106811523 seconds for one epoch ---
--- 0.5999407768249512 seconds for one epoch ---
--- 0.3261148929595947 seconds for one epoch ---
--- 0.576371431350708 seconds for one epoch ---
--- 0.3348538875579834 seconds for one epoch ---
--- 0.5985438823699951 seconds for one epoch ---
--- 0.3258039951324463 seconds for one epoch ---
--- 0.5887413024902344 seconds for one epoch ---
--- 0.32424187660217285 seconds for one epoch ---
--- 0.5863866806030273 seconds for one epoch ---
=========================
[[0.5583431]
 [0.9975583]
 [0.9068578]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.9995999]]
[[-0.3682426 ]
 [-0.65755814]
 [ 0.4704906 ]
 [ 0.        ]
 [-0.        ]
 [-1.1354234 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.3780062 ]
 [ 0.7482663 ]]
--- 0.31515049934387207 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4975.46923828125, (1706.6675, 3.436726, 3263.985, 1.379785)
   validation loss 1403.2650146484375, (1068.8157, 0.2106066, 332.859, 1.379785)
decoder loss ratio: 41407.774750, decoder SINDy loss  ratio: 0.718523
--- 0.27674317359924316 seconds for one epoch ---
--- 0.3256502151489258 seconds for one epoch ---
--- 0.59043288230896 seconds for one epoch ---
--- 0.313579797744751 seconds for one epoch ---
--- 0.6113986968994141 seconds for one epoch ---
--- 0.31241464614868164 seconds for one epoch ---
--- 0.5886459350585938 seconds for one epoch ---
--- 0.3227424621582031 seconds for one epoch ---
--- 0.6090209484100342 seconds for one epoch ---
--- 0.3321201801300049 seconds for one epoch ---
--- 0.5900180339813232 seconds for one epoch ---
--- 0.28702425956726074 seconds for one epoch ---
--- 0.5942370891571045 seconds for one epoch ---
--- 0.26755475997924805 seconds for one epoch ---
--- 0.5648460388183594 seconds for one epoch ---
--- 0.32211899757385254 seconds for one epoch ---
--- 0.598818302154541 seconds for one epoch ---
--- 0.3070363998413086 seconds for one epoch ---
--- 0.6171097755432129 seconds for one epoch ---
--- 0.3032565116882324 seconds for one epoch ---
--- 0.5960462093353271 seconds for one epoch ---
--- 0.2968308925628662 seconds for one epoch ---
--- 0.6326634883880615 seconds for one epoch ---
--- 0.32551050186157227 seconds for one epoch ---
=========================
[[0.70398766]
 [0.9981365 ]
 [0.849682  ]
 [0.        ]
 [0.        ]
 [0.99999726]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99902   ]]
[[-0.39994356]
 [-0.6711419 ]
 [ 0.4432946 ]
 [ 0.        ]
 [-0.        ]
 [-1.0831877 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.4317868 ]
 [ 0.7033878 ]]
--- 0.2655777931213379 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3963.70849609375, (2394.306, 0.18804227, 1567.819, 1.395418)
   validation loss 1314.9222412109375, (1006.40533, 0.18103425, 306.94052, 1.395418)
decoder loss ratio: 38989.889854, decoder SINDy loss  ratio: 0.662574
--- 0.31571340560913086 seconds for one epoch ---
--- 0.5897400379180908 seconds for one epoch ---
--- 0.3290748596191406 seconds for one epoch ---
--- 0.6102635860443115 seconds for one epoch ---
--- 0.3231985569000244 seconds for one epoch ---
--- 0.5970869064331055 seconds for one epoch ---
--- 0.3235025405883789 seconds for one epoch ---
--- 0.6054818630218506 seconds for one epoch ---
--- 0.32655954360961914 seconds for one epoch ---
--- 0.6050546169281006 seconds for one epoch ---
--- 0.305849552154541 seconds for one epoch ---
--- 0.6067967414855957 seconds for one epoch ---
--- 0.31882357597351074 seconds for one epoch ---
--- 0.6116337776184082 seconds for one epoch ---
--- 0.31294751167297363 seconds for one epoch ---
--- 0.6108899116516113 seconds for one epoch ---
--- 0.30380702018737793 seconds for one epoch ---
--- 0.6043417453765869 seconds for one epoch ---
--- 0.31789588928222656 seconds for one epoch ---
--- 0.6078648567199707 seconds for one epoch ---
--- 0.31499743461608887 seconds for one epoch ---
--- 0.6046340465545654 seconds for one epoch ---
--- 0.31650280952453613 seconds for one epoch ---
--- 0.607032060623169 seconds for one epoch ---
=========================
[[0.9507326 ]
 [0.9992075 ]
 [0.77180195]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9976704 ]]
[[-0.5047777 ]
 [-0.7140153 ]
 [ 0.41760156]
 [ 0.        ]
 [-0.        ]
 [-1.1185946 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5216148 ]
 [ 0.6599491 ]]
--- 0.3109242916107178 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3499.457763671875, (1123.1517, 1.6837945, 2373.2104, 1.4119707)
   validation loss 1262.5853271484375, (915.4537, 0.19097416, 345.52872, 1.4119707)
decoder loss ratio: 35466.264640, decoder SINDy loss  ratio: 0.745872
--- 0.2811248302459717 seconds for one epoch ---
--- 0.3297617435455322 seconds for one epoch ---
--- 0.5861756801605225 seconds for one epoch ---
--- 0.3168158531188965 seconds for one epoch ---
--- 0.5935623645782471 seconds for one epoch ---
--- 0.3164408206939697 seconds for one epoch ---
--- 0.6119861602783203 seconds for one epoch ---
--- 0.3313486576080322 seconds for one epoch ---
--- 0.6019878387451172 seconds for one epoch ---
--- 0.2830369472503662 seconds for one epoch ---
--- 0.6161117553710938 seconds for one epoch ---
--- 0.30890345573425293 seconds for one epoch ---
--- 0.624269962310791 seconds for one epoch ---
--- 0.32166314125061035 seconds for one epoch ---
--- 0.6296923160552979 seconds for one epoch ---
--- 0.3161947727203369 seconds for one epoch ---
--- 0.5919458866119385 seconds for one epoch ---
--- 0.33309149742126465 seconds for one epoch ---
--- 0.6225628852844238 seconds for one epoch ---
--- 0.32182931900024414 seconds for one epoch ---
--- 0.6315717697143555 seconds for one epoch ---
--- 0.3166005611419678 seconds for one epoch ---
--- 0.6339049339294434 seconds for one epoch ---
--- 0.3296468257904053 seconds for one epoch ---
=========================
[[0.9874333 ]
 [0.99953043]
 [0.6060021 ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99797153]]
[[-0.57508004]
 [-0.740259  ]
 [ 0.37816328]
 [ 0.        ]
 [-0.        ]
 [-1.0981561 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6110613 ]
 [ 0.6669067 ]]
--- 0.2662041187286377 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2467.04638671875, (1243.1588, 0.9063326, 1221.5857, 1.3954622)
   validation loss 1667.336181640625, (1328.164, 0.14161138, 337.63513, 1.3954622)
decoder loss ratio: 51455.376846, decoder SINDy loss  ratio: 0.728833
--- 0.3338451385498047 seconds for one epoch ---
--- 0.6192591190338135 seconds for one epoch ---
--- 0.3214998245239258 seconds for one epoch ---
--- 0.6390306949615479 seconds for one epoch ---
--- 0.3313109874725342 seconds for one epoch ---
--- 0.6402745246887207 seconds for one epoch ---
--- 0.33053064346313477 seconds for one epoch ---
--- 0.6371886730194092 seconds for one epoch ---
--- 0.3048245906829834 seconds for one epoch ---
--- 0.6246681213378906 seconds for one epoch ---
--- 0.3211171627044678 seconds for one epoch ---
--- 0.6325349807739258 seconds for one epoch ---
--- 0.31592893600463867 seconds for one epoch ---
--- 0.6294436454772949 seconds for one epoch ---
--- 0.32263898849487305 seconds for one epoch ---
--- 0.6357433795928955 seconds for one epoch ---
--- 0.3190653324127197 seconds for one epoch ---
--- 0.6265347003936768 seconds for one epoch ---
--- 0.3186523914337158 seconds for one epoch ---
--- 0.6192474365234375 seconds for one epoch ---
--- 0.32138490676879883 seconds for one epoch ---
--- 0.6342735290527344 seconds for one epoch ---
--- 0.31258440017700195 seconds for one epoch ---
--- 0.641453742980957 seconds for one epoch ---
=========================
[[0.9956724 ]
 [0.9994099 ]
 [0.5410742 ]
 [0.        ]
 [0.        ]
 [0.99999595]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9974754 ]]
[[-0.62887454]
 [-0.72883034]
 [ 0.36486614]
 [ 0.        ]
 [-0.        ]
 [-1.0697035 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.675216  ]
 [ 0.6559402 ]]
--- 0.30761170387268066 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5831.47021484375, (3631.81, 1.083965, 2197.1907, 1.3853276)
   validation loss 1145.7691650390625, (760.2336, 0.271194, 383.8791, 1.3853276)
decoder loss ratio: 29452.768773, decoder SINDy loss  ratio: 0.828657
--- 0.281374454498291 seconds for one epoch ---
--- 0.3186643123626709 seconds for one epoch ---
--- 0.6327633857727051 seconds for one epoch ---
--- 0.32816171646118164 seconds for one epoch ---
--- 0.6492741107940674 seconds for one epoch ---
--- 0.32349514961242676 seconds for one epoch ---
--- 0.648590087890625 seconds for one epoch ---
--- 0.32013821601867676 seconds for one epoch ---
--- 0.6497106552124023 seconds for one epoch ---
--- 0.3296630382537842 seconds for one epoch ---
--- 0.6574339866638184 seconds for one epoch ---
--- 0.32280683517456055 seconds for one epoch ---
--- 0.6498456001281738 seconds for one epoch ---
--- 0.3206648826599121 seconds for one epoch ---
--- 0.6619377136230469 seconds for one epoch ---
--- 0.32320165634155273 seconds for one epoch ---
--- 0.6686351299285889 seconds for one epoch ---
--- 0.3232555389404297 seconds for one epoch ---
--- 0.6612460613250732 seconds for one epoch ---
--- 0.34130334854125977 seconds for one epoch ---
--- 0.6442711353302002 seconds for one epoch ---
--- 0.30686044692993164 seconds for one epoch ---
--- 0.6648356914520264 seconds for one epoch ---
--- 0.3398268222808838 seconds for one epoch ---
=========================
[[0.9988285 ]
 [0.99672544]
 [0.46038592]
 [0.        ]
 [0.        ]
 [0.9999956 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99542516]]
[[-0.69448406]
 [-0.64289886]
 [ 0.34868324]
 [ 0.        ]
 [-0.        ]
 [-1.0613567 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7413328 ]
 [ 0.6260963 ]]
--- 0.24682950973510742 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5507.46044921875, (1987.2411, 1.2279912, 3517.6167, 1.3744439)
   validation loss 1487.337158203125, (1116.9645, 0.18592565, 368.81235, 1.3744439)
decoder loss ratio: 43273.142995, decoder SINDy loss  ratio: 0.796133
--- 0.29749131202697754 seconds for one epoch ---
--- 0.6489417552947998 seconds for one epoch ---
--- 0.32346177101135254 seconds for one epoch ---
--- 0.6528053283691406 seconds for one epoch ---
--- 0.3177168369293213 seconds for one epoch ---
--- 0.6346361637115479 seconds for one epoch ---
--- 0.3104972839355469 seconds for one epoch ---
--- 0.6397199630737305 seconds for one epoch ---
--- 0.32013559341430664 seconds for one epoch ---
--- 0.6580946445465088 seconds for one epoch ---
--- 0.31491756439208984 seconds for one epoch ---
--- 0.6625642776489258 seconds for one epoch ---
--- 0.3340442180633545 seconds for one epoch ---
--- 0.6579761505126953 seconds for one epoch ---
--- 0.3199155330657959 seconds for one epoch ---
--- 0.6700193881988525 seconds for one epoch ---
--- 0.3168478012084961 seconds for one epoch ---
--- 0.6538805961608887 seconds for one epoch ---
--- 0.3257761001586914 seconds for one epoch ---
--- 0.6654472351074219 seconds for one epoch ---
--- 0.32726359367370605 seconds for one epoch ---
--- 0.6453545093536377 seconds for one epoch ---
--- 0.3248319625854492 seconds for one epoch ---
--- 0.6493687629699707 seconds for one epoch ---
=========================
[[0.9996517 ]
 [0.99824214]
 [0.521695  ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.98371446]]
[[-0.7553212 ]
 [-0.67412555]
 [ 0.36100316]
 [ 0.        ]
 [-0.        ]
 [-1.0594182 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.784541  ]
 [ 0.5619442 ]]
--- 0.2977743148803711 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5541.77099609375, (1933.5969, 3.1422815, 3603.651, 1.3809588)
   validation loss 1187.3388671875, (860.1417, 0.15807533, 325.6581, 1.3809588)
decoder loss ratio: 33323.383645, decoder SINDy loss  ratio: 0.702979
--- 0.280285120010376 seconds for one epoch ---
--- 0.32109975814819336 seconds for one epoch ---
--- 0.6497032642364502 seconds for one epoch ---
--- 0.32736873626708984 seconds for one epoch ---
--- 0.6767289638519287 seconds for one epoch ---
--- 0.3150155544281006 seconds for one epoch ---
--- 0.6524186134338379 seconds for one epoch ---
--- 0.32417964935302734 seconds for one epoch ---
--- 0.6603143215179443 seconds for one epoch ---
--- 0.31008267402648926 seconds for one epoch ---
--- 0.6496756076812744 seconds for one epoch ---
--- 0.3144550323486328 seconds for one epoch ---
--- 0.6903061866760254 seconds for one epoch ---
--- 0.3271172046661377 seconds for one epoch ---
--- 0.6645328998565674 seconds for one epoch ---
--- 0.3175168037414551 seconds for one epoch ---
--- 0.6639072895050049 seconds for one epoch ---
--- 0.29357337951660156 seconds for one epoch ---
--- 0.6467621326446533 seconds for one epoch ---
--- 0.31539297103881836 seconds for one epoch ---
--- 0.6713786125183105 seconds for one epoch ---
--- 0.30376672744750977 seconds for one epoch ---
--- 0.6595971584320068 seconds for one epoch ---
--- 0.3104538917541504 seconds for one epoch ---
=========================
[[0.99982524]
 [0.99755687]
 [0.42712003]
 [0.        ]
 [0.        ]
 [0.9999954 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.96277505]]
[[-0.7901653 ]
 [-0.65761864]
 [ 0.34196466]
 [ 0.        ]
 [-0.        ]
 [-1.0279652 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8199875 ]
 [ 0.5194933 ]]
--- 0.26010704040527344 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2296.12158203125, (1049.4982, 0.13433684, 1245.125, 1.3641651)
   validation loss 1443.9158935546875, (1019.94086, 0.21670862, 422.3942, 1.3641651)
decoder loss ratio: 39514.279493, decoder SINDy loss  ratio: 0.911797
--- 0.31409358978271484 seconds for one epoch ---
--- 0.6725847721099854 seconds for one epoch ---
--- 0.32143735885620117 seconds for one epoch ---
--- 0.6631665229797363 seconds for one epoch ---
--- 0.31479692459106445 seconds for one epoch ---
--- 0.6844637393951416 seconds for one epoch ---
--- 0.3273046016693115 seconds for one epoch ---
--- 0.6431026458740234 seconds for one epoch ---
--- 0.3168938159942627 seconds for one epoch ---
--- 0.6750385761260986 seconds for one epoch ---
--- 0.3263227939605713 seconds for one epoch ---
--- 0.6769278049468994 seconds for one epoch ---
--- 0.3178215026855469 seconds for one epoch ---
--- 0.6737151145935059 seconds for one epoch ---
--- 0.32629871368408203 seconds for one epoch ---
--- 0.6804008483886719 seconds for one epoch ---
--- 0.30550599098205566 seconds for one epoch ---
--- 0.6942458152770996 seconds for one epoch ---
--- 0.31120944023132324 seconds for one epoch ---
--- 0.6888949871063232 seconds for one epoch ---
--- 0.31719541549682617 seconds for one epoch ---
--- 0.6826403141021729 seconds for one epoch ---
--- 0.32663798332214355 seconds for one epoch ---
--- 0.6963584423065186 seconds for one epoch ---
=========================
[[0.99994916]
 [0.99790883]
 [0.49161753]
 [0.        ]
 [0.        ]
 [0.99999535]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.9129879 ]]
[[-0.85405505]
 [-0.6654302 ]
 [ 0.35500172]
 [ 0.        ]
 [-0.        ]
 [-1.0041703 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8857706 ]
 [ 0.47434372]]
--- 0.31024956703186035 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4176.48095703125, (1512.4609, 0.98810494, 2661.6555, 1.3763456)
   validation loss 2258.10009765625, (1924.5634, 0.14050573, 332.01978, 1.3763456)
decoder loss ratio: 74560.925542, decoder SINDy loss  ratio: 0.716711
--- 0.27109479904174805 seconds for one epoch ---
--- 0.30925583839416504 seconds for one epoch ---
--- 0.6712119579315186 seconds for one epoch ---
--- 0.3114197254180908 seconds for one epoch ---
--- 0.6697616577148438 seconds for one epoch ---
--- 0.3259429931640625 seconds for one epoch ---
--- 0.6572830677032471 seconds for one epoch ---
--- 0.3119494915008545 seconds for one epoch ---
--- 0.6777758598327637 seconds for one epoch ---
--- 0.3337864875793457 seconds for one epoch ---
--- 0.6875936985015869 seconds for one epoch ---
--- 0.3218250274658203 seconds for one epoch ---
--- 0.6639828681945801 seconds for one epoch ---
--- 0.4618349075317383 seconds for one epoch ---
--- 0.6665799617767334 seconds for one epoch ---
--- 0.3033907413482666 seconds for one epoch ---
--- 0.6756668090820312 seconds for one epoch ---
--- 0.3266468048095703 seconds for one epoch ---
--- 0.7038531303405762 seconds for one epoch ---
--- 0.3156697750091553 seconds for one epoch ---
--- 0.6698663234710693 seconds for one epoch ---
--- 0.32928013801574707 seconds for one epoch ---
--- 0.674220085144043 seconds for one epoch ---
--- 0.298886775970459 seconds for one epoch ---
=========================
[[0.99998033]
 [0.9985382 ]
 [0.45650014]
 [0.        ]
 [0.        ]
 [0.99999523]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.63824844]]
[[-0.9063511 ]
 [-0.68338484]
 [ 0.34795746]
 [ 0.        ]
 [-0.        ]
 [-1.0046906 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9165776 ]
 [ 0.3851135 ]]
--- 0.2631046772003174 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6463.49609375, (3400.055, 2.7499776, 3059.3625, 1.3286481)
   validation loss 1752.779296875, (1455.818, 0.24280226, 295.38995, 1.3286481)
decoder loss ratio: 56400.916466, decoder SINDy loss  ratio: 0.637641
--- 0.31461191177368164 seconds for one epoch ---
--- 0.7093708515167236 seconds for one epoch ---
--- 0.3024756908416748 seconds for one epoch ---
--- 0.679030179977417 seconds for one epoch ---
--- 0.31424570083618164 seconds for one epoch ---
--- 0.7091529369354248 seconds for one epoch ---
--- 0.32488393783569336 seconds for one epoch ---
--- 0.700831413269043 seconds for one epoch ---
--- 0.30844616889953613 seconds for one epoch ---
--- 0.6863532066345215 seconds for one epoch ---
--- 0.33446669578552246 seconds for one epoch ---
--- 0.6997394561767578 seconds for one epoch ---
--- 0.32399892807006836 seconds for one epoch ---
--- 0.6914105415344238 seconds for one epoch ---
--- 0.31162047386169434 seconds for one epoch ---
--- 0.688793420791626 seconds for one epoch ---
--- 0.3094208240509033 seconds for one epoch ---
--- 0.7003381252288818 seconds for one epoch ---
--- 0.31343698501586914 seconds for one epoch ---
--- 0.7112457752227783 seconds for one epoch ---
--- 0.3063395023345947 seconds for one epoch ---
--- 0.6990840435028076 seconds for one epoch ---
--- 0.3272695541381836 seconds for one epoch ---
--- 0.7032203674316406 seconds for one epoch ---
=========================
[[0.9999943 ]
 [0.9994197 ]
 [0.40886995]
 [0.        ]
 [0.        ]
 [0.99999523]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.35077927]]
[[-0.9448868 ]
 [-0.72969854]
 [ 0.33824345]
 [ 0.        ]
 [-0.        ]
 [-0.9852762 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9493608 ]
 [ 0.32587627]]
--- 0.30576467514038086 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3894.31103515625, (1354.7638, 1.0922203, 2537.18, 1.275106)
   validation loss 1073.2978515625, (716.3235, 0.11430671, 355.5849, 1.275106)
decoder loss ratio: 27751.615453, decoder SINDy loss  ratio: 0.767580
--- 0.27666568756103516 seconds for one epoch ---
--- 0.30863475799560547 seconds for one epoch ---
--- 0.711418867111206 seconds for one epoch ---
--- 0.31885290145874023 seconds for one epoch ---
--- 0.709038496017456 seconds for one epoch ---
--- 0.3019697666168213 seconds for one epoch ---
--- 0.7097387313842773 seconds for one epoch ---
--- 0.3237595558166504 seconds for one epoch ---
--- 0.7204930782318115 seconds for one epoch ---
--- 0.32079505920410156 seconds for one epoch ---
--- 0.7223374843597412 seconds for one epoch ---
--- 0.31517863273620605 seconds for one epoch ---
--- 0.7114815711975098 seconds for one epoch ---
--- 0.31232762336730957 seconds for one epoch ---
--- 0.7021157741546631 seconds for one epoch ---
--- 0.3165092468261719 seconds for one epoch ---
--- 0.7356157302856445 seconds for one epoch ---
--- 0.32665228843688965 seconds for one epoch ---
--- 0.7167379856109619 seconds for one epoch ---
--- 0.32276225090026855 seconds for one epoch ---
--- 0.7197365760803223 seconds for one epoch ---
--- 0.33386945724487305 seconds for one epoch ---
--- 0.7127656936645508 seconds for one epoch ---
--- 0.3158421516418457 seconds for one epoch ---
=========================
[[0.9999951 ]
 [0.99940693]
 [0.44024926]
 [0.        ]
 [0.        ]
 [0.9999951 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.37891775]]
[[-0.98996234]
 [-0.7286503 ]
 [ 0.34468514]
 [ 0.        ]
 [-0.        ]
 [-0.97283   ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9770873 ]
 [ 0.331969  ]]
--- 0.2711911201477051 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3967.2373046875, (1552.6819, 0.94472086, 2412.3257, 1.2850986)
   validation loss 1134.1060791015625, (715.8908, 0.2558957, 416.6742, 1.2850986)
decoder loss ratio: 27734.852747, decoder SINDy loss  ratio: 0.899450
--- 0.31963586807250977 seconds for one epoch ---
--- 0.707573652267456 seconds for one epoch ---
--- 0.31602025032043457 seconds for one epoch ---
--- 0.6956288814544678 seconds for one epoch ---
--- 0.30016350746154785 seconds for one epoch ---
--- 0.7009382247924805 seconds for one epoch ---
--- 0.3166947364807129 seconds for one epoch ---
--- 0.7144367694854736 seconds for one epoch ---
--- 0.3244059085845947 seconds for one epoch ---
--- 0.7247624397277832 seconds for one epoch ---
--- 0.32640552520751953 seconds for one epoch ---
--- 0.7272753715515137 seconds for one epoch ---
--- 0.316204309463501 seconds for one epoch ---
--- 0.7326564788818359 seconds for one epoch ---
--- 0.3211507797241211 seconds for one epoch ---
--- 0.7330648899078369 seconds for one epoch ---
--- 0.33266305923461914 seconds for one epoch ---
--- 0.7186896800994873 seconds for one epoch ---
--- 0.3286459445953369 seconds for one epoch ---
--- 0.7458615303039551 seconds for one epoch ---
--- 0.3280043601989746 seconds for one epoch ---
--- 0.7246932983398438 seconds for one epoch ---
--- 0.3239247798919678 seconds for one epoch ---
--- 0.7433853149414062 seconds for one epoch ---
=========================
[[0.9999951 ]
 [0.99975026]
 [0.4494902 ]
 [0.        ]
 [0.        ]
 [0.99999505]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.4716367 ]]
[[-1.0289342 ]
 [-0.77199346]
 [ 0.34656495]
 [ 0.        ]
 [-0.        ]
 [-0.9527949 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.010057  ]
 [ 0.3510278 ]]
--- 0.30287981033325195 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3804.634521484375, (1773.5162, 0.5724566, 2029.238, 1.3077824)
   validation loss 1114.517822265625, (736.6018, 0.1944841, 376.41385, 1.3077824)
decoder loss ratio: 28537.232786, decoder SINDy loss  ratio: 0.812542
THRESHOLDING: 6 active coefficients
--- 0.6920921802520752 seconds for one epoch ---
--- 0.30646729469299316 seconds for one epoch ---
--- 0.7249279022216797 seconds for one epoch ---
--- 0.3210759162902832 seconds for one epoch ---
--- 0.7124652862548828 seconds for one epoch ---
--- 0.3309900760650635 seconds for one epoch ---
--- 0.7198877334594727 seconds for one epoch ---
--- 0.3212146759033203 seconds for one epoch ---
--- 0.7275419235229492 seconds for one epoch ---
--- 0.2984590530395508 seconds for one epoch ---
--- 0.7090737819671631 seconds for one epoch ---
--- 0.3196532726287842 seconds for one epoch ---
--- 0.7392196655273438 seconds for one epoch ---
--- 0.3339083194732666 seconds for one epoch ---
--- 0.7347447872161865 seconds for one epoch ---
--- 0.3290414810180664 seconds for one epoch ---
--- 0.7570772171020508 seconds for one epoch ---
--- 0.3268725872039795 seconds for one epoch ---
--- 0.7283177375793457 seconds for one epoch ---
--- 0.3405442237854004 seconds for one epoch ---
--- 0.7383286952972412 seconds for one epoch ---
--- 0.324373722076416 seconds for one epoch ---
--- 0.7362730503082275 seconds for one epoch ---
--- 0.3100247383117676 seconds for one epoch ---
=========================
[[0.99999726]
 [0.9990761 ]
 [0.5348533 ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.4275454 ]]
[[-1.098107  ]
 [-0.7064429 ]
 [ 0.3637072 ]
 [ 0.        ]
 [-0.        ]
 [-0.94197744]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0817683 ]
 [ 0.34210894]]
--- 0.2637650966644287 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4257.34716796875, (1823.248, 5.833654, 2426.983, 1.2826506)
   validation loss 1353.5244140625, (1052.8107, 0.19202599, 299.23914, 1.2826506)
decoder loss ratio: 40787.713075, decoder SINDy loss  ratio: 0.645950
--- 0.30341434478759766 seconds for one epoch ---
--- 0.7289550304412842 seconds for one epoch ---
--- 0.321378231048584 seconds for one epoch ---
--- 0.7052693367004395 seconds for one epoch ---
--- 0.3141288757324219 seconds for one epoch ---
--- 0.7405989170074463 seconds for one epoch ---
--- 0.323275089263916 seconds for one epoch ---
--- 0.7392053604125977 seconds for one epoch ---
--- 0.30936288833618164 seconds for one epoch ---
--- 0.7326779365539551 seconds for one epoch ---
--- 0.30515360832214355 seconds for one epoch ---
--- 0.7299208641052246 seconds for one epoch ---
--- 0.30994343757629395 seconds for one epoch ---
--- 0.7459945678710938 seconds for one epoch ---
--- 0.32118773460388184 seconds for one epoch ---
--- 0.7451131343841553 seconds for one epoch ---
--- 0.31905341148376465 seconds for one epoch ---
--- 0.7585921287536621 seconds for one epoch ---
--- 0.3155691623687744 seconds for one epoch ---
--- 0.7510678768157959 seconds for one epoch ---
--- 0.3298344612121582 seconds for one epoch ---
--- 0.7640032768249512 seconds for one epoch ---
--- 0.3154022693634033 seconds for one epoch ---
--- 0.7588450908660889 seconds for one epoch ---
=========================
[[0.99999976]
 [0.9988877 ]
 [0.51884484]
 [0.        ]
 [0.        ]
 [0.99998516]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.34803355]]
[[-1.1524916 ]
 [-0.6971173 ]
 [ 0.3604968 ]
 [ 0.        ]
 [-0.        ]
 [-0.9293417 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.1391637 ]
 [ 0.32530433]]
--- 0.3139183521270752 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2587.284912109375, (1229.9688, 0.45729345, 1355.5858, 1.273309)
   validation loss 1082.0140380859375, (729.6064, 0.2310627, 350.90332, 1.273309)
decoder loss ratio: 28266.217979, decoder SINDy loss  ratio: 0.757474
--- 0.27999234199523926 seconds for one epoch ---
--- 0.31935882568359375 seconds for one epoch ---
--- 0.736309289932251 seconds for one epoch ---
--- 0.313107967376709 seconds for one epoch ---
--- 0.7509236335754395 seconds for one epoch ---
--- 0.32573795318603516 seconds for one epoch ---
--- 0.7590663433074951 seconds for one epoch ---
--- 0.3373904228210449 seconds for one epoch ---
--- 0.7410962581634521 seconds for one epoch ---
--- 0.29982995986938477 seconds for one epoch ---
--- 0.7601354122161865 seconds for one epoch ---
--- 0.31549644470214844 seconds for one epoch ---
--- 0.735424280166626 seconds for one epoch ---
--- 0.3144259452819824 seconds for one epoch ---
--- 0.7455394268035889 seconds for one epoch ---
--- 0.31646299362182617 seconds for one epoch ---
--- 0.7488663196563721 seconds for one epoch ---
--- 0.3204202651977539 seconds for one epoch ---
--- 0.7512025833129883 seconds for one epoch ---
--- 0.31015920639038086 seconds for one epoch ---
--- 0.7419772148132324 seconds for one epoch ---
--- 0.31789588928222656 seconds for one epoch ---
--- 0.7573168277740479 seconds for one epoch ---
--- 0.31767821311950684 seconds for one epoch ---
=========================
[[1.        ]
 [0.9987128 ]
 [0.36264843]
 [0.        ]
 [0.        ]
 [0.9999848 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.21559438]]
[[-1.2276065 ]
 [-0.6897887 ]
 [ 0.32850367]
 [ 0.        ]
 [-0.        ]
 [-0.9273451 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.2134454 ]
 [ 0.292077  ]]
--- 0.26384687423706055 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4113.31298828125, (2299.5657, 1.375764, 1811.1421, 1.2295969)
   validation loss 1090.2056884765625, (736.1043, 0.19573823, 352.67603, 1.2295969)
decoder loss ratio: 28517.958867, decoder SINDy loss  ratio: 0.761301
--- 0.30824780464172363 seconds for one epoch ---
--- 0.7506294250488281 seconds for one epoch ---
--- 0.3281519412994385 seconds for one epoch ---
--- 0.7687950134277344 seconds for one epoch ---
--- 0.31910228729248047 seconds for one epoch ---
--- 0.7821648120880127 seconds for one epoch ---
--- 0.3277754783630371 seconds for one epoch ---
--- 0.7686290740966797 seconds for one epoch ---
--- 0.3343198299407959 seconds for one epoch ---
--- 0.7725608348846436 seconds for one epoch ---
--- 0.32406091690063477 seconds for one epoch ---
--- 0.7650444507598877 seconds for one epoch ---
--- 0.31388378143310547 seconds for one epoch ---
--- 0.7689356803894043 seconds for one epoch ---
--- 0.3295142650604248 seconds for one epoch ---
--- 0.7647421360015869 seconds for one epoch ---
--- 0.3351421356201172 seconds for one epoch ---
--- 0.7526886463165283 seconds for one epoch ---
--- 0.32184648513793945 seconds for one epoch ---
--- 0.7647676467895508 seconds for one epoch ---
--- 0.32846999168395996 seconds for one epoch ---
--- 0.7867472171783447 seconds for one epoch ---
--- 0.3262476921081543 seconds for one epoch ---
--- 0.7690062522888184 seconds for one epoch ---
=========================
[[1.        ]
 [0.9980639 ]
 [0.33473402]
 [0.        ]
 [0.        ]
 [0.9999845 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.0894511 ]]
[[-1.2733784 ]
 [-0.6693235 ]
 [ 0.3223534 ]
 [ 0.        ]
 [-0.        ]
 [-0.91870016]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.2438476 ]
 [ 0.2405486 ]]
--- 0.308535099029541 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5388.53271484375, (2839.1753, 0.5985321, 2547.5742, 1.1845865)
   validation loss 869.834716796875, (568.62634, 0.20021996, 299.8236, 1.1845865)
decoder loss ratio: 22029.571698, decoder SINDy loss  ratio: 0.647211
--- 0.259357213973999 seconds for one epoch ---
--- 0.3231823444366455 seconds for one epoch ---
--- 0.755476713180542 seconds for one epoch ---
--- 0.3164665699005127 seconds for one epoch ---
--- 0.7636711597442627 seconds for one epoch ---
--- 0.3239715099334717 seconds for one epoch ---
--- 0.78067946434021 seconds for one epoch ---
--- 0.30640411376953125 seconds for one epoch ---
--- 0.748509407043457 seconds for one epoch ---
--- 0.3374605178833008 seconds for one epoch ---
--- 0.7658932209014893 seconds for one epoch ---
--- 0.3069419860839844 seconds for one epoch ---
--- 0.7679464817047119 seconds for one epoch ---
--- 0.30358099937438965 seconds for one epoch ---
--- 0.7627990245819092 seconds for one epoch ---
--- 0.32285237312316895 seconds for one epoch ---
--- 0.7770135402679443 seconds for one epoch ---
--- 0.325864315032959 seconds for one epoch ---
--- 0.78363037109375 seconds for one epoch ---
--- 0.3282020092010498 seconds for one epoch ---
--- 0.7790207862854004 seconds for one epoch ---
--- 0.33348941802978516 seconds for one epoch ---
--- 0.7790298461914062 seconds for one epoch ---
--- 0.32855820655822754 seconds for one epoch ---
=========================
[[1.        ]
 [0.9985901 ]
 [0.32259852]
 [0.        ]
 [0.        ]
 [0.9999844 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.08047431]]
[[-1.3451095 ]
 [-0.68523073]
 [ 0.31960467]
 [ 0.        ]
 [-0.        ]
 [-0.9223822 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.3031738 ]
 [ 0.23477252]]
--- 0.27652406692504883 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3017.79248046875, (1382.7441, 0.51700383, 1633.357, 1.174234)
   validation loss 780.4298706054688, (472.98236, 0.219275, 306.054, 1.174234)
decoder loss ratio: 18324.157792, decoder SINDy loss  ratio: 0.660661
--- 0.3139200210571289 seconds for one epoch ---
--- 0.7942864894866943 seconds for one epoch ---
--- 0.30962371826171875 seconds for one epoch ---
--- 0.768277645111084 seconds for one epoch ---
--- 0.32306480407714844 seconds for one epoch ---
--- 0.7506673336029053 seconds for one epoch ---
--- 0.31169962882995605 seconds for one epoch ---
--- 0.7702264785766602 seconds for one epoch ---
--- 0.32346487045288086 seconds for one epoch ---
--- 0.7693884372711182 seconds for one epoch ---
--- 0.3237032890319824 seconds for one epoch ---
--- 0.7928688526153564 seconds for one epoch ---
--- 0.32233238220214844 seconds for one epoch ---
--- 0.7876033782958984 seconds for one epoch ---
--- 0.3317394256591797 seconds for one epoch ---
--- 0.7609672546386719 seconds for one epoch ---
--- 0.32069897651672363 seconds for one epoch ---
--- 0.7802808284759521 seconds for one epoch ---
--- 0.308513879776001 seconds for one epoch ---
--- 0.7753548622131348 seconds for one epoch ---
--- 0.31281518936157227 seconds for one epoch ---
--- 0.7872989177703857 seconds for one epoch ---
--- 0.3055613040924072 seconds for one epoch ---
--- 0.8009252548217773 seconds for one epoch ---
=========================
[[1.        ]
 [0.9977948 ]
 [0.29398912]
 [0.        ]
 [0.        ]
 [0.99997354]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.03383909]]
[[-1.3889716 ]
 [-0.66278684]
 [ 0.31288987]
 [ 0.        ]
 [-0.        ]
 [-0.8867161 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.3601596 ]
 [ 0.18884595]]
--- 0.30804991722106934 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4193.7744140625, (1781.6051, 1.0031445, 2410.0156, 1.1504618)
   validation loss 1799.164794921875, (1465.1039, 0.33450505, 332.57596, 1.1504618)
decoder loss ratio: 56760.667915, decoder SINDy loss  ratio: 0.717912
--- 0.27740049362182617 seconds for one epoch ---
--- 0.320676326751709 seconds for one epoch ---
--- 0.7898633480072021 seconds for one epoch ---
--- 0.3238651752471924 seconds for one epoch ---
--- 0.7892179489135742 seconds for one epoch ---
--- 0.3213634490966797 seconds for one epoch ---
--- 0.7934808731079102 seconds for one epoch ---
--- 0.32189464569091797 seconds for one epoch ---
--- 0.793865442276001 seconds for one epoch ---
--- 0.33414125442504883 seconds for one epoch ---
--- 0.7792255878448486 seconds for one epoch ---
--- 0.32080960273742676 seconds for one epoch ---
--- 0.8018016815185547 seconds for one epoch ---
--- 0.30559563636779785 seconds for one epoch ---
--- 0.7864689826965332 seconds for one epoch ---
--- 0.29613542556762695 seconds for one epoch ---
--- 0.7865116596221924 seconds for one epoch ---
--- 0.314286470413208 seconds for one epoch ---
--- 0.8008997440338135 seconds for one epoch ---
--- 0.32006168365478516 seconds for one epoch ---
--- 0.8061754703521729 seconds for one epoch ---
--- 0.33202481269836426 seconds for one epoch ---
--- 0.7897899150848389 seconds for one epoch ---
--- 0.3226771354675293 seconds for one epoch ---
=========================
[[1.        ]
 [0.9982141 ]
 [0.34326258]
 [0.        ]
 [0.        ]
 [0.99997026]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.05834407]]
[[-1.4591045 ]
 [-0.67337555]
 [ 0.32426888]
 [ 0.        ]
 [-0.        ]
 [-0.8802854 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.4285564 ]
 [ 0.21749221]]
--- 0.26200032234191895 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2631.6259765625, (1203.8376, 0.62200195, 1425.9957, 1.1707194)
   validation loss 2264.895263671875, (1967.9498, 0.20126672, 295.5735, 1.1707194)
decoder loss ratio: 76241.792891, decoder SINDy loss  ratio: 0.638037
--- 0.3188965320587158 seconds for one epoch ---
--- 0.7963039875030518 seconds for one epoch ---
--- 0.30869483947753906 seconds for one epoch ---
--- 0.7966334819793701 seconds for one epoch ---
--- 0.3235797882080078 seconds for one epoch ---
--- 0.8078594207763672 seconds for one epoch ---
--- 0.32520174980163574 seconds for one epoch ---
--- 0.8076202869415283 seconds for one epoch ---
--- 0.3163628578186035 seconds for one epoch ---
--- 0.7910380363464355 seconds for one epoch ---
--- 0.32300353050231934 seconds for one epoch ---
--- 0.7935519218444824 seconds for one epoch ---
--- 0.30867481231689453 seconds for one epoch ---
--- 0.8132009506225586 seconds for one epoch ---
--- 0.3216078281402588 seconds for one epoch ---
--- 0.8156068325042725 seconds for one epoch ---
--- 0.3232998847961426 seconds for one epoch ---
--- 0.8081164360046387 seconds for one epoch ---
--- 0.3174159526824951 seconds for one epoch ---
--- 0.8275246620178223 seconds for one epoch ---
--- 0.323638916015625 seconds for one epoch ---
--- 0.8015267848968506 seconds for one epoch ---
--- 0.3123738765716553 seconds for one epoch ---
--- 0.7984912395477295 seconds for one epoch ---
=========================
[[1.        ]
 [0.9966674 ]
 [0.28153226]
 [0.        ]
 [0.        ]
 [0.9999651 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.01968951]]
[[-1.5308583 ]
 [-0.6420602 ]
 [ 0.3098542 ]
 [ 0.        ]
 [-0.        ]
 [-0.8760019 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.508257  ]
 [ 0.16096446]]
--- 0.30963659286499023 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4947.36376953125, (1214.7432, 2.328619, 3729.153, 1.1390224)
   validation loss 889.1441650390625, (570.90015, 0.19753139, 316.90744, 1.1390224)
decoder loss ratio: 22117.662801, decoder SINDy loss  ratio: 0.684089
--- 0.2619318962097168 seconds for one epoch ---
--- 0.31303858757019043 seconds for one epoch ---
--- 0.8198390007019043 seconds for one epoch ---
--- 0.3279407024383545 seconds for one epoch ---
--- 0.8098759651184082 seconds for one epoch ---
--- 0.3159000873565674 seconds for one epoch ---
--- 0.8164870738983154 seconds for one epoch ---
--- 0.322659969329834 seconds for one epoch ---
--- 0.8210148811340332 seconds for one epoch ---
--- 0.3244659900665283 seconds for one epoch ---
--- 0.7833094596862793 seconds for one epoch ---
--- 0.3130757808685303 seconds for one epoch ---
--- 0.7964580059051514 seconds for one epoch ---
--- 0.3132328987121582 seconds for one epoch ---
--- 0.8272891044616699 seconds for one epoch ---
--- 0.3258180618286133 seconds for one epoch ---
--- 0.8186757564544678 seconds for one epoch ---
--- 0.32503390312194824 seconds for one epoch ---
--- 0.8251180648803711 seconds for one epoch ---
--- 0.31523728370666504 seconds for one epoch ---
--- 0.810276985168457 seconds for one epoch ---
--- 0.32120561599731445 seconds for one epoch ---
--- 0.8260197639465332 seconds for one epoch ---
--- 0.32648396492004395 seconds for one epoch ---
=========================
[[1.        ]
 [0.9974946 ]
 [0.25909787]
 [0.        ]
 [0.        ]
 [0.9999553 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.0108904 ]]
[[-1.5860354 ]
 [-0.65638846]
 [ 0.30416235]
 [-0.        ]
 [ 0.        ]
 [-0.861383  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.5747273 ]
 [ 0.13073047]]
--- 0.2718219757080078 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4068.771728515625, (2222.065, 0.77067447, 1844.8103, 1.1257558)
   validation loss 1379.4425048828125, (1055.1439, 0.1597499, 323.01306, 1.1257558)
decoder loss ratio: 40878.107306, decoder SINDy loss  ratio: 0.697269
--- 0.2967209815979004 seconds for one epoch ---
--- 0.8134853839874268 seconds for one epoch ---
--- 0.32706451416015625 seconds for one epoch ---
--- 0.814713716506958 seconds for one epoch ---
--- 0.31593799591064453 seconds for one epoch ---
--- 0.8052551746368408 seconds for one epoch ---
--- 0.3128082752227783 seconds for one epoch ---
--- 0.7955615520477295 seconds for one epoch ---
--- 0.3074057102203369 seconds for one epoch ---
--- 0.8387405872344971 seconds for one epoch ---
--- 0.3211400508880615 seconds for one epoch ---
--- 0.8403415679931641 seconds for one epoch ---
--- 0.3320424556732178 seconds for one epoch ---
--- 0.8383080959320068 seconds for one epoch ---
--- 0.337904691696167 seconds for one epoch ---
--- 0.8275818824768066 seconds for one epoch ---
--- 0.3244786262512207 seconds for one epoch ---
--- 0.8215100765228271 seconds for one epoch ---
--- 0.31423306465148926 seconds for one epoch ---
--- 0.8496742248535156 seconds for one epoch ---
--- 0.32152342796325684 seconds for one epoch ---
--- 0.8453102111816406 seconds for one epoch ---
--- 0.32745981216430664 seconds for one epoch ---
--- 0.8243145942687988 seconds for one epoch ---
=========================
[[1.        ]
 [0.9984714 ]
 [0.17358816]
 [0.        ]
 [0.        ]
 [0.9999553 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.01041503]]
[[-1.6439492 ]
 [-0.6811865 ]
 [ 0.27865425]
 [-0.        ]
 [ 0.        ]
 [-0.86124796]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.627132  ]
 [ 0.12851217]]
--- 0.29591917991638184 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4559.02197265625, (1357.5985, 0.6486122, 3199.672, 1.1028131)
   validation loss 1380.0244140625, (1068.1168, 0.19595411, 310.6089, 1.1028131)
decoder loss ratio: 41380.699989, decoder SINDy loss  ratio: 0.670493
--- 0.2690398693084717 seconds for one epoch ---
--- 0.333820104598999 seconds for one epoch ---
--- 0.8104045391082764 seconds for one epoch ---
--- 0.31713390350341797 seconds for one epoch ---
--- 0.8291177749633789 seconds for one epoch ---
--- 0.32338523864746094 seconds for one epoch ---
--- 0.8427736759185791 seconds for one epoch ---
--- 0.3130223751068115 seconds for one epoch ---
--- 0.8312573432922363 seconds for one epoch ---
--- 0.30501747131347656 seconds for one epoch ---
--- 0.8172597885131836 seconds for one epoch ---
--- 0.31011390686035156 seconds for one epoch ---
--- 0.8212785720825195 seconds for one epoch ---
--- 0.3117690086364746 seconds for one epoch ---
--- 0.837867021560669 seconds for one epoch ---
--- 0.3187081813812256 seconds for one epoch ---
--- 0.8512732982635498 seconds for one epoch ---
--- 0.4951157569885254 seconds for one epoch ---
--- 0.8206007480621338 seconds for one epoch ---
--- 0.29737305641174316 seconds for one epoch ---
--- 0.8299438953399658 seconds for one epoch ---
--- 0.3169271945953369 seconds for one epoch ---
--- 0.8550534248352051 seconds for one epoch ---
--- 0.32131457328796387 seconds for one epoch ---
=========================
[[1.        ]
 [0.99864924]
 [0.15202162]
 [0.        ]
 [0.        ]
 [0.9999299 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.00366913]]
[[-1.7041695 ]
 [-0.6873907 ]
 [ 0.27072877]
 [-0.        ]
 [ 0.        ]
 [-0.8368262 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.7046864 ]
 [ 0.07536524]]
--- 0.25800132751464844 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2702.78564453125, (1106.0486, 1.7643157, 1593.8947, 1.078069)
   validation loss 1115.849853515625, (798.7181, 0.21353042, 315.8401, 1.078069)
decoder loss ratio: 30943.725001, decoder SINDy loss  ratio: 0.681785
--- 0.3150174617767334 seconds for one epoch ---
--- 0.8155310153961182 seconds for one epoch ---
--- 0.3161938190460205 seconds for one epoch ---
--- 0.831798791885376 seconds for one epoch ---
--- 0.3197362422943115 seconds for one epoch ---
--- 0.8089590072631836 seconds for one epoch ---
--- 0.3262648582458496 seconds for one epoch ---
--- 0.8196628093719482 seconds for one epoch ---
--- 0.31049108505249023 seconds for one epoch ---
--- 0.8359911441802979 seconds for one epoch ---
--- 0.30865001678466797 seconds for one epoch ---
--- 0.8536698818206787 seconds for one epoch ---
--- 0.31831932067871094 seconds for one epoch ---
--- 0.8142645359039307 seconds for one epoch ---
--- 0.30716538429260254 seconds for one epoch ---
--- 0.8523988723754883 seconds for one epoch ---
--- 0.31331324577331543 seconds for one epoch ---
--- 0.8710296154022217 seconds for one epoch ---
--- 0.3194146156311035 seconds for one epoch ---
--- 0.8557701110839844 seconds for one epoch ---
--- 0.31933045387268066 seconds for one epoch ---
--- 0.8494031429290771 seconds for one epoch ---
--- 0.32407593727111816 seconds for one epoch ---
--- 0.8573136329650879 seconds for one epoch ---
=========================
[[1.        ]
 [0.9982755 ]
 [0.15839942]
 [0.        ]
 [0.        ]
 [0.99992156]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.00342746]]
[[-1.7627478 ]
 [-0.6751386 ]
 [ 0.27316636]
 [-0.        ]
 [ 0.        ]
 [-0.83130026]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7642303 ]
 [ 0.07200639]]
--- 0.29352831840515137 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4199.716796875, (2108.8044, 3.7900996, 2086.0447, 1.0777056)
   validation loss 1845.232666015625, (1361.0438, 0.4054003, 482.70566, 1.0777056)
decoder loss ratio: 52729.200588, decoder SINDy loss  ratio: 1.041988
--- 0.2758474349975586 seconds for one epoch ---
--- 0.3275563716888428 seconds for one epoch ---
--- 0.8741886615753174 seconds for one epoch ---
--- 0.3178746700286865 seconds for one epoch ---
--- 0.8414790630340576 seconds for one epoch ---
--- 0.3092215061187744 seconds for one epoch ---
--- 0.8546333312988281 seconds for one epoch ---
--- 0.32436585426330566 seconds for one epoch ---
--- 0.8326408863067627 seconds for one epoch ---
--- 0.3316187858581543 seconds for one epoch ---
--- 0.8674981594085693 seconds for one epoch ---
--- 0.33375072479248047 seconds for one epoch ---
--- 0.846358060836792 seconds for one epoch ---
--- 0.32856202125549316 seconds for one epoch ---
--- 0.8494608402252197 seconds for one epoch ---
--- 0.3123760223388672 seconds for one epoch ---
--- 0.849238395690918 seconds for one epoch ---
--- 0.3134644031524658 seconds for one epoch ---
--- 0.8527133464813232 seconds for one epoch ---
--- 0.31986093521118164 seconds for one epoch ---
--- 0.8509471416473389 seconds for one epoch ---
--- 0.3310229778289795 seconds for one epoch ---
--- 0.8751542568206787 seconds for one epoch ---
--- 0.3185234069824219 seconds for one epoch ---
=========================
[[1.        ]
 [0.99938285]
 [0.10445187]
 [0.        ]
 [0.        ]
 [0.99992514]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.00156475]]
[[-1.8348533 ]
 [-0.7266333 ]
 [ 0.24922073]
 [ 0.        ]
 [-0.        ]
 [-0.8327473 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.840433  ]
 [ 0.03177677]]
--- 0.2752852439880371 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3343.77783203125, (1739.171, 1.2861291, 1602.2686, 1.0522145)
   validation loss 2717.12646484375, (2110.8474, 0.4634155, 604.7634, 1.0522145)
decoder loss ratio: 81777.893337, decoder SINDy loss  ratio: 1.305467
--- 0.3104860782623291 seconds for one epoch ---
--- 0.8402166366577148 seconds for one epoch ---
--- 0.32830023765563965 seconds for one epoch ---
--- 0.8907661437988281 seconds for one epoch ---
--- 0.3237025737762451 seconds for one epoch ---
--- 0.8772022724151611 seconds for one epoch ---
--- 0.33242249488830566 seconds for one epoch ---
--- 0.863663911819458 seconds for one epoch ---
--- 0.3174002170562744 seconds for one epoch ---
--- 0.8700366020202637 seconds for one epoch ---
--- 0.3137333393096924 seconds for one epoch ---
--- 0.8730535507202148 seconds for one epoch ---
--- 0.3023717403411865 seconds for one epoch ---
--- 0.8765335083007812 seconds for one epoch ---
--- 0.3223423957824707 seconds for one epoch ---
--- 0.8916070461273193 seconds for one epoch ---
--- 0.32445335388183594 seconds for one epoch ---
--- 0.8644602298736572 seconds for one epoch ---
--- 0.31893181800842285 seconds for one epoch ---
--- 0.8833699226379395 seconds for one epoch ---
--- 0.323030948638916 seconds for one epoch ---
--- 0.8721258640289307 seconds for one epoch ---
--- 0.32939600944519043 seconds for one epoch ---
--- 0.885972261428833 seconds for one epoch ---
=========================
[[1.0000000e+00]
 [9.9914360e-01]
 [1.6903134e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [9.9988770e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [0.0000000e+00]
 [1.0000000e+00]
 [9.8080188e-04]]
[[-1.8873832 ]
 [-0.7102431 ]
 [ 0.2770583 ]
 [ 0.        ]
 [ 0.        ]
 [-0.81185937]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9067159 ]
 [ 0.0075802 ]]
--- 0.29555463790893555 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2811.752197265625, (1288.4181, 0.7410819, 1521.532, 1.0611019)
   validation loss 955.7776489257812, (621.8591, 0.33825603, 332.5192, 1.0611019)
decoder loss ratio: 24091.899960, decoder SINDy loss  ratio: 0.717789
--- 0.27092719078063965 seconds for one epoch ---
--- 0.31993889808654785 seconds for one epoch ---
--- 0.8778564929962158 seconds for one epoch ---
--- 0.30426859855651855 seconds for one epoch ---
--- 0.8694648742675781 seconds for one epoch ---
--- 0.3211064338684082 seconds for one epoch ---
--- 0.8698246479034424 seconds for one epoch ---
--- 0.3122563362121582 seconds for one epoch ---
--- 0.8952617645263672 seconds for one epoch ---
--- 0.31923818588256836 seconds for one epoch ---
--- 0.85298752784729 seconds for one epoch ---
--- 0.3193652629852295 seconds for one epoch ---
--- 0.849370002746582 seconds for one epoch ---
--- 0.31096458435058594 seconds for one epoch ---
--- 0.8785860538482666 seconds for one epoch ---
--- 0.3270297050476074 seconds for one epoch ---
--- 0.8975188732147217 seconds for one epoch ---
--- 0.34409284591674805 seconds for one epoch ---
--- 0.8764464855194092 seconds for one epoch ---
--- 0.32071757316589355 seconds for one epoch ---
--- 0.8762390613555908 seconds for one epoch ---
--- 0.31556057929992676 seconds for one epoch ---
--- 0.8803493976593018 seconds for one epoch ---
--- 0.3278646469116211 seconds for one epoch ---
=========================
[[1.0000000e+00]
 [9.9855679e-01]
 [1.3970304e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [9.9986649e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [0.0000000e+00]
 [1.0000000e+00]
 [9.8753627e-04]]
[[-1.9471145 ]
 [-0.6840623 ]
 [ 0.26578867]
 [ 0.        ]
 [-0.        ]
 [-0.80345744]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.9697201 ]
 [-0.00828567]]
--- 0.26805758476257324 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3796.674072265625, (1234.5972, 2.7707314, 2558.2517, 1.054428)
   validation loss 1239.2467041015625, (899.0576, 0.28417557, 338.8505, 1.054428)
decoder loss ratio: 34831.052923, decoder SINDy loss  ratio: 0.731456
--- 0.3228631019592285 seconds for one epoch ---
--- 0.8700876235961914 seconds for one epoch ---
--- 0.322951078414917 seconds for one epoch ---
--- 0.8634934425354004 seconds for one epoch ---
--- 0.32932591438293457 seconds for one epoch ---
--- 0.8620872497558594 seconds for one epoch ---
--- 0.3239774703979492 seconds for one epoch ---
--- 0.8561418056488037 seconds for one epoch ---
--- 0.3126230239868164 seconds for one epoch ---
--- 0.9013803005218506 seconds for one epoch ---
--- 0.32607007026672363 seconds for one epoch ---
--- 0.9015212059020996 seconds for one epoch ---
--- 0.32291698455810547 seconds for one epoch ---
--- 0.9106228351593018 seconds for one epoch ---
--- 0.3101022243499756 seconds for one epoch ---
--- 0.8820099830627441 seconds for one epoch ---
--- 0.32619786262512207 seconds for one epoch ---
--- 0.8816678524017334 seconds for one epoch ---
--- 0.34061169624328613 seconds for one epoch ---
--- 0.8884532451629639 seconds for one epoch ---
--- 0.31573033332824707 seconds for one epoch ---
--- 0.8963439464569092 seconds for one epoch ---
--- 0.3167843818664551 seconds for one epoch ---
--- 0.8901791572570801 seconds for one epoch ---
=========================
[[1.        ]
 [0.99698234]
 [0.11049762]
 [0.        ]
 [0.        ]
 [0.9998588 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.00307333]]
[[-1.9930168 ]
 [-0.64704907]
 [ 0.2523843 ]
 [ 0.        ]
 [ 0.        ]
 [-0.80090034]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0018086 ]
 [-0.06686689]]
--- 0.28948235511779785 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4206.74755859375, (1093.4971, 0.79983765, 3111.382, 1.0690322)
   validation loss 854.8732299804688, (567.487, 0.28105187, 286.03613, 1.0690322)
decoder loss ratio: 21985.431562, decoder SINDy loss  ratio: 0.617449
--- 0.26547789573669434 seconds for one epoch ---
--- 0.32471537590026855 seconds for one epoch ---
--- 0.8906505107879639 seconds for one epoch ---
--- 0.3028557300567627 seconds for one epoch ---
--- 0.8839654922485352 seconds for one epoch ---
--- 0.32228541374206543 seconds for one epoch ---
--- 0.8995165824890137 seconds for one epoch ---
--- 0.3203847408294678 seconds for one epoch ---
--- 0.8954689502716064 seconds for one epoch ---
--- 0.3188314437866211 seconds for one epoch ---
--- 0.9002556800842285 seconds for one epoch ---
--- 0.32781291007995605 seconds for one epoch ---
--- 0.898186206817627 seconds for one epoch ---
--- 0.31392884254455566 seconds for one epoch ---
--- 0.9158594608306885 seconds for one epoch ---
--- 0.32053232192993164 seconds for one epoch ---
--- 0.8824949264526367 seconds for one epoch ---
--- 0.3110802173614502 seconds for one epoch ---
--- 0.9020984172821045 seconds for one epoch ---
--- 0.3247687816619873 seconds for one epoch ---
--- 0.9075679779052734 seconds for one epoch ---
--- 0.321138858795166 seconds for one epoch ---
--- 0.922344446182251 seconds for one epoch ---
--- 0.31494855880737305 seconds for one epoch ---
=========================
[[1.        ]
 [0.998192  ]
 [0.08613329]
 [0.        ]
 [0.        ]
 [0.9998617 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.01352371]]
[[-2.063893  ]
 [-0.6727617 ]
 [ 0.23856914]
 [ 0.        ]
 [ 0.        ]
 [-0.8020165 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.06879   ]
 [-0.14202577]]
--- 0.2726478576660156 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3150.230712890625, (1616.6241, 1.8584964, 1530.6573, 1.0904881)
   validation loss 1004.9213256835938, (714.5821, 0.19429177, 289.0544, 1.0904881)
decoder loss ratio: 27684.150824, decoder SINDy loss  ratio: 0.623965
--- 0.3226315975189209 seconds for one epoch ---
--- 0.929358720779419 seconds for one epoch ---
--- 0.33359384536743164 seconds for one epoch ---
--- 0.9237809181213379 seconds for one epoch ---
--- 0.32120728492736816 seconds for one epoch ---
--- 0.9168591499328613 seconds for one epoch ---
--- 0.32474231719970703 seconds for one epoch ---
--- 0.9166789054870605 seconds for one epoch ---
--- 0.32309818267822266 seconds for one epoch ---
--- 0.9168448448181152 seconds for one epoch ---
--- 0.3248276710510254 seconds for one epoch ---
--- 0.9014317989349365 seconds for one epoch ---
--- 0.3130836486816406 seconds for one epoch ---
--- 0.92877197265625 seconds for one epoch ---
--- 0.3108847141265869 seconds for one epoch ---
--- 0.9214780330657959 seconds for one epoch ---
--- 0.31953001022338867 seconds for one epoch ---
--- 0.9279286861419678 seconds for one epoch ---
--- 0.3274385929107666 seconds for one epoch ---
--- 0.9083242416381836 seconds for one epoch ---
--- 0.3311944007873535 seconds for one epoch ---
--- 0.9189655780792236 seconds for one epoch ---
--- 0.31769680976867676 seconds for one epoch ---
--- 0.9116342067718506 seconds for one epoch ---
=========================
[[1.        ]
 [0.99828553]
 [0.07250038]
 [0.        ]
 [0.        ]
 [0.99983037]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.02768267]]
[[-2.10479   ]
 [-0.67544055]
 [ 0.22920798]
 [-0.        ]
 [-0.        ]
 [-0.79147696]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.106388  ]
 [-0.17865317]]
--- 0.30728602409362793 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2850.81494140625, (1087.2179, 1.1865327, 1761.3112, 1.0994349)
   validation loss 1215.6707763671875, (924.5119, 0.22934306, 289.83008, 1.0994349)
decoder loss ratio: 35817.196101, decoder SINDy loss  ratio: 0.625639
--- 0.2799654006958008 seconds for one epoch ---
--- 0.31954455375671387 seconds for one epoch ---
--- 0.9120640754699707 seconds for one epoch ---
--- 0.3332092761993408 seconds for one epoch ---
--- 0.9216647148132324 seconds for one epoch ---
--- 0.318845272064209 seconds for one epoch ---
--- 0.9391708374023438 seconds for one epoch ---
--- 0.3163173198699951 seconds for one epoch ---
--- 0.909773588180542 seconds for one epoch ---
--- 0.33512043952941895 seconds for one epoch ---
--- 0.9263875484466553 seconds for one epoch ---
--- 0.3290445804595947 seconds for one epoch ---
--- 0.9297966957092285 seconds for one epoch ---
--- 0.3308548927307129 seconds for one epoch ---
--- 0.9156203269958496 seconds for one epoch ---
--- 0.3301815986633301 seconds for one epoch ---
--- 0.9267828464508057 seconds for one epoch ---
--- 0.319472074508667 seconds for one epoch ---
--- 0.9293413162231445 seconds for one epoch ---
--- 0.333606481552124 seconds for one epoch ---
--- 0.933218240737915 seconds for one epoch ---
--- 0.3244445323944092 seconds for one epoch ---
--- 0.9245972633361816 seconds for one epoch ---
--- 0.31860804557800293 seconds for one epoch ---
=========================
[[1.        ]
 [0.9991568 ]
 [0.09249478]
 [0.        ]
 [0.        ]
 [0.9998121 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.04627118]]
[[-2.1613104 ]
 [-0.71099293]
 [ 0.24248865]
 [-0.        ]
 [-0.        ]
 [-0.7864322 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.161403  ]
 [-0.20534128]]
--- 0.26596856117248535 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2327.195556640625, (1150.8131, 3.6395361, 1171.6215, 1.1212375)
   validation loss 920.456787109375, (640.98145, 0.33302596, 278.0211, 1.1212375)
decoder loss ratio: 24832.733984, decoder SINDy loss  ratio: 0.600148
--- 0.32028675079345703 seconds for one epoch ---
--- 0.9117550849914551 seconds for one epoch ---
--- 0.319793701171875 seconds for one epoch ---
--- 0.8997139930725098 seconds for one epoch ---
--- 0.32934069633483887 seconds for one epoch ---
--- 0.9319088459014893 seconds for one epoch ---
--- 0.31046414375305176 seconds for one epoch ---
--- 0.8986992835998535 seconds for one epoch ---
--- 0.3249483108520508 seconds for one epoch ---
--- 0.9161348342895508 seconds for one epoch ---
--- 0.2921309471130371 seconds for one epoch ---
--- 0.9199552536010742 seconds for one epoch ---
--- 0.3309638500213623 seconds for one epoch ---
--- 0.9346506595611572 seconds for one epoch ---
--- 0.33152103424072266 seconds for one epoch ---
--- 0.9266777038574219 seconds for one epoch ---
--- 0.3168518543243408 seconds for one epoch ---
--- 0.9205543994903564 seconds for one epoch ---
--- 0.3280482292175293 seconds for one epoch ---
--- 0.9595947265625 seconds for one epoch ---
--- 0.32652997970581055 seconds for one epoch ---
--- 0.9321370124816895 seconds for one epoch ---
--- 0.3255653381347656 seconds for one epoch ---
--- 0.9491498470306396 seconds for one epoch ---
=========================
[[1.        ]
 [0.99858654]
 [0.08786914]
 [0.        ]
 [0.        ]
 [0.99980134]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.03495032]]
[[-2.1966527 ]
 [-0.68510246]
 [ 0.2396688 ]
 [ 0.        ]
 [ 0.        ]
 [-0.7835266 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.180815  ]
 [-0.19071047]]
--- 0.3120903968811035 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2279.536376953125, (1091.151, 1.0364052, 1186.2368, 1.1121663)
   validation loss 846.0888671875, (517.71533, 0.47994056, 326.78146, 1.1121663)
decoder loss ratio: 20057.190756, decoder SINDy loss  ratio: 0.705404
THRESHOLDING: 4 active coefficients
--- 0.2780337333679199 seconds for one epoch ---
--- 0.3179657459259033 seconds for one epoch ---
--- 0.9349851608276367 seconds for one epoch ---
--- 0.3170340061187744 seconds for one epoch ---
--- 0.9455866813659668 seconds for one epoch ---
--- 0.3185081481933594 seconds for one epoch ---
--- 0.9446487426757812 seconds for one epoch ---
--- 0.3195657730102539 seconds for one epoch ---
--- 0.9611234664916992 seconds for one epoch ---
--- 0.3136789798736572 seconds for one epoch ---
--- 0.925445556640625 seconds for one epoch ---
--- 0.3230628967285156 seconds for one epoch ---
--- 0.9315669536590576 seconds for one epoch ---
--- 0.3128018379211426 seconds for one epoch ---
--- 0.958376407623291 seconds for one epoch ---
--- 0.31569552421569824 seconds for one epoch ---
--- 0.9628486633300781 seconds for one epoch ---
--- 0.31966710090637207 seconds for one epoch ---
--- 0.9491183757781982 seconds for one epoch ---
--- 0.33737611770629883 seconds for one epoch ---
--- 0.9532182216644287 seconds for one epoch ---
--- 0.3341553211212158 seconds for one epoch ---
--- 0.9206647872924805 seconds for one epoch ---
--- 0.32403063774108887 seconds for one epoch ---
=========================
[[1.       ]
 [0.9985688]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997655]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.2546747 ]
 [-0.6844875 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.77522475]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.239124  ]
 [-0.        ]]
--- 0.26595282554626465 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2828.54296875, (1887.3823, 0.7833649, 939.40906, 0.96821684)
   validation loss 914.307373046875, (634.47974, 0.31124926, 278.54816, 0.96821684)
decoder loss ratio: 24580.846491, decoder SINDy loss  ratio: 0.601285
--- 0.3072783946990967 seconds for one epoch ---
--- 0.9611074924468994 seconds for one epoch ---
--- 0.31966209411621094 seconds for one epoch ---
--- 0.97021484375 seconds for one epoch ---
--- 0.3214147090911865 seconds for one epoch ---
--- 0.9442791938781738 seconds for one epoch ---
--- 0.3310685157775879 seconds for one epoch ---
--- 0.9435904026031494 seconds for one epoch ---
--- 0.3142521381378174 seconds for one epoch ---
--- 0.9342489242553711 seconds for one epoch ---
--- 0.32601213455200195 seconds for one epoch ---
--- 0.9440083503723145 seconds for one epoch ---
--- 0.31304240226745605 seconds for one epoch ---
--- 0.9503428936004639 seconds for one epoch ---
--- 0.32840943336486816 seconds for one epoch ---
--- 0.9632241725921631 seconds for one epoch ---
--- 0.3170323371887207 seconds for one epoch ---
--- 0.9454278945922852 seconds for one epoch ---
--- 0.3306882381439209 seconds for one epoch ---
--- 0.9477024078369141 seconds for one epoch ---
--- 0.3181025981903076 seconds for one epoch ---
--- 0.9552001953125 seconds for one epoch ---
--- 0.3188600540161133 seconds for one epoch ---
--- 0.9468135833740234 seconds for one epoch ---
=========================
[[1.        ]
 [0.9912471 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99964225]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.2927341 ]
 [-0.59345144]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.753979  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.284891  ]
 [-0.        ]]
--- 0.3152453899383545 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1994.0496826171875, (843.3699, 0.4410684, 1149.2704, 0.9683504)
   validation loss 1070.47265625, (753.57367, 0.27087337, 315.65976, 0.9683504)
decoder loss ratio: 29194.752215, decoder SINDy loss  ratio: 0.681396
--- 0.25250768661499023 seconds for one epoch ---
--- 0.3307178020477295 seconds for one epoch ---
--- 0.9436697959899902 seconds for one epoch ---
--- 0.32214808464050293 seconds for one epoch ---
--- 0.9649486541748047 seconds for one epoch ---
--- 0.2889397144317627 seconds for one epoch ---
--- 0.9682543277740479 seconds for one epoch ---
--- 0.32677340507507324 seconds for one epoch ---
--- 0.9551279544830322 seconds for one epoch ---
--- 0.32137250900268555 seconds for one epoch ---
--- 0.9887640476226807 seconds for one epoch ---
--- 0.32263779640197754 seconds for one epoch ---
--- 0.9843318462371826 seconds for one epoch ---
--- 0.3276057243347168 seconds for one epoch ---
--- 0.9702575206756592 seconds for one epoch ---
--- 0.3112478256225586 seconds for one epoch ---
--- 0.970850944519043 seconds for one epoch ---
--- 0.32446885108947754 seconds for one epoch ---
--- 0.9658973217010498 seconds for one epoch ---
--- 0.3102903366088867 seconds for one epoch ---
--- 0.9916820526123047 seconds for one epoch ---
--- 0.32329583168029785 seconds for one epoch ---
--- 0.9814720153808594 seconds for one epoch ---
--- 0.32203221321105957 seconds for one epoch ---
=========================
[[1.        ]
 [0.99564576]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999645  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.3383286 ]
 [-0.62862647]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.7544017 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.3127327 ]
 [-0.        ]]
--- 0.25411105155944824 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2476.886962890625, (969.48334, 3.9954522, 1502.4392, 0.9688875)
   validation loss 884.6199951171875, (590.0092, 0.38499242, 293.2569, 0.9688875)
decoder loss ratio: 22857.981341, decoder SINDy loss  ratio: 0.633036
--- 0.32871317863464355 seconds for one epoch ---
--- 0.9661250114440918 seconds for one epoch ---
--- 0.34763169288635254 seconds for one epoch ---
--- 0.969773530960083 seconds for one epoch ---
--- 0.3222949504852295 seconds for one epoch ---
--- 0.9801235198974609 seconds for one epoch ---
--- 0.33019018173217773 seconds for one epoch ---
--- 0.9764697551727295 seconds for one epoch ---
--- 0.3343660831451416 seconds for one epoch ---
--- 0.9793477058410645 seconds for one epoch ---
--- 0.3413209915161133 seconds for one epoch ---
--- 0.9879121780395508 seconds for one epoch ---
--- 0.32524538040161133 seconds for one epoch ---
--- 0.9956953525543213 seconds for one epoch ---
--- 0.3173999786376953 seconds for one epoch ---
--- 0.9446258544921875 seconds for one epoch ---
--- 0.3213503360748291 seconds for one epoch ---
--- 0.9777979850769043 seconds for one epoch ---
--- 0.33337926864624023 seconds for one epoch ---
--- 0.9876563549041748 seconds for one epoch ---
--- 0.31939148902893066 seconds for one epoch ---
--- 0.9936139583587646 seconds for one epoch ---
--- 0.32425642013549805 seconds for one epoch ---
--- 1.0055873394012451 seconds for one epoch ---
=========================
[[1.        ]
 [0.98760533]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99965346]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.3906014]
 [-0.5758487]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.7556605]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.355121 ]
 [-0.       ]]
--- 0.3103001117706299 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3779.356689453125, (964.81146, 3.7449963, 2809.8313, 0.9689922)
   validation loss 770.6239013671875, (506.32782, 0.3843812, 262.94272, 0.9689922)
decoder loss ratio: 19616.018764, decoder SINDy loss  ratio: 0.567599
--- 0.27782201766967773 seconds for one epoch ---
--- 0.3207237720489502 seconds for one epoch ---
--- 0.9650657176971436 seconds for one epoch ---
--- 0.32431650161743164 seconds for one epoch ---
--- 0.9673817157745361 seconds for one epoch ---
--- 0.3360936641693115 seconds for one epoch ---
--- 0.9714546203613281 seconds for one epoch ---
--- 0.30462193489074707 seconds for one epoch ---
--- 0.9852213859558105 seconds for one epoch ---
--- 0.3171069622039795 seconds for one epoch ---
--- 0.9894533157348633 seconds for one epoch ---
--- 0.3097503185272217 seconds for one epoch ---
--- 1.0023596286773682 seconds for one epoch ---
--- 0.3250892162322998 seconds for one epoch ---
--- 0.98533034324646 seconds for one epoch ---
--- 0.3294079303741455 seconds for one epoch ---
--- 1.0013651847839355 seconds for one epoch ---
--- 0.3340597152709961 seconds for one epoch ---
--- 0.995568037033081 seconds for one epoch ---
--- 0.3194308280944824 seconds for one epoch ---
--- 0.9759442806243896 seconds for one epoch ---
--- 0.3290565013885498 seconds for one epoch ---
--- 0.9582576751708984 seconds for one epoch ---
--- 0.3253769874572754 seconds for one epoch ---
=========================
[[1.        ]
 [0.9956976 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99963677]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.4391513]
 [-0.6292259]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.7532009]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.394729 ]
 [-0.       ]]
--- 0.2772355079650879 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3800.49462890625, (1607.2665, 3.0488276, 2189.2097, 0.9697256)
   validation loss 1061.058349609375, (782.8785, 0.47215843, 276.738, 0.9697256)
decoder loss ratio: 30330.071413, decoder SINDy loss  ratio: 0.597378
--- 0.327526330947876 seconds for one epoch ---
--- 1.0065832138061523 seconds for one epoch ---
--- 0.32424306869506836 seconds for one epoch ---
--- 0.9791367053985596 seconds for one epoch ---
--- 0.33005428314208984 seconds for one epoch ---
--- 0.9783468246459961 seconds for one epoch ---
--- 0.31525540351867676 seconds for one epoch ---
--- 0.9969666004180908 seconds for one epoch ---
--- 0.3167240619659424 seconds for one epoch ---
--- 1.0099148750305176 seconds for one epoch ---
--- 0.3085031509399414 seconds for one epoch ---
--- 1.0131323337554932 seconds for one epoch ---
--- 0.3185555934906006 seconds for one epoch ---
--- 1.02716064453125 seconds for one epoch ---
--- 0.3284311294555664 seconds for one epoch ---
--- 1.0057878494262695 seconds for one epoch ---
--- 0.3303396701812744 seconds for one epoch ---
--- 1.0189249515533447 seconds for one epoch ---
--- 0.3206183910369873 seconds for one epoch ---
--- 1.0114519596099854 seconds for one epoch ---
--- 0.3368723392486572 seconds for one epoch ---
--- 1.000497817993164 seconds for one epoch ---
--- 0.32042503356933594 seconds for one epoch ---
--- 1.0171523094177246 seconds for one epoch ---
=========================
[[1.       ]
 [0.9968736]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9996129]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.4740815 ]
 [-0.64526623]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.7499368 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.413474  ]
 [-0.        ]]
--- 0.2870001792907715 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3168.011962890625, (1372.77, 0.6761359, 1793.5957, 0.9699578)
   validation loss 1104.297607421875, (818.01404, 0.42365962, 284.89, 0.9699578)
decoder loss ratio: 31691.283970, decoder SINDy loss  ratio: 0.614975
--- 0.26535940170288086 seconds for one epoch ---
--- 0.336803674697876 seconds for one epoch ---
--- 0.9813029766082764 seconds for one epoch ---
--- 0.31975483894348145 seconds for one epoch ---
--- 0.9759070873260498 seconds for one epoch ---
--- 0.3328893184661865 seconds for one epoch ---
--- 1.001622200012207 seconds for one epoch ---
--- 0.3202834129333496 seconds for one epoch ---
--- 0.9962882995605469 seconds for one epoch ---
--- 0.32306599617004395 seconds for one epoch ---
--- 1.013324499130249 seconds for one epoch ---
--- 0.320676326751709 seconds for one epoch ---
--- 1.0289497375488281 seconds for one epoch ---
--- 0.31751489639282227 seconds for one epoch ---
--- 0.9957048892974854 seconds for one epoch ---
--- 0.31474900245666504 seconds for one epoch ---
--- 1.0183899402618408 seconds for one epoch ---
--- 0.3226454257965088 seconds for one epoch ---
--- 1.0212335586547852 seconds for one epoch ---
--- 0.3320300579071045 seconds for one epoch ---
--- 1.0146379470825195 seconds for one epoch ---
--- 0.3222670555114746 seconds for one epoch ---
--- 1.0027492046356201 seconds for one epoch ---
--- 0.32745361328125 seconds for one epoch ---
=========================
[[1.        ]
 [0.99751663]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9994624 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.5178177]
 [-0.6568161]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7334835]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.4610744]
 [-0.       ]]
--- 0.27858662605285645 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5951.109375, (1863.9698, 7.4855185, 4078.6838, 0.9703736)
   validation loss 1574.5159912109375, (1275.6448, 0.5005684, 297.4002, 0.9703736)
decoder loss ratio: 49420.693215, decoder SINDy loss  ratio: 0.641980
--- 0.319427490234375 seconds for one epoch ---
--- 0.9952595233917236 seconds for one epoch ---
--- 0.32766056060791016 seconds for one epoch ---
--- 1.0297715663909912 seconds for one epoch ---
--- 0.33110976219177246 seconds for one epoch ---
--- 0.9993526935577393 seconds for one epoch ---
--- 0.3257429599761963 seconds for one epoch ---
--- 1.0193355083465576 seconds for one epoch ---
--- 0.321979284286499 seconds for one epoch ---
--- 1.0248146057128906 seconds for one epoch ---
--- 0.3249368667602539 seconds for one epoch ---
--- 1.0075569152832031 seconds for one epoch ---
--- 0.31207895278930664 seconds for one epoch ---
--- 1.018519401550293 seconds for one epoch ---
--- 0.31737446784973145 seconds for one epoch ---
--- 0.9948766231536865 seconds for one epoch ---
--- 0.3097569942474365 seconds for one epoch ---
--- 1.0142159461975098 seconds for one epoch ---
--- 0.3230769634246826 seconds for one epoch ---
--- 1.0441079139709473 seconds for one epoch ---
--- 0.3280177116394043 seconds for one epoch ---
--- 1.0237774848937988 seconds for one epoch ---
--- 0.33965110778808594 seconds for one epoch ---
--- 1.0076045989990234 seconds for one epoch ---
=========================
[[1.       ]
 [0.9970051]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994023]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.553361  ]
 [-0.6474285 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.72822565]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.483001  ]
 [-0.        ]]
--- 0.5346338748931885 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5229.24853515625, (1532.6936, 4.874316, 3690.71, 0.97065765)
   validation loss 1027.6759033203125, (704.2251, 0.45749545, 322.02255, 0.97065765)
decoder loss ratio: 27282.902872, decoder SINDy loss  ratio: 0.695131
--- 0.2686178684234619 seconds for one epoch ---
--- 0.32224559783935547 seconds for one epoch ---
--- 1.023862361907959 seconds for one epoch ---
--- 0.3209571838378906 seconds for one epoch ---
--- 1.010376214981079 seconds for one epoch ---
--- 0.3227198123931885 seconds for one epoch ---
--- 1.0331916809082031 seconds for one epoch ---
--- 0.33004093170166016 seconds for one epoch ---
--- 1.024364709854126 seconds for one epoch ---
--- 0.31481170654296875 seconds for one epoch ---
--- 1.0255818367004395 seconds for one epoch ---
--- 0.32471179962158203 seconds for one epoch ---
--- 1.0548319816589355 seconds for one epoch ---
--- 0.30693745613098145 seconds for one epoch ---
--- 1.0372731685638428 seconds for one epoch ---
--- 0.316206693649292 seconds for one epoch ---
--- 1.033785343170166 seconds for one epoch ---
--- 0.32574939727783203 seconds for one epoch ---
--- 1.061333179473877 seconds for one epoch ---
--- 0.32701921463012695 seconds for one epoch ---
--- 1.0340349674224854 seconds for one epoch ---
--- 0.319840669631958 seconds for one epoch ---
--- 1.034705400466919 seconds for one epoch ---
--- 0.32312655448913574 seconds for one epoch ---
=========================
[[1.        ]
 [0.99745554]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9994764 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.5930524 ]
 [-0.6555969 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.73483896]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.497304  ]
 [-0.        ]]
--- 0.2639317512512207 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2673.32958984375, (1179.5469, 3.2250104, 1489.5868, 0.970829)
   validation loss 990.169677734375, (648.9572, 0.44447201, 339.7972, 0.970829)
decoder loss ratio: 25141.729123, decoder SINDy loss  ratio: 0.733500
--- 0.2990143299102783 seconds for one epoch ---
--- 1.0449514389038086 seconds for one epoch ---
--- 0.31636643409729004 seconds for one epoch ---
--- 1.0268223285675049 seconds for one epoch ---
--- 0.3225886821746826 seconds for one epoch ---
--- 1.0416178703308105 seconds for one epoch ---
--- 0.3235611915588379 seconds for one epoch ---
--- 1.01796555519104 seconds for one epoch ---
--- 0.3258206844329834 seconds for one epoch ---
--- 1.0544004440307617 seconds for one epoch ---
--- 0.32749366760253906 seconds for one epoch ---
--- 1.0549581050872803 seconds for one epoch ---
--- 0.3173074722290039 seconds for one epoch ---
--- 1.0406546592712402 seconds for one epoch ---
--- 0.33253049850463867 seconds for one epoch ---
--- 1.059279441833496 seconds for one epoch ---
--- 0.3277134895324707 seconds for one epoch ---
--- 1.0857734680175781 seconds for one epoch ---
--- 0.31272339820861816 seconds for one epoch ---
--- 1.0627617835998535 seconds for one epoch ---
--- 0.3200185298919678 seconds for one epoch ---
--- 1.0664548873901367 seconds for one epoch ---
--- 0.3286149501800537 seconds for one epoch ---
--- 1.0651090145111084 seconds for one epoch ---
=========================
[[1.        ]
 [0.99636793]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9994379 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.6288996]
 [-0.6377312]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7312771]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.516246 ]
 [-0.       ]]
--- 0.31224799156188965 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2858.041015625, (1301.5161, 1.5437118, 1554.0103, 0.97098553)
   validation loss 842.6111450195312, (546.5152, 0.61427975, 294.51065, 0.97098553)
decoder loss ratio: 21172.947553, decoder SINDy loss  ratio: 0.635743
--- 0.26377344131469727 seconds for one epoch ---
--- 0.3038613796234131 seconds for one epoch ---
--- 1.0557897090911865 seconds for one epoch ---
--- 0.3208291530609131 seconds for one epoch ---
--- 1.052596092224121 seconds for one epoch ---
--- 0.3019685745239258 seconds for one epoch ---
--- 1.0616436004638672 seconds for one epoch ---
--- 0.3155343532562256 seconds for one epoch ---
--- 1.0494394302368164 seconds for one epoch ---
--- 0.2950129508972168 seconds for one epoch ---
--- 1.0413775444030762 seconds for one epoch ---
--- 0.3302280902862549 seconds for one epoch ---
--- 1.0495202541351318 seconds for one epoch ---
--- 0.3042917251586914 seconds for one epoch ---
--- 1.0597877502441406 seconds for one epoch ---
--- 0.3197498321533203 seconds for one epoch ---
--- 1.0757238864898682 seconds for one epoch ---
--- 0.3117802143096924 seconds for one epoch ---
--- 1.0715081691741943 seconds for one epoch ---
--- 0.324568510055542 seconds for one epoch ---
--- 1.0559685230255127 seconds for one epoch ---
--- 0.3258965015411377 seconds for one epoch ---
--- 1.0449721813201904 seconds for one epoch ---
--- 0.3387155532836914 seconds for one epoch ---
=========================
[[1.        ]
 [0.99717623]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9993062 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.6506517 ]
 [-0.6503839 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.72075826]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5229244 ]
 [-0.        ]]
--- 0.2734041213989258 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2467.77197265625, (977.6403, 3.4372847, 1485.7234, 0.9709647)
   validation loss 949.5833740234375, (664.0257, 0.56053823, 284.02618, 0.9709647)
decoder loss ratio: 25725.508255, decoder SINDy loss  ratio: 0.613110
--- 0.32735538482666016 seconds for one epoch ---
--- 1.0554039478302002 seconds for one epoch ---
--- 0.311769962310791 seconds for one epoch ---
--- 1.0511119365692139 seconds for one epoch ---
--- 0.32282114028930664 seconds for one epoch ---
--- 1.052992582321167 seconds for one epoch ---
--- 0.3209502696990967 seconds for one epoch ---
--- 1.0472896099090576 seconds for one epoch ---
--- 0.33944082260131836 seconds for one epoch ---
--- 1.0524556636810303 seconds for one epoch ---
--- 0.31986236572265625 seconds for one epoch ---
--- 1.0672528743743896 seconds for one epoch ---
--- 0.3309757709503174 seconds for one epoch ---
--- 1.0823609828948975 seconds for one epoch ---
--- 0.32445621490478516 seconds for one epoch ---
--- 1.079514503479004 seconds for one epoch ---
--- 0.3265342712402344 seconds for one epoch ---
--- 1.0762693881988525 seconds for one epoch ---
--- 0.31749415397644043 seconds for one epoch ---
--- 1.0695886611938477 seconds for one epoch ---
--- 0.331986665725708 seconds for one epoch ---
--- 1.0705533027648926 seconds for one epoch ---
--- 0.31230974197387695 seconds for one epoch ---
--- 1.0300228595733643 seconds for one epoch ---
=========================
[[1.        ]
 [0.9976662 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99917287]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.672621  ]
 [-0.6599378 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.71194005]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.527034  ]
 [-0.        ]]
--- 0.2972445487976074 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4444.912109375, (1972.2229, 1.2436405, 2470.4746, 0.97088784)
   validation loss 1256.0074462890625, (951.3091, 0.5226861, 303.2047, 0.97088784)
decoder loss ratio: 36855.365383, decoder SINDy loss  ratio: 0.654510
--- 0.2723665237426758 seconds for one epoch ---
--- 0.3133988380432129 seconds for one epoch ---
--- 1.0494630336761475 seconds for one epoch ---
--- 0.3166837692260742 seconds for one epoch ---
--- 1.074023723602295 seconds for one epoch ---
--- 0.33530545234680176 seconds for one epoch ---
--- 1.0602893829345703 seconds for one epoch ---
--- 0.29947519302368164 seconds for one epoch ---
--- 1.0757687091827393 seconds for one epoch ---
--- 0.3210289478302002 seconds for one epoch ---
--- 1.0915780067443848 seconds for one epoch ---
--- 0.294187068939209 seconds for one epoch ---
--- 1.058222770690918 seconds for one epoch ---
--- 0.32364535331726074 seconds for one epoch ---
--- 1.0672476291656494 seconds for one epoch ---
--- 0.292586088180542 seconds for one epoch ---
--- 1.094987392425537 seconds for one epoch ---
--- 0.32783031463623047 seconds for one epoch ---
--- 1.098301649093628 seconds for one epoch ---
--- 0.32069873809814453 seconds for one epoch ---
--- 1.076890468597412 seconds for one epoch ---
--- 0.33504509925842285 seconds for one epoch ---
--- 1.061913013458252 seconds for one epoch ---
--- 0.3131754398345947 seconds for one epoch ---
=========================
[[1.       ]
 [0.9981259]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991913]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.7053716]
 [-0.6709487]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7130752]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.538011 ]
 [-0.       ]]
--- 0.2512481212615967 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4198.87109375, (1484.817, 1.966908, 2711.1162, 0.9707427)
   validation loss 1010.2343139648438, (729.5024, 0.6145482, 279.14664, 0.9707427)
decoder loss ratio: 28262.188687, decoder SINDy loss  ratio: 0.602577
--- 0.2949347496032715 seconds for one epoch ---
--- 1.0919923782348633 seconds for one epoch ---
--- 0.3344118595123291 seconds for one epoch ---
--- 1.0875747203826904 seconds for one epoch ---
--- 0.33730316162109375 seconds for one epoch ---
--- 1.088808298110962 seconds for one epoch ---
--- 0.32231640815734863 seconds for one epoch ---
--- 1.0879387855529785 seconds for one epoch ---
--- 0.31570982933044434 seconds for one epoch ---
--- 1.1219961643218994 seconds for one epoch ---
--- 0.33495473861694336 seconds for one epoch ---
--- 1.0981285572052002 seconds for one epoch ---
--- 0.331646203994751 seconds for one epoch ---
--- 1.0992989540100098 seconds for one epoch ---
--- 0.3236083984375 seconds for one epoch ---
--- 1.0919654369354248 seconds for one epoch ---
--- 0.32622265815734863 seconds for one epoch ---
--- 1.0794708728790283 seconds for one epoch ---
--- 0.31937718391418457 seconds for one epoch ---
--- 1.125324010848999 seconds for one epoch ---
--- 0.3186202049255371 seconds for one epoch ---
--- 1.0929243564605713 seconds for one epoch ---
--- 0.32402849197387695 seconds for one epoch ---
--- 1.1249761581420898 seconds for one epoch ---
=========================
[[1.        ]
 [0.99784017]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99907887]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.7376232 ]
 [-0.66384155]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.7065511 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.5604615 ]
 [-0.        ]]
--- 0.28397178649902344 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3509.875732421875, (2319.8638, 0.5266248, 1188.5148, 0.97055024)
   validation loss 839.1868286132812, (561.02386, 0.4597523, 276.7327, 0.97055024)
decoder loss ratio: 21735.038501, decoder SINDy loss  ratio: 0.597366
--- 0.27742910385131836 seconds for one epoch ---
--- 0.3255579471588135 seconds for one epoch ---
--- 1.0980455875396729 seconds for one epoch ---
--- 0.32100987434387207 seconds for one epoch ---
--- 1.1111714839935303 seconds for one epoch ---
--- 0.3200266361236572 seconds for one epoch ---
--- 1.1217055320739746 seconds for one epoch ---
--- 0.30800962448120117 seconds for one epoch ---
--- 1.0871913433074951 seconds for one epoch ---
--- 0.32196617126464844 seconds for one epoch ---
--- 1.091705083847046 seconds for one epoch ---
--- 0.3043234348297119 seconds for one epoch ---
--- 1.1233577728271484 seconds for one epoch ---
--- 0.30696535110473633 seconds for one epoch ---
--- 1.1078388690948486 seconds for one epoch ---
--- 0.31556248664855957 seconds for one epoch ---
--- 1.0944221019744873 seconds for one epoch ---
--- 0.3101365566253662 seconds for one epoch ---
--- 1.111847162246704 seconds for one epoch ---
--- 0.30585718154907227 seconds for one epoch ---
--- 1.1095056533813477 seconds for one epoch ---
--- 0.3208272457122803 seconds for one epoch ---
--- 1.096397876739502 seconds for one epoch ---
--- 0.32342004776000977 seconds for one epoch ---
=========================
[[1.        ]
 [0.99849385]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99921894]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.7805865]
 [-0.6819324]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7148231]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.584398 ]
 [-0.       ]]
--- 0.25855445861816406 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2607.264404296875, (1071.9069, 1.1361593, 1533.2515, 0.9700686)
   validation loss 1360.3240966796875, (1095.433, 0.50426596, 263.4167, 0.9700686)
decoder loss ratio: 42438.975532, decoder SINDy loss  ratio: 0.568622
--- 0.3012526035308838 seconds for one epoch ---
--- 1.0923399925231934 seconds for one epoch ---
--- 0.31375765800476074 seconds for one epoch ---
--- 1.1158335208892822 seconds for one epoch ---
--- 0.32097387313842773 seconds for one epoch ---
--- 1.1156890392303467 seconds for one epoch ---
--- 0.3201112747192383 seconds for one epoch ---
--- 1.0756821632385254 seconds for one epoch ---
--- 0.32230424880981445 seconds for one epoch ---
--- 1.1115872859954834 seconds for one epoch ---
--- 0.32483625411987305 seconds for one epoch ---
--- 1.1082205772399902 seconds for one epoch ---
--- 0.31506943702697754 seconds for one epoch ---
--- 1.1299598217010498 seconds for one epoch ---
--- 0.3311729431152344 seconds for one epoch ---
--- 1.1269562244415283 seconds for one epoch ---
--- 0.3102986812591553 seconds for one epoch ---
--- 1.1142988204956055 seconds for one epoch ---
--- 0.3304460048675537 seconds for one epoch ---
--- 1.101123332977295 seconds for one epoch ---
--- 0.3317689895629883 seconds for one epoch ---
--- 1.119713306427002 seconds for one epoch ---
--- 0.323150634765625 seconds for one epoch ---
--- 1.130371332168579 seconds for one epoch ---
=========================
[[1.        ]
 [0.99817634]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9990599 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8088596 ]
 [-0.67231905]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.7055315 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6046443 ]
 [-0.        ]]
--- 0.3086686134338379 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3391.899169921875, (1234.352, 1.8859484, 2154.692, 0.9691699)
   validation loss 844.5486450195312, (577.06104, 0.510686, 266.00775, 0.9691699)
decoder loss ratio: 22356.346324, decoder SINDy loss  ratio: 0.574215
--- 0.2659494876861572 seconds for one epoch ---
--- 0.3164560794830322 seconds for one epoch ---
--- 1.0983986854553223 seconds for one epoch ---
--- 0.31699442863464355 seconds for one epoch ---
--- 1.144536018371582 seconds for one epoch ---
--- 0.3499476909637451 seconds for one epoch ---
--- 1.1219103336334229 seconds for one epoch ---
--- 0.3240323066711426 seconds for one epoch ---
--- 1.1169016361236572 seconds for one epoch ---
--- 0.33096957206726074 seconds for one epoch ---
--- 1.1365687847137451 seconds for one epoch ---
--- 0.34108686447143555 seconds for one epoch ---
--- 1.1533968448638916 seconds for one epoch ---
--- 0.3191206455230713 seconds for one epoch ---
--- 1.1276347637176514 seconds for one epoch ---
--- 0.3237416744232178 seconds for one epoch ---
--- 1.1622653007507324 seconds for one epoch ---
--- 0.3342611789703369 seconds for one epoch ---
--- 1.1225688457489014 seconds for one epoch ---
--- 0.3368794918060303 seconds for one epoch ---
--- 1.1175339221954346 seconds for one epoch ---
--- 0.33507442474365234 seconds for one epoch ---
--- 1.1361057758331299 seconds for one epoch ---
--- 0.3354167938232422 seconds for one epoch ---
=========================
[[1.        ]
 [0.99774104]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9991099 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8452437 ]
 [-0.6615888 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.70831853]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6198807 ]
 [-0.        ]]
--- 0.27398228645324707 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2086.43212890625, (1115.2914, 1.2322001, 968.9409, 0.9678051)
   validation loss 1050.0987548828125, (765.89166, 0.57762617, 282.66165, 0.9678051)
decoder loss ratio: 29671.972655, decoder SINDy loss  ratio: 0.610165
--- 0.3185274600982666 seconds for one epoch ---
--- 1.1189215183258057 seconds for one epoch ---
--- 0.3308854103088379 seconds for one epoch ---
--- 1.1171624660491943 seconds for one epoch ---
--- 0.31327247619628906 seconds for one epoch ---
--- 1.1491999626159668 seconds for one epoch ---
--- 0.31949639320373535 seconds for one epoch ---
--- 1.1122663021087646 seconds for one epoch ---
--- 0.33155369758605957 seconds for one epoch ---
--- 1.129032850265503 seconds for one epoch ---
--- 0.31162524223327637 seconds for one epoch ---
--- 1.1383318901062012 seconds for one epoch ---
--- 0.326127290725708 seconds for one epoch ---
--- 1.1421256065368652 seconds for one epoch ---
--- 0.3352370262145996 seconds for one epoch ---
--- 1.1241562366485596 seconds for one epoch ---
--- 0.3144502639770508 seconds for one epoch ---
--- 1.1641087532043457 seconds for one epoch ---
--- 0.3074324131011963 seconds for one epoch ---
--- 1.1311473846435547 seconds for one epoch ---
--- 0.32055211067199707 seconds for one epoch ---
--- 1.1378097534179688 seconds for one epoch ---
--- 0.3160581588745117 seconds for one epoch ---
--- 1.1395597457885742 seconds for one epoch ---
=========================
[[1.        ]
 [0.99732393]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9990908 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.8838747]
 [-0.6530775]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7071855]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.6485634]
 [-0.       ]]
--- 0.3003082275390625 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4153.21875, (1156.8462, 2.3747022, 2993.0322, 0.9658805)
   validation loss 1447.765380859375, (1155.2927, 0.5863206, 290.92047, 0.9658805)
decoder loss ratio: 44758.045828, decoder SINDy loss  ratio: 0.627993
--- 0.2762138843536377 seconds for one epoch ---
--- 0.32816123962402344 seconds for one epoch ---
--- 1.1528654098510742 seconds for one epoch ---
--- 0.32282495498657227 seconds for one epoch ---
--- 1.1265239715576172 seconds for one epoch ---
--- 0.3112218379974365 seconds for one epoch ---
--- 1.1388542652130127 seconds for one epoch ---
--- 0.32851123809814453 seconds for one epoch ---
--- 1.144648551940918 seconds for one epoch ---
--- 0.3300187587738037 seconds for one epoch ---
--- 1.1529731750488281 seconds for one epoch ---
--- 0.3217041492462158 seconds for one epoch ---
--- 1.1375515460968018 seconds for one epoch ---
--- 0.3191263675689697 seconds for one epoch ---
--- 1.1260571479797363 seconds for one epoch ---
--- 0.3291041851043701 seconds for one epoch ---
--- 1.157348871231079 seconds for one epoch ---
--- 0.3287971019744873 seconds for one epoch ---
--- 1.1528778076171875 seconds for one epoch ---
--- 0.32106590270996094 seconds for one epoch ---
--- 1.1381943225860596 seconds for one epoch ---
--- 0.3223717212677002 seconds for one epoch ---
--- 1.1743245124816895 seconds for one epoch ---
--- 0.32834792137145996 seconds for one epoch ---
=========================
[[1.       ]
 [0.9965689]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986819]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-2.899036  ]
 [-0.64060044]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6885956 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6523824 ]
 [-0.        ]]
--- 0.2633936405181885 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3440.557861328125, (1109.1818, 1.040989, 2329.3718, 0.96306515)
   validation loss 755.8119506835938, (446.07645, 0.37180826, 308.40063, 0.96306515)
decoder loss ratio: 17281.775961, decoder SINDy loss  ratio: 0.665726
--- 0.3282351493835449 seconds for one epoch ---
--- 1.1515090465545654 seconds for one epoch ---
--- 0.3137030601501465 seconds for one epoch ---
--- 1.1240110397338867 seconds for one epoch ---
--- 0.31410861015319824 seconds for one epoch ---
--- 1.1582481861114502 seconds for one epoch ---
--- 0.3229856491088867 seconds for one epoch ---
--- 1.1210365295410156 seconds for one epoch ---
--- 0.31482744216918945 seconds for one epoch ---
--- 1.170396327972412 seconds for one epoch ---
--- 0.3189234733581543 seconds for one epoch ---
--- 1.160301685333252 seconds for one epoch ---
--- 0.32892346382141113 seconds for one epoch ---
--- 1.1426365375518799 seconds for one epoch ---
--- 0.332444429397583 seconds for one epoch ---
--- 1.1680097579956055 seconds for one epoch ---
--- 0.3304417133331299 seconds for one epoch ---
--- 1.16102933883667 seconds for one epoch ---
--- 0.320082426071167 seconds for one epoch ---
--- 1.164304494857788 seconds for one epoch ---
--- 0.3144347667694092 seconds for one epoch ---
--- 1.1387717723846436 seconds for one epoch ---
--- 0.33024048805236816 seconds for one epoch ---
--- 1.1638567447662354 seconds for one epoch ---
=========================
[[1.        ]
 [0.99761856]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9985904 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9118078]
 [-0.6589474]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6852318]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6360173]
 [-0.       ]]
--- 0.3096432685852051 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2332.5224609375, (1391.547, 0.48625535, 939.52954, 0.95975083)
   validation loss 785.5670166015625, (490.42804, 0.44974658, 293.72946, 0.95975083)
decoder loss ratio: 19000.033673, decoder SINDy loss  ratio: 0.634056
THRESHOLDING: 4 active coefficients
--- 1.1448113918304443 seconds for one epoch ---
--- 0.33368444442749023 seconds for one epoch ---
--- 1.1474828720092773 seconds for one epoch ---
--- 0.3305399417877197 seconds for one epoch ---
--- 1.1505167484283447 seconds for one epoch ---
--- 0.32503461837768555 seconds for one epoch ---
--- 1.165604829788208 seconds for one epoch ---
--- 0.31868791580200195 seconds for one epoch ---
--- 1.1648986339569092 seconds for one epoch ---
--- 0.3127608299255371 seconds for one epoch ---
--- 1.1618003845214844 seconds for one epoch ---
--- 0.31656336784362793 seconds for one epoch ---
--- 1.1680488586425781 seconds for one epoch ---
--- 0.3223559856414795 seconds for one epoch ---
--- 1.1765756607055664 seconds for one epoch ---
--- 0.32355260848999023 seconds for one epoch ---
--- 1.1621582508087158 seconds for one epoch ---
--- 0.3266775608062744 seconds for one epoch ---
--- 1.1786353588104248 seconds for one epoch ---
--- 0.3283510208129883 seconds for one epoch ---
--- 1.1992385387420654 seconds for one epoch ---
--- 0.34673237800598145 seconds for one epoch ---
--- 1.1792376041412354 seconds for one epoch ---
--- 0.32479429244995117 seconds for one epoch ---
=========================
[[1.        ]
 [0.99789035]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9989057 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.94547   ]
 [-0.6650193 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.69794035]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6391706 ]
 [-0.        ]]
--- 0.25968003273010254 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3326.31982421875, (1171.6343, 0.19466631, 2153.5476, 0.94330806)
   validation loss 1195.7847900390625, (859.9979, 0.41682723, 334.4267, 0.94330806)
decoder loss ratio: 33317.812629, decoder SINDy loss  ratio: 0.721907
--- 0.310840368270874 seconds for one epoch ---
--- 1.1786818504333496 seconds for one epoch ---
--- 0.33011412620544434 seconds for one epoch ---
--- 1.1634745597839355 seconds for one epoch ---
--- 0.3170778751373291 seconds for one epoch ---
--- 1.1686768531799316 seconds for one epoch ---
--- 0.33048462867736816 seconds for one epoch ---
--- 1.1722075939178467 seconds for one epoch ---
--- 0.33281588554382324 seconds for one epoch ---
--- 1.2149550914764404 seconds for one epoch ---
--- 0.3320028781890869 seconds for one epoch ---
--- 1.1701807975769043 seconds for one epoch ---
--- 0.3279106616973877 seconds for one epoch ---
--- 1.16591477394104 seconds for one epoch ---
--- 0.33071303367614746 seconds for one epoch ---
--- 1.196941614151001 seconds for one epoch ---
--- 0.3286738395690918 seconds for one epoch ---
--- 1.2133452892303467 seconds for one epoch ---
--- 0.33467984199523926 seconds for one epoch ---
--- 1.1779327392578125 seconds for one epoch ---
--- 0.322798490524292 seconds for one epoch ---
--- 1.1727962493896484 seconds for one epoch ---
--- 0.3127250671386719 seconds for one epoch ---
--- 1.1883604526519775 seconds for one epoch ---
=========================
[[1.        ]
 [0.99800026]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.998798  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.965432  ]
 [-0.66771424]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6932442 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.635843  ]
 [-0.        ]]
--- 0.30593299865722656 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3527.38671875, (1395.4235, 3.7122023, 2127.3079, 0.9433732)
   validation loss 1373.326171875, (1085.351, 0.55433756, 286.4776, 0.9433732)
decoder loss ratio: 42048.380138, decoder SINDy loss  ratio: 0.618402
--- 0.27304577827453613 seconds for one epoch ---
--- 0.33245325088500977 seconds for one epoch ---
--- 1.1851017475128174 seconds for one epoch ---
--- 0.29973602294921875 seconds for one epoch ---
--- 1.1707401275634766 seconds for one epoch ---
--- 0.33739614486694336 seconds for one epoch ---
--- 1.1748521327972412 seconds for one epoch ---
--- 0.33481287956237793 seconds for one epoch ---
--- 1.1855504512786865 seconds for one epoch ---
--- 0.318713903427124 seconds for one epoch ---
--- 1.1691148281097412 seconds for one epoch ---
--- 0.32651209831237793 seconds for one epoch ---
--- 1.2056915760040283 seconds for one epoch ---
--- 0.33401942253112793 seconds for one epoch ---
--- 1.2087864875793457 seconds for one epoch ---
--- 0.31914782524108887 seconds for one epoch ---
--- 1.2087936401367188 seconds for one epoch ---
--- 0.32462239265441895 seconds for one epoch ---
--- 1.1904840469360352 seconds for one epoch ---
--- 0.33270812034606934 seconds for one epoch ---
--- 1.1975419521331787 seconds for one epoch ---
--- 0.3080790042877197 seconds for one epoch ---
--- 1.2129900455474854 seconds for one epoch ---
--- 0.32433247566223145 seconds for one epoch ---
=========================
[[1.        ]
 [0.99777555]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9984137 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9826672 ]
 [-0.6623703 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.67932355]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.638892  ]
 [-0.        ]]
--- 0.268444299697876 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2051.12646484375, (1172.9839, 0.47211376, 876.7269, 0.9434523)
   validation loss 1113.688720703125, (840.88226, 0.49857783, 271.36435, 0.9434523)
decoder loss ratio: 32577.238712, decoder SINDy loss  ratio: 0.585778
--- 0.31775736808776855 seconds for one epoch ---
--- 1.1788992881774902 seconds for one epoch ---
--- 0.33870577812194824 seconds for one epoch ---
--- 1.193589448928833 seconds for one epoch ---
--- 0.3289217948913574 seconds for one epoch ---
--- 1.2099034786224365 seconds for one epoch ---
--- 0.32390880584716797 seconds for one epoch ---
--- 1.1740038394927979 seconds for one epoch ---
--- 0.3255879878997803 seconds for one epoch ---
--- 1.2061574459075928 seconds for one epoch ---
--- 0.31416988372802734 seconds for one epoch ---
--- 1.197845458984375 seconds for one epoch ---
--- 0.3195157051086426 seconds for one epoch ---
--- 1.2145495414733887 seconds for one epoch ---
--- 0.33028578758239746 seconds for one epoch ---
--- 1.228006362915039 seconds for one epoch ---
--- 0.340770959854126 seconds for one epoch ---
--- 1.204913854598999 seconds for one epoch ---
--- 0.33186912536621094 seconds for one epoch ---
--- 1.200552225112915 seconds for one epoch ---
--- 0.3172786235809326 seconds for one epoch ---
--- 1.1860837936401367 seconds for one epoch ---
--- 0.3229033946990967 seconds for one epoch ---
--- 1.2273311614990234 seconds for one epoch ---
=========================
[[1.        ]
 [0.998356  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99784285]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-2.9980266]
 [-0.6775412]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6639111]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.646919 ]
 [-0.       ]]
--- 0.31256532669067383 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4379.0263671875, (3112.6433, 0.5442795, 1264.8958, 0.943555)
   validation loss 1379.91748046875, (1056.2511, 0.55141866, 322.17145, 0.943555)
decoder loss ratio: 40921.001294, decoder SINDy loss  ratio: 0.695452
--- 0.25859951972961426 seconds for one epoch ---
--- 0.3138010501861572 seconds for one epoch ---
--- 1.2259116172790527 seconds for one epoch ---
--- 0.32959413528442383 seconds for one epoch ---
--- 1.2141859531402588 seconds for one epoch ---
--- 0.32833075523376465 seconds for one epoch ---
--- 1.23832106590271 seconds for one epoch ---
--- 0.3053922653198242 seconds for one epoch ---
--- 1.1924469470977783 seconds for one epoch ---
--- 0.331437349319458 seconds for one epoch ---
--- 1.2294812202453613 seconds for one epoch ---
--- 0.3356053829193115 seconds for one epoch ---
--- 1.2289669513702393 seconds for one epoch ---
--- 0.32895445823669434 seconds for one epoch ---
--- 1.2265605926513672 seconds for one epoch ---
--- 0.3307456970214844 seconds for one epoch ---
--- 1.2252089977264404 seconds for one epoch ---
--- 0.34274768829345703 seconds for one epoch ---
--- 1.221198558807373 seconds for one epoch ---
--- 0.32360363006591797 seconds for one epoch ---
--- 1.2169723510742188 seconds for one epoch ---
--- 0.3239407539367676 seconds for one epoch ---
--- 1.233327865600586 seconds for one epoch ---
--- 0.3335916996002197 seconds for one epoch ---
=========================
[[1.       ]
 [0.998695 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9981595]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.042062  ]
 [-0.68910384]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.67187685]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6753125 ]
 [-0.        ]]
--- 0.2639610767364502 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3141.475341796875, (1443.2244, 0.25031027, 1697.0568, 0.9439522)
   validation loss 670.3548583984375, (403.08218, 0.7194946, 265.6092, 0.9439522)
decoder loss ratio: 15616.103583, decoder SINDy loss  ratio: 0.573355
--- 0.32036662101745605 seconds for one epoch ---
--- 1.1795899868011475 seconds for one epoch ---
--- 0.3215322494506836 seconds for one epoch ---
--- 1.218174934387207 seconds for one epoch ---
--- 0.3117341995239258 seconds for one epoch ---
--- 1.2348313331604004 seconds for one epoch ---
--- 0.31655216217041016 seconds for one epoch ---
--- 1.2137939929962158 seconds for one epoch ---
--- 0.32337141036987305 seconds for one epoch ---
--- 1.2224276065826416 seconds for one epoch ---
--- 0.3287055492401123 seconds for one epoch ---
--- 1.2447938919067383 seconds for one epoch ---
--- 0.3128185272216797 seconds for one epoch ---
--- 1.2343833446502686 seconds for one epoch ---
--- 0.331188440322876 seconds for one epoch ---
--- 1.2609689235687256 seconds for one epoch ---
--- 0.3251664638519287 seconds for one epoch ---
--- 1.2175321578979492 seconds for one epoch ---
--- 0.3335740566253662 seconds for one epoch ---
--- 1.2219271659851074 seconds for one epoch ---
--- 0.3256690502166748 seconds for one epoch ---
--- 1.2281060218811035 seconds for one epoch ---
--- 0.3169269561767578 seconds for one epoch ---
--- 1.2537221908569336 seconds for one epoch ---
=========================
[[1.       ]
 [0.999007 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9980784]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.0667064]
 [-0.7027962]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6697167]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.680287 ]
 [-0.       ]]
--- 0.31055402755737305 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4034.8232421875, (1854.0043, 2.307303, 2177.5676, 0.9441172)
   validation loss 821.29541015625, (516.942, 0.72220874, 302.68704, 0.9441172)
decoder loss ratio: 20027.231174, decoder SINDy loss  ratio: 0.653393
--- 0.26404523849487305 seconds for one epoch ---
--- 0.3332540988922119 seconds for one epoch ---
--- 1.2367918491363525 seconds for one epoch ---
--- 0.31542420387268066 seconds for one epoch ---
--- 1.2279672622680664 seconds for one epoch ---
--- 0.32656359672546387 seconds for one epoch ---
--- 1.2101073265075684 seconds for one epoch ---
--- 0.3246767520904541 seconds for one epoch ---
--- 1.257934808731079 seconds for one epoch ---
--- 0.32767820358276367 seconds for one epoch ---
--- 1.2492187023162842 seconds for one epoch ---
--- 0.31740379333496094 seconds for one epoch ---
--- 1.2323250770568848 seconds for one epoch ---
--- 0.3229405879974365 seconds for one epoch ---
--- 1.2244908809661865 seconds for one epoch ---
--- 0.3161044120788574 seconds for one epoch ---
--- 1.251279354095459 seconds for one epoch ---
--- 0.32500171661376953 seconds for one epoch ---
--- 1.2281627655029297 seconds for one epoch ---
--- 0.3267049789428711 seconds for one epoch ---
--- 1.2258808612823486 seconds for one epoch ---
--- 0.33776116371154785 seconds for one epoch ---
--- 1.2265772819519043 seconds for one epoch ---
--- 0.32745814323425293 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995111 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99743605]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.0737033 ]
 [-0.73834676]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.6552419 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6701336 ]
 [-0.        ]]
--- 0.26542067527770996 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2621.741943359375, (1526.7059, 1.1670648, 1092.9249, 0.94409317)
   validation loss 2331.165771484375, (2022.7721, 0.823686, 306.62576, 0.94409317)
decoder loss ratio: 78365.702636, decoder SINDy loss  ratio: 0.661895
--- 0.32541680335998535 seconds for one epoch ---
--- 1.236224889755249 seconds for one epoch ---
--- 0.33165526390075684 seconds for one epoch ---
--- 1.2279694080352783 seconds for one epoch ---
--- 0.3266289234161377 seconds for one epoch ---
--- 1.2535998821258545 seconds for one epoch ---
--- 0.3216516971588135 seconds for one epoch ---
--- 1.250147819519043 seconds for one epoch ---
--- 0.3371701240539551 seconds for one epoch ---
--- 1.2431015968322754 seconds for one epoch ---
--- 0.3323550224304199 seconds for one epoch ---
--- 1.2493221759796143 seconds for one epoch ---
--- 0.3147892951965332 seconds for one epoch ---
--- 1.2573590278625488 seconds for one epoch ---
--- 0.3193333148956299 seconds for one epoch ---
--- 1.2616033554077148 seconds for one epoch ---
--- 0.33097219467163086 seconds for one epoch ---
--- 1.2564756870269775 seconds for one epoch ---
--- 0.32449936866760254 seconds for one epoch ---
--- 1.271653413772583 seconds for one epoch ---
--- 0.31357884407043457 seconds for one epoch ---
--- 1.2681350708007812 seconds for one epoch ---
--- 0.3223998546600342 seconds for one epoch ---
--- 1.2626497745513916 seconds for one epoch ---
=========================
[[1.       ]
 [0.9991033]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9982183]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.1149147 ]
 [-0.7079273 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.67349905]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.68219   ]
 [-0.        ]]
--- 0.32079052925109863 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3964.29931640625, (2189.5193, 5.8170376, 1768.0186, 0.9443852)
   validation loss 1034.048828125, (717.26154, 0.75515276, 315.08777, 0.9443852)
decoder loss ratio: 27787.957112, decoder SINDy loss  ratio: 0.680161
--- 0.2739987373352051 seconds for one epoch ---
--- 0.31572484970092773 seconds for one epoch ---
--- 1.2627205848693848 seconds for one epoch ---
--- 0.34038496017456055 seconds for one epoch ---
--- 1.2680995464324951 seconds for one epoch ---
--- 0.33123350143432617 seconds for one epoch ---
--- 1.24461030960083 seconds for one epoch ---
--- 0.3166615962982178 seconds for one epoch ---
--- 1.2623686790466309 seconds for one epoch ---
--- 0.32824158668518066 seconds for one epoch ---
--- 1.2883129119873047 seconds for one epoch ---
--- 0.34438371658325195 seconds for one epoch ---
--- 1.2500269412994385 seconds for one epoch ---
--- 0.3186910152435303 seconds for one epoch ---
--- 1.2634966373443604 seconds for one epoch ---
--- 0.32457995414733887 seconds for one epoch ---
--- 1.2678802013397217 seconds for one epoch ---
--- 0.32012343406677246 seconds for one epoch ---
--- 1.2887187004089355 seconds for one epoch ---
--- 0.33011531829833984 seconds for one epoch ---
--- 1.2591197490692139 seconds for one epoch ---
--- 0.32018089294433594 seconds for one epoch ---
--- 1.2423982620239258 seconds for one epoch ---
--- 0.31118059158325195 seconds for one epoch ---
=========================
[[1.        ]
 [0.9989653 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99824876]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.1468842 ]
 [-0.70074916]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.67435396]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.703766  ]
 [-0.        ]]
--- 0.27083277702331543 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2328.64404296875, (1297.9427, 0.7589595, 1028.9978, 0.9446296)
   validation loss 1231.5721435546875, (928.2957, 0.71712583, 301.61472, 0.9446296)
decoder loss ratio: 35963.787604, decoder SINDy loss  ratio: 0.651078
--- 0.3351283073425293 seconds for one epoch ---
--- 1.2735841274261475 seconds for one epoch ---
--- 0.3327946662902832 seconds for one epoch ---
--- 1.2783706188201904 seconds for one epoch ---
--- 0.32897210121154785 seconds for one epoch ---
--- 1.2817199230194092 seconds for one epoch ---
--- 0.327756404876709 seconds for one epoch ---
--- 1.268127679824829 seconds for one epoch ---
--- 0.31796717643737793 seconds for one epoch ---
--- 1.269707202911377 seconds for one epoch ---
--- 0.3392910957336426 seconds for one epoch ---
--- 1.2703068256378174 seconds for one epoch ---
--- 0.3152146339416504 seconds for one epoch ---
--- 1.2904853820800781 seconds for one epoch ---
--- 0.31748437881469727 seconds for one epoch ---
--- 1.269416093826294 seconds for one epoch ---
--- 0.31798887252807617 seconds for one epoch ---
--- 1.2608468532562256 seconds for one epoch ---
--- 0.319350004196167 seconds for one epoch ---
--- 1.2491977214813232 seconds for one epoch ---
--- 0.3287160396575928 seconds for one epoch ---
--- 1.2639026641845703 seconds for one epoch ---
--- 0.5637986660003662 seconds for one epoch ---
--- 1.25528883934021 seconds for one epoch ---
=========================
[[1.        ]
 [0.9992783 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99798906]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.168271  ]
 [-0.71880853]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.6674268 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.7094307 ]
 [-0.        ]]
--- 0.3119008541107178 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3551.96435546875, (1734.6356, 3.6449015, 1812.739, 0.9447951)
   validation loss 950.5582275390625, (654.75745, 0.569207, 294.28674, 0.9447951)
decoder loss ratio: 25366.440178, decoder SINDy loss  ratio: 0.635259
--- 0.28237009048461914 seconds for one epoch ---
--- 0.294921875 seconds for one epoch ---
--- 1.287832498550415 seconds for one epoch ---
--- 0.32878851890563965 seconds for one epoch ---
--- 1.2562355995178223 seconds for one epoch ---
--- 0.32385897636413574 seconds for one epoch ---
--- 1.285566806793213 seconds for one epoch ---
--- 0.32062482833862305 seconds for one epoch ---
--- 1.2571110725402832 seconds for one epoch ---
--- 0.33150792121887207 seconds for one epoch ---
--- 1.275871753692627 seconds for one epoch ---
--- 0.32467007637023926 seconds for one epoch ---
--- 1.2902884483337402 seconds for one epoch ---
--- 0.31788110733032227 seconds for one epoch ---
--- 1.2958638668060303 seconds for one epoch ---
--- 0.32085418701171875 seconds for one epoch ---
--- 1.2953672409057617 seconds for one epoch ---
--- 0.32790541648864746 seconds for one epoch ---
--- 1.2987680435180664 seconds for one epoch ---
--- 0.3260986804962158 seconds for one epoch ---
--- 1.2979350090026855 seconds for one epoch ---
--- 0.32204389572143555 seconds for one epoch ---
--- 1.3110721111297607 seconds for one epoch ---
--- 0.33468055725097656 seconds for one epoch ---
=========================
[[1.       ]
 [0.9987512]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976134]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.1864038 ]
 [-0.69132197]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.6588358 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.71583   ]
 [-0.        ]]
--- 0.2571754455566406 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3927.09375, (1784.852, 5.311995, 2135.9849, 0.9448735)
   validation loss 875.3939819335938, (575.80273, 0.81278825, 297.83356, 0.9448735)
decoder loss ratio: 22307.597567, decoder SINDy loss  ratio: 0.642916
--- 0.31858325004577637 seconds for one epoch ---
--- 1.2762811183929443 seconds for one epoch ---
--- 0.33449602127075195 seconds for one epoch ---
--- 1.2870965003967285 seconds for one epoch ---
--- 0.3175833225250244 seconds for one epoch ---
--- 1.2697789669036865 seconds for one epoch ---
--- 0.31264209747314453 seconds for one epoch ---
--- 1.3045883178710938 seconds for one epoch ---
--- 0.3204329013824463 seconds for one epoch ---
--- 1.3045711517333984 seconds for one epoch ---
--- 0.3351624011993408 seconds for one epoch ---
--- 1.2993550300598145 seconds for one epoch ---
--- 0.3201453685760498 seconds for one epoch ---
--- 1.264467716217041 seconds for one epoch ---
--- 0.31491875648498535 seconds for one epoch ---
--- 1.3043911457061768 seconds for one epoch ---
--- 0.3292686939239502 seconds for one epoch ---
--- 1.2818288803100586 seconds for one epoch ---
--- 0.3272702693939209 seconds for one epoch ---
--- 1.2909953594207764 seconds for one epoch ---
--- 0.3109591007232666 seconds for one epoch ---
--- 1.2915699481964111 seconds for one epoch ---
--- 0.3290896415710449 seconds for one epoch ---
--- 1.3135719299316406 seconds for one epoch ---
=========================
[[1.        ]
 [0.99893737]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9974947 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.203625  ]
 [-0.69939417]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6563903 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.7078786 ]
 [-0.        ]]
--- 0.31708192825317383 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2682.936767578125, (1092.5365, 3.715545, 1585.7399, 0.94493)
   validation loss 808.997802734375, (548.498, 0.5601691, 258.99466, 0.94493)
decoder loss ratio: 21249.764206, decoder SINDy loss  ratio: 0.559076
--- 0.28461456298828125 seconds for one epoch ---
--- 0.32088494300842285 seconds for one epoch ---
--- 1.2953121662139893 seconds for one epoch ---
--- 0.3201720714569092 seconds for one epoch ---
--- 1.3132846355438232 seconds for one epoch ---
--- 0.33811378479003906 seconds for one epoch ---
--- 1.2906372547149658 seconds for one epoch ---
--- 0.3228929042816162 seconds for one epoch ---
--- 1.2954401969909668 seconds for one epoch ---
--- 0.3354673385620117 seconds for one epoch ---
--- 1.2918405532836914 seconds for one epoch ---
--- 0.33537745475769043 seconds for one epoch ---
--- 1.2980051040649414 seconds for one epoch ---
--- 0.3122408390045166 seconds for one epoch ---
--- 1.2946572303771973 seconds for one epoch ---
--- 0.3217191696166992 seconds for one epoch ---
--- 1.295412540435791 seconds for one epoch ---
--- 0.3120856285095215 seconds for one epoch ---
--- 1.3211534023284912 seconds for one epoch ---
--- 0.3141632080078125 seconds for one epoch ---
--- 1.302414894104004 seconds for one epoch ---
--- 0.3340179920196533 seconds for one epoch ---
--- 1.3066487312316895 seconds for one epoch ---
--- 0.32268643379211426 seconds for one epoch ---
=========================
[[1.       ]
 [0.9988156]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9973702]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.2192183]
 [-0.69396  ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6539486]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7044296]
 [-0.       ]]
--- 0.2549092769622803 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2505.482421875, (1233.838, 0.7417746, 1269.9576, 0.9449116)
   validation loss 935.8828735351562, (671.2312, 0.7098065, 262.99698, 0.9449116)
decoder loss ratio: 26004.662042, decoder SINDy loss  ratio: 0.567716
--- 0.3028872013092041 seconds for one epoch ---
--- 1.3434391021728516 seconds for one epoch ---
--- 0.32451629638671875 seconds for one epoch ---
--- 1.3059322834014893 seconds for one epoch ---
--- 0.3037581443786621 seconds for one epoch ---
--- 1.3224437236785889 seconds for one epoch ---
--- 0.32522106170654297 seconds for one epoch ---
--- 1.330197811126709 seconds for one epoch ---
--- 0.31078410148620605 seconds for one epoch ---
--- 1.2988173961639404 seconds for one epoch ---
--- 0.3232247829437256 seconds for one epoch ---
--- 1.3133761882781982 seconds for one epoch ---
--- 0.323563814163208 seconds for one epoch ---
--- 1.3151235580444336 seconds for one epoch ---
--- 0.32276082038879395 seconds for one epoch ---
--- 1.3282794952392578 seconds for one epoch ---
--- 0.31726527214050293 seconds for one epoch ---
--- 1.3109040260314941 seconds for one epoch ---
--- 0.3188598155975342 seconds for one epoch ---
--- 1.321103572845459 seconds for one epoch ---
--- 0.3303511142730713 seconds for one epoch ---
--- 1.312148094177246 seconds for one epoch ---
--- 0.3343491554260254 seconds for one epoch ---
--- 1.3138272762298584 seconds for one epoch ---
=========================
[[1.        ]
 [0.99916804]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9971639 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.235494  ]
 [-0.7116694 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.65016407]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.7000566 ]
 [-0.        ]]
--- 0.3203248977661133 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3615.300048828125, (1138.9926, 1.6335878, 2473.7288, 0.9450418)
   validation loss 865.8255615234375, (580.7345, 0.7470136, 283.39896, 0.9450418)
decoder loss ratio: 22498.662616, decoder SINDy loss  ratio: 0.611757
--- 0.27358531951904297 seconds for one epoch ---
--- 0.327664852142334 seconds for one epoch ---
--- 1.3321995735168457 seconds for one epoch ---
--- 0.34159183502197266 seconds for one epoch ---
--- 1.3063879013061523 seconds for one epoch ---
--- 0.3278801441192627 seconds for one epoch ---
--- 1.3281736373901367 seconds for one epoch ---
--- 0.3178112506866455 seconds for one epoch ---
--- 1.3135089874267578 seconds for one epoch ---
--- 0.3102266788482666 seconds for one epoch ---
--- 1.3235743045806885 seconds for one epoch ---
--- 0.33034300804138184 seconds for one epoch ---
--- 1.3003580570220947 seconds for one epoch ---
--- 0.32487964630126953 seconds for one epoch ---
--- 1.359727144241333 seconds for one epoch ---
--- 0.3262016773223877 seconds for one epoch ---
--- 1.3532695770263672 seconds for one epoch ---
--- 0.32827138900756836 seconds for one epoch ---
--- 1.348106861114502 seconds for one epoch ---
--- 0.32335615158081055 seconds for one epoch ---
--- 1.3441417217254639 seconds for one epoch ---
--- 0.3319246768951416 seconds for one epoch ---
--- 1.3135735988616943 seconds for one epoch ---
--- 0.3250424861907959 seconds for one epoch ---
=========================
[[1.       ]
 [0.9994824]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976258]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.2555692]
 [-0.7354395]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6590807]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.6930757]
 [-0.       ]]
--- 0.26532888412475586 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2370.232421875, (908.53937, 0.8184165, 1459.9296, 0.94505036)
   validation loss 758.5360107421875, (440.97186, 0.71259373, 315.9065, 0.94505036)
decoder loss ratio: 17084.015525, decoder SINDy loss  ratio: 0.681929
--- 0.3246767520904541 seconds for one epoch ---
--- 1.33949613571167 seconds for one epoch ---
--- 0.32709765434265137 seconds for one epoch ---
--- 1.3405241966247559 seconds for one epoch ---
--- 0.3146994113922119 seconds for one epoch ---
--- 1.3298542499542236 seconds for one epoch ---
--- 0.31469273567199707 seconds for one epoch ---
--- 1.350271224975586 seconds for one epoch ---
--- 0.31433725357055664 seconds for one epoch ---
--- 1.349327564239502 seconds for one epoch ---
--- 0.3067440986633301 seconds for one epoch ---
--- 1.3511998653411865 seconds for one epoch ---
--- 0.31740903854370117 seconds for one epoch ---
--- 1.325284719467163 seconds for one epoch ---
--- 0.31003499031066895 seconds for one epoch ---
--- 1.3403217792510986 seconds for one epoch ---
--- 0.3161966800689697 seconds for one epoch ---
--- 1.3222200870513916 seconds for one epoch ---
--- 0.3091564178466797 seconds for one epoch ---
--- 1.32330322265625 seconds for one epoch ---
--- 0.32343459129333496 seconds for one epoch ---
--- 1.3441243171691895 seconds for one epoch ---
--- 0.3311755657196045 seconds for one epoch ---
--- 1.3506543636322021 seconds for one epoch ---
=========================
[[1.       ]
 [0.9994844]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976442]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.2891002 ]
 [-0.73566765]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.65945715]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.7170215 ]
 [-0.        ]]
--- 0.31496739387512207 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5412.67724609375, (1593.4624, 1.2653242, 3817.0042, 0.9453832)
   validation loss 1055.34619140625, (796.48517, 0.7020896, 257.21347, 0.9453832)
decoder loss ratio: 30857.218185, decoder SINDy loss  ratio: 0.555231
--- 0.29136157035827637 seconds for one epoch ---
--- 0.34679293632507324 seconds for one epoch ---
--- 1.3428783416748047 seconds for one epoch ---
--- 0.33751416206359863 seconds for one epoch ---
--- 1.3519175052642822 seconds for one epoch ---
--- 0.3310110569000244 seconds for one epoch ---
--- 1.348670482635498 seconds for one epoch ---
--- 0.31424665451049805 seconds for one epoch ---
--- 1.3339042663574219 seconds for one epoch ---
--- 0.33116888999938965 seconds for one epoch ---
--- 1.339458703994751 seconds for one epoch ---
--- 0.32912302017211914 seconds for one epoch ---
--- 1.3271262645721436 seconds for one epoch ---
--- 0.3106803894042969 seconds for one epoch ---
--- 1.356919288635254 seconds for one epoch ---
--- 0.332042932510376 seconds for one epoch ---
--- 1.3541088104248047 seconds for one epoch ---
--- 0.3425886631011963 seconds for one epoch ---
--- 1.3626885414123535 seconds for one epoch ---
--- 0.3222198486328125 seconds for one epoch ---
--- 1.340278148651123 seconds for one epoch ---
--- 0.32205986976623535 seconds for one epoch ---
--- 1.3368020057678223 seconds for one epoch ---
--- 0.32339930534362793 seconds for one epoch ---
=========================
[[1.        ]
 [0.99953747]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9976603 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3148372]
 [-0.741129 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.6598126]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.722525 ]
 [-0.       ]]
--- 0.2666902542114258 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2831.267822265625, (1691.9048, 0.6369407, 1137.7805, 0.9455432)
   validation loss 902.4508056640625, (620.20984, 0.85245496, 280.44296, 0.9455432)
decoder loss ratio: 24028.005889, decoder SINDy loss  ratio: 0.605376
--- 0.3369588851928711 seconds for one epoch ---
--- 1.369542121887207 seconds for one epoch ---
--- 0.32402515411376953 seconds for one epoch ---
--- 1.3980841636657715 seconds for one epoch ---
--- 0.33297228813171387 seconds for one epoch ---
--- 1.362727165222168 seconds for one epoch ---
--- 0.32070231437683105 seconds for one epoch ---
--- 1.3340489864349365 seconds for one epoch ---
--- 0.3171989917755127 seconds for one epoch ---
--- 1.3445086479187012 seconds for one epoch ---
--- 0.3305034637451172 seconds for one epoch ---
--- 1.3452627658843994 seconds for one epoch ---
--- 0.32793402671813965 seconds for one epoch ---
--- 1.3671159744262695 seconds for one epoch ---
--- 0.33295774459838867 seconds for one epoch ---
--- 1.3551671504974365 seconds for one epoch ---
--- 0.34514617919921875 seconds for one epoch ---
--- 1.364368200302124 seconds for one epoch ---
--- 0.3258934020996094 seconds for one epoch ---
--- 1.3709650039672852 seconds for one epoch ---
--- 0.3154265880584717 seconds for one epoch ---
--- 1.3819589614868164 seconds for one epoch ---
--- 0.31165409088134766 seconds for one epoch ---
--- 1.4060866832733154 seconds for one epoch ---
=========================
[[1.        ]
 [0.99932736]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9972824 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3247166 ]
 [-0.7222998 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.65231425]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.713757  ]
 [-0.        ]]
--- 0.3085024356842041 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2855.875244140625, (1585.5588, 0.070866615, 1269.2999, 0.9455153)
   validation loss 862.4031372070312, (579.196, 0.93637466, 281.3253, 0.9455153)
decoder loss ratio: 22439.057944, decoder SINDy loss  ratio: 0.607280
--- 0.2782928943634033 seconds for one epoch ---
--- 0.3278214931488037 seconds for one epoch ---
--- 1.3664467334747314 seconds for one epoch ---
--- 0.3294401168823242 seconds for one epoch ---
--- 1.3672382831573486 seconds for one epoch ---
--- 0.3266482353210449 seconds for one epoch ---
--- 1.3763103485107422 seconds for one epoch ---
--- 0.3250291347503662 seconds for one epoch ---
--- 1.3660099506378174 seconds for one epoch ---
--- 0.3071424961090088 seconds for one epoch ---
--- 1.3518955707550049 seconds for one epoch ---
--- 0.3273780345916748 seconds for one epoch ---
--- 1.3671395778656006 seconds for one epoch ---
--- 0.302487850189209 seconds for one epoch ---
--- 1.3545501232147217 seconds for one epoch ---
--- 0.32328081130981445 seconds for one epoch ---
--- 1.3860666751861572 seconds for one epoch ---
--- 0.33313894271850586 seconds for one epoch ---
--- 1.3679664134979248 seconds for one epoch ---
--- 0.32596373558044434 seconds for one epoch ---
--- 1.3690943717956543 seconds for one epoch ---
--- 0.31635403633117676 seconds for one epoch ---
--- 1.3688747882843018 seconds for one epoch ---
--- 0.3274803161621094 seconds for one epoch ---
=========================
[[1.       ]
 [0.9992349]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9974745]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.3432796]
 [-0.7158722]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6559877]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.7057204]
 [-0.       ]]
--- 0.27440547943115234 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4900.7900390625, (1901.2396, 8.173501, 2990.432, 0.94553155)
   validation loss 1115.41845703125, (829.2855, 0.97090095, 284.21646, 0.94553155)
decoder loss ratio: 32127.960843, decoder SINDy loss  ratio: 0.613521
--- 0.30890607833862305 seconds for one epoch ---
--- 1.3563570976257324 seconds for one epoch ---
--- 0.3391540050506592 seconds for one epoch ---
--- 1.357534646987915 seconds for one epoch ---
--- 0.32143735885620117 seconds for one epoch ---
--- 1.381648063659668 seconds for one epoch ---
--- 0.31598544120788574 seconds for one epoch ---
--- 1.385193109512329 seconds for one epoch ---
--- 0.33208560943603516 seconds for one epoch ---
--- 1.393604040145874 seconds for one epoch ---
--- 0.32166242599487305 seconds for one epoch ---
--- 1.393742322921753 seconds for one epoch ---
--- 0.3029193878173828 seconds for one epoch ---
--- 1.3858683109283447 seconds for one epoch ---
--- 0.30472874641418457 seconds for one epoch ---
--- 1.3607509136199951 seconds for one epoch ---
--- 0.32570409774780273 seconds for one epoch ---
--- 1.3875112533569336 seconds for one epoch ---
--- 0.3211793899536133 seconds for one epoch ---
--- 1.388033151626587 seconds for one epoch ---
--- 0.3180270195007324 seconds for one epoch ---
--- 1.3849139213562012 seconds for one epoch ---
--- 0.31735968589782715 seconds for one epoch ---
--- 1.3728806972503662 seconds for one epoch ---
=========================
[[1.       ]
 [0.9992994]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9967475]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.3549712]
 [-0.7203059]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.643291 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.710425 ]
 [-0.       ]]
--- 0.32068443298339844 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2555.958740234375, (1329.3582, 1.1135919, 1224.5415, 0.945628)
   validation loss 918.4134521484375, (618.183, 1.0794611, 298.20538, 0.945628)
decoder loss ratio: 23949.481990, decoder SINDy loss  ratio: 0.643718
THRESHOLDING: 4 active coefficients
--- 1.3837614059448242 seconds for one epoch ---
--- 0.32961273193359375 seconds for one epoch ---
--- 1.3741919994354248 seconds for one epoch ---
--- 0.3274869918823242 seconds for one epoch ---
--- 1.3692266941070557 seconds for one epoch ---
--- 0.3192102909088135 seconds for one epoch ---
--- 1.3361809253692627 seconds for one epoch ---
--- 0.3268446922302246 seconds for one epoch ---
--- 1.3926701545715332 seconds for one epoch ---
--- 0.3240945339202881 seconds for one epoch ---
--- 1.390293836593628 seconds for one epoch ---
--- 0.3287036418914795 seconds for one epoch ---
--- 1.4263088703155518 seconds for one epoch ---
--- 0.32302117347717285 seconds for one epoch ---
--- 1.409503698348999 seconds for one epoch ---
--- 0.322371244430542 seconds for one epoch ---
--- 1.4067895412445068 seconds for one epoch ---
--- 0.33032941818237305 seconds for one epoch ---
--- 1.4061317443847656 seconds for one epoch ---
--- 0.33391809463500977 seconds for one epoch ---
--- 1.4081039428710938 seconds for one epoch ---
--- 0.3372828960418701 seconds for one epoch ---
--- 1.3608717918395996 seconds for one epoch ---
--- 0.3233771324157715 seconds for one epoch ---
=========================
[[1.        ]
 [0.99891466]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9973233 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.38224   ]
 [-0.6983568 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.65308577]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.7078767 ]
 [-0.        ]]
--- 0.27613186836242676 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3589.952392578125, (1566.5925, 3.1043885, 2019.3097, 0.9457516)
   validation loss 1360.6343994140625, (1070.6263, 0.8840695, 288.1782, 0.9457516)
decoder loss ratio: 41477.923208, decoder SINDy loss  ratio: 0.622073
--- 0.3018031120300293 seconds for one epoch ---
--- 1.3900015354156494 seconds for one epoch ---
--- 0.3181114196777344 seconds for one epoch ---
--- 1.3756110668182373 seconds for one epoch ---
--- 0.32424044609069824 seconds for one epoch ---
--- 1.4013926982879639 seconds for one epoch ---
--- 0.32633209228515625 seconds for one epoch ---
--- 1.3923671245574951 seconds for one epoch ---
--- 0.33145642280578613 seconds for one epoch ---
--- 1.421985149383545 seconds for one epoch ---
--- 0.32631468772888184 seconds for one epoch ---
--- 1.4141440391540527 seconds for one epoch ---
--- 0.33043789863586426 seconds for one epoch ---
--- 1.4112441539764404 seconds for one epoch ---
--- 0.3271324634552002 seconds for one epoch ---
--- 1.3933582305908203 seconds for one epoch ---
--- 0.3335247039794922 seconds for one epoch ---
--- 1.4050934314727783 seconds for one epoch ---
--- 0.3146991729736328 seconds for one epoch ---
--- 1.403350591659546 seconds for one epoch ---
--- 0.3184623718261719 seconds for one epoch ---
--- 1.3969643115997314 seconds for one epoch ---
--- 0.32631397247314453 seconds for one epoch ---
--- 1.403991937637329 seconds for one epoch ---
=========================
[[1.        ]
 [0.99869615]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99667025]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.3868484 ]
 [-0.68917966]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.6421203 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.693274  ]
 [-0.        ]]
--- 0.3143787384033203 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3283.595458984375, (2066.7322, 0.96488476, 1214.9529, 0.9456169)
   validation loss 1294.986572265625, (975.08875, 1.0437726, 317.90857, 0.9456169)
decoder loss ratio: 37776.630814, decoder SINDy loss  ratio: 0.686250
--- 0.2742629051208496 seconds for one epoch ---
--- 0.3231217861175537 seconds for one epoch ---
--- 1.397064208984375 seconds for one epoch ---
--- 0.321058988571167 seconds for one epoch ---
--- 1.399982213973999 seconds for one epoch ---
--- 0.3282129764556885 seconds for one epoch ---
--- 1.4262123107910156 seconds for one epoch ---
--- 0.32691216468811035 seconds for one epoch ---
--- 1.4304866790771484 seconds for one epoch ---
--- 0.31825685501098633 seconds for one epoch ---
--- 1.4190952777862549 seconds for one epoch ---
--- 0.3276987075805664 seconds for one epoch ---
--- 1.3942701816558838 seconds for one epoch ---
--- 0.3329274654388428 seconds for one epoch ---
--- 1.4603519439697266 seconds for one epoch ---
--- 0.32166552543640137 seconds for one epoch ---
--- 1.40944504737854 seconds for one epoch ---
--- 0.3260676860809326 seconds for one epoch ---
--- 1.412687063217163 seconds for one epoch ---
--- 0.33850526809692383 seconds for one epoch ---
--- 1.433300256729126 seconds for one epoch ---
--- 0.34180665016174316 seconds for one epoch ---
--- 1.4183809757232666 seconds for one epoch ---
--- 0.3271348476409912 seconds for one epoch ---
=========================
[[1.        ]
 [0.99845827]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9964692 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4028876]
 [-0.6807709]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.6391748]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.69303  ]
 [-0.       ]]
--- 0.267742395401001 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3272.766845703125, (1420.6246, 1.0544183, 1850.142, 0.94570696)
   validation loss 1665.603271484375, (1366.2476, 1.184822, 297.22525, 0.94570696)
decoder loss ratio: 52930.802330, decoder SINDy loss  ratio: 0.641603
--- 0.31264638900756836 seconds for one epoch ---
--- 1.413926601409912 seconds for one epoch ---
--- 0.32435035705566406 seconds for one epoch ---
--- 1.4335331916809082 seconds for one epoch ---
--- 0.3310964107513428 seconds for one epoch ---
--- 1.4090826511383057 seconds for one epoch ---
--- 0.3330380916595459 seconds for one epoch ---
--- 1.4080567359924316 seconds for one epoch ---
--- 0.3206818103790283 seconds for one epoch ---
--- 1.439375400543213 seconds for one epoch ---
--- 0.31902432441711426 seconds for one epoch ---
--- 1.432830810546875 seconds for one epoch ---
--- 0.322678804397583 seconds for one epoch ---
--- 1.4362115859985352 seconds for one epoch ---
--- 0.3230929374694824 seconds for one epoch ---
--- 1.4147160053253174 seconds for one epoch ---
--- 0.32308053970336914 seconds for one epoch ---
--- 1.4533886909484863 seconds for one epoch ---
--- 0.30358362197875977 seconds for one epoch ---
--- 1.4194188117980957 seconds for one epoch ---
--- 0.32474255561828613 seconds for one epoch ---
--- 1.4114441871643066 seconds for one epoch ---
--- 0.33013010025024414 seconds for one epoch ---
--- 1.427189588546753 seconds for one epoch ---
=========================
[[1.        ]
 [0.99853873]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9963697 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4299319 ]
 [-0.68345714]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.63777786]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.7110286 ]
 [-0.        ]]
--- 0.3146989345550537 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1649.591064453125, (1137.7244, 1.0024853, 509.91833, 0.9459338)
   validation loss 1011.1181640625, (716.3547, 1.0838975, 292.73364, 0.9459338)
decoder loss ratio: 27752.823767, decoder SINDy loss  ratio: 0.631907
--- 0.2769348621368408 seconds for one epoch ---
--- 0.3331623077392578 seconds for one epoch ---
--- 1.4626505374908447 seconds for one epoch ---
--- 0.3213684558868408 seconds for one epoch ---
--- 1.4250743389129639 seconds for one epoch ---
--- 0.32408857345581055 seconds for one epoch ---
--- 1.4629597663879395 seconds for one epoch ---
--- 0.32218456268310547 seconds for one epoch ---
--- 1.4296555519104004 seconds for one epoch ---
--- 0.3327493667602539 seconds for one epoch ---
--- 1.421828269958496 seconds for one epoch ---
--- 0.32457900047302246 seconds for one epoch ---
--- 1.4172391891479492 seconds for one epoch ---
--- 0.340503454208374 seconds for one epoch ---
--- 1.4343223571777344 seconds for one epoch ---
--- 0.3166229724884033 seconds for one epoch ---
--- 1.4335415363311768 seconds for one epoch ---
--- 0.3279001712799072 seconds for one epoch ---
--- 1.4641602039337158 seconds for one epoch ---
--- 0.3106043338775635 seconds for one epoch ---
--- 1.4539029598236084 seconds for one epoch ---
--- 0.3212883472442627 seconds for one epoch ---
--- 1.4476044178009033 seconds for one epoch ---
--- 0.32781505584716797 seconds for one epoch ---
=========================
[[1.       ]
 [0.9985835]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9968302]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4514647 ]
 [-0.68500847]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.6446022 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.70858   ]
 [-0.        ]]
--- 0.27002644538879395 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2734.001220703125, (1171.6604, 0.34171614, 1561.0531, 0.9460549)
   validation loss 2296.587890625, (1960.5956, 1.4656867, 333.58063, 0.9460549)
decoder loss ratio: 75956.876554, decoder SINDy loss  ratio: 0.720081
--- 0.3042480945587158 seconds for one epoch ---
--- 1.4537420272827148 seconds for one epoch ---
--- 0.33077359199523926 seconds for one epoch ---
--- 1.4579839706420898 seconds for one epoch ---
--- 0.3183016777038574 seconds for one epoch ---
--- 1.4641869068145752 seconds for one epoch ---
--- 0.34329652786254883 seconds for one epoch ---
--- 1.4261133670806885 seconds for one epoch ---
--- 0.3406085968017578 seconds for one epoch ---
--- 1.4430325031280518 seconds for one epoch ---
--- 0.30103492736816406 seconds for one epoch ---
--- 1.439225196838379 seconds for one epoch ---
--- 0.32916927337646484 seconds for one epoch ---
--- 1.4389281272888184 seconds for one epoch ---
--- 0.3315713405609131 seconds for one epoch ---
--- 1.4881258010864258 seconds for one epoch ---
--- 0.309467077255249 seconds for one epoch ---
--- 1.4654231071472168 seconds for one epoch ---
--- 0.3255496025085449 seconds for one epoch ---
--- 1.4667623043060303 seconds for one epoch ---
--- 0.3382837772369385 seconds for one epoch ---
--- 1.4681265354156494 seconds for one epoch ---
--- 0.30818915367126465 seconds for one epoch ---
--- 1.4565343856811523 seconds for one epoch ---
=========================
[[1.        ]
 [0.99880576]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9971345 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4737866 ]
 [-0.6936051 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.64965963]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.706897  ]
 [-0.        ]]
--- 0.2961101531982422 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2857.7294921875, (687.808, 1.04458, 2167.9307, 0.9461881)
   validation loss 975.1307373046875, (671.40656, 1.2433975, 301.5346, 0.9461881)
decoder loss ratio: 26011.455561, decoder SINDy loss  ratio: 0.650905
--- 0.27225589752197266 seconds for one epoch ---
--- 0.3276097774505615 seconds for one epoch ---
--- 1.4562172889709473 seconds for one epoch ---
--- 0.32086968421936035 seconds for one epoch ---
--- 1.4462485313415527 seconds for one epoch ---
--- 0.3141341209411621 seconds for one epoch ---
--- 1.4898557662963867 seconds for one epoch ---
--- 0.33337903022766113 seconds for one epoch ---
--- 1.4698281288146973 seconds for one epoch ---
--- 0.3371284008026123 seconds for one epoch ---
--- 1.4543240070343018 seconds for one epoch ---
--- 0.3197214603424072 seconds for one epoch ---
--- 1.4599757194519043 seconds for one epoch ---
--- 0.31702733039855957 seconds for one epoch ---
--- 1.472076177597046 seconds for one epoch ---
--- 0.33008408546447754 seconds for one epoch ---
--- 1.4534239768981934 seconds for one epoch ---
--- 0.33679866790771484 seconds for one epoch ---
--- 1.4831252098083496 seconds for one epoch ---
--- 0.3350682258605957 seconds for one epoch ---
--- 1.4496965408325195 seconds for one epoch ---
--- 0.33393120765686035 seconds for one epoch ---
--- 1.4673793315887451 seconds for one epoch ---
--- 0.33426928520202637 seconds for one epoch ---
=========================
[[1.        ]
 [0.99849504]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99624294]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.476883 ]
 [-0.6819525]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6360383]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.6948156]
 [-0.       ]]
--- 0.27204275131225586 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2688.256591796875, (1135.5803, 4.152235, 1547.5781, 0.9460778)
   validation loss 994.1719360351562, (706.23096, 1.3338695, 285.66104, 0.9460778)
decoder loss ratio: 27360.613346, decoder SINDy loss  ratio: 0.616640
--- 0.3239610195159912 seconds for one epoch ---
--- 1.4575269222259521 seconds for one epoch ---
--- 0.33588147163391113 seconds for one epoch ---
--- 1.5004510879516602 seconds for one epoch ---
--- 0.3216896057128906 seconds for one epoch ---
--- 1.4862160682678223 seconds for one epoch ---
--- 0.3324699401855469 seconds for one epoch ---
--- 1.4514062404632568 seconds for one epoch ---
--- 0.31276822090148926 seconds for one epoch ---
--- 1.4764869213104248 seconds for one epoch ---
--- 0.32951903343200684 seconds for one epoch ---
--- 1.4801442623138428 seconds for one epoch ---
--- 0.3221249580383301 seconds for one epoch ---
--- 1.482886791229248 seconds for one epoch ---
--- 0.32774806022644043 seconds for one epoch ---
--- 1.4682142734527588 seconds for one epoch ---
--- 0.32314014434814453 seconds for one epoch ---
--- 1.450878381729126 seconds for one epoch ---
--- 0.31850600242614746 seconds for one epoch ---
--- 1.4978294372558594 seconds for one epoch ---
--- 0.3262300491333008 seconds for one epoch ---
--- 1.4474539756774902 seconds for one epoch ---
--- 0.31796884536743164 seconds for one epoch ---
--- 1.4717905521392822 seconds for one epoch ---
=========================
[[1.        ]
 [0.9987236 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99615526]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.4933438]
 [-0.690222 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6348796]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6951756]
 [-0.       ]]
--- 0.30563998222351074 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2546.0595703125, (1096.3312, 3.044627, 1445.7375, 0.94617397)
   validation loss 1149.8887939453125, (845.76904, 1.1731085, 302.0005, 0.94617397)
decoder loss ratio: 32766.561044, decoder SINDy loss  ratio: 0.651911
--- 0.26925182342529297 seconds for one epoch ---
--- 0.3202087879180908 seconds for one epoch ---
--- 1.484677791595459 seconds for one epoch ---
--- 0.34096622467041016 seconds for one epoch ---
--- 1.4739630222320557 seconds for one epoch ---
--- 0.3247683048248291 seconds for one epoch ---
--- 1.4857704639434814 seconds for one epoch ---
--- 0.3250715732574463 seconds for one epoch ---
--- 1.4832181930541992 seconds for one epoch ---
--- 0.318922758102417 seconds for one epoch ---
--- 1.499121904373169 seconds for one epoch ---
--- 0.33168697357177734 seconds for one epoch ---
--- 1.4887118339538574 seconds for one epoch ---
--- 0.32806968688964844 seconds for one epoch ---
--- 1.4807147979736328 seconds for one epoch ---
--- 0.3179492950439453 seconds for one epoch ---
--- 1.4779038429260254 seconds for one epoch ---
--- 0.34122276306152344 seconds for one epoch ---
--- 1.4931561946868896 seconds for one epoch ---
--- 0.3228726387023926 seconds for one epoch ---
--- 1.4995646476745605 seconds for one epoch ---
--- 0.3199799060821533 seconds for one epoch ---
--- 1.486262559890747 seconds for one epoch ---
--- 0.3225393295288086 seconds for one epoch ---
=========================
[[1.        ]
 [0.99873984]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99540716]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5013945 ]
 [-0.69088   ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.62594944]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.691974  ]
 [-0.        ]]
--- 0.26853132247924805 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2399.5947265625, (1248.4291, 1.8652033, 1148.3541, 0.94619733)
   validation loss 1201.324462890625, (903.69696, 1.5974807, 295.08386, 0.94619733)
decoder loss ratio: 35010.789135, decoder SINDy loss  ratio: 0.636980
--- 0.31772470474243164 seconds for one epoch ---
--- 1.499657154083252 seconds for one epoch ---
--- 0.3397667407989502 seconds for one epoch ---
--- 1.4817628860473633 seconds for one epoch ---
--- 0.3215036392211914 seconds for one epoch ---
--- 1.4866313934326172 seconds for one epoch ---
--- 0.3408505916595459 seconds for one epoch ---
--- 1.4955222606658936 seconds for one epoch ---
--- 0.3203303813934326 seconds for one epoch ---
--- 1.5087876319885254 seconds for one epoch ---
--- 0.3306276798248291 seconds for one epoch ---
--- 1.4836504459381104 seconds for one epoch ---
--- 0.309053897857666 seconds for one epoch ---
--- 1.4845290184020996 seconds for one epoch ---
--- 0.3253445625305176 seconds for one epoch ---
--- 1.4855074882507324 seconds for one epoch ---
--- 0.3185462951660156 seconds for one epoch ---
--- 1.4691784381866455 seconds for one epoch ---
--- 0.31499505043029785 seconds for one epoch ---
--- 1.500208854675293 seconds for one epoch ---
--- 0.31777334213256836 seconds for one epoch ---
--- 1.4822392463684082 seconds for one epoch ---
--- 0.3291490077972412 seconds for one epoch ---
--- 1.485703468322754 seconds for one epoch ---
=========================
[[1.        ]
 [0.99870956]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9958309 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5181816 ]
 [-0.68969595]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.6308195 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6846237 ]
 [-0.        ]]
--- 0.29949188232421875 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1640.7718505859375, (853.24994, 0.24576086, 786.3299, 0.9462081)
   validation loss 851.1063842773438, (526.3167, 1.5104622, 322.33298, 0.9462081)
decoder loss ratio: 20390.423127, decoder SINDy loss  ratio: 0.695801
--- 0.25933241844177246 seconds for one epoch ---
--- 0.3051035404205322 seconds for one epoch ---
--- 1.4959290027618408 seconds for one epoch ---
--- 0.32453250885009766 seconds for one epoch ---
--- 1.5042777061462402 seconds for one epoch ---
--- 0.3252389430999756 seconds for one epoch ---
--- 1.4989221096038818 seconds for one epoch ---
--- 0.3136427402496338 seconds for one epoch ---
--- 1.494431972503662 seconds for one epoch ---
--- 0.33167314529418945 seconds for one epoch ---
--- 1.5103685855865479 seconds for one epoch ---
--- 0.33353352546691895 seconds for one epoch ---
--- 1.492231845855713 seconds for one epoch ---
--- 0.33075761795043945 seconds for one epoch ---
--- 1.494602918624878 seconds for one epoch ---
--- 0.3257777690887451 seconds for one epoch ---
--- 1.504786729812622 seconds for one epoch ---
--- 0.30431270599365234 seconds for one epoch ---
--- 1.518209457397461 seconds for one epoch ---
--- 0.31598424911499023 seconds for one epoch ---
--- 1.4989447593688965 seconds for one epoch ---
--- 0.326169490814209 seconds for one epoch ---
--- 1.4922349452972412 seconds for one epoch ---
--- 0.3123176097869873 seconds for one epoch ---
=========================
[[1.        ]
 [0.99900925]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99534965]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5350344]
 [-0.7028917]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6253255]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.6915174]
 [-0.       ]]
--- 0.2536189556121826 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3496.3056640625, (1024.1382, 2.7943664, 2468.427, 0.9463579)
   validation loss 847.5281982421875, (553.4837, 1.0924311, 292.00574, 0.9463579)
decoder loss ratio: 21442.919568, decoder SINDy loss  ratio: 0.630335
--- 0.2979698181152344 seconds for one epoch ---
--- 1.521256446838379 seconds for one epoch ---
--- 0.3294408321380615 seconds for one epoch ---
--- 1.5208549499511719 seconds for one epoch ---
--- 0.3194458484649658 seconds for one epoch ---
--- 1.5296828746795654 seconds for one epoch ---
--- 0.32520341873168945 seconds for one epoch ---
--- 1.5076236724853516 seconds for one epoch ---
--- 0.33091211318969727 seconds for one epoch ---
--- 1.5019781589508057 seconds for one epoch ---
--- 0.3021070957183838 seconds for one epoch ---
--- 1.5221257209777832 seconds for one epoch ---
--- 0.3223416805267334 seconds for one epoch ---
--- 1.5075829029083252 seconds for one epoch ---
--- 0.3228898048400879 seconds for one epoch ---
--- 1.5256104469299316 seconds for one epoch ---
--- 0.3324127197265625 seconds for one epoch ---
--- 1.5352072715759277 seconds for one epoch ---
--- 0.31897997856140137 seconds for one epoch ---
--- 1.5213708877563477 seconds for one epoch ---
--- 0.32529568672180176 seconds for one epoch ---
--- 1.5107989311218262 seconds for one epoch ---
--- 0.33139705657958984 seconds for one epoch ---
--- 1.5445749759674072 seconds for one epoch ---
=========================
[[1.        ]
 [0.99918056]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99593186]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.555171 ]
 [-0.7124512]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6320482]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6874585]
 [-0.       ]]
--- 0.31255221366882324 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3924.107666015625, (1471.9387, 3.9114645, 2447.3108, 0.9464491)
   validation loss 838.4329833984375, (547.1858, 1.0883701, 289.21234, 0.9464491)
decoder loss ratio: 21198.927500, decoder SINDy loss  ratio: 0.624306
--- 0.2687082290649414 seconds for one epoch ---
--- 0.3375699520111084 seconds for one epoch ---
--- 1.527001142501831 seconds for one epoch ---
--- 0.33290529251098633 seconds for one epoch ---
--- 1.5559046268463135 seconds for one epoch ---
--- 0.31949639320373535 seconds for one epoch ---
--- 1.5002098083496094 seconds for one epoch ---
--- 0.32245922088623047 seconds for one epoch ---
--- 1.5193417072296143 seconds for one epoch ---
--- 0.31575798988342285 seconds for one epoch ---
--- 1.5134031772613525 seconds for one epoch ---
--- 0.32050466537475586 seconds for one epoch ---
--- 1.523019790649414 seconds for one epoch ---
--- 0.338529109954834 seconds for one epoch ---
--- 1.5288441181182861 seconds for one epoch ---
--- 0.3282597064971924 seconds for one epoch ---
--- 1.527174711227417 seconds for one epoch ---
--- 0.33304500579833984 seconds for one epoch ---
--- 1.5192391872406006 seconds for one epoch ---
--- 0.332258939743042 seconds for one epoch ---
--- 1.536081314086914 seconds for one epoch ---
--- 0.3295156955718994 seconds for one epoch ---
--- 1.5253350734710693 seconds for one epoch ---
--- 0.3034970760345459 seconds for one epoch ---
=========================
[[1.       ]
 [0.9992608]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9958205]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5654936 ]
 [-0.71763253]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.63068634]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.679416  ]
 [-0.        ]]
--- 0.27285337448120117 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4716.47216796875, (1485.7103, 3.466273, 3226.3494, 0.9464574)
   validation loss 860.6146850585938, (593.4347, 0.688682, 265.5449, 0.9464574)
decoder loss ratio: 22990.690231, decoder SINDy loss  ratio: 0.573216
--- 0.31766414642333984 seconds for one epoch ---
--- 1.5439140796661377 seconds for one epoch ---
--- 0.25752902030944824 seconds for one epoch ---
--- 1.520009994506836 seconds for one epoch ---
--- 0.336794376373291 seconds for one epoch ---
--- 1.5266015529632568 seconds for one epoch ---
--- 0.33418822288513184 seconds for one epoch ---
--- 1.541794776916504 seconds for one epoch ---
--- 0.3154001235961914 seconds for one epoch ---
--- 1.5261693000793457 seconds for one epoch ---
--- 0.3295936584472656 seconds for one epoch ---
--- 1.505481243133545 seconds for one epoch ---
--- 0.34982895851135254 seconds for one epoch ---
--- 1.518111228942871 seconds for one epoch ---
--- 0.3274989128112793 seconds for one epoch ---
--- 1.5523226261138916 seconds for one epoch ---
--- 0.33599019050598145 seconds for one epoch ---
--- 1.553288459777832 seconds for one epoch ---
--- 0.3380568027496338 seconds for one epoch ---
--- 1.539513111114502 seconds for one epoch ---
--- 0.32325220108032227 seconds for one epoch ---
--- 1.5770866870880127 seconds for one epoch ---
--- 0.31641435623168945 seconds for one epoch ---
--- 1.5643630027770996 seconds for one epoch ---
=========================
[[1.        ]
 [0.99946904]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.995746  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5746183]
 [-0.7341994]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6298087]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6696196]
 [-0.       ]]
--- 0.3038032054901123 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4179.03466796875, (1545.5244, 1.7954363, 2630.7686, 0.94646883)
   validation loss 923.6870727539062, (661.9529, 0.80539453, 259.98233, 0.94646883)
decoder loss ratio: 25645.203805, decoder SINDy loss  ratio: 0.561208
--- 0.2701733112335205 seconds for one epoch ---
--- 0.32515454292297363 seconds for one epoch ---
--- 1.5411107540130615 seconds for one epoch ---
--- 0.323758602142334 seconds for one epoch ---
--- 1.5406785011291504 seconds for one epoch ---
--- 0.3311939239501953 seconds for one epoch ---
--- 1.5435380935668945 seconds for one epoch ---
--- 0.3274109363555908 seconds for one epoch ---
--- 1.5575659275054932 seconds for one epoch ---
--- 0.3428027629852295 seconds for one epoch ---
--- 1.5453531742095947 seconds for one epoch ---
--- 0.32918858528137207 seconds for one epoch ---
--- 1.5397624969482422 seconds for one epoch ---
--- 0.32082653045654297 seconds for one epoch ---
--- 1.57313871383667 seconds for one epoch ---
--- 0.3199191093444824 seconds for one epoch ---
--- 1.5641114711761475 seconds for one epoch ---
--- 0.3311319351196289 seconds for one epoch ---
--- 1.5697402954101562 seconds for one epoch ---
--- 0.32967209815979004 seconds for one epoch ---
--- 1.5657379627227783 seconds for one epoch ---
--- 0.3149287700653076 seconds for one epoch ---
--- 1.5531349182128906 seconds for one epoch ---
--- 0.2966456413269043 seconds for one epoch ---
=========================
[[1.        ]
 [0.99953777]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9960198 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.59663   ]
 [-0.74120045]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.6331514 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6752586 ]
 [-0.        ]]
--- 0.23109745979309082 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2960.149169921875, (1532.7332, 1.045573, 1425.4241, 0.946619)
   validation loss 786.1065673828125, (512.53674, 0.96954656, 271.6537, 0.946619)
decoder loss ratio: 19856.563233, decoder SINDy loss  ratio: 0.586403
--- 0.3094141483306885 seconds for one epoch ---
--- 1.5725555419921875 seconds for one epoch ---
--- 0.3191206455230713 seconds for one epoch ---
--- 1.5958359241485596 seconds for one epoch ---
--- 0.31478190422058105 seconds for one epoch ---
--- 1.5317838191986084 seconds for one epoch ---
--- 0.33980464935302734 seconds for one epoch ---
--- 1.5491361618041992 seconds for one epoch ---
--- 0.3320431709289551 seconds for one epoch ---
--- 1.58870267868042 seconds for one epoch ---
--- 0.3329024314880371 seconds for one epoch ---
--- 1.5582313537597656 seconds for one epoch ---
--- 0.31240129470825195 seconds for one epoch ---
--- 1.5596964359283447 seconds for one epoch ---
--- 0.3230571746826172 seconds for one epoch ---
--- 1.5666496753692627 seconds for one epoch ---
--- 0.32566118240356445 seconds for one epoch ---
--- 1.579981803894043 seconds for one epoch ---
--- 0.32874155044555664 seconds for one epoch ---
--- 1.555891513824463 seconds for one epoch ---
--- 0.3198220729827881 seconds for one epoch ---
--- 1.5694942474365234 seconds for one epoch ---
--- 0.30438661575317383 seconds for one epoch ---
--- 1.58636474609375 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995396 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99541104]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6039681 ]
 [-0.74140835]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.62598735]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.672803  ]
 [-0.        ]]
--- 0.2942080497741699 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4066.86376953125, (2035.0106, 3.626416, 2027.2802, 0.94659233)
   validation loss 1355.442138671875, (1067.7585, 1.107647, 285.62933, 0.94659233)
decoder loss ratio: 41366.819741, decoder SINDy loss  ratio: 0.616571
--- 0.26923322677612305 seconds for one epoch ---
--- 0.3243849277496338 seconds for one epoch ---
--- 1.5868475437164307 seconds for one epoch ---
--- 0.3346998691558838 seconds for one epoch ---
--- 1.5701518058776855 seconds for one epoch ---
--- 0.34019017219543457 seconds for one epoch ---
--- 1.5702025890350342 seconds for one epoch ---
--- 0.3308145999908447 seconds for one epoch ---
--- 1.5929465293884277 seconds for one epoch ---
--- 0.3294942378997803 seconds for one epoch ---
--- 1.566817045211792 seconds for one epoch ---
--- 0.3138093948364258 seconds for one epoch ---
--- 1.59576416015625 seconds for one epoch ---
--- 0.3237435817718506 seconds for one epoch ---
--- 1.5811800956726074 seconds for one epoch ---
--- 0.32596588134765625 seconds for one epoch ---
--- 1.5704574584960938 seconds for one epoch ---
--- 0.3233451843261719 seconds for one epoch ---
--- 1.5824558734893799 seconds for one epoch ---
--- 0.3211970329284668 seconds for one epoch ---
--- 1.5868797302246094 seconds for one epoch ---
--- 0.3160076141357422 seconds for one epoch ---
--- 1.5985798835754395 seconds for one epoch ---
--- 0.33275485038757324 seconds for one epoch ---
=========================
[[1.        ]
 [0.99951905]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9958508 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6217868 ]
 [-0.73914015]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.63105446]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6716013 ]
 [-0.        ]]
--- 0.2502896785736084 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2369.01123046875, (867.337, 3.2033904, 1497.524, 0.9467017)
   validation loss 844.9154663085938, (574.73926, 1.1254787, 268.10403, 0.9467017)
decoder loss ratio: 22266.396639, decoder SINDy loss  ratio: 0.578740
--- 0.32769107818603516 seconds for one epoch ---
--- 1.571556568145752 seconds for one epoch ---
--- 0.3293285369873047 seconds for one epoch ---
--- 1.5921416282653809 seconds for one epoch ---
--- 0.3286590576171875 seconds for one epoch ---
--- 1.6017177104949951 seconds for one epoch ---
--- 0.6233367919921875 seconds for one epoch ---
--- 1.5541834831237793 seconds for one epoch ---
--- 0.2965986728668213 seconds for one epoch ---
--- 1.5769562721252441 seconds for one epoch ---
--- 0.34218263626098633 seconds for one epoch ---
--- 1.5999417304992676 seconds for one epoch ---
--- 0.3232734203338623 seconds for one epoch ---
--- 1.601839303970337 seconds for one epoch ---
--- 0.320908784866333 seconds for one epoch ---
--- 1.5737802982330322 seconds for one epoch ---
--- 0.3252105712890625 seconds for one epoch ---
--- 1.5760185718536377 seconds for one epoch ---
--- 0.31780123710632324 seconds for one epoch ---
--- 1.5994017124176025 seconds for one epoch ---
--- 0.31992650032043457 seconds for one epoch ---
--- 1.5812442302703857 seconds for one epoch ---
--- 0.32966113090515137 seconds for one epoch ---
--- 1.594581127166748 seconds for one epoch ---
=========================
[[1.        ]
 [0.9992775 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99555856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6322525 ]
 [-0.71872574]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6276235 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.667683  ]
 [-0.        ]]
--- 0.30806660652160645 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2802.284912109375, (1073.9858, 1.5408012, 1725.8115, 0.94669884)
   validation loss 798.1339111328125, (507.53217, 1.0755092, 288.57953, 0.94669884)
decoder loss ratio: 19662.677207, decoder SINDy loss  ratio: 0.622940
--- 0.2513613700866699 seconds for one epoch ---
--- 0.32091665267944336 seconds for one epoch ---
--- 1.6017577648162842 seconds for one epoch ---
--- 0.32512950897216797 seconds for one epoch ---
--- 1.583571434020996 seconds for one epoch ---
--- 0.32434535026550293 seconds for one epoch ---
--- 1.5945584774017334 seconds for one epoch ---
--- 0.328535795211792 seconds for one epoch ---
--- 1.6046538352966309 seconds for one epoch ---
--- 0.3329184055328369 seconds for one epoch ---
--- 1.593337059020996 seconds for one epoch ---
--- 0.3320040702819824 seconds for one epoch ---
--- 1.6330928802490234 seconds for one epoch ---
--- 0.33351850509643555 seconds for one epoch ---
--- 1.586073875427246 seconds for one epoch ---
--- 0.28123021125793457 seconds for one epoch ---
--- 1.5949089527130127 seconds for one epoch ---
--- 0.32437849044799805 seconds for one epoch ---
--- 1.6135039329528809 seconds for one epoch ---
--- 0.3160512447357178 seconds for one epoch ---
--- 1.5782124996185303 seconds for one epoch ---
--- 0.3298358917236328 seconds for one epoch ---
--- 1.5875508785247803 seconds for one epoch ---
--- 0.32850003242492676 seconds for one epoch ---
=========================
[[1.       ]
 [0.9993849]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9951776]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6430633]
 [-0.7268205]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6234947]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.6676083]
 [-0.       ]]
--- 0.2717933654785156 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3811.31591796875, (784.95166, 0.63436687, 3024.7832, 0.9467382)
   validation loss 824.977294921875, (552.8169, 1.1750773, 270.03864, 0.9467382)
decoder loss ratio: 21417.086226, decoder SINDy loss  ratio: 0.582916
--- 0.3033289909362793 seconds for one epoch ---
--- 1.5953853130340576 seconds for one epoch ---
--- 0.3089427947998047 seconds for one epoch ---
--- 1.6027746200561523 seconds for one epoch ---
--- 0.32566380500793457 seconds for one epoch ---
--- 1.591446876525879 seconds for one epoch ---
--- 0.34139347076416016 seconds for one epoch ---
--- 1.6080756187438965 seconds for one epoch ---
--- 0.34175705909729004 seconds for one epoch ---
--- 1.6179308891296387 seconds for one epoch ---
--- 0.34481215476989746 seconds for one epoch ---
--- 1.6283714771270752 seconds for one epoch ---
--- 0.3333146572113037 seconds for one epoch ---
--- 1.6331794261932373 seconds for one epoch ---
--- 0.32809948921203613 seconds for one epoch ---
--- 1.6319406032562256 seconds for one epoch ---
--- 0.319427490234375 seconds for one epoch ---
--- 1.5976929664611816 seconds for one epoch ---
--- 0.3217887878417969 seconds for one epoch ---
--- 1.5919251441955566 seconds for one epoch ---
--- 0.33097100257873535 seconds for one epoch ---
--- 1.6038522720336914 seconds for one epoch ---
--- 0.3160841464996338 seconds for one epoch ---
--- 1.594313621520996 seconds for one epoch ---
=========================
[[1.        ]
 [0.99938786]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9946502 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6483316]
 [-0.7270792]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6182725]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.655163 ]
 [-0.       ]]
--- 0.3123650550842285 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2340.9814453125, (1179.7539, 3.640503, 1156.6404, 0.94670343)
   validation loss 719.9939575195312, (448.44955, 1.3010634, 269.29663, 0.94670343)
decoder loss ratio: 17373.714282, decoder SINDy loss  ratio: 0.581315
THRESHOLDING: 4 active coefficients
--- 0.28603339195251465 seconds for one epoch ---
--- 0.3228580951690674 seconds for one epoch ---
--- 1.6243767738342285 seconds for one epoch ---
--- 0.3291809558868408 seconds for one epoch ---
--- 1.6257960796356201 seconds for one epoch ---
--- 0.3121821880340576 seconds for one epoch ---
--- 1.6184306144714355 seconds for one epoch ---
--- 0.3266115188598633 seconds for one epoch ---
--- 1.6550898551940918 seconds for one epoch ---
--- 0.3454782962799072 seconds for one epoch ---
--- 1.6137263774871826 seconds for one epoch ---
--- 0.328627347946167 seconds for one epoch ---
--- 1.6457507610321045 seconds for one epoch ---
--- 0.3169896602630615 seconds for one epoch ---
--- 1.6072182655334473 seconds for one epoch ---
--- 0.3176734447479248 seconds for one epoch ---
--- 1.60915207862854 seconds for one epoch ---
--- 0.31830739974975586 seconds for one epoch ---
--- 1.6220676898956299 seconds for one epoch ---
--- 0.31464099884033203 seconds for one epoch ---
--- 1.6686933040618896 seconds for one epoch ---
--- 0.34043073654174805 seconds for one epoch ---
--- 1.6138439178466797 seconds for one epoch ---
--- 0.3251686096191406 seconds for one epoch ---
=========================
[[1.        ]
 [0.99957985]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99343085]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6548877 ]
 [-0.74590313]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.60793036]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.656831  ]
 [-0.        ]]
--- 0.2741832733154297 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3487.64599609375, (1513.032, 0.8745147, 1972.7927, 0.9467167)
   validation loss 917.3727416992188, (634.00116, 1.5917461, 280.8331, 0.9467167)
decoder loss ratio: 24562.305600, decoder SINDy loss  ratio: 0.606218
--- 0.30332016944885254 seconds for one epoch ---
--- 1.586993932723999 seconds for one epoch ---
--- 0.33475732803344727 seconds for one epoch ---
--- 1.5887057781219482 seconds for one epoch ---
--- 0.3313179016113281 seconds for one epoch ---
--- 1.6250057220458984 seconds for one epoch ---
--- 0.32581043243408203 seconds for one epoch ---
--- 1.6663222312927246 seconds for one epoch ---
--- 0.3226950168609619 seconds for one epoch ---
--- 1.6019086837768555 seconds for one epoch ---
--- 0.30962061882019043 seconds for one epoch ---
--- 1.612663984298706 seconds for one epoch ---
--- 0.3274688720703125 seconds for one epoch ---
--- 1.6431944370269775 seconds for one epoch ---
--- 0.313138484954834 seconds for one epoch ---
--- 1.6228044033050537 seconds for one epoch ---
--- 0.30898404121398926 seconds for one epoch ---
--- 1.6241552829742432 seconds for one epoch ---
--- 0.32910609245300293 seconds for one epoch ---
--- 1.6410071849822998 seconds for one epoch ---
--- 0.31839919090270996 seconds for one epoch ---
--- 1.6493711471557617 seconds for one epoch ---
--- 0.3365647792816162 seconds for one epoch ---
--- 1.6369149684906006 seconds for one epoch ---
=========================
[[1.        ]
 [0.999489  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99364245]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6643455 ]
 [-0.73607713]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6095766 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.6483006 ]
 [-0.        ]]
--- 0.3063623905181885 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4825.12255859375, (1119.1794, 4.616832, 3700.3796, 0.94667625)
   validation loss 898.696533203125, (625.57605, 1.4933013, 270.68057, 0.94667625)
decoder loss ratio: 24235.902217, decoder SINDy loss  ratio: 0.584302
--- 0.2833092212677002 seconds for one epoch ---
--- 0.3281822204589844 seconds for one epoch ---
--- 1.6346921920776367 seconds for one epoch ---
--- 0.32633256912231445 seconds for one epoch ---
--- 1.62379789352417 seconds for one epoch ---
--- 0.33741092681884766 seconds for one epoch ---
--- 1.6639447212219238 seconds for one epoch ---
--- 0.33013916015625 seconds for one epoch ---
--- 1.650130033493042 seconds for one epoch ---
--- 0.32970690727233887 seconds for one epoch ---
--- 1.6767077445983887 seconds for one epoch ---
--- 0.3288424015045166 seconds for one epoch ---
--- 1.6370823383331299 seconds for one epoch ---
--- 0.31102800369262695 seconds for one epoch ---
--- 1.626255989074707 seconds for one epoch ---
--- 0.33151745796203613 seconds for one epoch ---
--- 1.629504680633545 seconds for one epoch ---
--- 0.3339657783508301 seconds for one epoch ---
--- 1.6595935821533203 seconds for one epoch ---
--- 0.31279635429382324 seconds for one epoch ---
--- 1.6230487823486328 seconds for one epoch ---
--- 0.30988454818725586 seconds for one epoch ---
--- 1.64332914352417 seconds for one epoch ---
--- 0.3369467258453369 seconds for one epoch ---
=========================
[[1.        ]
 [0.9994555 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99389863]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6813211]
 [-0.7329758]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6116529]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.65126  ]
 [-0.       ]]
--- 0.27573275566101074 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1957.6607666015625, (1213.9348, 1.1473141, 741.6317, 0.9468417)
   validation loss 940.6443481445312, (662.2169, 1.7136252, 275.76694, 0.9468417)
decoder loss ratio: 25655.433099, decoder SINDy loss  ratio: 0.595282
--- 0.32134437561035156 seconds for one epoch ---
--- 1.6542747020721436 seconds for one epoch ---
--- 0.3311448097229004 seconds for one epoch ---
--- 1.634948492050171 seconds for one epoch ---
--- 0.3372471332550049 seconds for one epoch ---
--- 1.7003841400146484 seconds for one epoch ---
--- 0.309614896774292 seconds for one epoch ---
--- 1.6734154224395752 seconds for one epoch ---
--- 0.3323030471801758 seconds for one epoch ---
--- 1.6431126594543457 seconds for one epoch ---
--- 0.32435011863708496 seconds for one epoch ---
--- 1.6436567306518555 seconds for one epoch ---
--- 0.31896018981933594 seconds for one epoch ---
--- 1.6602823734283447 seconds for one epoch ---
--- 0.32463979721069336 seconds for one epoch ---
--- 1.6457998752593994 seconds for one epoch ---
--- 0.32975244522094727 seconds for one epoch ---
--- 1.6904258728027344 seconds for one epoch ---
--- 0.3291354179382324 seconds for one epoch ---
--- 1.6584153175354004 seconds for one epoch ---
--- 0.32491493225097656 seconds for one epoch ---
--- 1.6516916751861572 seconds for one epoch ---
--- 0.3314478397369385 seconds for one epoch ---
--- 1.6911301612854004 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995041 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99353063]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.68578   ]
 [-0.73767596]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.60870117]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6395035 ]
 [-0.        ]]
--- 0.2911684513092041 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2015.26953125, (1029.6445, 1.5197432, 983.1585, 0.94678706)
   validation loss 799.910400390625, (537.9293, 1.7328843, 259.30136, 0.94678706)
decoder loss ratio: 20840.315793, decoder SINDy loss  ratio: 0.559738
--- 0.2785193920135498 seconds for one epoch ---
--- 0.3264589309692383 seconds for one epoch ---
--- 1.6418728828430176 seconds for one epoch ---
--- 0.3262977600097656 seconds for one epoch ---
--- 1.652815580368042 seconds for one epoch ---
--- 0.3330247402191162 seconds for one epoch ---
--- 1.6506354808807373 seconds for one epoch ---
--- 0.33202147483825684 seconds for one epoch ---
--- 1.6934735774993896 seconds for one epoch ---
--- 0.32726550102233887 seconds for one epoch ---
--- 1.6879920959472656 seconds for one epoch ---
--- 0.3254821300506592 seconds for one epoch ---
--- 1.6513869762420654 seconds for one epoch ---
--- 0.33168959617614746 seconds for one epoch ---
--- 1.6531977653503418 seconds for one epoch ---
--- 0.3407936096191406 seconds for one epoch ---
--- 1.6610381603240967 seconds for one epoch ---
--- 0.3415539264678955 seconds for one epoch ---
--- 1.6531648635864258 seconds for one epoch ---
--- 0.3210721015930176 seconds for one epoch ---
--- 1.6726737022399902 seconds for one epoch ---
--- 0.3297576904296875 seconds for one epoch ---
--- 1.7047135829925537 seconds for one epoch ---
--- 0.3365142345428467 seconds for one epoch ---
=========================
[[1.       ]
 [0.9996056]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9929518]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.695696  ]
 [-0.7491672 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.60438544]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6398287 ]
 [-0.        ]]
--- 0.279238224029541 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4233.30908203125, (1576.253, 1.0149629, 2655.0942, 0.9468083)
   validation loss 718.7095336914062, (448.1874, 1.6258115, 267.94946, 0.9468083)
decoder loss ratio: 17363.558291, decoder SINDy loss  ratio: 0.578407
--- 0.3045785427093506 seconds for one epoch ---
--- 1.6439549922943115 seconds for one epoch ---
--- 0.3189229965209961 seconds for one epoch ---
--- 1.6661314964294434 seconds for one epoch ---
--- 0.32601070404052734 seconds for one epoch ---
--- 1.6698341369628906 seconds for one epoch ---
--- 0.32294440269470215 seconds for one epoch ---
--- 1.6509456634521484 seconds for one epoch ---
--- 0.3323657512664795 seconds for one epoch ---
--- 1.6992428302764893 seconds for one epoch ---
--- 0.3323957920074463 seconds for one epoch ---
--- 1.674297571182251 seconds for one epoch ---
--- 0.33117127418518066 seconds for one epoch ---
--- 1.671865463256836 seconds for one epoch ---
--- 0.3267946243286133 seconds for one epoch ---
--- 1.6830708980560303 seconds for one epoch ---
--- 0.3345906734466553 seconds for one epoch ---
--- 1.6785693168640137 seconds for one epoch ---
--- 0.3280162811279297 seconds for one epoch ---
--- 1.6723370552062988 seconds for one epoch ---
--- 0.31499195098876953 seconds for one epoch ---
--- 1.6902828216552734 seconds for one epoch ---
--- 0.3348724842071533 seconds for one epoch ---
--- 1.684577465057373 seconds for one epoch ---
=========================
[[1.        ]
 [0.99957716]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99369144]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.71239   ]
 [-0.7455956 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.60997194]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.6359453 ]
 [-0.        ]]
--- 0.3268418312072754 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2200.63916015625, (912.48474, 2.3177385, 1284.89, 0.94689196)
   validation loss 881.5186767578125, (598.475, 1.5813847, 280.51544, 0.94689196)
decoder loss ratio: 23185.959552, decoder SINDy loss  ratio: 0.605532
--- 0.2801053524017334 seconds for one epoch ---
--- 0.32589173316955566 seconds for one epoch ---
--- 1.681283950805664 seconds for one epoch ---
--- 0.3047645092010498 seconds for one epoch ---
--- 1.7077126502990723 seconds for one epoch ---
--- 0.3312807083129883 seconds for one epoch ---
--- 1.6749165058135986 seconds for one epoch ---
--- 0.31713414192199707 seconds for one epoch ---
--- 1.6975407600402832 seconds for one epoch ---
--- 0.34440159797668457 seconds for one epoch ---
--- 1.6619019508361816 seconds for one epoch ---
--- 0.31946444511413574 seconds for one epoch ---
--- 1.6565406322479248 seconds for one epoch ---
--- 0.3144831657409668 seconds for one epoch ---
--- 1.7080450057983398 seconds for one epoch ---
--- 0.3267831802368164 seconds for one epoch ---
--- 1.669238567352295 seconds for one epoch ---
--- 0.326793909072876 seconds for one epoch ---
--- 1.6868317127227783 seconds for one epoch ---
--- 0.31125307083129883 seconds for one epoch ---
--- 1.6858329772949219 seconds for one epoch ---
--- 0.33521461486816406 seconds for one epoch ---
--- 1.6813292503356934 seconds for one epoch ---
--- 0.32033300399780273 seconds for one epoch ---
=========================
[[1.        ]
 [0.99950445]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9936623 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7241025 ]
 [-0.73773164]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.6097392 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6339984 ]
 [-0.        ]]
--- 0.2743980884552002 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2659.09814453125, (1552.2009, 2.0727015, 1103.8774, 0.94693893)
   validation loss 803.2117309570312, (504.3797, 1.4686323, 296.41644, 0.94693893)
decoder loss ratio: 19540.545208, decoder SINDy loss  ratio: 0.639857
--- 0.3153417110443115 seconds for one epoch ---
--- 1.6829516887664795 seconds for one epoch ---
--- 0.33260202407836914 seconds for one epoch ---
--- 1.718205213546753 seconds for one epoch ---
--- 0.33456945419311523 seconds for one epoch ---
--- 1.7148213386535645 seconds for one epoch ---
--- 0.3093085289001465 seconds for one epoch ---
--- 1.696824550628662 seconds for one epoch ---
--- 0.3332638740539551 seconds for one epoch ---
--- 1.6984977722167969 seconds for one epoch ---
--- 0.3247261047363281 seconds for one epoch ---
--- 1.7552142143249512 seconds for one epoch ---
--- 0.3258049488067627 seconds for one epoch ---
--- 1.6823303699493408 seconds for one epoch ---
--- 0.32193851470947266 seconds for one epoch ---
--- 1.7293078899383545 seconds for one epoch ---
--- 0.33276867866516113 seconds for one epoch ---
--- 1.6934573650360107 seconds for one epoch ---
--- 0.33222508430480957 seconds for one epoch ---
--- 1.7300128936767578 seconds for one epoch ---
--- 0.3356602191925049 seconds for one epoch ---
--- 1.692054271697998 seconds for one epoch ---
--- 0.328716516494751 seconds for one epoch ---
--- 1.7160415649414062 seconds for one epoch ---
=========================
[[1.       ]
 [0.9995212]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9926628]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.7284358 ]
 [-0.73940146]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.6023606 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.624249  ]
 [-0.        ]]
--- 0.3063344955444336 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3654.0, (1366.4946, 0.5897104, 2285.969, 0.9468447)
   validation loss 807.2282104492188, (521.21875, 1.5513256, 283.51132, 0.9468447)
decoder loss ratio: 20192.919251, decoder SINDy loss  ratio: 0.611999
--- 0.27532505989074707 seconds for one epoch ---
--- 0.3270070552825928 seconds for one epoch ---
--- 1.7149081230163574 seconds for one epoch ---
--- 0.3222639560699463 seconds for one epoch ---
--- 1.703589677810669 seconds for one epoch ---
--- 0.33653759956359863 seconds for one epoch ---
--- 1.69106125831604 seconds for one epoch ---
--- 0.32071518898010254 seconds for one epoch ---
--- 1.7108476161956787 seconds for one epoch ---
--- 0.3340425491333008 seconds for one epoch ---
--- 1.7226109504699707 seconds for one epoch ---
--- 0.3161170482635498 seconds for one epoch ---
--- 1.7247889041900635 seconds for one epoch ---
--- 0.3299553394317627 seconds for one epoch ---
--- 1.7059972286224365 seconds for one epoch ---
--- 0.3245859146118164 seconds for one epoch ---
--- 1.7377381324768066 seconds for one epoch ---
--- 0.3282167911529541 seconds for one epoch ---
--- 1.7385449409484863 seconds for one epoch ---
--- 0.33441686630249023 seconds for one epoch ---
--- 1.7016139030456543 seconds for one epoch ---
--- 0.35005760192871094 seconds for one epoch ---
--- 1.702726125717163 seconds for one epoch ---
--- 0.3370990753173828 seconds for one epoch ---
=========================
[[1.        ]
 [0.99943507]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9937166 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7436378]
 [-0.7311326]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6101781]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.6211166]
 [-0.       ]]
--- 0.2658967971801758 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3539.666259765625, (1641.6166, 1.7593328, 1895.3435, 0.9469597)
   validation loss 884.6681518554688, (603.0803, 1.6510772, 278.98978, 0.9469597)
decoder loss ratio: 23364.378678, decoder SINDy loss  ratio: 0.602239
--- 0.3153858184814453 seconds for one epoch ---
--- 1.6810336112976074 seconds for one epoch ---
--- 0.325009822845459 seconds for one epoch ---
--- 1.7053391933441162 seconds for one epoch ---
--- 0.3355686664581299 seconds for one epoch ---
--- 1.7390656471252441 seconds for one epoch ---
--- 0.3122260570526123 seconds for one epoch ---
--- 1.7319049835205078 seconds for one epoch ---
--- 0.3186469078063965 seconds for one epoch ---
--- 1.715775489807129 seconds for one epoch ---
--- 0.3376960754394531 seconds for one epoch ---
--- 1.7344048023223877 seconds for one epoch ---
--- 0.32184791564941406 seconds for one epoch ---
--- 1.7436447143554688 seconds for one epoch ---
--- 0.3270576000213623 seconds for one epoch ---
--- 1.7466022968292236 seconds for one epoch ---
--- 0.33793187141418457 seconds for one epoch ---
--- 1.7270712852478027 seconds for one epoch ---
--- 0.3252582550048828 seconds for one epoch ---
--- 1.7160389423370361 seconds for one epoch ---
--- 0.32375669479370117 seconds for one epoch ---
--- 1.7261717319488525 seconds for one epoch ---
--- 0.32520174980163574 seconds for one epoch ---
--- 1.7177693843841553 seconds for one epoch ---
=========================
[[1.        ]
 [0.9994749 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99369323]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7530403 ]
 [-0.7347886 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.60998917]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6147156 ]
 [-0.        ]]
--- 0.32062625885009766 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1929.200439453125, (1024.2255, 0.7083003, 903.31976, 0.94697446)
   validation loss 779.3971557617188, (486.43063, 1.7246871, 290.2949, 0.94697446)
decoder loss ratio: 18845.167224, decoder SINDy loss  ratio: 0.626642
--- 0.27163171768188477 seconds for one epoch ---
--- 0.3179130554199219 seconds for one epoch ---
--- 1.703693151473999 seconds for one epoch ---
--- 0.3263990879058838 seconds for one epoch ---
--- 1.7740118503570557 seconds for one epoch ---
--- 0.32961058616638184 seconds for one epoch ---
--- 1.743645191192627 seconds for one epoch ---
--- 0.32665157318115234 seconds for one epoch ---
--- 1.7180442810058594 seconds for one epoch ---
--- 0.31642961502075195 seconds for one epoch ---
--- 1.7395880222320557 seconds for one epoch ---
--- 0.33225274085998535 seconds for one epoch ---
--- 1.754216194152832 seconds for one epoch ---
--- 0.3310413360595703 seconds for one epoch ---
--- 1.733867883682251 seconds for one epoch ---
--- 0.33054327964782715 seconds for one epoch ---
--- 1.7429418563842773 seconds for one epoch ---
--- 0.3249959945678711 seconds for one epoch ---
--- 1.7720696926116943 seconds for one epoch ---
--- 0.3078470230102539 seconds for one epoch ---
--- 1.7349779605865479 seconds for one epoch ---
--- 0.3326878547668457 seconds for one epoch ---
--- 1.7561171054840088 seconds for one epoch ---
--- 0.34247303009033203 seconds for one epoch ---
=========================
[[1.        ]
 [0.99946904]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99379945]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.763946  ]
 [-0.73416084]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.61084265]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6114798 ]
 [-0.        ]]
--- 0.28658485412597656 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1396.877197265625, (725.38196, 0.6607923, 669.8875, 0.94696563)
   validation loss 1133.53173828125, (818.5096, 1.6302607, 312.44482, 0.94696563)
decoder loss ratio: 31710.482222, decoder SINDy loss  ratio: 0.674456
--- 0.3260188102722168 seconds for one epoch ---
--- 1.7653930187225342 seconds for one epoch ---
--- 0.3174276351928711 seconds for one epoch ---
--- 1.725949764251709 seconds for one epoch ---
--- 0.34498047828674316 seconds for one epoch ---
--- 1.718644618988037 seconds for one epoch ---
--- 0.3257639408111572 seconds for one epoch ---
--- 1.7606589794158936 seconds for one epoch ---
--- 0.3073298931121826 seconds for one epoch ---
--- 1.7363855838775635 seconds for one epoch ---
--- 0.32920050621032715 seconds for one epoch ---
--- 1.7317421436309814 seconds for one epoch ---
--- 0.3357572555541992 seconds for one epoch ---
--- 1.7453124523162842 seconds for one epoch ---
--- 0.3177027702331543 seconds for one epoch ---
--- 1.7471113204956055 seconds for one epoch ---
--- 0.3276646137237549 seconds for one epoch ---
--- 1.7586324214935303 seconds for one epoch ---
--- 0.3292105197906494 seconds for one epoch ---
--- 1.7712807655334473 seconds for one epoch ---
--- 0.33419060707092285 seconds for one epoch ---
--- 1.777543544769287 seconds for one epoch ---
--- 0.3182647228240967 seconds for one epoch ---
--- 1.7737703323364258 seconds for one epoch ---
=========================
[[1.       ]
 [0.9995615]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9938971]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.7765126]
 [-0.7438964]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.611644 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.6117067]
 [-0.       ]]
--- 0.3209555149078369 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2028.060791015625, (760.10645, 1.2135189, 1265.7938, 0.9470795)
   validation loss 819.4933471679688, (526.9591, 1.5293107, 290.0579, 0.9470795)
decoder loss ratio: 20415.310625, decoder SINDy loss  ratio: 0.626131
--- 0.27869129180908203 seconds for one epoch ---
--- 0.3181583881378174 seconds for one epoch ---
--- 1.731917381286621 seconds for one epoch ---
--- 0.3033730983734131 seconds for one epoch ---
--- 1.7326593399047852 seconds for one epoch ---
--- 0.2894463539123535 seconds for one epoch ---
--- 1.7517421245574951 seconds for one epoch ---
--- 0.3298513889312744 seconds for one epoch ---
--- 1.7609169483184814 seconds for one epoch ---
--- 0.3241896629333496 seconds for one epoch ---
--- 1.7316830158233643 seconds for one epoch ---
--- 0.32157230377197266 seconds for one epoch ---
--- 1.7145898342132568 seconds for one epoch ---
--- 0.3190340995788574 seconds for one epoch ---
--- 1.7260465621948242 seconds for one epoch ---
--- 0.33573198318481445 seconds for one epoch ---
--- 1.7748503684997559 seconds for one epoch ---
--- 0.3278024196624756 seconds for one epoch ---
--- 1.7603962421417236 seconds for one epoch ---
--- 0.33033132553100586 seconds for one epoch ---
--- 1.7634985446929932 seconds for one epoch ---
--- 0.32968807220458984 seconds for one epoch ---
--- 1.7645235061645508 seconds for one epoch ---
--- 0.3350505828857422 seconds for one epoch ---
=========================
[[1.        ]
 [0.99958944]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9936514 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7866998 ]
 [-0.74717575]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.60965043]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6080136 ]
 [-0.        ]]
--- 0.2760124206542969 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2158.73828125, (1597.9869, 0.35713002, 559.4471, 0.9471013)
   validation loss 1048.0323486328125, (768.9915, 1.4908756, 276.60275, 0.9471013)
decoder loss ratio: 29792.066362, decoder SINDy loss  ratio: 0.597086
--- 0.3159911632537842 seconds for one epoch ---
--- 1.7564828395843506 seconds for one epoch ---
--- 0.3255422115325928 seconds for one epoch ---
--- 1.7641048431396484 seconds for one epoch ---
--- 0.3276083469390869 seconds for one epoch ---
--- 1.7613129615783691 seconds for one epoch ---
--- 0.3305222988128662 seconds for one epoch ---
--- 1.7828691005706787 seconds for one epoch ---
--- 0.3330082893371582 seconds for one epoch ---
--- 1.7717697620391846 seconds for one epoch ---
--- 0.3205075263977051 seconds for one epoch ---
--- 1.788062572479248 seconds for one epoch ---
--- 0.345745325088501 seconds for one epoch ---
--- 1.7528076171875 seconds for one epoch ---
--- 0.332611083984375 seconds for one epoch ---
--- 1.7575185298919678 seconds for one epoch ---
--- 0.3220648765563965 seconds for one epoch ---
--- 1.7532861232757568 seconds for one epoch ---
--- 0.3221092224121094 seconds for one epoch ---
--- 1.7560467720031738 seconds for one epoch ---
--- 0.3463468551635742 seconds for one epoch ---
--- 1.7829794883728027 seconds for one epoch ---
--- 0.3240058422088623 seconds for one epoch ---
--- 1.800903081893921 seconds for one epoch ---
=========================
[[1.        ]
 [0.99955076]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9939312 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8092356 ]
 [-0.74267584]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.61192036]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6236377 ]
 [-0.        ]]
--- 0.28966832160949707 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2004.459716796875, (963.5954, 1.9148797, 1038.0021, 0.9473629)
   validation loss 1253.7569580078125, (967.88477, 1.6092436, 283.31552, 0.9473629)
decoder loss ratio: 37497.536142, decoder SINDy loss  ratio: 0.611576
--- 0.2824394702911377 seconds for one epoch ---
--- 0.33011627197265625 seconds for one epoch ---
--- 1.7507336139678955 seconds for one epoch ---
--- 0.3161888122558594 seconds for one epoch ---
--- 1.7770376205444336 seconds for one epoch ---
--- 0.3210773468017578 seconds for one epoch ---
--- 1.7749285697937012 seconds for one epoch ---
--- 0.3160896301269531 seconds for one epoch ---
--- 1.7507290840148926 seconds for one epoch ---
--- 0.3362288475036621 seconds for one epoch ---
--- 1.7517518997192383 seconds for one epoch ---
--- 0.3237924575805664 seconds for one epoch ---
--- 1.7941806316375732 seconds for one epoch ---
--- 0.3157217502593994 seconds for one epoch ---
--- 1.792262315750122 seconds for one epoch ---
--- 0.3144237995147705 seconds for one epoch ---
--- 1.756920337677002 seconds for one epoch ---
--- 0.3280181884765625 seconds for one epoch ---
--- 1.7647411823272705 seconds for one epoch ---
--- 0.31797289848327637 seconds for one epoch ---
--- 1.7844927310943604 seconds for one epoch ---
--- 0.3382453918457031 seconds for one epoch ---
--- 1.7640252113342285 seconds for one epoch ---
--- 0.32092857360839844 seconds for one epoch ---
=========================
[[1.        ]
 [0.9994985 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99384165]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8200815]
 [-0.7370102]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6111872]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.623505 ]
 [-0.       ]]
--- 0.2725040912628174 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2146.637451171875, (979.66406, 1.7842633, 1164.2418, 0.94737047)
   validation loss 1028.3111572265625, (741.7815, 1.460572, 284.12167, 0.94737047)
decoder loss ratio: 28737.902872, decoder SINDy loss  ratio: 0.613317
--- 0.3241910934448242 seconds for one epoch ---
--- 1.7720367908477783 seconds for one epoch ---
--- 0.3288757801055908 seconds for one epoch ---
--- 1.784069299697876 seconds for one epoch ---
--- 0.334766149520874 seconds for one epoch ---
--- 1.7940673828125 seconds for one epoch ---
--- 0.3252549171447754 seconds for one epoch ---
--- 1.78572678565979 seconds for one epoch ---
--- 0.3245961666107178 seconds for one epoch ---
--- 1.7882657051086426 seconds for one epoch ---
--- 0.32971906661987305 seconds for one epoch ---
--- 1.772719383239746 seconds for one epoch ---
--- 0.32219433784484863 seconds for one epoch ---
--- 1.7930707931518555 seconds for one epoch ---
--- 0.3192455768585205 seconds for one epoch ---
--- 1.8079445362091064 seconds for one epoch ---
--- 0.3260204792022705 seconds for one epoch ---
--- 1.7883307933807373 seconds for one epoch ---
--- 0.3346855640411377 seconds for one epoch ---
--- 1.7614305019378662 seconds for one epoch ---
--- 0.3021683692932129 seconds for one epoch ---
--- 1.7758700847625732 seconds for one epoch ---
--- 0.3254358768463135 seconds for one epoch ---
--- 1.755934476852417 seconds for one epoch ---
=========================
[[1.        ]
 [0.9994705 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99260366]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8214393 ]
 [-0.7343443 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.60195047]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.6184816 ]
 [-0.        ]]
--- 0.30042290687561035 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3951.096923828125, (2305.9363, 2.2087371, 1642.0046, 0.9473187)
   validation loss 905.0059814453125, (617.874, 1.4459195, 284.7387, 0.9473187)
decoder loss ratio: 23937.512344, decoder SINDy loss  ratio: 0.614649
--- 0.2835543155670166 seconds for one epoch ---
--- 0.31776881217956543 seconds for one epoch ---
--- 1.775122880935669 seconds for one epoch ---
--- 0.32616400718688965 seconds for one epoch ---
--- 1.7794079780578613 seconds for one epoch ---
--- 0.3259117603302002 seconds for one epoch ---
--- 1.8217766284942627 seconds for one epoch ---
--- 0.30469369888305664 seconds for one epoch ---
--- 1.7862770557403564 seconds for one epoch ---
--- 0.31143808364868164 seconds for one epoch ---
--- 1.821662425994873 seconds for one epoch ---
--- 0.32248830795288086 seconds for one epoch ---
--- 1.7740516662597656 seconds for one epoch ---
--- 0.32496094703674316 seconds for one epoch ---
--- 1.790468692779541 seconds for one epoch ---
--- 0.3199000358581543 seconds for one epoch ---
--- 1.784470558166504 seconds for one epoch ---
--- 0.32183218002319336 seconds for one epoch ---
--- 1.7949683666229248 seconds for one epoch ---
--- 0.32999730110168457 seconds for one epoch ---
--- 1.7975034713745117 seconds for one epoch ---
--- 0.32818102836608887 seconds for one epoch ---
--- 1.816274642944336 seconds for one epoch ---
--- 0.3216667175292969 seconds for one epoch ---
=========================
[[1.        ]
 [0.9994998 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99243957]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.829463  ]
 [-0.73721004]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.6008477 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.613202  ]
 [-0.        ]]
--- 0.27457284927368164 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3180.9130859375, (1153.4331, 0.6957866, 2025.8368, 0.9473095)
   validation loss 1034.159423828125, (745.1081, 1.3972896, 286.70673, 0.9473095)
decoder loss ratio: 28866.781097, decoder SINDy loss  ratio: 0.618897
--- 0.31380677223205566 seconds for one epoch ---
--- 1.789069414138794 seconds for one epoch ---
--- 0.3278481960296631 seconds for one epoch ---
--- 1.8020620346069336 seconds for one epoch ---
--- 0.3232388496398926 seconds for one epoch ---
--- 1.8034546375274658 seconds for one epoch ---
--- 0.3224499225616455 seconds for one epoch ---
--- 1.789442539215088 seconds for one epoch ---
--- 0.3360023498535156 seconds for one epoch ---
--- 1.8168299198150635 seconds for one epoch ---
--- 0.32456040382385254 seconds for one epoch ---
--- 1.799259901046753 seconds for one epoch ---
--- 0.33538293838500977 seconds for one epoch ---
--- 1.8292787075042725 seconds for one epoch ---
--- 0.3157308101654053 seconds for one epoch ---
--- 1.7909901142120361 seconds for one epoch ---
--- 0.3309154510498047 seconds for one epoch ---
--- 1.8278477191925049 seconds for one epoch ---
--- 0.32414913177490234 seconds for one epoch ---
--- 1.7937653064727783 seconds for one epoch ---
--- 0.33394956588745117 seconds for one epoch ---
--- 1.8111085891723633 seconds for one epoch ---
--- 0.3224482536315918 seconds for one epoch ---
--- 1.8019990921020508 seconds for one epoch ---
=========================
[[1.       ]
 [0.999609 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9929424]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8361921]
 [-0.749693 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6043105]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.601005 ]
 [-0.       ]]
--- 0.29805898666381836 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3544.37744140625, (1075.6385, 2.6917715, 2465.0999, 0.9473116)
   validation loss 1179.6749267578125, (907.8539, 1.357505, 269.51627, 0.9473116)
decoder loss ratio: 35171.835486, decoder SINDy loss  ratio: 0.581789
--- 0.27068281173706055 seconds for one epoch ---
--- 0.3212850093841553 seconds for one epoch ---
--- 1.807744026184082 seconds for one epoch ---
--- 0.32448363304138184 seconds for one epoch ---
--- 1.7948768138885498 seconds for one epoch ---
--- 0.3210771083831787 seconds for one epoch ---
--- 1.8422303199768066 seconds for one epoch ---
--- 0.32924485206604004 seconds for one epoch ---
--- 1.8288042545318604 seconds for one epoch ---
--- 0.3346550464630127 seconds for one epoch ---
--- 1.8120131492614746 seconds for one epoch ---
--- 0.3206369876861572 seconds for one epoch ---
--- 1.8397841453552246 seconds for one epoch ---
--- 0.33333635330200195 seconds for one epoch ---
--- 1.8371448516845703 seconds for one epoch ---
--- 0.32497739791870117 seconds for one epoch ---
--- 1.8449573516845703 seconds for one epoch ---
--- 0.31772518157958984 seconds for one epoch ---
--- 1.8282511234283447 seconds for one epoch ---
--- 0.3057839870452881 seconds for one epoch ---
--- 1.8340635299682617 seconds for one epoch ---
--- 0.3267080783843994 seconds for one epoch ---
--- 1.8182449340820312 seconds for one epoch ---
--- 0.31815671920776367 seconds for one epoch ---
=========================
[[1.       ]
 [0.9995529]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9928479]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.84417   ]
 [-0.74286705]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6036461 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.5985775 ]
 [-0.        ]]
--- 0.28880906105041504 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3343.2236328125, (1476.7229, 5.1596746, 1860.3937, 0.94733137)
   validation loss 947.0697631835938, (644.74713, 1.5967375, 299.7786, 0.94733137)
decoder loss ratio: 24978.623199, decoder SINDy loss  ratio: 0.647114
--- 0.3110644817352295 seconds for one epoch ---
--- 1.8141741752624512 seconds for one epoch ---
--- 0.3452930450439453 seconds for one epoch ---
--- 1.8085293769836426 seconds for one epoch ---
--- 0.3304119110107422 seconds for one epoch ---
--- 1.8269932270050049 seconds for one epoch ---
--- 0.32411861419677734 seconds for one epoch ---
--- 1.8397791385650635 seconds for one epoch ---
--- 0.31944847106933594 seconds for one epoch ---
--- 1.842625379562378 seconds for one epoch ---
--- 0.324352502822876 seconds for one epoch ---
--- 1.8224554061889648 seconds for one epoch ---
--- 0.3118166923522949 seconds for one epoch ---
--- 1.8480987548828125 seconds for one epoch ---
--- 0.3207564353942871 seconds for one epoch ---
--- 1.8328454494476318 seconds for one epoch ---
--- 0.3385899066925049 seconds for one epoch ---
--- 1.809373140335083 seconds for one epoch ---
--- 0.32793331146240234 seconds for one epoch ---
--- 1.8080394268035889 seconds for one epoch ---
--- 0.324307918548584 seconds for one epoch ---
--- 1.8457999229431152 seconds for one epoch ---
--- 0.32674717903137207 seconds for one epoch ---
--- 1.8234906196594238 seconds for one epoch ---
=========================
[[1.      ]
 [0.999508]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.993518]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-3.8550262]
 [-0.7380734]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.6086033]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5917196]
 [-0.       ]]
--- 0.3011341094970703 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2359.269775390625, (1399.3857, 3.1495867, 955.7873, 0.9473715)
   validation loss 1019.0606079101562, (744.36786, 1.2623848, 272.48297, 0.9473715)
decoder loss ratio: 28838.103133, decoder SINDy loss  ratio: 0.588193
THRESHOLDING: 4 active coefficients
--- 1.80149245262146 seconds for one epoch ---
--- 0.32848668098449707 seconds for one epoch ---
--- 1.8003721237182617 seconds for one epoch ---
--- 0.33281922340393066 seconds for one epoch ---
--- 1.8175170421600342 seconds for one epoch ---
--- 0.345592737197876 seconds for one epoch ---
--- 1.8315894603729248 seconds for one epoch ---
--- 0.3283820152282715 seconds for one epoch ---
--- 1.8385238647460938 seconds for one epoch ---
--- 0.31654858589172363 seconds for one epoch ---
--- 1.8399262428283691 seconds for one epoch ---
--- 0.29265284538269043 seconds for one epoch ---
--- 1.8295886516571045 seconds for one epoch ---
--- 0.34716272354125977 seconds for one epoch ---
--- 1.8366835117340088 seconds for one epoch ---
--- 0.3302006721496582 seconds for one epoch ---
--- 1.8420164585113525 seconds for one epoch ---
--- 0.31214284896850586 seconds for one epoch ---
--- 1.8579432964324951 seconds for one epoch ---
--- 0.32717370986938477 seconds for one epoch ---
--- 1.8646492958068848 seconds for one epoch ---
--- 0.3255338668823242 seconds for one epoch ---
--- 1.865983247756958 seconds for one epoch ---
--- 0.32804107666015625 seconds for one epoch ---
=========================
[[1.       ]
 [0.9995301]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9923909]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.859349  ]
 [-0.7402964 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.60051984]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5908227 ]
 [-0.        ]]
--- 0.2625415325164795 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2468.754638671875, (1067.9918, 0.63356334, 1399.182, 0.9473734)
   validation loss 996.7755126953125, (699.23236, 1.6690265, 294.92673, 0.9473734)
decoder loss ratio: 27089.475580, decoder SINDy loss  ratio: 0.636641
--- 0.307218074798584 seconds for one epoch ---
--- 1.8490545749664307 seconds for one epoch ---
--- 0.3306431770324707 seconds for one epoch ---
--- 1.858884572982788 seconds for one epoch ---
--- 0.33873724937438965 seconds for one epoch ---
--- 1.8624026775360107 seconds for one epoch ---
--- 0.3261685371398926 seconds for one epoch ---
--- 1.8750784397125244 seconds for one epoch ---
--- 0.3341526985168457 seconds for one epoch ---
--- 1.8708922863006592 seconds for one epoch ---
--- 0.31078004837036133 seconds for one epoch ---
--- 1.8556277751922607 seconds for one epoch ---
--- 0.3272559642791748 seconds for one epoch ---
--- 1.8931162357330322 seconds for one epoch ---
--- 0.3232426643371582 seconds for one epoch ---
--- 1.8826706409454346 seconds for one epoch ---
--- 0.32752203941345215 seconds for one epoch ---
--- 1.8920884132385254 seconds for one epoch ---
--- 0.3446376323699951 seconds for one epoch ---
--- 1.8727388381958008 seconds for one epoch ---
--- 0.3278968334197998 seconds for one epoch ---
--- 1.892721176147461 seconds for one epoch ---
--- 0.3259921073913574 seconds for one epoch ---
--- 1.8880040645599365 seconds for one epoch ---
=========================
[[1.        ]
 [0.9996196 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99222124]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8686745 ]
 [-0.75099397]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.59940886]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.5913086 ]
 [-0.        ]]
--- 0.31677937507629395 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2503.712158203125, (1203.6547, 2.2823749, 1296.8278, 0.9474489)
   validation loss 1100.9813232421875, (811.609, 1.8631228, 286.56168, 0.9474489)
decoder loss ratio: 31443.142016, decoder SINDy loss  ratio: 0.618584
--- 0.28619384765625 seconds for one epoch ---
--- 0.33529019355773926 seconds for one epoch ---
--- 1.8438150882720947 seconds for one epoch ---
--- 0.3367013931274414 seconds for one epoch ---
--- 1.8815701007843018 seconds for one epoch ---
--- 0.32582855224609375 seconds for one epoch ---
--- 1.8645131587982178 seconds for one epoch ---
--- 0.3315396308898926 seconds for one epoch ---
--- 1.909381628036499 seconds for one epoch ---
--- 0.33197021484375 seconds for one epoch ---
--- 1.924638032913208 seconds for one epoch ---
--- 0.32399511337280273 seconds for one epoch ---
--- 1.8715152740478516 seconds for one epoch ---
--- 0.3363769054412842 seconds for one epoch ---
--- 1.9148240089416504 seconds for one epoch ---
--- 0.3211219310760498 seconds for one epoch ---
--- 1.9056317806243896 seconds for one epoch ---
--- 0.32709550857543945 seconds for one epoch ---
--- 1.8879117965698242 seconds for one epoch ---
--- 0.32686710357666016 seconds for one epoch ---
--- 1.908473253250122 seconds for one epoch ---
--- 0.3284487724304199 seconds for one epoch ---
--- 1.9049673080444336 seconds for one epoch ---
--- 0.33609914779663086 seconds for one epoch ---
=========================
[[1.       ]
 [0.9996315]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9917326]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.876204 ]
 [-0.7526085]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5963283]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.5908723]
 [-0.       ]]
--- 0.26860499382019043 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4558.36767578125, (1030.3196, 2.545409, 3524.5554, 0.94743675)
   validation loss 823.2110595703125, (547.5261, 2.0032973, 272.7342, 0.94743675)
decoder loss ratio: 21212.112554, decoder SINDy loss  ratio: 0.588735
--- 0.31684446334838867 seconds for one epoch ---
--- 1.9182026386260986 seconds for one epoch ---
--- 0.3316340446472168 seconds for one epoch ---
--- 1.897533893585205 seconds for one epoch ---
--- 0.32509922981262207 seconds for one epoch ---
--- 1.8944132328033447 seconds for one epoch ---
--- 0.33679938316345215 seconds for one epoch ---
--- 1.9064807891845703 seconds for one epoch ---
--- 0.32776641845703125 seconds for one epoch ---
--- 1.8823881149291992 seconds for one epoch ---
--- 0.34011101722717285 seconds for one epoch ---
--- 1.8942415714263916 seconds for one epoch ---
--- 0.33164358139038086 seconds for one epoch ---
--- 1.8900015354156494 seconds for one epoch ---
--- 0.33268046379089355 seconds for one epoch ---
--- 1.929628610610962 seconds for one epoch ---
--- 0.3431360721588135 seconds for one epoch ---
--- 1.9084246158599854 seconds for one epoch ---
--- 0.3438723087310791 seconds for one epoch ---
--- 1.889432668685913 seconds for one epoch ---
--- 0.32855677604675293 seconds for one epoch ---
--- 1.8897454738616943 seconds for one epoch ---
--- 0.3324880599975586 seconds for one epoch ---
--- 1.9411346912384033 seconds for one epoch ---
=========================
[[1.        ]
 [0.99969697]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9921207 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8888001 ]
 [-0.7623801 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.59876037]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.592175  ]
 [-0.        ]]
--- 0.324474573135376 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2004.44384765625, (1205.6199, 0.9533908, 796.92303, 0.9475428)
   validation loss 984.3603515625, (687.3997, 2.0373526, 293.9757, 0.9475428)
decoder loss ratio: 26631.058502, decoder SINDy loss  ratio: 0.634588
--- 0.2794005870819092 seconds for one epoch ---
--- 0.34595322608947754 seconds for one epoch ---
--- 1.9184982776641846 seconds for one epoch ---
--- 0.33713340759277344 seconds for one epoch ---
--- 1.9062423706054688 seconds for one epoch ---
--- 0.33328938484191895 seconds for one epoch ---
--- 1.9458026885986328 seconds for one epoch ---
--- 0.3306763172149658 seconds for one epoch ---
--- 1.8860864639282227 seconds for one epoch ---
--- 0.3374061584472656 seconds for one epoch ---
--- 1.890291690826416 seconds for one epoch ---
--- 0.3408076763153076 seconds for one epoch ---
--- 1.9121863842010498 seconds for one epoch ---
--- 0.3329617977142334 seconds for one epoch ---
--- 1.8999252319335938 seconds for one epoch ---
--- 0.325333833694458 seconds for one epoch ---
--- 1.906505823135376 seconds for one epoch ---
--- 0.3319857120513916 seconds for one epoch ---
--- 1.9568431377410889 seconds for one epoch ---
--- 0.3371860980987549 seconds for one epoch ---
--- 1.916191577911377 seconds for one epoch ---
--- 0.32251763343811035 seconds for one epoch ---
--- 1.8956222534179688 seconds for one epoch ---
--- 0.3352377414703369 seconds for one epoch ---
=========================
[[1.        ]
 [0.99959505]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9910835 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8907785]
 [-0.7478505]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5925149]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.585814 ]
 [-0.       ]]
--- 0.27210497856140137 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1609.860107421875, (792.5669, 1.8239986, 814.52167, 0.94746655)
   validation loss 874.3949584960938, (571.0743, 1.9452585, 300.428, 0.94746655)
decoder loss ratio: 22124.409027, decoder SINDy loss  ratio: 0.648516
--- 0.3146946430206299 seconds for one epoch ---
--- 1.9280333518981934 seconds for one epoch ---
--- 0.34267377853393555 seconds for one epoch ---
--- 1.926720380783081 seconds for one epoch ---
--- 0.3326914310455322 seconds for one epoch ---
--- 1.9115796089172363 seconds for one epoch ---
--- 0.3356201648712158 seconds for one epoch ---
--- 1.9064559936523438 seconds for one epoch ---
--- 0.3289206027984619 seconds for one epoch ---
--- 1.9035518169403076 seconds for one epoch ---
--- 0.3148941993713379 seconds for one epoch ---
--- 1.9126477241516113 seconds for one epoch ---
--- 0.32174038887023926 seconds for one epoch ---
--- 1.9469120502471924 seconds for one epoch ---
--- 0.32878923416137695 seconds for one epoch ---
--- 1.9477059841156006 seconds for one epoch ---
--- 0.3388192653656006 seconds for one epoch ---
--- 1.9112961292266846 seconds for one epoch ---
--- 0.33298802375793457 seconds for one epoch ---
--- 1.9618303775787354 seconds for one epoch ---
--- 0.33364200592041016 seconds for one epoch ---
--- 1.917259931564331 seconds for one epoch ---
--- 0.3159611225128174 seconds for one epoch ---
--- 1.9120986461639404 seconds for one epoch ---
=========================
[[1.        ]
 [0.99946487]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99034953]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8974006]
 [-0.7337916]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5885183]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.5840898]
 [-0.       ]]
--- 0.3048286437988281 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2003.0347900390625, (836.2539, 0.4940735, 1165.3395, 0.94742805)
   validation loss 771.3279418945312, (485.51477, 1.8375967, 283.02817, 0.94742805)
decoder loss ratio: 18809.685100, decoder SINDy loss  ratio: 0.610956
--- 0.2745232582092285 seconds for one epoch ---
--- 0.3298487663269043 seconds for one epoch ---
--- 1.8878707885742188 seconds for one epoch ---
--- 0.30983400344848633 seconds for one epoch ---
--- 1.9072589874267578 seconds for one epoch ---
--- 0.3357052803039551 seconds for one epoch ---
--- 1.898517370223999 seconds for one epoch ---
--- 0.326662540435791 seconds for one epoch ---
--- 1.9529492855072021 seconds for one epoch ---
--- 0.3253955841064453 seconds for one epoch ---
--- 1.9065508842468262 seconds for one epoch ---
--- 0.33075928688049316 seconds for one epoch ---
--- 1.9354910850524902 seconds for one epoch ---
--- 0.31428027153015137 seconds for one epoch ---
--- 1.967350721359253 seconds for one epoch ---
--- 0.324476957321167 seconds for one epoch ---
--- 1.9030635356903076 seconds for one epoch ---
--- 0.31676149368286133 seconds for one epoch ---
--- 1.9456684589385986 seconds for one epoch ---
--- 0.30544495582580566 seconds for one epoch ---
--- 1.9449443817138672 seconds for one epoch ---
--- 0.3213040828704834 seconds for one epoch ---
--- 1.9299986362457275 seconds for one epoch ---
--- 0.32888150215148926 seconds for one epoch ---
=========================
[[1.        ]
 [0.99927306]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9919378 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9129477 ]
 [-0.71844804]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5976043 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.5836506 ]
 [-0.        ]]
--- 0.25945305824279785 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2647.137939453125, (1398.4274, 6.900123, 1240.8628, 0.9475257)
   validation loss 774.589111328125, (507.33823, 1.8129568, 264.49042, 0.9475257)
decoder loss ratio: 19655.163665, decoder SINDy loss  ratio: 0.570940
--- 0.29809093475341797 seconds for one epoch ---
--- 1.9500150680541992 seconds for one epoch ---
--- 0.3158082962036133 seconds for one epoch ---
--- 1.9519612789154053 seconds for one epoch ---
--- 0.32451605796813965 seconds for one epoch ---
--- 1.9515173435211182 seconds for one epoch ---
--- 0.3277707099914551 seconds for one epoch ---
--- 1.9270639419555664 seconds for one epoch ---
--- 0.32498979568481445 seconds for one epoch ---
--- 1.9248979091644287 seconds for one epoch ---
--- 0.32511091232299805 seconds for one epoch ---
--- 1.9876790046691895 seconds for one epoch ---
--- 0.3186800479888916 seconds for one epoch ---
--- 1.9331107139587402 seconds for one epoch ---
--- 0.3179352283477783 seconds for one epoch ---
--- 1.9350221157073975 seconds for one epoch ---
--- 0.3352811336517334 seconds for one epoch ---
--- 1.9560282230377197 seconds for one epoch ---
--- 0.31769657135009766 seconds for one epoch ---
--- 1.9511027336120605 seconds for one epoch ---
--- 0.3252537250518799 seconds for one epoch ---
--- 1.9408814907073975 seconds for one epoch ---
--- 0.3252732753753662 seconds for one epoch ---
--- 1.9651305675506592 seconds for one epoch ---
=========================
[[1.        ]
 [0.99926984]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99090296]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9151492 ]
 [-0.71823335]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5915038 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.577949  ]
 [-0.        ]]
--- 0.29752659797668457 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3499.89697265625, (1450.1125, 2.3030655, 2046.5338, 0.94752645)
   validation loss 1025.4747314453125, (715.07166, 1.9016621, 307.55386, 0.94752645)
decoder loss ratio: 27703.117344, decoder SINDy loss  ratio: 0.663898
--- 0.2684500217437744 seconds for one epoch ---
--- 0.3173692226409912 seconds for one epoch ---
--- 1.9734883308410645 seconds for one epoch ---
--- 0.3231346607208252 seconds for one epoch ---
--- 1.9608445167541504 seconds for one epoch ---
--- 0.3307831287384033 seconds for one epoch ---
--- 1.9436514377593994 seconds for one epoch ---
--- 0.32863473892211914 seconds for one epoch ---
--- 1.9382691383361816 seconds for one epoch ---
--- 0.3273048400878906 seconds for one epoch ---
--- 1.9667980670928955 seconds for one epoch ---
--- 0.3209960460662842 seconds for one epoch ---
--- 1.9695007801055908 seconds for one epoch ---
--- 0.31496596336364746 seconds for one epoch ---
--- 1.9704110622406006 seconds for one epoch ---
--- 0.323300838470459 seconds for one epoch ---
--- 1.9466543197631836 seconds for one epoch ---
--- 0.33693432807922363 seconds for one epoch ---
--- 1.9855077266693115 seconds for one epoch ---
--- 0.31619906425476074 seconds for one epoch ---
--- 1.967951774597168 seconds for one epoch ---
--- 0.33968114852905273 seconds for one epoch ---
--- 1.9588613510131836 seconds for one epoch ---
--- 0.3304581642150879 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995148 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99079764]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9232504 ]
 [-0.73872375]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.5909229 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.57724   ]
 [-0.        ]]
--- 0.27829456329345703 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2988.29052734375, (1044.5485, 1.5346376, 1941.2599, 0.9475304)
   validation loss 893.956787109375, (606.876, 1.8393087, 284.294, 0.9475304)
decoder loss ratio: 23511.428915, decoder SINDy loss  ratio: 0.613689
--- 0.3210337162017822 seconds for one epoch ---
--- 1.9514939785003662 seconds for one epoch ---
--- 0.32939934730529785 seconds for one epoch ---
--- 1.9520797729492188 seconds for one epoch ---
--- 0.32512569427490234 seconds for one epoch ---
--- 1.9773290157318115 seconds for one epoch ---
--- 0.3217284679412842 seconds for one epoch ---
--- 1.9565472602844238 seconds for one epoch ---
--- 0.3112218379974365 seconds for one epoch ---
--- 1.9695255756378174 seconds for one epoch ---
--- 0.31091952323913574 seconds for one epoch ---
--- 2.0201451778411865 seconds for one epoch ---
--- 0.3129243850708008 seconds for one epoch ---
--- 1.9917006492614746 seconds for one epoch ---
--- 0.3329153060913086 seconds for one epoch ---
--- 1.978214979171753 seconds for one epoch ---
--- 0.32812976837158203 seconds for one epoch ---
--- 2.004096508026123 seconds for one epoch ---
--- 0.32149791717529297 seconds for one epoch ---
--- 2.004957914352417 seconds for one epoch ---
--- 0.3256211280822754 seconds for one epoch ---
--- 1.9611506462097168 seconds for one epoch ---
--- 0.33187389373779297 seconds for one epoch ---
--- 1.9646072387695312 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995891 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99130595]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.935638  ]
 [-0.74700636]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.59379655]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.579587  ]
 [-0.        ]]
--- 0.30841493606567383 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3589.46435546875, (1527.4393, 2.2057765, 2058.8716, 0.94766647)
   validation loss 1291.8026123046875, (985.1154, 1.9291103, 303.81046, 0.94766647)
decoder loss ratio: 38165.081509, decoder SINDy loss  ratio: 0.655818
--- 0.27791285514831543 seconds for one epoch ---
--- 0.32529163360595703 seconds for one epoch ---
--- 1.9800467491149902 seconds for one epoch ---
--- 0.32820701599121094 seconds for one epoch ---
--- 1.964658260345459 seconds for one epoch ---
--- 0.31990623474121094 seconds for one epoch ---
--- 1.952301025390625 seconds for one epoch ---
--- 0.31992530822753906 seconds for one epoch ---
--- 1.9783165454864502 seconds for one epoch ---
--- 0.333604097366333 seconds for one epoch ---
--- 1.9809315204620361 seconds for one epoch ---
--- 0.3319246768951416 seconds for one epoch ---
--- 2.0164432525634766 seconds for one epoch ---
--- 0.3374135494232178 seconds for one epoch ---
--- 1.9632091522216797 seconds for one epoch ---
--- 0.3228588104248047 seconds for one epoch ---
--- 1.9912300109863281 seconds for one epoch ---
--- 0.31528472900390625 seconds for one epoch ---
--- 2.0035669803619385 seconds for one epoch ---
--- 0.3223416805267334 seconds for one epoch ---
--- 2.0038414001464844 seconds for one epoch ---
--- 0.32497715950012207 seconds for one epoch ---
--- 1.98166823387146 seconds for one epoch ---
--- 0.3187582492828369 seconds for one epoch ---
=========================
[[1.        ]
 [0.9996462 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99181813]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9424818 ]
 [-0.7547611 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.59685785]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.57141   ]
 [-0.        ]]
--- 0.2661769390106201 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2075.150146484375, (1120.7723, 1.1605749, 952.2695, 0.9477081)
   validation loss 981.8717651367188, (649.76587, 1.7446749, 329.41348, 0.9477081)
decoder loss ratio: 25173.057814, decoder SINDy loss  ratio: 0.711085
--- 0.31026148796081543 seconds for one epoch ---
--- 1.9838318824768066 seconds for one epoch ---
--- 0.34813666343688965 seconds for one epoch ---
--- 1.975698471069336 seconds for one epoch ---
--- 0.32639122009277344 seconds for one epoch ---
--- 2.009396553039551 seconds for one epoch ---
--- 0.3245670795440674 seconds for one epoch ---
--- 2.0403177738189697 seconds for one epoch ---
--- 0.3377041816711426 seconds for one epoch ---
--- 1.96626615524292 seconds for one epoch ---
--- 0.3267958164215088 seconds for one epoch ---
--- 2.017948865890503 seconds for one epoch ---
--- 0.655289888381958 seconds for one epoch ---
--- 2.019287109375 seconds for one epoch ---
--- 0.3210563659667969 seconds for one epoch ---
--- 2.005420446395874 seconds for one epoch ---
--- 0.31794309616088867 seconds for one epoch ---
--- 1.9836070537567139 seconds for one epoch ---
--- 0.3299992084503174 seconds for one epoch ---
--- 2.0533199310302734 seconds for one epoch ---
--- 0.34111690521240234 seconds for one epoch ---
--- 2.0404741764068604 seconds for one epoch ---
--- 0.3247506618499756 seconds for one epoch ---
--- 2.0406761169433594 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995954 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99144226]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9529772 ]
 [-0.74792016]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.59459645]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.5773516 ]
 [-0.        ]]
--- 0.28502583503723145 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5534.19189453125, (1832.1547, 4.513621, 3696.5757, 0.94775003)
   validation loss 839.8829345703125, (550.59814, 2.0529213, 286.28412, 0.94775003)
decoder loss ratio: 21331.128000, decoder SINDy loss  ratio: 0.617985
--- 0.2718660831451416 seconds for one epoch ---
--- 0.32251429557800293 seconds for one epoch ---
--- 1.9803054332733154 seconds for one epoch ---
--- 0.32455015182495117 seconds for one epoch ---
--- 2.0174479484558105 seconds for one epoch ---
--- 0.32682061195373535 seconds for one epoch ---
--- 1.9833767414093018 seconds for one epoch ---
--- 0.31688427925109863 seconds for one epoch ---
--- 2.047116279602051 seconds for one epoch ---
--- 0.32614850997924805 seconds for one epoch ---
--- 1.982957363128662 seconds for one epoch ---
--- 0.3326292037963867 seconds for one epoch ---
--- 2.0276639461517334 seconds for one epoch ---
--- 0.311431884765625 seconds for one epoch ---
--- 2.0036802291870117 seconds for one epoch ---
--- 0.3245525360107422 seconds for one epoch ---
--- 1.9946279525756836 seconds for one epoch ---
--- 0.32198262214660645 seconds for one epoch ---
--- 2.0248029232025146 seconds for one epoch ---
--- 0.3210010528564453 seconds for one epoch ---
--- 1.9964900016784668 seconds for one epoch ---
--- 0.33314013481140137 seconds for one epoch ---
--- 2.046276569366455 seconds for one epoch ---
--- 0.33007097244262695 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995144 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99190795]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9642065 ]
 [-0.7387701 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.59742326]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.5787582 ]
 [-0.        ]]
--- 0.26667189598083496 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5664.90966796875, (1996.2229, 0.8120278, 3666.9268, 0.9478583)
   validation loss 759.2417602539062, (463.25238, 1.9469929, 293.0945, 0.9478583)
decoder loss ratio: 17947.201457, decoder SINDy loss  ratio: 0.632686
--- 0.3221139907836914 seconds for one epoch ---
--- 1.9955501556396484 seconds for one epoch ---
--- 0.318073034286499 seconds for one epoch ---
--- 2.0039806365966797 seconds for one epoch ---
--- 0.32337450981140137 seconds for one epoch ---
--- 2.0306689739227295 seconds for one epoch ---
--- 0.3249204158782959 seconds for one epoch ---
--- 2.0054750442504883 seconds for one epoch ---
--- 0.3335423469543457 seconds for one epoch ---
--- 2.0132923126220703 seconds for one epoch ---
--- 0.3254246711730957 seconds for one epoch ---
--- 2.022324562072754 seconds for one epoch ---
--- 0.3205735683441162 seconds for one epoch ---
--- 2.0550537109375 seconds for one epoch ---
--- 0.33188533782958984 seconds for one epoch ---
--- 2.0387661457061768 seconds for one epoch ---
--- 0.34758687019348145 seconds for one epoch ---
--- 2.008843421936035 seconds for one epoch ---
--- 0.31455349922180176 seconds for one epoch ---
--- 2.0300958156585693 seconds for one epoch ---
--- 0.3220396041870117 seconds for one epoch ---
--- 2.032862424850464 seconds for one epoch ---
--- 0.3210008144378662 seconds for one epoch ---
--- 2.015031576156616 seconds for one epoch ---
=========================
[[1.        ]
 [0.9993968 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99037254]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9669418]
 [-0.7278812]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5886439]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5822635]
 [-0.       ]]
--- 0.30567359924316406 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2045.249755859375, (1110.346, 1.0441322, 932.9119, 0.94780207)
   validation loss 900.6531372070312, (593.7025, 1.8152645, 304.1876, 0.94780207)
decoder loss ratio: 23001.066130, decoder SINDy loss  ratio: 0.656632
--- 0.27291297912597656 seconds for one epoch ---
--- 0.29813051223754883 seconds for one epoch ---
--- 2.054025411605835 seconds for one epoch ---
--- 0.3389894962310791 seconds for one epoch ---
--- 2.023341417312622 seconds for one epoch ---
--- 0.3224000930786133 seconds for one epoch ---
--- 2.0361740589141846 seconds for one epoch ---
--- 0.3276057243347168 seconds for one epoch ---
--- 2.046917200088501 seconds for one epoch ---
--- 0.32247447967529297 seconds for one epoch ---
--- 2.009711742401123 seconds for one epoch ---
--- 0.3138892650604248 seconds for one epoch ---
--- 2.01033616065979 seconds for one epoch ---
--- 0.3331277370452881 seconds for one epoch ---
--- 2.014735221862793 seconds for one epoch ---
--- 0.31452250480651855 seconds for one epoch ---
--- 2.059265613555908 seconds for one epoch ---
--- 0.34414196014404297 seconds for one epoch ---
--- 2.0493414402008057 seconds for one epoch ---
--- 0.3104252815246582 seconds for one epoch ---
--- 2.0156679153442383 seconds for one epoch ---
--- 0.32939624786376953 seconds for one epoch ---
--- 2.020493984222412 seconds for one epoch ---
--- 0.3083512783050537 seconds for one epoch ---
=========================
[[1.       ]
 [0.9996066]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9891783]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.966602  ]
 [-0.7492873 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.58272773]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.576188  ]
 [-0.        ]]
--- 0.28682947158813477 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2942.38818359375, (1411.1613, 4.580636, 1525.6986, 0.9477553)
   validation loss 863.7227783203125, (536.3088, 2.1885679, 324.27774, 0.9477553)
decoder loss ratio: 20777.533088, decoder SINDy loss  ratio: 0.699999
--- 0.28877854347229004 seconds for one epoch ---
--- 2.0314619541168213 seconds for one epoch ---
--- 0.3335597515106201 seconds for one epoch ---
--- 2.056464195251465 seconds for one epoch ---
--- 0.33295369148254395 seconds for one epoch ---
--- 1.992612600326538 seconds for one epoch ---
--- 0.3209545612335205 seconds for one epoch ---
--- 2.0349271297454834 seconds for one epoch ---
--- 0.30545473098754883 seconds for one epoch ---
--- 2.0326316356658936 seconds for one epoch ---
--- 0.3256394863128662 seconds for one epoch ---
--- 2.043391227722168 seconds for one epoch ---
--- 0.3149905204772949 seconds for one epoch ---
--- 2.0120396614074707 seconds for one epoch ---
--- 0.32029008865356445 seconds for one epoch ---
--- 2.0518226623535156 seconds for one epoch ---
--- 0.3347740173339844 seconds for one epoch ---
--- 2.0464611053466797 seconds for one epoch ---
--- 0.3275001049041748 seconds for one epoch ---
--- 2.039902448654175 seconds for one epoch ---
--- 0.3260078430175781 seconds for one epoch ---
--- 2.0575778484344482 seconds for one epoch ---
--- 0.3195304870605469 seconds for one epoch ---
--- 2.0744516849517822 seconds for one epoch ---
=========================
[[1.        ]
 [0.99942833]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9903984 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9808915]
 [-0.7305597]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5887767]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5784917]
 [-0.       ]]
--- 0.3099861145019531 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2661.72021484375, (1091.6163, 2.1924694, 1566.9637, 0.94784564)
   validation loss 785.286376953125, (505.89288, 1.8693826, 276.57626, 0.94784564)
decoder loss ratio: 19599.168568, decoder SINDy loss  ratio: 0.597029
--- 0.9796805381774902 seconds for one epoch ---
--- 0.3209521770477295 seconds for one epoch ---
--- 2.0708374977111816 seconds for one epoch ---
--- 0.3298482894897461 seconds for one epoch ---
--- 2.047292470932007 seconds for one epoch ---
--- 0.3361475467681885 seconds for one epoch ---
--- 2.060014247894287 seconds for one epoch ---
--- 0.325319766998291 seconds for one epoch ---
--- 2.0403733253479004 seconds for one epoch ---
--- 0.3582429885864258 seconds for one epoch ---
--- 2.063464641571045 seconds for one epoch ---
--- 0.33118748664855957 seconds for one epoch ---
--- 2.0563902854919434 seconds for one epoch ---
--- 0.34004950523376465 seconds for one epoch ---
--- 2.0451467037200928 seconds for one epoch ---
--- 0.3293800354003906 seconds for one epoch ---
--- 2.0745372772216797 seconds for one epoch ---
--- 0.3310558795928955 seconds for one epoch ---
--- 2.04775333404541 seconds for one epoch ---
--- 0.3289625644683838 seconds for one epoch ---
--- 2.03073787689209 seconds for one epoch ---
--- 0.3274996280670166 seconds for one epoch ---
--- 2.1089961528778076 seconds for one epoch ---
--- 0.3341653347015381 seconds for one epoch ---
=========================
[[1.       ]
 [0.9994967]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9910194]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9868917]
 [-0.7369567]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5921556]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.570665 ]
 [-0.       ]]
--- 0.28785061836242676 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2531.835693359375, (952.5051, 2.0597146, 1576.3229, 0.94788754)
   validation loss 1003.317138671875, (695.3135, 1.5064254, 305.54938, 0.94788754)
decoder loss ratio: 26937.651199, decoder SINDy loss  ratio: 0.659571
--- 0.31406545639038086 seconds for one epoch ---
--- 2.071601152420044 seconds for one epoch ---
--- 0.33449602127075195 seconds for one epoch ---
--- 2.0427145957946777 seconds for one epoch ---
--- 0.32980847358703613 seconds for one epoch ---
--- 2.084268093109131 seconds for one epoch ---
--- 0.3254826068878174 seconds for one epoch ---
--- 2.0473196506500244 seconds for one epoch ---
--- 0.33037710189819336 seconds for one epoch ---
--- 2.0901498794555664 seconds for one epoch ---
--- 0.33353495597839355 seconds for one epoch ---
--- 2.0463171005249023 seconds for one epoch ---
--- 0.34108996391296387 seconds for one epoch ---
--- 2.041210889816284 seconds for one epoch ---
--- 0.3315136432647705 seconds for one epoch ---
--- 2.0841028690338135 seconds for one epoch ---
--- 0.32739830017089844 seconds for one epoch ---
--- 2.0683438777923584 seconds for one epoch ---
--- 0.3348526954650879 seconds for one epoch ---
--- 2.1050631999969482 seconds for one epoch ---
--- 0.3273017406463623 seconds for one epoch ---
--- 2.0611722469329834 seconds for one epoch ---
--- 0.30890488624572754 seconds for one epoch ---
--- 2.1224143505096436 seconds for one epoch ---
=========================
[[1.       ]
 [0.9996357]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9914293]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9975584]
 [-0.7531471]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5945156]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.5724454]
 [-0.       ]]
--- 0.3180828094482422 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3472.463134765625, (1309.7393, 0.7523523, 2161.0237, 0.94795173)
   validation loss 1162.7156982421875, (875.2442, 2.0177145, 284.50583, 0.94795173)
decoder loss ratio: 33908.479863, decoder SINDy loss  ratio: 0.614146
--- 0.27788329124450684 seconds for one epoch ---
--- 0.33046889305114746 seconds for one epoch ---
--- 2.1108224391937256 seconds for one epoch ---
--- 0.3290555477142334 seconds for one epoch ---
--- 2.0684313774108887 seconds for one epoch ---
--- 0.31914544105529785 seconds for one epoch ---
--- 2.079493761062622 seconds for one epoch ---
--- 0.32657361030578613 seconds for one epoch ---
--- 2.108694076538086 seconds for one epoch ---
--- 0.32473087310791016 seconds for one epoch ---
--- 2.1016125679016113 seconds for one epoch ---
--- 0.3335294723510742 seconds for one epoch ---
--- 2.0873806476593018 seconds for one epoch ---
--- 0.3293116092681885 seconds for one epoch ---
--- 2.0914571285247803 seconds for one epoch ---
--- 0.32192063331604004 seconds for one epoch ---
--- 2.0612568855285645 seconds for one epoch ---
--- 0.32085466384887695 seconds for one epoch ---
--- 2.09828519821167 seconds for one epoch ---
--- 0.33045125007629395 seconds for one epoch ---
--- 2.0655715465545654 seconds for one epoch ---
--- 0.3124418258666992 seconds for one epoch ---
--- 2.0779387950897217 seconds for one epoch ---
--- 0.33623337745666504 seconds for one epoch ---
=========================
[[1.        ]
 [0.9995892 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99074817]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.000917  ]
 [-0.74702716]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5906535 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.567784  ]
 [-0.        ]]
--- 0.25311779975891113 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1798.717041015625, (1158.6024, 0.8961679, 638.27057, 0.9479731)
   validation loss 888.1761474609375, (594.2011, 1.5794079, 291.44763, 0.9479731)
decoder loss ratio: 23020.382612, decoder SINDy loss  ratio: 0.629131
--- 0.3118476867675781 seconds for one epoch ---
--- 2.130315065383911 seconds for one epoch ---
--- 0.32982897758483887 seconds for one epoch ---
--- 2.0507540702819824 seconds for one epoch ---
--- 0.33147644996643066 seconds for one epoch ---
--- 2.05692458152771 seconds for one epoch ---
--- 0.32753825187683105 seconds for one epoch ---
--- 2.0597422122955322 seconds for one epoch ---
--- 0.32242393493652344 seconds for one epoch ---
--- 2.11869740486145 seconds for one epoch ---
--- 0.31736111640930176 seconds for one epoch ---
--- 2.0734806060791016 seconds for one epoch ---
--- 0.328873872756958 seconds for one epoch ---
--- 2.1239659786224365 seconds for one epoch ---
--- 0.33236265182495117 seconds for one epoch ---
--- 2.0970160961151123 seconds for one epoch ---
--- 0.336742639541626 seconds for one epoch ---
--- 2.0981318950653076 seconds for one epoch ---
--- 0.33116984367370605 seconds for one epoch ---
--- 2.10109543800354 seconds for one epoch ---
--- 0.33265042304992676 seconds for one epoch ---
--- 2.076951265335083 seconds for one epoch ---
--- 0.32863640785217285 seconds for one epoch ---
--- 2.1368095874786377 seconds for one epoch ---
=========================
[[1.       ]
 [0.9994919]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9903229]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.0089226]
 [-0.736444 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5883831]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.5694118]
 [-0.       ]]
--- 0.31049203872680664 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2930.208984375, (1252.989, 1.3017579, 1674.9702, 0.947978)
   validation loss 830.097412109375, (538.0654, 1.5729336, 289.51108, 0.947978)
decoder loss ratio: 20845.588869, decoder SINDy loss  ratio: 0.624950
THRESHOLDING: 4 active coefficients
REFINEMENT
=========================
[[1.       ]
 [0.9994693]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9902259]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.009499  ]
 [-0.73437077]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5878808 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.570411  ]
 [-0.        ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1135.6334228515625, (576.3932, 1.1640966, 558.0761, 0.94796056)
   validation loss 700.1361083984375, (438.4687, 1.0200164, 260.6474, 0.94796056)
decoder loss ratio: 16987.038226, decoder SINDy loss  ratio: 0.562644
=========================
[[1.       ]
 [0.9998692]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.989516 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.935505  ]
 [-0.80645597]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.58559155]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.459731  ]
 [-0.        ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1506.522705078125, (951.5864, 0.3757073, 554.56055, 0.94755214)
   validation loss 1025.9566650390625, (771.56744, 0.18309924, 254.2061, 0.94755214)
decoder loss ratio: 29891.862275, decoder SINDy loss  ratio: 0.548740
=========================
[[1.       ]
 [0.9993142]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823761]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9382644]
 [-0.7333744]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5227363]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.3585687]
 [-0.       ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.4117431640625, (347.66238, 0.29885623, 487.45053, 0.9457222)
   validation loss 499.9266662597656, (273.395, 0.14623767, 226.38544, 0.9457222)
decoder loss ratio: 10591.796509, decoder SINDy loss  ratio: 0.488685
=========================
[[1.        ]
 [0.99722123]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97516865]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8719895 ]
 [-0.67554796]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.539824  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.1115303 ]
 [-0.        ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1031.5570068359375, (546.20703, 0.23780957, 485.11215, 0.9436869)
   validation loss 740.3236083984375, (504.64035, 0.098862536, 235.58435, 0.9436869)
decoder loss ratio: 19550.643266, decoder SINDy loss  ratio: 0.508542
=========================
[[1.        ]
 [0.99404395]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97375524]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.830169  ]
 [-0.597922  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.49743092]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.9739673 ]
 [ 0.        ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.537353515625, (280.56473, 0.26133868, 480.71124, 0.94215167)
   validation loss 441.110107421875, (212.97542, 0.099253096, 228.03545, 0.94215167)
decoder loss ratio: 8251.037438, decoder SINDy loss  ratio: 0.492247
=========================
[[1.        ]
 [0.989808  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97522163]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7530804 ]
 [-0.5924192 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.53489363]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.8099043 ]
 [-0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.5443115234375, (290.09628, 0.26537445, 467.18265, 0.94093305)
   validation loss 468.4434814453125, (241.52373, 0.09199005, 226.82776, 0.94093305)
decoder loss ratio: 9357.048504, decoder SINDy loss  ratio: 0.489640
=========================
[[1.        ]
 [0.98706174]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9803331 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7105865 ]
 [-0.5315288 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.52653944]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6961644 ]
 [ 0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.9937744140625, (291.9191, 0.31155863, 462.7631, 0.94014275)
   validation loss 464.83892822265625, (240.30519, 0.09414595, 224.43958, 0.94014275)
decoder loss ratio: 9309.840289, decoder SINDy loss  ratio: 0.484484
=========================
[[1.       ]
 [0.9887446]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9759046]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.670843  ]
 [-0.49758655]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5257136 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.6842487 ]
 [ 0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.272705078125, (268.72787, 0.2843473, 470.26053, 0.9390456)
   validation loss 432.2213134765625, (203.10483, 0.09790118, 229.0186, 0.9390456)
decoder loss ratio: 7868.633638, decoder SINDy loss  ratio: 0.494369
=========================
[[1.        ]
 [0.98774004]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9772277 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6774652 ]
 [-0.57214886]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5699613 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.4219968 ]
 [ 0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.3245849609375, (278.73077, 0.29150748, 460.30234, 0.9383214)
   validation loss 454.17230224609375, (226.42766, 0.10027648, 227.64436, 0.9383214)
decoder loss ratio: 8772.200570, decoder SINDy loss  ratio: 0.491402
=========================
[[1.        ]
 [0.98729664]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9834316 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6022944]
 [-0.5918138]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5836437]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.314984 ]
 [ 0.       ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.8721923828125, (255.00322, 0.33332062, 464.53568, 0.9379584)
   validation loss 431.3956298828125, (204.081, 0.103790976, 227.21085, 0.9379584)
decoder loss ratio: 7906.451994, decoder SINDy loss  ratio: 0.490467
=========================
[[1.        ]
 [0.99060965]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97910947]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.629084  ]
 [-0.54093266]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.4538273 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2332766 ]
 [ 0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.5648193359375, (279.361, 0.3101965, 468.89362, 0.93731594)
   validation loss 437.0865783691406, (205.47188, 0.11271262, 231.50198, 0.93731594)
decoder loss ratio: 7960.337271, decoder SINDy loss  ratio: 0.499730
=========================
[[1.       ]
 [0.9893521]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9813226]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6187778 ]
 [-0.63217044]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.5996856 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.0693827 ]
 [-0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.0087280273438, (262.9487, 0.3104904, 458.74954, 0.9368807)
   validation loss 433.6769104003906, (204.71445, 0.11371516, 228.84875, 0.9368807)
decoder loss ratio: 7930.993078, decoder SINDy loss  ratio: 0.494002
=========================
[[1.        ]
 [0.99019533]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98556167]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5663683 ]
 [-0.5901733 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.56830406]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.029668  ]
 [-0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.4671630859375, (269.5729, 0.36122987, 457.53305, 0.93673795)
   validation loss 444.5953369140625, (218.75632, 0.11990654, 225.71913, 0.93673795)
decoder loss ratio: 8474.999504, decoder SINDy loss  ratio: 0.487246
=========================
[[1.        ]
 [0.9921677 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98107326]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.573589  ]
 [-0.62472856]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.48314992]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9546955 ]
 [ 0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.1993408203125, (258.29562, 0.31676722, 457.5869, 0.936176)
   validation loss 429.6383056640625, (198.70047, 0.12935443, 230.80849, 0.936176)
decoder loss ratio: 7698.001166, decoder SINDy loss  ratio: 0.498233
=========================
[[1.        ]
 [0.99191386]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9823968 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6099033 ]
 [-0.6099273 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.64309156]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8289592 ]
 [-0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.9755249023438, (294.05194, 0.3231244, 451.60046, 0.93588305)
   validation loss 471.33123779296875, (242.11229, 0.13173257, 229.0872, 0.93588305)
decoder loss ratio: 9379.850418, decoder SINDy loss  ratio: 0.494517
=========================
[[1.        ]
 [0.99246716]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98496026]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5547953 ]
 [-0.59781575]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5726763 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7719517 ]
 [ 0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.2698364257812, (340.48663, 0.38006783, 452.40314, 0.9358469)
   validation loss 501.177490234375, (273.55435, 0.15127759, 227.47185, 0.9358469)
decoder loss ratio: 10597.970500, decoder SINDy loss  ratio: 0.491030
=========================
[[1.        ]
 [0.99284977]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98251367]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5546298]
 [-0.5833124]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5517324]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.7609868]
 [-0.       ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.972900390625, (390.85538, 0.31427488, 448.80322, 0.9353921)
   validation loss 570.5970458984375, (338.99466, 0.14366162, 231.45874, 0.9353921)
decoder loss ratio: 13133.241627, decoder SINDy loss  ratio: 0.499636
=========================
[[1.        ]
 [0.99180925]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9834784 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.562905  ]
 [-0.6661822 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.53908813]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7132657 ]
 [ 0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.4752807617188, (282.7027, 0.3073637, 450.4652, 0.93521327)
   validation loss 465.7359619140625, (233.69185, 0.14558007, 231.89851, 0.93521327)
decoder loss ratio: 9053.627928, decoder SINDy loss  ratio: 0.500586
=========================
[[1.      ]
 [0.992834]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.983912]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-3.5798666 ]
 [-0.61213356]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.50807405]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.665722  ]
 [ 0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 904.5234375, (452.9188, 0.30771112, 451.29697, 0.93510437)
   validation loss 634.7435302734375, (400.5057, 0.15372244, 234.08414, 0.93510437)
decoder loss ratio: 15516.286389, decoder SINDy loss  ratio: 0.505304
=========================
[[1.        ]
 [0.9934177 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98430365]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5583324]
 [-0.6054866]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6499462]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.6069014]
 [-0.       ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1014.549560546875, (524.38257, 0.34240806, 489.8246, 0.9349729)
   validation loss 663.6058349609375, (417.19885, 0.14587465, 246.26114, 0.9349729)
decoder loss ratio: 16163.007836, decoder SINDy loss  ratio: 0.531589
=========================
[[1.        ]
 [0.99456954]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98284674]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.674393  ]
 [-0.64458644]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5620425 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5598166 ]
 [-0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.6395263671875, (267.02902, 0.33339396, 451.27707, 0.93483096)
   validation loss 435.3805847167969, (201.47888, 0.16471799, 233.73698, 0.93483096)
decoder loss ratio: 7805.641665, decoder SINDy loss  ratio: 0.504554
=========================
[[1.        ]
 [0.99437773]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98253536]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5711422]
 [-0.6233371]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.4938721]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.5261605]
 [ 0.       ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.1920166015625, (255.25906, 0.34251094, 448.59045, 0.9346861)
   validation loss 433.40692138671875, (200.69626, 0.16776615, 232.54291, 0.9346861)
decoder loss ratio: 7775.321480, decoder SINDy loss  ratio: 0.501977
=========================
[[1.        ]
 [0.99427253]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98434305]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6180367 ]
 [-0.62608826]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.5722375 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.510314  ]
 [ 0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.870361328125, (246.1997, 0.3707191, 450.29993, 0.93467695)
   validation loss 426.3900146484375, (193.60371, 0.17569947, 232.61061, 0.93467695)
decoder loss ratio: 7500.543991, decoder SINDy loss  ratio: 0.502123
=========================
[[1.       ]
 [0.9943638]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829524]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5809991 ]
 [-0.55998856]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5506676 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.4965162 ]
 [ 0.        ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 823.3517456054688, (376.5324, 0.3320717, 446.48727, 0.93460554)
   validation loss 561.2050170898438, (327.68295, 0.17916085, 233.34291, 0.93460554)
decoder loss ratio: 12695.006477, decoder SINDy loss  ratio: 0.503703
=========================
[[1.       ]
 [0.9935776]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9831128]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6737115 ]
 [-0.5877035 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.50965875]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.4691782 ]
 [ 0.        ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1756.816650390625, (1208.6489, 0.3898599, 547.77783, 0.9344821)
   validation loss 1321.005615234375, (1043.0527, 0.1650935, 277.78778, 0.9344821)
decoder loss ratio: 40409.673749, decoder SINDy loss  ratio: 0.599644
=========================
[[1.        ]
 [0.99423957]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9817265 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6842182]
 [-0.6059028]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6118305]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.3938096]
 [-0.       ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.9600219726562, (264.76205, 0.34837747, 449.84958, 0.93441194)
   validation loss 428.677001953125, (193.99484, 0.1804818, 234.50166, 0.93441194)
decoder loss ratio: 7515.696989, decoder SINDy loss  ratio: 0.506205
=========================
[[1.        ]
 [0.99379474]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98125964]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6501665]
 [-0.5357468]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6084287]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3884308]
 [ 0.       ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.9310913085938, (332.9699, 0.34621832, 443.61496, 0.9343443)
   validation loss 514.6851196289062, (282.21628, 0.18778911, 232.28105, 0.9343443)
decoder loss ratio: 10933.548562, decoder SINDy loss  ratio: 0.501411
=========================
[[1.        ]
 [0.9936644 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98269004]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6607528]
 [-0.6448324]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5559428]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.4380472]
 [ 0.       ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.0877685546875, (243.89052, 0.37418813, 445.8231, 0.9343831)
   validation loss 423.8838195800781, (191.33662, 0.19066481, 232.35654, 0.9343831)
decoder loss ratio: 7412.712994, decoder SINDy loss  ratio: 0.501574
=========================
[[1.        ]
 [0.99353665]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98205614]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7279336 ]
 [-0.665172  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.54563797]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.34698   ]
 [ 0.        ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1168.1571044921875, (717.4006, 0.33899194, 450.41754, 0.93442595)
   validation loss 899.6680297851562, (660.2851, 0.19710791, 239.18587, 0.93442595)
decoder loss ratio: 25580.590894, decoder SINDy loss  ratio: 0.516316
=========================
[[1.        ]
 [0.99271226]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98157156]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.797319 ]
 [-0.6447915]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5105177]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.3331776]
 [ 0.       ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.3598022460938, (310.86462, 0.33599722, 443.15918, 0.93435174)
   validation loss 493.32159423828125, (259.37717, 0.19171217, 233.75273, 0.93435174)
decoder loss ratio: 10048.721738, decoder SINDy loss  ratio: 0.504588
=========================
[[1.       ]
 [0.9934696]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9842435]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6775784 ]
 [-0.7292298 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.53331614]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.2644813 ]
 [-0.        ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.5244140625, (250.09859, 0.3875475, 444.03827, 0.9345142)
   validation loss 431.4361572265625, (198.0857, 0.19983606, 233.15063, 0.9345142)
decoder loss ratio: 7674.183653, decoder SINDy loss  ratio: 0.503288
=========================
[[1.       ]
 [0.9935241]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9800247]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.7717528 ]
 [-0.54094744]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.45666552]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.257199  ]
 [-0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1017.868408203125, (534.7621, 0.43018565, 482.67612, 0.93437904)
   validation loss 703.198974609375, (447.4638, 0.22203226, 255.5131, 0.93437904)
decoder loss ratio: 17335.524682, decoder SINDy loss  ratio: 0.551561
=========================
[[1.        ]
 [0.99295235]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9790794 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7255733]
 [-0.5723431]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.551433 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.240654 ]
 [ 0.       ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.461181640625, (252.76471, 0.38255954, 449.3139, 0.934322)
   validation loss 437.89984130859375, (199.88486, 0.21053842, 237.80444, 0.934322)
decoder loss ratio: 7743.886382, decoder SINDy loss  ratio: 0.513334
=========================
[[1.       ]
 [0.9930208]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9818372]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8113852 ]
 [-0.6084412 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.51027614]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.243348  ]
 [-0.        ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.0509643554688, (251.37025, 0.40399832, 447.27673, 0.93440163)
   validation loss 432.4937438964844, (197.93741, 0.20012712, 234.3562, 0.93440163)
decoder loss ratio: 7668.438838, decoder SINDy loss  ratio: 0.505891
=========================
[[1.       ]
 [0.9932962]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9759688]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.747427  ]
 [-0.56090665]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.6627956 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2115345 ]
 [ 0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.8389892578125, (268.78476, 0.3932632, 451.66095, 0.9341635)
   validation loss 463.85699462890625, (223.21846, 0.21943623, 240.4191, 0.9341635)
decoder loss ratio: 8647.870668, decoder SINDy loss  ratio: 0.518978
=========================
[[1.        ]
 [0.99299693]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9757501 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.781529  ]
 [-0.62313795]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.46699396]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.1848767 ]
 [-0.        ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1084.4312744140625, (602.898, 0.42642817, 481.10684, 0.93419904)
   validation loss 791.523681640625, (532.9356, 0.21697876, 258.3711, 0.93419904)
decoder loss ratio: 20646.850667, decoder SINDy loss  ratio: 0.557730
=========================
[[1.        ]
 [0.99244225]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9761484 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8546472 ]
 [-0.60407925]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.45552707]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.182412  ]
 [ 0.        ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1230.455810546875, (774.95135, 0.33380115, 455.17065, 0.9341674)
   validation loss 944.4086303710938, (701.9444, 0.21046488, 242.25377, 0.9341674)
decoder loss ratio: 27194.544568, decoder SINDy loss  ratio: 0.522939
=========================
[[1.        ]
 [0.9927052 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97330105]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7758796]
 [-0.6109221]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5874626]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.1007192]
 [ 0.       ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.7095947265625, (240.48314, 0.39749393, 447.82895, 0.93409294)
   validation loss 427.9644775390625, (189.99371, 0.21305187, 237.7577, 0.93409294)
decoder loss ratio: 7360.686300, decoder SINDy loss  ratio: 0.513233
=========================
[[1.       ]
 [0.9918709]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9765212]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8843215 ]
 [-0.6495504 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.60683864]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.088341  ]
 [-0.        ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 938.7014770507812, (461.73145, 0.47136742, 476.49866, 0.93439764)
   validation loss 605.2752685546875, (355.66202, 0.22643605, 249.38683, 0.93439764)
decoder loss ratio: 13778.964027, decoder SINDy loss  ratio: 0.538337
=========================
[[1.        ]
 [0.99264485]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9712274 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8428116]
 [-0.5485881]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.4934726]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.0211647]
 [-0.       ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.86669921875, (255.98235, 0.3758523, 441.50854, 0.93402284)
   validation loss 427.86773681640625, (194.59367, 0.19639541, 233.07767, 0.93402284)
decoder loss ratio: 7538.896749, decoder SINDy loss  ratio: 0.503131
=========================
[[1.       ]
 [0.9923827]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9707496]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8976505 ]
 [-0.65968454]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5244164 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.0989172 ]
 [-0.        ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.3189086914062, (245.19504, 0.3818238, 443.74203, 0.93406963)
   validation loss 435.6382141113281, (198.79747, 0.21654586, 236.62419, 0.93406963)
decoder loss ratio: 7701.759119, decoder SINDy loss  ratio: 0.510787
=========================
[[1.       ]
 [0.9921732]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.969929 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.928563  ]
 [-0.5708732 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.58914065]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.070085  ]
 [ 0.        ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.4820556640625, (247.46576, 0.39151427, 440.62482, 0.9340208)
   validation loss 429.02899169921875, (195.51471, 0.21307763, 233.30121, 0.9340208)
decoder loss ratio: 7574.579273, decoder SINDy loss  ratio: 0.503613
=========================
[[1.        ]
 [0.99176645]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9721687 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8855586 ]
 [-0.58893245]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.613814  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.0732899 ]
 [ 0.        ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.3699951171875, (236.92215, 0.41567552, 442.0322, 0.9341883)
   validation loss 420.8281555175781, (187.72722, 0.21357043, 232.88736, 0.9341883)
decoder loss ratio: 7272.878358, decoder SINDy loss  ratio: 0.502720
=========================
[[1.        ]
 [0.99207115]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9677418 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9864352 ]
 [-0.61242115]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.5529474 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.983679  ]
 [ 0.        ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.8642578125, (278.57477, 0.4072578, 452.8822, 0.93402)
   validation loss 455.1402587890625, (214.38924, 0.20523159, 240.54579, 0.93402)
decoder loss ratio: 8305.811216, decoder SINDy loss  ratio: 0.519252
=========================
[[1.        ]
 [0.99181116]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9667509 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8997195]
 [-0.5832134]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5050861]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.9910965]
 [ 0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.3314819335938, (239.03203, 0.3998127, 445.89966, 0.9340194)
   validation loss 427.28765869140625, (189.8448, 0.20985307, 237.23299, 0.9340194)
decoder loss ratio: 7354.917248, decoder SINDy loss  ratio: 0.512101
=========================
[[1.        ]
 [0.99097395]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9691622 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9667575 ]
 [-0.6202444 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.46955693]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.007504  ]
 [-0.        ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.29931640625, (326.66153, 0.37250656, 437.26526, 0.9341666)
   validation loss 494.05242919921875, (262.71246, 0.18965927, 231.15028, 0.9341666)
decoder loss ratio: 10177.936920, decoder SINDy loss  ratio: 0.498970
=========================
[[1.        ]
 [0.9914454 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96635437]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9834092 ]
 [-0.53572196]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.5962185 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.9999602 ]
 [ 0.        ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1034.5931396484375, (582.24963, 0.3634815, 451.98007, 0.93412954)
   validation loss 755.0882568359375, (514.4502, 0.22812521, 240.4099, 0.93412954)
decoder loss ratio: 19930.693691, decoder SINDy loss  ratio: 0.518959
=========================
[[1.        ]
 [0.9914901 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96510494]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9704914]
 [-0.6030582]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5094387]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.9803267]
 [ 0.       ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 946.3741455078125, (475.90042, 0.40662947, 470.06714, 0.9340129)
   validation loss 630.7906494140625, (383.79822, 0.18231808, 246.81013, 0.9340129)
decoder loss ratio: 14869.009260, decoder SINDy loss  ratio: 0.532774
=========================
[[1.        ]
 [0.9905963 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96695644]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0090466 ]
 [-0.60602736]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4689997 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.9952657 ]
 [-0.        ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1048.618408203125, (600.4661, 0.3664679, 447.78583, 0.93419296)
   validation loss 767.720703125, (531.16876, 0.20971039, 236.3422, 0.93419296)
decoder loss ratio: 20578.399997, decoder SINDy loss  ratio: 0.510178
=========================
[[1.        ]
 [0.99093324]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96594024]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0673056 ]
 [-0.5843192 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.40887845]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.0442107 ]
 [ 0.        ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.013916015625, (344.42166, 0.3836471, 440.2086, 0.93416995)
   validation loss 520.8682250976562, (287.5982, 0.21053916, 233.05946, 0.93416995)
decoder loss ratio: 11142.053776, decoder SINDy loss  ratio: 0.503092
=========================
[[1.        ]
 [0.99085075]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9609369 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.149332 ]
 [-0.6659714]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5537014]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.9370893]
 [-0.       ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.5558471679688, (262.12195, 0.37914166, 441.05475, 0.9339656)
   validation loss 449.55950927734375, (214.25551, 0.21105097, 235.09297, 0.9339656)
decoder loss ratio: 8300.630360, decoder SINDy loss  ratio: 0.507481
=========================
[[1.       ]
 [0.9905972]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9594478]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.1060743]
 [-0.5248381]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6566103]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.8617213]
 [ 0.       ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.9627685546875, (413.39993, 0.44202256, 464.12085, 0.93396056)
   validation loss 602.9445190429688, (352.2205, 0.2220864, 250.50195, 0.93396056)
decoder loss ratio: 13645.633245, decoder SINDy loss  ratio: 0.540744
=========================
[[1.        ]
 [0.98926866]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9602449 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0362964 ]
 [-0.58242387]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.52558273]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.892631  ]
 [ 0.        ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1081.62158203125, (595.19336, 0.4784231, 485.94983, 0.9340874)
   validation loss 759.6859130859375, (499.76743, 0.21789165, 259.70056, 0.9340874)
decoder loss ratio: 19361.857700, decoder SINDy loss  ratio: 0.560600
=========================
[[1.        ]
 [0.99026597]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95692   ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1398673]
 [-0.5823707]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.4850134]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.8186116]
 [-0.       ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1217.119384765625, (767.3131, 0.3513412, 449.4549, 0.9339014)
   validation loss 939.5840454101562, (699.3523, 0.20142785, 240.03032, 0.9339014)
decoder loss ratio: 27094.122034, decoder SINDy loss  ratio: 0.518139
=========================
[[1.        ]
 [0.99023724]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95467937]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1540146 ]
 [-0.6049404 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.45092684]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.8687525 ]
 [ 0.        ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.6173095703125, (341.29947, 0.4296583, 458.8882, 0.93390656)
   validation loss 531.6904296875, (283.82053, 0.22333242, 247.64659, 0.93390656)
decoder loss ratio: 10995.699916, decoder SINDy loss  ratio: 0.534580
=========================
[[1.       ]
 [0.9895246]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9543937]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.1400657 ]
 [-0.5688448 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.51216596]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.8662071 ]
 [-0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.6195068359375, (252.96509, 0.42034462, 450.23407, 0.9338361)
   validation loss 445.72589111328125, (204.1056, 0.21931325, 241.40096, 0.9338361)
decoder loss ratio: 7907.405522, decoder SINDy loss  ratio: 0.521098
=========================
[[1.        ]
 [0.989096  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95358956]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.104999  ]
 [-0.63770944]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5368986 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.7823728 ]
 [ 0.        ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.5850219726562, (251.33043, 0.40067866, 440.8539, 0.9337784)
   validation loss 429.0880126953125, (194.2665, 0.21697915, 234.60452, 0.9337784)
decoder loss ratio: 7526.221268, decoder SINDy loss  ratio: 0.506427
=========================
[[1.       ]
 [0.9882838]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9552194]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.1476502]
 [-0.5239547]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5839193]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.8050481]
 [-0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.2871704101562, (233.78506, 0.4110919, 443.091, 0.9338757)
   validation loss 420.60760498046875, (185.13611, 0.21863191, 235.25285, 0.9338757)
decoder loss ratio: 7172.494250, decoder SINDy loss  ratio: 0.507826
=========================
[[1.        ]
 [0.9892218 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94769955]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2006354 ]
 [-0.5048046 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.52093184]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.7531003 ]
 [ 0.        ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.8934936523438, (247.45543, 0.38835686, 443.0497, 0.9335883)
   validation loss 429.49859619140625, (193.11255, 0.2131373, 236.17293, 0.9335883)
decoder loss ratio: 7481.515400, decoder SINDy loss  ratio: 0.509812
=========================
[[1.       ]
 [0.9883405]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9470665]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.2304254 ]
 [-0.55733544]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.49834335]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.7746912 ]
 [ 0.        ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.607177734375, (297.53342, 0.4324942, 455.6413, 0.93359596)
   validation loss 497.56939697265625, (252.38028, 0.23084165, 244.9583, 0.93359596)
decoder loss ratio: 9777.650181, decoder SINDy loss  ratio: 0.528777
=========================
[[1.        ]
 [0.98741895]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.950952  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.24828   ]
 [-0.64704967]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.49902096]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.7205676 ]
 [ 0.        ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.9935302734375, (265.0552, 0.38700724, 443.55133, 0.93384475)
   validation loss 447.94647216796875, (211.18636, 0.21867318, 236.54144, 0.93384475)
decoder loss ratio: 8181.726051, decoder SINDy loss  ratio: 0.510608
=========================
[[1.        ]
 [0.98724586]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9479433 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.328073  ]
 [-0.61905277]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.43416384]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.6999062 ]
 [-0.        ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.2052612304688, (247.26381, 0.3998786, 446.54156, 0.93374234)
   validation loss 434.0634765625, (194.9346, 0.23141155, 238.89745, 0.93374234)
decoder loss ratio: 7552.104858, decoder SINDy loss  ratio: 0.515694
=========================
[[1.       ]
 [0.9858213]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9513532]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.336189  ]
 [-0.45374703]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.5707814 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.6520007 ]
 [-0.        ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 938.7244873046875, (465.56897, 0.43921474, 472.71634, 0.9338337)
   validation loss 651.3294067382812, (395.5646, 0.22655115, 255.53825, 0.9338337)
decoder loss ratio: 15324.859556, decoder SINDy loss  ratio: 0.551615
=========================
[[1.        ]
 [0.98735964]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93882704]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3163753 ]
 [-0.519894  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.46541205]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.6759617 ]
 [ 0.        ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.414306640625, (257.96057, 0.4059637, 447.0478, 0.93323517)
   validation loss 441.5771484375, (204.92415, 0.22604506, 236.42696, 0.93323517)
decoder loss ratio: 7939.117279, decoder SINDy loss  ratio: 0.510361
=========================
[[1.       ]
 [0.9886131]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9362328]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.2688923]
 [-0.5418406]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5270152]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.6659613]
 [-0.       ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1273.474365234375, (776.7857, 0.459581, 496.229, 0.9332275)
   validation loss 970.5716552734375, (701.074, 0.21293944, 269.2847, 0.9332275)
decoder loss ratio: 27160.822894, decoder SINDy loss  ratio: 0.581289
=========================
[[1.       ]
 [0.9860336]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.94489  ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.3460345 ]
 [-0.58426464]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.5136044 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.6735533 ]
 [ 0.        ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.2713012695312, (241.38167, 0.40331617, 443.48633, 0.93348056)
   validation loss 422.1075439453125, (189.06845, 0.20265093, 232.83644, 0.93348056)
decoder loss ratio: 7324.840026, decoder SINDy loss  ratio: 0.502610
=========================
[[1.        ]
 [0.98693687]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9351665 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.30263   ]
 [-0.61261594]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.49384525]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.6391548 ]
 [ 0.        ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1330.761474609375, (868.78827, 0.34365776, 461.6296, 0.9331989)
   validation loss 1022.5223388671875, (777.5456, 0.21382532, 244.76295, 0.9331989)
decoder loss ratio: 30123.466161, decoder SINDy loss  ratio: 0.528355
=========================
[[1.        ]
 [0.9879236 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93393195]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.394377  ]
 [-0.5236066 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.56939304]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.5840176 ]
 [ 0.        ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1088.6055908203125, (628.8791, 0.33475697, 459.39172, 0.9329832)
   validation loss 784.8985595703125, (543.7452, 0.20717333, 240.94621, 0.9329832)
decoder loss ratio: 21065.632187, decoder SINDy loss  ratio: 0.520116
=========================
[[1.        ]
 [0.9880729 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92969155]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.352849  ]
 [-0.59900355]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.50701153]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.6560612 ]
 [ 0.        ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 998.4900512695312, (523.9601, 0.41879869, 474.11115, 0.93290484)
   validation loss 725.5509033203125, (468.45334, 0.21552345, 256.88205, 0.93290484)
decoder loss ratio: 18148.695609, decoder SINDy loss  ratio: 0.554516
=========================
[[1.       ]
 [0.9869829]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.935536 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.4132795 ]
 [-0.5804441 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.54682744]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.5585144 ]
 [-0.        ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.162109375, (320.08908, 0.36333397, 444.70966, 0.9331012)
   validation loss 493.20477294921875, (259.63174, 0.19290629, 233.38011, 0.9331012)
decoder loss ratio: 10058.584518, decoder SINDy loss  ratio: 0.503784
=========================
[[1.        ]
 [0.98752594]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92919225]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.389542  ]
 [-0.5216385 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.52932495]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.5282001 ]
 [-0.        ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.5722045898438, (313.84814, 0.40474424, 454.3193, 0.9327222)
   validation loss 491.18017578125, (250.07155, 0.18219596, 240.92644, 0.9327222)
decoder loss ratio: 9688.205931, decoder SINDy loss  ratio: 0.520074
=========================
[[1.        ]
 [0.98749495]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92601013]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.452471  ]
 [-0.4763895 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.58605057]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.579461  ]
 [ 0.        ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.138916015625, (231.76906, 0.37782452, 447.99207, 0.93271226)
   validation loss 420.77972412109375, (182.56837, 0.20360483, 238.00777, 0.93271226)
decoder loss ratio: 7073.015786, decoder SINDy loss  ratio: 0.513773
=========================
[[1.        ]
 [0.98655164]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9256843 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3616705 ]
 [-0.61059505]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.49653554]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.4606481 ]
 [-0.        ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.3297119140625, (245.76941, 0.4048221, 451.1555, 0.93267196)
   validation loss 433.534912109375, (193.62807, 0.20520073, 239.70163, 0.93267196)
decoder loss ratio: 7501.487469, decoder SINDy loss  ratio: 0.517430
=========================
[[1.        ]
 [0.98710465]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9188911 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.475125 ]
 [-0.571397 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.4917319]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.4652349]
 [ 0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.7999267578125, (284.9625, 0.3761929, 446.46124, 0.932228)
   validation loss 462.34710693359375, (227.77003, 0.19641203, 234.38066, 0.932228)
decoder loss ratio: 8824.206574, decoder SINDy loss  ratio: 0.505944
=========================
[[1.        ]
 [0.98677427]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9196892 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3955917 ]
 [-0.6280434 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.43436122]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.4905621 ]
 [-0.        ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.9776611328125, (302.8, 0.40702626, 453.7707, 0.93223447)
   validation loss 475.98388671875, (236.18257, 0.17603414, 239.62526, 0.93223447)
decoder loss ratio: 9150.122847, decoder SINDy loss  ratio: 0.517265
=========================
[[1.        ]
 [0.98724246]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9152106 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.449878  ]
 [-0.53724015]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.47213078]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.5485436 ]
 [-0.        ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.424072265625, (234.72705, 0.37790176, 451.3191, 0.9321419)
   validation loss 426.01806640625, (186.32005, 0.19873074, 239.49927, 0.9321419)
decoder loss ratio: 7218.362323, decoder SINDy loss  ratio: 0.516993
=========================
[[1.        ]
 [0.98689705]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91533244]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5649614 ]
 [-0.5338536 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.43020895]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.5253742 ]
 [-0.        ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1208.5101318359375, (712.69977, 0.4280727, 495.38226, 0.9321413)
   validation loss 885.697021484375, (618.4345, 0.18984787, 267.07266, 0.9321413)
decoder loss ratio: 23959.226539, decoder SINDy loss  ratio: 0.576514
=========================
[[1.        ]
 [0.98662865]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9091445 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5268054 ]
 [-0.56455255]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.43609694]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.5170047 ]
 [-0.        ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.9639892578125, (425.63196, 0.35380086, 451.9782, 0.9315691)
   validation loss 593.1846313476562, (357.0076, 0.19206232, 235.98499, 0.9315691)
decoder loss ratio: 13831.094173, decoder SINDy loss  ratio: 0.509407
=========================
[[1.       ]
 [0.9870194]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9037578]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.528912  ]
 [-0.6411099 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.51558554]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.4452529 ]
 [ 0.        ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 890.16015625, (420.88617, 0.41112524, 468.86288, 0.93132585)
   validation loss 604.0443115234375, (353.36404, 0.18702894, 250.49323, 0.93132585)
decoder loss ratio: 13689.936539, decoder SINDy loss  ratio: 0.540725
=========================
[[1.        ]
 [0.98631036]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9046086 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.637155 ]
 [-0.5974348]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.4706658]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.3919002]
 [ 0.       ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 898.6751708984375, (426.60867, 0.39388296, 471.67264, 0.9316353)
   validation loss 621.7100219726562, (369.11496, 0.19128762, 252.40376, 0.9316353)
decoder loss ratio: 14300.154351, decoder SINDy loss  ratio: 0.544849
=========================
[[1.       ]
 [0.9845923]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9148353]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.590149 ]
 [-0.5556144]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5177784]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.3608353]
 [-0.       ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.4641723632812, (254.23112, 0.3550384, 456.878, 0.93259853)
   validation loss 438.6855773925781, (195.79056, 0.21059684, 242.68442, 0.93259853)
decoder loss ratio: 7585.266119, decoder SINDy loss  ratio: 0.523868
=========================
[[1.        ]
 [0.9851016 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.90640604]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5714617 ]
 [-0.6104446 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.51065093]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.3519951 ]
 [-0.        ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 978.9639282226562, (519.3864, 0.3191699, 459.25836, 0.93196815)
   validation loss 685.1937255859375, (444.2713, 0.20595263, 240.71645, 0.93196815)
decoder loss ratio: 17211.841500, decoder SINDy loss  ratio: 0.519620
=========================
[[1.        ]
 [0.9853475 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.90554565]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6061697 ]
 [-0.5896355 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.49204773]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.2795192 ]
 [ 0.        ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.776611328125, (323.11813, 0.33983722, 451.31863, 0.93166304)
   validation loss 491.83746337890625, (255.4562, 0.19079179, 236.19046, 0.93166304)
decoder loss ratio: 9896.816961, decoder SINDy loss  ratio: 0.509850
=========================
[[1.       ]
 [0.9839889]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.906092 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.58428  ]
 [-0.5692754]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5336314]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3375695]
 [-0.       ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1452.8095703125, (975.01227, 0.31677875, 477.48047, 0.93174726)
   validation loss 1110.575927734375, (861.8727, 0.18428083, 248.51901, 0.93174726)
decoder loss ratio: 33390.443926, decoder SINDy loss  ratio: 0.536463
=========================
[[1.       ]
 [0.9864446]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8921621]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.606267  ]
 [-0.61912465]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4338201 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.3397702 ]
 [ 0.        ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 820.4552612304688, (355.0107, 0.38152906, 465.06302, 0.93074447)
   validation loss 538.00634765625, (289.62848, 0.18122116, 248.19667, 0.93074447)
decoder loss ratio: 11220.710094, decoder SINDy loss  ratio: 0.535767
=========================
[[1.        ]
 [0.98380727]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8995982 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.6042004]
 [-0.5366446]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.4423142]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.3083922]
 [-0.       ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1051.4713134765625, (588.03876, 0.3289081, 463.10367, 0.93127674)
   validation loss 748.57666015625, (507.5171, 0.20131384, 240.85828, 0.93127674)
decoder loss ratio: 19662.093149, decoder SINDy loss  ratio: 0.519926
=========================
[[1.       ]
 [0.9851992]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8828912]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.6870503 ]
 [-0.6132798 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.50535244]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.3295399 ]
 [ 0.        ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1100.62060546875, (613.5385, 0.39702895, 486.6851, 0.93027467)
   validation loss 816.7494506835938, (554.11145, 0.20235234, 262.43567, 0.93027467)
decoder loss ratio: 21467.239560, decoder SINDy loss  ratio: 0.566504
=========================
[[1.        ]
 [0.98363453]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8831481 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7032843 ]
 [-0.567467  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.44457933]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.242625  ]
 [-0.        ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1267.049072265625, (767.6678, 0.40897426, 498.97226, 0.9304768)
   validation loss 979.3804931640625, (709.3258, 0.21253261, 269.8422, 0.9304768)
decoder loss ratio: 27480.513155, decoder SINDy loss  ratio: 0.582492
=========================
[[1.        ]
 [0.98455226]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8836338 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.659957  ]
 [-0.5294094 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.44694787]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.2809881 ]
 [-0.        ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.1434326171875, (245.64067, 0.38117185, 454.12158, 0.9300837)
   validation loss 416.86865234375, (179.76825, 0.16945688, 236.93095, 0.9300837)
decoder loss ratio: 6964.534077, decoder SINDy loss  ratio: 0.511449
=========================
[[1.        ]
 [0.98556393]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8791821 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.723653  ]
 [-0.54932153]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.54628646]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.2269446 ]
 [-0.        ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1172.9788818359375, (701.7831, 0.3001716, 470.8956, 0.9298932)
   validation loss 840.9307861328125, (597.6463, 0.17894308, 243.10551, 0.9298932)
decoder loss ratio: 23153.855271, decoder SINDy loss  ratio: 0.524777
=========================
[[1.        ]
 [0.9865928 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.87365454]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7520957 ]
 [-0.4988604 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.39844424]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.2615688 ]
 [-0.        ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.4058227539062, (251.25966, 0.34030455, 458.80585, 0.92952883)
   validation loss 436.4618835449219, (194.7496, 0.17794895, 241.53433, 0.92952883)
decoder loss ratio: 7544.937731, decoder SINDy loss  ratio: 0.521386
=========================
[[1.        ]
 [0.98526025]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.87177795]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-4.6961207]
 [-0.5248111]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.404476 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1872594]
 [-0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.7193603515625, (312.7097, 0.32137167, 469.6883, 0.9299734)
   validation loss 520.44091796875, (271.69525, 0.20569116, 248.54001, 0.9299734)
decoder loss ratio: 10525.945725, decoder SINDy loss  ratio: 0.536509
=========================
[[1.        ]
 [0.98595035]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86920714]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-4.795832  ]
 [-0.574293  ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.45719293]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.202305  ]
 [-0.        ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.6712646484375, (334.97052, 0.30932745, 458.39145, 0.9296508)
   validation loss 506.7125244140625, (267.66708, 0.18594712, 238.8595, 0.9296508)
decoder loss ratio: 10369.887515, decoder SINDy loss  ratio: 0.515612
=========================
[[1.        ]
 [0.98473716]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8702277 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-4.875232  ]
 [-0.60301405]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.43376008]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0931953 ]
 [-0.        ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.26123046875, (317.9915, 0.29953662, 460.97018, 0.9300055)
   validation loss 494.04229736328125, (254.19014, 0.19625661, 239.65588, 0.9300055)
decoder loss ratio: 9847.767308, decoder SINDy loss  ratio: 0.517331
=========================
[[1.       ]
 [0.9858812]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8655617]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]]
[[-4.782089  ]
 [-0.57975525]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4589701 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1560006 ]
 [ 0.        ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.1746826171875, (309.1779, 0.31352082, 457.68326, 0.9291224)
   validation loss 473.94195556640625, (236.44957, 0.1704032, 237.32199, 0.9291224)
decoder loss ratio: 9160.466825, decoder SINDy loss  ratio: 0.512293
=========================
[[1.        ]
 [0.98545015]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8620978 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999945 ]
 [0.        ]]
[[-4.802307  ]
 [-0.5392117 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.48555264]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.1123728 ]
 [-0.        ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1134.7073974609375, (659.7321, 0.27787927, 474.6974, 0.9290781)
   validation loss 808.44775390625, (563.84515, 0.1844915, 244.41806, 0.9290781)
decoder loss ratio: 21844.340137, decoder SINDy loss  ratio: 0.527611
=========================
[[1.        ]
 [0.98569286]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8568943 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]]
[[-4.8558774 ]
 [-0.50431776]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4898048 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0104738 ]
 [ 0.        ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 908.36865234375, (443.43378, 0.29661512, 464.63828, 0.9287391)
   validation loss 602.79443359375, (362.29135, 0.18173867, 240.32135, 0.9287391)
decoder loss ratio: 14035.795916, decoder SINDy loss  ratio: 0.518767
=========================
[[1.        ]
 [0.9870213 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84560406]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]]
[[-4.8236876 ]
 [-0.5438739 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.47051516]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.044044  ]
 [ 0.        ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.7845458984375, (275.3731, 0.32371932, 467.0877, 0.9277789)
   validation loss 472.19482421875, (226.95616, 0.17218302, 245.06648, 0.9277789)
decoder loss ratio: 8792.675710, decoder SINDy loss  ratio: 0.529010
=========================
[[1.       ]
 [0.9859201]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8503368]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]]
[[-4.8939514 ]
 [-0.61779815]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.42202765]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0749042 ]
 [ 0.        ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.4873046875, (264.37842, 0.33445513, 465.77444, 0.92794037)
   validation loss 454.24713134765625, (210.28816, 0.17228751, 243.78667, 0.92794037)
decoder loss ratio: 8146.928481, decoder SINDy loss  ratio: 0.526248
=========================
[[1.        ]
 [0.9869455 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83703506]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998355]
 [0.        ]]
[[-4.8472357 ]
 [-0.5916244 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4437448 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.97348464]
 [-0.        ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 873.0191650390625, (394.04486, 0.3279075, 478.6464, 0.9273018)
   validation loss 597.6685791015625, (343.63525, 0.17388792, 253.85942, 0.9273018)
decoder loss ratio: 13313.026313, decoder SINDy loss  ratio: 0.547991
=========================
[[1.        ]
 [0.9867814 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83536184]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998116]
 [0.        ]]
[[-4.8924804 ]
 [-0.56476367]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.44476318]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.99577093]
 [ 0.        ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 923.4487915039062, (439.6292, 0.3219948, 483.4976, 0.9272546)
   validation loss 639.36865234375, (381.0798, 0.18355988, 258.1053, 0.9272546)
decoder loss ratio: 14763.693170, decoder SINDy loss  ratio: 0.557157
=========================
[[1.        ]
 [0.986387  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83545554]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999979  ]
 [0.        ]]
[[-4.885624  ]
 [-0.57347804]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.42467335]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.95744365]
 [ 0.        ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.9129028320312, (236.12317, 0.29257366, 467.49716, 0.9276053)
   validation loss 430.6148986816406, (186.88866, 0.18294127, 243.5433, 0.9276053)
decoder loss ratio: 7240.391010, decoder SINDy loss  ratio: 0.525722
=========================
[[1.       ]
 [0.986489 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8252174]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]]
[[-4.93742   ]
 [-0.56797916]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4464683 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.96894133]
 [-0.        ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.3817138671875, (267.55408, 0.32721144, 468.50046, 0.9259996)
   validation loss 454.12481689453125, (208.40082, 0.17156918, 245.55244, 0.9259996)
decoder loss ratio: 8073.809484, decoder SINDy loss  ratio: 0.530059
=========================
[[1.        ]
 [0.98517054]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83320236]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-4.911707  ]
 [-0.5122814 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.46826655]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.9567346 ]
 [-0.        ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 954.701416015625, (482.5312, 0.2893922, 471.88083, 0.9265853)
   validation loss 638.7938232421875, (398.11212, 0.16412948, 240.51755, 0.9265853)
decoder loss ratio: 15423.554743, decoder SINDy loss  ratio: 0.519191
=========================
[[1.        ]
 [0.9858453 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.82178605]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-4.9761004 ]
 [-0.5738193 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.39988753]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.88738966]
 [-0.        ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.9108276367188, (280.0362, 0.33262825, 469.542, 0.9256019)
   validation loss 465.24786376953125, (220.37143, 0.15798557, 244.71846, 0.9256019)
decoder loss ratio: 8537.571758, decoder SINDy loss  ratio: 0.528259
=========================
[[1.        ]
 [0.98664725]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.81149054]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-4.9698033 ]
 [-0.5416564 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.42373645]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.8349693 ]
 [-0.        ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.4261474609375, (384.25128, 0.3134729, 481.8614, 0.92536116)
   validation loss 589.8959350585938, (335.3498, 0.16969612, 254.37643, 0.92536116)
decoder loss ratio: 12992.033154, decoder SINDy loss  ratio: 0.549107
=========================
[[1.       ]
 [0.98678  ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8077929]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999659]
 [0.       ]]
[[-4.979084  ]
 [-0.55874056]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.3813951 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.92046154]
 [-0.        ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1017.1641845703125, (523.7248, 0.30857405, 493.13083, 0.9252885)
   validation loss 728.9498901367188, (465.2707, 0.18048166, 263.49872, 0.9252885)
decoder loss ratio: 18025.394312, decoder SINDy loss  ratio: 0.568799
=========================
[[1.        ]
 [0.98646045]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.808277  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999417 ]
 [0.        ]]
[[-4.985942  ]
 [-0.46970022]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.4498889 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.8298449 ]
 [-0.        ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.848876953125, (242.73969, 0.2807672, 472.82846, 0.9255808)
   validation loss 438.2632751464844, (192.97742, 0.17746873, 245.10838, 0.9255808)
decoder loss ratio: 7476.280158, decoder SINDy loss  ratio: 0.529101
=========================
[[1.        ]
 [0.9868179 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.80399096]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993014]
 [0.        ]]
[[-4.9880347 ]
 [-0.59631544]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.45941964]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.7825572 ]
 [-0.        ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.0427856445312, (279.25754, 0.29010403, 475.49515, 0.92483777)
   validation loss 471.8683166503906, (222.60838, 0.1710289, 249.0889, 0.92483777)
decoder loss ratio: 8624.235229, decoder SINDy loss  ratio: 0.537693
=========================
[[1.       ]
 [0.9858226]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8161397]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998952]
 [0.       ]]
[[-5.0547853 ]
 [-0.6083062 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.42359686]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.78513885]
 [ 0.        ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.7052612304688, (338.2132, 0.284198, 471.20786, 0.92528784)
   validation loss 503.6021728515625, (264.1366, 0.15715851, 239.3084, 0.92528784)
decoder loss ratio: 10233.110317, decoder SINDy loss  ratio: 0.516581
=========================
[[1.        ]
 [0.98706174]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7941544 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99985284]
 [0.        ]]
[[-5.0558615 ]
 [-0.55530936]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.43434787]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.7574464 ]
 [ 0.        ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 828.1480712890625, (349.20633, 0.31226847, 478.62946, 0.9233983)
   validation loss 541.4993896484375, (290.8828, 0.14844276, 250.46814, 0.9233983)
decoder loss ratio: 11269.305151, decoder SINDy loss  ratio: 0.540671
=========================
[[1.        ]
 [0.9879446 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7821636 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99977565]
 [0.        ]]
[[-5.016258  ]
 [-0.59024364]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.37692374]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.7065045 ]
 [ 0.        ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 752.5120849609375, (275.21005, 0.2771658, 477.02484, 0.9229493)
   validation loss 476.90740966796875, (228.84187, 0.16128203, 247.90424, 0.9229493)
decoder loss ratio: 8865.731454, decoder SINDy loss  ratio: 0.535136
=========================
[[1.        ]
 [0.9872921 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.77657783]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9996679 ]
 [0.        ]]
[[-5.0560646 ]
 [-0.61302745]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4528817 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.77801156]
 [ 0.        ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.200927734375, (293.66296, 0.26897293, 472.26895, 0.9222196)
   validation loss 468.4783020019531, (227.75644, 0.15941301, 240.56245, 0.9222196)
decoder loss ratio: 8823.679858, decoder SINDy loss  ratio: 0.519288
=========================
[[1.        ]
 [0.987687  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.77428424]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9995291 ]
 [0.        ]]
[[-5.1126113 ]
 [-0.5729    ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.3317138 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.71426666]
 [ 0.        ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.484375, (242.04764, 0.2737056, 472.16302, 0.9220688)
   validation loss 421.58270263671875, (179.5379, 0.15956576, 241.88522, 0.9220688)
decoder loss ratio: 6955.610047, decoder SINDy loss  ratio: 0.522143
=========================
[[1.        ]
 [0.9883201 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.77068317]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99932307]
 [0.        ]]
[[-5.071557  ]
 [-0.58882684]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.3287583 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.7289655 ]
 [ 0.        ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 996.3646240234375, (500.4896, 0.28527796, 495.58972, 0.92229503)
   validation loss 707.3397216796875, (444.35617, 0.15746218, 262.82605, 0.92229503)
decoder loss ratio: 17215.129487, decoder SINDy loss  ratio: 0.567347
=========================
[[1.        ]
 [0.98889124]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7632162 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9990485 ]
 [0.        ]]
[[-5.2468987 ]
 [-0.5730425 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.41136393]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.8081354 ]
 [-0.        ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.6123657226562, (251.5619, 0.28257683, 471.76788, 0.9212742)
   validation loss 423.34234619140625, (181.35605, 0.1496331, 241.83665, 0.9212742)
decoder loss ratio: 7026.048170, decoder SINDy loss  ratio: 0.522038
=========================
[[1.       ]
 [0.9883519]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7526259]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.998592 ]
 [0.       ]]
[[-5.178998  ]
 [-0.5569571 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.4095074 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.67759955]
 [ 0.        ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.67626953125, (261.76096, 0.26302513, 475.6523, 0.92050505)
   validation loss 443.659423828125, (201.24445, 0.1589423, 242.25606, 0.92050505)
decoder loss ratio: 7796.559206, decoder SINDy loss  ratio: 0.522944
=========================
[[1.        ]
 [0.9887351 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.74757075]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99809104]
 [0.        ]]
[[-5.1590395 ]
 [-0.56567276]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.4843697 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.69215524]
 [ 0.        ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 878.96533203125, (391.03076, 0.2900463, 487.64453, 0.91965646)
   validation loss 587.0009155273438, (330.30212, 0.15279147, 256.546, 0.91965646)
decoder loss ratio: 12796.477714, decoder SINDy loss  ratio: 0.553791
=========================
[[1.       ]
 [0.9890772]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7413179]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9973476]
 [0.       ]]
[[-5.1730356 ]
 [-0.56621504]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.38424164]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.69107646]
 [ 0.        ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.8899536132812, (237.73329, 0.25412667, 476.90253, 0.91938764)
   validation loss 429.3197937011719, (185.475, 0.14764926, 243.69714, 0.91938764)
decoder loss ratio: 7185.623735, decoder SINDy loss  ratio: 0.526055
=========================
[[1.        ]
 [0.9874288 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7541224 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99635756]
 [0.        ]]
[[-5.132988  ]
 [-0.601912  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.47111884]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.5941283 ]
 [ 0.        ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.3308715820312, (255.56967, 0.25756934, 477.50363, 0.92099494)
   validation loss 438.68487548828125, (195.22601, 0.15724792, 243.30164, 0.92099494)
decoder loss ratio: 7563.394678, decoder SINDy loss  ratio: 0.525201
=========================
[[1.        ]
 [0.9880247 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.74342495]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99476755]
 [0.        ]]
[[-5.1726503 ]
 [-0.5822113 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.38084096]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.6589432 ]
 [ 0.        ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1156.6068115234375, (663.5947, 0.24182868, 492.77026, 0.9199478)
   validation loss 812.7355346679688, (563.87537, 0.1525432, 248.70763, 0.9199478)
decoder loss ratio: 21845.510618, decoder SINDy loss  ratio: 0.536870
=========================
[[1.        ]
 [0.9888404 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.73725015]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9925899 ]
 [0.        ]]
[[-5.2425327 ]
 [-0.58038056]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.44503105]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.5740037 ]
 [-0.        ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.9542236328125, (239.804, 0.2602341, 476.88995, 0.9187364)
   validation loss 420.93011474609375, (177.54889, 0.14231244, 243.23892, 0.9187364)
decoder loss ratio: 6878.552204, decoder SINDy loss  ratio: 0.525065
=========================
[[1.       ]
 [0.9882474]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7275182]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9894614]
 [0.       ]]
[[-5.189543  ]
 [-0.5886304 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.40602723]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.52301633]
 [-0.        ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1239.2080078125, (744.81714, 0.24721606, 494.14365, 0.9182026)
   validation loss 899.892333984375, (649.0891, 0.14968164, 250.65355, 0.9182026)
decoder loss ratio: 25146.839041, decoder SINDy loss  ratio: 0.541071
=========================
[[1.        ]
 [0.9886788 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.71097684]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9853055 ]
 [0.        ]]
[[-5.1901865 ]
 [-0.49584007]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.33815134]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.6285841 ]
 [ 0.        ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.7080078125, (347.21466, 0.28118923, 488.21216, 0.9159768)
   validation loss 546.639892578125, (292.17896, 0.14811172, 254.31284, 0.9159768)
decoder loss ratio: 11319.519965, decoder SINDy loss  ratio: 0.548970
=========================
[[1.       ]
 [0.9865049]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7334658]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.980379 ]
 [0.       ]]
[[-5.2300534 ]
 [-0.5029781 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.43488982]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.51387143]
 [-0.        ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1108.8670654296875, (615.69415, 0.24052063, 492.93237, 0.9184125)
   validation loss 760.6619873046875, (513.3523, 0.1455249, 247.1642, 0.9184125)
decoder loss ratio: 19888.159124, decoder SINDy loss  ratio: 0.533539
=========================
[[1.       ]
 [0.9872463]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7215335]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9716648]
 [0.       ]]
[[-5.2293425 ]
 [-0.58416915]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3836072 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.43498302]
 [-0.        ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.1828002929688, (237.99635, 0.26996508, 481.91647, 0.9162752)
   validation loss 428.54144287109375, (183.27766, 0.14388749, 245.11989, 0.9162752)
decoder loss ratio: 7100.494895, decoder SINDy loss  ratio: 0.529126
=========================
[[1.       ]
 [0.9874195]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7067391]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9617825]
 [0.       ]]
[[-5.27041   ]
 [-0.5943465 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.37920624]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.52307165]
 [-0.        ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1150.8631591796875, (657.82764, 0.24868059, 492.7869, 0.91445446)
   validation loss 804.1285400390625, (556.68414, 0.13913138, 247.30524, 0.91445446)
decoder loss ratio: 21566.910149, decoder SINDy loss  ratio: 0.533843
=========================
[[1.        ]
 [0.98656404]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.71970993]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9488095 ]
 [0.        ]]
[[-5.2860255]
 [-0.5905071]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.3320433]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5266869]
 [ 0.       ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.2581787109375, (249.49194, 0.25818276, 482.50806, 0.91547775)
   validation loss 431.8779296875, (187.05612, 0.14739467, 244.6744, 0.91547775)
decoder loss ratio: 7246.878903, decoder SINDy loss  ratio: 0.528164
=========================
[[1.        ]
 [0.98767143]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6945809 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9272684 ]
 [0.        ]]
[[-5.342904  ]
 [-0.52820593]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3906082 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.44723028]
 [ 0.        ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1190.302734375, (692.21625, 0.23895732, 497.8476, 0.9116048)
   validation loss 837.3927001953125, (587.4061, 0.14308783, 249.8435, 0.9116048)
decoder loss ratio: 22757.133178, decoder SINDy loss  ratio: 0.539322
=========================
[[1.        ]
 [0.9882425 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.69801927]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8994076 ]
 [0.        ]]
[[-5.3279324 ]
 [-0.60203797]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.38914487]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.452823  ]
 [-0.        ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 759.0814819335938, (277.16623, 0.25899902, 481.65625, 0.9088656)
   validation loss 444.52447509765625, (202.04726, 0.13129316, 242.34595, 0.9088656)
decoder loss ratio: 7827.661485, decoder SINDy loss  ratio: 0.523138
=========================
[[1.        ]
 [0.9893496 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.68234634]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.856351  ]
 [0.        ]]
[[-5.3932166 ]
 [-0.588366  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.33078986]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.40931952]
 [ 0.        ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.5106811523438, (236.68814, 0.24699591, 483.57556, 0.90385383)
   validation loss 424.4525146484375, (180.23647, 0.13630712, 244.07976, 0.90385383)
decoder loss ratio: 6982.673576, decoder SINDy loss  ratio: 0.526880
=========================
[[1.        ]
 [0.98688334]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7151502 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8153842 ]
 [0.        ]]
[[-5.3420467 ]
 [-0.5249863 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.40354925]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.46602866]
 [-0.        ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.6732177734375, (261.29623, 0.2724304, 484.10455, 0.9026584)
   validation loss 436.62860107421875, (194.3092, 0.13355179, 242.18584, 0.9026584)
decoder loss ratio: 7527.875903, decoder SINDy loss  ratio: 0.522792
=========================
[[1.        ]
 [0.9878031 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.66967666]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7577895 ]
 [0.        ]]
[[-5.3646364 ]
 [-0.53033704]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.425186  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.39505047]
 [-0.        ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.0524291992188, (310.6171, 0.24747641, 487.18787, 0.89381886)
   validation loss 484.921142578125, (241.86433, 0.14025187, 242.91653, 0.89381886)
decoder loss ratio: 9370.244198, decoder SINDy loss  ratio: 0.524370
=========================
[[1.       ]
 [0.9880054]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6771123]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6924064]
 [0.       ]]
[[-5.345803  ]
 [-0.56432736]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.39209473]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.42946863]
 [-0.        ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.8900146484375, (278.43726, 0.24572484, 486.20703, 0.8873014)
   validation loss 456.23907470703125, (212.98524, 0.13555332, 243.11827, 0.8873014)
decoder loss ratio: 8251.418140, decoder SINDy loss  ratio: 0.524805
=========================
[[1.        ]
 [0.98931617]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.664558  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.61081433]
 [0.        ]]
[[-5.400019  ]
 [-0.5776913 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.48823228]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.353198  ]
 [ 0.        ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.38623046875, (239.97244, 0.24675669, 487.16705, 0.8756755)
   validation loss 435.56829833984375, (189.17268, 0.1295939, 246.26604, 0.8756755)
decoder loss ratio: 7328.878185, decoder SINDy loss  ratio: 0.531600
=========================
[[1.       ]
 [0.9884087]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6636553]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.531487 ]
 [0.       ]]
[[-5.4634857 ]
 [-0.61263394]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.35681164]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.3613914 ]
 [ 0.        ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 817.1849365234375, (322.49182, 0.25373068, 494.4394, 0.86571264)
   validation loss 527.7952880859375, (274.16592, 0.13843393, 253.49094, 0.86571264)
decoder loss ratio: 10621.663872, decoder SINDy loss  ratio: 0.547196
=========================
[[1.        ]
 [0.9878389 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6656261 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.44856012]
 [0.        ]]
[[-5.3283467 ]
 [-0.58792233]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.36176482]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.32573536]
 [ 0.        ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.7401123046875, (296.00366, 0.25980076, 487.47665, 0.8536938)
   validation loss 467.0833740234375, (224.8756, 0.12580428, 242.08199, 0.8536938)
decoder loss ratio: 8712.070955, decoder SINDy loss  ratio: 0.522568
=========================
[[1.        ]
 [0.98745865]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6433589 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37011576]
 [0.        ]]
[[-5.429453  ]
 [-0.6315026 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.34955508]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.30419087]
 [ 0.        ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.6219482421875, (243.72092, 0.24935527, 489.65167, 0.84213203)
   validation loss 433.52447509765625, (187.39992, 0.14024194, 245.98431, 0.84213203)
decoder loss ratio: 7260.198148, decoder SINDy loss  ratio: 0.530992
=========================
[[1.        ]
 [0.98821884]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6403874 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28957736]
 [0.        ]]
[[-5.5114207 ]
 [-0.59729743]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.36803684]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.2998497 ]
 [ 0.        ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1008.74072265625, (513.13916, 0.24430983, 495.35727, 0.82654953)
   validation loss 664.18701171875, (418.15155, 0.12535937, 245.91013, 0.82654953)
decoder loss ratio: 16199.917001, decoder SINDy loss  ratio: 0.530832
=========================
[[1.        ]
 [0.98907423]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6145364 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22296305]
 [0.        ]]
[[-5.4527073 ]
 [-0.59877837]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.36755174]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.35202235]
 [-0.        ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 915.336181640625, (413.2058, 0.26172704, 501.86868, 0.810084)
   validation loss 622.7216796875, (362.77393, 0.13048269, 259.81723, 0.810084)
decoder loss ratio: 14054.491688, decoder SINDy loss  ratio: 0.560852
=========================
[[1.        ]
 [0.9872349 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6610862 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17376351]
 [0.        ]]
[[-5.464875  ]
 [-0.6004285 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.29166013]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.23985738]
 [-0.        ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.624267578125, (287.86755, 0.2660649, 489.49066, 0.8048822)
   validation loss 457.76007080078125, (215.1775, 0.12216369, 242.46039, 0.8048822)
decoder loss ratio: 8336.350127, decoder SINDy loss  ratio: 0.523385
=========================
[[1.        ]
 [0.9886301 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6199789 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13155773]
 [0.        ]]
[[-5.5656495 ]
 [-0.6021304 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.40577736]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.28454396]
 [ 0.        ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.6348876953125, (322.82318, 0.25036222, 499.56137, 0.7914116)
   validation loss 530.9727783203125, (276.7453, 0.13570571, 254.09175, 0.7914116)
decoder loss ratio: 10721.593384, decoder SINDy loss  ratio: 0.548493
=========================
[[1.        ]
 [0.98919684]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5900147 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0976094 ]
 [0.        ]]
[[-5.5327883 ]
 [-0.5279974 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.41577026]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.19725001]
 [-0.        ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1289.09814453125, (762.70996, 0.26317143, 526.12494, 0.7794036)
   validation loss 995.8363037109375, (718.57935, 0.14366762, 277.11328, 0.7794036)
decoder loss ratio: 27839.011361, decoder SINDy loss  ratio: 0.598188
=========================
[[1.        ]
 [0.9894594 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5864691 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07600695]
 [0.        ]]
[[-5.570969  ]
 [-0.59518063]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.41718587]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.20890296]
 [-0.        ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 816.7755737304688, (318.48267, 0.23648727, 498.05643, 0.7685958)
   validation loss 486.84796142578125, (243.5048, 0.1223951, 243.22076, 0.7685958)
decoder loss ratio: 9433.798947, decoder SINDy loss  ratio: 0.525026
=========================
[[1.        ]
 [0.9898316 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.57036316]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05548525]
 [0.        ]]
[[-5.5606575 ]
 [-0.56224054]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.3691291 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.23077087]
 [ 0.        ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.26220703125, (261.9958, 0.24315229, 493.0233, 0.7582006)
   validation loss 454.0328063964844, (205.46742, 0.124295846, 248.44109, 0.7582006)
decoder loss ratio: 7960.164654, decoder SINDy loss  ratio: 0.536295
=========================
[[1.        ]
 [0.98825413]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.60413045]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04060422]
 [0.        ]]
[[-5.5735216 ]
 [-0.59104425]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.4117809 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.20676532]
 [ 0.        ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1045.18115234375, (545.9076, 0.24814804, 499.02542, 0.7533652)
   validation loss 688.1312255859375, (441.3071, 0.115587085, 246.70853, 0.7533652)
decoder loss ratio: 17097.003134, decoder SINDy loss  ratio: 0.532555
=========================
[[1.       ]
 [0.98937  ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5737816]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0291434]
 [0.       ]]
[[-5.521157  ]
 [-0.5683872 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.40069634]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.18820179]
 [ 0.        ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.40771484375, (269.3621, 0.25961727, 493.786, 0.7422206)
   validation loss 459.2982482910156, (209.71152, 0.12045388, 249.46628, 0.7422206)
decoder loss ratio: 8124.588257, decoder SINDy loss  ratio: 0.538508
=========================
[[1.       ]
 [0.9894882]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5706824]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0204296]
 [0.       ]]
[[-5.5370398 ]
 [-0.5243031 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.38787985]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.21110198]
 [-0.        ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1147.039306640625, (647.38824, 0.2418828, 499.40915, 0.73474455)
   validation loss 799.4513549804688, (550.19507, 0.11952541, 249.13676, 0.73474455)
decoder loss ratio: 21315.512129, decoder SINDy loss  ratio: 0.537797
=========================
[[1.        ]
 [0.9889792 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.565373  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.01414538]
 [0.        ]]
[[-5.6085963 ]
 [-0.5146936 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.37881935]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.14466447]
 [-0.        ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.3117065429688, (246.04341, 0.24962929, 495.01868, 0.72603935)
   validation loss 436.9671630859375, (189.47408, 0.12203424, 247.37103, 0.72603935)
decoder loss ratio: 7340.554619, decoder SINDy loss  ratio: 0.533985
=========================
[[1.        ]
 [0.98888624]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.585261  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.01025433]
 [0.        ]]
[[-5.5550585 ]
 [-0.576866  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.30824146]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.10506367]
 [-0.        ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.2015380859375, (238.09459, 0.25793907, 493.84903, 0.72128415)
   validation loss 424.63275146484375, (180.13689, 0.11736558, 244.37851, 0.72128415)
decoder loss ratio: 6978.815718, decoder SINDy loss  ratio: 0.527525
=========================
[[1.        ]
 [0.9883374 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5825936 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00825993]
 [0.        ]]
[[-5.57697   ]
 [-0.57002574]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.38977188]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.09024732]
 [-0.        ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 816.9930419921875, (321.88327, 0.26511174, 494.84467, 0.71821684)
   validation loss 486.84698486328125, (243.42526, 0.11729067, 243.30444, 0.71821684)
decoder loss ratio: 9430.717272, decoder SINDy loss  ratio: 0.525207
=========================
[[1.        ]
 [0.98873127]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.55135924]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00610532]
 [0.        ]]
[[-5.576595  ]
 [-0.6311016 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.41377494]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.03316362]
 [-0.        ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1124.389404296875, (619.6001, 0.24222958, 504.5471, 0.7078574)
   validation loss 756.976318359375, (507.36655, 0.11404446, 249.49573, 0.7078574)
decoder loss ratio: 19656.260844, decoder SINDy loss  ratio: 0.538572
=========================
[[1.        ]
 [0.9895861 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.52840614]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00448424]
 [0.        ]]
[[-5.6256275 ]
 [-0.62406784]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.43875453]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.10772732]
 [-0.        ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.5504760742188, (254.4567, 0.24504845, 493.84875, 0.699706)
   validation loss 428.34820556640625, (183.37769, 0.11760267, 244.85292, 0.699706)
decoder loss ratio: 7104.369896, decoder SINDy loss  ratio: 0.528549
=========================
[[1.        ]
 [0.98970413]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.51375264]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00319612]
 [0.        ]]
[[-5.6022334 ]
 [-0.5379359 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.33647788]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.10821724]
 [-0.        ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.52783203125, (271.41238, 0.23821712, 494.8772, 0.6913647)
   validation loss 451.9714660644531, (207.78885, 0.11565241, 244.06697, 0.6913647)
decoder loss ratio: 8050.100743, decoder SINDy loss  ratio: 0.526853
=========================
[[1.        ]
 [0.9897059 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5170591 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00235129]
 [0.        ]]
[[-5.7718477 ]
 [-0.61631745]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.40520403]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.06633551]
 [-0.        ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.2073364257812, (240.37909, 0.24433534, 495.5839, 0.6855695)
   validation loss 421.90606689453125, (176.8361, 0.11630944, 244.95367, 0.6855695)
decoder loss ratio: 6850.937722, decoder SINDy loss  ratio: 0.528767
=========================
[[1.        ]
 [0.9899436 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.50924593]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00175404]
 [0.        ]]
[[-5.7225914 ]
 [-0.58179575]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.41289   ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.01160203]
 [-0.        ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.917724609375, (289.13278, 0.23590326, 495.54907, 0.679351)
   validation loss 463.00286865234375, (218.79846, 0.113559544, 244.09085, 0.679351)
decoder loss ratio: 8476.632265, decoder SINDy loss  ratio: 0.526904
=========================
[[1.        ]
 [0.9891486 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.52340937]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00131462]
 [0.        ]]
[[-5.7208223 ]
 [-0.61706686]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.39715135]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.05427852]
 [ 0.        ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 865.44189453125, (356.53012, 0.24536137, 508.6664, 0.6769314)
   validation loss 572.4803466796875, (315.47043, 0.12091499, 256.889, 0.6769314)
decoder loss ratio: 12221.872080, decoder SINDy loss  ratio: 0.554531
=========================
[[1.0000000e+00]
 [9.8920786e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [0.0000000e+00]
 [5.4234427e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [0.0000000e+00]
 [9.6974761e-04]
 [0.0000000e+00]]
[[-5.695893  ]
 [-0.63596797]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.3966048 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.06706929]
 [-0.        ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.9273681640625, (293.4818, 0.2690678, 497.1765, 0.6727666)
   validation loss 464.58782958984375, (221.13905, 0.11270937, 243.33604, 0.6727666)
decoder loss ratio: 8567.310841, decoder SINDy loss  ratio: 0.525275
=========================
[[1.0000000e+00]
 [9.8992229e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [0.0000000e+00]
 [4.9390882e-01]
 [0.0000000e+00]
 [0.0000000e+00]
 [0.0000000e+00]
 [9.0499496e-04]
 [0.0000000e+00]]
[[-5.719277  ]
 [-0.5640663 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.34356606]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.1037677 ]
 [ 0.        ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.8089599609375, (278.84512, 0.24696337, 502.7169, 0.6662164)
   validation loss 480.953857421875, (229.03783, 0.11706506, 251.79898, 0.6662164)
decoder loss ratio: 8873.323027, decoder SINDy loss  ratio: 0.543544
=========================
[[1.        ]
 [0.9904854 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.47628927]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00124357]
 [0.        ]]
[[-5.7712784 ]
 [-0.63710517]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.396572  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.04899668]
 [ 0.        ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 836.3602294921875, (338.8205, 0.24818197, 497.29153, 0.66905206)
   validation loss 505.90496826171875, (261.13123, 0.11345507, 244.66026, 0.66905206)
decoder loss ratio: 10116.677023, decoder SINDy loss  ratio: 0.528134
=========================
[[1.        ]
 [0.9905473 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.46590412]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.00167521]
 [0.        ]]
[[-5.7764325 ]
 [-0.5999703 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.3645533 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.00787756]
 [-0.        ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.4549560546875, (261.38348, 0.24740236, 500.82404, 0.6735715)
   validation loss 455.6617431640625, (205.61842, 0.11509875, 249.92824, 0.6735715)
decoder loss ratio: 7966.014694, decoder SINDy loss  ratio: 0.539505
params['save_name']
pendulum_2023_10_27_08_43_16_503369
