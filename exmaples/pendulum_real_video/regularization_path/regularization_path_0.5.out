nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 09:40:39.748660: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 09:40:39.756209: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 09:40:39.758043: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55923ff8cbc0 executing computations on platform Host. Devices:
2023-10-25 09:40:39.758078: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 09:40:39.759947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 09:40:39.891856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5592401000e0 executing computations on platform CUDA. Devices:
2023-10-25 09:40:39.891921: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 09:40:39.892901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-25 09:40:39.893476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 09:40:39.895363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 09:40:39.896772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 09:40:39.897062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 09:40:39.898687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 09:40:39.899499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 09:40:39.902746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 09:40:39.903411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 09:40:39.903444: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 09:40:39.903780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 09:40:39.903789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 09:40:39.903794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 09:40:39.904355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-25 09:40:41.063374: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.5, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8758485317230225 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 106190.6328125, (99856.98, 0.0025300006, 6316.463, 2.531784)
   validation loss 88420.4609375, (87202.5, 0.0039324514, 1200.7565, 2.531784)
decoder loss ratio: 3378376.240198, decoder SINDy loss  ratio: 2.592002
--- 0.26508283615112305 seconds for one epoch ---
--- 0.3245377540588379 seconds for one epoch ---
--- 0.3330368995666504 seconds for one epoch ---
--- 0.3165884017944336 seconds for one epoch ---
--- 0.30661630630493164 seconds for one epoch ---
--- 0.30042076110839844 seconds for one epoch ---
--- 0.34637022018432617 seconds for one epoch ---
--- 0.300692081451416 seconds for one epoch ---
--- 0.32392382621765137 seconds for one epoch ---
--- 0.28436994552612305 seconds for one epoch ---
--- 0.3299274444580078 seconds for one epoch ---
--- 0.32038021087646484 seconds for one epoch ---
--- 0.3329777717590332 seconds for one epoch ---
--- 0.31264185905456543 seconds for one epoch ---
--- 0.32208967208862305 seconds for one epoch ---
--- 0.28313422203063965 seconds for one epoch ---
--- 0.31447792053222656 seconds for one epoch ---
--- 0.3097503185272217 seconds for one epoch ---
--- 0.3062620162963867 seconds for one epoch ---
--- 0.3153226375579834 seconds for one epoch ---
--- 0.33301734924316406 seconds for one epoch ---
--- 0.3172774314880371 seconds for one epoch ---
--- 0.33817577362060547 seconds for one epoch ---
--- 0.30498671531677246 seconds for one epoch ---
=========================
[[0.77408916]
 [0.77760464]
 [0.77901685]
 [0.7806812 ]
 [0.7738695 ]
 [0.794177  ]
 [0.78163135]
 [0.7737719 ]
 [0.77308154]
 [0.829006  ]
 [0.77466697]]
[[ 0.22683056]
 [ 0.64127344]
 [-0.74628365]
 [-0.8487935 ]
 [-0.18593012]
 [-1.3353763 ]
 [ 0.89985955]
 [-0.16662629]
 [ 0.00473167]
 [-1.9086457 ]
 [ 0.32130864]]
--- 0.2686953544616699 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 67043.0390625, (61716.37, 10.603167, 5280.389, 2.5317726)
   validation loss 47177.39453125, (45856.934, 10.501066, 1274.2823, 2.5317726)
decoder loss ratio: 1776577.218560, decoder SINDy loss  ratio: 2.750718
--- 0.31438159942626953 seconds for one epoch ---
--- 0.33995771408081055 seconds for one epoch ---
--- 0.29287171363830566 seconds for one epoch ---
--- 0.34016966819763184 seconds for one epoch ---
--- 0.30292272567749023 seconds for one epoch ---
--- 0.33605051040649414 seconds for one epoch ---
--- 0.3179049491882324 seconds for one epoch ---
--- 0.3393537998199463 seconds for one epoch ---
--- 0.3239328861236572 seconds for one epoch ---
--- 0.33344292640686035 seconds for one epoch ---
--- 0.33002161979675293 seconds for one epoch ---
--- 0.34628987312316895 seconds for one epoch ---
--- 0.31923866271972656 seconds for one epoch ---
--- 0.3443610668182373 seconds for one epoch ---
--- 0.30515551567077637 seconds for one epoch ---
--- 0.35050535202026367 seconds for one epoch ---
--- 0.31549787521362305 seconds for one epoch ---
--- 0.33966541290283203 seconds for one epoch ---
--- 0.2991364002227783 seconds for one epoch ---
--- 0.3253333568572998 seconds for one epoch ---
--- 0.30272960662841797 seconds for one epoch ---
--- 0.3267056941986084 seconds for one epoch ---
--- 0.2999610900878906 seconds for one epoch ---
--- 0.31342434883117676 seconds for one epoch ---
=========================
[[0.63075244]
 [0.6159588 ]
 [0.6155469 ]
 [0.61654055]
 [0.61223   ]
 [0.6671709 ]
 [0.6200672 ]
 [0.61253005]
 [0.611758  ]
 [0.6247466 ]
 [0.61427534]]
[[ 1.0173517e+00]
 [ 4.3588293e-01]
 [-4.0607032e-01]
 [-4.7529098e-01]
 [-7.2217941e-02]
 [-1.5704589e+00]
 [ 6.6686857e-01]
 [ 1.1294261e-01]
 [ 8.4500707e-04]
 [-8.4756786e-01]
 [ 3.0176020e-01]]
--- 0.2923092842102051 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 40510.73046875, (34020.67, 7.3628983, 6428.6763, 2.5317369)
   validation loss 38576.17578125, (37350.297, 5.1771283, 1166.6847, 2.5317369)
decoder loss ratio: 1447015.343904, decoder SINDy loss  ratio: 2.518453
--- 0.2726891040802002 seconds for one epoch ---
--- 0.3058450222015381 seconds for one epoch ---
--- 0.3618791103363037 seconds for one epoch ---
--- 0.30011606216430664 seconds for one epoch ---
--- 0.3485729694366455 seconds for one epoch ---
--- 0.318434476852417 seconds for one epoch ---
--- 0.3429558277130127 seconds for one epoch ---
--- 0.29769062995910645 seconds for one epoch ---
--- 0.3406107425689697 seconds for one epoch ---
--- 0.33077573776245117 seconds for one epoch ---
--- 0.34818601608276367 seconds for one epoch ---
--- 0.32562255859375 seconds for one epoch ---
--- 0.35628771781921387 seconds for one epoch ---
--- 0.30342984199523926 seconds for one epoch ---
--- 0.35254430770874023 seconds for one epoch ---
--- 0.3805525302886963 seconds for one epoch ---
--- 0.3387441635131836 seconds for one epoch ---
--- 0.3076205253601074 seconds for one epoch ---
--- 0.34242916107177734 seconds for one epoch ---
--- 0.3142127990722656 seconds for one epoch ---
--- 0.35965657234191895 seconds for one epoch ---
--- 0.31546854972839355 seconds for one epoch ---
--- 0.32076430320739746 seconds for one epoch ---
--- 0.3231828212738037 seconds for one epoch ---
=========================
[[0.5151411 ]
 [0.47970665]
 [0.47962222]
 [0.48113734]
 [0.47696972]
 [0.6206066 ]
 [0.4840473 ]
 [0.47913945]
 [0.47666207]
 [0.48035163]
 [0.48142692]]
[[ 1.2146662 ]
 [ 0.2789912 ]
 [-0.27301073]
 [-0.37101263]
 [-0.03858336]
 [-1.984122  ]
 [ 0.5197141 ]
 [ 0.23749582]
 [ 0.00292307]
 [-0.32246318]
 [ 0.38781583]]
--- 0.27080440521240234 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 35371.34765625, (29224.518, 0.71082926, 6075.8013, 2.5317428)
   validation loss 17213.822265625, (16122.456, 1.6715775, 1019.37555, 2.5317428)
decoder loss ratio: 624611.937373, decoder SINDy loss  ratio: 2.200466
--- 0.3091416358947754 seconds for one epoch ---
--- 0.3403637409210205 seconds for one epoch ---
--- 0.30579257011413574 seconds for one epoch ---
--- 0.32390689849853516 seconds for one epoch ---
--- 0.2879149913787842 seconds for one epoch ---
--- 0.33072519302368164 seconds for one epoch ---
--- 0.3000786304473877 seconds for one epoch ---
--- 0.356903076171875 seconds for one epoch ---
--- 0.30727458000183105 seconds for one epoch ---
--- 0.3537142276763916 seconds for one epoch ---
--- 0.29800963401794434 seconds for one epoch ---
--- 0.3646514415740967 seconds for one epoch ---
--- 0.30692172050476074 seconds for one epoch ---
--- 0.3502652645111084 seconds for one epoch ---
--- 0.31824517250061035 seconds for one epoch ---
--- 0.3374497890472412 seconds for one epoch ---
--- 0.3149392604827881 seconds for one epoch ---
--- 0.3653562068939209 seconds for one epoch ---
--- 0.3231041431427002 seconds for one epoch ---
--- 0.35623788833618164 seconds for one epoch ---
--- 0.3144986629486084 seconds for one epoch ---
--- 0.372377872467041 seconds for one epoch ---
--- 0.3029787540435791 seconds for one epoch ---
--- 0.34743475914001465 seconds for one epoch ---
=========================
[[0.4062441 ]
 [0.3817135 ]
 [0.38116816]
 [0.3835396 ]
 [0.38050905]
 [0.69918674]
 [0.38559636]
 [0.38367113]
 [0.38004556]
 [0.3837679 ]
 [0.38666746]]
[[ 0.95091045]
 [ 0.15028462]
 [-0.10705585]
 [-0.27331042]
 [-0.04947507]
 [-2.515556  ]
 [ 0.38414094]
 [ 0.2811489 ]
 [-0.00473055]
 [-0.28685308]
 [ 0.4337601 ]]
--- 0.2971489429473877 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 37880.68359375, (31920.125, 18.79064, 5857.5747, 2.531756)
   validation loss 12662.6435546875, (11699.686, 0.5986322, 878.168, 2.531756)
decoder loss ratio: 453266.129633, decoder SINDy loss  ratio: 1.895649
--- 0.25911951065063477 seconds for one epoch ---
--- 0.31802916526794434 seconds for one epoch ---
--- 0.34630250930786133 seconds for one epoch ---
--- 0.2841074466705322 seconds for one epoch ---
--- 0.3572516441345215 seconds for one epoch ---
--- 0.3090188503265381 seconds for one epoch ---
--- 0.36121368408203125 seconds for one epoch ---
--- 0.29117584228515625 seconds for one epoch ---
--- 0.34946632385253906 seconds for one epoch ---
--- 0.2918376922607422 seconds for one epoch ---
--- 0.3496358394622803 seconds for one epoch ---
--- 0.2934610843658447 seconds for one epoch ---
--- 0.3530924320220947 seconds for one epoch ---
--- 0.2962486743927002 seconds for one epoch ---
--- 0.37024807929992676 seconds for one epoch ---
--- 0.32090091705322266 seconds for one epoch ---
--- 0.3667910099029541 seconds for one epoch ---
--- 0.31650352478027344 seconds for one epoch ---
--- 0.35615110397338867 seconds for one epoch ---
--- 0.31737685203552246 seconds for one epoch ---
--- 0.3578670024871826 seconds for one epoch ---
--- 0.30178213119506836 seconds for one epoch ---
--- 0.39022088050842285 seconds for one epoch ---
--- 0.2917473316192627 seconds for one epoch ---
=========================
[[0.31201538]
 [0.29924223]
 [0.29967925]
 [0.30028653]
 [0.29885212]
 [0.79878473]
 [0.3037771 ]
 [0.3031287 ]
 [0.29856947]
 [0.30633998]
 [0.3069643 ]]
[[ 6.2567729e-01]
 [ 5.7859752e-02]
 [ 9.1834836e-02]
 [-1.3563158e-01]
 [-2.5517194e-02]
 [-2.9636753e+00]
 [ 3.3384600e-01]
 [ 3.0227572e-01]
 [-7.3603500e-04]
 [-4.4284275e-01]
 [ 4.6629727e-01]]
--- 0.25908875465393066 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 25880.3359375, (20644.943, 22.30732, 5116.4014, 2.531774)
   validation loss 9887.3974609375, (9020.128, 0.27688262, 770.3075, 2.531774)
decoder loss ratio: 349455.415627, decoder SINDy loss  ratio: 1.662817
--- 0.33661627769470215 seconds for one epoch ---
--- 0.3614490032196045 seconds for one epoch ---
--- 0.29998326301574707 seconds for one epoch ---
--- 0.382007360458374 seconds for one epoch ---
--- 0.3087618350982666 seconds for one epoch ---
--- 0.36138916015625 seconds for one epoch ---
--- 0.29727697372436523 seconds for one epoch ---
--- 0.39399051666259766 seconds for one epoch ---
--- 0.30617594718933105 seconds for one epoch ---
--- 0.38547849655151367 seconds for one epoch ---
--- 0.3203575611114502 seconds for one epoch ---
--- 0.3648262023925781 seconds for one epoch ---
--- 0.30620312690734863 seconds for one epoch ---
--- 0.39205265045166016 seconds for one epoch ---
--- 0.327986478805542 seconds for one epoch ---
--- 0.39101672172546387 seconds for one epoch ---
--- 0.3128397464752197 seconds for one epoch ---
--- 0.37962770462036133 seconds for one epoch ---
--- 0.3051333427429199 seconds for one epoch ---
--- 0.37032461166381836 seconds for one epoch ---
--- 0.29271531105041504 seconds for one epoch ---
--- 0.38245463371276855 seconds for one epoch ---
--- 0.29770755767822266 seconds for one epoch ---
--- 0.3874232769012451 seconds for one epoch ---
=========================
[[0.24435353]
 [0.24042203]
 [0.24425824]
 [0.24013762]
 [0.24012186]
 [0.88370365]
 [0.24493797]
 [0.24508728]
 [0.24003305]
 [0.25694177]
 [0.24989213]]
[[ 0.2757662 ]
 [-0.03677607]
 [ 0.27110392]
 [-0.01434112]
 [-0.01305584]
 [-3.3901315 ]
 [ 0.30349115]
 [ 0.31034657]
 [ 0.00580201]
 [-0.6830382 ]
 [ 0.49356613]]
--- 0.30618834495544434 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11990.1865234375, (7991.4766, 2.3545172, 3887.3428, 2.5318024)
   validation loss 6998.197265625, (6199.7993, 0.15346847, 689.2323, 2.5318024)
decoder loss ratio: 240190.988843, decoder SINDy loss  ratio: 1.487805
--- 0.26544618606567383 seconds for one epoch ---
--- 0.34159231185913086 seconds for one epoch ---
--- 0.3882923126220703 seconds for one epoch ---
--- 0.3129854202270508 seconds for one epoch ---
--- 0.38506054878234863 seconds for one epoch ---
--- 0.2881619930267334 seconds for one epoch ---
--- 0.4165976047515869 seconds for one epoch ---
--- 0.30449485778808594 seconds for one epoch ---
--- 0.40961217880249023 seconds for one epoch ---
--- 0.307361364364624 seconds for one epoch ---
--- 0.4007432460784912 seconds for one epoch ---
--- 0.3231379985809326 seconds for one epoch ---
--- 0.370943546295166 seconds for one epoch ---
--- 0.3472888469696045 seconds for one epoch ---
--- 0.3722496032714844 seconds for one epoch ---
--- 0.31296610832214355 seconds for one epoch ---
--- 0.39389705657958984 seconds for one epoch ---
--- 0.30347561836242676 seconds for one epoch ---
--- 0.3874785900115967 seconds for one epoch ---
--- 0.29581642150878906 seconds for one epoch ---
--- 0.38645100593566895 seconds for one epoch ---
--- 0.3007476329803467 seconds for one epoch ---
--- 0.38003087043762207 seconds for one epoch ---
--- 0.31995081901550293 seconds for one epoch ---
=========================
[[0.19062935]
 [0.19243938]
 [0.19995424]
 [0.1911673 ]
 [0.19054064]
 [0.9325362 ]
 [0.19421655]
 [0.19573471]
 [0.19033737]
 [0.22159058]
 [0.2014697 ]]
[[-2.5861803e-02]
 [-1.4506036e-01]
 [ 4.6519062e-01]
 [ 6.4247385e-02]
 [ 1.9251779e-02]
 [-3.7596636e+00]
 [ 2.4026608e-01]
 [ 3.0976319e-01]
 [-3.7570326e-03]
 [-9.1033971e-01]
 [ 5.1148105e-01]]
--- 0.25171589851379395 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8960.6240234375, (4488.5913, 1.0205547, 4350.455, 2.5318363)
   validation loss 3284.353515625, (2581.2263, 0.12663984, 582.4433, 2.5318363)
decoder loss ratio: 100001.188779, decoder SINDy loss  ratio: 1.257286
--- 0.29810261726379395 seconds for one epoch ---
--- 0.3710606098175049 seconds for one epoch ---
--- 0.31065940856933594 seconds for one epoch ---
--- 0.4008777141571045 seconds for one epoch ---
--- 0.3317258358001709 seconds for one epoch ---
--- 0.40503835678100586 seconds for one epoch ---
--- 0.2933166027069092 seconds for one epoch ---
--- 0.41315150260925293 seconds for one epoch ---
--- 0.3275876045227051 seconds for one epoch ---
--- 0.39795899391174316 seconds for one epoch ---
--- 0.285846471786499 seconds for one epoch ---
--- 0.3826172351837158 seconds for one epoch ---
--- 0.3194310665130615 seconds for one epoch ---
--- 0.34914350509643555 seconds for one epoch ---
--- 0.3266897201538086 seconds for one epoch ---
--- 0.42013001441955566 seconds for one epoch ---
--- 0.3086886405944824 seconds for one epoch ---
--- 0.40702295303344727 seconds for one epoch ---
--- 0.28487610816955566 seconds for one epoch ---
--- 0.38707828521728516 seconds for one epoch ---
--- 0.30746960639953613 seconds for one epoch ---
--- 0.40254855155944824 seconds for one epoch ---
--- 0.297835111618042 seconds for one epoch ---
--- 0.397960901260376 seconds for one epoch ---
=========================
[[0.15832195]
 [0.15722501]
 [0.1676656 ]
 [0.15618393]
 [0.15434311]
 [0.9555086 ]
 [0.15763704]
 [0.1598283 ]
 [0.15444818]
 [0.20046999]
 [0.16545133]]
[[-2.3483887e-01]
 [-1.8010208e-01]
 [ 5.5589241e-01]
 [ 1.2219169e-01]
 [ 5.7336257e-04]
 [-4.0266633e+00]
 [ 2.0133543e-01]
 [ 3.0171093e-01]
 [-8.3527211e-03]
 [-1.0684363e+00]
 [ 4.9552265e-01]]
--- 0.2980170249938965 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7965.916015625, (4573.187, 0.97603005, 3262.935, 2.5318656)
   validation loss 5070.17041015625, (4429.3467, 0.085007556, 511.9208, 2.5318656)
decoder loss ratio: 171600.580055, decoder SINDy loss  ratio: 1.105053
--- 0.27495241165161133 seconds for one epoch ---
--- 0.3232998847961426 seconds for one epoch ---
--- 0.3936805725097656 seconds for one epoch ---
--- 0.29653286933898926 seconds for one epoch ---
--- 0.3838956356048584 seconds for one epoch ---
--- 0.29251909255981445 seconds for one epoch ---
--- 0.3886229991912842 seconds for one epoch ---
--- 0.2980635166168213 seconds for one epoch ---
--- 0.4128241539001465 seconds for one epoch ---
--- 0.3045632839202881 seconds for one epoch ---
--- 0.3994588851928711 seconds for one epoch ---
--- 0.310499906539917 seconds for one epoch ---
--- 0.40865540504455566 seconds for one epoch ---
--- 0.32752418518066406 seconds for one epoch ---
--- 0.43714046478271484 seconds for one epoch ---
--- 0.41530370712280273 seconds for one epoch ---
--- 0.3985614776611328 seconds for one epoch ---
--- 0.3105778694152832 seconds for one epoch ---
--- 0.3940556049346924 seconds for one epoch ---
--- 0.30959439277648926 seconds for one epoch ---
--- 0.4098060131072998 seconds for one epoch ---
--- 0.3181636333465576 seconds for one epoch ---
--- 0.39835262298583984 seconds for one epoch ---
--- 0.31035733222961426 seconds for one epoch ---
=========================
[[0.13098693]
 [0.12814406]
 [0.1423371 ]
 [0.1264943 ]
 [0.12378219]
 [0.9639574 ]
 [0.1274459 ]
 [0.1293612 ]
 [0.12379806]
 [0.18288866]
 [0.13575065]]
[[-0.3628646 ]
 [-0.24977227]
 [ 0.66461474]
 [ 0.1707874 ]
 [ 0.00718162]
 [-4.1672497 ]
 [ 0.21780093]
 [ 0.30120713]
 [-0.00831444]
 [-1.1721734 ]
 [ 0.5106298 ]]
--- 0.2553689479827881 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9922.884765625, (3780.8118, 1.1904855, 6005.244, 2.5318854)
   validation loss 2207.244873046875, (1600.1007, 0.07660791, 471.42905, 2.5318854)
decoder loss ratio: 61990.679325, decoder SINDy loss  ratio: 1.017646
--- 0.3173496723175049 seconds for one epoch ---
--- 0.41196751594543457 seconds for one epoch ---
--- 0.30663537979125977 seconds for one epoch ---
--- 0.40537452697753906 seconds for one epoch ---
--- 0.32367491722106934 seconds for one epoch ---
--- 0.40395617485046387 seconds for one epoch ---
--- 0.29069972038269043 seconds for one epoch ---
--- 0.4097886085510254 seconds for one epoch ---
--- 0.3386411666870117 seconds for one epoch ---
--- 0.40614938735961914 seconds for one epoch ---
--- 0.2913796901702881 seconds for one epoch ---
--- 0.3977992534637451 seconds for one epoch ---
--- 0.29911303520202637 seconds for one epoch ---
--- 0.40338969230651855 seconds for one epoch ---
--- 0.291715145111084 seconds for one epoch ---
--- 0.42000412940979004 seconds for one epoch ---
--- 0.30362486839294434 seconds for one epoch ---
--- 0.41206836700439453 seconds for one epoch ---
--- 0.30182361602783203 seconds for one epoch ---
--- 0.41687583923339844 seconds for one epoch ---
--- 0.32909655570983887 seconds for one epoch ---
--- 0.40370988845825195 seconds for one epoch ---
--- 0.3105473518371582 seconds for one epoch ---
--- 0.40903806686401367 seconds for one epoch ---
=========================
[[0.11147545]
 [0.10650122]
 [0.12538418]
 [0.10554987]
 [0.10149188]
 [0.9655633 ]
 [0.10481036]
 [0.10773505]
 [0.10140745]
 [0.17318773]
 [0.11501217]]
[[-4.4710258e-01]
 [-2.7339694e-01]
 [ 7.5385302e-01]
 [ 2.3244953e-01]
 [ 8.6839786e-03]
 [-4.2074299e+00]
 [ 1.9823433e-01]
 [ 3.2212955e-01]
 [ 2.8245305e-03]
 [-1.2566484e+00]
 [ 5.4312259e-01]]
--- 0.32378673553466797 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7562.0830078125, (3481.2383, 0.4456203, 3938.518, 2.531897)
   validation loss 3583.79736328125, (2990.223, 0.0718232, 451.62152, 2.531897)
decoder loss ratio: 115846.426416, decoder SINDy loss  ratio: 0.974889
--- 0.2509787082672119 seconds for one epoch ---
--- 0.3038947582244873 seconds for one epoch ---
--- 0.43697190284729004 seconds for one epoch ---
--- 0.3056800365447998 seconds for one epoch ---
--- 0.3948228359222412 seconds for one epoch ---
--- 0.31069135665893555 seconds for one epoch ---
--- 0.4260857105255127 seconds for one epoch ---
--- 0.31717658042907715 seconds for one epoch ---
--- 0.43837594985961914 seconds for one epoch ---
--- 0.30635857582092285 seconds for one epoch ---
--- 0.4189732074737549 seconds for one epoch ---
--- 0.3244459629058838 seconds for one epoch ---
--- 0.4172983169555664 seconds for one epoch ---
--- 0.3126993179321289 seconds for one epoch ---
--- 0.41303253173828125 seconds for one epoch ---
--- 0.3108255863189697 seconds for one epoch ---
--- 0.4279181957244873 seconds for one epoch ---
--- 0.2987244129180908 seconds for one epoch ---
--- 0.4166426658630371 seconds for one epoch ---
--- 0.3008415699005127 seconds for one epoch ---
--- 0.4227888584136963 seconds for one epoch ---
--- 0.29949426651000977 seconds for one epoch ---
--- 0.40900588035583496 seconds for one epoch ---
--- 0.2964968681335449 seconds for one epoch ---
=========================
[[0.09573198]
 [0.08796649]
 [0.11056098]
 [0.08724001]
 [0.08241984]
 [0.9667999 ]
 [0.08571411]
 [0.08901022]
 [0.08228671]
 [0.16965522]
 [0.09667565]]
[[-5.3235316e-01]
 [-2.9282632e-01]
 [ 8.1322390e-01]
 [ 2.6365817e-01]
 [ 1.2580829e-02]
 [-4.2401109e+00]
 [ 1.9649172e-01]
 [ 3.3208093e-01]
 [-3.5697811e-03]
 [-1.3478051e+00]
 [ 5.5528206e-01]]
--- 0.2523367404937744 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5627.4521484375, (3214.0818, 3.3104558, 2261.5605, 2.5319076)
   validation loss 3784.02783203125, (3196.143, 0.057536557, 439.3275, 2.5319076)
decoder loss ratio: 123824.131141, decoder SINDy loss  ratio: 0.948350
--- 0.3314485549926758 seconds for one epoch ---
--- 0.4244053363800049 seconds for one epoch ---
--- 0.30507493019104004 seconds for one epoch ---
--- 0.42270350456237793 seconds for one epoch ---
--- 0.3009462356567383 seconds for one epoch ---
--- 0.42864060401916504 seconds for one epoch ---
--- 0.3047518730163574 seconds for one epoch ---
--- 0.448352575302124 seconds for one epoch ---
--- 0.309157133102417 seconds for one epoch ---
--- 0.4146554470062256 seconds for one epoch ---
--- 0.3173983097076416 seconds for one epoch ---
--- 0.4342477321624756 seconds for one epoch ---
--- 0.32082390785217285 seconds for one epoch ---
--- 0.4145064353942871 seconds for one epoch ---
--- 0.31360673904418945 seconds for one epoch ---
--- 0.42786431312561035 seconds for one epoch ---
--- 0.3104419708251953 seconds for one epoch ---
--- 0.4353339672088623 seconds for one epoch ---
--- 0.32364559173583984 seconds for one epoch ---
--- 0.4357268810272217 seconds for one epoch ---
--- 0.3044259548187256 seconds for one epoch ---
--- 0.4484832286834717 seconds for one epoch ---
--- 0.2888824939727783 seconds for one epoch ---
--- 0.4484372138977051 seconds for one epoch ---
=========================
[[0.08667101]
 [0.07569087]
 [0.10117358]
 [0.07383952]
 [0.068513  ]
 [0.9668432 ]
 [0.07192173]
 [0.07508991]
 [0.06830179]
 [0.1798631 ]
 [0.08461117]]
[[-0.6372661 ]
 [-0.35247996]
 [ 0.87123305]
 [ 0.28472978]
 [ 0.01887269]
 [-4.2494316 ]
 [ 0.20385095]
 [ 0.33143064]
 [-0.00490494]
 [-1.4717393 ]
 [ 0.5941509 ]]
--- 0.2981245517730713 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4267.0048828125, (2190.914, 0.41410673, 1921.6783, 2.531917)
   validation loss 1801.31591796875, (1207.1927, 0.069242895, 440.05502, 2.531917)
decoder loss ratio: 46768.742876, decoder SINDy loss  ratio: 0.949921
--- 0.2632119655609131 seconds for one epoch ---
--- 0.2889420986175537 seconds for one epoch ---
--- 0.42273998260498047 seconds for one epoch ---
--- 0.2942218780517578 seconds for one epoch ---
--- 0.4355893135070801 seconds for one epoch ---
--- 0.30740833282470703 seconds for one epoch ---
--- 0.43991947174072266 seconds for one epoch ---
--- 0.2963283061981201 seconds for one epoch ---
--- 0.4312245845794678 seconds for one epoch ---
--- 0.2970845699310303 seconds for one epoch ---
--- 0.4264400005340576 seconds for one epoch ---
--- 0.28166747093200684 seconds for one epoch ---
--- 0.4331977367401123 seconds for one epoch ---
--- 0.2993185520172119 seconds for one epoch ---
--- 0.44698572158813477 seconds for one epoch ---
--- 0.3232686519622803 seconds for one epoch ---
--- 0.4536473751068115 seconds for one epoch ---
--- 0.31063365936279297 seconds for one epoch ---
--- 0.4578821659088135 seconds for one epoch ---
--- 0.3139479160308838 seconds for one epoch ---
--- 0.46121811866760254 seconds for one epoch ---
--- 0.33276844024658203 seconds for one epoch ---
--- 0.45035219192504883 seconds for one epoch ---
--- 0.31151747703552246 seconds for one epoch ---
=========================
[[0.07911085]
 [0.06426656]
 [0.09246692]
 [0.06198751]
 [0.05656077]
 [0.9655452 ]
 [0.06035582]
 [0.06315621]
 [0.05616431]
 [0.19193256]
 [0.0720716 ]]
[[-7.1617305e-01]
 [-3.7090424e-01]
 [ 9.0821660e-01]
 [ 2.9046923e-01]
 [ 2.6453109e-02]
 [-4.2349610e+00]
 [ 2.2419490e-01]
 [ 3.3325532e-01]
 [-6.4460002e-04]
 [-1.5749415e+00]
 [ 5.7937360e-01]]
--- 0.266965389251709 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6919.44970703125, (3311.164, 1.3467382, 3446.8206, 2.5319233)
   validation loss 3685.185302734375, (3081.688, 0.04573422, 443.33276, 2.5319233)
decoder loss ratio: 119389.942712, decoder SINDy loss  ratio: 0.956996
--- 0.32562732696533203 seconds for one epoch ---
--- 0.459057092666626 seconds for one epoch ---
--- 0.3279423713684082 seconds for one epoch ---
--- 0.4514782428741455 seconds for one epoch ---
--- 0.31318116188049316 seconds for one epoch ---
--- 0.4473745822906494 seconds for one epoch ---
--- 0.29285335540771484 seconds for one epoch ---
--- 0.4514484405517578 seconds for one epoch ---
--- 0.28797125816345215 seconds for one epoch ---
--- 0.45125246047973633 seconds for one epoch ---
--- 0.2979893684387207 seconds for one epoch ---
--- 0.46017026901245117 seconds for one epoch ---
--- 0.2789008617401123 seconds for one epoch ---
--- 0.4647073745727539 seconds for one epoch ---
--- 0.2794790267944336 seconds for one epoch ---
--- 0.4473567008972168 seconds for one epoch ---
--- 0.3084142208099365 seconds for one epoch ---
--- 0.4516923427581787 seconds for one epoch ---
--- 0.300262451171875 seconds for one epoch ---
--- 0.4520761966705322 seconds for one epoch ---
--- 0.3015897274017334 seconds for one epoch ---
--- 0.4617772102355957 seconds for one epoch ---
--- 0.30237913131713867 seconds for one epoch ---
--- 0.4556300640106201 seconds for one epoch ---
=========================
[[0.07737014]
 [0.05596993]
 [0.0828688 ]
 [0.0534992 ]
 [0.04792523]
 [0.96357316]
 [0.05117761]
 [0.05445776]
 [0.04734295]
 [0.22195704]
 [0.06367055]]
[[-0.8230886 ]
 [-0.38731524]
 [ 0.895373  ]
 [ 0.30330804]
 [ 0.04180389]
 [-4.208725  ]
 [ 0.20980428]
 [ 0.33751065]
 [-0.00496547]
 [-1.7189124 ]
 [ 0.5866864 ]]
--- 0.29184794425964355 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6475.6845703125, (3238.7456, 0.15867299, 3071.3977, 2.5319288)
   validation loss 1476.6851806640625, (965.2754, 0.04393014, 345.98306, 2.5319288)
decoder loss ratio: 37396.444425, decoder SINDy loss  ratio: 0.746853
--- 0.25849461555480957 seconds for one epoch ---
--- 0.31239938735961914 seconds for one epoch ---
--- 0.4544057846069336 seconds for one epoch ---
--- 0.29493165016174316 seconds for one epoch ---
--- 0.475461483001709 seconds for one epoch ---
--- 0.30400824546813965 seconds for one epoch ---
--- 0.4725008010864258 seconds for one epoch ---
--- 0.29745006561279297 seconds for one epoch ---
--- 0.4749331474304199 seconds for one epoch ---
--- 0.29559993743896484 seconds for one epoch ---
--- 0.45699524879455566 seconds for one epoch ---
--- 0.314650297164917 seconds for one epoch ---
--- 0.47179174423217773 seconds for one epoch ---
--- 0.3205525875091553 seconds for one epoch ---
--- 0.45830655097961426 seconds for one epoch ---
--- 0.29924941062927246 seconds for one epoch ---
--- 0.48003244400024414 seconds for one epoch ---
--- 0.3113105297088623 seconds for one epoch ---
--- 0.47397303581237793 seconds for one epoch ---
--- 0.2962610721588135 seconds for one epoch ---
--- 0.4655783176422119 seconds for one epoch ---
--- 0.3000667095184326 seconds for one epoch ---
--- 0.48102307319641113 seconds for one epoch ---
--- 0.32411885261535645 seconds for one epoch ---
=========================
[[0.07578026]
 [0.04984536]
 [0.07405496]
 [0.04563185]
 [0.04011195]
 [0.96026194]
 [0.04318765]
 [0.04697432]
 [0.0396335 ]
 [0.2502766 ]
 [0.0559458 ]]
[[-0.8993532 ]
 [-0.4323398 ]
 [ 0.8779867 ]
 [ 0.29538202]
 [ 0.03473955]
 [-4.1638713 ]
 [ 0.19566213]
 [ 0.343007  ]
 [-0.00448859]
 [-1.8317583 ]
 [ 0.5833627 ]]
--- 0.25653910636901855 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6709.93017578125, (2651.7888, 0.73225236, 3888.5745, 2.531932)
   validation loss 2131.32568359375, (1620.6077, 0.052618444, 341.83044, 2.531932)
decoder loss ratio: 62785.154480, decoder SINDy loss  ratio: 0.737889
--- 0.298583984375 seconds for one epoch ---
--- 0.4706690311431885 seconds for one epoch ---
--- 0.30955052375793457 seconds for one epoch ---
--- 0.4762759208679199 seconds for one epoch ---
--- 0.33657002449035645 seconds for one epoch ---
--- 0.4710817337036133 seconds for one epoch ---
--- 0.3111569881439209 seconds for one epoch ---
--- 0.46761465072631836 seconds for one epoch ---
--- 0.32318592071533203 seconds for one epoch ---
--- 0.4455399513244629 seconds for one epoch ---
--- 0.3025383949279785 seconds for one epoch ---
--- 0.4827151298522949 seconds for one epoch ---
--- 0.30107736587524414 seconds for one epoch ---
--- 0.48981189727783203 seconds for one epoch ---
--- 0.2946147918701172 seconds for one epoch ---
--- 0.48123884201049805 seconds for one epoch ---
--- 0.30063462257385254 seconds for one epoch ---
--- 0.457716703414917 seconds for one epoch ---
--- 0.3120415210723877 seconds for one epoch ---
--- 0.4672431945800781 seconds for one epoch ---
--- 0.31922245025634766 seconds for one epoch ---
--- 0.48662853240966797 seconds for one epoch ---
--- 0.30353593826293945 seconds for one epoch ---
--- 0.481550931930542 seconds for one epoch ---
=========================
[[0.07628141]
 [0.04505295]
 [0.06749659]
 [0.03892512]
 [0.03427057]
 [0.9563344 ]
 [0.03741975]
 [0.04098338]
 [0.0339002 ]
 [0.28185812]
 [0.04992509]]
[[-9.6742845e-01]
 [-4.5588753e-01]
 [ 8.6448526e-01]
 [ 2.5537744e-01]
 [ 2.5806759e-02]
 [-4.1135559e+00]
 [ 1.9163032e-01]
 [ 3.3157668e-01]
 [-2.2730257e-03]
 [-1.9361041e+00]
 [ 5.7431614e-01]]
--- 0.3976256847381592 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6507.056640625, (2944.632, 5.594007, 3384.4531, 2.5319319)
   validation loss 1651.7568359375, (1154.4185, 0.06933453, 324.89124, 2.5319319)
decoder loss ratio: 44724.175184, decoder SINDy loss  ratio: 0.701323
--- 0.2452986240386963 seconds for one epoch ---
--- 0.29328060150146484 seconds for one epoch ---
--- 0.48013925552368164 seconds for one epoch ---
--- 0.3016395568847656 seconds for one epoch ---
--- 0.48700642585754395 seconds for one epoch ---
--- 0.30359363555908203 seconds for one epoch ---
--- 0.4828174114227295 seconds for one epoch ---
--- 0.3290879726409912 seconds for one epoch ---
--- 0.47992992401123047 seconds for one epoch ---
--- 0.3220090866088867 seconds for one epoch ---
--- 0.47252845764160156 seconds for one epoch ---
--- 0.3021414279937744 seconds for one epoch ---
--- 0.49756741523742676 seconds for one epoch ---
--- 0.3099331855773926 seconds for one epoch ---
--- 0.47584056854248047 seconds for one epoch ---
--- 0.290424108505249 seconds for one epoch ---
--- 0.4769628047943115 seconds for one epoch ---
--- 0.30237340927124023 seconds for one epoch ---
--- 0.4981212615966797 seconds for one epoch ---
--- 0.29556870460510254 seconds for one epoch ---
--- 0.4812431335449219 seconds for one epoch ---
--- 0.3248887062072754 seconds for one epoch ---
--- 0.5012273788452148 seconds for one epoch ---
--- 0.31068897247314453 seconds for one epoch ---
=========================
[[0.07612793]
 [0.04084508]
 [0.06111128]
 [0.03442123]
 [0.02937797]
 [0.94752926]
 [0.03249087]
 [0.03571857]
 [0.0289295 ]
 [0.3145682 ]
 [0.04529897]]
[[-1.0144680e+00]
 [-4.7452635e-01]
 [ 8.4374827e-01]
 [ 2.7238268e-01]
 [ 3.0185645e-02]
 [-4.0113587e+00]
 [ 1.9246797e-01]
 [ 3.1994760e-01]
 [ 1.9495735e-03]
 [-2.0320089e+00]
 [ 5.7986754e-01]]
--- 0.25881099700927734 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5882.7421875, (2106.9558, 0.66370213, 3599.544, 2.53193)
   validation loss 1936.869384765625, (1456.311, 0.06192205, 304.91745, 2.53193)
decoder loss ratio: 56420.017769, decoder SINDy loss  ratio: 0.658207
--- 0.29829883575439453 seconds for one epoch ---
--- 0.4669003486633301 seconds for one epoch ---
--- 0.28882813453674316 seconds for one epoch ---
--- 0.4853839874267578 seconds for one epoch ---
--- 0.29624366760253906 seconds for one epoch ---
--- 0.4824349880218506 seconds for one epoch ---
--- 0.2895638942718506 seconds for one epoch ---
--- 0.4844322204589844 seconds for one epoch ---
--- 0.2939929962158203 seconds for one epoch ---
--- 0.5005640983581543 seconds for one epoch ---
--- 0.28959131240844727 seconds for one epoch ---
--- 0.49731922149658203 seconds for one epoch ---
--- 0.32787609100341797 seconds for one epoch ---
--- 0.4918954372406006 seconds for one epoch ---
--- 0.32731008529663086 seconds for one epoch ---
--- 0.48578834533691406 seconds for one epoch ---
--- 0.32346391677856445 seconds for one epoch ---
--- 0.5153124332427979 seconds for one epoch ---
--- 0.3343539237976074 seconds for one epoch ---
--- 0.5115201473236084 seconds for one epoch ---
--- 0.31712937355041504 seconds for one epoch ---
--- 0.5046482086181641 seconds for one epoch ---
--- 0.2908961772918701 seconds for one epoch ---
--- 0.5030245780944824 seconds for one epoch ---
=========================
[[0.07621339]
 [0.0380207 ]
 [0.05621605]
 [0.03053504]
 [0.02561007]
 [0.9370573 ]
 [0.0290582 ]
 [0.03235238]
 [0.02524775]
 [0.34365058]
 [0.0442159 ]]
[[-1.0487063e+00]
 [-4.9556214e-01]
 [ 8.2596880e-01]
 [ 2.6415044e-01]
 [ 2.5513913e-02]
 [-3.9085844e+00]
 [ 2.0337287e-01]
 [ 3.3036718e-01]
 [ 2.7012571e-03]
 [-2.1099043e+00]
 [ 6.3178837e-01]]
--- 0.29093003273010254 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3568.8212890625, (1583.1053, 0.2433665, 1806.3141, 2.5319273)
   validation loss 1121.5152587890625, (604.71594, 0.093859576, 337.54694, 2.5319273)
decoder loss ratio: 23427.745441, decoder SINDy loss  ratio: 0.728643
--- 0.248612642288208 seconds for one epoch ---
--- 0.3264048099517822 seconds for one epoch ---
--- 0.5133965015411377 seconds for one epoch ---
--- 0.32631540298461914 seconds for one epoch ---
--- 0.5081031322479248 seconds for one epoch ---
--- 0.30960893630981445 seconds for one epoch ---
--- 0.4948897361755371 seconds for one epoch ---
--- 0.2841000556945801 seconds for one epoch ---
--- 0.4920334815979004 seconds for one epoch ---
--- 0.2992739677429199 seconds for one epoch ---
--- 0.49422526359558105 seconds for one epoch ---
--- 0.28302645683288574 seconds for one epoch ---
--- 0.48157215118408203 seconds for one epoch ---
--- 0.3060600757598877 seconds for one epoch ---
--- 0.5074198246002197 seconds for one epoch ---
--- 0.28610777854919434 seconds for one epoch ---
--- 0.5284132957458496 seconds for one epoch ---
--- 0.28799891471862793 seconds for one epoch ---
--- 0.5101377964019775 seconds for one epoch ---
--- 0.29456019401550293 seconds for one epoch ---
--- 0.5198500156402588 seconds for one epoch ---
--- 0.3208732604980469 seconds for one epoch ---
--- 0.5104193687438965 seconds for one epoch ---
--- 0.3131392002105713 seconds for one epoch ---
=========================
[[0.08008426]
 [0.03561142]
 [0.05171664]
 [0.02685558]
 [0.02222047]
 [0.92871124]
 [0.02532585]
 [0.02872875]
 [0.02208612]
 [0.3843326 ]
 [0.04153034]]
[[-1.109355  ]
 [-0.5147437 ]
 [ 0.80705124]
 [ 0.2459218 ]
 [ 0.01581721]
 [-3.8380911 ]
 [ 0.1806637 ]
 [ 0.3160883 ]
 [-0.00734342]
 [-2.209377  ]
 [ 0.6411141 ]]
--- 0.25418567657470703 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5245.80126953125, (2188.3445, 0.33086932, 2875.7117, 2.5319276)
   validation loss 2582.71337890625, (2013.8833, 0.054779086, 387.36078, 2.5319276)
decoder loss ratio: 78021.335327, decoder SINDy loss  ratio: 0.836173
--- 0.3137178421020508 seconds for one epoch ---
--- 0.5103163719177246 seconds for one epoch ---
--- 0.3041117191314697 seconds for one epoch ---
--- 0.5215051174163818 seconds for one epoch ---
--- 0.29165220260620117 seconds for one epoch ---
--- 0.5133473873138428 seconds for one epoch ---
--- 0.30655455589294434 seconds for one epoch ---
--- 0.5176823139190674 seconds for one epoch ---
--- 0.30559659004211426 seconds for one epoch ---
--- 0.5305571556091309 seconds for one epoch ---
--- 0.2950272560119629 seconds for one epoch ---
--- 0.5136492252349854 seconds for one epoch ---
--- 0.2940378189086914 seconds for one epoch ---
--- 0.5132381916046143 seconds for one epoch ---
--- 0.30647706985473633 seconds for one epoch ---
--- 0.5375018119812012 seconds for one epoch ---
--- 0.2963871955871582 seconds for one epoch ---
--- 0.5426549911499023 seconds for one epoch ---
--- 0.3319263458251953 seconds for one epoch ---
--- 0.511164665222168 seconds for one epoch ---
--- 0.3255009651184082 seconds for one epoch ---
--- 0.5176758766174316 seconds for one epoch ---
--- 0.3148818016052246 seconds for one epoch ---
--- 0.5412044525146484 seconds for one epoch ---
=========================
[[0.08301219]
 [0.03297821]
 [0.04911718]
 [0.02474329]
 [0.01997109]
 [0.9143668 ]
 [0.02252177]
 [0.02581262]
 [0.01957501]
 [0.42205775]
 [0.03793732]]
[[-1.1510109e+00]
 [-5.0872999e-01]
 [ 8.0346012e-01]
 [ 2.5753051e-01]
 [ 2.6190205e-02]
 [-3.7318254e+00]
 [ 1.6246162e-01]
 [ 2.9776546e-01]
 [ 1.3766551e-03]
 [-2.2964172e+00]
 [ 6.1737168e-01]]
--- 0.30066680908203125 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3252.869140625, (1866.4792, 0.5178202, 1201.4636, 2.5319238)
   validation loss 2916.17578125, (2270.5203, 0.045571588, 461.20132, 2.5319238)
decoder loss ratio: 87963.896811, decoder SINDy loss  ratio: 0.995568
THRESHOLDING: 2 active coefficients
--- 0.5103292465209961 seconds for one epoch ---
--- 0.30129528045654297 seconds for one epoch ---
--- 0.5452525615692139 seconds for one epoch ---
--- 0.30617547035217285 seconds for one epoch ---
--- 0.5052003860473633 seconds for one epoch ---
--- 0.32494354248046875 seconds for one epoch ---
--- 0.5137317180633545 seconds for one epoch ---
--- 0.3301115036010742 seconds for one epoch ---
--- 0.5207176208496094 seconds for one epoch ---
--- 0.3259429931640625 seconds for one epoch ---
--- 0.5228807926177979 seconds for one epoch ---
--- 0.3130607604980469 seconds for one epoch ---
--- 0.5318698883056641 seconds for one epoch ---
--- 0.297654390335083 seconds for one epoch ---
--- 0.5264675617218018 seconds for one epoch ---
--- 0.3005087375640869 seconds for one epoch ---
--- 0.5479989051818848 seconds for one epoch ---
--- 0.2953524589538574 seconds for one epoch ---
--- 0.5109434127807617 seconds for one epoch ---
--- 0.2999882698059082 seconds for one epoch ---
--- 0.5439755916595459 seconds for one epoch ---
--- 0.3058807849884033 seconds for one epoch ---
--- 0.5397841930389404 seconds for one epoch ---
--- 0.29297327995300293 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5627016 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24677972]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.600016 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.8722624]
 [ 0.       ]]
--- 0.2613048553466797 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4529.05615234375, (1483.7859, 2.2079854, 3042.7253, 0.3369561)
   validation loss 1595.7977294921875, (1256.8556, 0.067567185, 338.53763, 0.3369561)
decoder loss ratio: 48692.767586, decoder SINDy loss  ratio: 0.730781
--- 0.29677271842956543 seconds for one epoch ---
--- 0.5262784957885742 seconds for one epoch ---
--- 0.3285558223724365 seconds for one epoch ---
--- 0.5298497676849365 seconds for one epoch ---
--- 0.3137938976287842 seconds for one epoch ---
--- 0.5419456958770752 seconds for one epoch ---
--- 0.32024264335632324 seconds for one epoch ---
--- 0.5174376964569092 seconds for one epoch ---
--- 0.30425071716308594 seconds for one epoch ---
--- 0.5304923057556152 seconds for one epoch ---
--- 0.2884540557861328 seconds for one epoch ---
--- 0.5223202705383301 seconds for one epoch ---
--- 0.2892031669616699 seconds for one epoch ---
--- 0.5189590454101562 seconds for one epoch ---
--- 0.29701757431030273 seconds for one epoch ---
--- 0.5260448455810547 seconds for one epoch ---
--- 0.28276586532592773 seconds for one epoch ---
--- 0.5355603694915771 seconds for one epoch ---
--- 0.31286120414733887 seconds for one epoch ---
--- 0.5365352630615234 seconds for one epoch ---
--- 0.31594347953796387 seconds for one epoch ---
--- 0.5546047687530518 seconds for one epoch ---
--- 0.320723295211792 seconds for one epoch ---
--- 0.53080153465271 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31023258]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17730452]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.0441961]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.6518751]
 [ 0.       ]]
--- 0.31288957595825195 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3106.8515625, (1747.1779, 0.48680317, 1358.9163, 0.27055588)
   validation loss 1008.7799072265625, (713.3485, 0.094282, 295.06653, 0.27055588)
decoder loss ratio: 27636.359734, decoder SINDy loss  ratio: 0.636943
--- 0.24241399765014648 seconds for one epoch ---
--- 0.30680060386657715 seconds for one epoch ---
--- 0.5368070602416992 seconds for one epoch ---
--- 0.3066539764404297 seconds for one epoch ---
--- 0.5344579219818115 seconds for one epoch ---
--- 0.2944352626800537 seconds for one epoch ---
--- 0.5342199802398682 seconds for one epoch ---
--- 0.2935919761657715 seconds for one epoch ---
--- 0.5507960319519043 seconds for one epoch ---
--- 0.29506826400756836 seconds for one epoch ---
--- 0.578221321105957 seconds for one epoch ---
--- 0.2984466552734375 seconds for one epoch ---
--- 0.5611662864685059 seconds for one epoch ---
--- 0.3017721176147461 seconds for one epoch ---
--- 0.5742449760437012 seconds for one epoch ---
--- 0.30382561683654785 seconds for one epoch ---
--- 0.5562992095947266 seconds for one epoch ---
--- 0.2943840026855469 seconds for one epoch ---
--- 0.5517446994781494 seconds for one epoch ---
--- 0.2918252944946289 seconds for one epoch ---
--- 0.5436761379241943 seconds for one epoch ---
--- 0.28951191902160645 seconds for one epoch ---
--- 0.5562496185302734 seconds for one epoch ---
--- 0.3023688793182373 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19942982]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15361814]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.7333714]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5643978]
 [ 0.       ]]
--- 0.25066041946411133 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4146.32421875, (1548.5599, 0.40944055, 2597.1157, 0.23926432)
   validation loss 1700.806640625, (1398.0177, 0.12686208, 302.42288, 0.23926432)
decoder loss ratio: 54161.632771, decoder SINDy loss  ratio: 0.652822
--- 0.30420732498168945 seconds for one epoch ---
--- 0.5590152740478516 seconds for one epoch ---
--- 0.2844219207763672 seconds for one epoch ---
--- 0.5500845909118652 seconds for one epoch ---
--- 0.29746389389038086 seconds for one epoch ---
--- 0.5534493923187256 seconds for one epoch ---
--- 0.3088266849517822 seconds for one epoch ---
--- 0.565173864364624 seconds for one epoch ---
--- 0.2963144779205322 seconds for one epoch ---
--- 0.5659871101379395 seconds for one epoch ---
--- 0.3130350112915039 seconds for one epoch ---
--- 0.5576276779174805 seconds for one epoch ---
--- 0.3223435878753662 seconds for one epoch ---
--- 0.5691156387329102 seconds for one epoch ---
--- 0.34328317642211914 seconds for one epoch ---
--- 0.5474724769592285 seconds for one epoch ---
--- 0.325941801071167 seconds for one epoch ---
--- 0.5598156452178955 seconds for one epoch ---
--- 0.3213920593261719 seconds for one epoch ---
--- 0.5630631446838379 seconds for one epoch ---
--- 0.2850046157836914 seconds for one epoch ---
--- 0.5495204925537109 seconds for one epoch ---
--- 0.2903256416320801 seconds for one epoch ---
--- 0.5622913837432861 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16300377]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1476699 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.6056366]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5433973]
 [ 0.       ]]
--- 0.2929863929748535 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5504.72314453125, (3021.564, 1.6316172, 2481.2996, 0.22817245)
   validation loss 4529.34619140625, (4126.4546, 0.10215823, 402.5615, 0.22817245)
decoder loss ratio: 159866.014651, decoder SINDy loss  ratio: 0.868986
--- 0.2609837055206299 seconds for one epoch ---
--- 0.2972583770751953 seconds for one epoch ---
--- 0.5805821418762207 seconds for one epoch ---
--- 0.29822278022766113 seconds for one epoch ---
--- 0.5535871982574463 seconds for one epoch ---
--- 0.2992289066314697 seconds for one epoch ---
--- 0.5698306560516357 seconds for one epoch ---
--- 0.3066573143005371 seconds for one epoch ---
--- 0.57297682762146 seconds for one epoch ---
--- 0.3185610771179199 seconds for one epoch ---
--- 0.5935733318328857 seconds for one epoch ---
--- 0.3070685863494873 seconds for one epoch ---
--- 0.5721867084503174 seconds for one epoch ---
--- 0.33632969856262207 seconds for one epoch ---
--- 0.5493614673614502 seconds for one epoch ---
--- 0.2959866523742676 seconds for one epoch ---
--- 0.5698492527008057 seconds for one epoch ---
--- 0.3179502487182617 seconds for one epoch ---
--- 0.5820944309234619 seconds for one epoch ---
--- 0.2976062297821045 seconds for one epoch ---
--- 0.5795629024505615 seconds for one epoch ---
--- 0.3066747188568115 seconds for one epoch ---
--- 0.6069521903991699 seconds for one epoch ---
--- 0.29744791984558105 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1448791 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14770098]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.5350105]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5469847]
 [ 0.       ]]
--- 0.2565467357635498 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3165.141845703125, (1133.4414, 0.26412967, 2031.2129, 0.22348101)
   validation loss 1028.304931640625, (730.0875, 0.076164514, 297.91776, 0.22348101)
decoder loss ratio: 28284.858183, decoder SINDy loss  ratio: 0.643097
--- 0.30164051055908203 seconds for one epoch ---
--- 0.5432925224304199 seconds for one epoch ---
--- 0.409670352935791 seconds for one epoch ---
--- 0.569598913192749 seconds for one epoch ---
--- 0.2843968868255615 seconds for one epoch ---
--- 0.5809144973754883 seconds for one epoch ---
--- 0.2949814796447754 seconds for one epoch ---
--- 0.592249870300293 seconds for one epoch ---
--- 0.30155253410339355 seconds for one epoch ---
--- 0.6006450653076172 seconds for one epoch ---
--- 0.3177351951599121 seconds for one epoch ---
--- 0.5816440582275391 seconds for one epoch ---
--- 0.3310511112213135 seconds for one epoch ---
--- 0.6005709171295166 seconds for one epoch ---
--- 0.32593536376953125 seconds for one epoch ---
--- 0.5930447578430176 seconds for one epoch ---
--- 0.3410766124725342 seconds for one epoch ---
--- 0.5980799198150635 seconds for one epoch ---
--- 0.34949421882629395 seconds for one epoch ---
--- 0.5759334564208984 seconds for one epoch ---
--- 0.3243260383605957 seconds for one epoch ---
--- 0.5922346115112305 seconds for one epoch ---
--- 0.31879401206970215 seconds for one epoch ---
--- 0.5957956314086914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13822916]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15463859]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.5087749]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5781083]
 [ 0.       ]]
--- 0.3004109859466553 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4073.2353515625, (1919.5707, 0.6366934, 2152.8037, 0.22423987)
   validation loss 924.5015869140625, (605.74176, 0.117515035, 318.41806, 0.22423987)
decoder loss ratio: 23467.487406, decoder SINDy loss  ratio: 0.687350
--- 0.25445079803466797 seconds for one epoch ---
--- 0.3059406280517578 seconds for one epoch ---
--- 0.5830862522125244 seconds for one epoch ---
--- 0.2858767509460449 seconds for one epoch ---
--- 0.6123552322387695 seconds for one epoch ---
--- 0.29462504386901855 seconds for one epoch ---
--- 0.582355260848999 seconds for one epoch ---
--- 0.2917509078979492 seconds for one epoch ---
--- 0.5809931755065918 seconds for one epoch ---
--- 0.3082609176635742 seconds for one epoch ---
--- 0.5851390361785889 seconds for one epoch ---
--- 0.30894947052001953 seconds for one epoch ---
--- 0.6122291088104248 seconds for one epoch ---
--- 0.32511115074157715 seconds for one epoch ---
--- 0.6106789112091064 seconds for one epoch ---
--- 0.33501553535461426 seconds for one epoch ---
--- 0.6136727333068848 seconds for one epoch ---
--- 0.32928943634033203 seconds for one epoch ---
--- 0.6083269119262695 seconds for one epoch ---
--- 0.3269379138946533 seconds for one epoch ---
--- 0.6012771129608154 seconds for one epoch ---
--- 0.33649468421936035 seconds for one epoch ---
--- 0.6037228107452393 seconds for one epoch ---
--- 0.29390525817871094 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13320722]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1591548 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4887279]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5982531]
 [ 0.       ]]
--- 0.26862335205078125 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3466.27392578125, (1544.7871, 0.5609881, 1920.7018, 0.22413968)
   validation loss 1167.245361328125, (810.78064, 0.20100442, 356.03958, 0.22413968)
decoder loss ratio: 31411.049557, decoder SINDy loss  ratio: 0.768562
--- 0.309603214263916 seconds for one epoch ---
--- 0.6139316558837891 seconds for one epoch ---
--- 0.3101208209991455 seconds for one epoch ---
--- 0.5797779560089111 seconds for one epoch ---
--- 0.29311537742614746 seconds for one epoch ---
--- 0.5944826602935791 seconds for one epoch ---
--- 0.28581905364990234 seconds for one epoch ---
--- 0.6072204113006592 seconds for one epoch ---
--- 0.29095888137817383 seconds for one epoch ---
--- 0.608842134475708 seconds for one epoch ---
--- 0.2978818416595459 seconds for one epoch ---
--- 0.629683256149292 seconds for one epoch ---
--- 0.2993505001068115 seconds for one epoch ---
--- 0.6212522983551025 seconds for one epoch ---
--- 0.3156743049621582 seconds for one epoch ---
--- 0.6282572746276855 seconds for one epoch ---
--- 0.3340160846710205 seconds for one epoch ---
--- 0.6133236885070801 seconds for one epoch ---
--- 0.31670546531677246 seconds for one epoch ---
--- 0.6267280578613281 seconds for one epoch ---
--- 0.32801103591918945 seconds for one epoch ---
--- 0.6068363189697266 seconds for one epoch ---
--- 0.30954790115356445 seconds for one epoch ---
--- 0.6173083782196045 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13129513]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17212674]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4819386]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.6490673]
 [ 0.       ]]
--- 0.28942179679870605 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6870.79052734375, (2039.2126, 1.7119298, 4829.638, 0.22780035)
   validation loss 1480.342041015625, (1116.6132, 0.1007335, 363.40036, 0.22780035)
decoder loss ratio: 43259.532312, decoder SINDy loss  ratio: 0.784451
--- 0.26941728591918945 seconds for one epoch ---
--- 0.29859137535095215 seconds for one epoch ---
--- 0.6394076347351074 seconds for one epoch ---
--- 0.30380797386169434 seconds for one epoch ---
--- 0.5990829467773438 seconds for one epoch ---
--- 0.3116147518157959 seconds for one epoch ---
--- 0.6179182529449463 seconds for one epoch ---
--- 0.2934761047363281 seconds for one epoch ---
--- 0.6125719547271729 seconds for one epoch ---
--- 0.2839386463165283 seconds for one epoch ---
--- 0.6147422790527344 seconds for one epoch ---
--- 0.29279160499572754 seconds for one epoch ---
--- 0.591036319732666 seconds for one epoch ---
--- 0.29897451400756836 seconds for one epoch ---
--- 0.6395902633666992 seconds for one epoch ---
--- 0.29507946968078613 seconds for one epoch ---
--- 0.6260085105895996 seconds for one epoch ---
--- 0.28342390060424805 seconds for one epoch ---
--- 0.6255042552947998 seconds for one epoch ---
--- 0.32479333877563477 seconds for one epoch ---
--- 0.6157779693603516 seconds for one epoch ---
--- 0.3194887638092041 seconds for one epoch ---
--- 0.6277177333831787 seconds for one epoch ---
--- 0.321988582611084 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12479296]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18252988]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.453242 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.6876922]
 [ 0.       ]]
--- 0.24355077743530273 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4891.15771484375, (1779.9581, 1.1458737, 3109.8237, 0.23013745)
   validation loss 951.0819091796875, (644.76953, 0.11394901, 305.96826, 0.23013745)
decoder loss ratio: 24979.491010, decoder SINDy loss  ratio: 0.660476
--- 0.2950708866119385 seconds for one epoch ---
--- 0.6296961307525635 seconds for one epoch ---
--- 0.2965421676635742 seconds for one epoch ---
--- 0.6183550357818604 seconds for one epoch ---
--- 0.30225443840026855 seconds for one epoch ---
--- 0.6271276473999023 seconds for one epoch ---
--- 0.28975558280944824 seconds for one epoch ---
--- 0.6335971355438232 seconds for one epoch ---
--- 0.28702878952026367 seconds for one epoch ---
--- 0.6307578086853027 seconds for one epoch ---
--- 0.2975149154663086 seconds for one epoch ---
--- 0.607478141784668 seconds for one epoch ---
--- 0.2958414554595947 seconds for one epoch ---
--- 0.642613410949707 seconds for one epoch ---
--- 0.2946343421936035 seconds for one epoch ---
--- 0.6290059089660645 seconds for one epoch ---
--- 0.29126453399658203 seconds for one epoch ---
--- 0.6409223079681396 seconds for one epoch ---
--- 0.3037385940551758 seconds for one epoch ---
--- 0.6554501056671143 seconds for one epoch ---
--- 0.312457799911499 seconds for one epoch ---
--- 0.6685423851013184 seconds for one epoch ---
--- 0.3261864185333252 seconds for one epoch ---
--- 0.6580691337585449 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11928724]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19447474]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4278406]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.7294258]
 [ 0.       ]]
--- 0.30893564224243164 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4959.52294921875, (2468.0095, 0.47219443, 2490.8115, 0.2298793)
   validation loss 2005.66650390625, (1659.9646, 0.123461254, 345.34863, 0.2298793)
decoder loss ratio: 64309.910414, decoder SINDy loss  ratio: 0.745484
--- 0.2649271488189697 seconds for one epoch ---
--- 0.3234436511993408 seconds for one epoch ---
--- 0.6305398941040039 seconds for one epoch ---
--- 0.2984597682952881 seconds for one epoch ---
--- 0.6490817070007324 seconds for one epoch ---
--- 0.3032252788543701 seconds for one epoch ---
--- 0.6261565685272217 seconds for one epoch ---
--- 0.29349660873413086 seconds for one epoch ---
--- 0.6502068042755127 seconds for one epoch ---
--- 0.3034827709197998 seconds for one epoch ---
--- 0.6346638202667236 seconds for one epoch ---
--- 0.302689790725708 seconds for one epoch ---
--- 0.6286277770996094 seconds for one epoch ---
--- 0.30152416229248047 seconds for one epoch ---
--- 0.649768590927124 seconds for one epoch ---
--- 0.29681825637817383 seconds for one epoch ---
--- 0.6459238529205322 seconds for one epoch ---
--- 0.2915053367614746 seconds for one epoch ---
--- 0.642219066619873 seconds for one epoch ---
--- 0.2963829040527344 seconds for one epoch ---
--- 0.6206481456756592 seconds for one epoch ---
--- 0.2858314514160156 seconds for one epoch ---
--- 0.6341061592102051 seconds for one epoch ---
--- 0.3225886821746826 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11551273]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21280892]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4102035]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.7892259]
 [ 0.       ]]
--- 0.25570249557495117 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3844.907958984375, (2058.6118, 0.44423983, 1785.6185, 0.23303257)
   validation loss 2168.90771484375, (1754.1421, 0.07154984, 414.46103, 0.23303257)
decoder loss ratio: 67958.509885, decoder SINDy loss  ratio: 0.894672
--- 0.3198671340942383 seconds for one epoch ---
--- 0.6403453350067139 seconds for one epoch ---
--- 0.3130636215209961 seconds for one epoch ---
--- 0.6413207054138184 seconds for one epoch ---
--- 0.3224780559539795 seconds for one epoch ---
--- 0.6510288715362549 seconds for one epoch ---
--- 0.27856993675231934 seconds for one epoch ---
--- 0.6464543342590332 seconds for one epoch ---
--- 0.29345703125 seconds for one epoch ---
--- 0.6549253463745117 seconds for one epoch ---
--- 0.2907376289367676 seconds for one epoch ---
--- 0.658625602722168 seconds for one epoch ---
--- 0.2998530864715576 seconds for one epoch ---
--- 0.6511144638061523 seconds for one epoch ---
--- 0.2897510528564453 seconds for one epoch ---
--- 0.6754779815673828 seconds for one epoch ---
--- 0.30562329292297363 seconds for one epoch ---
--- 0.652259349822998 seconds for one epoch ---
--- 0.3028907775878906 seconds for one epoch ---
--- 0.6676785945892334 seconds for one epoch ---
--- 0.3087904453277588 seconds for one epoch ---
--- 0.6391098499298096 seconds for one epoch ---
--- 0.2967362403869629 seconds for one epoch ---
--- 0.6597151756286621 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1156459]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2418512]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4119362]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.8761002]
 [ 0.       ]]
--- 0.297149658203125 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3580.3486328125, (2236.7158, 0.7377792, 1342.6538, 0.24124146)
   validation loss 1389.363525390625, (1076.917, 0.12184763, 312.08356, 0.24124146)
decoder loss ratio: 41721.633887, decoder SINDy loss  ratio: 0.673676
--- 0.2769796848297119 seconds for one epoch ---
--- 0.32567381858825684 seconds for one epoch ---
--- 0.673567533493042 seconds for one epoch ---
--- 0.3163299560546875 seconds for one epoch ---
--- 0.6767170429229736 seconds for one epoch ---
--- 0.3238961696624756 seconds for one epoch ---
--- 0.6870529651641846 seconds for one epoch ---
--- 0.3217957019805908 seconds for one epoch ---
--- 0.6732199192047119 seconds for one epoch ---
--- 0.33585309982299805 seconds for one epoch ---
--- 0.6893126964569092 seconds for one epoch ---
--- 0.32177209854125977 seconds for one epoch ---
--- 0.6578948497772217 seconds for one epoch ---
--- 0.30477094650268555 seconds for one epoch ---
--- 0.6580338478088379 seconds for one epoch ---
--- 0.3107311725616455 seconds for one epoch ---
--- 0.6887218952178955 seconds for one epoch ---
--- 0.326723575592041 seconds for one epoch ---
--- 0.6826639175415039 seconds for one epoch ---
--- 0.29991960525512695 seconds for one epoch ---
--- 0.6879854202270508 seconds for one epoch ---
--- 0.2905552387237549 seconds for one epoch ---
--- 0.681891918182373 seconds for one epoch ---
--- 0.2887392044067383 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1126753]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2498214]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3976433]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.8989735]
 [ 0.       ]]
--- 0.25971317291259766 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4996.0693359375, (2230.479, 0.9491105, 2764.3977, 0.2430046)
   validation loss 940.970703125, (636.48444, 0.1048615, 304.13843, 0.2430046)
decoder loss ratio: 24658.512038, decoder SINDy loss  ratio: 0.656526
--- 0.33455896377563477 seconds for one epoch ---
--- 0.6558952331542969 seconds for one epoch ---
--- 0.3033568859100342 seconds for one epoch ---
--- 0.6824040412902832 seconds for one epoch ---
--- 0.30680370330810547 seconds for one epoch ---
--- 0.6687452793121338 seconds for one epoch ---
--- 0.3037421703338623 seconds for one epoch ---
--- 0.6748111248016357 seconds for one epoch ---
--- 0.28145313262939453 seconds for one epoch ---
--- 0.6911025047302246 seconds for one epoch ---
--- 0.3037600517272949 seconds for one epoch ---
--- 0.6776010990142822 seconds for one epoch ---
--- 0.291989803314209 seconds for one epoch ---
--- 0.6694860458374023 seconds for one epoch ---
--- 0.29701995849609375 seconds for one epoch ---
--- 0.7052314281463623 seconds for one epoch ---
--- 0.31021785736083984 seconds for one epoch ---
--- 0.6787734031677246 seconds for one epoch ---
--- 0.32657742500305176 seconds for one epoch ---
--- 0.7096314430236816 seconds for one epoch ---
--- 0.32364892959594727 seconds for one epoch ---
--- 0.6928746700286865 seconds for one epoch ---
--- 0.32129478454589844 seconds for one epoch ---
--- 0.6777462959289551 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10961366]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27642238]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3823342]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.9709136]
 [ 0.       ]]
--- 0.27683448791503906 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3720.415771484375, (1448.9348, 0.257691, 2270.9758, 0.24728703)
   validation loss 832.1737060546875, (561.30774, 0.14732213, 270.4713, 0.24728703)
decoder loss ratio: 21746.036292, decoder SINDy loss  ratio: 0.583850
--- 0.2547321319580078 seconds for one epoch ---
--- 0.30110979080200195 seconds for one epoch ---
--- 0.6876704692840576 seconds for one epoch ---
--- 0.2982614040374756 seconds for one epoch ---
--- 0.6889557838439941 seconds for one epoch ---
--- 0.29443812370300293 seconds for one epoch ---
--- 0.6727592945098877 seconds for one epoch ---
--- 0.29645276069641113 seconds for one epoch ---
--- 0.6925559043884277 seconds for one epoch ---
--- 0.30661511421203613 seconds for one epoch ---
--- 0.6800742149353027 seconds for one epoch ---
--- 0.32547521591186523 seconds for one epoch ---
--- 0.6908843517303467 seconds for one epoch ---
--- 0.31265687942504883 seconds for one epoch ---
--- 0.7047936916351318 seconds for one epoch ---
--- 0.33133792877197266 seconds for one epoch ---
--- 0.6949143409729004 seconds for one epoch ---
--- 0.31045961380004883 seconds for one epoch ---
--- 0.7079107761383057 seconds for one epoch ---
--- 0.29979562759399414 seconds for one epoch ---
--- 0.6857919692993164 seconds for one epoch ---
--- 0.318767786026001 seconds for one epoch ---
--- 0.6802775859832764 seconds for one epoch ---
--- 0.29961252212524414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10985138]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32154483]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3842953]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.0837605]
 [ 0.       ]]
--- 0.26408863067626953 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4744.720703125, (1727.7766, 0.3339155, 3016.3538, 0.25617725)
   validation loss 818.0894165039062, (525.6619, 0.13461798, 292.0367, 0.25617725)
decoder loss ratio: 20365.055613, decoder SINDy loss  ratio: 0.630402
--- 0.32364726066589355 seconds for one epoch ---
--- 0.6968779563903809 seconds for one epoch ---
--- 0.3112599849700928 seconds for one epoch ---
--- 0.673494815826416 seconds for one epoch ---
--- 0.297865629196167 seconds for one epoch ---
--- 0.7051756381988525 seconds for one epoch ---
--- 0.28856325149536133 seconds for one epoch ---
--- 0.670886754989624 seconds for one epoch ---
--- 0.2954592704772949 seconds for one epoch ---
--- 0.7094292640686035 seconds for one epoch ---
--- 0.2878451347351074 seconds for one epoch ---
--- 0.6922316551208496 seconds for one epoch ---
--- 0.2941110134124756 seconds for one epoch ---
--- 0.6975398063659668 seconds for one epoch ---
--- 0.30051207542419434 seconds for one epoch ---
--- 0.6865415573120117 seconds for one epoch ---
--- 0.3006589412689209 seconds for one epoch ---
--- 0.6844873428344727 seconds for one epoch ---
--- 0.29369449615478516 seconds for one epoch ---
--- 0.7006471157073975 seconds for one epoch ---
--- 0.3034083843231201 seconds for one epoch ---
--- 0.7031145095825195 seconds for one epoch ---
--- 0.28839540481567383 seconds for one epoch ---
--- 0.6930017471313477 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10115459]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35003936]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3371683]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.150772 ]
 [ 0.       ]]
--- 0.30224037170410156 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4606.89794921875, (1641.8339, 2.2788973, 2962.5256, 0.25926396)
   validation loss 1038.355224609375, (721.4264, 0.13678016, 316.5327, 0.25926396)
decoder loss ratio: 27949.310862, decoder SINDy loss  ratio: 0.683280
--- 0.268979549407959 seconds for one epoch ---
--- 0.32806897163391113 seconds for one epoch ---
--- 0.6770620346069336 seconds for one epoch ---
--- 0.32537341117858887 seconds for one epoch ---
--- 0.6962730884552002 seconds for one epoch ---
--- 0.30794620513916016 seconds for one epoch ---
--- 0.6936056613922119 seconds for one epoch ---
--- 0.3053314685821533 seconds for one epoch ---
--- 0.7090170383453369 seconds for one epoch ---
--- 0.31285977363586426 seconds for one epoch ---
--- 0.7112574577331543 seconds for one epoch ---
--- 0.29677915573120117 seconds for one epoch ---
--- 0.6957955360412598 seconds for one epoch ---
--- 0.45697522163391113 seconds for one epoch ---
--- 0.691460132598877 seconds for one epoch ---
--- 0.31162142753601074 seconds for one epoch ---
--- 0.7046611309051514 seconds for one epoch ---
--- 0.2815375328063965 seconds for one epoch ---
--- 0.7023520469665527 seconds for one epoch ---
--- 0.29823946952819824 seconds for one epoch ---
--- 0.7030720710754395 seconds for one epoch ---
--- 0.3046095371246338 seconds for one epoch ---
--- 0.7025606632232666 seconds for one epoch ---
--- 0.2982633113861084 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10423525]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39529225]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3549718]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.2523642]
 [ 0.       ]]
--- 0.24349689483642578 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1974.795166015625, (1053.2817, 1.5999216, 919.64404, 0.269428)
   validation loss 2587.069091796875, (2207.353, 0.11200762, 379.33438, 0.269428)
decoder loss ratio: 85516.688413, decoder SINDy loss  ratio: 0.818847
--- 0.3115546703338623 seconds for one epoch ---
--- 0.7045490741729736 seconds for one epoch ---
--- 0.30637407302856445 seconds for one epoch ---
--- 0.7170469760894775 seconds for one epoch ---
--- 0.3006470203399658 seconds for one epoch ---
--- 0.7158854007720947 seconds for one epoch ---
--- 0.28901052474975586 seconds for one epoch ---
--- 0.6958887577056885 seconds for one epoch ---
--- 0.29041600227355957 seconds for one epoch ---
--- 0.759148120880127 seconds for one epoch ---
--- 0.29159975051879883 seconds for one epoch ---
--- 0.7256002426147461 seconds for one epoch ---
--- 0.30315351486206055 seconds for one epoch ---
--- 0.7400627136230469 seconds for one epoch ---
--- 0.2954845428466797 seconds for one epoch ---
--- 0.7224900722503662 seconds for one epoch ---
--- 0.31023693084716797 seconds for one epoch ---
--- 0.7481153011322021 seconds for one epoch ---
--- 0.32874393463134766 seconds for one epoch ---
--- 0.7496225833892822 seconds for one epoch ---
--- 0.3116874694824219 seconds for one epoch ---
--- 0.7312872409820557 seconds for one epoch ---
--- 0.30719423294067383 seconds for one epoch ---
--- 0.723848819732666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09704211]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4303472 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3143499]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.328342 ]
 [ 0.       ]]
--- 0.30008769035339355 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3342.94482421875, (1118.0087, 0.4400355, 2224.223, 0.2731906)
   validation loss 798.0167236328125, (497.30765, 0.16240092, 300.27344, 0.2731906)
decoder loss ratio: 19266.561636, decoder SINDy loss  ratio: 0.648182
--- 0.2769770622253418 seconds for one epoch ---
--- 0.31198573112487793 seconds for one epoch ---
--- 0.723874568939209 seconds for one epoch ---
--- 0.3254208564758301 seconds for one epoch ---
--- 0.7339162826538086 seconds for one epoch ---
--- 0.32065629959106445 seconds for one epoch ---
--- 0.7306783199310303 seconds for one epoch ---
--- 0.30800485610961914 seconds for one epoch ---
--- 0.7228245735168457 seconds for one epoch ---
--- 0.3266031742095947 seconds for one epoch ---
--- 0.7330620288848877 seconds for one epoch ---
--- 0.32788729667663574 seconds for one epoch ---
--- 0.7330453395843506 seconds for one epoch ---
--- 0.32634639739990234 seconds for one epoch ---
--- 0.7519960403442383 seconds for one epoch ---
--- 0.3101353645324707 seconds for one epoch ---
--- 0.7261195182800293 seconds for one epoch ---
--- 0.3072788715362549 seconds for one epoch ---
--- 0.7331335544586182 seconds for one epoch ---
--- 0.28934693336486816 seconds for one epoch ---
--- 0.7146339416503906 seconds for one epoch ---
--- 0.29711341857910156 seconds for one epoch ---
--- 0.7263033390045166 seconds for one epoch ---
--- 0.29418015480041504 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09592241]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.47254708]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3081253]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.4179847]
 [ 0.       ]]
--- 0.25516748428344727 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2919.155517578125, (1196.1663, 1.6994185, 1721.0106, 0.27905366)
   validation loss 1168.0401611328125, (816.6847, 0.1226243, 350.95383, 0.27905366)
decoder loss ratio: 31639.782810, decoder SINDy loss  ratio: 0.757583
--- 0.30255651473999023 seconds for one epoch ---
--- 0.7154872417449951 seconds for one epoch ---
--- 0.29985499382019043 seconds for one epoch ---
--- 0.7443618774414062 seconds for one epoch ---
--- 0.30119824409484863 seconds for one epoch ---
--- 0.7351429462432861 seconds for one epoch ---
--- 0.2953665256500244 seconds for one epoch ---
--- 0.721022367477417 seconds for one epoch ---
--- 0.281055212020874 seconds for one epoch ---
--- 0.7322421073913574 seconds for one epoch ---
--- 0.29810500144958496 seconds for one epoch ---
--- 0.7191405296325684 seconds for one epoch ---
--- 0.29210901260375977 seconds for one epoch ---
--- 0.7430911064147949 seconds for one epoch ---
--- 0.2924962043762207 seconds for one epoch ---
--- 0.7527523040771484 seconds for one epoch ---
--- 0.31037211418151855 seconds for one epoch ---
--- 0.7465126514434814 seconds for one epoch ---
--- 0.2981719970703125 seconds for one epoch ---
--- 0.7784969806671143 seconds for one epoch ---
--- 0.31235313415527344 seconds for one epoch ---
--- 0.7580816745758057 seconds for one epoch ---
--- 0.3068501949310303 seconds for one epoch ---
--- 0.7783303260803223 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09589816]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.51991785]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3082948]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.517828 ]
 [ 0.       ]]
--- 0.2930722236633301 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2804.231689453125, (1433.667, 0.33231288, 1369.9463, 0.28613746)
   validation loss 1295.1007080078125, (949.8997, 0.12658612, 344.78827, 0.28613746)
decoder loss ratio: 36800.764222, decoder SINDy loss  ratio: 0.744274
THRESHOLDING: 1 active coefficients
--- 0.7526829242706299 seconds for one epoch ---
--- 0.3059711456298828 seconds for one epoch ---
--- 0.7250709533691406 seconds for one epoch ---
--- 0.32027769088745117 seconds for one epoch ---
--- 0.7521886825561523 seconds for one epoch ---
--- 0.32434821128845215 seconds for one epoch ---
--- 0.7540733814239502 seconds for one epoch ---
--- 0.3173232078552246 seconds for one epoch ---
--- 0.7637076377868652 seconds for one epoch ---
--- 0.30811023712158203 seconds for one epoch ---
--- 0.7603611946105957 seconds for one epoch ---
--- 0.29193687438964844 seconds for one epoch ---
--- 0.7475214004516602 seconds for one epoch ---
--- 0.30246615409851074 seconds for one epoch ---
--- 0.7795653343200684 seconds for one epoch ---
--- 0.28772664070129395 seconds for one epoch ---
--- 0.7409844398498535 seconds for one epoch ---
--- 0.2966427803039551 seconds for one epoch ---
--- 0.7649273872375488 seconds for one epoch ---
--- 0.2894928455352783 seconds for one epoch ---
--- 0.7714755535125732 seconds for one epoch ---
--- 0.2837369441986084 seconds for one epoch ---
--- 0.7552065849304199 seconds for one epoch ---
--- 0.28537654876708984 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.71048456]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9506419]
 [ 0.       ]]
--- 0.2557041645050049 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2451.75927734375, (1052.073, 1.2081522, 1398.2566, 0.22156654)
   validation loss 1363.2880859375, (1045.443, 0.21275614, 317.41077, 0.22156654)
decoder loss ratio: 40502.276524, decoder SINDy loss  ratio: 0.685176
--- 0.3095114231109619 seconds for one epoch ---
--- 0.761807918548584 seconds for one epoch ---
--- 0.33069300651550293 seconds for one epoch ---
--- 0.7422487735748291 seconds for one epoch ---
--- 0.3189852237701416 seconds for one epoch ---
--- 0.7487061023712158 seconds for one epoch ---
--- 0.29764461517333984 seconds for one epoch ---
--- 0.7494885921478271 seconds for one epoch ---
--- 0.28926706314086914 seconds for one epoch ---
--- 0.7495534420013428 seconds for one epoch ---
--- 0.30544519424438477 seconds for one epoch ---
--- 0.7650659084320068 seconds for one epoch ---
--- 0.2963695526123047 seconds for one epoch ---
--- 0.7861349582672119 seconds for one epoch ---
--- 0.30512166023254395 seconds for one epoch ---
--- 0.7807962894439697 seconds for one epoch ---
--- 0.28560900688171387 seconds for one epoch ---
--- 0.7493231296539307 seconds for one epoch ---
--- 0.2926292419433594 seconds for one epoch ---
--- 0.7799198627471924 seconds for one epoch ---
--- 0.2899298667907715 seconds for one epoch ---
--- 0.774024486541748 seconds for one epoch ---
--- 0.29758429527282715 seconds for one epoch ---
--- 0.7863633632659912 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84378767]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.3718035]
 [ 0.       ]]
--- 0.2745630741119385 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4328.01611328125, (1492.2053, 1.2818962, 2834.2861, 0.24247728)
   validation loss 926.0866088867188, (612.8843, 0.25484404, 312.70505, 0.24247728)
decoder loss ratio: 23744.200918, decoder SINDy loss  ratio: 0.675018
--- 0.2548410892486572 seconds for one epoch ---
--- 0.288069486618042 seconds for one epoch ---
--- 0.7689497470855713 seconds for one epoch ---
--- 0.29419851303100586 seconds for one epoch ---
--- 0.7738676071166992 seconds for one epoch ---
--- 0.28499436378479004 seconds for one epoch ---
--- 0.784907341003418 seconds for one epoch ---
--- 0.2975955009460449 seconds for one epoch ---
--- 0.7748861312866211 seconds for one epoch ---
--- 0.3067340850830078 seconds for one epoch ---
--- 0.7619144916534424 seconds for one epoch ---
--- 0.31615591049194336 seconds for one epoch ---
--- 0.7635514736175537 seconds for one epoch ---
--- 0.3222806453704834 seconds for one epoch ---
--- 0.8074004650115967 seconds for one epoch ---
--- 0.3362593650817871 seconds for one epoch ---
--- 0.7721052169799805 seconds for one epoch ---
--- 0.307614803314209 seconds for one epoch ---
--- 0.7731072902679443 seconds for one epoch ---
--- 0.28911542892456055 seconds for one epoch ---
--- 0.7720792293548584 seconds for one epoch ---
--- 0.28541016578674316 seconds for one epoch ---
--- 0.7815463542938232 seconds for one epoch ---
--- 0.2978386878967285 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9144837]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7394683]
 [ 0.       ]]
--- 0.25307321548461914 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4645.736328125, (1249.9568, 2.4740381, 3393.0522, 0.25355363)
   validation loss 1133.15185546875, (747.2177, 0.19600631, 385.4846, 0.25355363)
decoder loss ratio: 28948.511405, decoder SINDy loss  ratio: 0.832123
--- 0.3148481845855713 seconds for one epoch ---
--- 0.7946224212646484 seconds for one epoch ---
--- 0.3184349536895752 seconds for one epoch ---
--- 0.7958841323852539 seconds for one epoch ---
--- 0.31787538528442383 seconds for one epoch ---
--- 0.7909104824066162 seconds for one epoch ---
--- 0.3087451457977295 seconds for one epoch ---
--- 0.8006899356842041 seconds for one epoch ---
--- 0.3096134662628174 seconds for one epoch ---
--- 0.8001229763031006 seconds for one epoch ---
--- 0.3045766353607178 seconds for one epoch ---
--- 0.7940552234649658 seconds for one epoch ---
--- 0.3174574375152588 seconds for one epoch ---
--- 0.8032569885253906 seconds for one epoch ---
--- 0.2906181812286377 seconds for one epoch ---
--- 0.7878580093383789 seconds for one epoch ---
--- 0.27712202072143555 seconds for one epoch ---
--- 0.7898428440093994 seconds for one epoch ---
--- 0.283947229385376 seconds for one epoch ---
--- 0.7979781627655029 seconds for one epoch ---
--- 0.30475401878356934 seconds for one epoch ---
--- 0.8046169281005859 seconds for one epoch ---
--- 0.2805800437927246 seconds for one epoch ---
--- 0.7814886569976807 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95610285]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.1255383]
 [-0.       ]]
--- 0.29827117919921875 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3376.239013671875, (1532.2426, 3.7257597, 1840.0103, 0.26052386)
   validation loss 957.0140991210938, (601.4448, 0.15502107, 355.15375, 0.26052386)
decoder loss ratio: 23301.016644, decoder SINDy loss  ratio: 0.766649
--- 0.2549877166748047 seconds for one epoch ---
--- 0.3022193908691406 seconds for one epoch ---
--- 0.8110189437866211 seconds for one epoch ---
--- 0.281266450881958 seconds for one epoch ---
--- 0.7905771732330322 seconds for one epoch ---
--- 0.3069770336151123 seconds for one epoch ---
--- 0.7767224311828613 seconds for one epoch ---
--- 0.30045557022094727 seconds for one epoch ---
--- 0.7992150783538818 seconds for one epoch ---
--- 0.2958664894104004 seconds for one epoch ---
--- 0.7968800067901611 seconds for one epoch ---
--- 0.29709386825561523 seconds for one epoch ---
--- 0.786144495010376 seconds for one epoch ---
--- 0.30539774894714355 seconds for one epoch ---
--- 0.8115653991699219 seconds for one epoch ---
--- 0.3054373264312744 seconds for one epoch ---
--- 0.7962973117828369 seconds for one epoch ---
--- 0.29305553436279297 seconds for one epoch ---
--- 0.8277187347412109 seconds for one epoch ---
--- 0.29881882667541504 seconds for one epoch ---
--- 0.7948410511016846 seconds for one epoch ---
--- 0.31675291061401367 seconds for one epoch ---
--- 0.806473970413208 seconds for one epoch ---
--- 0.29637813568115234 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9770296]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.491765]
 [-0.      ]]
--- 0.2666172981262207 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4427.30517578125, (1958.7635, 2.855374, 2465.421, 0.26499084)
   validation loss 1704.447998046875, (1296.5433, 0.22723666, 407.41232, 0.26499084)
decoder loss ratio: 50230.339695, decoder SINDy loss  ratio: 0.879457
--- 0.2890737056732178 seconds for one epoch ---
--- 0.8018968105316162 seconds for one epoch ---
--- 0.2883644104003906 seconds for one epoch ---
--- 0.8133058547973633 seconds for one epoch ---
--- 0.30350685119628906 seconds for one epoch ---
--- 0.8073022365570068 seconds for one epoch ---
--- 0.32134342193603516 seconds for one epoch ---
--- 0.8024437427520752 seconds for one epoch ---
--- 0.30193066596984863 seconds for one epoch ---
--- 0.8129472732543945 seconds for one epoch ---
--- 0.320253849029541 seconds for one epoch ---
--- 0.8322916030883789 seconds for one epoch ---
--- 0.32138609886169434 seconds for one epoch ---
--- 0.8118135929107666 seconds for one epoch ---
--- 0.33710169792175293 seconds for one epoch ---
--- 0.81160569190979 seconds for one epoch ---
--- 0.3242647647857666 seconds for one epoch ---
--- 0.8091170787811279 seconds for one epoch ---
--- 0.3293497562408447 seconds for one epoch ---
--- 0.8230926990509033 seconds for one epoch ---
--- 0.29810070991516113 seconds for one epoch ---
--- 0.8121037483215332 seconds for one epoch ---
--- 0.2812037467956543 seconds for one epoch ---
--- 0.8036098480224609 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98789585]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.851227]
 [ 0.      ]]
--- 0.2948896884918213 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3719.974853515625, (1315.3875, 2.7868934, 2401.5322, 0.2683954)
   validation loss 1110.9312744140625, (813.0811, 0.3321763, 297.2496, 0.2683954)
decoder loss ratio: 31500.173994, decoder SINDy loss  ratio: 0.641655
--- 0.26152539253234863 seconds for one epoch ---
--- 0.300400972366333 seconds for one epoch ---
--- 0.8108415603637695 seconds for one epoch ---
--- 0.31903696060180664 seconds for one epoch ---
--- 0.8011949062347412 seconds for one epoch ---
--- 0.3024773597717285 seconds for one epoch ---
--- 0.8175089359283447 seconds for one epoch ---
--- 0.30463504791259766 seconds for one epoch ---
--- 0.832892656326294 seconds for one epoch ---
--- 0.3117983341217041 seconds for one epoch ---
--- 0.8250679969787598 seconds for one epoch ---
--- 0.3090062141418457 seconds for one epoch ---
--- 0.8092927932739258 seconds for one epoch ---
--- 0.2931523323059082 seconds for one epoch ---
--- 0.8454501628875732 seconds for one epoch ---
--- 0.2909841537475586 seconds for one epoch ---
--- 0.8191566467285156 seconds for one epoch ---
--- 0.29213786125183105 seconds for one epoch ---
--- 0.8117196559906006 seconds for one epoch ---
--- 0.293595552444458 seconds for one epoch ---
--- 0.8149075508117676 seconds for one epoch ---
--- 0.29668402671813965 seconds for one epoch ---
--- 0.8238844871520996 seconds for one epoch ---
--- 0.2926938533782959 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99352956]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-5.202568]
 [ 0.      ]]
--- 0.24077391624450684 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3835.302001953125, (1495.9454, 3.0208645, 2336.0642, 0.2714606)
   validation loss 1186.6566162109375, (814.04755, 0.177778, 372.15982, 0.2714606)
decoder loss ratio: 31537.615196, decoder SINDy loss  ratio: 0.803359
--- 0.2956514358520508 seconds for one epoch ---
--- 0.8289158344268799 seconds for one epoch ---
--- 0.29157567024230957 seconds for one epoch ---
--- 0.8306689262390137 seconds for one epoch ---
--- 0.29131364822387695 seconds for one epoch ---
--- 0.8238010406494141 seconds for one epoch ---
--- 0.29178428649902344 seconds for one epoch ---
--- 0.8049631118774414 seconds for one epoch ---
--- 0.2961907386779785 seconds for one epoch ---
--- 0.8272943496704102 seconds for one epoch ---
--- 0.2998385429382324 seconds for one epoch ---
--- 0.8331964015960693 seconds for one epoch ---
--- 0.3034806251525879 seconds for one epoch ---
--- 0.8372199535369873 seconds for one epoch ---
--- 0.2971189022064209 seconds for one epoch ---
--- 0.8484158515930176 seconds for one epoch ---
--- 0.2942490577697754 seconds for one epoch ---
--- 0.8325531482696533 seconds for one epoch ---
--- 0.3020651340484619 seconds for one epoch ---
--- 0.8457574844360352 seconds for one epoch ---
--- 0.3088386058807373 seconds for one epoch ---
--- 0.8508391380310059 seconds for one epoch ---
--- 0.3155789375305176 seconds for one epoch ---
--- 0.8347570896148682 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9964952]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.5477123]
 [ 0.       ]]
--- 0.2953071594238281 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5089.4130859375, (2456.288, 1.3168514, 2631.5337, 0.27429658)
   validation loss 1178.2786865234375, (805.3681, 0.11902466, 372.51727, 0.27429658)
decoder loss ratio: 31201.358492, decoder SINDy loss  ratio: 0.804131
--- 0.27001214027404785 seconds for one epoch ---
--- 0.30111217498779297 seconds for one epoch ---
--- 0.8539869785308838 seconds for one epoch ---
--- 0.3014261722564697 seconds for one epoch ---
--- 0.8413422107696533 seconds for one epoch ---
--- 0.3020472526550293 seconds for one epoch ---
--- 0.8217272758483887 seconds for one epoch ---
--- 0.29117345809936523 seconds for one epoch ---
--- 0.8085916042327881 seconds for one epoch ---
--- 0.2876095771789551 seconds for one epoch ---
--- 0.8693814277648926 seconds for one epoch ---
--- 0.2920677661895752 seconds for one epoch ---
--- 0.869065523147583 seconds for one epoch ---
--- 0.2962331771850586 seconds for one epoch ---
--- 0.8600003719329834 seconds for one epoch ---
--- 0.29889535903930664 seconds for one epoch ---
--- 0.867372989654541 seconds for one epoch ---
--- 0.31362366676330566 seconds for one epoch ---
--- 0.8584082126617432 seconds for one epoch ---
--- 0.3175804615020752 seconds for one epoch ---
--- 0.8729290962219238 seconds for one epoch ---
--- 0.31344175338745117 seconds for one epoch ---
--- 0.858165979385376 seconds for one epoch ---
--- 0.3361318111419678 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99796087]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-5.854274]
 [-0.      ]]
--- 0.25754809379577637 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4833.20654296875, (1075.6426, 0.96076256, 3756.3262, 0.27696726)
   validation loss 1015.3424682617188, (627.8997, 0.2053144, 386.96045, 0.27696726)
decoder loss ratio: 24325.925205, decoder SINDy loss  ratio: 0.835309
--- 0.2995007038116455 seconds for one epoch ---
--- 0.8452262878417969 seconds for one epoch ---
--- 0.2901897430419922 seconds for one epoch ---
--- 0.83986496925354 seconds for one epoch ---
--- 0.2957625389099121 seconds for one epoch ---
--- 0.8443303108215332 seconds for one epoch ---
--- 0.30756402015686035 seconds for one epoch ---
--- 0.7956290245056152 seconds for one epoch ---
--- 0.28324079513549805 seconds for one epoch ---
--- 0.8525164127349854 seconds for one epoch ---
--- 0.31516385078430176 seconds for one epoch ---
--- 0.8606207370758057 seconds for one epoch ---
--- 0.32630372047424316 seconds for one epoch ---
--- 0.8655540943145752 seconds for one epoch ---
--- 0.3367576599121094 seconds for one epoch ---
--- 0.8780920505523682 seconds for one epoch ---
--- 0.32555532455444336 seconds for one epoch ---
--- 0.8754923343658447 seconds for one epoch ---
--- 0.32653141021728516 seconds for one epoch ---
--- 0.8660812377929688 seconds for one epoch ---
--- 0.3433847427368164 seconds for one epoch ---
--- 0.8473148345947266 seconds for one epoch ---
--- 0.33582377433776855 seconds for one epoch ---
--- 0.8618340492248535 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988378]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.174591]
 [-0.      ]]
--- 0.31140685081481934 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2796.83837890625, (1112.425, 0.6569252, 1683.4767, 0.27977198)
   validation loss 1072.043212890625, (790.9434, 0.54833484, 280.27167, 0.27977198)
decoder loss ratio: 30642.521245, decoder SINDy loss  ratio: 0.605006
--- 0.27146220207214355 seconds for one epoch ---
--- 0.336897611618042 seconds for one epoch ---
--- 0.8502588272094727 seconds for one epoch ---
--- 0.29796671867370605 seconds for one epoch ---
--- 0.8638434410095215 seconds for one epoch ---
--- 0.28051280975341797 seconds for one epoch ---
--- 0.8663163185119629 seconds for one epoch ---
--- 0.29353857040405273 seconds for one epoch ---
--- 0.8806183338165283 seconds for one epoch ---
--- 0.2935802936553955 seconds for one epoch ---
--- 0.8509061336517334 seconds for one epoch ---
--- 0.2897155284881592 seconds for one epoch ---
--- 0.8735108375549316 seconds for one epoch ---
--- 0.31185364723205566 seconds for one epoch ---
--- 0.8536577224731445 seconds for one epoch ---
--- 0.3125488758087158 seconds for one epoch ---
--- 0.859851598739624 seconds for one epoch ---
--- 0.4676229953765869 seconds for one epoch ---
--- 0.8691601753234863 seconds for one epoch ---
--- 0.30988121032714844 seconds for one epoch ---
--- 0.8890097141265869 seconds for one epoch ---
--- 0.3066527843475342 seconds for one epoch ---
--- 0.8668875694274902 seconds for one epoch ---
--- 0.33414244651794434 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993242]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.4855266]
 [-0.       ]]
--- 0.2770686149597168 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2936.66650390625, (1316.0581, 0.66800624, 1619.6578, 0.2826514)
   validation loss 850.5173950195312, (533.5774, 0.4849804, 316.1724, 0.2826514)
decoder loss ratio: 20671.714520, decoder SINDy loss  ratio: 0.682503
--- 0.30139851570129395 seconds for one epoch ---
--- 0.8755943775177002 seconds for one epoch ---
--- 0.310563325881958 seconds for one epoch ---
--- 0.8848552703857422 seconds for one epoch ---
--- 0.3027830123901367 seconds for one epoch ---
--- 0.865231990814209 seconds for one epoch ---
--- 0.30538010597229004 seconds for one epoch ---
--- 0.8933072090148926 seconds for one epoch ---
--- 0.28974032402038574 seconds for one epoch ---
--- 0.8866446018218994 seconds for one epoch ---
--- 0.2975156307220459 seconds for one epoch ---
--- 0.8702032566070557 seconds for one epoch ---
--- 0.2828974723815918 seconds for one epoch ---
--- 0.8649656772613525 seconds for one epoch ---
--- 0.3009068965911865 seconds for one epoch ---
--- 0.8848443031311035 seconds for one epoch ---
--- 0.30560922622680664 seconds for one epoch ---
--- 0.8739256858825684 seconds for one epoch ---
--- 0.2978181838989258 seconds for one epoch ---
--- 0.883561372756958 seconds for one epoch ---
--- 0.29949498176574707 seconds for one epoch ---
--- 0.868196964263916 seconds for one epoch ---
--- 0.2906193733215332 seconds for one epoch ---
--- 0.8634309768676758 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9996003]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.7886906]
 [ 0.       ]]
--- 0.3086252212524414 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4103.2197265625, (1539.4227, 0.6574467, 2562.854, 0.28554985)
   validation loss 1221.10888671875, (883.1837, 0.31110626, 337.32858, 0.28554985)
decoder loss ratio: 34216.070425, decoder SINDy loss  ratio: 0.728171
--- 0.2906208038330078 seconds for one epoch ---
--- 0.31523585319519043 seconds for one epoch ---
--- 0.8782539367675781 seconds for one epoch ---
--- 0.3221001625061035 seconds for one epoch ---
--- 0.8748235702514648 seconds for one epoch ---
--- 0.3315610885620117 seconds for one epoch ---
--- 0.8766546249389648 seconds for one epoch ---
--- 0.28612303733825684 seconds for one epoch ---
--- 0.874873161315918 seconds for one epoch ---
--- 0.2989225387573242 seconds for one epoch ---
--- 0.8767931461334229 seconds for one epoch ---
--- 0.29406094551086426 seconds for one epoch ---
--- 0.8743457794189453 seconds for one epoch ---
--- 0.3100733757019043 seconds for one epoch ---
--- 0.8881359100341797 seconds for one epoch ---
--- 0.2938680648803711 seconds for one epoch ---
--- 0.8689060211181641 seconds for one epoch ---
--- 0.2835054397583008 seconds for one epoch ---
--- 0.894550085067749 seconds for one epoch ---
--- 0.2848377227783203 seconds for one epoch ---
--- 0.9042403697967529 seconds for one epoch ---
--- 0.3019862174987793 seconds for one epoch ---
--- 0.9072716236114502 seconds for one epoch ---
--- 0.302107572555542 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999766]
 [0.      ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.1004424]
 [ 0.       ]]
--- 0.24493169784545898 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2068.5322265625, (877.01013, 1.0673759, 1190.166, 0.28866413)
   validation loss 945.6459350585938, (611.07745, 0.21824685, 334.0616, 0.28866413)
decoder loss ratio: 23674.201430, decoder SINDy loss  ratio: 0.721119
--- 0.32221436500549316 seconds for one epoch ---
--- 0.8724696636199951 seconds for one epoch ---
--- 0.3056449890136719 seconds for one epoch ---
--- 0.8802914619445801 seconds for one epoch ---
--- 0.30538105964660645 seconds for one epoch ---
--- 0.8737764358520508 seconds for one epoch ---
--- 0.31430745124816895 seconds for one epoch ---
--- 0.8798704147338867 seconds for one epoch ---
--- 0.28420472145080566 seconds for one epoch ---
--- 0.8988854885101318 seconds for one epoch ---
--- 0.2986743450164795 seconds for one epoch ---
--- 0.9076073169708252 seconds for one epoch ---
--- 0.2945442199707031 seconds for one epoch ---
--- 0.9057672023773193 seconds for one epoch ---
--- 0.29238462448120117 seconds for one epoch ---
--- 0.9283480644226074 seconds for one epoch ---
--- 0.2827272415161133 seconds for one epoch ---
--- 0.881767988204956 seconds for one epoch ---
--- 0.2925093173980713 seconds for one epoch ---
--- 0.9138579368591309 seconds for one epoch ---
--- 0.30147886276245117 seconds for one epoch ---
--- 0.9051706790924072 seconds for one epoch ---
--- 0.3261911869049072 seconds for one epoch ---
--- 0.9105432033538818 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99986076]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-7.408811]
 [ 0.      ]]
--- 0.29968857765197754 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3919.3037109375, (1384.479, 1.0796748, 2533.4531, 0.29192027)
   validation loss 835.2653198242188, (536.4723, 0.3696699, 298.1314, 0.29192027)
decoder loss ratio: 20783.867873, decoder SINDy loss  ratio: 0.643559
--- 0.2596414089202881 seconds for one epoch ---
--- 0.31278324127197266 seconds for one epoch ---
--- 0.9120378494262695 seconds for one epoch ---
--- 0.3074610233306885 seconds for one epoch ---
--- 0.8897020816802979 seconds for one epoch ---
--- 0.2930879592895508 seconds for one epoch ---
--- 0.906226634979248 seconds for one epoch ---
--- 0.30366063117980957 seconds for one epoch ---
--- 0.9100356101989746 seconds for one epoch ---
--- 0.29593324661254883 seconds for one epoch ---
--- 0.9086945056915283 seconds for one epoch ---
--- 0.2912864685058594 seconds for one epoch ---
--- 0.8985614776611328 seconds for one epoch ---
--- 0.3061063289642334 seconds for one epoch ---
--- 0.9053323268890381 seconds for one epoch ---
--- 0.2869575023651123 seconds for one epoch ---
--- 0.9068074226379395 seconds for one epoch ---
--- 0.28953027725219727 seconds for one epoch ---
--- 0.9291012287139893 seconds for one epoch ---
--- 0.2991342544555664 seconds for one epoch ---
--- 0.8581666946411133 seconds for one epoch ---
--- 0.29917478561401367 seconds for one epoch ---
--- 0.921546220779419 seconds for one epoch ---
--- 0.32596349716186523 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999132]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-7.6936274]
 [-0.       ]]
--- 0.2532339096069336 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1986.7379150390625, (1152.1201, 0.71110505, 833.6118, 0.29491523)
   validation loss 1557.744873046875, (1214.0886, 0.21073784, 343.1506, 0.29491523)
decoder loss ratio: 47035.901007, decoder SINDy loss  ratio: 0.740739
--- 0.2896566390991211 seconds for one epoch ---
--- 0.8824877738952637 seconds for one epoch ---
--- 0.2808959484100342 seconds for one epoch ---
--- 0.8952207565307617 seconds for one epoch ---
--- 0.30170559883117676 seconds for one epoch ---
--- 0.9035873413085938 seconds for one epoch ---
--- 0.3006401062011719 seconds for one epoch ---
--- 0.9213871955871582 seconds for one epoch ---
--- 0.3069283962249756 seconds for one epoch ---
--- 0.9005424976348877 seconds for one epoch ---
--- 0.28371095657348633 seconds for one epoch ---
--- 0.9421753883361816 seconds for one epoch ---
--- 0.29694581031799316 seconds for one epoch ---
--- 0.9082059860229492 seconds for one epoch ---
--- 0.29953765869140625 seconds for one epoch ---
--- 0.9094290733337402 seconds for one epoch ---
--- 0.29343557357788086 seconds for one epoch ---
--- 0.924569845199585 seconds for one epoch ---
--- 0.2938547134399414 seconds for one epoch ---
--- 0.9280133247375488 seconds for one epoch ---
--- 0.30512094497680664 seconds for one epoch ---
--- 0.9207005500793457 seconds for one epoch ---
--- 0.2942814826965332 seconds for one epoch ---
--- 0.9012646675109863 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999454]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-7.958207]
 [-0.      ]]
--- 0.2876310348510742 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3355.28857421875, (1308.7118, 0.95358086, 2045.3253, 0.2978285)
   validation loss 979.66357421875, (679.93994, 0.4757953, 298.95004, 0.2978285)
decoder loss ratio: 26342.053758, decoder SINDy loss  ratio: 0.645326
--- 0.25168871879577637 seconds for one epoch ---
--- 0.2994093894958496 seconds for one epoch ---
--- 0.9385840892791748 seconds for one epoch ---
--- 0.3146843910217285 seconds for one epoch ---
--- 0.9491431713104248 seconds for one epoch ---
--- 0.31233763694763184 seconds for one epoch ---
--- 0.9417111873626709 seconds for one epoch ---
--- 0.32106709480285645 seconds for one epoch ---
--- 0.9475419521331787 seconds for one epoch ---
--- 0.32703208923339844 seconds for one epoch ---
--- 0.9460618495941162 seconds for one epoch ---
--- 0.3396267890930176 seconds for one epoch ---
--- 0.9508473873138428 seconds for one epoch ---
--- 0.334230899810791 seconds for one epoch ---
--- 0.9389071464538574 seconds for one epoch ---
--- 0.30699944496154785 seconds for one epoch ---
--- 0.973879337310791 seconds for one epoch ---
--- 0.3167304992675781 seconds for one epoch ---
--- 0.9443507194519043 seconds for one epoch ---
--- 0.2977449893951416 seconds for one epoch ---
--- 0.9469161033630371 seconds for one epoch ---
--- 0.3178365230560303 seconds for one epoch ---
--- 0.9580874443054199 seconds for one epoch ---
--- 0.309830904006958 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996185]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.219828]
 [-0.      ]]
--- 0.25876379013061523 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2073.26513671875, (937.6895, 1.863448, 1133.4115, 0.30082005)
   validation loss 1137.7239990234375, (819.1365, 0.2488539, 318.03787, 0.30082005)
decoder loss ratio: 31734.769110, decoder SINDy loss  ratio: 0.686529
--- 0.29476046562194824 seconds for one epoch ---
--- 0.885404109954834 seconds for one epoch ---
--- 0.2904703617095947 seconds for one epoch ---
--- 0.9736833572387695 seconds for one epoch ---
--- 0.29007816314697266 seconds for one epoch ---
--- 0.9329330921173096 seconds for one epoch ---
--- 0.29213547706604004 seconds for one epoch ---
--- 0.9309713840484619 seconds for one epoch ---
--- 0.2910478115081787 seconds for one epoch ---
--- 0.9141676425933838 seconds for one epoch ---
--- 0.2822110652923584 seconds for one epoch ---
--- 0.9414927959442139 seconds for one epoch ---
--- 0.290114164352417 seconds for one epoch ---
--- 0.9557435512542725 seconds for one epoch ---
--- 0.30326223373413086 seconds for one epoch ---
--- 0.9734148979187012 seconds for one epoch ---
--- 0.28936076164245605 seconds for one epoch ---
--- 0.9231219291687012 seconds for one epoch ---
--- 0.27852869033813477 seconds for one epoch ---
--- 0.9426450729370117 seconds for one epoch ---
--- 0.29897284507751465 seconds for one epoch ---
--- 0.9528489112854004 seconds for one epoch ---
--- 0.29497265815734863 seconds for one epoch ---
--- 0.946295976638794 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999734]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.465675]
 [ 0.      ]]
--- 0.29779052734375 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3290.75927734375, (1330.1866, 1.3222905, 1958.9468, 0.30361566)
   validation loss 1194.4146728515625, (883.6292, 0.38235906, 310.09955, 0.30361566)
decoder loss ratio: 34233.329698, decoder SINDy loss  ratio: 0.669393
--- 0.26564812660217285 seconds for one epoch ---
--- 0.2954561710357666 seconds for one epoch ---
--- 0.9521143436431885 seconds for one epoch ---
--- 0.29811739921569824 seconds for one epoch ---
--- 0.9335651397705078 seconds for one epoch ---
--- 0.2887420654296875 seconds for one epoch ---
--- 0.949409008026123 seconds for one epoch ---
--- 0.29680752754211426 seconds for one epoch ---
--- 0.9580423831939697 seconds for one epoch ---
--- 0.29451823234558105 seconds for one epoch ---
--- 0.9754352569580078 seconds for one epoch ---
--- 0.29892396926879883 seconds for one epoch ---
--- 0.952939510345459 seconds for one epoch ---
--- 0.28952527046203613 seconds for one epoch ---
--- 0.9485247135162354 seconds for one epoch ---
--- 0.2930793762207031 seconds for one epoch ---
--- 0.973991870880127 seconds for one epoch ---
--- 0.29647040367126465 seconds for one epoch ---
--- 0.9392013549804688 seconds for one epoch ---
--- 0.2924211025238037 seconds for one epoch ---
--- 0.9544088840484619 seconds for one epoch ---
--- 0.280658483505249 seconds for one epoch ---
--- 0.9661157131195068 seconds for one epoch ---
--- 0.2909679412841797 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999813]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-8.719511]
 [ 0.      ]]
--- 0.25138068199157715 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1734.2684326171875, (841.0253, 0.9297319, 892.0069, 0.30653936)
   validation loss 1474.193603515625, (1133.5596, 0.3620401, 339.96542, 0.30653936)
decoder loss ratio: 43916.065700, decoder SINDy loss  ratio: 0.733863
--- 0.2842881679534912 seconds for one epoch ---
--- 0.9402439594268799 seconds for one epoch ---
--- 0.2881169319152832 seconds for one epoch ---
--- 0.965876579284668 seconds for one epoch ---
--- 0.2911503314971924 seconds for one epoch ---
--- 0.960395336151123 seconds for one epoch ---
--- 0.29749083518981934 seconds for one epoch ---
--- 0.9637830257415771 seconds for one epoch ---
--- 0.27237653732299805 seconds for one epoch ---
--- 0.9498143196105957 seconds for one epoch ---
--- 0.29144811630249023 seconds for one epoch ---
--- 0.9703898429870605 seconds for one epoch ---
--- 0.3080284595489502 seconds for one epoch ---
--- 0.9483633041381836 seconds for one epoch ---
--- 0.2871417999267578 seconds for one epoch ---
--- 0.9740231037139893 seconds for one epoch ---
--- 0.2962355613708496 seconds for one epoch ---
--- 0.969456672668457 seconds for one epoch ---
--- 0.29769015312194824 seconds for one epoch ---
--- 0.9669828414916992 seconds for one epoch ---
--- 0.29768919944763184 seconds for one epoch ---
--- 0.9657473564147949 seconds for one epoch ---
--- 0.2851419448852539 seconds for one epoch ---
--- 0.9732804298400879 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998635]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.942691]
 [ 0.      ]]
--- 0.29038357734680176 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2487.9091796875, (1045.0626, 2.2790625, 1440.2585, 0.30897573)
   validation loss 949.3447875976562, (642.40857, 0.28167236, 306.34558, 0.30897573)
decoder loss ratio: 24888.023246, decoder SINDy loss  ratio: 0.661290
THRESHOLDING: 1 active coefficients
--- 0.26558709144592285 seconds for one epoch ---
--- 0.2917819023132324 seconds for one epoch ---
--- 0.9709875583648682 seconds for one epoch ---
--- 0.2960951328277588 seconds for one epoch ---
--- 0.9757068157196045 seconds for one epoch ---
--- 0.29761338233947754 seconds for one epoch ---
--- 0.9876120090484619 seconds for one epoch ---
--- 0.3001232147216797 seconds for one epoch ---
--- 0.9898452758789062 seconds for one epoch ---
--- 0.28850769996643066 seconds for one epoch ---
--- 0.9712297916412354 seconds for one epoch ---
--- 0.2981996536254883 seconds for one epoch ---
--- 0.9609341621398926 seconds for one epoch ---
--- 0.3030083179473877 seconds for one epoch ---
--- 0.9896113872528076 seconds for one epoch ---
--- 0.3023498058319092 seconds for one epoch ---
--- 0.9754319190979004 seconds for one epoch ---
--- 0.30208563804626465 seconds for one epoch ---
--- 0.9947047233581543 seconds for one epoch ---
--- 0.3022329807281494 seconds for one epoch ---
--- 0.9835731983184814 seconds for one epoch ---
--- 0.2941291332244873 seconds for one epoch ---
--- 0.9633636474609375 seconds for one epoch ---
--- 0.291947603225708 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999936]
 [0.       ]]
[[ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-9.18426]
 [-0.     ]]
--- 0.2578592300415039 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3041.165283203125, (1357.8574, 0.70402074, 1682.3121, 0.2916313)
   validation loss 962.1853637695312, (646.00024, 0.3939376, 315.49957, 0.2916313)
decoder loss ratio: 25027.170964, decoder SINDy loss  ratio: 0.681050
--- 0.29201793670654297 seconds for one epoch ---
--- 0.9665331840515137 seconds for one epoch ---
--- 0.31209850311279297 seconds for one epoch ---
--- 0.9939446449279785 seconds for one epoch ---
--- 0.32943177223205566 seconds for one epoch ---
--- 1.021515130996704 seconds for one epoch ---
--- 0.3440079689025879 seconds for one epoch ---
--- 1.0015277862548828 seconds for one epoch ---
--- 0.3206150531768799 seconds for one epoch ---
--- 1.0143234729766846 seconds for one epoch ---
--- 0.3396158218383789 seconds for one epoch ---
--- 1.0017542839050293 seconds for one epoch ---
--- 0.3248023986816406 seconds for one epoch ---
--- 0.9888336658477783 seconds for one epoch ---
--- 0.327085018157959 seconds for one epoch ---
--- 0.9880132675170898 seconds for one epoch ---
--- 0.30732011795043945 seconds for one epoch ---
--- 1.0002086162567139 seconds for one epoch ---
--- 0.3044257164001465 seconds for one epoch ---
--- 1.0177967548370361 seconds for one epoch ---
--- 0.31601428985595703 seconds for one epoch ---
--- 0.9983677864074707 seconds for one epoch ---
--- 0.28679776191711426 seconds for one epoch ---
--- 0.9883720874786377 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999935]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.417625]
 [-0.      ]]
--- 0.2951231002807617 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3053.513427734375, (1302.1938, 1.6102135, 1749.4147, 0.29476604)
   validation loss 851.5300903320312, (580.6949, 0.40780735, 270.13266, 0.29476604)
decoder loss ratio: 22497.127985, decoder SINDy loss  ratio: 0.583119
--- 0.2542378902435303 seconds for one epoch ---
--- 0.28474926948547363 seconds for one epoch ---
--- 0.9793453216552734 seconds for one epoch ---
--- 0.3166236877441406 seconds for one epoch ---
--- 0.9789102077484131 seconds for one epoch ---
--- 0.3203613758087158 seconds for one epoch ---
--- 0.9814584255218506 seconds for one epoch ---
--- 0.3287792205810547 seconds for one epoch ---
--- 1.0118324756622314 seconds for one epoch ---
--- 0.3261377811431885 seconds for one epoch ---
--- 0.9994411468505859 seconds for one epoch ---
--- 0.31540536880493164 seconds for one epoch ---
--- 1.0060713291168213 seconds for one epoch ---
--- 0.31058716773986816 seconds for one epoch ---
--- 1.0120491981506348 seconds for one epoch ---
--- 0.3060119152069092 seconds for one epoch ---
--- 1.017237901687622 seconds for one epoch ---
--- 0.2961099147796631 seconds for one epoch ---
--- 1.0197923183441162 seconds for one epoch ---
--- 0.29880523681640625 seconds for one epoch ---
--- 1.0047307014465332 seconds for one epoch ---
--- 0.2904527187347412 seconds for one epoch ---
--- 0.9821376800537109 seconds for one epoch ---
--- 0.29495954513549805 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999935]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.644565]
 [-0.      ]]
--- 0.25186657905578613 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3587.43603515625, (1515.9738, 0.759616, 2070.4048, 0.29789636)
   validation loss 1110.062255859375, (766.3847, 0.38253394, 342.99713, 0.29789636)
decoder loss ratio: 29691.073958, decoder SINDy loss  ratio: 0.740408
--- 0.2830688953399658 seconds for one epoch ---
--- 1.0056922435760498 seconds for one epoch ---
--- 0.2876589298248291 seconds for one epoch ---
--- 0.9777021408081055 seconds for one epoch ---
--- 0.2872469425201416 seconds for one epoch ---
--- 1.0024280548095703 seconds for one epoch ---
--- 0.3045368194580078 seconds for one epoch ---
--- 0.9913842678070068 seconds for one epoch ---
--- 0.3046090602874756 seconds for one epoch ---
--- 1.037515640258789 seconds for one epoch ---
--- 0.292339563369751 seconds for one epoch ---
--- 0.9871740341186523 seconds for one epoch ---
--- 0.2904088497161865 seconds for one epoch ---
--- 1.0063273906707764 seconds for one epoch ---
--- 0.2963535785675049 seconds for one epoch ---
--- 1.0074069499969482 seconds for one epoch ---
--- 0.2926623821258545 seconds for one epoch ---
--- 1.0174996852874756 seconds for one epoch ---
--- 0.30904603004455566 seconds for one epoch ---
--- 1.016754150390625 seconds for one epoch ---
--- 0.29233384132385254 seconds for one epoch ---
--- 1.0066380500793457 seconds for one epoch ---
--- 0.29144763946533203 seconds for one epoch ---
--- 1.0262048244476318 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999934]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.847728]
 [ 0.      ]]
--- 0.30209875106811523 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2239.0322265625, (918.2853, 2.121092, 1318.3252, 0.30082616)
   validation loss 955.4660034179688, (650.1478, 0.38751036, 304.6298, 0.30082616)
decoder loss ratio: 25187.855530, decoder SINDy loss  ratio: 0.657586
--- 0.26494669914245605 seconds for one epoch ---
--- 0.29503536224365234 seconds for one epoch ---
--- 1.0357849597930908 seconds for one epoch ---
--- 0.2869899272918701 seconds for one epoch ---
--- 0.9795098304748535 seconds for one epoch ---
--- 0.3029611110687256 seconds for one epoch ---
--- 1.0161027908325195 seconds for one epoch ---
--- 0.3232581615447998 seconds for one epoch ---
--- 1.0169174671173096 seconds for one epoch ---
--- 0.3295567035675049 seconds for one epoch ---
--- 1.0324299335479736 seconds for one epoch ---
--- 0.32787513732910156 seconds for one epoch ---
--- 1.035327672958374 seconds for one epoch ---
--- 0.32610225677490234 seconds for one epoch ---
--- 1.0567235946655273 seconds for one epoch ---
--- 0.3214752674102783 seconds for one epoch ---
--- 1.0622222423553467 seconds for one epoch ---
--- 0.3209552764892578 seconds for one epoch ---
--- 1.0270936489105225 seconds for one epoch ---
--- 0.2983896732330322 seconds for one epoch ---
--- 1.043323040008545 seconds for one epoch ---
--- 0.31033992767333984 seconds for one epoch ---
--- 1.0271141529083252 seconds for one epoch ---
--- 0.29064488410949707 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999934]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.058409]
 [  0.      ]]
--- 0.2562828063964844 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3662.23486328125, (1343.6582, 1.2367207, 2317.0364, 0.30377045)
   validation loss 994.9842529296875, (678.56055, 0.2767514, 315.8432, 0.30377045)
decoder loss ratio: 26288.613619, decoder SINDy loss  ratio: 0.681792
--- 0.296694278717041 seconds for one epoch ---
--- 1.0169837474822998 seconds for one epoch ---
--- 0.28516697883605957 seconds for one epoch ---
--- 0.9793269634246826 seconds for one epoch ---
--- 0.2810492515563965 seconds for one epoch ---
--- 1.0243899822235107 seconds for one epoch ---
--- 0.2994351387023926 seconds for one epoch ---
--- 0.987656831741333 seconds for one epoch ---
--- 0.28871917724609375 seconds for one epoch ---
--- 1.0428767204284668 seconds for one epoch ---
--- 0.29268407821655273 seconds for one epoch ---
--- 1.0428977012634277 seconds for one epoch ---
--- 0.3002786636352539 seconds for one epoch ---
--- 1.0278613567352295 seconds for one epoch ---
--- 0.2843358516693115 seconds for one epoch ---
--- 1.0160326957702637 seconds for one epoch ---
--- 0.2985837459564209 seconds for one epoch ---
--- 1.0261640548706055 seconds for one epoch ---
--- 0.2834901809692383 seconds for one epoch ---
--- 1.0508229732513428 seconds for one epoch ---
--- 0.2951972484588623 seconds for one epoch ---
--- 1.0317540168762207 seconds for one epoch ---
--- 0.2938194274902344 seconds for one epoch ---
--- 1.0375230312347412 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999326]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.258104]
 [  0.      ]]
--- 0.318678617477417 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2615.34130859375, (1367.5981, 1.1863527, 1246.25, 0.30674964)
   validation loss 1368.5611572265625, (1033.7981, 0.38436973, 334.0719, 0.30674964)
decoder loss ratio: 40051.132980, decoder SINDy loss  ratio: 0.721141
--- 0.25089573860168457 seconds for one epoch ---
--- 0.2800002098083496 seconds for one epoch ---
--- 1.0040535926818848 seconds for one epoch ---
--- 0.28148388862609863 seconds for one epoch ---
--- 1.010648488998413 seconds for one epoch ---
--- 0.2971065044403076 seconds for one epoch ---
--- 1.0319509506225586 seconds for one epoch ---
--- 0.2854177951812744 seconds for one epoch ---
--- 1.0371778011322021 seconds for one epoch ---
--- 0.2920055389404297 seconds for one epoch ---
--- 1.011181116104126 seconds for one epoch ---
--- 0.2942826747894287 seconds for one epoch ---
--- 1.0603833198547363 seconds for one epoch ---
--- 0.2951505184173584 seconds for one epoch ---
--- 1.0390806198120117 seconds for one epoch ---
--- 0.29567384719848633 seconds for one epoch ---
--- 1.0430738925933838 seconds for one epoch ---
--- 0.28946805000305176 seconds for one epoch ---
--- 1.0489468574523926 seconds for one epoch ---
--- 0.2827889919281006 seconds for one epoch ---
--- 1.037674903869629 seconds for one epoch ---
--- 0.2994835376739502 seconds for one epoch ---
--- 1.032743215560913 seconds for one epoch ---
--- 0.30390095710754395 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999934]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.466069]
 [ -0.      ]]
--- 0.24872612953186035 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2807.902099609375, (1523.0073, 2.9418437, 1281.6432, 0.30988598)
   validation loss 1015.8238525390625, (698.4014, 0.40058792, 316.71198, 0.30988598)
decoder loss ratio: 27057.283808, decoder SINDy loss  ratio: 0.683667
--- 0.31371593475341797 seconds for one epoch ---
--- 1.043680191040039 seconds for one epoch ---
--- 0.301560640335083 seconds for one epoch ---
--- 1.0458099842071533 seconds for one epoch ---
--- 0.3046712875366211 seconds for one epoch ---
--- 1.0375080108642578 seconds for one epoch ---
--- 0.2928180694580078 seconds for one epoch ---
--- 1.0424368381500244 seconds for one epoch ---
--- 0.30110716819763184 seconds for one epoch ---
--- 1.07920503616333 seconds for one epoch ---
--- 0.29998326301574707 seconds for one epoch ---
--- 1.020076036453247 seconds for one epoch ---
--- 0.29714226722717285 seconds for one epoch ---
--- 1.0621123313903809 seconds for one epoch ---
--- 0.3017082214355469 seconds for one epoch ---
--- 1.04189133644104 seconds for one epoch ---
--- 0.29178571701049805 seconds for one epoch ---
--- 1.06461763381958 seconds for one epoch ---
--- 0.2934608459472656 seconds for one epoch ---
--- 1.0838706493377686 seconds for one epoch ---
--- 0.29022765159606934 seconds for one epoch ---
--- 1.0515828132629395 seconds for one epoch ---
--- 0.28696227073669434 seconds for one epoch ---
--- 1.1044268608093262 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999344]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.653478]
 [ -0.      ]]
--- 0.2917354106903076 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5784.8505859375, (1788.8059, 1.1765459, 3994.5557, 0.31274074)
   validation loss 951.113525390625, (660.17377, 0.30630535, 290.32068, 0.31274074)
decoder loss ratio: 25576.277849, decoder SINDy loss  ratio: 0.626698
--- 0.26619410514831543 seconds for one epoch ---
--- 0.3141632080078125 seconds for one epoch ---
--- 1.1045854091644287 seconds for one epoch ---
--- 0.317673921585083 seconds for one epoch ---
--- 1.0739362239837646 seconds for one epoch ---
--- 0.2983682155609131 seconds for one epoch ---
--- 1.0765964984893799 seconds for one epoch ---
--- 0.3057408332824707 seconds for one epoch ---
--- 1.0931429862976074 seconds for one epoch ---
--- 0.2888784408569336 seconds for one epoch ---
--- 1.1054470539093018 seconds for one epoch ---
--- 0.5111134052276611 seconds for one epoch ---
--- 1.0393366813659668 seconds for one epoch ---
--- 0.29636573791503906 seconds for one epoch ---
--- 1.0661392211914062 seconds for one epoch ---
--- 0.2950119972229004 seconds for one epoch ---
--- 1.0998773574829102 seconds for one epoch ---
--- 0.33276796340942383 seconds for one epoch ---
--- 1.0760157108306885 seconds for one epoch ---
--- 0.3135364055633545 seconds for one epoch ---
--- 1.0852141380310059 seconds for one epoch ---
--- 0.273470401763916 seconds for one epoch ---
--- 1.0917305946350098 seconds for one epoch ---
--- 0.2869746685028076 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999949]
 [0.       ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-10.8531065]
 [ -0.       ]]
--- 0.2575514316558838 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2415.033203125, (1224.7007, 7.435338, 1182.5812, 0.3158927)
   validation loss 861.1724853515625, (588.62683, 0.4251612, 271.8046, 0.3158927)
decoder loss ratio: 22804.425336, decoder SINDy loss  ratio: 0.586728
--- 0.28289365768432617 seconds for one epoch ---
--- 1.0479846000671387 seconds for one epoch ---
--- 0.28946423530578613 seconds for one epoch ---
--- 1.0665738582611084 seconds for one epoch ---
--- 0.2930490970611572 seconds for one epoch ---
--- 1.0546817779541016 seconds for one epoch ---
--- 0.3012425899505615 seconds for one epoch ---
--- 1.0548431873321533 seconds for one epoch ---
--- 0.29654693603515625 seconds for one epoch ---
--- 1.087284803390503 seconds for one epoch ---
--- 0.2862420082092285 seconds for one epoch ---
--- 1.0839226245880127 seconds for one epoch ---
--- 0.2935655117034912 seconds for one epoch ---
--- 1.114156723022461 seconds for one epoch ---
--- 0.29618310928344727 seconds for one epoch ---
--- 1.0545692443847656 seconds for one epoch ---
--- 0.3080899715423584 seconds for one epoch ---
--- 1.0720219612121582 seconds for one epoch ---
--- 0.29698944091796875 seconds for one epoch ---
--- 1.0878992080688477 seconds for one epoch ---
--- 0.2941594123840332 seconds for one epoch ---
--- 1.0807673931121826 seconds for one epoch ---
--- 0.2898550033569336 seconds for one epoch ---
--- 1.0762031078338623 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999964]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.018745]
 [  0.      ]]
--- 0.28464388847351074 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4817.1884765625, (1803.0015, 2.1211174, 3011.7476, 0.3185548)
   validation loss 1271.2628173828125, (963.91473, 0.34811378, 306.68143, 0.3185548)
decoder loss ratio: 37343.730220, decoder SINDy loss  ratio: 0.662015
--- 0.2749145030975342 seconds for one epoch ---
--- 0.2971034049987793 seconds for one epoch ---
--- 1.0905978679656982 seconds for one epoch ---
--- 0.30480527877807617 seconds for one epoch ---
--- 1.1113200187683105 seconds for one epoch ---
--- 0.29844069480895996 seconds for one epoch ---
--- 1.0849976539611816 seconds for one epoch ---
--- 0.29091715812683105 seconds for one epoch ---
--- 1.1094677448272705 seconds for one epoch ---
--- 0.2927098274230957 seconds for one epoch ---
--- 1.1154725551605225 seconds for one epoch ---
--- 0.29685044288635254 seconds for one epoch ---
--- 1.1237306594848633 seconds for one epoch ---
--- 0.2833995819091797 seconds for one epoch ---
--- 1.1107385158538818 seconds for one epoch ---
--- 0.2989006042480469 seconds for one epoch ---
--- 1.072918176651001 seconds for one epoch ---
--- 0.29443931579589844 seconds for one epoch ---
--- 1.116755485534668 seconds for one epoch ---
--- 0.29498291015625 seconds for one epoch ---
--- 1.1357672214508057 seconds for one epoch ---
--- 0.289470911026001 seconds for one epoch ---
--- 1.1082351207733154 seconds for one epoch ---
--- 0.2983720302581787 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.207008]
 [  0.      ]]
--- 0.27005815505981445 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3307.166259765625, (1758.8271, 0.66360134, 1547.3539, 0.32160866)
   validation loss 1390.4736328125, (1063.2129, 0.5990906, 326.33994, 0.32160866)
decoder loss ratio: 41190.713202, decoder SINDy loss  ratio: 0.704451
--- 0.31043219566345215 seconds for one epoch ---
--- 1.1359291076660156 seconds for one epoch ---
--- 0.29312849044799805 seconds for one epoch ---
--- 1.1315665245056152 seconds for one epoch ---
--- 0.29587769508361816 seconds for one epoch ---
--- 1.127229928970337 seconds for one epoch ---
--- 0.29491472244262695 seconds for one epoch ---
--- 1.0969359874725342 seconds for one epoch ---
--- 0.3023808002471924 seconds for one epoch ---
--- 1.1066155433654785 seconds for one epoch ---
--- 0.29732513427734375 seconds for one epoch ---
--- 1.1110951900482178 seconds for one epoch ---
--- 0.29697704315185547 seconds for one epoch ---
--- 1.1158504486083984 seconds for one epoch ---
--- 0.2865464687347412 seconds for one epoch ---
--- 1.1181414127349854 seconds for one epoch ---
--- 0.28954195976257324 seconds for one epoch ---
--- 1.1213974952697754 seconds for one epoch ---
--- 0.2947807312011719 seconds for one epoch ---
--- 1.0754213333129883 seconds for one epoch ---
--- 0.2924976348876953 seconds for one epoch ---
--- 1.1477370262145996 seconds for one epoch ---
--- 0.29683399200439453 seconds for one epoch ---
--- 1.1717956066131592 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.371003]
 [  0.      ]]
--- 0.2885317802429199 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2162.727294921875, (976.2098, 2.8966296, 1183.2968, 0.3242886)
   validation loss 1210.7685546875, (895.4185, 0.5951606, 314.4305, 0.3242886)
decoder loss ratio: 34690.067905, decoder SINDy loss  ratio: 0.678742
--- 0.2571384906768799 seconds for one epoch ---
--- 0.2941114902496338 seconds for one epoch ---
--- 1.1000950336456299 seconds for one epoch ---
--- 0.2942698001861572 seconds for one epoch ---
--- 1.0883419513702393 seconds for one epoch ---
--- 0.29425859451293945 seconds for one epoch ---
--- 1.1128771305084229 seconds for one epoch ---
--- 0.28913378715515137 seconds for one epoch ---
--- 1.141911506652832 seconds for one epoch ---
--- 0.29204607009887695 seconds for one epoch ---
--- 1.131545066833496 seconds for one epoch ---
--- 0.29088783264160156 seconds for one epoch ---
--- 1.1215710639953613 seconds for one epoch ---
--- 0.2944469451904297 seconds for one epoch ---
--- 1.1252801418304443 seconds for one epoch ---
--- 0.2887899875640869 seconds for one epoch ---
--- 1.1257987022399902 seconds for one epoch ---
--- 0.28742194175720215 seconds for one epoch ---
--- 1.1655542850494385 seconds for one epoch ---
--- 0.2932474613189697 seconds for one epoch ---
--- 1.0858774185180664 seconds for one epoch ---
--- 0.27559423446655273 seconds for one epoch ---
--- 1.1296100616455078 seconds for one epoch ---
--- 0.3017549514770508 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999995]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-11.53169]
 [ -0.     ]]
--- 0.2579319477081299 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2244.503173828125, (1203.1252, 0.9474266, 1040.1035, 0.32695547)
   validation loss 959.8886108398438, (683.59064, 0.79447657, 275.1765, 0.32695547)
decoder loss ratio: 26483.488051, decoder SINDy loss  ratio: 0.594007
--- 0.30316996574401855 seconds for one epoch ---
--- 1.1262495517730713 seconds for one epoch ---
--- 0.3104372024536133 seconds for one epoch ---
--- 1.1303765773773193 seconds for one epoch ---
--- 0.31976318359375 seconds for one epoch ---
--- 1.142054557800293 seconds for one epoch ---
--- 0.3244900703430176 seconds for one epoch ---
--- 1.1639180183410645 seconds for one epoch ---
--- 0.3153400421142578 seconds for one epoch ---
--- 1.1887507438659668 seconds for one epoch ---
--- 0.29409360885620117 seconds for one epoch ---
--- 1.1471471786499023 seconds for one epoch ---
--- 0.2965888977050781 seconds for one epoch ---
--- 1.1678059101104736 seconds for one epoch ---
--- 0.29976987838745117 seconds for one epoch ---
--- 1.1297752857208252 seconds for one epoch ---
--- 0.2925596237182617 seconds for one epoch ---
--- 1.1515395641326904 seconds for one epoch ---
--- 0.28087615966796875 seconds for one epoch ---
--- 1.172715187072754 seconds for one epoch ---
--- 0.29875612258911133 seconds for one epoch ---
--- 1.1221046447753906 seconds for one epoch ---
--- 0.3049027919769287 seconds for one epoch ---
--- 1.1349575519561768 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999995]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.726527]
 [ -0.      ]]
--- 0.293670654296875 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2856.168701171875, (1149.4183, 0.41161367, 1706.0085, 0.3302365)
   validation loss 971.2007446289062, (665.6925, 0.59958273, 304.57834, 0.3302365)
decoder loss ratio: 25790.083332, decoder SINDy loss  ratio: 0.657475
--- 0.25150299072265625 seconds for one epoch ---
--- 0.294858455657959 seconds for one epoch ---
--- 1.1371936798095703 seconds for one epoch ---
--- 0.2883474826812744 seconds for one epoch ---
--- 1.1493268013000488 seconds for one epoch ---
--- 0.29935359954833984 seconds for one epoch ---
--- 1.14296555519104 seconds for one epoch ---
--- 0.2955918312072754 seconds for one epoch ---
--- 1.1441097259521484 seconds for one epoch ---
--- 0.2968451976776123 seconds for one epoch ---
--- 1.1431090831756592 seconds for one epoch ---
--- 0.29276156425476074 seconds for one epoch ---
--- 1.1390974521636963 seconds for one epoch ---
--- 0.29883837699890137 seconds for one epoch ---
--- 1.1215977668762207 seconds for one epoch ---
--- 0.29562830924987793 seconds for one epoch ---
--- 1.1551260948181152 seconds for one epoch ---
--- 0.28857994079589844 seconds for one epoch ---
--- 1.1486186981201172 seconds for one epoch ---
--- 0.28925275802612305 seconds for one epoch ---
--- 1.1410799026489258 seconds for one epoch ---
--- 0.28066444396972656 seconds for one epoch ---
--- 1.0993740558624268 seconds for one epoch ---
--- 0.27460455894470215 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999995]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.903189]
 [ -0.      ]]
--- 0.25440311431884766 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2148.291748046875, (1136.5283, 1.837861, 1009.5923, 0.33326098)
   validation loss 782.2618408203125, (516.5439, 0.7593433, 264.62537, 0.33326098)
decoder loss ratio: 20011.806837, decoder SINDy loss  ratio: 0.571231
--- 0.28605222702026367 seconds for one epoch ---
--- 1.1516492366790771 seconds for one epoch ---
--- 0.2966158390045166 seconds for one epoch ---
--- 1.130077838897705 seconds for one epoch ---
--- 0.28870105743408203 seconds for one epoch ---
--- 1.1559240818023682 seconds for one epoch ---
--- 0.29129767417907715 seconds for one epoch ---
--- 1.1839790344238281 seconds for one epoch ---
--- 0.2954378128051758 seconds for one epoch ---
--- 1.173511266708374 seconds for one epoch ---
--- 0.2947118282318115 seconds for one epoch ---
--- 1.175597906112671 seconds for one epoch ---
--- 0.28784966468811035 seconds for one epoch ---
--- 1.1530134677886963 seconds for one epoch ---
--- 0.29886651039123535 seconds for one epoch ---
--- 1.164147138595581 seconds for one epoch ---
--- 0.28868746757507324 seconds for one epoch ---
--- 1.143568515777588 seconds for one epoch ---
--- 0.29432129859924316 seconds for one epoch ---
--- 1.1461310386657715 seconds for one epoch ---
--- 0.2815241813659668 seconds for one epoch ---
--- 1.1457056999206543 seconds for one epoch ---
--- 0.289478063583374 seconds for one epoch ---
--- 1.1676716804504395 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999995]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.055221]
 [  0.      ]]
--- 0.2961463928222656 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2210.11767578125, (1216.2737, 1.2139643, 992.29407, 0.33592805)
   validation loss 922.0679931640625, (633.65125, 0.672088, 287.40875, 0.33592805)
decoder loss ratio: 24548.749303, decoder SINDy loss  ratio: 0.620412
--- 0.2554011344909668 seconds for one epoch ---
--- 0.29460740089416504 seconds for one epoch ---
--- 1.1695890426635742 seconds for one epoch ---
--- 0.28989720344543457 seconds for one epoch ---
--- 1.1571259498596191 seconds for one epoch ---
--- 0.29663705825805664 seconds for one epoch ---
--- 1.164414644241333 seconds for one epoch ---
--- 0.28914427757263184 seconds for one epoch ---
--- 1.1805732250213623 seconds for one epoch ---
--- 0.2961459159851074 seconds for one epoch ---
--- 1.173417568206787 seconds for one epoch ---
--- 0.297149658203125 seconds for one epoch ---
--- 1.186725378036499 seconds for one epoch ---
--- 0.2889368534088135 seconds for one epoch ---
--- 1.184051275253296 seconds for one epoch ---
--- 0.29795336723327637 seconds for one epoch ---
--- 1.1593234539031982 seconds for one epoch ---
--- 0.2994554042816162 seconds for one epoch ---
--- 1.185403823852539 seconds for one epoch ---
--- 0.2966010570526123 seconds for one epoch ---
--- 1.1739141941070557 seconds for one epoch ---
--- 0.292680025100708 seconds for one epoch ---
--- 1.1827619075775146 seconds for one epoch ---
--- 0.29445934295654297 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999995]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.220446]
 [  0.      ]]
--- 0.26076745986938477 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3203.7939453125, (1435.677, 2.5981255, 1765.1798, 0.33879027)
   validation loss 1184.6761474609375, (888.5887, 0.8010426, 294.9477, 0.33879027)
decoder loss ratio: 34425.468279, decoder SINDy loss  ratio: 0.636686
--- 0.29596567153930664 seconds for one epoch ---
--- 1.14198899269104 seconds for one epoch ---
--- 0.277249813079834 seconds for one epoch ---
--- 1.1339998245239258 seconds for one epoch ---
--- 0.2966887950897217 seconds for one epoch ---
--- 1.1699903011322021 seconds for one epoch ---
--- 0.31713104248046875 seconds for one epoch ---
--- 1.1466484069824219 seconds for one epoch ---
--- 0.2933840751647949 seconds for one epoch ---
--- 1.1670727729797363 seconds for one epoch ---
--- 0.2949683666229248 seconds for one epoch ---
--- 1.1849780082702637 seconds for one epoch ---
--- 0.29787588119506836 seconds for one epoch ---
--- 1.183438777923584 seconds for one epoch ---
--- 0.300978422164917 seconds for one epoch ---
--- 1.183413028717041 seconds for one epoch ---
--- 0.29582691192626953 seconds for one epoch ---
--- 1.1855485439300537 seconds for one epoch ---
--- 0.2922999858856201 seconds for one epoch ---
--- 1.188180923461914 seconds for one epoch ---
--- 0.2944772243499756 seconds for one epoch ---
--- 1.182332992553711 seconds for one epoch ---
--- 0.2888169288635254 seconds for one epoch ---
--- 1.17002272605896 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.358968]
 [  0.      ]]
--- 0.2847719192504883 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3857.736328125, (2018.1222, 1.1178622, 1838.1549, 0.3412789)
   validation loss 1463.9326171875, (1174.1208, 0.85810435, 288.61234, 0.3412789)
decoder loss ratio: 45487.480077, decoder SINDy loss  ratio: 0.623010
--- 0.25860095024108887 seconds for one epoch ---
--- 0.2871556282043457 seconds for one epoch ---
--- 1.1469945907592773 seconds for one epoch ---
--- 0.29144906997680664 seconds for one epoch ---
--- 1.1419358253479004 seconds for one epoch ---
--- 0.29415130615234375 seconds for one epoch ---
--- 1.187396764755249 seconds for one epoch ---
--- 0.2886192798614502 seconds for one epoch ---
--- 1.1934406757354736 seconds for one epoch ---
--- 0.2925231456756592 seconds for one epoch ---
--- 1.209829330444336 seconds for one epoch ---
--- 0.299548864364624 seconds for one epoch ---
--- 1.1864013671875 seconds for one epoch ---
--- 0.2862837314605713 seconds for one epoch ---
--- 1.1828932762145996 seconds for one epoch ---
--- 0.29265832901000977 seconds for one epoch ---
--- 1.2104034423828125 seconds for one epoch ---
--- 0.3081345558166504 seconds for one epoch ---
--- 1.19635009765625 seconds for one epoch ---
--- 0.29300451278686523 seconds for one epoch ---
--- 1.1906318664550781 seconds for one epoch ---
--- 0.2946910858154297 seconds for one epoch ---
--- 1.1473240852355957 seconds for one epoch ---
--- 0.2965679168701172 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.482347]
 [ -0.      ]]
--- 0.25510716438293457 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2463.318359375, (1133.396, 1.9196857, 1327.6592, 0.34350917)
   validation loss 1429.2503662109375, (1043.5693, 0.7634943, 384.574, 0.34350917)
decoder loss ratio: 40429.687790, decoder SINDy loss  ratio: 0.830157
--- 0.29147863388061523 seconds for one epoch ---
--- 1.1875760555267334 seconds for one epoch ---
--- 0.2910909652709961 seconds for one epoch ---
--- 1.241030216217041 seconds for one epoch ---
--- 0.29721593856811523 seconds for one epoch ---
--- 1.2242228984832764 seconds for one epoch ---
--- 0.28714632987976074 seconds for one epoch ---
--- 1.194612979888916 seconds for one epoch ---
--- 0.2928445339202881 seconds for one epoch ---
--- 1.1757020950317383 seconds for one epoch ---
--- 0.2949092388153076 seconds for one epoch ---
--- 1.2120375633239746 seconds for one epoch ---
--- 0.3013441562652588 seconds for one epoch ---
--- 1.1860697269439697 seconds for one epoch ---
--- 0.29402875900268555 seconds for one epoch ---
--- 1.1985242366790771 seconds for one epoch ---
--- 0.27899956703186035 seconds for one epoch ---
--- 1.1687400341033936 seconds for one epoch ---
--- 0.28870463371276855 seconds for one epoch ---
--- 1.2063109874725342 seconds for one epoch ---
--- 0.29868602752685547 seconds for one epoch ---
--- 1.1578960418701172 seconds for one epoch ---
--- 0.28945159912109375 seconds for one epoch ---
--- 1.1942899227142334 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.614483]
 [ -0.      ]]
--- 0.2949028015136719 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5206.0263671875, (1760.9194, 3.369337, 3441.3916, 0.34594512)
   validation loss 1280.582275390625, (985.3836, 0.515486, 294.33722, 0.34594512)
decoder loss ratio: 38175.471596, decoder SINDy loss  ratio: 0.635368
THRESHOLDING: 1 active coefficients
--- 1.188920021057129 seconds for one epoch ---
--- 0.29651665687561035 seconds for one epoch ---
--- 1.2060997486114502 seconds for one epoch ---
--- 0.29143571853637695 seconds for one epoch ---
--- 1.1864326000213623 seconds for one epoch ---
--- 0.30116844177246094 seconds for one epoch ---
--- 1.2008624076843262 seconds for one epoch ---
--- 0.2646763324737549 seconds for one epoch ---
--- 1.2212445735931396 seconds for one epoch ---
--- 0.28728437423706055 seconds for one epoch ---
--- 1.1869661808013916 seconds for one epoch ---
--- 0.29743051528930664 seconds for one epoch ---
--- 1.1880781650543213 seconds for one epoch ---
--- 0.2802751064300537 seconds for one epoch ---
--- 1.220618724822998 seconds for one epoch ---
--- 0.2902095317840576 seconds for one epoch ---
--- 1.1928622722625732 seconds for one epoch ---
--- 0.294630765914917 seconds for one epoch ---
--- 1.1911201477050781 seconds for one epoch ---
--- 0.3064610958099365 seconds for one epoch ---
--- 1.245410442352295 seconds for one epoch ---
--- 0.30191874504089355 seconds for one epoch ---
--- 1.2317008972167969 seconds for one epoch ---
--- 0.2871994972229004 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-12.75844]
 [ -0.     ]]
--- 0.25089454650878906 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2957.12158203125, (1275.7323, 1.4269779, 1679.6135, 0.34859493)
   validation loss 892.4033813476562, (621.8498, 0.8947457, 269.31027, 0.34859493)
decoder loss ratio: 24091.540539, decoder SINDy loss  ratio: 0.581344
--- 0.30023622512817383 seconds for one epoch ---
--- 1.2106263637542725 seconds for one epoch ---
--- 0.28328752517700195 seconds for one epoch ---
--- 1.2311124801635742 seconds for one epoch ---
--- 0.28133487701416016 seconds for one epoch ---
--- 1.226511001586914 seconds for one epoch ---
--- 0.2860691547393799 seconds for one epoch ---
--- 1.2522242069244385 seconds for one epoch ---
--- 0.29461145401000977 seconds for one epoch ---
--- 1.2405974864959717 seconds for one epoch ---
--- 0.3041362762451172 seconds for one epoch ---
--- 1.2246859073638916 seconds for one epoch ---
--- 0.31206703186035156 seconds for one epoch ---
--- 1.242096185684204 seconds for one epoch ---
--- 0.31169939041137695 seconds for one epoch ---
--- 1.252504825592041 seconds for one epoch ---
--- 0.3146488666534424 seconds for one epoch ---
--- 1.2607150077819824 seconds for one epoch ---
--- 0.3083326816558838 seconds for one epoch ---
--- 1.2277908325195312 seconds for one epoch ---
--- 0.3233175277709961 seconds for one epoch ---
--- 1.2797331809997559 seconds for one epoch ---
--- 0.33115077018737793 seconds for one epoch ---
--- 1.2273781299591064 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.888362]
 [  0.      ]]
--- 0.28430962562561035 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4219.013671875, (1889.2655, 1.9240439, 2327.473, 0.35102335)
   validation loss 781.8688354492188, (510.95557, 0.89816433, 269.66412, 0.35102335)
decoder loss ratio: 19795.305700, decoder SINDy loss  ratio: 0.582108
--- 0.27163267135620117 seconds for one epoch ---
--- 0.2983520030975342 seconds for one epoch ---
--- 1.2128381729125977 seconds for one epoch ---
--- 0.2984302043914795 seconds for one epoch ---
--- 1.238541603088379 seconds for one epoch ---
--- 0.29735374450683594 seconds for one epoch ---
--- 1.2388544082641602 seconds for one epoch ---
--- 0.29066920280456543 seconds for one epoch ---
--- 1.2431352138519287 seconds for one epoch ---
--- 0.30141758918762207 seconds for one epoch ---
--- 1.2576618194580078 seconds for one epoch ---
--- 0.2989790439605713 seconds for one epoch ---
--- 1.2545268535614014 seconds for one epoch ---
--- 0.29352712631225586 seconds for one epoch ---
--- 1.2468664646148682 seconds for one epoch ---
--- 0.30437350273132324 seconds for one epoch ---
--- 1.2796907424926758 seconds for one epoch ---
--- 0.31497716903686523 seconds for one epoch ---
--- 1.2604036331176758 seconds for one epoch ---
--- 0.30449533462524414 seconds for one epoch ---
--- 1.2832293510437012 seconds for one epoch ---
--- 0.3175466060638428 seconds for one epoch ---
--- 1.2637102603912354 seconds for one epoch ---
--- 0.3193190097808838 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.017932]
 [  0.      ]]
--- 0.24109506607055664 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2494.555908203125, (997.6571, 5.0365505, 1491.5088, 0.3535029)
   validation loss 1470.703857421875, (1185.753, 0.6463021, 283.9509, 0.3535029)
decoder loss ratio: 45938.131783, decoder SINDy loss  ratio: 0.612948
--- 0.26654696464538574 seconds for one epoch ---
--- 1.2297320365905762 seconds for one epoch ---
--- 0.3190450668334961 seconds for one epoch ---
--- 1.2262794971466064 seconds for one epoch ---
--- 0.29753971099853516 seconds for one epoch ---
--- 1.2502961158752441 seconds for one epoch ---
--- 0.31122255325317383 seconds for one epoch ---
--- 1.2748486995697021 seconds for one epoch ---
--- 0.31673145294189453 seconds for one epoch ---
--- 1.2649977207183838 seconds for one epoch ---
--- 0.3055229187011719 seconds for one epoch ---
--- 1.3062963485717773 seconds for one epoch ---
--- 0.29860353469848633 seconds for one epoch ---
--- 1.2687351703643799 seconds for one epoch ---
--- 0.30258774757385254 seconds for one epoch ---
--- 1.2917087078094482 seconds for one epoch ---
--- 0.2866785526275635 seconds for one epoch ---
--- 1.3022525310516357 seconds for one epoch ---
--- 0.30638742446899414 seconds for one epoch ---
--- 1.2551076412200928 seconds for one epoch ---
--- 0.2910768985748291 seconds for one epoch ---
--- 1.251159429550171 seconds for one epoch ---
--- 0.2993311882019043 seconds for one epoch ---
--- 1.3054594993591309 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.156125]
 [  0.      ]]
--- 0.2769308090209961 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2420.561279296875, (1080.1559, 0.8504035, 1339.1987, 0.35609034)
   validation loss 837.469970703125, (557.3707, 0.65126544, 279.09192, 0.35609034)
decoder loss ratio: 21593.509623, decoder SINDy loss  ratio: 0.602459
--- 0.26031923294067383 seconds for one epoch ---
--- 0.2955961227416992 seconds for one epoch ---
--- 1.2766175270080566 seconds for one epoch ---
--- 0.3025059700012207 seconds for one epoch ---
--- 1.2851626873016357 seconds for one epoch ---
--- 0.30460095405578613 seconds for one epoch ---
--- 1.2703680992126465 seconds for one epoch ---
--- 0.29998183250427246 seconds for one epoch ---
--- 1.2993712425231934 seconds for one epoch ---
--- 0.3088033199310303 seconds for one epoch ---
--- 1.2783524990081787 seconds for one epoch ---
--- 0.2878439426422119 seconds for one epoch ---
--- 1.2737493515014648 seconds for one epoch ---
--- 0.32082366943359375 seconds for one epoch ---
--- 1.2683308124542236 seconds for one epoch ---
--- 0.33790016174316406 seconds for one epoch ---
--- 1.2743725776672363 seconds for one epoch ---
--- 0.32738280296325684 seconds for one epoch ---
--- 1.3069560527801514 seconds for one epoch ---
--- 0.33057260513305664 seconds for one epoch ---
--- 1.3106791973114014 seconds for one epoch ---
--- 0.3231804370880127 seconds for one epoch ---
--- 1.3076179027557373 seconds for one epoch ---
--- 0.34755706787109375 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.280665]
 [ -0.      ]]
--- 0.25821900367736816 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3524.0615234375, (2013.1953, 2.054189, 1508.4535, 0.3584826)
   validation loss 844.855224609375, (557.74023, 0.60280144, 286.15375, 0.3584826)
decoder loss ratio: 21607.824959, decoder SINDy loss  ratio: 0.617703
--- 0.2789797782897949 seconds for one epoch ---
--- 1.2694504261016846 seconds for one epoch ---
--- 0.29834437370300293 seconds for one epoch ---
--- 1.2705111503601074 seconds for one epoch ---
--- 0.3125951290130615 seconds for one epoch ---
--- 1.2563502788543701 seconds for one epoch ---
--- 0.30430030822753906 seconds for one epoch ---
--- 1.2962846755981445 seconds for one epoch ---
--- 0.29901719093322754 seconds for one epoch ---
--- 1.289628028869629 seconds for one epoch ---
--- 0.2991769313812256 seconds for one epoch ---
--- 1.2882816791534424 seconds for one epoch ---
--- 0.2972736358642578 seconds for one epoch ---
--- 1.2898962497711182 seconds for one epoch ---
--- 0.30612754821777344 seconds for one epoch ---
--- 1.2770674228668213 seconds for one epoch ---
--- 0.2813832759857178 seconds for one epoch ---
--- 1.273158073425293 seconds for one epoch ---
--- 0.3006937503814697 seconds for one epoch ---
--- 1.2894797325134277 seconds for one epoch ---
--- 0.29627442359924316 seconds for one epoch ---
--- 1.278688907623291 seconds for one epoch ---
--- 0.2902345657348633 seconds for one epoch ---
--- 1.2669172286987305 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.398089]
 [ -0.      ]]
--- 0.29053425788879395 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1841.697265625, (757.4052, 0.33111048, 1083.6001, 0.360846)
   validation loss 742.8896484375, (458.14352, 0.42739558, 283.9579, 0.360846)
decoder loss ratio: 17749.275498, decoder SINDy loss  ratio: 0.612963
--- 0.2634871006011963 seconds for one epoch ---
--- 0.2944817543029785 seconds for one epoch ---
--- 1.2809641361236572 seconds for one epoch ---
--- 0.2910792827606201 seconds for one epoch ---
--- 1.2729425430297852 seconds for one epoch ---
--- 0.28493738174438477 seconds for one epoch ---
--- 1.278454303741455 seconds for one epoch ---
--- 0.29937148094177246 seconds for one epoch ---
--- 1.2862353324890137 seconds for one epoch ---
--- 0.30032968521118164 seconds for one epoch ---
--- 1.3013417720794678 seconds for one epoch ---
--- 0.2826826572418213 seconds for one epoch ---
--- 1.2973902225494385 seconds for one epoch ---
--- 0.28920459747314453 seconds for one epoch ---
--- 1.2897067070007324 seconds for one epoch ---
--- 0.30291008949279785 seconds for one epoch ---
--- 1.301133632659912 seconds for one epoch ---
--- 0.30954813957214355 seconds for one epoch ---
--- 1.3120908737182617 seconds for one epoch ---
--- 0.3092179298400879 seconds for one epoch ---
--- 1.2804605960845947 seconds for one epoch ---
--- 0.30635786056518555 seconds for one epoch ---
--- 1.3220839500427246 seconds for one epoch ---
--- 0.31078290939331055 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.519994]
 [ -0.      ]]
--- 0.25594401359558105 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2467.8544921875, (1523.868, 1.2466637, 942.37634, 0.3632364)
   validation loss 812.8190307617188, (521.5561, 0.469133, 290.43063, 0.3632364)
decoder loss ratio: 20205.988438, decoder SINDy loss  ratio: 0.626935
--- 0.2868168354034424 seconds for one epoch ---
--- 1.2637498378753662 seconds for one epoch ---
--- 0.2854502201080322 seconds for one epoch ---
--- 1.2894165515899658 seconds for one epoch ---
--- 0.2725100517272949 seconds for one epoch ---
--- 1.2883739471435547 seconds for one epoch ---
--- 0.3081376552581787 seconds for one epoch ---
--- 1.3258728981018066 seconds for one epoch ---
--- 0.30086231231689453 seconds for one epoch ---
--- 1.2919275760650635 seconds for one epoch ---
--- 0.3090076446533203 seconds for one epoch ---
--- 1.308189868927002 seconds for one epoch ---
--- 0.2865612506866455 seconds for one epoch ---
--- 1.3027756214141846 seconds for one epoch ---
--- 0.2955794334411621 seconds for one epoch ---
--- 1.2980103492736816 seconds for one epoch ---
--- 0.3022148609161377 seconds for one epoch ---
--- 1.3131039142608643 seconds for one epoch ---
--- 0.296705961227417 seconds for one epoch ---
--- 1.3241829872131348 seconds for one epoch ---
--- 0.30249643325805664 seconds for one epoch ---
--- 1.3121168613433838 seconds for one epoch ---
--- 0.292757511138916 seconds for one epoch ---
--- 1.3198270797729492 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.659246]
 [  0.      ]]
--- 0.3013484477996826 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3334.939453125, (1746.5476, 0.915048, 1587.1108, 0.36587057)
   validation loss 862.464599609375, (567.7661, 0.6158969, 293.71674, 0.36587057)
decoder loss ratio: 21996.244914, decoder SINDy loss  ratio: 0.634029
--- 0.2598898410797119 seconds for one epoch ---
--- 0.296781063079834 seconds for one epoch ---
--- 1.269454002380371 seconds for one epoch ---
--- 0.2953617572784424 seconds for one epoch ---
--- 1.2611522674560547 seconds for one epoch ---
--- 0.298555850982666 seconds for one epoch ---
--- 1.3344333171844482 seconds for one epoch ---
--- 0.32154202461242676 seconds for one epoch ---
--- 1.3226652145385742 seconds for one epoch ---
--- 0.3192777633666992 seconds for one epoch ---
--- 1.3352282047271729 seconds for one epoch ---
--- 0.3089470863342285 seconds for one epoch ---
--- 1.2998437881469727 seconds for one epoch ---
--- 0.3167304992675781 seconds for one epoch ---
--- 1.319554328918457 seconds for one epoch ---
--- 0.3189711570739746 seconds for one epoch ---
--- 1.3405234813690186 seconds for one epoch ---
--- 0.30470943450927734 seconds for one epoch ---
--- 1.323777437210083 seconds for one epoch ---
--- 0.30324244499206543 seconds for one epoch ---
--- 1.350590705871582 seconds for one epoch ---
--- 0.3034796714782715 seconds for one epoch ---
--- 1.3311436176300049 seconds for one epoch ---
--- 0.3113710880279541 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.757841]
 [  0.      ]]
--- 0.26447534561157227 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4591.248046875, (1770.5779, 2.3218534, 2817.9807, 0.3679071)
   validation loss 1382.4068603515625, (1061.5702, 0.872234, 319.59656, 0.3679071)
decoder loss ratio: 41127.072144, decoder SINDy loss  ratio: 0.689894
--- 0.30022287368774414 seconds for one epoch ---
--- 1.317251443862915 seconds for one epoch ---
--- 0.280667781829834 seconds for one epoch ---
--- 1.2742977142333984 seconds for one epoch ---
--- 0.290921688079834 seconds for one epoch ---
--- 1.3134384155273438 seconds for one epoch ---
--- 0.302398681640625 seconds for one epoch ---
--- 1.3233060836791992 seconds for one epoch ---
--- 0.29316139221191406 seconds for one epoch ---
--- 1.330453872680664 seconds for one epoch ---
--- 0.2759113311767578 seconds for one epoch ---
--- 1.3334338665008545 seconds for one epoch ---
--- 0.29648447036743164 seconds for one epoch ---
--- 1.3316218852996826 seconds for one epoch ---
--- 0.29224586486816406 seconds for one epoch ---
--- 1.3271045684814453 seconds for one epoch ---
--- 0.3094766139984131 seconds for one epoch ---
--- 1.3194034099578857 seconds for one epoch ---
--- 0.30257272720336914 seconds for one epoch ---
--- 1.3327815532684326 seconds for one epoch ---
--- 0.2954671382904053 seconds for one epoch ---
--- 1.326164960861206 seconds for one epoch ---
--- 0.3002145290374756 seconds for one epoch ---
--- 1.3454627990722656 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.886298]
 [  0.      ]]
--- 0.29228734970092773 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3889.5087890625, (1258.0535, 2.5474875, 2628.537, 0.3705047)
   validation loss 1046.4364013671875, (755.6945, 0.663398, 289.70795, 0.3705047)
decoder loss ratio: 29276.917611, decoder SINDy loss  ratio: 0.625375
--- 0.2736527919769287 seconds for one epoch ---
--- 0.3025658130645752 seconds for one epoch ---
--- 1.336374282836914 seconds for one epoch ---
--- 0.2924051284790039 seconds for one epoch ---
--- 1.2944588661193848 seconds for one epoch ---
--- 0.2912745475769043 seconds for one epoch ---
--- 1.285646677017212 seconds for one epoch ---
--- 0.3163774013519287 seconds for one epoch ---
--- 1.3271586894989014 seconds for one epoch ---
--- 0.5383586883544922 seconds for one epoch ---
--- 1.3221569061279297 seconds for one epoch ---
--- 0.3106520175933838 seconds for one epoch ---
--- 1.3131227493286133 seconds for one epoch ---
--- 0.31039905548095703 seconds for one epoch ---
--- 1.364929437637329 seconds for one epoch ---
--- 0.2974228858947754 seconds for one epoch ---
--- 1.3435461521148682 seconds for one epoch ---
--- 0.3009054660797119 seconds for one epoch ---
--- 1.3013718128204346 seconds for one epoch ---
--- 0.301652193069458 seconds for one epoch ---
--- 1.3086018562316895 seconds for one epoch ---
--- 0.2913680076599121 seconds for one epoch ---
--- 1.3538684844970703 seconds for one epoch ---
--- 0.2962517738342285 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.005812]
 [ -0.      ]]
--- 0.2482600212097168 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2460.762451171875, (1175.6361, 2.2677042, 1282.4856, 0.37296635)
   validation loss 957.2850952148438, (658.1205, 0.85775995, 297.93384, 0.37296635)
decoder loss ratio: 25496.730074, decoder SINDy loss  ratio: 0.643132
--- 0.2998847961425781 seconds for one epoch ---
--- 1.359973669052124 seconds for one epoch ---
--- 0.28874850273132324 seconds for one epoch ---
--- 1.3330941200256348 seconds for one epoch ---
--- 0.29360294342041016 seconds for one epoch ---
--- 1.3000962734222412 seconds for one epoch ---
--- 0.2836165428161621 seconds for one epoch ---
--- 1.282156229019165 seconds for one epoch ---
--- 0.2906205654144287 seconds for one epoch ---
--- 1.3551287651062012 seconds for one epoch ---
--- 0.2955617904663086 seconds for one epoch ---
--- 1.3629868030548096 seconds for one epoch ---
--- 0.3164029121398926 seconds for one epoch ---
--- 1.3378510475158691 seconds for one epoch ---
--- 0.3103322982788086 seconds for one epoch ---
--- 1.366457223892212 seconds for one epoch ---
--- 0.3004887104034424 seconds for one epoch ---
--- 1.3468666076660156 seconds for one epoch ---
--- 0.29001545906066895 seconds for one epoch ---
--- 1.3794043064117432 seconds for one epoch ---
--- 0.30898332595825195 seconds for one epoch ---
--- 1.3530795574188232 seconds for one epoch ---
--- 0.30133914947509766 seconds for one epoch ---
--- 1.3650476932525635 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.116988]
 [ -0.      ]]
--- 0.28710246086120605 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2773.443603515625, (1560.468, 1.252032, 1211.3483, 0.3751869)
   validation loss 875.6635131835938, (584.19696, 1.0925406, 289.99884, 0.3751869)
decoder loss ratio: 22632.804458, decoder SINDy loss  ratio: 0.626003
--- 0.260636568069458 seconds for one epoch ---
--- 0.2931230068206787 seconds for one epoch ---
--- 1.362133502960205 seconds for one epoch ---
--- 0.28939056396484375 seconds for one epoch ---
--- 1.379446029663086 seconds for one epoch ---
--- 0.2977931499481201 seconds for one epoch ---
--- 1.3291199207305908 seconds for one epoch ---
--- 0.2913172245025635 seconds for one epoch ---
--- 1.3199100494384766 seconds for one epoch ---
--- 0.2833223342895508 seconds for one epoch ---
--- 1.3724565505981445 seconds for one epoch ---
--- 0.2839987277984619 seconds for one epoch ---
--- 1.3589746952056885 seconds for one epoch ---
--- 0.2849435806274414 seconds for one epoch ---
--- 1.3464159965515137 seconds for one epoch ---
--- 0.29422783851623535 seconds for one epoch ---
--- 1.350066900253296 seconds for one epoch ---
--- 0.2771179676055908 seconds for one epoch ---
--- 1.3919968605041504 seconds for one epoch ---
--- 0.29469966888427734 seconds for one epoch ---
--- 1.3897838592529297 seconds for one epoch ---
--- 0.29451513290405273 seconds for one epoch ---
--- 1.3908154964447021 seconds for one epoch ---
--- 0.2908284664154053 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.209581]
 [ -0.      ]]
--- 0.2530488967895508 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2300.0595703125, (1127.1694, 2.356478, 1170.1566, 0.377048)
   validation loss 965.1080322265625, (686.61426, 1.1679496, 276.94876, 0.377048)
decoder loss ratio: 26600.628362, decoder SINDy loss  ratio: 0.597833
--- 0.2944915294647217 seconds for one epoch ---
--- 1.3478217124938965 seconds for one epoch ---
--- 0.29175901412963867 seconds for one epoch ---
--- 1.3593976497650146 seconds for one epoch ---
--- 0.2894449234008789 seconds for one epoch ---
--- 1.382955551147461 seconds for one epoch ---
--- 0.29274606704711914 seconds for one epoch ---
--- 1.3078296184539795 seconds for one epoch ---
--- 0.2881791591644287 seconds for one epoch ---
--- 1.3127758502960205 seconds for one epoch ---
--- 0.29508209228515625 seconds for one epoch ---
--- 1.3587241172790527 seconds for one epoch ---
--- 0.3015143871307373 seconds for one epoch ---
--- 1.391758680343628 seconds for one epoch ---
--- 0.2926170825958252 seconds for one epoch ---
--- 1.367307424545288 seconds for one epoch ---
--- 0.29110240936279297 seconds for one epoch ---
--- 1.3512904644012451 seconds for one epoch ---
--- 0.29872608184814453 seconds for one epoch ---
--- 1.367504596710205 seconds for one epoch ---
--- 0.29160284996032715 seconds for one epoch ---
--- 1.3799681663513184 seconds for one epoch ---
--- 0.2901124954223633 seconds for one epoch ---
--- 1.386350393295288 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.302553]
 [  0.      ]]
--- 0.29042840003967285 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1694.4439697265625, (772.2569, 1.061774, 920.7463, 0.37908623)
   validation loss 949.6041870117188, (660.5068, 1.1262492, 287.5921, 0.37908623)
decoder loss ratio: 25589.179150, decoder SINDy loss  ratio: 0.620808
--- 0.2696359157562256 seconds for one epoch ---
--- 0.2974965572357178 seconds for one epoch ---
--- 1.3641688823699951 seconds for one epoch ---
--- 0.2815127372741699 seconds for one epoch ---
--- 1.3672902584075928 seconds for one epoch ---
--- 0.28232431411743164 seconds for one epoch ---
--- 1.3719134330749512 seconds for one epoch ---
--- 0.2851569652557373 seconds for one epoch ---
--- 1.345916509628296 seconds for one epoch ---
--- 0.2866976261138916 seconds for one epoch ---
--- 1.3188519477844238 seconds for one epoch ---
--- 0.29245638847351074 seconds for one epoch ---
--- 1.3284850120544434 seconds for one epoch ---
--- 0.29827260971069336 seconds for one epoch ---
--- 1.3828892707824707 seconds for one epoch ---
--- 0.3293421268463135 seconds for one epoch ---
--- 1.4125454425811768 seconds for one epoch ---
--- 0.3326754570007324 seconds for one epoch ---
--- 1.3896484375 seconds for one epoch ---
--- 0.335036039352417 seconds for one epoch ---
--- 1.3835465908050537 seconds for one epoch ---
--- 0.3340280055999756 seconds for one epoch ---
--- 1.3963656425476074 seconds for one epoch ---
--- 0.3151400089263916 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.417422]
 [  0.      ]]
--- 0.25860595703125 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3342.77001953125, (1870.9071, 1.4499818, 1470.0316, 0.381381)
   validation loss 950.955078125, (634.5341, 1.1295601, 314.90997, 0.381381)
decoder loss ratio: 24582.953356, decoder SINDy loss  ratio: 0.679777
--- 0.29564666748046875 seconds for one epoch ---
--- 1.3985633850097656 seconds for one epoch ---
--- 0.2966477870941162 seconds for one epoch ---
--- 1.4030320644378662 seconds for one epoch ---
--- 0.29947352409362793 seconds for one epoch ---
--- 1.3723680973052979 seconds for one epoch ---
--- 0.29950523376464844 seconds for one epoch ---
--- 1.415515661239624 seconds for one epoch ---
--- 0.2937278747558594 seconds for one epoch ---
--- 1.3819301128387451 seconds for one epoch ---
--- 0.2886049747467041 seconds for one epoch ---
--- 1.35776948928833 seconds for one epoch ---
--- 0.2973062992095947 seconds for one epoch ---
--- 1.401867389678955 seconds for one epoch ---
--- 0.2926170825958252 seconds for one epoch ---
--- 1.3880748748779297 seconds for one epoch ---
--- 0.29987645149230957 seconds for one epoch ---
--- 1.4019651412963867 seconds for one epoch ---
--- 0.3016519546508789 seconds for one epoch ---
--- 1.4212887287139893 seconds for one epoch ---
--- 0.30715322494506836 seconds for one epoch ---
--- 1.417830467224121 seconds for one epoch ---
--- 0.3031759262084961 seconds for one epoch ---
--- 1.4065186977386475 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.505725]
 [  0.      ]]
--- 0.31782031059265137 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1719.8724365234375, (881.8262, 1.2629714, 836.4001, 0.3831863)
   validation loss 1056.8912353515625, (760.8653, 0.5174436, 295.12527, 0.3831863)
decoder loss ratio: 29477.242464, decoder SINDy loss  ratio: 0.637069
--- 0.2665257453918457 seconds for one epoch ---
--- 0.29564952850341797 seconds for one epoch ---
--- 1.4010274410247803 seconds for one epoch ---
--- 0.29683780670166016 seconds for one epoch ---
--- 1.3988020420074463 seconds for one epoch ---
--- 0.2981574535369873 seconds for one epoch ---
--- 1.4034216403961182 seconds for one epoch ---
--- 0.29905271530151367 seconds for one epoch ---
--- 1.3933582305908203 seconds for one epoch ---
--- 0.3043091297149658 seconds for one epoch ---
--- 1.4023592472076416 seconds for one epoch ---
--- 0.28223109245300293 seconds for one epoch ---
--- 1.3622963428497314 seconds for one epoch ---
--- 0.2917027473449707 seconds for one epoch ---
--- 1.3738341331481934 seconds for one epoch ---
--- 0.2946012020111084 seconds for one epoch ---
--- 1.4250504970550537 seconds for one epoch ---
--- 0.30001401901245117 seconds for one epoch ---
--- 1.4277675151824951 seconds for one epoch ---
--- 0.3043088912963867 seconds for one epoch ---
--- 1.4024581909179688 seconds for one epoch ---
--- 0.29759979248046875 seconds for one epoch ---
--- 1.3994548320770264 seconds for one epoch ---
--- 0.29473376274108887 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.568752]
 [ -0.      ]]
--- 0.25293731689453125 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3500.875244140625, (1773.4377, 1.5204885, 1725.5326, 0.38457733)
   validation loss 1031.53564453125, (752.3342, 0.82692164, 277.98996, 0.38457733)
decoder loss ratio: 29146.734122, decoder SINDy loss  ratio: 0.600080
--- 0.29073572158813477 seconds for one epoch ---
--- 1.4066648483276367 seconds for one epoch ---
--- 0.29287052154541016 seconds for one epoch ---
--- 1.3883469104766846 seconds for one epoch ---
--- 0.292022705078125 seconds for one epoch ---
--- 1.4151978492736816 seconds for one epoch ---
--- 0.2934074401855469 seconds for one epoch ---
--- 1.4170193672180176 seconds for one epoch ---
--- 0.2924683094024658 seconds for one epoch ---
--- 1.416588306427002 seconds for one epoch ---
--- 0.2954089641571045 seconds for one epoch ---
--- 1.390622615814209 seconds for one epoch ---
--- 0.28562068939208984 seconds for one epoch ---
--- 1.3664474487304688 seconds for one epoch ---
--- 0.2927558422088623 seconds for one epoch ---
--- 1.349973201751709 seconds for one epoch ---
--- 0.2887444496154785 seconds for one epoch ---
--- 1.3905019760131836 seconds for one epoch ---
--- 0.3088114261627197 seconds for one epoch ---
--- 1.403395414352417 seconds for one epoch ---
--- 0.29079389572143555 seconds for one epoch ---
--- 1.4471852779388428 seconds for one epoch ---
--- 0.2844972610473633 seconds for one epoch ---
--- 1.4114999771118164 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.649028]
 [ -0.      ]]
--- 0.2848227024078369 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3464.1337890625, (1295.0623, 1.1281338, 2167.5571, 0.38628012)
   validation loss 1262.9835205078125, (966.7977, 0.916896, 294.8827, 0.38628012)
decoder loss ratio: 37455.422475, decoder SINDy loss  ratio: 0.636546
--- 0.25814127922058105 seconds for one epoch ---
--- 0.2886528968811035 seconds for one epoch ---
--- 1.4045398235321045 seconds for one epoch ---
--- 0.28157591819763184 seconds for one epoch ---
--- 1.3975002765655518 seconds for one epoch ---
--- 0.29380345344543457 seconds for one epoch ---
--- 1.4261338710784912 seconds for one epoch ---
--- 0.2952408790588379 seconds for one epoch ---
--- 1.4213502407073975 seconds for one epoch ---
--- 0.29547977447509766 seconds for one epoch ---
--- 1.4152648448944092 seconds for one epoch ---
--- 0.30251479148864746 seconds for one epoch ---
--- 1.403655767440796 seconds for one epoch ---
--- 0.29554200172424316 seconds for one epoch ---
--- 1.4430806636810303 seconds for one epoch ---
--- 0.3016986846923828 seconds for one epoch ---
--- 1.4202425479888916 seconds for one epoch ---
--- 0.28799009323120117 seconds for one epoch ---
--- 1.434938669204712 seconds for one epoch ---
--- 0.2983548641204834 seconds for one epoch ---
--- 1.4440503120422363 seconds for one epoch ---
--- 0.29116272926330566 seconds for one epoch ---
--- 1.4646575450897217 seconds for one epoch ---
--- 0.2889716625213623 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.735926]
 [ -0.      ]]
--- 0.26038384437561035 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2971.87744140625, (1473.3743, 1.4885138, 1496.6266, 0.38815054)
   validation loss 974.7332153320312, (644.89435, 0.68159866, 328.7692, 0.38815054)
decoder loss ratio: 24984.326633, decoder SINDy loss  ratio: 0.709695
--- 0.3024172782897949 seconds for one epoch ---
--- 1.4257676601409912 seconds for one epoch ---
--- 0.29349732398986816 seconds for one epoch ---
--- 1.420048713684082 seconds for one epoch ---
--- 0.30400538444519043 seconds for one epoch ---
--- 1.4412400722503662 seconds for one epoch ---
--- 0.2944529056549072 seconds for one epoch ---
--- 1.4616217613220215 seconds for one epoch ---
--- 0.3032386302947998 seconds for one epoch ---
--- 1.4471476078033447 seconds for one epoch ---
--- 0.30077075958251953 seconds for one epoch ---
--- 1.4184305667877197 seconds for one epoch ---
--- 0.2818584442138672 seconds for one epoch ---
--- 1.3916916847229004 seconds for one epoch ---
--- 0.29789042472839355 seconds for one epoch ---
--- 1.4099409580230713 seconds for one epoch ---
--- 0.2900257110595703 seconds for one epoch ---
--- 1.4219374656677246 seconds for one epoch ---
--- 0.282839298248291 seconds for one epoch ---
--- 1.421241044998169 seconds for one epoch ---
--- 0.3005526065826416 seconds for one epoch ---
--- 1.4463324546813965 seconds for one epoch ---
--- 0.27808356285095215 seconds for one epoch ---
--- 1.441310167312622 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-14.8183155]
 [  0.       ]]
--- 0.29714083671569824 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1759.4873046875, (995.1693, 0.7355475, 763.19244, 0.38999137)
   validation loss 844.391357421875, (548.41565, 0.9792625, 294.60648, 0.38999137)
decoder loss ratio: 21246.574350, decoder SINDy loss  ratio: 0.635950
THRESHOLDING: 1 active coefficients
--- 1.4170231819152832 seconds for one epoch ---
--- 0.2942202091217041 seconds for one epoch ---
--- 1.4531145095825195 seconds for one epoch ---
--- 0.2997298240661621 seconds for one epoch ---
--- 1.5150325298309326 seconds for one epoch ---
--- 0.301410436630249 seconds for one epoch ---
--- 1.451611042022705 seconds for one epoch ---
--- 0.30207157135009766 seconds for one epoch ---
--- 1.4228127002716064 seconds for one epoch ---
--- 0.28794026374816895 seconds for one epoch ---
--- 1.451643943786621 seconds for one epoch ---
--- 0.29190826416015625 seconds for one epoch ---
--- 1.4570834636688232 seconds for one epoch ---
--- 0.2934088706970215 seconds for one epoch ---
--- 1.433772325515747 seconds for one epoch ---
--- 0.29216504096984863 seconds for one epoch ---
--- 1.487102746963501 seconds for one epoch ---
--- 0.2936089038848877 seconds for one epoch ---
--- 1.4708194732666016 seconds for one epoch ---
--- 0.29729747772216797 seconds for one epoch ---
--- 1.4830682277679443 seconds for one epoch ---
--- 0.2875986099243164 seconds for one epoch ---
--- 1.4873542785644531 seconds for one epoch ---
--- 0.297161340713501 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.904923]
 [  0.      ]]
--- 0.2571601867675781 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2917.95361328125, (1003.3478, 1.6473237, 1912.567, 0.39170977)
   validation loss 969.896240234375, (657.1873, 0.7922329, 311.52496, 0.39170977)
decoder loss ratio: 25460.577584, decoder SINDy loss  ratio: 0.672470
--- 0.30257177352905273 seconds for one epoch ---
--- 1.4393947124481201 seconds for one epoch ---
--- 0.2890963554382324 seconds for one epoch ---
--- 1.4666879177093506 seconds for one epoch ---
--- 0.2942829132080078 seconds for one epoch ---
--- 1.447291612625122 seconds for one epoch ---
--- 0.30027151107788086 seconds for one epoch ---
--- 1.4675536155700684 seconds for one epoch ---
--- 0.3023650646209717 seconds for one epoch ---
--- 1.458644151687622 seconds for one epoch ---
--- 0.29440855979919434 seconds for one epoch ---
--- 1.48353910446167 seconds for one epoch ---
--- 0.2963900566101074 seconds for one epoch ---
--- 1.4594287872314453 seconds for one epoch ---
--- 0.30359983444213867 seconds for one epoch ---
--- 1.478961706161499 seconds for one epoch ---
--- 0.2869739532470703 seconds for one epoch ---
--- 1.4269611835479736 seconds for one epoch ---
--- 0.27583861351013184 seconds for one epoch ---
--- 1.4268794059753418 seconds for one epoch ---
--- 0.2725498676300049 seconds for one epoch ---
--- 1.4668962955474854 seconds for one epoch ---
--- 0.3014519214630127 seconds for one epoch ---
--- 1.4497473239898682 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.979974]
 [  0.      ]]
--- 0.2947719097137451 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5522.37646484375, (3140.093, 1.7388777, 2380.1511, 0.39339337)
   validation loss 847.2593994140625, (521.3907, 0.63184625, 324.8435, 0.39339337)
decoder loss ratio: 20199.580351, decoder SINDy loss  ratio: 0.701220
--- 0.2621598243713379 seconds for one epoch ---
--- 0.2923741340637207 seconds for one epoch ---
--- 1.4823904037475586 seconds for one epoch ---
--- 0.2997448444366455 seconds for one epoch ---
--- 1.4758028984069824 seconds for one epoch ---
--- 0.29552578926086426 seconds for one epoch ---
--- 1.49092435836792 seconds for one epoch ---
--- 0.2964513301849365 seconds for one epoch ---
--- 1.4795277118682861 seconds for one epoch ---
--- 0.29364728927612305 seconds for one epoch ---
--- 1.4863343238830566 seconds for one epoch ---
--- 0.2921273708343506 seconds for one epoch ---
--- 1.473970651626587 seconds for one epoch ---
--- 0.29366517066955566 seconds for one epoch ---
--- 1.4782335758209229 seconds for one epoch ---
--- 0.30132150650024414 seconds for one epoch ---
--- 1.4890005588531494 seconds for one epoch ---
--- 0.2970263957977295 seconds for one epoch ---
--- 1.4648230075836182 seconds for one epoch ---
--- 0.3019075393676758 seconds for one epoch ---
--- 1.4602487087249756 seconds for one epoch ---
--- 0.2938065528869629 seconds for one epoch ---
--- 1.4469993114471436 seconds for one epoch ---
--- 0.2846829891204834 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.053098]
 [ -0.      ]]
--- 0.26666903495788574 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2597.890625, (1322.9067, 1.5218474, 1273.067, 0.39504477)
   validation loss 1058.92626953125, (771.96484, 0.73256665, 285.83386, 0.39504477)
decoder loss ratio: 29907.258237, decoder SINDy loss  ratio: 0.617013
--- 0.3215484619140625 seconds for one epoch ---
--- 1.5378963947296143 seconds for one epoch ---
--- 0.33197641372680664 seconds for one epoch ---
--- 1.4997870922088623 seconds for one epoch ---
--- 0.31375861167907715 seconds for one epoch ---
--- 1.504838466644287 seconds for one epoch ---
--- 0.35249876976013184 seconds for one epoch ---
--- 1.4748280048370361 seconds for one epoch ---
--- 0.3145906925201416 seconds for one epoch ---
--- 1.4782636165618896 seconds for one epoch ---
--- 0.30009913444519043 seconds for one epoch ---
--- 1.4908196926116943 seconds for one epoch ---
--- 0.2919795513153076 seconds for one epoch ---
--- 1.502021074295044 seconds for one epoch ---
--- 0.2822272777557373 seconds for one epoch ---
--- 1.5178751945495605 seconds for one epoch ---
--- 0.29728174209594727 seconds for one epoch ---
--- 1.508399486541748 seconds for one epoch ---
--- 0.29518675804138184 seconds for one epoch ---
--- 1.4412736892700195 seconds for one epoch ---
--- 0.2701280117034912 seconds for one epoch ---
--- 1.4581904411315918 seconds for one epoch ---
--- 0.30491209030151367 seconds for one epoch ---
--- 1.461653470993042 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.122235]
 [ -0.      ]]
--- 0.2814676761627197 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1979.396240234375, (1044.9764, 1.1384965, 932.88464, 0.39660013)
   validation loss 1008.6025390625, (652.30316, 0.5295957, 355.37314, 0.39660013)
decoder loss ratio: 25271.356929, decoder SINDy loss  ratio: 0.767123
--- 0.2598764896392822 seconds for one epoch ---
--- 0.300081729888916 seconds for one epoch ---
--- 1.4941082000732422 seconds for one epoch ---
--- 0.2970235347747803 seconds for one epoch ---
--- 1.5260558128356934 seconds for one epoch ---
--- 0.2943723201751709 seconds for one epoch ---
--- 1.5339665412902832 seconds for one epoch ---
--- 0.3084449768066406 seconds for one epoch ---
--- 1.5167665481567383 seconds for one epoch ---
--- 0.28890490531921387 seconds for one epoch ---
--- 1.501502513885498 seconds for one epoch ---
--- 0.2980949878692627 seconds for one epoch ---
--- 1.477381944656372 seconds for one epoch ---
--- 0.2896392345428467 seconds for one epoch ---
--- 1.4756360054016113 seconds for one epoch ---
--- 0.3037841320037842 seconds for one epoch ---
--- 1.5078673362731934 seconds for one epoch ---
--- 0.2925410270690918 seconds for one epoch ---
--- 1.52341890335083 seconds for one epoch ---
--- 0.2950713634490967 seconds for one epoch ---
--- 1.4865756034851074 seconds for one epoch ---
--- 0.2946915626525879 seconds for one epoch ---
--- 1.442091703414917 seconds for one epoch ---
--- 0.28806400299072266 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.198037]
 [ -0.      ]]
--- 0.24824237823486328 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2397.308837890625, (1113.0509, 1.6786023, 1282.1813, 0.39817128)
   validation loss 771.2379150390625, (469.61014, 1.014644, 300.21494, 0.39817128)
decoder loss ratio: 18193.512023, decoder SINDy loss  ratio: 0.648056
--- 0.3082284927368164 seconds for one epoch ---
--- 1.4954164028167725 seconds for one epoch ---
--- 0.3081505298614502 seconds for one epoch ---
--- 1.5138132572174072 seconds for one epoch ---
--- 0.3040475845336914 seconds for one epoch ---
--- 1.5130865573883057 seconds for one epoch ---
--- 0.3055894374847412 seconds for one epoch ---
--- 1.523791790008545 seconds for one epoch ---
--- 0.3077414035797119 seconds for one epoch ---
--- 1.4938015937805176 seconds for one epoch ---
--- 0.3008871078491211 seconds for one epoch ---
--- 1.5036392211914062 seconds for one epoch ---
--- 0.29261326789855957 seconds for one epoch ---
--- 1.5183954238891602 seconds for one epoch ---
--- 0.2912869453430176 seconds for one epoch ---
--- 1.5109918117523193 seconds for one epoch ---
--- 0.29787540435791016 seconds for one epoch ---
--- 1.5005838871002197 seconds for one epoch ---
--- 0.29010725021362305 seconds for one epoch ---
--- 1.5297267436981201 seconds for one epoch ---
--- 0.29157519340515137 seconds for one epoch ---
--- 1.5052340030670166 seconds for one epoch ---
--- 0.2926828861236572 seconds for one epoch ---
--- 1.4660067558288574 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.27544]
 [  0.     ]]
--- 0.32665252685546875 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1358.285400390625, (756.25354, 0.39858428, 601.23334, 0.39994118)
   validation loss 939.4916381835938, (622.90027, 0.8469806, 315.3444, 0.39994118)
decoder loss ratio: 24132.237806, decoder SINDy loss  ratio: 0.680715
--- 0.279433012008667 seconds for one epoch ---
--- 0.3115098476409912 seconds for one epoch ---
--- 1.5287649631500244 seconds for one epoch ---
--- 0.33388519287109375 seconds for one epoch ---
--- 1.5059049129486084 seconds for one epoch ---
--- 0.3208649158477783 seconds for one epoch ---
--- 1.5163090229034424 seconds for one epoch ---
--- 0.308185338973999 seconds for one epoch ---
--- 1.5335233211517334 seconds for one epoch ---
--- 0.2925586700439453 seconds for one epoch ---
--- 1.517479658126831 seconds for one epoch ---
--- 0.32811975479125977 seconds for one epoch ---
--- 1.5249338150024414 seconds for one epoch ---
--- 0.30173540115356445 seconds for one epoch ---
--- 1.53434419631958 seconds for one epoch ---
--- 0.30016136169433594 seconds for one epoch ---
--- 1.538503646850586 seconds for one epoch ---
--- 0.2982149124145508 seconds for one epoch ---
--- 1.549236536026001 seconds for one epoch ---
--- 0.294771671295166 seconds for one epoch ---
--- 1.54490065574646 seconds for one epoch ---
--- 0.3134739398956299 seconds for one epoch ---
--- 1.5538794994354248 seconds for one epoch ---
--- 0.2990398406982422 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.342392]
 [  0.      ]]
--- 0.25374889373779297 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2995.2021484375, (1435.622, 2.5897624, 1556.5892, 0.40137622)
   validation loss 994.574462890625, (671.0168, 0.9919142, 322.16434, 0.40137622)
decoder loss ratio: 25996.355174, decoder SINDy loss  ratio: 0.695437
--- 0.3372948169708252 seconds for one epoch ---
--- 1.5478401184082031 seconds for one epoch ---
--- 0.32505130767822266 seconds for one epoch ---
--- 1.5470025539398193 seconds for one epoch ---
--- 0.32228684425354004 seconds for one epoch ---
--- 1.5436763763427734 seconds for one epoch ---
--- 0.33561205863952637 seconds for one epoch ---
--- 1.5228850841522217 seconds for one epoch ---
--- 0.3065652847290039 seconds for one epoch ---
--- 1.5560786724090576 seconds for one epoch ---
--- 0.30715107917785645 seconds for one epoch ---
--- 1.5584497451782227 seconds for one epoch ---
--- 0.3194541931152344 seconds for one epoch ---
--- 1.5527763366699219 seconds for one epoch ---
--- 0.2945668697357178 seconds for one epoch ---
--- 1.5491125583648682 seconds for one epoch ---
--- 0.29225826263427734 seconds for one epoch ---
--- 1.5518462657928467 seconds for one epoch ---
--- 0.29398345947265625 seconds for one epoch ---
--- 1.548593282699585 seconds for one epoch ---
--- 0.2993803024291992 seconds for one epoch ---
--- 1.5684936046600342 seconds for one epoch ---
--- 0.2960512638092041 seconds for one epoch ---
--- 1.5040545463562012 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.413577]
 [  0.      ]]
--- 0.2894399166107178 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2283.510986328125, (1101.6846, 0.46722734, 1180.956, 0.4030264)
   validation loss 1046.6275634765625, (717.3147, 0.9329097, 327.97687, 0.4030264)
decoder loss ratio: 27790.016685, decoder SINDy loss  ratio: 0.707984
--- 0.2598910331726074 seconds for one epoch ---
--- 0.30026674270629883 seconds for one epoch ---
--- 1.521906852722168 seconds for one epoch ---
--- 0.29692769050598145 seconds for one epoch ---
--- 1.535310983657837 seconds for one epoch ---
--- 0.2859029769897461 seconds for one epoch ---
--- 1.5240252017974854 seconds for one epoch ---
--- 0.28534722328186035 seconds for one epoch ---
--- 1.5461456775665283 seconds for one epoch ---
--- 0.2950115203857422 seconds for one epoch ---
--- 1.524751901626587 seconds for one epoch ---
--- 0.28699564933776855 seconds for one epoch ---
--- 1.5329041481018066 seconds for one epoch ---
--- 0.2923290729522705 seconds for one epoch ---
--- 1.559887170791626 seconds for one epoch ---
--- 0.30022406578063965 seconds for one epoch ---
--- 1.5529694557189941 seconds for one epoch ---
--- 0.2977604866027832 seconds for one epoch ---
--- 1.5607125759124756 seconds for one epoch ---
--- 0.29560351371765137 seconds for one epoch ---
--- 1.547792911529541 seconds for one epoch ---
--- 0.29997825622558594 seconds for one epoch ---
--- 1.5819401741027832 seconds for one epoch ---
--- 0.2974052429199219 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.480783]
 [ -0.      ]]
--- 0.251507043838501 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3736.777099609375, (1559.7639, 1.7512786, 2174.8574, 0.40448633)
   validation loss 928.3858032226562, (611.3811, 0.9825642, 315.61765, 0.40448633)
decoder loss ratio: 23685.965354, decoder SINDy loss  ratio: 0.681305
--- 0.29753732681274414 seconds for one epoch ---
--- 1.5322461128234863 seconds for one epoch ---
--- 0.2986032962799072 seconds for one epoch ---
--- 1.5405049324035645 seconds for one epoch ---
--- 0.28427815437316895 seconds for one epoch ---
--- 1.5470259189605713 seconds for one epoch ---
--- 0.3059351444244385 seconds for one epoch ---
--- 1.5360107421875 seconds for one epoch ---
--- 0.29610252380371094 seconds for one epoch ---
--- 1.5232009887695312 seconds for one epoch ---
--- 0.29868102073669434 seconds for one epoch ---
--- 1.5336153507232666 seconds for one epoch ---
--- 0.2963600158691406 seconds for one epoch ---
--- 1.546644687652588 seconds for one epoch ---
--- 0.29554247856140137 seconds for one epoch ---
--- 1.5642213821411133 seconds for one epoch ---
--- 0.27999424934387207 seconds for one epoch ---
--- 1.5334553718566895 seconds for one epoch ---
--- 0.29482245445251465 seconds for one epoch ---
--- 1.5422770977020264 seconds for one epoch ---
--- 0.29917454719543457 seconds for one epoch ---
--- 1.5606143474578857 seconds for one epoch ---
--- 0.2829928398132324 seconds for one epoch ---
--- 1.5926132202148438 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.541533]
 [ -0.      ]]
--- 0.29239749908447266 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2763.139404296875, (1465.4229, 2.3279042, 1294.9829, 0.40580988)
   validation loss 868.4712524414062, (572.0264, 1.0995739, 294.93945, 0.40580988)
decoder loss ratio: 22161.296911, decoder SINDy loss  ratio: 0.636668
--- 0.2551403045654297 seconds for one epoch ---
--- 0.30159473419189453 seconds for one epoch ---
--- 1.5410058498382568 seconds for one epoch ---
--- 0.2921149730682373 seconds for one epoch ---
--- 1.5417096614837646 seconds for one epoch ---
--- 0.28418636322021484 seconds for one epoch ---
--- 1.5779380798339844 seconds for one epoch ---
--- 0.30451464653015137 seconds for one epoch ---
--- 1.5826845169067383 seconds for one epoch ---
--- 0.3033156394958496 seconds for one epoch ---
--- 1.5655517578125 seconds for one epoch ---
--- 0.29767775535583496 seconds for one epoch ---
--- 1.5864522457122803 seconds for one epoch ---
--- 0.2848525047302246 seconds for one epoch ---
--- 1.5563125610351562 seconds for one epoch ---
--- 0.29940223693847656 seconds for one epoch ---
--- 1.593989372253418 seconds for one epoch ---
--- 0.2978365421295166 seconds for one epoch ---
--- 1.5802853107452393 seconds for one epoch ---
--- 0.2881309986114502 seconds for one epoch ---
--- 1.5710794925689697 seconds for one epoch ---
--- 0.29468607902526855 seconds for one epoch ---
--- 1.5580005645751953 seconds for one epoch ---
--- 0.2929532527923584 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.6005335]
 [ -0.       ]]
--- 0.24680161476135254 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3408.36962890625, (1518.6664, 2.0728238, 1887.2231, 0.40717837)
   validation loss 1611.2783203125, (1307.2885, 1.0965627, 302.48615, 0.40717837)
decoder loss ratio: 50646.624189, decoder SINDy loss  ratio: 0.652959
--- 0.29181408882141113 seconds for one epoch ---
--- 1.598494291305542 seconds for one epoch ---
--- 0.2990427017211914 seconds for one epoch ---
--- 1.5845401287078857 seconds for one epoch ---
--- 0.3030223846435547 seconds for one epoch ---
--- 1.5399491786956787 seconds for one epoch ---
--- 0.2987203598022461 seconds for one epoch ---
--- 1.5961463451385498 seconds for one epoch ---
--- 0.2973825931549072 seconds for one epoch ---
--- 1.586296796798706 seconds for one epoch ---
--- 0.27652978897094727 seconds for one epoch ---
--- 1.594064712524414 seconds for one epoch ---
--- 0.2964482307434082 seconds for one epoch ---
--- 1.5652680397033691 seconds for one epoch ---
--- 0.2875936031341553 seconds for one epoch ---
--- 1.614236831665039 seconds for one epoch ---
--- 0.2964630126953125 seconds for one epoch ---
--- 1.6096088886260986 seconds for one epoch ---
--- 0.29412055015563965 seconds for one epoch ---
--- 1.5827643871307373 seconds for one epoch ---
--- 0.3017892837524414 seconds for one epoch ---
--- 1.5955064296722412 seconds for one epoch ---
--- 0.29047346115112305 seconds for one epoch ---
--- 1.5908584594726562 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.642618]
 [  0.      ]]
--- 0.2894258499145508 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1716.3408203125, (876.69775, 0.9645262, 838.2703, 0.4081494)
   validation loss 913.5105590820312, (601.8081, 0.95270973, 310.34158, 0.4081494)
decoder loss ratio: 23315.090791, decoder SINDy loss  ratio: 0.669916
--- 0.2653994560241699 seconds for one epoch ---
--- 0.28238344192504883 seconds for one epoch ---
--- 1.5866801738739014 seconds for one epoch ---
--- 0.30407285690307617 seconds for one epoch ---
--- 1.603994369506836 seconds for one epoch ---
--- 0.29775404930114746 seconds for one epoch ---
--- 1.5914874076843262 seconds for one epoch ---
--- 0.31089210510253906 seconds for one epoch ---
--- 1.596506118774414 seconds for one epoch ---
--- 0.3111450672149658 seconds for one epoch ---
--- 1.6023974418640137 seconds for one epoch ---
--- 0.29575562477111816 seconds for one epoch ---
--- 1.6182548999786377 seconds for one epoch ---
--- 0.3098642826080322 seconds for one epoch ---
--- 1.583392858505249 seconds for one epoch ---
--- 0.3218872547149658 seconds for one epoch ---
--- 1.5873050689697266 seconds for one epoch ---
--- 0.29741811752319336 seconds for one epoch ---
--- 1.5935962200164795 seconds for one epoch ---
--- 0.29518651962280273 seconds for one epoch ---
--- 1.5977435111999512 seconds for one epoch ---
--- 0.2919154167175293 seconds for one epoch ---
--- 1.5595722198486328 seconds for one epoch ---
--- 0.2895069122314453 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.692208]
 [  0.      ]]
--- 0.27532339096069336 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3326.17822265625, (1360.6605, 1.7652096, 1963.3434, 0.40924072)
   validation loss 1212.220703125, (838.49963, 0.9794117, 372.33246, 0.40924072)
decoder loss ratio: 32484.931512, decoder SINDy loss  ratio: 0.803732
--- 0.28560352325439453 seconds for one epoch ---
--- 1.5732929706573486 seconds for one epoch ---
--- 0.30469274520874023 seconds for one epoch ---
--- 1.59751296043396 seconds for one epoch ---
--- 0.3088042736053467 seconds for one epoch ---
--- 1.601560115814209 seconds for one epoch ---
--- 0.3024482727050781 seconds for one epoch ---
--- 1.5934271812438965 seconds for one epoch ---
--- 0.31936097145080566 seconds for one epoch ---
--- 1.636690378189087 seconds for one epoch ---
--- 0.31821751594543457 seconds for one epoch ---
--- 1.6452693939208984 seconds for one epoch ---
--- 0.3375263214111328 seconds for one epoch ---
--- 1.6427152156829834 seconds for one epoch ---
--- 0.3259420394897461 seconds for one epoch ---
--- 1.5975048542022705 seconds for one epoch ---
--- 0.32558727264404297 seconds for one epoch ---
--- 1.66188383102417 seconds for one epoch ---
--- 0.29995083808898926 seconds for one epoch ---
--- 1.6307072639465332 seconds for one epoch ---
--- 0.2906026840209961 seconds for one epoch ---
--- 1.6120710372924805 seconds for one epoch ---
--- 0.3030109405517578 seconds for one epoch ---
--- 1.6264631748199463 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.754177]
 [  0.      ]]
--- 0.2906513214111328 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3192.19287109375, (1634.9657, 0.4794289, 1556.3372, 0.4107383)
   validation loss 835.0377197265625, (545.57794, 0.9391737, 288.1099, 0.4107383)
decoder loss ratio: 21136.636634, decoder SINDy loss  ratio: 0.621926
--- 0.26267194747924805 seconds for one epoch ---
--- 0.29068589210510254 seconds for one epoch ---
--- 1.607351541519165 seconds for one epoch ---
--- 0.28662919998168945 seconds for one epoch ---
--- 1.6659362316131592 seconds for one epoch ---
--- 0.2872166633605957 seconds for one epoch ---
--- 1.6643126010894775 seconds for one epoch ---
--- 0.2817826271057129 seconds for one epoch ---
--- 1.670447587966919 seconds for one epoch ---
--- 0.28878283500671387 seconds for one epoch ---
--- 1.690157175064087 seconds for one epoch ---
--- 0.28334665298461914 seconds for one epoch ---
--- 1.6679654121398926 seconds for one epoch ---
--- 0.29599618911743164 seconds for one epoch ---
--- 1.6050779819488525 seconds for one epoch ---
--- 0.28763771057128906 seconds for one epoch ---
--- 1.618086814880371 seconds for one epoch ---
--- 0.2914283275604248 seconds for one epoch ---
--- 1.6305646896362305 seconds for one epoch ---
--- 0.30416154861450195 seconds for one epoch ---
--- 1.6135048866271973 seconds for one epoch ---
--- 0.29407668113708496 seconds for one epoch ---
--- 1.623671293258667 seconds for one epoch ---
--- 0.29837536811828613 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.814565]
 [ -0.      ]]
--- 0.25973987579345703 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2932.10400390625, (1227.0198, 6.8098965, 1697.8622, 0.41220808)
   validation loss 1005.9096069335938, (702.9369, 1.2207531, 301.33972, 0.41220808)
decoder loss ratio: 27232.995457, decoder SINDy loss  ratio: 0.650484
--- 0.2920951843261719 seconds for one epoch ---
--- 1.6160500049591064 seconds for one epoch ---
--- 0.29369354248046875 seconds for one epoch ---
--- 1.5957412719726562 seconds for one epoch ---
--- 0.2846653461456299 seconds for one epoch ---
--- 1.620377540588379 seconds for one epoch ---
--- 0.28687572479248047 seconds for one epoch ---
--- 1.6414635181427002 seconds for one epoch ---
--- 0.29129981994628906 seconds for one epoch ---
--- 1.638153076171875 seconds for one epoch ---
--- 0.30648159980773926 seconds for one epoch ---
--- 1.6224031448364258 seconds for one epoch ---
--- 0.30384373664855957 seconds for one epoch ---
--- 1.6426043510437012 seconds for one epoch ---
--- 0.2977116107940674 seconds for one epoch ---
--- 1.62367582321167 seconds for one epoch ---
--- 0.33225440979003906 seconds for one epoch ---
--- 1.6803615093231201 seconds for one epoch ---
--- 0.3406405448913574 seconds for one epoch ---
--- 1.6187701225280762 seconds for one epoch ---
--- 0.3234128952026367 seconds for one epoch ---
--- 1.6344819068908691 seconds for one epoch ---
--- 0.28647732734680176 seconds for one epoch ---
--- 1.6062040328979492 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.89091]
 [ -0.     ]]
--- 0.28835415840148926 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4093.56982421875, (2136.2043, 4.8646245, 1952.0869, 0.413848)
   validation loss 929.9844970703125, (637.4322, 1.2168851, 290.92163, 0.413848)
decoder loss ratio: 24695.229669, decoder SINDy loss  ratio: 0.627995
--- 0.24718475341796875 seconds for one epoch ---
--- 0.30524134635925293 seconds for one epoch ---
--- 1.6621580123901367 seconds for one epoch ---
--- 0.3045060634613037 seconds for one epoch ---
--- 1.6456811428070068 seconds for one epoch ---
--- 0.2714500427246094 seconds for one epoch ---
--- 1.648906946182251 seconds for one epoch ---
--- 0.2992112636566162 seconds for one epoch ---
--- 1.6414105892181396 seconds for one epoch ---
--- 0.29729461669921875 seconds for one epoch ---
--- 1.6394498348236084 seconds for one epoch ---
--- 0.2938263416290283 seconds for one epoch ---
--- 1.6386840343475342 seconds for one epoch ---
--- 0.2997903823852539 seconds for one epoch ---
--- 1.6730029582977295 seconds for one epoch ---
--- 0.3045380115509033 seconds for one epoch ---
--- 1.6948223114013672 seconds for one epoch ---
--- 0.2863647937774658 seconds for one epoch ---
--- 1.6421995162963867 seconds for one epoch ---
--- 0.31151533126831055 seconds for one epoch ---
--- 1.6453051567077637 seconds for one epoch ---
--- 0.31679654121398926 seconds for one epoch ---
--- 1.6273813247680664 seconds for one epoch ---
--- 0.30274224281311035 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.948385]
 [ -0.      ]]
--- 0.2613067626953125 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5123.7587890625, (2609.8489, 1.5531669, 2511.9417, 0.41516605)
   validation loss 1152.240234375, (819.9683, 1.3492603, 330.50754, 0.41516605)
decoder loss ratio: 31766.996351, decoder SINDy loss  ratio: 0.713447
--- 0.2991335391998291 seconds for one epoch ---
--- 1.6979539394378662 seconds for one epoch ---
--- 0.2912294864654541 seconds for one epoch ---
--- 1.6696395874023438 seconds for one epoch ---
--- 0.29331040382385254 seconds for one epoch ---
--- 1.664799451828003 seconds for one epoch ---
--- 0.2968881130218506 seconds for one epoch ---
--- 1.6623120307922363 seconds for one epoch ---
--- 0.29199767112731934 seconds for one epoch ---
--- 1.6624670028686523 seconds for one epoch ---
--- 0.2997736930847168 seconds for one epoch ---
--- 1.6805574893951416 seconds for one epoch ---
--- 0.30410218238830566 seconds for one epoch ---
--- 1.688960075378418 seconds for one epoch ---
--- 0.3038136959075928 seconds for one epoch ---
--- 1.648960828781128 seconds for one epoch ---
--- 0.29401230812072754 seconds for one epoch ---
--- 1.6817924976348877 seconds for one epoch ---
--- 0.6001002788543701 seconds for one epoch ---
--- 1.6547961235046387 seconds for one epoch ---
--- 0.3049435615539551 seconds for one epoch ---
--- 1.665144681930542 seconds for one epoch ---
--- 0.28606653213500977 seconds for one epoch ---
--- 1.6903038024902344 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.01354]
 [  0.     ]]
--- 0.2944190502166748 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6431.658203125, (2357.0054, 0.7631318, 4073.4724, 0.4167986)
   validation loss 958.4829711914062, (638.497, 0.97443885, 318.5947, 0.4167986)
decoder loss ratio: 24736.482619, decoder SINDy loss  ratio: 0.687731
--- 0.27314019203186035 seconds for one epoch ---
--- 0.29514455795288086 seconds for one epoch ---
--- 1.6419293880462646 seconds for one epoch ---
--- 0.29775381088256836 seconds for one epoch ---
--- 1.6550111770629883 seconds for one epoch ---
--- 0.29933834075927734 seconds for one epoch ---
--- 1.649787187576294 seconds for one epoch ---
--- 0.2933359146118164 seconds for one epoch ---
--- 1.6494503021240234 seconds for one epoch ---
--- 0.2910137176513672 seconds for one epoch ---
--- 1.6414098739624023 seconds for one epoch ---
--- 0.27718067169189453 seconds for one epoch ---
--- 1.5980818271636963 seconds for one epoch ---
--- 0.2963447570800781 seconds for one epoch ---
--- 1.6292016506195068 seconds for one epoch ---
--- 0.29802775382995605 seconds for one epoch ---
--- 1.5789217948913574 seconds for one epoch ---
--- 0.297025203704834 seconds for one epoch ---
--- 1.6995346546173096 seconds for one epoch ---
--- 0.31554198265075684 seconds for one epoch ---
--- 1.673713207244873 seconds for one epoch ---
--- 0.2977464199066162 seconds for one epoch ---
--- 1.6890451908111572 seconds for one epoch ---
--- 0.31868958473205566 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.06685]
 [  0.     ]]
--- 0.24912714958190918 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2462.2998046875, (1144.6134, 0.82884234, 1316.4397, 0.41792116)
   validation loss 1257.5596923828125, (880.076, 0.83273476, 376.233, 0.41792116)
decoder loss ratio: 34095.671684, decoder SINDy loss  ratio: 0.812152
--- 0.2857630252838135 seconds for one epoch ---
--- 1.6896226406097412 seconds for one epoch ---
--- 0.28957366943359375 seconds for one epoch ---
--- 1.686659336090088 seconds for one epoch ---
--- 0.2818155288696289 seconds for one epoch ---
--- 1.6621692180633545 seconds for one epoch ---
--- 0.29343295097351074 seconds for one epoch ---
--- 1.6800177097320557 seconds for one epoch ---
--- 0.3025507926940918 seconds for one epoch ---
--- 1.6797420978546143 seconds for one epoch ---
--- 0.29297494888305664 seconds for one epoch ---
--- 1.6592061519622803 seconds for one epoch ---
--- 0.2921023368835449 seconds for one epoch ---
--- 1.668632984161377 seconds for one epoch ---
--- 0.29511404037475586 seconds for one epoch ---
--- 1.6698460578918457 seconds for one epoch ---
--- 0.2954723834991455 seconds for one epoch ---
--- 1.6976256370544434 seconds for one epoch ---
--- 0.2998929023742676 seconds for one epoch ---
--- 1.691345453262329 seconds for one epoch ---
--- 0.3099818229675293 seconds for one epoch ---
--- 1.6513159275054932 seconds for one epoch ---
--- 0.2945988178253174 seconds for one epoch ---
--- 1.6688289642333984 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.118551]
 [  0.      ]]
--- 0.29111361503601074 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3139.440185546875, (1685.745, 0.97966677, 1452.2964, 0.41911253)
   validation loss 849.7047729492188, (544.8707, 0.92205876, 303.4929, 0.41911253)
decoder loss ratio: 21109.237922, decoder SINDy loss  ratio: 0.655132
THRESHOLDING: 1 active coefficients
--- 0.25834107398986816 seconds for one epoch ---
--- 0.3038766384124756 seconds for one epoch ---
--- 1.686906099319458 seconds for one epoch ---
--- 0.29291725158691406 seconds for one epoch ---
--- 1.6946353912353516 seconds for one epoch ---
--- 0.30773067474365234 seconds for one epoch ---
--- 1.6736996173858643 seconds for one epoch ---
--- 0.297121524810791 seconds for one epoch ---
--- 1.6773796081542969 seconds for one epoch ---
--- 0.3038341999053955 seconds for one epoch ---
--- 1.6777863502502441 seconds for one epoch ---
--- 0.2936854362487793 seconds for one epoch ---
--- 1.6583852767944336 seconds for one epoch ---
--- 0.2964954376220703 seconds for one epoch ---
--- 1.6791353225708008 seconds for one epoch ---
--- 0.2974061965942383 seconds for one epoch ---
--- 1.6810131072998047 seconds for one epoch ---
--- 0.2918717861175537 seconds for one epoch ---
--- 1.621222972869873 seconds for one epoch ---
--- 0.29024481773376465 seconds for one epoch ---
--- 1.6309287548065186 seconds for one epoch ---
--- 0.27765655517578125 seconds for one epoch ---
--- 1.6525728702545166 seconds for one epoch ---
--- 0.26772499084472656 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.159357]
 [ -0.      ]]
--- 0.2801215648651123 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3276.7880859375, (1544.2368, 2.2476473, 1729.8834, 0.420132)
   validation loss 1207.993896484375, (869.8071, 0.64863926, 337.11792, 0.420132)
decoder loss ratio: 33697.838225, decoder SINDy loss  ratio: 0.727716
--- 0.2977285385131836 seconds for one epoch ---
--- 1.6720497608184814 seconds for one epoch ---
--- 0.29550909996032715 seconds for one epoch ---
--- 1.6762332916259766 seconds for one epoch ---
--- 0.2970256805419922 seconds for one epoch ---
--- 1.680443286895752 seconds for one epoch ---
--- 0.29290294647216797 seconds for one epoch ---
--- 1.6700665950775146 seconds for one epoch ---
--- 0.29974365234375 seconds for one epoch ---
--- 1.7290160655975342 seconds for one epoch ---
--- 0.3039121627807617 seconds for one epoch ---
--- 1.7082910537719727 seconds for one epoch ---
--- 0.3125193119049072 seconds for one epoch ---
--- 1.7114427089691162 seconds for one epoch ---
--- 0.3090629577636719 seconds for one epoch ---
--- 1.6981303691864014 seconds for one epoch ---
--- 0.31225085258483887 seconds for one epoch ---
--- 1.705272912979126 seconds for one epoch ---
--- 0.31197524070739746 seconds for one epoch ---
--- 1.6996543407440186 seconds for one epoch ---
--- 0.3083376884460449 seconds for one epoch ---
--- 1.7441349029541016 seconds for one epoch ---
--- 0.336195707321167 seconds for one epoch ---
--- 1.7271170616149902 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.199059]
 [ -0.      ]]
--- 0.29258036613464355 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2121.328125, (928.51196, 3.4079578, 1188.9873, 0.4210055)
   validation loss 1351.727783203125, (1009.8498, 1.1034721, 340.35355, 0.4210055)
decoder loss ratio: 39123.334137, decoder SINDy loss  ratio: 0.734701
--- 0.255033016204834 seconds for one epoch ---
--- 0.2984929084777832 seconds for one epoch ---
--- 1.7101919651031494 seconds for one epoch ---
--- 0.29554295539855957 seconds for one epoch ---
--- 1.7151317596435547 seconds for one epoch ---
--- 0.2884657382965088 seconds for one epoch ---
--- 1.7164928913116455 seconds for one epoch ---
--- 0.2962679862976074 seconds for one epoch ---
--- 1.704486608505249 seconds for one epoch ---
--- 0.299269437789917 seconds for one epoch ---
--- 1.73409104347229 seconds for one epoch ---
--- 0.2915661334991455 seconds for one epoch ---
--- 1.7201521396636963 seconds for one epoch ---
--- 0.2926633358001709 seconds for one epoch ---
--- 1.67946457862854 seconds for one epoch ---
--- 0.3065328598022461 seconds for one epoch ---
--- 1.723543643951416 seconds for one epoch ---
--- 0.2920870780944824 seconds for one epoch ---
--- 1.7759058475494385 seconds for one epoch ---
--- 0.29846978187561035 seconds for one epoch ---
--- 1.7499525547027588 seconds for one epoch ---
--- 0.3035554885864258 seconds for one epoch ---
--- 1.7278704643249512 seconds for one epoch ---
--- 0.3025949001312256 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.237173]
 [ -0.      ]]
--- 0.26778626441955566 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2635.05810546875, (1293.9636, 0.5519115, 1340.1208, 0.4219048)
   validation loss 1414.4835205078125, (1038.3066, 0.8790824, 374.87595, 0.4219048)
decoder loss ratio: 40225.801837, decoder SINDy loss  ratio: 0.809222
--- 0.29781317710876465 seconds for one epoch ---
--- 1.6857714653015137 seconds for one epoch ---
--- 0.3062257766723633 seconds for one epoch ---
--- 1.722203254699707 seconds for one epoch ---
--- 0.3097867965698242 seconds for one epoch ---
--- 1.730792760848999 seconds for one epoch ---
--- 0.296722412109375 seconds for one epoch ---
--- 1.7465221881866455 seconds for one epoch ---
--- 0.30629825592041016 seconds for one epoch ---
--- 1.7112641334533691 seconds for one epoch ---
--- 0.3040294647216797 seconds for one epoch ---
--- 1.715759515762329 seconds for one epoch ---
--- 0.2900245189666748 seconds for one epoch ---
--- 1.704073429107666 seconds for one epoch ---
--- 0.30107736587524414 seconds for one epoch ---
--- 1.728924036026001 seconds for one epoch ---
--- 0.29490041732788086 seconds for one epoch ---
--- 1.736083745956421 seconds for one epoch ---
--- 0.29974961280822754 seconds for one epoch ---
--- 1.7472100257873535 seconds for one epoch ---
--- 0.3073594570159912 seconds for one epoch ---
--- 1.7441356182098389 seconds for one epoch ---
--- 0.29998254776000977 seconds for one epoch ---
--- 1.7223315238952637 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.286217]
 [  0.      ]]
--- 0.28352952003479004 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2149.718505859375, (1046.7113, 0.9767535, 1101.6073, 0.42314863)
   validation loss 1452.146484375, (1082.2161, 1.1519084, 368.35544, 0.42314863)
decoder loss ratio: 41926.929147, decoder SINDy loss  ratio: 0.795147
--- 0.2652566432952881 seconds for one epoch ---
--- 0.2895064353942871 seconds for one epoch ---
--- 1.6808714866638184 seconds for one epoch ---
--- 0.29553747177124023 seconds for one epoch ---
--- 1.7129652500152588 seconds for one epoch ---
--- 0.2901179790496826 seconds for one epoch ---
--- 1.7476789951324463 seconds for one epoch ---
--- 0.2713770866394043 seconds for one epoch ---
--- 1.7275702953338623 seconds for one epoch ---
--- 0.2927381992340088 seconds for one epoch ---
--- 1.7176122665405273 seconds for one epoch ---
--- 0.3037571907043457 seconds for one epoch ---
--- 1.7282557487487793 seconds for one epoch ---
--- 0.2970614433288574 seconds for one epoch ---
--- 1.7295854091644287 seconds for one epoch ---
--- 0.3019907474517822 seconds for one epoch ---
--- 1.7189912796020508 seconds for one epoch ---
--- 0.2964437007904053 seconds for one epoch ---
--- 1.7630529403686523 seconds for one epoch ---
--- 0.3022329807281494 seconds for one epoch ---
--- 1.7342236042022705 seconds for one epoch ---
--- 0.29691195487976074 seconds for one epoch ---
--- 1.752767562866211 seconds for one epoch ---
--- 0.29385972023010254 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.32606]
 [  0.     ]]
--- 0.24920916557312012 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6991.1318359375, (1698.5902, 2.970359, 5289.1475, 0.42404017)
   validation loss 962.9037475585938, (652.55334, 1.2463838, 308.67996, 0.42404017)
decoder loss ratio: 25281.049457, decoder SINDy loss  ratio: 0.666329
--- 0.3032798767089844 seconds for one epoch ---
--- 1.703434705734253 seconds for one epoch ---
--- 0.3006453514099121 seconds for one epoch ---
--- 1.69938063621521 seconds for one epoch ---
--- 0.2972884178161621 seconds for one epoch ---
--- 1.7284595966339111 seconds for one epoch ---
--- 0.2955777645111084 seconds for one epoch ---
--- 1.7174663543701172 seconds for one epoch ---
--- 0.3132646083831787 seconds for one epoch ---
--- 1.7750742435455322 seconds for one epoch ---
--- 0.3136413097381592 seconds for one epoch ---
--- 1.7849500179290771 seconds for one epoch ---
--- 0.32134532928466797 seconds for one epoch ---
--- 1.7697937488555908 seconds for one epoch ---
--- 0.3224668502807617 seconds for one epoch ---
--- 1.785646915435791 seconds for one epoch ---
--- 0.33352041244506836 seconds for one epoch ---
--- 1.7706925868988037 seconds for one epoch ---
--- 0.31148338317871094 seconds for one epoch ---
--- 1.7821242809295654 seconds for one epoch ---
--- 0.3208041191101074 seconds for one epoch ---
--- 1.796088695526123 seconds for one epoch ---
--- 0.3366847038269043 seconds for one epoch ---
--- 1.7859408855438232 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.377932]
 [  0.      ]]
--- 0.29498863220214844 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3353.59521484375, (1559.8191, 1.853489, 1791.4974, 0.42528078)
   validation loss 794.6966552734375, (476.49777, 0.8296295, 316.944, 0.42528078)
decoder loss ratio: 18460.350932, decoder SINDy loss  ratio: 0.684168
--- 0.263491153717041 seconds for one epoch ---
--- 0.2902226448059082 seconds for one epoch ---
--- 1.723609447479248 seconds for one epoch ---
--- 0.30095577239990234 seconds for one epoch ---
--- 1.7417023181915283 seconds for one epoch ---
--- 0.28241562843322754 seconds for one epoch ---
--- 1.7698643207550049 seconds for one epoch ---
--- 0.30500197410583496 seconds for one epoch ---
--- 1.788109302520752 seconds for one epoch ---
--- 0.32705211639404297 seconds for one epoch ---
--- 1.75960373878479 seconds for one epoch ---
--- 0.32926130294799805 seconds for one epoch ---
--- 1.794661045074463 seconds for one epoch ---
--- 0.31702423095703125 seconds for one epoch ---
--- 1.785271167755127 seconds for one epoch ---
--- 0.3179354667663574 seconds for one epoch ---
--- 1.8092906475067139 seconds for one epoch ---
--- 0.32835841178894043 seconds for one epoch ---
--- 1.7695086002349854 seconds for one epoch ---
--- 0.3093760013580322 seconds for one epoch ---
--- 1.7929306030273438 seconds for one epoch ---
--- 0.3235971927642822 seconds for one epoch ---
--- 1.7910869121551514 seconds for one epoch ---
--- 0.3189527988433838 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.423616]
 [ -0.      ]]
--- 0.264054536819458 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2115.6162109375, (1192.6494, 0.9616981, 921.57874, 0.42634773)
   validation loss 1003.4677124023438, (696.99945, 1.0404512, 305.0015, 0.42634773)
decoder loss ratio: 27002.968764, decoder SINDy loss  ratio: 0.658389
--- 0.2893056869506836 seconds for one epoch ---
--- 1.7447428703308105 seconds for one epoch ---
--- 0.28990769386291504 seconds for one epoch ---
--- 1.7486953735351562 seconds for one epoch ---
--- 0.2935445308685303 seconds for one epoch ---
--- 1.7810797691345215 seconds for one epoch ---
--- 0.29630136489868164 seconds for one epoch ---
--- 1.804941177368164 seconds for one epoch ---
--- 0.31273317337036133 seconds for one epoch ---
--- 1.7851150035858154 seconds for one epoch ---
--- 0.3014192581176758 seconds for one epoch ---
--- 1.7658538818359375 seconds for one epoch ---
--- 0.30887651443481445 seconds for one epoch ---
--- 1.8350632190704346 seconds for one epoch ---
--- 0.29152607917785645 seconds for one epoch ---
--- 1.7837677001953125 seconds for one epoch ---
--- 0.30008435249328613 seconds for one epoch ---
--- 1.7964973449707031 seconds for one epoch ---
--- 0.30289125442504883 seconds for one epoch ---
--- 1.80842924118042 seconds for one epoch ---
--- 0.31239843368530273 seconds for one epoch ---
--- 1.7866406440734863 seconds for one epoch ---
--- 0.3022639751434326 seconds for one epoch ---
--- 1.7588088512420654 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.466642]
 [ -0.      ]]
--- 0.29402875900268555 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3541.8388671875, (1327.2388, 1.6432264, 2212.5295, 0.42734152)
   validation loss 928.9868774414062, (616.1664, 1.3511152, 311.042, 0.42734152)
decoder loss ratio: 23871.355344, decoder SINDy loss  ratio: 0.671428
--- 0.26856231689453125 seconds for one epoch ---
--- 0.2905604839324951 seconds for one epoch ---
--- 1.7519917488098145 seconds for one epoch ---
--- 0.2927260398864746 seconds for one epoch ---
--- 1.7683961391448975 seconds for one epoch ---
--- 0.30202412605285645 seconds for one epoch ---
--- 1.744490623474121 seconds for one epoch ---
--- 0.29883837699890137 seconds for one epoch ---
--- 1.8071701526641846 seconds for one epoch ---
--- 0.29570436477661133 seconds for one epoch ---
--- 1.7616558074951172 seconds for one epoch ---
--- 0.3019580841064453 seconds for one epoch ---
--- 1.793445348739624 seconds for one epoch ---
--- 0.2928893566131592 seconds for one epoch ---
--- 1.8034968376159668 seconds for one epoch ---
--- 0.29842329025268555 seconds for one epoch ---
--- 1.8041133880615234 seconds for one epoch ---
--- 0.30497002601623535 seconds for one epoch ---
--- 1.797327995300293 seconds for one epoch ---
--- 0.2878754138946533 seconds for one epoch ---
--- 1.8191931247711182 seconds for one epoch ---
--- 0.3132898807525635 seconds for one epoch ---
--- 1.8055944442749023 seconds for one epoch ---
--- 0.2973170280456543 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.502441]
 [ -0.      ]]
--- 0.2590763568878174 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2101.33544921875, (1007.67017, 0.35362783, 1092.8835, 0.42819712)
   validation loss 993.976318359375, (661.4617, 1.0944005, 330.99203, 0.42819712)
decoder loss ratio: 25626.173441, decoder SINDy loss  ratio: 0.714493
--- 0.29610633850097656 seconds for one epoch ---
--- 1.7629272937774658 seconds for one epoch ---
--- 0.29428553581237793 seconds for one epoch ---
--- 1.761324167251587 seconds for one epoch ---
--- 0.29968881607055664 seconds for one epoch ---
--- 1.7774837017059326 seconds for one epoch ---
--- 0.2912003993988037 seconds for one epoch ---
--- 1.8093173503875732 seconds for one epoch ---
--- 0.2764780521392822 seconds for one epoch ---
--- 1.8133411407470703 seconds for one epoch ---
--- 0.2937791347503662 seconds for one epoch ---
--- 1.7664170265197754 seconds for one epoch ---
--- 0.2787032127380371 seconds for one epoch ---
--- 1.7975382804870605 seconds for one epoch ---
--- 0.2975456714630127 seconds for one epoch ---
--- 1.7900171279907227 seconds for one epoch ---
--- 0.30002832412719727 seconds for one epoch ---
--- 1.798856258392334 seconds for one epoch ---
--- 0.2993655204772949 seconds for one epoch ---
--- 1.8132455348968506 seconds for one epoch ---
--- 0.2955188751220703 seconds for one epoch ---
--- 1.7942299842834473 seconds for one epoch ---
--- 0.29308199882507324 seconds for one epoch ---
--- 1.790395736694336 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.541838]
 [  0.      ]]
--- 0.28734683990478516 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3370.32763671875, (1547.8099, 2.0338151, 1820.0547, 0.42912737)
   validation loss 917.0609741210938, (613.90125, 1.1700556, 301.56058, 0.42912737)
decoder loss ratio: 23783.600015, decoder SINDy loss  ratio: 0.650961
--- 0.2540876865386963 seconds for one epoch ---
--- 0.30651187896728516 seconds for one epoch ---
--- 1.7885258197784424 seconds for one epoch ---
--- 0.29945874214172363 seconds for one epoch ---
--- 1.807943344116211 seconds for one epoch ---
--- 0.3082284927368164 seconds for one epoch ---
--- 1.8225393295288086 seconds for one epoch ---
--- 0.2926967144012451 seconds for one epoch ---
--- 1.7937581539154053 seconds for one epoch ---
--- 0.28138136863708496 seconds for one epoch ---
--- 1.8007512092590332 seconds for one epoch ---
--- 0.30208802223205566 seconds for one epoch ---
--- 1.790759563446045 seconds for one epoch ---
--- 0.30376291275024414 seconds for one epoch ---
--- 1.8116025924682617 seconds for one epoch ---
--- 0.2960851192474365 seconds for one epoch ---
--- 1.8164498805999756 seconds for one epoch ---
--- 0.2911033630371094 seconds for one epoch ---
--- 1.8403146266937256 seconds for one epoch ---
--- 0.312760591506958 seconds for one epoch ---
--- 1.8146960735321045 seconds for one epoch ---
--- 0.2984449863433838 seconds for one epoch ---
--- 1.8118596076965332 seconds for one epoch ---
--- 0.2938356399536133 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.575554]
 [  0.      ]]
--- 0.24918818473815918 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2917.864990234375, (1488.7703, 0.674228, 1427.9906, 0.4300339)
   validation loss 1127.0496826171875, (750.3732, 0.58034325, 375.66608, 0.4300339)
decoder loss ratio: 29070.761635, decoder SINDy loss  ratio: 0.810928
--- 0.2909889221191406 seconds for one epoch ---
--- 1.7897441387176514 seconds for one epoch ---
--- 0.2996063232421875 seconds for one epoch ---
--- 1.7958567142486572 seconds for one epoch ---
--- 0.29230594635009766 seconds for one epoch ---
--- 1.8256762027740479 seconds for one epoch ---
--- 0.2957727909088135 seconds for one epoch ---
--- 1.835524320602417 seconds for one epoch ---
--- 0.29951906204223633 seconds for one epoch ---
--- 1.8198912143707275 seconds for one epoch ---
--- 0.2922234535217285 seconds for one epoch ---
--- 1.832000732421875 seconds for one epoch ---
--- 0.28110432624816895 seconds for one epoch ---
--- 1.8489174842834473 seconds for one epoch ---
--- 0.3092367649078369 seconds for one epoch ---
--- 1.8198344707489014 seconds for one epoch ---
--- 0.2936875820159912 seconds for one epoch ---
--- 1.8407888412475586 seconds for one epoch ---
--- 0.29412221908569336 seconds for one epoch ---
--- 1.8342804908752441 seconds for one epoch ---
--- 0.3081998825073242 seconds for one epoch ---
--- 1.8495969772338867 seconds for one epoch ---
--- 0.30069494247436523 seconds for one epoch ---
--- 1.8305912017822266 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.611763]
 [  0.      ]]
--- 0.2904219627380371 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1688.1900634765625, (796.4933, 0.99746513, 890.26843, 0.43085727)
   validation loss 872.9826049804688, (557.8876, 1.1041347, 313.5601, 0.43085727)
decoder loss ratio: 21613.533123, decoder SINDy loss  ratio: 0.676864
--- 0.2563774585723877 seconds for one epoch ---
--- 0.2999558448791504 seconds for one epoch ---
--- 1.811173915863037 seconds for one epoch ---
--- 0.2858853340148926 seconds for one epoch ---
--- 1.8263051509857178 seconds for one epoch ---
--- 0.2957777976989746 seconds for one epoch ---
--- 1.8445799350738525 seconds for one epoch ---
--- 0.2962162494659424 seconds for one epoch ---
--- 1.8332438468933105 seconds for one epoch ---
--- 0.2958686351776123 seconds for one epoch ---
--- 1.814284324645996 seconds for one epoch ---
--- 0.3008458614349365 seconds for one epoch ---
--- 1.8074755668640137 seconds for one epoch ---
--- 0.307481050491333 seconds for one epoch ---
--- 1.8315813541412354 seconds for one epoch ---
--- 0.291074275970459 seconds for one epoch ---
--- 1.83848237991333 seconds for one epoch ---
--- 0.3013317584991455 seconds for one epoch ---
--- 1.8590869903564453 seconds for one epoch ---
--- 0.3068509101867676 seconds for one epoch ---
--- 1.8218886852264404 seconds for one epoch ---
--- 0.29840946197509766 seconds for one epoch ---
--- 1.8603355884552002 seconds for one epoch ---
--- 0.3120706081390381 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.651209]
 [ -0.      ]]
--- 0.24997234344482422 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3364.1533203125, (2206.4985, 0.19531465, 1157.0276, 0.4318758)
   validation loss 1109.8707275390625, (760.2854, 1.0852562, 348.0682, 0.4318758)
decoder loss ratio: 29454.776325, decoder SINDy loss  ratio: 0.751354
--- 0.2875492572784424 seconds for one epoch ---
--- 1.7984163761138916 seconds for one epoch ---
--- 0.29801392555236816 seconds for one epoch ---
--- 1.8116188049316406 seconds for one epoch ---
--- 0.2851688861846924 seconds for one epoch ---
--- 1.8454642295837402 seconds for one epoch ---
--- 0.29392075538635254 seconds for one epoch ---
--- 1.8564677238464355 seconds for one epoch ---
--- 0.292621374130249 seconds for one epoch ---
--- 1.8508024215698242 seconds for one epoch ---
--- 0.295635461807251 seconds for one epoch ---
--- 1.8437252044677734 seconds for one epoch ---
--- 0.3018515110015869 seconds for one epoch ---
--- 1.8500580787658691 seconds for one epoch ---
--- 0.29583144187927246 seconds for one epoch ---
--- 1.8545401096343994 seconds for one epoch ---
--- 0.2923622131347656 seconds for one epoch ---
--- 1.8633472919464111 seconds for one epoch ---
--- 0.2948648929595947 seconds for one epoch ---
--- 1.873887062072754 seconds for one epoch ---
--- 0.29943251609802246 seconds for one epoch ---
--- 1.8326280117034912 seconds for one epoch ---
--- 0.276597261428833 seconds for one epoch ---
--- 1.8501384258270264 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.68798]
 [ -0.     ]]
--- 0.27576279640197754 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1616.676025390625, (730.6056, 1.6284678, 884.0093, 0.43265152)
   validation loss 875.1846923828125, (567.30774, 1.0725034, 306.37177, 0.43265152)
decoder loss ratio: 21978.486708, decoder SINDy loss  ratio: 0.661347
--- 0.25746703147888184 seconds for one epoch ---
--- 0.29332661628723145 seconds for one epoch ---
--- 1.7982683181762695 seconds for one epoch ---
--- 0.2810490131378174 seconds for one epoch ---
--- 1.7809076309204102 seconds for one epoch ---
--- 0.2960679531097412 seconds for one epoch ---
--- 1.8989982604980469 seconds for one epoch ---
--- 0.2921574115753174 seconds for one epoch ---
--- 1.8392252922058105 seconds for one epoch ---
--- 0.28781795501708984 seconds for one epoch ---
--- 1.8375334739685059 seconds for one epoch ---
--- 0.29203295707702637 seconds for one epoch ---
--- 1.866197109222412 seconds for one epoch ---
--- 0.2959098815917969 seconds for one epoch ---
--- 1.8704743385314941 seconds for one epoch ---
--- 0.28582334518432617 seconds for one epoch ---
--- 1.855431318283081 seconds for one epoch ---
--- 0.30573534965515137 seconds for one epoch ---
--- 1.861161708831787 seconds for one epoch ---
--- 0.29035353660583496 seconds for one epoch ---
--- 1.8631377220153809 seconds for one epoch ---
--- 0.30202651023864746 seconds for one epoch ---
--- 1.9041075706481934 seconds for one epoch ---
--- 0.3011171817779541 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.719225]
 [ -0.      ]]
--- 0.2575521469116211 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3321.402099609375, (1472.1735, 2.3479702, 1846.4474, 0.4334651)
   validation loss 880.5618286132812, (545.8564, 0.9140659, 333.3579, 0.4334651)
decoder loss ratio: 21147.423975, decoder SINDy loss  ratio: 0.719600
--- 0.2839229106903076 seconds for one epoch ---
--- 1.8215410709381104 seconds for one epoch ---
--- 0.30129337310791016 seconds for one epoch ---
--- 1.8011689186096191 seconds for one epoch ---
--- 0.30429863929748535 seconds for one epoch ---
--- 1.813117504119873 seconds for one epoch ---
--- 0.3010237216949463 seconds for one epoch ---
--- 1.8150527477264404 seconds for one epoch ---
--- 0.29651641845703125 seconds for one epoch ---
--- 1.9036731719970703 seconds for one epoch ---
--- 0.3167150020599365 seconds for one epoch ---
--- 1.8722808361053467 seconds for one epoch ---
--- 0.31588029861450195 seconds for one epoch ---
--- 1.8732717037200928 seconds for one epoch ---
--- 0.29491138458251953 seconds for one epoch ---
--- 1.8807132244110107 seconds for one epoch ---
--- 0.3183596134185791 seconds for one epoch ---
--- 1.8519158363342285 seconds for one epoch ---
--- 0.29659032821655273 seconds for one epoch ---
--- 1.9085705280303955 seconds for one epoch ---
--- 0.28125834465026855 seconds for one epoch ---
--- 1.8938097953796387 seconds for one epoch ---
--- 0.30531859397888184 seconds for one epoch ---
--- 1.8956546783447266 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.752054]
 [  0.      ]]
--- 0.27979302406311035 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3553.7822265625, (1462.8303, 1.7204683, 2088.797, 0.43431813)
   validation loss 1079.6202392578125, (731.8417, 0.8067126, 346.5375, 0.43431813)
decoder loss ratio: 28352.817015, decoder SINDy loss  ratio: 0.748050
--- 0.25597071647644043 seconds for one epoch ---
--- 0.30439209938049316 seconds for one epoch ---
--- 1.8320415019989014 seconds for one epoch ---
--- 0.3004007339477539 seconds for one epoch ---
--- 1.846834421157837 seconds for one epoch ---
--- 0.29927730560302734 seconds for one epoch ---
--- 1.8452277183532715 seconds for one epoch ---
--- 0.3076343536376953 seconds for one epoch ---
--- 1.8483858108520508 seconds for one epoch ---
--- 0.32662487030029297 seconds for one epoch ---
--- 1.8977391719818115 seconds for one epoch ---
--- 0.3401672840118408 seconds for one epoch ---
--- 1.9072186946868896 seconds for one epoch ---
--- 0.31965041160583496 seconds for one epoch ---
--- 1.9079864025115967 seconds for one epoch ---
--- 0.3315911293029785 seconds for one epoch ---
--- 1.8728368282318115 seconds for one epoch ---
--- 0.32265639305114746 seconds for one epoch ---
--- 1.9128954410552979 seconds for one epoch ---
--- 0.3325495719909668 seconds for one epoch ---
--- 1.8744490146636963 seconds for one epoch ---
--- 0.32068395614624023 seconds for one epoch ---
--- 1.860771656036377 seconds for one epoch ---
--- 0.3174867630004883 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.784739]
 [  0.      ]]
--- 0.2581808567047119 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2429.23828125, (1214.93, 2.4159534, 1211.4573, 0.43506643)
   validation loss 1092.5162353515625, (748.0664, 0.7467907, 343.268, 0.43506643)
decoder loss ratio: 28981.391279, decoder SINDy loss  ratio: 0.740992
--- 0.2946944236755371 seconds for one epoch ---
--- 1.843515157699585 seconds for one epoch ---
--- 0.30277442932128906 seconds for one epoch ---
--- 1.8579494953155518 seconds for one epoch ---
--- 0.29461145401000977 seconds for one epoch ---
--- 1.8500874042510986 seconds for one epoch ---
--- 0.296586275100708 seconds for one epoch ---
--- 1.8916161060333252 seconds for one epoch ---
--- 0.29750752449035645 seconds for one epoch ---
--- 1.919053077697754 seconds for one epoch ---
--- 0.31275367736816406 seconds for one epoch ---
--- 1.898693561553955 seconds for one epoch ---
--- 0.30133891105651855 seconds for one epoch ---
--- 1.9152472019195557 seconds for one epoch ---
--- 0.3167412281036377 seconds for one epoch ---
--- 1.9128906726837158 seconds for one epoch ---
--- 0.2848491668701172 seconds for one epoch ---
--- 1.8739113807678223 seconds for one epoch ---
--- 0.32468628883361816 seconds for one epoch ---
--- 1.9203722476959229 seconds for one epoch ---
--- 0.3212156295776367 seconds for one epoch ---
--- 1.9023141860961914 seconds for one epoch ---
--- 0.30910706520080566 seconds for one epoch ---
--- 1.9421651363372803 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.815783]
 [  0.      ]]
--- 0.29577136039733887 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2664.2958984375, (1307.1278, 1.090667, 1355.6416, 0.43580166)
   validation loss 991.8560180664062, (634.5606, 1.0271969, 355.8324, 0.43580166)
decoder loss ratio: 24583.979596, decoder SINDy loss  ratio: 0.768114
--- 0.2571732997894287 seconds for one epoch ---
--- 0.29427289962768555 seconds for one epoch ---
--- 1.8486762046813965 seconds for one epoch ---
--- 0.2949237823486328 seconds for one epoch ---
--- 1.8584587574005127 seconds for one epoch ---
--- 0.28974342346191406 seconds for one epoch ---
--- 1.8449804782867432 seconds for one epoch ---
--- 0.2943911552429199 seconds for one epoch ---
--- 1.8617398738861084 seconds for one epoch ---
--- 0.2880558967590332 seconds for one epoch ---
--- 1.8934526443481445 seconds for one epoch ---
--- 0.26241230964660645 seconds for one epoch ---
--- 1.883676290512085 seconds for one epoch ---
--- 0.30286407470703125 seconds for one epoch ---
--- 1.8880269527435303 seconds for one epoch ---
--- 0.28742003440856934 seconds for one epoch ---
--- 1.8698673248291016 seconds for one epoch ---
--- 0.29349517822265625 seconds for one epoch ---
--- 1.8939180374145508 seconds for one epoch ---
--- 0.30041003227233887 seconds for one epoch ---
--- 1.923161506652832 seconds for one epoch ---
--- 0.29419398307800293 seconds for one epoch ---
--- 1.9107415676116943 seconds for one epoch ---
--- 0.29878902435302734 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.84674]
 [ -0.     ]]
--- 0.2557251453399658 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2131.660400390625, (1020.4587, 1.376398, 1109.3888, 0.43659687)
   validation loss 992.5693969726562, (643.82196, 1.253747, 347.05713, 0.43659687)
decoder loss ratio: 24942.780472, decoder SINDy loss  ratio: 0.749172
--- 0.31137967109680176 seconds for one epoch ---
--- 1.896845817565918 seconds for one epoch ---
--- 0.33408331871032715 seconds for one epoch ---
--- 1.8857100009918213 seconds for one epoch ---
--- 0.3071756362915039 seconds for one epoch ---
--- 1.918116807937622 seconds for one epoch ---
--- 0.308729887008667 seconds for one epoch ---
--- 1.9381678104400635 seconds for one epoch ---
--- 0.3089306354522705 seconds for one epoch ---
--- 1.9235029220581055 seconds for one epoch ---
--- 0.33380913734436035 seconds for one epoch ---
--- 1.8955812454223633 seconds for one epoch ---
--- 0.29039835929870605 seconds for one epoch ---
--- 1.8999969959259033 seconds for one epoch ---
--- 0.3027927875518799 seconds for one epoch ---
--- 1.9126427173614502 seconds for one epoch ---
--- 0.2949483394622803 seconds for one epoch ---
--- 1.8869092464447021 seconds for one epoch ---
--- 0.29547977447509766 seconds for one epoch ---
--- 1.9158480167388916 seconds for one epoch ---
--- 0.2836735248565674 seconds for one epoch ---
--- 1.9264216423034668 seconds for one epoch ---
--- 0.29188108444213867 seconds for one epoch ---
--- 1.922231912612915 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.882917]
 [ -0.      ]]
--- 0.29498291015625 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2172.722412109375, (1230.1691, 2.3876436, 939.7282, 0.43750784)
   validation loss 815.0079956054688, (480.89023, 1.0876157, 332.59265, 0.43750784)
decoder loss ratio: 18630.522305, decoder SINDy loss  ratio: 0.717948
THRESHOLDING: 1 active coefficients
--- 1.9289665222167969 seconds for one epoch ---
--- 0.2933487892150879 seconds for one epoch ---
--- 1.9500861167907715 seconds for one epoch ---
--- 0.2971494197845459 seconds for one epoch ---
--- 1.9427425861358643 seconds for one epoch ---
--- 0.2799701690673828 seconds for one epoch ---
--- 1.917616844177246 seconds for one epoch ---
--- 0.28962039947509766 seconds for one epoch ---
--- 1.9045994281768799 seconds for one epoch ---
--- 0.2937734127044678 seconds for one epoch ---
--- 1.9252912998199463 seconds for one epoch ---
--- 0.29117631912231445 seconds for one epoch ---
--- 1.9058074951171875 seconds for one epoch ---
--- 0.2902066707611084 seconds for one epoch ---
--- 1.9198877811431885 seconds for one epoch ---
--- 0.28786516189575195 seconds for one epoch ---
--- 1.9357755184173584 seconds for one epoch ---
--- 0.3131275177001953 seconds for one epoch ---
--- 1.9190595149993896 seconds for one epoch ---
--- 0.29088473320007324 seconds for one epoch ---
--- 1.956444263458252 seconds for one epoch ---
--- 0.29814934730529785 seconds for one epoch ---
--- 1.9764316082000732 seconds for one epoch ---
--- 0.30206751823425293 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.91564]
 [ -0.     ]]
--- 0.2739980220794678 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2711.73828125, (1185.8107, 1.8761451, 1523.6133, 0.4382374)
   validation loss 914.0125732421875, (574.07294, 0.90179783, 338.5996, 0.4382374)
decoder loss ratio: 22240.582214, decoder SINDy loss  ratio: 0.730915
--- 0.30239033699035645 seconds for one epoch ---
--- 1.9466552734375 seconds for one epoch ---
--- 0.28033876419067383 seconds for one epoch ---
--- 1.9725334644317627 seconds for one epoch ---
--- 0.3022465705871582 seconds for one epoch ---
--- 1.9326138496398926 seconds for one epoch ---
--- 0.29231786727905273 seconds for one epoch ---
--- 1.9253079891204834 seconds for one epoch ---
--- 0.29972028732299805 seconds for one epoch ---
--- 1.9299261569976807 seconds for one epoch ---
--- 0.29906773567199707 seconds for one epoch ---
--- 1.9254474639892578 seconds for one epoch ---
--- 0.29355406761169434 seconds for one epoch ---
--- 1.9399590492248535 seconds for one epoch ---
--- 0.29535460472106934 seconds for one epoch ---
--- 1.9583139419555664 seconds for one epoch ---
--- 0.32521677017211914 seconds for one epoch ---
--- 1.9479680061340332 seconds for one epoch ---
--- 0.3357381820678711 seconds for one epoch ---
--- 1.9946048259735107 seconds for one epoch ---
--- 0.3262178897857666 seconds for one epoch ---
--- 2.0390677452087402 seconds for one epoch ---
--- 0.3304784297943115 seconds for one epoch ---
--- 1.9635956287384033 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.938349]
 [  0.      ]]
--- 0.304973840713501 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2041.5618896484375, (1020.7883, 0.6570898, 1019.67755, 0.43887702)
   validation loss 926.3178100585938, (602.756, 1.1783904, 321.94452, 0.43887702)
decoder loss ratio: 23351.813152, decoder SINDy loss  ratio: 0.694963
--- 0.25969529151916504 seconds for one epoch ---
--- 0.29205322265625 seconds for one epoch ---
--- 1.9571502208709717 seconds for one epoch ---
--- 0.3287956714630127 seconds for one epoch ---
--- 1.982041835784912 seconds for one epoch ---
--- 0.31467628479003906 seconds for one epoch ---
--- 1.9247150421142578 seconds for one epoch ---
--- 0.30420851707458496 seconds for one epoch ---
--- 1.9239122867584229 seconds for one epoch ---
--- 0.2964620590209961 seconds for one epoch ---
--- 1.9202702045440674 seconds for one epoch ---
--- 0.3019731044769287 seconds for one epoch ---
--- 1.9230079650878906 seconds for one epoch ---
--- 0.29601192474365234 seconds for one epoch ---
--- 1.9549274444580078 seconds for one epoch ---
--- 0.30057525634765625 seconds for one epoch ---
--- 1.9600436687469482 seconds for one epoch ---
--- 0.2909204959869385 seconds for one epoch ---
--- 1.9959015846252441 seconds for one epoch ---
--- 0.30024170875549316 seconds for one epoch ---
--- 2.0058071613311768 seconds for one epoch ---
--- 0.2921936511993408 seconds for one epoch ---
--- 1.9785325527191162 seconds for one epoch ---
--- 0.29732346534729004 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.970308]
 [  0.      ]]
--- 0.25971150398254395 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2301.915771484375, (1310.0911, 7.57352, 983.81146, 0.43962508)
   validation loss 896.1976928710938, (553.40155, 1.1095018, 341.247, 0.43962508)
decoder loss ratio: 21439.736806, decoder SINDy loss  ratio: 0.736630
--- 0.28747081756591797 seconds for one epoch ---
--- 1.9445219039916992 seconds for one epoch ---
--- 0.3034822940826416 seconds for one epoch ---
--- 1.9612619876861572 seconds for one epoch ---
--- 0.3067753314971924 seconds for one epoch ---
--- 1.9897856712341309 seconds for one epoch ---
--- 0.3107185363769531 seconds for one epoch ---
--- 1.9893214702606201 seconds for one epoch ---
--- 0.2957570552825928 seconds for one epoch ---
--- 1.9247756004333496 seconds for one epoch ---
--- 0.292417049407959 seconds for one epoch ---
--- 1.9395866394042969 seconds for one epoch ---
--- 0.30635762214660645 seconds for one epoch ---
--- 1.9386234283447266 seconds for one epoch ---
--- 0.29980039596557617 seconds for one epoch ---
--- 1.94917631149292 seconds for one epoch ---
--- 0.29749011993408203 seconds for one epoch ---
--- 1.9637527465820312 seconds for one epoch ---
--- 0.2911086082458496 seconds for one epoch ---
--- 1.9740324020385742 seconds for one epoch ---
--- 0.29520559310913086 seconds for one epoch ---
--- 1.9695630073547363 seconds for one epoch ---
--- 0.30596446990966797 seconds for one epoch ---
--- 1.9855685234069824 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.997255]
 [  0.      ]]
--- 0.30400848388671875 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2141.811767578125, (1078.9373, 1.42209, 1061.0123, 0.4402565)
   validation loss 927.4774780273438, (614.5131, 1.01433, 311.50977, 0.4402565)
decoder loss ratio: 23807.305210, decoder SINDy loss  ratio: 0.672438
--- 0.26438236236572266 seconds for one epoch ---
--- 0.2933468818664551 seconds for one epoch ---
--- 1.984525442123413 seconds for one epoch ---
--- 0.2778472900390625 seconds for one epoch ---
--- 1.9532151222229004 seconds for one epoch ---
--- 0.2975459098815918 seconds for one epoch ---
--- 1.9979255199432373 seconds for one epoch ---
--- 0.2967829704284668 seconds for one epoch ---
--- 1.9916725158691406 seconds for one epoch ---
--- 0.2911670207977295 seconds for one epoch ---
--- 1.9335660934448242 seconds for one epoch ---
--- 0.2870194911956787 seconds for one epoch ---
--- 1.928938865661621 seconds for one epoch ---
--- 0.2976071834564209 seconds for one epoch ---
--- 1.9475538730621338 seconds for one epoch ---
--- 0.2925574779510498 seconds for one epoch ---
--- 1.9505798816680908 seconds for one epoch ---
--- 0.2917928695678711 seconds for one epoch ---
--- 1.9620850086212158 seconds for one epoch ---
--- 0.2956418991088867 seconds for one epoch ---
--- 1.9925742149353027 seconds for one epoch ---
--- 0.29978227615356445 seconds for one epoch ---
--- 1.99436354637146 seconds for one epoch ---
--- 0.2990152835845947 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.02442]
 [ -0.     ]]
--- 0.2505476474761963 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2158.1259765625, (1299.6326, 0.4744291, 857.57806, 0.44100353)
   validation loss 855.3699340820312, (524.32367, 0.95899165, 329.64627, 0.44100353)
decoder loss ratio: 20313.209220, decoder SINDy loss  ratio: 0.711588
--- 0.30413222312927246 seconds for one epoch ---
--- 2.008357048034668 seconds for one epoch ---
--- 0.29416894912719727 seconds for one epoch ---
--- 1.9649879932403564 seconds for one epoch ---
--- 0.2929720878601074 seconds for one epoch ---
--- 1.9971606731414795 seconds for one epoch ---
--- 0.3092985153198242 seconds for one epoch ---
--- 1.9886033535003662 seconds for one epoch ---
--- 0.2979393005371094 seconds for one epoch ---
--- 2.0186357498168945 seconds for one epoch ---
--- 0.29685258865356445 seconds for one epoch ---
--- 1.9497334957122803 seconds for one epoch ---
--- 0.27310872077941895 seconds for one epoch ---
--- 1.9490556716918945 seconds for one epoch ---
--- 0.2930920124053955 seconds for one epoch ---
--- 1.9789056777954102 seconds for one epoch ---
--- 0.2901582717895508 seconds for one epoch ---
--- 1.937939167022705 seconds for one epoch ---
--- 0.2933030128479004 seconds for one epoch ---
--- 2.01352858543396 seconds for one epoch ---
--- 0.29935288429260254 seconds for one epoch ---
--- 2.0371246337890625 seconds for one epoch ---
--- 0.3016831874847412 seconds for one epoch ---
--- 2.038038492202759 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.053633]
 [ -0.      ]]
--- 0.29518914222717285 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2315.828857421875, (1184.812, 1.4837127, 1129.0913, 0.44170585)
   validation loss 877.4443969726562, (556.59534, 1.3931756, 319.01413, 0.44170585)
decoder loss ratio: 21563.469644, decoder SINDy loss  ratio: 0.688637
--- 0.27343130111694336 seconds for one epoch ---
--- 0.3018465042114258 seconds for one epoch ---
--- 2.035172700881958 seconds for one epoch ---
--- 0.3101227283477783 seconds for one epoch ---
--- 2.013699531555176 seconds for one epoch ---
--- 0.3014030456542969 seconds for one epoch ---
--- 2.0343782901763916 seconds for one epoch ---
--- 0.29299211502075195 seconds for one epoch ---
--- 2.062345027923584 seconds for one epoch ---
--- 0.2968254089355469 seconds for one epoch ---
--- 1.9937467575073242 seconds for one epoch ---
--- 0.2952244281768799 seconds for one epoch ---
--- 2.0062196254730225 seconds for one epoch ---
--- 0.292133092880249 seconds for one epoch ---
--- 2.003563165664673 seconds for one epoch ---
--- 0.30048704147338867 seconds for one epoch ---
--- 1.9966886043548584 seconds for one epoch ---
--- 0.2913525104522705 seconds for one epoch ---
--- 2.0318119525909424 seconds for one epoch ---
--- 0.3111002445220947 seconds for one epoch ---
--- 2.0415289402008057 seconds for one epoch ---
--- 0.2944333553314209 seconds for one epoch ---
--- 2.0131900310516357 seconds for one epoch ---
--- 0.2768363952636719 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.075737]
 [ -0.      ]]
--- 0.24796247482299805 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3722.876708984375, (1667.7327, 4.8075614, 2049.8943, 0.44217548)
   validation loss 853.0712280273438, (534.9171, 0.8443752, 316.86758, 0.44217548)
decoder loss ratio: 20723.617663, decoder SINDy loss  ratio: 0.684003
--- 0.28757596015930176 seconds for one epoch ---
--- 2.0004470348358154 seconds for one epoch ---
--- 0.29648494720458984 seconds for one epoch ---
--- 2.0437748432159424 seconds for one epoch ---
--- 0.29187846183776855 seconds for one epoch ---
--- 2.021860361099243 seconds for one epoch ---
--- 0.2871994972229004 seconds for one epoch ---
--- 2.057173728942871 seconds for one epoch ---
--- 0.3013498783111572 seconds for one epoch ---
--- 2.045828104019165 seconds for one epoch ---
--- 0.28588271141052246 seconds for one epoch ---
--- 1.9928371906280518 seconds for one epoch ---
--- 0.29526448249816895 seconds for one epoch ---
--- 2.0217387676239014 seconds for one epoch ---
--- 0.29489588737487793 seconds for one epoch ---
--- 2.014179229736328 seconds for one epoch ---
--- 0.28059864044189453 seconds for one epoch ---
--- 2.01487398147583 seconds for one epoch ---
--- 0.29447126388549805 seconds for one epoch ---
--- 2.0532515048980713 seconds for one epoch ---
--- 0.30376267433166504 seconds for one epoch ---
--- 2.05108380317688 seconds for one epoch ---
--- 0.30471086502075195 seconds for one epoch ---
--- 2.0349929332733154 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.09838]
 [  0.     ]]
--- 0.2856733798980713 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2120.39306640625, (1031.4049, 1.1179335, 1087.4274, 0.44281703)
   validation loss 955.2151489257812, (623.3074, 1.1410068, 330.32394, 0.44281703)
decoder loss ratio: 24148.009741, decoder SINDy loss  ratio: 0.713051
--- 0.24501299858093262 seconds for one epoch ---
--- 0.2965075969696045 seconds for one epoch ---
--- 2.0306074619293213 seconds for one epoch ---
--- 0.2999444007873535 seconds for one epoch ---
--- 2.0721113681793213 seconds for one epoch ---
--- 0.28754425048828125 seconds for one epoch ---
--- 2.0440971851348877 seconds for one epoch ---
--- 0.3004765510559082 seconds for one epoch ---
--- 2.0733795166015625 seconds for one epoch ---
--- 0.2974121570587158 seconds for one epoch ---
--- 1.9931995868682861 seconds for one epoch ---
--- 0.29546356201171875 seconds for one epoch ---
--- 2.020899534225464 seconds for one epoch ---
--- 0.2653157711029053 seconds for one epoch ---
--- 1.9973888397216797 seconds for one epoch ---
--- 0.2941300868988037 seconds for one epoch ---
--- 2.0114905834198 seconds for one epoch ---
--- 0.28791189193725586 seconds for one epoch ---
--- 2.038856029510498 seconds for one epoch ---
--- 0.2964165210723877 seconds for one epoch ---
--- 2.0546507835388184 seconds for one epoch ---
--- 0.2921319007873535 seconds for one epoch ---
--- 2.0619325637817383 seconds for one epoch ---
--- 0.2954111099243164 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.130552]
 [  0.      ]]
--- 0.26253747940063477 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2640.13525390625, (1221.0397, 1.5576675, 1417.0944, 0.4435916)
   validation loss 907.5318603515625, (585.0501, 1.0192823, 321.01883, 0.4435916)
decoder loss ratio: 22665.856948, decoder SINDy loss  ratio: 0.692964
--- 0.29186344146728516 seconds for one epoch ---
--- 2.064854145050049 seconds for one epoch ---
--- 0.30307650566101074 seconds for one epoch ---
--- 2.063225746154785 seconds for one epoch ---
--- 0.2978372573852539 seconds for one epoch ---
--- 2.0758109092712402 seconds for one epoch ---
--- 0.2950737476348877 seconds for one epoch ---
--- 2.081936836242676 seconds for one epoch ---
--- 0.2962827682495117 seconds for one epoch ---
--- 2.100543737411499 seconds for one epoch ---
--- 0.2975883483886719 seconds for one epoch ---
--- 2.0349504947662354 seconds for one epoch ---
--- 0.2909870147705078 seconds for one epoch ---
--- 2.0351903438568115 seconds for one epoch ---
--- 0.2834961414337158 seconds for one epoch ---
--- 2.025641679763794 seconds for one epoch ---
--- 0.29413318634033203 seconds for one epoch ---
--- 2.0256543159484863 seconds for one epoch ---
--- 0.28935885429382324 seconds for one epoch ---
--- 2.024324417114258 seconds for one epoch ---
--- 0.29050517082214355 seconds for one epoch ---
--- 2.0741028785705566 seconds for one epoch ---
--- 0.30140066146850586 seconds for one epoch ---
--- 2.07482647895813 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.151377]
 [  0.      ]]
--- 0.29100728034973145 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2562.876708984375, (1079.6699, 1.6224484, 1481.1404, 0.44409147)
   validation loss 1041.6724853515625, (684.61444, 0.8932722, 355.7207, 0.44409147)
decoder loss ratio: 26523.151984, decoder SINDy loss  ratio: 0.767873
--- 0.2630271911621094 seconds for one epoch ---
--- 0.2884836196899414 seconds for one epoch ---
--- 2.0513038635253906 seconds for one epoch ---
--- 0.29390883445739746 seconds for one epoch ---
--- 2.0793840885162354 seconds for one epoch ---
--- 0.2952992916107178 seconds for one epoch ---
--- 2.0920729637145996 seconds for one epoch ---
--- 0.2992119789123535 seconds for one epoch ---
--- 2.1036901473999023 seconds for one epoch ---
--- 0.2866361141204834 seconds for one epoch ---
--- 2.0767853260040283 seconds for one epoch ---
--- 0.29460787773132324 seconds for one epoch ---
--- 2.033360719680786 seconds for one epoch ---
--- 0.28719425201416016 seconds for one epoch ---
--- 2.045048475265503 seconds for one epoch ---
--- 0.2905125617980957 seconds for one epoch ---
--- 2.0640509128570557 seconds for one epoch ---
--- 0.29605674743652344 seconds for one epoch ---
--- 2.049161672592163 seconds for one epoch ---
--- 0.2948746681213379 seconds for one epoch ---
--- 2.073331117630005 seconds for one epoch ---
--- 0.3152346611022949 seconds for one epoch ---
--- 2.102187395095825 seconds for one epoch ---
--- 0.3424417972564697 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.17182]
 [ -0.     ]]
--- 0.26554059982299805 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3602.644775390625, (1643.0122, 4.1964965, 1954.9916, 0.44467163)
   validation loss 1120.585693359375, (752.72296, 0.7786676, 366.63934, 0.44467163)
decoder loss ratio: 29161.794310, decoder SINDy loss  ratio: 0.791443
--- 0.3086104393005371 seconds for one epoch ---
--- 2.0992789268493652 seconds for one epoch ---
--- 0.2973048686981201 seconds for one epoch ---
--- 2.074162006378174 seconds for one epoch ---
--- 0.28939366340637207 seconds for one epoch ---
--- 2.0907466411590576 seconds for one epoch ---
--- 0.30132198333740234 seconds for one epoch ---
--- 2.0736520290374756 seconds for one epoch ---
--- 0.28376150131225586 seconds for one epoch ---
--- 2.0945873260498047 seconds for one epoch ---
--- 0.2914555072784424 seconds for one epoch ---
--- 2.106525182723999 seconds for one epoch ---
--- 0.2913384437561035 seconds for one epoch ---
--- 2.0283641815185547 seconds for one epoch ---
--- 0.28718996047973633 seconds for one epoch ---
--- 2.036308526992798 seconds for one epoch ---
--- 0.29501843452453613 seconds for one epoch ---
--- 2.060633897781372 seconds for one epoch ---
--- 0.2839515209197998 seconds for one epoch ---
--- 2.0441839694976807 seconds for one epoch ---
--- 0.30022478103637695 seconds for one epoch ---
--- 2.0592403411865234 seconds for one epoch ---
--- 0.6576321125030518 seconds for one epoch ---
--- 2.108563184738159 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.200773]
 [ -0.      ]]
--- 0.28897571563720703 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2798.96728515625, (1475.5742, 1.2042875, 1321.7435, 0.44533595)
   validation loss 1161.818603515625, (791.4656, 1.032039, 368.8757, 0.44533595)
decoder loss ratio: 30662.750466, decoder SINDy loss  ratio: 0.796270
--- 0.2608354091644287 seconds for one epoch ---
--- 0.302227258682251 seconds for one epoch ---
--- 2.0967328548431396 seconds for one epoch ---
--- 0.30142712593078613 seconds for one epoch ---
--- 2.0777204036712646 seconds for one epoch ---
--- 0.3122272491455078 seconds for one epoch ---
--- 2.0954782962799072 seconds for one epoch ---
--- 0.2978639602661133 seconds for one epoch ---
--- 2.081721067428589 seconds for one epoch ---
--- 0.3061213493347168 seconds for one epoch ---
--- 2.123438596725464 seconds for one epoch ---
--- 0.3003695011138916 seconds for one epoch ---
--- 2.0947046279907227 seconds for one epoch ---
--- 0.3000035285949707 seconds for one epoch ---
--- 2.061905860900879 seconds for one epoch ---
--- 0.2947204113006592 seconds for one epoch ---
--- 2.0614919662475586 seconds for one epoch ---
--- 0.2969496250152588 seconds for one epoch ---
--- 2.0697031021118164 seconds for one epoch ---
--- 0.29145002365112305 seconds for one epoch ---
--- 2.067715644836426 seconds for one epoch ---
--- 0.3025343418121338 seconds for one epoch ---
--- 2.088512420654297 seconds for one epoch ---
--- 0.3050105571746826 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.215208]
 [ -0.      ]]
--- 0.26857709884643555 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1978.9071044921875, (1054.696, 8.917149, 914.8482, 0.44570103)
   validation loss 814.9473876953125, (476.1867, 1.1454263, 337.16956, 0.44570103)
decoder loss ratio: 18448.299708, decoder SINDy loss  ratio: 0.727828
--- 0.30846595764160156 seconds for one epoch ---
--- 2.1025595664978027 seconds for one epoch ---
--- 0.2870156764984131 seconds for one epoch ---
--- 2.0797111988067627 seconds for one epoch ---
--- 0.2925405502319336 seconds for one epoch ---
--- 2.086512327194214 seconds for one epoch ---
--- 0.29012036323547363 seconds for one epoch ---
--- 2.0809576511383057 seconds for one epoch ---
--- 0.2816050052642822 seconds for one epoch ---
--- 2.0851786136627197 seconds for one epoch ---
--- 0.2951960563659668 seconds for one epoch ---
--- 2.1057777404785156 seconds for one epoch ---
--- 0.3016953468322754 seconds for one epoch ---
--- 2.1111559867858887 seconds for one epoch ---
--- 0.2952291965484619 seconds for one epoch ---
--- 2.077666997909546 seconds for one epoch ---
--- 0.28022289276123047 seconds for one epoch ---
--- 2.075071096420288 seconds for one epoch ---
--- 0.2859690189361572 seconds for one epoch ---
--- 2.0719454288482666 seconds for one epoch ---
--- 0.28778886795043945 seconds for one epoch ---
--- 2.052006959915161 seconds for one epoch ---
--- 0.2929520606994629 seconds for one epoch ---
--- 2.0711829662323 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.23605]
 [  0.     ]]
--- 0.29646825790405273 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2961.05322265625, (1129.193, 0.7695861, 1830.6444, 0.44625852)
   validation loss 1710.6778564453125, (1296.6239, 1.0629647, 412.5447, 0.44625852)
decoder loss ratio: 50233.460977, decoder SINDy loss  ratio: 0.890536
--- 0.25540900230407715 seconds for one epoch ---
--- 0.29535627365112305 seconds for one epoch ---
--- 2.106668710708618 seconds for one epoch ---
--- 0.29572153091430664 seconds for one epoch ---
--- 2.1184897422790527 seconds for one epoch ---
--- 0.29882335662841797 seconds for one epoch ---
--- 2.1141774654388428 seconds for one epoch ---
--- 0.29439640045166016 seconds for one epoch ---
--- 2.1149044036865234 seconds for one epoch ---
--- 0.2985215187072754 seconds for one epoch ---
--- 2.134685754776001 seconds for one epoch ---
--- 0.2925598621368408 seconds for one epoch ---
--- 2.150045394897461 seconds for one epoch ---
--- 0.3100624084472656 seconds for one epoch ---
--- 2.10982084274292 seconds for one epoch ---
--- 0.29317188262939453 seconds for one epoch ---
--- 2.111747980117798 seconds for one epoch ---
--- 0.28923463821411133 seconds for one epoch ---
--- 2.1073148250579834 seconds for one epoch ---
--- 0.2941412925720215 seconds for one epoch ---
--- 2.0981874465942383 seconds for one epoch ---
--- 0.30091238021850586 seconds for one epoch ---
--- 2.075172185897827 seconds for one epoch ---
--- 0.2917914390563965 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.258015]
 [  0.      ]]
--- 0.2755589485168457 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2330.03369140625, (1176.6161, 0.49935588, 1152.4713, 0.44680825)
   validation loss 925.5872192382812, (574.46655, 1.1723882, 349.5015, 0.44680825)
decoder loss ratio: 22255.831571, decoder SINDy loss  ratio: 0.754448
--- 0.29337430000305176 seconds for one epoch ---
--- 2.112828016281128 seconds for one epoch ---
--- 0.30689001083374023 seconds for one epoch ---
--- 2.132721424102783 seconds for one epoch ---
--- 0.2907674312591553 seconds for one epoch ---
--- 2.135233163833618 seconds for one epoch ---
--- 0.3031284809112549 seconds for one epoch ---
--- 2.1226584911346436 seconds for one epoch ---
--- 0.2926154136657715 seconds for one epoch ---
--- 2.1292002201080322 seconds for one epoch ---
--- 0.2851533889770508 seconds for one epoch ---
--- 2.1572790145874023 seconds for one epoch ---
--- 0.2863290309906006 seconds for one epoch ---
--- 2.1811060905456543 seconds for one epoch ---
--- 0.30460667610168457 seconds for one epoch ---
--- 2.1062469482421875 seconds for one epoch ---
--- 0.284285306930542 seconds for one epoch ---
--- 2.1149659156799316 seconds for one epoch ---
--- 0.28020215034484863 seconds for one epoch ---
--- 2.123213768005371 seconds for one epoch ---
--- 0.2873575687408447 seconds for one epoch ---
--- 2.1241040229797363 seconds for one epoch ---
--- 0.2946298122406006 seconds for one epoch ---
--- 2.1167149543762207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.284054]
 [  0.      ]]
--- 0.2897608280181885 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3808.840576171875, (1374.9583, 1.0682064, 2432.3667, 0.447402)
   validation loss 1028.7464599609375, (650.6803, 0.8347055, 376.784, 0.447402)
decoder loss ratio: 25208.484369, decoder SINDy loss  ratio: 0.813341
--- 0.9906513690948486 seconds for one epoch ---
--- 0.28549861907958984 seconds for one epoch ---
--- 2.1462957859039307 seconds for one epoch ---
--- 0.3010241985321045 seconds for one epoch ---
--- 2.1291651725769043 seconds for one epoch ---
--- 0.2995738983154297 seconds for one epoch ---
--- 2.1115810871124268 seconds for one epoch ---
--- 0.28511953353881836 seconds for one epoch ---
--- 2.127479076385498 seconds for one epoch ---
--- 0.30035877227783203 seconds for one epoch ---
--- 2.1087000370025635 seconds for one epoch ---
--- 0.28766584396362305 seconds for one epoch ---
--- 2.140782356262207 seconds for one epoch ---
--- 0.2962768077850342 seconds for one epoch ---
--- 2.1380093097686768 seconds for one epoch ---
--- 0.2959885597229004 seconds for one epoch ---
--- 2.0955822467803955 seconds for one epoch ---
--- 0.28870487213134766 seconds for one epoch ---
--- 2.094982862472534 seconds for one epoch ---
--- 0.29322004318237305 seconds for one epoch ---
--- 2.108764171600342 seconds for one epoch ---
--- 0.29966163635253906 seconds for one epoch ---
--- 2.110677719116211 seconds for one epoch ---
--- 0.2947824001312256 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.301268]
 [ -0.      ]]
--- 0.25429534912109375 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3113.6962890625, (1432.2788, 0.9195101, 1680.0503, 0.44781914)
   validation loss 854.4491577148438, (523.3641, 1.0701461, 329.56714, 0.44781914)
decoder loss ratio: 20276.032854, decoder SINDy loss  ratio: 0.711417
--- 0.30455732345581055 seconds for one epoch ---
--- 2.183074474334717 seconds for one epoch ---
--- 0.2981116771697998 seconds for one epoch ---
--- 2.1765286922454834 seconds for one epoch ---
--- 0.2950296401977539 seconds for one epoch ---
--- 2.1755876541137695 seconds for one epoch ---
--- 0.3032844066619873 seconds for one epoch ---
--- 2.1543784141540527 seconds for one epoch ---
--- 0.2926821708679199 seconds for one epoch ---
--- 2.1703522205352783 seconds for one epoch ---
--- 0.30182528495788574 seconds for one epoch ---
--- 2.170285940170288 seconds for one epoch ---
--- 0.2989919185638428 seconds for one epoch ---
--- 2.1954290866851807 seconds for one epoch ---
--- 0.299299955368042 seconds for one epoch ---
--- 2.1695830821990967 seconds for one epoch ---
--- 0.30347466468811035 seconds for one epoch ---
--- 2.1376020908355713 seconds for one epoch ---
--- 0.28615903854370117 seconds for one epoch ---
--- 2.1258292198181152 seconds for one epoch ---
--- 0.28847789764404297 seconds for one epoch ---
--- 2.139927864074707 seconds for one epoch ---
--- 0.2997417449951172 seconds for one epoch ---
--- 2.145106554031372 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.31939]
 [ -0.     ]]
--- 0.3008718490600586 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4123.1904296875, (1318.3021, 3.0580268, 2801.3818, 0.4483207)
   validation loss 1140.204345703125, (814.27814, 0.98011893, 324.49777, 0.4483207)
decoder loss ratio: 31546.548684, decoder SINDy loss  ratio: 0.700474
--- 0.26728057861328125 seconds for one epoch ---
--- 0.3005805015563965 seconds for one epoch ---
--- 2.138880729675293 seconds for one epoch ---
--- 0.30020904541015625 seconds for one epoch ---
--- 2.152024745941162 seconds for one epoch ---
--- 0.3026096820831299 seconds for one epoch ---
--- 2.1571640968322754 seconds for one epoch ---
--- 0.3014488220214844 seconds for one epoch ---
--- 2.1232166290283203 seconds for one epoch ---
--- 0.29274630546569824 seconds for one epoch ---
--- 2.164783477783203 seconds for one epoch ---
--- 0.28556323051452637 seconds for one epoch ---
--- 2.1367809772491455 seconds for one epoch ---
--- 0.3009200096130371 seconds for one epoch ---
--- 2.1581599712371826 seconds for one epoch ---
--- 0.28950047492980957 seconds for one epoch ---
--- 2.128448724746704 seconds for one epoch ---
--- 0.29683804512023926 seconds for one epoch ---
--- 2.132295608520508 seconds for one epoch ---
--- 0.29015016555786133 seconds for one epoch ---
--- 2.109506845474243 seconds for one epoch ---
--- 0.2877223491668701 seconds for one epoch ---
--- 2.1158249378204346 seconds for one epoch ---
--- 0.30208873748779297 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.339396]
 [ -0.      ]]
--- 0.24216055870056152 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2289.41357421875, (678.4681, 0.6472857, 1609.8496, 0.4488063)
   validation loss 917.30517578125, (593.8131, 1.3176801, 321.7256, 0.4488063)
decoder loss ratio: 23005.350800, decoder SINDy loss  ratio: 0.694490
--- 0.3030092716217041 seconds for one epoch ---
--- 2.1055281162261963 seconds for one epoch ---
--- 0.3014514446258545 seconds for one epoch ---
--- 2.1135571002960205 seconds for one epoch ---
--- 0.29174351692199707 seconds for one epoch ---
--- 2.1527695655822754 seconds for one epoch ---
--- 0.2929356098175049 seconds for one epoch ---
--- 2.164386749267578 seconds for one epoch ---
--- 0.2965707778930664 seconds for one epoch ---
--- 2.149622678756714 seconds for one epoch ---
--- 0.2800014019012451 seconds for one epoch ---
--- 2.204319953918457 seconds for one epoch ---
--- 0.29190611839294434 seconds for one epoch ---
--- 2.1698739528656006 seconds for one epoch ---
--- 0.2914724349975586 seconds for one epoch ---
--- 2.1693806648254395 seconds for one epoch ---
--- 0.2967946529388428 seconds for one epoch ---
--- 2.1614584922790527 seconds for one epoch ---
--- 0.29078245162963867 seconds for one epoch ---
--- 2.1590871810913086 seconds for one epoch ---
--- 0.2876870632171631 seconds for one epoch ---
--- 2.1855528354644775 seconds for one epoch ---
--- 0.31574249267578125 seconds for one epoch ---
--- 2.1708686351776123 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-17.3603]
 [  0.    ]]
--- 0.300081729888916 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3441.9794921875, (1576.7571, 1.8946347, 1862.8783, 0.44941354)
   validation loss 986.5031127929688, (654.52124, 1.1745795, 330.35794, 0.44941354)
decoder loss ratio: 25357.289146, decoder SINDy loss  ratio: 0.713124
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.363495]
 [  0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1290.974609375, (655.8709, 0.88925886, 634.21436, 0.4494477)
   validation loss 838.3927001953125, (501.06442, 0.8116871, 336.5166, 0.4494477)
decoder loss ratio: 19412.105618, decoder SINDy loss  ratio: 0.726418
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.403532]
 [  0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1417.39013671875, (810.0071, 0.73085624, 606.6522, 0.44998723)
   validation loss 843.037353515625, (575.52435, 0.7092422, 266.80374, 0.44998723)
decoder loss ratio: 22296.812590, decoder SINDy loss  ratio: 0.575933
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.34222]
 [  0.     ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.5650634765625, (306.54996, 0.5350388, 528.48004, 0.44798765)
   validation loss 476.43408203125, (233.92311, 0.3435288, 242.16743, 0.44798765)
decoder loss ratio: 9062.587427, decoder SINDy loss  ratio: 0.522752
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.176413]
 [  0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.9862060546875, (268.62003, 0.44314575, 507.92307, 0.44506904)
   validation loss 452.4476013183594, (216.07039, 0.2037058, 236.17351, 0.44506904)
decoder loss ratio: 8370.941977, decoder SINDy loss  ratio: 0.509814
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.06713]
 [  0.     ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.33154296875, (275.52573, 0.39246577, 500.4134, 0.4418025)
   validation loss 448.31195068359375, (218.67339, 0.13953839, 229.49904, 0.4418025)
decoder loss ratio: 8471.786593, decoder SINDy loss  ratio: 0.495406
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.00428]
 [ -0.     ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.5516357421875, (253.54877, 0.3335476, 491.6693, 0.4385967)
   validation loss 428.14959716796875, (201.29453, 0.10284013, 226.75221, 0.4385967)
decoder loss ratio: 7798.499367, decoder SINDy loss  ratio: 0.489477
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.709919]
 [  0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.679931640625, (263.90518, 0.31757787, 490.45718, 0.4355653)
   validation loss 424.1942138671875, (202.7002, 0.08484596, 221.4092, 0.4355653)
decoder loss ratio: 7852.957469, decoder SINDy loss  ratio: 0.477943
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.627579]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.790283203125, (258.05576, 0.29979786, 487.43475, 0.43275157)
   validation loss 418.8162841796875, (198.46198, 0.07288415, 220.2814, 0.43275157)
decoder loss ratio: 7688.761460, decoder SINDy loss  ratio: 0.475508
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.60902]
 [ -0.     ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.462646484375, (252.54259, 0.2864603, 482.63358, 0.43012118)
   validation loss 420.403564453125, (195.65163, 0.065887295, 224.68604, 0.43012118)
decoder loss ratio: 7579.883680, decoder SINDy loss  ratio: 0.485016
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.47326]
 [  0.     ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 929.5170288085938, (426.55133, 0.28267735, 502.683, 0.4277082)
   validation loss 566.6929931640625, (348.45322, 0.06419829, 218.17557, 0.4277082)
decoder loss ratio: 13499.682551, decoder SINDy loss  ratio: 0.470963
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.396664]
 [ -0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 905.25390625, (417.55093, 0.27454692, 487.42847, 0.42554885)
   validation loss 579.8475952148438, (343.47836, 0.054686133, 236.31454, 0.42554885)
decoder loss ratio: 13306.948089, decoder SINDy loss  ratio: 0.510118
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.318512]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.3038330078125, (312.7315, 0.27035633, 490.30194, 0.42359185)
   validation loss 463.7619323730469, (246.72797, 0.05976931, 216.9742, 0.42359185)
decoder loss ratio: 9558.669753, decoder SINDy loss  ratio: 0.468369
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.251478]
 [  0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.713623046875, (243.79582, 0.2594986, 479.6583, 0.42182598)
   validation loss 403.30877685546875, (185.0435, 0.058220115, 218.20705, 0.42182598)
decoder loss ratio: 7168.906548, decoder SINDy loss  ratio: 0.471031
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.195826]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.855224609375, (311.40054, 0.26194906, 475.19272, 0.4203314)
   validation loss 474.10858154296875, (247.22635, 0.056081053, 226.82614, 0.4203314)
decoder loss ratio: 9577.977959, decoder SINDy loss  ratio: 0.489636
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.088327]
 [  0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.7100219726562, (246.23566, 0.2530746, 473.22128, 0.41893935)
   validation loss 412.5057373046875, (190.53372, 0.057838634, 221.91415, 0.41893935)
decoder loss ratio: 7381.607168, decoder SINDy loss  ratio: 0.479033
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.141106]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.3585205078125, (264.51398, 0.24985848, 479.59473, 0.4177409)
   validation loss 426.03497314453125, (208.47581, 0.061494116, 217.49768, 0.4177409)
decoder loss ratio: 8076.714996, decoder SINDy loss  ratio: 0.469499
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.021563]
 [ -0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.4993286132812, (459.21527, 0.262797, 481.02127, 0.41677004)
   validation loss 606.3069458007812, (370.3668, 0.058195896, 235.88194, 0.41677004)
decoder loss ratio: 14348.652460, decoder SINDy loss  ratio: 0.509184
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.992487]
 [ -0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.6613159179688, (253.87358, 0.24481256, 475.5429, 0.4158685)
   validation loss 417.21954345703125, (199.27979, 0.06421909, 217.87552, 0.4158685)
decoder loss ratio: 7720.444842, decoder SINDy loss  ratio: 0.470315
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.016659]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.5514526367188, (318.6205, 0.2468596, 469.68408, 0.41507253)
   validation loss 480.766357421875, (253.62584, 0.06336745, 227.07715, 0.41507253)
decoder loss ratio: 9825.905326, decoder SINDy loss  ratio: 0.490178
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.903181]
 [  0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.484619140625, (288.6245, 0.24495839, 468.61514, 0.41434154)
   validation loss 453.2591247558594, (227.83182, 0.06505394, 225.36226, 0.41434154)
decoder loss ratio: 8826.600148, decoder SINDy loss  ratio: 0.486476
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.823032]
 [ -0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.7261962890625, (230.01044, 0.24444999, 469.47128, 0.41369468)
   validation loss 395.3829040527344, (175.91374, 0.06784342, 219.40132, 0.41369468)
decoder loss ratio: 6815.203767, decoder SINDy loss  ratio: 0.473609
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.907154]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 946.2252197265625, (472.98038, 0.24257983, 473.00226, 0.4132347)
   validation loss 628.2425537109375, (392.78964, 0.06614385, 235.38678, 0.4132347)
decoder loss ratio: 15217.352657, decoder SINDy loss  ratio: 0.508115
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.855459]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.2662963867188, (257.27057, 0.3260675, 468.66965, 0.41276193)
   validation loss 419.94281005859375, (200.92401, 0.06376869, 218.95502, 0.41276193)
decoder loss ratio: 7784.145014, decoder SINDy loss  ratio: 0.472645
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.80414]
 [  0.     ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.1275024414062, (253.67368, 0.2531204, 473.2007, 0.4123368)
   validation loss 411.9735107421875, (193.63199, 0.072550766, 218.26898, 0.4123368)
decoder loss ratio: 7501.639395, decoder SINDy loss  ratio: 0.471164
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.858405]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 829.858642578125, (362.90668, 0.23559138, 466.71637, 0.4120648)
   validation loss 524.5234985351562, (294.73956, 0.07014669, 229.71379, 0.4120648)
decoder loss ratio: 11418.722361, decoder SINDy loss  ratio: 0.495870
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.776008]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.6781005859375, (230.54309, 0.26720068, 466.86783, 0.41193634)
   validation loss 396.268310546875, (177.25739, 0.07451265, 218.93643, 0.41193634)
decoder loss ratio: 6867.258837, decoder SINDy loss  ratio: 0.472605
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.835553]
 [  0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.0433349609375, (280.3213, 0.26371956, 474.45834, 0.41173083)
   validation loss 441.21795654296875, (222.9416, 0.075340606, 218.20102, 0.41173083)
decoder loss ratio: 8637.144806, decoder SINDy loss  ratio: 0.471018
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-15.7829485]
 [  0.       ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.0419311523438, (259.6724, 0.25381872, 472.11572, 0.41164476)
   validation loss 418.879150390625, (200.40253, 0.077463634, 218.39914, 0.41164476)
decoder loss ratio: 7763.941804, decoder SINDy loss  ratio: 0.471445
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.7896385]
 [ -0.       ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.8602294921875, (385.4629, 0.23409691, 465.16324, 0.41164085)
   validation loss 545.2780151367188, (314.3905, 0.073926784, 230.8136, 0.41164085)
decoder loss ratio: 12180.033889, decoder SINDy loss  ratio: 0.498244
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.7806015]
 [ -0.       ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.1573486328125, (230.09753, 0.23597056, 462.82385, 0.41163588)
   validation loss 396.17138671875, (175.0112, 0.07667823, 221.0835, 0.41163588)
decoder loss ratio: 6780.237719, decoder SINDy loss  ratio: 0.477240
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.808735]
 [ -0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.97216796875, (245.38722, 0.27203652, 461.3129, 0.41168198)
   validation loss 407.05450439453125, (185.63849, 0.07881435, 221.33719, 0.41168198)
decoder loss ratio: 7191.957338, decoder SINDy loss  ratio: 0.477787
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.807466]
 [ -0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1878.5068359375, (1351.3451, 0.2600972, 526.9017, 0.411752)
   validation loss 1404.9976806640625, (1126.564, 0.08073051, 278.35303, 0.411752)
decoder loss ratio: 43645.043799, decoder SINDy loss  ratio: 0.600864
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.788898]
 [ -0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.7671508789062, (318.6688, 0.2569913, 478.84137, 0.41181383)
   validation loss 469.3781433105469, (249.39561, 0.07813604, 219.90439, 0.41181383)
decoder loss ratio: 9662.019080, decoder SINDy loss  ratio: 0.474695
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-15.7089]
 [ -0.    ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.2716064453125, (289.19037, 0.25191584, 472.8293, 0.41195035)
   validation loss 448.78375244140625, (229.5424, 0.07892932, 219.16241, 0.41195035)
decoder loss ratio: 8892.871241, decoder SINDy loss  ratio: 0.473093
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.877824]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.5302734375, (264.9869, 0.2416886, 459.30164, 0.41212875)
   validation loss 429.0046691894531, (204.68127, 0.07965606, 224.24374, 0.41212875)
decoder loss ratio: 7929.707913, decoder SINDy loss  ratio: 0.484062
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.872303]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.746826171875, (228.14551, 0.24408281, 462.35727, 0.41228744)
   validation loss 394.76641845703125, (174.85078, 0.08028686, 219.83536, 0.41228744)
decoder loss ratio: 6774.022938, decoder SINDy loss  ratio: 0.474546
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.798856]
 [ -0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 881.1823120117188, (417.97394, 0.2261926, 462.98218, 0.4124972)
   validation loss 573.7434692382812, (340.38943, 0.077907905, 233.27614, 0.4124972)
decoder loss ratio: 13187.277647, decoder SINDy loss  ratio: 0.503559
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.751847]
 [ -0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.045654296875, (354.25998, 0.22617726, 459.55948, 0.41271576)
   validation loss 516.2743530273438, (285.9054, 0.0763538, 230.2926, 0.41271576)
decoder loss ratio: 11076.471376, decoder SINDy loss  ratio: 0.497119
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.876446]
 [  0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.5826416015625, (225.39822, 0.2446358, 458.93976, 0.4129903)
   validation loss 392.3921203613281, (171.01912, 0.07998518, 221.29301, 0.4129903)
decoder loss ratio: 6625.577582, decoder SINDy loss  ratio: 0.477692
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.897853]
 [  0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 825.2069702148438, (365.2771, 0.2473, 459.68256, 0.4132726)
   validation loss 521.7781372070312, (292.18613, 0.08278591, 229.5092, 0.4132726)
decoder loss ratio: 11319.797806, decoder SINDy loss  ratio: 0.495428
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.8489275]
 [  0.       ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.8391723632812, (228.68814, 0.28638738, 458.86465, 0.41355404)
   validation loss 392.29217529296875, (172.66235, 0.08351385, 219.5463, 0.41355404)
decoder loss ratio: 6689.239330, decoder SINDy loss  ratio: 0.473922
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.938098]
 [  0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.0196533203125, (284.76376, 0.26518306, 465.99072, 0.4137547)
   validation loss 450.58929443359375, (231.74625, 0.07932153, 218.76373, 0.4137547)
decoder loss ratio: 8978.251912, decoder SINDy loss  ratio: 0.472232
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.962054]
 [ -0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.8129272460938, (231.40756, 0.24842802, 460.15695, 0.41402838)
   validation loss 393.0052185058594, (172.83606, 0.08018447, 220.08897, 0.41402838)
decoder loss ratio: 6695.969004, decoder SINDy loss  ratio: 0.475093
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.904772]
 [  0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.2833862304688, (293.33847, 0.24096772, 456.70395, 0.4142674)
   validation loss 453.36334228515625, (227.00446, 0.08003497, 226.27885, 0.4142674)
decoder loss ratio: 8794.546706, decoder SINDy loss  ratio: 0.488455
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.824844]
 [  0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.4356689453125, (290.8703, 0.23558512, 456.32977, 0.41451502)
   validation loss 450.1798095703125, (223.66135, 0.07963225, 226.43881, 0.41451502)
decoder loss ratio: 8665.028854, decoder SINDy loss  ratio: 0.488800
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.966845]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.0665283203125, (225.42328, 0.23178078, 455.41147, 0.41476354)
   validation loss 392.8031311035156, (171.71715, 0.077002354, 221.00899, 0.41476354)
decoder loss ratio: 6652.620421, decoder SINDy loss  ratio: 0.477079
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.950638]
 [  0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.28955078125, (227.00514, 0.23695046, 455.04745, 0.41502544)
   validation loss 391.4321594238281, (169.72107, 0.07904986, 221.63203, 0.41502544)
decoder loss ratio: 6575.288875, decoder SINDy loss  ratio: 0.478424
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.890985]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.7666015625, (309.5477, 0.2273258, 453.99155, 0.4153276)
   validation loss 472.73651123046875, (245.18288, 0.077802524, 227.47583, 0.4153276)
decoder loss ratio: 9498.810295, decoder SINDy loss  ratio: 0.491039
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.985114]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 848.5381469726562, (389.49802, 0.2370808, 458.80304, 0.415616)
   validation loss 540.4117431640625, (308.55316, 0.080322556, 231.77829, 0.415616)
decoder loss ratio: 11953.885153, decoder SINDy loss  ratio: 0.500326
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.948109]
 [  0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.1729125976562, (281.12958, 0.24189079, 464.80145, 0.4158772)
   validation loss 442.45843505859375, (222.80637, 0.07515732, 219.57692, 0.4158772)
decoder loss ratio: 8631.905426, decoder SINDy loss  ratio: 0.473988
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.976563]
 [  0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.36767578125, (226.27223, 0.23825322, 455.85718, 0.4162198)
   validation loss 390.70379638671875, (170.50562, 0.07791545, 220.12025, 0.4162198)
decoder loss ratio: 6605.683545, decoder SINDy loss  ratio: 0.475161
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.976766]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.807373046875, (286.25897, 0.23078702, 453.31763, 0.41651997)
   validation loss 447.8448486328125, (221.63048, 0.078791514, 226.13556, 0.41651997)
decoder loss ratio: 8586.349481, decoder SINDy loss  ratio: 0.488145
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.998496]
 [ -0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.2626342773438, (228.55917, 0.23978522, 455.46365, 0.4168315)
   validation loss 394.7854919433594, (175.0069, 0.08051452, 219.69807, 0.4168315)
decoder loss ratio: 6780.071014, decoder SINDy loss  ratio: 0.474249
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.008638]
 [ -0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.552978515625, (237.94524, 0.24855825, 453.3592, 0.4170641)
   validation loss 399.2977294921875, (177.33597, 0.08236391, 221.8794, 0.4170641)
decoder loss ratio: 6870.303270, decoder SINDy loss  ratio: 0.478958
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.051418]
 [  0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.3463745117188, (222.26605, 0.26037714, 454.81995, 0.41727924)
   validation loss 387.07373046875, (168.10458, 0.0834074, 218.88573, 0.41727924)
decoder loss ratio: 6512.663416, decoder SINDy loss  ratio: 0.472496
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.049347]
 [  0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.39794921875, (222.83162, 0.26854998, 454.29776, 0.4174764)
   validation loss 386.9898681640625, (168.01106, 0.08279294, 218.89601, 0.4174764)
decoder loss ratio: 6509.040246, decoder SINDy loss  ratio: 0.472518
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.045902]
 [ -0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.4095458984375, (330.33746, 0.298151, 472.77396, 0.41768414)
   validation loss 484.1321716308594, (266.63577, 0.079404645, 217.41699, 0.41768414)
decoder loss ratio: 10329.932735, decoder SINDy loss  ratio: 0.469325
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.108942]
 [  0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 913.1776733398438, (429.78598, 0.2933743, 483.09833, 0.41784033)
   validation loss 580.0446166992188, (359.42184, 0.073569834, 220.54918, 0.41784033)
decoder loss ratio: 13924.626239, decoder SINDy loss  ratio: 0.476086
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.01718]
 [ -0.     ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.9365234375, (465.89542, 0.31061426, 476.7305, 0.4179913)
   validation loss 612.0469970703125, (392.05524, 0.076595716, 219.91519, 0.4179913)
decoder loss ratio: 15188.900512, decoder SINDy loss  ratio: 0.474718
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.161436]
 [ -0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 967.510009765625, (495.9505, 0.25569072, 471.3038, 0.418121)
   validation loss 675.8272705078125, (456.08597, 0.07571309, 219.66557, 0.418121)
decoder loss ratio: 17669.562201, decoder SINDy loss  ratio: 0.474179
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.094736]
 [  0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.5464477539062, (238.12718, 0.23136123, 453.1879, 0.4184761)
   validation loss 396.59124755859375, (174.28824, 0.075857334, 222.22714, 0.4184761)
decoder loss ratio: 6752.228938, decoder SINDy loss  ratio: 0.479709
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.166368]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.165771484375, (224.25833, 0.22992167, 451.67752, 0.41866407)
   validation loss 387.11962890625, (167.07101, 0.07589546, 219.9727, 0.41866407)
decoder loss ratio: 6472.621146, decoder SINDy loss  ratio: 0.474842
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.077454]
 [ -0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.1058349609375, (266.4315, 0.22526659, 450.44904, 0.4187912)
   validation loss 424.1818542480469, (200.32835, 0.07641439, 223.77708, 0.4187912)
decoder loss ratio: 7761.068215, decoder SINDy loss  ratio: 0.483054
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.058655]
 [ -0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1652.6063232421875, (1161.4915, 0.20580232, 490.90906, 0.4189988)
   validation loss 1263.4517822265625, (995.90216, 0.080335446, 267.46927, 0.4189988)
decoder loss ratio: 38582.978666, decoder SINDy loss  ratio: 0.577370
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.162266]
 [  0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 860.4053955078125, (389.08777, 0.22742021, 471.0902, 0.41919813)
   validation loss 551.0310668945312, (330.81937, 0.06981629, 220.14189, 0.41919813)
decoder loss ratio: 12816.516584, decoder SINDy loss  ratio: 0.475207
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.095331]
 [  0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1197.781005859375, (709.4432, 0.25887164, 488.079, 0.41934028)
   validation loss 888.70849609375, (663.1758, 0.07314453, 225.45958, 0.41934028)
decoder loss ratio: 25692.581089, decoder SINDy loss  ratio: 0.486686
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.023743]
 [  0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.9432373046875, (251.06949, 0.22836545, 455.6454, 0.41957685)
   validation loss 417.22686767578125, (199.31415, 0.07100091, 217.84174, 0.41957685)
decoder loss ratio: 7721.776116, decoder SINDy loss  ratio: 0.470242
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.151562]
 [ -0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.4892578125, (254.56691, 0.2444436, 457.67792, 0.4198497)
   validation loss 414.5049743652344, (195.43532, 0.07518308, 218.99448, 0.4198497)
decoder loss ratio: 7571.503510, decoder SINDy loss  ratio: 0.472730
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.115576]
 [ -0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1018.978759765625, (562.1109, 0.20247582, 456.66544, 0.42004576)
   validation loss 707.0616455078125, (467.78223, 0.0759627, 239.20345, 0.42004576)
decoder loss ratio: 18122.695563, decoder SINDy loss  ratio: 0.516354
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.177721]
 [  0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.5858154296875, (291.31528, 0.22128579, 450.0493, 0.4202349)
   validation loss 441.736083984375, (216.93295, 0.077544935, 224.7256, 0.4202349)
decoder loss ratio: 8404.359207, decoder SINDy loss  ratio: 0.485102
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.243502]
 [ -0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.825439453125, (222.24245, 0.22172345, 450.36127, 0.4202898)
   validation loss 384.76300048828125, (165.69247, 0.07487991, 218.99564, 0.4202898)
decoder loss ratio: 6419.214112, decoder SINDy loss  ratio: 0.472733
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.193653]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.717529296875, (301.56906, 0.21684197, 449.93164, 0.42038208)
   validation loss 452.0910339355469, (227.15414, 0.07541853, 224.86147, 0.42038208)
decoder loss ratio: 8800.345907, decoder SINDy loss  ratio: 0.485395
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.114603]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.5254516601562, (255.83717, 0.23439431, 457.4539, 0.4205412)
   validation loss 416.88104248046875, (198.64165, 0.073788434, 218.16562, 0.4205412)
decoder loss ratio: 7695.722275, decoder SINDy loss  ratio: 0.470941
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.202843]
 [ -0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.5869750976562, (223.2208, 0.22015373, 449.14603, 0.42064467)
   validation loss 384.65191650390625, (165.82892, 0.07589487, 218.7471, 0.42064467)
decoder loss ratio: 6424.500193, decoder SINDy loss  ratio: 0.472196
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.111853]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.7059326171875, (350.0508, 0.19854201, 447.4566, 0.42070863)
   validation loss 502.0115051269531, (274.5707, 0.07127193, 227.36954, 0.42070863)
decoder loss ratio: 10637.345951, decoder SINDy loss  ratio: 0.490809
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.134264]
 [ -0.      ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1196.16796875, (728.6824, 0.20389786, 467.28168, 0.42086044)
   validation loss 845.8201293945312, (599.0959, 0.076811805, 246.64748, 0.42086044)
decoder loss ratio: 23210.014709, decoder SINDy loss  ratio: 0.532423
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.189001]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.4575805664062, (222.43498, 0.23126031, 450.79135, 0.42093703)
   validation loss 388.0196838378906, (170.27065, 0.07658279, 217.67245, 0.42093703)
decoder loss ratio: 6596.580396, decoder SINDy loss  ratio: 0.469877
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.225708]
 [ -0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.2664794921875, (271.62988, 0.21936867, 447.41727, 0.4210019)
   validation loss 425.1874084472656, (202.674, 0.077122346, 222.4363, 0.4210019)
decoder loss ratio: 7851.942461, decoder SINDy loss  ratio: 0.480160
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.18022]
 [  0.     ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.5623168945312, (222.9107, 0.22126779, 450.43033, 0.42098942)
   validation loss 388.6678771972656, (170.83975, 0.074612126, 217.75351, 0.42098942)
decoder loss ratio: 6618.628591, decoder SINDy loss  ratio: 0.470052
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.207306]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.8300170898438, (219.57468, 0.23363455, 450.0217, 0.4209643)
   validation loss 385.3197021484375, (168.19637, 0.075891145, 217.04745, 0.4209643)
decoder loss ratio: 6516.219196, decoder SINDy loss  ratio: 0.468527
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.137495]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.4337158203125, (221.65004, 0.23365659, 449.55, 0.42099532)
   validation loss 384.0593566894531, (166.34268, 0.07395092, 217.64273, 0.42099532)
decoder loss ratio: 6444.404280, decoder SINDy loss  ratio: 0.469812
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.206966]
 [ -0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.1610107421875, (257.14554, 0.2416914, 457.77377, 0.42100063)
   validation loss 422.0445556640625, (204.854, 0.072796494, 217.11777, 0.42100063)
decoder loss ratio: 7936.399754, decoder SINDy loss  ratio: 0.468679
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.27308]
 [ -0.     ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.749755859375, (222.60632, 0.24947406, 448.89395, 0.42096278)
   validation loss 386.533935546875, (169.22066, 0.07771008, 217.23558, 0.42096278)
decoder loss ratio: 6555.902046, decoder SINDy loss  ratio: 0.468934
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.249445]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.3519287109375, (367.82718, 0.21314326, 445.3116, 0.4209133)
   validation loss 520.02880859375, (296.9311, 0.06605987, 223.03166, 0.4209133)
decoder loss ratio: 11503.625972, decoder SINDy loss  ratio: 0.481445
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.277113]
 [ -0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.5239868164062, (231.18037, 0.21928747, 451.12433, 0.42081943)
   validation loss 395.319091796875, (178.11847, 0.06883724, 217.1318, 0.42081943)
decoder loss ratio: 6900.618726, decoder SINDy loss  ratio: 0.468710
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.227184]
 [ -0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 883.9288330078125, (436.9441, 0.19847418, 446.78625, 0.42078516)
   validation loss 587.3063354492188, (357.71033, 0.07134835, 229.52467, 0.42078516)
decoder loss ratio: 13858.319086, decoder SINDy loss  ratio: 0.495461
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.118769]
 [ -0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.3338623046875, (297.97238, 0.19259608, 447.1689, 0.42081633)
   validation loss 446.12890625, (221.1304, 0.06829121, 224.93019, 0.42081633)
decoder loss ratio: 8566.975658, decoder SINDy loss  ratio: 0.485543
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.169222]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.8448486328125, (234.76726, 0.1975188, 444.88007, 0.42084774)
   validation loss 393.2281494140625, (173.20018, 0.068450704, 219.9595, 0.42084774)
decoder loss ratio: 6710.075664, decoder SINDy loss  ratio: 0.474814
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.111502]
 [ -0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.1260986328125, (249.44725, 0.19903085, 444.47983, 0.4207585)
   validation loss 407.7142333984375, (186.49881, 0.066643655, 221.14876, 0.4207585)
decoder loss ratio: 7225.287668, decoder SINDy loss  ratio: 0.477381
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.220207]
 [ -0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.66259765625, (348.43887, 0.196474, 448.02725, 0.42075396)
   validation loss 490.57098388671875, (263.4151, 0.069875136, 227.08601, 0.42075396)
decoder loss ratio: 10205.158287, decoder SINDy loss  ratio: 0.490197
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.210371]
 [  0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.4630737304688, (228.36786, 0.19904302, 444.89618, 0.4207029)
   validation loss 388.18304443359375, (168.72554, 0.06824388, 219.38927, 0.4207029)
decoder loss ratio: 6536.720346, decoder SINDy loss  ratio: 0.473583
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.24431]
 [ -0.     ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.9072265625, (301.71188, 0.19807592, 445.99728, 0.4207347)
   validation loss 447.21331787109375, (223.64003, 0.07121749, 223.50209, 0.4207347)
decoder loss ratio: 8664.203015, decoder SINDy loss  ratio: 0.482461
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.213228]
 [ -0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.134521484375, (307.35898, 0.1965202, 456.579, 0.42065278)
   validation loss 479.2716979980469, (262.49072, 0.0620148, 216.71896, 0.42065278)
decoder loss ratio: 10169.346300, decoder SINDy loss  ratio: 0.467818
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.264372]
 [ -0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.76953125, (386.9952, 0.18734956, 443.58694, 0.42074424)
   validation loss 532.6297607421875, (306.2823, 0.06761515, 226.27986, 0.42074424)
decoder loss ratio: 11865.907551, decoder SINDy loss  ratio: 0.488457
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.143787]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1377.1915283203125, (873.5369, 0.22767048, 503.42697, 0.42058626)
   validation loss 1045.8160400390625, (816.7866, 0.062482774, 228.96689, 0.42058626)
decoder loss ratio: 31643.731705, decoder SINDy loss  ratio: 0.494257
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.144958]
 [  0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.2523193359375, (241.48572, 0.19436629, 443.57227, 0.420521)
   validation loss 396.4986572265625, (176.54094, 0.066666335, 219.89107, 0.420521)
decoder loss ratio: 6839.502478, decoder SINDy loss  ratio: 0.474666
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.209362]
 [  0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1108.14794921875, (648.29395, 0.17776431, 459.6763, 0.4205577)
   validation loss 762.5089721679688, (520.30994, 0.071395025, 242.12764, 0.4205577)
decoder loss ratio: 20157.710239, decoder SINDy loss  ratio: 0.522667
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-16.1949]
 [  0.    ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.4759521484375, (284.30182, 0.21395424, 453.9602, 0.4205695)
   validation loss 453.48956298828125, (236.74486, 0.06729536, 216.67741, 0.4205695)
decoder loss ratio: 9171.906798, decoder SINDy loss  ratio: 0.467729
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.169333]
 [ -0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1055.2891845703125, (564.1524, 0.26325512, 490.87357, 0.4205626)
   validation loss 710.4603881835938, (488.25546, 0.065097824, 222.13982, 0.4205626)
decoder loss ratio: 18915.864272, decoder SINDy loss  ratio: 0.479520
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.123238]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.9129028320312, (220.03691, 0.19891295, 445.6771, 0.42039624)
   validation loss 381.5804443359375, (164.42459, 0.065475725, 217.09036, 0.42039624)
decoder loss ratio: 6370.094111, decoder SINDy loss  ratio: 0.468620
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.303549]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 885.068603515625, (435.34787, 0.17560877, 449.5451, 0.42041403)
   validation loss 569.3756103515625, (337.0702, 0.067222364, 232.23817, 0.42041403)
decoder loss ratio: 13058.684357, decoder SINDy loss  ratio: 0.501319
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.170023]
 [  0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.4058837890625, (226.48158, 0.20037194, 443.72394, 0.42047986)
   validation loss 385.21807861328125, (166.89098, 0.071877435, 218.2552, 0.42047986)
decoder loss ratio: 6465.646144, decoder SINDy loss  ratio: 0.471135
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.182251]
 [ -0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.7938232421875, (255.34213, 0.20154555, 450.25015, 0.42044505)
   validation loss 425.1923828125, (209.03578, 0.065988734, 216.0906, 0.42044505)
decoder loss ratio: 8098.409091, decoder SINDy loss  ratio: 0.466462
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.270216]
 [  0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.86474609375, (219.77583, 0.19608574, 444.89285, 0.4204257)
   validation loss 382.7906494140625, (165.66998, 0.06900603, 217.05167, 0.4204257)
decoder loss ratio: 6418.342754, decoder SINDy loss  ratio: 0.468537
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.18143]
 [ -0.     ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.9696655273438, (285.9605, 0.18962583, 442.81952, 0.42036945)
   validation loss 434.42095947265625, (211.94351, 0.070094936, 222.40735, 0.42036945)
decoder loss ratio: 8211.059604, decoder SINDy loss  ratio: 0.480098
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.255363]
 [  0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.9446411132812, (217.00763, 0.20098984, 444.73602, 0.42026183)
   validation loss 379.81536865234375, (162.80421, 0.07126013, 216.93991, 0.42026183)
decoder loss ratio: 6307.317909, decoder SINDy loss  ratio: 0.468295
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.050482]
 [  0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.328125, (216.14487, 0.20139968, 444.98184, 0.42014247)
   validation loss 380.49554443359375, (163.84981, 0.06975367, 216.57597, 0.42014247)
decoder loss ratio: 6347.826008, decoder SINDy loss  ratio: 0.467510
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.149767]
 [  0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.8303833007812, (218.2407, 0.21729907, 444.37238, 0.4200049)
   validation loss 380.951171875, (165.07399, 0.07334307, 215.80385, 0.4200049)
decoder loss ratio: 6395.252949, decoder SINDy loss  ratio: 0.465843
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.166779]
 [ -0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1126.8258056640625, (643.08325, 0.21776974, 483.52478, 0.41987228)
   validation loss 821.6832885742188, (599.0053, 0.06124791, 222.61676, 0.41987228)
decoder loss ratio: 23206.505631, decoder SINDy loss  ratio: 0.480550
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.175097]
 [  0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1527.8446044921875, (1054.257, 0.16419728, 473.42346, 0.4198289)
   validation loss 1157.24951171875, (897.24347, 0.07089393, 259.93512, 0.4198289)
decoder loss ratio: 34760.769681, decoder SINDy loss  ratio: 0.561107
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.09485]
 [ -0.     ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.817138671875, (219.89864, 0.19748992, 444.72098, 0.41982222)
   validation loss 384.95831298828125, (168.57796, 0.06936854, 216.31099, 0.41982222)
decoder loss ratio: 6531.002724, decoder SINDy loss  ratio: 0.466938
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.125116]
 [  0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.2734375, (395.04385, 0.1715773, 444.058, 0.41974607)
   validation loss 536.23876953125, (307.30624, 0.065790065, 228.86673, 0.41974607)
decoder loss ratio: 11905.577396, decoder SINDy loss  ratio: 0.494041
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.185183]
 [ -0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.159912109375, (232.73828, 0.1834518, 441.23816, 0.419656)
   validation loss 388.3822326660156, (169.21973, 0.06670198, 219.09581, 0.419656)
decoder loss ratio: 6555.865985, decoder SINDy loss  ratio: 0.472949
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.139442]
 [ -0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.6736450195312, (232.79407, 0.1904027, 441.68918, 0.4195559)
   validation loss 388.310791015625, (169.42218, 0.06885063, 218.81976, 0.4195559)
decoder loss ratio: 6563.709390, decoder SINDy loss  ratio: 0.472353
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.178791]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.435302734375, (216.4072, 0.20150262, 443.82657, 0.41941833)
   validation loss 382.153076171875, (166.26654, 0.07009871, 215.81645, 0.41941833)
decoder loss ratio: 6441.454431, decoder SINDy loss  ratio: 0.465870
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.099682]
 [ -0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1363.254638671875, (855.47876, 0.24916005, 507.5267, 0.41928077)
   validation loss 1022.7815551757812, (791.84845, 0.0664084, 230.86671, 0.41928077)
decoder loss ratio: 30677.583651, decoder SINDy loss  ratio: 0.498358
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.17443]
 [ -0.     ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1930.79736328125, (1384.757, 0.23748669, 545.803, 0.41912442)
   validation loss 1535.701904296875, (1292.1838, 0.061129875, 243.45692, 0.41912442)
decoder loss ratio: 50061.445210, decoder SINDy loss  ratio: 0.525536
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.115442]
 [  0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.5445556640625, (393.3334, 0.21296386, 456.9982, 0.4189856)
   validation loss 576.87744140625, (360.29196, 0.06282986, 216.52266, 0.4189856)
decoder loss ratio: 13958.336089, decoder SINDy loss  ratio: 0.467395
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.12433]
 [  0.     ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.0155029296875, (264.75287, 0.18285789, 440.0798, 0.41884765)
   validation loss 419.7046203613281, (198.82756, 0.06323747, 220.81383, 0.41884765)
decoder loss ratio: 7702.924871, decoder SINDy loss  ratio: 0.476658
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.097069]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.5531005859375, (219.20842, 0.18010552, 442.1646, 0.4187626)
   validation loss 380.74749755859375, (163.56546, 0.062105633, 217.11995, 0.4187626)
decoder loss ratio: 6336.809890, decoder SINDy loss  ratio: 0.468684
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.128393]
 [ -0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1679.5689697265625, (1200.4487, 0.14977376, 478.97043, 0.41867837)
   validation loss 1284.7205810546875, (1018.44476, 0.06969525, 266.20615, 0.41867837)
decoder loss ratio: 39456.318224, decoder SINDy loss  ratio: 0.574643
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.139017]
 [  0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.2811889648438, (262.49945, 0.16899848, 438.61273, 0.41865644)
   validation loss 415.20501708984375, (194.15121, 0.06464292, 220.98917, 0.41865644)
decoder loss ratio: 7521.755115, decoder SINDy loss  ratio: 0.477036
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.139938]
 [ -0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 982.6588134765625, (535.8028, 0.1658519, 446.69016, 0.41861597)
   validation loss 666.70849609375, (431.98636, 0.06750471, 234.65463, 0.41861597)
decoder loss ratio: 16735.901495, decoder SINDy loss  ratio: 0.506535
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.081854]
 [ -0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.0616455078125, (216.9054, 0.19263405, 442.96362, 0.41858408)
   validation loss 381.478515625, (164.88976, 0.068519965, 216.52023, 0.41858408)
decoder loss ratio: 6388.115380, decoder SINDy loss  ratio: 0.467389
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.019222]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1025.0067138671875, (576.2194, 0.16035482, 448.62695, 0.4184942)
   validation loss 705.9210205078125, (468.2973, 0.066109516, 237.5576, 0.4184942)
decoder loss ratio: 18142.650489, decoder SINDy loss  ratio: 0.512801
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.074232]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1254.3349609375, (793.19666, 0.1584753, 460.9798, 0.41845155)
   validation loss 901.1945190429688, (652.61176, 0.069744796, 248.51302, 0.41845155)
decoder loss ratio: 25283.312387, decoder SINDy loss  ratio: 0.536450
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.097652]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1026.1966552734375, (546.13544, 0.2377861, 479.82346, 0.41843006)
   validation loss 714.3095092773438, (491.6957, 0.065052405, 222.54874, 0.41843006)
decoder loss ratio: 19049.145397, decoder SINDy loss  ratio: 0.480403
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.081854]
 [  0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.50244140625, (226.11472, 0.23022117, 449.15753, 0.41835555)
   validation loss 394.3577880859375, (179.22377, 0.074178465, 215.05984, 0.41835555)
decoder loss ratio: 6943.440001, decoder SINDy loss  ratio: 0.464237
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.108501]
 [  0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.428466796875, (218.98488, 0.2120516, 443.2315, 0.4182008)
   validation loss 379.9193115234375, (164.27605, 0.071895406, 215.57135, 0.4182008)
decoder loss ratio: 6364.339247, decoder SINDy loss  ratio: 0.465341
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.038963]
 [ -0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.479248046875, (334.91776, 0.24699983, 464.31445, 0.41803303)
   validation loss 495.3983154296875, (279.57855, 0.06767972, 215.75208, 0.41803303)
decoder loss ratio: 10831.358484, decoder SINDy loss  ratio: 0.465731
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.056461]
 [ -0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2085.96875, (1590.9474, 0.14965385, 494.8717, 0.41788933)
   validation loss 1648.21826171875, (1369.8818, 0.07737768, 278.25906, 0.41788933)
decoder loss ratio: 53071.600544, decoder SINDy loss  ratio: 0.600661
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.126694]
 [ -0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.1075439453125, (217.36789, 0.20536657, 442.53427, 0.4177938)
   validation loss 381.88970947265625, (165.81786, 0.07217195, 215.99966, 0.4177938)
decoder loss ratio: 6424.071608, decoder SINDy loss  ratio: 0.466266
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.05577]
 [  0.     ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.18505859375, (247.0329, 0.21972045, 450.9324, 0.41768265)
   validation loss 414.5270080566406, (199.2593, 0.0709737, 215.19675, 0.41768265)
decoder loss ratio: 7719.650925, decoder SINDy loss  ratio: 0.464532
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.090899]
 [  0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.73095703125, (215.5713, 0.19322242, 441.9664, 0.4174841)
   validation loss 380.63458251953125, (165.5379, 0.06848017, 215.02818, 0.4174841)
decoder loss ratio: 6413.225742, decoder SINDy loss  ratio: 0.464169
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.062286]
 [  0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 905.23095703125, (432.61118, 0.24668749, 472.3731, 0.41735885)
   validation loss 601.9166259765625, (382.76282, 0.06802108, 219.08575, 0.41735885)
decoder loss ratio: 14828.896051, decoder SINDy loss  ratio: 0.472927
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [-16.0426]
 [ -0.    ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 880.48779296875, (408.74445, 0.23568004, 471.50766, 0.41723022)
   validation loss 569.1993408203125, (351.14194, 0.062379193, 217.99504, 0.41723022)
decoder loss ratio: 13603.848259, decoder SINDy loss  ratio: 0.470573
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.006828]
 [ -0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1413.35400390625, (908.03656, 0.21723513, 505.10022, 0.41694003)
   validation loss 1094.6483154296875, (861.58563, 0.057073053, 233.00557, 0.41694003)
decoder loss ratio: 33379.323175, decoder SINDy loss  ratio: 0.502975
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.00948]
 [ -0.     ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.2633056640625, (223.0997, 0.1619095, 438.0017, 0.41691232)
   validation loss 382.75177001953125, (165.10721, 0.059415612, 217.58516, 0.41691232)
decoder loss ratio: 6396.539886, decoder SINDy loss  ratio: 0.469688
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.05801]
 [  0.     ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.8517456054688, (223.2455, 0.18645364, 443.4198, 0.41685438)
   validation loss 391.92218017578125, (176.22687, 0.0664442, 215.62889, 0.41685438)
decoder loss ratio: 6827.334797, decoder SINDy loss  ratio: 0.465465
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.090755]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.5496826171875, (215.45255, 0.19620709, 440.9009, 0.41673875)
   validation loss 377.85888671875, (162.11241, 0.07035683, 215.67613, 0.41673875)
decoder loss ratio: 6280.516261, decoder SINDy loss  ratio: 0.465567
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.984869]
 [ -0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.3046264648438, (242.23402, 0.20883527, 448.8618, 0.41663328)
   validation loss 409.3726806640625, (193.84207, 0.066828035, 215.46378, 0.41663328)
decoder loss ratio: 7509.778376, decoder SINDy loss  ratio: 0.465109
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.951795]
 [ -0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.823486328125, (295.65704, 0.16192006, 437.00455, 0.416466)
   validation loss 446.552001953125, (224.2816, 0.06029526, 222.21008, 0.416466)
decoder loss ratio: 8689.058591, decoder SINDy loss  ratio: 0.479672
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.024944]
 [ -0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 812.8712158203125, (356.67575, 0.17245999, 456.023, 0.41635752)
   validation loss 527.38916015625, (310.03073, 0.05477589, 217.30367, 0.41635752)
decoder loss ratio: 12011.128764, decoder SINDy loss  ratio: 0.469081
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.038258]
 [ -0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.888671875, (264.8523, 0.17421806, 440.86212, 0.41625205)
   validation loss 404.5003967285156, (183.70251, 0.06501504, 220.73286, 0.41625205)
decoder loss ratio: 7116.954339, decoder SINDy loss  ratio: 0.476483
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.96889]
 [ -0.     ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.4107666015625, (356.12756, 0.16616789, 439.117, 0.4161254)
   validation loss 499.081787109375, (273.77402, 0.06499751, 225.24278, 0.4161254)
decoder loss ratio: 10606.480724, decoder SINDy loss  ratio: 0.486218
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.917223]
 [ -0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.4971313476562, (217.98846, 0.17041092, 439.33826, 0.41597304)
   validation loss 377.49017333984375, (160.93422, 0.06010315, 216.49583, 0.41597304)
decoder loss ratio: 6234.871052, decoder SINDy loss  ratio: 0.467337
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.976204]
 [  0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.0015869140625, (260.11765, 0.16735828, 437.71658, 0.41580972)
   validation loss 409.02081298828125, (188.89505, 0.0627742, 220.06299, 0.41580972)
decoder loss ratio: 7318.122175, decoder SINDy loss  ratio: 0.475037
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.980374]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1109.5440673828125, (630.09406, 0.19657451, 479.2534, 0.41565296)
   validation loss 812.7095947265625, (589.34094, 0.054372355, 223.31429, 0.41565296)
decoder loss ratio: 22832.091249, decoder SINDy loss  ratio: 0.482055
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.993762]
 [ -0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.2217407226562, (269.8755, 0.17058468, 438.17566, 0.4155863)
   validation loss 424.69183349609375, (206.42528, 0.058482803, 218.20805, 0.4155863)
decoder loss ratio: 7997.273629, decoder SINDy loss  ratio: 0.471033
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.916405]
 [ -0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.4849853515625, (266.159, 0.18858345, 446.13742, 0.41535053)
   validation loss 438.02069091796875, (222.93028, 0.05965032, 215.03076, 0.41535053)
decoder loss ratio: 8636.706172, decoder SINDy loss  ratio: 0.464174
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.937426]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.3118286132812, (245.66066, 0.16505702, 436.4861, 0.41515088)
   validation loss 398.7803649902344, (179.72734, 0.061207984, 218.99182, 0.41515088)
decoder loss ratio: 6962.949199, decoder SINDy loss  ratio: 0.472725
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.917449]
 [  0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.065185546875, (289.52374, 0.16208474, 437.37933, 0.41502166)
   validation loss 434.3843994140625, (212.73393, 0.0630262, 221.58746, 0.41502166)
decoder loss ratio: 8241.681867, decoder SINDy loss  ratio: 0.478328
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.879012]
 [  0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.2891845703125, (239.82576, 0.16019309, 436.30325, 0.4148209)
   validation loss 393.2777099609375, (174.69025, 0.060790643, 218.52666, 0.4148209)
decoder loss ratio: 6767.803428, decoder SINDy loss  ratio: 0.471721
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.872793]
 [  0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.2529907226562, (213.77216, 0.17667812, 439.30414, 0.41465482)
   validation loss 377.31842041015625, (161.6913, 0.06522419, 215.56189, 0.41465482)
decoder loss ratio: 6264.201649, decoder SINDy loss  ratio: 0.465321
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.860292]
 [  0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1087.0557861328125, (605.9021, 0.22014579, 480.9335, 0.4145573)
   validation loss 788.5557861328125, (565.07935, 0.0671696, 223.40923, 0.4145573)
decoder loss ratio: 21892.154873, decoder SINDy loss  ratio: 0.482260
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.952945]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 950.806640625, (477.033, 0.19525066, 473.57843, 0.41438198)
   validation loss 650.908203125, (429.28012, 0.0575096, 221.5706, 0.41438198)
decoder loss ratio: 16631.057145, decoder SINDy loss  ratio: 0.478291
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.944402]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1053.63427734375, (609.96, 0.14767975, 443.52652, 0.4144244)
   validation loss 731.8878784179688, (497.65985, 0.067802474, 234.16023, 0.4144244)
decoder loss ratio: 19280.206606, decoder SINDy loss  ratio: 0.505468
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.906342]
 [ -0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.078369140625, (290.4159, 0.21441421, 457.44803, 0.41434088)
   validation loss 458.75634765625, (242.79079, 0.06584206, 215.89972, 0.41434088)
decoder loss ratio: 9406.136582, decoder SINDy loss  ratio: 0.466050
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.932117]
 [  0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.2411499023438, (238.08113, 0.20246905, 447.95755, 0.41418824)
   validation loss 407.71832275390625, (193.15817, 0.07041724, 214.48973, 0.41418824)
decoder loss ratio: 7483.282944, decoder SINDy loss  ratio: 0.463006
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.870049]
 [  0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.5406494140625, (216.00294, 0.16871849, 437.369, 0.4140222)
   validation loss 376.620849609375, (161.28708, 0.06672923, 215.26704, 0.4140222)
decoder loss ratio: 6248.541442, decoder SINDy loss  ratio: 0.464684
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.877008]
 [ -0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1128.25927734375, (678.73846, 0.14008465, 449.38074, 0.41385147)
   validation loss 793.1732177734375, (552.78674, 0.065664195, 240.32079, 0.41385147)
decoder loss ratio: 21415.918110, decoder SINDy loss  ratio: 0.518766
params['save_name']
pendulum_2023_10_25_09_40_37_659913
