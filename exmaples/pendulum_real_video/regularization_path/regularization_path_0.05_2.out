nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-29 04:57:51.268484: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-29 04:57:51.276066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-29 04:57:51.278036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ae20ad34c0 executing computations on platform Host. Devices:
2023-10-29 04:57:51.278073: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-29 04:57:51.279953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-29 04:57:51.403141: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ae20bc80d0 executing computations on platform CUDA. Devices:
2023-10-29 04:57:51.403265: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-29 04:57:51.404249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-29 04:57:51.404853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-29 04:57:51.409659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-29 04:57:51.413467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-29 04:57:51.414251: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-29 04:57:51.418077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-29 04:57:51.419779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-29 04:57:51.426242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-29 04:57:51.427061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-29 04:57:51.427112: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-29 04:57:51.427558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-29 04:57:51.427571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-29 04:57:51.427579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-29 04:57:51.428324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-29 04:57:52.540385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.05, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8422458171844482 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 109622.078125, (102532.69, 0.02723634, 7072.205, 2.5317838)
   validation loss 91984.4921875, (90766.56, 0.009185873, 1200.7574, 2.5317838)
decoder loss ratio: 3516454.208932, decoder SINDy loss  ratio: 2.592004
--- 0.2806220054626465 seconds for one epoch ---
--- 0.34067487716674805 seconds for one epoch ---
--- 0.3461015224456787 seconds for one epoch ---
--- 0.3263535499572754 seconds for one epoch ---
--- 0.33747172355651855 seconds for one epoch ---
--- 0.32378530502319336 seconds for one epoch ---
--- 0.346163272857666 seconds for one epoch ---
--- 0.3351576328277588 seconds for one epoch ---
--- 0.3370347023010254 seconds for one epoch ---
--- 0.3308420181274414 seconds for one epoch ---
--- 0.35913801193237305 seconds for one epoch ---
--- 0.32841968536376953 seconds for one epoch ---
--- 0.34624338150024414 seconds for one epoch ---
--- 0.3193068504333496 seconds for one epoch ---
--- 0.3559868335723877 seconds for one epoch ---
--- 0.3292717933654785 seconds for one epoch ---
--- 0.3451650142669678 seconds for one epoch ---
--- 0.3323051929473877 seconds for one epoch ---
--- 0.35929298400878906 seconds for one epoch ---
--- 0.32756996154785156 seconds for one epoch ---
--- 0.3458590507507324 seconds for one epoch ---
--- 0.32819271087646484 seconds for one epoch ---
--- 0.3454928398132324 seconds for one epoch ---
--- 0.3237795829772949 seconds for one epoch ---
=========================
[[0.7725684 ]
 [0.98989767]
 [0.9999902 ]
 [0.99991226]
 [0.7737262 ]
 [1.        ]
 [0.99993974]
 [0.7728699 ]
 [0.77145267]
 [1.        ]
 [0.79073817]]
[[-0.09903545]
 [ 0.51061845]
 [-0.86015403]
 [-0.75050026]
 [-0.13085678]
 [-1.473014  ]
 [ 0.7694425 ]
 [-0.10942196]
 [ 0.00475841]
 [-2.013021  ]
 [ 0.2379857 ]]
--- 0.2754671573638916 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 80128.453125, (74627.9, 10.029911, 5456.934, 2.5317736)
   validation loss 75952.4296875, (74599.875, 3.2457635, 1315.7303, 2.5317736)
decoder loss ratio: 2890128.668578, decoder SINDy loss  ratio: 2.840189
--- 0.3256955146789551 seconds for one epoch ---
--- 0.35915517807006836 seconds for one epoch ---
--- 0.33275532722473145 seconds for one epoch ---
--- 0.3455843925476074 seconds for one epoch ---
--- 0.33017945289611816 seconds for one epoch ---
--- 0.3379092216491699 seconds for one epoch ---
--- 0.338503360748291 seconds for one epoch ---
--- 0.34377503395080566 seconds for one epoch ---
--- 0.33005571365356445 seconds for one epoch ---
--- 0.3485987186431885 seconds for one epoch ---
--- 0.348527193069458 seconds for one epoch ---
--- 0.3475215435028076 seconds for one epoch ---
--- 0.32164883613586426 seconds for one epoch ---
--- 0.3529179096221924 seconds for one epoch ---
--- 0.33159518241882324 seconds for one epoch ---
--- 0.35361814498901367 seconds for one epoch ---
--- 0.3299143314361572 seconds for one epoch ---
--- 0.3491537570953369 seconds for one epoch ---
--- 0.32686448097229004 seconds for one epoch ---
--- 0.36479902267456055 seconds for one epoch ---
--- 0.325610876083374 seconds for one epoch ---
--- 0.36392879486083984 seconds for one epoch ---
--- 0.3248636722564697 seconds for one epoch ---
--- 0.3484327793121338 seconds for one epoch ---
=========================
[[0.6178717 ]
 [0.8326496 ]
 [0.9424611 ]
 [0.96894807]
 [0.6095437 ]
 [1.        ]
 [0.99954146]
 [0.6161823 ]
 [0.6089806 ]
 [1.        ]
 [0.63853365]]
[[ 0.17043072]
 [ 0.37133762]
 [-0.44472566]
 [-0.47941503]
 [-0.05254151]
 [-1.9874457 ]
 [ 0.6945073 ]
 [ 0.16008848]
 [-0.00255103]
 [-1.3120471 ]
 [ 0.2320305 ]]
--- 0.3018519878387451 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 89675.75, (80462.32, 264.1457, 8905.928, 2.5317504)
   validation loss 56239.171875, (54735.793, 7.3914747, 1452.6385, 2.5317504)
decoder loss ratio: 2120559.645125, decoder SINDy loss  ratio: 3.135725
--- 0.2812530994415283 seconds for one epoch ---
--- 0.32347631454467773 seconds for one epoch ---
--- 0.3684818744659424 seconds for one epoch ---
--- 0.32809877395629883 seconds for one epoch ---
--- 0.35513734817504883 seconds for one epoch ---
--- 0.3370938301086426 seconds for one epoch ---
--- 0.35134387016296387 seconds for one epoch ---
--- 0.3169989585876465 seconds for one epoch ---
--- 0.34758734703063965 seconds for one epoch ---
--- 0.3300204277038574 seconds for one epoch ---
--- 0.34638357162475586 seconds for one epoch ---
--- 0.3256092071533203 seconds for one epoch ---
--- 0.35353517532348633 seconds for one epoch ---
--- 0.32308053970336914 seconds for one epoch ---
--- 0.3604154586791992 seconds for one epoch ---
--- 0.4443051815032959 seconds for one epoch ---
--- 0.33635568618774414 seconds for one epoch ---
--- 0.3273332118988037 seconds for one epoch ---
--- 0.3573734760284424 seconds for one epoch ---
--- 0.32149434089660645 seconds for one epoch ---
--- 0.35701680183410645 seconds for one epoch ---
--- 0.32035398483276367 seconds for one epoch ---
--- 0.382981538772583 seconds for one epoch ---
--- 0.31580400466918945 seconds for one epoch ---
=========================
[[0.4728857 ]
 [0.5315862 ]
 [0.48437998]
 [0.88842535]
 [0.47300696]
 [1.        ]
 [0.9992361 ]
 [0.48664582]
 [0.47288892]
 [0.99999857]
 [0.51285726]]
[[-8.7542960e-04]
 [ 2.5320497e-01]
 [-1.6830572e-01]
 [-4.2259678e-01]
 [-1.3358099e-02]
 [-2.6245809e+00]
 [ 6.8391019e-01]
 [ 1.7722809e-01]
 [-1.2513585e-03]
 [-1.0302230e+00]
 [ 2.3219030e-01]]
--- 0.2713947296142578 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 67044.796875, (60530.195, 21.514801, 6436.846, 2.531766)
   validation loss 36415.9140625, (35080.6, 1.9390485, 1277.1366, 2.531766)
decoder loss ratio: 1359083.407134, decoder SINDy loss  ratio: 2.756879
--- 0.3256828784942627 seconds for one epoch ---
--- 0.3753654956817627 seconds for one epoch ---
--- 0.3147144317626953 seconds for one epoch ---
--- 0.3578221797943115 seconds for one epoch ---
--- 0.3273799419403076 seconds for one epoch ---
--- 0.36115407943725586 seconds for one epoch ---
--- 0.3255000114440918 seconds for one epoch ---
--- 0.3637354373931885 seconds for one epoch ---
--- 0.32706260681152344 seconds for one epoch ---
--- 0.3618650436401367 seconds for one epoch ---
--- 0.3176581859588623 seconds for one epoch ---
--- 0.3833634853363037 seconds for one epoch ---
--- 0.3277111053466797 seconds for one epoch ---
--- 0.3550443649291992 seconds for one epoch ---
--- 0.32880258560180664 seconds for one epoch ---
--- 0.35768890380859375 seconds for one epoch ---
--- 0.32308197021484375 seconds for one epoch ---
--- 0.3800840377807617 seconds for one epoch ---
--- 0.3361084461212158 seconds for one epoch ---
--- 0.36270737648010254 seconds for one epoch ---
--- 0.28940463066101074 seconds for one epoch ---
--- 0.34673142433166504 seconds for one epoch ---
--- 0.30216217041015625 seconds for one epoch ---
--- 0.34959912300109863 seconds for one epoch ---
=========================
[[0.381436  ]
 [0.40172225]
 [0.38864478]
 [0.7910242 ]
 [0.37590745]
 [1.        ]
 [0.9988076 ]
 [0.4080567 ]
 [0.37555146]
 [0.98979783]
 [0.40840402]]
[[-1.2800260e-01]
 [ 2.0114751e-01]
 [ 1.6636407e-01]
 [-3.9119604e-01]
 [-2.7323274e-02]
 [-3.2932808e+00]
 [ 6.7006457e-01]
 [ 2.1233793e-01]
 [-6.4116996e-04]
 [-5.6186706e-01]
 [ 2.1289080e-01]]
--- 0.2954108715057373 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 36977.7890625, (29312.771, 22.805946, 7574.844, 2.5317976)
   validation loss 19731.6484375, (18525.053, 0.6922078, 1138.536, 2.5317976)
decoder loss ratio: 717692.703836, decoder SINDy loss  ratio: 2.457690
--- 0.2564384937286377 seconds for one epoch ---
--- 0.29300594329833984 seconds for one epoch ---
--- 0.34098219871520996 seconds for one epoch ---
--- 0.29691553115844727 seconds for one epoch ---
--- 0.3589801788330078 seconds for one epoch ---
--- 0.300152063369751 seconds for one epoch ---
--- 0.34305477142333984 seconds for one epoch ---
--- 0.29544734954833984 seconds for one epoch ---
--- 0.34981632232666016 seconds for one epoch ---
--- 0.2922852039337158 seconds for one epoch ---
--- 0.3729226589202881 seconds for one epoch ---
--- 0.32446908950805664 seconds for one epoch ---
--- 0.3939976692199707 seconds for one epoch ---
--- 0.34703898429870605 seconds for one epoch ---
--- 0.3728816509246826 seconds for one epoch ---
--- 0.33458375930786133 seconds for one epoch ---
--- 0.3716726303100586 seconds for one epoch ---
--- 0.33469462394714355 seconds for one epoch ---
--- 0.38065171241760254 seconds for one epoch ---
--- 0.3467094898223877 seconds for one epoch ---
--- 0.3748905658721924 seconds for one epoch ---
--- 0.3326890468597412 seconds for one epoch ---
--- 0.3841702938079834 seconds for one epoch ---
--- 0.32964444160461426 seconds for one epoch ---
=========================
[[0.35266572]
 [0.30346596]
 [0.84335434]
 [0.67137676]
 [0.29428652]
 [1.        ]
 [0.9963536 ]
 [0.32685965]
 [0.29356048]
 [0.2992348 ]
 [0.3739697 ]]
[[-2.37508252e-01]
 [ 1.46942109e-01]
 [ 4.19631124e-01]
 [-3.63809079e-01]
 [-4.28451151e-02]
 [-3.89605951e+00]
 [ 6.20117307e-01]
 [ 2.07240194e-01]
 [-3.21798190e-03]
 [-1.20867014e-01]
 [ 2.54446477e-01]]
--- 0.26595544815063477 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 45010.4453125, (36920.6, 25.117197, 7986.032, 2.5318396)
   validation loss 7498.2265625, (6506.42, 0.25183466, 912.861, 2.5318396)
decoder loss ratio: 252070.003415, decoder SINDy loss  ratio: 1.970539
--- 0.33980536460876465 seconds for one epoch ---
--- 0.3897871971130371 seconds for one epoch ---
--- 0.3393974304199219 seconds for one epoch ---
--- 0.3762965202331543 seconds for one epoch ---
--- 0.33910465240478516 seconds for one epoch ---
--- 0.38827991485595703 seconds for one epoch ---
--- 0.3289222717285156 seconds for one epoch ---
--- 0.3790912628173828 seconds for one epoch ---
--- 0.3493461608886719 seconds for one epoch ---
--- 0.3749735355377197 seconds for one epoch ---
--- 0.33509039878845215 seconds for one epoch ---
--- 0.38070201873779297 seconds for one epoch ---
--- 0.330902099609375 seconds for one epoch ---
--- 0.38513851165771484 seconds for one epoch ---
--- 0.33278918266296387 seconds for one epoch ---
--- 0.38941144943237305 seconds for one epoch ---
--- 0.3456153869628906 seconds for one epoch ---
--- 0.40930676460266113 seconds for one epoch ---
--- 0.3468005657196045 seconds for one epoch ---
--- 0.3903372287750244 seconds for one epoch ---
--- 0.32365870475769043 seconds for one epoch ---
--- 0.3823564052581787 seconds for one epoch ---
--- 0.31700825691223145 seconds for one epoch ---
--- 0.3875701427459717 seconds for one epoch ---
=========================
[[0.3328248 ]
 [0.2353315 ]
 [0.9917502 ]
 [0.6271056 ]
 [0.2370542 ]
 [1.        ]
 [0.9962072 ]
 [0.2547145 ]
 [0.23454994]
 [0.3466613 ]
 [0.276985  ]]
[[-2.6126009e-01]
 [ 4.2874694e-02]
 [ 5.8297926e-01]
 [-3.5940447e-01]
 [-8.2337469e-02]
 [-4.4025822e+00]
 [ 6.2217051e-01]
 [ 1.7776734e-01]
 [-3.6800774e-03]
 [ 2.6885727e-01]
 [ 2.1566561e-01]]
--- 0.3074634075164795 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 43119.94921875, (31956.639, 5.262205, 11069.5625, 2.531886)
   validation loss 12034.396484375, (11033.178, 0.13508789, 912.59656, 2.531886)
decoder loss ratio: 427444.459869, decoder SINDy loss  ratio: 1.969968
--- 0.27902841567993164 seconds for one epoch ---
--- 0.3118479251861572 seconds for one epoch ---
--- 0.413316011428833 seconds for one epoch ---
--- 0.3295731544494629 seconds for one epoch ---
--- 0.3733818531036377 seconds for one epoch ---
--- 0.2977416515350342 seconds for one epoch ---
--- 0.39539122581481934 seconds for one epoch ---
--- 0.32901501655578613 seconds for one epoch ---
--- 0.40476179122924805 seconds for one epoch ---
--- 0.34620022773742676 seconds for one epoch ---
--- 0.40576171875 seconds for one epoch ---
--- 0.3312385082244873 seconds for one epoch ---
--- 0.4093143939971924 seconds for one epoch ---
--- 0.3278203010559082 seconds for one epoch ---
--- 0.4274485111236572 seconds for one epoch ---
--- 0.3320586681365967 seconds for one epoch ---
--- 0.40068674087524414 seconds for one epoch ---
--- 0.33069920539855957 seconds for one epoch ---
--- 0.39861321449279785 seconds for one epoch ---
--- 0.3303987979888916 seconds for one epoch ---
--- 0.41011714935302734 seconds for one epoch ---
--- 0.3128523826599121 seconds for one epoch ---
--- 0.3874015808105469 seconds for one epoch ---
--- 0.3185427188873291 seconds for one epoch ---
=========================
[[0.19557045]
 [0.18645777]
 [0.9980038 ]
 [0.3920528 ]
 [0.18937224]
 [1.        ]
 [0.9882024 ]
 [0.20198268]
 [0.18452184]
 [0.9987384 ]
 [0.1994805 ]]
[[-1.4532581e-01]
 [-7.0027277e-02]
 [ 6.5759796e-01]
 [-3.0314237e-01]
 [-1.0744083e-01]
 [-4.7849655e+00]
 [ 5.6805182e-01]
 [ 1.6750869e-01]
 [-3.6329736e-03]
 [ 6.8062317e-01]
 [ 1.5993710e-01]]
--- 0.2766268253326416 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 43914.93359375, (35183.473, 5.8033333, 8629.414, 2.5319264)
   validation loss 5846.7412109375, (4941.5176, 0.12840739, 808.85406, 2.5319264)
decoder loss ratio: 191442.969828, decoder SINDy loss  ratio: 1.746025
--- 0.33968067169189453 seconds for one epoch ---
--- 0.40758252143859863 seconds for one epoch ---
--- 0.3238346576690674 seconds for one epoch ---
--- 0.3902297019958496 seconds for one epoch ---
--- 0.32254576683044434 seconds for one epoch ---
--- 0.40819883346557617 seconds for one epoch ---
--- 0.3452775478363037 seconds for one epoch ---
--- 0.4311859607696533 seconds for one epoch ---
--- 0.32349658012390137 seconds for one epoch ---
--- 0.3915526866912842 seconds for one epoch ---
--- 0.3230879306793213 seconds for one epoch ---
--- 0.3902449607849121 seconds for one epoch ---
--- 0.3287186622619629 seconds for one epoch ---
--- 0.40883636474609375 seconds for one epoch ---
--- 0.33010220527648926 seconds for one epoch ---
--- 0.4086568355560303 seconds for one epoch ---
--- 0.3250904083251953 seconds for one epoch ---
--- 0.3960144519805908 seconds for one epoch ---
--- 0.30477237701416016 seconds for one epoch ---
--- 0.4291269779205322 seconds for one epoch ---
--- 0.3176612854003906 seconds for one epoch ---
--- 0.4265472888946533 seconds for one epoch ---
--- 0.30890679359436035 seconds for one epoch ---
--- 0.41898465156555176 seconds for one epoch ---
=========================
[[0.15084745]
 [0.16876629]
 [0.9997808 ]
 [0.24443164]
 [0.15467139]
 [1.        ]
 [0.95390373]
 [0.17309293]
 [0.1482764 ]
 [0.9999967 ]
 [0.15862817]]
[[-7.8607924e-02]
 [-1.7317297e-01]
 [ 7.7049905e-01]
 [-2.5397214e-01]
 [-1.1758993e-01]
 [-5.1448064e+00]
 [ 4.9995971e-01]
 [ 1.8272954e-01]
 [-1.1243916e-03]
 [ 1.0038499e+00]
 [ 1.4000146e-01]]
--- 0.29906487464904785 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 38419.734375, (32680.332, 10.346434, 5625.7705, 2.5319707)
   validation loss 4531.68505859375, (3669.1436, 0.1398087, 759.11615, 2.5319707)
decoder loss ratio: 142148.991222, decoder SINDy loss  ratio: 1.638659
--- 0.26610422134399414 seconds for one epoch ---
--- 0.3111886978149414 seconds for one epoch ---
--- 0.4416935443878174 seconds for one epoch ---
--- 0.3235659599304199 seconds for one epoch ---
--- 0.4165830612182617 seconds for one epoch ---
--- 0.33190393447875977 seconds for one epoch ---
--- 0.4075613021850586 seconds for one epoch ---
--- 0.3279745578765869 seconds for one epoch ---
--- 0.41162967681884766 seconds for one epoch ---
--- 0.32331395149230957 seconds for one epoch ---
--- 0.43331170082092285 seconds for one epoch ---
--- 0.3258330821990967 seconds for one epoch ---
--- 0.4067494869232178 seconds for one epoch ---
--- 0.307004451751709 seconds for one epoch ---
--- 0.4063742160797119 seconds for one epoch ---
--- 0.411712646484375 seconds for one epoch ---
--- 0.3984537124633789 seconds for one epoch ---
--- 0.3225564956665039 seconds for one epoch ---
--- 0.40969085693359375 seconds for one epoch ---
--- 0.3315610885620117 seconds for one epoch ---
--- 0.42650628089904785 seconds for one epoch ---
--- 0.3148684501647949 seconds for one epoch ---
--- 0.43827366828918457 seconds for one epoch ---
--- 0.343761682510376 seconds for one epoch ---
=========================
[[0.11774738]
 [0.22568053]
 [0.9999311 ]
 [0.1600911 ]
 [0.12667416]
 [1.        ]
 [0.9171829 ]
 [0.14272547]
 [0.11738934]
 [1.        ]
 [0.13268185]]
[[ 2.0665720e-02]
 [-2.5865674e-01]
 [ 8.3008832e-01]
 [-2.0853487e-01]
 [-1.3311534e-01]
 [-5.4646459e+00]
 [ 4.7027338e-01]
 [ 1.8195577e-01]
 [ 1.6544800e-04]
 [ 1.3311627e+00]
 [ 1.5700555e-01]]
--- 0.2842710018157959 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 26155.12109375, (18840.648, 20.634804, 7184.67, 2.5320156)
   validation loss 5730.599609375, (4905.4478, 0.14345191, 715.8396, 2.5320156)
decoder loss ratio: 190045.562218, decoder SINDy loss  ratio: 1.545240
--- 0.32187795639038086 seconds for one epoch ---
--- 0.4296536445617676 seconds for one epoch ---
--- 0.33174991607666016 seconds for one epoch ---
--- 0.42258620262145996 seconds for one epoch ---
--- 0.32827186584472656 seconds for one epoch ---
--- 0.4194972515106201 seconds for one epoch ---
--- 0.33263325691223145 seconds for one epoch ---
--- 0.4143674373626709 seconds for one epoch ---
--- 0.32778429985046387 seconds for one epoch ---
--- 0.4193117618560791 seconds for one epoch ---
--- 0.32309913635253906 seconds for one epoch ---
--- 0.43437814712524414 seconds for one epoch ---
--- 0.34291625022888184 seconds for one epoch ---
--- 0.41703104972839355 seconds for one epoch ---
--- 0.33730340003967285 seconds for one epoch ---
--- 0.40355658531188965 seconds for one epoch ---
--- 0.3340291976928711 seconds for one epoch ---
--- 0.4177522659301758 seconds for one epoch ---
--- 0.3252236843109131 seconds for one epoch ---
--- 0.4174211025238037 seconds for one epoch ---
--- 0.3370182514190674 seconds for one epoch ---
--- 0.43802642822265625 seconds for one epoch ---
--- 0.30821895599365234 seconds for one epoch ---
--- 0.45982837677001953 seconds for one epoch ---
=========================
[[0.10028308]
 [0.45063463]
 [0.99998987]
 [0.12467882]
 [0.11023785]
 [1.        ]
 [0.7363749 ]
 [0.11680045]
 [0.09493704]
 [1.        ]
 [0.10683028]]
[[ 1.0689526e-01]
 [-3.3510545e-01]
 [ 9.2431217e-01]
 [-1.8879765e-01]
 [-1.5588018e-01]
 [-5.7780399e+00]
 [ 4.0130088e-01]
 [ 1.7339732e-01]
 [ 1.6957492e-03]
 [ 1.6412896e+00]
 [ 1.4375193e-01]]
--- 0.31745362281799316 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 49601.515625, (39295.24, 25.179783, 10165.969, 2.5320652)
   validation loss 3150.90478515625, (2396.7573, 0.14358845, 638.87427, 2.5320652)
decoder loss ratio: 92854.539694, decoder SINDy loss  ratio: 1.379100
--- 0.2592346668243408 seconds for one epoch ---
--- 0.32427334785461426 seconds for one epoch ---
--- 0.4175760746002197 seconds for one epoch ---
--- 0.33054423332214355 seconds for one epoch ---
--- 0.4569699764251709 seconds for one epoch ---
--- 0.3384687900543213 seconds for one epoch ---
--- 0.4490077495574951 seconds for one epoch ---
--- 0.33225131034851074 seconds for one epoch ---
--- 0.4452528953552246 seconds for one epoch ---
--- 0.3282051086425781 seconds for one epoch ---
--- 0.45676445960998535 seconds for one epoch ---
--- 0.32616662979125977 seconds for one epoch ---
--- 0.46536731719970703 seconds for one epoch ---
--- 0.3188786506652832 seconds for one epoch ---
--- 0.4563441276550293 seconds for one epoch ---
--- 0.3127884864807129 seconds for one epoch ---
--- 0.4523656368255615 seconds for one epoch ---
--- 0.3246498107910156 seconds for one epoch ---
--- 0.4375441074371338 seconds for one epoch ---
--- 0.29920244216918945 seconds for one epoch ---
--- 0.42009544372558594 seconds for one epoch ---
--- 0.3294031620025635 seconds for one epoch ---
--- 0.4431915283203125 seconds for one epoch ---
--- 0.3332092761993408 seconds for one epoch ---
=========================
[[0.11661749]
 [0.7931797 ]
 [0.9999966 ]
 [0.09528723]
 [0.09497708]
 [1.        ]
 [0.44141334]
 [0.09677553]
 [0.07566619]
 [1.        ]
 [0.08170632]]
[[ 2.0401762e-01]
 [-4.1904804e-01]
 [ 1.0326781e+00]
 [-1.6700506e-01]
 [-1.6622135e-01]
 [-6.0660610e+00]
 [ 3.3566573e-01]
 [ 1.7061256e-01]
 [-1.6058751e-03]
 [ 1.9447436e+00]
 [ 1.1137297e-01]]
--- 0.2936844825744629 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 29227.59765625, (24914.45, 0.7486059, 4192.213, 2.5321152)
   validation loss 2941.6005859375, (2221.2048, 0.156318, 600.05164, 2.5321152)
decoder loss ratio: 86053.331450, decoder SINDy loss  ratio: 1.295296
--- 0.32784032821655273 seconds for one epoch ---
--- 0.4335978031158447 seconds for one epoch ---
--- 0.3355088233947754 seconds for one epoch ---
--- 0.4469313621520996 seconds for one epoch ---
--- 0.313976526260376 seconds for one epoch ---
--- 0.4341151714324951 seconds for one epoch ---
--- 0.3173105716705322 seconds for one epoch ---
--- 0.4509437084197998 seconds for one epoch ---
--- 0.3050973415374756 seconds for one epoch ---
--- 0.4366896152496338 seconds for one epoch ---
--- 0.3101499080657959 seconds for one epoch ---
--- 0.44488954544067383 seconds for one epoch ---
--- 0.3062887191772461 seconds for one epoch ---
--- 0.43325114250183105 seconds for one epoch ---
--- 0.31567978858947754 seconds for one epoch ---
--- 0.4622647762298584 seconds for one epoch ---
--- 0.31807804107666016 seconds for one epoch ---
--- 0.4425961971282959 seconds for one epoch ---
--- 0.31387829780578613 seconds for one epoch ---
--- 0.4308440685272217 seconds for one epoch ---
--- 0.33071446418762207 seconds for one epoch ---
--- 0.43080902099609375 seconds for one epoch ---
--- 0.3297741413116455 seconds for one epoch ---
--- 0.4409346580505371 seconds for one epoch ---
=========================
[[0.3981395 ]
 [0.868238  ]
 [0.99999905]
 [0.07422823]
 [0.08583388]
 [1.        ]
 [0.23840664]
 [0.07341955]
 [0.06154701]
 [1.        ]
 [0.06848208]]
[[ 3.2778499e-01]
 [-4.4746679e-01]
 [ 1.1073481e+00]
 [-1.4503038e-01]
 [-1.7679146e-01]
 [-6.3126235e+00]
 [ 2.8391472e-01]
 [ 1.4188367e-01]
 [-7.3606451e-04]
 [ 2.2505450e+00]
 [ 1.1682731e-01]]
--- 0.30457234382629395 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 38014.9296875, (31616.75, 1.9447722, 6270.2188, 2.532163)
   validation loss 2878.775390625, (2182.2627, 0.16517289, 570.3298, 2.532163)
decoder loss ratio: 84544.645391, decoder SINDy loss  ratio: 1.231137
--- 0.2897939682006836 seconds for one epoch ---
--- 0.3220512866973877 seconds for one epoch ---
--- 0.44649481773376465 seconds for one epoch ---
--- 0.3144502639770508 seconds for one epoch ---
--- 0.45520997047424316 seconds for one epoch ---
--- 0.3108704090118408 seconds for one epoch ---
--- 0.44213294982910156 seconds for one epoch ---
--- 0.30362892150878906 seconds for one epoch ---
--- 0.4564826488494873 seconds for one epoch ---
--- 0.32364392280578613 seconds for one epoch ---
--- 0.43959736824035645 seconds for one epoch ---
--- 0.33341264724731445 seconds for one epoch ---
--- 0.4524507522583008 seconds for one epoch ---
--- 0.3308236598968506 seconds for one epoch ---
--- 0.4563415050506592 seconds for one epoch ---
--- 0.3002192974090576 seconds for one epoch ---
--- 0.4384329319000244 seconds for one epoch ---
--- 0.33618736267089844 seconds for one epoch ---
--- 0.4521486759185791 seconds for one epoch ---
--- 0.3301680088043213 seconds for one epoch ---
--- 0.45424532890319824 seconds for one epoch ---
--- 0.3275437355041504 seconds for one epoch ---
--- 0.4696009159088135 seconds for one epoch ---
--- 0.33588600158691406 seconds for one epoch ---
=========================
[[0.93685824]
 [0.94114393]
 [1.        ]
 [0.05865123]
 [0.07519904]
 [1.        ]
 [0.0962259 ]
 [0.05794103]
 [0.04941269]
 [1.        ]
 [0.06316594]]
[[ 4.8905438e-01]
 [-4.9281341e-01]
 [ 1.1572493e+00]
 [-1.2958026e-01]
 [-1.7918998e-01]
 [-6.4678345e+00]
 [ 2.0948978e-01]
 [ 1.2587203e-01]
 [ 2.4279447e-03]
 [ 2.5369575e+00]
 [ 1.4839965e-01]]
--- 0.27922677993774414 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18319.521484375, (16096.411, 0.73816246, 2090.874, 2.5321999)
   validation loss 1710.06103515625, (1088.9644, 0.19098726, 489.4069, 2.5321999)
decoder loss ratio: 42188.369656, decoder SINDy loss  ratio: 1.056454
--- 0.31735730171203613 seconds for one epoch ---
--- 0.46466779708862305 seconds for one epoch ---
--- 0.3142366409301758 seconds for one epoch ---
--- 0.4516255855560303 seconds for one epoch ---
--- 0.3258969783782959 seconds for one epoch ---
--- 0.45415401458740234 seconds for one epoch ---
--- 0.3203597068786621 seconds for one epoch ---
--- 0.4599149227142334 seconds for one epoch ---
--- 0.3437929153442383 seconds for one epoch ---
--- 0.4581716060638428 seconds for one epoch ---
--- 0.3119778633117676 seconds for one epoch ---
--- 0.4710733890533447 seconds for one epoch ---
--- 0.32344508171081543 seconds for one epoch ---
--- 0.46001148223876953 seconds for one epoch ---
--- 0.3122870922088623 seconds for one epoch ---
--- 0.44815969467163086 seconds for one epoch ---
--- 0.33780407905578613 seconds for one epoch ---
--- 0.4642033576965332 seconds for one epoch ---
--- 0.3374173641204834 seconds for one epoch ---
--- 0.4699089527130127 seconds for one epoch ---
--- 0.33627748489379883 seconds for one epoch ---
--- 0.4741513729095459 seconds for one epoch ---
--- 0.34017086029052734 seconds for one epoch ---
--- 0.4802374839782715 seconds for one epoch ---
=========================
[[0.9995539 ]
 [0.9832135 ]
 [0.9999989 ]
 [0.0447756 ]
 [0.07766584]
 [1.        ]
 [0.06105483]
 [0.04700586]
 [0.04047664]
 [1.        ]
 [0.04910808]]
[[ 7.40848124e-01]
 [-5.58388114e-01]
 [ 1.09638405e+00]
 [-9.51733291e-02]
 [-1.97206199e-01]
 [-6.50734615e+00]
 [ 1.67575851e-01]
 [ 1.13377996e-01]
 [ 3.32848611e-03]
 [ 2.85622954e+00]
 [ 1.26071662e-01]]
--- 0.3276538848876953 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 32057.59375, (25808.3, 5.97433, 6106.347, 2.5322268)
   validation loss 2225.39306640625, (1535.5535, 0.23103192, 552.6396, 2.5322268)
decoder loss ratio: 59490.007142, decoder SINDy loss  ratio: 1.192950
--- 0.2613234519958496 seconds for one epoch ---
--- 0.34366440773010254 seconds for one epoch ---
--- 0.4811568260192871 seconds for one epoch ---
--- 0.3301887512207031 seconds for one epoch ---
--- 0.47487497329711914 seconds for one epoch ---
--- 0.3454153537750244 seconds for one epoch ---
--- 0.5055966377258301 seconds for one epoch ---
--- 0.32609081268310547 seconds for one epoch ---
--- 0.489656925201416 seconds for one epoch ---
--- 0.33685994148254395 seconds for one epoch ---
--- 0.45960235595703125 seconds for one epoch ---
--- 0.29384303092956543 seconds for one epoch ---
--- 0.4609558582305908 seconds for one epoch ---
--- 0.318554162979126 seconds for one epoch ---
--- 0.47019314765930176 seconds for one epoch ---
--- 0.33559679985046387 seconds for one epoch ---
--- 0.4924333095550537 seconds for one epoch ---
--- 0.3273789882659912 seconds for one epoch ---
--- 0.4946315288543701 seconds for one epoch ---
--- 0.3268015384674072 seconds for one epoch ---
--- 0.5148530006408691 seconds for one epoch ---
--- 0.33368659019470215 seconds for one epoch ---
--- 0.49207425117492676 seconds for one epoch ---
--- 0.32433032989501953 seconds for one epoch ---
=========================
[[0.99999636]
 [0.99012387]
 [0.99999636]
 [0.03607477]
 [0.06212221]
 [1.        ]
 [0.04354244]
 [0.0374741 ]
 [0.03268048]
 [1.        ]
 [0.04273019]]
[[ 1.0257638e+00]
 [-5.8571428e-01]
 [ 9.9998164e-01]
 [-8.4611997e-02]
 [-1.8491538e-01]
 [-6.4713550e+00]
 [ 1.3624060e-01]
 [ 9.9120848e-02]
 [-9.2926412e-04]
 [ 3.1569157e+00]
 [ 1.3258338e-01]]
--- 0.27695155143737793 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 17103.66796875, (14779.369, 2.6011932, 2180.5847, 2.532246)
   validation loss 1882.072265625, (1238.9904, 0.18973143, 501.7804, 2.532246)
decoder loss ratio: 48000.637391, decoder SINDy loss  ratio: 1.083164
--- 0.32784152030944824 seconds for one epoch ---
--- 0.47788166999816895 seconds for one epoch ---
--- 0.3227663040161133 seconds for one epoch ---
--- 0.4798929691314697 seconds for one epoch ---
--- 0.32929515838623047 seconds for one epoch ---
--- 0.48970580101013184 seconds for one epoch ---
--- 0.3232855796813965 seconds for one epoch ---
--- 0.4884324073791504 seconds for one epoch ---
--- 0.30148839950561523 seconds for one epoch ---
--- 0.48252296447753906 seconds for one epoch ---
--- 0.3274838924407959 seconds for one epoch ---
--- 0.49898457527160645 seconds for one epoch ---
--- 0.32788920402526855 seconds for one epoch ---
--- 0.4909098148345947 seconds for one epoch ---
--- 0.3348376750946045 seconds for one epoch ---
--- 0.478513240814209 seconds for one epoch ---
--- 0.3222315311431885 seconds for one epoch ---
--- 0.49770259857177734 seconds for one epoch ---
--- 0.3238058090209961 seconds for one epoch ---
--- 0.4819345474243164 seconds for one epoch ---
--- 0.3148946762084961 seconds for one epoch ---
--- 0.49801063537597656 seconds for one epoch ---
--- 0.3142848014831543 seconds for one epoch ---
--- 0.4976930618286133 seconds for one epoch ---
=========================
[[1.        ]
 [0.9875398 ]
 [0.9999963 ]
 [0.03512695]
 [0.05564885]
 [1.        ]
 [0.06176357]
 [0.0314094 ]
 [0.02696319]
 [1.        ]
 [0.03481153]]
[[ 1.2690609e+00]
 [-5.7424408e-01]
 [ 9.5088148e-01]
 [-1.2278080e-01]
 [-1.8335167e-01]
 [-6.4832363e+00]
 [ 1.9309835e-01]
 [ 9.5857516e-02]
 [-2.3741066e-03]
 [ 3.4305592e+00]
 [ 1.2097588e-01]]
--- 0.4177095890045166 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 31000.65625, (24445.312, 5.9043674, 6404.469, 2.5322733)
   validation loss 1753.01123046875, (1097.4498, 0.2026243, 510.38922, 2.5322733)
decoder loss ratio: 42517.111636, decoder SINDy loss  ratio: 1.101747
--- 0.28571176528930664 seconds for one epoch ---
--- 0.31681299209594727 seconds for one epoch ---
--- 0.47747039794921875 seconds for one epoch ---
--- 0.31494975090026855 seconds for one epoch ---
--- 0.48616838455200195 seconds for one epoch ---
--- 0.30660033226013184 seconds for one epoch ---
--- 0.493544340133667 seconds for one epoch ---
--- 0.2842564582824707 seconds for one epoch ---
--- 0.5072999000549316 seconds for one epoch ---
--- 0.33174967765808105 seconds for one epoch ---
--- 0.4959840774536133 seconds for one epoch ---
--- 0.32994794845581055 seconds for one epoch ---
--- 0.4981358051300049 seconds for one epoch ---
--- 0.32480573654174805 seconds for one epoch ---
--- 0.49583888053894043 seconds for one epoch ---
--- 0.2910444736480713 seconds for one epoch ---
--- 0.4880666732788086 seconds for one epoch ---
--- 0.32112550735473633 seconds for one epoch ---
--- 0.5105874538421631 seconds for one epoch ---
--- 0.3124196529388428 seconds for one epoch ---
--- 0.4939427375793457 seconds for one epoch ---
--- 0.3160727024078369 seconds for one epoch ---
--- 0.4969754219055176 seconds for one epoch ---
--- 0.3038170337677002 seconds for one epoch ---
=========================
[[1.        ]
 [0.98245835]
 [0.99997425]
 [0.03578432]
 [0.05759798]
 [1.        ]
 [0.0634346 ]
 [0.02780309]
 [0.02192913]
 [1.        ]
 [0.03001757]]
[[ 1.5264834e+00]
 [-5.5711877e-01]
 [ 8.8912237e-01]
 [-1.4727171e-01]
 [-1.9404280e-01]
 [-6.4725041e+00]
 [ 2.0178194e-01]
 [ 1.0746474e-01]
 [ 3.3408613e-04]
 [ 3.7114012e+00]
 [ 1.2193466e-01]]
--- 0.27710461616516113 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18983.724609375, (15289.089, 5.3884363, 3540.7458, 2.5323005)
   validation loss 1882.766845703125, (1204.1678, 0.20349081, 529.89496, 2.5323005)
decoder loss ratio: 46651.552908, decoder SINDy loss  ratio: 1.143853
--- 0.29933786392211914 seconds for one epoch ---
--- 0.5087146759033203 seconds for one epoch ---
--- 0.313201904296875 seconds for one epoch ---
--- 0.4752464294433594 seconds for one epoch ---
--- 0.2989363670349121 seconds for one epoch ---
--- 0.4860966205596924 seconds for one epoch ---
--- 0.31172847747802734 seconds for one epoch ---
--- 0.5006427764892578 seconds for one epoch ---
--- 0.33771586418151855 seconds for one epoch ---
--- 0.5197665691375732 seconds for one epoch ---
--- 0.3313617706298828 seconds for one epoch ---
--- 0.5421698093414307 seconds for one epoch ---
--- 0.3341488838195801 seconds for one epoch ---
--- 0.5403709411621094 seconds for one epoch ---
--- 0.32245922088623047 seconds for one epoch ---
--- 0.526282548904419 seconds for one epoch ---
--- 0.33332252502441406 seconds for one epoch ---
--- 0.533721923828125 seconds for one epoch ---
--- 0.31510210037231445 seconds for one epoch ---
--- 0.5291264057159424 seconds for one epoch ---
--- 0.32327866554260254 seconds for one epoch ---
--- 0.5250334739685059 seconds for one epoch ---
--- 0.30068159103393555 seconds for one epoch ---
--- 0.5065560340881348 seconds for one epoch ---
=========================
[[1.        ]
 [0.98050696]
 [0.9999    ]
 [0.0378687 ]
 [0.056396  ]
 [1.        ]
 [0.06276209]
 [0.02218404]
 [0.01827407]
 [1.        ]
 [0.02108326]]
[[ 1.7989725e+00]
 [-5.5193210e-01]
 [ 8.1785554e-01]
 [-1.6408856e-01]
 [-1.9732372e-01]
 [-6.4324222e+00]
 [ 2.0522976e-01]
 [ 9.0423137e-02]
 [-4.2911842e-03]
 [ 3.9922404e+00]
 [ 7.7228524e-02]]
--- 0.30380749702453613 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10802.1796875, (8767.8545, 85.18246, 1795.9481, 2.5323257)
   validation loss 1474.710693359375, (831.57697, 0.17675515, 489.76248, 2.5323257)
decoder loss ratio: 32216.735318, decoder SINDy loss  ratio: 1.057221
--- 0.2695181369781494 seconds for one epoch ---
--- 0.2999427318572998 seconds for one epoch ---
--- 0.5079400539398193 seconds for one epoch ---
--- 0.2911036014556885 seconds for one epoch ---
--- 0.49332571029663086 seconds for one epoch ---
--- 0.32407093048095703 seconds for one epoch ---
--- 0.5455901622772217 seconds for one epoch ---
--- 0.34516191482543945 seconds for one epoch ---
--- 0.5244698524475098 seconds for one epoch ---
--- 0.33640408515930176 seconds for one epoch ---
--- 0.5311360359191895 seconds for one epoch ---
--- 0.3280034065246582 seconds for one epoch ---
--- 0.5225996971130371 seconds for one epoch ---
--- 0.33263444900512695 seconds for one epoch ---
--- 0.529660701751709 seconds for one epoch ---
--- 0.33295774459838867 seconds for one epoch ---
--- 0.529287576675415 seconds for one epoch ---
--- 0.319927453994751 seconds for one epoch ---
--- 0.5242834091186523 seconds for one epoch ---
--- 0.3174302577972412 seconds for one epoch ---
--- 0.5092868804931641 seconds for one epoch ---
--- 0.31290268898010254 seconds for one epoch ---
--- 0.5391521453857422 seconds for one epoch ---
--- 0.3241000175476074 seconds for one epoch ---
=========================
[[1.        ]
 [0.9838712 ]
 [0.9991712 ]
 [0.0498045 ]
 [0.04457846]
 [1.        ]
 [0.07981014]
 [0.01737591]
 [0.01503426]
 [1.        ]
 [0.01586731]]
[[ 2.0993643e+00]
 [-5.6175733e-01]
 [ 7.1117699e-01]
 [-1.9250667e-01]
 [-1.8430218e-01]
 [-6.3524508e+00]
 [ 2.2466138e-01]
 [ 7.0531376e-02]
 [-5.3088241e-03]
 [ 4.2862668e+00]
 [ 3.8799621e-02]]
--- 0.25810861587524414 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 35471.2578125, (28915.168, 21.243103, 6378.0, 2.5323522)
   validation loss 1731.0457763671875, (1122.5278, 0.1742656, 451.4952, 2.5323522)
decoder loss ratio: 43488.677007, decoder SINDy loss  ratio: 0.974616
--- 0.3001251220703125 seconds for one epoch ---
--- 0.5076322555541992 seconds for one epoch ---
--- 0.295642614364624 seconds for one epoch ---
--- 0.5046095848083496 seconds for one epoch ---
--- 0.29212141036987305 seconds for one epoch ---
--- 0.5146768093109131 seconds for one epoch ---
--- 0.3034696578979492 seconds for one epoch ---
--- 0.529088020324707 seconds for one epoch ---
--- 0.30677032470703125 seconds for one epoch ---
--- 0.5515232086181641 seconds for one epoch ---
--- 0.31458520889282227 seconds for one epoch ---
--- 0.517338752746582 seconds for one epoch ---
--- 0.3305239677429199 seconds for one epoch ---
--- 0.5211327075958252 seconds for one epoch ---
--- 0.31876444816589355 seconds for one epoch ---
--- 0.5183248519897461 seconds for one epoch ---
--- 0.3224050998687744 seconds for one epoch ---
--- 0.558870792388916 seconds for one epoch ---
--- 0.3160538673400879 seconds for one epoch ---
--- 0.5311746597290039 seconds for one epoch ---
--- 0.3431732654571533 seconds for one epoch ---
--- 0.5331995487213135 seconds for one epoch ---
--- 0.3344235420227051 seconds for one epoch ---
--- 0.5649027824401855 seconds for one epoch ---
=========================
[[1.        ]
 [0.9803438 ]
 [0.9968513 ]
 [0.04486949]
 [0.03631819]
 [1.        ]
 [0.07107564]
 [0.01548051]
 [0.0125528 ]
 [1.        ]
 [0.01889815]]
[[ 2.3594627e+00]
 [-5.5180210e-01]
 [ 6.4432544e-01]
 [-1.8861362e-01]
 [-1.7324352e-01]
 [-6.2878156e+00]
 [ 2.1914454e-01]
 [ 7.8219801e-02]
 [ 2.5875156e-03]
 [ 4.5451484e+00]
 [ 1.1073775e-01]]
--- 0.30846381187438965 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11386.2822265625, (7630.3213, 3.0742564, 3592.6323, 2.532379)
   validation loss 1411.7861328125, (826.89, 0.17896764, 424.46188, 2.532379)
decoder loss ratio: 32035.154712, decoder SINDy loss  ratio: 0.916261
THRESHOLDING: 5 active coefficients
--- 0.5253961086273193 seconds for one epoch ---
--- 0.3168346881866455 seconds for one epoch ---
--- 0.5427346229553223 seconds for one epoch ---
--- 0.3070507049560547 seconds for one epoch ---
--- 0.5141727924346924 seconds for one epoch ---
--- 0.3048121929168701 seconds for one epoch ---
--- 0.5462234020233154 seconds for one epoch ---
--- 0.3042032718658447 seconds for one epoch ---
--- 0.5365562438964844 seconds for one epoch ---
--- 0.31383848190307617 seconds for one epoch ---
--- 0.5489122867584229 seconds for one epoch ---
--- 0.3063688278198242 seconds for one epoch ---
--- 0.5535743236541748 seconds for one epoch ---
--- 0.3358888626098633 seconds for one epoch ---
--- 0.5330121517181396 seconds for one epoch ---
--- 0.34010910987854004 seconds for one epoch ---
--- 0.5409247875213623 seconds for one epoch ---
--- 0.3481757640838623 seconds for one epoch ---
--- 0.5512926578521729 seconds for one epoch ---
--- 0.34181761741638184 seconds for one epoch ---
--- 0.5690279006958008 seconds for one epoch ---
--- 0.31690168380737305 seconds for one epoch ---
--- 0.5217742919921875 seconds for one epoch ---
--- 0.3010249137878418 seconds for one epoch ---
=========================
[[1.        ]
 [0.9245442 ]
 [0.01060663]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 3.223131  ]
 [-0.48162127]
 [ 0.01321487]
 [-0.        ]
 [-0.        ]
 [-5.691763  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 5.1803713 ]
 [ 0.        ]]
--- 0.2760491371154785 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 31371.736328125, (23949.676, 9.451937, 7411.599, 1.0089148)
   validation loss 1592.3289794921875, (1076.3296, 0.22035715, 514.77014, 1.0089148)
decoder loss ratio: 41698.876901, decoder SINDy loss  ratio: 1.111204
--- 0.314072847366333 seconds for one epoch ---
--- 0.5404257774353027 seconds for one epoch ---
--- 0.3092334270477295 seconds for one epoch ---
--- 0.5425713062286377 seconds for one epoch ---
--- 0.30881547927856445 seconds for one epoch ---
--- 0.5542528629302979 seconds for one epoch ---
--- 0.3209986686706543 seconds for one epoch ---
--- 0.5410878658294678 seconds for one epoch ---
--- 0.3167133331298828 seconds for one epoch ---
--- 0.5273051261901855 seconds for one epoch ---
--- 0.3265817165374756 seconds for one epoch ---
--- 0.5385499000549316 seconds for one epoch ---
--- 0.3289628028869629 seconds for one epoch ---
--- 0.5518443584442139 seconds for one epoch ---
--- 0.30683112144470215 seconds for one epoch ---
--- 0.5484292507171631 seconds for one epoch ---
--- 0.3007946014404297 seconds for one epoch ---
--- 0.5405170917510986 seconds for one epoch ---
--- 0.3361177444458008 seconds for one epoch ---
--- 0.5538885593414307 seconds for one epoch ---
--- 0.3338747024536133 seconds for one epoch ---
--- 0.5332164764404297 seconds for one epoch ---
--- 0.3296692371368408 seconds for one epoch ---
--- 0.5390625 seconds for one epoch ---
=========================
[[1.        ]
 [0.92314214]
 [0.46261647]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 3.8146515 ]
 [-0.48071122]
 [-0.34838453]
 [-0.        ]
 [-0.        ]
 [-5.339888  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 5.681526  ]
 [ 0.        ]]
--- 0.30024099349975586 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 40850.70703125, (28979.527, 5.212593, 11864.784, 1.1821074)
   validation loss 1948.4954833984375, (1499.354, 0.24037324, 447.71902, 1.1821074)
decoder loss ratio: 58087.577104, decoder SINDy loss  ratio: 0.966464
--- 0.2894105911254883 seconds for one epoch ---
--- 0.3025333881378174 seconds for one epoch ---
--- 0.5757312774658203 seconds for one epoch ---
--- 0.3000142574310303 seconds for one epoch ---
--- 0.5595383644104004 seconds for one epoch ---
--- 0.3089287281036377 seconds for one epoch ---
--- 0.5676968097686768 seconds for one epoch ---
--- 0.3219742774963379 seconds for one epoch ---
--- 0.5470089912414551 seconds for one epoch ---
--- 0.3014638423919678 seconds for one epoch ---
--- 0.5791707038879395 seconds for one epoch ---
--- 0.307384729385376 seconds for one epoch ---
--- 0.5688304901123047 seconds for one epoch ---
--- 0.2965857982635498 seconds for one epoch ---
--- 0.566159725189209 seconds for one epoch ---
--- 0.29233360290527344 seconds for one epoch ---
--- 0.5467629432678223 seconds for one epoch ---
--- 0.3035297393798828 seconds for one epoch ---
--- 0.5468299388885498 seconds for one epoch ---
--- 0.29532456398010254 seconds for one epoch ---
--- 0.5579519271850586 seconds for one epoch ---
--- 0.32376933097839355 seconds for one epoch ---
--- 0.5532500743865967 seconds for one epoch ---
--- 0.3328988552093506 seconds for one epoch ---
=========================
[[1.        ]
 [0.75125986]
 [0.9899388 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 4.2736015 ]
 [-0.4116217 ]
 [-0.58608055]
 [-0.        ]
 [-0.        ]
 [-5.0961795 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.0618553 ]
 [ 0.        ]]
--- 0.2805955410003662 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 33198.90234375, (27368.035, 0.8985836, 5828.747, 1.2233195)
   validation loss 2142.12060546875, (1507.1461, 0.2882601, 633.4629, 1.2233195)
decoder loss ratio: 58389.457138, decoder SINDy loss  ratio: 1.367419
--- 0.30777931213378906 seconds for one epoch ---
--- 0.567908525466919 seconds for one epoch ---
--- 0.3045487403869629 seconds for one epoch ---
--- 0.5622689723968506 seconds for one epoch ---
--- 0.2994420528411865 seconds for one epoch ---
--- 0.5804905891418457 seconds for one epoch ---
--- 0.30477118492126465 seconds for one epoch ---
--- 0.5630612373352051 seconds for one epoch ---
--- 0.31804561614990234 seconds for one epoch ---
--- 0.5678768157958984 seconds for one epoch ---
--- 0.30341386795043945 seconds for one epoch ---
--- 0.5687863826751709 seconds for one epoch ---
--- 0.31414151191711426 seconds for one epoch ---
--- 0.5605912208557129 seconds for one epoch ---
--- 0.2987635135650635 seconds for one epoch ---
--- 0.5448927879333496 seconds for one epoch ---
--- 0.29742932319641113 seconds for one epoch ---
--- 0.5620205402374268 seconds for one epoch ---
--- 0.30049872398376465 seconds for one epoch ---
--- 0.5692908763885498 seconds for one epoch ---
--- 0.301267147064209 seconds for one epoch ---
--- 0.5557899475097656 seconds for one epoch ---
--- 0.30525922775268555 seconds for one epoch ---
--- 0.5876893997192383 seconds for one epoch ---
=========================
[[1.       ]
 [0.7238011]
 [0.9998637]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 4.705954  ]
 [-0.40457684]
 [-0.8024203 ]
 [-0.        ]
 [-0.        ]
 [-4.862968  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.4079394 ]
 [ 0.        ]]
--- 0.3158271312713623 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 19114.77734375, (17652.059, 4.855156, 1456.6364, 1.2265921)
   validation loss 1418.262939453125, (925.94275, 0.27838084, 490.81525, 1.2265921)
decoder loss ratio: 35872.629604, decoder SINDy loss  ratio: 1.059494
--- 0.28124356269836426 seconds for one epoch ---
--- 0.3262217044830322 seconds for one epoch ---
--- 0.590313196182251 seconds for one epoch ---
--- 0.31200313568115234 seconds for one epoch ---
--- 0.5715186595916748 seconds for one epoch ---
--- 0.3116734027862549 seconds for one epoch ---
--- 0.5939955711364746 seconds for one epoch ---
--- 0.3031167984008789 seconds for one epoch ---
--- 0.6083159446716309 seconds for one epoch ---
--- 0.30925774574279785 seconds for one epoch ---
--- 0.5795266628265381 seconds for one epoch ---
--- 0.29749011993408203 seconds for one epoch ---
--- 0.6208503246307373 seconds for one epoch ---
--- 0.30474424362182617 seconds for one epoch ---
--- 0.604144811630249 seconds for one epoch ---
--- 0.31888437271118164 seconds for one epoch ---
--- 0.5738692283630371 seconds for one epoch ---
--- 0.31645941734313965 seconds for one epoch ---
--- 0.594935417175293 seconds for one epoch ---
--- 0.3017544746398926 seconds for one epoch ---
--- 0.585329532623291 seconds for one epoch ---
--- 0.2955937385559082 seconds for one epoch ---
--- 0.6055529117584229 seconds for one epoch ---
--- 0.31005096435546875 seconds for one epoch ---
=========================
[[1.       ]
 [0.6570887]
 [0.9999932]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 5.029882  ]
 [-0.38894662]
 [-0.94582766]
 [-0.        ]
 [-0.        ]
 [-4.6743326 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.6217012 ]
 [ 0.        ]]
--- 0.272871732711792 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 33328.7421875, (28902.996, 10.244665, 4414.296, 1.207391)
   validation loss 1265.5374755859375, (851.1637, 0.2443622, 412.92206, 1.207391)
decoder loss ratio: 32975.559279, decoder SINDy loss  ratio: 0.891350
--- 0.3253164291381836 seconds for one epoch ---
--- 0.6066362857818604 seconds for one epoch ---
--- 0.4405548572540283 seconds for one epoch ---
--- 0.6046268939971924 seconds for one epoch ---
--- 0.31458067893981934 seconds for one epoch ---
--- 0.5882761478424072 seconds for one epoch ---
--- 0.3084871768951416 seconds for one epoch ---
--- 0.5738718509674072 seconds for one epoch ---
--- 0.3013179302215576 seconds for one epoch ---
--- 0.5820879936218262 seconds for one epoch ---
--- 0.3235743045806885 seconds for one epoch ---
--- 0.6328423023223877 seconds for one epoch ---
--- 0.3258237838745117 seconds for one epoch ---
--- 0.5952847003936768 seconds for one epoch ---
--- 0.337399959564209 seconds for one epoch ---
--- 0.5992677211761475 seconds for one epoch ---
--- 0.3009042739868164 seconds for one epoch ---
--- 0.5773565769195557 seconds for one epoch ---
--- 0.3015129566192627 seconds for one epoch ---
--- 0.6008379459381104 seconds for one epoch ---
--- 0.3036026954650879 seconds for one epoch ---
--- 0.595491886138916 seconds for one epoch ---
--- 0.3044869899749756 seconds for one epoch ---
--- 0.5925531387329102 seconds for one epoch ---
=========================
[[1.        ]
 [0.4106106 ]
 [0.99999595]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 5.312736 ]
 [-0.3382016]
 [-1.0548224]
 [-0.       ]
 [-0.       ]
 [-4.492513 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 6.7672186]
 [ 0.       ]]
--- 0.29524779319763184 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 23932.3125, (17764.18, 4.0068974, 6162.9365, 1.1878344)
   validation loss 1072.0277099609375, (672.3237, 0.28675827, 398.22943, 1.1878344)
decoder loss ratio: 26046.988524, decoder SINDy loss  ratio: 0.859634
--- 0.2764270305633545 seconds for one epoch ---
--- 0.3057680130004883 seconds for one epoch ---
--- 0.5976917743682861 seconds for one epoch ---
--- 0.2882113456726074 seconds for one epoch ---
--- 0.5767641067504883 seconds for one epoch ---
--- 0.3000473976135254 seconds for one epoch ---
--- 0.6112194061279297 seconds for one epoch ---
--- 0.2996199131011963 seconds for one epoch ---
--- 0.6000926494598389 seconds for one epoch ---
--- 0.3017725944519043 seconds for one epoch ---
--- 0.5985627174377441 seconds for one epoch ---
--- 0.3022286891937256 seconds for one epoch ---
--- 0.6416559219360352 seconds for one epoch ---
--- 0.29560375213623047 seconds for one epoch ---
--- 0.604297399520874 seconds for one epoch ---
--- 0.3014955520629883 seconds for one epoch ---
--- 0.6098353862762451 seconds for one epoch ---
--- 0.29897308349609375 seconds for one epoch ---
--- 0.5973508358001709 seconds for one epoch ---
--- 0.31586623191833496 seconds for one epoch ---
--- 0.6139578819274902 seconds for one epoch ---
--- 0.34642505645751953 seconds for one epoch ---
--- 0.6130406856536865 seconds for one epoch ---
--- 0.3410494327545166 seconds for one epoch ---
=========================
[[1.       ]
 [0.2812854]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 5.5756693 ]
 [-0.30925235]
 [-1.1724308 ]
 [-0.        ]
 [-0.        ]
 [-4.2922907 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.8423653 ]
 [ 0.        ]]
--- 0.27366042137145996 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11662.458984375, (8438.523, 10.689937, 3212.0798, 1.1661032)
   validation loss 1930.8310546875, (1500.545, 0.34442005, 428.77554, 1.1661032)
decoder loss ratio: 58133.720063, decoder SINDy loss  ratio: 0.925572
--- 0.3272855281829834 seconds for one epoch ---
--- 0.6185517311096191 seconds for one epoch ---
--- 0.33833789825439453 seconds for one epoch ---
--- 0.6177456378936768 seconds for one epoch ---
--- 0.3288271427154541 seconds for one epoch ---
--- 0.6303091049194336 seconds for one epoch ---
--- 0.3358113765716553 seconds for one epoch ---
--- 0.6435954570770264 seconds for one epoch ---
--- 0.33786892890930176 seconds for one epoch ---
--- 0.6316919326782227 seconds for one epoch ---
--- 0.329362154006958 seconds for one epoch ---
--- 0.6393716335296631 seconds for one epoch ---
--- 0.3189840316772461 seconds for one epoch ---
--- 0.6265366077423096 seconds for one epoch ---
--- 0.30150508880615234 seconds for one epoch ---
--- 0.6223499774932861 seconds for one epoch ---
--- 0.3063986301422119 seconds for one epoch ---
--- 0.6003594398498535 seconds for one epoch ---
--- 0.3162968158721924 seconds for one epoch ---
--- 0.616776704788208 seconds for one epoch ---
--- 0.30290746688842773 seconds for one epoch ---
--- 0.6277952194213867 seconds for one epoch ---
--- 0.2984588146209717 seconds for one epoch ---
--- 0.6242845058441162 seconds for one epoch ---
=========================
[[1.        ]
 [0.33259997]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 5.832196  ]
 [-0.32150406]
 [-1.361892  ]
 [-0.        ]
 [-0.        ]
 [-4.075168  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.8596344 ]
 [ 0.        ]]
--- 0.31503891944885254 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 16086.9462890625, (12728.897, 1.441422, 3355.4329, 1.1744534)
   validation loss 2023.6983642578125, (1569.8092, 0.33101648, 452.38364, 1.1744534)
decoder loss ratio: 60817.133876, decoder SINDy loss  ratio: 0.976534
--- 0.2645268440246582 seconds for one epoch ---
--- 0.31980085372924805 seconds for one epoch ---
--- 0.6179084777832031 seconds for one epoch ---
--- 0.3310055732727051 seconds for one epoch ---
--- 0.6076464653015137 seconds for one epoch ---
--- 0.3307209014892578 seconds for one epoch ---
--- 0.6100847721099854 seconds for one epoch ---
--- 0.3291811943054199 seconds for one epoch ---
--- 0.6390833854675293 seconds for one epoch ---
--- 0.32984185218811035 seconds for one epoch ---
--- 0.6318566799163818 seconds for one epoch ---
--- 0.3299837112426758 seconds for one epoch ---
--- 0.6280598640441895 seconds for one epoch ---
--- 0.3113861083984375 seconds for one epoch ---
--- 0.6188666820526123 seconds for one epoch ---
--- 0.2937355041503906 seconds for one epoch ---
--- 0.6434681415557861 seconds for one epoch ---
--- 0.30887651443481445 seconds for one epoch ---
--- 0.6273384094238281 seconds for one epoch ---
--- 0.3027639389038086 seconds for one epoch ---
--- 0.6539406776428223 seconds for one epoch ---
--- 0.30262041091918945 seconds for one epoch ---
--- 0.6569161415100098 seconds for one epoch ---
--- 0.30712461471557617 seconds for one epoch ---
=========================
[[1.        ]
 [0.35249072]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 5.9423413 ]
 [-0.32600972]
 [-1.4441823 ]
 [-0.        ]
 [-0.        ]
 [-3.9652398 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.7656546 ]
 [ 0.        ]]
--- 0.26332592964172363 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 39409.81640625, (32212.186, 52.908688, 7143.5444, 1.1783767)
   validation loss 3670.455810546875, (3218.8555, 0.26593354, 450.15594, 1.1783767)
decoder loss ratio: 124704.049038, decoder SINDy loss  ratio: 0.971725
--- 0.30235767364501953 seconds for one epoch ---
--- 0.6258420944213867 seconds for one epoch ---
--- 0.30808258056640625 seconds for one epoch ---
--- 0.6338601112365723 seconds for one epoch ---
--- 0.3195011615753174 seconds for one epoch ---
--- 0.637479305267334 seconds for one epoch ---
--- 0.30414247512817383 seconds for one epoch ---
--- 0.6377677917480469 seconds for one epoch ---
--- 0.33835935592651367 seconds for one epoch ---
--- 0.6341218948364258 seconds for one epoch ---
--- 0.3082892894744873 seconds for one epoch ---
--- 0.6322927474975586 seconds for one epoch ---
--- 0.30109167098999023 seconds for one epoch ---
--- 0.6368124485015869 seconds for one epoch ---
--- 0.3059389591217041 seconds for one epoch ---
--- 0.6459841728210449 seconds for one epoch ---
--- 0.3166625499725342 seconds for one epoch ---
--- 0.6486248970031738 seconds for one epoch ---
--- 0.3423335552215576 seconds for one epoch ---
--- 0.6660716533660889 seconds for one epoch ---
--- 0.33813929557800293 seconds for one epoch ---
--- 0.6683120727539062 seconds for one epoch ---
--- 0.31794118881225586 seconds for one epoch ---
--- 0.6492564678192139 seconds for one epoch ---
=========================
[[1.        ]
 [0.59929746]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 6.1211767]
 [-0.3767354]
 [-1.5944195]
 [-0.       ]
 [-0.       ]
 [-3.7651951]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 6.666903 ]
 [ 0.       ]]
--- 0.29936695098876953 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18257.59375, (14564.193, 5.4015985, 3686.7927, 1.2076677)
   validation loss 1574.8441162109375, (1157.7529, 0.17560013, 415.70792, 1.2076677)
decoder loss ratio: 44853.358444, decoder SINDy loss  ratio: 0.897364
--- 0.2835850715637207 seconds for one epoch ---
--- 0.30654287338256836 seconds for one epoch ---
--- 0.6503181457519531 seconds for one epoch ---
--- 0.30772995948791504 seconds for one epoch ---
--- 0.6503572463989258 seconds for one epoch ---
--- 0.31182146072387695 seconds for one epoch ---
--- 0.6392335891723633 seconds for one epoch ---
--- 0.29250097274780273 seconds for one epoch ---
--- 0.6497476100921631 seconds for one epoch ---
--- 0.30210280418395996 seconds for one epoch ---
--- 0.6385278701782227 seconds for one epoch ---
--- 0.3072226047515869 seconds for one epoch ---
--- 0.6324365139007568 seconds for one epoch ---
--- 0.3098781108856201 seconds for one epoch ---
--- 0.6511118412017822 seconds for one epoch ---
--- 0.3205084800720215 seconds for one epoch ---
--- 0.6421468257904053 seconds for one epoch ---
--- 0.3378572463989258 seconds for one epoch ---
--- 0.6499893665313721 seconds for one epoch ---
--- 0.34714412689208984 seconds for one epoch ---
--- 0.6556696891784668 seconds for one epoch ---
--- 0.31250476837158203 seconds for one epoch ---
--- 0.6551158428192139 seconds for one epoch ---
--- 0.3490869998931885 seconds for one epoch ---
=========================
[[1.        ]
 [0.40898487]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 6.207199  ]
 [-0.33813745]
 [-1.7180067 ]
 [-0.        ]
 [-0.        ]
 [-3.6121314 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.4837236 ]
 [ 0.        ]]
--- 0.27899932861328125 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7155.3681640625, (6168.0234, 2.0996318, 984.05835, 1.1865556)
   validation loss 1844.4674072265625, (1468.3005, 0.18379392, 374.79654, 1.1865556)
decoder loss ratio: 56884.511889, decoder SINDy loss  ratio: 0.809051
--- 0.3240203857421875 seconds for one epoch ---
--- 0.6442720890045166 seconds for one epoch ---
--- 0.3187854290008545 seconds for one epoch ---
--- 0.6863646507263184 seconds for one epoch ---
--- 0.3118741512298584 seconds for one epoch ---
--- 0.6860702037811279 seconds for one epoch ---
--- 0.3060884475708008 seconds for one epoch ---
--- 0.6492292881011963 seconds for one epoch ---
--- 0.30304384231567383 seconds for one epoch ---
--- 0.660750150680542 seconds for one epoch ---
--- 0.30304718017578125 seconds for one epoch ---
--- 0.6404428482055664 seconds for one epoch ---
--- 0.3057096004486084 seconds for one epoch ---
--- 0.651395320892334 seconds for one epoch ---
--- 0.301455020904541 seconds for one epoch ---
--- 0.6725764274597168 seconds for one epoch ---
--- 0.29605650901794434 seconds for one epoch ---
--- 0.671694278717041 seconds for one epoch ---
--- 0.32204675674438477 seconds for one epoch ---
--- 0.6619303226470947 seconds for one epoch ---
--- 0.29628729820251465 seconds for one epoch ---
--- 0.672417402267456 seconds for one epoch ---
--- 0.3049886226654053 seconds for one epoch ---
--- 0.654118537902832 seconds for one epoch ---
=========================
[[1.       ]
 [0.5775426]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 6.294987  ]
 [-0.37228066]
 [-1.8639017 ]
 [-0.        ]
 [-0.        ]
 [-3.4089718 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.2735977 ]
 [ 0.        ]]
--- 0.3234422206878662 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 24243.6328125, (18869.84, 9.4593115, 5363.1265, 1.2074307)
   validation loss 1935.7574462890625, (1512.1208, 0.20642048, 422.22275, 1.2074307)
decoder loss ratio: 58582.186871, decoder SINDy loss  ratio: 0.911427
--- 0.28006887435913086 seconds for one epoch ---
--- 0.3416571617126465 seconds for one epoch ---
--- 0.674612283706665 seconds for one epoch ---
--- 0.3441774845123291 seconds for one epoch ---
--- 0.684473991394043 seconds for one epoch ---
--- 0.2991628646850586 seconds for one epoch ---
--- 0.6752743721008301 seconds for one epoch ---
--- 0.29685378074645996 seconds for one epoch ---
--- 0.6602320671081543 seconds for one epoch ---
--- 0.29508018493652344 seconds for one epoch ---
--- 0.6572329998016357 seconds for one epoch ---
--- 0.3314054012298584 seconds for one epoch ---
--- 0.680006742477417 seconds for one epoch ---
--- 0.3276650905609131 seconds for one epoch ---
--- 0.7067728042602539 seconds for one epoch ---
--- 0.32185888290405273 seconds for one epoch ---
--- 0.6929953098297119 seconds for one epoch ---
--- 0.3083689212799072 seconds for one epoch ---
--- 0.707658052444458 seconds for one epoch ---
--- 0.30699634552001953 seconds for one epoch ---
--- 0.6951110363006592 seconds for one epoch ---
--- 0.3149070739746094 seconds for one epoch ---
--- 0.6924707889556885 seconds for one epoch ---
--- 0.30381083488464355 seconds for one epoch ---
=========================
[[1.       ]
 [0.4632252]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 6.358137  ]
 [-0.34925556]
 [-1.9815807 ]
 [-0.        ]
 [-0.        ]
 [-3.2207515 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 6.065633  ]
 [ 0.        ]]
--- 0.2651958465576172 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 20683.5390625, (15268.579, 2.1703498, 5411.596, 1.1933041)
   validation loss 1573.432373046875, (1174.562, 0.16398285, 397.5131, 1.1933041)
decoder loss ratio: 45504.571463, decoder SINDy loss  ratio: 0.858088
--- 0.32938122749328613 seconds for one epoch ---
--- 0.6678431034088135 seconds for one epoch ---
--- 0.3148643970489502 seconds for one epoch ---
--- 0.6757359504699707 seconds for one epoch ---
--- 0.2967643737792969 seconds for one epoch ---
--- 0.6574656963348389 seconds for one epoch ---
--- 0.3020956516265869 seconds for one epoch ---
--- 0.6638407707214355 seconds for one epoch ---
--- 0.29792213439941406 seconds for one epoch ---
--- 0.6621992588043213 seconds for one epoch ---
--- 0.31889891624450684 seconds for one epoch ---
--- 0.6878502368927002 seconds for one epoch ---
--- 0.31381654739379883 seconds for one epoch ---
--- 0.6839134693145752 seconds for one epoch ---
--- 0.3219313621520996 seconds for one epoch ---
--- 0.6987488269805908 seconds for one epoch ---
--- 0.3328864574432373 seconds for one epoch ---
--- 0.6898703575134277 seconds for one epoch ---
--- 0.3200235366821289 seconds for one epoch ---
--- 0.7048032283782959 seconds for one epoch ---
--- 0.3461110591888428 seconds for one epoch ---
--- 0.6746785640716553 seconds for one epoch ---
--- 0.32210803031921387 seconds for one epoch ---
--- 0.7051293849945068 seconds for one epoch ---
=========================
[[1.        ]
 [0.69508636]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 6.3907514]
 [-0.3979126]
 [-2.030891 ]
 [-0.       ]
 [-0.       ]
 [-3.0724196]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 5.8609333]
 [ 0.       ]]
--- 0.29392290115356445 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14121.28515625, (10354.53, 3.6929402, 3761.8452, 1.217111)
   validation loss 1303.3387451171875, (880.8093, 0.14461292, 421.1677, 1.217111)
decoder loss ratio: 34124.082448, decoder SINDy loss  ratio: 0.909150
--- 0.2654252052307129 seconds for one epoch ---
--- 0.3113372325897217 seconds for one epoch ---
--- 0.6761636734008789 seconds for one epoch ---
--- 0.29902124404907227 seconds for one epoch ---
--- 0.6980018615722656 seconds for one epoch ---
--- 0.29703259468078613 seconds for one epoch ---
--- 0.6923134326934814 seconds for one epoch ---
--- 0.2984137535095215 seconds for one epoch ---
--- 0.6951084136962891 seconds for one epoch ---
--- 0.2978346347808838 seconds for one epoch ---
--- 0.7202610969543457 seconds for one epoch ---
--- 0.2964901924133301 seconds for one epoch ---
--- 0.7037582397460938 seconds for one epoch ---
--- 0.2996938228607178 seconds for one epoch ---
--- 0.7124652862548828 seconds for one epoch ---
--- 0.30162525177001953 seconds for one epoch ---
--- 0.6841590404510498 seconds for one epoch ---
--- 0.30280256271362305 seconds for one epoch ---
--- 0.7104892730712891 seconds for one epoch ---
--- 0.2977609634399414 seconds for one epoch ---
--- 0.6995153427124023 seconds for one epoch ---
--- 0.2978534698486328 seconds for one epoch ---
--- 0.690319299697876 seconds for one epoch ---
--- 0.3030421733856201 seconds for one epoch ---
=========================
[[1.       ]
 [0.5079645]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 6.412726  ]
 [-0.35826465]
 [-2.1316395 ]
 [-0.        ]
 [-0.        ]
 [-2.8499615 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 5.574052  ]
 [ 0.        ]]
--- 0.2999138832092285 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 24639.76171875, (22643.746, 1.922557, 1992.9028, 1.1912261)
   validation loss 4301.18408203125, (3874.4712, 0.18361475, 425.33804, 1.1912261)
decoder loss ratio: 150103.740333, decoder SINDy loss  ratio: 0.918152
--- 0.3239321708679199 seconds for one epoch ---
--- 0.6932125091552734 seconds for one epoch ---
--- 0.29822516441345215 seconds for one epoch ---
--- 0.6945180892944336 seconds for one epoch ---
--- 0.30301761627197266 seconds for one epoch ---
--- 0.7033038139343262 seconds for one epoch ---
--- 0.29230165481567383 seconds for one epoch ---
--- 0.7054243087768555 seconds for one epoch ---
--- 0.3205873966217041 seconds for one epoch ---
--- 0.7224512100219727 seconds for one epoch ---
--- 0.34011173248291016 seconds for one epoch ---
--- 0.7108421325683594 seconds for one epoch ---
--- 0.3335909843444824 seconds for one epoch ---
--- 0.6940999031066895 seconds for one epoch ---
--- 0.33990955352783203 seconds for one epoch ---
--- 0.7322039604187012 seconds for one epoch ---
--- 0.3327212333679199 seconds for one epoch ---
--- 0.7249634265899658 seconds for one epoch ---
--- 0.3381829261779785 seconds for one epoch ---
--- 0.7195408344268799 seconds for one epoch ---
--- 0.3254852294921875 seconds for one epoch ---
--- 0.732759952545166 seconds for one epoch ---
--- 0.3416116237640381 seconds for one epoch ---
--- 0.7289516925811768 seconds for one epoch ---
=========================
[[1.       ]
 [0.7565516]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 6.204384  ]
 [-0.41344118]
 [-2.1474338 ]
 [-0.        ]
 [-0.        ]
 [-2.6643157 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 5.0633726 ]
 [ 0.        ]]
--- 0.30571937561035156 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7905.41796875, (3606.1501, 2.5470307, 4295.506, 1.2148032)
   validation loss 2055.824951171875, (1580.4291, 0.18834715, 473.99265, 1.2148032)
decoder loss ratio: 61228.566194, decoder SINDy loss  ratio: 1.023180
--- 0.26428961753845215 seconds for one epoch ---
--- 0.30287623405456543 seconds for one epoch ---
--- 0.704169750213623 seconds for one epoch ---
--- 0.29866886138916016 seconds for one epoch ---
--- 0.693124532699585 seconds for one epoch ---
--- 0.3067891597747803 seconds for one epoch ---
--- 0.7100217342376709 seconds for one epoch ---
--- 0.3089287281036377 seconds for one epoch ---
--- 0.737973690032959 seconds for one epoch ---
--- 0.3084080219268799 seconds for one epoch ---
--- 0.7203168869018555 seconds for one epoch ---
--- 0.30396175384521484 seconds for one epoch ---
--- 0.735029935836792 seconds for one epoch ---
--- 0.46320605278015137 seconds for one epoch ---
--- 0.7136032581329346 seconds for one epoch ---
--- 0.3325686454772949 seconds for one epoch ---
--- 0.7340290546417236 seconds for one epoch ---
--- 0.3236260414123535 seconds for one epoch ---
--- 0.7529659271240234 seconds for one epoch ---
--- 0.3233964443206787 seconds for one epoch ---
--- 0.7395250797271729 seconds for one epoch ---
--- 0.33742213249206543 seconds for one epoch ---
--- 0.7444260120391846 seconds for one epoch ---
--- 0.3276646137237549 seconds for one epoch ---
=========================
[[1.       ]
 [0.9446795]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 5.8215103 ]
 [-0.49872544]
 [-1.9546614 ]
 [-0.        ]
 [-0.        ]
 [-2.593401  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 4.490959  ]
 [ 0.        ]]
--- 0.2670116424560547 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5195.859375, (2847.6692, 2.776746, 2344.1797, 1.2332743)
   validation loss 1046.4234619140625, (648.90924, 0.2188813, 396.062, 1.2332743)
decoder loss ratio: 25139.870542, decoder SINDy loss  ratio: 0.854956
--- 0.31811094284057617 seconds for one epoch ---
--- 0.712578535079956 seconds for one epoch ---
--- 0.30400776863098145 seconds for one epoch ---
--- 0.7207696437835693 seconds for one epoch ---
--- 0.3026413917541504 seconds for one epoch ---
--- 0.7223784923553467 seconds for one epoch ---
--- 0.3017923831939697 seconds for one epoch ---
--- 0.7336785793304443 seconds for one epoch ---
--- 0.3133275508880615 seconds for one epoch ---
--- 0.7192943096160889 seconds for one epoch ---
--- 0.315690279006958 seconds for one epoch ---
--- 0.7321860790252686 seconds for one epoch ---
--- 0.2984778881072998 seconds for one epoch ---
--- 0.7178881168365479 seconds for one epoch ---
--- 0.32317686080932617 seconds for one epoch ---
--- 0.741593599319458 seconds for one epoch ---
--- 0.28575611114501953 seconds for one epoch ---
--- 0.7210633754730225 seconds for one epoch ---
--- 0.32627415657043457 seconds for one epoch ---
--- 0.7372777462005615 seconds for one epoch ---
--- 0.3321983814239502 seconds for one epoch ---
--- 0.7456502914428711 seconds for one epoch ---
--- 0.32539868354797363 seconds for one epoch ---
--- 0.7391400337219238 seconds for one epoch ---
=========================
[[1.       ]
 [0.9833138]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 5.4865313]
 [-0.560727 ]
 [-1.7216055]
 [-0.       ]
 [-0.       ]
 [-2.5285938]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 4.0084553]
 [ 0.       ]]
--- 0.29608678817749023 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6096.091796875, (3158.3118, 1.83435, 2934.7158, 1.2298876)
   validation loss 1328.5125732421875, (900.2945, 0.14459819, 426.84366, 1.2298876)
decoder loss ratio: 34878.971702, decoder SINDy loss  ratio: 0.921402
--- 0.27005457878112793 seconds for one epoch ---
--- 0.300642728805542 seconds for one epoch ---
--- 0.7148559093475342 seconds for one epoch ---
--- 0.32120513916015625 seconds for one epoch ---
--- 0.7497916221618652 seconds for one epoch ---
--- 0.33245015144348145 seconds for one epoch ---
--- 0.7646670341491699 seconds for one epoch ---
--- 0.3410773277282715 seconds for one epoch ---
--- 0.7520899772644043 seconds for one epoch ---
--- 0.3183939456939697 seconds for one epoch ---
--- 0.7481307983398438 seconds for one epoch ---
--- 0.3118705749511719 seconds for one epoch ---
--- 0.7684097290039062 seconds for one epoch ---
--- 0.30270886421203613 seconds for one epoch ---
--- 0.763422966003418 seconds for one epoch ---
--- 0.3137331008911133 seconds for one epoch ---
--- 0.7645061016082764 seconds for one epoch ---
--- 0.3074376583099365 seconds for one epoch ---
--- 0.7450721263885498 seconds for one epoch ---
--- 0.3289158344268799 seconds for one epoch ---
--- 0.7390637397766113 seconds for one epoch ---
--- 0.32566118240356445 seconds for one epoch ---
--- 0.7641251087188721 seconds for one epoch ---
--- 0.328671932220459 seconds for one epoch ---
=========================
[[1.       ]
 [0.9953727]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 5.1394205 ]
 [-0.62555075]
 [-1.5403075 ]
 [-0.        ]
 [-0.        ]
 [-2.446534  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 3.510119  ]
 [ 0.        ]]
--- 0.2683830261230469 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4823.14794921875, (2451.0032, 3.830706, 2367.089, 1.2249826)
   validation loss 1077.4949951171875, (704.62726, 0.12987654, 371.51282, 1.2249826)
decoder loss ratio: 27298.483273, decoder SINDy loss  ratio: 0.801963
--- 0.29978442192077637 seconds for one epoch ---
--- 0.7245066165924072 seconds for one epoch ---
--- 0.31005382537841797 seconds for one epoch ---
--- 0.7176923751831055 seconds for one epoch ---
--- 0.29772138595581055 seconds for one epoch ---
--- 0.751328706741333 seconds for one epoch ---
--- 0.29981184005737305 seconds for one epoch ---
--- 0.7328078746795654 seconds for one epoch ---
--- 0.30491185188293457 seconds for one epoch ---
--- 0.7483241558074951 seconds for one epoch ---
--- 0.3229258060455322 seconds for one epoch ---
--- 0.7543478012084961 seconds for one epoch ---
--- 0.33090829849243164 seconds for one epoch ---
--- 0.7639813423156738 seconds for one epoch ---
--- 0.32146763801574707 seconds for one epoch ---
--- 0.7561635971069336 seconds for one epoch ---
--- 0.31873226165771484 seconds for one epoch ---
--- 0.7657995223999023 seconds for one epoch ---
--- 0.30635619163513184 seconds for one epoch ---
--- 0.757899284362793 seconds for one epoch ---
--- 0.3172738552093506 seconds for one epoch ---
--- 0.7685086727142334 seconds for one epoch ---
--- 0.33106017112731934 seconds for one epoch ---
--- 0.7479841709136963 seconds for one epoch ---
=========================
[[1.        ]
 [0.99804986]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 4.786525  ]
 [-0.66896904]
 [-1.3516362 ]
 [-0.        ]
 [-0.        ]
 [-2.373629  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 3.008224  ]
 [ 0.        ]]
--- 0.29436182975769043 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5035.68603515625, (2328.5842, 2.7678342, 2703.1147, 1.2193893)
   validation loss 1032.2056884765625, (668.487, 0.1717235, 362.3276, 1.2193893)
decoder loss ratio: 25898.346906, decoder SINDy loss  ratio: 0.782135
THRESHOLDING: 5 active coefficients
--- 0.7671816349029541 seconds for one epoch ---
--- 0.34497714042663574 seconds for one epoch ---
--- 0.7602334022521973 seconds for one epoch ---
--- 0.3323659896850586 seconds for one epoch ---
--- 0.763312816619873 seconds for one epoch ---
--- 0.340501070022583 seconds for one epoch ---
--- 0.7546498775482178 seconds for one epoch ---
--- 0.33580803871154785 seconds for one epoch ---
--- 0.7486083507537842 seconds for one epoch ---
--- 0.3310425281524658 seconds for one epoch ---
--- 0.7795548439025879 seconds for one epoch ---
--- 0.34258365631103516 seconds for one epoch ---
--- 0.7832751274108887 seconds for one epoch ---
--- 0.3482027053833008 seconds for one epoch ---
--- 0.7787597179412842 seconds for one epoch ---
--- 0.3316206932067871 seconds for one epoch ---
--- 0.808032751083374 seconds for one epoch ---
--- 0.322922945022583 seconds for one epoch ---
--- 0.7687313556671143 seconds for one epoch ---
--- 0.2993152141571045 seconds for one epoch ---
--- 0.7712407112121582 seconds for one epoch ---
--- 0.29785633087158203 seconds for one epoch ---
--- 0.7806422710418701 seconds for one epoch ---
--- 0.3022599220275879 seconds for one epoch ---
=========================
[[1.        ]
 [0.99939275]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 4.4728994]
 [-0.7274913]
 [-1.2292678]
 [-0.       ]
 [-0.       ]
 [-2.2816093]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 2.5467787]
 [-0.       ]]
--- 0.26134681701660156 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2826.622314453125, (1101.9213, 1.8377328, 1721.6884, 1.1749753)
   validation loss 1124.4447021484375, (733.8418, 0.11104409, 389.31702, 1.1749753)
decoder loss ratio: 28430.305216, decoder SINDy loss  ratio: 0.840396
--- 0.31414365768432617 seconds for one epoch ---
--- 0.7556717395782471 seconds for one epoch ---
--- 0.3229978084564209 seconds for one epoch ---
--- 0.801572322845459 seconds for one epoch ---
--- 0.3329939842224121 seconds for one epoch ---
--- 0.7755851745605469 seconds for one epoch ---
--- 0.30235743522644043 seconds for one epoch ---
--- 0.7754855155944824 seconds for one epoch ---
--- 0.29096436500549316 seconds for one epoch ---
--- 0.7586424350738525 seconds for one epoch ---
--- 0.30933189392089844 seconds for one epoch ---
--- 0.7557525634765625 seconds for one epoch ---
--- 0.31330251693725586 seconds for one epoch ---
--- 0.7841007709503174 seconds for one epoch ---
--- 0.30065298080444336 seconds for one epoch ---
--- 0.7831070423126221 seconds for one epoch ---
--- 0.30179691314697266 seconds for one epoch ---
--- 0.7763190269470215 seconds for one epoch ---
--- 0.3106555938720703 seconds for one epoch ---
--- 0.7968065738677979 seconds for one epoch ---
--- 0.3055295944213867 seconds for one epoch ---
--- 0.7689604759216309 seconds for one epoch ---
--- 0.3063490390777588 seconds for one epoch ---
--- 0.7871673107147217 seconds for one epoch ---
=========================
[[1.        ]
 [0.9988868 ]
 [0.99999714]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 4.1818423]
 [-0.6970951]
 [-1.1036606]
 [-0.       ]
 [-0.       ]
 [-2.1997702]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 2.114583 ]
 [-0.       ]]
--- 0.3336515426635742 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6396.00537109375, (2285.9287, 1.9135933, 4106.9917, 1.1712115)
   validation loss 1086.2623291015625, (729.4048, 0.16472992, 355.5215, 1.1712115)
decoder loss ratio: 28258.407679, decoder SINDy loss  ratio: 0.767443
--- 0.2788524627685547 seconds for one epoch ---
--- 0.3367033004760742 seconds for one epoch ---
--- 0.8056519031524658 seconds for one epoch ---
--- 0.33963918685913086 seconds for one epoch ---
--- 0.8064389228820801 seconds for one epoch ---
--- 0.336669921875 seconds for one epoch ---
--- 0.8030111789703369 seconds for one epoch ---
--- 0.3410074710845947 seconds for one epoch ---
--- 0.7877635955810547 seconds for one epoch ---
--- 0.326214075088501 seconds for one epoch ---
--- 0.7734992504119873 seconds for one epoch ---
--- 0.334230899810791 seconds for one epoch ---
--- 0.7828238010406494 seconds for one epoch ---
--- 0.2975292205810547 seconds for one epoch ---
--- 0.7708778381347656 seconds for one epoch ---
--- 0.2939004898071289 seconds for one epoch ---
--- 0.7899682521820068 seconds for one epoch ---
--- 0.2989232540130615 seconds for one epoch ---
--- 0.7780656814575195 seconds for one epoch ---
--- 0.30500268936157227 seconds for one epoch ---
--- 0.774712324142456 seconds for one epoch ---
--- 0.28944873809814453 seconds for one epoch ---
--- 0.8041677474975586 seconds for one epoch ---
--- 0.2992217540740967 seconds for one epoch ---
=========================
[[1.        ]
 [0.99891675]
 [0.99999493]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 3.8723388]
 [-0.6984424]
 [-1.0095518]
 [-0.       ]
 [-0.       ]
 [-2.152413 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 1.6659532]
 [-0.       ]]
--- 0.2771298885345459 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3567.8544921875, (1523.7551, 0.946583, 2041.985, 1.1679584)
   validation loss 1535.973876953125, (1206.4176, 0.16609599, 328.22214, 1.1679584)
decoder loss ratio: 46738.712355, decoder SINDy loss  ratio: 0.708514
--- 0.34036779403686523 seconds for one epoch ---
--- 0.8223061561584473 seconds for one epoch ---
--- 0.32123494148254395 seconds for one epoch ---
--- 0.7972126007080078 seconds for one epoch ---
--- 0.3144059181213379 seconds for one epoch ---
--- 0.7921416759490967 seconds for one epoch ---
--- 0.313739538192749 seconds for one epoch ---
--- 0.7946634292602539 seconds for one epoch ---
--- 0.3126804828643799 seconds for one epoch ---
--- 0.8043222427368164 seconds for one epoch ---
--- 0.3102586269378662 seconds for one epoch ---
--- 0.8031198978424072 seconds for one epoch ---
--- 0.30321431159973145 seconds for one epoch ---
--- 0.8105714321136475 seconds for one epoch ---
--- 0.3080711364746094 seconds for one epoch ---
--- 0.8099076747894287 seconds for one epoch ---
--- 0.29326915740966797 seconds for one epoch ---
--- 0.8163447380065918 seconds for one epoch ---
--- 0.30659914016723633 seconds for one epoch ---
--- 0.7983944416046143 seconds for one epoch ---
--- 0.29663896560668945 seconds for one epoch ---
--- 0.8090305328369141 seconds for one epoch ---
--- 0.3134934902191162 seconds for one epoch ---
--- 0.8071660995483398 seconds for one epoch ---
=========================
[[1.       ]
 [0.9987472]
 [0.9999847]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 3.5972488 ]
 [-0.6911764 ]
 [-0.92899567]
 [-0.        ]
 [-0.        ]
 [-2.105203  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 1.2650259 ]
 [-0.        ]]
--- 0.33716368675231934 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3750.281982421875, (1380.8326, 1.2495817, 2367.0344, 1.165358)
   validation loss 1082.1923828125, (752.5483, 0.14340784, 328.33524, 1.165358)
decoder loss ratio: 29155.026802, decoder SINDy loss  ratio: 0.708758
--- 0.2790687084197998 seconds for one epoch ---
--- 0.33434629440307617 seconds for one epoch ---
--- 0.8202733993530273 seconds for one epoch ---
--- 0.33344554901123047 seconds for one epoch ---
--- 0.828418493270874 seconds for one epoch ---
--- 0.33640456199645996 seconds for one epoch ---
--- 0.811089277267456 seconds for one epoch ---
--- 0.3329799175262451 seconds for one epoch ---
--- 0.82509446144104 seconds for one epoch ---
--- 0.32024717330932617 seconds for one epoch ---
--- 0.8196718692779541 seconds for one epoch ---
--- 0.3177311420440674 seconds for one epoch ---
--- 0.8165934085845947 seconds for one epoch ---
--- 0.3319709300994873 seconds for one epoch ---
--- 0.8062314987182617 seconds for one epoch ---
--- 0.3365345001220703 seconds for one epoch ---
--- 0.8066666126251221 seconds for one epoch ---
--- 0.3109428882598877 seconds for one epoch ---
--- 0.8186941146850586 seconds for one epoch ---
--- 0.31440114974975586 seconds for one epoch ---
--- 0.7898495197296143 seconds for one epoch ---
--- 0.3025972843170166 seconds for one epoch ---
--- 0.8073465824127197 seconds for one epoch ---
--- 0.30955982208251953 seconds for one epoch ---
=========================
[[1.        ]
 [0.99796695]
 [0.9999426 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999647 ]
 [0.        ]]
[[ 3.3220499 ]
 [-0.66688013]
 [-0.84578633]
 [-0.        ]
 [-0.        ]
 [-2.07455   ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.8751936 ]
 [ 0.        ]]
--- 0.2704353332519531 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4111.49560546875, (1559.4066, 1.4858241, 2549.44, 1.1631727)
   validation loss 950.3003540039062, (605.02496, 0.15011992, 343.96213, 1.1631727)
decoder loss ratio: 23439.717451, decoder SINDy loss  ratio: 0.742491
--- 0.29662227630615234 seconds for one epoch ---
--- 0.8025507926940918 seconds for one epoch ---
--- 0.30221033096313477 seconds for one epoch ---
--- 0.8223185539245605 seconds for one epoch ---
--- 0.3044564723968506 seconds for one epoch ---
--- 0.8159921169281006 seconds for one epoch ---
--- 0.298037052154541 seconds for one epoch ---
--- 0.7919304370880127 seconds for one epoch ---
--- 0.3024933338165283 seconds for one epoch ---
--- 0.8044066429138184 seconds for one epoch ---
--- 0.3007693290710449 seconds for one epoch ---
--- 0.8415577411651611 seconds for one epoch ---
--- 0.2901034355163574 seconds for one epoch ---
--- 0.8343234062194824 seconds for one epoch ---
--- 0.30594873428344727 seconds for one epoch ---
--- 0.8018946647644043 seconds for one epoch ---
--- 0.3099076747894287 seconds for one epoch ---
--- 0.7990593910217285 seconds for one epoch ---
--- 0.31542158126831055 seconds for one epoch ---
--- 0.8215789794921875 seconds for one epoch ---
--- 0.3028981685638428 seconds for one epoch ---
--- 0.8190069198608398 seconds for one epoch ---
--- 0.30159687995910645 seconds for one epoch ---
--- 0.8268020153045654 seconds for one epoch ---
=========================
[[1.        ]
 [0.99791646]
 [0.9996998 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93780994]
 [0.        ]]
[[ 3.0624774 ]
 [-0.6656417 ]
 [-0.7627974 ]
 [-0.        ]
 [-0.        ]
 [-2.016088  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.49252486]
 [-0.        ]]
--- 0.3238062858581543 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4258.9267578125, (1726.3839, 1.5294179, 2529.8562, 1.1570288)
   validation loss 1196.2420654296875, (879.5504, 0.20500639, 315.32962, 1.1570288)
decoder loss ratio: 34075.310045, decoder SINDy loss  ratio: 0.680683
--- 0.252152681350708 seconds for one epoch ---
--- 0.3279578685760498 seconds for one epoch ---
--- 0.8080065250396729 seconds for one epoch ---
--- 0.3373880386352539 seconds for one epoch ---
--- 0.8332417011260986 seconds for one epoch ---
--- 0.35399365425109863 seconds for one epoch ---
--- 0.8350422382354736 seconds for one epoch ---
--- 0.3250703811645508 seconds for one epoch ---
--- 0.8355543613433838 seconds for one epoch ---
--- 0.33891987800598145 seconds for one epoch ---
--- 0.8549478054046631 seconds for one epoch ---
--- 0.3380434513092041 seconds for one epoch ---
--- 0.8553867340087891 seconds for one epoch ---
--- 0.337125301361084 seconds for one epoch ---
--- 0.8511435985565186 seconds for one epoch ---
--- 0.3307018280029297 seconds for one epoch ---
--- 0.8440093994140625 seconds for one epoch ---
--- 0.3328821659088135 seconds for one epoch ---
--- 0.8343431949615479 seconds for one epoch ---
--- 0.2991666793823242 seconds for one epoch ---
--- 0.8262224197387695 seconds for one epoch ---
--- 0.2981894016265869 seconds for one epoch ---
--- 0.824843168258667 seconds for one epoch ---
--- 0.31232714653015137 seconds for one epoch ---
=========================
[[1.        ]
 [0.99927783]
 [0.9991766 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.027104  ]
 [0.        ]]
[[ 2.8490198 ]
 [-0.7187634 ]
 [-0.7122006 ]
 [-0.        ]
 [-0.        ]
 [-1.95322   ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.17737965]
 [-0.        ]]
--- 0.26564455032348633 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2223.31787109375, (1199.2438, 0.6100897, 1022.4709, 0.99308175)
   validation loss 1274.0406494140625, (923.8594, 0.1821109, 349.00613, 0.99308175)
decoder loss ratio: 35791.916078, decoder SINDy loss  ratio: 0.753379
--- 0.3075981140136719 seconds for one epoch ---
--- 0.8285880088806152 seconds for one epoch ---
--- 0.3054511547088623 seconds for one epoch ---
--- 0.8214499950408936 seconds for one epoch ---
--- 0.29261326789855957 seconds for one epoch ---
--- 0.8234691619873047 seconds for one epoch ---
--- 0.3034324645996094 seconds for one epoch ---
--- 0.816704511642456 seconds for one epoch ---
--- 0.30437374114990234 seconds for one epoch ---
--- 0.856459379196167 seconds for one epoch ---
--- 0.3089313507080078 seconds for one epoch ---
--- 0.8453032970428467 seconds for one epoch ---
--- 0.3071136474609375 seconds for one epoch ---
--- 0.8303325176239014 seconds for one epoch ---
--- 0.3081955909729004 seconds for one epoch ---
--- 0.8339130878448486 seconds for one epoch ---
--- 0.3049910068511963 seconds for one epoch ---
--- 0.8686749935150146 seconds for one epoch ---
--- 0.29290032386779785 seconds for one epoch ---
--- 0.8255758285522461 seconds for one epoch ---
--- 0.30612993240356445 seconds for one epoch ---
--- 0.8336501121520996 seconds for one epoch ---
--- 0.2976999282836914 seconds for one epoch ---
--- 0.8095238208770752 seconds for one epoch ---
=========================
[[1.       ]
 [0.9994542]
 [0.9971322]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0126563]
 [0.       ]]
[[ 2.6277986 ]
 [-0.73280126]
 [-0.64960575]
 [-0.        ]
 [-0.        ]
 [-1.9080323 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.13833925]
 [ 0.        ]]
--- 0.3208589553833008 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3680.185302734375, (1406.9291, 2.2735329, 2269.9976, 0.98500746)
   validation loss 952.8394775390625, (595.075, 0.1898104, 356.58963, 0.98500746)
decoder loss ratio: 23054.239069, decoder SINDy loss  ratio: 0.769749
--- 0.280458927154541 seconds for one epoch ---
--- 0.3314938545227051 seconds for one epoch ---
--- 0.8480017185211182 seconds for one epoch ---
--- 0.3370509147644043 seconds for one epoch ---
--- 0.8569300174713135 seconds for one epoch ---
--- 0.32653260231018066 seconds for one epoch ---
--- 0.8863861560821533 seconds for one epoch ---
--- 0.32019662857055664 seconds for one epoch ---
--- 0.849639892578125 seconds for one epoch ---
--- 0.31476688385009766 seconds for one epoch ---
--- 0.8592517375946045 seconds for one epoch ---
--- 0.32666492462158203 seconds for one epoch ---
--- 0.8526036739349365 seconds for one epoch ---
--- 0.32271742820739746 seconds for one epoch ---
--- 0.868842601776123 seconds for one epoch ---
--- 0.32779526710510254 seconds for one epoch ---
--- 0.8483550548553467 seconds for one epoch ---
--- 0.2981700897216797 seconds for one epoch ---
--- 0.8468995094299316 seconds for one epoch ---
--- 0.2983369827270508 seconds for one epoch ---
--- 0.846989631652832 seconds for one epoch ---
--- 0.3038520812988281 seconds for one epoch ---
--- 0.845787525177002 seconds for one epoch ---
--- 0.29834604263305664 seconds for one epoch ---
=========================
[[1.        ]
 [0.9992254 ]
 [0.9897406 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.81819344]
 [0.        ]]
[[ 2.4218717 ]
 [-0.71525943]
 [-0.5854236 ]
 [-0.        ]
 [-0.        ]
 [-1.8715111 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.43201068]
 [ 0.        ]]
--- 0.26014113426208496 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4756.33544921875, (2519.4976, 0.4369042, 2235.2515, 1.1492)
   validation loss 2513.025146484375, (2180.123, 0.18870442, 331.56418, 1.1492)
decoder loss ratio: 84461.751696, decoder SINDy loss  ratio: 0.715728
--- 0.31194186210632324 seconds for one epoch ---
--- 0.8295135498046875 seconds for one epoch ---
--- 0.3131709098815918 seconds for one epoch ---
--- 0.8403937816619873 seconds for one epoch ---
--- 0.3154151439666748 seconds for one epoch ---
--- 0.8900365829467773 seconds for one epoch ---
--- 0.31328415870666504 seconds for one epoch ---
--- 0.86484694480896 seconds for one epoch ---
--- 0.32094240188598633 seconds for one epoch ---
--- 0.8716626167297363 seconds for one epoch ---
--- 0.31964612007141113 seconds for one epoch ---
--- 0.8636531829833984 seconds for one epoch ---
--- 0.3141472339630127 seconds for one epoch ---
--- 0.8654186725616455 seconds for one epoch ---
--- 0.3210411071777344 seconds for one epoch ---
--- 0.8887317180633545 seconds for one epoch ---
--- 0.3029935359954834 seconds for one epoch ---
--- 0.8566243648529053 seconds for one epoch ---
--- 0.2997019290924072 seconds for one epoch ---
--- 0.8807005882263184 seconds for one epoch ---
--- 0.3019540309906006 seconds for one epoch ---
--- 0.8245997428894043 seconds for one epoch ---
--- 0.30088257789611816 seconds for one epoch ---
--- 0.890653133392334 seconds for one epoch ---
=========================
[[1.       ]
 [0.998049 ]
 [0.9813217]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994702]
 [0.       ]]
[[ 2.2066586 ]
 [-0.66895074]
 [-0.5550024 ]
 [ 0.        ]
 [-0.        ]
 [-1.8375962 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.73429483]
 [-0.        ]]
--- 0.30383896827697754 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3444.17578125, (1418.6549, 0.89277637, 2023.4711, 1.1569567)
   validation loss 1331.080078125, (1022.38904, 0.19893259, 307.3352, 1.1569567)
decoder loss ratio: 39609.126281, decoder SINDy loss  ratio: 0.663426
--- 0.27017760276794434 seconds for one epoch ---
--- 0.3042597770690918 seconds for one epoch ---
--- 0.8554279804229736 seconds for one epoch ---
--- 0.3007371425628662 seconds for one epoch ---
--- 0.8496894836425781 seconds for one epoch ---
--- 0.30252861976623535 seconds for one epoch ---
--- 0.9041657447814941 seconds for one epoch ---
--- 0.30121421813964844 seconds for one epoch ---
--- 0.8674285411834717 seconds for one epoch ---
--- 0.30583882331848145 seconds for one epoch ---
--- 0.911578893661499 seconds for one epoch ---
--- 0.30886101722717285 seconds for one epoch ---
--- 0.8832731246948242 seconds for one epoch ---
--- 0.306382417678833 seconds for one epoch ---
--- 0.8865664005279541 seconds for one epoch ---
--- 0.31290507316589355 seconds for one epoch ---
--- 0.8713870048522949 seconds for one epoch ---
--- 0.48149895668029785 seconds for one epoch ---
--- 0.8829512596130371 seconds for one epoch ---
--- 0.29692721366882324 seconds for one epoch ---
--- 0.8712551593780518 seconds for one epoch ---
--- 0.30075573921203613 seconds for one epoch ---
--- 0.8709273338317871 seconds for one epoch ---
--- 0.2992069721221924 seconds for one epoch ---
=========================
[[1.        ]
 [0.99838847]
 [0.97654104]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999944 ]
 [0.        ]]
[[ 2.0343792 ]
 [-0.6785371 ]
 [-0.54335314]
 [-0.        ]
 [-0.        ]
 [-1.7841398 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.9916882 ]
 [ 0.        ]]
--- 0.2668468952178955 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2300.90087890625, (951.3257, 0.58855087, 1347.8302, 1.156378)
   validation loss 1047.12158203125, (727.13794, 0.14100425, 318.68625, 1.156378)
decoder loss ratio: 28170.586141, decoder SINDy loss  ratio: 0.687929
--- 0.3005828857421875 seconds for one epoch ---
--- 0.8607397079467773 seconds for one epoch ---
--- 0.30037975311279297 seconds for one epoch ---
--- 0.9122915267944336 seconds for one epoch ---
--- 0.29136013984680176 seconds for one epoch ---
--- 0.8704612255096436 seconds for one epoch ---
--- 0.2987205982208252 seconds for one epoch ---
--- 0.9177327156066895 seconds for one epoch ---
--- 0.29933834075927734 seconds for one epoch ---
--- 0.9133999347686768 seconds for one epoch ---
--- 0.29952383041381836 seconds for one epoch ---
--- 0.8919558525085449 seconds for one epoch ---
--- 0.2935051918029785 seconds for one epoch ---
--- 0.8961420059204102 seconds for one epoch ---
--- 0.28912854194641113 seconds for one epoch ---
--- 0.8774974346160889 seconds for one epoch ---
--- 0.30254197120666504 seconds for one epoch ---
--- 0.887641191482544 seconds for one epoch ---
--- 0.27881455421447754 seconds for one epoch ---
--- 0.9095396995544434 seconds for one epoch ---
--- 0.3174755573272705 seconds for one epoch ---
--- 0.9243044853210449 seconds for one epoch ---
--- 0.33426594734191895 seconds for one epoch ---
--- 0.898090124130249 seconds for one epoch ---
=========================
[[1.        ]
 [0.99945617]
 [0.9473598 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.8724695 ]
 [-0.732999  ]
 [-0.50138044]
 [-0.        ]
 [-0.        ]
 [-1.747763  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.218463  ]
 [-0.        ]]
--- 0.3247702121734619 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4464.54296875, (1327.3147, 1.9558914, 3134.1177, 1.1545919)
   validation loss 1180.662841796875, (856.89496, 0.16998744, 322.4434, 1.1545919)
decoder loss ratio: 33197.598327, decoder SINDy loss  ratio: 0.696039
--- 0.26456236839294434 seconds for one epoch ---
--- 0.3338174819946289 seconds for one epoch ---
--- 0.8798141479492188 seconds for one epoch ---
--- 0.33871006965637207 seconds for one epoch ---
--- 0.8718528747558594 seconds for one epoch ---
--- 0.3215067386627197 seconds for one epoch ---
--- 0.8864295482635498 seconds for one epoch ---
--- 0.32433605194091797 seconds for one epoch ---
--- 0.8949973583221436 seconds for one epoch ---
--- 0.3213160037994385 seconds for one epoch ---
--- 0.900489091873169 seconds for one epoch ---
--- 0.2952289581298828 seconds for one epoch ---
--- 0.8912696838378906 seconds for one epoch ---
--- 0.2938823699951172 seconds for one epoch ---
--- 0.8981430530548096 seconds for one epoch ---
--- 0.3011195659637451 seconds for one epoch ---
--- 0.9001312255859375 seconds for one epoch ---
--- 0.3056044578552246 seconds for one epoch ---
--- 0.8606481552124023 seconds for one epoch ---
--- 0.30995798110961914 seconds for one epoch ---
--- 0.8906307220458984 seconds for one epoch ---
--- 0.31891584396362305 seconds for one epoch ---
--- 0.9165201187133789 seconds for one epoch ---
--- 0.31037044525146484 seconds for one epoch ---
=========================
[[1.        ]
 [0.99955094]
 [0.95139945]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.7151437 ]
 [-0.74263537]
 [-0.50559014]
 [-0.        ]
 [-0.        ]
 [-1.7066966 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.4487114 ]
 [-0.        ]]
--- 0.2787022590637207 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3577.56640625, (1762.2026, 0.25011665, 1813.9589, 1.154705)
   validation loss 1328.4620361328125, (958.65967, 0.19012877, 368.4576, 1.154705)
decoder loss ratio: 37140.139843, decoder SINDy loss  ratio: 0.795368
--- 0.3088376522064209 seconds for one epoch ---
--- 0.9159767627716064 seconds for one epoch ---
--- 0.3068091869354248 seconds for one epoch ---
--- 0.9007425308227539 seconds for one epoch ---
--- 0.2998659610748291 seconds for one epoch ---
--- 0.9055109024047852 seconds for one epoch ---
--- 0.312542200088501 seconds for one epoch ---
--- 0.9209985733032227 seconds for one epoch ---
--- 0.29978299140930176 seconds for one epoch ---
--- 0.912419319152832 seconds for one epoch ---
--- 0.2898268699645996 seconds for one epoch ---
--- 0.8963565826416016 seconds for one epoch ---
--- 0.2930338382720947 seconds for one epoch ---
--- 0.9140276908874512 seconds for one epoch ---
--- 0.2999904155731201 seconds for one epoch ---
--- 0.9356288909912109 seconds for one epoch ---
--- 0.299213171005249 seconds for one epoch ---
--- 0.9172952175140381 seconds for one epoch ---
--- 0.2969181537628174 seconds for one epoch ---
--- 0.8996193408966064 seconds for one epoch ---
--- 0.3182218074798584 seconds for one epoch ---
--- 0.9175231456756592 seconds for one epoch ---
--- 0.3193168640136719 seconds for one epoch ---
--- 0.928532600402832 seconds for one epoch ---
=========================
[[1.       ]
 [0.9991957]
 [0.9404778]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 1.5705441]
 [-0.7133824]
 [-0.4948664]
 [ 0.       ]
 [-0.       ]
 [-1.6768484]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.6530515]
 [ 0.       ]]
--- 0.31733131408691406 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4451.18359375, (1752.8767, 0.8180959, 2696.3345, 1.1542783)
   validation loss 1330.5015869140625, (991.6806, 0.19263747, 337.4741, 1.1542783)
decoder loss ratio: 38419.428195, decoder SINDy loss  ratio: 0.728485
--- 0.2823970317840576 seconds for one epoch ---
--- 0.3345770835876465 seconds for one epoch ---
--- 0.9368274211883545 seconds for one epoch ---
--- 0.32972192764282227 seconds for one epoch ---
--- 0.9311642646789551 seconds for one epoch ---
--- 0.3332810401916504 seconds for one epoch ---
--- 0.9378707408905029 seconds for one epoch ---
--- 0.31484222412109375 seconds for one epoch ---
--- 0.920945405960083 seconds for one epoch ---
--- 0.2946746349334717 seconds for one epoch ---
--- 0.9006068706512451 seconds for one epoch ---
--- 0.30223655700683594 seconds for one epoch ---
--- 0.9019355773925781 seconds for one epoch ---
--- 0.2936856746673584 seconds for one epoch ---
--- 0.9090087413787842 seconds for one epoch ---
--- 0.29929280281066895 seconds for one epoch ---
--- 0.8717429637908936 seconds for one epoch ---
--- 0.29718780517578125 seconds for one epoch ---
--- 0.9198532104492188 seconds for one epoch ---
--- 0.3045835494995117 seconds for one epoch ---
--- 0.9349136352539062 seconds for one epoch ---
--- 0.2915215492248535 seconds for one epoch ---
--- 0.9422588348388672 seconds for one epoch ---
--- 0.3001565933227539 seconds for one epoch ---
=========================
[[1.        ]
 [0.99929357]
 [0.88134074]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.4206676 ]
 [-0.71987736]
 [-0.4570878 ]
 [-0.        ]
 [-0.        ]
 [-1.6539924 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.8555886 ]
 [ 0.        ]]
--- 0.2724144458770752 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5578.0859375, (1370.6387, 0.90775865, 4205.389, 1.1502388)
   validation loss 1014.1956787109375, (673.6515, 0.11676792, 339.2772, 1.1502388)
decoder loss ratio: 26098.428204, decoder SINDy loss  ratio: 0.732378
--- 0.3109161853790283 seconds for one epoch ---
--- 0.8985836505889893 seconds for one epoch ---
--- 0.2883920669555664 seconds for one epoch ---
--- 0.9337284564971924 seconds for one epoch ---
--- 0.2995734214782715 seconds for one epoch ---
--- 0.9229168891906738 seconds for one epoch ---
--- 0.3001267910003662 seconds for one epoch ---
--- 0.9069082736968994 seconds for one epoch ---
--- 0.29586267471313477 seconds for one epoch ---
--- 0.9207568168640137 seconds for one epoch ---
--- 0.30150723457336426 seconds for one epoch ---
--- 0.9402756690979004 seconds for one epoch ---
--- 0.30518555641174316 seconds for one epoch ---
--- 0.9447221755981445 seconds for one epoch ---
--- 0.30242085456848145 seconds for one epoch ---
--- 0.933687686920166 seconds for one epoch ---
--- 0.29948973655700684 seconds for one epoch ---
--- 0.9299812316894531 seconds for one epoch ---
--- 0.30032849311828613 seconds for one epoch ---
--- 0.9511775970458984 seconds for one epoch ---
--- 0.3022189140319824 seconds for one epoch ---
--- 0.9475891590118408 seconds for one epoch ---
--- 0.310194730758667 seconds for one epoch ---
--- 0.9290223121643066 seconds for one epoch ---
=========================
[[1.        ]
 [0.9986799 ]
 [0.87319094]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.3091853 ]
 [-0.68853676]
 [-0.45329896]
 [ 0.        ]
 [ 0.        ]
 [-1.6104213 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.0201945 ]
 [-0.        ]]
--- 0.314237117767334 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2683.779052734375, (1334.22, 1.209526, 1347.2008, 1.1485728)
   validation loss 1456.111328125, (1121.5153, 0.19708517, 333.25034, 1.1485728)
decoder loss ratio: 43449.448162, decoder SINDy loss  ratio: 0.719368
--- 0.2639429569244385 seconds for one epoch ---
--- 0.3233468532562256 seconds for one epoch ---
--- 0.9131941795349121 seconds for one epoch ---
--- 0.342695951461792 seconds for one epoch ---
--- 0.9413626194000244 seconds for one epoch ---
--- 0.33130455017089844 seconds for one epoch ---
--- 0.9281995296478271 seconds for one epoch ---
--- 0.28973817825317383 seconds for one epoch ---
--- 0.9244081974029541 seconds for one epoch ---
--- 0.2941429615020752 seconds for one epoch ---
--- 0.9264395236968994 seconds for one epoch ---
--- 0.28951072692871094 seconds for one epoch ---
--- 0.939666748046875 seconds for one epoch ---
--- 0.2989175319671631 seconds for one epoch ---
--- 0.9181253910064697 seconds for one epoch ---
--- 0.3029289245605469 seconds for one epoch ---
--- 0.9456803798675537 seconds for one epoch ---
--- 0.3080260753631592 seconds for one epoch ---
--- 0.9474842548370361 seconds for one epoch ---
--- 0.33416056632995605 seconds for one epoch ---
--- 0.9398918151855469 seconds for one epoch ---
--- 0.3428339958190918 seconds for one epoch ---
--- 0.944880485534668 seconds for one epoch ---
--- 0.34790658950805664 seconds for one epoch ---
=========================
[[1.        ]
 [0.99779797]
 [0.9019429 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.2023444]
 [-0.6628718]
 [-0.4677891]
 [ 0.       ]
 [-0.       ]
 [-1.5785437]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.1702204]
 [ 0.       ]]
--- 0.2771313190460205 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3252.615966796875, (1195.0862, 0.6849717, 2055.6936, 1.1512257)
   validation loss 927.76806640625, (585.09735, 0.18727453, 341.33224, 1.1512257)
decoder loss ratio: 22667.687154, decoder SINDy loss  ratio: 0.736814
--- 0.29703664779663086 seconds for one epoch ---
--- 0.9504492282867432 seconds for one epoch ---
--- 0.30190134048461914 seconds for one epoch ---
--- 0.9617385864257812 seconds for one epoch ---
--- 0.2961399555206299 seconds for one epoch ---
--- 0.9451959133148193 seconds for one epoch ---
--- 0.2993152141571045 seconds for one epoch ---
--- 0.9306292533874512 seconds for one epoch ---
--- 0.30318784713745117 seconds for one epoch ---
--- 0.9370574951171875 seconds for one epoch ---
--- 0.3039414882659912 seconds for one epoch ---
--- 0.9401195049285889 seconds for one epoch ---
--- 0.30106091499328613 seconds for one epoch ---
--- 0.9139997959136963 seconds for one epoch ---
--- 0.3013267517089844 seconds for one epoch ---
--- 0.9765915870666504 seconds for one epoch ---
--- 0.3051114082336426 seconds for one epoch ---
--- 0.9509098529815674 seconds for one epoch ---
--- 0.30710434913635254 seconds for one epoch ---
--- 0.9731504917144775 seconds for one epoch ---
--- 0.3078756332397461 seconds for one epoch ---
--- 0.9790539741516113 seconds for one epoch ---
--- 0.29428625106811523 seconds for one epoch ---
--- 0.9692068099975586 seconds for one epoch ---
=========================
[[0.99999666]
 [0.9968964 ]
 [0.877846  ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.096803  ]
 [-0.6456373 ]
 [-0.45543727]
 [-0.        ]
 [ 0.        ]
 [-1.5621165 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.3087006 ]
 [-0.        ]]
--- 0.31386542320251465 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2824.794189453125, (1204.2809, 0.8586705, 1618.5049, 1.1496148)
   validation loss 920.3057861328125, (617.3464, 0.19587238, 301.61395, 1.1496148)
decoder loss ratio: 23917.070309, decoder SINDy loss  ratio: 0.651076
--- 0.2673015594482422 seconds for one epoch ---
--- 0.301952600479126 seconds for one epoch ---
--- 0.9456584453582764 seconds for one epoch ---
--- 0.3198549747467041 seconds for one epoch ---
--- 0.9678821563720703 seconds for one epoch ---
--- 0.29842543601989746 seconds for one epoch ---
--- 0.978853702545166 seconds for one epoch ---
--- 0.2995011806488037 seconds for one epoch ---
--- 0.9546582698822021 seconds for one epoch ---
--- 0.2994868755340576 seconds for one epoch ---
--- 0.9700613021850586 seconds for one epoch ---
--- 0.30410218238830566 seconds for one epoch ---
--- 0.946810245513916 seconds for one epoch ---
--- 0.29428672790527344 seconds for one epoch ---
--- 0.9556562900543213 seconds for one epoch ---
--- 0.30735135078430176 seconds for one epoch ---
--- 0.9591948986053467 seconds for one epoch ---
--- 0.30554819107055664 seconds for one epoch ---
--- 0.9690086841583252 seconds for one epoch ---
--- 0.3176712989807129 seconds for one epoch ---
--- 0.9487426280975342 seconds for one epoch ---
--- 0.30101823806762695 seconds for one epoch ---
--- 0.9727804660797119 seconds for one epoch ---
--- 0.3108952045440674 seconds for one epoch ---
=========================
[[0.99999374]
 [0.9959928 ]
 [0.8191526 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 1.0060023 ]
 [-0.63279766]
 [-0.43233833]
 [ 0.        ]
 [ 0.        ]
 [-1.5437374 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.4220057 ]
 [-0.        ]]
--- 0.27337098121643066 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4551.3564453125, (1962.1589, 3.4977336, 2584.5542, 1.1453332)
   validation loss 1276.1580810546875, (962.27765, 0.14758366, 312.58752, 1.1453332)
decoder loss ratio: 37280.306707, decoder SINDy loss  ratio: 0.674764
--- 0.29225945472717285 seconds for one epoch ---
--- 0.9571077823638916 seconds for one epoch ---
--- 0.2970552444458008 seconds for one epoch ---
--- 0.957305908203125 seconds for one epoch ---
--- 0.299898624420166 seconds for one epoch ---
--- 0.9593067169189453 seconds for one epoch ---
--- 0.30191469192504883 seconds for one epoch ---
--- 0.9604418277740479 seconds for one epoch ---
--- 0.2977151870727539 seconds for one epoch ---
--- 0.9755117893218994 seconds for one epoch ---
--- 0.308351993560791 seconds for one epoch ---
--- 0.9322941303253174 seconds for one epoch ---
--- 0.29111409187316895 seconds for one epoch ---
--- 0.9676868915557861 seconds for one epoch ---
--- 0.31520867347717285 seconds for one epoch ---
--- 0.9886460304260254 seconds for one epoch ---
--- 0.3264181613922119 seconds for one epoch ---
--- 0.9879148006439209 seconds for one epoch ---
--- 0.3393216133117676 seconds for one epoch ---
--- 1.0255508422851562 seconds for one epoch ---
--- 0.3321380615234375 seconds for one epoch ---
--- 0.9857850074768066 seconds for one epoch ---
--- 0.34334802627563477 seconds for one epoch ---
--- 1.0076406002044678 seconds for one epoch ---
=========================
[[0.99998105]
 [0.9958651 ]
 [0.8801036 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.90074086]
 [-0.6312271 ]
 [-0.45649967]
 [-0.        ]
 [-0.        ]
 [-1.5280235 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5562584 ]
 [ 0.        ]]
--- 0.30911850929260254 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2078.21533203125, (1105.6697, 0.21863638, 971.1765, 1.1504083)
   validation loss 995.9241943359375, (650.2292, 0.129491, 344.41507, 1.1504083)
decoder loss ratio: 25191.007552, decoder SINDy loss  ratio: 0.743468
THRESHOLDING: 5 active coefficients
--- 0.25641417503356934 seconds for one epoch ---
--- 0.2931203842163086 seconds for one epoch ---
--- 0.949885368347168 seconds for one epoch ---
--- 0.30014967918395996 seconds for one epoch ---
--- 0.9824953079223633 seconds for one epoch ---
--- 0.29926180839538574 seconds for one epoch ---
--- 0.9584989547729492 seconds for one epoch ---
--- 0.29633378982543945 seconds for one epoch ---
--- 1.002805471420288 seconds for one epoch ---
--- 0.29419517517089844 seconds for one epoch ---
--- 0.9726190567016602 seconds for one epoch ---
--- 0.31288957595825195 seconds for one epoch ---
--- 0.9909186363220215 seconds for one epoch ---
--- 0.29811954498291016 seconds for one epoch ---
--- 0.985295295715332 seconds for one epoch ---
--- 0.32492852210998535 seconds for one epoch ---
--- 0.9788327217102051 seconds for one epoch ---
--- 0.3136279582977295 seconds for one epoch ---
--- 0.9929533004760742 seconds for one epoch ---
--- 0.3187546730041504 seconds for one epoch ---
--- 0.9889867305755615 seconds for one epoch ---
--- 0.32149481773376465 seconds for one epoch ---
--- 0.9791853427886963 seconds for one epoch ---
--- 0.33322954177856445 seconds for one epoch ---
=========================
[[0.9999299 ]
 [0.99835193]
 [0.80991924]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.8356953 ]
 [-0.6774022 ]
 [-0.42927936]
 [-0.        ]
 [ 0.        ]
 [-1.4946222 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.6461058 ]
 [ 0.        ]]
--- 0.26134824752807617 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3288.89794921875, (1218.163, 1.2196186, 2068.3726, 1.1427337)
   validation loss 1171.8123779296875, (832.6501, 0.18819924, 337.83136, 1.1427337)
decoder loss ratio: 32258.309854, decoder SINDy loss  ratio: 0.729257
--- 0.31453609466552734 seconds for one epoch ---
--- 1.0124037265777588 seconds for one epoch ---
--- 0.31890106201171875 seconds for one epoch ---
--- 0.990908145904541 seconds for one epoch ---
--- 0.34229063987731934 seconds for one epoch ---
--- 0.9985687732696533 seconds for one epoch ---
--- 0.32616114616394043 seconds for one epoch ---
--- 0.9898586273193359 seconds for one epoch ---
--- 0.33145713806152344 seconds for one epoch ---
--- 1.0038843154907227 seconds for one epoch ---
--- 0.32163000106811523 seconds for one epoch ---
--- 1.039637565612793 seconds for one epoch ---
--- 0.321274995803833 seconds for one epoch ---
--- 1.0322566032409668 seconds for one epoch ---
--- 0.3334622383117676 seconds for one epoch ---
--- 1.0150465965270996 seconds for one epoch ---
--- 0.3354671001434326 seconds for one epoch ---
--- 1.0114591121673584 seconds for one epoch ---
--- 0.32848381996154785 seconds for one epoch ---
--- 1.0238633155822754 seconds for one epoch ---
--- 0.3334047794342041 seconds for one epoch ---
--- 1.001403570175171 seconds for one epoch ---
--- 0.3143434524536133 seconds for one epoch ---
--- 0.9847517013549805 seconds for one epoch ---
=========================
[[0.99967074]
 [0.99927247]
 [0.79313886]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.7580508]
 [-0.7184177]
 [-0.4239984]
 [-0.       ]
 [-0.       ]
 [-1.49013  ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.7282662]
 [-0.       ]]
--- 0.2960517406463623 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3684.369384765625, (1808.9454, 0.867033, 1873.4154, 1.1413778)
   validation loss 1123.9049072265625, (732.7956, 0.20058638, 389.7674, 1.1413778)
decoder loss ratio: 28389.773472, decoder SINDy loss  ratio: 0.841368
--- 0.26767683029174805 seconds for one epoch ---
--- 0.3027462959289551 seconds for one epoch ---
--- 0.9967973232269287 seconds for one epoch ---
--- 0.3141787052154541 seconds for one epoch ---
--- 0.9885869026184082 seconds for one epoch ---
--- 0.31093478202819824 seconds for one epoch ---
--- 1.0106401443481445 seconds for one epoch ---
--- 0.30841660499572754 seconds for one epoch ---
--- 1.0010666847229004 seconds for one epoch ---
--- 0.2966904640197754 seconds for one epoch ---
--- 0.9687438011169434 seconds for one epoch ---
--- 0.29752373695373535 seconds for one epoch ---
--- 1.0285274982452393 seconds for one epoch ---
--- 0.3018927574157715 seconds for one epoch ---
--- 1.0073444843292236 seconds for one epoch ---
--- 0.30101799964904785 seconds for one epoch ---
--- 1.0290427207946777 seconds for one epoch ---
--- 0.30056190490722656 seconds for one epoch ---
--- 1.0118508338928223 seconds for one epoch ---
--- 0.30135393142700195 seconds for one epoch ---
--- 1.0168261528015137 seconds for one epoch ---
--- 0.3107130527496338 seconds for one epoch ---
--- 1.0227556228637695 seconds for one epoch ---
--- 0.29462480545043945 seconds for one epoch ---
=========================
[[0.9985996]
 [0.9990112]
 [0.7184732]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.6855539]
 [-0.7030081]
 [-0.4036291]
 [ 0.       ]
 [-0.       ]
 [-1.4683609]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.8186338]
 [ 0.       ]]
--- 0.2612118721008301 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3266.41357421875, (1404.0947, 0.29745018, 1860.885, 1.136258)
   validation loss 953.141357421875, (609.61816, 0.2112337, 342.1757, 1.136258)
decoder loss ratio: 23617.666019, decoder SINDy loss  ratio: 0.738634
--- 0.3017458915710449 seconds for one epoch ---
--- 1.0136864185333252 seconds for one epoch ---
--- 0.3000960350036621 seconds for one epoch ---
--- 0.9973170757293701 seconds for one epoch ---
--- 0.2984299659729004 seconds for one epoch ---
--- 1.022620439529419 seconds for one epoch ---
--- 0.29393482208251953 seconds for one epoch ---
--- 1.015794038772583 seconds for one epoch ---
--- 0.2880592346191406 seconds for one epoch ---
--- 1.007314682006836 seconds for one epoch ---
--- 0.300703763961792 seconds for one epoch ---
--- 1.0335719585418701 seconds for one epoch ---
--- 0.31064414978027344 seconds for one epoch ---
--- 1.0464375019073486 seconds for one epoch ---
--- 0.31055641174316406 seconds for one epoch ---
--- 1.0331439971923828 seconds for one epoch ---
--- 0.3154458999633789 seconds for one epoch ---
--- 1.0166974067687988 seconds for one epoch ---
--- 0.3380086421966553 seconds for one epoch ---
--- 1.0229625701904297 seconds for one epoch ---
--- 0.33243870735168457 seconds for one epoch ---
--- 1.0221993923187256 seconds for one epoch ---
--- 0.33777284622192383 seconds for one epoch ---
--- 1.0299105644226074 seconds for one epoch ---
=========================
[[0.99480045]
 [0.9989947 ]
 [0.6795982 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.6197041 ]
 [-0.7021947 ]
 [-0.39437297]
 [-0.        ]
 [-0.        ]
 [-1.4473649 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.9005287 ]
 [-0.        ]]
--- 0.30519795417785645 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3193.36767578125, (1465.0807, 0.59364206, 1726.5629, 1.1304611)
   validation loss 975.7681274414062, (595.24414, 0.15140268, 379.24216, 1.1304611)
decoder loss ratio: 23060.791397, decoder SINDy loss  ratio: 0.818648
--- 0.26833319664001465 seconds for one epoch ---
--- 0.2941446304321289 seconds for one epoch ---
--- 1.0050437450408936 seconds for one epoch ---
--- 0.29934191703796387 seconds for one epoch ---
--- 1.023665189743042 seconds for one epoch ---
--- 0.30140137672424316 seconds for one epoch ---
--- 1.0322222709655762 seconds for one epoch ---
--- 0.30406641960144043 seconds for one epoch ---
--- 0.976616382598877 seconds for one epoch ---
--- 0.29737186431884766 seconds for one epoch ---
--- 1.0416865348815918 seconds for one epoch ---
--- 0.31492161750793457 seconds for one epoch ---
--- 1.0524020195007324 seconds for one epoch ---
--- 0.30820441246032715 seconds for one epoch ---
--- 1.0296099185943604 seconds for one epoch ---
--- 0.31240153312683105 seconds for one epoch ---
--- 1.0193612575531006 seconds for one epoch ---
--- 0.3145129680633545 seconds for one epoch ---
--- 1.0266094207763672 seconds for one epoch ---
--- 0.31653332710266113 seconds for one epoch ---
--- 1.0532844066619873 seconds for one epoch ---
--- 0.3125014305114746 seconds for one epoch ---
--- 1.0538232326507568 seconds for one epoch ---
--- 0.3190300464630127 seconds for one epoch ---
=========================
[[0.9835892 ]
 [0.9980793 ]
 [0.65388495]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.5615989 ]
 [-0.66972643]
 [-0.3885803 ]
 [ 0.        ]
 [ 0.        ]
 [-1.4405227 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.956886  ]
 [-0.        ]]
--- 0.25691890716552734 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4424.65673828125, (1383.2318, 3.3723242, 3036.925, 1.1276758)
   validation loss 998.6251220703125, (675.4707, 0.2015338, 321.82523, 1.1276758)
decoder loss ratio: 26168.907708, decoder SINDy loss  ratio: 0.694705
--- 0.2910888195037842 seconds for one epoch ---
--- 1.0159354209899902 seconds for one epoch ---
--- 0.2916879653930664 seconds for one epoch ---
--- 1.0342090129852295 seconds for one epoch ---
--- 0.2948157787322998 seconds for one epoch ---
--- 1.0431597232818604 seconds for one epoch ---
--- 0.30144381523132324 seconds for one epoch ---
--- 1.001204252243042 seconds for one epoch ---
--- 0.29633188247680664 seconds for one epoch ---
--- 1.0365231037139893 seconds for one epoch ---
--- 0.30188465118408203 seconds for one epoch ---
--- 1.022601842880249 seconds for one epoch ---
--- 0.3019583225250244 seconds for one epoch ---
--- 1.036292552947998 seconds for one epoch ---
--- 0.3107106685638428 seconds for one epoch ---
--- 1.0637621879577637 seconds for one epoch ---
--- 0.30055809020996094 seconds for one epoch ---
--- 1.0391671657562256 seconds for one epoch ---
--- 0.29839563369750977 seconds for one epoch ---
--- 1.054183006286621 seconds for one epoch ---
--- 0.30530714988708496 seconds for one epoch ---
--- 1.0517199039459229 seconds for one epoch ---
--- 0.30495285987854004 seconds for one epoch ---
--- 1.0491251945495605 seconds for one epoch ---
=========================
[[0.936944  ]
 [0.9981424 ]
 [0.62653506]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.4917934 ]
 [-0.6713881 ]
 [-0.38263682]
 [ 0.        ]
 [-0.        ]
 [-1.4398855 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.0281644 ]
 [ 0.        ]]
--- 0.28384995460510254 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4826.96533203125, (1762.1384, 0.5322455, 3063.1724, 1.1227869)
   validation loss 1458.4962158203125, (1087.2742, 0.23721166, 369.8621, 1.1227869)
decoder loss ratio: 42122.888934, decoder SINDy loss  ratio: 0.798399
--- 0.2570195198059082 seconds for one epoch ---
--- 0.29119324684143066 seconds for one epoch ---
--- 1.0480983257293701 seconds for one epoch ---
--- 0.3011658191680908 seconds for one epoch ---
--- 1.0319077968597412 seconds for one epoch ---
--- 0.29708242416381836 seconds for one epoch ---
--- 1.0086913108825684 seconds for one epoch ---
--- 0.29620361328125 seconds for one epoch ---
--- 1.0418915748596191 seconds for one epoch ---
--- 0.3129856586456299 seconds for one epoch ---
--- 1.0363402366638184 seconds for one epoch ---
--- 0.31518983840942383 seconds for one epoch ---
--- 1.055872917175293 seconds for one epoch ---
--- 0.2926459312438965 seconds for one epoch ---
--- 1.067819595336914 seconds for one epoch ---
--- 0.32016682624816895 seconds for one epoch ---
--- 1.0598087310791016 seconds for one epoch ---
--- 0.3178749084472656 seconds for one epoch ---
--- 1.0447654724121094 seconds for one epoch ---
--- 0.3213820457458496 seconds for one epoch ---
--- 1.0443997383117676 seconds for one epoch ---
--- 0.33136916160583496 seconds for one epoch ---
--- 1.0361716747283936 seconds for one epoch ---
--- 0.30802083015441895 seconds for one epoch ---
=========================
[[0.77684975]
 [0.99836004]
 [0.61935467]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.4191674 ]
 [-0.67764056]
 [-0.38110712]
 [-0.        ]
 [ 0.        ]
 [-1.4299734 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1080346 ]
 [ 0.        ]]
--- 0.2529945373535156 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3554.311279296875, (1210.334, 0.63780534, 2342.2346, 1.1047226)
   validation loss 876.5590209960938, (569.9644, 0.14165682, 305.3482, 1.1047226)
decoder loss ratio: 22081.410997, decoder SINDy loss  ratio: 0.659137
--- 0.30780768394470215 seconds for one epoch ---
--- 1.0316476821899414 seconds for one epoch ---
--- 0.30308032035827637 seconds for one epoch ---
--- 1.0686028003692627 seconds for one epoch ---
--- 0.29737162590026855 seconds for one epoch ---
--- 1.0090928077697754 seconds for one epoch ---
--- 0.3030107021331787 seconds for one epoch ---
--- 1.0633020401000977 seconds for one epoch ---
--- 0.2983551025390625 seconds for one epoch ---
--- 1.0560436248779297 seconds for one epoch ---
--- 0.33398985862731934 seconds for one epoch ---
--- 1.044572114944458 seconds for one epoch ---
--- 0.32056474685668945 seconds for one epoch ---
--- 1.0695643424987793 seconds for one epoch ---
--- 0.3203854560852051 seconds for one epoch ---
--- 1.0783421993255615 seconds for one epoch ---
--- 0.33205604553222656 seconds for one epoch ---
--- 1.0660858154296875 seconds for one epoch ---
--- 0.31716394424438477 seconds for one epoch ---
--- 1.0997231006622314 seconds for one epoch ---
--- 0.3138618469238281 seconds for one epoch ---
--- 1.0901782512664795 seconds for one epoch ---
--- 0.3098628520965576 seconds for one epoch ---
--- 1.1175084114074707 seconds for one epoch ---
=========================
[[0.52124137]
 [0.99800515]
 [0.6711407 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.36100242]
 [-0.6678092 ]
 [-0.39244294]
 [ 0.        ]
 [ 0.        ]
 [-1.4073926 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.180389  ]
 [-0.        ]]
--- 0.29883432388305664 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3266.070556640625, (1647.2537, 1.8814322, 1615.8523, 1.083221)
   validation loss 1451.0489501953125, (1142.2847, 0.20714395, 307.47388, 1.083221)
decoder loss ratio: 44254.091131, decoder SINDy loss  ratio: 0.663726
--- 0.26085758209228516 seconds for one epoch ---
--- 0.3002476692199707 seconds for one epoch ---
--- 1.0778820514678955 seconds for one epoch ---
--- 0.29102158546447754 seconds for one epoch ---
--- 1.0297513008117676 seconds for one epoch ---
--- 0.29799318313598633 seconds for one epoch ---
--- 1.069239854812622 seconds for one epoch ---
--- 0.29631662368774414 seconds for one epoch ---
--- 1.0616323947906494 seconds for one epoch ---
--- 0.28986597061157227 seconds for one epoch ---
--- 1.0763046741485596 seconds for one epoch ---
--- 0.5015816688537598 seconds for one epoch ---
--- 1.0917766094207764 seconds for one epoch ---
--- 0.32004213333129883 seconds for one epoch ---
--- 1.0858333110809326 seconds for one epoch ---
--- 0.31536865234375 seconds for one epoch ---
--- 1.102827548980713 seconds for one epoch ---
--- 0.32938265800476074 seconds for one epoch ---
--- 1.092163324356079 seconds for one epoch ---
--- 0.33389806747436523 seconds for one epoch ---
--- 1.0873401165008545 seconds for one epoch ---
--- 0.3380391597747803 seconds for one epoch ---
--- 1.1100733280181885 seconds for one epoch ---
--- 0.3304269313812256 seconds for one epoch ---
=========================
[[0.25726444]
 [0.999307  ]
 [0.70715714]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.30370098]
 [-0.7208201 ]
 [-0.40086317]
 [-0.        ]
 [-0.        ]
 [-1.3974854 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.240356  ]
 [ 0.        ]]
--- 0.26262521743774414 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4333.28759765625, (1329.7935, 0.7960791, 3001.6528, 1.0452648)
   validation loss 1013.8223876953125, (672.8203, 0.20357041, 339.75327, 1.0452648)
decoder loss ratio: 26066.226974, decoder SINDy loss  ratio: 0.733405
--- 0.29674243927001953 seconds for one epoch ---
--- 1.0622951984405518 seconds for one epoch ---
--- 0.29305505752563477 seconds for one epoch ---
--- 1.0512421131134033 seconds for one epoch ---
--- 0.28955769538879395 seconds for one epoch ---
--- 1.0640172958374023 seconds for one epoch ---
--- 0.3179352283477783 seconds for one epoch ---
--- 1.1075291633605957 seconds for one epoch ---
--- 0.3325376510620117 seconds for one epoch ---
--- 1.0975682735443115 seconds for one epoch ---
--- 0.31871771812438965 seconds for one epoch ---
--- 1.119671106338501 seconds for one epoch ---
--- 0.3123054504394531 seconds for one epoch ---
--- 1.1042723655700684 seconds for one epoch ---
--- 0.29911279678344727 seconds for one epoch ---
--- 1.0969252586364746 seconds for one epoch ---
--- 0.3109712600708008 seconds for one epoch ---
--- 1.1169147491455078 seconds for one epoch ---
--- 0.3098733425140381 seconds for one epoch ---
--- 1.1433289051055908 seconds for one epoch ---
--- 0.32661008834838867 seconds for one epoch ---
--- 1.108898401260376 seconds for one epoch ---
--- 0.3093733787536621 seconds for one epoch ---
--- 1.1376655101776123 seconds for one epoch ---
=========================
[[0.12276259]
 [0.9994525 ]
 [0.6785393 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.25835946]
 [-0.73261863]
 [-0.39413023]
 [-0.        ]
 [ 0.        ]
 [-1.3851933 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.2858517 ]
 [-0.        ]]
--- 0.29219818115234375 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3475.620849609375, (1985.8324, 1.658832, 1487.1196, 1.0099194)
   validation loss 961.4310913085938, (607.2262, 0.21326159, 352.9817, 1.0099194)
decoder loss ratio: 23524.997035, decoder SINDy loss  ratio: 0.761961
--- 0.2727649211883545 seconds for one epoch ---
--- 0.298753023147583 seconds for one epoch ---
--- 1.1031544208526611 seconds for one epoch ---
--- 0.29164838790893555 seconds for one epoch ---
--- 1.0590014457702637 seconds for one epoch ---
--- 0.29839563369750977 seconds for one epoch ---
--- 1.1128406524658203 seconds for one epoch ---
--- 0.31275439262390137 seconds for one epoch ---
--- 1.1189019680023193 seconds for one epoch ---
--- 0.310316801071167 seconds for one epoch ---
--- 1.1044666767120361 seconds for one epoch ---
--- 0.30002355575561523 seconds for one epoch ---
--- 1.108215570449829 seconds for one epoch ---
--- 0.30867528915405273 seconds for one epoch ---
--- 1.1197330951690674 seconds for one epoch ---
--- 0.3028686046600342 seconds for one epoch ---
--- 1.1118011474609375 seconds for one epoch ---
--- 0.3001716136932373 seconds for one epoch ---
--- 1.1474087238311768 seconds for one epoch ---
--- 0.30108189582824707 seconds for one epoch ---
--- 1.146819829940796 seconds for one epoch ---
--- 0.30231165885925293 seconds for one epoch ---
--- 1.1145505905151367 seconds for one epoch ---
--- 0.29526376724243164 seconds for one epoch ---
=========================
[[0.05438545]
 [0.99938357]
 [0.63267815]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.21387444]
 [-0.7266203 ]
 [-0.38395536]
 [-0.        ]
 [-0.        ]
 [-1.3707999 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3343704 ]
 [-0.        ]]
--- 0.27260613441467285 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3781.9990234375, (1245.12, 2.7481205, 2533.1497, 0.98113424)
   validation loss 1203.0401611328125, (893.889, 0.27913818, 307.89105, 0.98113424)
decoder loss ratio: 34630.810830, decoder SINDy loss  ratio: 0.664626
--- 0.2948470115661621 seconds for one epoch ---
--- 1.064208745956421 seconds for one epoch ---
--- 0.29500722885131836 seconds for one epoch ---
--- 1.081054449081421 seconds for one epoch ---
--- 0.2975809574127197 seconds for one epoch ---
--- 1.0843300819396973 seconds for one epoch ---
--- 0.3004891872406006 seconds for one epoch ---
--- 1.0880305767059326 seconds for one epoch ---
--- 0.2895364761352539 seconds for one epoch ---
--- 1.0981037616729736 seconds for one epoch ---
--- 0.30280351638793945 seconds for one epoch ---
--- 1.1031684875488281 seconds for one epoch ---
--- 0.30052661895751953 seconds for one epoch ---
--- 1.1157619953155518 seconds for one epoch ---
--- 0.2976353168487549 seconds for one epoch ---
--- 1.1061766147613525 seconds for one epoch ---
--- 0.30375027656555176 seconds for one epoch ---
--- 1.1191585063934326 seconds for one epoch ---
--- 0.29770970344543457 seconds for one epoch ---
--- 1.1288161277770996 seconds for one epoch ---
--- 0.31392574310302734 seconds for one epoch ---
--- 1.1073541641235352 seconds for one epoch ---
--- 0.30439329147338867 seconds for one epoch ---
--- 1.100656270980835 seconds for one epoch ---
=========================
[[0.01765412]
 [0.999372  ]
 [0.54158485]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.15567896]
 [-0.7257491 ]
 [-0.36509123]
 [ 0.        ]
 [-0.        ]
 [-1.3678082 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3945758 ]
 [ 0.        ]]
--- 0.30271339416503906 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3575.945556640625, (1256.7373, 5.9464765, 2312.317, 0.9448177)
   validation loss 917.8892211914062, (616.2242, 0.26002344, 300.4602, 0.9448177)
decoder loss ratio: 23873.594628, decoder SINDy loss  ratio: 0.648586
--- 0.2658815383911133 seconds for one epoch ---
--- 0.303422212600708 seconds for one epoch ---
--- 1.063607931137085 seconds for one epoch ---
--- 0.30043792724609375 seconds for one epoch ---
--- 1.1090788841247559 seconds for one epoch ---
--- 0.3272097110748291 seconds for one epoch ---
--- 1.1282753944396973 seconds for one epoch ---
--- 0.3444647789001465 seconds for one epoch ---
--- 1.119507074356079 seconds for one epoch ---
--- 0.33030247688293457 seconds for one epoch ---
--- 1.1177549362182617 seconds for one epoch ---
--- 0.3270266056060791 seconds for one epoch ---
--- 1.1221494674682617 seconds for one epoch ---
--- 0.33363938331604004 seconds for one epoch ---
--- 1.1107356548309326 seconds for one epoch ---
--- 0.33489418029785156 seconds for one epoch ---
--- 1.164872169494629 seconds for one epoch ---
--- 0.3264453411102295 seconds for one epoch ---
--- 1.1415088176727295 seconds for one epoch ---
--- 0.3305988311767578 seconds for one epoch ---
--- 1.1681549549102783 seconds for one epoch ---
--- 0.32602381706237793 seconds for one epoch ---
--- 1.1603782176971436 seconds for one epoch ---
--- 0.32650279998779297 seconds for one epoch ---
=========================
[[0.00862504]
 [0.9989931 ]
 [0.5138022 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.11938063]
 [-0.7020821 ]
 [-0.35951203]
 [-0.        ]
 [-0.        ]
 [-1.3446736 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.4385755 ]
 [ 0.        ]]
--- 0.2650885581970215 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2767.72021484375, (935.2448, 1.0870438, 1830.4626, 0.92585576)
   validation loss 904.9409790039062, (592.7577, 0.25459677, 311.0029, 0.92585576)
decoder loss ratio: 22964.462000, decoder SINDy loss  ratio: 0.671344
--- 0.29283976554870605 seconds for one epoch ---
--- 1.1067476272583008 seconds for one epoch ---
--- 0.32033395767211914 seconds for one epoch ---
--- 1.1280906200408936 seconds for one epoch ---
--- 0.30446577072143555 seconds for one epoch ---
--- 1.152137041091919 seconds for one epoch ---
--- 0.3362398147583008 seconds for one epoch ---
--- 1.1574976444244385 seconds for one epoch ---
--- 0.31282758712768555 seconds for one epoch ---
--- 1.1775550842285156 seconds for one epoch ---
--- 0.31090259552001953 seconds for one epoch ---
--- 1.1586410999298096 seconds for one epoch ---
--- 0.3110973834991455 seconds for one epoch ---
--- 1.156736135482788 seconds for one epoch ---
--- 0.3065972328186035 seconds for one epoch ---
--- 1.1520195007324219 seconds for one epoch ---
--- 0.3198258876800537 seconds for one epoch ---
--- 1.1692368984222412 seconds for one epoch ---
--- 0.30425477027893066 seconds for one epoch ---
--- 1.1734130382537842 seconds for one epoch ---
--- 0.2959318161010742 seconds for one epoch ---
--- 1.1708154678344727 seconds for one epoch ---
--- 0.29936718940734863 seconds for one epoch ---
--- 1.1502671241760254 seconds for one epoch ---
=========================
[[0.00270118]
 [0.9988673 ]
 [0.40524217]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.06095712]
 [-0.6961901 ]
 [-0.33755204]
 [ 0.        ]
 [ 0.        ]
 [-1.3495213 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.4940908 ]
 [-0.        ]]
--- 0.29642176628112793 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3496.490966796875, (1364.194, 1.2836993, 2130.1235, 0.8898279)
   validation loss 886.2396850585938, (573.6213, 0.2147646, 311.51382, 0.8898279)
decoder loss ratio: 22223.084116, decoder SINDy loss  ratio: 0.672446
--- 0.2594473361968994 seconds for one epoch ---
--- 0.2985200881958008 seconds for one epoch ---
--- 1.123100757598877 seconds for one epoch ---
--- 0.2955331802368164 seconds for one epoch ---
--- 1.136134147644043 seconds for one epoch ---
--- 0.3011038303375244 seconds for one epoch ---
--- 1.1536076068878174 seconds for one epoch ---
--- 0.29662346839904785 seconds for one epoch ---
--- 1.1490025520324707 seconds for one epoch ---
--- 0.2995123863220215 seconds for one epoch ---
--- 1.161184549331665 seconds for one epoch ---
--- 0.29233336448669434 seconds for one epoch ---
--- 1.1449575424194336 seconds for one epoch ---
--- 0.29885101318359375 seconds for one epoch ---
--- 1.134274959564209 seconds for one epoch ---
--- 0.2935526371002197 seconds for one epoch ---
--- 1.151474952697754 seconds for one epoch ---
--- 0.29425668716430664 seconds for one epoch ---
--- 1.1652779579162598 seconds for one epoch ---
--- 0.29845237731933594 seconds for one epoch ---
--- 1.1583070755004883 seconds for one epoch ---
--- 0.30826783180236816 seconds for one epoch ---
--- 1.1563537120819092 seconds for one epoch ---
--- 0.29825544357299805 seconds for one epoch ---
=========================
[[0.00131607]
 [0.99914825]
 [0.38529137]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.02484648]
 [-0.71050006]
 [-0.33337536]
 [ 0.        ]
 [-0.        ]
 [-1.3347049 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.5335574 ]
 [ 0.        ]]
--- 0.264101505279541 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4059.763427734375, (1953.0164, 0.998701, 2104.8782, 0.87037355)
   validation loss 966.4629516601562, (668.321, 0.22544509, 297.04614, 0.87037355)
decoder loss ratio: 25891.915172, decoder SINDy loss  ratio: 0.641216
--- 0.29440855979919434 seconds for one epoch ---
--- 1.1322975158691406 seconds for one epoch ---
--- 0.3001389503479004 seconds for one epoch ---
--- 1.1399857997894287 seconds for one epoch ---
--- 0.29662418365478516 seconds for one epoch ---
--- 1.1854963302612305 seconds for one epoch ---
--- 0.29766225814819336 seconds for one epoch ---
--- 1.2062664031982422 seconds for one epoch ---
--- 0.30373430252075195 seconds for one epoch ---
--- 1.1774978637695312 seconds for one epoch ---
--- 0.2988154888153076 seconds for one epoch ---
--- 1.164698600769043 seconds for one epoch ---
--- 0.29667091369628906 seconds for one epoch ---
--- 1.1495022773742676 seconds for one epoch ---
--- 0.3027036190032959 seconds for one epoch ---
--- 1.1643989086151123 seconds for one epoch ---
--- 0.3067295551300049 seconds for one epoch ---
--- 1.1694080829620361 seconds for one epoch ---
--- 0.3119938373565674 seconds for one epoch ---
--- 1.172407627105713 seconds for one epoch ---
--- 0.31165194511413574 seconds for one epoch ---
--- 1.1834805011749268 seconds for one epoch ---
--- 0.32190608978271484 seconds for one epoch ---
--- 1.1768620014190674 seconds for one epoch ---
=========================
[[0.00122764]
 [0.9987151 ]
 [0.29086933]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.02136835]
 [-0.6898692 ]
 [-0.31216067]
 [-0.        ]
 [ 0.        ]
 [-1.3232054 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.586103  ]
 [-0.        ]]
--- 0.29884982109069824 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3377.791259765625, (944.69806, 4.8657594, 2427.3687, 0.8586362)
   validation loss 1501.664794921875, (1166.8739, 0.22794409, 333.70428, 0.8586362)
decoder loss ratio: 45206.720721, decoder SINDy loss  ratio: 0.720348
--- 0.2537708282470703 seconds for one epoch ---
--- 0.297666072845459 seconds for one epoch ---
--- 1.153414011001587 seconds for one epoch ---
--- 0.3194444179534912 seconds for one epoch ---
--- 1.149026870727539 seconds for one epoch ---
--- 0.3153507709503174 seconds for one epoch ---
--- 1.168419599533081 seconds for one epoch ---
--- 0.31113219261169434 seconds for one epoch ---
--- 1.1791324615478516 seconds for one epoch ---
--- 0.30573081970214844 seconds for one epoch ---
--- 1.1471526622772217 seconds for one epoch ---
--- 0.3035733699798584 seconds for one epoch ---
--- 1.1938393115997314 seconds for one epoch ---
--- 0.3023543357849121 seconds for one epoch ---
--- 1.1635630130767822 seconds for one epoch ---
--- 0.29420900344848633 seconds for one epoch ---
--- 1.1657137870788574 seconds for one epoch ---
--- 0.3155021667480469 seconds for one epoch ---
--- 1.1654305458068848 seconds for one epoch ---
--- 0.30310869216918945 seconds for one epoch ---
--- 1.1681461334228516 seconds for one epoch ---
--- 0.30746030807495117 seconds for one epoch ---
--- 1.156245231628418 seconds for one epoch ---
--- 0.29489731788635254 seconds for one epoch ---
=========================
[[0.00399785]
 [0.99912083]
 [0.2553137 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.08067845]
 [-0.70886207]
 [-0.3031899 ]
 [ 0.        ]
 [ 0.        ]
 [-1.3229191 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.6505675 ]
 [-0.        ]]
--- 0.26373720169067383 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4868.9912109375, (2139.595, 1.427538, 2727.0977, 0.87108624)
   validation loss 921.648681640625, (575.98645, 0.22243959, 344.5687, 0.87108624)
decoder loss ratio: 22314.715037, decoder SINDy loss  ratio: 0.743800
--- 0.29792046546936035 seconds for one epoch ---
--- 1.1450417041778564 seconds for one epoch ---
--- 0.3233067989349365 seconds for one epoch ---
--- 1.1599254608154297 seconds for one epoch ---
--- 0.3413565158843994 seconds for one epoch ---
--- 1.1672382354736328 seconds for one epoch ---
--- 0.33872008323669434 seconds for one epoch ---
--- 1.197859287261963 seconds for one epoch ---
--- 0.3386194705963135 seconds for one epoch ---
--- 1.213440179824829 seconds for one epoch ---
--- 0.3222513198852539 seconds for one epoch ---
--- 1.1942124366760254 seconds for one epoch ---
--- 0.3338508605957031 seconds for one epoch ---
--- 1.2219257354736328 seconds for one epoch ---
--- 0.33881711959838867 seconds for one epoch ---
--- 1.1982510089874268 seconds for one epoch ---
--- 0.33058714866638184 seconds for one epoch ---
--- 1.21714448928833 seconds for one epoch ---
--- 0.3273634910583496 seconds for one epoch ---
--- 1.2284903526306152 seconds for one epoch ---
--- 0.3380134105682373 seconds for one epoch ---
--- 1.188617467880249 seconds for one epoch ---
--- 0.34021425247192383 seconds for one epoch ---
--- 1.2190029621124268 seconds for one epoch ---
=========================
[[0.00911221]
 [0.9991494 ]
 [0.1955733 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.12216768]
 [-0.71055007]
 [-0.2859935 ]
 [-0.        ]
 [-0.        ]
 [-1.3138775 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6945472 ]
 [ 0.        ]]
--- 0.2877683639526367 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2667.55859375, (1026.1483, 0.9647439, 1639.5693, 0.876115)
   validation loss 1061.9075927734375, (748.59796, 0.30857885, 312.12488, 0.876115)
decoder loss ratio: 29001.984649, decoder SINDy loss  ratio: 0.673765
--- 0.2626230716705322 seconds for one epoch ---
--- 0.29676008224487305 seconds for one epoch ---
--- 1.188856601715088 seconds for one epoch ---
--- 0.30548763275146484 seconds for one epoch ---
--- 1.2062830924987793 seconds for one epoch ---
--- 0.302656888961792 seconds for one epoch ---
--- 1.184650182723999 seconds for one epoch ---
--- 0.30495715141296387 seconds for one epoch ---
--- 1.2014336585998535 seconds for one epoch ---
--- 0.3014872074127197 seconds for one epoch ---
--- 1.1758449077606201 seconds for one epoch ---
--- 0.29987478256225586 seconds for one epoch ---
--- 1.201706886291504 seconds for one epoch ---
--- 0.3016688823699951 seconds for one epoch ---
--- 1.204836368560791 seconds for one epoch ---
--- 0.30995678901672363 seconds for one epoch ---
--- 1.1923980712890625 seconds for one epoch ---
--- 0.29889631271362305 seconds for one epoch ---
--- 1.1808404922485352 seconds for one epoch ---
--- 0.304595947265625 seconds for one epoch ---
--- 1.226151704788208 seconds for one epoch ---
--- 0.2951350212097168 seconds for one epoch ---
--- 1.220128059387207 seconds for one epoch ---
--- 0.29927754402160645 seconds for one epoch ---
=========================
[[0.01617582]
 [0.9993262 ]
 [0.19423142]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.15123844]
 [-0.7222657 ]
 [-0.28556573]
 [-0.        ]
 [ 0.        ]
 [-1.3013016 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.7206373 ]
 [ 0.        ]]
--- 0.264923095703125 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2269.95068359375, (863.95215, 0.5945448, 1404.5177, 0.88617927)
   validation loss 1060.278564453125, (738.54913, 0.27273223, 320.57053, 0.88617927)
decoder loss ratio: 28612.675602, decoder SINDy loss  ratio: 0.691997
--- 0.3287324905395508 seconds for one epoch ---
--- 1.1927058696746826 seconds for one epoch ---
--- 0.3313002586364746 seconds for one epoch ---
--- 1.1928129196166992 seconds for one epoch ---
--- 0.3352077007293701 seconds for one epoch ---
--- 1.1973202228546143 seconds for one epoch ---
--- 0.3334054946899414 seconds for one epoch ---
--- 1.1956703662872314 seconds for one epoch ---
--- 0.32830810546875 seconds for one epoch ---
--- 1.2023510932922363 seconds for one epoch ---
--- 0.3505861759185791 seconds for one epoch ---
--- 1.2245638370513916 seconds for one epoch ---
--- 0.32970643043518066 seconds for one epoch ---
--- 1.2177009582519531 seconds for one epoch ---
--- 0.32266831398010254 seconds for one epoch ---
--- 1.1999363899230957 seconds for one epoch ---
--- 0.3392064571380615 seconds for one epoch ---
--- 1.233304500579834 seconds for one epoch ---
--- 0.3435494899749756 seconds for one epoch ---
--- 1.2090377807617188 seconds for one epoch ---
--- 0.3234977722167969 seconds for one epoch ---
--- 1.228348731994629 seconds for one epoch ---
--- 0.3381345272064209 seconds for one epoch ---
--- 1.260873556137085 seconds for one epoch ---
=========================
[[0.03580062]
 [0.9994781 ]
 [0.20436798]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.19198821]
 [-0.73505175]
 [-0.2887442 ]
 [-0.        ]
 [-0.        ]
 [-1.292585  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7659738 ]
 [-0.        ]]
--- 0.29323577880859375 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6156.833984375, (1233.1862, 1.3706088, 4921.367, 0.9102629)
   validation loss 979.7943115234375, (641.28687, 0.17699446, 337.42014, 0.9102629)
decoder loss ratio: 24844.566482, decoder SINDy loss  ratio: 0.728369
THRESHOLDING: 4 active coefficients
--- 1.1911423206329346 seconds for one epoch ---
--- 0.3008120059967041 seconds for one epoch ---
--- 1.20965576171875 seconds for one epoch ---
--- 0.29782867431640625 seconds for one epoch ---
--- 1.2078793048858643 seconds for one epoch ---
--- 0.2948331832885742 seconds for one epoch ---
--- 1.1984126567840576 seconds for one epoch ---
--- 0.2979898452758789 seconds for one epoch ---
--- 1.2001597881317139 seconds for one epoch ---
--- 0.3035125732421875 seconds for one epoch ---
--- 1.228963851928711 seconds for one epoch ---
--- 0.2977421283721924 seconds for one epoch ---
--- 1.2416319847106934 seconds for one epoch ---
--- 0.31187868118286133 seconds for one epoch ---
--- 1.216165542602539 seconds for one epoch ---
--- 0.2949240207672119 seconds for one epoch ---
--- 1.2367193698883057 seconds for one epoch ---
--- 0.2972099781036377 seconds for one epoch ---
--- 1.2165718078613281 seconds for one epoch ---
--- 0.3003396987915039 seconds for one epoch ---
--- 1.2368478775024414 seconds for one epoch ---
--- 0.307680606842041 seconds for one epoch ---
--- 1.1797771453857422 seconds for one epoch ---
--- 0.29060792922973633 seconds for one epoch ---
=========================
[[0.        ]
 [0.9987859 ]
 [0.22128409]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.69274265]
 [-0.2937981 ]
 [ 0.        ]
 [-0.        ]
 [-1.3091863 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.8183324 ]
 [ 0.        ]]
--- 0.268204927444458 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4344.197265625, (2443.0632, 0.7813791, 1899.506, 0.8468081)
   validation loss 2045.7891845703125, (1689.1854, 0.27792066, 355.47894, 0.8468081)
decoder loss ratio: 65441.975912, decoder SINDy loss  ratio: 0.767351
--- 0.32642078399658203 seconds for one epoch ---
--- 1.2537810802459717 seconds for one epoch ---
--- 0.3336977958679199 seconds for one epoch ---
--- 1.2335777282714844 seconds for one epoch ---
--- 0.34198451042175293 seconds for one epoch ---
--- 1.2321412563323975 seconds for one epoch ---
--- 0.2981095314025879 seconds for one epoch ---
--- 1.2506237030029297 seconds for one epoch ---
--- 0.31170082092285156 seconds for one epoch ---
--- 1.231734275817871 seconds for one epoch ---
--- 0.2998530864715576 seconds for one epoch ---
--- 1.247868299484253 seconds for one epoch ---
--- 0.3030734062194824 seconds for one epoch ---
--- 1.2573211193084717 seconds for one epoch ---
--- 0.3086566925048828 seconds for one epoch ---
--- 1.21372652053833 seconds for one epoch ---
--- 0.29535770416259766 seconds for one epoch ---
--- 1.2075400352478027 seconds for one epoch ---
--- 0.2986869812011719 seconds for one epoch ---
--- 1.2473604679107666 seconds for one epoch ---
--- 0.29897189140319824 seconds for one epoch ---
--- 1.251023530960083 seconds for one epoch ---
--- 0.2965846061706543 seconds for one epoch ---
--- 1.2224788665771484 seconds for one epoch ---
=========================
[[0.        ]
 [0.99850893]
 [0.18541805]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.68241507]
 [-0.28269848]
 [-0.        ]
 [-0.        ]
 [-1.3029869 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.8624916 ]
 [-0.        ]]
--- 0.29804182052612305 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4654.67138671875, (1940.3035, 1.1151844, 2712.4153, 0.83727837)
   validation loss 803.244140625, (502.36856, 0.32244635, 299.71582, 0.83727837)
decoder loss ratio: 19462.630195, decoder SINDy loss  ratio: 0.646979
--- 0.26805996894836426 seconds for one epoch ---
--- 0.30821824073791504 seconds for one epoch ---
--- 1.226691484451294 seconds for one epoch ---
--- 0.29933714866638184 seconds for one epoch ---
--- 1.2249751091003418 seconds for one epoch ---
--- 0.3011496067047119 seconds for one epoch ---
--- 1.2378301620483398 seconds for one epoch ---
--- 0.29625630378723145 seconds for one epoch ---
--- 1.226604700088501 seconds for one epoch ---
--- 0.2993760108947754 seconds for one epoch ---
--- 1.2657709121704102 seconds for one epoch ---
--- 0.3014066219329834 seconds for one epoch ---
--- 1.258275032043457 seconds for one epoch ---
--- 0.30355191230773926 seconds for one epoch ---
--- 1.2482609748840332 seconds for one epoch ---
--- 0.30362820625305176 seconds for one epoch ---
--- 1.2405762672424316 seconds for one epoch ---
--- 0.3018779754638672 seconds for one epoch ---
--- 1.2420623302459717 seconds for one epoch ---
--- 0.2991909980773926 seconds for one epoch ---
--- 1.247800350189209 seconds for one epoch ---
--- 0.302661657333374 seconds for one epoch ---
--- 1.2678577899932861 seconds for one epoch ---
--- 0.310558557510376 seconds for one epoch ---
=========================
[[0.        ]
 [0.99801564]
 [0.22454736]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.6681117 ]
 [-0.29474068]
 [ 0.        ]
 [ 0.        ]
 [-1.3167659 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9132376 ]
 [-0.        ]]
--- 0.2648909091949463 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2448.219482421875, (1471.7393, 0.25192142, 975.38306, 0.84530735)
   validation loss 1161.1885986328125, (855.18115, 0.2821256, 304.87994, 0.84530735)
decoder loss ratio: 33131.202502, decoder SINDy loss  ratio: 0.658126
--- 0.2950916290283203 seconds for one epoch ---
--- 1.2336962223052979 seconds for one epoch ---
--- 0.29750633239746094 seconds for one epoch ---
--- 1.2687597274780273 seconds for one epoch ---
--- 0.29172539710998535 seconds for one epoch ---
--- 1.2408020496368408 seconds for one epoch ---
--- 0.3162109851837158 seconds for one epoch ---
--- 1.2579154968261719 seconds for one epoch ---
--- 0.30385637283325195 seconds for one epoch ---
--- 1.2637786865234375 seconds for one epoch ---
--- 0.3154942989349365 seconds for one epoch ---
--- 1.256993055343628 seconds for one epoch ---
--- 0.306351900100708 seconds for one epoch ---
--- 1.2706091403961182 seconds for one epoch ---
--- 0.2906620502471924 seconds for one epoch ---
--- 1.2708394527435303 seconds for one epoch ---
--- 0.29840779304504395 seconds for one epoch ---
--- 1.2694342136383057 seconds for one epoch ---
--- 0.3242917060852051 seconds for one epoch ---
--- 1.2804656028747559 seconds for one epoch ---
--- 0.31585240364074707 seconds for one epoch ---
--- 1.262031078338623 seconds for one epoch ---
--- 0.30827832221984863 seconds for one epoch ---
--- 1.2596571445465088 seconds for one epoch ---
=========================
[[0.        ]
 [0.998201  ]
 [0.19195473]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.67301154]
 [-0.284835  ]
 [ 0.        ]
 [-0.        ]
 [-1.3134245 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9538834 ]
 [ 0.        ]]
--- 0.30021238327026367 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2845.078125, (1243.286, 1.0515379, 1599.9006, 0.8397307)
   validation loss 1038.5592041015625, (737.42175, 0.22832936, 300.06934, 0.8397307)
decoder loss ratio: 28568.998929, decoder SINDy loss  ratio: 0.647742
--- 0.26381444931030273 seconds for one epoch ---
--- 0.31891655921936035 seconds for one epoch ---
--- 1.2567310333251953 seconds for one epoch ---
--- 0.32173705101013184 seconds for one epoch ---
--- 1.249027967453003 seconds for one epoch ---
--- 0.31385350227355957 seconds for one epoch ---
--- 1.2605445384979248 seconds for one epoch ---
--- 0.3492591381072998 seconds for one epoch ---
--- 1.2613260746002197 seconds for one epoch ---
--- 0.32098388671875 seconds for one epoch ---
--- 1.270418405532837 seconds for one epoch ---
--- 0.33541250228881836 seconds for one epoch ---
--- 1.271000862121582 seconds for one epoch ---
--- 0.33617568016052246 seconds for one epoch ---
--- 1.2653908729553223 seconds for one epoch ---
--- 0.3427877426147461 seconds for one epoch ---
--- 1.3040258884429932 seconds for one epoch ---
--- 0.3381462097167969 seconds for one epoch ---
--- 1.2728276252746582 seconds for one epoch ---
--- 0.3349037170410156 seconds for one epoch ---
--- 1.2722692489624023 seconds for one epoch ---
--- 0.31951308250427246 seconds for one epoch ---
--- 1.2849960327148438 seconds for one epoch ---
--- 0.2979586124420166 seconds for one epoch ---
=========================
[[0.        ]
 [0.9980812 ]
 [0.18452784]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.66978   ]
 [-0.28240323]
 [-0.        ]
 [ 0.        ]
 [-1.3014413 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.005572  ]
 [ 0.        ]]
--- 0.28165555000305176 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4476.65087890625, (2061.7886, 2.7924085, 2411.2317, 0.83842593)
   validation loss 972.4647827148438, (675.37317, 0.26713064, 295.98605, 0.83842593)
decoder loss ratio: 26165.129064, decoder SINDy loss  ratio: 0.638928
--- 0.3006713390350342 seconds for one epoch ---
--- 1.2864067554473877 seconds for one epoch ---
--- 0.2983534336090088 seconds for one epoch ---
--- 1.2804944515228271 seconds for one epoch ---
--- 0.2970254421234131 seconds for one epoch ---
--- 1.2593672275543213 seconds for one epoch ---
--- 0.297102689743042 seconds for one epoch ---
--- 1.2980914115905762 seconds for one epoch ---
--- 0.3005075454711914 seconds for one epoch ---
--- 1.281095266342163 seconds for one epoch ---
--- 0.3000948429107666 seconds for one epoch ---
--- 1.2929368019104004 seconds for one epoch ---
--- 0.3036537170410156 seconds for one epoch ---
--- 1.2676591873168945 seconds for one epoch ---
--- 0.2901942729949951 seconds for one epoch ---
--- 1.3030478954315186 seconds for one epoch ---
--- 0.29831957817077637 seconds for one epoch ---
--- 1.3048019409179688 seconds for one epoch ---
--- 0.302201509475708 seconds for one epoch ---
--- 1.2836859226226807 seconds for one epoch ---
--- 0.29607105255126953 seconds for one epoch ---
--- 1.267254114151001 seconds for one epoch ---
--- 0.296917200088501 seconds for one epoch ---
--- 1.2720561027526855 seconds for one epoch ---
=========================
[[0.        ]
 [0.99774396]
 [0.19175968]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6616602]
 [-0.2847722]
 [ 0.       ]
 [ 0.       ]
 [-1.310036 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.0425277]
 [-0.       ]]
--- 0.2995316982269287 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1701.458740234375, (779.89954, 0.19401416, 920.52295, 0.84228563)
   validation loss 843.849609375, (527.814, 0.24855615, 314.94476, 0.84228563)
decoder loss ratio: 20448.431688, decoder SINDy loss  ratio: 0.679853
--- 0.2848231792449951 seconds for one epoch ---
--- 0.2974569797515869 seconds for one epoch ---
--- 1.2951045036315918 seconds for one epoch ---
--- 0.3109719753265381 seconds for one epoch ---
--- 1.2959012985229492 seconds for one epoch ---
--- 0.29855823516845703 seconds for one epoch ---
--- 1.3290674686431885 seconds for one epoch ---
--- 0.3039891719818115 seconds for one epoch ---
--- 1.308783769607544 seconds for one epoch ---
--- 0.28452491760253906 seconds for one epoch ---
--- 1.293194055557251 seconds for one epoch ---
--- 0.3007190227508545 seconds for one epoch ---
--- 1.3005869388580322 seconds for one epoch ---
--- 0.2998807430267334 seconds for one epoch ---
--- 1.285933017730713 seconds for one epoch ---
--- 0.2956693172454834 seconds for one epoch ---
--- 1.2967073917388916 seconds for one epoch ---
--- 0.30856847763061523 seconds for one epoch ---
--- 1.3120605945587158 seconds for one epoch ---
--- 0.29534912109375 seconds for one epoch ---
--- 1.3045916557312012 seconds for one epoch ---
--- 0.30710911750793457 seconds for one epoch ---
--- 1.298976182937622 seconds for one epoch ---
--- 0.2968270778656006 seconds for one epoch ---
=========================
[[0.        ]
 [0.9986408 ]
 [0.20414957]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.68707615]
 [-0.2886773 ]
 [-0.        ]
 [-0.        ]
 [-1.302056  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.081581  ]
 [ 0.        ]]
--- 0.26725268363952637 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3628.98974609375, (1460.7167, 2.3849518, 2165.046, 0.8422046)
   validation loss 1166.9483642578125, (876.5429, 0.26250112, 289.30084, 0.8422046)
decoder loss ratio: 33958.793990, decoder SINDy loss  ratio: 0.624497
--- 0.29065608978271484 seconds for one epoch ---
--- 1.2998766899108887 seconds for one epoch ---
--- 0.2933988571166992 seconds for one epoch ---
--- 1.3124315738677979 seconds for one epoch ---
--- 0.3064544200897217 seconds for one epoch ---
--- 1.3169867992401123 seconds for one epoch ---
--- 0.3015472888946533 seconds for one epoch ---
--- 1.3384168148040771 seconds for one epoch ---
--- 0.30310988426208496 seconds for one epoch ---
--- 1.2919974327087402 seconds for one epoch ---
--- 0.30713796615600586 seconds for one epoch ---
--- 1.3179750442504883 seconds for one epoch ---
--- 0.31437134742736816 seconds for one epoch ---
--- 1.3114986419677734 seconds for one epoch ---
--- 0.295379638671875 seconds for one epoch ---
--- 1.2851941585540771 seconds for one epoch ---
--- 0.30003786087036133 seconds for one epoch ---
--- 1.2820794582366943 seconds for one epoch ---
--- 0.3065152168273926 seconds for one epoch ---
--- 1.300809621810913 seconds for one epoch ---
--- 0.30028867721557617 seconds for one epoch ---
--- 1.3306710720062256 seconds for one epoch ---
--- 0.2979717254638672 seconds for one epoch ---
--- 1.3069376945495605 seconds for one epoch ---
=========================
[[0.        ]
 [0.9988246 ]
 [0.17017283]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.6943624 ]
 [-0.27747878]
 [-0.        ]
 [ 0.        ]
 [-1.2978972 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.112415  ]
 [-0.        ]]
--- 0.314408540725708 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3255.860595703125, (1276.6317, 2.6448526, 1975.748, 0.83591884)
   validation loss 844.056884765625, (533.1132, 0.3229049, 309.78482, 0.83591884)
decoder loss ratio: 20653.731676, decoder SINDy loss  ratio: 0.668714
--- 0.29139161109924316 seconds for one epoch ---
--- 0.3302648067474365 seconds for one epoch ---
--- 1.3569896221160889 seconds for one epoch ---
--- 0.33032727241516113 seconds for one epoch ---
--- 1.3301353454589844 seconds for one epoch ---
--- 0.32988524436950684 seconds for one epoch ---
--- 1.3341081142425537 seconds for one epoch ---
--- 0.3184998035430908 seconds for one epoch ---
--- 1.3496251106262207 seconds for one epoch ---
--- 0.3015446662902832 seconds for one epoch ---
--- 1.3075535297393799 seconds for one epoch ---
--- 0.3207547664642334 seconds for one epoch ---
--- 1.3397445678710938 seconds for one epoch ---
--- 0.3306753635406494 seconds for one epoch ---
--- 1.3523280620574951 seconds for one epoch ---
--- 0.3125145435333252 seconds for one epoch ---
--- 1.3411879539489746 seconds for one epoch ---
--- 0.3087430000305176 seconds for one epoch ---
--- 1.3393490314483643 seconds for one epoch ---
--- 0.29837679862976074 seconds for one epoch ---
--- 1.328066349029541 seconds for one epoch ---
--- 0.30109524726867676 seconds for one epoch ---
--- 1.3232934474945068 seconds for one epoch ---
--- 0.3148829936981201 seconds for one epoch ---
=========================
[[0.        ]
 [0.9983603 ]
 [0.17961273]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.67766577]
 [-0.28075206]
 [-0.        ]
 [-0.        ]
 [-1.2907909 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.1470075 ]
 [-0.        ]]
--- 0.2650127410888672 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5072.05224609375, (1336.7603, 0.78333324, 3733.6692, 0.83911973)
   validation loss 833.9647216796875, (517.54944, 0.3180028, 315.25818, 0.83911973)
decoder loss ratio: 20050.763752, decoder SINDy loss  ratio: 0.680529
--- 0.2999591827392578 seconds for one epoch ---
--- 1.3337502479553223 seconds for one epoch ---
--- 0.3261229991912842 seconds for one epoch ---
--- 1.3164160251617432 seconds for one epoch ---
--- 0.2936587333679199 seconds for one epoch ---
--- 1.329301118850708 seconds for one epoch ---
--- 0.3008425235748291 seconds for one epoch ---
--- 1.3300933837890625 seconds for one epoch ---
--- 0.28345823287963867 seconds for one epoch ---
--- 1.3041882514953613 seconds for one epoch ---
--- 0.3010892868041992 seconds for one epoch ---
--- 1.3438646793365479 seconds for one epoch ---
--- 0.2986304759979248 seconds for one epoch ---
--- 1.3489010334014893 seconds for one epoch ---
--- 0.28122973442077637 seconds for one epoch ---
--- 1.3416283130645752 seconds for one epoch ---
--- 0.2977564334869385 seconds for one epoch ---
--- 1.3436129093170166 seconds for one epoch ---
--- 0.2959573268890381 seconds for one epoch ---
--- 1.3683507442474365 seconds for one epoch ---
--- 0.30922532081604004 seconds for one epoch ---
--- 1.3357925415039062 seconds for one epoch ---
--- 0.30075573921203613 seconds for one epoch ---
--- 1.3520517349243164 seconds for one epoch ---
=========================
[[0.        ]
 [0.99744064]
 [0.16915151]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.6553208 ]
 [-0.27711618]
 [ 0.        ]
 [-0.        ]
 [-1.2923119 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.1841946 ]
 [ 0.        ]]
--- 0.29737186431884766 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4035.522705078125, (2065.907, 2.3111742, 1966.4685, 0.8358161)
   validation loss 1555.0914306640625, (1189.9167, 0.30007473, 364.03888, 0.8358161)
decoder loss ratio: 46099.440606, decoder SINDy loss  ratio: 0.785829
--- 0.2794468402862549 seconds for one epoch ---
--- 0.3024721145629883 seconds for one epoch ---
--- 1.341996669769287 seconds for one epoch ---
--- 0.30066800117492676 seconds for one epoch ---
--- 1.3428552150726318 seconds for one epoch ---
--- 0.30794310569763184 seconds for one epoch ---
--- 1.3328657150268555 seconds for one epoch ---
--- 0.3023216724395752 seconds for one epoch ---
--- 1.3466312885284424 seconds for one epoch ---
--- 0.5520474910736084 seconds for one epoch ---
--- 1.319312572479248 seconds for one epoch ---
--- 0.29586052894592285 seconds for one epoch ---
--- 1.333181381225586 seconds for one epoch ---
--- 0.29895949363708496 seconds for one epoch ---
--- 1.343214750289917 seconds for one epoch ---
--- 0.3097505569458008 seconds for one epoch ---
--- 1.3166043758392334 seconds for one epoch ---
--- 0.2965834140777588 seconds for one epoch ---
--- 1.3319172859191895 seconds for one epoch ---
--- 0.29255104064941406 seconds for one epoch ---
--- 1.3512330055236816 seconds for one epoch ---
--- 0.2940075397491455 seconds for one epoch ---
--- 1.3281965255737305 seconds for one epoch ---
--- 0.2982316017150879 seconds for one epoch ---
=========================
[[0.       ]
 [0.9976056]
 [0.1548859]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.65865934]
 [-0.27185673]
 [-0.        ]
 [-0.        ]
 [-1.3040512 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.2348166 ]
 [ 0.        ]]
--- 0.2709691524505615 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2955.0537109375, (1209.268, 2.83703, 1742.1161, 0.8324413)
   validation loss 1026.5035400390625, (707.2993, 0.3236284, 318.04825, 0.8324413)
decoder loss ratio: 27402.003443, decoder SINDy loss  ratio: 0.686552
--- 0.30095601081848145 seconds for one epoch ---
--- 1.3466949462890625 seconds for one epoch ---
--- 0.30156373977661133 seconds for one epoch ---
--- 1.3422918319702148 seconds for one epoch ---
--- 0.30547332763671875 seconds for one epoch ---
--- 1.3700573444366455 seconds for one epoch ---
--- 0.29546046257019043 seconds for one epoch ---
--- 1.3725204467773438 seconds for one epoch ---
--- 0.30378079414367676 seconds for one epoch ---
--- 1.3759989738464355 seconds for one epoch ---
--- 0.3040890693664551 seconds for one epoch ---
--- 1.3744444847106934 seconds for one epoch ---
--- 0.30078983306884766 seconds for one epoch ---
--- 1.3568894863128662 seconds for one epoch ---
--- 0.29993486404418945 seconds for one epoch ---
--- 1.378976583480835 seconds for one epoch ---
--- 0.301314115524292 seconds for one epoch ---
--- 1.3474798202514648 seconds for one epoch ---
--- 0.3001530170440674 seconds for one epoch ---
--- 1.35032057762146 seconds for one epoch ---
--- 0.2981598377227783 seconds for one epoch ---
--- 1.353837251663208 seconds for one epoch ---
--- 0.30320239067077637 seconds for one epoch ---
--- 1.3591341972351074 seconds for one epoch ---
=========================
[[0.        ]
 [0.99833584]
 [0.13438798]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.6769137 ]
 [-0.26355615]
 [ 0.        ]
 [ 0.        ]
 [-1.3027767 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.2668843 ]
 [-0.        ]]
--- 0.30024123191833496 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4047.868896484375, (2824.5015, 0.4808995, 1222.0571, 0.82939255)
   validation loss 1786.242431640625, (1468.1844, 0.34455702, 316.884, 0.82939255)
decoder loss ratio: 56880.014405, decoder SINDy loss  ratio: 0.684039
--- 0.2767508029937744 seconds for one epoch ---
--- 0.3019232749938965 seconds for one epoch ---
--- 1.3759355545043945 seconds for one epoch ---
--- 0.30079102516174316 seconds for one epoch ---
--- 1.3515172004699707 seconds for one epoch ---
--- 0.29952096939086914 seconds for one epoch ---
--- 1.3683032989501953 seconds for one epoch ---
--- 0.302459716796875 seconds for one epoch ---
--- 1.3815197944641113 seconds for one epoch ---
--- 0.30014967918395996 seconds for one epoch ---
--- 1.3632473945617676 seconds for one epoch ---
--- 0.3067293167114258 seconds for one epoch ---
--- 1.3769307136535645 seconds for one epoch ---
--- 0.30130958557128906 seconds for one epoch ---
--- 1.36464262008667 seconds for one epoch ---
--- 0.31786608695983887 seconds for one epoch ---
--- 1.352100133895874 seconds for one epoch ---
--- 0.30510568618774414 seconds for one epoch ---
--- 1.37105393409729 seconds for one epoch ---
--- 0.30321455001831055 seconds for one epoch ---
--- 1.3568661212921143 seconds for one epoch ---
--- 0.2994821071624756 seconds for one epoch ---
--- 1.3568871021270752 seconds for one epoch ---
--- 0.2985827922821045 seconds for one epoch ---
=========================
[[0.        ]
 [0.9986705 ]
 [0.11488016]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.68815917]
 [-0.25459504]
 [ 0.        ]
 [-0.        ]
 [-1.289742  ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.2990375 ]
 [ 0.        ]]
--- 0.2672388553619385 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2706.847412109375, (1378.6677, 1.04383, 1326.3121, 0.82367355)
   validation loss 1330.25, (1020.7247, 0.29184073, 308.40976, 0.82367355)
decoder loss ratio: 39544.645788, decoder SINDy loss  ratio: 0.665746
--- 0.31001758575439453 seconds for one epoch ---
--- 1.3687660694122314 seconds for one epoch ---
--- 0.2947561740875244 seconds for one epoch ---
--- 1.3753368854522705 seconds for one epoch ---
--- 0.28992509841918945 seconds for one epoch ---
--- 1.3701796531677246 seconds for one epoch ---
--- 0.3030424118041992 seconds for one epoch ---
--- 1.3410730361938477 seconds for one epoch ---
--- 0.2894604206085205 seconds for one epoch ---
--- 1.3549854755401611 seconds for one epoch ---
--- 0.294649600982666 seconds for one epoch ---
--- 1.3655805587768555 seconds for one epoch ---
--- 0.2945253849029541 seconds for one epoch ---
--- 1.367666482925415 seconds for one epoch ---
--- 0.3005104064941406 seconds for one epoch ---
--- 1.3641953468322754 seconds for one epoch ---
--- 0.30097079277038574 seconds for one epoch ---
--- 1.3970415592193604 seconds for one epoch ---
--- 0.307833194732666 seconds for one epoch ---
--- 1.3955175876617432 seconds for one epoch ---
--- 0.30945444107055664 seconds for one epoch ---
--- 1.3813230991363525 seconds for one epoch ---
--- 0.3081214427947998 seconds for one epoch ---
--- 1.3983027935028076 seconds for one epoch ---
=========================
[[0.        ]
 [0.998298  ]
 [0.10599913]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.67577875]
 [-0.25007066]
 [-0.        ]
 [ 0.        ]
 [-1.2835718 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.3266764 ]
 [-0.        ]]
--- 0.29250502586364746 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3208.939453125, (1170.4987, 1.0502348, 2036.5691, 0.82133305)
   validation loss 819.9196166992188, (512.5924, 0.3232535, 306.18262, 0.82133305)
decoder loss ratio: 19858.719756, decoder SINDy loss  ratio: 0.660938
--- 0.2646970748901367 seconds for one epoch ---
--- 0.3124995231628418 seconds for one epoch ---
--- 1.4012880325317383 seconds for one epoch ---
--- 0.3379659652709961 seconds for one epoch ---
--- 1.3878228664398193 seconds for one epoch ---
--- 0.33652591705322266 seconds for one epoch ---
--- 1.3790864944458008 seconds for one epoch ---
--- 0.33304476737976074 seconds for one epoch ---
--- 1.3814942836761475 seconds for one epoch ---
--- 0.3273143768310547 seconds for one epoch ---
--- 1.3683035373687744 seconds for one epoch ---
--- 0.334766149520874 seconds for one epoch ---
--- 1.393312692642212 seconds for one epoch ---
--- 0.32207155227661133 seconds for one epoch ---
--- 1.4190871715545654 seconds for one epoch ---
--- 0.32282471656799316 seconds for one epoch ---
--- 1.3893611431121826 seconds for one epoch ---
--- 0.30013132095336914 seconds for one epoch ---
--- 1.369987964630127 seconds for one epoch ---
--- 0.28998780250549316 seconds for one epoch ---
--- 1.3775815963745117 seconds for one epoch ---
--- 0.2906649112701416 seconds for one epoch ---
--- 1.386228322982788 seconds for one epoch ---
--- 0.3020803928375244 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991344]
 [0.1007559]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.70969105]
 [-0.24724033]
 [ 0.        ]
 [ 0.        ]
 [-1.2779369 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.358773  ]
 [-0.        ]]
--- 0.2523972988128662 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3269.209716796875, (1418.5466, 2.7399762, 1847.1046, 0.8184841)
   validation loss 861.0833129882812, (556.63684, 0.26950204, 303.35846, 0.8184841)
decoder loss ratio: 21565.077577, decoder SINDy loss  ratio: 0.654842
--- 0.3236124515533447 seconds for one epoch ---
--- 1.3723042011260986 seconds for one epoch ---
--- 0.3261709213256836 seconds for one epoch ---
--- 1.4062552452087402 seconds for one epoch ---
--- 0.3370034694671631 seconds for one epoch ---
--- 1.3906230926513672 seconds for one epoch ---
--- 0.33351850509643555 seconds for one epoch ---
--- 1.3837242126464844 seconds for one epoch ---
--- 0.34093451499938965 seconds for one epoch ---
--- 1.3843414783477783 seconds for one epoch ---
--- 0.3336801528930664 seconds for one epoch ---
--- 1.4090588092803955 seconds for one epoch ---
--- 0.33278894424438477 seconds for one epoch ---
--- 1.401660442352295 seconds for one epoch ---
--- 0.3392496109008789 seconds for one epoch ---
--- 1.4131038188934326 seconds for one epoch ---
--- 0.3023102283477783 seconds for one epoch ---
--- 1.4111807346343994 seconds for one epoch ---
--- 0.3237438201904297 seconds for one epoch ---
--- 1.410750389099121 seconds for one epoch ---
--- 0.30492091178894043 seconds for one epoch ---
--- 1.4014105796813965 seconds for one epoch ---
--- 0.2886195182800293 seconds for one epoch ---
--- 1.4361894130706787 seconds for one epoch ---
=========================
[[0.        ]
 [0.9993987 ]
 [0.10700355]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.7279141 ]
 [-0.25059873]
 [-0.        ]
 [-0.        ]
 [-1.2777982 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.394629  ]
 [ 0.        ]]
--- 0.29547548294067383 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2936.732666015625, (956.66693, 1.7133, 1977.533, 0.81963205)
   validation loss 1401.6407470703125, (1036.8042, 0.25168407, 363.76526, 0.81963205)
decoder loss ratio: 40167.594649, decoder SINDy loss  ratio: 0.785238
--- 0.26805591583251953 seconds for one epoch ---
--- 0.308107852935791 seconds for one epoch ---
--- 1.394286870956421 seconds for one epoch ---
--- 0.2926919460296631 seconds for one epoch ---
--- 1.4028651714324951 seconds for one epoch ---
--- 0.29877495765686035 seconds for one epoch ---
--- 1.3976492881774902 seconds for one epoch ---
--- 0.3083817958831787 seconds for one epoch ---
--- 1.3944571018218994 seconds for one epoch ---
--- 0.30361080169677734 seconds for one epoch ---
--- 1.4125211238861084 seconds for one epoch ---
--- 0.3099379539489746 seconds for one epoch ---
--- 1.4273045063018799 seconds for one epoch ---
--- 0.30234766006469727 seconds for one epoch ---
--- 1.4061338901519775 seconds for one epoch ---
--- 0.29670095443725586 seconds for one epoch ---
--- 1.4060497283935547 seconds for one epoch ---
--- 0.3001682758331299 seconds for one epoch ---
--- 1.3929860591888428 seconds for one epoch ---
--- 0.2960643768310547 seconds for one epoch ---
--- 1.3827705383300781 seconds for one epoch ---
--- 0.303727388381958 seconds for one epoch ---
--- 1.4302115440368652 seconds for one epoch ---
--- 0.3023343086242676 seconds for one epoch ---
=========================
[[0.        ]
 [0.9993322 ]
 [0.11256214]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.72262746]
 [-0.2534446 ]
 [-0.        ]
 [ 0.        ]
 [-1.269864  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.43814   ]
 [ 0.        ]]
--- 0.2731969356536865 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3912.52392578125, (2121.4805, 0.51808536, 1789.7045, 0.8208944)
   validation loss 763.85302734375, (445.8811, 0.30461955, 316.8464, 0.8208944)
decoder loss ratio: 17274.208034, decoder SINDy loss  ratio: 0.683958
--- 0.30338096618652344 seconds for one epoch ---
--- 1.3944997787475586 seconds for one epoch ---
--- 0.30518436431884766 seconds for one epoch ---
--- 1.408909559249878 seconds for one epoch ---
--- 0.31087803840637207 seconds for one epoch ---
--- 1.4316277503967285 seconds for one epoch ---
--- 0.30178165435791016 seconds for one epoch ---
--- 1.4234380722045898 seconds for one epoch ---
--- 0.2980537414550781 seconds for one epoch ---
--- 1.421947717666626 seconds for one epoch ---
--- 0.3020060062408447 seconds for one epoch ---
--- 1.4346551895141602 seconds for one epoch ---
--- 0.29799938201904297 seconds for one epoch ---
--- 1.3992233276367188 seconds for one epoch ---
--- 0.2921104431152344 seconds for one epoch ---
--- 1.3962960243225098 seconds for one epoch ---
--- 0.2941298484802246 seconds for one epoch ---
--- 1.4236319065093994 seconds for one epoch ---
--- 0.29666614532470703 seconds for one epoch ---
--- 1.412041425704956 seconds for one epoch ---
--- 0.29630208015441895 seconds for one epoch ---
--- 1.4083991050720215 seconds for one epoch ---
--- 0.30118441581726074 seconds for one epoch ---
--- 1.4527404308319092 seconds for one epoch ---
=========================
[[0.        ]
 [0.9994968 ]
 [0.12792741]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.73689467]
 [-0.26071948]
 [-0.        ]
 [-0.        ]
 [-1.2697004 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.474326  ]
 [-0.        ]]
--- 0.29291319847106934 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3577.697021484375, (1575.3019, 2.0589802, 1999.5116, 0.82449067)
   validation loss 903.3960571289062, (566.49817, 0.29029077, 335.78314, 0.82449067)
decoder loss ratio: 21947.122549, decoder SINDy loss  ratio: 0.724835
--- 0.2657902240753174 seconds for one epoch ---
--- 0.30025219917297363 seconds for one epoch ---
--- 1.4405741691589355 seconds for one epoch ---
--- 0.30681753158569336 seconds for one epoch ---
--- 1.4558131694793701 seconds for one epoch ---
--- 0.3005540370941162 seconds for one epoch ---
--- 1.4354393482208252 seconds for one epoch ---
--- 0.3019750118255615 seconds for one epoch ---
--- 1.434828519821167 seconds for one epoch ---
--- 0.3097646236419678 seconds for one epoch ---
--- 1.4428412914276123 seconds for one epoch ---
--- 0.2994399070739746 seconds for one epoch ---
--- 1.4335455894470215 seconds for one epoch ---
--- 0.30252504348754883 seconds for one epoch ---
--- 1.4195237159729004 seconds for one epoch ---
--- 0.30451536178588867 seconds for one epoch ---
--- 1.4342601299285889 seconds for one epoch ---
--- 0.2950737476348877 seconds for one epoch ---
--- 1.416196346282959 seconds for one epoch ---
--- 0.3052554130554199 seconds for one epoch ---
--- 1.4226558208465576 seconds for one epoch ---
--- 0.29601454734802246 seconds for one epoch ---
--- 1.4392242431640625 seconds for one epoch ---
--- 0.30214905738830566 seconds for one epoch ---
=========================
[[0.        ]
 [0.99955636]
 [0.1101959 ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.74321204]
 [-0.2522486 ]
 [ 0.        ]
 [-0.        ]
 [-1.2795985 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.5195694 ]
 [ 0.        ]]
--- 0.26161623001098633 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7787.9384765625, (1097.5553, 0.6305833, 6688.934, 0.81824684)
   validation loss 896.3385009765625, (597.6515, 0.2795798, 297.58914, 0.81824684)
decoder loss ratio: 23154.056262, decoder SINDy loss  ratio: 0.642388
--- 0.2953317165374756 seconds for one epoch ---
--- 1.438565969467163 seconds for one epoch ---
--- 0.30390477180480957 seconds for one epoch ---
--- 1.461176872253418 seconds for one epoch ---
--- 0.2987215518951416 seconds for one epoch ---
--- 1.4459264278411865 seconds for one epoch ---
--- 0.29779577255249023 seconds for one epoch ---
--- 1.4478304386138916 seconds for one epoch ---
--- 0.2996704578399658 seconds for one epoch ---
--- 1.45656418800354 seconds for one epoch ---
--- 0.29525279998779297 seconds for one epoch ---
--- 1.4459049701690674 seconds for one epoch ---
--- 0.30393528938293457 seconds for one epoch ---
--- 1.4350528717041016 seconds for one epoch ---
--- 0.29776620864868164 seconds for one epoch ---
--- 1.4497623443603516 seconds for one epoch ---
--- 0.3057518005371094 seconds for one epoch ---
--- 1.4237949848175049 seconds for one epoch ---
--- 0.30075883865356445 seconds for one epoch ---
--- 1.4337754249572754 seconds for one epoch ---
--- 0.2998390197753906 seconds for one epoch ---
--- 1.4456794261932373 seconds for one epoch ---
--- 0.2999601364135742 seconds for one epoch ---
--- 1.467113733291626 seconds for one epoch ---
=========================
[[0.        ]
 [0.9994569 ]
 [0.09451105]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.733065  ]
 [-0.24369352]
 [-0.        ]
 [-0.        ]
 [-1.2794058 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.559059  ]
 [-0.        ]]
--- 0.29888272285461426 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2846.788330078125, (1016.97754, 2.020925, 1826.9761, 0.813841)
   validation loss 886.220703125, (577.8866, 0.23810022, 307.28214, 0.813841)
decoder loss ratio: 22388.330011, decoder SINDy loss  ratio: 0.663312
THRESHOLDING: 3 active coefficients
--- 1.4255404472351074 seconds for one epoch ---
--- 0.2999699115753174 seconds for one epoch ---
--- 1.4456143379211426 seconds for one epoch ---
--- 0.2902557849884033 seconds for one epoch ---
--- 1.449599027633667 seconds for one epoch ---
--- 0.300462007522583 seconds for one epoch ---
--- 1.4522979259490967 seconds for one epoch ---
--- 0.305713415145874 seconds for one epoch ---
--- 1.4547479152679443 seconds for one epoch ---
--- 0.29734325408935547 seconds for one epoch ---
--- 1.395693302154541 seconds for one epoch ---
--- 0.2951691150665283 seconds for one epoch ---
--- 1.412524938583374 seconds for one epoch ---
--- 0.30543994903564453 seconds for one epoch ---
--- 1.4590809345245361 seconds for one epoch ---
--- 0.3047924041748047 seconds for one epoch ---
--- 1.4588432312011719 seconds for one epoch ---
--- 0.29323720932006836 seconds for one epoch ---
--- 1.4734668731689453 seconds for one epoch ---
--- 0.3000063896179199 seconds for one epoch ---
--- 1.4596469402313232 seconds for one epoch ---
--- 0.30016565322875977 seconds for one epoch ---
--- 1.4756159782409668 seconds for one epoch ---
--- 0.30344581604003906 seconds for one epoch ---
=========================
[[0.       ]
 [0.9995676]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7444786]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2842593]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.616727 ]
 [-0.       ]]
--- 0.26397705078125 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3447.883544921875, (1613.694, 1.2164396, 1832.2433, 0.72964555)
   validation loss 1375.7484130859375, (1061.8695, 0.36037466, 312.7889, 0.72964555)
decoder loss ratio: 41138.668181, decoder SINDy loss  ratio: 0.675199
--- 0.300276517868042 seconds for one epoch ---
--- 1.4838917255401611 seconds for one epoch ---
--- 0.3000950813293457 seconds for one epoch ---
--- 1.429513692855835 seconds for one epoch ---
--- 0.3068211078643799 seconds for one epoch ---
--- 1.4291486740112305 seconds for one epoch ---
--- 0.3014860153198242 seconds for one epoch ---
--- 1.4638304710388184 seconds for one epoch ---
--- 0.30204296112060547 seconds for one epoch ---
--- 1.4537646770477295 seconds for one epoch ---
--- 0.3045165538787842 seconds for one epoch ---
--- 1.4368150234222412 seconds for one epoch ---
--- 0.301389217376709 seconds for one epoch ---
--- 1.4513115882873535 seconds for one epoch ---
--- 0.2996344566345215 seconds for one epoch ---
--- 1.4662272930145264 seconds for one epoch ---
--- 0.3037741184234619 seconds for one epoch ---
--- 1.4447121620178223 seconds for one epoch ---
--- 0.3038327693939209 seconds for one epoch ---
--- 1.4760403633117676 seconds for one epoch ---
--- 0.30549073219299316 seconds for one epoch ---
--- 1.471301555633545 seconds for one epoch ---
--- 0.3003726005554199 seconds for one epoch ---
--- 1.4574522972106934 seconds for one epoch ---
=========================
[[0.        ]
 [0.99930453]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.7206528]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2707952]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.6496224]
 [ 0.       ]]
--- 0.2966639995574951 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4029.311767578125, (1592.3425, 0.6313108, 2435.6082, 0.72978574)
   validation loss 990.7814331054688, (656.1298, 0.3340472, 333.58777, 0.72978574)
decoder loss ratio: 25419.608387, decoder SINDy loss  ratio: 0.720096
--- 0.26503539085388184 seconds for one epoch ---
--- 0.29987454414367676 seconds for one epoch ---
--- 1.4743454456329346 seconds for one epoch ---
--- 0.30391788482666016 seconds for one epoch ---
--- 1.4966862201690674 seconds for one epoch ---
--- 0.30689001083374023 seconds for one epoch ---
--- 1.5037646293640137 seconds for one epoch ---
--- 0.32538270950317383 seconds for one epoch ---
--- 1.4650859832763672 seconds for one epoch ---
--- 0.2994668483734131 seconds for one epoch ---
--- 1.5002803802490234 seconds for one epoch ---
--- 0.31823182106018066 seconds for one epoch ---
--- 1.486722469329834 seconds for one epoch ---
--- 0.33063220977783203 seconds for one epoch ---
--- 1.4746909141540527 seconds for one epoch ---
--- 0.30487704277038574 seconds for one epoch ---
--- 1.4801232814788818 seconds for one epoch ---
--- 0.30585598945617676 seconds for one epoch ---
--- 1.4532356262207031 seconds for one epoch ---
--- 0.3052973747253418 seconds for one epoch ---
--- 1.4889190196990967 seconds for one epoch ---
--- 0.3006095886230469 seconds for one epoch ---
--- 1.4983305931091309 seconds for one epoch ---
--- 0.304288387298584 seconds for one epoch ---
=========================
[[0.        ]
 [0.99871016]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6897073]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2816321]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.705111 ]
 [ 0.       ]]
--- 0.2575950622558594 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4299.70751953125, (1223.7568, 3.663275, 3071.5571, 0.7301667)
   validation loss 862.1690063476562, (549.79047, 0.36806595, 311.2803, 0.7301667)
decoder loss ratio: 21299.837143, decoder SINDy loss  ratio: 0.671942
--- 0.3282015323638916 seconds for one epoch ---
--- 1.5037462711334229 seconds for one epoch ---
--- 0.3207061290740967 seconds for one epoch ---
--- 1.509145975112915 seconds for one epoch ---
--- 0.31592679023742676 seconds for one epoch ---
--- 1.496279001235962 seconds for one epoch ---
--- 0.3083150386810303 seconds for one epoch ---
--- 1.4670114517211914 seconds for one epoch ---
--- 0.3224484920501709 seconds for one epoch ---
--- 1.5003328323364258 seconds for one epoch ---
--- 0.3130004405975342 seconds for one epoch ---
--- 1.4960079193115234 seconds for one epoch ---
--- 0.30474376678466797 seconds for one epoch ---
--- 1.5080857276916504 seconds for one epoch ---
--- 0.29275083541870117 seconds for one epoch ---
--- 1.5004966259002686 seconds for one epoch ---
--- 0.3100888729095459 seconds for one epoch ---
--- 1.497887372970581 seconds for one epoch ---
--- 0.30336761474609375 seconds for one epoch ---
--- 1.5052101612091064 seconds for one epoch ---
--- 0.30518126487731934 seconds for one epoch ---
--- 1.5042550563812256 seconds for one epoch ---
--- 0.30056190490722656 seconds for one epoch ---
--- 1.5097923278808594 seconds for one epoch ---
=========================
[[0.       ]
 [0.9988066]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.69362897]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.2688311 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.735563  ]
 [-0.        ]]
--- 0.30077314376831055 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2380.229736328125, (1325.0134, 0.5670669, 1053.9188, 0.7303831)
   validation loss 1240.9794921875, (933.48596, 0.31883386, 306.44437, 0.7303831)
decoder loss ratio: 36164.866767, decoder SINDy loss  ratio: 0.661503
--- 0.2653508186340332 seconds for one epoch ---
--- 0.29904937744140625 seconds for one epoch ---
--- 1.5119264125823975 seconds for one epoch ---
--- 0.30355143547058105 seconds for one epoch ---
--- 1.4915850162506104 seconds for one epoch ---
--- 0.30228614807128906 seconds for one epoch ---
--- 1.5143513679504395 seconds for one epoch ---
--- 0.3123316764831543 seconds for one epoch ---
--- 1.5098812580108643 seconds for one epoch ---
--- 0.3011941909790039 seconds for one epoch ---
--- 1.5176451206207275 seconds for one epoch ---
--- 0.3062450885772705 seconds for one epoch ---
--- 1.499213457107544 seconds for one epoch ---
--- 0.30217432975769043 seconds for one epoch ---
--- 1.5173492431640625 seconds for one epoch ---
--- 0.29282712936401367 seconds for one epoch ---
--- 1.5202059745788574 seconds for one epoch ---
--- 0.3043785095214844 seconds for one epoch ---
--- 1.5037896633148193 seconds for one epoch ---
--- 0.30190515518188477 seconds for one epoch ---
--- 1.5451195240020752 seconds for one epoch ---
--- 0.3016777038574219 seconds for one epoch ---
--- 1.5100281238555908 seconds for one epoch ---
--- 0.2992124557495117 seconds for one epoch ---
=========================
[[0.       ]
 [0.9988283]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6945481]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2625806]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.772888 ]
 [ 0.       ]]
--- 0.25882482528686523 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3060.578857421875, (1030.9456, 1.5569638, 2027.3457, 0.73062176)
   validation loss 1390.8604736328125, (1070.7628, 0.34658402, 319.02057, 0.73062176)
decoder loss ratio: 41483.210471, decoder SINDy loss  ratio: 0.688651
--- 0.321610689163208 seconds for one epoch ---
--- 1.5148258209228516 seconds for one epoch ---
--- 0.347581148147583 seconds for one epoch ---
--- 1.4998571872711182 seconds for one epoch ---
--- 0.332364559173584 seconds for one epoch ---
--- 1.5326781272888184 seconds for one epoch ---
--- 0.3418467044830322 seconds for one epoch ---
--- 1.551837682723999 seconds for one epoch ---
--- 0.3341946601867676 seconds for one epoch ---
--- 1.5493948459625244 seconds for one epoch ---
--- 0.3488187789916992 seconds for one epoch ---
--- 1.4992485046386719 seconds for one epoch ---
--- 0.30979108810424805 seconds for one epoch ---
--- 1.516404151916504 seconds for one epoch ---
--- 0.2991049289703369 seconds for one epoch ---
--- 1.5004305839538574 seconds for one epoch ---
--- 0.30950236320495605 seconds for one epoch ---
--- 1.5007977485656738 seconds for one epoch ---
--- 0.30062270164489746 seconds for one epoch ---
--- 1.4977548122406006 seconds for one epoch ---
--- 0.30361294746398926 seconds for one epoch ---
--- 1.5239174365997314 seconds for one epoch ---
--- 0.2977561950683594 seconds for one epoch ---
--- 1.4603569507598877 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991476]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.71047205]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.2687435 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.828048  ]
 [-0.        ]]
--- 0.3240067958831787 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4563.74169921875, (2006.568, 4.0130568, 2552.43, 0.73102677)
   validation loss 951.5160522460938, (593.59955, 0.4179953, 356.7675, 0.73102677)
decoder loss ratio: 22997.077037, decoder SINDy loss  ratio: 0.770133
--- 0.2805204391479492 seconds for one epoch ---
--- 0.3242311477661133 seconds for one epoch ---
--- 1.5230216979980469 seconds for one epoch ---
--- 0.34350085258483887 seconds for one epoch ---
--- 1.5787353515625 seconds for one epoch ---
--- 0.3418910503387451 seconds for one epoch ---
--- 1.5601887702941895 seconds for one epoch ---
--- 0.3336629867553711 seconds for one epoch ---
--- 1.5411138534545898 seconds for one epoch ---
--- 0.3261430263519287 seconds for one epoch ---
--- 1.5319886207580566 seconds for one epoch ---
--- 0.31234312057495117 seconds for one epoch ---
--- 1.5496826171875 seconds for one epoch ---
--- 0.3009636402130127 seconds for one epoch ---
--- 1.5310957431793213 seconds for one epoch ---
--- 0.30052924156188965 seconds for one epoch ---
--- 1.5568292140960693 seconds for one epoch ---
--- 0.30103039741516113 seconds for one epoch ---
--- 1.5401322841644287 seconds for one epoch ---
--- 0.29782652854919434 seconds for one epoch ---
--- 1.5585553646087646 seconds for one epoch ---
--- 0.29522275924682617 seconds for one epoch ---
--- 1.5138745307922363 seconds for one epoch ---
--- 0.29911279678344727 seconds for one epoch ---
=========================
[[0.        ]
 [0.99919134]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7131002]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2859455]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.8808103]
 [-0.       ]]
--- 0.2680683135986328 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5102.1083984375, (1910.3274, 1.8310113, 3189.2183, 0.7314066)
   validation loss 803.0195922851562, (501.39813, 0.30848357, 300.5816, 0.7314066)
decoder loss ratio: 19425.034112, decoder SINDy loss  ratio: 0.648848
--- 0.3025782108306885 seconds for one epoch ---
--- 1.5447685718536377 seconds for one epoch ---
--- 0.3032827377319336 seconds for one epoch ---
--- 1.5399253368377686 seconds for one epoch ---
--- 0.3038182258605957 seconds for one epoch ---
--- 1.5420401096343994 seconds for one epoch ---
--- 0.30191946029663086 seconds for one epoch ---
--- 1.5546519756317139 seconds for one epoch ---
--- 0.2943246364593506 seconds for one epoch ---
--- 1.5380346775054932 seconds for one epoch ---
--- 0.29921746253967285 seconds for one epoch ---
--- 1.552675724029541 seconds for one epoch ---
--- 0.29958391189575195 seconds for one epoch ---
--- 1.5456268787384033 seconds for one epoch ---
--- 0.3091163635253906 seconds for one epoch ---
--- 1.5473394393920898 seconds for one epoch ---
--- 0.30225110054016113 seconds for one epoch ---
--- 1.516993522644043 seconds for one epoch ---
--- 0.29808831214904785 seconds for one epoch ---
--- 1.5616097450256348 seconds for one epoch ---
--- 0.30422186851501465 seconds for one epoch ---
--- 1.4976000785827637 seconds for one epoch ---
--- 0.29923224449157715 seconds for one epoch ---
--- 1.4971933364868164 seconds for one epoch ---
=========================
[[0.        ]
 [0.99896795]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.70087916]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.2786964 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.917504  ]
 [ 0.        ]]
--- 0.29370641708374023 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2519.5390625, (1279.8397, 0.26135892, 1238.7063, 0.7316831)
   validation loss 802.2402954101562, (498.97003, 0.3162478, 302.22232, 0.7316831)
decoder loss ratio: 19330.965280, decoder SINDy loss  ratio: 0.652389
--- 0.2624835968017578 seconds for one epoch ---
--- 0.3024282455444336 seconds for one epoch ---
--- 1.5381083488464355 seconds for one epoch ---
--- 0.30297136306762695 seconds for one epoch ---
--- 1.5728027820587158 seconds for one epoch ---
--- 0.2994866371154785 seconds for one epoch ---
--- 1.54221773147583 seconds for one epoch ---
--- 0.2982189655303955 seconds for one epoch ---
--- 1.556929111480713 seconds for one epoch ---
--- 0.2947967052459717 seconds for one epoch ---
--- 1.5771818161010742 seconds for one epoch ---
--- 0.29012322425842285 seconds for one epoch ---
--- 1.5580055713653564 seconds for one epoch ---
--- 0.3017416000366211 seconds for one epoch ---
--- 1.5399019718170166 seconds for one epoch ---
--- 0.3029494285583496 seconds for one epoch ---
--- 1.5365321636199951 seconds for one epoch ---
--- 0.29201221466064453 seconds for one epoch ---
--- 1.576066493988037 seconds for one epoch ---
--- 0.3147273063659668 seconds for one epoch ---
--- 1.5042407512664795 seconds for one epoch ---
--- 0.2882559299468994 seconds for one epoch ---
--- 1.501683235168457 seconds for one epoch ---
--- 0.29936742782592773 seconds for one epoch ---
=========================
[[0.      ]
 [0.999316]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-0.       ]
 [-0.7215062]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2743311]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.960239 ]
 [ 0.       ]]
--- 0.2659480571746826 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3160.468017578125, (1121.0323, 0.6646798, 2038.0391, 0.73193204)
   validation loss 864.3732299804688, (549.09503, 0.3268818, 314.21936, 0.73193204)
decoder loss ratio: 21272.894800, decoder SINDy loss  ratio: 0.678287
--- 0.3056302070617676 seconds for one epoch ---
--- 1.5490586757659912 seconds for one epoch ---
--- 0.2989053726196289 seconds for one epoch ---
--- 1.566115140914917 seconds for one epoch ---
--- 0.30441951751708984 seconds for one epoch ---
--- 1.5542991161346436 seconds for one epoch ---
--- 0.29955387115478516 seconds for one epoch ---
--- 1.577310562133789 seconds for one epoch ---
--- 0.303239107131958 seconds for one epoch ---
--- 1.5591208934783936 seconds for one epoch ---
--- 0.2984201908111572 seconds for one epoch ---
--- 1.575467824935913 seconds for one epoch ---
--- 0.2966599464416504 seconds for one epoch ---
--- 1.5777862071990967 seconds for one epoch ---
--- 0.29386472702026367 seconds for one epoch ---
--- 1.5586552619934082 seconds for one epoch ---
--- 0.30493712425231934 seconds for one epoch ---
--- 1.5757465362548828 seconds for one epoch ---
--- 0.30405640602111816 seconds for one epoch ---
--- 1.5910990238189697 seconds for one epoch ---
--- 0.312147855758667 seconds for one epoch ---
--- 1.530545711517334 seconds for one epoch ---
--- 0.29856157302856445 seconds for one epoch ---
--- 1.549476146697998 seconds for one epoch ---
=========================
[[0.        ]
 [0.99908674]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7069979]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2665375]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.0011196]
 [-0.       ]]
--- 0.3097085952758789 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3252.047607421875, (1218.8838, 2.2800384, 2030.1516, 0.7321904)
   validation loss 1026.548828125, (716.39545, 0.2524267, 309.16876, 0.7321904)
decoder loss ratio: 27754.403325, decoder SINDy loss  ratio: 0.667384
--- 0.27405881881713867 seconds for one epoch ---
--- 0.3007838726043701 seconds for one epoch ---
--- 1.6115381717681885 seconds for one epoch ---
--- 0.30345821380615234 seconds for one epoch ---
--- 1.596071481704712 seconds for one epoch ---
--- 0.30330586433410645 seconds for one epoch ---
--- 1.5875933170318604 seconds for one epoch ---
--- 0.30194973945617676 seconds for one epoch ---
--- 1.5882539749145508 seconds for one epoch ---
--- 0.2918376922607422 seconds for one epoch ---
--- 1.5599627494812012 seconds for one epoch ---
--- 0.29904651641845703 seconds for one epoch ---
--- 1.5506415367126465 seconds for one epoch ---
--- 0.29238319396972656 seconds for one epoch ---
--- 1.573211908340454 seconds for one epoch ---
--- 0.2934401035308838 seconds for one epoch ---
--- 1.569634199142456 seconds for one epoch ---
--- 0.29764366149902344 seconds for one epoch ---
--- 1.5728344917297363 seconds for one epoch ---
--- 0.3001565933227539 seconds for one epoch ---
--- 1.536837100982666 seconds for one epoch ---
--- 0.29442644119262695 seconds for one epoch ---
--- 1.5310990810394287 seconds for one epoch ---
--- 0.2834169864654541 seconds for one epoch ---
=========================
[[0.        ]
 [0.99903166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.7040847]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2746689]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.0476055]
 [ 0.       ]]
--- 0.27834343910217285 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2096.28564453125, (888.72534, 0.9122194, 1205.9158, 0.73252636)
   validation loss 809.9046630859375, (513.8002, 0.26954693, 295.1024, 0.73252636)
decoder loss ratio: 19905.510617, decoder SINDy loss  ratio: 0.637020
--- 0.28679633140563965 seconds for one epoch ---
--- 1.5647954940795898 seconds for one epoch ---
--- 0.29802417755126953 seconds for one epoch ---
--- 1.5917184352874756 seconds for one epoch ---
--- 0.2996695041656494 seconds for one epoch ---
--- 1.6014823913574219 seconds for one epoch ---
--- 0.29884934425354004 seconds for one epoch ---
--- 1.566460371017456 seconds for one epoch ---
--- 0.30590081214904785 seconds for one epoch ---
--- 1.5915608406066895 seconds for one epoch ---
--- 0.2986931800842285 seconds for one epoch ---
--- 1.6016380786895752 seconds for one epoch ---
--- 0.3009028434753418 seconds for one epoch ---
--- 1.5956368446350098 seconds for one epoch ---
--- 0.30341148376464844 seconds for one epoch ---
--- 1.5887622833251953 seconds for one epoch ---
--- 0.28731656074523926 seconds for one epoch ---
--- 1.599644422531128 seconds for one epoch ---
--- 0.30367398262023926 seconds for one epoch ---
--- 1.6040763854980469 seconds for one epoch ---
--- 0.2993452548980713 seconds for one epoch ---
--- 1.5621099472045898 seconds for one epoch ---
--- 0.2847921848297119 seconds for one epoch ---
--- 1.5506927967071533 seconds for one epoch ---
=========================
[[0.        ]
 [0.99909973]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7077339]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2614   ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.085767 ]
 [-0.       ]]
--- 0.30147576332092285 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2199.088134765625, (780.56085, 0.8500149, 1416.9446, 0.73273987)
   validation loss 863.6447143554688, (552.0235, 0.30965993, 310.57886, 0.73273987)
decoder loss ratio: 21386.348688, decoder SINDy loss  ratio: 0.670428
--- 0.26371216773986816 seconds for one epoch ---
--- 0.3048272132873535 seconds for one epoch ---
--- 1.5972881317138672 seconds for one epoch ---
--- 0.3068394660949707 seconds for one epoch ---
--- 1.6029736995697021 seconds for one epoch ---
--- 0.29723477363586426 seconds for one epoch ---
--- 1.6479079723358154 seconds for one epoch ---
--- 0.29842233657836914 seconds for one epoch ---
--- 1.6151840686798096 seconds for one epoch ---
--- 0.3042120933532715 seconds for one epoch ---
--- 1.602154016494751 seconds for one epoch ---
--- 0.30659961700439453 seconds for one epoch ---
--- 1.6018738746643066 seconds for one epoch ---
--- 0.2991058826446533 seconds for one epoch ---
--- 1.6142308712005615 seconds for one epoch ---
--- 0.30257463455200195 seconds for one epoch ---
--- 1.633589744567871 seconds for one epoch ---
--- 0.32023048400878906 seconds for one epoch ---
--- 1.5926487445831299 seconds for one epoch ---
--- 0.30197882652282715 seconds for one epoch ---
--- 1.5886542797088623 seconds for one epoch ---
--- 0.3065207004547119 seconds for one epoch ---
--- 1.5570487976074219 seconds for one epoch ---
--- 0.29978108406066895 seconds for one epoch ---
=========================
[[0.       ]
 [0.9994525]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.7326584]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2670356]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.12559  ]
 [-0.       ]]
--- 0.2700049877166748 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3233.993896484375, (1622.3577, 2.4980829, 1608.4053, 0.73295945)
   validation loss 920.6038818359375, (607.54926, 0.24343678, 312.07825, 0.73295945)
decoder loss ratio: 23537.512905, decoder SINDy loss  ratio: 0.673665
--- 0.3001737594604492 seconds for one epoch ---
--- 1.612962007522583 seconds for one epoch ---
--- 0.3003208637237549 seconds for one epoch ---
--- 1.622476577758789 seconds for one epoch ---
--- 0.30577826499938965 seconds for one epoch ---
--- 1.6023337841033936 seconds for one epoch ---
--- 0.3063645362854004 seconds for one epoch ---
--- 1.6149327754974365 seconds for one epoch ---
--- 0.3045938014984131 seconds for one epoch ---
--- 1.6438922882080078 seconds for one epoch ---
--- 0.30538010597229004 seconds for one epoch ---
--- 1.631399154663086 seconds for one epoch ---
--- 0.3254561424255371 seconds for one epoch ---
--- 1.6186370849609375 seconds for one epoch ---
--- 0.3062899112701416 seconds for one epoch ---
--- 1.6311821937561035 seconds for one epoch ---
--- 0.31116461753845215 seconds for one epoch ---
--- 1.6360430717468262 seconds for one epoch ---
--- 0.31275439262390137 seconds for one epoch ---
--- 1.592318058013916 seconds for one epoch ---
--- 0.3010232448577881 seconds for one epoch ---
--- 1.6000158786773682 seconds for one epoch ---
--- 0.3034346103668213 seconds for one epoch ---
--- 1.579967975616455 seconds for one epoch ---
=========================
[[0.        ]
 [0.99943286]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.730928 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.267331 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.1575403]
 [ 0.       ]]
--- 0.3081791400909424 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2999.728271484375, (2007.2742, 0.25903937, 991.46204, 0.73308253)
   validation loss 787.4482421875, (481.5241, 0.31449735, 304.87656, 0.73308253)
decoder loss ratio: 18655.079941, decoder SINDy loss  ratio: 0.658119
--- 0.2665674686431885 seconds for one epoch ---
--- 0.30420517921447754 seconds for one epoch ---
--- 1.6316938400268555 seconds for one epoch ---
--- 0.2999227046966553 seconds for one epoch ---
--- 1.6225666999816895 seconds for one epoch ---
--- 0.2991151809692383 seconds for one epoch ---
--- 1.6410191059112549 seconds for one epoch ---
--- 0.2927734851837158 seconds for one epoch ---
--- 1.6134464740753174 seconds for one epoch ---
--- 0.3021118640899658 seconds for one epoch ---
--- 1.6164417266845703 seconds for one epoch ---
--- 0.2968180179595947 seconds for one epoch ---
--- 1.594125509262085 seconds for one epoch ---
--- 0.30196380615234375 seconds for one epoch ---
--- 1.6343164443969727 seconds for one epoch ---
--- 0.30037713050842285 seconds for one epoch ---
--- 1.6223068237304688 seconds for one epoch ---
--- 0.2939286231994629 seconds for one epoch ---
--- 1.5805394649505615 seconds for one epoch ---
--- 0.3046231269836426 seconds for one epoch ---
--- 1.5588738918304443 seconds for one epoch ---
--- 0.29614877700805664 seconds for one epoch ---
--- 1.5830302238464355 seconds for one epoch ---
--- 0.2939445972442627 seconds for one epoch ---
=========================
[[0.       ]
 [0.9992566]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7173523]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2703601]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.197776 ]
 [ 0.       ]]
--- 0.2574186325073242 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4457.22021484375, (1872.89, 0.68662876, 2582.9102, 0.7332068)
   validation loss 1234.388427734375, (911.5007, 0.32840347, 321.82623, 0.7332068)
decoder loss ratio: 35313.118444, decoder SINDy loss  ratio: 0.694707
--- 0.3140580654144287 seconds for one epoch ---
--- 1.6398932933807373 seconds for one epoch ---
--- 0.2944767475128174 seconds for one epoch ---
--- 1.6424574851989746 seconds for one epoch ---
--- 0.31113624572753906 seconds for one epoch ---
--- 1.6346893310546875 seconds for one epoch ---
--- 0.30048370361328125 seconds for one epoch ---
--- 1.6110093593597412 seconds for one epoch ---
--- 0.2943096160888672 seconds for one epoch ---
--- 1.6169164180755615 seconds for one epoch ---
--- 0.296022891998291 seconds for one epoch ---
--- 1.6039955615997314 seconds for one epoch ---
--- 0.3023796081542969 seconds for one epoch ---
--- 1.627377986907959 seconds for one epoch ---
--- 0.3014180660247803 seconds for one epoch ---
--- 1.6232352256774902 seconds for one epoch ---
--- 0.3025844097137451 seconds for one epoch ---
--- 1.649193525314331 seconds for one epoch ---
--- 0.2931070327758789 seconds for one epoch ---
--- 1.5857887268066406 seconds for one epoch ---
--- 0.29480481147766113 seconds for one epoch ---
--- 1.5855920314788818 seconds for one epoch ---
--- 0.2875385284423828 seconds for one epoch ---
--- 1.6041648387908936 seconds for one epoch ---
=========================
[[0.        ]
 [0.99908465]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.706887 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2631054]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.2312613]
 [-0.       ]]
--- 0.3120579719543457 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1998.7110595703125, (998.3175, 0.8205114, 998.8399, 0.7331034)
   validation loss 952.306640625, (637.78986, 0.30459702, 313.47906, 0.7331034)
decoder loss ratio: 24709.086272, decoder SINDy loss  ratio: 0.676689
--- 0.2679586410522461 seconds for one epoch ---
--- 0.3400082588195801 seconds for one epoch ---
--- 1.6509580612182617 seconds for one epoch ---
--- 0.3347442150115967 seconds for one epoch ---
--- 1.655317783355713 seconds for one epoch ---
--- 0.33606934547424316 seconds for one epoch ---
--- 1.664597988128662 seconds for one epoch ---
--- 0.31970882415771484 seconds for one epoch ---
--- 1.6514358520507812 seconds for one epoch ---
--- 0.30826687812805176 seconds for one epoch ---
--- 1.6462631225585938 seconds for one epoch ---
--- 0.30869221687316895 seconds for one epoch ---
--- 1.639965295791626 seconds for one epoch ---
--- 0.30121517181396484 seconds for one epoch ---
--- 1.6330115795135498 seconds for one epoch ---
--- 0.29816579818725586 seconds for one epoch ---
--- 1.6666667461395264 seconds for one epoch ---
--- 0.3030846118927002 seconds for one epoch ---
--- 1.610365390777588 seconds for one epoch ---
--- 0.29564404487609863 seconds for one epoch ---
--- 1.5849053859710693 seconds for one epoch ---
--- 0.29480695724487305 seconds for one epoch ---
--- 1.579209566116333 seconds for one epoch ---
--- 0.2971675395965576 seconds for one epoch ---
=========================
[[0.        ]
 [0.99923813]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.71609896]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.2571607 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.272027  ]
 [ 0.        ]]
--- 0.26488447189331055 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3436.85302734375, (1490.7777, 1.3546973, 1943.9875, 0.73295397)
   validation loss 909.6359252929688, (609.2518, 0.31259122, 299.33862, 0.73295397)
decoder loss ratio: 23603.471278, decoder SINDy loss  ratio: 0.646165
--- 0.30432915687561035 seconds for one epoch ---
--- 1.6682515144348145 seconds for one epoch ---
--- 0.3078606128692627 seconds for one epoch ---
--- 1.6634738445281982 seconds for one epoch ---
--- 0.30062294006347656 seconds for one epoch ---
--- 1.6582589149475098 seconds for one epoch ---
--- 0.3016824722290039 seconds for one epoch ---
--- 1.651378870010376 seconds for one epoch ---
--- 0.29683947563171387 seconds for one epoch ---
--- 1.6698284149169922 seconds for one epoch ---
--- 0.3007664680480957 seconds for one epoch ---
--- 1.653336524963379 seconds for one epoch ---
--- 0.29695796966552734 seconds for one epoch ---
--- 1.6463124752044678 seconds for one epoch ---
--- 0.312410831451416 seconds for one epoch ---
--- 1.624485969543457 seconds for one epoch ---
--- 0.30925798416137695 seconds for one epoch ---
--- 1.6620583534240723 seconds for one epoch ---
--- 0.6084864139556885 seconds for one epoch ---
--- 1.6031982898712158 seconds for one epoch ---
--- 0.2906007766723633 seconds for one epoch ---
--- 1.606088399887085 seconds for one epoch ---
--- 0.30490899085998535 seconds for one epoch ---
--- 1.6044507026672363 seconds for one epoch ---
=========================
[[0.       ]
 [0.9992065]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.71403825]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.266439  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.3097343 ]
 [-0.        ]]
--- 0.2948191165924072 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3366.17138671875, (1164.3268, 1.8653486, 2199.2468, 0.7325339)
   validation loss 905.0303955078125, (601.1814, 0.22856115, 302.88785, 0.7325339)
decoder loss ratio: 23290.810997, decoder SINDy loss  ratio: 0.653826
--- 0.2574906349182129 seconds for one epoch ---
--- 0.2968144416809082 seconds for one epoch ---
--- 1.6612639427185059 seconds for one epoch ---
--- 0.3013927936553955 seconds for one epoch ---
--- 1.6554694175720215 seconds for one epoch ---
--- 0.30034947395324707 seconds for one epoch ---
--- 1.6516032218933105 seconds for one epoch ---
--- 0.2951841354370117 seconds for one epoch ---
--- 1.6365759372711182 seconds for one epoch ---
--- 0.2972729206085205 seconds for one epoch ---
--- 1.638430118560791 seconds for one epoch ---
--- 0.292985200881958 seconds for one epoch ---
--- 1.644913911819458 seconds for one epoch ---
--- 0.2958495616912842 seconds for one epoch ---
--- 1.6694552898406982 seconds for one epoch ---
--- 0.30128049850463867 seconds for one epoch ---
--- 1.6612539291381836 seconds for one epoch ---
--- 0.29976749420166016 seconds for one epoch ---
--- 1.6735618114471436 seconds for one epoch ---
--- 0.29309868812561035 seconds for one epoch ---
--- 1.6213898658752441 seconds for one epoch ---
--- 0.2933540344238281 seconds for one epoch ---
--- 1.6192655563354492 seconds for one epoch ---
--- 0.29822278022766113 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.712303 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2702159]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.354214 ]
 [-0.       ]]
--- 0.2600088119506836 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3408.7021484375, (2222.8806, 0.517365, 1184.5725, 0.73176825)
   validation loss 1159.633056640625, (860.7578, 0.28041106, 297.86307, 0.73176825)
decoder loss ratio: 33347.251998, decoder SINDy loss  ratio: 0.642979
--- 0.3036057949066162 seconds for one epoch ---
--- 1.703221082687378 seconds for one epoch ---
--- 0.3111081123352051 seconds for one epoch ---
--- 1.690422534942627 seconds for one epoch ---
--- 0.2937462329864502 seconds for one epoch ---
--- 1.6938517093658447 seconds for one epoch ---
--- 0.29599666595458984 seconds for one epoch ---
--- 1.6855990886688232 seconds for one epoch ---
--- 0.30199432373046875 seconds for one epoch ---
--- 1.6944029331207275 seconds for one epoch ---
--- 0.3004162311553955 seconds for one epoch ---
--- 1.6840651035308838 seconds for one epoch ---
--- 0.3050813674926758 seconds for one epoch ---
--- 1.6871850490570068 seconds for one epoch ---
--- 0.3058187961578369 seconds for one epoch ---
--- 1.687436819076538 seconds for one epoch ---
--- 0.2964200973510742 seconds for one epoch ---
--- 1.7088041305541992 seconds for one epoch ---
--- 0.312175989151001 seconds for one epoch ---
--- 1.6560819149017334 seconds for one epoch ---
--- 0.2968435287475586 seconds for one epoch ---
--- 1.6443934440612793 seconds for one epoch ---
--- 0.28445935249328613 seconds for one epoch ---
--- 1.636195421218872 seconds for one epoch ---
=========================
[[0.       ]
 [0.9994841]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.735658 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2721791]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.384061 ]
 [ 0.       ]]
--- 0.2946784496307373 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4169.61181640625, (1537.4973, 0.4727199, 2630.9111, 0.7303676)
   validation loss 794.3193359375, (502.87323, 0.25285468, 290.46286, 0.7303676)
decoder loss ratio: 19482.181956, decoder SINDy loss  ratio: 0.627005
THRESHOLDING: 3 active coefficients
--- 0.2678699493408203 seconds for one epoch ---
--- 0.3010239601135254 seconds for one epoch ---
--- 1.6347804069519043 seconds for one epoch ---
--- 0.30101656913757324 seconds for one epoch ---
--- 1.6319375038146973 seconds for one epoch ---
--- 0.29752445220947266 seconds for one epoch ---
--- 1.624910831451416 seconds for one epoch ---
--- 0.3011775016784668 seconds for one epoch ---
--- 1.7028460502624512 seconds for one epoch ---
--- 0.30913305282592773 seconds for one epoch ---
--- 1.6751348972320557 seconds for one epoch ---
--- 0.30750060081481934 seconds for one epoch ---
--- 1.7132916450500488 seconds for one epoch ---
--- 0.29854798316955566 seconds for one epoch ---
--- 1.6912918090820312 seconds for one epoch ---
--- 0.29744839668273926 seconds for one epoch ---
--- 1.722557544708252 seconds for one epoch ---
--- 0.3008859157562256 seconds for one epoch ---
--- 1.7212374210357666 seconds for one epoch ---
--- 0.29897379875183105 seconds for one epoch ---
--- 1.7390356063842773 seconds for one epoch ---
--- 0.302227258682251 seconds for one epoch ---
--- 1.648329257965088 seconds for one epoch ---
--- 0.2878398895263672 seconds for one epoch ---
=========================
[[0.        ]
 [0.99935824]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.7246718]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2718154]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.415037 ]
 [ 0.       ]]
--- 0.2643723487854004 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4125.603515625, (1552.2633, 1.196118, 2571.4307, 0.7133606)
   validation loss 955.66015625, (649.1892, 0.26432222, 305.49326, 0.7133606)
decoder loss ratio: 25150.716998, decoder SINDy loss  ratio: 0.659450
--- 0.29830455780029297 seconds for one epoch ---
--- 1.6884279251098633 seconds for one epoch ---
--- 0.3066539764404297 seconds for one epoch ---
--- 1.7056422233581543 seconds for one epoch ---
--- 0.2951381206512451 seconds for one epoch ---
--- 1.7222180366516113 seconds for one epoch ---
--- 0.29975104331970215 seconds for one epoch ---
--- 1.7070415019989014 seconds for one epoch ---
--- 0.29616761207580566 seconds for one epoch ---
--- 1.7033796310424805 seconds for one epoch ---
--- 0.29810619354248047 seconds for one epoch ---
--- 1.693612813949585 seconds for one epoch ---
--- 0.2986140251159668 seconds for one epoch ---
--- 1.6978588104248047 seconds for one epoch ---
--- 0.29355692863464355 seconds for one epoch ---
--- 1.7222814559936523 seconds for one epoch ---
--- 0.3104093074798584 seconds for one epoch ---
--- 1.727637767791748 seconds for one epoch ---
--- 0.30309605598449707 seconds for one epoch ---
--- 1.7129032611846924 seconds for one epoch ---
--- 0.2982785701751709 seconds for one epoch ---
--- 1.6456856727600098 seconds for one epoch ---
--- 0.3043076992034912 seconds for one epoch ---
--- 1.6552889347076416 seconds for one epoch ---
=========================
[[0.        ]
 [0.99899644]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7022964]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2749423]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.4501266]
 [-0.       ]]
--- 0.3130357265472412 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1627.6207275390625, (662.75055, 0.4808073, 963.6757, 0.71364325)
   validation loss 988.755859375, (679.79694, 0.26355416, 307.98178, 0.71364325)
decoder loss ratio: 26336.513481, decoder SINDy loss  ratio: 0.664822
--- 0.26224708557128906 seconds for one epoch ---
--- 0.3367955684661865 seconds for one epoch ---
--- 1.7386839389801025 seconds for one epoch ---
--- 0.3371436595916748 seconds for one epoch ---
--- 1.731048583984375 seconds for one epoch ---
--- 0.35082197189331055 seconds for one epoch ---
--- 1.7512567043304443 seconds for one epoch ---
--- 0.3196570873260498 seconds for one epoch ---
--- 1.7453944683074951 seconds for one epoch ---
--- 0.31082749366760254 seconds for one epoch ---
--- 1.768927812576294 seconds for one epoch ---
--- 0.30283069610595703 seconds for one epoch ---
--- 1.7218446731567383 seconds for one epoch ---
--- 0.30149221420288086 seconds for one epoch ---
--- 1.730048418045044 seconds for one epoch ---
--- 0.30497312545776367 seconds for one epoch ---
--- 1.7559058666229248 seconds for one epoch ---
--- 0.3001415729522705 seconds for one epoch ---
--- 1.6988086700439453 seconds for one epoch ---
--- 0.30108642578125 seconds for one epoch ---
--- 1.694800615310669 seconds for one epoch ---
--- 0.3068077564239502 seconds for one epoch ---
--- 1.6989197731018066 seconds for one epoch ---
--- 0.29773926734924316 seconds for one epoch ---
=========================
[[0.        ]
 [0.99857754]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6847637]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2666779]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.477647 ]
 [ 0.       ]]
--- 0.267193078994751 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4027.4599609375, (1100.3182, 3.3015542, 2923.1262, 0.713824)
   validation loss 1048.98583984375, (755.09644, 0.25621217, 292.91925, 0.713824)
decoder loss ratio: 29253.746818, decoder SINDy loss  ratio: 0.632307
--- 0.30453038215637207 seconds for one epoch ---
--- 1.694788932800293 seconds for one epoch ---
--- 0.30896449089050293 seconds for one epoch ---
--- 1.7254233360290527 seconds for one epoch ---
--- 0.3065636157989502 seconds for one epoch ---
--- 1.7074198722839355 seconds for one epoch ---
--- 0.30301618576049805 seconds for one epoch ---
--- 1.731044054031372 seconds for one epoch ---
--- 0.30571818351745605 seconds for one epoch ---
--- 1.7619707584381104 seconds for one epoch ---
--- 0.3066437244415283 seconds for one epoch ---
--- 1.729936122894287 seconds for one epoch ---
--- 0.3094010353088379 seconds for one epoch ---
--- 1.717437744140625 seconds for one epoch ---
--- 0.3113377094268799 seconds for one epoch ---
--- 1.7540240287780762 seconds for one epoch ---
--- 0.3031308650970459 seconds for one epoch ---
--- 1.7268610000610352 seconds for one epoch ---
--- 0.30576324462890625 seconds for one epoch ---
--- 1.69130539894104 seconds for one epoch ---
--- 0.3046879768371582 seconds for one epoch ---
--- 1.6979258060455322 seconds for one epoch ---
--- 0.30746984481811523 seconds for one epoch ---
--- 1.7075893878936768 seconds for one epoch ---
=========================
[[0.        ]
 [0.99806416]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6693379]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2633846]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.509197 ]
 [-0.       ]]
--- 0.3145272731781006 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5305.3447265625, (1924.3951, 1.6883146, 3378.547, 0.7140258)
   validation loss 1236.3165283203125, (919.06964, 0.24683042, 316.286, 0.7140258)
decoder loss ratio: 35606.353472, decoder SINDy loss  ratio: 0.682748
--- 0.27205348014831543 seconds for one epoch ---
--- 0.300412654876709 seconds for one epoch ---
--- 1.7546443939208984 seconds for one epoch ---
--- 0.2954590320587158 seconds for one epoch ---
--- 1.7577991485595703 seconds for one epoch ---
--- 0.31774044036865234 seconds for one epoch ---
--- 1.7483298778533936 seconds for one epoch ---
--- 0.3093838691711426 seconds for one epoch ---
--- 1.7562878131866455 seconds for one epoch ---
--- 0.30145978927612305 seconds for one epoch ---
--- 1.740741491317749 seconds for one epoch ---
--- 0.30736756324768066 seconds for one epoch ---
--- 1.7504994869232178 seconds for one epoch ---
--- 0.308300256729126 seconds for one epoch ---
--- 1.7639482021331787 seconds for one epoch ---
--- 0.30615949630737305 seconds for one epoch ---
--- 1.7692208290100098 seconds for one epoch ---
--- 0.3031463623046875 seconds for one epoch ---
--- 1.7226195335388184 seconds for one epoch ---
--- 0.30338025093078613 seconds for one epoch ---
--- 1.7243750095367432 seconds for one epoch ---
--- 0.2980010509490967 seconds for one epoch ---
--- 1.7158093452453613 seconds for one epoch ---
--- 0.28860926628112793 seconds for one epoch ---
=========================
[[0.       ]
 [0.9981549]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6717461]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2639987]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.549003 ]
 [-0.       ]]
--- 0.27664732933044434 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3160.713134765625, (1364.1737, 1.5035595, 1794.3215, 0.7143641)
   validation loss 910.349853515625, (592.61346, 0.25322124, 316.76883, 0.7143641)
decoder loss ratio: 22958.874431, decoder SINDy loss  ratio: 0.683790
--- 0.3095393180847168 seconds for one epoch ---
--- 1.7703049182891846 seconds for one epoch ---
--- 0.3140830993652344 seconds for one epoch ---
--- 1.7773373126983643 seconds for one epoch ---
--- 0.3197824954986572 seconds for one epoch ---
--- 1.7471208572387695 seconds for one epoch ---
--- 0.3139986991882324 seconds for one epoch ---
--- 1.7247767448425293 seconds for one epoch ---
--- 0.30095553398132324 seconds for one epoch ---
--- 1.7433671951293945 seconds for one epoch ---
--- 0.2994351387023926 seconds for one epoch ---
--- 1.7399423122406006 seconds for one epoch ---
--- 0.29941344261169434 seconds for one epoch ---
--- 1.7564873695373535 seconds for one epoch ---
--- 0.30765795707702637 seconds for one epoch ---
--- 1.7765181064605713 seconds for one epoch ---
--- 0.32184576988220215 seconds for one epoch ---
--- 1.698826551437378 seconds for one epoch ---
--- 0.30002355575561523 seconds for one epoch ---
--- 1.703564167022705 seconds for one epoch ---
--- 0.29975366592407227 seconds for one epoch ---
--- 1.7308602333068848 seconds for one epoch ---
--- 0.30036473274230957 seconds for one epoch ---
--- 1.7406229972839355 seconds for one epoch ---
=========================
[[0.        ]
 [0.99869174]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6889835]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2600274]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.5910344]
 [ 0.       ]]
--- 0.29720640182495117 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6856.09375, (1188.1882, 0.83046883, 5666.3604, 0.7146961)
   validation loss 930.6127319335938, (637.2651, 0.26326653, 292.3697, 0.7146961)
decoder loss ratio: 24688.755373, decoder SINDy loss  ratio: 0.631121
--- 0.2704954147338867 seconds for one epoch ---
--- 0.31252169609069824 seconds for one epoch ---
--- 1.7519350051879883 seconds for one epoch ---
--- 0.3096146583557129 seconds for one epoch ---
--- 1.7521131038665771 seconds for one epoch ---
--- 0.30294013023376465 seconds for one epoch ---
--- 1.7671387195587158 seconds for one epoch ---
--- 0.3040475845336914 seconds for one epoch ---
--- 1.7550077438354492 seconds for one epoch ---
--- 0.3075826168060303 seconds for one epoch ---
--- 1.764784574508667 seconds for one epoch ---
--- 0.29285335540771484 seconds for one epoch ---
--- 1.7765424251556396 seconds for one epoch ---
--- 0.304030179977417 seconds for one epoch ---
--- 1.8119771480560303 seconds for one epoch ---
--- 0.3025016784667969 seconds for one epoch ---
--- 1.7070724964141846 seconds for one epoch ---
--- 0.2963547706604004 seconds for one epoch ---
--- 1.7340712547302246 seconds for one epoch ---
--- 0.2965683937072754 seconds for one epoch ---
--- 1.7247745990753174 seconds for one epoch ---
--- 0.29847264289855957 seconds for one epoch ---
--- 1.76131010055542 seconds for one epoch ---
--- 0.30045604705810547 seconds for one epoch ---
=========================
[[0.       ]
 [0.9990866]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7069884]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2563325]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.612395 ]
 [ 0.       ]]
--- 0.2815244197845459 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2518.22998046875, (895.30066, 0.3095737, 1621.9049, 0.7149021)
   validation loss 976.8119506835938, (666.6536, 0.28384367, 309.15958, 0.7149021)
decoder loss ratio: 25827.318813, decoder SINDy loss  ratio: 0.667364
--- 0.31652235984802246 seconds for one epoch ---
--- 1.7545640468597412 seconds for one epoch ---
--- 0.3086233139038086 seconds for one epoch ---
--- 1.7964167594909668 seconds for one epoch ---
--- 0.2992222309112549 seconds for one epoch ---
--- 1.785323143005371 seconds for one epoch ---
--- 0.3079793453216553 seconds for one epoch ---
--- 1.793224811553955 seconds for one epoch ---
--- 0.29788684844970703 seconds for one epoch ---
--- 1.7850267887115479 seconds for one epoch ---
--- 0.301572322845459 seconds for one epoch ---
--- 1.8221065998077393 seconds for one epoch ---
--- 0.30124402046203613 seconds for one epoch ---
--- 1.7857179641723633 seconds for one epoch ---
--- 0.295335054397583 seconds for one epoch ---
--- 1.814941167831421 seconds for one epoch ---
--- 0.31065940856933594 seconds for one epoch ---
--- 1.7280077934265137 seconds for one epoch ---
--- 0.3026280403137207 seconds for one epoch ---
--- 1.762740135192871 seconds for one epoch ---
--- 0.3008604049682617 seconds for one epoch ---
--- 1.7625608444213867 seconds for one epoch ---
--- 0.3017768859863281 seconds for one epoch ---
--- 1.7935223579406738 seconds for one epoch ---
=========================
[[0.       ]
 [0.9993243]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.7221369]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2511803]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.6445503]
 [-0.       ]]
--- 0.29706287384033203 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3927.843017578125, (1557.2295, 2.7005367, 2367.198, 0.7151541)
   validation loss 783.7634887695312, (474.90402, 0.35891995, 307.78537, 0.7151541)
decoder loss ratio: 18398.606290, decoder SINDy loss  ratio: 0.664398
--- 0.2667572498321533 seconds for one epoch ---
--- 0.29314756393432617 seconds for one epoch ---
--- 1.79270601272583 seconds for one epoch ---
--- 0.30175328254699707 seconds for one epoch ---
--- 1.7868824005126953 seconds for one epoch ---
--- 0.2937929630279541 seconds for one epoch ---
--- 1.777799367904663 seconds for one epoch ---
--- 0.2924015522003174 seconds for one epoch ---
--- 1.7921297550201416 seconds for one epoch ---
--- 0.29999685287475586 seconds for one epoch ---
--- 1.8065838813781738 seconds for one epoch ---
--- 0.29944515228271484 seconds for one epoch ---
--- 1.8181006908416748 seconds for one epoch ---
--- 0.29843711853027344 seconds for one epoch ---
--- 1.823371171951294 seconds for one epoch ---
--- 0.2940218448638916 seconds for one epoch ---
--- 1.7575984001159668 seconds for one epoch ---
--- 0.2977437973022461 seconds for one epoch ---
--- 1.77315354347229 seconds for one epoch ---
--- 0.3026869297027588 seconds for one epoch ---
--- 1.758596420288086 seconds for one epoch ---
--- 0.3054921627044678 seconds for one epoch ---
--- 1.7657084465026855 seconds for one epoch ---
--- 0.2996859550476074 seconds for one epoch ---
=========================
[[0.      ]
 [0.999266]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-0.       ]
 [-0.7179718]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2488676]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.6795964]
 [ 0.       ]]
--- 0.27004528045654297 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4484.20458984375, (2243.624, 0.3102002, 2239.5552, 0.7154489)
   validation loss 1274.3118896484375, (970.35864, 0.28950828, 302.94827, 0.7154489)
decoder loss ratio: 37593.378430, decoder SINDy loss  ratio: 0.653956
--- 0.2985250949859619 seconds for one epoch ---
--- 1.835495948791504 seconds for one epoch ---
--- 0.3007359504699707 seconds for one epoch ---
--- 1.8087828159332275 seconds for one epoch ---
--- 0.3032083511352539 seconds for one epoch ---
--- 1.8304622173309326 seconds for one epoch ---
--- 0.3129732608795166 seconds for one epoch ---
--- 1.8125765323638916 seconds for one epoch ---
--- 0.31899404525756836 seconds for one epoch ---
--- 1.8073794841766357 seconds for one epoch ---
--- 0.30808591842651367 seconds for one epoch ---
--- 1.8117504119873047 seconds for one epoch ---
--- 0.30661964416503906 seconds for one epoch ---
--- 1.8374364376068115 seconds for one epoch ---
--- 0.30208897590637207 seconds for one epoch ---
--- 1.7997221946716309 seconds for one epoch ---
--- 0.30724382400512695 seconds for one epoch ---
--- 1.7853600978851318 seconds for one epoch ---
--- 0.29783177375793457 seconds for one epoch ---
--- 1.7892494201660156 seconds for one epoch ---
--- 0.29903340339660645 seconds for one epoch ---
--- 1.8013181686401367 seconds for one epoch ---
--- 0.3019587993621826 seconds for one epoch ---
--- 1.7805819511413574 seconds for one epoch ---
=========================
[[0.        ]
 [0.99912155]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7089504]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2540054]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.7137184]
 [-0.       ]]
--- 0.3048896789550781 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2538.10888671875, (1291.0073, 0.43925995, 1245.9464, 0.71571803)
   validation loss 953.98876953125, (639.90533, 0.329646, 313.0381, 0.71571803)
decoder loss ratio: 24791.043582, decoder SINDy loss  ratio: 0.675737
--- 0.273090124130249 seconds for one epoch ---
--- 0.31780314445495605 seconds for one epoch ---
--- 1.7888848781585693 seconds for one epoch ---
--- 0.3124697208404541 seconds for one epoch ---
--- 1.8301746845245361 seconds for one epoch ---
--- 0.30601048469543457 seconds for one epoch ---
--- 1.8225929737091064 seconds for one epoch ---
--- 0.30855250358581543 seconds for one epoch ---
--- 1.8063139915466309 seconds for one epoch ---
--- 0.3096435070037842 seconds for one epoch ---
--- 1.807546615600586 seconds for one epoch ---
--- 0.2953379154205322 seconds for one epoch ---
--- 1.856276035308838 seconds for one epoch ---
--- 0.3035264015197754 seconds for one epoch ---
--- 1.8280029296875 seconds for one epoch ---
--- 0.29996252059936523 seconds for one epoch ---
--- 1.8035578727722168 seconds for one epoch ---
--- 0.30472660064697266 seconds for one epoch ---
--- 1.7802913188934326 seconds for one epoch ---
--- 0.29430055618286133 seconds for one epoch ---
--- 1.7986233234405518 seconds for one epoch ---
--- 0.30184340476989746 seconds for one epoch ---
--- 1.8070018291473389 seconds for one epoch ---
--- 0.3223145008087158 seconds for one epoch ---
=========================
[[0.       ]
 [0.9993707]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.72571266]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.2592379 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.7337604 ]
 [-0.        ]]
--- 0.26256299018859863 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4480.85498046875, (2716.0383, 1.7545822, 1762.3463, 0.7159193)
   validation loss 1006.256591796875, (695.784, 0.36112437, 309.3955, 0.7159193)
decoder loss ratio: 26955.879962, decoder SINDy loss  ratio: 0.667874
--- 0.2903017997741699 seconds for one epoch ---
--- 1.8320786952972412 seconds for one epoch ---
--- 0.3010416030883789 seconds for one epoch ---
--- 1.8451337814331055 seconds for one epoch ---
--- 0.301727294921875 seconds for one epoch ---
--- 1.8323583602905273 seconds for one epoch ---
--- 0.3007519245147705 seconds for one epoch ---
--- 1.827709436416626 seconds for one epoch ---
--- 0.3008537292480469 seconds for one epoch ---
--- 1.8169126510620117 seconds for one epoch ---
--- 0.3000752925872803 seconds for one epoch ---
--- 1.8391335010528564 seconds for one epoch ---
--- 0.3118455410003662 seconds for one epoch ---
--- 1.8292944431304932 seconds for one epoch ---
--- 0.2941281795501709 seconds for one epoch ---
--- 1.7879071235656738 seconds for one epoch ---
--- 0.2952573299407959 seconds for one epoch ---
--- 1.795302152633667 seconds for one epoch ---
--- 0.3025779724121094 seconds for one epoch ---
--- 1.7841973304748535 seconds for one epoch ---
--- 0.31603384017944336 seconds for one epoch ---
--- 1.808107614517212 seconds for one epoch ---
--- 0.29732418060302734 seconds for one epoch ---
--- 1.8430802822113037 seconds for one epoch ---
=========================
[[0.        ]
 [0.99925065]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.71697897]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.2522525 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.7628784 ]
 [ 0.        ]]
--- 0.3106265068054199 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3215.716552734375, (1155.308, 0.5494464, 2059.143, 0.7161307)
   validation loss 1028.837890625, (731.51324, 0.24913488, 296.35934, 0.7161307)
decoder loss ratio: 28340.093060, decoder SINDy loss  ratio: 0.639733
--- 0.26879096031188965 seconds for one epoch ---
--- 0.30208516120910645 seconds for one epoch ---
--- 1.850158452987671 seconds for one epoch ---
--- 0.2957007884979248 seconds for one epoch ---
--- 1.826470136642456 seconds for one epoch ---
--- 0.2944834232330322 seconds for one epoch ---
--- 1.8353538513183594 seconds for one epoch ---
--- 0.31096982955932617 seconds for one epoch ---
--- 1.843461036682129 seconds for one epoch ---
--- 0.3012516498565674 seconds for one epoch ---
--- 1.8700919151306152 seconds for one epoch ---
--- 0.30274534225463867 seconds for one epoch ---
--- 1.8114597797393799 seconds for one epoch ---
--- 0.2949826717376709 seconds for one epoch ---
--- 1.8012793064117432 seconds for one epoch ---
--- 0.3069779872894287 seconds for one epoch ---
--- 1.8020052909851074 seconds for one epoch ---
--- 0.2996664047241211 seconds for one epoch ---
--- 1.8259303569793701 seconds for one epoch ---
--- 0.3004474639892578 seconds for one epoch ---
--- 1.8420486450195312 seconds for one epoch ---
--- 0.28390955924987793 seconds for one epoch ---
--- 1.853729009628296 seconds for one epoch ---
--- 0.3116436004638672 seconds for one epoch ---
=========================
[[0.       ]
 [0.9988873]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6971012]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2483639]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.783289 ]
 [ 0.       ]]
--- 0.26560187339782715 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5078.15966796875, (1858.4543, 3.065137, 3215.924, 0.71630496)
   validation loss 870.7492065429688, (583.08105, 0.26055607, 286.69128, 0.71630496)
decoder loss ratio: 22589.572332, decoder SINDy loss  ratio: 0.618863
--- 0.3103146553039551 seconds for one epoch ---
--- 1.8559398651123047 seconds for one epoch ---
--- 0.31091856956481934 seconds for one epoch ---
--- 1.8387722969055176 seconds for one epoch ---
--- 0.3031797409057617 seconds for one epoch ---
--- 1.8478715419769287 seconds for one epoch ---
--- 0.29664182662963867 seconds for one epoch ---
--- 1.872910976409912 seconds for one epoch ---
--- 0.3021829128265381 seconds for one epoch ---
--- 1.8657965660095215 seconds for one epoch ---
--- 0.3073310852050781 seconds for one epoch ---
--- 1.8372726440429688 seconds for one epoch ---
--- 0.2993960380554199 seconds for one epoch ---
--- 1.8345048427581787 seconds for one epoch ---
--- 0.2845754623413086 seconds for one epoch ---
--- 1.8133001327514648 seconds for one epoch ---
--- 0.30083346366882324 seconds for one epoch ---
--- 1.8057262897491455 seconds for one epoch ---
--- 0.2885549068450928 seconds for one epoch ---
--- 1.821976661682129 seconds for one epoch ---
--- 0.2999238967895508 seconds for one epoch ---
--- 1.865501880645752 seconds for one epoch ---
--- 0.29918575286865234 seconds for one epoch ---
--- 1.8478553295135498 seconds for one epoch ---
=========================
[[0.        ]
 [0.99883676]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6948598]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2490854]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.808452 ]
 [-0.       ]]
--- 0.29498839378356934 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2848.800537109375, (908.893, 0.57780623, 1938.613, 0.71650285)
   validation loss 776.7750854492188, (483.5085, 0.29176593, 292.2583, 0.71650285)
decoder loss ratio: 18731.959256, decoder SINDy loss  ratio: 0.630881
--- 0.26232218742370605 seconds for one epoch ---
--- 0.2997450828552246 seconds for one epoch ---
--- 1.8172345161437988 seconds for one epoch ---
--- 0.29943394660949707 seconds for one epoch ---
--- 1.829622745513916 seconds for one epoch ---
--- 0.299088716506958 seconds for one epoch ---
--- 1.8339009284973145 seconds for one epoch ---
--- 0.31133604049682617 seconds for one epoch ---
--- 1.8508973121643066 seconds for one epoch ---
--- 0.2931187152862549 seconds for one epoch ---
--- 1.8150980472564697 seconds for one epoch ---
--- 0.29718542098999023 seconds for one epoch ---
--- 1.8133997917175293 seconds for one epoch ---
--- 0.2969326972961426 seconds for one epoch ---
--- 1.8111393451690674 seconds for one epoch ---
--- 0.29761242866516113 seconds for one epoch ---
--- 1.804297924041748 seconds for one epoch ---
--- 0.2896134853363037 seconds for one epoch ---
--- 1.8429555892944336 seconds for one epoch ---
--- 0.29401683807373047 seconds for one epoch ---
--- 1.866913080215454 seconds for one epoch ---
--- 0.29863786697387695 seconds for one epoch ---
--- 1.8444674015045166 seconds for one epoch ---
--- 0.3033440113067627 seconds for one epoch ---
=========================
[[0.        ]
 [0.99872345]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6902166]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.256396 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.8347244]
 [ 0.       ]]
--- 0.2658560276031494 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2478.30126953125, (1076.2921, 1.0539647, 1400.2385, 0.71674913)
   validation loss 967.3141479492188, (677.9956, 0.2828039, 288.31906, 0.71674913)
decoder loss ratio: 26266.726808, decoder SINDy loss  ratio: 0.622377
--- 0.3063349723815918 seconds for one epoch ---
--- 1.875821828842163 seconds for one epoch ---
--- 0.3092176914215088 seconds for one epoch ---
--- 1.8525803089141846 seconds for one epoch ---
--- 0.30116868019104004 seconds for one epoch ---
--- 1.8770718574523926 seconds for one epoch ---
--- 0.301436185836792 seconds for one epoch ---
--- 1.8602232933044434 seconds for one epoch ---
--- 0.30483388900756836 seconds for one epoch ---
--- 1.8972136974334717 seconds for one epoch ---
--- 0.31676244735717773 seconds for one epoch ---
--- 1.8223166465759277 seconds for one epoch ---
--- 0.2975170612335205 seconds for one epoch ---
--- 1.8471128940582275 seconds for one epoch ---
--- 0.29982829093933105 seconds for one epoch ---
--- 1.8372488021850586 seconds for one epoch ---
--- 0.2972440719604492 seconds for one epoch ---
--- 1.8630833625793457 seconds for one epoch ---
--- 0.29781556129455566 seconds for one epoch ---
--- 1.8557531833648682 seconds for one epoch ---
--- 0.33046865463256836 seconds for one epoch ---
--- 1.8839197158813477 seconds for one epoch ---
--- 0.32137155532836914 seconds for one epoch ---
--- 1.8821823596954346 seconds for one epoch ---
=========================
[[0.        ]
 [0.99898744]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.70183444]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.2551485 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.8573084 ]
 [-0.        ]]
--- 0.2961857318878174 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1919.6575927734375, (915.2976, 0.9650788, 1002.6779, 0.71694046)
   validation loss 781.2774658203125, (471.95547, 0.33813897, 308.2669, 0.71694046)
decoder loss ratio: 18284.374447, decoder SINDy loss  ratio: 0.665437
--- 0.266207218170166 seconds for one epoch ---
--- 0.2981266975402832 seconds for one epoch ---
--- 1.8665757179260254 seconds for one epoch ---
--- 0.2964150905609131 seconds for one epoch ---
--- 1.8287885189056396 seconds for one epoch ---
--- 0.3032832145690918 seconds for one epoch ---
--- 1.864119529724121 seconds for one epoch ---
--- 0.3003838062286377 seconds for one epoch ---
--- 1.8756639957427979 seconds for one epoch ---
--- 0.2982625961303711 seconds for one epoch ---
--- 1.833425760269165 seconds for one epoch ---
--- 0.30032825469970703 seconds for one epoch ---
--- 1.8308892250061035 seconds for one epoch ---
--- 0.29764413833618164 seconds for one epoch ---
--- 1.8212509155273438 seconds for one epoch ---
--- 0.29989123344421387 seconds for one epoch ---
--- 1.8181231021881104 seconds for one epoch ---
--- 0.2979745864868164 seconds for one epoch ---
--- 1.9015142917633057 seconds for one epoch ---
--- 0.3140377998352051 seconds for one epoch ---
--- 1.8753728866577148 seconds for one epoch ---
--- 0.33746981620788574 seconds for one epoch ---
--- 1.8934295177459717 seconds for one epoch ---
--- 0.3271012306213379 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991968]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.7134351]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2498561]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.879633 ]
 [-0.       ]]
--- 0.25737786293029785 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3613.02734375, (1511.7952, 2.4763417, 2098.0388, 0.7171118)
   validation loss 731.8152465820312, (448.9592, 0.28420296, 281.85477, 0.7171118)
decoder loss ratio: 17393.458758, decoder SINDy loss  ratio: 0.608423
--- 0.2993030548095703 seconds for one epoch ---
--- 1.866147518157959 seconds for one epoch ---
--- 0.29175424575805664 seconds for one epoch ---
--- 1.8449573516845703 seconds for one epoch ---
--- 0.30260181427001953 seconds for one epoch ---
--- 1.8616809844970703 seconds for one epoch ---
--- 0.2931530475616455 seconds for one epoch ---
--- 1.8852989673614502 seconds for one epoch ---
--- 0.30875277519226074 seconds for one epoch ---
--- 1.8826489448547363 seconds for one epoch ---
--- 0.30148863792419434 seconds for one epoch ---
--- 1.826420783996582 seconds for one epoch ---
--- 0.29117393493652344 seconds for one epoch ---
--- 1.8390419483184814 seconds for one epoch ---
--- 0.3012509346008301 seconds for one epoch ---
--- 1.8584051132202148 seconds for one epoch ---
--- 0.3082249164581299 seconds for one epoch ---
--- 1.8253414630889893 seconds for one epoch ---
--- 0.30809521675109863 seconds for one epoch ---
--- 1.8586313724517822 seconds for one epoch ---
--- 0.3032798767089844 seconds for one epoch ---
--- 1.8654191493988037 seconds for one epoch ---
--- 0.30064892768859863 seconds for one epoch ---
--- 1.890859603881836 seconds for one epoch ---
=========================
[[0.       ]
 [0.9990066]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7027843]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2502719]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.9024205]
 [ 0.       ]]
--- 0.2918407917022705 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4234.31103515625, (1678.3885, 0.7536849, 2554.4517, 0.7172935)
   validation loss 927.1234130859375, (609.9778, 0.3492176, 316.0791, 0.7172935)
decoder loss ratio: 23631.598289, decoder SINDy loss  ratio: 0.682301
--- 0.25653529167175293 seconds for one epoch ---
--- 0.3003067970275879 seconds for one epoch ---
--- 1.852125883102417 seconds for one epoch ---
--- 0.2971799373626709 seconds for one epoch ---
--- 1.852315902709961 seconds for one epoch ---
--- 0.29522013664245605 seconds for one epoch ---
--- 1.8874118328094482 seconds for one epoch ---
--- 0.3059818744659424 seconds for one epoch ---
--- 1.8868634700775146 seconds for one epoch ---
--- 0.30196714401245117 seconds for one epoch ---
--- 1.8984265327453613 seconds for one epoch ---
--- 0.29467272758483887 seconds for one epoch ---
--- 1.8498902320861816 seconds for one epoch ---
--- 0.29549694061279297 seconds for one epoch ---
--- 1.8710484504699707 seconds for one epoch ---
--- 0.2921109199523926 seconds for one epoch ---
--- 1.8461661338806152 seconds for one epoch ---
--- 0.29591965675354004 seconds for one epoch ---
--- 1.8950791358947754 seconds for one epoch ---
--- 0.3080298900604248 seconds for one epoch ---
--- 1.8882403373718262 seconds for one epoch ---
--- 0.296445369720459 seconds for one epoch ---
--- 1.9337918758392334 seconds for one epoch ---
--- 0.29794740676879883 seconds for one epoch ---
=========================
[[0.        ]
 [0.99881583]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6939736]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2553796]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.926325 ]
 [ 0.       ]]
--- 0.2657921314239502 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4157.478515625, (1831.7747, 0.78469384, 2324.2012, 0.717545)
   validation loss 840.8621826171875, (550.02905, 0.2538935, 289.8617, 0.717545)
decoder loss ratio: 21309.080395, decoder SINDy loss  ratio: 0.625707
--- 0.3029336929321289 seconds for one epoch ---
--- 1.9355874061584473 seconds for one epoch ---
--- 0.3017857074737549 seconds for one epoch ---
--- 1.905336856842041 seconds for one epoch ---
--- 0.3069295883178711 seconds for one epoch ---
--- 1.9047045707702637 seconds for one epoch ---
--- 0.3058335781097412 seconds for one epoch ---
--- 1.9210898876190186 seconds for one epoch ---
--- 0.3021726608276367 seconds for one epoch ---
--- 1.9350063800811768 seconds for one epoch ---
--- 0.30490851402282715 seconds for one epoch ---
--- 1.8954014778137207 seconds for one epoch ---
--- 0.3055281639099121 seconds for one epoch ---
--- 1.8922207355499268 seconds for one epoch ---
--- 0.3008146286010742 seconds for one epoch ---
--- 1.895629644393921 seconds for one epoch ---
--- 0.30466246604919434 seconds for one epoch ---
--- 1.896977186203003 seconds for one epoch ---
--- 0.29830074310302734 seconds for one epoch ---
--- 1.9567945003509521 seconds for one epoch ---
--- 0.31006455421447754 seconds for one epoch ---
--- 1.9147121906280518 seconds for one epoch ---
--- 0.3455085754394531 seconds for one epoch ---
--- 1.9632587432861328 seconds for one epoch ---
=========================
[[0.       ]
 [0.9989177]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6984663]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2578454]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.947716 ]
 [-0.       ]]
--- 0.3062288761138916 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4334.16845703125, (1663.4929, 0.72300035, 2669.2349, 0.7177079)
   validation loss 826.6021118164062, (519.8294, 0.30194622, 305.75308, 0.7177079)
decoder loss ratio: 20139.093681, decoder SINDy loss  ratio: 0.660011
THRESHOLDING: 3 active coefficients
--- 1.9145050048828125 seconds for one epoch ---
--- 0.2948641777038574 seconds for one epoch ---
--- 1.932450294494629 seconds for one epoch ---
--- 0.30728650093078613 seconds for one epoch ---
--- 1.9263408184051514 seconds for one epoch ---
--- 0.3060038089752197 seconds for one epoch ---
--- 1.910447359085083 seconds for one epoch ---
--- 0.30262231826782227 seconds for one epoch ---
--- 1.9336555004119873 seconds for one epoch ---
--- 0.29990696907043457 seconds for one epoch ---
--- 1.957420825958252 seconds for one epoch ---
--- 0.3069789409637451 seconds for one epoch ---
--- 1.9131994247436523 seconds for one epoch ---
--- 0.3024473190307617 seconds for one epoch ---
--- 1.889862298965454 seconds for one epoch ---
--- 0.29997897148132324 seconds for one epoch ---
--- 1.9047925472259521 seconds for one epoch ---
--- 0.2861640453338623 seconds for one epoch ---
--- 1.8816287517547607 seconds for one epoch ---
--- 0.3018925189971924 seconds for one epoch ---
--- 1.9769008159637451 seconds for one epoch ---
--- 0.30730724334716797 seconds for one epoch ---
--- 1.92728590965271 seconds for one epoch ---
--- 0.30378103256225586 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991078]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.70818275]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.2537503 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-5.9655952 ]
 [ 0.        ]]
--- 0.2672557830810547 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3742.45654296875, (1930.5718, 0.4584669, 1810.7086, 0.7178866)
   validation loss 869.4036865234375, (575.2423, 0.31818005, 293.12534, 0.7178866)
decoder loss ratio: 22285.885737, decoder SINDy loss  ratio: 0.632752
--- 0.30233025550842285 seconds for one epoch ---
--- 1.9247074127197266 seconds for one epoch ---
--- 0.29947495460510254 seconds for one epoch ---
--- 1.937114953994751 seconds for one epoch ---
--- 0.31125473976135254 seconds for one epoch ---
--- 1.9261565208435059 seconds for one epoch ---
--- 0.29901838302612305 seconds for one epoch ---
--- 1.9587669372558594 seconds for one epoch ---
--- 0.3056681156158447 seconds for one epoch ---
--- 1.9550392627716064 seconds for one epoch ---
--- 0.2906372547149658 seconds for one epoch ---
--- 1.9320242404937744 seconds for one epoch ---
--- 0.2964513301849365 seconds for one epoch ---
--- 1.906799077987671 seconds for one epoch ---
--- 0.2927820682525635 seconds for one epoch ---
--- 1.9022557735443115 seconds for one epoch ---
--- 0.29873037338256836 seconds for one epoch ---
--- 1.928391933441162 seconds for one epoch ---
--- 0.2967970371246338 seconds for one epoch ---
--- 1.9121716022491455 seconds for one epoch ---
--- 0.30624938011169434 seconds for one epoch ---
--- 1.948692798614502 seconds for one epoch ---
--- 0.3052637577056885 seconds for one epoch ---
--- 1.9543108940124512 seconds for one epoch ---
=========================
[[0.       ]
 [0.9990223]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.7036362]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2504045]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.9853525]
 [-0.       ]]
--- 0.3089256286621094 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2079.654052734375, (909.52686, 1.8175114, 1167.5918, 0.71803623)
   validation loss 1021.2587280273438, (697.8663, 0.2658619, 322.40857, 0.71803623)
decoder loss ratio: 27036.550925, decoder SINDy loss  ratio: 0.695964
--- 0.2658841609954834 seconds for one epoch ---
--- 0.3147153854370117 seconds for one epoch ---
--- 1.9921653270721436 seconds for one epoch ---
--- 0.3023362159729004 seconds for one epoch ---
--- 1.9658186435699463 seconds for one epoch ---
--- 0.2974882125854492 seconds for one epoch ---
--- 2.0035696029663086 seconds for one epoch ---
--- 0.29786157608032227 seconds for one epoch ---
--- 2.008795976638794 seconds for one epoch ---
--- 0.30937862396240234 seconds for one epoch ---
--- 1.9822299480438232 seconds for one epoch ---
--- 0.30431151390075684 seconds for one epoch ---
--- 1.929819107055664 seconds for one epoch ---
--- 0.3007490634918213 seconds for one epoch ---
--- 1.953742504119873 seconds for one epoch ---
--- 0.30631351470947266 seconds for one epoch ---
--- 1.9429385662078857 seconds for one epoch ---
--- 0.3048591613769531 seconds for one epoch ---
--- 1.9718997478485107 seconds for one epoch ---
--- 0.3041222095489502 seconds for one epoch ---
--- 2.0079448223114014 seconds for one epoch ---
--- 0.30617427825927734 seconds for one epoch ---
--- 1.9778127670288086 seconds for one epoch ---
--- 0.3053004741668701 seconds for one epoch ---
=========================
[[0.        ]
 [0.99906117]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7056442]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2562555]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.004666 ]
 [-0.       ]]
--- 0.2637364864349365 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4195.4716796875, (1399.2477, 1.137191, 2794.3687, 0.7182145)
   validation loss 886.0745239257812, (566.5098, 0.26403537, 318.58246, 0.7182145)
decoder loss ratio: 21947.574189, decoder SINDy loss  ratio: 0.687705
--- 0.30320000648498535 seconds for one epoch ---
--- 1.9502251148223877 seconds for one epoch ---
--- 0.30382466316223145 seconds for one epoch ---
--- 1.9577162265777588 seconds for one epoch ---
--- 0.3024756908416748 seconds for one epoch ---
--- 1.9657433032989502 seconds for one epoch ---
--- 0.30463504791259766 seconds for one epoch ---
--- 1.9765355587005615 seconds for one epoch ---
--- 0.3002204895019531 seconds for one epoch ---
--- 1.9877071380615234 seconds for one epoch ---
--- 0.3089933395385742 seconds for one epoch ---
--- 1.950730323791504 seconds for one epoch ---
--- 0.3046762943267822 seconds for one epoch ---
--- 1.9296882152557373 seconds for one epoch ---
--- 0.29590630531311035 seconds for one epoch ---
--- 1.9446606636047363 seconds for one epoch ---
--- 0.30148839950561523 seconds for one epoch ---
--- 1.934056043624878 seconds for one epoch ---
--- 0.30362415313720703 seconds for one epoch ---
--- 1.9289393424987793 seconds for one epoch ---
--- 0.303633451461792 seconds for one epoch ---
--- 2.025195360183716 seconds for one epoch ---
--- 0.318103551864624 seconds for one epoch ---
--- 2.018319845199585 seconds for one epoch ---
=========================
[[0.       ]
 [0.9990455]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7047439]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2573677]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.030113 ]
 [ 0.       ]]
--- 0.30139684677124023 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4190.37890625, (1500.8743, 2.042568, 2686.7437, 0.71842736)
   validation loss 1014.180908203125, (714.78503, 0.28401944, 298.39343, 0.71842736)
decoder loss ratio: 27692.013146, decoder SINDy loss  ratio: 0.644124
--- 0.27297115325927734 seconds for one epoch ---
--- 0.3005061149597168 seconds for one epoch ---
--- 1.9740955829620361 seconds for one epoch ---
--- 0.29971957206726074 seconds for one epoch ---
--- 1.972804307937622 seconds for one epoch ---
--- 0.30133986473083496 seconds for one epoch ---
--- 1.9772357940673828 seconds for one epoch ---
--- 0.29831361770629883 seconds for one epoch ---
--- 1.966615915298462 seconds for one epoch ---
--- 0.3015289306640625 seconds for one epoch ---
--- 1.992072343826294 seconds for one epoch ---
--- 0.30628180503845215 seconds for one epoch ---
--- 1.9271018505096436 seconds for one epoch ---
--- 0.2997870445251465 seconds for one epoch ---
--- 1.9351606369018555 seconds for one epoch ---
--- 0.2987203598022461 seconds for one epoch ---
--- 1.9387333393096924 seconds for one epoch ---
--- 0.2984180450439453 seconds for one epoch ---
--- 1.9471189975738525 seconds for one epoch ---
--- 0.3012697696685791 seconds for one epoch ---
--- 1.9758143424987793 seconds for one epoch ---
--- 0.294785737991333 seconds for one epoch ---
--- 2.0027050971984863 seconds for one epoch ---
--- 0.30469799041748047 seconds for one epoch ---
=========================
[[0.       ]
 [0.9986526]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6874922]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2702036]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.053617 ]
 [ 0.       ]]
--- 0.26365232467651367 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3537.23095703125, (1886.383, 3.2009065, 1646.9281, 0.718655)
   validation loss 1305.658447265625, (1016.39594, 0.3089312, 288.23492, 0.718655)
decoder loss ratio: 39376.943065, decoder SINDy loss  ratio: 0.622196
--- 0.30164670944213867 seconds for one epoch ---
--- 2.008850574493408 seconds for one epoch ---
--- 0.3063967227935791 seconds for one epoch ---
--- 1.9968700408935547 seconds for one epoch ---
--- 0.30370187759399414 seconds for one epoch ---
--- 2.0264620780944824 seconds for one epoch ---
--- 0.3021886348724365 seconds for one epoch ---
--- 2.0046703815460205 seconds for one epoch ---
--- 0.2964303493499756 seconds for one epoch ---
--- 2.040515661239624 seconds for one epoch ---
--- 0.3099212646484375 seconds for one epoch ---
--- 2.028046131134033 seconds for one epoch ---
--- 0.299877405166626 seconds for one epoch ---
--- 1.9622275829315186 seconds for one epoch ---
--- 0.30817341804504395 seconds for one epoch ---
--- 1.9808259010314941 seconds for one epoch ---
--- 0.29887962341308594 seconds for one epoch ---
--- 1.9961433410644531 seconds for one epoch ---
--- 0.2994868755340576 seconds for one epoch ---
--- 2.0040953159332275 seconds for one epoch ---
--- 0.2939274311065674 seconds for one epoch ---
--- 2.0104715824127197 seconds for one epoch ---
--- 0.3230152130126953 seconds for one epoch ---
--- 2.046046495437622 seconds for one epoch ---
=========================
[[0.       ]
 [0.9987526]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6913749]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.262844 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.0721827]
 [-0.       ]]
--- 0.28867483139038086 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3220.9404296875, (872.65765, 0.21773864, 2347.3464, 0.71880215)
   validation loss 896.400146484375, (613.5794, 0.31826, 281.7837, 0.71880215)
decoder loss ratio: 23771.131438, decoder SINDy loss  ratio: 0.608270
--- 0.26879167556762695 seconds for one epoch ---
--- 0.29323315620422363 seconds for one epoch ---
--- 1.9883456230163574 seconds for one epoch ---
--- 0.3043055534362793 seconds for one epoch ---
--- 1.9929180145263672 seconds for one epoch ---
--- 0.30199766159057617 seconds for one epoch ---
--- 1.9990694522857666 seconds for one epoch ---
--- 0.29812026023864746 seconds for one epoch ---
--- 2.0285282135009766 seconds for one epoch ---
--- 0.3012702465057373 seconds for one epoch ---
--- 1.9695568084716797 seconds for one epoch ---
--- 0.30004096031188965 seconds for one epoch ---
--- 1.9702939987182617 seconds for one epoch ---
--- 0.3012208938598633 seconds for one epoch ---
--- 1.987440824508667 seconds for one epoch ---
--- 0.29965710639953613 seconds for one epoch ---
--- 1.974358081817627 seconds for one epoch ---
--- 0.30251312255859375 seconds for one epoch ---
--- 1.966963768005371 seconds for one epoch ---
--- 0.2993032932281494 seconds for one epoch ---
--- 2.0063838958740234 seconds for one epoch ---
--- 0.29822754859924316 seconds for one epoch ---
--- 2.000739336013794 seconds for one epoch ---
--- 0.3047049045562744 seconds for one epoch ---
=========================
[[0.        ]
 [0.99912065]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.708854 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2535894]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.0988836]
 [ 0.       ]]
--- 0.2633700370788574 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3547.945556640625, (1306.2128, 0.5101854, 2240.5037, 0.71904397)
   validation loss 932.8805541992188, (628.33636, 0.27704626, 303.54813, 0.71904397)
decoder loss ratio: 24342.841610, decoder SINDy loss  ratio: 0.655251
--- 0.3114950656890869 seconds for one epoch ---
--- 2.0037789344787598 seconds for one epoch ---
--- 0.2933375835418701 seconds for one epoch ---
--- 1.980459451675415 seconds for one epoch ---
--- 0.29857754707336426 seconds for one epoch ---
--- 2.0281119346618652 seconds for one epoch ---
--- 0.29842495918273926 seconds for one epoch ---
--- 2.0151429176330566 seconds for one epoch ---
--- 0.2990560531616211 seconds for one epoch ---
--- 2.0099751949310303 seconds for one epoch ---
--- 0.293656587600708 seconds for one epoch ---
--- 1.9997220039367676 seconds for one epoch ---
--- 0.29878807067871094 seconds for one epoch ---
--- 1.9692587852478027 seconds for one epoch ---
--- 0.29795098304748535 seconds for one epoch ---
--- 1.9716477394104004 seconds for one epoch ---
--- 0.29642248153686523 seconds for one epoch ---
--- 1.991511583328247 seconds for one epoch ---
--- 0.30196595191955566 seconds for one epoch ---
--- 1.973907232284546 seconds for one epoch ---
--- 0.296222448348999 seconds for one epoch ---
--- 2.0433332920074463 seconds for one epoch ---
--- 0.30319929122924805 seconds for one epoch ---
--- 2.045858144760132 seconds for one epoch ---
=========================
[[0.        ]
 [0.99898446]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.70169526]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.2560571 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.1155763 ]
 [-0.        ]]
--- 0.2947275638580322 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4756.50048828125, (2528.9478, 0.82130337, 2226.0125, 0.7191841)
   validation loss 1022.052978515625, (720.99176, 0.33512056, 300.0069, 0.7191841)
decoder loss ratio: 27932.472489, decoder SINDy loss  ratio: 0.647607
--- 0.27136659622192383 seconds for one epoch ---
--- 0.2971360683441162 seconds for one epoch ---
--- 2.0251336097717285 seconds for one epoch ---
--- 0.302746057510376 seconds for one epoch ---
--- 2.0272138118743896 seconds for one epoch ---
--- 0.2973208427429199 seconds for one epoch ---
--- 2.0472612380981445 seconds for one epoch ---
--- 0.3058311939239502 seconds for one epoch ---
--- 2.0642480850219727 seconds for one epoch ---
--- 0.3011970520019531 seconds for one epoch ---
--- 2.0421717166900635 seconds for one epoch ---
--- 0.29306936264038086 seconds for one epoch ---
--- 2.0182716846466064 seconds for one epoch ---
--- 0.29538488388061523 seconds for one epoch ---
--- 2.033447265625 seconds for one epoch ---
--- 0.2961406707763672 seconds for one epoch ---
--- 2.0179238319396973 seconds for one epoch ---
--- 0.2972886562347412 seconds for one epoch ---
--- 2.0143046379089355 seconds for one epoch ---
--- 0.302809476852417 seconds for one epoch ---
--- 2.041532516479492 seconds for one epoch ---
--- 0.3216531276702881 seconds for one epoch ---
--- 2.0781500339508057 seconds for one epoch ---
--- 0.32916688919067383 seconds for one epoch ---
=========================
[[0.        ]
 [0.99903923]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7044485]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2536874]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.134522 ]
 [-0.       ]]
--- 0.26365065574645996 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2540.89794921875, (959.78186, 0.8164622, 1579.5803, 0.7193495)
   validation loss 1448.5955810546875, (1155.0604, 0.26403502, 292.55182, 0.7193495)
decoder loss ratio: 44749.046130, decoder SINDy loss  ratio: 0.631514
--- 0.3013122081756592 seconds for one epoch ---
--- 2.0788371562957764 seconds for one epoch ---
--- 0.30653882026672363 seconds for one epoch ---
--- 2.064894676208496 seconds for one epoch ---
--- 0.30362653732299805 seconds for one epoch ---
--- 2.065891742706299 seconds for one epoch ---
--- 0.3017141819000244 seconds for one epoch ---
--- 2.0825905799865723 seconds for one epoch ---
--- 0.29985952377319336 seconds for one epoch ---
--- 2.0947203636169434 seconds for one epoch ---
--- 0.3001222610473633 seconds for one epoch ---
--- 2.036942481994629 seconds for one epoch ---
--- 0.3037734031677246 seconds for one epoch ---
--- 2.0517630577087402 seconds for one epoch ---
--- 0.29560089111328125 seconds for one epoch ---
--- 2.044555902481079 seconds for one epoch ---
--- 0.2998323440551758 seconds for one epoch ---
--- 2.041811943054199 seconds for one epoch ---
--- 0.2967185974121094 seconds for one epoch ---
--- 2.076124906539917 seconds for one epoch ---
--- 0.3011023998260498 seconds for one epoch ---
--- 2.0912129878997803 seconds for one epoch ---
--- 0.29159021377563477 seconds for one epoch ---
--- 2.094086170196533 seconds for one epoch ---
=========================
[[0.        ]
 [0.99922216]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.71505487]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.2513148 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.147497  ]
 [ 0.        ]]
--- 0.2948758602142334 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2957.82275390625, (1006.08704, 0.9600226, 1950.0562, 0.71945906)
   validation loss 872.5797119140625, (582.2562, 0.3217467, 289.28232, 0.71945906)
decoder loss ratio: 22557.617020, decoder SINDy loss  ratio: 0.624457
--- 0.2607917785644531 seconds for one epoch ---
--- 0.30339765548706055 seconds for one epoch ---
--- 2.091949224472046 seconds for one epoch ---
--- 0.30489635467529297 seconds for one epoch ---
--- 2.099506139755249 seconds for one epoch ---
--- 0.2957322597503662 seconds for one epoch ---
--- 2.099546432495117 seconds for one epoch ---
--- 0.3072793483734131 seconds for one epoch ---
--- 2.1002261638641357 seconds for one epoch ---
--- 0.3032395839691162 seconds for one epoch ---
--- 2.0354979038238525 seconds for one epoch ---
--- 0.3027212619781494 seconds for one epoch ---
--- 2.0413975715637207 seconds for one epoch ---
--- 0.3075447082519531 seconds for one epoch ---
--- 2.033581256866455 seconds for one epoch ---
--- 0.30495691299438477 seconds for one epoch ---
--- 2.0585455894470215 seconds for one epoch ---
--- 0.30822062492370605 seconds for one epoch ---
--- 2.0902657508850098 seconds for one epoch ---
--- 0.330411434173584 seconds for one epoch ---
--- 2.03843092918396 seconds for one epoch ---
--- 0.33884334564208984 seconds for one epoch ---
--- 2.078230619430542 seconds for one epoch ---
--- 0.3545660972595215 seconds for one epoch ---
=========================
[[0.       ]
 [0.9993305]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7226479]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2477137]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.1659594]
 [ 0.       ]]
--- 0.2578456401824951 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6603.8623046875, (1775.9026, 6.0395684, 4821.2, 0.7196221)
   validation loss 804.7730712890625, (501.66583, 0.32992312, 302.0577, 0.7196221)
decoder loss ratio: 19435.405282, decoder SINDy loss  ratio: 0.652034
--- 0.30234837532043457 seconds for one epoch ---
--- 2.0619900226593018 seconds for one epoch ---
--- 0.30493974685668945 seconds for one epoch ---
--- 2.063455581665039 seconds for one epoch ---
--- 0.280778169631958 seconds for one epoch ---
--- 2.054439067840576 seconds for one epoch ---
--- 0.30174946784973145 seconds for one epoch ---
--- 2.0766067504882812 seconds for one epoch ---
--- 0.30288267135620117 seconds for one epoch ---
--- 2.0878093242645264 seconds for one epoch ---
--- 0.29567694664001465 seconds for one epoch ---
--- 2.011075735092163 seconds for one epoch ---
--- 0.2985711097717285 seconds for one epoch ---
--- 2.02203369140625 seconds for one epoch ---
--- 0.29488706588745117 seconds for one epoch ---
--- 2.0391204357147217 seconds for one epoch ---
--- 0.2991628646850586 seconds for one epoch ---
--- 2.03728985786438 seconds for one epoch ---
--- 0.2998833656311035 seconds for one epoch ---
--- 2.075049638748169 seconds for one epoch ---
--- 0.3103809356689453 seconds for one epoch ---
--- 2.099335193634033 seconds for one epoch ---
--- 0.6726484298706055 seconds for one epoch ---
--- 2.116379737854004 seconds for one epoch ---
=========================
[[0.        ]
 [0.99930143]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7204667]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2437886]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.1766467]
 [-0.       ]]
--- 0.2938730716705322 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3988.90185546875, (2136.8103, 2.1337192, 1849.2382, 0.7197336)
   validation loss 813.1331787109375, (507.13916, 0.284129, 304.99017, 0.7197336)
decoder loss ratio: 19647.451497, decoder SINDy loss  ratio: 0.658364
--- 0.2722194194793701 seconds for one epoch ---
--- 0.3004794120788574 seconds for one epoch ---
--- 2.0971519947052 seconds for one epoch ---
--- 0.2994956970214844 seconds for one epoch ---
--- 2.094390630722046 seconds for one epoch ---
--- 0.29959678649902344 seconds for one epoch ---
--- 2.136232852935791 seconds for one epoch ---
--- 0.3123447895050049 seconds for one epoch ---
--- 2.082606315612793 seconds for one epoch ---
--- 0.2945394515991211 seconds for one epoch ---
--- 2.0652105808258057 seconds for one epoch ---
--- 0.3033583164215088 seconds for one epoch ---
--- 2.075019121170044 seconds for one epoch ---
--- 0.3116288185119629 seconds for one epoch ---
--- 2.087150812149048 seconds for one epoch ---
--- 0.3019137382507324 seconds for one epoch ---
--- 2.1044788360595703 seconds for one epoch ---
--- 0.29596471786499023 seconds for one epoch ---
--- 2.077744483947754 seconds for one epoch ---
--- 0.2992215156555176 seconds for one epoch ---
--- 2.1121368408203125 seconds for one epoch ---
--- 0.2954740524291992 seconds for one epoch ---
--- 2.0906624794006348 seconds for one epoch ---
--- 0.29733729362487793 seconds for one epoch ---
=========================
[[0.       ]
 [0.9992856]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.71937543]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.2402129 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.193591  ]
 [ 0.        ]]
--- 0.2611849308013916 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3681.33642578125, (1418.013, 4.528769, 2258.0747, 0.7198618)
   validation loss 923.7562255859375, (610.89453, 0.26845628, 311.87344, 0.7198618)
decoder loss ratio: 23667.114700, decoder SINDy loss  ratio: 0.673223
--- 0.3003230094909668 seconds for one epoch ---
--- 2.1311380863189697 seconds for one epoch ---
--- 0.29754066467285156 seconds for one epoch ---
--- 2.117091417312622 seconds for one epoch ---
--- 0.30215930938720703 seconds for one epoch ---
--- 2.149707555770874 seconds for one epoch ---
--- 0.3041534423828125 seconds for one epoch ---
--- 2.1278231143951416 seconds for one epoch ---
--- 0.29903101921081543 seconds for one epoch ---
--- 2.076420783996582 seconds for one epoch ---
--- 0.3074178695678711 seconds for one epoch ---
--- 2.076760768890381 seconds for one epoch ---
--- 0.29353952407836914 seconds for one epoch ---
--- 2.093047618865967 seconds for one epoch ---
--- 0.30138611793518066 seconds for one epoch ---
--- 2.071540355682373 seconds for one epoch ---
--- 0.3069641590118408 seconds for one epoch ---
--- 2.103337287902832 seconds for one epoch ---
--- 0.2950427532196045 seconds for one epoch ---
--- 2.123508930206299 seconds for one epoch ---
--- 0.2994072437286377 seconds for one epoch ---
--- 2.1066620349884033 seconds for one epoch ---
--- 0.30209946632385254 seconds for one epoch ---
--- 2.15805983543396 seconds for one epoch ---
=========================
[[0.       ]
 [0.9990144]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.7031953]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.240439 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.2094603]
 [-0.       ]]
--- 0.29740071296691895 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2934.493896484375, (1287.2067, 2.9186673, 1643.6486, 0.7200019)
   validation loss 1010.3064575195312, (705.29596, 0.2562745, 304.03415, 0.7200019)
decoder loss ratio: 27324.389918, decoder SINDy loss  ratio: 0.656300
--- 0.26894116401672363 seconds for one epoch ---
--- 0.30425167083740234 seconds for one epoch ---
--- 2.127999782562256 seconds for one epoch ---
--- 0.3081367015838623 seconds for one epoch ---
--- 2.148242712020874 seconds for one epoch ---
--- 0.3117506504058838 seconds for one epoch ---
--- 2.1016674041748047 seconds for one epoch ---
--- 0.29340219497680664 seconds for one epoch ---
--- 2.1034092903137207 seconds for one epoch ---
--- 0.30104851722717285 seconds for one epoch ---
--- 2.0917787551879883 seconds for one epoch ---
--- 0.30242156982421875 seconds for one epoch ---
--- 2.082429885864258 seconds for one epoch ---
--- 0.2991750240325928 seconds for one epoch ---
--- 2.130709171295166 seconds for one epoch ---
--- 0.30083179473876953 seconds for one epoch ---
--- 2.130209445953369 seconds for one epoch ---
--- 0.3015165328979492 seconds for one epoch ---
--- 2.163830518722534 seconds for one epoch ---
--- 0.30403900146484375 seconds for one epoch ---
--- 2.1243956089019775 seconds for one epoch ---
--- 0.30402183532714844 seconds for one epoch ---
--- 2.1323678493499756 seconds for one epoch ---
--- 0.29897499084472656 seconds for one epoch ---
=========================
[[0.       ]
 [0.9990525]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.705195 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2363595]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.220858 ]
 [-0.       ]]
--- 0.2534043788909912 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2049.420166015625, (756.7459, 0.28407446, 1291.67, 0.7201118)
   validation loss 1651.4012451171875, (1323.0616, 0.33659583, 327.283, 0.7201118)
decoder loss ratio: 51257.705083, decoder SINDy loss  ratio: 0.706486
--- 0.29785871505737305 seconds for one epoch ---
--- 2.112987756729126 seconds for one epoch ---
--- 0.3045203685760498 seconds for one epoch ---
--- 2.116835355758667 seconds for one epoch ---
--- 0.30118632316589355 seconds for one epoch ---
--- 2.1465141773223877 seconds for one epoch ---
--- 0.29746389389038086 seconds for one epoch ---
--- 2.0692708492279053 seconds for one epoch ---
--- 0.29821062088012695 seconds for one epoch ---
--- 2.083324432373047 seconds for one epoch ---
--- 0.29998278617858887 seconds for one epoch ---
--- 2.0697078704833984 seconds for one epoch ---
--- 0.30170369148254395 seconds for one epoch ---
--- 2.072115898132324 seconds for one epoch ---
--- 0.29645752906799316 seconds for one epoch ---
--- 2.076080799102783 seconds for one epoch ---
--- 0.3011448383331299 seconds for one epoch ---
--- 2.131939649581909 seconds for one epoch ---
--- 0.3125886917114258 seconds for one epoch ---
--- 2.145608901977539 seconds for one epoch ---
--- 0.32701945304870605 seconds for one epoch ---
--- 2.1117727756500244 seconds for one epoch ---
--- 0.35187458992004395 seconds for one epoch ---
--- 2.1307504177093506 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991165]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7086798]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2337806]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.2333784]
 [ 0.       ]]
--- 0.30229973793029785 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2861.859375, (1792.9402, 0.907373, 1067.2917, 0.7202083)
   validation loss 866.63525390625, (525.6233, 0.3054882, 339.9863, 0.7202083)
decoder loss ratio: 20363.558816, decoder SINDy loss  ratio: 0.733908
--- 0.9957892894744873 seconds for one epoch ---
--- 0.29885387420654297 seconds for one epoch ---
--- 2.1817760467529297 seconds for one epoch ---
--- 0.30242085456848145 seconds for one epoch ---
--- 2.109260320663452 seconds for one epoch ---
--- 0.2993948459625244 seconds for one epoch ---
--- 2.0749807357788086 seconds for one epoch ---
--- 0.3009672164916992 seconds for one epoch ---
--- 2.0819637775421143 seconds for one epoch ---
--- 0.30558300018310547 seconds for one epoch ---
--- 2.1148743629455566 seconds for one epoch ---
--- 0.3126382827758789 seconds for one epoch ---
--- 2.0639309883117676 seconds for one epoch ---
--- 0.2951507568359375 seconds for one epoch ---
--- 2.1408183574676514 seconds for one epoch ---
--- 0.295259952545166 seconds for one epoch ---
--- 2.128319501876831 seconds for one epoch ---
--- 0.30278611183166504 seconds for one epoch ---
--- 2.148730516433716 seconds for one epoch ---
--- 0.2999289035797119 seconds for one epoch ---
--- 2.132955312728882 seconds for one epoch ---
--- 0.29317164421081543 seconds for one epoch ---
--- 2.15216326713562 seconds for one epoch ---
--- 0.29120802879333496 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991919]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7131896]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2392739]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.2552476]
 [ 0.       ]]
--- 0.2633378505706787 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4180.51708984375, (1694.1675, 0.35384482, 2485.2756, 0.7204069)
   validation loss 876.8570556640625, (586.77014, 0.27888486, 289.08765, 0.7204069)
decoder loss ratio: 22732.493963, decoder SINDy loss  ratio: 0.624036
--- 0.2995645999908447 seconds for one epoch ---
--- 2.164618730545044 seconds for one epoch ---
--- 0.3161430358886719 seconds for one epoch ---
--- 2.2071120738983154 seconds for one epoch ---
--- 0.3060793876647949 seconds for one epoch ---
--- 2.141723871231079 seconds for one epoch ---
--- 0.3009021282196045 seconds for one epoch ---
--- 2.1324989795684814 seconds for one epoch ---
--- 0.2957017421722412 seconds for one epoch ---
--- 2.133042812347412 seconds for one epoch ---
--- 0.30240392684936523 seconds for one epoch ---
--- 2.1469779014587402 seconds for one epoch ---
--- 0.3055553436279297 seconds for one epoch ---
--- 2.146852493286133 seconds for one epoch ---
--- 0.3053905963897705 seconds for one epoch ---
--- 2.1760427951812744 seconds for one epoch ---
--- 0.3087730407714844 seconds for one epoch ---
--- 2.1843857765197754 seconds for one epoch ---
--- 0.30957984924316406 seconds for one epoch ---
--- 2.145561695098877 seconds for one epoch ---
--- 0.30823206901550293 seconds for one epoch ---
--- 2.1774120330810547 seconds for one epoch ---
--- 0.30387330055236816 seconds for one epoch ---
--- 2.162769079208374 seconds for one epoch ---
=========================
[[0.       ]
 [0.9991038]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.70800656]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.2387474 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-6.2724466 ]
 [-0.        ]]
--- 0.29622602462768555 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4219.12451171875, (1041.9486, 0.91863453, 3175.5366, 0.720571)
   validation loss 839.8450927734375, (546.78204, 0.26779878, 292.07462, 0.720571)
decoder loss ratio: 21183.285619, decoder SINDy loss  ratio: 0.630484
--- 0.2679252624511719 seconds for one epoch ---
--- 0.29998779296875 seconds for one epoch ---
--- 2.16325306892395 seconds for one epoch ---
--- 0.296065092086792 seconds for one epoch ---
--- 2.137511968612671 seconds for one epoch ---
--- 0.29813456535339355 seconds for one epoch ---
--- 2.110518455505371 seconds for one epoch ---
--- 0.29984068870544434 seconds for one epoch ---
--- 2.115739107131958 seconds for one epoch ---
--- 0.2999272346496582 seconds for one epoch ---
--- 2.1221377849578857 seconds for one epoch ---
--- 0.30449724197387695 seconds for one epoch ---
--- 2.112100601196289 seconds for one epoch ---
--- 0.3064277172088623 seconds for one epoch ---
--- 2.1320126056671143 seconds for one epoch ---
--- 0.30309605598449707 seconds for one epoch ---
--- 2.167858839035034 seconds for one epoch ---
--- 0.3059549331665039 seconds for one epoch ---
--- 2.1340408325195312 seconds for one epoch ---
--- 0.3025023937225342 seconds for one epoch ---
--- 2.1501681804656982 seconds for one epoch ---
--- 0.3022758960723877 seconds for one epoch ---
--- 2.207023859024048 seconds for one epoch ---
--- 0.3022582530975342 seconds for one epoch ---
=========================
[[0.       ]
 [0.9992198]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.7149339]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2457651]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.292358 ]
 [ 0.       ]]
--- 0.2650752067565918 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3134.568359375, (1072.6226, 2.17318, 2059.0518, 0.7207495)
   validation loss 837.4375610351562, (534.41797, 0.26550838, 302.03336, 0.7207495)
decoder loss ratio: 20704.279900, decoder SINDy loss  ratio: 0.651981
--- 0.31108832359313965 seconds for one epoch ---
--- 2.189415693283081 seconds for one epoch ---
--- 0.30286550521850586 seconds for one epoch ---
--- 2.225153684616089 seconds for one epoch ---
--- 0.3078775405883789 seconds for one epoch ---
--- 2.143949270248413 seconds for one epoch ---
--- 0.3071112632751465 seconds for one epoch ---
--- 2.1577064990997314 seconds for one epoch ---
--- 0.3014051914215088 seconds for one epoch ---
--- 2.1278254985809326 seconds for one epoch ---
--- 0.2988593578338623 seconds for one epoch ---
--- 2.1300535202026367 seconds for one epoch ---
--- 0.3002352714538574 seconds for one epoch ---
--- 2.1567752361297607 seconds for one epoch ---
--- 0.3002760410308838 seconds for one epoch ---
--- 2.1767475605010986 seconds for one epoch ---
--- 0.3370790481567383 seconds for one epoch ---
--- 2.194575548171997 seconds for one epoch ---
--- 0.3166992664337158 seconds for one epoch ---
--- 2.182525396347046 seconds for one epoch ---
--- 0.3191249370574951 seconds for one epoch ---
--- 2.2360689640045166 seconds for one epoch ---
--- 0.32420778274536133 seconds for one epoch ---
--- 2.2181334495544434 seconds for one epoch ---
=========================
[[0.       ]
 [0.9993874]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.72711  ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2410297]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.3058105]
 [-0.       ]]
--- 0.2986421585083008 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2177.792724609375, (769.85736, 1.3558677, 1405.8586, 0.72089416)
   validation loss 873.5601196289062, (577.93945, 0.25030056, 294.64948, 0.72089416)
decoder loss ratio: 22390.377761, decoder SINDy loss  ratio: 0.636042
THRESHOLDING: 3 active coefficients
REFINEMENT
=========================
[[0.        ]
 [0.99937606]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.7261814]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2407138]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.306464 ]
 [-0.       ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1219.47900390625, (628.0452, 0.35744575, 591.0764, 0.7209057)
   validation loss 837.4166259765625, (558.61505, 0.16796659, 278.63364, 0.7209057)
decoder loss ratio: 21641.716885, decoder SINDy loss  ratio: 0.601470
=========================
[[0.      ]
 [0.999892]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-0.       ]
 [-0.8139605]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.336401 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.292677 ]
 [ 0.       ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1031.04736328125, (462.29898, 0.63694656, 568.1115, 0.7212409)
   validation loss 620.202880859375, (352.22174, 0.10794929, 267.8732, 0.7212409)
decoder loss ratio: 13645.681719, decoder SINDy loss  ratio: 0.578242
=========================
[[0.      ]
 [0.999789]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-0.        ]
 [-0.77244556]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1483299 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.297123  ]
 [-0.        ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 893.068359375, (346.12704, 0.427964, 546.51337, 0.7207173)
   validation loss 540.087158203125, (282.74048, 0.11768936, 257.22903, 0.7207173)
decoder loss ratio: 10953.856997, decoder SINDy loss  ratio: 0.555265
=========================
[[0.       ]
 [0.9992132]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.70277476]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.2318347 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.24768   ]
 [-0.        ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.0298461914062, (320.4753, 0.3655089, 545.189, 0.7200426)
   validation loss 513.5676879882812, (255.8637, 0.11614664, 257.58786, 0.7200426)
decoder loss ratio: 9912.603675, decoder SINDy loss  ratio: 0.556040
=========================
[[0.       ]
 [0.9972285]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.66110975]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.249121  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.0855384 ]
 [-0.        ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 870.0126953125, (327.17908, 0.30975533, 542.52386, 0.7193877)
   validation loss 526.4073486328125, (269.12308, 0.11339958, 257.1709, 0.7193877)
decoder loss ratio: 10426.295236, decoder SINDy loss  ratio: 0.555140
=========================
[[0.       ]
 [0.9946518]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6045628]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2255374]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.1452284]
 [ 0.       ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.4111328125, (324.22128, 0.29124862, 541.8986, 0.71873325)
   validation loss 507.9012451171875, (249.86565, 0.11281219, 257.9228, 0.71873325)
decoder loss ratio: 9680.228926, decoder SINDy loss  ratio: 0.556763
=========================
[[0.        ]
 [0.99135906]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6421868]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1873814]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.051612 ]
 [ 0.       ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 889.8718872070312, (351.23682, 0.2746554, 538.3604, 0.7180854)
   validation loss 542.87451171875, (286.49335, 0.107858285, 256.27335, 0.7180854)
decoder loss ratio: 11099.249644, decoder SINDy loss  ratio: 0.553202
=========================
[[0.        ]
 [0.98866475]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.49928176]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1371607 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.02361   ]
 [-0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.546875, (310.70233, 0.27194527, 538.5726, 0.7174658)
   validation loss 495.5741271972656, (238.61063, 0.107079364, 256.8564, 0.7174658)
decoder loss ratio: 9244.189906, decoder SINDy loss  ratio: 0.554461
=========================
[[0.       ]
 [0.9812777]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.48423722]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1215914 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-5.9533267 ]
 [-0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1282.97021484375, (733.1861, 0.24163134, 549.54254, 0.716684)
   validation loss 919.3043212890625, (656.33655, 0.10342769, 262.86435, 0.716684)
decoder loss ratio: 25427.617314, decoder SINDy loss  ratio: 0.567430
=========================
[[0.       ]
 [0.9796263]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5851125]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1572492]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.8725905]
 [-0.       ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.2994384765625, (328.78668, 0.25984278, 537.2529, 0.71615)
   validation loss 506.40869140625, (250.07114, 0.10734926, 256.23022, 0.71615)
decoder loss ratio: 9688.189970, decoder SINDy loss  ratio: 0.553109
=========================
[[0.       ]
 [0.9776182]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.57248837]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.230309  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.924798  ]
 [-0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 897.039306640625, (360.29465, 0.24323678, 536.5014, 0.7157871)
   validation loss 557.5053100585938, (300.9272, 0.10258523, 256.47552, 0.7157871)
decoder loss ratio: 11658.441582, decoder SINDy loss  ratio: 0.553638
=========================
[[0.        ]
 [0.97905934]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6252848]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1586692]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.7662783]
 [-0.       ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 923.1419677734375, (388.74188, 0.24295473, 534.15717, 0.71541786)
   validation loss 579.30712890625, (323.3876, 0.103533715, 255.81595, 0.71541786)
decoder loss ratio: 12528.597195, decoder SINDy loss  ratio: 0.552215
=========================
[[0.        ]
 [0.97914976]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.5258467]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1801302]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.790323 ]
 [-0.       ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1074.76416015625, (538.908, 0.24554437, 535.61066, 0.7150787)
   validation loss 735.6234741210938, (477.65555, 0.105181284, 257.86273, 0.7150787)
decoder loss ratio: 18505.205180, decoder SINDy loss  ratio: 0.556633
=========================
[[0.        ]
 [0.98087823]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.48856345]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1177521 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.712324  ]
 [ 0.        ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 985.4954833984375, (451.1235, 0.24781679, 534.1242, 0.7148041)
   validation loss 641.4594116210938, (384.85635, 0.10114721, 256.50192, 0.7148041)
decoder loss ratio: 14910.003285, decoder SINDy loss  ratio: 0.553695
=========================
[[0.       ]
 [0.9817216]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5245572]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1930739]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.674427 ]
 [-0.       ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1104.6103515625, (569.33795, 0.25161594, 535.0209, 0.71459734)
   validation loss 770.092041015625, (512.82715, 0.102333374, 257.1625, 0.71459734)
decoder loss ratio: 19867.814038, decoder SINDy loss  ratio: 0.555121
=========================
[[0.       ]
 [0.9853217]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5617562]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0909722]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.6132693]
 [ 0.       ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 895.7235717773438, (366.2706, 0.26375893, 529.1892, 0.7143895)
   validation loss 544.138671875, (290.61758, 0.10116294, 253.41995, 0.7143895)
decoder loss ratio: 11259.029747, decoder SINDy loss  ratio: 0.547043
=========================
[[0.       ]
 [0.987254 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.56617105]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.1511995 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-5.593953  ]
 [-0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 905.3716430664062, (366.12823, 0.27031124, 538.9731, 0.71420854)
   validation loss 569.7075805664062, (309.00757, 0.09440407, 260.60562, 0.71420854)
decoder loss ratio: 11971.489659, decoder SINDy loss  ratio: 0.562554
=========================
[[0.       ]
 [0.9890999]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.62137806]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1689957 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-5.5488396 ]
 [ 0.        ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 986.6353759765625, (457.04956, 0.2694459, 529.3164, 0.71394956)
   validation loss 629.1826171875, (377.18832, 0.09557221, 251.89874, 0.71394956)
decoder loss ratio: 14612.930499, decoder SINDy loss  ratio: 0.543759
=========================
[[0.       ]
 [0.9854853]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.56406826]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1883396 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.5734653 ]
 [-0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 988.334228515625, (461.659, 0.26805305, 526.40717, 0.71351695)
   validation loss 640.9428100585938, (388.33856, 0.09953656, 252.5047, 0.71351695)
decoder loss ratio: 15044.910078, decoder SINDy loss  ratio: 0.545067
=========================
[[0.        ]
 [0.98840195]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.59869826]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.1881577 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-5.529741  ]
 [ 0.        ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.615234375, (306.23633, 0.2733309, 532.1055, 0.7134222)
   validation loss 480.02667236328125, (224.78734, 0.095378384, 255.14395, 0.7134222)
decoder loss ratio: 8708.651732, decoder SINDy loss  ratio: 0.550764
=========================
[[0.       ]
 [0.9880613]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5600625]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1684453]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.483569 ]
 [-0.       ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1014.8118286132812, (484.20496, 0.25922492, 530.34766, 0.71322775)
   validation loss 661.0055541992188, (408.9142, 0.09383034, 251.99748, 0.71322775)
decoder loss ratio: 15842.046599, decoder SINDy loss  ratio: 0.543972
=========================
[[0.       ]
 [0.9853849]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.581205 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1574113]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.4135203]
 [-0.       ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 828.84228515625, (299.4184, 0.25344482, 529.1705, 0.71297306)
   validation loss 487.913330078125, (233.86223, 0.09388949, 253.95721, 0.71297306)
decoder loss ratio: 9060.228731, decoder SINDy loss  ratio: 0.548202
=========================
[[0.        ]
 [0.98697805]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.62035197]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1211158 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.446077  ]
 [ 0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 842.376220703125, (310.75912, 0.26924053, 531.3479, 0.7129195)
   validation loss 505.38897705078125, (250.17726, 0.0929845, 255.11874, 0.7129195)
decoder loss ratio: 9692.301432, decoder SINDy loss  ratio: 0.550710
=========================
[[0.       ]
 [0.9880349]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6231224]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1126436]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.4163694]
 [-0.       ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 829.25439453125, (299.53253, 0.27897716, 529.4429, 0.7128317)
   validation loss 483.5325622558594, (230.84793, 0.09317265, 252.59146, 0.7128317)
decoder loss ratio: 8943.449613, decoder SINDy loss  ratio: 0.545254
=========================
[[0.       ]
 [0.9882773]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5568183]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1743741]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.4017057]
 [-0.       ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.66162109375, (303.82837, 0.2552882, 526.578, 0.7127277)
   validation loss 499.0710754394531, (245.9683, 0.09151196, 253.01126, 0.7127277)
decoder loss ratio: 9529.239252, decoder SINDy loss  ratio: 0.546160
=========================
[[0.       ]
 [0.99304  ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.601649 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1697695]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.4075937]
 [-0.       ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1217.490966796875, (655.05316, 0.2889457, 562.14886, 0.7127453)
   validation loss 865.2015380859375, (588.0899, 0.0895816, 277.022, 0.7127453)
decoder loss ratio: 22783.623880, decoder SINDy loss  ratio: 0.597991
=========================
[[0.        ]
 [0.99382794]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.55145735]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.1693523 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-5.3627357 ]
 [ 0.        ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 858.33837890625, (336.35974, 0.27557838, 521.70306, 0.7126404)
   validation loss 507.3148193359375, (259.5289, 0.09065629, 247.69524, 0.7126404)
decoder loss ratio: 10054.600154, decoder SINDy loss  ratio: 0.534685
=========================
[[0.       ]
 [0.9937446]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.56079686]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1597701 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.346437  ]
 [ 0.        ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1003.480712890625, (459.39838, 0.30208576, 543.7802, 0.712557)
   validation loss 669.2749633789062, (404.0748, 0.08848106, 265.1117, 0.712557)
decoder loss ratio: 15654.559202, decoder SINDy loss  ratio: 0.572281
=========================
[[0.       ]
 [0.9943923]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5180824]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1544161]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.394822 ]
 [-0.       ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1187.755126953125, (659.35645, 0.2840021, 528.11475, 0.71250695)
   validation loss 781.3276977539062, (534.2957, 0.09022421, 246.94176, 0.71250695)
decoder loss ratio: 20699.543590, decoder SINDy loss  ratio: 0.533059
=========================
[[0.       ]
 [0.9928625]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5851694]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1506977]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.3089223]
 [ 0.       ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.6058349609375, (330.0504, 0.27389172, 519.28156, 0.71243423)
   validation loss 493.3458251953125, (247.49402, 0.09119104, 245.76062, 0.71243423)
decoder loss ratio: 9588.347947, decoder SINDy loss  ratio: 0.530509
=========================
[[0.       ]
 [0.9905391]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5793608]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1680012]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.4106097]
 [-0.       ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1337.012451171875, (801.13525, 0.236499, 535.6407, 0.71237624)
   validation loss 931.3417358398438, (676.7913, 0.09392313, 254.45647, 0.71237624)
decoder loss ratio: 26220.070729, decoder SINDy loss  ratio: 0.549280
=========================
[[0.        ]
 [0.99180865]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.63382244]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.095181  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-5.339812  ]
 [ 0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 894.27783203125, (360.17636, 0.26331973, 533.8382, 0.7124256)
   validation loss 512.3377685546875, (257.0799, 0.094230294, 255.1636, 0.7124256)
decoder loss ratio: 9959.721443, decoder SINDy loss  ratio: 0.550807
=========================
[[0.       ]
 [0.9927426]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.61040956]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0865424 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.3840194 ]
 [ 0.        ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 807.0860595703125, (286.11722, 0.26527256, 520.7036, 0.712495)
   validation loss 472.40045166015625, (223.67706, 0.093660824, 248.62973, 0.712495)
decoder loss ratio: 8665.637741, decoder SINDy loss  ratio: 0.536702
=========================
[[0.        ]
 [0.99248683]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.61955374]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.1410736 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.345014  ]
 [ 0.        ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1671.999267578125, (1087.644, 0.28986788, 584.06537, 0.71255344)
   validation loss 1340.350341796875, (1044.072, 0.09134512, 296.18698, 0.71255344)
decoder loss ratio: 40449.162701, decoder SINDy loss  ratio: 0.639361
=========================
[[0.        ]
 [0.99329096]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.61614543]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1323136 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.3613224 ]
 [-0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2375.47216796875, (1810.2262, 0.24380116, 565.0021, 0.71265656)
   validation loss 1897.796875, (1625.2008, 0.09645989, 272.49957, 0.71265656)
decoder loss ratio: 62963.100684, decoder SINDy loss  ratio: 0.588229
=========================
[[0.       ]
 [0.9921799]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.57018614]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.1539218 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-5.4148917 ]
 [-0.        ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.7266845703125, (316.48804, 0.251811, 524.9869, 0.7127465)
   validation loss 486.9134216308594, (235.23012, 0.09550222, 251.5878, 0.7127465)
decoder loss ratio: 9113.223141, decoder SINDy loss  ratio: 0.543088
=========================
[[0.        ]
 [0.99223816]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6267084]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.143921 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.4733915]
 [-0.       ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.3560791015625, (318.66425, 0.24735951, 514.4445, 0.71288174)
   validation loss 491.7474060058594, (246.19235, 0.09719918, 245.45786, 0.71288174)
decoder loss ratio: 9537.919137, decoder SINDy loss  ratio: 0.529855
=========================
[[0.        ]
 [0.99261874]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.5520642]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1525029]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.3761015]
 [-0.       ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.6682739257812, (303.4255, 0.2414298, 518.00134, 0.7130139)
   validation loss 469.1451416015625, (221.1455, 0.09795922, 247.9017, 0.7130139)
decoder loss ratio: 8567.560307, decoder SINDy loss  ratio: 0.535131
=========================
[[0.       ]
 [0.9932363]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5737402]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0941969]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.4371   ]
 [ 0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 887.46142578125, (373.8094, 0.24538961, 513.4067, 0.71321076)
   validation loss 545.9805297851562, (301.5317, 0.09792038, 244.35089, 0.71321076)
decoder loss ratio: 11681.861841, decoder SINDy loss  ratio: 0.527466
=========================
[[0.       ]
 [0.9948476]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5803935]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0863523]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.431271 ]
 [-0.       ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.9658203125, (300.08142, 0.27019194, 518.6142, 0.7133731)
   validation loss 490.4491271972656, (240.89078, 0.09408978, 249.46426, 0.7133731)
decoder loss ratio: 9332.526929, decoder SINDy loss  ratio: 0.538504
=========================
[[0.       ]
 [0.9948317]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.642017 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1291535]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.458479 ]
 [-0.       ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.43310546875, (297.9118, 0.27717903, 516.2441, 0.7135764)
   validation loss 469.4278564453125, (224.10524, 0.09505035, 245.22757, 0.7135764)
decoder loss ratio: 8682.226056, decoder SINDy loss  ratio: 0.529358
=========================
[[0.       ]
 [0.9949632]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5945656]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0342885]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.492907 ]
 [-0.       ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.13720703125, (330.35986, 0.2473382, 521.53, 0.71371603)
   validation loss 501.9862060546875, (251.9827, 0.09878317, 249.90472, 0.71371603)
decoder loss ratio: 9762.247125, decoder SINDy loss  ratio: 0.539454
=========================
[[0.        ]
 [0.99539584]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6536082]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1512439]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-5.503639 ]
 [ 0.       ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.159423828125, (286.68927, 0.261983, 512.2081, 0.71390384)
   validation loss 462.96124267578125, (218.01361, 0.09863763, 244.84898, 0.71390384)
decoder loss ratio: 8446.225772, decoder SINDy loss  ratio: 0.528541
=========================
[[0.       ]
 [0.9951222]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6153483]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0817147]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.523522 ]
 [ 0.       ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.0137329101562, (297.67178, 0.24941379, 516.0925, 0.7140806)
   validation loss 474.5333251953125, (226.55913, 0.10050823, 247.8737, 0.7140806)
decoder loss ratio: 8777.293935, decoder SINDy loss  ratio: 0.535070
=========================
[[0.       ]
 [0.9952031]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.637929 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1044824]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.5934453]
 [-0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.843994140625, (286.71646, 0.2504771, 511.877, 0.71428716)
   validation loss 465.02935791015625, (219.30554, 0.10167545, 245.62216, 0.71428716)
decoder loss ratio: 8496.277428, decoder SINDy loss  ratio: 0.530210
=========================
[[0.       ]
 [0.9945246]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6823778]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1512893]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.6460876]
 [-0.       ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1109.022705078125, (562.9246, 0.25313336, 545.845, 0.71447974)
   validation loss 748.068603515625, (480.29037, 0.10152853, 267.6767, 0.71447974)
decoder loss ratio: 18607.282939, decoder SINDy loss  ratio: 0.577818
=========================
[[0.        ]
 [0.99432254]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6529222]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0418394]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.6027646]
 [ 0.       ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 802.377685546875, (289.86002, 0.2351381, 512.28253, 0.71471226)
   validation loss 472.93798828125, (225.4605, 0.1053759, 247.3721, 0.71471226)
decoder loss ratio: 8734.730993, decoder SINDy loss  ratio: 0.533987
=========================
[[0.       ]
 [0.9944823]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6184653]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2103136]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.6487584]
 [ 0.       ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 916.4493408203125, (390.37634, 0.237081, 525.8359, 0.7149461)
   validation loss 570.488037109375, (314.5127, 0.10542173, 255.86992, 0.7149461)
decoder loss ratio: 12184.767834, decoder SINDy loss  ratio: 0.552331
=========================
[[0.        ]
 [0.99533474]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.63057613]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1457493 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.7475014 ]
 [ 0.        ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1002.3490600585938, (497.25378, 0.23718224, 504.8581, 0.7151966)
   validation loss 659.14111328125, (416.8257, 0.10784421, 242.20752, 0.7151966)
decoder loss ratio: 16148.551806, decoder SINDy loss  ratio: 0.522839
=========================
[[0.       ]
 [0.9964886]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.68516815]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0787643 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.700289  ]
 [ 0.        ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 811.816162109375, (300.08484, 0.25484395, 511.47647, 0.7154009)
   validation loss 474.76824951171875, (227.977, 0.10546642, 246.68576, 0.7154009)
decoder loss ratio: 8832.224959, decoder SINDy loss  ratio: 0.532506
=========================
[[0.       ]
 [0.9957167]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6534643]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1001791]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.6832314]
 [ 0.       ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1019.7728271484375, (484.0581, 0.2543594, 535.4604, 0.7156057)
   validation loss 673.9111328125, (410.62582, 0.10684453, 263.1785, 0.7156057)
decoder loss ratio: 15908.357299, decoder SINDy loss  ratio: 0.568108
=========================
[[0.       ]
 [0.9960598]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6068031]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1000847]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.710942 ]
 [-0.       ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 959.219970703125, (459.55267, 0.2324342, 499.43484, 0.7158124)
   validation loss 612.89892578125, (372.45135, 0.10955549, 240.33798, 0.7158124)
decoder loss ratio: 14429.412096, decoder SINDy loss  ratio: 0.518803
=========================
[[0.       ]
 [0.9957519]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.65239567]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.1334189 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.778516  ]
 [ 0.        ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 914.1007080078125, (413.9345, 0.22669326, 499.93954, 0.71601826)
   validation loss 576.1124267578125, (335.71222, 0.11177343, 240.28842, 0.71601826)
decoder loss ratio: 13006.074195, decoder SINDy loss  ratio: 0.518696
=========================
[[0.       ]
 [0.9963217]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.63687176]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.056458  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.844635  ]
 [ 0.        ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 789.210205078125, (286.64334, 0.23784192, 502.329, 0.71623975)
   validation loss 456.6441650390625, (214.58366, 0.10882645, 241.95166, 0.71623975)
decoder loss ratio: 8313.343675, decoder SINDy loss  ratio: 0.522287
=========================
[[0.        ]
 [0.99514115]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.63771355]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.066476  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.8197846 ]
 [ 0.        ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 860.6534423828125, (361.41183, 0.2087036, 499.03287, 0.7164663)
   validation loss 525.4989624023438, (285.14838, 0.11305145, 240.23756, 0.7164663)
decoder loss ratio: 11047.143144, decoder SINDy loss  ratio: 0.518587
=========================
[[0.       ]
 [0.9957939]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6285633]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.095805 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.928051 ]
 [ 0.       ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 859.4749755859375, (362.041, 0.23023237, 497.20377, 0.71672636)
   validation loss 523.1430053710938, (284.26575, 0.11069202, 238.76657, 0.71672636)
decoder loss ratio: 11012.948549, decoder SINDy loss  ratio: 0.515411
=========================
[[0.        ]
 [0.9958198 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.7038214]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1120309]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.9072976]
 [ 0.       ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 901.9176025390625, (404.3096, 0.21413706, 497.3939, 0.7169504)
   validation loss 565.6972045898438, (325.8134, 0.116416425, 239.76738, 0.7169504)
decoder loss ratio: 12622.576172, decoder SINDy loss  ratio: 0.517572
=========================
[[0.        ]
 [0.99666667]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.5993179]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0677102]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.7698956]
 [-0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 789.7098999023438, (290.56406, 0.24031813, 498.90552, 0.7171524)
   validation loss 459.76251220703125, (219.07922, 0.10905893, 240.57425, 0.7171524)
decoder loss ratio: 8487.509462, decoder SINDy loss  ratio: 0.519313
=========================
[[0.        ]
 [0.9963894 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.70216566]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0832285 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-5.9287257 ]
 [-0.        ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.644775390625, (292.46432, 0.23501432, 504.94547, 0.71737564)
   validation loss 471.34234619140625, (226.20792, 0.114875816, 245.01955, 0.71737564)
decoder loss ratio: 8763.687390, decoder SINDy loss  ratio: 0.528909
=========================
[[0.        ]
 [0.9966863 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6778539]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0956036]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.920186 ]
 [ 0.       ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 840.8271484375, (346.27634, 0.22386388, 494.32693, 0.7175493)
   validation loss 499.92193603515625, (262.2985, 0.11633527, 237.50711, 0.7175493)
decoder loss ratio: 10161.898967, decoder SINDy loss  ratio: 0.512693
=========================
[[0.        ]
 [0.9959307 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6618456]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1233045]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.9812803]
 [ 0.       ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1012.7003784179688, (516.9137, 0.20377155, 495.5829, 0.7177577)
   validation loss 661.4739379882812, (422.1988, 0.122763425, 239.15239, 0.7177577)
decoder loss ratio: 16356.714152, decoder SINDy loss  ratio: 0.516244
=========================
[[0.        ]
 [0.9959791 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6411657]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0862831]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.1162524]
 [ 0.       ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 834.68701171875, (328.11295, 0.20225093, 506.37186, 0.7179427)
   validation loss 496.12005615234375, (250.11841, 0.120744966, 245.88089, 0.7179427)
decoder loss ratio: 9690.021358, decoder SINDy loss  ratio: 0.530768
=========================
[[0.        ]
 [0.9959808 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.60634065]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0189073 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.0641894 ]
 [-0.        ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.434326171875, (328.46097, 0.21210563, 493.7613, 0.7181252)
   validation loss 493.49481201171875, (255.26584, 0.12145989, 238.10753, 0.7181252)
decoder loss ratio: 9889.441749, decoder SINDy loss  ratio: 0.513989
=========================
[[0.        ]
 [0.9966998 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6757388]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.110006 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.1001873]
 [ 0.       ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 802.3956909179688, (308.16205, 0.22217265, 494.01147, 0.71831536)
   validation loss 464.03289794921875, (226.4981, 0.12029791, 237.4145, 0.71831536)
decoder loss ratio: 8774.929327, decoder SINDy loss  ratio: 0.512493
=========================
[[0.        ]
 [0.99538547]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6023368]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0458498]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.115132 ]
 [-0.       ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.9166259765625, (357.22076, 0.19917504, 492.49664, 0.71849316)
   validation loss 520.5444946289062, (282.4949, 0.12603037, 237.92354, 0.71849316)
decoder loss ratio: 10944.342997, decoder SINDy loss  ratio: 0.513591
=========================
[[0.        ]
 [0.99610543]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.66160107]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.1457652 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.1045403 ]
 [-0.        ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 941.21826171875, (424.99048, 0.19248624, 516.0353, 0.7186443)
   validation loss 584.639892578125, (333.93436, 0.12502903, 250.58047, 0.7186443)
decoder loss ratio: 12937.196714, decoder SINDy loss  ratio: 0.540913
=========================
[[0.        ]
 [0.9958259 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.63152665]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1332122 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.114675  ]
 [-0.        ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 981.294189453125, (489.71146, 0.19977024, 491.38297, 0.7188285)
   validation loss 643.8656005859375, (406.67575, 0.12787375, 237.06201, 0.7188285)
decoder loss ratio: 15755.324604, decoder SINDy loss  ratio: 0.511732
=========================
[[0.        ]
 [0.9961464 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6609121]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0922672]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.228509 ]
 [-0.       ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 893.9312744140625, (381.21326, 0.20641564, 512.5116, 0.71897614)
   validation loss 552.2601318359375, (301.64944, 0.123407446, 250.48729, 0.71897614)
decoder loss ratio: 11686.423169, decoder SINDy loss  ratio: 0.540712
=========================
[[0.        ]
 [0.99609166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.67617166]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0961753 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.200626  ]
 [ 0.        ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 780.0245361328125, (283.09186, 0.2091508, 496.7235, 0.7191841)
   validation loss 455.656494140625, (214.86124, 0.12700708, 240.66823, 0.7191841)
decoder loss ratio: 8324.097320, decoder SINDy loss  ratio: 0.519516
=========================
[[0.        ]
 [0.9966601 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6552005]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.002636 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.152908 ]
 [-0.       ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.7188720703125, (284.39706, 0.20859511, 494.11322, 0.71933883)
   validation loss 448.9827575683594, (210.21144, 0.12521441, 238.6461, 0.71933883)
decoder loss ratio: 8143.956169, decoder SINDy loss  ratio: 0.515151
=========================
[[0.        ]
 [0.9960955 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6930849]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.106651 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.205828 ]
 [ 0.       ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1086.341796875, (560.64435, 0.22708555, 525.4704, 0.7195162)
   validation loss 771.263427734375, (508.62265, 0.12318555, 262.51755, 0.7195162)
decoder loss ratio: 19704.924474, decoder SINDy loss  ratio: 0.566681
=========================
[[0.        ]
 [0.99665236]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6112858]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0526657]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.1912303]
 [-0.       ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.8050537109375, (300.9861, 0.22416428, 492.5948, 0.71968955)
   validation loss 459.59820556640625, (223.87018, 0.12165691, 235.60635, 0.71968955)
decoder loss ratio: 8673.119360, decoder SINDy loss  ratio: 0.508589
=========================
[[0.       ]
 [0.9951837]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.64039475]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.1368297 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.2239475 ]
 [-0.        ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.6597900390625, (344.92618, 0.1807468, 490.5529, 0.71981144)
   validation loss 506.3114929199219, (269.63956, 0.132786, 236.53915, 0.71981144)
decoder loss ratio: 10446.304549, decoder SINDy loss  ratio: 0.510603
=========================
[[0.       ]
 [0.9961885]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6595901]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0801119]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.2613325]
 [ 0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1137.847412109375, (602.57837, 0.20072262, 535.0683, 0.7199857)
   validation loss 767.4932861328125, (502.88367, 0.129772, 264.47983, 0.7199857)
decoder loss ratio: 19482.586304, decoder SINDy loss  ratio: 0.570917
=========================
[[0.        ]
 [0.99663484]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6309205]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0636175]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.253837 ]
 [-0.       ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.0564575195312, (337.40573, 0.22876953, 501.42197, 0.7201186)
   validation loss 510.3524169921875, (267.40186, 0.12251099, 242.82808, 0.7201186)
decoder loss ratio: 10359.612111, decoder SINDy loss  ratio: 0.524179
=========================
[[0.        ]
 [0.99589646]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6564399]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0814946]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.2524257]
 [-0.       ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.2069702148438, (452.57922, 0.18130383, 489.44644, 0.7202595)
   validation loss 595.7359008789062, (360.10458, 0.13621737, 235.4951, 0.7202595)
decoder loss ratio: 13951.076743, decoder SINDy loss  ratio: 0.508349
=========================
[[0.        ]
 [0.99612147]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6077001]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.111852 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.3556895]
 [ 0.       ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 831.1395263671875, (328.9731, 0.18780322, 501.9786, 0.7203867)
   validation loss 495.1462707519531, (250.7849, 0.13475905, 244.22661, 0.7203867)
decoder loss ratio: 9715.842286, decoder SINDy loss  ratio: 0.527197
=========================
[[0.       ]
 [0.9955238]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6147343]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0826117]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.384311 ]
 [-0.       ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 848.0078125, (360.3914, 0.18872695, 487.42773, 0.7205511)
   validation loss 518.785888671875, (283.15002, 0.13826716, 235.49757, 0.7205511)
decoder loss ratio: 10969.723516, decoder SINDy loss  ratio: 0.508355
=========================
[[0.       ]
 [0.995593 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5561227]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0487425]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.3384743]
 [ 0.       ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1127.6669921875, (597.05676, 0.18531197, 530.4249, 0.7206797)
   validation loss 772.138671875, (510.11652, 0.13596152, 261.88623, 0.7206797)
decoder loss ratio: 19762.799435, decoder SINDy loss  ratio: 0.565318
=========================
[[0.       ]
 [0.9964013]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.632346 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1317191]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.348473 ]
 [ 0.       ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 811.952392578125, (316.5243, 0.22824806, 495.19983, 0.7208239)
   validation loss 494.63348388671875, (255.12114, 0.12699829, 239.38535, 0.7208239)
decoder loss ratio: 9883.835855, decoder SINDy loss  ratio: 0.516747
=========================
[[0.        ]
 [0.99647486]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6419892]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0032743]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.4482303]
 [-0.       ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.2696533203125, (283.34866, 0.1991818, 491.72183, 0.7209392)
   validation loss 446.99395751953125, (209.47722, 0.1343523, 237.38237, 0.7209392)
decoder loss ratio: 8115.511118, decoder SINDy loss  ratio: 0.512423
=========================
[[0.       ]
 [0.995632 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5990619]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0478531]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.3682942]
 [ 0.       ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.84814453125, (282.20667, 0.20447443, 492.437, 0.7210687)
   validation loss 458.8955993652344, (220.22995, 0.13288659, 238.53276, 0.7210687)
decoder loss ratio: 8532.090597, decoder SINDy loss  ratio: 0.514907
=========================
[[0.       ]
 [0.9961863]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5746512]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0743139]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.4166994]
 [-0.       ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.496826171875, (300.5911, 0.18247244, 487.7233, 0.72118664)
   validation loss 450.87493896484375, (215.2296, 0.14069982, 235.50464, 0.72118664)
decoder loss ratio: 8338.368320, decoder SINDy loss  ratio: 0.508370
=========================
[[0.       ]
 [0.9954539]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.58639866]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.1008447 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.435012  ]
 [-0.        ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.3060302734375, (353.13583, 0.18703261, 485.9832, 0.7213451)
   validation loss 512.066650390625, (277.0992, 0.14150971, 234.82593, 0.7213451)
decoder loss ratio: 10735.304563, decoder SINDy loss  ratio: 0.506905
=========================
[[0.       ]
 [0.9964533]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6432687]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0338013]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.448037 ]
 [-0.       ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 967.7445068359375, (456.06482, 0.20818155, 511.47147, 0.72146446)
   validation loss 648.2667846679688, (395.20322, 0.13128802, 252.9323, 0.72146446)
decoder loss ratio: 15310.858712, decoder SINDy loss  ratio: 0.545990
=========================
[[0.       ]
 [0.995873 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.60607105]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.0201684 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.428753  ]
 [ 0.        ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.310302734375, (312.85638, 0.2324831, 491.2214, 0.72162)
   validation loss 493.9415283203125, (256.35965, 0.13231744, 237.44957, 0.72162)
decoder loss ratio: 9931.817888, decoder SINDy loss  ratio: 0.512568
=========================
[[0.       ]
 [0.9953426]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6235122]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0530314]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.4028535]
 [ 0.       ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 972.765625, (460.49304, 0.164223, 512.1084, 0.7217348)
   validation loss 628.863525390625, (379.08557, 0.1477801, 249.6302, 0.7217348)
decoder loss ratio: 14686.433153, decoder SINDy loss  ratio: 0.538862
=========================
[[0.       ]
 [0.9959291]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.59895957]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.1012812 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.4078927 ]
 [ 0.        ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 805.5027465820312, (319.6298, 0.2018782, 485.67108, 0.72189325)
   validation loss 478.3455810546875, (243.98322, 0.14005417, 234.22229, 0.72189325)
decoder loss ratio: 9452.333335, decoder SINDy loss  ratio: 0.505602
=========================
[[0.        ]
 [0.99535996]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.55217874]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.98330986]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.509648  ]
 [ 0.        ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 771.3222045898438, (282.8722, 0.1823422, 488.26767, 0.7220156)
   validation loss 445.90484619140625, (208.90248, 0.14327478, 236.8591, 0.7220156)
decoder loss ratio: 8093.244788, decoder SINDy loss  ratio: 0.511294
=========================
[[0.        ]
 [0.99526435]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.65605825]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0255854 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.448215  ]
 [ 0.        ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.7821044921875, (313.85736, 0.1879102, 486.73688, 0.72215885)
   validation loss 476.2451477050781, (239.96663, 0.14623013, 236.1323, 0.72215885)
decoder loss ratio: 9296.723809, decoder SINDy loss  ratio: 0.509725
=========================
[[0.        ]
 [0.9962722 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.62776566]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0900614 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.5157447 ]
 [ 0.        ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.617919921875, (305.17892, 0.19494204, 485.24408, 0.72227067)
   validation loss 453.33367919921875, (218.28586, 0.14230505, 234.90552, 0.72227067)
decoder loss ratio: 8456.773106, decoder SINDy loss  ratio: 0.507077
=========================
[[0.       ]
 [0.9946317]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6472601]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1249212]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.530178 ]
 [ 0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1483.2041015625, (937.2291, 0.21934213, 545.7556, 0.72243154)
   validation loss 1159.583251953125, (881.78375, 0.14047869, 277.65903, 0.72243154)
decoder loss ratio: 34161.833413, decoder SINDy loss  ratio: 0.599366
=========================
[[0.        ]
 [0.99587286]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.64003396]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0631851 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.503019  ]
 [ 0.        ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 801.4736328125, (316.6973, 0.18460217, 484.59174, 0.7225712)
   validation loss 463.6531982421875, (227.94667, 0.14896533, 235.55757, 0.7225712)
decoder loss ratio: 8831.049749, decoder SINDy loss  ratio: 0.508484
=========================
[[0.        ]
 [0.995873  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.6455324 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.96800274]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.5372176 ]
 [-0.        ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 845.5520629882812, (347.34085, 0.21139558, 497.99982, 0.72270864)
   validation loss 541.625732421875, (296.45755, 0.13685441, 245.03137, 0.72270864)
decoder loss ratio: 11485.280162, decoder SINDy loss  ratio: 0.528935
=========================
[[0.       ]
 [0.9948188]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.71373665]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.1261876 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.496573  ]
 [-0.        ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.6993408203125, (292.46463, 0.18599959, 491.04868, 0.72288436)
   validation loss 461.7503967285156, (222.1351, 0.1435247, 239.47177, 0.72288436)
decoder loss ratio: 8605.899469, decoder SINDy loss  ratio: 0.516934
=========================
[[0.        ]
 [0.99576026]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6692531]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.048048 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.5883   ]
 [ 0.       ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 927.81591796875, (445.18198, 0.20059633, 482.43335, 0.7230191)
   validation loss 598.1790771484375, (363.79355, 0.14843178, 234.23709, 0.7230191)
decoder loss ratio: 14093.993646, decoder SINDy loss  ratio: 0.505634
=========================
[[0.        ]
 [0.9953663 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.5767224]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0043168]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.6443214]
 [ 0.       ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1594.267333984375, (1042.6469, 0.21947314, 551.401, 0.7231372)
   validation loss 1271.072998046875, (988.4286, 0.13832425, 282.50604, 0.7231372)
decoder loss ratio: 38293.439520, decoder SINDy loss  ratio: 0.609829
=========================
[[0.        ]
 [0.99622333]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.62961316]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0870737 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-6.514002  ]
 [ 0.        ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 792.750244140625, (308.22635, 0.20808083, 484.31583, 0.7232441)
   validation loss 462.4538269042969, (228.05467, 0.14554238, 234.25362, 0.7232441)
decoder loss ratio: 8835.233923, decoder SINDy loss  ratio: 0.505669
=========================
[[0.        ]
 [0.9953283 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.65874624]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0631788 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.613161  ]
 [ 0.        ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.6573486328125, (315.4375, 0.16619436, 483.05365, 0.7233481)
   validation loss 465.65142822265625, (230.49792, 0.15591723, 234.99757, 0.7233481)
decoder loss ratio: 8929.889769, decoder SINDy loss  ratio: 0.507275
=========================
[[0.        ]
 [0.9957638 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.7135545]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0792012]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.6087294]
 [ 0.       ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.5338134765625, (303.63904, 0.22432068, 484.67047, 0.7235059)
   validation loss 463.2734375, (230.5035, 0.13812885, 232.63184, 0.7235059)
decoder loss ratio: 8930.105539, decoder SINDy loss  ratio: 0.502169
=========================
[[0.        ]
 [0.994769  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6143762]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.134981 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.5788045]
 [-0.       ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 792.5405883789062, (300.88876, 0.18624987, 491.46558, 0.72361237)
   validation loss 473.307861328125, (232.99347, 0.14634447, 240.16805, 0.72361237)
decoder loss ratio: 9026.571493, decoder SINDy loss  ratio: 0.518437
=========================
[[0.        ]
 [0.9956068 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.60655224]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.039861  ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.709866  ]
 [-0.        ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 913.9658203125, (432.00113, 0.2121919, 481.75247, 0.72375435)
   validation loss 578.0874633789062, (345.78458, 0.14268383, 232.16023, 0.72375435)
decoder loss ratio: 13396.294799, decoder SINDy loss  ratio: 0.501151
=========================
[[0.        ]
 [0.9953182 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6014386]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1426089]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.6735086]
 [-0.       ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.4921875, (302.65375, 0.18434009, 490.65408, 0.72382754)
   validation loss 461.60015869140625, (221.89363, 0.15321308, 239.55333, 0.72382754)
decoder loss ratio: 8596.544489, decoder SINDy loss  ratio: 0.517110
=========================
[[0.       ]
 [0.9952749]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999877]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.63934857]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0476242 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.7044024 ]
 [-0.        ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.1409912109375, (332.15665, 0.20840226, 497.7759, 0.7239249)
   validation loss 516.8067626953125, (271.7542, 0.14511944, 244.90742, 0.7239249)
decoder loss ratio: 10528.229937, decoder SINDy loss  ratio: 0.528667
=========================
[[0.        ]
 [0.99541426]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.63228863]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.9995621 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.712535  ]
 [-0.        ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.1199951171875, (306.57663, 0.22617917, 486.31723, 0.7240283)
   validation loss 472.25701904296875, (238.14783, 0.14141847, 233.96777, 0.7240283)
decoder loss ratio: 9226.260267, decoder SINDy loss  ratio: 0.505052
=========================
[[0.       ]
 [0.9948623]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999877]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5731865]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0150247]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.691501 ]
 [ 0.       ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.6385498046875, (395.37448, 0.19991833, 482.06412, 0.7241226)
   validation loss 544.48291015625, (310.56723, 0.15078808, 233.76486, 0.7241226)
decoder loss ratio: 12031.913667, decoder SINDy loss  ratio: 0.504614
=========================
[[0.        ]
 [0.99512184]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.5840677]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0036163]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.7314816]
 [ 0.       ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1019.543701171875, (505.875, 0.20531303, 513.4634, 0.72421134)
   validation loss 696.0652465820312, (440.40036, 0.14577696, 255.5191, 0.72421134)
decoder loss ratio: 17061.874519, decoder SINDy loss  ratio: 0.551574
=========================
[[0.        ]
 [0.99437284]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.5409305]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1113745]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.7557635]
 [-0.       ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 970.2332763671875, (461.0084, 0.20781459, 509.01703, 0.72431546)
   validation loss 662.2484741210938, (408.46213, 0.14884433, 253.6375, 0.72431546)
decoder loss ratio: 15824.531948, decoder SINDy loss  ratio: 0.547512
=========================
[[0.        ]
 [0.99524415]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6023561]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0638188]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.7629266]
 [-0.       ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.8939208984375, (314.2665, 0.21359667, 482.41385, 0.72444457)
   validation loss 466.78436279296875, (234.0852, 0.14497566, 232.55417, 0.72444457)
decoder loss ratio: 9068.867235, decoder SINDy loss  ratio: 0.502001
=========================
[[0.        ]
 [0.99444556]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.62927717]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.98670703]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.661049  ]
 [-0.        ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.520263671875, (303.48163, 0.20545831, 492.83322, 0.7245392)
   validation loss 485.8887939453125, (243.1111, 0.1524478, 242.62523, 0.7245392)
decoder loss ratio: 9418.546044, decoder SINDy loss  ratio: 0.523741
=========================
[[0.        ]
 [0.99520016]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6048554]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0530659]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.768431 ]
 [ 0.       ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.3155517578125, (281.7024, 0.20720863, 485.4059, 0.7246792)
   validation loss 444.7083740234375, (207.34, 0.15479277, 237.2136, 0.7246792)
decoder loss ratio: 8032.711416, decoder SINDy loss  ratio: 0.512059
=========================
[[0.        ]
 [0.99481213]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6080212]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1534003]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.7961946]
 [-0.       ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.483642578125, (293.12756, 0.2063352, 484.14978, 0.72477263)
   validation loss 458.5643005371094, (221.68213, 0.15511616, 236.72705, 0.72477263)
decoder loss ratio: 8588.350531, decoder SINDy loss  ratio: 0.511009
=========================
[[0.       ]
 [0.9945637]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999877]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.58950174]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0769776 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.758962  ]
 [ 0.        ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.8194580078125, (322.9794, 0.19467495, 480.6454, 0.7248747)
   validation loss 475.53289794921875, (240.89632, 0.15667143, 234.4799, 0.7248747)
decoder loss ratio: 9332.741517, decoder SINDy loss  ratio: 0.506158
=========================
[[0.        ]
 [0.99462247]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6309238]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0117116]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.7841964]
 [ 0.       ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1182.16357421875, (697.6242, 0.19863367, 484.34076, 0.7249999)
   validation loss 823.918212890625, (584.8086, 0.16647907, 238.9431, 0.7249999)
decoder loss ratio: 22656.500194, decoder SINDy loss  ratio: 0.515792
=========================
[[0.        ]
 [0.99476844]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.61542684]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.0257019 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-6.7361937 ]
 [-0.        ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.486328125, (332.90518, 0.20763381, 494.37354, 0.7250781)
   validation loss 506.47222900390625, (262.41437, 0.15382104, 243.90407, 0.7250781)
decoder loss ratio: 10166.388175, decoder SINDy loss  ratio: 0.526501
=========================
[[0.        ]
 [0.99452794]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.56152916]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0644377 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-6.792461  ]
 [ 0.        ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 812.3065185546875, (331.3488, 0.20746122, 480.7503, 0.72519535)
   validation loss 488.066162109375, (251.89691, 0.16250618, 236.00676, 0.72519535)
decoder loss ratio: 9758.923668, decoder SINDy loss  ratio: 0.509454
=========================
[[0.       ]
 [0.9939991]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999877]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6245853]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0535295]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.8114033]
 [ 0.       ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.08740234375, (304.59174, 0.19348682, 491.30222, 0.725308)
   validation loss 472.5581359863281, (229.77692, 0.16042201, 242.6208, 0.725308)
decoder loss ratio: 8901.956656, decoder SINDy loss  ratio: 0.523731
=========================
[[0.       ]
 [0.9948578]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999877]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.61668426]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0264128 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.8149467 ]
 [ 0.        ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.2901611328125, (315.07083, 0.2396573, 487.9797, 0.7254204)
   validation loss 490.41021728515625, (252.41727, 0.15082245, 237.84213, 0.7254204)
decoder loss ratio: 9779.083133, decoder SINDy loss  ratio: 0.513416
=========================
[[0.       ]
 [0.9945395]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999869]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.67864007]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0367658 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.873672  ]
 [ 0.        ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.70654296875, (292.45596, 0.19264545, 485.0579, 0.7255007)
   validation loss 457.9759521484375, (218.98769, 0.16514872, 238.82314, 0.7255007)
decoder loss ratio: 8483.963141, decoder SINDy loss  ratio: 0.515533
=========================
[[0.        ]
 [0.99466616]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999869 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6972697]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1122006]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.7634435]
 [-0.       ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1208.4317626953125, (687.66266, 0.24403483, 520.5251, 0.72559845)
   validation loss 923.5654296875, (658.4272, 0.1491575, 264.98904, 0.72559845)
decoder loss ratio: 25508.612229, decoder SINDy loss  ratio: 0.572016
=========================
[[0.       ]
 [0.9948598]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999869]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6680694]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1055903]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.9849043]
 [ 0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.1064453125, (322.6856, 0.22578871, 480.19507, 0.72571653)
   validation loss 474.09552001953125, (240.36313, 0.15343949, 233.57895, 0.72571653)
decoder loss ratio: 9312.084893, decoder SINDy loss  ratio: 0.504213
=========================
[[0.       ]
 [0.9936025]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999869]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6026486]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0488034]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.8615265]
 [-0.       ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.4345703125, (289.57587, 0.20996797, 483.64877, 0.7258014)
   validation loss 457.944580078125, (219.22241, 0.16235177, 238.55981, 0.7258014)
decoder loss ratio: 8493.056832, decoder SINDy loss  ratio: 0.514965
=========================
[[0.        ]
 [0.99454683]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999862 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6965279]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.042714 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.8090086]
 [-0.       ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1393.4017333984375, (862.4624, 0.24230424, 530.697, 0.72589034)
   validation loss 1102.7681884765625, (830.42255, 0.14903122, 272.19656, 0.72589034)
decoder loss ratio: 32172.011124, decoder SINDy loss  ratio: 0.587575
=========================
[[0.        ]
 [0.99453837]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999869 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.64401734]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.1562188 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.958706  ]
 [-0.        ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1067.82861328125, (586.82916, 0.22127861, 480.77826, 0.7260248)
   validation loss 722.447265625, (486.2929, 0.16224475, 235.99214, 0.7260248)
decoder loss ratio: 18839.831486, decoder SINDy loss  ratio: 0.509422
=========================
[[0.       ]
 [0.9942601]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6285047]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0341263]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.92265  ]
 [-0.       ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 863.2387084960938, (365.4325, 0.21207611, 497.59415, 0.72609437)
   validation loss 541.5213623046875, (293.45312, 0.16231681, 247.90591, 0.72609437)
decoder loss ratio: 11368.883520, decoder SINDy loss  ratio: 0.535140
=========================
[[0.        ]
 [0.99435997]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999862 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6321814]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9962015]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.907445 ]
 [-0.       ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 956.61572265625, (455.06393, 0.2627009, 501.2891, 0.72618705)
   validation loss 670.2945556640625, (419.35522, 0.15342674, 250.78593, 0.72618705)
decoder loss ratio: 16246.549434, decoder SINDy loss  ratio: 0.541357
=========================
[[0.       ]
 [0.9940827]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6437105]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0105959]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.886095 ]
 [-0.       ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.074462890625, (291.17245, 0.20426597, 484.69772, 0.72627825)
   validation loss 457.75494384765625, (217.69667, 0.16843748, 239.88982, 0.72627825)
decoder loss ratio: 8433.946954, decoder SINDy loss  ratio: 0.517836
=========================
[[0.       ]
 [0.9941052]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.60952616]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.082197  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-6.989902  ]
 [ 0.        ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.4819946289062, (333.6772, 0.21920046, 479.5856, 0.7263864)
   validation loss 492.3099365234375, (255.42146, 0.1656968, 236.72276, 0.7263864)
decoder loss ratio: 9895.470908, decoder SINDy loss  ratio: 0.510999
=========================
[[0.        ]
 [0.99451077]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999869 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6344614]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0159762]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.962737 ]
 [-0.       ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 811.8755493164062, (332.78873, 0.23015533, 478.85666, 0.7264964)
   validation loss 483.43048095703125, (248.62085, 0.15919434, 234.65042, 0.7264964)
decoder loss ratio: 9632.003339, decoder SINDy loss  ratio: 0.506526
=========================
[[0.       ]
 [0.9944558]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.5928956]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0827019]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-6.907261 ]
 [ 0.       ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.774169921875, (295.572, 0.23030563, 480.97186, 0.72656596)
   validation loss 458.77386474609375, (221.12703, 0.16612023, 237.4807, 0.72656596)
decoder loss ratio: 8566.845013, decoder SINDy loss  ratio: 0.512635
=========================
[[0.       ]
 [0.9938269]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.63585436]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0588717 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.9550633 ]
 [-0.        ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 881.10791015625, (382.47723, 0.21670844, 498.41397, 0.72666544)
   validation loss 565.72900390625, (315.81223, 0.16359982, 249.75316, 0.72666544)
decoder loss ratio: 12235.113884, decoder SINDy loss  ratio: 0.539127
=========================
[[0.       ]
 [0.9933595]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.        ]
 [-0.66106075]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0776818 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-7.022977  ]
 [ 0.        ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.43505859375, (300.05972, 0.2196935, 481.15564, 0.72676694)
   validation loss 464.5735778808594, (226.32939, 0.16854456, 238.07564, 0.72676694)
decoder loss ratio: 8768.393551, decoder SINDy loss  ratio: 0.513920
=========================
[[0.       ]
 [0.993955 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999869]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6269654]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0177512]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.975654 ]
 [-0.       ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.1153564453125, (348.1403, 0.2260481, 478.74902, 0.7268874)
   validation loss 500.49432373046875, (263.59045, 0.16583286, 236.73804, 0.7268874)
decoder loss ratio: 10211.951805, decoder SINDy loss  ratio: 0.511032
=========================
[[0.       ]
 [0.9937328]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999862]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.5907001]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0535209]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.9900527]
 [ 0.       ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 888.1318359375, (409.3518, 0.214253, 478.56577, 0.7269999)
   validation loss 563.91162109375, (325.85178, 0.16816652, 237.8917, 0.7269999)
decoder loss ratio: 12624.063511, decoder SINDy loss  ratio: 0.513523
=========================
[[0.        ]
 [0.994269  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.61637634]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0860933 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-6.9751587 ]
 [-0.        ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.79638671875, (425.9463, 0.20380928, 476.6463, 0.72708434)
   validation loss 565.5440673828125, (327.2673, 0.17769003, 238.09904, 0.72708434)
decoder loss ratio: 12678.903497, decoder SINDy loss  ratio: 0.513970
=========================
[[0.        ]
 [0.993732  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.5876131]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0807339]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.016594 ]
 [ 0.       ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.1893310546875, (384.68396, 0.21842411, 477.28696, 0.7271795)
   validation loss 542.8499755859375, (304.12766, 0.17410615, 238.5482, 0.7271795)
decoder loss ratio: 11782.433345, decoder SINDy loss  ratio: 0.514940
=========================
[[0.        ]
 [0.99361277]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.5687439]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0899336]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.0094104]
 [-0.       ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.8670654296875, (287.10498, 0.20879129, 480.5533, 0.72729844)
   validation loss 450.60357666015625, (209.28261, 0.17645523, 241.14452, 0.72729844)
decoder loss ratio: 8107.971566, decoder SINDy loss  ratio: 0.520544
=========================
[[0.       ]
 [0.9949807]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6141885]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0880839]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.9849315]
 [-0.       ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.3028564453125, (301.053, 0.23614094, 480.01373, 0.72741026)
   validation loss 465.3468933105469, (225.27872, 0.16912872, 239.89905, 0.72741026)
decoder loss ratio: 8727.688599, decoder SINDy loss  ratio: 0.517856
=========================
[[0.        ]
 [0.99471605]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999851 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.643848 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0910935]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.0644255]
 [-0.       ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.80859375, (336.4042, 0.22868608, 477.17566, 0.727496)
   validation loss 491.30059814453125, (251.80057, 0.17558585, 239.32446, 0.727496)
decoder loss ratio: 9755.191135, decoder SINDy loss  ratio: 0.516616
=========================
[[0.        ]
 [0.99367094]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999851 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.59769017]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.148048  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-7.0614448 ]
 [ 0.        ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.5333251953125, (301.4599, 0.22774932, 481.84567, 0.7276002)
   validation loss 468.62933349609375, (225.60957, 0.17429702, 242.84544, 0.7276002)
decoder loss ratio: 8740.506548, decoder SINDy loss  ratio: 0.524216
=========================
[[0.       ]
 [0.994652 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6146446]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0510477]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-7.044828 ]
 [-0.       ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.9793701171875, (290.51398, 0.22852634, 483.23685, 0.72771615)
   validation loss 455.68682861328125, (212.40526, 0.17063291, 243.11093, 0.72771615)
decoder loss ratio: 8228.948454, decoder SINDy loss  ratio: 0.524789
=========================
[[0.       ]
 [0.9944016]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.       ]
 [-0.6584369]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0246025]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.1137137]
 [ 0.       ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.0819702148438, (295.40402, 0.24215524, 483.4358, 0.7278256)
   validation loss 481.3907470703125, (239.55914, 0.16408959, 241.66751, 0.7278256)
decoder loss ratio: 9280.937095, decoder SINDy loss  ratio: 0.521673
=========================
[[0.       ]
 [0.9940742]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6392528]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0494614]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.0920043]
 [-0.       ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.6621704101562, (290.54892, 0.24216892, 484.8711, 0.7279312)
   validation loss 465.12310791015625, (221.25864, 0.17066208, 243.69382, 0.7279312)
decoder loss ratio: 8571.943699, decoder SINDy loss  ratio: 0.526047
=========================
[[0.        ]
 [0.9943191 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6238866]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0097207]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.116038 ]
 [ 0.       ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 883.435791015625, (406.00452, 0.25067738, 477.1806, 0.7280783)
   validation loss 558.0232543945312, (319.83417, 0.17181174, 238.01729, 0.7280783)
decoder loss ratio: 12390.930905, decoder SINDy loss  ratio: 0.513794
=========================
[[0.        ]
 [0.99380267]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6320497]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.005322 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.0679736]
 [ 0.       ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.106201171875, (288.4742, 0.24492192, 481.38702, 0.7281429)
   validation loss 449.27020263671875, (205.86412, 0.1776203, 243.22844, 0.7281429)
decoder loss ratio: 7975.533423, decoder SINDy loss  ratio: 0.525043
=========================
[[0.        ]
 [0.9933706 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.56493384]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0586696 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-7.149133  ]
 [ 0.        ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1119.030517578125, (638.9915, 0.24235292, 479.7966, 0.72827286)
   validation loss 777.0017700195312, (533.9265, 0.18163127, 242.8936, 0.72827286)
decoder loss ratio: 20685.240077, decoder SINDy loss  ratio: 0.524320
=========================
[[0.        ]
 [0.99376047]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.6024021 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.99207884]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-7.1866717 ]
 [ 0.        ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.8121948242188, (285.31708, 0.24794906, 482.24716, 0.72833484)
   validation loss 450.4770812988281, (207.01825, 0.17402145, 243.2848, 0.72833484)
decoder loss ratio: 8020.246386, decoder SINDy loss  ratio: 0.525164
=========================
[[0.       ]
 [0.9929295]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6076816]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0454226]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.1212225]
 [ 0.       ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 826.930419921875, (349.54065, 0.2481475, 477.14166, 0.72846216)
   validation loss 511.2628173828125, (269.99615, 0.17902294, 241.08766, 0.72846216)
decoder loss ratio: 10460.119770, decoder SINDy loss  ratio: 0.520422
=========================
[[0.        ]
 [0.9935353 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.62545717]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0096208 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-7.0961494 ]
 [-0.        ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.4644165039062, (327.9253, 0.23417929, 476.30493, 0.72856253)
   validation loss 483.6419677734375, (241.5585, 0.18571545, 241.89777, 0.72856253)
decoder loss ratio: 9358.395739, decoder SINDy loss  ratio: 0.522170
=========================
[[0.        ]
 [0.9937247 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.68487024]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.9840205 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-7.1475697 ]
 [-0.        ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.6026611328125, (284.32245, 0.26068458, 481.01956, 0.72866625)
   validation loss 457.867919921875, (215.55376, 0.17270295, 242.14148, 0.72866625)
decoder loss ratio: 8350.926753, decoder SINDy loss  ratio: 0.522696
=========================
[[0.       ]
 [0.9940603]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999844]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.61575323]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.0529568 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-7.11413   ]
 [ 0.        ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.356201171875, (357.99698, 0.24426182, 493.115, 0.72875774)
   validation loss 535.8723754882812, (283.00494, 0.17883477, 252.6886, 0.72875774)
decoder loss ratio: 10964.102843, decoder SINDy loss  ratio: 0.545464
=========================
[[0.        ]
 [0.9940325 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.        ]
 [-0.67375416]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.0244544 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-7.2168746 ]
 [ 0.        ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1026.984130859375, (549.87317, 0.2506277, 476.86032, 0.72886586)
   validation loss 691.5430908203125, (448.8671, 0.18439491, 242.49161, 0.72886586)
decoder loss ratio: 17389.890565, decoder SINDy loss  ratio: 0.523452
=========================
[[0.        ]
 [0.99362123]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999846 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[ 0.       ]
 [-0.6014753]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9897448]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.1344647]
 [ 0.       ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.4451904296875, (290.96405, 0.26335093, 479.21777, 0.72895145)
   validation loss 461.20648193359375, (218.84592, 0.1751574, 242.18542, 0.72895145)
decoder loss ratio: 8478.470748, decoder SINDy loss  ratio: 0.522791
=========================
[[0.        ]
 [0.99376374]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999846 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.       ]
 [-0.6051051]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0320545]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.138229 ]
 [-0.       ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 791.61962890625, (307.69385, 0.279054, 483.6467, 0.7290652)
   validation loss 490.9228515625, (248.64503, 0.16918693, 242.10861, 0.7290652)
decoder loss ratio: 9632.940315, decoder SINDy loss  ratio: 0.522625
=========================
[[0.       ]
 [0.9927483]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6324307]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0352296]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-7.2056103]
 [-0.       ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.2412109375, (320.40225, 0.2547254, 476.58426, 0.7291433)
   validation loss 484.3451232910156, (242.02823, 0.1795124, 242.13737, 0.7291433)
decoder loss ratio: 9376.593762, decoder SINDy loss  ratio: 0.522688
=========================
[[0.        ]
 [0.99339074]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999844 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.55117196]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.0709004 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-7.2436776 ]
 [ 0.        ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.632080078125, (356.60965, 0.25980437, 476.76263, 0.7292688)
   validation loss 517.6976318359375, (275.51196, 0.1782741, 242.0074, 0.7292688)
decoder loss ratio: 10673.811752, decoder SINDy loss  ratio: 0.522407
=========================
[[0.       ]
 [0.9934216]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.608604 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0199758]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.2776184]
 [-0.       ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.9197998046875, (281.92996, 0.26615468, 480.72372, 0.72936225)
   validation loss 454.2886047363281, (209.12065, 0.18066551, 244.98729, 0.72936225)
decoder loss ratio: 8101.697079, decoder SINDy loss  ratio: 0.528840
=========================
[[0.       ]
 [0.9928911]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.999984 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.56896937]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0680536 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-7.251558  ]
 [-0.        ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.5187377929688, (288.61682, 0.26506743, 479.63684, 0.72943103)
   validation loss 456.55908203125, (210.96071, 0.1812977, 245.41705, 0.72943103)
decoder loss ratio: 8172.984096, decoder SINDy loss  ratio: 0.529767
=========================
[[0.        ]
 [0.99315995]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999844 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-0.        ]
 [-0.55945534]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0764264 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.1768923 ]
 [ 0.        ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 771.3494262695312, (291.5911, 0.27108806, 479.48724, 0.72955334)
   validation loss 464.8543701171875, (221.21774, 0.1767525, 243.45988, 0.72955334)
decoder loss ratio: 8570.359412, decoder SINDy loss  ratio: 0.525542
=========================
[[0.       ]
 [0.9935575]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999839]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-0.       ]
 [-0.6755203]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0210059]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.26708  ]
 [-0.       ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1393.148193359375, (863.9714, 0.2896349, 528.88715, 0.72963923)
   validation loss 1098.270751953125, (820.24567, 0.1691207, 277.85602, 0.72963923)
decoder loss ratio: 31777.741129, decoder SINDy loss  ratio: 0.599791
=========================
[[0.       ]
 [0.9927654]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999844]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[ 0.        ]
 [-0.62281984]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.0020694 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-7.148162  ]
 [ 0.        ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.819580078125, (307.6662, 0.27050766, 476.88284, 0.7297411)
   validation loss 473.7313537597656, (229.7604, 0.18268396, 243.78827, 0.7297411)
decoder loss ratio: 8901.317029, decoder SINDy loss  ratio: 0.526251
params['save_name']
pendulum_2023_10_29_04_57_49_288015
