nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-24 20:57:54.283266: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-24 20:57:54.290515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-24 20:57:54.292498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556e673b5490 executing computations on platform Host. Devices:
2023-10-24 20:57:54.292527: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-24 20:57:54.294393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-24 20:57:54.393289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556e673f4090 executing computations on platform CUDA. Devices:
2023-10-24 20:57:54.393353: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-24 20:57:54.394006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-24 20:57:54.394265: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-24 20:57:54.395882: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-24 20:57:54.397323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-24 20:57:54.397596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-24 20:57:54.399178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-24 20:57:54.399992: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-24 20:57:54.403214: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-24 20:57:54.403817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-24 20:57:54.403858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-24 20:57:54.404190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-24 20:57:54.404199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-24 20:57:54.404205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-24 20:57:54.404768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-24 20:57:55.496873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.2, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.83506178855896 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 101742.125, (94227.04, 0.053132873, 7496.9824, 2.5317798)
   validation loss 83060.390625, (81841.58, 0.021772576, 1200.743, 2.5317798)
decoder loss ratio: 3170684.819790, decoder SINDy loss  ratio: 2.591973
--- 0.2648766040802002 seconds for one epoch ---
--- 0.31708741188049316 seconds for one epoch ---
--- 0.33240532875061035 seconds for one epoch ---
--- 0.3253021240234375 seconds for one epoch ---
--- 0.3419830799102783 seconds for one epoch ---
--- 0.33532142639160156 seconds for one epoch ---
--- 0.3344120979309082 seconds for one epoch ---
--- 0.31671810150146484 seconds for one epoch ---
--- 0.3295023441314697 seconds for one epoch ---
--- 0.3241598606109619 seconds for one epoch ---
--- 0.3494076728820801 seconds for one epoch ---
--- 0.3227088451385498 seconds for one epoch ---
--- 0.323702335357666 seconds for one epoch ---
--- 0.3296635150909424 seconds for one epoch ---
--- 0.34771013259887695 seconds for one epoch ---
--- 0.32112574577331543 seconds for one epoch ---
--- 0.33688783645629883 seconds for one epoch ---
--- 0.333528995513916 seconds for one epoch ---
--- 0.3413074016571045 seconds for one epoch ---
--- 0.33513593673706055 seconds for one epoch ---
--- 0.3395102024078369 seconds for one epoch ---
--- 0.327847957611084 seconds for one epoch ---
--- 0.33225417137145996 seconds for one epoch ---
--- 0.3166694641113281 seconds for one epoch ---
=========================
[[0.77358043]
 [0.7868119 ]
 [0.87856424]
 [0.7939569 ]
 [0.7722579 ]
 [0.8538692 ]
 [0.8155407 ]
 [0.7720634 ]
 [0.77200276]
 [0.98374873]
 [0.7815574 ]]
[[ 0.23403622]
 [ 0.6273121 ]
 [-1.1296073 ]
 [-0.7101492 ]
 [ 0.0648625 ]
 [-1.0394971 ]
 [ 0.8668974 ]
 [-0.02171808]
 [ 0.00613042]
 [-1.6746011 ]
 [ 0.5396311 ]]
--- 0.26049280166625977 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 83896.5859375, (79185.53, 13.925163, 4661.7817, 2.5317612)
   validation loss 51626.31640625, (50370.895, 9.252651, 1210.8173, 2.5317612)
decoder loss ratio: 1951455.901859, decoder SINDy loss  ratio: 2.613719
--- 0.32474637031555176 seconds for one epoch ---
--- 0.33900880813598633 seconds for one epoch ---
--- 0.31622314453125 seconds for one epoch ---
--- 0.34058666229248047 seconds for one epoch ---
--- 0.32045984268188477 seconds for one epoch ---
--- 0.3627510070800781 seconds for one epoch ---
--- 0.32083749771118164 seconds for one epoch ---
--- 0.339993953704834 seconds for one epoch ---
--- 0.31383490562438965 seconds for one epoch ---
--- 0.3417072296142578 seconds for one epoch ---
--- 0.3088414669036865 seconds for one epoch ---
--- 0.33183836936950684 seconds for one epoch ---
--- 0.3137810230255127 seconds for one epoch ---
--- 0.3451671600341797 seconds for one epoch ---
--- 0.32305169105529785 seconds for one epoch ---
--- 0.36408305168151855 seconds for one epoch ---
--- 0.3269541263580322 seconds for one epoch ---
--- 0.3408646583557129 seconds for one epoch ---
--- 0.3156168460845947 seconds for one epoch ---
--- 0.35109543800354004 seconds for one epoch ---
--- 0.31243324279785156 seconds for one epoch ---
--- 0.35337090492248535 seconds for one epoch ---
--- 0.33011889457702637 seconds for one epoch ---
--- 0.34061622619628906 seconds for one epoch ---
=========================
[[0.6421817 ]
 [0.61755186]
 [0.9127547 ]
 [0.64559746]
 [0.6101365 ]
 [0.9675364 ]
 [0.6432873 ]
 [0.6120006 ]
 [0.609907  ]
 [0.634156  ]
 [0.62434155]]
[[ 6.7754805e-01]
 [ 3.9775622e-01]
 [-1.4068767e+00]
 [-6.9898695e-01]
 [ 3.5136685e-02]
 [-1.6405734e+00]
 [ 6.8469644e-01]
 [ 1.9891348e-01]
 [ 1.4135086e-03]
 [-6.1808813e-01]
 [ 5.1515728e-01]]
--- 0.3043501377105713 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 43569.08203125, (35862.664, 15.319134, 7637.4717, 2.53176)
   validation loss 41201.15625, (39991.562, 5.6128063, 1150.356, 2.53176)
decoder loss ratio: 1549342.559656, decoder SINDy loss  ratio: 2.483205
--- 0.2764863967895508 seconds for one epoch ---
--- 0.3245394229888916 seconds for one epoch ---
--- 0.36496829986572266 seconds for one epoch ---
--- 0.33504462242126465 seconds for one epoch ---
--- 0.34458303451538086 seconds for one epoch ---
--- 0.3231692314147949 seconds for one epoch ---
--- 0.34662580490112305 seconds for one epoch ---
--- 0.3195340633392334 seconds for one epoch ---
--- 0.35091161727905273 seconds for one epoch ---
--- 0.3302438259124756 seconds for one epoch ---
--- 0.35201263427734375 seconds for one epoch ---
--- 0.32198429107666016 seconds for one epoch ---
--- 0.35257959365844727 seconds for one epoch ---
--- 0.31499290466308594 seconds for one epoch ---
--- 0.3454773426055908 seconds for one epoch ---
--- 0.4218025207519531 seconds for one epoch ---
--- 0.3403627872467041 seconds for one epoch ---
--- 0.3284621238708496 seconds for one epoch ---
--- 0.35254335403442383 seconds for one epoch ---
--- 0.327664852142334 seconds for one epoch ---
--- 0.3543698787689209 seconds for one epoch ---
--- 0.3289377689361572 seconds for one epoch ---
--- 0.35721755027770996 seconds for one epoch ---
--- 0.3363986015319824 seconds for one epoch ---
=========================
[[0.52226806]
 [0.47544605]
 [0.92836225]
 [0.510319  ]
 [0.4748244 ]
 [0.9960832 ]
 [0.49211594]
 [0.4779467 ]
 [0.47416815]
 [0.47650728]
 [0.49163398]]
[[ 0.6990225 ]
 [ 0.11574721]
 [-1.5287116 ]
 [-0.6389024 ]
 [ 0.06883608]
 [-2.1467664 ]
 [ 0.49988762]
 [ 0.23847592]
 [ 0.00367018]
 [-0.17700139]
 [ 0.4947096 ]]
--- 0.26149535179138184 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 34993.0625, (29250.72, 85.84595, 5585.879, 2.5317717)
   validation loss 16792.61328125, (15654.696, 0.7534838, 1066.5466, 2.5317717)
decoder loss ratio: 606490.111986, decoder SINDy loss  ratio: 2.302291
--- 0.31513500213623047 seconds for one epoch ---
--- 0.3576364517211914 seconds for one epoch ---
--- 0.32892394065856934 seconds for one epoch ---
--- 0.3467414379119873 seconds for one epoch ---
--- 0.3263437747955322 seconds for one epoch ---
--- 0.35499095916748047 seconds for one epoch ---
--- 0.31824731826782227 seconds for one epoch ---
--- 0.35814642906188965 seconds for one epoch ---
--- 0.3205437660217285 seconds for one epoch ---
--- 0.35668516159057617 seconds for one epoch ---
--- 0.32511067390441895 seconds for one epoch ---
--- 0.37197184562683105 seconds for one epoch ---
--- 0.3224301338195801 seconds for one epoch ---
--- 0.3653583526611328 seconds for one epoch ---
--- 0.31485867500305176 seconds for one epoch ---
--- 0.36426639556884766 seconds for one epoch ---
--- 0.32034778594970703 seconds for one epoch ---
--- 0.3771681785583496 seconds for one epoch ---
--- 0.3229076862335205 seconds for one epoch ---
--- 0.36206626892089844 seconds for one epoch ---
--- 0.31644272804260254 seconds for one epoch ---
--- 0.36186885833740234 seconds for one epoch ---
--- 0.32074880599975586 seconds for one epoch ---
--- 0.3657822608947754 seconds for one epoch ---
=========================
[[0.3907196 ]
 [0.37774622]
 [0.95337117]
 [0.40038398]
 [0.3781553 ]
 [0.9994028 ]
 [0.38752148]
 [0.38250065]
 [0.3770449 ]
 [0.38142735]
 [0.4083253 ]]
[[ 4.1786683e-01]
 [-6.1204962e-02]
 [-1.6638871e+00]
 [-5.1750207e-01]
 [ 8.9584306e-02]
 [-2.5659838e+00]
 [ 3.7102458e-01]
 [ 2.6613781e-01]
 [-7.9220685e-04]
 [-2.3463875e-01]
 [ 5.7494640e-01]]
--- 0.3070716857910156 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 30224.357421875, (24379.783, 4.7312446, 5752.6494, 2.531791)
   validation loss 9944.1591796875, (8936.5625, 0.45993403, 919.9432, 2.531791)
decoder loss ratio: 346217.945805, decoder SINDy loss  ratio: 1.985827
--- 0.27467966079711914 seconds for one epoch ---
--- 0.31513094902038574 seconds for one epoch ---
--- 0.35773324966430664 seconds for one epoch ---
--- 0.31301283836364746 seconds for one epoch ---
--- 0.34979939460754395 seconds for one epoch ---
--- 0.32481861114501953 seconds for one epoch ---
--- 0.3664395809173584 seconds for one epoch ---
--- 0.3235323429107666 seconds for one epoch ---
--- 0.36533236503601074 seconds for one epoch ---
--- 0.32164454460144043 seconds for one epoch ---
--- 0.3536837100982666 seconds for one epoch ---
--- 0.32980847358703613 seconds for one epoch ---
--- 0.37026476860046387 seconds for one epoch ---
--- 0.3249638080596924 seconds for one epoch ---
--- 0.37421274185180664 seconds for one epoch ---
--- 0.3166086673736572 seconds for one epoch ---
--- 0.37348389625549316 seconds for one epoch ---
--- 0.315706729888916 seconds for one epoch ---
--- 0.36447668075561523 seconds for one epoch ---
--- 0.3256523609161377 seconds for one epoch ---
--- 0.3742995262145996 seconds for one epoch ---
--- 0.3193628787994385 seconds for one epoch ---
--- 0.3651883602142334 seconds for one epoch ---
--- 0.312502384185791 seconds for one epoch ---
=========================
[[0.29602402]
 [0.29847527]
 [0.9812555 ]
 [0.31102294]
 [0.29566643]
 [0.9998439 ]
 [0.3025208 ]
 [0.30212268]
 [0.29522446]
 [0.32568356]
 [0.34969875]]
[[ 6.1936174e-02]
 [-1.8026644e-01]
 [-1.8840927e+00]
 [-4.2168918e-01]
 [ 3.7014902e-02]
 [-2.8657424e+00]
 [ 2.9164135e-01]
 [ 2.8300807e-01]
 [ 1.2598709e-03]
 [-5.4530829e-01]
 [ 6.6319942e-01]]
--- 0.27106595039367676 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 20391.583984375, (14864.444, 5.97987, 5420.7363, 2.5318182)
   validation loss 6246.88916015625, (5325.773, 0.20144066, 820.4904, 2.5318182)
decoder loss ratio: 206329.690001, decoder SINDy loss  ratio: 1.771144
--- 0.31589245796203613 seconds for one epoch ---
--- 0.3612534999847412 seconds for one epoch ---
--- 0.3210611343383789 seconds for one epoch ---
--- 0.37660765647888184 seconds for one epoch ---
--- 0.32846736907958984 seconds for one epoch ---
--- 0.3707542419433594 seconds for one epoch ---
--- 0.32920026779174805 seconds for one epoch ---
--- 0.3752436637878418 seconds for one epoch ---
--- 0.31823158264160156 seconds for one epoch ---
--- 0.36865973472595215 seconds for one epoch ---
--- 0.3193049430847168 seconds for one epoch ---
--- 0.3720862865447998 seconds for one epoch ---
--- 0.3247206211090088 seconds for one epoch ---
--- 0.3721187114715576 seconds for one epoch ---
--- 0.3285865783691406 seconds for one epoch ---
--- 0.39862942695617676 seconds for one epoch ---
--- 0.32265162467956543 seconds for one epoch ---
--- 0.3789205551147461 seconds for one epoch ---
--- 0.33075881004333496 seconds for one epoch ---
--- 0.3769998550415039 seconds for one epoch ---
--- 0.3136279582977295 seconds for one epoch ---
--- 0.3770253658294678 seconds for one epoch ---
--- 0.3274507522583008 seconds for one epoch ---
--- 0.3780691623687744 seconds for one epoch ---
=========================
[[0.24559315]
 [0.24340966]
 [0.98478544]
 [0.24788465]
 [0.23716107]
 [0.9999645 ]
 [0.24205151]
 [0.24346893]
 [0.23634386]
 [0.39220205]
 [0.31628913]]
[[-3.1638691e-01]
 [-2.7440584e-01]
 [-1.9441504e+00]
 [-3.5285613e-01]
 [ 5.8748025e-02]
 [-3.1859596e+00]
 [ 2.4318485e-01]
 [ 2.7566317e-01]
 [ 1.0031876e-03]
 [-8.8329405e-01]
 [ 7.2815502e-01]]
--- 0.2907083034515381 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 17579.138671875, (11121.969, 6.169471, 6337.7373, 2.531853)
   validation loss 4610.9130859375, (3790.5232, 0.12146337, 707.0039, 2.531853)
decoder loss ratio: 146851.449148, decoder SINDy loss  ratio: 1.526167
--- 0.25089287757873535 seconds for one epoch ---
--- 0.32276320457458496 seconds for one epoch ---
--- 0.397113561630249 seconds for one epoch ---
--- 0.32559895515441895 seconds for one epoch ---
--- 0.3719649314880371 seconds for one epoch ---
--- 0.32564568519592285 seconds for one epoch ---
--- 0.383528470993042 seconds for one epoch ---
--- 0.3202657699584961 seconds for one epoch ---
--- 0.3796558380126953 seconds for one epoch ---
--- 0.33669376373291016 seconds for one epoch ---
--- 0.3847815990447998 seconds for one epoch ---
--- 0.31000709533691406 seconds for one epoch ---
--- 0.3892247676849365 seconds for one epoch ---
--- 0.32129812240600586 seconds for one epoch ---
--- 0.38343214988708496 seconds for one epoch ---
--- 0.31558704376220703 seconds for one epoch ---
--- 0.39107847213745117 seconds for one epoch ---
--- 0.3190469741821289 seconds for one epoch ---
--- 0.3867042064666748 seconds for one epoch ---
--- 0.32311058044433594 seconds for one epoch ---
--- 0.386929988861084 seconds for one epoch ---
--- 0.3297591209411621 seconds for one epoch ---
--- 0.3961935043334961 seconds for one epoch ---
--- 0.3404698371887207 seconds for one epoch ---
=========================
[[0.24045193]
 [0.19915941]
 [0.9912344 ]
 [0.19142658]
 [0.18699865]
 [0.9999897 ]
 [0.19065624]
 [0.19438352]
 [0.1864901 ]
 [0.61335987]
 [0.28181818]]
[[-0.63159114]
 [-0.35867947]
 [-2.0709841 ]
 [-0.2161318 ]
 [ 0.04029189]
 [-3.4326813 ]
 [ 0.19454232]
 [ 0.2826854 ]
 [-0.00529194]
 [-1.175804  ]
 [ 0.7531416 ]]
--- 0.26517772674560547 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11993.26171875, (9204.003, 8.614274, 2656.1782, 2.5318882)
   validation loss 5042.2451171875, (4318.2896, 0.099467576, 599.3891, 2.5318882)
decoder loss ratio: 167298.034078, decoder SINDy loss  ratio: 1.293866
--- 0.3256204128265381 seconds for one epoch ---
--- 0.37941861152648926 seconds for one epoch ---
--- 0.33559298515319824 seconds for one epoch ---
--- 0.38696789741516113 seconds for one epoch ---
--- 0.3237478733062744 seconds for one epoch ---
--- 0.3805849552154541 seconds for one epoch ---
--- 0.3193783760070801 seconds for one epoch ---
--- 0.39095211029052734 seconds for one epoch ---
--- 0.32846713066101074 seconds for one epoch ---
--- 0.3909931182861328 seconds for one epoch ---
--- 0.3326609134674072 seconds for one epoch ---
--- 0.3848609924316406 seconds for one epoch ---
--- 0.31945180892944336 seconds for one epoch ---
--- 0.40830063819885254 seconds for one epoch ---
--- 0.31879448890686035 seconds for one epoch ---
--- 0.39918947219848633 seconds for one epoch ---
--- 0.32071948051452637 seconds for one epoch ---
--- 0.38105154037475586 seconds for one epoch ---
--- 0.32381272315979004 seconds for one epoch ---
--- 0.38504648208618164 seconds for one epoch ---
--- 0.316392183303833 seconds for one epoch ---
--- 0.3947114944458008 seconds for one epoch ---
--- 0.31912708282470703 seconds for one epoch ---
--- 0.405869722366333 seconds for one epoch ---
=========================
[[0.29549855]
 [0.16478303]
 [0.993654  ]
 [0.1543273 ]
 [0.15074193]
 [0.9999962 ]
 [0.15544339]
 [0.15902281]
 [0.15031566]
 [0.7916752 ]
 [0.26176262]]
[[-8.3988577e-01]
 [-3.7326077e-01]
 [-2.1462071e+00]
 [-1.8314713e-01]
 [ 3.0564675e-02]
 [-3.5827484e+00]
 [ 2.1408439e-01]
 [ 2.9011568e-01]
 [-1.4892956e-03]
 [-1.3826267e+00]
 [ 7.7835965e-01]]
--- 0.30129241943359375 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10651.208984375, (6494.504, 136.25168, 3887.2903, 2.5319152)
   validation loss 3033.426513671875, (2357.0063, 0.07950311, 543.1777, 2.5319152)
decoder loss ratio: 91314.517851, decoder SINDy loss  ratio: 1.172525
--- 0.26482295989990234 seconds for one epoch ---
--- 0.3385748863220215 seconds for one epoch ---
--- 0.399930477142334 seconds for one epoch ---
--- 0.32393980026245117 seconds for one epoch ---
--- 0.41632652282714844 seconds for one epoch ---
--- 0.32480549812316895 seconds for one epoch ---
--- 0.4094045162200928 seconds for one epoch ---
--- 0.32538461685180664 seconds for one epoch ---
--- 0.4137098789215088 seconds for one epoch ---
--- 0.32315707206726074 seconds for one epoch ---
--- 0.3925001621246338 seconds for one epoch ---
--- 0.3251676559448242 seconds for one epoch ---
--- 0.4094846248626709 seconds for one epoch ---
--- 0.31839537620544434 seconds for one epoch ---
--- 0.418287992477417 seconds for one epoch ---
--- 0.43204259872436523 seconds for one epoch ---
--- 0.38840675354003906 seconds for one epoch ---
--- 0.31557726860046387 seconds for one epoch ---
--- 0.4165158271789551 seconds for one epoch ---
--- 0.3259894847869873 seconds for one epoch ---
--- 0.4209260940551758 seconds for one epoch ---
--- 0.3244469165802002 seconds for one epoch ---
--- 0.39937567710876465 seconds for one epoch ---
--- 0.32887959480285645 seconds for one epoch ---
=========================
[[0.37965682]
 [0.13758478]
 [0.9951591 ]
 [0.12482262]
 [0.11960769]
 [0.99999666]
 [0.12432707]
 [0.12869944]
 [0.11950286]
 [0.8877223 ]
 [0.25614905]]
[[-9.8144060e-01]
 [-4.0591884e-01]
 [-2.2089632e+00]
 [-2.1390301e-01]
 [ 7.8752842e-03]
 [-3.6548102e+00]
 [ 2.0120685e-01]
 [ 2.9284623e-01]
 [-5.5184739e-04]
 [-1.5441210e+00]
 [ 8.1709856e-01]]
--- 0.262676477432251 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10281.08203125, (6060.3457, 5.766131, 4073.7317, 2.5319345)
   validation loss 2173.31201171875, (1551.0995, 0.076445214, 480.8984, 2.5319345)
decoder loss ratio: 60092.286965, decoder SINDy loss  ratio: 1.038087
--- 0.32517218589782715 seconds for one epoch ---
--- 0.39812302589416504 seconds for one epoch ---
--- 0.33318519592285156 seconds for one epoch ---
--- 0.39420080184936523 seconds for one epoch ---
--- 0.3156862258911133 seconds for one epoch ---
--- 0.3910677433013916 seconds for one epoch ---
--- 0.3244619369506836 seconds for one epoch ---
--- 0.3986358642578125 seconds for one epoch ---
--- 0.32195019721984863 seconds for one epoch ---
--- 0.401216983795166 seconds for one epoch ---
--- 0.3263590335845947 seconds for one epoch ---
--- 0.4319007396697998 seconds for one epoch ---
--- 0.3171103000640869 seconds for one epoch ---
--- 0.40082216262817383 seconds for one epoch ---
--- 0.3181757926940918 seconds for one epoch ---
--- 0.42354702949523926 seconds for one epoch ---
--- 0.33196187019348145 seconds for one epoch ---
--- 0.39933323860168457 seconds for one epoch ---
--- 0.3377065658569336 seconds for one epoch ---
--- 0.4122586250305176 seconds for one epoch ---
--- 0.3303241729736328 seconds for one epoch ---
--- 0.41688036918640137 seconds for one epoch ---
--- 0.338787317276001 seconds for one epoch ---
--- 0.3999180793762207 seconds for one epoch ---
=========================
[[0.48940983]
 [0.11829916]
 [0.99613136]
 [0.1028107 ]
 [0.09711941]
 [0.9999966 ]
 [0.10131569]
 [0.10669348]
 [0.09713372]
 [0.93926543]
 [0.27036718]]
[[-1.1028713e+00]
 [-4.3012506e-01]
 [-2.2599742e+00]
 [-2.2042461e-01]
 [ 3.1307726e-03]
 [-3.6998215e+00]
 [ 1.8194316e-01]
 [ 2.9581010e-01]
 [-4.1164812e-03]
 [-1.6871995e+00]
 [ 8.6803514e-01]]
--- 0.3091456890106201 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12115.39453125, (6647.709, 11.598124, 5307.6577, 2.5319502)
   validation loss 2090.6162109375, (1503.2551, 0.05552295, 438.87595, 2.5319502)
decoder loss ratio: 58238.713384, decoder SINDy loss  ratio: 0.947375
--- 0.26747989654541016 seconds for one epoch ---
--- 0.32466936111450195 seconds for one epoch ---
--- 0.40224456787109375 seconds for one epoch ---
--- 0.33074021339416504 seconds for one epoch ---
--- 0.40281033515930176 seconds for one epoch ---
--- 0.32287120819091797 seconds for one epoch ---
--- 0.4161336421966553 seconds for one epoch ---
--- 0.32090210914611816 seconds for one epoch ---
--- 0.439896821975708 seconds for one epoch ---
--- 0.3218846321105957 seconds for one epoch ---
--- 0.4253079891204834 seconds for one epoch ---
--- 0.3212747573852539 seconds for one epoch ---
--- 0.4329960346221924 seconds for one epoch ---
--- 0.3242800235748291 seconds for one epoch ---
--- 0.41924309730529785 seconds for one epoch ---
--- 0.32055163383483887 seconds for one epoch ---
--- 0.40921449661254883 seconds for one epoch ---
--- 0.3337438106536865 seconds for one epoch ---
--- 0.4192054271697998 seconds for one epoch ---
--- 0.3345975875854492 seconds for one epoch ---
--- 0.4171743392944336 seconds for one epoch ---
--- 0.3349189758300781 seconds for one epoch ---
--- 0.4136390686035156 seconds for one epoch ---
--- 0.33679819107055664 seconds for one epoch ---
=========================
[[0.5868933 ]
 [0.10060955]
 [0.99659854]
 [0.08309452]
 [0.07805195]
 [0.9999966 ]
 [0.08167141]
 [0.08834126]
 [0.07785222]
 [0.9660972 ]
 [0.2631579 ]]
[[-1.1978897e+00]
 [-4.3900016e-01]
 [-2.2905958e+00]
 [-2.0579530e-01]
 [-1.3295197e-02]
 [-3.6956418e+00]
 [ 1.6725822e-01]
 [ 3.0615947e-01]
 [-1.4477238e-04]
 [-1.8162371e+00]
 [ 8.7940770e-01]]
--- 0.26990175247192383 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5336.05859375, (2856.435, 2.4423542, 2322.8574, 2.53196)
   validation loss 1747.171875, (1180.3848, 0.081930585, 412.38126, 2.53196)
decoder loss ratio: 45730.155058, decoder SINDy loss  ratio: 0.890183
--- 0.32373571395874023 seconds for one epoch ---
--- 0.4146294593811035 seconds for one epoch ---
--- 0.3252065181732178 seconds for one epoch ---
--- 0.41681766510009766 seconds for one epoch ---
--- 0.32216763496398926 seconds for one epoch ---
--- 0.42226076126098633 seconds for one epoch ---
--- 0.3145558834075928 seconds for one epoch ---
--- 0.41738080978393555 seconds for one epoch ---
--- 0.32328057289123535 seconds for one epoch ---
--- 0.42752957344055176 seconds for one epoch ---
--- 0.3179616928100586 seconds for one epoch ---
--- 0.43673086166381836 seconds for one epoch ---
--- 0.3290269374847412 seconds for one epoch ---
--- 0.42403268814086914 seconds for one epoch ---
--- 0.33201169967651367 seconds for one epoch ---
--- 0.4425816535949707 seconds for one epoch ---
--- 0.31733107566833496 seconds for one epoch ---
--- 0.4222102165222168 seconds for one epoch ---
--- 0.3218042850494385 seconds for one epoch ---
--- 0.4436016082763672 seconds for one epoch ---
--- 0.32256221771240234 seconds for one epoch ---
--- 0.4395599365234375 seconds for one epoch ---
--- 0.3205726146697998 seconds for one epoch ---
--- 0.44255495071411133 seconds for one epoch ---
=========================
[[0.70839   ]
 [0.08789644]
 [0.99641824]
 [0.06802896]
 [0.06379442]
 [0.9999965 ]
 [0.06692438]
 [0.074297  ]
 [0.06379309]
 [0.9838741 ]
 [0.2839133 ]]
[[-1.3157272e+00]
 [-4.4685951e-01]
 [-2.2831428e+00]
 [-1.7789036e-01]
 [-1.1244491e-03]
 [-3.6822760e+00]
 [ 1.4451525e-01]
 [ 3.0418459e-01]
 [-1.0263971e-03]
 [-1.9742746e+00]
 [ 9.1939956e-01]]
--- 0.31769657135009766 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7997.15869140625, (3017.987, 0.88977957, 4818.0225, 2.5319693)
   validation loss 1972.9937744140625, (1360.3788, 0.05212799, 452.3034, 2.5319693)
decoder loss ratio: 52703.435821, decoder SINDy loss  ratio: 0.976361
--- 0.27531981468200684 seconds for one epoch ---
--- 0.3260831832885742 seconds for one epoch ---
--- 0.422680139541626 seconds for one epoch ---
--- 0.325244665145874 seconds for one epoch ---
--- 0.45806145668029785 seconds for one epoch ---
--- 0.32934141159057617 seconds for one epoch ---
--- 0.4507474899291992 seconds for one epoch ---
--- 0.32138705253601074 seconds for one epoch ---
--- 0.4389078617095947 seconds for one epoch ---
--- 0.32271552085876465 seconds for one epoch ---
--- 0.4338099956512451 seconds for one epoch ---
--- 0.31281208992004395 seconds for one epoch ---
--- 0.4309570789337158 seconds for one epoch ---
--- 0.3261909484863281 seconds for one epoch ---
--- 0.437908411026001 seconds for one epoch ---
--- 0.3319277763366699 seconds for one epoch ---
--- 0.46800780296325684 seconds for one epoch ---
--- 0.3282206058502197 seconds for one epoch ---
--- 0.44916367530822754 seconds for one epoch ---
--- 0.32346248626708984 seconds for one epoch ---
--- 0.44484782218933105 seconds for one epoch ---
--- 0.32680654525756836 seconds for one epoch ---
--- 0.43917346000671387 seconds for one epoch ---
--- 0.33185601234436035 seconds for one epoch ---
=========================
[[0.8024584 ]
 [0.07560347]
 [0.9965115 ]
 [0.05527559]
 [0.05176443]
 [0.9999965 ]
 [0.05516078]
 [0.06229196]
 [0.05169407]
 [0.9928051 ]
 [0.27354482]]
[[-1.4252024e+00]
 [-4.4326514e-01]
 [-2.2911558e+00]
 [-1.5837629e-01]
 [-7.7108662e-03]
 [-3.6339252e+00]
 [ 1.5486915e-01]
 [ 3.0404541e-01]
 [-3.1741585e-03]
 [-2.1429813e+00]
 [ 9.1812444e-01]]
--- 0.26033782958984375 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6977.966796875, (3463.1382, 2.086254, 3346.933, 2.531977)
   validation loss 1891.66650390625, (1318.8514, 0.03962149, 406.96564, 2.531977)
decoder loss ratio: 51094.594429, decoder SINDy loss  ratio: 0.878493
--- 0.31998491287231445 seconds for one epoch ---
--- 0.430617094039917 seconds for one epoch ---
--- 0.3250117301940918 seconds for one epoch ---
--- 0.45806026458740234 seconds for one epoch ---
--- 0.32050371170043945 seconds for one epoch ---
--- 0.439359188079834 seconds for one epoch ---
--- 0.3192110061645508 seconds for one epoch ---
--- 0.44558048248291016 seconds for one epoch ---
--- 0.3228321075439453 seconds for one epoch ---
--- 0.45272374153137207 seconds for one epoch ---
--- 0.32541465759277344 seconds for one epoch ---
--- 0.4393939971923828 seconds for one epoch ---
--- 0.3143925666809082 seconds for one epoch ---
--- 0.464160680770874 seconds for one epoch ---
--- 0.32171201705932617 seconds for one epoch ---
--- 0.449185848236084 seconds for one epoch ---
--- 0.32245755195617676 seconds for one epoch ---
--- 0.44187164306640625 seconds for one epoch ---
--- 0.314725399017334 seconds for one epoch ---
--- 0.44147276878356934 seconds for one epoch ---
--- 0.3196878433227539 seconds for one epoch ---
--- 0.44796013832092285 seconds for one epoch ---
--- 0.32060670852661133 seconds for one epoch ---
--- 0.4607048034667969 seconds for one epoch ---
=========================
[[0.8711671 ]
 [0.06752883]
 [0.99670166]
 [0.04653306]
 [0.04274106]
 [0.9999964 ]
 [0.04620943]
 [0.0528697 ]
 [0.04279875]
 [0.9966987 ]
 [0.28491578]]
[[-1.5315591e+00]
 [-4.4798478e-01]
 [-2.3045728e+00]
 [-1.6290982e-01]
 [ 1.6264000e-03]
 [-3.6005516e+00]
 [ 1.5318599e-01]
 [ 2.9511920e-01]
 [-5.3533809e-03]
 [-2.3043914e+00]
 [ 9.3873781e-01]]
--- 0.29566097259521484 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6867.6552734375, (2328.2344, 0.45017752, 4368.2446, 2.5319872)
   validation loss 1333.25732421875, (785.856, 0.048263956, 376.62744, 2.5319872)
decoder loss ratio: 30445.426446, decoder SINDy loss  ratio: 0.813003
--- 0.2719879150390625 seconds for one epoch ---
--- 0.32631421089172363 seconds for one epoch ---
--- 0.44202542304992676 seconds for one epoch ---
--- 0.326066255569458 seconds for one epoch ---
--- 0.4487876892089844 seconds for one epoch ---
--- 0.3253509998321533 seconds for one epoch ---
--- 0.4643089771270752 seconds for one epoch ---
--- 0.33572864532470703 seconds for one epoch ---
--- 0.45078158378601074 seconds for one epoch ---
--- 0.326831579208374 seconds for one epoch ---
--- 0.45220470428466797 seconds for one epoch ---
--- 0.32342529296875 seconds for one epoch ---
--- 0.44591450691223145 seconds for one epoch ---
--- 0.3271632194519043 seconds for one epoch ---
--- 0.4583251476287842 seconds for one epoch ---
--- 0.33606624603271484 seconds for one epoch ---
--- 0.4643983840942383 seconds for one epoch ---
--- 0.31975769996643066 seconds for one epoch ---
--- 0.4726295471191406 seconds for one epoch ---
--- 0.3243882656097412 seconds for one epoch ---
--- 0.4471123218536377 seconds for one epoch ---
--- 0.3216698169708252 seconds for one epoch ---
--- 0.44679856300354004 seconds for one epoch ---
--- 0.328540563583374 seconds for one epoch ---
=========================
[[0.9068699 ]
 [0.06412421]
 [0.99646145]
 [0.0392359 ]
 [0.03504634]
 [0.9999896 ]
 [0.0389889 ]
 [0.04591453]
 [0.03508625]
 [0.99836665]
 [0.30450815]]
[[-1.6076092 ]
 [-0.47642717]
 [-2.2918367 ]
 [-0.17454572]
 [-0.0044854 ]
 [-3.5200722 ]
 [ 0.1676396 ]
 [ 0.30556777]
 [-0.007013  ]
 [-2.44982   ]
 [ 0.9656489 ]]
--- 0.2664003372192383 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5859.740234375, (2137.5571, 0.48211214, 3547.4417, 2.5319934)
   validation loss 1394.39013671875, (867.51746, 0.037348643, 352.57657, 2.5319934)
decoder loss ratio: 33609.132324, decoder SINDy loss  ratio: 0.761086
--- 0.321521520614624 seconds for one epoch ---
--- 0.46436357498168945 seconds for one epoch ---
--- 0.3383488655090332 seconds for one epoch ---
--- 0.4597749710083008 seconds for one epoch ---
--- 0.32280945777893066 seconds for one epoch ---
--- 0.4509744644165039 seconds for one epoch ---
--- 0.31208300590515137 seconds for one epoch ---
--- 0.4700620174407959 seconds for one epoch ---
--- 0.338106632232666 seconds for one epoch ---
--- 0.4706461429595947 seconds for one epoch ---
--- 0.319425106048584 seconds for one epoch ---
--- 0.4607694149017334 seconds for one epoch ---
--- 0.3347289562225342 seconds for one epoch ---
--- 0.4652540683746338 seconds for one epoch ---
--- 0.3248424530029297 seconds for one epoch ---
--- 0.47389960289001465 seconds for one epoch ---
--- 0.32630300521850586 seconds for one epoch ---
--- 0.48294806480407715 seconds for one epoch ---
--- 0.32909059524536133 seconds for one epoch ---
--- 0.466533899307251 seconds for one epoch ---
--- 0.3215301036834717 seconds for one epoch ---
--- 0.4855208396911621 seconds for one epoch ---
--- 0.32802772521972656 seconds for one epoch ---
--- 0.4660825729370117 seconds for one epoch ---
=========================
[[0.9332946 ]
 [0.05986873]
 [0.99603707]
 [0.03305747]
 [0.02927622]
 [0.9999891 ]
 [0.03297579]
 [0.03961913]
 [0.02927926]
 [0.99914616]
 [0.3400396 ]]
[[-1.6825585e+00]
 [-4.8458743e-01]
 [-2.2698741e+00]
 [-1.6107842e-01]
 [ 1.7006105e-03]
 [-3.4576616e+00]
 [ 1.5868039e-01]
 [ 2.9622319e-01]
 [-1.8979076e-03]
 [-2.5835063e+00]
 [ 1.0046414e+00]]
--- 0.40834760665893555 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3518.9345703125, (1328.1577, 0.34179357, 2012.2719, 2.5319993)
   validation loss 1561.2978515625, (1032.0942, 0.044045776, 350.99646, 2.5319993)
decoder loss ratio: 39985.122585, decoder SINDy loss  ratio: 0.757675
--- 0.26056385040283203 seconds for one epoch ---
--- 0.32093262672424316 seconds for one epoch ---
--- 0.4792323112487793 seconds for one epoch ---
--- 0.32056641578674316 seconds for one epoch ---
--- 0.4921233654022217 seconds for one epoch ---
--- 0.3221611976623535 seconds for one epoch ---
--- 0.4748244285583496 seconds for one epoch ---
--- 0.3321235179901123 seconds for one epoch ---
--- 0.4720020294189453 seconds for one epoch ---
--- 0.32280945777893066 seconds for one epoch ---
--- 0.4799525737762451 seconds for one epoch ---
--- 0.31319260597229004 seconds for one epoch ---
--- 0.4799621105194092 seconds for one epoch ---
--- 0.3300173282623291 seconds for one epoch ---
--- 0.487933874130249 seconds for one epoch ---
--- 0.3218977451324463 seconds for one epoch ---
--- 0.4778475761413574 seconds for one epoch ---
--- 0.3217458724975586 seconds for one epoch ---
--- 0.5019967555999756 seconds for one epoch ---
--- 0.3160264492034912 seconds for one epoch ---
--- 0.48226022720336914 seconds for one epoch ---
--- 0.3403441905975342 seconds for one epoch ---
--- 0.47463035583496094 seconds for one epoch ---
--- 0.3232569694519043 seconds for one epoch ---
=========================
[[0.9533523 ]
 [0.05747338]
 [0.99529696]
 [0.02811272]
 [0.02447449]
 [0.99998164]
 [0.02729416]
 [0.03426932]
 [0.02429436]
 [0.9995742 ]
 [0.3432916 ]]
[[-1.7606159e+00]
 [-4.9904662e-01]
 [-2.2359092e+00]
 [-1.6181165e-01]
 [ 1.3338241e-02]
 [-3.3855689e+00]
 [ 1.3662684e-01]
 [ 2.8991860e-01]
 [ 2.1850031e-03]
 [-2.7269046e+00]
 [ 1.0108730e+00]]
--- 0.2684900760650635 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4781.47998046875, (1742.378, 1.025717, 2856.4321, 2.5320039)
   validation loss 1507.9127197265625, (986.7059, 0.041967582, 339.52097, 2.5320039)
decoder loss ratio: 38226.698462, decoder SINDy loss  ratio: 0.732904
--- 0.319502592086792 seconds for one epoch ---
--- 0.4976639747619629 seconds for one epoch ---
--- 0.32076549530029297 seconds for one epoch ---
--- 0.4646289348602295 seconds for one epoch ---
--- 0.3161764144897461 seconds for one epoch ---
--- 0.47574710845947266 seconds for one epoch ---
--- 0.32441163063049316 seconds for one epoch ---
--- 0.4747498035430908 seconds for one epoch ---
--- 0.32622385025024414 seconds for one epoch ---
--- 0.4799656867980957 seconds for one epoch ---
--- 0.3300137519836426 seconds for one epoch ---
--- 0.48120808601379395 seconds for one epoch ---
--- 0.3354060649871826 seconds for one epoch ---
--- 0.4871487617492676 seconds for one epoch ---
--- 0.325061559677124 seconds for one epoch ---
--- 0.5071942806243896 seconds for one epoch ---
--- 0.32370996475219727 seconds for one epoch ---
--- 0.502685546875 seconds for one epoch ---
--- 0.32372617721557617 seconds for one epoch ---
--- 0.4831380844116211 seconds for one epoch ---
--- 0.32288384437561035 seconds for one epoch ---
--- 0.4895317554473877 seconds for one epoch ---
--- 0.33197689056396484 seconds for one epoch ---
--- 0.4880795478820801 seconds for one epoch ---
=========================
[[0.96571016]
 [0.05405447]
 [0.99549955]
 [0.0246234 ]
 [0.02100273]
 [0.9999739 ]
 [0.02302307]
 [0.03031211]
 [0.02055971]
 [0.99977756]
 [0.34736118]]
[[-1.8265405e+00]
 [-4.9999380e-01]
 [-2.2457173e+00]
 [-1.6769871e-01]
 [ 2.7172608e-02]
 [-3.2920599e+00]
 [ 1.1706879e-01]
 [ 2.8549063e-01]
 [ 6.8376970e-04]
 [-2.8620920e+00]
 [ 1.0169456e+00]]
--- 0.3022935390472412 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5487.2138671875, (2611.1013, 0.31187725, 2691.3816, 2.5320084)
   validation loss 2019.511474609375, (1417.3046, 0.05557663, 417.73257, 2.5320084)
decoder loss ratio: 54908.839414, decoder SINDy loss  ratio: 0.901735
--- 0.2626800537109375 seconds for one epoch ---
--- 0.32124757766723633 seconds for one epoch ---
--- 0.47842884063720703 seconds for one epoch ---
--- 0.3226137161254883 seconds for one epoch ---
--- 0.5005478858947754 seconds for one epoch ---
--- 0.3296167850494385 seconds for one epoch ---
--- 0.49625205993652344 seconds for one epoch ---
--- 0.327777624130249 seconds for one epoch ---
--- 0.5121972560882568 seconds for one epoch ---
--- 0.31354689598083496 seconds for one epoch ---
--- 0.49692773818969727 seconds for one epoch ---
--- 0.3246028423309326 seconds for one epoch ---
--- 0.4921560287475586 seconds for one epoch ---
--- 0.31629395484924316 seconds for one epoch ---
--- 0.5119540691375732 seconds for one epoch ---
--- 0.3230428695678711 seconds for one epoch ---
--- 0.5178194046020508 seconds for one epoch ---
--- 0.3065602779388428 seconds for one epoch ---
--- 0.4938936233520508 seconds for one epoch ---
--- 0.3246886730194092 seconds for one epoch ---
--- 0.4867973327636719 seconds for one epoch ---
--- 0.3294999599456787 seconds for one epoch ---
--- 0.5007712841033936 seconds for one epoch ---
--- 0.3238670825958252 seconds for one epoch ---
=========================
[[0.97339576]
 [0.05578291]
 [0.9953583 ]
 [0.02172538]
 [0.01761035]
 [0.999959  ]
 [0.01981305]
 [0.0268271 ]
 [0.01731919]
 [0.9998698 ]
 [0.34427142]]
[[-1.8803902e+00]
 [-5.2599913e-01]
 [-2.2400415e+00]
 [-1.7693022e-01]
 [ 1.8965049e-02]
 [-3.2203877e+00]
 [ 1.1819846e-01]
 [ 2.8124619e-01]
 [ 1.2765058e-03]
 [-2.9739063e+00]
 [ 1.0160975e+00]]
--- 0.25914955139160156 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6593.77587890625, (2010.3164, 2.7993085, 4393.645, 2.5320134)
   validation loss 1344.87890625, (795.3224, 0.05548638, 362.48627, 2.5320134)
decoder loss ratio: 30812.170040, decoder SINDy loss  ratio: 0.782478
--- 0.32425451278686523 seconds for one epoch ---
--- 0.49393630027770996 seconds for one epoch ---
--- 0.32596445083618164 seconds for one epoch ---
--- 0.4881124496459961 seconds for one epoch ---
--- 0.3078453540802002 seconds for one epoch ---
--- 0.48826098442077637 seconds for one epoch ---
--- 0.3301215171813965 seconds for one epoch ---
--- 0.4917283058166504 seconds for one epoch ---
--- 0.325178861618042 seconds for one epoch ---
--- 0.4958813190460205 seconds for one epoch ---
--- 0.31697535514831543 seconds for one epoch ---
--- 0.4942436218261719 seconds for one epoch ---
--- 0.3026580810546875 seconds for one epoch ---
--- 0.4879453182220459 seconds for one epoch ---
--- 0.3126401901245117 seconds for one epoch ---
--- 0.5052754878997803 seconds for one epoch ---
--- 0.3223423957824707 seconds for one epoch ---
--- 0.4853487014770508 seconds for one epoch ---
--- 0.31839728355407715 seconds for one epoch ---
--- 0.521172285079956 seconds for one epoch ---
--- 0.31829380989074707 seconds for one epoch ---
--- 0.498523473739624 seconds for one epoch ---
--- 0.31767773628234863 seconds for one epoch ---
--- 0.5059459209442139 seconds for one epoch ---
=========================
[[0.9786723 ]
 [0.05365711]
 [0.9955997 ]
 [0.01964423]
 [0.01509738]
 [0.9999428 ]
 [0.01745133]
 [0.02429919]
 [0.01495048]
 [0.99992085]
 [0.36808676]]
[[-1.9269108 ]
 [-0.5270449 ]
 [-2.2514813 ]
 [-0.18571611]
 [ 0.01401534]
 [-3.1417918 ]
 [ 0.12037287]
 [ 0.27928543]
 [ 0.00508393]
 [-3.07702   ]
 [ 1.0389891 ]]
--- 0.3085758686065674 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3211.13134765625, (1521.5189, 0.28297898, 1499.77, 2.5320182)
   validation loss 1732.0638427734375, (1186.5051, 0.061900232, 355.9372, 2.5320182)
decoder loss ratio: 45967.268482, decoder SINDy loss  ratio: 0.768340
THRESHOLDING: 5 active coefficients
--- 0.5092928409576416 seconds for one epoch ---
--- 0.3223237991333008 seconds for one epoch ---
--- 0.5208415985107422 seconds for one epoch ---
--- 0.32190752029418945 seconds for one epoch ---
--- 0.5035758018493652 seconds for one epoch ---
--- 0.3073916435241699 seconds for one epoch ---
--- 0.510631799697876 seconds for one epoch ---
--- 0.3296527862548828 seconds for one epoch ---
--- 0.5204689502716064 seconds for one epoch ---
--- 0.33232951164245605 seconds for one epoch ---
--- 0.5138068199157715 seconds for one epoch ---
--- 0.3137059211730957 seconds for one epoch ---
--- 0.5140423774719238 seconds for one epoch ---
--- 0.3213541507720947 seconds for one epoch ---
--- 0.5143346786499023 seconds for one epoch ---
--- 0.3238215446472168 seconds for one epoch ---
--- 0.5316188335418701 seconds for one epoch ---
--- 0.3085489273071289 seconds for one epoch ---
--- 0.5171637535095215 seconds for one epoch ---
--- 0.3117549419403076 seconds for one epoch ---
--- 0.4911377429962158 seconds for one epoch ---
--- 0.31890106201171875 seconds for one epoch ---
--- 0.5309183597564697 seconds for one epoch ---
--- 0.328214168548584 seconds for one epoch ---
=========================
[[0.5560318 ]
 [0.        ]
 [0.9950982 ]
 [0.        ]
 [0.        ]
 [0.9896596 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999439  ]
 [0.46974874]]
[[-1.1964965]
 [-0.       ]
 [-2.2298164]
 [-0.       ]
 [ 0.       ]
 [-2.0768049]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.6729555]
 [ 1.1259514]]
--- 0.2648773193359375 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2702.17822265625, (1159.5308, 1.0254874, 1540.5625, 1.0595785)
   validation loss 2591.13671875, (2133.9612, 0.032794297, 456.08316, 1.0595785)
decoder loss ratio: 82673.360896, decoder SINDy loss  ratio: 0.984520
--- 0.3104400634765625 seconds for one epoch ---
--- 0.520456075668335 seconds for one epoch ---
--- 0.33237600326538086 seconds for one epoch ---
--- 0.5058014392852783 seconds for one epoch ---
--- 0.3330979347229004 seconds for one epoch ---
--- 0.5275330543518066 seconds for one epoch ---
--- 0.3422563076019287 seconds for one epoch ---
--- 0.5134589672088623 seconds for one epoch ---
--- 0.3283572196960449 seconds for one epoch ---
--- 0.536858081817627 seconds for one epoch ---
--- 0.3037447929382324 seconds for one epoch ---
--- 0.5160679817199707 seconds for one epoch ---
--- 0.322131872177124 seconds for one epoch ---
--- 0.5287623405456543 seconds for one epoch ---
--- 0.3220705986022949 seconds for one epoch ---
--- 0.5459330081939697 seconds for one epoch ---
--- 0.3215217590332031 seconds for one epoch ---
--- 0.5224893093109131 seconds for one epoch ---
--- 0.3193535804748535 seconds for one epoch ---
--- 0.5083744525909424 seconds for one epoch ---
--- 0.3210911750793457 seconds for one epoch ---
--- 0.5101795196533203 seconds for one epoch ---
--- 0.32497358322143555 seconds for one epoch ---
--- 0.5277442932128906 seconds for one epoch ---
=========================
[[0.22579737]
 [0.        ]
 [0.99018455]
 [0.        ]
 [0.        ]
 [0.92413414]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9987511 ]
 [0.54017496]]
[[-0.8988398]
 [-0.       ]
 [-2.0878239]
 [-0.       ]
 [ 0.       ]
 [-1.6584803]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.509698 ]
 [ 1.1840769]]
--- 0.30513882637023926 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3672.259521484375, (2079.7527, 0.9928447, 1590.5192, 0.9949382)
   validation loss 1230.786865234375, (892.3007, 0.11223377, 337.37894, 0.9949382)
decoder loss ratio: 34569.279003, decoder SINDy loss  ratio: 0.728280
--- 0.2895066738128662 seconds for one epoch ---
--- 0.3307197093963623 seconds for one epoch ---
--- 0.5282166004180908 seconds for one epoch ---
--- 0.32204556465148926 seconds for one epoch ---
--- 0.5290977954864502 seconds for one epoch ---
--- 0.3244450092315674 seconds for one epoch ---
--- 0.530592679977417 seconds for one epoch ---
--- 0.3254554271697998 seconds for one epoch ---
--- 0.5318648815155029 seconds for one epoch ---
--- 0.3180873394012451 seconds for one epoch ---
--- 0.5286426544189453 seconds for one epoch ---
--- 0.32113122940063477 seconds for one epoch ---
--- 0.5297341346740723 seconds for one epoch ---
--- 0.32306933403015137 seconds for one epoch ---
--- 0.5505623817443848 seconds for one epoch ---
--- 0.3209390640258789 seconds for one epoch ---
--- 0.5306904315948486 seconds for one epoch ---
--- 0.3183588981628418 seconds for one epoch ---
--- 0.5319540500640869 seconds for one epoch ---
--- 0.31433773040771484 seconds for one epoch ---
--- 0.5503242015838623 seconds for one epoch ---
--- 0.31580233573913574 seconds for one epoch ---
--- 0.5528943538665771 seconds for one epoch ---
--- 0.3191804885864258 seconds for one epoch ---
=========================
[[0.1276679]
 [0.       ]
 [0.9753995]
 [0.       ]
 [0.       ]
 [0.8276805]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9980644]
 [0.6644128]]
[[-0.75665456]
 [-0.        ]
 [-1.8983179 ]
 [-0.        ]
 [ 0.        ]
 [-1.4701444 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.420461  ]
 [ 1.2905177 ]]
--- 0.2793750762939453 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4923.87060546875, (1759.2797, 0.5911629, 3163.0225, 0.9770244)
   validation loss 1287.925537109375, (948.0587, 0.12173432, 338.768, 0.9770244)
decoder loss ratio: 36729.440553, decoder SINDy loss  ratio: 0.731278
--- 0.32040882110595703 seconds for one epoch ---
--- 0.5448794364929199 seconds for one epoch ---
--- 0.31827592849731445 seconds for one epoch ---
--- 0.544633150100708 seconds for one epoch ---
--- 0.32866692543029785 seconds for one epoch ---
--- 0.5398578643798828 seconds for one epoch ---
--- 0.3164069652557373 seconds for one epoch ---
--- 0.5509054660797119 seconds for one epoch ---
--- 0.32698869705200195 seconds for one epoch ---
--- 0.5585043430328369 seconds for one epoch ---
--- 0.32535386085510254 seconds for one epoch ---
--- 0.5423352718353271 seconds for one epoch ---
--- 0.31750965118408203 seconds for one epoch ---
--- 0.5463838577270508 seconds for one epoch ---
--- 0.3339347839355469 seconds for one epoch ---
--- 0.5526483058929443 seconds for one epoch ---
--- 0.3183140754699707 seconds for one epoch ---
--- 0.5530157089233398 seconds for one epoch ---
--- 0.3242158889770508 seconds for one epoch ---
--- 0.5456991195678711 seconds for one epoch ---
--- 0.3209998607635498 seconds for one epoch ---
--- 0.558391809463501 seconds for one epoch ---
--- 0.3354475498199463 seconds for one epoch ---
--- 0.5471830368041992 seconds for one epoch ---
=========================
[[0.10531254]
 [0.        ]
 [0.9358404 ]
 [0.        ]
 [0.        ]
 [0.774973  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9977783 ]
 [0.6741057 ]]
[[-0.7126956]
 [-0.       ]
 [-1.6955736]
 [-0.       ]
 [ 0.       ]
 [-1.4030108]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3925002]
 [ 1.2997222]]
--- 0.3027338981628418 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3333.80322265625, (1878.1266, 1.4663975, 1453.2516, 0.9584138)
   validation loss 2953.387939453125, (2587.3398, 0.15770876, 364.93195, 0.9584138)
decoder loss ratio: 100238.037366, decoder SINDy loss  ratio: 0.787757
--- 0.2733900547027588 seconds for one epoch ---
--- 0.3271613121032715 seconds for one epoch ---
--- 0.5654525756835938 seconds for one epoch ---
--- 0.3282780647277832 seconds for one epoch ---
--- 0.5279521942138672 seconds for one epoch ---
--- 0.3136909008026123 seconds for one epoch ---
--- 0.5472497940063477 seconds for one epoch ---
--- 0.32240939140319824 seconds for one epoch ---
--- 0.5591294765472412 seconds for one epoch ---
--- 0.3147616386413574 seconds for one epoch ---
--- 0.5578019618988037 seconds for one epoch ---
--- 0.30817103385925293 seconds for one epoch ---
--- 0.5460829734802246 seconds for one epoch ---
--- 0.3367428779602051 seconds for one epoch ---
--- 0.5447239875793457 seconds for one epoch ---
--- 0.3368494510650635 seconds for one epoch ---
--- 0.5459856986999512 seconds for one epoch ---
--- 0.3145918846130371 seconds for one epoch ---
--- 0.5574114322662354 seconds for one epoch ---
--- 0.32298851013183594 seconds for one epoch ---
--- 0.5602421760559082 seconds for one epoch ---
--- 0.3068108558654785 seconds for one epoch ---
--- 0.5671961307525635 seconds for one epoch ---
--- 0.33612585067749023 seconds for one epoch ---
=========================
[[0.08787578]
 [0.        ]
 [0.8790592 ]
 [0.        ]
 [0.        ]
 [0.7229254 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99744076]
 [0.7382313 ]]
[[-0.6725328]
 [-0.       ]
 [-1.5545791]
 [-0.       ]
 [ 0.       ]
 [-1.3470411]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3637717]
 [ 1.3627932]]
--- 0.25379061698913574 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5014.1572265625, (3135.6707, 3.9244976, 1873.6158, 0.9461498)
   validation loss 1048.7030029296875, (726.32996, 0.1401263, 321.2868, 0.9461498)
decoder loss ratio: 28139.283462, decoder SINDy loss  ratio: 0.693543
--- 0.333404541015625 seconds for one epoch ---
--- 0.5589561462402344 seconds for one epoch ---
--- 0.44993114471435547 seconds for one epoch ---
--- 0.5737371444702148 seconds for one epoch ---
--- 0.3329629898071289 seconds for one epoch ---
--- 0.5620968341827393 seconds for one epoch ---
--- 0.330080509185791 seconds for one epoch ---
--- 0.5654394626617432 seconds for one epoch ---
--- 0.3259603977203369 seconds for one epoch ---
--- 0.5884547233581543 seconds for one epoch ---
--- 0.32221412658691406 seconds for one epoch ---
--- 0.5701050758361816 seconds for one epoch ---
--- 0.3251621723175049 seconds for one epoch ---
--- 0.5761628150939941 seconds for one epoch ---
--- 0.32253432273864746 seconds for one epoch ---
--- 0.5727317333221436 seconds for one epoch ---
--- 0.3130931854248047 seconds for one epoch ---
--- 0.5892753601074219 seconds for one epoch ---
--- 0.32844972610473633 seconds for one epoch ---
--- 0.5855705738067627 seconds for one epoch ---
--- 0.32390379905700684 seconds for one epoch ---
--- 0.5786001682281494 seconds for one epoch ---
--- 0.3215751647949219 seconds for one epoch ---
--- 0.5908792018890381 seconds for one epoch ---
=========================
[[0.07488388]
 [0.        ]
 [0.72879547]
 [0.        ]
 [0.        ]
 [0.6878861 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9969071 ]
 [0.77588344]]
[[-0.6376877]
 [-0.       ]
 [-1.3532183]
 [-0.       ]
 [ 0.       ]
 [-1.3130748]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3252378]
 [ 1.4045101]]
--- 0.31352996826171875 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2858.015380859375, (1031.1417, 0.56039804, 1825.3912, 0.9222109)
   validation loss 1502.18310546875, (1171.5944, 0.11735792, 329.5492, 0.9222109)
decoder loss ratio: 45389.599497, decoder SINDy loss  ratio: 0.711378
--- 0.2797372341156006 seconds for one epoch ---
--- 0.3292553424835205 seconds for one epoch ---
--- 0.5857043266296387 seconds for one epoch ---
--- 0.3300135135650635 seconds for one epoch ---
--- 0.5690491199493408 seconds for one epoch ---
--- 0.323230504989624 seconds for one epoch ---
--- 0.5671446323394775 seconds for one epoch ---
--- 0.31349706649780273 seconds for one epoch ---
--- 0.5781917572021484 seconds for one epoch ---
--- 0.31273770332336426 seconds for one epoch ---
--- 0.578157901763916 seconds for one epoch ---
--- 0.3403775691986084 seconds for one epoch ---
--- 0.5838403701782227 seconds for one epoch ---
--- 0.3274221420288086 seconds for one epoch ---
--- 0.573239803314209 seconds for one epoch ---
--- 0.3263719081878662 seconds for one epoch ---
--- 0.5807287693023682 seconds for one epoch ---
--- 0.32149338722229004 seconds for one epoch ---
--- 0.600095272064209 seconds for one epoch ---
--- 0.3289356231689453 seconds for one epoch ---
--- 0.5981574058532715 seconds for one epoch ---
--- 0.3213489055633545 seconds for one epoch ---
--- 0.5755491256713867 seconds for one epoch ---
--- 0.32254624366760254 seconds for one epoch ---
=========================
[[0.08949087]
 [0.        ]
 [0.5791299 ]
 [0.        ]
 [0.        ]
 [0.6835492 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9975457 ]
 [0.8308881 ]]
[[-0.6799675]
 [-0.       ]
 [-1.217918 ]
 [-0.       ]
 [ 0.       ]
 [-1.3091927]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3726194]
 [ 1.4755704]]
--- 0.2669341564178467 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4365.70849609375, (1824.2936, 0.74141014, 2539.765, 0.9089059)
   validation loss 1173.4339599609375, (867.9136, 0.15917093, 304.45227, 0.9089059)
decoder loss ratio: 33624.478629, decoder SINDy loss  ratio: 0.657203
--- 0.33046936988830566 seconds for one epoch ---
--- 0.5721113681793213 seconds for one epoch ---
--- 0.32471275329589844 seconds for one epoch ---
--- 0.5935964584350586 seconds for one epoch ---
--- 0.33013248443603516 seconds for one epoch ---
--- 0.5923888683319092 seconds for one epoch ---
--- 0.3242506980895996 seconds for one epoch ---
--- 0.6083548069000244 seconds for one epoch ---
--- 0.3270244598388672 seconds for one epoch ---
--- 0.6013517379760742 seconds for one epoch ---
--- 0.3265080451965332 seconds for one epoch ---
--- 0.613706111907959 seconds for one epoch ---
--- 0.3244786262512207 seconds for one epoch ---
--- 0.616912841796875 seconds for one epoch ---
--- 0.3347203731536865 seconds for one epoch ---
--- 0.5926060676574707 seconds for one epoch ---
--- 0.3269155025482178 seconds for one epoch ---
--- 0.6101300716400146 seconds for one epoch ---
--- 0.3323400020599365 seconds for one epoch ---
--- 0.6073269844055176 seconds for one epoch ---
--- 0.3183712959289551 seconds for one epoch ---
--- 0.6040306091308594 seconds for one epoch ---
--- 0.31044507026672363 seconds for one epoch ---
--- 0.6099710464477539 seconds for one epoch ---
=========================
[[0.09881956]
 [0.        ]
 [0.43124005]
 [0.        ]
 [0.        ]
 [0.66174567]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.997927  ]
 [0.82335657]]
[[-0.7037029]
 [-0.       ]
 [-1.0974588]
 [-0.       ]
 [ 0.       ]
 [-1.2892954]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4072518]
 [ 1.4650242]]
--- 0.30170655250549316 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3458.688232421875, (1556.0989, 0.4864229, 1901.2161, 0.8869044)
   validation loss 1126.1376953125, (784.31506, 0.1305142, 340.80515, 0.8869044)
decoder loss ratio: 30385.727190, decoder SINDy loss  ratio: 0.735676
--- 0.2732415199279785 seconds for one epoch ---
--- 0.3141458034515381 seconds for one epoch ---
--- 0.5961966514587402 seconds for one epoch ---
--- 0.33170294761657715 seconds for one epoch ---
--- 0.5947535037994385 seconds for one epoch ---
--- 0.32495546340942383 seconds for one epoch ---
--- 0.6143252849578857 seconds for one epoch ---
--- 0.34082937240600586 seconds for one epoch ---
--- 0.5738153457641602 seconds for one epoch ---
--- 0.3382909297943115 seconds for one epoch ---
--- 0.5955896377563477 seconds for one epoch ---
--- 0.3225879669189453 seconds for one epoch ---
--- 0.6015751361846924 seconds for one epoch ---
--- 0.3215179443359375 seconds for one epoch ---
--- 0.5925028324127197 seconds for one epoch ---
--- 0.31208086013793945 seconds for one epoch ---
--- 0.5933058261871338 seconds for one epoch ---
--- 0.33309221267700195 seconds for one epoch ---
--- 0.6229441165924072 seconds for one epoch ---
--- 0.3189210891723633 seconds for one epoch ---
--- 0.6146881580352783 seconds for one epoch ---
--- 0.32808852195739746 seconds for one epoch ---
--- 0.5898854732513428 seconds for one epoch ---
--- 0.31882524490356445 seconds for one epoch ---
=========================
[[0.10799271]
 [0.        ]
 [0.33539638]
 [0.        ]
 [0.        ]
 [0.6122799 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99828815]
 [0.80736786]]
[[-0.7249279]
 [-0.       ]
 [-1.0152599]
 [-0.       ]
 [ 0.       ]
 [-1.2461019]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.446446 ]
 [ 1.4436198]]
--- 0.2640669345855713 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3461.748046875, (1483.0883, 0.9244576, 1976.8774, 0.85796565)
   validation loss 1126.841552734375, (787.8077, 0.13328612, 338.04263, 0.85796565)
decoder loss ratio: 30521.037149, decoder SINDy loss  ratio: 0.729713
--- 0.31932687759399414 seconds for one epoch ---
--- 0.6046621799468994 seconds for one epoch ---
--- 0.3205265998840332 seconds for one epoch ---
--- 0.6040694713592529 seconds for one epoch ---
--- 0.32926416397094727 seconds for one epoch ---
--- 0.591193675994873 seconds for one epoch ---
--- 0.3272213935852051 seconds for one epoch ---
--- 0.6064858436584473 seconds for one epoch ---
--- 0.32090306282043457 seconds for one epoch ---
--- 0.6130590438842773 seconds for one epoch ---
--- 0.3259437084197998 seconds for one epoch ---
--- 0.5959677696228027 seconds for one epoch ---
--- 0.32556843757629395 seconds for one epoch ---
--- 0.6243195533752441 seconds for one epoch ---
--- 0.3219473361968994 seconds for one epoch ---
--- 0.6218676567077637 seconds for one epoch ---
--- 0.33055710792541504 seconds for one epoch ---
--- 0.6296415328979492 seconds for one epoch ---
--- 0.3294064998626709 seconds for one epoch ---
--- 0.6283695697784424 seconds for one epoch ---
--- 0.29471659660339355 seconds for one epoch ---
--- 0.6183657646179199 seconds for one epoch ---
--- 0.3276708126068115 seconds for one epoch ---
--- 0.6160643100738525 seconds for one epoch ---
=========================
[[0.13777393]
 [0.        ]
 [0.27200714]
 [0.        ]
 [0.        ]
 [0.6139151 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99877286]
 [0.8316447 ]]
[[-0.78217125]
 [-0.        ]
 [-0.95460707]
 [-0.        ]
 [ 0.        ]
 [-1.2476083 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5144455 ]
 [ 1.4769734 ]]
--- 0.30422186851501465 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7094.23388671875, (2923.333, 3.2475615, 4166.7935, 0.8597865)
   validation loss 3249.0166015625, (2754.1106, 0.07948016, 493.96664, 0.8597865)
decoder loss ratio: 106699.025824, decoder SINDy loss  ratio: 1.066296
--- 0.26863932609558105 seconds for one epoch ---
--- 0.3209085464477539 seconds for one epoch ---
--- 0.6058433055877686 seconds for one epoch ---
--- 0.3189663887023926 seconds for one epoch ---
--- 0.6138880252838135 seconds for one epoch ---
--- 0.3267059326171875 seconds for one epoch ---
--- 0.6261992454528809 seconds for one epoch ---
--- 0.320310115814209 seconds for one epoch ---
--- 0.633009672164917 seconds for one epoch ---
--- 0.33801794052124023 seconds for one epoch ---
--- 0.6276905536651611 seconds for one epoch ---
--- 0.32689738273620605 seconds for one epoch ---
--- 0.6322581768035889 seconds for one epoch ---
--- 0.3265688419342041 seconds for one epoch ---
--- 0.6205606460571289 seconds for one epoch ---
--- 0.32711315155029297 seconds for one epoch ---
--- 0.6242978572845459 seconds for one epoch ---
--- 0.3443796634674072 seconds for one epoch ---
--- 0.630131721496582 seconds for one epoch ---
--- 0.32381248474121094 seconds for one epoch ---
--- 0.6270649433135986 seconds for one epoch ---
--- 0.3238792419433594 seconds for one epoch ---
--- 0.6509993076324463 seconds for one epoch ---
--- 0.3294546604156494 seconds for one epoch ---
=========================
[[0.15841874]
 [0.        ]
 [0.21265677]
 [0.        ]
 [0.        ]
 [0.59543085]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9989846 ]
 [0.78248197]]
[[-0.81590533]
 [-0.        ]
 [-0.8891227 ]
 [-0.        ]
 [ 0.        ]
 [-1.2320702 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.55329   ]
 [ 1.4128541 ]]
--- 0.26330018043518066 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1895.7579345703125, (1012.12695, 0.59700984, 882.1883, 0.845673)
   validation loss 2502.697998046875, (2108.426, 0.09619267, 393.33014, 0.845673)
decoder loss ratio: 81684.084612, decoder SINDy loss  ratio: 0.849058
--- 0.3198354244232178 seconds for one epoch ---
--- 0.6109302043914795 seconds for one epoch ---
--- 0.32126450538635254 seconds for one epoch ---
--- 0.6207141876220703 seconds for one epoch ---
--- 0.3298521041870117 seconds for one epoch ---
--- 0.6315646171569824 seconds for one epoch ---
--- 0.3176138401031494 seconds for one epoch ---
--- 0.6280710697174072 seconds for one epoch ---
--- 0.3307175636291504 seconds for one epoch ---
--- 0.6251986026763916 seconds for one epoch ---
--- 0.32766151428222656 seconds for one epoch ---
--- 0.6348488330841064 seconds for one epoch ---
--- 0.3192882537841797 seconds for one epoch ---
--- 0.6409773826599121 seconds for one epoch ---
--- 0.3190751075744629 seconds for one epoch ---
--- 0.6327705383300781 seconds for one epoch ---
--- 0.331193208694458 seconds for one epoch ---
--- 0.636530876159668 seconds for one epoch ---
--- 0.33333301544189453 seconds for one epoch ---
--- 0.6379868984222412 seconds for one epoch ---
--- 0.31501126289367676 seconds for one epoch ---
--- 0.640324592590332 seconds for one epoch ---
--- 0.32344579696655273 seconds for one epoch ---
--- 0.6357119083404541 seconds for one epoch ---
=========================
[[0.20062017]
 [0.        ]
 [0.18105501]
 [0.        ]
 [0.        ]
 [0.58658123]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99928474]
 [0.73684186]]
[[-0.8744781]
 [-0.       ]
 [-0.8487987]
 [-0.       ]
 [ 0.       ]
 [-1.2247479]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.6250348]
 [ 1.3622167]]
--- 0.31611204147338867 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5093.07177734375, (2643.5955, 0.9395577, 2447.6997, 0.83745825)
   validation loss 1164.4134521484375, (855.2688, 0.1349451, 308.17233, 0.83745825)
decoder loss ratio: 33134.598079, decoder SINDy loss  ratio: 0.665233
--- 0.2731053829193115 seconds for one epoch ---
--- 0.3206195831298828 seconds for one epoch ---
--- 0.6301164627075195 seconds for one epoch ---
--- 0.32401561737060547 seconds for one epoch ---
--- 0.6454951763153076 seconds for one epoch ---
--- 0.30931949615478516 seconds for one epoch ---
--- 0.6314091682434082 seconds for one epoch ---
--- 0.3315117359161377 seconds for one epoch ---
--- 0.6448957920074463 seconds for one epoch ---
--- 0.32300448417663574 seconds for one epoch ---
--- 0.6483221054077148 seconds for one epoch ---
--- 0.32111525535583496 seconds for one epoch ---
--- 0.6508066654205322 seconds for one epoch ---
--- 0.318950891494751 seconds for one epoch ---
--- 0.6549646854400635 seconds for one epoch ---
--- 0.32756471633911133 seconds for one epoch ---
--- 0.6337318420410156 seconds for one epoch ---
--- 0.3178138732910156 seconds for one epoch ---
--- 0.6351447105407715 seconds for one epoch ---
--- 0.3214535713195801 seconds for one epoch ---
--- 0.6432352066040039 seconds for one epoch ---
--- 0.3311474323272705 seconds for one epoch ---
--- 0.6461849212646484 seconds for one epoch ---
--- 0.32677483558654785 seconds for one epoch ---
=========================
[[0.2385831 ]
 [0.        ]
 [0.15683264]
 [0.        ]
 [0.        ]
 [0.57122874]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9994446 ]
 [0.6634029 ]]
[[-0.91958386]
 [-0.        ]
 [-0.81405735]
 [-0.        ]
 [ 0.        ]
 [-1.2120898 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6768868 ]
 [ 1.2912627 ]]
--- 0.26543521881103516 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5095.20849609375, (3046.8376, 0.3697541, 2047.1694, 0.83168423)
   validation loss 1351.4122314453125, (1007.00226, 0.1543987, 343.42392, 0.83168423)
decoder loss ratio: 39013.015719, decoder SINDy loss  ratio: 0.741329
--- 0.3270578384399414 seconds for one epoch ---
--- 0.6465284824371338 seconds for one epoch ---
--- 0.325610876083374 seconds for one epoch ---
--- 0.6341352462768555 seconds for one epoch ---
--- 0.3367912769317627 seconds for one epoch ---
--- 0.6362369060516357 seconds for one epoch ---
--- 0.3366537094116211 seconds for one epoch ---
--- 0.6473841667175293 seconds for one epoch ---
--- 0.31488609313964844 seconds for one epoch ---
--- 0.6448941230773926 seconds for one epoch ---
--- 0.3242759704589844 seconds for one epoch ---
--- 0.6620326042175293 seconds for one epoch ---
--- 0.32598090171813965 seconds for one epoch ---
--- 0.6494555473327637 seconds for one epoch ---
--- 0.31093811988830566 seconds for one epoch ---
--- 0.6393356323242188 seconds for one epoch ---
--- 0.32315635681152344 seconds for one epoch ---
--- 0.6738467216491699 seconds for one epoch ---
--- 0.3197944164276123 seconds for one epoch ---
--- 0.6543712615966797 seconds for one epoch ---
--- 0.33031678199768066 seconds for one epoch ---
--- 0.6623117923736572 seconds for one epoch ---
--- 0.32009172439575195 seconds for one epoch ---
--- 0.6763262748718262 seconds for one epoch ---
=========================
[[0.27168643]
 [0.        ]
 [0.1291628 ]
 [0.        ]
 [0.        ]
 [0.5388397 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9995629 ]
 [0.62228984]]
[[-0.9549603]
 [-0.       ]
 [-0.7684378]
 [-0.       ]
 [ 0.       ]
 [-1.1856344]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.725824 ]
 [ 1.2550814]]
--- 0.3063020706176758 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3184.506591796875, (1175.5651, 1.3282819, 2006.7968, 0.8167295)
   validation loss 1342.58837890625, (1012.8795, 0.094846725, 328.7972, 0.8167295)
decoder loss ratio: 39240.710909, decoder SINDy loss  ratio: 0.709755
--- 0.2697474956512451 seconds for one epoch ---
--- 0.31589746475219727 seconds for one epoch ---
--- 0.6451003551483154 seconds for one epoch ---
--- 0.3160412311553955 seconds for one epoch ---
--- 0.6556346416473389 seconds for one epoch ---
--- 0.32408857345581055 seconds for one epoch ---
--- 0.6588573455810547 seconds for one epoch ---
--- 0.31665515899658203 seconds for one epoch ---
--- 0.6448183059692383 seconds for one epoch ---
--- 0.3177335262298584 seconds for one epoch ---
--- 0.670112133026123 seconds for one epoch ---
--- 0.32979702949523926 seconds for one epoch ---
--- 0.6548590660095215 seconds for one epoch ---
--- 0.33449816703796387 seconds for one epoch ---
--- 0.6667525768280029 seconds for one epoch ---
--- 0.32314515113830566 seconds for one epoch ---
--- 0.6659092903137207 seconds for one epoch ---
--- 0.32743215560913086 seconds for one epoch ---
--- 0.7011196613311768 seconds for one epoch ---
--- 0.3248274326324463 seconds for one epoch ---
--- 0.6795785427093506 seconds for one epoch ---
--- 0.32501983642578125 seconds for one epoch ---
--- 0.674518346786499 seconds for one epoch ---
--- 0.3256959915161133 seconds for one epoch ---
=========================
[[0.33809182]
 [0.        ]
 [0.09810945]
 [0.        ]
 [0.        ]
 [0.5225657 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99969757]
 [0.6332851 ]]
[[-1.0185429 ]
 [-0.        ]
 [-0.70589817]
 [-0.        ]
 [ 0.        ]
 [-1.1724864 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8013628 ]
 [ 1.2646413 ]]
--- 0.25594592094421387 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3207.858642578125, (1521.3452, 0.48516282, 1685.2073, 0.8209915)
   validation loss 1441.650634765625, (1104.9303, 0.14610028, 335.75317, 0.8209915)
decoder loss ratio: 42806.917982, decoder SINDy loss  ratio: 0.724770
--- 0.3243381977081299 seconds for one epoch ---
--- 0.6708517074584961 seconds for one epoch ---
--- 0.33814454078674316 seconds for one epoch ---
--- 0.6686897277832031 seconds for one epoch ---
--- 0.3241267204284668 seconds for one epoch ---
--- 0.6582770347595215 seconds for one epoch ---
--- 0.3223857879638672 seconds for one epoch ---
--- 0.6813976764678955 seconds for one epoch ---
--- 0.32964611053466797 seconds for one epoch ---
--- 0.6821820735931396 seconds for one epoch ---
--- 0.327120304107666 seconds for one epoch ---
--- 0.6856627464294434 seconds for one epoch ---
--- 0.3281569480895996 seconds for one epoch ---
--- 0.6992204189300537 seconds for one epoch ---
--- 0.31534552574157715 seconds for one epoch ---
--- 0.6719202995300293 seconds for one epoch ---
--- 0.325639009475708 seconds for one epoch ---
--- 0.6959147453308105 seconds for one epoch ---
--- 0.3318045139312744 seconds for one epoch ---
--- 0.7084906101226807 seconds for one epoch ---
--- 0.332308292388916 seconds for one epoch ---
--- 0.6859502792358398 seconds for one epoch ---
--- 0.3145737648010254 seconds for one epoch ---
--- 0.6999266147613525 seconds for one epoch ---
=========================
[[0.3797786 ]
 [0.        ]
 [0.08723688]
 [0.        ]
 [0.        ]
 [0.50021434]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99974674]
 [0.51091546]]
[[-1.0552245]
 [-0.       ]
 [-0.6799264]
 [-0.       ]
 [ 0.       ]
 [-1.1544579]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8381288]
 [ 1.1631061]]
--- 0.30362629890441895 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3774.197509765625, (1463.5364, 1.9319408, 2307.927, 0.8021253)
   validation loss 2111.5166015625, (1778.684, 0.1957063, 331.83472, 0.8021253)
decoder loss ratio: 68909.304540, decoder SINDy loss  ratio: 0.716312
--- 0.25704526901245117 seconds for one epoch ---
--- 0.3299999237060547 seconds for one epoch ---
--- 0.6880881786346436 seconds for one epoch ---
--- 0.3075573444366455 seconds for one epoch ---
--- 0.6739456653594971 seconds for one epoch ---
--- 0.33125925064086914 seconds for one epoch ---
--- 0.6811466217041016 seconds for one epoch ---
--- 0.32032179832458496 seconds for one epoch ---
--- 0.6840386390686035 seconds for one epoch ---
--- 0.32950544357299805 seconds for one epoch ---
--- 0.7100086212158203 seconds for one epoch ---
--- 0.3321239948272705 seconds for one epoch ---
--- 0.6898641586303711 seconds for one epoch ---
--- 0.4883546829223633 seconds for one epoch ---
--- 0.674271821975708 seconds for one epoch ---
--- 0.3274259567260742 seconds for one epoch ---
--- 0.7119033336639404 seconds for one epoch ---
--- 0.3216989040374756 seconds for one epoch ---
--- 0.7010729312896729 seconds for one epoch ---
--- 0.3210258483886719 seconds for one epoch ---
--- 0.6969141960144043 seconds for one epoch ---
--- 0.31465888023376465 seconds for one epoch ---
--- 0.6808419227600098 seconds for one epoch ---
--- 0.3307466506958008 seconds for one epoch ---
=========================
[[0.46033165]
 [0.        ]
 [0.07431512]
 [0.        ]
 [0.        ]
 [0.5037731 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998262 ]
 [0.44490948]]
[[-1.122213  ]
 [-0.        ]
 [-0.64487445]
 [-0.        ]
 [ 0.        ]
 [-1.1573753 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.915409  ]
 [ 1.1096413 ]]
--- 0.2652781009674072 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3855.677490234375, (1376.3118, 2.0560067, 2476.507, 0.80247146)
   validation loss 1267.5870361328125, (951.93494, 0.29999876, 314.5496, 0.80247146)
decoder loss ratio: 36879.612073, decoder SINDy loss  ratio: 0.679000
--- 0.3290243148803711 seconds for one epoch ---
--- 0.6948935985565186 seconds for one epoch ---
--- 0.3254871368408203 seconds for one epoch ---
--- 0.6763825416564941 seconds for one epoch ---
--- 0.32807469367980957 seconds for one epoch ---
--- 0.7027988433837891 seconds for one epoch ---
--- 0.3113687038421631 seconds for one epoch ---
--- 0.7050309181213379 seconds for one epoch ---
--- 0.334075927734375 seconds for one epoch ---
--- 0.6981620788574219 seconds for one epoch ---
--- 0.3234829902648926 seconds for one epoch ---
--- 0.7053771018981934 seconds for one epoch ---
--- 0.3084838390350342 seconds for one epoch ---
--- 0.7181525230407715 seconds for one epoch ---
--- 0.331437349319458 seconds for one epoch ---
--- 0.7122282981872559 seconds for one epoch ---
--- 0.3256356716156006 seconds for one epoch ---
--- 0.7133805751800537 seconds for one epoch ---
--- 0.31920480728149414 seconds for one epoch ---
--- 0.6871070861816406 seconds for one epoch ---
--- 0.31786251068115234 seconds for one epoch ---
--- 0.70865797996521 seconds for one epoch ---
--- 0.3191244602203369 seconds for one epoch ---
--- 0.736591100692749 seconds for one epoch ---
=========================
[[0.5161037 ]
 [0.        ]
 [0.08053082]
 [0.        ]
 [0.        ]
 [0.4969071 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998596 ]
 [0.34675828]]
[[-1.1673747 ]
 [-0.        ]
 [-0.66270643]
 [-0.        ]
 [ 0.        ]
 [-1.1518614 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9590273 ]
 [ 1.0264921 ]]
--- 0.3018834590911865 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3451.2109375, (2329.8008, 0.26810464, 1120.35, 0.79199266)
   validation loss 1142.1617431640625, (802.38416, 0.108814105, 338.87677, 0.79199266)
decoder loss ratio: 31085.755175, decoder SINDy loss  ratio: 0.731513
--- 0.28001928329467773 seconds for one epoch ---
--- 0.3230431079864502 seconds for one epoch ---
--- 0.6974058151245117 seconds for one epoch ---
--- 0.3278985023498535 seconds for one epoch ---
--- 0.7005996704101562 seconds for one epoch ---
--- 0.32564544677734375 seconds for one epoch ---
--- 0.7070062160491943 seconds for one epoch ---
--- 0.33417630195617676 seconds for one epoch ---
--- 0.7002956867218018 seconds for one epoch ---
--- 0.33179616928100586 seconds for one epoch ---
--- 0.7209937572479248 seconds for one epoch ---
--- 0.3003988265991211 seconds for one epoch ---
--- 0.7190237045288086 seconds for one epoch ---
--- 0.3143301010131836 seconds for one epoch ---
--- 0.7118549346923828 seconds for one epoch ---
--- 0.32721877098083496 seconds for one epoch ---
--- 0.7043602466583252 seconds for one epoch ---
--- 0.3248450756072998 seconds for one epoch ---
--- 0.7288684844970703 seconds for one epoch ---
--- 0.3246471881866455 seconds for one epoch ---
--- 0.7164301872253418 seconds for one epoch ---
--- 0.3193333148956299 seconds for one epoch ---
--- 0.7299695014953613 seconds for one epoch ---
--- 0.31714725494384766 seconds for one epoch ---
=========================
[[0.58128655]
 [0.        ]
 [0.07657202]
 [0.        ]
 [0.        ]
 [0.47079065]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998991 ]
 [0.25204602]]
[[-1.2206551]
 [-0.       ]
 [-0.65184  ]
 [-0.       ]
 [ 0.       ]
 [-1.1307697]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.028517 ]
 [ 0.9348414]]
--- 0.26944613456726074 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4118.3642578125, (2192.1746, 0.24678557, 1925.1696, 0.7735359)
   validation loss 1424.540771484375, (1091.6233, 0.17087415, 331.97302, 0.7735359)
decoder loss ratio: 42291.381435, decoder SINDy loss  ratio: 0.716610
--- 0.31678032875061035 seconds for one epoch ---
--- 0.6958129405975342 seconds for one epoch ---
--- 0.3262476921081543 seconds for one epoch ---
--- 0.7207634449005127 seconds for one epoch ---
--- 0.32582783699035645 seconds for one epoch ---
--- 0.6960792541503906 seconds for one epoch ---
--- 0.3210928440093994 seconds for one epoch ---
--- 0.6951260566711426 seconds for one epoch ---
--- 0.32476091384887695 seconds for one epoch ---
--- 0.7201666831970215 seconds for one epoch ---
--- 0.3381221294403076 seconds for one epoch ---
--- 0.7185380458831787 seconds for one epoch ---
--- 0.3357417583465576 seconds for one epoch ---
--- 0.7077689170837402 seconds for one epoch ---
--- 0.3210182189941406 seconds for one epoch ---
--- 0.7425186634063721 seconds for one epoch ---
--- 0.32187867164611816 seconds for one epoch ---
--- 0.729337215423584 seconds for one epoch ---
--- 0.32341885566711426 seconds for one epoch ---
--- 0.7196018695831299 seconds for one epoch ---
--- 0.3332054615020752 seconds for one epoch ---
--- 0.7056581974029541 seconds for one epoch ---
--- 0.3233981132507324 seconds for one epoch ---
--- 0.7429683208465576 seconds for one epoch ---
=========================
[[0.6638701 ]
 [0.        ]
 [0.07033811]
 [0.        ]
 [0.        ]
 [0.48228252]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999304 ]
 [0.19610563]]
[[-1.2919139 ]
 [-0.        ]
 [-0.63348395]
 [-0.        ]
 [ 0.        ]
 [-1.1400971 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1081872 ]
 [ 0.8697172 ]]
--- 0.30385398864746094 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1938.1182861328125, (1032.8704, 0.69745016, 903.7718, 0.77862555)
   validation loss 830.8483276367188, (517.26715, 0.20981543, 312.59268, 0.77862555)
decoder loss ratio: 20039.827440, decoder SINDy loss  ratio: 0.674775
THRESHOLDING: 4 active coefficients
--- 0.7292680740356445 seconds for one epoch ---
--- 0.3278992176055908 seconds for one epoch ---
--- 0.7337327003479004 seconds for one epoch ---
--- 0.3204970359802246 seconds for one epoch ---
--- 0.7549283504486084 seconds for one epoch ---
--- 0.3392653465270996 seconds for one epoch ---
--- 0.72835373878479 seconds for one epoch ---
--- 0.33107614517211914 seconds for one epoch ---
--- 0.7202448844909668 seconds for one epoch ---
--- 0.3231668472290039 seconds for one epoch ---
--- 0.7295489311218262 seconds for one epoch ---
--- 0.33241963386535645 seconds for one epoch ---
--- 0.7317869663238525 seconds for one epoch ---
--- 0.317610502243042 seconds for one epoch ---
--- 0.7245533466339111 seconds for one epoch ---
--- 0.3207435607910156 seconds for one epoch ---
--- 0.7244722843170166 seconds for one epoch ---
--- 0.3358325958251953 seconds for one epoch ---
--- 0.7361502647399902 seconds for one epoch ---
--- 0.3285491466522217 seconds for one epoch ---
--- 0.74456787109375 seconds for one epoch ---
--- 0.3340482711791992 seconds for one epoch ---
--- 0.7344248294830322 seconds for one epoch ---
--- 0.3404412269592285 seconds for one epoch ---
=========================
[[0.67031014]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40093306]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994254]
 [0.16382802]]
[[-1.2977911]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0733663]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1464553]
 [ 0.825569 ]]
--- 0.265383243560791 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3544.89453125, (1319.9633, 1.5629737, 2222.6738, 0.6943237)
   validation loss 1696.9134521484375, (1382.2847, 0.19548443, 313.739, 0.6943237)
decoder loss ratio: 53552.107789, decoder SINDy loss  ratio: 0.677250
--- 0.3084735870361328 seconds for one epoch ---
--- 0.7222604751586914 seconds for one epoch ---
--- 0.32401347160339355 seconds for one epoch ---
--- 0.7285692691802979 seconds for one epoch ---
--- 0.33822107315063477 seconds for one epoch ---
--- 0.7325437068939209 seconds for one epoch ---
--- 0.3283846378326416 seconds for one epoch ---
--- 0.730903148651123 seconds for one epoch ---
--- 0.3103773593902588 seconds for one epoch ---
--- 0.7303216457366943 seconds for one epoch ---
--- 0.3286244869232178 seconds for one epoch ---
--- 0.7401607036590576 seconds for one epoch ---
--- 0.3372213840484619 seconds for one epoch ---
--- 0.739633321762085 seconds for one epoch ---
--- 0.33298397064208984 seconds for one epoch ---
--- 0.750622034072876 seconds for one epoch ---
--- 0.3296372890472412 seconds for one epoch ---
--- 0.761601448059082 seconds for one epoch ---
--- 0.32702112197875977 seconds for one epoch ---
--- 0.7369785308837891 seconds for one epoch ---
--- 0.33047962188720703 seconds for one epoch ---
--- 0.7567777633666992 seconds for one epoch ---
--- 0.3251314163208008 seconds for one epoch ---
--- 0.7577197551727295 seconds for one epoch ---
=========================
[[0.71450716]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3629446 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999554 ]
 [0.12988728]]
[[-1.3398099]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0408928]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2081652]
 [ 0.7707956]]
--- 0.3003230094909668 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2346.5263671875, (1384.3438, 1.5216409, 959.9768, 0.68418163)
   validation loss 1266.6378173828125, (874.7959, 0.13138193, 391.02634, 0.68418163)
decoder loss ratio: 33891.111818, decoder SINDy loss  ratio: 0.844085
--- 0.27576279640197754 seconds for one epoch ---
--- 0.31688976287841797 seconds for one epoch ---
--- 0.7291123867034912 seconds for one epoch ---
--- 0.3189542293548584 seconds for one epoch ---
--- 0.7487637996673584 seconds for one epoch ---
--- 0.3231940269470215 seconds for one epoch ---
--- 0.7640683650970459 seconds for one epoch ---
--- 0.31888747215270996 seconds for one epoch ---
--- 0.7659335136413574 seconds for one epoch ---
--- 0.33408308029174805 seconds for one epoch ---
--- 0.751448392868042 seconds for one epoch ---
--- 0.3295705318450928 seconds for one epoch ---
--- 0.7711150646209717 seconds for one epoch ---
--- 0.32312440872192383 seconds for one epoch ---
--- 0.7690286636352539 seconds for one epoch ---
--- 0.31261420249938965 seconds for one epoch ---
--- 0.7615926265716553 seconds for one epoch ---
--- 0.32488226890563965 seconds for one epoch ---
--- 0.7763311862945557 seconds for one epoch ---
--- 0.32565832138061523 seconds for one epoch ---
--- 0.7463769912719727 seconds for one epoch ---
--- 0.3364377021789551 seconds for one epoch ---
--- 0.7507643699645996 seconds for one epoch ---
--- 0.3166966438293457 seconds for one epoch ---
=========================
[[0.73867893]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33995864]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999635 ]
 [0.12386727]]
[[-1.3644366 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0205635 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2368026 ]
 [ 0.75990075]]
--- 0.26366448402404785 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2902.431884765625, (1155.9093, 0.52383, 1745.3145, 0.6843323)
   validation loss 895.49560546875, (555.27747, 0.12912054, 339.40466, 0.6843323)
decoder loss ratio: 21512.413030, decoder SINDy loss  ratio: 0.732653
--- 0.3336765766143799 seconds for one epoch ---
--- 0.7511765956878662 seconds for one epoch ---
--- 0.32804155349731445 seconds for one epoch ---
--- 0.7688145637512207 seconds for one epoch ---
--- 0.33351612091064453 seconds for one epoch ---
--- 0.7877779006958008 seconds for one epoch ---
--- 0.326430082321167 seconds for one epoch ---
--- 0.7738955020904541 seconds for one epoch ---
--- 0.32912516593933105 seconds for one epoch ---
--- 0.7697718143463135 seconds for one epoch ---
--- 0.3228461742401123 seconds for one epoch ---
--- 0.7889556884765625 seconds for one epoch ---
--- 0.3310425281524658 seconds for one epoch ---
--- 0.7740018367767334 seconds for one epoch ---
--- 0.3423464298248291 seconds for one epoch ---
--- 0.7661693096160889 seconds for one epoch ---
--- 0.3334949016571045 seconds for one epoch ---
--- 0.7621479034423828 seconds for one epoch ---
--- 0.3232901096343994 seconds for one epoch ---
--- 0.7717158794403076 seconds for one epoch ---
--- 0.3262453079223633 seconds for one epoch ---
--- 0.7602248191833496 seconds for one epoch ---
--- 0.32666850090026855 seconds for one epoch ---
--- 0.7857756614685059 seconds for one epoch ---
=========================
[[0.7777355 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33699286]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999665 ]
 [0.10863545]]
[[-1.4076076]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0179098]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2763653]
 [ 0.7300362]]
--- 0.2987499237060547 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2609.687255859375, (1433.6641, 1.8809998, 1173.4592, 0.6829173)
   validation loss 1235.026123046875, (769.0854, 0.28186092, 464.976, 0.6829173)
decoder loss ratio: 29795.703129, decoder SINDy loss  ratio: 1.003716
--- 0.27826929092407227 seconds for one epoch ---
--- 0.32848548889160156 seconds for one epoch ---
--- 0.7726340293884277 seconds for one epoch ---
--- 0.33849549293518066 seconds for one epoch ---
--- 0.7705285549163818 seconds for one epoch ---
--- 0.3247661590576172 seconds for one epoch ---
--- 0.7770142555236816 seconds for one epoch ---
--- 0.31247401237487793 seconds for one epoch ---
--- 0.790499210357666 seconds for one epoch ---
--- 0.3262753486633301 seconds for one epoch ---
--- 0.771235466003418 seconds for one epoch ---
--- 0.3252403736114502 seconds for one epoch ---
--- 0.7637956142425537 seconds for one epoch ---
--- 0.3236277103424072 seconds for one epoch ---
--- 0.7689938545227051 seconds for one epoch ---
--- 0.32409095764160156 seconds for one epoch ---
--- 0.7682802677154541 seconds for one epoch ---
--- 0.32340145111083984 seconds for one epoch ---
--- 0.7857162952423096 seconds for one epoch ---
--- 0.326155424118042 seconds for one epoch ---
--- 0.783940315246582 seconds for one epoch ---
--- 0.3295481204986572 seconds for one epoch ---
--- 0.7658851146697998 seconds for one epoch ---
--- 0.3154575824737549 seconds for one epoch ---
=========================
[[0.8234595 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32474467]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999751 ]
 [0.08549736]]
[[-1.4657744 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.0067668 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.3502028 ]
 [ 0.67667276]]
--- 0.2723255157470703 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2830.57470703125, (1400.227, 0.37183326, 1429.2947, 0.68121165)
   validation loss 1237.2852783203125, (906.6707, 0.107135095, 329.82632, 0.68121165)
decoder loss ratio: 35125.997562, decoder SINDy loss  ratio: 0.711977
--- 0.3167877197265625 seconds for one epoch ---
--- 0.7556865215301514 seconds for one epoch ---
--- 0.3236250877380371 seconds for one epoch ---
--- 0.775921106338501 seconds for one epoch ---
--- 0.3284914493560791 seconds for one epoch ---
--- 0.7775647640228271 seconds for one epoch ---
--- 0.32266855239868164 seconds for one epoch ---
--- 0.7753772735595703 seconds for one epoch ---
--- 0.3246016502380371 seconds for one epoch ---
--- 0.7760341167449951 seconds for one epoch ---
--- 0.31766843795776367 seconds for one epoch ---
--- 0.788602352142334 seconds for one epoch ---
--- 0.3264138698577881 seconds for one epoch ---
--- 0.7873542308807373 seconds for one epoch ---
--- 0.32306385040283203 seconds for one epoch ---
--- 0.7475128173828125 seconds for one epoch ---
--- 0.32596731185913086 seconds for one epoch ---
--- 0.7836742401123047 seconds for one epoch ---
--- 0.32175564765930176 seconds for one epoch ---
--- 0.7842268943786621 seconds for one epoch ---
--- 0.3192267417907715 seconds for one epoch ---
--- 0.7911739349365234 seconds for one epoch ---
--- 0.3398559093475342 seconds for one epoch ---
--- 0.8040614128112793 seconds for one epoch ---
=========================
[[0.839705  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30944067]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998033]
 [0.06823967]]
[[-1.4892731 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.9925251 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.3740566 ]
 [ 0.62754744]]
--- 0.3093743324279785 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5460.5908203125, (1360.223, 4.536489, 4095.1602, 0.6706646)
   validation loss 1282.6629638671875, (988.34796, 0.23399514, 293.4103, 0.6706646)
decoder loss ratio: 38290.315873, decoder SINDy loss  ratio: 0.633367
--- 0.275160551071167 seconds for one epoch ---
--- 0.32657480239868164 seconds for one epoch ---
--- 0.774939775466919 seconds for one epoch ---
--- 0.310870885848999 seconds for one epoch ---
--- 0.7613561153411865 seconds for one epoch ---
--- 0.3225588798522949 seconds for one epoch ---
--- 0.7790877819061279 seconds for one epoch ---
--- 0.32019615173339844 seconds for one epoch ---
--- 0.7945437431335449 seconds for one epoch ---
--- 0.33853912353515625 seconds for one epoch ---
--- 0.7802226543426514 seconds for one epoch ---
--- 0.3213338851928711 seconds for one epoch ---
--- 0.7918701171875 seconds for one epoch ---
--- 0.32115721702575684 seconds for one epoch ---
--- 0.7926206588745117 seconds for one epoch ---
--- 0.3161051273345947 seconds for one epoch ---
--- 0.8219237327575684 seconds for one epoch ---
--- 0.31404972076416016 seconds for one epoch ---
--- 0.7868576049804688 seconds for one epoch ---
--- 0.3168985843658447 seconds for one epoch ---
--- 0.7953944206237793 seconds for one epoch ---
--- 0.31734681129455566 seconds for one epoch ---
--- 0.7873492240905762 seconds for one epoch ---
--- 0.325120210647583 seconds for one epoch ---
=========================
[[0.8766978 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32274938]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998397]
 [0.07008983]]
[[-1.5511284 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.0049556 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.4300666 ]
 [ 0.63339585]]
--- 0.2637941837310791 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3735.015869140625, (1588.4885, 0.7285812, 2145.1182, 0.68037677)
   validation loss 1394.881103515625, (1065.1862, 0.24036103, 328.77414, 0.68037677)
decoder loss ratio: 41267.160975, decoder SINDy loss  ratio: 0.709705
--- 0.3158581256866455 seconds for one epoch ---
--- 0.794975757598877 seconds for one epoch ---
--- 0.32019639015197754 seconds for one epoch ---
--- 0.7692670822143555 seconds for one epoch ---
--- 0.3197779655456543 seconds for one epoch ---
--- 0.7890152931213379 seconds for one epoch ---
--- 0.3377106189727783 seconds for one epoch ---
--- 0.792776346206665 seconds for one epoch ---
--- 0.32570576667785645 seconds for one epoch ---
--- 0.8027677536010742 seconds for one epoch ---
--- 0.3303213119506836 seconds for one epoch ---
--- 0.8061110973358154 seconds for one epoch ---
--- 0.3196535110473633 seconds for one epoch ---
--- 0.8155789375305176 seconds for one epoch ---
--- 0.3187544345855713 seconds for one epoch ---
--- 0.8093900680541992 seconds for one epoch ---
--- 0.3185923099517822 seconds for one epoch ---
--- 0.7983312606811523 seconds for one epoch ---
--- 0.3263425827026367 seconds for one epoch ---
--- 0.830230712890625 seconds for one epoch ---
--- 0.3139498233795166 seconds for one epoch ---
--- 0.7904665470123291 seconds for one epoch ---
--- 0.33843183517456055 seconds for one epoch ---
--- 0.8124876022338867 seconds for one epoch ---
=========================
[[0.89394855]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29739174]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999843 ]
 [0.06211431]]
[[-1.5856078 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.9810529 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.4763649 ]
 [ 0.60740316]]
--- 0.3105475902557373 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3442.721435546875, (1434.7646, 2.4507399, 2004.8324, 0.67358017)
   validation loss 1481.6654052734375, (1148.6255, 0.16866864, 332.19766, 0.67358017)
decoder loss ratio: 44499.745518, decoder SINDy loss  ratio: 0.717095
--- 0.26904821395874023 seconds for one epoch ---
--- 0.32137036323547363 seconds for one epoch ---
--- 0.8013668060302734 seconds for one epoch ---
--- 0.3141040802001953 seconds for one epoch ---
--- 0.8040502071380615 seconds for one epoch ---
--- 0.3266143798828125 seconds for one epoch ---
--- 0.8058154582977295 seconds for one epoch ---
--- 0.31028032302856445 seconds for one epoch ---
--- 0.7875421047210693 seconds for one epoch ---
--- 0.3109428882598877 seconds for one epoch ---
--- 0.798407793045044 seconds for one epoch ---
--- 0.31899452209472656 seconds for one epoch ---
--- 0.8217935562133789 seconds for one epoch ---
--- 0.33579349517822266 seconds for one epoch ---
--- 0.8220150470733643 seconds for one epoch ---
--- 0.3226649761199951 seconds for one epoch ---
--- 0.8040475845336914 seconds for one epoch ---
--- 0.32202577590942383 seconds for one epoch ---
--- 0.8160536289215088 seconds for one epoch ---
--- 0.3270902633666992 seconds for one epoch ---
--- 0.8166115283966064 seconds for one epoch ---
--- 0.33245348930358887 seconds for one epoch ---
--- 0.8014264106750488 seconds for one epoch ---
--- 0.32568955421447754 seconds for one epoch ---
=========================
[[0.9135962 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29229146]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998903]
 [0.06255413]]
[[-1.6315273]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.976117 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.521433 ]
 [ 0.6089677]]
--- 0.25496506690979004 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2972.453125, (1290.2885, 1.2498219, 1680.2385, 0.6762859)
   validation loss 1248.0234375, (927.4344, 0.17170891, 319.74115, 0.6762859)
decoder loss ratio: 35930.418257, decoder SINDy loss  ratio: 0.690206
--- 0.32246899604797363 seconds for one epoch ---
--- 0.8223483562469482 seconds for one epoch ---
--- 0.32120370864868164 seconds for one epoch ---
--- 0.8100509643554688 seconds for one epoch ---
--- 0.3221123218536377 seconds for one epoch ---
--- 0.8091676235198975 seconds for one epoch ---
--- 0.3244454860687256 seconds for one epoch ---
--- 0.8002009391784668 seconds for one epoch ---
--- 0.31865882873535156 seconds for one epoch ---
--- 0.8208770751953125 seconds for one epoch ---
--- 0.3191041946411133 seconds for one epoch ---
--- 0.8425314426422119 seconds for one epoch ---
--- 0.3142061233520508 seconds for one epoch ---
--- 0.8122532367706299 seconds for one epoch ---
--- 0.3218696117401123 seconds for one epoch ---
--- 0.831148624420166 seconds for one epoch ---
--- 0.32065892219543457 seconds for one epoch ---
--- 0.8220252990722656 seconds for one epoch ---
--- 0.31163954734802246 seconds for one epoch ---
--- 0.8332929611206055 seconds for one epoch ---
--- 0.3262641429901123 seconds for one epoch ---
--- 0.8163554668426514 seconds for one epoch ---
--- 0.3251476287841797 seconds for one epoch ---
--- 0.8549988269805908 seconds for one epoch ---
=========================
[[0.9291663 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2837084 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999944 ]
 [0.04873212]]
[[-1.6752284 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.96768594]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.5747097 ]
 [ 0.5558128 ]]
--- 0.30597400665283203 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4943.4599609375, (2137.04, 1.0170081, 2804.7354, 0.6676703)
   validation loss 1148.9884033203125, (797.9984, 0.14890717, 350.17334, 0.6676703)
decoder loss ratio: 30915.843909, decoder SINDy loss  ratio: 0.755898
--- 0.27076292037963867 seconds for one epoch ---
--- 0.31133389472961426 seconds for one epoch ---
--- 0.828460693359375 seconds for one epoch ---
--- 0.32465124130249023 seconds for one epoch ---
--- 0.8086264133453369 seconds for one epoch ---
--- 0.32054948806762695 seconds for one epoch ---
--- 0.8270187377929688 seconds for one epoch ---
--- 0.32743215560913086 seconds for one epoch ---
--- 0.8260345458984375 seconds for one epoch ---
--- 0.32495808601379395 seconds for one epoch ---
--- 0.8426432609558105 seconds for one epoch ---
--- 0.32415223121643066 seconds for one epoch ---
--- 0.8453998565673828 seconds for one epoch ---
--- 0.32834410667419434 seconds for one epoch ---
--- 0.8543789386749268 seconds for one epoch ---
--- 0.3416256904602051 seconds for one epoch ---
--- 0.8245506286621094 seconds for one epoch ---
--- 0.5014393329620361 seconds for one epoch ---
--- 0.8419198989868164 seconds for one epoch ---
--- 0.32374119758605957 seconds for one epoch ---
--- 0.8495256900787354 seconds for one epoch ---
--- 0.3393404483795166 seconds for one epoch ---
--- 0.8309462070465088 seconds for one epoch ---
--- 0.33061885833740234 seconds for one epoch ---
=========================
[[0.9426314 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29278514]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999944 ]
 [0.03559282]]
[[-1.7208978]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9766144]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.6063716]
 [ 0.4898852]]
--- 0.2558431625366211 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3458.189208984375, (1327.5448, 0.48885608, 2129.4907, 0.66471714)
   validation loss 1265.463134765625, (954.8137, 0.29398194, 309.69073, 0.66471714)
decoder loss ratio: 36991.141170, decoder SINDy loss  ratio: 0.668511
--- 0.3090953826904297 seconds for one epoch ---
--- 0.8326590061187744 seconds for one epoch ---
--- 0.3217442035675049 seconds for one epoch ---
--- 0.8445498943328857 seconds for one epoch ---
--- 0.31998276710510254 seconds for one epoch ---
--- 0.8254199028015137 seconds for one epoch ---
--- 0.3260622024536133 seconds for one epoch ---
--- 0.8414294719696045 seconds for one epoch ---
--- 0.3228449821472168 seconds for one epoch ---
--- 0.8472490310668945 seconds for one epoch ---
--- 0.3185114860534668 seconds for one epoch ---
--- 0.836054801940918 seconds for one epoch ---
--- 0.3149707317352295 seconds for one epoch ---
--- 0.8328986167907715 seconds for one epoch ---
--- 0.3212904930114746 seconds for one epoch ---
--- 0.8645563125610352 seconds for one epoch ---
--- 0.3384208679199219 seconds for one epoch ---
--- 0.8105731010437012 seconds for one epoch ---
--- 0.32953572273254395 seconds for one epoch ---
--- 0.848944902420044 seconds for one epoch ---
--- 0.3191492557525635 seconds for one epoch ---
--- 0.8484518527984619 seconds for one epoch ---
--- 0.31815409660339355 seconds for one epoch ---
--- 0.8786954879760742 seconds for one epoch ---
=========================
[[0.948874  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27658775]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999943 ]
 [0.03138711]]
[[-1.7456025 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.96058226]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6337302 ]
 [ 0.4637661 ]]
--- 0.31072998046875 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6730.0478515625, (3008.741, 1.7324278, 3718.9148, 0.65945476)
   validation loss 831.6762084960938, (549.433, 0.2575596, 281.32614, 0.65945476)
decoder loss ratio: 21285.987634, decoder SINDy loss  ratio: 0.607282
--- 0.2665975093841553 seconds for one epoch ---
--- 0.32213306427001953 seconds for one epoch ---
--- 0.8173384666442871 seconds for one epoch ---
--- 0.32378697395324707 seconds for one epoch ---
--- 0.8286373615264893 seconds for one epoch ---
--- 0.3220386505126953 seconds for one epoch ---
--- 0.8616812229156494 seconds for one epoch ---
--- 0.32378053665161133 seconds for one epoch ---
--- 0.8318731784820557 seconds for one epoch ---
--- 0.3213176727294922 seconds for one epoch ---
--- 0.8592081069946289 seconds for one epoch ---
--- 0.32692813873291016 seconds for one epoch ---
--- 0.8452215194702148 seconds for one epoch ---
--- 0.32409119606018066 seconds for one epoch ---
--- 0.8638739585876465 seconds for one epoch ---
--- 0.3222792148590088 seconds for one epoch ---
--- 0.8440747261047363 seconds for one epoch ---
--- 0.3273148536682129 seconds for one epoch ---
--- 0.8679356575012207 seconds for one epoch ---
--- 0.31742024421691895 seconds for one epoch ---
--- 0.8703439235687256 seconds for one epoch ---
--- 0.32144689559936523 seconds for one epoch ---
--- 0.8624687194824219 seconds for one epoch ---
--- 0.3075428009033203 seconds for one epoch ---
=========================
[[0.9542488 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28203416]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999942 ]
 [0.02175892]]
[[-1.7692829 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.9660431 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6364326 ]
 [ 0.38814312]]
--- 0.27160191535949707 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3634.402587890625, (1840.5319, 2.739641, 1790.4802, 0.6507862)
   validation loss 1002.72607421875, (711.5592, 0.18466468, 290.33145, 0.6507862)
decoder loss ratio: 27567.038888, decoder SINDy loss  ratio: 0.626721
--- 0.3168823719024658 seconds for one epoch ---
--- 0.8701238632202148 seconds for one epoch ---
--- 0.31557536125183105 seconds for one epoch ---
--- 0.8812563419342041 seconds for one epoch ---
--- 0.3114585876464844 seconds for one epoch ---
--- 0.8665332794189453 seconds for one epoch ---
--- 0.32932019233703613 seconds for one epoch ---
--- 0.8718979358673096 seconds for one epoch ---
--- 0.3231625556945801 seconds for one epoch ---
--- 0.8575704097747803 seconds for one epoch ---
--- 0.3319704532623291 seconds for one epoch ---
--- 0.8983922004699707 seconds for one epoch ---
--- 0.3126823902130127 seconds for one epoch ---
--- 0.8532993793487549 seconds for one epoch ---
--- 0.33577799797058105 seconds for one epoch ---
--- 0.8790225982666016 seconds for one epoch ---
--- 0.3211476802825928 seconds for one epoch ---
--- 0.8598742485046387 seconds for one epoch ---
--- 0.32655930519104004 seconds for one epoch ---
--- 0.8563239574432373 seconds for one epoch ---
--- 0.3291959762573242 seconds for one epoch ---
--- 0.8516755104064941 seconds for one epoch ---
--- 0.334583044052124 seconds for one epoch ---
--- 0.8853940963745117 seconds for one epoch ---
=========================
[[0.96066433]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2901506 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999941 ]
 [0.01743966]]
[[-1.8013014 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.9740594 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6446283 ]
 [ 0.34281838]]
--- 0.3096308708190918 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2690.793212890625, (1461.5624, 1.2883768, 1227.2941, 0.64839906)
   validation loss 1033.5343017578125, (682.3987, 0.22675797, 350.26047, 0.64839906)
decoder loss ratio: 26437.309623, decoder SINDy loss  ratio: 0.756086
--- 0.268998384475708 seconds for one epoch ---
--- 0.3413960933685303 seconds for one epoch ---
--- 0.841083288192749 seconds for one epoch ---
--- 0.31569981575012207 seconds for one epoch ---
--- 0.8644638061523438 seconds for one epoch ---
--- 0.3291175365447998 seconds for one epoch ---
--- 0.8749520778656006 seconds for one epoch ---
--- 0.33000683784484863 seconds for one epoch ---
--- 0.8687057495117188 seconds for one epoch ---
--- 0.3122248649597168 seconds for one epoch ---
--- 0.8779296875 seconds for one epoch ---
--- 0.3322570323944092 seconds for one epoch ---
--- 0.8683357238769531 seconds for one epoch ---
--- 0.315793514251709 seconds for one epoch ---
--- 0.8906834125518799 seconds for one epoch ---
--- 0.3181953430175781 seconds for one epoch ---
--- 0.876807451248169 seconds for one epoch ---
--- 0.31414294242858887 seconds for one epoch ---
--- 0.8743433952331543 seconds for one epoch ---
--- 0.32753562927246094 seconds for one epoch ---
--- 0.8964076042175293 seconds for one epoch ---
--- 0.32324719429016113 seconds for one epoch ---
--- 0.885462760925293 seconds for one epoch ---
--- 0.31674695014953613 seconds for one epoch ---
=========================
[[0.9628537 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27047372]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999941 ]
 [0.01353556]]
[[-1.8133831 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.95439637]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6498954 ]
 [ 0.29113114]]
--- 0.27408814430236816 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4182.443359375, (2183.4812, 0.94925135, 1997.3732, 0.63968915)
   validation loss 994.5222778320312, (710.51874, 0.20570397, 283.1581, 0.63968915)
decoder loss ratio: 27526.729417, decoder SINDy loss  ratio: 0.611237
--- 0.3168792724609375 seconds for one epoch ---
--- 0.8865292072296143 seconds for one epoch ---
--- 0.3213319778442383 seconds for one epoch ---
--- 0.8771986961364746 seconds for one epoch ---
--- 0.3237888813018799 seconds for one epoch ---
--- 0.8678805828094482 seconds for one epoch ---
--- 0.3160820007324219 seconds for one epoch ---
--- 0.8999850749969482 seconds for one epoch ---
--- 0.33028221130371094 seconds for one epoch ---
--- 0.8845789432525635 seconds for one epoch ---
--- 0.32364559173583984 seconds for one epoch ---
--- 0.87998366355896 seconds for one epoch ---
--- 0.32578396797180176 seconds for one epoch ---
--- 0.8947243690490723 seconds for one epoch ---
--- 0.3251609802246094 seconds for one epoch ---
--- 0.8937375545501709 seconds for one epoch ---
--- 0.31694459915161133 seconds for one epoch ---
--- 0.8914773464202881 seconds for one epoch ---
--- 0.3163590431213379 seconds for one epoch ---
--- 0.9114985466003418 seconds for one epoch ---
--- 0.3170154094696045 seconds for one epoch ---
--- 0.890143632888794 seconds for one epoch ---
--- 0.3200061321258545 seconds for one epoch ---
--- 0.9029831886291504 seconds for one epoch ---
=========================
[[0.9672762 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2726189 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999994  ]
 [0.00910664]]
[[-1.8400406 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.95658576]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6596274 ]
 [ 0.2105947 ]]
--- 0.29698801040649414 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2533.703125, (1004.4718, 0.8490833, 1527.7493, 0.6329931)
   validation loss 1597.377197265625, (1250.2875, 0.16978161, 346.28702, 0.6329931)
decoder loss ratio: 48438.307399, decoder SINDy loss  ratio: 0.747509
--- 0.277010440826416 seconds for one epoch ---
--- 0.3251149654388428 seconds for one epoch ---
--- 0.9024937152862549 seconds for one epoch ---
--- 0.31117773056030273 seconds for one epoch ---
--- 0.8738250732421875 seconds for one epoch ---
--- 0.3325061798095703 seconds for one epoch ---
--- 0.8724567890167236 seconds for one epoch ---
--- 0.3245270252227783 seconds for one epoch ---
--- 0.9092762470245361 seconds for one epoch ---
--- 0.3163106441497803 seconds for one epoch ---
--- 0.881688117980957 seconds for one epoch ---
--- 0.3194236755371094 seconds for one epoch ---
--- 0.9142651557922363 seconds for one epoch ---
--- 0.31946420669555664 seconds for one epoch ---
--- 0.9225451946258545 seconds for one epoch ---
--- 0.32193422317504883 seconds for one epoch ---
--- 0.9251375198364258 seconds for one epoch ---
--- 0.3204660415649414 seconds for one epoch ---
--- 0.9061880111694336 seconds for one epoch ---
--- 0.3252286911010742 seconds for one epoch ---
--- 0.9235970973968506 seconds for one epoch ---
--- 0.32227039337158203 seconds for one epoch ---
--- 0.8966789245605469 seconds for one epoch ---
--- 0.31621575355529785 seconds for one epoch ---
=========================
[[0.9740882 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.26645023]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999939 ]
 [0.00852547]]
[[-1.8888532 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.9502746 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7125096 ]
 [ 0.19732083]]
--- 0.25905799865722656 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4146.73583984375, (1292.7377, 3.4473894, 2849.92, 0.63082147)
   validation loss 1678.29833984375, (1328.5746, 0.17210132, 348.92075, 0.63082147)
decoder loss ratio: 51471.285928, decoder SINDy loss  ratio: 0.753195
--- 0.3134465217590332 seconds for one epoch ---
--- 0.9016733169555664 seconds for one epoch ---
--- 0.3301432132720947 seconds for one epoch ---
--- 0.9211561679840088 seconds for one epoch ---
--- 0.332378625869751 seconds for one epoch ---
--- 0.9028048515319824 seconds for one epoch ---
--- 0.3354613780975342 seconds for one epoch ---
--- 0.8959243297576904 seconds for one epoch ---
--- 0.31885671615600586 seconds for one epoch ---
--- 0.9006011486053467 seconds for one epoch ---
--- 0.3194613456726074 seconds for one epoch ---
--- 0.8992152214050293 seconds for one epoch ---
--- 0.3182218074798584 seconds for one epoch ---
--- 0.9008388519287109 seconds for one epoch ---
--- 0.3186776638031006 seconds for one epoch ---
--- 0.907813310623169 seconds for one epoch ---
--- 0.3134114742279053 seconds for one epoch ---
--- 0.9245767593383789 seconds for one epoch ---
--- 0.33009839057922363 seconds for one epoch ---
--- 0.9069340229034424 seconds for one epoch ---
--- 0.311323881149292 seconds for one epoch ---
--- 0.9125335216522217 seconds for one epoch ---
--- 0.31789636611938477 seconds for one epoch ---
--- 0.9312472343444824 seconds for one epoch ---
=========================
[[0.9750933 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24846078]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999939 ]
 [0.00715947]]
[[-1.8970983 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.93130666]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.7105148 ]
 [ 0.16202089]]
--- 0.2992117404937744 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3805.504638671875, (1385.9219, 0.5091246, 2418.4497, 0.6237404)
   validation loss 784.5503540039062, (496.56686, 0.2765171, 287.08322, 0.6237404)
decoder loss ratio: 19237.862390, decoder SINDy loss  ratio: 0.619710
--- 0.2771461009979248 seconds for one epoch ---
--- 0.3257467746734619 seconds for one epoch ---
--- 0.9255251884460449 seconds for one epoch ---
--- 0.31894898414611816 seconds for one epoch ---
--- 0.9046258926391602 seconds for one epoch ---
--- 0.3183567523956299 seconds for one epoch ---
--- 0.911494255065918 seconds for one epoch ---
--- 0.32294535636901855 seconds for one epoch ---
--- 0.9149990081787109 seconds for one epoch ---
--- 0.31766414642333984 seconds for one epoch ---
--- 0.9060523509979248 seconds for one epoch ---
--- 0.31835031509399414 seconds for one epoch ---
--- 0.9547643661499023 seconds for one epoch ---
--- 0.31507110595703125 seconds for one epoch ---
--- 0.9079899787902832 seconds for one epoch ---
--- 0.31591033935546875 seconds for one epoch ---
--- 0.9176392555236816 seconds for one epoch ---
--- 0.32826876640319824 seconds for one epoch ---
--- 0.9439418315887451 seconds for one epoch ---
--- 0.3183143138885498 seconds for one epoch ---
--- 0.8886549472808838 seconds for one epoch ---
--- 0.3065786361694336 seconds for one epoch ---
--- 0.9168388843536377 seconds for one epoch ---
--- 0.32095837593078613 seconds for one epoch ---
=========================
[[0.9786275 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2537195 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999374]
 [0.00570885]]
[[-1.9289136 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.9369453 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7253623 ]
 [ 0.11629969]]
--- 0.26831889152526855 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3039.052978515625, (1059.5327, 2.8295186, 1976.0721, 0.6187243)
   validation loss 788.6724853515625, (491.5132, 0.33587337, 296.20468, 0.6187243)
decoder loss ratio: 19042.075219, decoder SINDy loss  ratio: 0.639399
--- 0.3062310218811035 seconds for one epoch ---
--- 0.9079413414001465 seconds for one epoch ---
--- 0.3356170654296875 seconds for one epoch ---
--- 0.9105563163757324 seconds for one epoch ---
--- 0.3289055824279785 seconds for one epoch ---
--- 0.9233183860778809 seconds for one epoch ---
--- 0.339735746383667 seconds for one epoch ---
--- 0.9158437252044678 seconds for one epoch ---
--- 0.332094669342041 seconds for one epoch ---
--- 0.9370591640472412 seconds for one epoch ---
--- 0.34244418144226074 seconds for one epoch ---
--- 0.9272124767303467 seconds for one epoch ---
--- 0.315152645111084 seconds for one epoch ---
--- 0.9194002151489258 seconds for one epoch ---
--- 0.3093428611755371 seconds for one epoch ---
--- 0.9375526905059814 seconds for one epoch ---
--- 0.3149738311767578 seconds for one epoch ---
--- 0.9396908283233643 seconds for one epoch ---
--- 0.3225057125091553 seconds for one epoch ---
--- 0.9489598274230957 seconds for one epoch ---
--- 0.32892417907714844 seconds for one epoch ---
--- 0.936821460723877 seconds for one epoch ---
--- 0.3248929977416992 seconds for one epoch ---
--- 0.9381017684936523 seconds for one epoch ---
=========================
[[0.9801759 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.25871482]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999374]
 [0.00478487]]
[[-1.944513 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9422308]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7151055]
 [ 0.0807113]]
--- 0.29415345191955566 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4111.30615234375, (1732.5004, 0.8291297, 2377.3606, 0.61643934)
   validation loss 947.0880126953125, (663.7694, 0.32878494, 282.37332, 0.61643934)
decoder loss ratio: 25715.579266, decoder SINDy loss  ratio: 0.609543
THRESHOLDING: 3 active coefficients
--- 0.26458048820495605 seconds for one epoch ---
--- 0.3266613483428955 seconds for one epoch ---
--- 0.9287939071655273 seconds for one epoch ---
--- 0.3240077495574951 seconds for one epoch ---
--- 0.9333503246307373 seconds for one epoch ---
--- 0.3251984119415283 seconds for one epoch ---
--- 0.9365544319152832 seconds for one epoch ---
--- 0.31569743156433105 seconds for one epoch ---
--- 0.9379830360412598 seconds for one epoch ---
--- 0.3210015296936035 seconds for one epoch ---
--- 0.9270966053009033 seconds for one epoch ---
--- 0.3113117218017578 seconds for one epoch ---
--- 0.928412675857544 seconds for one epoch ---
--- 0.3248751163482666 seconds for one epoch ---
--- 0.9468827247619629 seconds for one epoch ---
--- 0.3353748321533203 seconds for one epoch ---
--- 0.9534106254577637 seconds for one epoch ---
--- 0.32083606719970703 seconds for one epoch ---
--- 0.9448447227478027 seconds for one epoch ---
--- 0.3124716281890869 seconds for one epoch ---
--- 0.949847936630249 seconds for one epoch ---
--- 0.3280961513519287 seconds for one epoch ---
--- 0.935474157333374 seconds for one epoch ---
--- 0.32421183586120605 seconds for one epoch ---
=========================
[[0.98295474]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2659377 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999937 ]
 [0.        ]]
[[-1.9757793]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9497556]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.7242675]
 [ 0.       ]]
--- 0.2579019069671631 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3423.655029296875, (1325.4125, 4.652216, 2092.9912, 0.59910077)
   validation loss 1049.4693603515625, (685.3469, 0.2509082, 363.27243, 0.59910077)
decoder loss ratio: 26551.529644, decoder SINDy loss  ratio: 0.784175
--- 0.3104257583618164 seconds for one epoch ---
--- 0.9513046741485596 seconds for one epoch ---
--- 0.3345296382904053 seconds for one epoch ---
--- 0.9608139991760254 seconds for one epoch ---
--- 0.31888771057128906 seconds for one epoch ---
--- 0.9451580047607422 seconds for one epoch ---
--- 0.3193240165710449 seconds for one epoch ---
--- 0.9743545055389404 seconds for one epoch ---
--- 0.32064390182495117 seconds for one epoch ---
--- 0.9589345455169678 seconds for one epoch ---
--- 0.32772135734558105 seconds for one epoch ---
--- 0.9516992568969727 seconds for one epoch ---
--- 0.32003235816955566 seconds for one epoch ---
--- 0.9698171615600586 seconds for one epoch ---
--- 0.31738829612731934 seconds for one epoch ---
--- 0.9372673034667969 seconds for one epoch ---
--- 0.3204174041748047 seconds for one epoch ---
--- 0.9440498352050781 seconds for one epoch ---
--- 0.3314528465270996 seconds for one epoch ---
--- 0.9530553817749023 seconds for one epoch ---
--- 0.3234097957611084 seconds for one epoch ---
--- 0.9536888599395752 seconds for one epoch ---
--- 0.3206596374511719 seconds for one epoch ---
--- 0.9428057670593262 seconds for one epoch ---
=========================
[[0.9841417 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24977861]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999935 ]
 [0.        ]]
[[-1.9906919 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.93273586]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7368977 ]
 [ 0.        ]]
--- 0.31444597244262695 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3240.382080078125, (1485.0774, 0.22217092, 1754.487, 0.59546655)
   validation loss 815.7950439453125, (518.4137, 0.22041969, 296.56552, 0.59546655)
decoder loss ratio: 20084.246600, decoder SINDy loss  ratio: 0.640178
--- 0.27266883850097656 seconds for one epoch ---
--- 0.3142697811126709 seconds for one epoch ---
--- 0.948239803314209 seconds for one epoch ---
--- 0.32577061653137207 seconds for one epoch ---
--- 0.9689586162567139 seconds for one epoch ---
--- 0.3273952007293701 seconds for one epoch ---
--- 0.9569752216339111 seconds for one epoch ---
--- 0.3165278434753418 seconds for one epoch ---
--- 0.945178747177124 seconds for one epoch ---
--- 0.32515430450439453 seconds for one epoch ---
--- 0.9560520648956299 seconds for one epoch ---
--- 0.3364427089691162 seconds for one epoch ---
--- 0.9594676494598389 seconds for one epoch ---
--- 0.3345448970794678 seconds for one epoch ---
--- 0.9740312099456787 seconds for one epoch ---
--- 0.32900285720825195 seconds for one epoch ---
--- 0.9572386741638184 seconds for one epoch ---
--- 0.30413317680358887 seconds for one epoch ---
--- 0.949164867401123 seconds for one epoch ---
--- 0.32705187797546387 seconds for one epoch ---
--- 0.9551966190338135 seconds for one epoch ---
--- 0.3210461139678955 seconds for one epoch ---
--- 0.9843518733978271 seconds for one epoch ---
--- 0.32524991035461426 seconds for one epoch ---
=========================
[[0.9861354 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.25149575]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999935 ]
 [0.        ]]
[[-2.0184124]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.9345801]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.74366  ]
 [ 0.       ]]
--- 0.26792287826538086 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2914.77734375, (1630.6825, 1.0730203, 1282.426, 0.5958229)
   validation loss 991.6607666015625, (680.9431, 0.24472295, 309.8771, 0.5958229)
decoder loss ratio: 26380.918453, decoder SINDy loss  ratio: 0.668913
--- 0.31175923347473145 seconds for one epoch ---
--- 0.9863524436950684 seconds for one epoch ---
--- 0.3262646198272705 seconds for one epoch ---
--- 0.9798076152801514 seconds for one epoch ---
--- 0.32700133323669434 seconds for one epoch ---
--- 0.9687404632568359 seconds for one epoch ---
--- 0.33434104919433594 seconds for one epoch ---
--- 0.9776973724365234 seconds for one epoch ---
--- 0.32144808769226074 seconds for one epoch ---
--- 0.9737236499786377 seconds for one epoch ---
--- 0.3189094066619873 seconds for one epoch ---
--- 0.9908745288848877 seconds for one epoch ---
--- 0.3370654582977295 seconds for one epoch ---
--- 0.9823544025421143 seconds for one epoch ---
--- 0.327502965927124 seconds for one epoch ---
--- 0.9821319580078125 seconds for one epoch ---
--- 0.30974435806274414 seconds for one epoch ---
--- 0.9738602638244629 seconds for one epoch ---
--- 0.3249070644378662 seconds for one epoch ---
--- 1.0049443244934082 seconds for one epoch ---
--- 0.32576704025268555 seconds for one epoch ---
--- 0.9739065170288086 seconds for one epoch ---
--- 0.3177306652069092 seconds for one epoch ---
--- 0.9776356220245361 seconds for one epoch ---
=========================
[[0.9874256 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24715182]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999934 ]
 [0.        ]]
[[-2.038536 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9299045]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7472403]
 [ 0.       ]]
--- 0.30225086212158203 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5114.12060546875, (2110.4507, 1.5523363, 3001.523, 0.59479517)
   validation loss 1046.89306640625, (714.72363, 0.20623815, 331.36832, 0.59479517)
decoder loss ratio: 27689.634350, decoder SINDy loss  ratio: 0.715305
--- 0.2733163833618164 seconds for one epoch ---
--- 0.3198659420013428 seconds for one epoch ---
--- 0.9913854598999023 seconds for one epoch ---
--- 0.3347358703613281 seconds for one epoch ---
--- 0.9906225204467773 seconds for one epoch ---
--- 0.3383357524871826 seconds for one epoch ---
--- 0.9866864681243896 seconds for one epoch ---
--- 0.3219587802886963 seconds for one epoch ---
--- 0.9765796661376953 seconds for one epoch ---
--- 0.319476842880249 seconds for one epoch ---
--- 1.0011489391326904 seconds for one epoch ---
--- 0.3226127624511719 seconds for one epoch ---
--- 1.0050818920135498 seconds for one epoch ---
--- 0.31650829315185547 seconds for one epoch ---
--- 1.003321647644043 seconds for one epoch ---
--- 0.330305814743042 seconds for one epoch ---
--- 0.9847433567047119 seconds for one epoch ---
--- 0.33405160903930664 seconds for one epoch ---
--- 0.9921987056732178 seconds for one epoch ---
--- 0.3294353485107422 seconds for one epoch ---
--- 0.987917423248291 seconds for one epoch ---
--- 0.32029104232788086 seconds for one epoch ---
--- 0.9957501888275146 seconds for one epoch ---
--- 0.3224806785583496 seconds for one epoch ---
=========================
[[0.9883529 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.23906475]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999933 ]
 [0.        ]]
[[-2.0543025]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9210492]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.7495685]
 [ 0.       ]]
--- 0.25808191299438477 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2981.4609375, (973.1982, 2.474552, 2005.195, 0.59319866)
   validation loss 1123.7008056640625, (833.50684, 0.19637096, 289.40445, 0.59319866)
decoder loss ratio: 32291.501856, decoder SINDy loss  ratio: 0.624720
--- 0.32056212425231934 seconds for one epoch ---
--- 0.9652278423309326 seconds for one epoch ---
--- 0.33421778678894043 seconds for one epoch ---
--- 0.9732468128204346 seconds for one epoch ---
--- 0.3274271488189697 seconds for one epoch ---
--- 0.9885883331298828 seconds for one epoch ---
--- 0.326810359954834 seconds for one epoch ---
--- 0.96659255027771 seconds for one epoch ---
--- 0.3243107795715332 seconds for one epoch ---
--- 1.001889944076538 seconds for one epoch ---
--- 0.32387828826904297 seconds for one epoch ---
--- 1.0031375885009766 seconds for one epoch ---
--- 0.3269937038421631 seconds for one epoch ---
--- 0.9872744083404541 seconds for one epoch ---
--- 0.3385765552520752 seconds for one epoch ---
--- 1.0021252632141113 seconds for one epoch ---
--- 0.326366662979126 seconds for one epoch ---
--- 0.970221996307373 seconds for one epoch ---
--- 0.31746363639831543 seconds for one epoch ---
--- 1.02254319190979 seconds for one epoch ---
--- 0.3300788402557373 seconds for one epoch ---
--- 1.0060975551605225 seconds for one epoch ---
--- 0.29804182052612305 seconds for one epoch ---
--- 1.0066678524017334 seconds for one epoch ---
=========================
[[0.9895408 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.23686272]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999326]
 [0.        ]]
[[-2.0764234]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9186036]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7554781]
 [ 0.       ]]
--- 0.31333255767822266 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4231.0703125, (1344.9832, 5.614621, 2879.88, 0.59289175)
   validation loss 809.0332641601562, (503.22592, 0.17669773, 305.03775, 0.59289175)
decoder loss ratio: 19495.845843, decoder SINDy loss  ratio: 0.658467
--- 0.2654237747192383 seconds for one epoch ---
--- 0.3159019947052002 seconds for one epoch ---
--- 0.9944300651550293 seconds for one epoch ---
--- 0.32457709312438965 seconds for one epoch ---
--- 0.9882125854492188 seconds for one epoch ---
--- 0.32308006286621094 seconds for one epoch ---
--- 0.978823184967041 seconds for one epoch ---
--- 0.32609987258911133 seconds for one epoch ---
--- 1.0391466617584229 seconds for one epoch ---
--- 0.33009791374206543 seconds for one epoch ---
--- 1.0050990581512451 seconds for one epoch ---
--- 0.32245588302612305 seconds for one epoch ---
--- 0.9968695640563965 seconds for one epoch ---
--- 0.32477402687072754 seconds for one epoch ---
--- 0.9864335060119629 seconds for one epoch ---
--- 0.32753849029541016 seconds for one epoch ---
--- 1.015228033065796 seconds for one epoch ---
--- 0.32512855529785156 seconds for one epoch ---
--- 1.0177903175354004 seconds for one epoch ---
--- 0.30752992630004883 seconds for one epoch ---
--- 1.0048389434814453 seconds for one epoch ---
--- 0.33135175704956055 seconds for one epoch ---
--- 0.9961214065551758 seconds for one epoch ---
--- 0.3148789405822754 seconds for one epoch ---
=========================
[[0.9902241 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22774321]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999315]
 [0.        ]]
[[-2.0903018]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9083009]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.7562232]
 [ 0.       ]]
--- 0.2696225643157959 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3695.51416015625, (1737.4576, 1.624722, 1955.8416, 0.5903684)
   validation loss 1706.380126953125, (1302.6893, 0.122919835, 402.9775, 0.5903684)
decoder loss ratio: 50468.446253, decoder SINDy loss  ratio: 0.869884
--- 0.3240389823913574 seconds for one epoch ---
--- 0.9909307956695557 seconds for one epoch ---
--- 0.32461977005004883 seconds for one epoch ---
--- 1.02744722366333 seconds for one epoch ---
--- 0.3268158435821533 seconds for one epoch ---
--- 0.9635589122772217 seconds for one epoch ---
--- 0.33212733268737793 seconds for one epoch ---
--- 0.9988322257995605 seconds for one epoch ---
--- 0.32774972915649414 seconds for one epoch ---
--- 1.0060276985168457 seconds for one epoch ---
--- 0.31583237648010254 seconds for one epoch ---
--- 1.049032211303711 seconds for one epoch ---
--- 0.3264031410217285 seconds for one epoch ---
--- 1.0321989059448242 seconds for one epoch ---
--- 0.3230762481689453 seconds for one epoch ---
--- 1.030122995376587 seconds for one epoch ---
--- 0.3156015872955322 seconds for one epoch ---
--- 1.003748893737793 seconds for one epoch ---
--- 0.3390159606933594 seconds for one epoch ---
--- 1.0211477279663086 seconds for one epoch ---
--- 0.3292508125305176 seconds for one epoch ---
--- 1.0243313312530518 seconds for one epoch ---
--- 0.32581448554992676 seconds for one epoch ---
--- 1.0329010486602783 seconds for one epoch ---
=========================
[[0.99085045]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2176466 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999993  ]
 [0.        ]]
[[-2.1038885 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.89654964]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7567148 ]
 [ 0.        ]]
--- 0.29401683807373047 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3723.15185546875, (1379.8737, 3.0981634, 2339.5918, 0.5884762)
   validation loss 1516.30712890625, (1102.1765, 0.2936852, 413.24844, 0.5884762)
decoder loss ratio: 42700.231602, decoder SINDy loss  ratio: 0.892055
--- 0.2705988883972168 seconds for one epoch ---
--- 0.3226184844970703 seconds for one epoch ---
--- 1.0285229682922363 seconds for one epoch ---
--- 0.3400909900665283 seconds for one epoch ---
--- 1.0202279090881348 seconds for one epoch ---
--- 0.3291478157043457 seconds for one epoch ---
--- 1.0038666725158691 seconds for one epoch ---
--- 0.30782032012939453 seconds for one epoch ---
--- 1.0406248569488525 seconds for one epoch ---
--- 0.3249967098236084 seconds for one epoch ---
--- 1.0608983039855957 seconds for one epoch ---
--- 0.5508086681365967 seconds for one epoch ---
--- 1.0040767192840576 seconds for one epoch ---
--- 0.3232076168060303 seconds for one epoch ---
--- 1.0268316268920898 seconds for one epoch ---
--- 0.30664920806884766 seconds for one epoch ---
--- 1.0253732204437256 seconds for one epoch ---
--- 0.31986546516418457 seconds for one epoch ---
--- 1.0503911972045898 seconds for one epoch ---
--- 0.315626859664917 seconds for one epoch ---
--- 1.0663132667541504 seconds for one epoch ---
--- 0.32289576530456543 seconds for one epoch ---
--- 1.0492570400238037 seconds for one epoch ---
--- 0.33293938636779785 seconds for one epoch ---
=========================
[[0.99212736]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2328798 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999993  ]
 [0.        ]]
[[-2.134725 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9141412]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7597003]
 [ 0.       ]]
--- 0.26100611686706543 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2809.664794921875, (1191.5834, 1.7346537, 1615.7551, 0.591671)
   validation loss 771.2281494140625, (465.07645, 0.20528796, 305.35477, 0.591671)
decoder loss ratio: 18017.868947, decoder SINDy loss  ratio: 0.659151
--- 0.32783055305480957 seconds for one epoch ---
--- 1.0325536727905273 seconds for one epoch ---
--- 0.3171823024749756 seconds for one epoch ---
--- 1.0488412380218506 seconds for one epoch ---
--- 0.32013559341430664 seconds for one epoch ---
--- 1.0381484031677246 seconds for one epoch ---
--- 0.3278813362121582 seconds for one epoch ---
--- 1.0296692848205566 seconds for one epoch ---
--- 0.321958065032959 seconds for one epoch ---
--- 1.088484287261963 seconds for one epoch ---
--- 0.3146953582763672 seconds for one epoch ---
--- 1.047252893447876 seconds for one epoch ---
--- 0.3230247497558594 seconds for one epoch ---
--- 1.0659189224243164 seconds for one epoch ---
--- 0.32257843017578125 seconds for one epoch ---
--- 1.0628859996795654 seconds for one epoch ---
--- 0.3208131790161133 seconds for one epoch ---
--- 1.059462547302246 seconds for one epoch ---
--- 0.31752943992614746 seconds for one epoch ---
--- 1.043309211730957 seconds for one epoch ---
--- 0.3122832775115967 seconds for one epoch ---
--- 1.0501320362091064 seconds for one epoch ---
--- 0.33488035202026367 seconds for one epoch ---
--- 1.0476255416870117 seconds for one epoch ---
=========================
[[0.99255276]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21243246]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999929 ]
 [0.        ]]
[[-2.1461194]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8903285]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.7699618]
 [ 0.       ]]
--- 0.30843639373779297 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4773.59716796875, (1754.0176, 0.7231586, 3018.2693, 0.58749455)
   validation loss 956.6624755859375, (653.0936, 0.24509448, 302.7362, 0.58749455)
decoder loss ratio: 25301.980966, decoder SINDy loss  ratio: 0.653499
--- 0.27486205101013184 seconds for one epoch ---
--- 0.31548094749450684 seconds for one epoch ---
--- 1.0208063125610352 seconds for one epoch ---
--- 0.3098781108856201 seconds for one epoch ---
--- 1.0264735221862793 seconds for one epoch ---
--- 0.32239508628845215 seconds for one epoch ---
--- 1.0260899066925049 seconds for one epoch ---
--- 0.3202528953552246 seconds for one epoch ---
--- 1.0555593967437744 seconds for one epoch ---
--- 0.30124545097351074 seconds for one epoch ---
--- 1.053525447845459 seconds for one epoch ---
--- 0.31002211570739746 seconds for one epoch ---
--- 1.050788402557373 seconds for one epoch ---
--- 0.3205103874206543 seconds for one epoch ---
--- 1.0517091751098633 seconds for one epoch ---
--- 0.32201218605041504 seconds for one epoch ---
--- 1.0524702072143555 seconds for one epoch ---
--- 0.3298978805541992 seconds for one epoch ---
--- 1.0696022510528564 seconds for one epoch ---
--- 0.32860445976257324 seconds for one epoch ---
--- 1.0690405368804932 seconds for one epoch ---
--- 0.31145620346069336 seconds for one epoch ---
--- 1.057133436203003 seconds for one epoch ---
--- 0.3231780529022217 seconds for one epoch ---
=========================
[[0.99343663]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20258577]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999928 ]
 [0.        ]]
[[-2.171995 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8782666]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.792055 ]
 [ 0.       ]]
--- 0.26964640617370605 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3892.68603515625, (1894.8784, 2.0139303, 1995.2084, 0.5853694)
   validation loss 1019.9675903320312, (709.3961, 0.21637025, 309.7697, 0.5853694)
decoder loss ratio: 27483.237183, decoder SINDy loss  ratio: 0.668681
--- 0.3238804340362549 seconds for one epoch ---
--- 1.0568442344665527 seconds for one epoch ---
--- 0.3170170783996582 seconds for one epoch ---
--- 1.0316548347473145 seconds for one epoch ---
--- 0.3245890140533447 seconds for one epoch ---
--- 1.0422766208648682 seconds for one epoch ---
--- 0.315185546875 seconds for one epoch ---
--- 1.0555877685546875 seconds for one epoch ---
--- 0.3208291530609131 seconds for one epoch ---
--- 1.0699024200439453 seconds for one epoch ---
--- 0.31380677223205566 seconds for one epoch ---
--- 1.0869965553283691 seconds for one epoch ---
--- 0.3064157962799072 seconds for one epoch ---
--- 1.0702857971191406 seconds for one epoch ---
--- 0.32602930068969727 seconds for one epoch ---
--- 1.0594308376312256 seconds for one epoch ---
--- 0.3296055793762207 seconds for one epoch ---
--- 1.0747838020324707 seconds for one epoch ---
--- 0.29778194427490234 seconds for one epoch ---
--- 1.0660560131072998 seconds for one epoch ---
--- 0.3262336254119873 seconds for one epoch ---
--- 1.0780143737792969 seconds for one epoch ---
--- 0.31371212005615234 seconds for one epoch ---
--- 1.0617737770080566 seconds for one epoch ---
=========================
[[0.9942312 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21081483]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999927 ]
 [0.        ]]
[[-2.1984575 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.88837683]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.7964225 ]
 [ 0.        ]]
--- 0.3104691505432129 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4815.80029296875, (1796.3152, 2.2005353, 3016.697, 0.5874719)
   validation loss 1029.514404296875, (696.5295, 0.17223346, 332.22513, 0.5874719)
decoder loss ratio: 26984.761283, decoder SINDy loss  ratio: 0.717155
--- 0.2682156562805176 seconds for one epoch ---
--- 0.3162703514099121 seconds for one epoch ---
--- 1.0498147010803223 seconds for one epoch ---
--- 0.3267843723297119 seconds for one epoch ---
--- 1.0570173263549805 seconds for one epoch ---
--- 0.3169429302215576 seconds for one epoch ---
--- 1.0492444038391113 seconds for one epoch ---
--- 0.316680908203125 seconds for one epoch ---
--- 1.0901131629943848 seconds for one epoch ---
--- 0.3271207809448242 seconds for one epoch ---
--- 1.0792980194091797 seconds for one epoch ---
--- 0.30681371688842773 seconds for one epoch ---
--- 1.0802206993103027 seconds for one epoch ---
--- 0.32613706588745117 seconds for one epoch ---
--- 1.0889525413513184 seconds for one epoch ---
--- 0.3258819580078125 seconds for one epoch ---
--- 1.083249568939209 seconds for one epoch ---
--- 0.31498169898986816 seconds for one epoch ---
--- 1.097538948059082 seconds for one epoch ---
--- 0.322664737701416 seconds for one epoch ---
--- 1.089005947113037 seconds for one epoch ---
--- 0.33131957054138184 seconds for one epoch ---
--- 1.0714969635009766 seconds for one epoch ---
--- 0.3258090019226074 seconds for one epoch ---
=========================
[[0.9948286 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21170995]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999926 ]
 [0.        ]]
[[-2.2208416 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.88945943]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.8008273 ]
 [ 0.        ]]
--- 0.274486780166626 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3536.28173828125, (1361.588, 1.3498342, 2172.7568, 0.5869752)
   validation loss 946.607666015625, (643.93787, 0.25080854, 301.83203, 0.5869752)
decoder loss ratio: 24947.270862, decoder SINDy loss  ratio: 0.651547
--- 0.3105590343475342 seconds for one epoch ---
--- 1.107480764389038 seconds for one epoch ---
--- 0.3219597339630127 seconds for one epoch ---
--- 1.1132187843322754 seconds for one epoch ---
--- 0.3189084529876709 seconds for one epoch ---
--- 1.0979037284851074 seconds for one epoch ---
--- 0.32906365394592285 seconds for one epoch ---
--- 1.093522548675537 seconds for one epoch ---
--- 0.32227492332458496 seconds for one epoch ---
--- 1.106130838394165 seconds for one epoch ---
--- 0.3228607177734375 seconds for one epoch ---
--- 1.072622537612915 seconds for one epoch ---
--- 0.3267960548400879 seconds for one epoch ---
--- 1.0908679962158203 seconds for one epoch ---
--- 0.32373499870300293 seconds for one epoch ---
--- 1.0965967178344727 seconds for one epoch ---
--- 0.33551907539367676 seconds for one epoch ---
--- 1.1018822193145752 seconds for one epoch ---
--- 0.31751251220703125 seconds for one epoch ---
--- 1.0842235088348389 seconds for one epoch ---
--- 0.3455934524536133 seconds for one epoch ---
--- 1.0757479667663574 seconds for one epoch ---
--- 0.32537412643432617 seconds for one epoch ---
--- 1.1154823303222656 seconds for one epoch ---
=========================
[[0.99546504]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20994624]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999255]
 [0.        ]]
[[-2.2477024 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.88732463]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.8182292 ]
 [ 0.        ]]
--- 0.3084142208099365 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4271.0361328125, (2290.7563, 0.8415913, 1978.8512, 0.5870237)
   validation loss 1314.7779541015625, (961.3602, 0.19836667, 352.63226, 0.5870237)
decoder loss ratio: 37244.764285, decoder SINDy loss  ratio: 0.761206
--- 0.2744407653808594 seconds for one epoch ---
--- 0.31437182426452637 seconds for one epoch ---
--- 1.0975067615509033 seconds for one epoch ---
--- 0.32222437858581543 seconds for one epoch ---
--- 1.1002955436706543 seconds for one epoch ---
--- 0.3237645626068115 seconds for one epoch ---
--- 1.0891568660736084 seconds for one epoch ---
--- 0.3177809715270996 seconds for one epoch ---
--- 1.1156527996063232 seconds for one epoch ---
--- 0.32183098793029785 seconds for one epoch ---
--- 1.096153974533081 seconds for one epoch ---
--- 0.3003973960876465 seconds for one epoch ---
--- 1.1000761985778809 seconds for one epoch ---
--- 0.3099825382232666 seconds for one epoch ---
--- 1.1048328876495361 seconds for one epoch ---
--- 0.30443358421325684 seconds for one epoch ---
--- 1.1117708683013916 seconds for one epoch ---
--- 0.3229529857635498 seconds for one epoch ---
--- 1.1127204895019531 seconds for one epoch ---
--- 0.31334352493286133 seconds for one epoch ---
--- 1.1018807888031006 seconds for one epoch ---
--- 0.3318300247192383 seconds for one epoch ---
--- 1.097646951675415 seconds for one epoch ---
--- 0.31348371505737305 seconds for one epoch ---
=========================
[[0.9959059 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20580292]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999243]
 [0.        ]]
[[-2.2686234]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8822567]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.826159 ]
 [ 0.       ]]
--- 0.27109742164611816 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6905.671875, (1387.6377, 0.7329779, 5516.7153, 0.58618)
   validation loss 1101.0126953125, (788.75055, 0.31949112, 311.3564, 0.58618)
decoder loss ratio: 30557.565612, decoder SINDy loss  ratio: 0.672107
--- 0.3189563751220703 seconds for one epoch ---
--- 1.0893630981445312 seconds for one epoch ---
--- 0.3282027244567871 seconds for one epoch ---
--- 1.0863511562347412 seconds for one epoch ---
--- 0.31621432304382324 seconds for one epoch ---
--- 1.1223580837249756 seconds for one epoch ---
--- 0.3227264881134033 seconds for one epoch ---
--- 1.1036376953125 seconds for one epoch ---
--- 0.3262820243835449 seconds for one epoch ---
--- 1.1562261581420898 seconds for one epoch ---
--- 0.3173990249633789 seconds for one epoch ---
--- 1.1240158081054688 seconds for one epoch ---
--- 0.3187856674194336 seconds for one epoch ---
--- 1.1352901458740234 seconds for one epoch ---
--- 0.3220834732055664 seconds for one epoch ---
--- 1.1223986148834229 seconds for one epoch ---
--- 0.3147242069244385 seconds for one epoch ---
--- 1.1388444900512695 seconds for one epoch ---
--- 0.3281879425048828 seconds for one epoch ---
--- 1.1211497783660889 seconds for one epoch ---
--- 0.3246290683746338 seconds for one epoch ---
--- 1.0901827812194824 seconds for one epoch ---
--- 0.3274061679840088 seconds for one epoch ---
--- 1.1161198616027832 seconds for one epoch ---
=========================
[[0.9960874 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19866163]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999243]
 [0.        ]]
[[-2.2778828 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.87334067]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.819499  ]
 [ 0.        ]]
--- 0.3152148723602295 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3012.0791015625, (1067.705, 0.8308242, 1942.9581, 0.58525336)
   validation loss 1130.1923828125, (780.0492, 0.3556062, 349.20245, 0.58525336)
decoder loss ratio: 30220.460014, decoder SINDy loss  ratio: 0.753803
--- 0.26575541496276855 seconds for one epoch ---
--- 0.3266470432281494 seconds for one epoch ---
--- 1.0889954566955566 seconds for one epoch ---
--- 0.31878185272216797 seconds for one epoch ---
--- 1.1104562282562256 seconds for one epoch ---
--- 0.3281111717224121 seconds for one epoch ---
--- 1.1250989437103271 seconds for one epoch ---
--- 0.32819485664367676 seconds for one epoch ---
--- 1.1211068630218506 seconds for one epoch ---
--- 0.3157522678375244 seconds for one epoch ---
--- 1.1158242225646973 seconds for one epoch ---
--- 0.3153197765350342 seconds for one epoch ---
--- 1.1101677417755127 seconds for one epoch ---
--- 0.32686591148376465 seconds for one epoch ---
--- 1.1325790882110596 seconds for one epoch ---
--- 0.31221771240234375 seconds for one epoch ---
--- 1.1301381587982178 seconds for one epoch ---
--- 0.3312563896179199 seconds for one epoch ---
--- 1.1291215419769287 seconds for one epoch ---
--- 0.323408842086792 seconds for one epoch ---
--- 1.139294147491455 seconds for one epoch ---
--- 0.3277719020843506 seconds for one epoch ---
--- 1.1357214450836182 seconds for one epoch ---
--- 0.3353843688964844 seconds for one epoch ---
=========================
[[0.99644357]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19483459]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999225]
 [0.        ]]
[[-2.2974267]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8684638]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.8301659]
 [ 0.       ]]
--- 0.25469493865966797 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3243.7197265625, (1500.341, 1.3819337, 1741.4119, 0.58494145)
   validation loss 1055.366455078125, (732.5257, 0.21208903, 322.0437, 0.58494145)
decoder loss ratio: 28379.317176, decoder SINDy loss  ratio: 0.695177
--- 0.32817769050598145 seconds for one epoch ---
--- 1.0975401401519775 seconds for one epoch ---
--- 0.3238987922668457 seconds for one epoch ---
--- 1.099743366241455 seconds for one epoch ---
--- 0.3158233165740967 seconds for one epoch ---
--- 1.1480059623718262 seconds for one epoch ---
--- 0.3169138431549072 seconds for one epoch ---
--- 1.1184866428375244 seconds for one epoch ---
--- 0.3405585289001465 seconds for one epoch ---
--- 1.1454222202301025 seconds for one epoch ---
--- 0.31433844566345215 seconds for one epoch ---
--- 1.1467385292053223 seconds for one epoch ---
--- 0.30728888511657715 seconds for one epoch ---
--- 1.127622127532959 seconds for one epoch ---
--- 0.33142685890197754 seconds for one epoch ---
--- 1.1418483257293701 seconds for one epoch ---
--- 0.32863330841064453 seconds for one epoch ---
--- 1.1470372676849365 seconds for one epoch ---
--- 0.32700228691101074 seconds for one epoch ---
--- 1.1246211528778076 seconds for one epoch ---
--- 0.3273603916168213 seconds for one epoch ---
--- 1.131622552871704 seconds for one epoch ---
--- 0.3282773494720459 seconds for one epoch ---
--- 1.1430165767669678 seconds for one epoch ---
=========================
[[0.9969063 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20066166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999213]
 [0.        ]]
[[-2.325918  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.87586236]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.8425558 ]
 [ 0.        ]]
--- 0.31650733947753906 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1480.2620849609375, (700.6816, 0.29311892, 778.70166, 0.5858607)
   validation loss 799.0363159179688, (499.60895, 0.27906215, 298.56247, 0.5858607)
decoder loss ratio: 19355.717995, decoder SINDy loss  ratio: 0.644489
--- 0.25386500358581543 seconds for one epoch ---
--- 0.32337093353271484 seconds for one epoch ---
--- 1.1194474697113037 seconds for one epoch ---
--- 0.3305349349975586 seconds for one epoch ---
--- 1.1417407989501953 seconds for one epoch ---
--- 0.30639123916625977 seconds for one epoch ---
--- 1.1325185298919678 seconds for one epoch ---
--- 0.33117222785949707 seconds for one epoch ---
--- 1.1339523792266846 seconds for one epoch ---
--- 0.32419800758361816 seconds for one epoch ---
--- 1.12939453125 seconds for one epoch ---
--- 0.3313024044036865 seconds for one epoch ---
--- 1.1474788188934326 seconds for one epoch ---
--- 0.3252441883087158 seconds for one epoch ---
--- 1.1349923610687256 seconds for one epoch ---
--- 0.31663990020751953 seconds for one epoch ---
--- 1.1360020637512207 seconds for one epoch ---
--- 0.3277873992919922 seconds for one epoch ---
--- 1.1388094425201416 seconds for one epoch ---
--- 0.3203103542327881 seconds for one epoch ---
--- 1.1732499599456787 seconds for one epoch ---
--- 0.3256192207336426 seconds for one epoch ---
--- 1.1535961627960205 seconds for one epoch ---
--- 0.33891916275024414 seconds for one epoch ---
=========================
[[0.9971664 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19881558]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999921 ]
 [0.        ]]
[[-2.343881 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8735368]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.8463671]
 [ 0.       ]]
--- 0.276043176651001 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3319.849365234375, (1020.5231, 4.6609735, 2294.08, 0.5851844)
   validation loss 716.1846923828125, (425.62863, 0.25737563, 289.71347, 0.5851844)
decoder loss ratio: 16489.592112, decoder SINDy loss  ratio: 0.625387
--- 0.3217618465423584 seconds for one epoch ---
--- 1.1369614601135254 seconds for one epoch ---
--- 0.32512879371643066 seconds for one epoch ---
--- 1.112440824508667 seconds for one epoch ---
--- 0.3220481872558594 seconds for one epoch ---
--- 1.1478111743927002 seconds for one epoch ---
--- 0.32698655128479004 seconds for one epoch ---
--- 1.1421232223510742 seconds for one epoch ---
--- 0.3251378536224365 seconds for one epoch ---
--- 1.1601476669311523 seconds for one epoch ---
--- 0.32036638259887695 seconds for one epoch ---
--- 1.1650362014770508 seconds for one epoch ---
--- 0.30147886276245117 seconds for one epoch ---
--- 1.14243483543396 seconds for one epoch ---
--- 0.32251691818237305 seconds for one epoch ---
--- 1.185342788696289 seconds for one epoch ---
--- 0.3254270553588867 seconds for one epoch ---
--- 1.1461830139160156 seconds for one epoch ---
--- 0.3232686519622803 seconds for one epoch ---
--- 1.1676580905914307 seconds for one epoch ---
--- 0.3283407688140869 seconds for one epoch ---
--- 1.1717514991760254 seconds for one epoch ---
--- 0.3349132537841797 seconds for one epoch ---
--- 1.1464588642120361 seconds for one epoch ---
=========================
[[0.9974986]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1942827]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999919]
 [0.       ]]
[[-2.369362  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.86775565]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.865007  ]
 [ 0.        ]]
--- 0.3025205135345459 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3901.185546875, (1978.3643, 0.44661933, 1921.7908, 0.5839643)
   validation loss 809.3741455078125, (511.5322, 0.25866845, 296.99933, 0.5839643)
decoder loss ratio: 19817.645334, decoder SINDy loss  ratio: 0.641115
THRESHOLDING: 3 active coefficients
--- 1.135650634765625 seconds for one epoch ---
--- 0.33215880393981934 seconds for one epoch ---
--- 1.164306402206421 seconds for one epoch ---
--- 0.3220398426055908 seconds for one epoch ---
--- 1.1617460250854492 seconds for one epoch ---
--- 0.3342568874359131 seconds for one epoch ---
--- 1.1689531803131104 seconds for one epoch ---
--- 0.3274822235107422 seconds for one epoch ---
--- 1.1527061462402344 seconds for one epoch ---
--- 0.32358646392822266 seconds for one epoch ---
--- 1.1779606342315674 seconds for one epoch ---
--- 0.31572532653808594 seconds for one epoch ---
--- 1.1711680889129639 seconds for one epoch ---
--- 0.3126986026763916 seconds for one epoch ---
--- 1.1502561569213867 seconds for one epoch ---
--- 0.3135871887207031 seconds for one epoch ---
--- 1.1777310371398926 seconds for one epoch ---
--- 0.3207268714904785 seconds for one epoch ---
--- 1.165170431137085 seconds for one epoch ---
--- 0.31789541244506836 seconds for one epoch ---
--- 1.1808764934539795 seconds for one epoch ---
--- 0.31449031829833984 seconds for one epoch ---
--- 1.148655652999878 seconds for one epoch ---
--- 0.3277277946472168 seconds for one epoch ---
=========================
[[0.99775565]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18337607]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999918 ]
 [0.        ]]
[[-2.3915293 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.85341316]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.8893657 ]
 [-0.        ]]
--- 0.27280569076538086 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2827.71240234375, (1377.2697, 2.458951, 1447.4021, 0.5814393)
   validation loss 973.3499755859375, (671.7539, 0.23159125, 300.78308, 0.5814393)
decoder loss ratio: 26024.912544, decoder SINDy loss  ratio: 0.649283
--- 0.2967662811279297 seconds for one epoch ---
--- 1.1956636905670166 seconds for one epoch ---
--- 0.33252429962158203 seconds for one epoch ---
--- 1.183744192123413 seconds for one epoch ---
--- 0.31566405296325684 seconds for one epoch ---
--- 1.182370901107788 seconds for one epoch ---
--- 0.32405734062194824 seconds for one epoch ---
--- 1.1942758560180664 seconds for one epoch ---
--- 0.33465051651000977 seconds for one epoch ---
--- 1.167625904083252 seconds for one epoch ---
--- 0.3083312511444092 seconds for one epoch ---
--- 1.1731538772583008 seconds for one epoch ---
--- 0.33055830001831055 seconds for one epoch ---
--- 1.173658847808838 seconds for one epoch ---
--- 0.3159658908843994 seconds for one epoch ---
--- 1.187474012374878 seconds for one epoch ---
--- 0.33478498458862305 seconds for one epoch ---
--- 1.176889419555664 seconds for one epoch ---
--- 0.32528257369995117 seconds for one epoch ---
--- 1.1922931671142578 seconds for one epoch ---
--- 0.32541537284851074 seconds for one epoch ---
--- 1.1844875812530518 seconds for one epoch ---
--- 0.32882213592529297 seconds for one epoch ---
--- 1.176374912261963 seconds for one epoch ---
=========================
[[0.9982246 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20011583]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999183]
 [0.        ]]
[[-2.439423 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8751777]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.920492 ]
 [ 0.       ]]
--- 0.3041343688964844 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3027.319580078125, (1348.886, 0.48600614, 1677.3624, 0.5852837)
   validation loss 720.487548828125, (433.622, 0.3643782, 285.9159, 0.5852837)
decoder loss ratio: 16799.269440, decoder SINDy loss  ratio: 0.617190
--- 0.2846379280090332 seconds for one epoch ---
--- 0.3412761688232422 seconds for one epoch ---
--- 1.162743091583252 seconds for one epoch ---
--- 0.3400301933288574 seconds for one epoch ---
--- 1.157270908355713 seconds for one epoch ---
--- 0.3202226161956787 seconds for one epoch ---
--- 1.1820428371429443 seconds for one epoch ---
--- 0.32849836349487305 seconds for one epoch ---
--- 1.1908602714538574 seconds for one epoch ---
--- 0.33446192741394043 seconds for one epoch ---
--- 1.1888065338134766 seconds for one epoch ---
--- 0.32840728759765625 seconds for one epoch ---
--- 1.1975681781768799 seconds for one epoch ---
--- 0.32778429985046387 seconds for one epoch ---
--- 1.1967041492462158 seconds for one epoch ---
--- 0.3258819580078125 seconds for one epoch ---
--- 1.205735683441162 seconds for one epoch ---
--- 0.3278019428253174 seconds for one epoch ---
--- 1.2102928161621094 seconds for one epoch ---
--- 0.3283565044403076 seconds for one epoch ---
--- 1.2068259716033936 seconds for one epoch ---
--- 0.3229677677154541 seconds for one epoch ---
--- 1.2017579078674316 seconds for one epoch ---
--- 0.3174858093261719 seconds for one epoch ---
=========================
[[0.998255  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19314101]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]]
[[-2.443005  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.86628443]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9107249 ]
 [ 0.        ]]
--- 0.2719390392303467 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3601.861083984375, (1915.3834, 0.78725123, 1685.1068, 0.5838195)
   validation loss 1385.0029296875, (1044.0858, 0.22052719, 340.11264, 0.5838195)
decoder loss ratio: 40449.697102, decoder SINDy loss  ratio: 0.734181
--- 0.3127758502960205 seconds for one epoch ---
--- 1.195744514465332 seconds for one epoch ---
--- 0.3295590877532959 seconds for one epoch ---
--- 1.2016618251800537 seconds for one epoch ---
--- 0.3223891258239746 seconds for one epoch ---
--- 1.1641125679016113 seconds for one epoch ---
--- 0.3168656826019287 seconds for one epoch ---
--- 1.1671767234802246 seconds for one epoch ---
--- 0.32698631286621094 seconds for one epoch ---
--- 1.2015292644500732 seconds for one epoch ---
--- 0.3245203495025635 seconds for one epoch ---
--- 1.2323312759399414 seconds for one epoch ---
--- 0.33138203620910645 seconds for one epoch ---
--- 1.205223560333252 seconds for one epoch ---
--- 0.328082799911499 seconds for one epoch ---
--- 1.2278001308441162 seconds for one epoch ---
--- 0.3147239685058594 seconds for one epoch ---
--- 1.2238519191741943 seconds for one epoch ---
--- 0.3356456756591797 seconds for one epoch ---
--- 1.205934762954712 seconds for one epoch ---
--- 0.33153653144836426 seconds for one epoch ---
--- 1.2058956623077393 seconds for one epoch ---
--- 0.3224222660064697 seconds for one epoch ---
--- 1.2221007347106934 seconds for one epoch ---
=========================
[[0.9984621 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18935417]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]]
[[-2.4687147]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8613533]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.9290926]
 [-0.       ]]
--- 0.3050425052642822 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2810.908935546875, (1293.6704, 1.2208064, 1515.435, 0.58288425)
   validation loss 803.6326904296875, (480.9088, 0.30430382, 321.83673, 0.58288425)
decoder loss ratio: 18631.242328, decoder SINDy loss  ratio: 0.694730
--- 0.2809417247772217 seconds for one epoch ---
--- 0.3202962875366211 seconds for one epoch ---
--- 1.1934266090393066 seconds for one epoch ---
--- 0.32253146171569824 seconds for one epoch ---
--- 1.2356297969818115 seconds for one epoch ---
--- 0.3365917205810547 seconds for one epoch ---
--- 1.2106308937072754 seconds for one epoch ---
--- 0.32775044441223145 seconds for one epoch ---
--- 1.207202434539795 seconds for one epoch ---
--- 0.31154465675354004 seconds for one epoch ---
--- 1.212721347808838 seconds for one epoch ---
--- 0.33286023139953613 seconds for one epoch ---
--- 1.206862449645996 seconds for one epoch ---
--- 0.32916712760925293 seconds for one epoch ---
--- 1.2356688976287842 seconds for one epoch ---
--- 0.31534910202026367 seconds for one epoch ---
--- 1.2206001281738281 seconds for one epoch ---
--- 0.3381776809692383 seconds for one epoch ---
--- 1.215954065322876 seconds for one epoch ---
--- 0.32766008377075195 seconds for one epoch ---
--- 1.2353699207305908 seconds for one epoch ---
--- 0.32399821281433105 seconds for one epoch ---
--- 1.2413811683654785 seconds for one epoch ---
--- 0.34920287132263184 seconds for one epoch ---
=========================
[[0.9986131 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18584517]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999917 ]
 [0.        ]]
[[-2.4899492]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.856717 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.9432456]
 [-0.       ]]
--- 0.23682761192321777 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4132.93310546875, (1502.1182, 1.6216048, 2628.6116, 0.5815377)
   validation loss 778.0491943359375, (477.93323, 0.3191742, 299.21524, 0.5815377)
decoder loss ratio: 18515.962963, decoder SINDy loss  ratio: 0.645898
--- 0.32492971420288086 seconds for one epoch ---
--- 1.228137731552124 seconds for one epoch ---
--- 0.3201560974121094 seconds for one epoch ---
--- 1.2409846782684326 seconds for one epoch ---
--- 0.32625484466552734 seconds for one epoch ---
--- 1.212035894393921 seconds for one epoch ---
--- 0.32087111473083496 seconds for one epoch ---
--- 1.2109732627868652 seconds for one epoch ---
--- 0.323941707611084 seconds for one epoch ---
--- 1.2467336654663086 seconds for one epoch ---
--- 0.3185906410217285 seconds for one epoch ---
--- 1.2165069580078125 seconds for one epoch ---
--- 0.33165478706359863 seconds for one epoch ---
--- 1.223567247390747 seconds for one epoch ---
--- 0.32581663131713867 seconds for one epoch ---
--- 1.2184786796569824 seconds for one epoch ---
--- 0.32836103439331055 seconds for one epoch ---
--- 1.228945016860962 seconds for one epoch ---
--- 0.3257465362548828 seconds for one epoch ---
--- 1.2321679592132568 seconds for one epoch ---
--- 0.32549238204956055 seconds for one epoch ---
--- 1.2485508918762207 seconds for one epoch ---
--- 0.33701014518737793 seconds for one epoch ---
--- 1.2291936874389648 seconds for one epoch ---
=========================
[[0.99865437]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.170929  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999915 ]
 [0.        ]]
[[-2.496078 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.8362143]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.9470623]
 [ 0.       ]]
--- 0.31780242919921875 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3794.73388671875, (1823.713, 3.0024328, 1967.4398, 0.5785186)
   validation loss 904.1531982421875, (584.6337, 0.311084, 318.62988, 0.5785186)
decoder loss ratio: 22649.725593, decoder SINDy loss  ratio: 0.687807
--- 0.2648472785949707 seconds for one epoch ---
--- 0.3242678642272949 seconds for one epoch ---
--- 1.2422351837158203 seconds for one epoch ---
--- 0.327256441116333 seconds for one epoch ---
--- 1.2056949138641357 seconds for one epoch ---
--- 0.3206791877746582 seconds for one epoch ---
--- 1.2309198379516602 seconds for one epoch ---
--- 0.318023681640625 seconds for one epoch ---
--- 1.2519478797912598 seconds for one epoch ---
--- 0.3300209045410156 seconds for one epoch ---
--- 1.212280511856079 seconds for one epoch ---
--- 0.33527088165283203 seconds for one epoch ---
--- 1.2434616088867188 seconds for one epoch ---
--- 0.32318592071533203 seconds for one epoch ---
--- 1.2349801063537598 seconds for one epoch ---
--- 0.3289201259613037 seconds for one epoch ---
--- 1.2593176364898682 seconds for one epoch ---
--- 0.32569408416748047 seconds for one epoch ---
--- 1.2476170063018799 seconds for one epoch ---
--- 0.32529163360595703 seconds for one epoch ---
--- 1.2332580089569092 seconds for one epoch ---
--- 0.3242337703704834 seconds for one epoch ---
--- 1.2676594257354736 seconds for one epoch ---
--- 0.32763123512268066 seconds for one epoch ---
=========================
[[0.9988697 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18376508]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999915 ]
 [0.        ]]
[[-2.5316997 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.85393685]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.962195  ]
 [ 0.        ]]
--- 0.26294445991516113 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2014.1448974609375, (1092.3009, 0.22028388, 921.0415, 0.5821443)
   validation loss 1071.9239501953125, (763.1363, 0.23984545, 307.9657, 0.5821443)
decoder loss ratio: 29565.224796, decoder SINDy loss  ratio: 0.664787
--- 0.3218047618865967 seconds for one epoch ---
--- 1.241459846496582 seconds for one epoch ---
--- 0.3345515727996826 seconds for one epoch ---
--- 1.2436838150024414 seconds for one epoch ---
--- 0.32181262969970703 seconds for one epoch ---
--- 1.2864172458648682 seconds for one epoch ---
--- 0.3298609256744385 seconds for one epoch ---
--- 1.2632436752319336 seconds for one epoch ---
--- 0.31626176834106445 seconds for one epoch ---
--- 1.2307226657867432 seconds for one epoch ---
--- 0.32643938064575195 seconds for one epoch ---
--- 1.2289252281188965 seconds for one epoch ---
--- 0.33289027214050293 seconds for one epoch ---
--- 1.2337796688079834 seconds for one epoch ---
--- 0.31523919105529785 seconds for one epoch ---
--- 1.2683565616607666 seconds for one epoch ---
--- 0.31963205337524414 seconds for one epoch ---
--- 1.2444286346435547 seconds for one epoch ---
--- 0.33061814308166504 seconds for one epoch ---
--- 1.2895865440368652 seconds for one epoch ---
--- 0.3197770118713379 seconds for one epoch ---
--- 1.2514657974243164 seconds for one epoch ---
--- 0.3374021053314209 seconds for one epoch ---
--- 1.2409074306488037 seconds for one epoch ---
=========================
[[0.9989785 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17488979]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999918 ]
 [0.        ]]
[[-2.5523703]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8417912]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.9825826]
 [-0.       ]]
--- 0.31020188331604004 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4296.6064453125, (1646.5612, 1.134826, 2648.3303, 0.5798515)
   validation loss 854.1055908203125, (556.95654, 0.27587894, 296.29333, 0.5798515)
decoder loss ratio: 21577.463394, decoder SINDy loss  ratio: 0.639591
--- 0.2748563289642334 seconds for one epoch ---
--- 0.32114362716674805 seconds for one epoch ---
--- 1.2327814102172852 seconds for one epoch ---
--- 0.3213343620300293 seconds for one epoch ---
--- 1.2432234287261963 seconds for one epoch ---
--- 0.3252449035644531 seconds for one epoch ---
--- 1.2446026802062988 seconds for one epoch ---
--- 0.33156681060791016 seconds for one epoch ---
--- 1.2766666412353516 seconds for one epoch ---
--- 0.3156006336212158 seconds for one epoch ---
--- 1.278590440750122 seconds for one epoch ---
--- 0.31432533264160156 seconds for one epoch ---
--- 1.235602617263794 seconds for one epoch ---
--- 0.34890270233154297 seconds for one epoch ---
--- 1.2524635791778564 seconds for one epoch ---
--- 0.3135714530944824 seconds for one epoch ---
--- 1.2459940910339355 seconds for one epoch ---
--- 0.32816314697265625 seconds for one epoch ---
--- 1.261768102645874 seconds for one epoch ---
--- 0.34011054039001465 seconds for one epoch ---
--- 1.2804276943206787 seconds for one epoch ---
--- 0.31857895851135254 seconds for one epoch ---
--- 1.2811501026153564 seconds for one epoch ---
--- 0.326723575592041 seconds for one epoch ---
=========================
[[0.9990411 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17507525]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999918 ]
 [0.        ]]
[[-2.5653987]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.84205  ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.9765875]
 [ 0.       ]]
--- 0.27412939071655273 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2289.11767578125, (959.7278, 1.8190578, 1326.9905, 0.58042425)
   validation loss 892.9356079101562, (557.21515, 0.28182134, 334.85822, 0.58042425)
decoder loss ratio: 21587.482237, decoder SINDy loss  ratio: 0.722839
--- 0.3143322467803955 seconds for one epoch ---
--- 1.249931812286377 seconds for one epoch ---
--- 0.31657838821411133 seconds for one epoch ---
--- 1.2888672351837158 seconds for one epoch ---
--- 0.3270695209503174 seconds for one epoch ---
--- 1.2442026138305664 seconds for one epoch ---
--- 0.3393683433532715 seconds for one epoch ---
--- 1.2556912899017334 seconds for one epoch ---
--- 0.31694674491882324 seconds for one epoch ---
--- 1.2352709770202637 seconds for one epoch ---
--- 0.3167691230773926 seconds for one epoch ---
--- 1.2743804454803467 seconds for one epoch ---
--- 0.323483943939209 seconds for one epoch ---
--- 1.2922816276550293 seconds for one epoch ---
--- 0.3189535140991211 seconds for one epoch ---
--- 1.3051409721374512 seconds for one epoch ---
--- 0.32917141914367676 seconds for one epoch ---
--- 1.2444164752960205 seconds for one epoch ---
--- 0.31269049644470215 seconds for one epoch ---
--- 1.2829601764678955 seconds for one epoch ---
--- 0.3259427547454834 seconds for one epoch ---
--- 1.2575559616088867 seconds for one epoch ---
--- 0.3284602165222168 seconds for one epoch ---
--- 1.283768892288208 seconds for one epoch ---
=========================
[[0.99911153]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17137156]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999918 ]
 [0.        ]]
[[-2.5810027]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8368427]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.982518 ]
 [-0.       ]]
--- 0.3109908103942871 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3803.87646484375, (2012.8939, 1.0595905, 1789.3439, 0.5790283)
   validation loss 1065.894775390625, (760.3617, 0.3045494, 304.64954, 0.5790283)
decoder loss ratio: 29457.732085, decoder SINDy loss  ratio: 0.657629
--- 0.27414631843566895 seconds for one epoch ---
--- 0.31479573249816895 seconds for one epoch ---
--- 1.2889442443847656 seconds for one epoch ---
--- 0.32644200325012207 seconds for one epoch ---
--- 1.2920939922332764 seconds for one epoch ---
--- 0.33230161666870117 seconds for one epoch ---
--- 1.268085241317749 seconds for one epoch ---
--- 0.3257300853729248 seconds for one epoch ---
--- 1.2969951629638672 seconds for one epoch ---
--- 0.5828444957733154 seconds for one epoch ---
--- 1.259993553161621 seconds for one epoch ---
--- 0.3270394802093506 seconds for one epoch ---
--- 1.2635583877563477 seconds for one epoch ---
--- 0.32828497886657715 seconds for one epoch ---
--- 1.2643203735351562 seconds for one epoch ---
--- 0.32700443267822266 seconds for one epoch ---
--- 1.2754499912261963 seconds for one epoch ---
--- 0.3266119956970215 seconds for one epoch ---
--- 1.2903501987457275 seconds for one epoch ---
--- 0.33063316345214844 seconds for one epoch ---
--- 1.261399507522583 seconds for one epoch ---
--- 0.3304941654205322 seconds for one epoch ---
--- 1.3004481792449951 seconds for one epoch ---
--- 0.3018655776977539 seconds for one epoch ---
=========================
[[0.9991735 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17039669]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]]
[[-2.595611  ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.83545715]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.9837627 ]
 [-0.        ]]
--- 0.25863146781921387 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3414.8466796875, (1573.7277, 1.2462327, 1839.2942, 0.57871)
   validation loss 766.5474853515625, (477.9209, 0.34656376, 287.70126, 0.57871)
decoder loss ratio: 18515.485313, decoder SINDy loss  ratio: 0.621044
--- 0.3156919479370117 seconds for one epoch ---
--- 1.2779765129089355 seconds for one epoch ---
--- 0.3290281295776367 seconds for one epoch ---
--- 1.2829594612121582 seconds for one epoch ---
--- 0.3233046531677246 seconds for one epoch ---
--- 1.2820653915405273 seconds for one epoch ---
--- 0.30486321449279785 seconds for one epoch ---
--- 1.2847366333007812 seconds for one epoch ---
--- 0.31191158294677734 seconds for one epoch ---
--- 1.324965000152588 seconds for one epoch ---
--- 0.33119773864746094 seconds for one epoch ---
--- 1.2685399055480957 seconds for one epoch ---
--- 0.31697821617126465 seconds for one epoch ---
--- 1.305560827255249 seconds for one epoch ---
--- 0.3325788974761963 seconds for one epoch ---
--- 1.2854876518249512 seconds for one epoch ---
--- 0.32496023178100586 seconds for one epoch ---
--- 1.2855865955352783 seconds for one epoch ---
--- 0.3258326053619385 seconds for one epoch ---
--- 1.2946813106536865 seconds for one epoch ---
--- 0.333035945892334 seconds for one epoch ---
--- 1.3100683689117432 seconds for one epoch ---
--- 0.3272404670715332 seconds for one epoch ---
--- 1.30985426902771 seconds for one epoch ---
=========================
[[0.9992544 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17227022]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.6167226 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.83811444]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.992198  ]
 [ 0.        ]]
--- 0.3240058422088623 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3063.3515625, (1307.8682, 1.2825971, 1753.6213, 0.5796549)
   validation loss 1250.6055908203125, (931.28265, 0.30677503, 318.43643, 0.5796549)
decoder loss ratio: 36079.506786, decoder SINDy loss  ratio: 0.687390
--- 0.27494239807128906 seconds for one epoch ---
--- 0.32244110107421875 seconds for one epoch ---
--- 1.2740285396575928 seconds for one epoch ---
--- 0.3324122428894043 seconds for one epoch ---
--- 1.2837681770324707 seconds for one epoch ---
--- 0.3269622325897217 seconds for one epoch ---
--- 1.293039083480835 seconds for one epoch ---
--- 0.33298754692077637 seconds for one epoch ---
--- 1.3008739948272705 seconds for one epoch ---
--- 0.32741332054138184 seconds for one epoch ---
--- 1.2907869815826416 seconds for one epoch ---
--- 0.3227536678314209 seconds for one epoch ---
--- 1.3084423542022705 seconds for one epoch ---
--- 0.3263819217681885 seconds for one epoch ---
--- 1.2928128242492676 seconds for one epoch ---
--- 0.3350863456726074 seconds for one epoch ---
--- 1.282179355621338 seconds for one epoch ---
--- 0.3262336254119873 seconds for one epoch ---
--- 1.3129832744598389 seconds for one epoch ---
--- 0.3228464126586914 seconds for one epoch ---
--- 1.2843883037567139 seconds for one epoch ---
--- 0.32636332511901855 seconds for one epoch ---
--- 1.284109354019165 seconds for one epoch ---
--- 0.32326722145080566 seconds for one epoch ---
=========================
[[0.9992809 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16715205]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.6241987 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.83080107]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.9859068 ]
 [ 0.        ]]
--- 0.2733275890350342 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3486.425537109375, (1022.7587, 1.5885147, 2461.5, 0.57840794)
   validation loss 833.7859497070312, (539.51086, 0.4253081, 293.27133, 0.57840794)
decoder loss ratio: 20901.587513, decoder SINDy loss  ratio: 0.633067
--- 0.32414889335632324 seconds for one epoch ---
--- 1.2785513401031494 seconds for one epoch ---
--- 0.33202290534973145 seconds for one epoch ---
--- 1.307478666305542 seconds for one epoch ---
--- 0.3202495574951172 seconds for one epoch ---
--- 1.2967250347137451 seconds for one epoch ---
--- 0.32671427726745605 seconds for one epoch ---
--- 1.3151071071624756 seconds for one epoch ---
--- 0.34006500244140625 seconds for one epoch ---
--- 1.306269884109497 seconds for one epoch ---
--- 0.3243896961212158 seconds for one epoch ---
--- 1.3224139213562012 seconds for one epoch ---
--- 0.31622767448425293 seconds for one epoch ---
--- 1.3019533157348633 seconds for one epoch ---
--- 0.33162784576416016 seconds for one epoch ---
--- 1.308563232421875 seconds for one epoch ---
--- 0.32083630561828613 seconds for one epoch ---
--- 1.3085954189300537 seconds for one epoch ---
--- 0.3321568965911865 seconds for one epoch ---
--- 1.3433825969696045 seconds for one epoch ---
--- 0.32416415214538574 seconds for one epoch ---
--- 1.321908712387085 seconds for one epoch ---
--- 0.32718873023986816 seconds for one epoch ---
--- 1.3106603622436523 seconds for one epoch ---
=========================
[[0.99932134]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15709805]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999918 ]
 [0.        ]]
[[-2.6359732]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.815896 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.999011 ]
 [-0.       ]]
--- 0.30407190322875977 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2994.4345703125, (1188.7367, 1.1600723, 1803.9623, 0.5756251)
   validation loss 835.3330078125, (550.0392, 0.3365121, 284.3817, 0.5756251)
decoder loss ratio: 21309.472920, decoder SINDy loss  ratio: 0.613878
--- 0.2737860679626465 seconds for one epoch ---
--- 0.3310112953186035 seconds for one epoch ---
--- 1.3278653621673584 seconds for one epoch ---
--- 0.3315768241882324 seconds for one epoch ---
--- 1.3139121532440186 seconds for one epoch ---
--- 0.3254733085632324 seconds for one epoch ---
--- 1.3036589622497559 seconds for one epoch ---
--- 0.3199880123138428 seconds for one epoch ---
--- 1.327854871749878 seconds for one epoch ---
--- 0.3084242343902588 seconds for one epoch ---
--- 1.348388671875 seconds for one epoch ---
--- 0.3290126323699951 seconds for one epoch ---
--- 1.3215186595916748 seconds for one epoch ---
--- 0.3225111961364746 seconds for one epoch ---
--- 1.3421318531036377 seconds for one epoch ---
--- 0.31658434867858887 seconds for one epoch ---
--- 1.3109920024871826 seconds for one epoch ---
--- 0.3353152275085449 seconds for one epoch ---
--- 1.322157621383667 seconds for one epoch ---
--- 0.33264851570129395 seconds for one epoch ---
--- 1.3076562881469727 seconds for one epoch ---
--- 0.32274532318115234 seconds for one epoch ---
--- 1.3339924812316895 seconds for one epoch ---
--- 0.32607555389404297 seconds for one epoch ---
=========================
[[0.9994205]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1597114]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999918]
 [0.       ]]
[[-2.668273  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.81984246]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.0282087 ]
 [ 0.        ]]
--- 0.2598848342895508 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3198.6962890625, (1039.0468, 0.61776334, 2158.4548, 0.5769565)
   validation loss 769.7787475585938, (471.62885, 0.3790665, 297.19385, 0.5769565)
decoder loss ratio: 18271.720247, decoder SINDy loss  ratio: 0.641535
--- 0.31464695930480957 seconds for one epoch ---
--- 1.3414907455444336 seconds for one epoch ---
--- 0.3260211944580078 seconds for one epoch ---
--- 1.3211603164672852 seconds for one epoch ---
--- 0.3250565528869629 seconds for one epoch ---
--- 1.3593087196350098 seconds for one epoch ---
--- 0.3193197250366211 seconds for one epoch ---
--- 1.3443498611450195 seconds for one epoch ---
--- 0.32316040992736816 seconds for one epoch ---
--- 1.3312146663665771 seconds for one epoch ---
--- 0.33191704750061035 seconds for one epoch ---
--- 1.3399858474731445 seconds for one epoch ---
--- 0.3115272521972656 seconds for one epoch ---
--- 1.3393092155456543 seconds for one epoch ---
--- 0.33469462394714355 seconds for one epoch ---
--- 1.3353097438812256 seconds for one epoch ---
--- 0.325451135635376 seconds for one epoch ---
--- 1.349696159362793 seconds for one epoch ---
--- 0.33007049560546875 seconds for one epoch ---
--- 1.355665922164917 seconds for one epoch ---
--- 0.329852819442749 seconds for one epoch ---
--- 1.3519139289855957 seconds for one epoch ---
--- 0.33287501335144043 seconds for one epoch ---
--- 1.3165783882141113 seconds for one epoch ---
=========================
[[0.99948937]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16074058]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999992  ]
 [0.        ]]
[[-2.694205 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8213824]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.046513 ]
 [-0.       ]]
--- 0.31462717056274414 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2765.02099609375, (1407.4072, 4.04294, 1352.9943, 0.57674474)
   validation loss 1075.39404296875, (775.2705, 0.29119477, 299.25555, 0.57674474)
decoder loss ratio: 30035.325401, decoder SINDy loss  ratio: 0.645985
--- 0.28134799003601074 seconds for one epoch ---
--- 0.3301389217376709 seconds for one epoch ---
--- 1.3272948265075684 seconds for one epoch ---
--- 0.32276082038879395 seconds for one epoch ---
--- 1.3300902843475342 seconds for one epoch ---
--- 0.3230559825897217 seconds for one epoch ---
--- 1.3503093719482422 seconds for one epoch ---
--- 0.3081505298614502 seconds for one epoch ---
--- 1.3698105812072754 seconds for one epoch ---
--- 0.3241312503814697 seconds for one epoch ---
--- 1.3292953968048096 seconds for one epoch ---
--- 0.3417398929595947 seconds for one epoch ---
--- 1.3198881149291992 seconds for one epoch ---
--- 0.3250126838684082 seconds for one epoch ---
--- 1.3561842441558838 seconds for one epoch ---
--- 0.30928492546081543 seconds for one epoch ---
--- 1.3303074836730957 seconds for one epoch ---
--- 0.32568907737731934 seconds for one epoch ---
--- 1.3809425830841064 seconds for one epoch ---
--- 0.352921724319458 seconds for one epoch ---
--- 1.3608200550079346 seconds for one epoch ---
--- 0.3309180736541748 seconds for one epoch ---
--- 1.3674626350402832 seconds for one epoch ---
--- 0.3348057270050049 seconds for one epoch ---
=========================
[[0.999521  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15756017]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999919 ]
 [0.        ]]
[[-2.7071881]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.8165979]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.052402 ]
 [-0.       ]]
--- 0.29180216789245605 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2828.8515625, (1413.1945, 1.2875794, 1413.7931, 0.57645863)
   validation loss 1172.296875, (860.3896, 0.3922358, 310.9387, 0.57645863)
decoder loss ratio: 33332.986318, decoder SINDy loss  ratio: 0.671205
--- 0.30626749992370605 seconds for one epoch ---
--- 1.357656478881836 seconds for one epoch ---
--- 0.33943748474121094 seconds for one epoch ---
--- 1.3435289859771729 seconds for one epoch ---
--- 0.3157382011413574 seconds for one epoch ---
--- 1.38431978225708 seconds for one epoch ---
--- 0.3332102298736572 seconds for one epoch ---
--- 1.3802611827850342 seconds for one epoch ---
--- 0.33362269401550293 seconds for one epoch ---
--- 1.378288745880127 seconds for one epoch ---
--- 0.3206963539123535 seconds for one epoch ---
--- 1.3766157627105713 seconds for one epoch ---
--- 0.31973934173583984 seconds for one epoch ---
--- 1.3647305965423584 seconds for one epoch ---
--- 0.32803773880004883 seconds for one epoch ---
--- 1.359870433807373 seconds for one epoch ---
--- 0.31975817680358887 seconds for one epoch ---
--- 1.3663556575775146 seconds for one epoch ---
--- 0.3299520015716553 seconds for one epoch ---
--- 1.3492064476013184 seconds for one epoch ---
--- 0.32366061210632324 seconds for one epoch ---
--- 1.3686754703521729 seconds for one epoch ---
--- 0.3258986473083496 seconds for one epoch ---
--- 1.3418521881103516 seconds for one epoch ---
=========================
[[0.99956393]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1532446 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999924 ]
 [0.        ]]
[[-2.7260797]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8099782]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0693097]
 [ 0.       ]]
--- 0.3001737594604492 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3387.758544921875, (1586.3691, 0.9863857, 1799.8274, 0.57559246)
   validation loss 850.1083374023438, (541.185, 0.35490566, 307.99277, 0.57559246)
decoder loss ratio: 20966.446344, decoder SINDy loss  ratio: 0.664846
--- 0.2688169479370117 seconds for one epoch ---
--- 0.316669225692749 seconds for one epoch ---
--- 1.347534418106079 seconds for one epoch ---
--- 0.3316934108734131 seconds for one epoch ---
--- 1.3847813606262207 seconds for one epoch ---
--- 0.3310370445251465 seconds for one epoch ---
--- 1.3437652587890625 seconds for one epoch ---
--- 0.32749509811401367 seconds for one epoch ---
--- 1.3608102798461914 seconds for one epoch ---
--- 0.33305883407592773 seconds for one epoch ---
--- 1.365006923675537 seconds for one epoch ---
--- 0.3217320442199707 seconds for one epoch ---
--- 1.3548343181610107 seconds for one epoch ---
--- 0.33302807807922363 seconds for one epoch ---
--- 1.3737120628356934 seconds for one epoch ---
--- 0.3260810375213623 seconds for one epoch ---
--- 1.3712377548217773 seconds for one epoch ---
--- 0.3215780258178711 seconds for one epoch ---
--- 1.3823118209838867 seconds for one epoch ---
--- 0.3314840793609619 seconds for one epoch ---
--- 1.3703644275665283 seconds for one epoch ---
--- 0.3201572895050049 seconds for one epoch ---
--- 1.3782904148101807 seconds for one epoch ---
--- 0.3097195625305176 seconds for one epoch ---
=========================
[[0.99957037]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14861661]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999924 ]
 [0.        ]]
[[-2.7297993 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.80270857]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.063812  ]
 [ 0.        ]]
--- 0.27271175384521484 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3244.870361328125, (1173.2166, 1.9528418, 2069.127, 0.5740651)
   validation loss 1443.2890625, (1117.8776, 0.5200688, 324.3174, 0.5740651)
decoder loss ratio: 43308.517530, decoder SINDy loss  ratio: 0.700085
--- 0.3232090473175049 seconds for one epoch ---
--- 1.368675947189331 seconds for one epoch ---
--- 0.3292117118835449 seconds for one epoch ---
--- 1.3823065757751465 seconds for one epoch ---
--- 0.3329918384552002 seconds for one epoch ---
--- 1.397606372833252 seconds for one epoch ---
--- 0.3319697380065918 seconds for one epoch ---
--- 1.3681085109710693 seconds for one epoch ---
--- 0.3357982635498047 seconds for one epoch ---
--- 1.3702137470245361 seconds for one epoch ---
--- 0.32179903984069824 seconds for one epoch ---
--- 1.3606173992156982 seconds for one epoch ---
--- 0.3272898197174072 seconds for one epoch ---
--- 1.4061098098754883 seconds for one epoch ---
--- 0.3181731700897217 seconds for one epoch ---
--- 1.3774266242980957 seconds for one epoch ---
--- 0.3404526710510254 seconds for one epoch ---
--- 1.3938775062561035 seconds for one epoch ---
--- 0.3291943073272705 seconds for one epoch ---
--- 1.387458086013794 seconds for one epoch ---
--- 0.31518006324768066 seconds for one epoch ---
--- 1.4035773277282715 seconds for one epoch ---
--- 0.33399105072021484 seconds for one epoch ---
--- 1.3707435131072998 seconds for one epoch ---
=========================
[[0.9996004 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15116967]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999924 ]
 [0.        ]]
[[-2.7444866]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8067417]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.063629 ]
 [-0.       ]]
--- 0.3043656349182129 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6873.20849609375, (1499.946, 1.5548226, 5371.1333, 0.5743972)
   validation loss 800.2200317382812, (492.6979, 0.45779526, 306.48996, 0.5743972)
decoder loss ratio: 19087.972259, decoder SINDy loss  ratio: 0.661602
THRESHOLDING: 3 active coefficients
--- 1.3649322986602783 seconds for one epoch ---
--- 0.33286213874816895 seconds for one epoch ---
--- 1.3672878742218018 seconds for one epoch ---
--- 0.33093786239624023 seconds for one epoch ---
--- 1.3910086154937744 seconds for one epoch ---
--- 0.33042001724243164 seconds for one epoch ---
--- 1.3954894542694092 seconds for one epoch ---
--- 0.32410335540771484 seconds for one epoch ---
--- 1.3698060512542725 seconds for one epoch ---
--- 0.32169127464294434 seconds for one epoch ---
--- 1.3964364528656006 seconds for one epoch ---
--- 0.3272981643676758 seconds for one epoch ---
--- 1.4024369716644287 seconds for one epoch ---
--- 0.3256673812866211 seconds for one epoch ---
--- 1.3799517154693604 seconds for one epoch ---
--- 0.3245849609375 seconds for one epoch ---
--- 1.402420997619629 seconds for one epoch ---
--- 0.32553648948669434 seconds for one epoch ---
--- 1.4019873142242432 seconds for one epoch ---
--- 0.3141450881958008 seconds for one epoch ---
--- 1.3844702243804932 seconds for one epoch ---
--- 0.3279900550842285 seconds for one epoch ---
--- 1.3929483890533447 seconds for one epoch ---
--- 0.3334338665008545 seconds for one epoch ---
=========================
[[0.999626  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15301123]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999992  ]
 [0.        ]]
[[-2.7583296]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8096167]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.065178 ]
 [ 0.       ]]
--- 0.27172231674194336 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2400.377197265625, (1261.7737, 1.9424882, 1136.086, 0.5749025)
   validation loss 987.3134155273438, (673.8975, 0.3187139, 312.52228, 0.5749025)
decoder loss ratio: 26107.959939, decoder SINDy loss  ratio: 0.674623
--- 0.3256034851074219 seconds for one epoch ---
--- 1.3990814685821533 seconds for one epoch ---
--- 0.3202669620513916 seconds for one epoch ---
--- 1.3899216651916504 seconds for one epoch ---
--- 0.3312108516693115 seconds for one epoch ---
--- 1.3885672092437744 seconds for one epoch ---
--- 0.3301079273223877 seconds for one epoch ---
--- 1.406637191772461 seconds for one epoch ---
--- 0.31720566749572754 seconds for one epoch ---
--- 1.377265453338623 seconds for one epoch ---
--- 0.3291153907775879 seconds for one epoch ---
--- 1.3831465244293213 seconds for one epoch ---
--- 0.32285165786743164 seconds for one epoch ---
--- 1.3920989036560059 seconds for one epoch ---
--- 0.3336191177368164 seconds for one epoch ---
--- 1.3962171077728271 seconds for one epoch ---
--- 0.31792426109313965 seconds for one epoch ---
--- 1.414275884628296 seconds for one epoch ---
--- 0.3443763256072998 seconds for one epoch ---
--- 1.420567274093628 seconds for one epoch ---
--- 0.3406209945678711 seconds for one epoch ---
--- 1.3983967304229736 seconds for one epoch ---
--- 0.3378119468688965 seconds for one epoch ---
--- 1.4108970165252686 seconds for one epoch ---
=========================
[[0.9996343 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14849135]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999912 ]
 [0.        ]]
[[-2.7627022 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.80250925]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0569944 ]
 [-0.        ]]
--- 0.31844258308410645 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2992.517333984375, (1544.5021, 2.7000206, 1444.7408, 0.5744347)
   validation loss 953.9978637695312, (649.1109, 0.52372986, 303.78876, 0.5744347)
decoder loss ratio: 25147.683206, decoder SINDy loss  ratio: 0.655771
--- 0.27350592613220215 seconds for one epoch ---
--- 0.32971858978271484 seconds for one epoch ---
--- 1.3865559101104736 seconds for one epoch ---
--- 0.3377823829650879 seconds for one epoch ---
--- 1.4193594455718994 seconds for one epoch ---
--- 0.34000658988952637 seconds for one epoch ---
--- 1.4060111045837402 seconds for one epoch ---
--- 0.33703184127807617 seconds for one epoch ---
--- 1.4349944591522217 seconds for one epoch ---
--- 0.31718993186950684 seconds for one epoch ---
--- 1.4177043437957764 seconds for one epoch ---
--- 0.33809566497802734 seconds for one epoch ---
--- 1.4362828731536865 seconds for one epoch ---
--- 0.3220174312591553 seconds for one epoch ---
--- 1.428903579711914 seconds for one epoch ---
--- 0.3275010585784912 seconds for one epoch ---
--- 1.4274687767028809 seconds for one epoch ---
--- 0.33225035667419434 seconds for one epoch ---
--- 1.4225807189941406 seconds for one epoch ---
--- 0.329866886138916 seconds for one epoch ---
--- 1.452667236328125 seconds for one epoch ---
--- 0.3332633972167969 seconds for one epoch ---
--- 1.421996831893921 seconds for one epoch ---
--- 0.3285701274871826 seconds for one epoch ---
=========================
[[0.9996644 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15283516]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999106]
 [0.        ]]
[[-2.7803967]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8093432]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.0571322]
 [-0.       ]]
--- 0.27069544792175293 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2035.0728759765625, (1043.419, 0.7524868, 990.3262, 0.5753323)
   validation loss 1142.6387939453125, (785.7857, 0.39074478, 355.88696, 0.5753323)
decoder loss ratio: 30442.702418, decoder SINDy loss  ratio: 0.768232
--- 0.31145477294921875 seconds for one epoch ---
--- 1.4436795711517334 seconds for one epoch ---
--- 0.34125423431396484 seconds for one epoch ---
--- 1.4162859916687012 seconds for one epoch ---
--- 0.32726526260375977 seconds for one epoch ---
--- 1.4304852485656738 seconds for one epoch ---
--- 0.32697367668151855 seconds for one epoch ---
--- 1.4356167316436768 seconds for one epoch ---
--- 0.3307318687438965 seconds for one epoch ---
--- 1.4358775615692139 seconds for one epoch ---
--- 0.33238744735717773 seconds for one epoch ---
--- 1.4103481769561768 seconds for one epoch ---
--- 0.3306467533111572 seconds for one epoch ---
--- 1.41487717628479 seconds for one epoch ---
--- 0.3416907787322998 seconds for one epoch ---
--- 1.4217095375061035 seconds for one epoch ---
--- 0.32824110984802246 seconds for one epoch ---
--- 1.4449899196624756 seconds for one epoch ---
--- 0.3351755142211914 seconds for one epoch ---
--- 1.4307184219360352 seconds for one epoch ---
--- 0.3349874019622803 seconds for one epoch ---
--- 1.42999267578125 seconds for one epoch ---
--- 0.32735657691955566 seconds for one epoch ---
--- 1.4252409934997559 seconds for one epoch ---
=========================
[[0.9996875 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15079969]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.7947206]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8061615]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.0650043]
 [ 0.       ]]
--- 0.312824010848999 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2547.802734375, (1622.5087, 0.60678405, 924.1121, 0.5752809)
   validation loss 756.4546508789062, (465.1646, 0.43566948, 290.27914, 0.5752809)
decoder loss ratio: 18021.284623, decoder SINDy loss  ratio: 0.626608
--- 0.27350664138793945 seconds for one epoch ---
--- 0.3312492370605469 seconds for one epoch ---
--- 1.4095041751861572 seconds for one epoch ---
--- 0.31535816192626953 seconds for one epoch ---
--- 1.4204425811767578 seconds for one epoch ---
--- 0.3335225582122803 seconds for one epoch ---
--- 1.4408469200134277 seconds for one epoch ---
--- 0.3316819667816162 seconds for one epoch ---
--- 1.430372714996338 seconds for one epoch ---
--- 0.32960987091064453 seconds for one epoch ---
--- 1.4418067932128906 seconds for one epoch ---
--- 0.32883334159851074 seconds for one epoch ---
--- 1.4272446632385254 seconds for one epoch ---
--- 0.3334932327270508 seconds for one epoch ---
--- 1.4269170761108398 seconds for one epoch ---
--- 0.32474541664123535 seconds for one epoch ---
--- 1.4552781581878662 seconds for one epoch ---
--- 0.3287935256958008 seconds for one epoch ---
--- 1.4536058902740479 seconds for one epoch ---
--- 0.3250291347503662 seconds for one epoch ---
--- 1.4402360916137695 seconds for one epoch ---
--- 0.3225841522216797 seconds for one epoch ---
--- 1.4413163661956787 seconds for one epoch ---
--- 0.3296511173248291 seconds for one epoch ---
=========================
[[0.9997048 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15189263]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.8067813]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.807874 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.066003 ]
 [ 0.       ]]
--- 0.2852027416229248 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2026.44873046875, (1156.8256, 1.2148608, 867.8331, 0.5752105)
   validation loss 725.7020263671875, (430.89185, 0.46686035, 293.76813, 0.5752105)
decoder loss ratio: 16693.498164, decoder SINDy loss  ratio: 0.634140
--- 0.3206307888031006 seconds for one epoch ---
--- 1.4564568996429443 seconds for one epoch ---
--- 0.3337724208831787 seconds for one epoch ---
--- 1.4701380729675293 seconds for one epoch ---
--- 0.3288915157318115 seconds for one epoch ---
--- 1.4680674076080322 seconds for one epoch ---
--- 0.33081626892089844 seconds for one epoch ---
--- 1.4359703063964844 seconds for one epoch ---
--- 0.3239870071411133 seconds for one epoch ---
--- 1.459341287612915 seconds for one epoch ---
--- 0.33138442039489746 seconds for one epoch ---
--- 1.4468858242034912 seconds for one epoch ---
--- 0.33330225944519043 seconds for one epoch ---
--- 1.4353041648864746 seconds for one epoch ---
--- 0.3264615535736084 seconds for one epoch ---
--- 1.4882440567016602 seconds for one epoch ---
--- 0.3300340175628662 seconds for one epoch ---
--- 1.4292519092559814 seconds for one epoch ---
--- 0.3285515308380127 seconds for one epoch ---
--- 1.4693677425384521 seconds for one epoch ---
--- 0.33188748359680176 seconds for one epoch ---
--- 1.4807443618774414 seconds for one epoch ---
--- 0.32728052139282227 seconds for one epoch ---
--- 1.4472911357879639 seconds for one epoch ---
=========================
[[0.9997265 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1524461 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.8226905]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8087375]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.070373 ]
 [-0.       ]]
--- 0.3145577907562256 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2491.9306640625, (1368.386, 1.2525742, 1121.7166, 0.5756661)
   validation loss 751.0899658203125, (468.21045, 0.43734306, 281.8665, 0.5756661)
decoder loss ratio: 18139.285652, decoder SINDy loss  ratio: 0.608448
--- 0.2740795612335205 seconds for one epoch ---
--- 0.32838940620422363 seconds for one epoch ---
--- 1.436659336090088 seconds for one epoch ---
--- 0.3284149169921875 seconds for one epoch ---
--- 1.444270133972168 seconds for one epoch ---
--- 0.33542776107788086 seconds for one epoch ---
--- 1.4682631492614746 seconds for one epoch ---
--- 0.32471776008605957 seconds for one epoch ---
--- 1.433542251586914 seconds for one epoch ---
--- 0.3315308094024658 seconds for one epoch ---
--- 1.454404592514038 seconds for one epoch ---
--- 0.32953500747680664 seconds for one epoch ---
--- 1.442591667175293 seconds for one epoch ---
--- 0.32181715965270996 seconds for one epoch ---
--- 1.4910492897033691 seconds for one epoch ---
--- 0.31046199798583984 seconds for one epoch ---
--- 1.452359676361084 seconds for one epoch ---
--- 0.32866668701171875 seconds for one epoch ---
--- 1.460357427597046 seconds for one epoch ---
--- 0.32737064361572266 seconds for one epoch ---
--- 1.4549739360809326 seconds for one epoch ---
--- 0.32533931732177734 seconds for one epoch ---
--- 1.4741501808166504 seconds for one epoch ---
--- 0.32642340660095215 seconds for one epoch ---
=========================
[[0.9997397 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14830723]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.832283  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.80221605]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0734997 ]
 [ 0.        ]]
--- 0.272205114364624 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2892.165283203125, (1643.6603, 0.58416486, 1247.3463, 0.57452786)
   validation loss 1012.8585815429688, (716.5002, 0.43108916, 295.35278, 0.57452786)
decoder loss ratio: 27758.460993, decoder SINDy loss  ratio: 0.637561
--- 0.3212599754333496 seconds for one epoch ---
--- 1.4681057929992676 seconds for one epoch ---
--- 0.31752896308898926 seconds for one epoch ---
--- 1.470445156097412 seconds for one epoch ---
--- 0.32372093200683594 seconds for one epoch ---
--- 1.4633464813232422 seconds for one epoch ---
--- 0.3357076644897461 seconds for one epoch ---
--- 1.50016188621521 seconds for one epoch ---
--- 0.3280055522918701 seconds for one epoch ---
--- 1.4620661735534668 seconds for one epoch ---
--- 0.3226432800292969 seconds for one epoch ---
--- 1.478212594985962 seconds for one epoch ---
--- 0.3205831050872803 seconds for one epoch ---
--- 1.473637580871582 seconds for one epoch ---
--- 0.3227229118347168 seconds for one epoch ---
--- 1.4696881771087646 seconds for one epoch ---
--- 0.32570314407348633 seconds for one epoch ---
--- 1.4782798290252686 seconds for one epoch ---
--- 0.33028078079223633 seconds for one epoch ---
--- 1.4645626544952393 seconds for one epoch ---
--- 0.32498741149902344 seconds for one epoch ---
--- 1.46995210647583 seconds for one epoch ---
--- 0.3294053077697754 seconds for one epoch ---
--- 1.4969041347503662 seconds for one epoch ---
=========================
[[0.99973834]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13877189]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.8315947 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.78659934]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.069001  ]
 [-0.        ]]
--- 0.30800509452819824 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2775.284912109375, (1290.8132, 1.2928337, 1482.6075, 0.57140434)
   validation loss 826.1268920898438, (544.57904, 0.5501496, 280.42627, 0.57140434)
decoder loss ratio: 21097.937461, decoder SINDy loss  ratio: 0.605340
--- 0.2734384536743164 seconds for one epoch ---
--- 0.3266885280609131 seconds for one epoch ---
--- 1.4836504459381104 seconds for one epoch ---
--- 0.32549023628234863 seconds for one epoch ---
--- 1.4682285785675049 seconds for one epoch ---
--- 0.32828831672668457 seconds for one epoch ---
--- 1.4780428409576416 seconds for one epoch ---
--- 0.31314826011657715 seconds for one epoch ---
--- 1.4866712093353271 seconds for one epoch ---
--- 0.32094454765319824 seconds for one epoch ---
--- 1.4937236309051514 seconds for one epoch ---
--- 0.3299541473388672 seconds for one epoch ---
--- 1.4898509979248047 seconds for one epoch ---
--- 0.325528621673584 seconds for one epoch ---
--- 1.4866211414337158 seconds for one epoch ---
--- 0.3394625186920166 seconds for one epoch ---
--- 1.5078036785125732 seconds for one epoch ---
--- 0.3280055522918701 seconds for one epoch ---
--- 1.531336784362793 seconds for one epoch ---
--- 0.3273484706878662 seconds for one epoch ---
--- 1.4725563526153564 seconds for one epoch ---
--- 0.3282051086425781 seconds for one epoch ---
--- 1.480212926864624 seconds for one epoch ---
--- 0.3281252384185791 seconds for one epoch ---
=========================
[[0.99976164]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13870628]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.8513117 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.78648907]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0846863 ]
 [-0.        ]]
--- 0.26717185974121094 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3002.29541015625, (1800.8303, 1.4204241, 1199.4734, 0.57123584)
   validation loss 1231.6561279296875, (895.3278, 0.5152208, 335.2418, 0.57123584)
decoder loss ratio: 34686.554097, decoder SINDy loss  ratio: 0.723667
--- 0.3174898624420166 seconds for one epoch ---
--- 1.4899680614471436 seconds for one epoch ---
--- 0.3319582939147949 seconds for one epoch ---
--- 1.477092981338501 seconds for one epoch ---
--- 0.3317091464996338 seconds for one epoch ---
--- 1.4967191219329834 seconds for one epoch ---
--- 0.33365297317504883 seconds for one epoch ---
--- 1.5072124004364014 seconds for one epoch ---
--- 0.31319260597229004 seconds for one epoch ---
--- 1.502730369567871 seconds for one epoch ---
--- 0.33342576026916504 seconds for one epoch ---
--- 1.5209810733795166 seconds for one epoch ---
--- 0.33901119232177734 seconds for one epoch ---
--- 1.471620798110962 seconds for one epoch ---
--- 0.32663655281066895 seconds for one epoch ---
--- 1.5055835247039795 seconds for one epoch ---
--- 0.32878661155700684 seconds for one epoch ---
--- 1.513489007949829 seconds for one epoch ---
--- 0.3318147659301758 seconds for one epoch ---
--- 1.5111491680145264 seconds for one epoch ---
--- 0.3282921314239502 seconds for one epoch ---
--- 1.4970407485961914 seconds for one epoch ---
--- 0.3221566677093506 seconds for one epoch ---
--- 1.4812774658203125 seconds for one epoch ---
=========================
[[0.999778  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13774903]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999154]
 [0.        ]]
[[-2.8653405 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.78487176]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.0933332 ]
 [ 0.        ]]
--- 0.29456210136413574 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2657.824462890625, (1429.7656, 1.4701228, 1226.0168, 0.5719856)
   validation loss 881.2290649414062, (581.1631, 0.4168712, 299.07715, 0.5719856)
decoder loss ratio: 22515.266893, decoder SINDy loss  ratio: 0.645600
--- 0.2745084762573242 seconds for one epoch ---
--- 0.3252403736114502 seconds for one epoch ---
--- 1.4866271018981934 seconds for one epoch ---
--- 0.32288527488708496 seconds for one epoch ---
--- 1.4934844970703125 seconds for one epoch ---
--- 0.32875585556030273 seconds for one epoch ---
--- 1.4861133098602295 seconds for one epoch ---
--- 0.3254568576812744 seconds for one epoch ---
--- 1.4707081317901611 seconds for one epoch ---
--- 0.321333646774292 seconds for one epoch ---
--- 1.485468864440918 seconds for one epoch ---
--- 0.3264632225036621 seconds for one epoch ---
--- 1.4804680347442627 seconds for one epoch ---
--- 0.33657288551330566 seconds for one epoch ---
--- 1.4948103427886963 seconds for one epoch ---
--- 0.3178560733795166 seconds for one epoch ---
--- 1.4978251457214355 seconds for one epoch ---
--- 0.32354259490966797 seconds for one epoch ---
--- 1.48311185836792 seconds for one epoch ---
--- 0.33269786834716797 seconds for one epoch ---
--- 1.4913713932037354 seconds for one epoch ---
--- 0.3157672882080078 seconds for one epoch ---
--- 1.5113964080810547 seconds for one epoch ---
--- 0.3276379108428955 seconds for one epoch ---
=========================
[[0.99979746]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1409566 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999913 ]
 [0.        ]]
[[-2.8835628]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7902549]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.1020217]
 [ 0.       ]]
--- 0.25899195671081543 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4048.255126953125, (1114.5385, 3.4927995, 2929.6514, 0.5724125)
   validation loss 825.1511840820312, (538.0486, 0.4856201, 286.04462, 0.5724125)
decoder loss ratio: 20844.936237, decoder SINDy loss  ratio: 0.617468
--- 0.30695056915283203 seconds for one epoch ---
--- 1.522350788116455 seconds for one epoch ---
--- 0.3341023921966553 seconds for one epoch ---
--- 1.518401861190796 seconds for one epoch ---
--- 0.32659363746643066 seconds for one epoch ---
--- 1.4940805435180664 seconds for one epoch ---
--- 0.32941484451293945 seconds for one epoch ---
--- 1.5355963706970215 seconds for one epoch ---
--- 0.3251824378967285 seconds for one epoch ---
--- 1.5017468929290771 seconds for one epoch ---
--- 0.3354477882385254 seconds for one epoch ---
--- 1.4965167045593262 seconds for one epoch ---
--- 0.3302276134490967 seconds for one epoch ---
--- 1.532536268234253 seconds for one epoch ---
--- 0.3230478763580322 seconds for one epoch ---
--- 1.5107836723327637 seconds for one epoch ---
--- 0.32423853874206543 seconds for one epoch ---
--- 1.5290088653564453 seconds for one epoch ---
--- 0.3338918685913086 seconds for one epoch ---
--- 1.5301542282104492 seconds for one epoch ---
--- 0.32590651512145996 seconds for one epoch ---
--- 1.540130376815796 seconds for one epoch ---
--- 0.3431856632232666 seconds for one epoch ---
--- 1.506514310836792 seconds for one epoch ---
=========================
[[0.9998036 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13842222]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999913 ]
 [0.        ]]
[[-2.8924503 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.78601015]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.1034555 ]
 [-0.        ]]
--- 0.3084437847137451 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1863.894287109375, (737.0008, 1.2728661, 1125.048, 0.5726227)
   validation loss 835.84521484375, (520.1223, 0.55722916, 314.59302, 0.5726227)
decoder loss ratio: 20150.441434, decoder SINDy loss  ratio: 0.679093
--- 0.27313685417175293 seconds for one epoch ---
--- 0.3249492645263672 seconds for one epoch ---
--- 1.529909372329712 seconds for one epoch ---
--- 0.3281843662261963 seconds for one epoch ---
--- 1.5014941692352295 seconds for one epoch ---
--- 0.3316800594329834 seconds for one epoch ---
--- 1.5186066627502441 seconds for one epoch ---
--- 0.32099103927612305 seconds for one epoch ---
--- 1.495920181274414 seconds for one epoch ---
--- 0.35318732261657715 seconds for one epoch ---
--- 1.5105018615722656 seconds for one epoch ---
--- 0.32672715187072754 seconds for one epoch ---
--- 1.5394699573516846 seconds for one epoch ---
--- 0.32561326026916504 seconds for one epoch ---
--- 1.5183165073394775 seconds for one epoch ---
--- 0.324800968170166 seconds for one epoch ---
--- 1.533294439315796 seconds for one epoch ---
--- 0.323408842086792 seconds for one epoch ---
--- 1.5232000350952148 seconds for one epoch ---
--- 0.33298563957214355 seconds for one epoch ---
--- 1.503927230834961 seconds for one epoch ---
--- 0.3232893943786621 seconds for one epoch ---
--- 1.5551023483276367 seconds for one epoch ---
--- 0.3303554058074951 seconds for one epoch ---
=========================
[[0.999827  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1395852 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999285]
 [0.        ]]
[[-2.9186654]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.787966 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.1283655]
 [ 0.       ]]
--- 0.2751424312591553 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6279.67529296875, (1997.2509, 1.6610383, 4280.191, 0.5726671)
   validation loss 817.1035766601562, (513.88556, 0.548035, 302.09732, 0.5726671)
decoder loss ratio: 19908.818703, decoder SINDy loss  ratio: 0.652120
--- 0.32552552223205566 seconds for one epoch ---
--- 1.5238609313964844 seconds for one epoch ---
--- 0.3278822898864746 seconds for one epoch ---
--- 1.5501866340637207 seconds for one epoch ---
--- 0.32636475563049316 seconds for one epoch ---
--- 1.5193650722503662 seconds for one epoch ---
--- 0.33094120025634766 seconds for one epoch ---
--- 1.5234479904174805 seconds for one epoch ---
--- 0.33055782318115234 seconds for one epoch ---
--- 1.520758867263794 seconds for one epoch ---
--- 0.32700467109680176 seconds for one epoch ---
--- 1.520632266998291 seconds for one epoch ---
--- 0.3637230396270752 seconds for one epoch ---
--- 1.5368571281433105 seconds for one epoch ---
--- 0.32418322563171387 seconds for one epoch ---
--- 1.5511925220489502 seconds for one epoch ---
--- 0.32677578926086426 seconds for one epoch ---
--- 1.5468320846557617 seconds for one epoch ---
--- 0.3360626697540283 seconds for one epoch ---
--- 1.5386626720428467 seconds for one epoch ---
--- 0.3378567695617676 seconds for one epoch ---
--- 1.5578017234802246 seconds for one epoch ---
--- 0.31221747398376465 seconds for one epoch ---
--- 1.5589478015899658 seconds for one epoch ---
=========================
[[0.99983895]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13322368]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999285]
 [0.        ]]
[[-2.9289865]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.7770957]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.1381526]
 [-0.       ]]
--- 0.3049347400665283 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4400.3271484375, (1707.1179, 3.1735342, 2689.4639, 0.5717644)
   validation loss 917.2484130859375, (602.3533, 0.63889015, 313.68445, 0.5717644)
decoder loss ratio: 23336.211469, decoder SINDy loss  ratio: 0.677132
--- 0.2761659622192383 seconds for one epoch ---
--- 0.3277170658111572 seconds for one epoch ---
--- 1.545219898223877 seconds for one epoch ---
--- 0.31923937797546387 seconds for one epoch ---
--- 1.5356764793395996 seconds for one epoch ---
--- 0.32661008834838867 seconds for one epoch ---
--- 1.5414316654205322 seconds for one epoch ---
--- 0.3272671699523926 seconds for one epoch ---
--- 1.5366103649139404 seconds for one epoch ---
--- 0.31807923316955566 seconds for one epoch ---
--- 1.5338852405548096 seconds for one epoch ---
--- 0.32549095153808594 seconds for one epoch ---
--- 1.535862922668457 seconds for one epoch ---
--- 0.3246479034423828 seconds for one epoch ---
--- 1.5793354511260986 seconds for one epoch ---
--- 0.3281209468841553 seconds for one epoch ---
--- 1.5741519927978516 seconds for one epoch ---
--- 0.33289098739624023 seconds for one epoch ---
--- 1.560124397277832 seconds for one epoch ---
--- 0.32372164726257324 seconds for one epoch ---
--- 1.5920741558074951 seconds for one epoch ---
--- 0.32810497283935547 seconds for one epoch ---
--- 1.5925953388214111 seconds for one epoch ---
--- 0.3291337490081787 seconds for one epoch ---
=========================
[[0.99984527]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13222513]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999285]
 [0.        ]]
[[-2.942405  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.77534956]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.147298  ]
 [-0.        ]]
--- 0.27362608909606934 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4207.0732421875, (1016.8829, 8.637808, 3180.982, 0.5710112)
   validation loss 879.4240112304688, (580.74664, 0.56474215, 297.54163, 0.5710112)
decoder loss ratio: 22499.133173, decoder SINDy loss  ratio: 0.642285
--- 0.31592607498168945 seconds for one epoch ---
--- 1.5549793243408203 seconds for one epoch ---
--- 0.3329594135284424 seconds for one epoch ---
--- 1.5403289794921875 seconds for one epoch ---
--- 0.3222818374633789 seconds for one epoch ---
--- 1.5769915580749512 seconds for one epoch ---
--- 0.33538293838500977 seconds for one epoch ---
--- 1.5612177848815918 seconds for one epoch ---
--- 0.32512784004211426 seconds for one epoch ---
--- 1.5917091369628906 seconds for one epoch ---
--- 0.3335421085357666 seconds for one epoch ---
--- 1.5584254264831543 seconds for one epoch ---
--- 0.32590436935424805 seconds for one epoch ---
--- 1.570462942123413 seconds for one epoch ---
--- 0.3364589214324951 seconds for one epoch ---
--- 1.5542495250701904 seconds for one epoch ---
--- 0.32854795455932617 seconds for one epoch ---
--- 1.5584862232208252 seconds for one epoch ---
--- 0.33069586753845215 seconds for one epoch ---
--- 1.5880084037780762 seconds for one epoch ---
--- 0.3257720470428467 seconds for one epoch ---
--- 1.5537850856781006 seconds for one epoch ---
--- 0.3207247257232666 seconds for one epoch ---
--- 1.5779633522033691 seconds for one epoch ---
=========================
[[0.99986166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13518332]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-2.9613128 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.78048956]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.1576724 ]
 [ 0.        ]]
--- 0.30637240409851074 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4152.6962890625, (1800.4197, 3.7753797, 2347.93, 0.5714833)
   validation loss 944.84375, (619.07513, 0.4731266, 324.724, 0.5714833)
decoder loss ratio: 23984.045464, decoder SINDy loss  ratio: 0.700962
--- 0.27071666717529297 seconds for one epoch ---
--- 0.3278031349182129 seconds for one epoch ---
--- 1.5508079528808594 seconds for one epoch ---
--- 0.33142614364624023 seconds for one epoch ---
--- 1.5676863193511963 seconds for one epoch ---
--- 0.32942700386047363 seconds for one epoch ---
--- 1.5991027355194092 seconds for one epoch ---
--- 0.3410303592681885 seconds for one epoch ---
--- 1.5555942058563232 seconds for one epoch ---
--- 0.30759286880493164 seconds for one epoch ---
--- 1.612185001373291 seconds for one epoch ---
--- 0.32543349266052246 seconds for one epoch ---
--- 1.6101737022399902 seconds for one epoch ---
--- 0.33466029167175293 seconds for one epoch ---
--- 1.5679407119750977 seconds for one epoch ---
--- 0.3312211036682129 seconds for one epoch ---
--- 1.5991623401641846 seconds for one epoch ---
--- 0.3187835216522217 seconds for one epoch ---
--- 1.5737872123718262 seconds for one epoch ---
--- 0.3192594051361084 seconds for one epoch ---
--- 1.5764434337615967 seconds for one epoch ---
--- 0.3323187828063965 seconds for one epoch ---
--- 1.5668141841888428 seconds for one epoch ---
--- 0.3339526653289795 seconds for one epoch ---
=========================
[[0.99987113]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13863806]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-2.9808905 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.78637445]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.166686  ]
 [ 0.        ]]
--- 0.270876407623291 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2663.94482421875, (1652.1467, 1.5580091, 1009.66705, 0.572952)
   validation loss 1751.7257080078125, (1359.5237, 0.53382516, 391.09525, 0.572952)
decoder loss ratio: 52670.307664, decoder SINDy loss  ratio: 0.844234
--- 0.3231203556060791 seconds for one epoch ---
--- 1.5678153038024902 seconds for one epoch ---
--- 0.33469510078430176 seconds for one epoch ---
--- 1.5686070919036865 seconds for one epoch ---
--- 0.3283054828643799 seconds for one epoch ---
--- 1.595656156539917 seconds for one epoch ---
--- 0.32755184173583984 seconds for one epoch ---
--- 1.60483717918396 seconds for one epoch ---
--- 0.32996606826782227 seconds for one epoch ---
--- 1.573047399520874 seconds for one epoch ---
--- 0.32843446731567383 seconds for one epoch ---
--- 1.5915353298187256 seconds for one epoch ---
--- 0.3186652660369873 seconds for one epoch ---
--- 1.5911588668823242 seconds for one epoch ---
--- 0.3310821056365967 seconds for one epoch ---
--- 1.596083164215088 seconds for one epoch ---
--- 0.32288050651550293 seconds for one epoch ---
--- 1.591550588607788 seconds for one epoch ---
--- 0.613037109375 seconds for one epoch ---
--- 1.5885484218597412 seconds for one epoch ---
--- 0.32209014892578125 seconds for one epoch ---
--- 1.6003491878509521 seconds for one epoch ---
--- 0.3286747932434082 seconds for one epoch ---
--- 1.6021604537963867 seconds for one epoch ---
=========================
[[0.99988455]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13924749]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-2.9992018 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.78739923]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.178932  ]
 [-0.        ]]
--- 0.30960798263549805 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3646.88134765625, (1110.4388, 2.518806, 2533.3503, 0.5733058)
   validation loss 878.0189208984375, (547.9192, 0.58239275, 328.94403, 0.5733058)
decoder loss ratio: 21227.340629, decoder SINDy loss  ratio: 0.710072
--- 0.271104097366333 seconds for one epoch ---
--- 0.3390364646911621 seconds for one epoch ---
--- 1.6260018348693848 seconds for one epoch ---
--- 0.3337745666503906 seconds for one epoch ---
--- 1.5878257751464844 seconds for one epoch ---
--- 0.33953213691711426 seconds for one epoch ---
--- 1.5801820755004883 seconds for one epoch ---
--- 0.3201150894165039 seconds for one epoch ---
--- 1.5917787551879883 seconds for one epoch ---
--- 0.3272714614868164 seconds for one epoch ---
--- 1.6303274631500244 seconds for one epoch ---
--- 0.31916117668151855 seconds for one epoch ---
--- 1.590050458908081 seconds for one epoch ---
--- 0.32798123359680176 seconds for one epoch ---
--- 1.6274433135986328 seconds for one epoch ---
--- 0.3258059024810791 seconds for one epoch ---
--- 1.6035420894622803 seconds for one epoch ---
--- 0.32693934440612793 seconds for one epoch ---
--- 1.608077049255371 seconds for one epoch ---
--- 0.3259904384613037 seconds for one epoch ---
--- 1.590484857559204 seconds for one epoch ---
--- 0.32009267807006836 seconds for one epoch ---
--- 1.6194276809692383 seconds for one epoch ---
--- 0.33188676834106445 seconds for one epoch ---
=========================
[[0.9998902 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14076607]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.0149493]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7899379]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.1851206]
 [ 0.       ]]
--- 0.27765965461730957 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7240.28564453125, (1353.3826, 14.670529, 5871.658, 0.57419556)
   validation loss 860.904052734375, (548.14136, 0.60797447, 311.5805, 0.57419556)
decoder loss ratio: 21235.947802, decoder SINDy loss  ratio: 0.672590
--- 0.30567479133605957 seconds for one epoch ---
--- 1.5699195861816406 seconds for one epoch ---
--- 0.32729196548461914 seconds for one epoch ---
--- 1.6101491451263428 seconds for one epoch ---
--- 0.3397834300994873 seconds for one epoch ---
--- 1.6112067699432373 seconds for one epoch ---
--- 0.3120145797729492 seconds for one epoch ---
--- 1.61244797706604 seconds for one epoch ---
--- 0.3297884464263916 seconds for one epoch ---
--- 1.5935144424438477 seconds for one epoch ---
--- 0.3143939971923828 seconds for one epoch ---
--- 1.635474681854248 seconds for one epoch ---
--- 0.32183337211608887 seconds for one epoch ---
--- 1.5995063781738281 seconds for one epoch ---
--- 0.33599352836608887 seconds for one epoch ---
--- 1.6038682460784912 seconds for one epoch ---
--- 0.3263735771179199 seconds for one epoch ---
--- 1.5780208110809326 seconds for one epoch ---
--- 0.33586692810058594 seconds for one epoch ---
--- 1.632469892501831 seconds for one epoch ---
--- 0.32895636558532715 seconds for one epoch ---
--- 1.615004539489746 seconds for one epoch ---
--- 0.32529115676879883 seconds for one epoch ---
--- 1.6063573360443115 seconds for one epoch ---
=========================
[[0.9998963 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13681036]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.0256314 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.78327656]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.1946216 ]
 [-0.        ]]
--- 0.31498289108276367 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2620.4052734375, (1013.6063, 3.5308652, 1602.6953, 0.5727846)
   validation loss 892.1231689453125, (598.45935, 0.6431909, 292.4478, 0.5727846)
decoder loss ratio: 23185.354213, decoder SINDy loss  ratio: 0.631290
THRESHOLDING: 3 active coefficients
--- 0.26310110092163086 seconds for one epoch ---
--- 0.32533740997314453 seconds for one epoch ---
--- 1.648228645324707 seconds for one epoch ---
--- 0.3262162208557129 seconds for one epoch ---
--- 1.600447177886963 seconds for one epoch ---
--- 0.32054877281188965 seconds for one epoch ---
--- 1.6159801483154297 seconds for one epoch ---
--- 0.327012300491333 seconds for one epoch ---
--- 1.5981018543243408 seconds for one epoch ---
--- 0.3158900737762451 seconds for one epoch ---
--- 1.6117868423461914 seconds for one epoch ---
--- 0.3281135559082031 seconds for one epoch ---
--- 1.638000726699829 seconds for one epoch ---
--- 0.32785916328430176 seconds for one epoch ---
--- 1.6218509674072266 seconds for one epoch ---
--- 0.33039402961730957 seconds for one epoch ---
--- 1.6421489715576172 seconds for one epoch ---
--- 0.3210902214050293 seconds for one epoch ---
--- 1.6122312545776367 seconds for one epoch ---
--- 0.3281400203704834 seconds for one epoch ---
--- 1.6294994354248047 seconds for one epoch ---
--- 0.32401514053344727 seconds for one epoch ---
--- 1.6348066329956055 seconds for one epoch ---
--- 0.3290729522705078 seconds for one epoch ---
=========================
[[0.99990153]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13612932]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.0323312]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7821135]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.192244 ]
 [-0.       ]]
--- 0.2717585563659668 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3147.51318359375, (1431.847, 0.79567146, 1714.2976, 0.57275736)
   validation loss 1024.3157958984375, (727.2642, 0.5818398, 295.897, 0.57275736)
decoder loss ratio: 28175.478515, decoder SINDy loss  ratio: 0.638735
--- 0.3278930187225342 seconds for one epoch ---
--- 1.6118102073669434 seconds for one epoch ---
--- 0.3304595947265625 seconds for one epoch ---
--- 1.6372485160827637 seconds for one epoch ---
--- 0.3185911178588867 seconds for one epoch ---
--- 1.6197388172149658 seconds for one epoch ---
--- 0.3331453800201416 seconds for one epoch ---
--- 1.6164300441741943 seconds for one epoch ---
--- 0.3314173221588135 seconds for one epoch ---
--- 1.6241791248321533 seconds for one epoch ---
--- 0.33587169647216797 seconds for one epoch ---
--- 1.6171698570251465 seconds for one epoch ---
--- 0.32542872428894043 seconds for one epoch ---
--- 1.6471459865570068 seconds for one epoch ---
--- 0.3338663578033447 seconds for one epoch ---
--- 1.640998363494873 seconds for one epoch ---
--- 0.3287534713745117 seconds for one epoch ---
--- 1.662886619567871 seconds for one epoch ---
--- 0.32827162742614746 seconds for one epoch ---
--- 1.6197583675384521 seconds for one epoch ---
--- 0.32315778732299805 seconds for one epoch ---
--- 1.6237335205078125 seconds for one epoch ---
--- 0.325634241104126 seconds for one epoch ---
--- 1.615729570388794 seconds for one epoch ---
=========================
[[0.99990517]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13610491]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.0404012]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7820717]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.189372 ]
 [ 0.       ]]
--- 0.33016419410705566 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4330.05126953125, (1533.2886, 3.0203047, 2793.1702, 0.5724536)
   validation loss 842.3477172851562, (535.8442, 0.61925936, 305.3118, 0.5724536)
decoder loss ratio: 20759.533693, decoder SINDy loss  ratio: 0.659058
--- 0.2648935317993164 seconds for one epoch ---
--- 0.32800984382629395 seconds for one epoch ---
--- 1.6251449584960938 seconds for one epoch ---
--- 0.33202648162841797 seconds for one epoch ---
--- 1.6258950233459473 seconds for one epoch ---
--- 0.32680439949035645 seconds for one epoch ---
--- 1.6766655445098877 seconds for one epoch ---
--- 0.32402873039245605 seconds for one epoch ---
--- 1.6720890998840332 seconds for one epoch ---
--- 0.3307912349700928 seconds for one epoch ---
--- 1.6539421081542969 seconds for one epoch ---
--- 0.3267076015472412 seconds for one epoch ---
--- 1.6775517463684082 seconds for one epoch ---
--- 0.335559606552124 seconds for one epoch ---
--- 1.6387524604797363 seconds for one epoch ---
--- 0.323685884475708 seconds for one epoch ---
--- 1.6329591274261475 seconds for one epoch ---
--- 0.32687997817993164 seconds for one epoch ---
--- 1.6446218490600586 seconds for one epoch ---
--- 0.33565282821655273 seconds for one epoch ---
--- 1.6614861488342285 seconds for one epoch ---
--- 0.3310413360595703 seconds for one epoch ---
--- 1.645648717880249 seconds for one epoch ---
--- 0.33262133598327637 seconds for one epoch ---
=========================
[[0.9999069 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13182808]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.0499585 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.77465224]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.1975408 ]
 [ 0.        ]]
--- 0.26392054557800293 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3088.30712890625, (1070.4905, 0.25099194, 2016.9944, 0.5712995)
   validation loss 953.7321166992188, (619.6467, 0.7615714, 332.7525, 0.5712995)
decoder loss ratio: 24006.190017, decoder SINDy loss  ratio: 0.718293
--- 0.31260085105895996 seconds for one epoch ---
--- 1.658968210220337 seconds for one epoch ---
--- 0.3322429656982422 seconds for one epoch ---
--- 1.6632838249206543 seconds for one epoch ---
--- 0.3380300998687744 seconds for one epoch ---
--- 1.6575934886932373 seconds for one epoch ---
--- 0.33176493644714355 seconds for one epoch ---
--- 1.6435105800628662 seconds for one epoch ---
--- 0.32822680473327637 seconds for one epoch ---
--- 1.6954121589660645 seconds for one epoch ---
--- 0.32277488708496094 seconds for one epoch ---
--- 1.649031162261963 seconds for one epoch ---
--- 0.31795692443847656 seconds for one epoch ---
--- 1.6425800323486328 seconds for one epoch ---
--- 0.329021692276001 seconds for one epoch ---
--- 1.673865795135498 seconds for one epoch ---
--- 0.32161927223205566 seconds for one epoch ---
--- 1.6721670627593994 seconds for one epoch ---
--- 0.34371280670166016 seconds for one epoch ---
--- 1.6541547775268555 seconds for one epoch ---
--- 0.3375215530395508 seconds for one epoch ---
--- 1.6880276203155518 seconds for one epoch ---
--- 0.3317539691925049 seconds for one epoch ---
--- 1.6586086750030518 seconds for one epoch ---
=========================
[[0.9999096 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1285881 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.059247  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.76889503]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.20344   ]
 [-0.        ]]
--- 0.3112936019897461 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3268.234130859375, (1253.4363, 3.7848094, 2010.4429, 0.5700811)
   validation loss 1316.540771484375, (967.5398, 0.6850367, 347.74582, 0.5700811)
decoder loss ratio: 37484.171378, decoder SINDy loss  ratio: 0.750658
--- 0.2811586856842041 seconds for one epoch ---
--- 0.33221435546875 seconds for one epoch ---
--- 1.6795916557312012 seconds for one epoch ---
--- 0.32235288619995117 seconds for one epoch ---
--- 1.655935525894165 seconds for one epoch ---
--- 0.334197998046875 seconds for one epoch ---
--- 1.6700592041015625 seconds for one epoch ---
--- 0.3263685703277588 seconds for one epoch ---
--- 1.6682751178741455 seconds for one epoch ---
--- 0.33148837089538574 seconds for one epoch ---
--- 1.6689507961273193 seconds for one epoch ---
--- 0.33182382583618164 seconds for one epoch ---
--- 1.6742265224456787 seconds for one epoch ---
--- 0.3379223346710205 seconds for one epoch ---
--- 1.6669108867645264 seconds for one epoch ---
--- 0.3308401107788086 seconds for one epoch ---
--- 1.663339614868164 seconds for one epoch ---
--- 0.3212575912475586 seconds for one epoch ---
--- 1.6665747165679932 seconds for one epoch ---
--- 0.33701467514038086 seconds for one epoch ---
--- 1.6516990661621094 seconds for one epoch ---
--- 0.322312593460083 seconds for one epoch ---
--- 1.6787176132202148 seconds for one epoch ---
--- 0.3248152732849121 seconds for one epoch ---
=========================
[[0.9999169 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1279732 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999547]
 [0.        ]]
[[-3.07441  ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7677888]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.2150526]
 [ 0.       ]]
--- 0.2713189125061035 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3855.423583984375, (1546.4628, 1.2321979, 2307.1582, 0.57051504)
   validation loss 871.50146484375, (545.08563, 0.57237685, 325.27295, 0.57051504)
decoder loss ratio: 21117.563707, decoder SINDy loss  ratio: 0.702147
--- 0.30475854873657227 seconds for one epoch ---
--- 1.6483521461486816 seconds for one epoch ---
--- 0.32691407203674316 seconds for one epoch ---
--- 1.6856937408447266 seconds for one epoch ---
--- 0.33640408515930176 seconds for one epoch ---
--- 1.6856141090393066 seconds for one epoch ---
--- 0.322101354598999 seconds for one epoch ---
--- 1.678649663925171 seconds for one epoch ---
--- 0.32887697219848633 seconds for one epoch ---
--- 1.6596527099609375 seconds for one epoch ---
--- 0.33295297622680664 seconds for one epoch ---
--- 1.6618943214416504 seconds for one epoch ---
--- 0.3138105869293213 seconds for one epoch ---
--- 1.7049486637115479 seconds for one epoch ---
--- 0.3228011131286621 seconds for one epoch ---
--- 1.699054479598999 seconds for one epoch ---
--- 0.3281867504119873 seconds for one epoch ---
--- 1.691596508026123 seconds for one epoch ---
--- 0.33208298683166504 seconds for one epoch ---
--- 1.6938879489898682 seconds for one epoch ---
--- 0.34823012351989746 seconds for one epoch ---
--- 1.7014565467834473 seconds for one epoch ---
--- 0.33426642417907715 seconds for one epoch ---
--- 1.6771175861358643 seconds for one epoch ---
=========================
[[0.9999238 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12443   ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.0857427]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7613225]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.2271314]
 [-0.       ]]
--- 0.3154730796813965 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2546.52685546875, (1124.144, 1.4574904, 1420.3566, 0.5689448)
   validation loss 1503.4715576171875, (1131.8527, 0.659738, 370.39008, 0.5689448)
decoder loss ratio: 43849.937075, decoder SINDy loss  ratio: 0.799539
--- 0.2724149227142334 seconds for one epoch ---
--- 0.33545517921447754 seconds for one epoch ---
--- 1.6719987392425537 seconds for one epoch ---
--- 0.3323996067047119 seconds for one epoch ---
--- 1.6853559017181396 seconds for one epoch ---
--- 0.34285497665405273 seconds for one epoch ---
--- 1.6766595840454102 seconds for one epoch ---
--- 0.3353574275970459 seconds for one epoch ---
--- 1.6994783878326416 seconds for one epoch ---
--- 0.324216365814209 seconds for one epoch ---
--- 1.6929457187652588 seconds for one epoch ---
--- 0.32657694816589355 seconds for one epoch ---
--- 1.654306411743164 seconds for one epoch ---
--- 0.3068511486053467 seconds for one epoch ---
--- 1.704679012298584 seconds for one epoch ---
--- 0.3216731548309326 seconds for one epoch ---
--- 1.7073242664337158 seconds for one epoch ---
--- 0.3307480812072754 seconds for one epoch ---
--- 1.6733136177062988 seconds for one epoch ---
--- 0.33028316497802734 seconds for one epoch ---
--- 1.6805775165557861 seconds for one epoch ---
--- 0.33913230895996094 seconds for one epoch ---
--- 1.7006242275238037 seconds for one epoch ---
--- 0.3341798782348633 seconds for one epoch ---
=========================
[[0.99992764]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12549247]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.0982265 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.76327765]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.23269   ]
 [-0.        ]]
--- 0.26113176345825195 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3447.9267578125, (2103.5642, 3.4789073, 1340.314, 0.5695688)
   validation loss 1409.65087890625, (1101.2242, 0.62339723, 307.23358, 0.5695688)
decoder loss ratio: 42663.338990, decoder SINDy loss  ratio: 0.663207
--- 0.3187401294708252 seconds for one epoch ---
--- 1.6931288242340088 seconds for one epoch ---
--- 0.3317384719848633 seconds for one epoch ---
--- 1.7051467895507812 seconds for one epoch ---
--- 0.3299448490142822 seconds for one epoch ---
--- 1.692192554473877 seconds for one epoch ---
--- 0.33051013946533203 seconds for one epoch ---
--- 1.7299518585205078 seconds for one epoch ---
--- 0.31971025466918945 seconds for one epoch ---
--- 1.679255723953247 seconds for one epoch ---
--- 0.3305370807647705 seconds for one epoch ---
--- 1.7115685939788818 seconds for one epoch ---
--- 0.3535938262939453 seconds for one epoch ---
--- 1.6988558769226074 seconds for one epoch ---
--- 0.32497572898864746 seconds for one epoch ---
--- 1.710744857788086 seconds for one epoch ---
--- 0.3412129878997803 seconds for one epoch ---
--- 1.68074369430542 seconds for one epoch ---
--- 0.3239157199859619 seconds for one epoch ---
--- 1.7577357292175293 seconds for one epoch ---
--- 0.30961012840270996 seconds for one epoch ---
--- 1.710202693939209 seconds for one epoch ---
--- 0.33429527282714844 seconds for one epoch ---
--- 1.7047853469848633 seconds for one epoch ---
=========================
[[0.9999265 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11827418]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.0959392]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7497035]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.2293773]
 [ 0.       ]]
--- 0.30370664596557617 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5611.43359375, (1772.118, 4.671813, 3834.0767, 0.56752867)
   validation loss 1057.234619140625, (740.65186, 0.71843237, 315.29684, 0.56752867)
decoder loss ratio: 28694.138709, decoder SINDy loss  ratio: 0.680613
--- 0.2748258113861084 seconds for one epoch ---
--- 0.3272526264190674 seconds for one epoch ---
--- 1.7183642387390137 seconds for one epoch ---
--- 0.34125661849975586 seconds for one epoch ---
--- 1.6907124519348145 seconds for one epoch ---
--- 0.3227250576019287 seconds for one epoch ---
--- 1.6918272972106934 seconds for one epoch ---
--- 0.3368053436279297 seconds for one epoch ---
--- 1.6970624923706055 seconds for one epoch ---
--- 0.3281364440917969 seconds for one epoch ---
--- 1.7061784267425537 seconds for one epoch ---
--- 0.3248317241668701 seconds for one epoch ---
--- 1.7058818340301514 seconds for one epoch ---
--- 0.3166017532348633 seconds for one epoch ---
--- 1.689671516418457 seconds for one epoch ---
--- 0.329603910446167 seconds for one epoch ---
--- 1.6913292407989502 seconds for one epoch ---
--- 0.3242201805114746 seconds for one epoch ---
--- 1.692657232284546 seconds for one epoch ---
--- 0.3205852508544922 seconds for one epoch ---
--- 1.730111837387085 seconds for one epoch ---
--- 0.3281064033508301 seconds for one epoch ---
--- 1.6917762756347656 seconds for one epoch ---
--- 0.3161919116973877 seconds for one epoch ---
=========================
[[0.9999267 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11773396]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1090539]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7486593]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.240019 ]
 [ 0.       ]]
--- 0.2631821632385254 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3624.875244140625, (1453.5497, 1.1158688, 2169.642, 0.5675683)
   validation loss 791.5225830078125, (495.50598, 0.66978, 294.77927, 0.5675683)
decoder loss ratio: 19196.761957, decoder SINDy loss  ratio: 0.636323
--- 0.31925487518310547 seconds for one epoch ---
--- 1.732313871383667 seconds for one epoch ---
--- 0.33728981018066406 seconds for one epoch ---
--- 1.7004313468933105 seconds for one epoch ---
--- 0.33080077171325684 seconds for one epoch ---
--- 1.727501392364502 seconds for one epoch ---
--- 0.33533334732055664 seconds for one epoch ---
--- 1.717933177947998 seconds for one epoch ---
--- 0.3186931610107422 seconds for one epoch ---
--- 1.7284936904907227 seconds for one epoch ---
--- 0.3236372470855713 seconds for one epoch ---
--- 1.7251145839691162 seconds for one epoch ---
--- 0.33553576469421387 seconds for one epoch ---
--- 1.7306180000305176 seconds for one epoch ---
--- 0.3353753089904785 seconds for one epoch ---
--- 1.7085378170013428 seconds for one epoch ---
--- 0.33141660690307617 seconds for one epoch ---
--- 1.7303078174591064 seconds for one epoch ---
--- 0.3432941436767578 seconds for one epoch ---
--- 1.7146947383880615 seconds for one epoch ---
--- 0.32538580894470215 seconds for one epoch ---
--- 1.7472243309020996 seconds for one epoch ---
--- 0.32033419609069824 seconds for one epoch ---
--- 1.7056896686553955 seconds for one epoch ---
=========================
[[0.9999293 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11990199]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1164849]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.752826 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.2323503]
 [-0.       ]]
--- 0.3001894950866699 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6085.3544921875, (1756.726, 10.574619, 4317.4854, 0.5681238)
   validation loss 751.5205078125, (443.47675, 0.6884232, 306.7872, 0.5681238)
decoder loss ratio: 17181.059034, decoder SINDy loss  ratio: 0.662243
--- 0.2651858329772949 seconds for one epoch ---
--- 0.3140678405761719 seconds for one epoch ---
--- 1.6978673934936523 seconds for one epoch ---
--- 0.31005072593688965 seconds for one epoch ---
--- 1.7010776996612549 seconds for one epoch ---
--- 0.3360109329223633 seconds for one epoch ---
--- 1.7301089763641357 seconds for one epoch ---
--- 0.3270578384399414 seconds for one epoch ---
--- 1.7352244853973389 seconds for one epoch ---
--- 0.3288912773132324 seconds for one epoch ---
--- 1.7218527793884277 seconds for one epoch ---
--- 0.31492185592651367 seconds for one epoch ---
--- 1.73287034034729 seconds for one epoch ---
--- 0.32695984840393066 seconds for one epoch ---
--- 1.7417128086090088 seconds for one epoch ---
--- 0.33119654655456543 seconds for one epoch ---
--- 1.709993839263916 seconds for one epoch ---
--- 0.3330361843109131 seconds for one epoch ---
--- 1.7405970096588135 seconds for one epoch ---
--- 0.32206296920776367 seconds for one epoch ---
--- 1.7272236347198486 seconds for one epoch ---
--- 0.3300776481628418 seconds for one epoch ---
--- 1.7710669040679932 seconds for one epoch ---
--- 0.33368730545043945 seconds for one epoch ---
=========================
[[0.9999336 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12023818]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1321084 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.75346607]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.244519  ]
 [ 0.        ]]
--- 0.267925500869751 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1928.7847900390625, (829.7509, 1.1226262, 1097.3425, 0.56875676)
   validation loss 1019.2750854492188, (700.7704, 0.6746943, 317.26123, 0.56875676)
decoder loss ratio: 27149.061335, decoder SINDy loss  ratio: 0.684853
--- 0.32215428352355957 seconds for one epoch ---
--- 1.7421679496765137 seconds for one epoch ---
--- 0.3368418216705322 seconds for one epoch ---
--- 1.722139835357666 seconds for one epoch ---
--- 0.3369274139404297 seconds for one epoch ---
--- 1.7675936222076416 seconds for one epoch ---
--- 0.3244044780731201 seconds for one epoch ---
--- 1.7287287712097168 seconds for one epoch ---
--- 0.32622790336608887 seconds for one epoch ---
--- 1.713526725769043 seconds for one epoch ---
--- 0.3237640857696533 seconds for one epoch ---
--- 1.7459354400634766 seconds for one epoch ---
--- 0.3301994800567627 seconds for one epoch ---
--- 1.7558062076568604 seconds for one epoch ---
--- 0.3285713195800781 seconds for one epoch ---
--- 1.7666051387786865 seconds for one epoch ---
--- 0.33133721351623535 seconds for one epoch ---
--- 1.7242937088012695 seconds for one epoch ---
--- 0.3331420421600342 seconds for one epoch ---
--- 1.7582855224609375 seconds for one epoch ---
--- 0.32680487632751465 seconds for one epoch ---
--- 1.7415499687194824 seconds for one epoch ---
--- 0.33322691917419434 seconds for one epoch ---
--- 1.7669119834899902 seconds for one epoch ---
=========================
[[0.99993706]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12023181]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.141864  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.75345397]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.2472734 ]
 [-0.        ]]
--- 0.31992244720458984 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3002.33447265625, (1414.301, 0.45137426, 1587.0135, 0.568448)
   validation loss 816.9091796875, (505.58258, 0.70009667, 310.05807, 0.568448)
decoder loss ratio: 19587.146901, decoder SINDy loss  ratio: 0.669304
--- 0.2503798007965088 seconds for one epoch ---
--- 0.32907581329345703 seconds for one epoch ---
--- 1.7357327938079834 seconds for one epoch ---
--- 0.3355743885040283 seconds for one epoch ---
--- 1.7343692779541016 seconds for one epoch ---
--- 0.32772326469421387 seconds for one epoch ---
--- 1.7634913921356201 seconds for one epoch ---
--- 0.33458495140075684 seconds for one epoch ---
--- 1.743530035018921 seconds for one epoch ---
--- 0.3349735736846924 seconds for one epoch ---
--- 1.7496984004974365 seconds for one epoch ---
--- 0.3247251510620117 seconds for one epoch ---
--- 1.737724781036377 seconds for one epoch ---
--- 0.3201916217803955 seconds for one epoch ---
--- 1.752769947052002 seconds for one epoch ---
--- 0.31423306465148926 seconds for one epoch ---
--- 1.7503678798675537 seconds for one epoch ---
--- 0.32611703872680664 seconds for one epoch ---
--- 1.7827374935150146 seconds for one epoch ---
--- 0.32805609703063965 seconds for one epoch ---
--- 1.7657432556152344 seconds for one epoch ---
--- 0.32413196563720703 seconds for one epoch ---
--- 1.7927038669586182 seconds for one epoch ---
--- 0.3311145305633545 seconds for one epoch ---
=========================
[[0.99994123]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11927877]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1498077 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.75163496]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.2497244 ]
 [-0.        ]]
--- 0.2682301998138428 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2604.86669921875, (1587.3025, 1.3337106, 1015.6618, 0.5687244)
   validation loss 918.0964965820312, (617.6207, 0.742858, 299.16418, 0.5687244)
decoder loss ratio: 23927.699222, decoder SINDy loss  ratio: 0.645788
--- 0.31815075874328613 seconds for one epoch ---
--- 1.7703607082366943 seconds for one epoch ---
--- 0.33194828033447266 seconds for one epoch ---
--- 1.7702703475952148 seconds for one epoch ---
--- 0.3248615264892578 seconds for one epoch ---
--- 1.7592556476593018 seconds for one epoch ---
--- 0.33016419410705566 seconds for one epoch ---
--- 1.772191047668457 seconds for one epoch ---
--- 0.32144904136657715 seconds for one epoch ---
--- 1.7695610523223877 seconds for one epoch ---
--- 0.33556485176086426 seconds for one epoch ---
--- 1.7579829692840576 seconds for one epoch ---
--- 0.3331472873687744 seconds for one epoch ---
--- 1.7943158149719238 seconds for one epoch ---
--- 0.32700657844543457 seconds for one epoch ---
--- 1.779430866241455 seconds for one epoch ---
--- 0.3300290107727051 seconds for one epoch ---
--- 1.7483153343200684 seconds for one epoch ---
--- 0.3252260684967041 seconds for one epoch ---
--- 1.785358190536499 seconds for one epoch ---
--- 0.316896915435791 seconds for one epoch ---
--- 1.788954496383667 seconds for one epoch ---
--- 0.3338155746459961 seconds for one epoch ---
--- 1.7964708805084229 seconds for one epoch ---
=========================
[[0.99994993]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12158845]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1692746]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7560223]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.264842 ]
 [ 0.       ]]
--- 0.30480122566223145 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4744.24755859375, (1240.4454, 4.7322106, 3498.5007, 0.569189)
   validation loss 828.5886840820312, (529.9155, 0.67795044, 297.42596, 0.569189)
decoder loss ratio: 20529.847503, decoder SINDy loss  ratio: 0.642036
--- 0.2601354122161865 seconds for one epoch ---
--- 0.3177614212036133 seconds for one epoch ---
--- 1.748992919921875 seconds for one epoch ---
--- 0.327725887298584 seconds for one epoch ---
--- 1.800063133239746 seconds for one epoch ---
--- 0.31487154960632324 seconds for one epoch ---
--- 1.8000719547271729 seconds for one epoch ---
--- 0.32358884811401367 seconds for one epoch ---
--- 1.793335199356079 seconds for one epoch ---
--- 0.325178861618042 seconds for one epoch ---
--- 1.7572553157806396 seconds for one epoch ---
--- 0.32736873626708984 seconds for one epoch ---
--- 1.7848002910614014 seconds for one epoch ---
--- 0.3155992031097412 seconds for one epoch ---
--- 1.7844657897949219 seconds for one epoch ---
--- 0.32189011573791504 seconds for one epoch ---
--- 1.7778093814849854 seconds for one epoch ---
--- 0.3046538829803467 seconds for one epoch ---
--- 1.819169521331787 seconds for one epoch ---
--- 0.32955169677734375 seconds for one epoch ---
--- 1.7716944217681885 seconds for one epoch ---
--- 0.31722593307495117 seconds for one epoch ---
--- 1.7936716079711914 seconds for one epoch ---
--- 0.33350706100463867 seconds for one epoch ---
=========================
[[0.9999518 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12345251]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1817818]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7595112]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.268833 ]
 [ 0.       ]]
--- 0.27110743522644043 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1934.5364990234375, (1108.7191, 0.9592604, 824.2884, 0.5696673)
   validation loss 823.1556396484375, (521.851, 0.8559736, 299.87903, 0.5696673)
decoder loss ratio: 20217.414224, decoder SINDy loss  ratio: 0.647331
--- 0.31656861305236816 seconds for one epoch ---
--- 1.7635443210601807 seconds for one epoch ---
--- 0.32952427864074707 seconds for one epoch ---
--- 1.7835805416107178 seconds for one epoch ---
--- 0.3282132148742676 seconds for one epoch ---
--- 1.7612364292144775 seconds for one epoch ---
--- 0.3222963809967041 seconds for one epoch ---
--- 1.7945685386657715 seconds for one epoch ---
--- 0.328263521194458 seconds for one epoch ---
--- 1.804617166519165 seconds for one epoch ---
--- 0.33641600608825684 seconds for one epoch ---
--- 1.7960238456726074 seconds for one epoch ---
--- 0.3260514736175537 seconds for one epoch ---
--- 1.7794394493103027 seconds for one epoch ---
--- 0.33188652992248535 seconds for one epoch ---
--- 1.7879645824432373 seconds for one epoch ---
--- 0.33086252212524414 seconds for one epoch ---
--- 1.7728371620178223 seconds for one epoch ---
--- 0.32251954078674316 seconds for one epoch ---
--- 1.8173949718475342 seconds for one epoch ---
--- 0.32764673233032227 seconds for one epoch ---
--- 1.7746248245239258 seconds for one epoch ---
--- 0.32785534858703613 seconds for one epoch ---
--- 1.796267032623291 seconds for one epoch ---
=========================
[[0.9999513 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11936125]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1871183]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.7517926]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.274327 ]
 [-0.       ]]
--- 0.3014099597930908 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2181.452392578125, (1028.0256, 0.43827444, 1152.4199, 0.5686703)
   validation loss 1009.9190063476562, (716.9081, 0.7334055, 291.70883, 0.5686703)
decoder loss ratio: 27774.263667, decoder SINDy loss  ratio: 0.629695
--- 0.2725536823272705 seconds for one epoch ---
--- 0.32975292205810547 seconds for one epoch ---
--- 1.801941156387329 seconds for one epoch ---
--- 0.334092378616333 seconds for one epoch ---
--- 1.8074531555175781 seconds for one epoch ---
--- 0.3360602855682373 seconds for one epoch ---
--- 1.787031650543213 seconds for one epoch ---
--- 0.33118414878845215 seconds for one epoch ---
--- 1.7819201946258545 seconds for one epoch ---
--- 0.32703590393066406 seconds for one epoch ---
--- 1.7910327911376953 seconds for one epoch ---
--- 0.33184289932250977 seconds for one epoch ---
--- 1.7881784439086914 seconds for one epoch ---
--- 0.3232698440551758 seconds for one epoch ---
--- 1.7761034965515137 seconds for one epoch ---
--- 0.31629276275634766 seconds for one epoch ---
--- 1.7763383388519287 seconds for one epoch ---
--- 0.3273038864135742 seconds for one epoch ---
--- 1.814758062362671 seconds for one epoch ---
--- 0.3151404857635498 seconds for one epoch ---
--- 1.7879421710968018 seconds for one epoch ---
--- 0.3265535831451416 seconds for one epoch ---
--- 1.8402318954467773 seconds for one epoch ---
--- 0.32190585136413574 seconds for one epoch ---
=========================
[[0.9999511 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11849643]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.1951222]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.750132 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.276875 ]
 [ 0.       ]]
--- 0.2725050449371338 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3778.6572265625, (1738.1902, 1.9829307, 2037.9155, 0.56870884)
   validation loss 791.3944091796875, (502.7017, 0.90839714, 287.21564, 0.56870884)
decoder loss ratio: 19475.536225, decoder SINDy loss  ratio: 0.619995
--- 0.31772303581237793 seconds for one epoch ---
--- 1.7962687015533447 seconds for one epoch ---
--- 0.32697105407714844 seconds for one epoch ---
--- 1.8265330791473389 seconds for one epoch ---
--- 0.33214378356933594 seconds for one epoch ---
--- 1.8181359767913818 seconds for one epoch ---
--- 0.33492326736450195 seconds for one epoch ---
--- 1.8078343868255615 seconds for one epoch ---
--- 0.33384275436401367 seconds for one epoch ---
--- 1.8080058097839355 seconds for one epoch ---
--- 0.3307023048400879 seconds for one epoch ---
--- 1.8350346088409424 seconds for one epoch ---
--- 0.3205862045288086 seconds for one epoch ---
--- 1.7898647785186768 seconds for one epoch ---
--- 0.3263263702392578 seconds for one epoch ---
--- 1.816831350326538 seconds for one epoch ---
--- 0.32152462005615234 seconds for one epoch ---
--- 1.7894260883331299 seconds for one epoch ---
--- 0.3212416172027588 seconds for one epoch ---
--- 1.8185689449310303 seconds for one epoch ---
--- 0.3322715759277344 seconds for one epoch ---
--- 1.8037762641906738 seconds for one epoch ---
--- 0.33155012130737305 seconds for one epoch ---
--- 1.8511967658996582 seconds for one epoch ---
=========================
[[0.9999511 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1102543 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.196301  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.73375463]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.2833834 ]
 [-0.        ]]
--- 0.31386494636535645 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2516.103515625, (911.78345, 1.3255647, 1602.4287, 0.5659154)
   validation loss 710.4532470703125, (394.09192, 0.83479345, 314.96057, 0.5659154)
decoder loss ratio: 15267.805114, decoder SINDy loss  ratio: 0.679887
--- 0.27706241607666016 seconds for one epoch ---
--- 0.3299570083618164 seconds for one epoch ---
--- 1.8154566287994385 seconds for one epoch ---
--- 0.3235197067260742 seconds for one epoch ---
--- 1.8244059085845947 seconds for one epoch ---
--- 0.3178257942199707 seconds for one epoch ---
--- 1.800098180770874 seconds for one epoch ---
--- 0.32593846321105957 seconds for one epoch ---
--- 1.8382904529571533 seconds for one epoch ---
--- 0.3195302486419678 seconds for one epoch ---
--- 1.8105580806732178 seconds for one epoch ---
--- 0.320697546005249 seconds for one epoch ---
--- 1.8269999027252197 seconds for one epoch ---
--- 0.324387788772583 seconds for one epoch ---
--- 1.8275327682495117 seconds for one epoch ---
--- 0.327350378036499 seconds for one epoch ---
--- 1.8505868911743164 seconds for one epoch ---
--- 0.3272969722747803 seconds for one epoch ---
--- 1.8263676166534424 seconds for one epoch ---
--- 0.33030056953430176 seconds for one epoch ---
--- 1.806563377380371 seconds for one epoch ---
--- 0.33405137062072754 seconds for one epoch ---
--- 1.8196961879730225 seconds for one epoch ---
--- 0.32477498054504395 seconds for one epoch ---
=========================
[[0.9999509 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10853437]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.206903  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.73020303]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.2942276 ]
 [-0.        ]]
--- 0.27265167236328125 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4871.38330078125, (1668.8811, 1.4960883, 3200.4402, 0.5657003)
   validation loss 1013.251953125, (642.1462, 0.73143184, 369.80865, 0.5657003)
decoder loss ratio: 24877.857797, decoder SINDy loss  ratio: 0.798284
--- 0.3144497871398926 seconds for one epoch ---
--- 1.8384840488433838 seconds for one epoch ---
--- 0.33515191078186035 seconds for one epoch ---
--- 1.8310210704803467 seconds for one epoch ---
--- 0.3250892162322998 seconds for one epoch ---
--- 1.7979657649993896 seconds for one epoch ---
--- 0.3246338367462158 seconds for one epoch ---
--- 1.8384358882904053 seconds for one epoch ---
--- 0.323091983795166 seconds for one epoch ---
--- 1.8429756164550781 seconds for one epoch ---
--- 0.33798980712890625 seconds for one epoch ---
--- 1.8166005611419678 seconds for one epoch ---
--- 0.32253336906433105 seconds for one epoch ---
--- 1.8032629489898682 seconds for one epoch ---
--- 0.3387610912322998 seconds for one epoch ---
--- 1.8168377876281738 seconds for one epoch ---
--- 0.3335280418395996 seconds for one epoch ---
--- 1.8742039203643799 seconds for one epoch ---
--- 0.3330254554748535 seconds for one epoch ---
--- 1.8515141010284424 seconds for one epoch ---
--- 0.330629825592041 seconds for one epoch ---
--- 1.850461721420288 seconds for one epoch ---
--- 0.32246971130371094 seconds for one epoch ---
--- 1.8171439170837402 seconds for one epoch ---
=========================
[[0.99995136]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10860514]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]]
[[-3.2213883]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7303505]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.3077726]
 [ 0.       ]]
--- 0.3150660991668701 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3337.9951171875, (1238.1309, 1.0189575, 2098.2798, 0.56543934)
   validation loss 882.281494140625, (578.3123, 0.7642166, 302.63953, 0.56543934)
decoder loss ratio: 22404.823151, decoder SINDy loss  ratio: 0.653290
THRESHOLDING: 3 active coefficients
--- 1.824681043624878 seconds for one epoch ---
--- 0.33341121673583984 seconds for one epoch ---
--- 1.821869134902954 seconds for one epoch ---
--- 0.3306448459625244 seconds for one epoch ---
--- 1.8241117000579834 seconds for one epoch ---
--- 0.32790327072143555 seconds for one epoch ---
--- 1.8233211040496826 seconds for one epoch ---
--- 0.329923152923584 seconds for one epoch ---
--- 1.883300542831421 seconds for one epoch ---
--- 0.32570719718933105 seconds for one epoch ---
--- 1.8631584644317627 seconds for one epoch ---
--- 0.322040319442749 seconds for one epoch ---
--- 1.8486676216125488 seconds for one epoch ---
--- 0.32279253005981445 seconds for one epoch ---
--- 1.8583331108093262 seconds for one epoch ---
--- 0.3217496871948242 seconds for one epoch ---
--- 1.856184959411621 seconds for one epoch ---
--- 0.33037424087524414 seconds for one epoch ---
--- 1.8285393714904785 seconds for one epoch ---
--- 0.3257145881652832 seconds for one epoch ---
--- 1.8793423175811768 seconds for one epoch ---
--- 0.3283705711364746 seconds for one epoch ---
--- 1.8741867542266846 seconds for one epoch ---
--- 0.3164947032928467 seconds for one epoch ---
=========================
[[0.9999513 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10811197]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]]
[[-3.225668 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7293235]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.303577 ]
 [ 0.       ]]
--- 0.27530670166015625 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5844.93115234375, (1860.482, 3.847862, 3980.036, 0.56543857)
   validation loss 722.2449951171875, (430.74103, 0.74152994, 290.19705, 0.56543857)
decoder loss ratio: 16687.655218, decoder SINDy loss  ratio: 0.626431
--- 0.30869174003601074 seconds for one epoch ---
--- 1.8762757778167725 seconds for one epoch ---
--- 0.32790064811706543 seconds for one epoch ---
--- 1.8805973529815674 seconds for one epoch ---
--- 0.3364560604095459 seconds for one epoch ---
--- 1.8413548469543457 seconds for one epoch ---
--- 0.33108949661254883 seconds for one epoch ---
--- 1.863581657409668 seconds for one epoch ---
--- 0.3248012065887451 seconds for one epoch ---
--- 1.9109392166137695 seconds for one epoch ---
--- 0.31729674339294434 seconds for one epoch ---
--- 1.851844310760498 seconds for one epoch ---
--- 0.32762813568115234 seconds for one epoch ---
--- 1.909456729888916 seconds for one epoch ---
--- 0.33493709564208984 seconds for one epoch ---
--- 1.8860855102539062 seconds for one epoch ---
--- 0.32591938972473145 seconds for one epoch ---
--- 1.864558219909668 seconds for one epoch ---
--- 0.325153112411499 seconds for one epoch ---
--- 1.878936767578125 seconds for one epoch ---
--- 0.33400511741638184 seconds for one epoch ---
--- 1.8876757621765137 seconds for one epoch ---
--- 0.3306760787963867 seconds for one epoch ---
--- 1.8961398601531982 seconds for one epoch ---
=========================
[[0.99995184]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10637699]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]]
[[-3.232541]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.725678]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-4.309178]
 [-0.      ]]
--- 0.31291937828063965 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18313.330078125, (1616.399, 1.830822, 16694.535, 0.564823)
   validation loss 751.357421875, (445.8114, 0.8141088, 304.16708, 0.564823)
decoder loss ratio: 17271.507652, decoder SINDy loss  ratio: 0.656587
--- 0.27042460441589355 seconds for one epoch ---
--- 0.3287982940673828 seconds for one epoch ---
--- 1.8779408931732178 seconds for one epoch ---
--- 0.330639123916626 seconds for one epoch ---
--- 1.9096770286560059 seconds for one epoch ---
--- 0.3334479331970215 seconds for one epoch ---
--- 1.8720059394836426 seconds for one epoch ---
--- 0.33238983154296875 seconds for one epoch ---
--- 1.8743133544921875 seconds for one epoch ---
--- 0.34113454818725586 seconds for one epoch ---
--- 1.880619764328003 seconds for one epoch ---
--- 0.33187079429626465 seconds for one epoch ---
--- 1.8658630847930908 seconds for one epoch ---
--- 0.32962822914123535 seconds for one epoch ---
--- 1.8906583786010742 seconds for one epoch ---
--- 0.3316061496734619 seconds for one epoch ---
--- 1.9009766578674316 seconds for one epoch ---
--- 0.32208967208862305 seconds for one epoch ---
--- 1.9030630588531494 seconds for one epoch ---
--- 0.33307981491088867 seconds for one epoch ---
--- 1.8994064331054688 seconds for one epoch ---
--- 0.3387796878814697 seconds for one epoch ---
--- 1.882904291152954 seconds for one epoch ---
--- 0.33287906646728516 seconds for one epoch ---
=========================
[[0.99995446]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11057201]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]]
[[-3.2440314]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7344056]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.3074703]
 [ 0.       ]]
--- 0.27237677574157715 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2584.828857421875, (1349.1239, 2.4603097, 1232.6785, 0.56626093)
   validation loss 730.0230712890625, (403.82263, 0.8463062, 324.7878, 0.56626093)
decoder loss ratio: 15644.789824, decoder SINDy loss  ratio: 0.701100
--- 0.3257579803466797 seconds for one epoch ---
--- 1.9089820384979248 seconds for one epoch ---
--- 0.3268299102783203 seconds for one epoch ---
--- 1.889500617980957 seconds for one epoch ---
--- 0.33216404914855957 seconds for one epoch ---
--- 1.9163050651550293 seconds for one epoch ---
--- 0.33476972579956055 seconds for one epoch ---
--- 1.9016473293304443 seconds for one epoch ---
--- 0.3237495422363281 seconds for one epoch ---
--- 1.9123058319091797 seconds for one epoch ---
--- 0.33413243293762207 seconds for one epoch ---
--- 1.9068961143493652 seconds for one epoch ---
--- 0.33591580390930176 seconds for one epoch ---
--- 1.8923990726470947 seconds for one epoch ---
--- 0.33226919174194336 seconds for one epoch ---
--- 1.9017448425292969 seconds for one epoch ---
--- 0.3351123332977295 seconds for one epoch ---
--- 1.9428858757019043 seconds for one epoch ---
--- 0.3367600440979004 seconds for one epoch ---
--- 1.8906564712524414 seconds for one epoch ---
--- 0.328566312789917 seconds for one epoch ---
--- 1.9168806076049805 seconds for one epoch ---
--- 0.331881046295166 seconds for one epoch ---
--- 1.887359857559204 seconds for one epoch ---
=========================
[[0.99995863]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11155497]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]]
[[-3.2579706 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.73640853]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.318977  ]
 [-0.        ]]
--- 0.3016486167907715 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1697.8048095703125, (904.1066, 1.8653494, 791.2662, 0.56664604)
   validation loss 956.2875366210938, (649.64496, 0.82150054, 305.25446, 0.56664604)
decoder loss ratio: 25168.373525, decoder SINDy loss  ratio: 0.658935
--- 0.28209614753723145 seconds for one epoch ---
--- 0.33284854888916016 seconds for one epoch ---
--- 1.932784080505371 seconds for one epoch ---
--- 0.3229351043701172 seconds for one epoch ---
--- 1.906601905822754 seconds for one epoch ---
--- 0.29718852043151855 seconds for one epoch ---
--- 1.9206371307373047 seconds for one epoch ---
--- 0.3387110233306885 seconds for one epoch ---
--- 1.9120244979858398 seconds for one epoch ---
--- 0.33452486991882324 seconds for one epoch ---
--- 1.8861567974090576 seconds for one epoch ---
--- 0.32340502738952637 seconds for one epoch ---
--- 1.9056568145751953 seconds for one epoch ---
--- 0.3277456760406494 seconds for one epoch ---
--- 1.9060227870941162 seconds for one epoch ---
--- 0.3320279121398926 seconds for one epoch ---
--- 1.9280223846435547 seconds for one epoch ---
--- 0.3277418613433838 seconds for one epoch ---
--- 1.9238872528076172 seconds for one epoch ---
--- 0.3339385986328125 seconds for one epoch ---
--- 1.9205143451690674 seconds for one epoch ---
--- 0.32663726806640625 seconds for one epoch ---
--- 1.940037727355957 seconds for one epoch ---
--- 0.32193994522094727 seconds for one epoch ---
=========================
[[0.9999625 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11035703]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.2714965]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.7339654]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.3324876]
 [-0.       ]]
--- 0.2749335765838623 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2656.971435546875, (1271.1207, 0.664652, 1384.6193, 0.56674063)
   validation loss 787.2107543945312, (474.5283, 0.90827984, 311.20743, 0.56674063)
decoder loss ratio: 18384.049764, decoder SINDy loss  ratio: 0.671785
--- 0.313610315322876 seconds for one epoch ---
--- 1.9198906421661377 seconds for one epoch ---
--- 0.3327677249908447 seconds for one epoch ---
--- 1.8805179595947266 seconds for one epoch ---
--- 0.3242933750152588 seconds for one epoch ---
--- 1.9388718605041504 seconds for one epoch ---
--- 0.33312129974365234 seconds for one epoch ---
--- 1.9238719940185547 seconds for one epoch ---
--- 0.3300650119781494 seconds for one epoch ---
--- 1.8986175060272217 seconds for one epoch ---
--- 0.33515262603759766 seconds for one epoch ---
--- 1.939884901046753 seconds for one epoch ---
--- 0.32112956047058105 seconds for one epoch ---
--- 1.9333806037902832 seconds for one epoch ---
--- 0.3311319351196289 seconds for one epoch ---
--- 1.925260066986084 seconds for one epoch ---
--- 0.31944823265075684 seconds for one epoch ---
--- 1.9160289764404297 seconds for one epoch ---
--- 0.33483195304870605 seconds for one epoch ---
--- 1.9028737545013428 seconds for one epoch ---
--- 0.32588958740234375 seconds for one epoch ---
--- 1.9152374267578125 seconds for one epoch ---
--- 0.32883119583129883 seconds for one epoch ---
--- 1.9524626731872559 seconds for one epoch ---
=========================
[[0.99996614]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11008651]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.2808335]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7334108]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.3368745]
 [ 0.       ]]
--- 0.312361478805542 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3869.755615234375, (1632.5745, 1.3284738, 2235.286, 0.5667266)
   validation loss 903.7438354492188, (584.0189, 0.8508231, 318.3074, 0.5667266)
decoder loss ratio: 22625.906897, decoder SINDy loss  ratio: 0.687111
--- 0.28027772903442383 seconds for one epoch ---
--- 0.32059741020202637 seconds for one epoch ---
--- 1.9417970180511475 seconds for one epoch ---
--- 0.3395066261291504 seconds for one epoch ---
--- 1.913294792175293 seconds for one epoch ---
--- 0.32378053665161133 seconds for one epoch ---
--- 1.9301061630249023 seconds for one epoch ---
--- 0.3312551975250244 seconds for one epoch ---
--- 1.9576137065887451 seconds for one epoch ---
--- 0.32912731170654297 seconds for one epoch ---
--- 1.9136643409729004 seconds for one epoch ---
--- 0.32775068283081055 seconds for one epoch ---
--- 1.9099113941192627 seconds for one epoch ---
--- 0.322857141494751 seconds for one epoch ---
--- 1.9387497901916504 seconds for one epoch ---
--- 0.33231592178344727 seconds for one epoch ---
--- 1.9509258270263672 seconds for one epoch ---
--- 0.34377551078796387 seconds for one epoch ---
--- 1.913874626159668 seconds for one epoch ---
--- 0.31462645530700684 seconds for one epoch ---
--- 1.9215588569641113 seconds for one epoch ---
--- 0.330202579498291 seconds for one epoch ---
--- 1.9659056663513184 seconds for one epoch ---
--- 0.32315993309020996 seconds for one epoch ---
=========================
[[0.9999713 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11069006]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.2924166]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7346471]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.344331 ]
 [ 0.       ]]
--- 0.2649965286254883 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3604.49853515625, (2151.554, 3.7011967, 1448.6766, 0.5668853)
   validation loss 745.820556640625, (427.81934, 0.9232121, 316.51114, 0.5668853)
decoder loss ratio: 16574.463801, decoder SINDy loss  ratio: 0.683234
--- 0.31266140937805176 seconds for one epoch ---
--- 1.9360291957855225 seconds for one epoch ---
--- 0.33959054946899414 seconds for one epoch ---
--- 1.9145002365112305 seconds for one epoch ---
--- 0.33265066146850586 seconds for one epoch ---
--- 1.9543862342834473 seconds for one epoch ---
--- 0.3280527591705322 seconds for one epoch ---
--- 1.9321603775024414 seconds for one epoch ---
--- 0.32748937606811523 seconds for one epoch ---
--- 1.9195060729980469 seconds for one epoch ---
--- 0.3292522430419922 seconds for one epoch ---
--- 1.944725751876831 seconds for one epoch ---
--- 0.3330557346343994 seconds for one epoch ---
--- 1.9716174602508545 seconds for one epoch ---
--- 0.32570672035217285 seconds for one epoch ---
--- 1.9239490032196045 seconds for one epoch ---
--- 0.32404422760009766 seconds for one epoch ---
--- 1.9760017395019531 seconds for one epoch ---
--- 0.3309977054595947 seconds for one epoch ---
--- 1.9680266380310059 seconds for one epoch ---
--- 0.3161590099334717 seconds for one epoch ---
--- 1.9406406879425049 seconds for one epoch ---
--- 0.321087121963501 seconds for one epoch ---
--- 1.9374351501464844 seconds for one epoch ---
=========================
[[0.99997306]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10919347]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.2951512]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.73157  ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.3404665]
 [-0.       ]]
--- 0.31243443489074707 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2433.73046875, (1105.1221, 0.3835435, 1327.6583, 0.5664646)
   validation loss 751.9396362304688, (461.9659, 0.8523612, 288.55487, 0.5664646)
decoder loss ratio: 17897.361434, decoder SINDy loss  ratio: 0.622886
--- 0.27006006240844727 seconds for one epoch ---
--- 0.3038911819458008 seconds for one epoch ---
--- 1.9288556575775146 seconds for one epoch ---
--- 0.3282909393310547 seconds for one epoch ---
--- 1.9538657665252686 seconds for one epoch ---
--- 0.33547496795654297 seconds for one epoch ---
--- 1.9741077423095703 seconds for one epoch ---
--- 0.32581210136413574 seconds for one epoch ---
--- 1.9462928771972656 seconds for one epoch ---
--- 0.32591962814331055 seconds for one epoch ---
--- 1.965864896774292 seconds for one epoch ---
--- 0.32794785499572754 seconds for one epoch ---
--- 1.9514353275299072 seconds for one epoch ---
--- 0.32291460037231445 seconds for one epoch ---
--- 1.9822866916656494 seconds for one epoch ---
--- 0.330843448638916 seconds for one epoch ---
--- 1.9487481117248535 seconds for one epoch ---
--- 0.3221445083618164 seconds for one epoch ---
--- 1.9382121562957764 seconds for one epoch ---
--- 0.3259713649749756 seconds for one epoch ---
--- 1.9410550594329834 seconds for one epoch ---
--- 0.3203589916229248 seconds for one epoch ---
--- 1.9479682445526123 seconds for one epoch ---
--- 0.3191866874694824 seconds for one epoch ---
=========================
[[0.99997604]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11172214]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3068144]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.736748 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.34309  ]
 [ 0.       ]]
--- 0.2769312858581543 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2238.183349609375, (1045.4979, 1.4088815, 1190.7094, 0.56724596)
   validation loss 1317.1065673828125, (978.4504, 0.84115094, 337.2478, 0.56724596)
decoder loss ratio: 37906.866324, decoder SINDy loss  ratio: 0.727997
--- 0.30745768547058105 seconds for one epoch ---
--- 1.9775025844573975 seconds for one epoch ---
--- 0.33862972259521484 seconds for one epoch ---
--- 1.951139211654663 seconds for one epoch ---
--- 0.3199934959411621 seconds for one epoch ---
--- 1.9609062671661377 seconds for one epoch ---
--- 0.33094191551208496 seconds for one epoch ---
--- 1.9522767066955566 seconds for one epoch ---
--- 0.32457399368286133 seconds for one epoch ---
--- 1.9694700241088867 seconds for one epoch ---
--- 0.33056044578552246 seconds for one epoch ---
--- 1.9973664283752441 seconds for one epoch ---
--- 0.33327269554138184 seconds for one epoch ---
--- 1.952873945236206 seconds for one epoch ---
--- 0.3323400020599365 seconds for one epoch ---
--- 1.9815661907196045 seconds for one epoch ---
--- 0.3316342830657959 seconds for one epoch ---
--- 2.001678943634033 seconds for one epoch ---
--- 0.327742338180542 seconds for one epoch ---
--- 1.9710862636566162 seconds for one epoch ---
--- 0.3326094150543213 seconds for one epoch ---
--- 1.9630842208862305 seconds for one epoch ---
--- 0.3311655521392822 seconds for one epoch ---
--- 1.9638557434082031 seconds for one epoch ---
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11167904]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3149076 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.73666036]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.3457665 ]
 [-0.        ]]
--- 0.300922155380249 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2029.858154296875, (798.5426, 1.5315472, 1229.2168, 0.5671754)
   validation loss 979.83056640625, (656.21735, 0.81085044, 322.23517, 0.5671754)
decoder loss ratio: 25422.999235, decoder SINDy loss  ratio: 0.695590
--- 0.268796443939209 seconds for one epoch ---
--- 0.3247971534729004 seconds for one epoch ---
--- 1.9502179622650146 seconds for one epoch ---
--- 0.3447706699371338 seconds for one epoch ---
--- 1.964329481124878 seconds for one epoch ---
--- 0.32303929328918457 seconds for one epoch ---
--- 1.9705784320831299 seconds for one epoch ---
--- 0.3270692825317383 seconds for one epoch ---
--- 1.9715297222137451 seconds for one epoch ---
--- 0.334644079208374 seconds for one epoch ---
--- 2.009887218475342 seconds for one epoch ---
--- 0.32407164573669434 seconds for one epoch ---
--- 2.0165367126464844 seconds for one epoch ---
--- 0.3153829574584961 seconds for one epoch ---
--- 1.9691853523254395 seconds for one epoch ---
--- 0.33031749725341797 seconds for one epoch ---
--- 2.0016660690307617 seconds for one epoch ---
--- 0.3123281002044678 seconds for one epoch ---
--- 2.01055645942688 seconds for one epoch ---
--- 0.3340620994567871 seconds for one epoch ---
--- 1.9735465049743652 seconds for one epoch ---
--- 0.3260023593902588 seconds for one epoch ---
--- 2.0207138061523438 seconds for one epoch ---
--- 0.3413689136505127 seconds for one epoch ---
=========================
[[0.99997914]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1060718 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3164349]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7250313]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.349901 ]
 [-0.       ]]
--- 0.27364158630371094 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2131.40771484375, (1204.9602, 0.5623626, 925.3197, 0.565396)
   validation loss 728.0921630859375, (432.39407, 0.7944035, 294.33832, 0.565396)
decoder loss ratio: 16751.697076, decoder SINDy loss  ratio: 0.635371
--- 0.31383347511291504 seconds for one epoch ---
--- 1.9614596366882324 seconds for one epoch ---
--- 0.33221888542175293 seconds for one epoch ---
--- 1.9771156311035156 seconds for one epoch ---
--- 0.3349730968475342 seconds for one epoch ---
--- 1.9916696548461914 seconds for one epoch ---
--- 0.326322078704834 seconds for one epoch ---
--- 1.9734880924224854 seconds for one epoch ---
--- 0.3387000560760498 seconds for one epoch ---
--- 2.0088329315185547 seconds for one epoch ---
--- 0.3348815441131592 seconds for one epoch ---
--- 1.9814586639404297 seconds for one epoch ---
--- 0.3259916305541992 seconds for one epoch ---
--- 2.005000114440918 seconds for one epoch ---
--- 0.3222975730895996 seconds for one epoch ---
--- 1.9842567443847656 seconds for one epoch ---
--- 0.33605408668518066 seconds for one epoch ---
--- 1.9906630516052246 seconds for one epoch ---
--- 0.31729793548583984 seconds for one epoch ---
--- 1.9765992164611816 seconds for one epoch ---
--- 0.3294823169708252 seconds for one epoch ---
--- 2.0064537525177 seconds for one epoch ---
--- 0.7058835029602051 seconds for one epoch ---
--- 1.9700210094451904 seconds for one epoch ---
=========================
[[0.99998015]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10798317]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.329764  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.72905487]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.359529  ]
 [ 0.        ]]
--- 0.3074026107788086 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5931.990234375, (1622.1342, 3.6757007, 4305.614, 0.56622714)
   validation loss 765.2147827148438, (452.70944, 0.94767195, 310.99142, 0.56622714)
decoder loss ratio: 17538.749727, decoder SINDy loss  ratio: 0.671319
--- 0.2757229804992676 seconds for one epoch ---
--- 0.34375762939453125 seconds for one epoch ---
--- 1.9873895645141602 seconds for one epoch ---
--- 0.329056978225708 seconds for one epoch ---
--- 2.001004457473755 seconds for one epoch ---
--- 0.31436991691589355 seconds for one epoch ---
--- 2.0350563526153564 seconds for one epoch ---
--- 0.33571290969848633 seconds for one epoch ---
--- 1.9779188632965088 seconds for one epoch ---
--- 0.32936787605285645 seconds for one epoch ---
--- 2.0101511478424072 seconds for one epoch ---
--- 0.32433032989501953 seconds for one epoch ---
--- 2.0032083988189697 seconds for one epoch ---
--- 0.3326413631439209 seconds for one epoch ---
--- 1.98805570602417 seconds for one epoch ---
--- 0.3428473472595215 seconds for one epoch ---
--- 1.9874868392944336 seconds for one epoch ---
--- 0.3224503993988037 seconds for one epoch ---
--- 2.000278949737549 seconds for one epoch ---
--- 0.3207254409790039 seconds for one epoch ---
--- 1.983827829360962 seconds for one epoch ---
--- 0.328876256942749 seconds for one epoch ---
--- 2.0367090702056885 seconds for one epoch ---
--- 0.330477237701416 seconds for one epoch ---
=========================
[[0.9999799 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10639991]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3364146]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7257266]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.3649764]
 [ 0.       ]]
--- 0.27300500869750977 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3795.6875, (1202.2585, 2.2626293, 2590.6003, 0.5659334)
   validation loss 850.22021484375, (557.7734, 0.9928947, 290.888, 0.5659334)
decoder loss ratio: 21609.108941, decoder SINDy loss  ratio: 0.627923
--- 0.30747532844543457 seconds for one epoch ---
--- 2.021810531616211 seconds for one epoch ---
--- 0.3207521438598633 seconds for one epoch ---
--- 2.04919695854187 seconds for one epoch ---
--- 0.33423638343811035 seconds for one epoch ---
--- 2.0477328300476074 seconds for one epoch ---
--- 0.33884143829345703 seconds for one epoch ---
--- 1.9904656410217285 seconds for one epoch ---
--- 0.32770442962646484 seconds for one epoch ---
--- 2.036984920501709 seconds for one epoch ---
--- 0.33411312103271484 seconds for one epoch ---
--- 2.022886276245117 seconds for one epoch ---
--- 0.32994699478149414 seconds for one epoch ---
--- 2.0380752086639404 seconds for one epoch ---
--- 0.3192310333251953 seconds for one epoch ---
--- 2.045659065246582 seconds for one epoch ---
--- 0.32729101181030273 seconds for one epoch ---
--- 2.018010139465332 seconds for one epoch ---
--- 0.3299448490142822 seconds for one epoch ---
--- 2.0123095512390137 seconds for one epoch ---
--- 0.33116912841796875 seconds for one epoch ---
--- 2.006103754043579 seconds for one epoch ---
--- 0.3425929546356201 seconds for one epoch ---
--- 2.0011327266693115 seconds for one epoch ---
=========================
[[0.99997956]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10818579]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3471136 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.72947764]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3681245 ]
 [-0.        ]]
--- 0.32227373123168945 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2862.68798828125, (999.1595, 1.901996, 1861.06, 0.5663101)
   validation loss 769.0570678710938, (440.18454, 0.97057986, 327.33566, 0.5663101)
decoder loss ratio: 17053.513266, decoder SINDy loss  ratio: 0.706600
--- 0.27376651763916016 seconds for one epoch ---
--- 0.32514214515686035 seconds for one epoch ---
--- 2.0056636333465576 seconds for one epoch ---
--- 0.33716726303100586 seconds for one epoch ---
--- 2.0656027793884277 seconds for one epoch ---
--- 0.33365535736083984 seconds for one epoch ---
--- 1.993537425994873 seconds for one epoch ---
--- 0.3362395763397217 seconds for one epoch ---
--- 2.041947603225708 seconds for one epoch ---
--- 0.32204103469848633 seconds for one epoch ---
--- 2.0241963863372803 seconds for one epoch ---
--- 0.3352982997894287 seconds for one epoch ---
--- 2.0346217155456543 seconds for one epoch ---
--- 0.3234426975250244 seconds for one epoch ---
--- 2.0564348697662354 seconds for one epoch ---
--- 0.33278727531433105 seconds for one epoch ---
--- 2.0329909324645996 seconds for one epoch ---
--- 0.32365965843200684 seconds for one epoch ---
--- 2.0215063095092773 seconds for one epoch ---
--- 0.3336915969848633 seconds for one epoch ---
--- 2.051323175430298 seconds for one epoch ---
--- 0.32282471656799316 seconds for one epoch ---
--- 2.04610276222229 seconds for one epoch ---
--- 0.3304450511932373 seconds for one epoch ---
=========================
[[0.9999794 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10556981]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3496194 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.72396415]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.3688817 ]
 [ 0.        ]]
--- 0.27721643447875977 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2357.138671875, (753.12415, 1.6008031, 1601.8483, 0.56545115)
   validation loss 796.696044921875, (487.3699, 0.9798052, 307.78088, 0.56545115)
decoder loss ratio: 18881.556175, decoder SINDy loss  ratio: 0.664388
--- 0.3121335506439209 seconds for one epoch ---
--- 2.058471202850342 seconds for one epoch ---
--- 0.32819175720214844 seconds for one epoch ---
--- 2.0058887004852295 seconds for one epoch ---
--- 0.32872891426086426 seconds for one epoch ---
--- 2.015817880630493 seconds for one epoch ---
--- 0.3275911808013916 seconds for one epoch ---
--- 2.0688953399658203 seconds for one epoch ---
--- 0.3261876106262207 seconds for one epoch ---
--- 2.0622613430023193 seconds for one epoch ---
--- 0.3281288146972656 seconds for one epoch ---
--- 2.0596420764923096 seconds for one epoch ---
--- 0.31792640686035156 seconds for one epoch ---
--- 2.031813859939575 seconds for one epoch ---
--- 0.31674909591674805 seconds for one epoch ---
--- 2.0244996547698975 seconds for one epoch ---
--- 0.3265237808227539 seconds for one epoch ---
--- 2.055669069290161 seconds for one epoch ---
--- 0.3297302722930908 seconds for one epoch ---
--- 2.0266854763031006 seconds for one epoch ---
--- 0.33283305168151855 seconds for one epoch ---
--- 2.048023223876953 seconds for one epoch ---
--- 0.3339836597442627 seconds for one epoch ---
--- 2.08463191986084 seconds for one epoch ---
=========================
[[0.9999791 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10487278]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3588374 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.72247505]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3769374 ]
 [-0.        ]]
--- 0.30367612838745117 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2789.866455078125, (1352.3693, 1.2921524, 1435.6399, 0.56523776)
   validation loss 815.983642578125, (475.24112, 0.9251931, 339.25208, 0.56523776)
decoder loss ratio: 18411.666020, decoder SINDy loss  ratio: 0.732323
--- 0.9881067276000977 seconds for one epoch ---
--- 0.3125934600830078 seconds for one epoch ---
--- 2.04011869430542 seconds for one epoch ---
--- 0.3309164047241211 seconds for one epoch ---
--- 2.0230183601379395 seconds for one epoch ---
--- 0.3285512924194336 seconds for one epoch ---
--- 2.060718297958374 seconds for one epoch ---
--- 0.3232758045196533 seconds for one epoch ---
--- 2.0245578289031982 seconds for one epoch ---
--- 0.33550572395324707 seconds for one epoch ---
--- 2.022937059402466 seconds for one epoch ---
--- 0.3326592445373535 seconds for one epoch ---
--- 2.0501303672790527 seconds for one epoch ---
--- 0.3333585262298584 seconds for one epoch ---
--- 2.065042734146118 seconds for one epoch ---
--- 0.33657407760620117 seconds for one epoch ---
--- 2.064478874206543 seconds for one epoch ---
--- 0.3295166492462158 seconds for one epoch ---
--- 2.072749137878418 seconds for one epoch ---
--- 0.33640456199645996 seconds for one epoch ---
--- 2.0553441047668457 seconds for one epoch ---
--- 0.3306095600128174 seconds for one epoch ---
--- 2.030897378921509 seconds for one epoch ---
--- 0.34255146980285645 seconds for one epoch ---
=========================
[[0.99997884]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10345481]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3652413]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7194183]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.382192 ]
 [-0.       ]]
--- 0.2693650722503662 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2034.1434326171875, (920.4277, 2.3677928, 1110.7828, 0.56511694)
   validation loss 887.6719360351562, (584.29877, 1.0251659, 301.7829, 0.56511694)
decoder loss ratio: 22636.748624, decoder SINDy loss  ratio: 0.651441
--- 0.30617213249206543 seconds for one epoch ---
--- 2.059920310974121 seconds for one epoch ---
--- 0.32868385314941406 seconds for one epoch ---
--- 2.0866923332214355 seconds for one epoch ---
--- 0.32984232902526855 seconds for one epoch ---
--- 2.0475072860717773 seconds for one epoch ---
--- 0.33536744117736816 seconds for one epoch ---
--- 2.035449981689453 seconds for one epoch ---
--- 0.33343052864074707 seconds for one epoch ---
--- 2.094208240509033 seconds for one epoch ---
--- 0.3332808017730713 seconds for one epoch ---
--- 2.072312831878662 seconds for one epoch ---
--- 0.3143191337585449 seconds for one epoch ---
--- 2.0437943935394287 seconds for one epoch ---
--- 0.3334391117095947 seconds for one epoch ---
--- 2.100576639175415 seconds for one epoch ---
--- 0.31759071350097656 seconds for one epoch ---
--- 2.082653045654297 seconds for one epoch ---
--- 0.31792116165161133 seconds for one epoch ---
--- 2.090649127960205 seconds for one epoch ---
--- 0.3234267234802246 seconds for one epoch ---
--- 2.0415639877319336 seconds for one epoch ---
--- 0.3311147689819336 seconds for one epoch ---
--- 2.0602238178253174 seconds for one epoch ---
=========================
[[0.99997854]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10593536]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999994 ]
 [0.        ]]
[[-3.3744109]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7247418]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.381861 ]
 [ 0.       ]]
--- 0.30359387397766113 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2489.766357421875, (1071.16, 1.1464897, 1416.8943, 0.56579155)
   validation loss 844.6704711914062, (503.6017, 0.9511728, 339.5518, 0.56579155)
decoder loss ratio: 19510.404734, decoder SINDy loss  ratio: 0.732970
--- 0.27848315238952637 seconds for one epoch ---
--- 0.2987093925476074 seconds for one epoch ---
--- 2.0362701416015625 seconds for one epoch ---
--- 0.33034586906433105 seconds for one epoch ---
--- 2.0597527027130127 seconds for one epoch ---
--- 0.34197258949279785 seconds for one epoch ---
--- 2.0501668453216553 seconds for one epoch ---
--- 0.3255302906036377 seconds for one epoch ---
--- 2.0987040996551514 seconds for one epoch ---
--- 0.32538390159606934 seconds for one epoch ---
--- 2.0691418647766113 seconds for one epoch ---
--- 0.32790493965148926 seconds for one epoch ---
--- 2.082770347595215 seconds for one epoch ---
--- 0.32624149322509766 seconds for one epoch ---
--- 2.100250244140625 seconds for one epoch ---
--- 0.3271040916442871 seconds for one epoch ---
--- 2.082319498062134 seconds for one epoch ---
--- 0.33391308784484863 seconds for one epoch ---
--- 2.0946176052093506 seconds for one epoch ---
--- 0.3285965919494629 seconds for one epoch ---
--- 2.0655782222747803 seconds for one epoch ---
--- 0.3320009708404541 seconds for one epoch ---
--- 2.0865352153778076 seconds for one epoch ---
--- 0.329160213470459 seconds for one epoch ---
=========================
[[0.99997836]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10365745]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-3.382703 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7198573]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.3916593]
 [ 0.       ]]
--- 0.28019094467163086 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3939.566162109375, (1906.8081, 7.0293703, 2025.1636, 0.56527084)
   validation loss 762.6965942382812, (450.2422, 0.96534497, 310.92383, 0.56527084)
decoder loss ratio: 17443.163999, decoder SINDy loss  ratio: 0.671173
--- 0.3160865306854248 seconds for one epoch ---
--- 2.104898691177368 seconds for one epoch ---
--- 0.32676219940185547 seconds for one epoch ---
--- 2.0548551082611084 seconds for one epoch ---
--- 0.32636237144470215 seconds for one epoch ---
--- 2.106132984161377 seconds for one epoch ---
--- 0.33141613006591797 seconds for one epoch ---
--- 2.1075968742370605 seconds for one epoch ---
--- 0.32579684257507324 seconds for one epoch ---
--- 2.102184295654297 seconds for one epoch ---
--- 0.3371419906616211 seconds for one epoch ---
--- 2.080441474914551 seconds for one epoch ---
--- 0.3177907466888428 seconds for one epoch ---
--- 2.1060192584991455 seconds for one epoch ---
--- 0.33445000648498535 seconds for one epoch ---
--- 2.102566957473755 seconds for one epoch ---
--- 0.3356645107269287 seconds for one epoch ---
--- 2.085911989212036 seconds for one epoch ---
--- 0.32279539108276367 seconds for one epoch ---
--- 2.062898635864258 seconds for one epoch ---
--- 0.3261566162109375 seconds for one epoch ---
--- 2.06801700592041 seconds for one epoch ---
--- 0.3298177719116211 seconds for one epoch ---
--- 2.1336798667907715 seconds for one epoch ---
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10362972]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-3.389497  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.71979725]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.3967752 ]
 [-0.        ]]
--- 0.30883336067199707 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3141.426025390625, (1341.4487, 1.520645, 1797.8914, 0.56513053)
   validation loss 849.7814331054688, (555.0614, 1.0055765, 293.14938, 0.56513053)
decoder loss ratio: 21504.042318, decoder SINDy loss  ratio: 0.632804
THRESHOLDING: 3 active coefficients
REFINEMENT
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10328964]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-3.3889034]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.71906  ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.3956685]
 [ 0.       ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1292.2122802734375, (713.64557, 0.62476456, 577.94196, 0.56527245)
   validation loss 980.11328125, (696.24084, 0.67664486, 283.19577, 0.56527245)
decoder loss ratio: 26973.579052, decoder SINDy loss  ratio: 0.611318
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10389968]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999993 ]
 [0.        ]]
[[-3.3919806 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.67896354]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.2913074 ]
 [-0.        ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 863.652587890625, (334.47986, 0.43215686, 528.74054, 0.5648728)
   validation loss 517.122802734375, (263.63736, 0.11509906, 253.3703, 0.5648728)
decoder loss ratio: 10213.769006, decoder SINDy loss  ratio: 0.546935
=========================
[[0.999978  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08787082]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999975 ]
 [0.        ]]
[[-3.372184 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.6846666]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.2514505]
 [-0.       ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 824.6702880859375, (310.3133, 0.3496865, 514.00726, 0.5584467)
   validation loss 523.959228515625, (277.5091, 0.10378262, 246.34636, 0.5584467)
decoder loss ratio: 10751.184088, decoder SINDy loss  ratio: 0.531773
=========================
[[0.9999739 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08159479]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]]
[[-3.2634943]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.7048457]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.0836234]
 [-0.       ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 855.925048828125, (335.48712, 0.27981266, 520.1581, 0.5551978)
   validation loss 521.6475830078125, (284.0913, 0.119158395, 237.4371, 0.5551978)
decoder loss ratio: 11006.190499, decoder SINDy loss  ratio: 0.512541
=========================
[[0.99995315]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07884137]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998856]
 [0.        ]]
[[-3.2191525 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.62464154]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.0069246 ]
 [ 0.        ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.3909912109375, (351.39297, 0.28120312, 505.71683, 0.5533658)
   validation loss 545.3303833007812, (305.38568, 0.1187109, 239.82599, 0.5533658)
decoder loss ratio: 11831.171461, decoder SINDy loss  ratio: 0.517698
=========================
[[0.9999441 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08037218]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999851 ]
 [0.        ]]
[[-3.1659226]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.622922 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.9281774]
 [-0.       ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1036.9095458984375, (504.462, 0.20918176, 532.2384, 0.5527806)
   validation loss 687.8740844726562, (454.61777, 0.1269119, 233.12941, 0.5527806)
decoder loss ratio: 17612.681558, decoder SINDy loss  ratio: 0.503243
=========================
[[0.99993634]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07919787]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998313]
 [0.        ]]
[[-3.1431036 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.66317123]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.8068323 ]
 [-0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.0145263671875, (249.84502, 0.22103052, 504.94852, 0.5517347)
   validation loss 423.59368896484375, (196.47044, 0.122396894, 227.00084, 0.5517347)
decoder loss ratio: 7611.606078, decoder SINDy loss  ratio: 0.490013
=========================
[[0.99993414]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08038391]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998   ]
 [0.        ]]
[[-3.1068861 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.64367145]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.7105486 ]
 [-0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.319091796875, (278.28128, 0.19361648, 515.8442, 0.55145645)
   validation loss 451.3792724609375, (225.99634, 0.13000675, 225.25291, 0.55145645)
decoder loss ratio: 8755.490477, decoder SINDy loss  ratio: 0.486240
=========================
[[0.9999212 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08116776]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999786 ]
 [0.        ]]
[[-3.0705497]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7034396]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.6575713]
 [ 0.       ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.2059936523438, (265.62384, 0.1982438, 502.3839, 0.55097115)
   validation loss 437.2484130859375, (212.4699, 0.1262416, 224.65227, 0.55097115)
decoder loss ratio: 8231.452573, decoder SINDy loss  ratio: 0.484944
=========================
[[0.9999081 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08255515]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999782 ]
 [0.        ]]
[[-3.0495334]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6358037]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.5441065]
 [ 0.       ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1036.6966552734375, (506.04773, 0.1691117, 530.47986, 0.5509068)
   validation loss 695.73583984375, (466.27646, 0.12703747, 229.33234, 0.5509068)
decoder loss ratio: 18064.359503, decoder SINDy loss  ratio: 0.495046
=========================
[[0.99989766]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08262224]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.0270672]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6729379]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4439378]
 [ 0.       ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.8784790039062, (293.4312, 0.19613169, 495.25113, 0.55085784)
   validation loss 452.44976806640625, (228.091, 0.11336096, 224.24542, 0.55085784)
decoder loss ratio: 8836.641456, decoder SINDy loss  ratio: 0.484065
=========================
[[0.99989575]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08710242]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.0845559 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.69855434]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.4848065 ]
 [-0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.7259521484375, (235.86247, 0.18322751, 503.68024, 0.55200714)
   validation loss 395.32501220703125, (175.58122, 0.11494301, 219.62886, 0.55200714)
decoder loss ratio: 6802.321383, decoder SINDy loss  ratio: 0.474100
=========================
[[0.99988467]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08261245]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-2.9943826]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6530162]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2792308]
 [-0.       ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 825.541748046875, (304.50375, 0.16319863, 520.87476, 0.54988426)
   validation loss 479.16314697265625, (256.81085, 0.1235038, 222.22878, 0.54988426)
decoder loss ratio: 9949.298252, decoder SINDy loss  ratio: 0.479712
=========================
[[0.99988127]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08505268]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.012536 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6397678]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3258004]
 [-0.       ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 991.8794555664062, (465.17938, 0.17540188, 526.52466, 0.5505774)
   validation loss 653.1273803710938, (428.2722, 0.10743616, 224.74779, 0.5505774)
decoder loss ratio: 16592.008010, decoder SINDy loss  ratio: 0.485150
=========================
[[0.9998748 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08536653]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999665 ]
 [0.        ]]
[[-2.9207134 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.71645737]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2850263 ]
 [-0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 752.7830810546875, (244.97787, 0.16131586, 507.64386, 0.5506112)
   validation loss 411.9008483886719, (193.52515, 0.115073055, 218.26064, 0.5506112)
decoder loss ratio: 7497.500149, decoder SINDy loss  ratio: 0.471146
=========================
[[0.99986637]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08265186]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999517 ]
 [0.        ]]
[[-2.9493976]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6333573]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.1539345]
 [ 0.       ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.713623046875, (240.75667, 0.1584778, 504.79846, 0.5491822)
   validation loss 409.4622802734375, (191.25237, 0.11200804, 218.09792, 0.5491822)
decoder loss ratio: 7409.448653, decoder SINDy loss  ratio: 0.470795
=========================
[[0.9998685 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08426892]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994504]
 [0.        ]]
[[-3.0017128]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6279988]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.1747787]
 [ 0.       ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.6900634765625, (330.0177, 0.16878225, 488.50354, 0.5496146)
   validation loss 473.9552001953125, (252.01884, 0.10742617, 221.82895, 0.5496146)
decoder loss ratio: 9763.647564, decoder SINDy loss  ratio: 0.478849
=========================
[[0.9998654 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0818529 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993837]
 [0.        ]]
[[-3.057067 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6474204]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.1126149]
 [ 0.       ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.1505737304688, (331.0888, 0.15174736, 517.91003, 0.5485621)
   validation loss 511.7808837890625, (290.8424, 0.10988259, 220.8286, 0.5485621)
decoder loss ratio: 11267.739781, decoder SINDy loss  ratio: 0.476690
=========================
[[0.9998678 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08177183]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993604]
 [0.        ]]
[[-2.905396  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.68159586]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1169167 ]
 [ 0.        ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.345947265625, (332.8141, 0.16816503, 485.3637, 0.5485135)
   validation loss 464.94232177734375, (243.20201, 0.10546386, 221.63486, 0.5485135)
decoder loss ratio: 9422.068128, decoder SINDy loss  ratio: 0.478430
=========================
[[0.99987006]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08080655]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999343 ]
 [0.        ]]
[[-3.0285661]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6884088]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.045021 ]
 [ 0.       ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.2117919921875, (240.49019, 0.15642242, 491.56516, 0.547956)
   validation loss 395.6858215332031, (178.56346, 0.10997484, 217.01239, 0.547956)
decoder loss ratio: 6917.858491, decoder SINDy loss  ratio: 0.468452
=========================
[[0.9998759 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08083424]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999934  ]
 [0.        ]]
[[-3.0122042]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6327531]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0916348]
 [-0.       ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 861.3984375, (339.1047, 0.14881888, 522.14496, 0.5478637)
   validation loss 518.9478149414062, (298.12076, 0.109250806, 220.71782, 0.5478637)
decoder loss ratio: 11549.715728, decoder SINDy loss  ratio: 0.476450
=========================
[[0.9998785 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07870451]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999261 ]
 [0.        ]]
[[-2.9905944 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.63769674]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.0979319 ]
 [ 0.        ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.70703125, (264.822, 0.15978916, 486.72522, 0.54708296)
   validation loss 412.56683349609375, (194.77122, 0.10851113, 217.6871, 0.54708296)
decoder loss ratio: 7545.775393, decoder SINDy loss  ratio: 0.469908
=========================
[[0.999889  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08031289]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99992466]
 [0.        ]]
[[-3.1129088 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.59625596]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.091266  ]
 [ 0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.857177734375, (226.58775, 0.15005367, 496.1194, 0.547596)
   validation loss 389.7012939453125, (173.78398, 0.10833725, 215.80898, 0.547596)
decoder loss ratio: 6732.693139, decoder SINDy loss  ratio: 0.465854
=========================
[[0.9998931 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08035336]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99992526]
 [0.        ]]
[[-2.9917712]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.7167043]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1483572]
 [-0.       ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.8314208984375, (358.9101, 0.1678351, 507.7535, 0.5480596)
   validation loss 546.579833984375, (328.1425, 0.097173214, 218.34021, 0.5480596)
decoder loss ratio: 12712.809610, decoder SINDy loss  ratio: 0.471318
=========================
[[0.99989706]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07768968]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99992704]
 [0.        ]]
[[-3.0794213 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.69022214]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.031882  ]
 [ 0.        ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.4859619140625, (285.10556, 0.15470846, 509.22574, 0.5468733)
   validation loss 458.3525085449219, (241.09714, 0.1039214, 217.15144, 0.5468733)
decoder loss ratio: 9340.521668, decoder SINDy loss  ratio: 0.468752
=========================
[[0.99990326]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07640505]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993414]
 [0.        ]]
[[-3.0349429]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.7313184]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.152203 ]
 [ 0.       ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.41943359375, (258.0547, 0.15439022, 484.21036, 0.54620224)
   validation loss 405.30255126953125, (188.84871, 0.10931315, 216.34451, 0.54620224)
decoder loss ratio: 7316.326847, decoder SINDy loss  ratio: 0.467010
=========================
[[0.9999119 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07554053]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993455]
 [0.        ]]
[[-3.0499926]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6051754]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.0643404]
 [-0.       ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.818603515625, (258.2719, 0.15910442, 484.38754, 0.5462038)
   validation loss 399.96148681640625, (183.89774, 0.10783913, 215.95593, 0.5462038)
decoder loss ratio: 7124.517537, decoder SINDy loss  ratio: 0.466171
=========================
[[0.99991965]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07315689]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993604]
 [0.        ]]
[[-3.0624816 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.71729404]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.0847766 ]
 [-0.        ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.5147705078125, (292.4261, 0.16522779, 507.9235, 0.54557204)
   validation loss 467.6663818359375, (251.72906, 0.10007433, 215.83725, 0.54557204)
decoder loss ratio: 9752.420997, decoder SINDy loss  ratio: 0.465915
=========================
[[0.99992955]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07195802]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993896]
 [0.        ]]
[[-3.1392863 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.66699195]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.171541  ]
 [ 0.        ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.09912109375, (315.3245, 0.1657138, 482.6089, 0.5453881)
   validation loss 461.917236328125, (244.12791, 0.106815375, 217.6825, 0.5453881)
decoder loss ratio: 9457.939230, decoder SINDy loss  ratio: 0.469898
=========================
[[0.99993414]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06897916]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994385]
 [0.        ]]
[[-3.1635401 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.62681246]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1469269 ]
 [-0.        ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 893.4027099609375, (416.3767, 0.16932051, 476.85672, 0.5439817)
   validation loss 537.7020263671875, (315.29022, 0.10705119, 222.30473, 0.5439817)
decoder loss ratio: 12214.890575, decoder SINDy loss  ratio: 0.479876
=========================
[[0.9999354]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0659321]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999505]
 [0.       ]]
[[-3.099346  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.60900253]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1863415 ]
 [ 0.        ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.9305419921875, (348.92462, 0.15609679, 518.8498, 0.54292864)
   validation loss 527.1646728515625, (308.0787, 0.10330644, 218.9827, 0.54292864)
decoder loss ratio: 11935.503873, decoder SINDy loss  ratio: 0.472705
=========================
[[0.9999372 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06429076]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999616 ]
 [0.        ]]
[[-3.1501055]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6271823]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.209042 ]
 [ 0.       ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.51318359375, (284.7484, 0.15893531, 477.60583, 0.5423111)
   validation loss 428.07501220703125, (211.10631, 0.110141076, 216.85855, 0.5423111)
decoder loss ratio: 8178.624868, decoder SINDy loss  ratio: 0.468120
=========================
[[0.99994326]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06513895]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.1992016]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.668917 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.2628891]
 [-0.       ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.4324951171875, (250.94836, 0.16319075, 481.32095, 0.542921)
   validation loss 391.11639404296875, (176.57808, 0.1080358, 214.43027, 0.542921)
decoder loss ratio: 6840.941342, decoder SINDy loss  ratio: 0.462878
=========================
[[0.99994755]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06196134]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.2943563 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.61869884]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2973928 ]
 [-0.        ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.4442138671875, (276.90732, 0.1579555, 511.3789, 0.54161066)
   validation loss 436.912353515625, (221.19069, 0.11042922, 215.61124, 0.54161066)
decoder loss ratio: 8569.311299, decoder SINDy loss  ratio: 0.465427
=========================
[[0.99995214]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05874758]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.236077 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5864439]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.305343 ]
 [-0.       ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 918.6270141601562, (391.6857, 0.15859737, 526.7827, 0.54070085)
   validation loss 566.4597778320312, (345.96924, 0.10252695, 220.38802, 0.54070085)
decoder loss ratio: 13403.448920, decoder SINDy loss  ratio: 0.475739
=========================
[[0.9999614 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05899661]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.2366858]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5837155]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4077277]
 [-0.       ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1073.202880859375, (593.1542, 0.16858518, 479.88016, 0.5411258)
   validation loss 702.3224487304688, (470.19424, 0.11718657, 232.011, 0.5411258)
decoder loss ratio: 18216.141321, decoder SINDy loss  ratio: 0.500828
=========================
[[0.999968  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05638819]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.2591238]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.6343182]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4698265]
 [-0.       ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.833984375, (309.3443, 0.17267676, 474.31702, 0.54032654)
   validation loss 440.49896240234375, (222.85786, 0.10727868, 217.53383, 0.54032654)
decoder loss ratio: 8633.900564, decoder SINDy loss  ratio: 0.469577
=========================
[[0.999978  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05623966]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.3386528]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.6460617]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.49849  ]
 [ 0.       ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.6593017578125, (306.53366, 0.16443689, 475.9612, 0.5401455)
   validation loss 441.58642578125, (222.88155, 0.11533173, 218.58957, 0.5401455)
decoder loss ratio: 8634.818032, decoder SINDy loss  ratio: 0.471856
=========================
[[0.999978  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05516246]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.2481782]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5156305]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5484846]
 [ 0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.0836791992188, (274.27863, 0.1685994, 476.63644, 0.54004014)
   validation loss 418.1197509765625, (200.87767, 0.11325112, 217.12881, 0.54004014)
decoder loss ratio: 7782.349686, decoder SINDy loss  ratio: 0.468703
=========================
[[0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.053662 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]]
[[-3.3019674 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.62330955]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6024778 ]
 [ 0.        ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 834.4096069335938, (359.9928, 0.17749396, 474.23932, 0.53996235)
   validation loss 494.85400390625, (274.00763, 0.11463095, 220.73177, 0.53996235)
decoder loss ratio: 10615.531261, decoder SINDy loss  ratio: 0.476481
=========================
[[0.999978  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05246691]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999782 ]
 [0.        ]]
[[-3.3838441]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.596536 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.5376225]
 [-0.       ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.6929931640625, (244.49191, 0.1624643, 497.03864, 0.53912985)
   validation loss 410.7295227050781, (194.31812, 0.109860435, 216.30154, 0.53912985)
decoder loss ratio: 7528.221135, decoder SINDy loss  ratio: 0.466917
=========================
[[0.999978  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05175876]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997854]
 [0.        ]]
[[-3.3039587]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5346777]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.6429996]
 [ 0.       ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.2495727539062, (232.58603, 0.17340954, 480.49014, 0.5391314)
   validation loss 386.66290283203125, (170.86801, 0.11586712, 215.67905, 0.5391314)
decoder loss ratio: 6619.723404, decoder SINDy loss  ratio: 0.465574
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05142292]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999979  ]
 [0.        ]]
[[-3.3713462]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.635122 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.7037926]
 [-0.       ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 865.3290405273438, (391.8367, 0.18271944, 473.30963, 0.5393086)
   validation loss 517.0001831054688, (293.527, 0.11996765, 223.3532, 0.5393086)
decoder loss ratio: 11371.745877, decoder SINDy loss  ratio: 0.482139
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05102589]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999794 ]
 [0.        ]]
[[-3.4139712 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.45336545]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7166216 ]
 [-0.        ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 930.229248046875, (454.9234, 0.18203266, 475.12384, 0.5392189)
   validation loss 590.9826049804688, (363.3871, 0.13098313, 227.46455, 0.5392189)
decoder loss ratio: 14078.246539, decoder SINDy loss  ratio: 0.491014
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05112286]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999795 ]
 [0.        ]]
[[-3.4795816]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5652742]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.6926935]
 [ 0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.6220092773438, (247.94466, 0.17706563, 496.50027, 0.53931016)
   validation loss 412.5031433105469, (194.96916, 0.11745102, 217.41653, 0.53931016)
decoder loss ratio: 7553.443817, decoder SINDy loss  ratio: 0.469324
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05030211]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999796 ]
 [0.        ]]
[[-3.3956933]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5689695]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.68675  ]
 [-0.       ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.704345703125, (256.62354, 0.1916503, 474.88916, 0.5390857)
   validation loss 400.7159729003906, (183.12234, 0.12530869, 217.46832, 0.5390857)
decoder loss ratio: 7094.477559, decoder SINDy loss  ratio: 0.469436
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05024479]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998057]
 [0.        ]]
[[-3.4459078 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.59779805]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.7411175 ]
 [-0.        ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.5291137695312, (304.68213, 0.19853282, 471.64844, 0.5393667)
   validation loss 441.13348388671875, (221.50589, 0.12581491, 219.50179, 0.5393667)
decoder loss ratio: 8581.522726, decoder SINDy loss  ratio: 0.473825
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05023385]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998116]
 [0.        ]]
[[-3.4909797 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.55332434]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.782655  ]
 [ 0.        ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 971.3381958007812, (497.12817, 0.1961411, 474.0139, 0.53941816)
   validation loss 624.607666015625, (394.66608, 0.138696, 229.80289, 0.53941816)
decoder loss ratio: 15290.048980, decoder SINDy loss  ratio: 0.496062
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05028444]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999813 ]
 [0.        ]]
[[-3.4771445 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.52550733]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.7768714 ]
 [ 0.        ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.4580078125, (235.56473, 0.1923855, 490.7009, 0.5394641)
   validation loss 399.48480224609375, (181.55717, 0.125207, 217.80243, 0.5394641)
decoder loss ratio: 7033.840144, decoder SINDy loss  ratio: 0.470157
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04984184]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999813 ]
 [0.        ]]
[[-3.5340264 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.63341457]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7488036 ]
 [ 0.        ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.45849609375, (234.7091, 0.20277494, 475.54663, 0.5392695)
   validation loss 387.57159423828125, (170.16939, 0.1320112, 217.2702, 0.5392695)
decoder loss ratio: 6592.657511, decoder SINDy loss  ratio: 0.469008
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04953172]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999815 ]
 [0.        ]]
[[-3.5462482]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5968496]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7591038]
 [ 0.       ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.0193481445312, (260.50085, 0.21030761, 471.3082, 0.5394001)
   validation loss 406.4360046386719, (188.43515, 0.1311433, 217.8697, 0.5394001)
decoder loss ratio: 7300.304854, decoder SINDy loss  ratio: 0.470302
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04969567]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999815 ]
 [0.        ]]
[[-3.5033274 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.63598865]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.815738  ]
 [ 0.        ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1045.541748046875, (571.9338, 0.20749079, 473.4004, 0.53950995)
   validation loss 688.033203125, (455.09952, 0.14570396, 232.78798, 0.53950995)
decoder loss ratio: 17631.345408, decoder SINDy loss  ratio: 0.502506
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04952119]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999815 ]
 [0.        ]]
[[-3.509944  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.60081077]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6860802 ]
 [-0.        ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.9700927734375, (414.67572, 0.19889612, 526.0955, 0.5392086)
   validation loss 578.4415283203125, (351.72714, 0.12471777, 226.58969, 0.5392086)
decoder loss ratio: 13626.520119, decoder SINDy loss  ratio: 0.489126
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04925953]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999815 ]
 [0.        ]]
[[-3.4295216]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.6077856]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7278833]
 [ 0.       ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.729736328125, (235.29808, 0.21024963, 473.22144, 0.53919065)
   validation loss 387.893798828125, (170.14876, 0.13695206, 217.60811, 0.53919065)
decoder loss ratio: 6591.858274, decoder SINDy loss  ratio: 0.469738
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04944946]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999815 ]
 [0.        ]]
[[-3.5119014 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.53815246]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.806132  ]
 [ 0.        ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.8695678710938, (226.02538, 0.21140637, 482.63278, 0.5392461)
   validation loss 389.56060791015625, (171.47423, 0.13604805, 217.95035, 0.5392461)
decoder loss ratio: 6643.209281, decoder SINDy loss  ratio: 0.470476
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04859549]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999813 ]
 [0.        ]]
[[-3.5951715 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.52812487]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.763475  ]
 [-0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.095703125, (287.73126, 0.21387358, 467.1506, 0.5388587)
   validation loss 432.65740966796875, (212.66856, 0.14290863, 219.84595, 0.5388587)
decoder loss ratio: 8239.149372, decoder SINDy loss  ratio: 0.474568
=========================
[[0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04933629]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999813 ]
 [0.        ]]
[[-3.5795798 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.56259274]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.7016149 ]
 [-0.        ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.2123413085938, (226.44487, 0.21651933, 473.55096, 0.5394241)
   validation loss 385.55792236328125, (167.91263, 0.13801327, 217.5073, 0.5394241)
decoder loss ratio: 6505.226725, decoder SINDy loss  ratio: 0.469520
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04865857]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998116]
 [0.        ]]
[[-3.633137  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.52063894]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.6917188 ]
 [ 0.        ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.273193359375, (275.65894, 0.21562782, 466.39865, 0.53885365)
   validation loss 418.38690185546875, (199.4562, 0.14328676, 218.7874, 0.53885365)
decoder loss ratio: 7727.279741, decoder SINDy loss  ratio: 0.472283
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04789532]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998057]
 [0.        ]]
[[-3.5491889 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.54539484]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6594906 ]
 [ 0.        ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.5772705078125, (225.19174, 0.21259409, 480.1729, 0.53841877)
   validation loss 391.750732421875, (173.48463, 0.13529257, 218.1308, 0.53841877)
decoder loss ratio: 6721.095919, decoder SINDy loss  ratio: 0.470866
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04867172]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998   ]
 [0.        ]]
[[-3.5792031 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.60744816]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.7632866 ]
 [-0.        ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.8871459960938, (300.82306, 0.21490566, 463.84918, 0.5387758)
   validation loss 443.1040344238281, (223.01453, 0.14643072, 219.94308, 0.5387758)
decoder loss ratio: 8639.969922, decoder SINDy loss  ratio: 0.474778
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04820335]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999796 ]
 [0.        ]]
[[-3.5339801]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.495389 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.7353468]
 [ 0.       ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.0572509765625, (250.27919, 0.21040231, 488.56766, 0.53858966)
   validation loss 421.48382568359375, (201.74709, 0.13224319, 219.6045, 0.53858966)
decoder loss ratio: 7816.032343, decoder SINDy loss  ratio: 0.474047
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04718433]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999796 ]
 [0.        ]]
[[-3.621043 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5188395]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7195816]
 [-0.       ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.32763671875, (290.23544, 0.21454991, 462.87762, 0.53803855)
   validation loss 430.1798095703125, (210.04883, 0.1473074, 219.98366, 0.53803855)
decoder loss ratio: 8137.656262, decoder SINDy loss  ratio: 0.474866
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04684784]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999794 ]
 [0.        ]]
[[-3.5917761]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5725435]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.744332 ]
 [ 0.       ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.4525146484375, (240.3057, 0.21694802, 483.92984, 0.5378111)
   validation loss 412.9559631347656, (193.30037, 0.13512388, 219.52048, 0.5378111)
decoder loss ratio: 7488.791889, decoder SINDy loss  ratio: 0.473866
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04697671]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999794 ]
 [0.        ]]
[[-3.5981214 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.51793474]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.6674602 ]
 [-0.        ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.611572265625, (395.13052, 0.22083992, 461.26022, 0.5379677)
   validation loss 517.0826416015625, (293.43842, 0.14908618, 223.49513, 0.5379677)
decoder loss ratio: 11368.313649, decoder SINDy loss  ratio: 0.482446
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04724312]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999794 ]
 [0.        ]]
[[-3.5627146]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5257515]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7213767]
 [-0.       ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.551025390625, (229.37433, 0.21880658, 481.9579, 0.53829235)
   validation loss 395.28692626953125, (176.50916, 0.13568918, 218.64207, 0.53829235)
decoder loss ratio: 6838.271109, decoder SINDy loss  ratio: 0.471970
=========================
[[0.9999782 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04638557]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997926]
 [0.        ]]
[[-3.5063062]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5391847]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.6813943]
 [ 0.       ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.1466674804688, (245.90338, 0.2281432, 479.01514, 0.5376276)
   validation loss 415.3387756347656, (196.47295, 0.14104445, 218.7248, 0.5376276)
decoder loss ratio: 7611.703027, decoder SINDy loss  ratio: 0.472148
=========================
[[0.99997836]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04623166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999979  ]
 [0.        ]]
[[-3.6839225]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5291767]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.637064 ]
 [-0.       ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.3155517578125, (272.6228, 0.21820123, 491.47452, 0.5373897)
   validation loss 448.71917724609375, (226.64317, 0.1370112, 221.939, 0.5373897)
decoder loss ratio: 8780.550000, decoder SINDy loss  ratio: 0.479087
=========================
[[0.99997836]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04661731]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999786 ]
 [0.        ]]
[[-3.6243932 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.50583315]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.6686547 ]
 [ 0.        ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.03857421875, (295.29483, 0.23430587, 461.50943, 0.53779614)
   validation loss 427.57342529296875, (208.66975, 0.14825785, 218.75542, 0.53779614)
decoder loss ratio: 8084.228538, decoder SINDy loss  ratio: 0.472214
=========================
[[0.99997854]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04657701]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999786 ]
 [0.        ]]
[[-3.580937 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5019124]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.6115122]
 [ 0.       ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.4222412109375, (226.26265, 0.22880304, 469.9308, 0.53766763)
   validation loss 391.947265625, (173.79433, 0.14294316, 218.00998, 0.53766763)
decoder loss ratio: 6733.093940, decoder SINDy loss  ratio: 0.470605
=========================
[[0.9999786 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04667768]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999786 ]
 [0.        ]]
[[-3.696702  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.51948977]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6234334 ]
 [ 0.        ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1063.669677734375, (600.4047, 0.21883376, 463.04614, 0.5378583)
   validation loss 698.4873657226562, (466.03894, 0.16039601, 232.28804, 0.5378583)
decoder loss ratio: 18055.157631, decoder SINDy loss  ratio: 0.501426
=========================
[[0.9999786 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04671279]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999784 ]
 [0.        ]]
[[-3.6554604]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.4452479]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.608341 ]
 [-0.       ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 887.2080688476562, (376.56766, 0.22236657, 510.41803, 0.53764343)
   validation loss 549.0687255859375, (321.73587, 0.13689406, 227.19592, 0.53764343)
decoder loss ratio: 12464.606176, decoder SINDy loss  ratio: 0.490434
=========================
[[0.999979  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04641883]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997836]
 [0.        ]]
[[-3.7256699]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5447077]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.6369402]
 [-0.       ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.5762329101562, (234.57756, 0.2240623, 462.77463, 0.53749985)
   validation loss 389.8193054199219, (170.78062, 0.15205991, 218.88663, 0.53749985)
decoder loss ratio: 6616.337877, decoder SINDy loss  ratio: 0.472498
=========================
[[0.999979  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04604299]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999782 ]
 [0.        ]]
[[-3.5858746 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.56694156]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.6641362 ]
 [-0.        ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.5079345703125, (259.33527, 0.23115808, 458.94147, 0.5376404)
   validation loss 410.4400939941406, (191.33789, 0.1524259, 218.94978, 0.5376404)
decoder loss ratio: 7412.762060, decoder SINDy loss  ratio: 0.472634
=========================
[[0.99997926]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04606669]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999782 ]
 [0.        ]]
[[-3.6695223]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.606176 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5882132]
 [-0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 909.6988525390625, (452.7904, 0.22211723, 456.68634, 0.53740185)
   validation loss 582.3680419921875, (355.04294, 0.16332659, 227.16179, 0.53740185)
decoder loss ratio: 13754.979809, decoder SINDy loss  ratio: 0.490361
=========================
[[0.9999794 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04609886]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999782 ]
 [0.        ]]
[[-3.6655312 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.49697068]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.475365  ]
 [ 0.        ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1207.037841796875, (656.75793, 0.23491561, 550.04504, 0.5370968)
   validation loss 821.2442626953125, (579.8885, 0.13583347, 241.21999, 0.5370968)
decoder loss ratio: 22465.886786, decoder SINDy loss  ratio: 0.520707
=========================
[[0.9999794]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0452107]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]]
[[-3.6785984 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.48004073]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.544676  ]
 [-0.        ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.8900756835938, (227.01509, 0.23547685, 464.63953, 0.53674066)
   validation loss 387.2543640136719, (168.27765, 0.15346806, 218.82324, 0.53674066)
decoder loss ratio: 6519.368262, decoder SINDy loss  ratio: 0.472361
=========================
[[0.9999794]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0456058]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]]
[[-3.6811678]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.6107271]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.5770814]
 [-0.       ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.9821166992188, (227.5194, 0.234076, 461.22864, 0.5370393)
   validation loss 386.357666015625, (167.54231, 0.15170091, 218.66367, 0.5370393)
decoder loss ratio: 6490.880057, decoder SINDy loss  ratio: 0.472016
=========================
[[0.9999795 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04573862]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.6504939 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.53263766]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.5237536 ]
 [-0.        ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 957.0028076171875, (500.03613, 0.22012763, 456.74652, 0.5371923)
   validation loss 610.07373046875, (381.14783, 0.16470952, 228.76123, 0.5371923)
decoder loss ratio: 14766.328525, decoder SINDy loss  ratio: 0.493813
=========================
[[0.9999796 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04530004]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.6912138 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.53598046]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.5200076 ]
 [-0.        ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 924.788330078125, (411.99918, 0.23457277, 512.5546, 0.5367103)
   validation loss 586.826904296875, (356.42206, 0.14070496, 230.26413, 0.5367103)
decoder loss ratio: 13808.409307, decoder SINDy loss  ratio: 0.497058
=========================
[[0.9999796 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04521884]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.6828723]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5664414]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5288436]
 [-0.       ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.8111572265625, (242.93785, 0.24702065, 460.62625, 0.53669196)
   validation loss 393.7750244140625, (175.1049, 0.15706818, 218.51305, 0.53669196)
decoder loss ratio: 6783.867983, decoder SINDy loss  ratio: 0.471691
=========================
[[0.99998   ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04441191]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.7303808]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5324804]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.3991246]
 [-0.       ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.9495849609375, (226.84673, 0.23655993, 459.86627, 0.536344)
   validation loss 387.21282958984375, (168.13464, 0.15413222, 218.92407, 0.536344)
decoder loss ratio: 6513.827986, decoder SINDy loss  ratio: 0.472578
=========================
[[0.99998057]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04452005]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.7151105]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5915117]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.4916978]
 [-0.       ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.8841552734375, (247.63954, 0.24488392, 460.9997, 0.53641015)
   validation loss 401.02496337890625, (182.02121, 0.15652236, 218.84724, 0.53641015)
decoder loss ratio: 7051.817667, decoder SINDy loss  ratio: 0.472413
=========================
[[0.9999807 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04379784]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.7367659]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5799346]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.502645 ]
 [ 0.       ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.2011108398438, (229.11351, 0.23207502, 459.85553, 0.5363578)
   validation loss 390.60693359375, (171.4394, 0.15097333, 219.01656, 0.5363578)
decoder loss ratio: 6641.860273, decoder SINDy loss  ratio: 0.472778
=========================
[[0.9999813 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0444806 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.7536526 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.47727716]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.4865139 ]
 [-0.        ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.7322387695312, (294.06012, 0.22807297, 452.44406, 0.53614205)
   validation loss 434.328125, (213.8204, 0.16101003, 220.34673, 0.53614205)
decoder loss ratio: 8283.773662, decoder SINDy loss  ratio: 0.475649
=========================
[[0.9999815 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04428985]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.785677  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.53221774]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.4685957 ]
 [-0.        ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.3287353515625, (217.94868, 0.22472312, 462.15536, 0.5361518)
   validation loss 385.59161376953125, (166.23557, 0.14622766, 219.20984, 0.5361518)
decoder loss ratio: 6440.254393, decoder SINDy loss  ratio: 0.473195
=========================
[[0.9999815 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04359326]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.7815335]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5870806]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5185678]
 [-0.       ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.404052734375, (273.46027, 0.23499584, 454.70877, 0.53580654)
   validation loss 411.51837158203125, (192.03041, 0.15644865, 219.33151, 0.53580654)
decoder loss ratio: 7439.591493, decoder SINDy loss  ratio: 0.473458
=========================
[[0.99998176]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04352186]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.8055744 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.50777847]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.4752495 ]
 [-0.        ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.1045532226562, (250.69928, 0.22913551, 473.17615, 0.535557)
   validation loss 428.1026611328125, (206.71791, 0.14464618, 221.2401, 0.535557)
decoder loss ratio: 8008.610741, decoder SINDy loss  ratio: 0.477578
=========================
[[0.99998236]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04306246]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.6938603]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5661534]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.3840146]
 [ 0.       ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.3908081054688, (228.50978, 0.22967143, 468.65137, 0.535399)
   validation loss 400.80352783203125, (180.3638, 0.15061352, 220.28911, 0.535399)
decoder loss ratio: 6987.606739, decoder SINDy loss  ratio: 0.475525
=========================
[[0.9999827 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04243754]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.7242603]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5012354]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.5242496]
 [-0.       ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.900146484375, (243.66557, 0.22703466, 475.0075, 0.53500175)
   validation loss 422.10003662109375, (200.03941, 0.1438079, 221.9168, 0.53500175)
decoder loss ratio: 7749.874161, decoder SINDy loss  ratio: 0.479039
=========================
[[0.9999827 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04231751]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.8482518 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.47544736]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.3958414 ]
 [-0.        ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.993408203125, (406.32797, 0.22479348, 451.44064, 0.5349873)
   validation loss 520.667724609375, (296.12195, 0.1605131, 224.38524, 0.5349873)
decoder loss ratio: 11472.278365, decoder SINDy loss  ratio: 0.484367
=========================
[[0.99998295]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04236988]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.8507812]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5749499]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.4612494]
 [ 0.       ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.924072265625, (220.12694, 0.23148127, 460.56567, 0.53502005)
   validation loss 388.4629821777344, (169.17758, 0.15016948, 219.13522, 0.53502005)
decoder loss ratio: 6554.233224, decoder SINDy loss  ratio: 0.473034
=========================
[[0.99998313]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04205425]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.765158 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.596253 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.3167884]
 [ 0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.5505981445312, (248.13403, 0.24046832, 473.1761, 0.53482383)
   validation loss 424.68212890625, (202.88892, 0.14979123, 221.64343, 0.53482383)
decoder loss ratio: 7860.268837, decoder SINDy loss  ratio: 0.478449
=========================
[[0.99998355]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04249597]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.8756912 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.47510314]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.369367  ]
 [ 0.        ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1029.323486328125, (512.71326, 0.24339013, 516.3669, 0.53483814)
   validation loss 697.0789794921875, (462.72748, 0.1357942, 234.2157, 0.53483814)
decoder loss ratio: 17926.865829, decoder SINDy loss  ratio: 0.505588
=========================
[[0.9999839 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04186624]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.822054 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.4624207]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.3915293]
 [ 0.       ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.138427734375, (258.84177, 0.22280258, 453.07382, 0.5346894)
   validation loss 415.0448913574219, (194.32709, 0.15831664, 220.5595, 0.5346894)
decoder loss ratio: 7528.568733, decoder SINDy loss  ratio: 0.476109
=========================
[[0.9999839 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04150843]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.899359  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.54671544]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.4020078 ]
 [ 0.        ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.325927734375, (220.85983, 0.22144416, 459.24463, 0.5347929)
   validation loss 387.8163146972656, (168.41284, 0.1449865, 219.25848, 0.5347929)
decoder loss ratio: 6524.605869, decoder SINDy loss  ratio: 0.473300
=========================
[[0.999984  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04076783]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.9331355]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5023521]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.446245 ]
 [-0.       ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.4473876953125, (259.80466, 0.27017066, 466.37256, 0.5342907)
   validation loss 420.92010498046875, (201.55359, 0.1494379, 219.21707, 0.5342907)
decoder loss ratio: 7808.535945, decoder SINDy loss  ratio: 0.473211
=========================
[[0.9999844 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04153578]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.8830152]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5101784]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.366898 ]
 [ 0.       ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.7398071289062, (217.88513, 0.22370854, 456.63095, 0.53449154)
   validation loss 385.5380859375, (166.28522, 0.14736953, 219.10551, 0.53449154)
decoder loss ratio: 6442.178001, decoder SINDy loss  ratio: 0.472970
=========================
[[0.9999844 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04146659]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]]
[[-3.9358206]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.596602 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.349042 ]
 [ 0.       ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 829.57275390625, (381.65976, 0.21519653, 447.69775, 0.53447616)
   validation loss 522.547119140625, (298.2132, 0.15919894, 224.17473, 0.53447616)
decoder loss ratio: 11553.296926, decoder SINDy loss  ratio: 0.483913
=========================
[[0.9999846 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04087968]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.8904145]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5218361]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2992887]
 [-0.       ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.3192749023438, (339.5636, 0.2294769, 493.5262, 0.53417546)
   validation loss 523.3779907226562, (296.13037, 0.13851906, 227.10912, 0.53417546)
decoder loss ratio: 11472.604681, decoder SINDy loss  ratio: 0.490247
=========================
[[0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0401739]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]]
[[-3.9428828]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.541996 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.4040763]
 [ 0.       ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.5069580078125, (454.81946, 0.21865009, 448.4688, 0.533728)
   validation loss 572.9566040039062, (345.44104, 0.161458, 227.35408, 0.533728)
decoder loss ratio: 13382.985603, decoder SINDy loss  ratio: 0.490776
=========================
[[0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04064805]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.960823 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5134006]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.3304102]
 [-0.       ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.4520263671875, (291.22662, 0.22888356, 481.9965, 0.53404444)
   validation loss 473.712646484375, (249.13982, 0.14032094, 224.43251, 0.53404444)
decoder loss ratio: 9652.109009, decoder SINDy loss  ratio: 0.484469
=========================
[[0.9999851 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04032209]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.874898  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.54312176]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3612301 ]
 [-0.        ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.0863647460938, (334.839, 0.2181748, 446.0292, 0.5338607)
   validation loss 468.9709167480469, (246.03767, 0.16062142, 222.77263, 0.5338607)
decoder loss ratio: 9531.926629, decoder SINDy loss  ratio: 0.480886
=========================
[[0.9999851 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04022588]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.911905  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.47561646]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.4076283 ]
 [ 0.        ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.2659912109375, (238.60718, 0.22461115, 468.43417, 0.53398365)
   validation loss 416.6192321777344, (195.15215, 0.14201452, 221.32507, 0.53398365)
decoder loss ratio: 7560.532911, decoder SINDy loss  ratio: 0.477761
=========================
[[0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03972414]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.9928775 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.50788265]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.3462033 ]
 [-0.        ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.671875, (453.95166, 0.21752593, 446.50266, 0.53356)
   validation loss 590.6111450195312, (363.0801, 0.16301106, 227.36803, 0.53356)
decoder loss ratio: 14066.353744, decoder SINDy loss  ratio: 0.490806
=========================
[[0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04050228]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.9240253]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5587431]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3605704]
 [-0.       ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.9715576171875, (401.32275, 0.24267477, 499.40616, 0.5338923)
   validation loss 587.8961181640625, (357.67032, 0.13846895, 230.08737, 0.5338923)
decoder loss ratio: 13856.769086, decoder SINDy loss  ratio: 0.496676
=========================
[[0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03968457]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.9839678 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.48018596]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.392459  ]
 [ 0.        ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.8485107421875, (227.7954, 0.23459399, 463.8185, 0.5335112)
   validation loss 403.32208251953125, (181.85965, 0.15248682, 221.30995, 0.5335112)
decoder loss ratio: 7045.558550, decoder SINDy loss  ratio: 0.477729
=========================
[[0.9999862 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03905885]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-4.00085   ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.49198166]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.305055  ]
 [-0.        ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.38330078125, (256.61395, 0.23241404, 472.5369, 0.53315717)
   validation loss 438.74517822265625, (215.21603, 0.1432404, 223.3859, 0.53315717)
decoder loss ratio: 8337.842786, decoder SINDy loss  ratio: 0.482210
=========================
[[0.9999862 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03942771]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.9934473 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.56474787]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.296334  ]
 [ 0.        ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.2796630859375, (227.45064, 0.24228808, 462.58673, 0.53341)
   validation loss 401.30816650390625, (180.10782, 0.15269208, 221.04764, 0.53341)
decoder loss ratio: 6977.689574, decoder SINDy loss  ratio: 0.477162
=========================
[[0.9999869 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03928553]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999978  ]
 [0.        ]]
[[-3.8838634 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.53833383]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.2575173 ]
 [-0.        ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.478271484375, (292.01465, 0.23611072, 478.2275, 0.53325564)
   validation loss 477.8953857421875, (252.91705, 0.14078815, 224.83755, 0.53325564)
decoder loss ratio: 9798.445725, decoder SINDy loss  ratio: 0.485343
=========================
[[0.9999869 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03943641]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999769 ]
 [0.        ]]
[[-3.9245417]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5547419]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.313324 ]
 [ 0.       ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.9735717773438, (309.47305, 0.22064911, 447.27988, 0.5334371)
   validation loss 461.99615478515625, (239.61661, 0.158438, 222.2211, 0.5334371)
decoder loss ratio: 9283.163374, decoder SINDy loss  ratio: 0.479696
=========================
[[0.9999869 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03838899]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997354]
 [0.        ]]
[[-4.0238695]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5130424]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.3071098]
 [-0.       ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.5042724609375, (238.68365, 0.25033408, 466.5703, 0.53341407)
   validation loss 415.50823974609375, (194.41002, 0.15051152, 220.9477, 0.53341407)
decoder loss ratio: 7531.781644, decoder SINDy loss  ratio: 0.476947
=========================
[[0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03824925]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996924]
 [0.        ]]
[[-4.0808563 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.49818295]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.225707  ]
 [ 0.        ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.0361328125, (230.34918, 0.24776755, 453.43915, 0.5327784)
   validation loss 389.44952392578125, (170.05971, 0.15333577, 219.23648, 0.5327784)
decoder loss ratio: 6588.408311, decoder SINDy loss  ratio: 0.473253
=========================
[[0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03891775]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996734]
 [0.        ]]
[[-3.9292927]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5802956]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2448828]
 [ 0.       ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.2113037109375, (228.27309, 0.23489831, 460.7033, 0.5331381)
   validation loss 405.22821044921875, (184.66495, 0.1458222, 220.41742, 0.5331381)
decoder loss ratio: 7154.240659, decoder SINDy loss  ratio: 0.475802
=========================
[[0.9999877 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03789299]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996364]
 [0.        ]]
[[-4.0492835 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.57781494]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.312063  ]
 [-0.        ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 807.2343139648438, (362.21884, 0.22283095, 444.79263, 0.53251064)
   validation loss 484.56646728515625, (261.17346, 0.15814506, 223.23488, 0.53251064)
decoder loss ratio: 10118.313332, decoder SINDy loss  ratio: 0.481884
=========================
[[0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03791957]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999961  ]
 [0.        ]]
[[-4.0267477]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5385538]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.2836878]
 [ 0.       ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1395.9542236328125, (843.6911, 0.26744613, 551.99567, 0.5323265)
   validation loss 1032.919189453125, (782.5985, 0.12830806, 250.19234, 0.5323265)
decoder loss ratio: 30319.224957, decoder SINDy loss  ratio: 0.540075
=========================
[[0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03782663]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999567 ]
 [0.        ]]
[[-3.972757  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.49266478]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.3156335 ]
 [-0.        ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.457763671875, (324.9967, 0.21808901, 443.243, 0.532478)
   validation loss 457.1327819824219, (235.15121, 0.15582398, 221.82574, 0.532478)
decoder loss ratio: 9110.166294, decoder SINDy loss  ratio: 0.478842
=========================
[[0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.037621  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999529 ]
 [0.        ]]
[[-4.0970044]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5276811]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1736937]
 [-0.       ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.6878662109375, (297.72952, 0.23959279, 475.71878, 0.5322506)
   validation loss 488.8177490234375, (263.77472, 0.14033811, 224.90268, 0.5322506)
decoder loss ratio: 10219.090556, decoder SINDy loss  ratio: 0.485484
=========================
[[0.99998856]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03769718]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999517 ]
 [0.        ]]
[[-4.1103377 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.49656385]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2824862 ]
 [-0.        ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.6007690429688, (287.12195, 0.23067448, 443.24814, 0.53257877)
   validation loss 430.16668701171875, (210.06538, 0.15806876, 219.94322, 0.53257877)
decoder loss ratio: 8138.297662, decoder SINDy loss  ratio: 0.474778
=========================
[[0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.037385 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999491]
 [0.       ]]
[[-3.9933133 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.50518894]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.1840224 ]
 [ 0.        ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.6505737304688, (250.35446, 0.23771653, 466.0584, 0.5321243)
   validation loss 435.49224853515625, (212.97586, 0.14204292, 222.37436, 0.5321243)
decoder loss ratio: 8251.054582, decoder SINDy loss  ratio: 0.480026
=========================
[[0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03701876]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999473 ]
 [0.        ]]
[[-3.9952426 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.43087888]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.196803  ]
 [ 0.        ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.53515625, (228.70395, 0.23901755, 460.59222, 0.5319393)
   validation loss 405.60125732421875, (184.31836, 0.14489524, 221.13799, 0.5319393)
decoder loss ratio: 7140.813233, decoder SINDy loss  ratio: 0.477357
=========================
[[0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03779153]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994576]
 [0.        ]]
[[-4.100719 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.4844206]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.2365115]
 [-0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.8971557617188, (237.49329, 0.2327827, 462.17108, 0.5323979)
   validation loss 417.419921875, (195.90219, 0.14134684, 221.3764, 0.5323979)
decoder loss ratio: 7589.590987, decoder SINDy loss  ratio: 0.477872
=========================
[[0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03686087]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99994326]
 [0.        ]]
[[-4.08779  ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5463042]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1317835]
 [-0.       ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.230712890625, (227.25887, 0.24793908, 458.72388, 0.5319054)
   validation loss 400.4542236328125, (179.60986, 0.1468007, 220.69754, 0.5319054)
decoder loss ratio: 6958.397920, decoder SINDy loss  ratio: 0.476407
=========================
[[0.9999895 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03673296]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999405 ]
 [0.        ]]
[[-4.15288   ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.50954425]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1625907 ]
 [ 0.        ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.577880859375, (228.45459, 0.22595966, 459.8973, 0.5317985)
   validation loss 408.4324951171875, (187.0255, 0.13879499, 221.2682, 0.5317985)
decoder loss ratio: 7245.692461, decoder SINDy loss  ratio: 0.477639
=========================
[[0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03635175]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999391 ]
 [0.        ]]
[[-4.095766  ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.49299324]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1678283 ]
 [-0.        ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.1078491210938, (330.73627, 0.22128235, 442.1503, 0.5315377)
   validation loss 463.35552978515625, (240.61902, 0.15339456, 222.5831, 0.5315377)
decoder loss ratio: 9321.998512, decoder SINDy loss  ratio: 0.480477
=========================
[[0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03654157]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993753]
 [0.        ]]
[[-4.156096  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.37849173]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.189218  ]
 [ 0.        ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.2485961914062, (248.6856, 0.24060346, 464.3224, 0.5316314)
   validation loss 434.0894775390625, (211.57974, 0.1411317, 222.36862, 0.5316314)
decoder loss ratio: 8196.966540, decoder SINDy loss  ratio: 0.480014
=========================
[[0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03603478]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999365 ]
 [0.        ]]
[[-4.165545 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.4949111]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1261585]
 [ 0.       ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.5609741210938, (232.53699, 0.24414484, 459.77985, 0.53134453)
   validation loss 409.620361328125, (188.2703, 0.14174779, 221.20831, 0.53134453)
decoder loss ratio: 7293.918049, decoder SINDy loss  ratio: 0.477509
=========================
[[0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03677348]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999361 ]
 [0.        ]]
[[-4.150341 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5492939]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0867968]
 [-0.       ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.3076782226562, (233.49225, 0.23081647, 459.5846, 0.5317814)
   validation loss 413.83734130859375, (192.48512, 0.1384814, 221.21371, 0.5317814)
decoder loss ratio: 7457.207822, decoder SINDy loss  ratio: 0.477521
=========================
[[0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03604989]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993527]
 [0.        ]]
[[-4.1487136 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.44673946]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.2341883 ]
 [ 0.        ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.5248413085938, (230.61458, 0.25113112, 459.65912, 0.53142035)
   validation loss 406.20001220703125, (184.84981, 0.14404152, 221.20615, 0.53142035)
decoder loss ratio: 7161.402465, decoder SINDy loss  ratio: 0.477505
=========================
[[0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03589165]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99993443]
 [0.        ]]
[[-4.112936 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.4619202]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1044683]
 [-0.       ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.0806884765625, (269.6794, 0.22939678, 469.1719, 0.53126085)
   validation loss 456.56927490234375, (232.80997, 0.13238698, 223.62692, 0.53126085)
decoder loss ratio: 9019.462299, decoder SINDy loss  ratio: 0.482730
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03617704]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999342 ]
 [0.        ]]
[[-4.1743755 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.57515836]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1494973 ]
 [ 0.        ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.6399536132812, (230.80919, 0.22619385, 451.60455, 0.5314594)
   validation loss 398.01947021484375, (177.20732, 0.14439332, 220.66777, 0.5314594)
decoder loss ratio: 6865.319267, decoder SINDy loss  ratio: 0.476342
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03573065]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999338 ]
 [0.        ]]
[[-4.1424165 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.50991786]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.1695065 ]
 [ 0.        ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.760986328125, (241.08449, 0.23124999, 461.44522, 0.53129405)
   validation loss 423.7585754394531, (202.02141, 0.13390705, 221.60326, 0.53129405)
decoder loss ratio: 7826.660074, decoder SINDy loss  ratio: 0.478362
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03500064]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999269 ]
 [0.        ]]
[[-4.2381086 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.46665394]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1517615 ]
 [-0.        ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.8814086914062, (407.69888, 0.2253256, 443.9572, 0.530732)
   validation loss 514.7885131835938, (289.59503, 0.15049219, 225.04301, 0.530732)
decoder loss ratio: 11219.414289, decoder SINDy loss  ratio: 0.485787
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03573459]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999239 ]
 [0.        ]]
[[-4.20922   ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.49530843]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.156078  ]
 [ 0.        ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.6926879882812, (218.39442, 0.23443352, 450.06384, 0.53126353)
   validation loss 389.7474365234375, (170.22397, 0.13867816, 219.38478, 0.53126353)
decoder loss ratio: 6594.772062, decoder SINDy loss  ratio: 0.473573
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03491289]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999168 ]
 [0.        ]]
[[-4.22038   ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.45967633]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0811412 ]
 [ 0.        ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.103515625, (285.6553, 0.23895285, 443.2093, 0.53068244)
   validation loss 420.88037109375, (200.27069, 0.14850561, 220.46117, 0.53068244)
decoder loss ratio: 7758.834251, decoder SINDy loss  ratio: 0.475896
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03510481]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999133 ]
 [0.        ]]
[[-4.2534037]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5252279]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.0771616]
 [-0.       ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.322021484375, (257.0597, 0.22716407, 464.03516, 0.5308581)
   validation loss 443.0016174316406, (220.5952, 0.12837072, 222.27805, 0.5308581)
decoder loss ratio: 8546.241002, decoder SINDy loss  ratio: 0.479818
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03456733]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999907  ]
 [0.        ]]
[[-4.112704 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5973912]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.058229 ]
 [ 0.       ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.525146484375, (232.85672, 0.26328918, 458.40515, 0.5304812)
   validation loss 406.970947265625, (185.9331, 0.13975032, 220.8981, 0.5304812)
decoder loss ratio: 7203.371300, decoder SINDy loss  ratio: 0.476840
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03471409]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99990284]
 [0.        ]]
[[-4.234362 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.5213797]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.0491598]
 [ 0.       ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.9673461914062, (214.92625, 0.22192885, 449.81915, 0.530621)
   validation loss 388.7018127441406, (168.6292, 0.13479343, 219.93782, 0.530621)
decoder loss ratio: 6532.987813, decoder SINDy loss  ratio: 0.474767
=========================
[[0.9999945 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03455908]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998982 ]
 [0.        ]]
[[-4.2310696]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5161873]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9716237]
 [-0.       ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.1428833007812, (250.1626, 0.27057007, 465.70972, 0.53052455)
   validation loss 428.0562438964844, (205.47748, 0.13799961, 222.44077, 0.53052455)
decoder loss ratio: 7960.554223, decoder SINDy loss  ratio: 0.480170
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03437781]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99989617]
 [0.        ]]
[[-4.284657  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.46773735]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.140747  ]
 [ 0.        ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.9984741210938, (219.12439, 0.21724042, 451.65683, 0.5304285)
   validation loss 395.75244140625, (175.58911, 0.13072373, 220.0326, 0.5304285)
decoder loss ratio: 6802.627009, decoder SINDy loss  ratio: 0.474971
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03451976]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998925 ]
 [0.        ]]
[[-4.2129703]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.514158 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.0462196]
 [ 0.       ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.5418701171875, (217.68332, 0.24203087, 448.61655, 0.5303515)
   validation loss 385.3863525390625, (165.16173, 0.14177991, 220.08286, 0.5303515)
decoder loss ratio: 6398.652072, decoder SINDy loss  ratio: 0.475080
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03403471]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99989   ]
 [0.        ]]
[[-4.243436  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.59436136]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.9339464 ]
 [-0.        ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.781005859375, (216.59485, 0.21483813, 449.97134, 0.5302128)
   validation loss 391.070068359375, (170.99118, 0.13142978, 219.94745, 0.5302128)
decoder loss ratio: 6624.495183, decoder SINDy loss  ratio: 0.474788
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03368606]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99988127]
 [0.        ]]
[[-4.282839  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.49495783]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.0386498 ]
 [-0.        ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.601318359375, (231.68987, 0.2706592, 455.64078, 0.52988935)
   validation loss 403.1092529296875, (182.52882, 0.13752952, 220.44292, 0.52988935)
decoder loss ratio: 7071.483520, decoder SINDy loss  ratio: 0.475857
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03405963]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998741 ]
 [0.        ]]
[[-4.2901087 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.49508137]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.0582485 ]
 [-0.        ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.407470703125, (215.77576, 0.22147758, 449.41025, 0.53018105)
   validation loss 390.39044189453125, (170.18456, 0.1315836, 220.07431, 0.53018105)
decoder loss ratio: 6593.245116, decoder SINDy loss  ratio: 0.475061
=========================
[[0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0336151]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998653]
 [0.       ]]
[[-4.259435 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.4381967]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.9272895]
 [ 0.       ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.3992309570312, (274.08838, 0.28648123, 472.02438, 0.5299487)
   validation loss 453.63824462890625, (229.51263, 0.13369691, 223.9919, 0.5299487)
decoder loss ratio: 8891.717903, decoder SINDy loss  ratio: 0.483518
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03368155]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998602 ]
 [0.        ]]
[[-4.2457075]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.3912266]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9731908]
 [-0.       ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.4386596679688, (216.38658, 0.21536152, 448.8367, 0.5300236)
   validation loss 391.23443603515625, (171.45921, 0.12900327, 219.64622, 0.5300236)
decoder loss ratio: 6642.627588, decoder SINDy loss  ratio: 0.474137
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03366512]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99985296]
 [0.        ]]
[[-4.2757087 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.51858354]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8817022 ]
 [-0.        ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.1810302734375, (228.29684, 0.26046193, 457.62372, 0.5298221)
   validation loss 406.64935302734375, (184.79129, 0.13782068, 221.72023, 0.5298221)
decoder loss ratio: 7159.135397, decoder SINDy loss  ratio: 0.478614
=========================
[[0.9999975]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0332616]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.999848 ]
 [0.       ]]
[[-4.2846136 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.47280946]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.9495904 ]
 [ 0.        ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.1989135742188, (246.94514, 0.21611409, 439.03766, 0.52976334)
   validation loss 399.8634338378906, (179.84906, 0.13923742, 219.87514, 0.52976334)
decoder loss ratio: 6967.664818, decoder SINDy loss  ratio: 0.474631
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03349992]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99984014]
 [0.        ]]
[[-4.3009624]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.4517535]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.8897054]
 [ 0.       ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.2906494140625, (227.25806, 0.2257966, 444.80682, 0.52967614)
   validation loss 390.84765625, (170.18835, 0.13725343, 220.52206, 0.52967614)
decoder loss ratio: 6593.392313, decoder SINDy loss  ratio: 0.476028
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03337981]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998305 ]
 [0.        ]]
[[-4.273426  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.45071253]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.903767  ]
 [-0.        ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.6766357421875, (217.4291, 0.23179042, 448.01578, 0.5295514)
   validation loss 392.41754150390625, (172.11038, 0.13270487, 220.17444, 0.5295514)
decoder loss ratio: 6667.854999, decoder SINDy loss  ratio: 0.475277
=========================
[[0.9999975 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03327429]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998199 ]
 [0.        ]]
[[-4.346157  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.48487312]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.909031  ]
 [-0.        ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.9663696289062, (346.34732, 0.2262143, 437.39282, 0.52967507)
   validation loss 476.000732421875, (253.42062, 0.1461467, 222.43394, 0.52967507)
decoder loss ratio: 9817.954923, decoder SINDy loss  ratio: 0.480155
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03315057]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998116 ]
 [0.        ]]
[[-4.3423686]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.4159397]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9102535]
 [ 0.       ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1105.866455078125, (587.8801, 0.26551816, 517.7208, 0.5293369)
   validation loss 781.4893798828125, (541.56616, 0.116100445, 239.80713, 0.5293369)
decoder loss ratio: 20981.213320, decoder SINDy loss  ratio: 0.517657
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03269016]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99980205]
 [0.        ]]
[[-4.368067  ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.45160478]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7839293 ]
 [ 0.        ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.6282958984375, (235.68117, 0.2490337, 443.69806, 0.52912)
   validation loss 390.85723876953125, (170.88948, 0.13947053, 219.82831, 0.52912)
decoder loss ratio: 6620.555155, decoder SINDy loss  ratio: 0.474530
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03267825]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99979144]
 [0.        ]]
[[-4.342951  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.44470036]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.83617   ]
 [-0.        ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.1522216796875, (220.73071, 0.21278544, 441.2087, 0.5293068)
   validation loss 384.99188232421875, (165.35298, 0.13172738, 219.50719, 0.5293068)
decoder loss ratio: 6406.061571, decoder SINDy loss  ratio: 0.473837
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03291104]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99977845]
 [0.        ]]
[[-4.408275 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.5415121]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8569417]
 [ 0.       ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.5890502929688, (232.33566, 0.23051687, 442.0229, 0.5292671)
   validation loss 392.46588134765625, (172.04672, 0.13698201, 220.2822, 0.5292671)
decoder loss ratio: 6665.388712, decoder SINDy loss  ratio: 0.475510
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03262059]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999766  ]
 [0.        ]]
[[-4.3974686]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.4605795]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8681433]
 [ 0.       ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.2269897460938, (220.63867, 0.2552847, 451.33304, 0.52913177)
   validation loss 397.0545654296875, (176.22528, 0.13750176, 220.69177, 0.52913177)
decoder loss ratio: 6827.273317, decoder SINDy loss  ratio: 0.476394
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03254157]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99975705]
 [0.        ]]
[[-4.4205346]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.5094006]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.8486667]
 [ 0.       ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.851806640625, (412.3143, 0.21445763, 437.32306, 0.5291839)
   validation loss 536.6773071289062, (311.16544, 0.14339663, 225.36847, 0.5291839)
decoder loss ratio: 12055.089189, decoder SINDy loss  ratio: 0.486490
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03232043]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9997423 ]
 [0.        ]]
[[-4.3844943]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.5192298]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.8660111]
 [-0.       ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1149.3284912109375, (628.0288, 0.27192256, 521.0278, 0.52872074)
   validation loss 827.3330078125, (585.17395, 0.11625379, 242.04276, 0.52872074)
decoder loss ratio: 22670.654737, decoder SINDy loss  ratio: 0.522483
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03204334]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9997249 ]
 [0.        ]]
[[-4.3479404 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.57665706]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.904356  ]
 [-0.        ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.57568359375, (281.16968, 0.23745349, 439.16858, 0.528653)
   validation loss 419.8365478515625, (198.85236, 0.14068699, 220.8435, 0.528653)
decoder loss ratio: 7703.885493, decoder SINDy loss  ratio: 0.476722
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03194182]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99971443]
 [0.        ]]
[[-4.4545    ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.47727874]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.7987075 ]
 [-0.        ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.2374877929688, (221.69545, 0.20909235, 440.33295, 0.52883166)
   validation loss 385.640869140625, (166.20465, 0.129884, 219.30635, 0.52883166)
decoder loss ratio: 6439.056719, decoder SINDy loss  ratio: 0.473404
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03202801]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9996964 ]
 [0.        ]]
[[-4.415651 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.439776 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.7715054]
 [-0.       ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.2169799804688, (234.83965, 0.22576745, 442.15158, 0.5286631)
   validation loss 395.3586730957031, (174.72745, 0.1333096, 220.49791, 0.5286631)
decoder loss ratio: 6769.244657, decoder SINDy loss  ratio: 0.475976
=========================
[[0.9999993 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03194991]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99967915]
 [0.        ]]
[[-4.4553647 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.44079116]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8114007 ]
 [-0.        ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.3182373046875, (260.0874, 0.24144536, 460.9894, 0.52853906)
   validation loss 451.1715087890625, (227.61986, 0.12555537, 223.42609, 0.52853906)
decoder loss ratio: 8818.388456, decoder SINDy loss  ratio: 0.482297
params['save_name']
pendulum_2023_10_24_20_57_52_347251
