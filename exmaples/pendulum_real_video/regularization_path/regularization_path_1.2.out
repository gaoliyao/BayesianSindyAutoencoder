nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 16:36:01.145008: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 16:36:01.154371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 16:36:01.155608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e0032a91b0 executing computations on platform Host. Devices:
2023-10-25 16:36:01.155642: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 16:36:01.158556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 16:36:01.279611: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e003339ef0 executing computations on platform CUDA. Devices:
2023-10-25 16:36:01.279642: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 16:36:01.280101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2023-10-25 16:36:01.280378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 16:36:01.282276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 16:36:01.283846: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 16:36:01.284155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 16:36:01.286121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 16:36:01.287048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 16:36:01.290683: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 16:36:01.291340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 16:36:01.291382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 16:36:01.291730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 16:36:01.291739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 16:36:01.291745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 16:36:01.292329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2023-10-25 16:36:02.566509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 1.2, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8365614414215088 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 103590.859375, (95821.59, 0.08465825, 7752.056, 2.5317786)
   validation loss 97056.1484375, (95838.195, 0.0732911, 1200.7573, 2.5317786)
decoder loss ratio: 3712938.068830, decoder SINDy loss  ratio: 2.592004
--- 0.18201351165771484 seconds for one epoch ---
--- 0.21378183364868164 seconds for one epoch ---
--- 0.23660516738891602 seconds for one epoch ---
--- 0.184600830078125 seconds for one epoch ---
--- 0.23642730712890625 seconds for one epoch ---
--- 0.20358681678771973 seconds for one epoch ---
--- 0.22401881217956543 seconds for one epoch ---
--- 0.19237208366394043 seconds for one epoch ---
--- 0.23581528663635254 seconds for one epoch ---
--- 0.21199345588684082 seconds for one epoch ---
--- 0.24603033065795898 seconds for one epoch ---
--- 0.20860600471496582 seconds for one epoch ---
--- 0.23479080200195312 seconds for one epoch ---
--- 0.18956756591796875 seconds for one epoch ---
--- 0.21544146537780762 seconds for one epoch ---
--- 0.2131049633026123 seconds for one epoch ---
--- 0.20696306228637695 seconds for one epoch ---
--- 0.2057955265045166 seconds for one epoch ---
--- 0.24346923828125 seconds for one epoch ---
--- 0.21611475944519043 seconds for one epoch ---
--- 0.23149657249450684 seconds for one epoch ---
--- 0.19211888313293457 seconds for one epoch ---
--- 0.23770642280578613 seconds for one epoch ---
--- 0.2181110382080078 seconds for one epoch ---
=========================
[[0.77733314]
 [0.777154  ]
 [0.7791415 ]
 [0.7807547 ]
 [0.77567214]
 [0.7775575 ]
 [0.77826285]
 [0.7755899 ]
 [0.7755837 ]
 [0.78723687]
 [0.77705985]]
[[ 0.42915872]
 [ 0.3916214 ]
 [-0.7608475 ]
 [-1.0031276 ]
 [ 0.03305569]
 [-0.4748503 ]
 [ 0.60943   ]
 [ 0.01012682]
 [ 0.00830434]
 [-1.7091612 ]
 [ 0.37141794]]
--- 0.17665386199951172 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 66891.25, (57542.348, 10.861425, 9303.122, 2.5317357)
   validation loss 46315.109375, (45049.332, 11.69641, 1219.1698, 2.5317357)
decoder loss ratio: 1745289.331970, decoder SINDy loss  ratio: 2.631749
--- 0.23142790794372559 seconds for one epoch ---
--- 0.2287442684173584 seconds for one epoch ---
--- 0.2112433910369873 seconds for one epoch ---
--- 0.24296307563781738 seconds for one epoch ---
--- 0.18272924423217773 seconds for one epoch ---
--- 0.23932337760925293 seconds for one epoch ---
--- 0.21860766410827637 seconds for one epoch ---
--- 0.23569750785827637 seconds for one epoch ---
--- 0.20363450050354004 seconds for one epoch ---
--- 0.21863985061645508 seconds for one epoch ---
--- 0.1967165470123291 seconds for one epoch ---
--- 0.23365044593811035 seconds for one epoch ---
--- 0.2126150131225586 seconds for one epoch ---
--- 0.22386932373046875 seconds for one epoch ---
--- 0.1717088222503662 seconds for one epoch ---
--- 0.20473289489746094 seconds for one epoch ---
--- 0.1834723949432373 seconds for one epoch ---
--- 0.2606520652770996 seconds for one epoch ---
--- 0.22245168685913086 seconds for one epoch ---
--- 0.27986717224121094 seconds for one epoch ---
--- 0.233306884765625 seconds for one epoch ---
--- 0.23709630966186523 seconds for one epoch ---
--- 0.1848134994506836 seconds for one epoch ---
--- 0.28578877449035645 seconds for one epoch ---
=========================
[[0.622256  ]
 [0.61665976]
 [0.6204105 ]
 [0.6257803 ]
 [0.61642104]
 [0.6246402 ]
 [0.6190348 ]
 [0.6169057 ]
 [0.6160215 ]
 [0.622509  ]
 [0.61782646]]
[[ 0.77094936]
 [ 0.10335269]
 [-0.58410156]
 [-1.0719445 ]
 [-0.06615877]
 [-0.9811469 ]
 [ 0.42661947]
 [ 0.14065482]
 [ 0.00139053]
 [-0.79473454]
 [ 0.27171493]]
--- 0.2064523696899414 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 65077.12109375, (57330.51, 15.342995, 7676.112, 2.531717)
   validation loss 40718.0859375, (39485.05, 5.6629133, 1172.2169, 2.531717)
decoder loss ratio: 1529719.416328, decoder SINDy loss  ratio: 2.530395
--- 0.16864895820617676 seconds for one epoch ---
--- 0.20824790000915527 seconds for one epoch ---
--- 0.27184009552001953 seconds for one epoch ---
--- 0.2081594467163086 seconds for one epoch ---
--- 0.2683753967285156 seconds for one epoch ---
--- 0.19889497756958008 seconds for one epoch ---
--- 0.24186086654663086 seconds for one epoch ---
--- 0.19205570220947266 seconds for one epoch ---
--- 0.2606692314147949 seconds for one epoch ---
--- 0.20578956604003906 seconds for one epoch ---
--- 0.2594425678253174 seconds for one epoch ---
--- 0.22203993797302246 seconds for one epoch ---
--- 0.2359311580657959 seconds for one epoch ---
--- 0.21030521392822266 seconds for one epoch ---
--- 0.2399146556854248 seconds for one epoch ---
--- 0.2911868095397949 seconds for one epoch ---
--- 0.2710251808166504 seconds for one epoch ---
--- 0.21368956565856934 seconds for one epoch ---
--- 0.23571157455444336 seconds for one epoch ---
--- 0.18043184280395508 seconds for one epoch ---
--- 0.23689532279968262 seconds for one epoch ---
--- 0.17331314086914062 seconds for one epoch ---
--- 0.26465463638305664 seconds for one epoch ---
--- 0.21374225616455078 seconds for one epoch ---
=========================
[[0.4917271 ]
 [0.4831605 ]
 [0.48532373]
 [0.49124846]
 [0.4828708 ]
 [0.5003057 ]
 [0.48674604]
 [0.48411566]
 [0.4823812 ]
 [0.48681384]
 [0.48406774]]
[[ 8.3506823e-01]
 [-9.2897974e-02]
 [-3.2106966e-01]
 [-8.0245471e-01]
 [-5.9142362e-02]
 [-1.3225980e+00]
 [ 4.5263606e-01]
 [ 1.9839968e-01]
 [-1.4162959e-04]
 [-4.5863262e-01]
 [ 1.9332740e-01]]
--- 0.22317981719970703 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 38667.55078125, (32378.898, 3.5801241, 6211.1885, 2.5317113)
   validation loss 17862.220703125, (16703.03, 0.4176162, 1084.8936, 2.5317113)
decoder loss ratio: 647104.352695, decoder SINDy loss  ratio: 2.341895
--- 0.2932159900665283 seconds for one epoch ---
--- 0.32974863052368164 seconds for one epoch ---
--- 0.20784473419189453 seconds for one epoch ---
--- 0.256636381149292 seconds for one epoch ---
--- 0.2340395450592041 seconds for one epoch ---
--- 0.2604367733001709 seconds for one epoch ---
--- 0.21883845329284668 seconds for one epoch ---
--- 0.2541019916534424 seconds for one epoch ---
--- 0.2203049659729004 seconds for one epoch ---
--- 0.23816442489624023 seconds for one epoch ---
--- 0.21258854866027832 seconds for one epoch ---
--- 0.28691935539245605 seconds for one epoch ---
--- 0.16913962364196777 seconds for one epoch ---
--- 0.22699403762817383 seconds for one epoch ---
--- 0.19359946250915527 seconds for one epoch ---
--- 0.26906514167785645 seconds for one epoch ---
--- 0.17963290214538574 seconds for one epoch ---
--- 0.25081944465637207 seconds for one epoch ---
--- 0.18973040580749512 seconds for one epoch ---
--- 0.292003870010376 seconds for one epoch ---
--- 0.18738937377929688 seconds for one epoch ---
--- 0.2605171203613281 seconds for one epoch ---
--- 0.22580671310424805 seconds for one epoch ---
--- 0.2763700485229492 seconds for one epoch ---
=========================
[[0.3937042 ]
 [0.39000767]
 [0.38835356]
 [0.39497155]
 [0.38800505]
 [0.41724712]
 [0.39158714]
 [0.389456  ]
 [0.38681018]
 [0.39436632]
 [0.38806087]]
[[ 5.75898886e-01]
 [-2.97834069e-01]
 [-1.52408361e-01]
 [-6.59768343e-01]
 [-1.19671665e-01]
 [-1.66111088e+00]
 [ 4.23553020e-01]
 [ 2.51030058e-01]
 [-8.93421646e-04]
 [-6.20346308e-01]
 [ 1.24958374e-01]]
--- 0.17708659172058105 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 33783.40234375, (28329.014, 160.40453, 5204.9897, 2.5317183)
   validation loss 10202.107421875, (9170.119, 0.34540012, 942.64667, 2.5317183)
decoder loss ratio: 355266.335535, decoder SINDy loss  ratio: 2.034835
--- 0.16629672050476074 seconds for one epoch ---
--- 0.21151137351989746 seconds for one epoch ---
--- 0.29030442237854004 seconds for one epoch ---
--- 0.1811690330505371 seconds for one epoch ---
--- 0.26256680488586426 seconds for one epoch ---
--- 0.21715593338012695 seconds for one epoch ---
--- 0.27689337730407715 seconds for one epoch ---
--- 0.23643755912780762 seconds for one epoch ---
--- 0.2756526470184326 seconds for one epoch ---
--- 0.1877422332763672 seconds for one epoch ---
--- 0.26404690742492676 seconds for one epoch ---
--- 0.18849539756774902 seconds for one epoch ---
--- 0.2687966823577881 seconds for one epoch ---
--- 0.1832594871520996 seconds for one epoch ---
--- 0.27193212509155273 seconds for one epoch ---
--- 0.1903080940246582 seconds for one epoch ---
--- 0.23960542678833008 seconds for one epoch ---
--- 0.22423171997070312 seconds for one epoch ---
--- 0.2908053398132324 seconds for one epoch ---
--- 0.18723678588867188 seconds for one epoch ---
--- 0.2700505256652832 seconds for one epoch ---
--- 0.24294734001159668 seconds for one epoch ---
--- 0.3034031391143799 seconds for one epoch ---
--- 0.20766472816467285 seconds for one epoch ---
=========================
[[0.3082415 ]
 [0.31225857]
 [0.30689946]
 [0.31334916]
 [0.3071336 ]
 [0.35173   ]
 [0.31121823]
 [0.3091871 ]
 [0.30627987]
 [0.3230249 ]
 [0.30751714]]
[[ 0.17097141]
 [-0.4624295 ]
 [ 0.05773176]
 [-0.5319574 ]
 [-0.07820349]
 [-1.9563448 ]
 [ 0.39270604]
 [ 0.24538954]
 [-0.00201649]
 [-1.0338542 ]
 [ 0.11103016]]
--- 0.1634833812713623 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 15722.9501953125, (9253.527, 2.6546311, 6362.8794, 2.5317323)
   validation loss 6315.6025390625, (5425.1333, 0.17953882, 786.3992, 2.5317323)
decoder loss ratio: 210179.082518, decoder SINDy loss  ratio: 1.697553
--- 0.2174854278564453 seconds for one epoch ---
--- 0.27277445793151855 seconds for one epoch ---
--- 0.2243363857269287 seconds for one epoch ---
--- 0.2849149703979492 seconds for one epoch ---
--- 0.18366599082946777 seconds for one epoch ---
--- 0.2537670135498047 seconds for one epoch ---
--- 0.186692476272583 seconds for one epoch ---
--- 0.26309990882873535 seconds for one epoch ---
--- 0.16025066375732422 seconds for one epoch ---
--- 0.28104734420776367 seconds for one epoch ---
--- 0.21770024299621582 seconds for one epoch ---
--- 0.28465700149536133 seconds for one epoch ---
--- 0.1648705005645752 seconds for one epoch ---
--- 0.3138751983642578 seconds for one epoch ---
--- 0.21617507934570312 seconds for one epoch ---
--- 0.280001163482666 seconds for one epoch ---
--- 0.2208092212677002 seconds for one epoch ---
--- 0.29741907119750977 seconds for one epoch ---
--- 0.1863410472869873 seconds for one epoch ---
--- 0.29985785484313965 seconds for one epoch ---
--- 0.20691537857055664 seconds for one epoch ---
--- 0.29189062118530273 seconds for one epoch ---
--- 0.18851423263549805 seconds for one epoch ---
--- 0.28871774673461914 seconds for one epoch ---
=========================
[[0.24967934]
 [0.25741512]
 [0.25188628]
 [0.2539976 ]
 [0.2492444 ]
 [0.30584615]
 [0.2534972 ]
 [0.25102165]
 [0.24831168]
 [0.27566385]
 [0.24951763]]
[[-1.1204300e-01]
 [-6.1169261e-01]
 [ 2.7408254e-01]
 [-4.1290680e-01]
 [-7.7655092e-02]
 [-2.1346383e+00]
 [ 3.8123748e-01]
 [ 2.1287803e-01]
 [-8.1560970e-04]
 [-1.3664440e+00]
 [ 9.9365287e-02]]
--- 0.19113397598266602 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 15482.998046875, (10163.931, 3.952148, 5198.0537, 2.5317526)
   validation loss 5959.44091796875, (5208.9272, 0.22593246, 633.2267, 2.5317526)
decoder loss ratio: 201802.884609, decoder SINDy loss  ratio: 1.366909
--- 0.16898512840270996 seconds for one epoch ---
--- 0.2248094081878662 seconds for one epoch ---
--- 0.284670352935791 seconds for one epoch ---
--- 0.18172454833984375 seconds for one epoch ---
--- 0.2928273677825928 seconds for one epoch ---
--- 0.17258644104003906 seconds for one epoch ---
--- 0.2834644317626953 seconds for one epoch ---
--- 0.2018287181854248 seconds for one epoch ---
--- 0.28667759895324707 seconds for one epoch ---
--- 0.19874811172485352 seconds for one epoch ---
--- 0.27916622161865234 seconds for one epoch ---
--- 0.2297041416168213 seconds for one epoch ---
--- 0.31014537811279297 seconds for one epoch ---
--- 0.200392484664917 seconds for one epoch ---
--- 0.28623056411743164 seconds for one epoch ---
--- 0.20465397834777832 seconds for one epoch ---
--- 0.26930904388427734 seconds for one epoch ---
--- 0.19870996475219727 seconds for one epoch ---
--- 0.2945821285247803 seconds for one epoch ---
--- 0.19263076782226562 seconds for one epoch ---
--- 0.3298935890197754 seconds for one epoch ---
--- 0.19159770011901855 seconds for one epoch ---
--- 0.291339635848999 seconds for one epoch ---
--- 0.21287202835083008 seconds for one epoch ---
=========================
[[0.20365465]
 [0.21059614]
 [0.20722693]
 [0.20418352]
 [0.20004655]
 [0.266052  ]
 [0.20424442]
 [0.2023783 ]
 [0.19918868]
 [0.23810035]
 [0.20012154]]
[[-3.1647837e-01]
 [-6.9632781e-01]
 [ 5.2481771e-01]
 [-3.4937817e-01]
 [-6.7776889e-02]
 [-2.2388797e+00]
 [ 3.5311109e-01]
 [ 2.3364112e-01]
 [-1.2131268e-03]
 [-1.6397933e+00]
 [ 7.3460840e-02]]
--- 0.18641948699951172 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9235.0966796875, (5970.781, 4.586078, 3130.7026, 2.5317748)
   validation loss 4166.31884765625, (3482.2744, 0.2175372, 554.80005, 2.5317748)
decoder loss ratio: 134909.356295, decoder SINDy loss  ratio: 1.197614
--- 0.19699573516845703 seconds for one epoch ---
--- 0.3097267150878906 seconds for one epoch ---
--- 0.22948598861694336 seconds for one epoch ---
--- 0.31772351264953613 seconds for one epoch ---
--- 0.19074296951293945 seconds for one epoch ---
--- 0.28082847595214844 seconds for one epoch ---
--- 0.2056128978729248 seconds for one epoch ---
--- 0.34660887718200684 seconds for one epoch ---
--- 0.1690051555633545 seconds for one epoch ---
--- 0.3026118278503418 seconds for one epoch ---
--- 0.2005455493927002 seconds for one epoch ---
--- 0.34178900718688965 seconds for one epoch ---
--- 0.17957210540771484 seconds for one epoch ---
--- 0.29425835609436035 seconds for one epoch ---
--- 0.2034449577331543 seconds for one epoch ---
--- 0.31938624382019043 seconds for one epoch ---
--- 0.1902904510498047 seconds for one epoch ---
--- 0.3025968074798584 seconds for one epoch ---
--- 0.3032710552215576 seconds for one epoch ---
--- 0.39298200607299805 seconds for one epoch ---
--- 0.23905086517333984 seconds for one epoch ---
--- 0.3098621368408203 seconds for one epoch ---
--- 0.21188950538635254 seconds for one epoch ---
--- 0.3262002468109131 seconds for one epoch ---
=========================
[[0.17138578]
 [0.17819342]
 [0.17762217]
 [0.1672774 ]
 [0.16420245]
 [0.23816508]
 [0.16846924]
 [0.16674937]
 [0.16367836]
 [0.2153058 ]
 [0.1651019 ]]
[[-0.4912386 ]
 [-0.8130381 ]
 [ 0.7886631 ]
 [-0.2537292 ]
 [-0.04412255]
 [-2.3190067 ]
 [ 0.32696214]
 [ 0.21996877]
 [-0.00486889]
 [-1.8913177 ]
 [ 0.10888471]]
--- 0.1892833709716797 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7920.03759765625, (4946.5767, 4.1335745, 2830.8418, 2.5317984)
   validation loss 4445.666015625, (3763.1228, 0.2215512, 543.8364, 2.5317984)
decoder loss ratio: 145789.910446, decoder SINDy loss  ratio: 1.173947
--- 0.1639559268951416 seconds for one epoch ---
--- 0.18685173988342285 seconds for one epoch ---
--- 0.3387269973754883 seconds for one epoch ---
--- 0.18025565147399902 seconds for one epoch ---
--- 0.31459784507751465 seconds for one epoch ---
--- 0.1815030574798584 seconds for one epoch ---
--- 0.3074951171875 seconds for one epoch ---
--- 0.20135951042175293 seconds for one epoch ---
--- 0.31729865074157715 seconds for one epoch ---
--- 0.1672661304473877 seconds for one epoch ---
--- 0.3141963481903076 seconds for one epoch ---
--- 0.21744990348815918 seconds for one epoch ---
--- 0.33848118782043457 seconds for one epoch ---
--- 0.2293076515197754 seconds for one epoch ---
--- 0.3285031318664551 seconds for one epoch ---
--- 0.2959599494934082 seconds for one epoch ---
--- 0.3114640712738037 seconds for one epoch ---
--- 0.21370339393615723 seconds for one epoch ---
--- 0.32288312911987305 seconds for one epoch ---
--- 0.17098259925842285 seconds for one epoch ---
--- 0.2919013500213623 seconds for one epoch ---
--- 0.18952584266662598 seconds for one epoch ---
--- 0.34032225608825684 seconds for one epoch ---
--- 0.18328547477722168 seconds for one epoch ---
=========================
[[0.14405207]
 [0.1492227 ]
 [0.15442644]
 [0.13591081]
 [0.1335841 ]
 [0.2109471 ]
 [0.1379624 ]
 [0.13650064]
 [0.13333714]
 [0.19833922]
 [0.13540517]]
[[-0.6232884 ]
 [-0.8460651 ]
 [ 1.0402333 ]
 [-0.17973611]
 [-0.02096397]
 [-2.3253815 ]
 [ 0.30569538]
 [ 0.21716006]
 [-0.00295748]
 [-2.1112647 ]
 [ 0.14680031]]
--- 0.14284658432006836 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6647.64892578125, (3548.233, 0.79479986, 2951.1536, 2.531818)
   validation loss 2917.040771484375, (2298.362, 0.18933323, 471.02228, 2.531818)
decoder loss ratio: 89042.536358, decoder SINDy loss  ratio: 1.016768
--- 0.20633745193481445 seconds for one epoch ---
--- 0.3103499412536621 seconds for one epoch ---
--- 0.23900747299194336 seconds for one epoch ---
--- 0.29370594024658203 seconds for one epoch ---
--- 0.23839306831359863 seconds for one epoch ---
--- 0.3252694606781006 seconds for one epoch ---
--- 0.17281389236450195 seconds for one epoch ---
--- 0.33054184913635254 seconds for one epoch ---
--- 0.18688035011291504 seconds for one epoch ---
--- 0.3310678005218506 seconds for one epoch ---
--- 0.18368792533874512 seconds for one epoch ---
--- 0.3436472415924072 seconds for one epoch ---
--- 0.19595670700073242 seconds for one epoch ---
--- 0.330888032913208 seconds for one epoch ---
--- 0.2102222442626953 seconds for one epoch ---
--- 0.3097257614135742 seconds for one epoch ---
--- 0.22315025329589844 seconds for one epoch ---
--- 0.29884767532348633 seconds for one epoch ---
--- 0.17579388618469238 seconds for one epoch ---
--- 0.3084371089935303 seconds for one epoch ---
--- 0.19968104362487793 seconds for one epoch ---
--- 0.31015920639038086 seconds for one epoch ---
--- 0.21902251243591309 seconds for one epoch ---
--- 0.3344082832336426 seconds for one epoch ---
=========================
[[0.1258222 ]
 [0.12809269]
 [0.13904266]
 [0.11250306]
 [0.11156179]
 [0.1927291 ]
 [0.11603539]
 [0.1144583 ]
 [0.11124908]
 [0.19202772]
 [0.11462786]]
[[-7.7685809e-01]
 [-8.6670220e-01]
 [ 1.2363871e+00]
 [-8.8565454e-02]
 [-2.3791736e-02]
 [-2.3544807e+00]
 [ 3.0707100e-01]
 [ 2.1385375e-01]
 [ 1.5605165e-03]
 [-2.3436441e+00]
 [ 2.2418337e-01]]
--- 0.1906118392944336 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7034.0078125, (3038.78, 0.43335766, 3840.4424, 2.5318398)
   validation loss 1999.7071533203125, (1431.7183, 0.16961642, 413.4672, 2.5318398)
decoder loss ratio: 55467.251031, decoder SINDy loss  ratio: 0.892527
--- 0.15401339530944824 seconds for one epoch ---
--- 0.1854381561279297 seconds for one epoch ---
--- 0.32025742530822754 seconds for one epoch ---
--- 0.19919896125793457 seconds for one epoch ---
--- 0.3248896598815918 seconds for one epoch ---
--- 0.2087233066558838 seconds for one epoch ---
--- 0.319443941116333 seconds for one epoch ---
--- 0.19123053550720215 seconds for one epoch ---
--- 0.36362195014953613 seconds for one epoch ---
--- 0.18261504173278809 seconds for one epoch ---
--- 0.31960606575012207 seconds for one epoch ---
--- 0.1723647117614746 seconds for one epoch ---
--- 0.3720238208770752 seconds for one epoch ---
--- 0.1717674732208252 seconds for one epoch ---
--- 0.35617494583129883 seconds for one epoch ---
--- 0.21126985549926758 seconds for one epoch ---
--- 0.308152437210083 seconds for one epoch ---
--- 0.19994711875915527 seconds for one epoch ---
--- 0.33443236351013184 seconds for one epoch ---
--- 0.19251704216003418 seconds for one epoch ---
--- 0.35431432723999023 seconds for one epoch ---
--- 0.20061349868774414 seconds for one epoch ---
--- 0.3518035411834717 seconds for one epoch ---
--- 0.18557405471801758 seconds for one epoch ---
=========================
[[0.11179654]
 [0.10960667]
 [0.12689596]
 [0.09284533]
 [0.0927154 ]
 [0.17735201]
 [0.09667301]
 [0.09566038]
 [0.09236338]
 [0.19312485]
 [0.09691063]]
[[-0.9494837 ]
 [-0.8696063 ]
 [ 1.4076731 ]
 [-0.03747069]
 [-0.02855582]
 [-2.3815923 ]
 [ 0.27638963]
 [ 0.21718724]
 [-0.00412247]
 [-2.603173  ]
 [ 0.28992534]]
--- 0.17667293548583984 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6613.07666015625, (2694.6482, 0.51866865, 3757.3394, 2.5318658)
   validation loss 1444.4534912109375, (865.08844, 0.13921845, 418.6552, 2.5318658)
decoder loss ratio: 33515.028023, decoder SINDy loss  ratio: 0.903726
--- 0.16245436668395996 seconds for one epoch ---
--- 0.3354334831237793 seconds for one epoch ---
--- 0.22286057472229004 seconds for one epoch ---
--- 0.3631432056427002 seconds for one epoch ---
--- 0.19771862030029297 seconds for one epoch ---
--- 0.34111714363098145 seconds for one epoch ---
--- 0.16192269325256348 seconds for one epoch ---
--- 0.35781264305114746 seconds for one epoch ---
--- 0.19889593124389648 seconds for one epoch ---
--- 0.3276329040527344 seconds for one epoch ---
--- 0.2147984504699707 seconds for one epoch ---
--- 0.33199357986450195 seconds for one epoch ---
--- 0.19015836715698242 seconds for one epoch ---
--- 0.3277921676635742 seconds for one epoch ---
--- 0.1730940341949463 seconds for one epoch ---
--- 0.3588228225708008 seconds for one epoch ---
--- 0.20151424407958984 seconds for one epoch ---
--- 0.42292213439941406 seconds for one epoch ---
--- 0.2955796718597412 seconds for one epoch ---
--- 0.4116973876953125 seconds for one epoch ---
--- 0.17121434211730957 seconds for one epoch ---
--- 0.32625675201416016 seconds for one epoch ---
--- 0.19127774238586426 seconds for one epoch ---
--- 0.3577899932861328 seconds for one epoch ---
=========================
[[0.10296964]
 [0.09633308]
 [0.12057411]
 [0.07903874]
 [0.07878421]
 [0.16473146]
 [0.08245529]
 [0.0818891 ]
 [0.07856702]
 [0.20136462]
 [0.08438735]]
[[-1.1061558 ]
 [-0.88117355]
 [ 1.5789434 ]
 [-0.03996116]
 [-0.02275381]
 [-2.3806193 ]
 [ 0.25180984]
 [ 0.21892078]
 [-0.00788279]
 [-2.8565397 ]
 [ 0.35838482]]
--- 0.18511724472045898 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4611.615234375, (1804.232, 0.5801782, 2639.1204, 2.5318923)
   validation loss 1542.48828125, (989.0559, 0.11756384, 385.63187, 2.5318923)
decoder loss ratio: 38317.742960, decoder SINDy loss  ratio: 0.832441
--- 0.16889142990112305 seconds for one epoch ---
--- 0.23253202438354492 seconds for one epoch ---
--- 0.3564610481262207 seconds for one epoch ---
--- 0.23448586463928223 seconds for one epoch ---
--- 0.33852696418762207 seconds for one epoch ---
--- 0.21484112739562988 seconds for one epoch ---
--- 0.3586854934692383 seconds for one epoch ---
--- 0.20975041389465332 seconds for one epoch ---
--- 0.3643167018890381 seconds for one epoch ---
--- 0.20608162879943848 seconds for one epoch ---
--- 0.3581676483154297 seconds for one epoch ---
--- 0.1846756935119629 seconds for one epoch ---
--- 0.3584625720977783 seconds for one epoch ---
--- 0.2076578140258789 seconds for one epoch ---
--- 0.34273791313171387 seconds for one epoch ---
--- 0.1877286434173584 seconds for one epoch ---
--- 0.38895535469055176 seconds for one epoch ---
--- 0.20184659957885742 seconds for one epoch ---
--- 0.3751535415649414 seconds for one epoch ---
--- 0.2784743309020996 seconds for one epoch ---
--- 0.44135046005249023 seconds for one epoch ---
--- 0.2196638584136963 seconds for one epoch ---
--- 0.3620030879974365 seconds for one epoch ---
--- 0.1904757022857666 seconds for one epoch ---
=========================
[[0.09612609]
 [0.0855684 ]
 [0.11622907]
 [0.06716032]
 [0.06680268]
 [0.15367027]
 [0.07001284]
 [0.06983526]
 [0.06651686]
 [0.21230204]
 [0.07378008]]
[[-1.2477497e+00]
 [-9.1496873e-01]
 [ 1.7328731e+00]
 [-4.3657791e-02]
 [-1.9798825e-02]
 [-2.3771808e+00]
 [ 2.2014131e-01]
 [ 2.0980884e-01]
 [ 4.0696835e-04]
 [-3.0888615e+00]
 [ 4.2274854e-01]]
--- 0.18189358711242676 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6308.0625, (3666.4504, 0.41965047, 2468.199, 2.5319183)
   validation loss 6074.1572265625, (5473.104, 0.11361527, 427.94653, 2.5319183)
decoder loss ratio: 212037.550838, decoder SINDy loss  ratio: 0.923783
--- 0.18868756294250488 seconds for one epoch ---
--- 0.3938896656036377 seconds for one epoch ---
--- 0.1911756992340088 seconds for one epoch ---
--- 0.3924717903137207 seconds for one epoch ---
--- 0.21600818634033203 seconds for one epoch ---
--- 0.371448278427124 seconds for one epoch ---
--- 0.21736669540405273 seconds for one epoch ---
--- 0.36344456672668457 seconds for one epoch ---
--- 0.21753144264221191 seconds for one epoch ---
--- 0.38023829460144043 seconds for one epoch ---
--- 0.20910859107971191 seconds for one epoch ---
--- 0.43785977363586426 seconds for one epoch ---
--- 0.22876858711242676 seconds for one epoch ---
--- 0.40860629081726074 seconds for one epoch ---
--- 0.2193911075592041 seconds for one epoch ---
--- 0.398958683013916 seconds for one epoch ---
--- 0.20361781120300293 seconds for one epoch ---
--- 0.36565136909484863 seconds for one epoch ---
--- 0.20389246940612793 seconds for one epoch ---
--- 0.3916909694671631 seconds for one epoch ---
--- 0.21868038177490234 seconds for one epoch ---
--- 0.40793919563293457 seconds for one epoch ---
--- 0.20183897018432617 seconds for one epoch ---
--- 0.39330029487609863 seconds for one epoch ---
=========================
[[0.09326245]
 [0.07670997]
 [0.11338156]
 [0.05798492]
 [0.05780494]
 [0.14646463]
 [0.06105086]
 [0.0610346 ]
 [0.05779342]
 [0.22852637]
 [0.06578661]]
[[-1.3983443 ]
 [-0.9062513 ]
 [ 1.8422183 ]
 [-0.01773085]
 [-0.00564595]
 [-2.388111  ]
 [ 0.20829308]
 [ 0.20735177]
 [ 0.0048721 ]
 [-3.32132   ]
 [ 0.45832667]]
--- 0.19053244590759277 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4868.2919921875, (2797.028, 0.536805, 1892.3431, 2.531943)
   validation loss 3365.377197265625, (2824.3857, 0.1035144, 362.5041, 2.531943)
decoder loss ratio: 109421.607002, decoder SINDy loss  ratio: 0.782516
--- 0.15793919563293457 seconds for one epoch ---
--- 0.2229304313659668 seconds for one epoch ---
--- 0.3877878189086914 seconds for one epoch ---
--- 0.19298720359802246 seconds for one epoch ---
--- 0.3671581745147705 seconds for one epoch ---
--- 0.1903822422027588 seconds for one epoch ---
--- 0.45928144454956055 seconds for one epoch ---
--- 0.22326087951660156 seconds for one epoch ---
--- 0.40787768363952637 seconds for one epoch ---
--- 0.22461628913879395 seconds for one epoch ---
--- 0.4331090450286865 seconds for one epoch ---
--- 0.192033052444458 seconds for one epoch ---
--- 0.41673803329467773 seconds for one epoch ---
--- 0.1888582706451416 seconds for one epoch ---
--- 0.4300706386566162 seconds for one epoch ---
--- 0.24876642227172852 seconds for one epoch ---
--- 0.4716019630432129 seconds for one epoch ---
--- 0.22392916679382324 seconds for one epoch ---
--- 0.4451568126678467 seconds for one epoch ---
--- 0.2034287452697754 seconds for one epoch ---
--- 0.4209098815917969 seconds for one epoch ---
--- 0.19055795669555664 seconds for one epoch ---
--- 0.4066329002380371 seconds for one epoch ---
--- 0.21046233177185059 seconds for one epoch ---
=========================
[[0.09105943]
 [0.06928164]
 [0.11132941]
 [0.05012191]
 [0.0502276 ]
 [0.13882595]
 [0.05297434]
 [0.05336932]
 [0.05015514]
 [0.24448085]
 [0.0590114 ]]
[[-1.5225941e+00]
 [-9.0752393e-01]
 [ 1.9376520e+00]
 [-1.2652148e-03]
 [-8.3340872e-03]
 [-2.3776295e+00]
 [ 1.8010628e-01]
 [ 2.0309407e-01]
 [ 3.4924899e-03]
 [-3.5211790e+00]
 [ 4.9507824e-01]]
--- 0.2228407859802246 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5256.37939453125, (2152.9016, 0.9766505, 2920.27, 2.5319664)
   validation loss 1581.5760498046875, (1001.57764, 0.10440412, 397.66278, 2.5319664)
decoder loss ratio: 38802.856462, decoder SINDy loss  ratio: 0.858411
--- 0.20987272262573242 seconds for one epoch ---
--- 0.4353337287902832 seconds for one epoch ---
--- 0.2235713005065918 seconds for one epoch ---
--- 0.42483067512512207 seconds for one epoch ---
--- 0.19913291931152344 seconds for one epoch ---
--- 0.44335198402404785 seconds for one epoch ---
--- 0.24283313751220703 seconds for one epoch ---
--- 0.36498594284057617 seconds for one epoch ---
--- 0.18675756454467773 seconds for one epoch ---
--- 0.3827855587005615 seconds for one epoch ---
--- 0.18483519554138184 seconds for one epoch ---
--- 0.42018842697143555 seconds for one epoch ---
--- 0.19618916511535645 seconds for one epoch ---
--- 0.4445066452026367 seconds for one epoch ---
--- 0.22503399848937988 seconds for one epoch ---
--- 0.43331456184387207 seconds for one epoch ---
--- 0.23980093002319336 seconds for one epoch ---
--- 0.4299623966217041 seconds for one epoch ---
--- 0.3071153163909912 seconds for one epoch ---
--- 0.48089027404785156 seconds for one epoch ---
--- 0.2106461524963379 seconds for one epoch ---
--- 0.48683810234069824 seconds for one epoch ---
--- 0.22525906562805176 seconds for one epoch ---
--- 0.4679872989654541 seconds for one epoch ---
=========================
[[0.09056862]
 [0.06466781]
 [0.11105918]
 [0.04464727]
 [0.04468527]
 [0.13320012]
 [0.04676724]
 [0.04767547]
 [0.04452781]
 [0.26086065]
 [0.05354213]]
[[-1.6323558 ]
 [-0.9387439 ]
 [ 2.0256371 ]
 [-0.01204332]
 [-0.01455747]
 [-2.370322  ]
 [ 0.14540698]
 [ 0.19871716]
 [ 0.00411771]
 [-3.696696  ]
 [ 0.5003931 ]]
--- 0.40355825424194336 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7195.14013671875, (5060.2256, 1.6919779, 1947.628, 2.531987)
   validation loss 1314.3621826171875, (743.9853, 0.11700878, 384.6654, 2.531987)
decoder loss ratio: 28823.281770, decoder SINDy loss  ratio: 0.830354
--- 0.18620657920837402 seconds for one epoch ---
--- 0.2070295810699463 seconds for one epoch ---
--- 0.4439244270324707 seconds for one epoch ---
--- 0.17890548706054688 seconds for one epoch ---
--- 0.45860743522644043 seconds for one epoch ---
--- 0.24500560760498047 seconds for one epoch ---
--- 0.4097127914428711 seconds for one epoch ---
--- 0.20023059844970703 seconds for one epoch ---
--- 0.42127346992492676 seconds for one epoch ---
--- 0.237565279006958 seconds for one epoch ---
--- 0.44532060623168945 seconds for one epoch ---
--- 0.2194051742553711 seconds for one epoch ---
--- 0.5218417644500732 seconds for one epoch ---
--- 0.18316245079040527 seconds for one epoch ---
--- 0.4218587875366211 seconds for one epoch ---
--- 0.22705507278442383 seconds for one epoch ---
--- 0.4278538227081299 seconds for one epoch ---
--- 0.1882014274597168 seconds for one epoch ---
--- 0.4454677104949951 seconds for one epoch ---
--- 0.22196221351623535 seconds for one epoch ---
--- 0.45754194259643555 seconds for one epoch ---
--- 0.19981789588928223 seconds for one epoch ---
--- 0.4204137325286865 seconds for one epoch ---
--- 0.20964574813842773 seconds for one epoch ---
=========================
[[0.09056807]
 [0.05933169]
 [0.11174782]
 [0.04009157]
 [0.03976738]
 [0.12731905]
 [0.04146181]
 [0.04296686]
 [0.03968427]
 [0.27769312]
 [0.04929512]]
[[-1.7300225 ]
 [-0.9207701 ]
 [ 2.1131477 ]
 [ 0.03519196]
 [-0.01405261]
 [-2.3500576 ]
 [ 0.12100612]
 [ 0.20933944]
 [ 0.00857858]
 [-3.860875  ]
 [ 0.5284927 ]]
--- 0.2042255401611328 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3177.88623046875, (1465.6405, 1.5501045, 1522.7776, 2.5320072)
   validation loss 3533.097900390625, (2972.7498, 0.09183425, 372.33832, 2.5320072)
decoder loss ratio: 115169.486463, decoder SINDy loss  ratio: 0.803745
--- 0.20936846733093262 seconds for one epoch ---
--- 0.42529797554016113 seconds for one epoch ---
--- 0.20836186408996582 seconds for one epoch ---
--- 0.48777127265930176 seconds for one epoch ---
--- 0.22972702980041504 seconds for one epoch ---
--- 0.4516429901123047 seconds for one epoch ---
--- 0.2208998203277588 seconds for one epoch ---
--- 0.5061819553375244 seconds for one epoch ---
--- 0.238997220993042 seconds for one epoch ---
--- 0.4727296829223633 seconds for one epoch ---
--- 0.2027301788330078 seconds for one epoch ---
--- 0.43532299995422363 seconds for one epoch ---
--- 0.23698163032531738 seconds for one epoch ---
--- 0.42960095405578613 seconds for one epoch ---
--- 0.18318653106689453 seconds for one epoch ---
--- 0.43228626251220703 seconds for one epoch ---
--- 0.2446146011352539 seconds for one epoch ---
--- 0.46322131156921387 seconds for one epoch ---
--- 0.2072618007659912 seconds for one epoch ---
--- 0.4649839401245117 seconds for one epoch ---
--- 0.21461248397827148 seconds for one epoch ---
--- 0.43356990814208984 seconds for one epoch ---
--- 0.2062671184539795 seconds for one epoch ---
--- 0.436129093170166 seconds for one epoch ---
=========================
[[0.09183478]
 [0.05606521]
 [0.11266437]
 [0.036626  ]
 [0.03606176]
 [0.1225011 ]
 [0.03739057]
 [0.03929855]
 [0.03599174]
 [0.2956398 ]
 [0.04679685]]
[[-1.822904  ]
 [-0.9313393 ]
 [ 2.1813416 ]
 [ 0.04708535]
 [-0.01055066]
 [-2.3286011 ]
 [ 0.09504599]
 [ 0.20773901]
 [ 0.00594417]
 [-4.0181036 ]
 [ 0.57775265]]
--- 0.2129662036895752 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7262.41796875, (2121.053, 2.1514864, 4947.772, 2.5320265)
   validation loss 2451.261962890625, (1922.5881, 0.08924814, 337.14377, 2.5320265)
decoder loss ratio: 74484.402101, decoder SINDy loss  ratio: 0.727772
--- 0.1817781925201416 seconds for one epoch ---
--- 0.2127077579498291 seconds for one epoch ---
--- 0.43050408363342285 seconds for one epoch ---
--- 0.2276313304901123 seconds for one epoch ---
--- 0.4691948890686035 seconds for one epoch ---
--- 0.2151806354522705 seconds for one epoch ---
--- 0.49973273277282715 seconds for one epoch ---
--- 0.19580698013305664 seconds for one epoch ---
--- 0.5063917636871338 seconds for one epoch ---
--- 0.20075106620788574 seconds for one epoch ---
--- 0.47725915908813477 seconds for one epoch ---
--- 0.2092456817626953 seconds for one epoch ---
--- 0.4951622486114502 seconds for one epoch ---
--- 0.21245098114013672 seconds for one epoch ---
--- 0.45341944694519043 seconds for one epoch ---
--- 0.22705626487731934 seconds for one epoch ---
--- 0.4844369888305664 seconds for one epoch ---
--- 0.20141315460205078 seconds for one epoch ---
--- 0.47980666160583496 seconds for one epoch ---
--- 0.2312150001525879 seconds for one epoch ---
--- 0.4727659225463867 seconds for one epoch ---
--- 0.2354884147644043 seconds for one epoch ---
--- 0.46773767471313477 seconds for one epoch ---
--- 0.22215819358825684 seconds for one epoch ---
=========================
[[0.09375308]
 [0.05260962]
 [0.11400457]
 [0.03331973]
 [0.03319842]
 [0.11812588]
 [0.03398379]
 [0.0359102 ]
 [0.03277241]
 [0.31418875]
 [0.04426059]]
[[-1.9143763 ]
 [-0.9203882 ]
 [ 2.2467089 ]
 [ 0.0400816 ]
 [-0.03229649]
 [-2.3074827 ]
 [ 0.08191501]
 [ 0.19636023]
 [ 0.00458651]
 [-4.1706743 ]
 [ 0.60454017]]
--- 0.25632715225219727 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9829.8369140625, (7452.142, 1.6121399, 2182.6904, 2.5320458)
   validation loss 1228.783203125, (665.792, 0.08750376, 369.51202, 2.5320458)
decoder loss ratio: 25793.937643, decoder SINDy loss  ratio: 0.797644
--- 0.31178736686706543 seconds for one epoch ---
--- 0.49093008041381836 seconds for one epoch ---
--- 0.2217099666595459 seconds for one epoch ---
--- 0.46968579292297363 seconds for one epoch ---
--- 0.20941376686096191 seconds for one epoch ---
--- 0.5030195713043213 seconds for one epoch ---
--- 0.19652390480041504 seconds for one epoch ---
--- 0.5126051902770996 seconds for one epoch ---
--- 0.23912715911865234 seconds for one epoch ---
--- 0.4615964889526367 seconds for one epoch ---
--- 0.24276947975158691 seconds for one epoch ---
--- 0.4422636032104492 seconds for one epoch ---
--- 0.1863994598388672 seconds for one epoch ---
--- 0.5055999755859375 seconds for one epoch ---
--- 0.20592260360717773 seconds for one epoch ---
--- 0.46729588508605957 seconds for one epoch ---
--- 0.21225500106811523 seconds for one epoch ---
--- 0.4832930564880371 seconds for one epoch ---
--- 0.23335838317871094 seconds for one epoch ---
--- 0.4636201858520508 seconds for one epoch ---
--- 0.19817471504211426 seconds for one epoch ---
--- 0.4747302532196045 seconds for one epoch ---
--- 0.1953601837158203 seconds for one epoch ---
--- 0.48023486137390137 seconds for one epoch ---
=========================
[[0.09772901]
 [0.05023145]
 [0.11472113]
 [0.03098942]
 [0.03058231]
 [0.1163462 ]
 [0.03144077]
 [0.03384065]
 [0.03041744]
 [0.3344378 ]
 [0.04292493]]
[[-2.0228977 ]
 [-0.919166  ]
 [ 2.2896762 ]
 [ 0.04387555]
 [-0.01770552]
 [-2.3132722 ]
 [ 0.07230273]
 [ 0.2140756 ]
 [ 0.00695974]
 [-4.325725  ]
 [ 0.64727736]]
--- 0.17343735694885254 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3746.050537109375, (1568.202, 1.3273178, 1981.0339, 2.5320675)
   validation loss 1311.69140625, (799.899, 0.07964262, 316.22546, 2.5320675)
decoder loss ratio: 30989.475435, decoder SINDy loss  ratio: 0.682617
THRESHOLDING: 3 active coefficients
--- 0.5244133472442627 seconds for one epoch ---
--- 0.23021435737609863 seconds for one epoch ---
--- 0.4439854621887207 seconds for one epoch ---
--- 0.222975492477417 seconds for one epoch ---
--- 0.5415513515472412 seconds for one epoch ---
--- 0.1783444881439209 seconds for one epoch ---
--- 0.46243882179260254 seconds for one epoch ---
--- 0.20714449882507324 seconds for one epoch ---
--- 0.4909207820892334 seconds for one epoch ---
--- 0.20857834815979004 seconds for one epoch ---
--- 0.47722864151000977 seconds for one epoch ---
--- 0.21314287185668945 seconds for one epoch ---
--- 0.4774436950683594 seconds for one epoch ---
--- 0.1998424530029297 seconds for one epoch ---
--- 0.4846038818359375 seconds for one epoch ---
--- 0.2309281826019287 seconds for one epoch ---
--- 0.4800403118133545 seconds for one epoch ---
--- 0.22670722007751465 seconds for one epoch ---
--- 0.5071032047271729 seconds for one epoch ---
--- 0.17855501174926758 seconds for one epoch ---
--- 0.5108349323272705 seconds for one epoch ---
--- 0.318617582321167 seconds for one epoch ---
--- 0.547015905380249 seconds for one epoch ---
--- 0.2874274253845215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.13844429]
 [0.        ]
 [0.        ]
 [0.075207  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3081601 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.6315193]
 [ 0.       ]
 [-0.       ]
 [-1.634759 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.150305 ]
 [ 0.       ]]
--- 0.1815798282623291 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4129.8681640625, (2002.6448, 0.6955822, 2126.2356, 0.29175004)
   validation loss 1829.919921875, (1484.7052, 0.08107022, 344.84195, 0.29175004)
decoder loss ratio: 57520.057017, decoder SINDy loss  ratio: 0.744390
--- 0.23568248748779297 seconds for one epoch ---
--- 0.4806687831878662 seconds for one epoch ---
--- 0.22602581977844238 seconds for one epoch ---
--- 0.45126986503601074 seconds for one epoch ---
--- 0.19285869598388672 seconds for one epoch ---
--- 0.4864501953125 seconds for one epoch ---
--- 0.21155142784118652 seconds for one epoch ---
--- 0.4978291988372803 seconds for one epoch ---
--- 0.21047401428222656 seconds for one epoch ---
--- 0.4730513095855713 seconds for one epoch ---
--- 0.22545194625854492 seconds for one epoch ---
--- 0.4938178062438965 seconds for one epoch ---
--- 0.19635391235351562 seconds for one epoch ---
--- 0.5220425128936768 seconds for one epoch ---
--- 0.1948704719543457 seconds for one epoch ---
--- 0.5143589973449707 seconds for one epoch ---
--- 0.18518853187561035 seconds for one epoch ---
--- 0.5007166862487793 seconds for one epoch ---
--- 0.19015860557556152 seconds for one epoch ---
--- 0.4896690845489502 seconds for one epoch ---
--- 0.19826722145080566 seconds for one epoch ---
--- 0.5040791034698486 seconds for one epoch ---
--- 0.2063443660736084 seconds for one epoch ---
--- 0.46576428413391113 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.13873708]
 [0.        ]
 [0.        ]
 [0.06574832]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29668775]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.6521423]
 [ 0.       ]
 [-0.       ]
 [-1.4565104]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0754995]
 [ 0.       ]]
--- 0.18912768363952637 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4677.26611328125, (2918.0793, 0.92456675, 1757.9764, 0.28571913)
   validation loss 2847.603759765625, (2511.0803, 0.07141898, 336.16626, 0.28571913)
decoder loss ratio: 97283.611112, decoder SINDy loss  ratio: 0.725662
--- 0.16966700553894043 seconds for one epoch ---
--- 0.21672654151916504 seconds for one epoch ---
--- 0.5145511627197266 seconds for one epoch ---
--- 0.22539472579956055 seconds for one epoch ---
--- 0.5064780712127686 seconds for one epoch ---
--- 0.20004749298095703 seconds for one epoch ---
--- 0.49948740005493164 seconds for one epoch ---
--- 0.23009562492370605 seconds for one epoch ---
--- 0.48134541511535645 seconds for one epoch ---
--- 0.221527099609375 seconds for one epoch ---
--- 0.510230541229248 seconds for one epoch ---
--- 0.20493435859680176 seconds for one epoch ---
--- 0.5092992782592773 seconds for one epoch ---
--- 0.24239230155944824 seconds for one epoch ---
--- 0.5067813396453857 seconds for one epoch ---
--- 0.23573946952819824 seconds for one epoch ---
--- 0.5549097061157227 seconds for one epoch ---
--- 0.23351407051086426 seconds for one epoch ---
--- 0.5371782779693604 seconds for one epoch ---
--- 0.18053340911865234 seconds for one epoch ---
--- 0.4827280044555664 seconds for one epoch ---
--- 0.21845054626464844 seconds for one epoch ---
--- 0.5172550678253174 seconds for one epoch ---
--- 0.20546364784240723 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.13295007]
 [0.        ]
 [0.        ]
 [0.06130183]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29197523]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.596371 ]
 [ 0.       ]
 [-0.       ]
 [-1.3812366]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0484753]
 [ 0.       ]]
--- 0.14812898635864258 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6822.330078125, (1970.2742, 1.0219347, 4850.7524, 0.2814547)
   validation loss 1343.33740234375, (988.95905, 0.0916706, 354.00522, 0.2814547)
decoder loss ratio: 38313.990328, decoder SINDy loss  ratio: 0.764170
--- 0.24009060859680176 seconds for one epoch ---
--- 0.5016257762908936 seconds for one epoch ---
--- 0.19841337203979492 seconds for one epoch ---
--- 0.5150675773620605 seconds for one epoch ---
--- 0.24210786819458008 seconds for one epoch ---
--- 0.5121138095855713 seconds for one epoch ---
--- 0.19602465629577637 seconds for one epoch ---
--- 0.5327036380767822 seconds for one epoch ---
--- 0.1763148307800293 seconds for one epoch ---
--- 0.5405244827270508 seconds for one epoch ---
--- 0.24293851852416992 seconds for one epoch ---
--- 0.4847733974456787 seconds for one epoch ---
--- 0.20494389533996582 seconds for one epoch ---
--- 0.5184485912322998 seconds for one epoch ---
--- 0.19791102409362793 seconds for one epoch ---
--- 0.49045681953430176 seconds for one epoch ---
--- 0.21065258979797363 seconds for one epoch ---
--- 0.5229687690734863 seconds for one epoch ---
--- 0.2077786922454834 seconds for one epoch ---
--- 0.496431827545166 seconds for one epoch ---
--- 0.17774224281311035 seconds for one epoch ---
--- 0.49889516830444336 seconds for one epoch ---
--- 0.20241522789001465 seconds for one epoch ---
--- 0.5208346843719482 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1248143 ]
 [0.        ]
 [0.        ]
 [0.05950193]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28902972]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.5050128]
 [ 0.       ]
 [-0.       ]
 [-1.3616719]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.032509 ]
 [ 0.       ]]
--- 0.20862221717834473 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3652.43359375, (2151.7024, 1.2114855, 1499.2417, 0.2781577)
   validation loss 1392.9920654296875, (1059.4305, 0.061319597, 333.2221, 0.2781577)
decoder loss ratio: 41044.178449, decoder SINDy loss  ratio: 0.719307
--- 0.17651987075805664 seconds for one epoch ---
--- 0.19294285774230957 seconds for one epoch ---
--- 0.518836259841919 seconds for one epoch ---
--- 0.1883251667022705 seconds for one epoch ---
--- 0.5049052238464355 seconds for one epoch ---
--- 0.22239136695861816 seconds for one epoch ---
--- 0.5180149078369141 seconds for one epoch ---
--- 0.18102049827575684 seconds for one epoch ---
--- 0.554976224899292 seconds for one epoch ---
--- 0.23833131790161133 seconds for one epoch ---
--- 0.5179164409637451 seconds for one epoch ---
--- 0.1950531005859375 seconds for one epoch ---
--- 0.550316572189331 seconds for one epoch ---
--- 0.2297670841217041 seconds for one epoch ---
--- 0.5870580673217773 seconds for one epoch ---
--- 0.19156670570373535 seconds for one epoch ---
--- 0.5431489944458008 seconds for one epoch ---
--- 0.21072030067443848 seconds for one epoch ---
--- 0.5361325740814209 seconds for one epoch ---
--- 0.22957873344421387 seconds for one epoch ---
--- 0.5340576171875 seconds for one epoch ---
--- 0.17119741439819336 seconds for one epoch ---
--- 0.552884578704834 seconds for one epoch ---
--- 0.18268227577209473 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11542655]
 [0.        ]
 [0.        ]
 [0.0586213 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2897115 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.3908715]
 [ 0.       ]
 [-0.       ]
 [-1.3622516]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0425076]
 [ 0.       ]]
--- 0.17636871337890625 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3244.0400390625, (1703.129, 0.8771115, 1539.7585, 0.27533492)
   validation loss 1055.290283203125, (712.2127, 0.0857369, 342.7165, 0.27533492)
decoder loss ratio: 27592.356745, decoder SINDy loss  ratio: 0.739802
--- 0.20781469345092773 seconds for one epoch ---
--- 0.5918591022491455 seconds for one epoch ---
--- 0.4153304100036621 seconds for one epoch ---
--- 0.5377469062805176 seconds for one epoch ---
--- 0.19521403312683105 seconds for one epoch ---
--- 0.5769214630126953 seconds for one epoch ---
--- 0.18235516548156738 seconds for one epoch ---
--- 0.6099927425384521 seconds for one epoch ---
--- 0.19345569610595703 seconds for one epoch ---
--- 0.5396022796630859 seconds for one epoch ---
--- 0.23184847831726074 seconds for one epoch ---
--- 0.5186331272125244 seconds for one epoch ---
--- 0.22727012634277344 seconds for one epoch ---
--- 0.5166478157043457 seconds for one epoch ---
--- 0.21184754371643066 seconds for one epoch ---
--- 0.5294582843780518 seconds for one epoch ---
--- 0.2053511142730713 seconds for one epoch ---
--- 0.5849006175994873 seconds for one epoch ---
--- 0.21883225440979004 seconds for one epoch ---
--- 0.587871789932251 seconds for one epoch ---
--- 0.22297072410583496 seconds for one epoch ---
--- 0.5472009181976318 seconds for one epoch ---
--- 0.20746469497680664 seconds for one epoch ---
--- 0.5402734279632568 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1077757 ]
 [0.        ]
 [0.        ]
 [0.05762174]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28891662]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.2920575]
 [ 0.       ]
 [-0.       ]
 [-1.3543552]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0404754]
 [ 0.       ]]
--- 0.23163890838623047 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3920.43408203125, (1914.007, 0.9873711, 2005.1674, 0.2724937)
   validation loss 2139.6376953125, (1772.2085, 0.06603947, 367.09076, 0.2724937)
decoder loss ratio: 68658.433828, decoder SINDy loss  ratio: 0.792417
--- 0.17567086219787598 seconds for one epoch ---
--- 0.21173357963562012 seconds for one epoch ---
--- 0.6073729991912842 seconds for one epoch ---
--- 0.18709516525268555 seconds for one epoch ---
--- 0.5583453178405762 seconds for one epoch ---
--- 0.20442724227905273 seconds for one epoch ---
--- 0.5256068706512451 seconds for one epoch ---
--- 0.19916462898254395 seconds for one epoch ---
--- 0.550044059753418 seconds for one epoch ---
--- 0.24116230010986328 seconds for one epoch ---
--- 0.5891971588134766 seconds for one epoch ---
--- 0.21504688262939453 seconds for one epoch ---
--- 0.5704832077026367 seconds for one epoch ---
--- 0.19834208488464355 seconds for one epoch ---
--- 0.5531282424926758 seconds for one epoch ---
--- 0.1922290325164795 seconds for one epoch ---
--- 0.5421285629272461 seconds for one epoch ---
--- 0.2284250259399414 seconds for one epoch ---
--- 0.5379297733306885 seconds for one epoch ---
--- 0.23142504692077637 seconds for one epoch ---
--- 0.5706629753112793 seconds for one epoch ---
--- 0.21352434158325195 seconds for one epoch ---
--- 0.5778915882110596 seconds for one epoch ---
--- 0.21662068367004395 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10264473]
 [0.        ]
 [0.        ]
 [0.05621493]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29284057]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.2250164]
 [ 0.       ]
 [-0.       ]
 [-1.3342067]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0724206]
 [ 0.       ]]
--- 0.19675946235656738 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3502.261962890625, (1511.8292, 3.1669462, 1986.9939, 0.27165318)
   validation loss 1344.2122802734375, (1023.6026, 0.081357345, 320.25677, 0.27165318)
decoder loss ratio: 39656.141780, decoder SINDy loss  ratio: 0.691319
--- 0.18703627586364746 seconds for one epoch ---
--- 0.609050989151001 seconds for one epoch ---
--- 0.22114086151123047 seconds for one epoch ---
--- 0.5959820747375488 seconds for one epoch ---
--- 0.19850420951843262 seconds for one epoch ---
--- 0.5558085441589355 seconds for one epoch ---
--- 0.22903776168823242 seconds for one epoch ---
--- 0.5931639671325684 seconds for one epoch ---
--- 0.1863689422607422 seconds for one epoch ---
--- 0.5234794616699219 seconds for one epoch ---
--- 0.225996732711792 seconds for one epoch ---
--- 0.5471386909484863 seconds for one epoch ---
--- 0.15269780158996582 seconds for one epoch ---
--- 0.5836336612701416 seconds for one epoch ---
--- 0.2081308364868164 seconds for one epoch ---
--- 0.5339603424072266 seconds for one epoch ---
--- 0.1931910514831543 seconds for one epoch ---
--- 0.5869472026824951 seconds for one epoch ---
--- 0.2621266841888428 seconds for one epoch ---
--- 0.5724480152130127 seconds for one epoch ---
--- 0.20742440223693848 seconds for one epoch ---
--- 0.5815854072570801 seconds for one epoch ---
--- 0.22515583038330078 seconds for one epoch ---
--- 0.6271734237670898 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09865009]
 [0.        ]
 [0.        ]
 [0.05532695]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29877448]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.1709967]
 [ 0.       ]
 [-0.       ]
 [-1.3234242]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.117781 ]
 [ 0.       ]]
--- 0.1888444423675537 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2277.89892578125, (1182.8225, 0.28509644, 1094.5195, 0.2716578)
   validation loss 1250.6370849609375, (929.6025, 0.096509054, 320.6665, 0.2716578)
decoder loss ratio: 36014.413860, decoder SINDy loss  ratio: 0.692204
--- 0.17037153244018555 seconds for one epoch ---
--- 0.2153770923614502 seconds for one epoch ---
--- 0.550391674041748 seconds for one epoch ---
--- 0.2615809440612793 seconds for one epoch ---
--- 0.5540633201599121 seconds for one epoch ---
--- 0.1977252960205078 seconds for one epoch ---
--- 0.588615894317627 seconds for one epoch ---
--- 0.2185192108154297 seconds for one epoch ---
--- 0.5611519813537598 seconds for one epoch ---
--- 0.20083832740783691 seconds for one epoch ---
--- 0.5446732044219971 seconds for one epoch ---
--- 0.1687624454498291 seconds for one epoch ---
--- 0.5575971603393555 seconds for one epoch ---
--- 0.17470002174377441 seconds for one epoch ---
--- 0.5776200294494629 seconds for one epoch ---
--- 0.20281386375427246 seconds for one epoch ---
--- 0.5776462554931641 seconds for one epoch ---
--- 0.19493937492370605 seconds for one epoch ---
--- 0.5844082832336426 seconds for one epoch ---
--- 0.25841856002807617 seconds for one epoch ---
--- 0.5835816860198975 seconds for one epoch ---
--- 0.23204803466796875 seconds for one epoch ---
--- 0.5817162990570068 seconds for one epoch ---
--- 0.21068572998046875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09434868]
 [0.        ]
 [0.        ]
 [0.05468432]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3020309 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.1097538]
 [ 0.       ]
 [-0.       ]
 [-1.3176626]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.143324 ]
 [ 0.       ]]
--- 0.16093087196350098 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3511.511474609375, (1642.4281, 3.15427, 1865.6582, 0.27083024)
   validation loss 1098.587646484375, (725.3154, 0.09910172, 372.9022, 0.27083024)
decoder loss ratio: 28099.978949, decoder SINDy loss  ratio: 0.804962
--- 0.17955803871154785 seconds for one epoch ---
--- 0.5567872524261475 seconds for one epoch ---
--- 0.2441871166229248 seconds for one epoch ---
--- 0.5396010875701904 seconds for one epoch ---
--- 0.20127606391906738 seconds for one epoch ---
--- 0.5388851165771484 seconds for one epoch ---
--- 0.17574191093444824 seconds for one epoch ---
--- 0.5608985424041748 seconds for one epoch ---
--- 0.24071860313415527 seconds for one epoch ---
--- 0.576347827911377 seconds for one epoch ---
--- 0.18541359901428223 seconds for one epoch ---
--- 0.5703761577606201 seconds for one epoch ---
--- 0.20626521110534668 seconds for one epoch ---
--- 0.6441066265106201 seconds for one epoch ---
--- 0.19183611869812012 seconds for one epoch ---
--- 0.6108996868133545 seconds for one epoch ---
--- 0.18902373313903809 seconds for one epoch ---
--- 0.6029326915740967 seconds for one epoch ---
--- 0.23210787773132324 seconds for one epoch ---
--- 0.5862629413604736 seconds for one epoch ---
--- 0.20202994346618652 seconds for one epoch ---
--- 0.5722465515136719 seconds for one epoch ---
--- 0.19964361190795898 seconds for one epoch ---
--- 0.5974352359771729 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09238075]
 [0.        ]
 [0.        ]
 [0.05316715]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30096442]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.0830488]
 [ 0.       ]
 [-0.       ]
 [-1.2865264]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.1373944]
 [ 0.       ]]
--- 0.1814281940460205 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2594.68505859375, (1442.7958, 1.4012694, 1150.2189, 0.26910907)
   validation loss 910.498046875, (594.082, 0.10376753, 316.0432, 0.26910907)
decoder loss ratio: 23015.766898, decoder SINDy loss  ratio: 0.682224
--- 0.2730858325958252 seconds for one epoch ---
--- 0.21473908424377441 seconds for one epoch ---
--- 0.5559446811676025 seconds for one epoch ---
--- 0.18848347663879395 seconds for one epoch ---
--- 0.5632503032684326 seconds for one epoch ---
--- 0.17938661575317383 seconds for one epoch ---
--- 0.6216821670532227 seconds for one epoch ---
--- 0.24515652656555176 seconds for one epoch ---
--- 0.5744695663452148 seconds for one epoch ---
--- 0.19652748107910156 seconds for one epoch ---
--- 0.6376104354858398 seconds for one epoch ---
--- 0.23459863662719727 seconds for one epoch ---
--- 0.6075725555419922 seconds for one epoch ---
--- 0.21612310409545898 seconds for one epoch ---
--- 0.6116266250610352 seconds for one epoch ---
--- 0.19849061965942383 seconds for one epoch ---
--- 0.565028190612793 seconds for one epoch ---
--- 0.17941856384277344 seconds for one epoch ---
--- 0.592517614364624 seconds for one epoch ---
--- 0.16530489921569824 seconds for one epoch ---
--- 0.6165587902069092 seconds for one epoch ---
--- 0.19789958000183105 seconds for one epoch ---
--- 0.5960218906402588 seconds for one epoch ---
--- 0.1935868263244629 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08879172]
 [0.        ]
 [0.        ]
 [0.05238459]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3014187 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.0285845]
 [ 0.       ]
 [-0.       ]
 [-1.2735001]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.142161 ]
 [ 0.       ]]
--- 0.15489816665649414 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2581.88330078125, (1090.7665, 0.16244465, 1490.6864, 0.26798135)
   validation loss 1204.865234375, (813.80237, 0.07277446, 390.72214, 0.26798135)
decoder loss ratio: 31528.116566, decoder SINDy loss  ratio: 0.843429
--- 0.1873011589050293 seconds for one epoch ---
--- 0.6654679775238037 seconds for one epoch ---
--- 0.22063946723937988 seconds for one epoch ---
--- 0.6057732105255127 seconds for one epoch ---
--- 0.2162456512451172 seconds for one epoch ---
--- 0.6093647480010986 seconds for one epoch ---
--- 0.24055886268615723 seconds for one epoch ---
--- 0.613222599029541 seconds for one epoch ---
--- 0.2153463363647461 seconds for one epoch ---
--- 0.6571216583251953 seconds for one epoch ---
--- 0.2293546199798584 seconds for one epoch ---
--- 0.6534547805786133 seconds for one epoch ---
--- 0.18369674682617188 seconds for one epoch ---
--- 0.6531529426574707 seconds for one epoch ---
--- 0.2122211456298828 seconds for one epoch ---
--- 0.6412599086761475 seconds for one epoch ---
--- 0.23479938507080078 seconds for one epoch ---
--- 0.5757529735565186 seconds for one epoch ---
--- 0.2289884090423584 seconds for one epoch ---
--- 0.6375367641448975 seconds for one epoch ---
--- 0.21515274047851562 seconds for one epoch ---
--- 0.6236646175384521 seconds for one epoch ---
--- 0.2361295223236084 seconds for one epoch ---
--- 0.6077215671539307 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08648171]
 [0.        ]
 [0.        ]
 [0.05163695]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3038424 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.9932295]
 [ 0.       ]
 [-0.       ]
 [-1.2595164]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.160594 ]
 [ 0.       ]]
--- 0.24819040298461914 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2299.399658203125, (1303.8156, 1.0498369, 994.26666, 0.26765963)
   validation loss 842.2546997070312, (502.64032, 0.089855425, 339.2569, 0.26765963)
decoder loss ratio: 19473.158612, decoder SINDy loss  ratio: 0.732334
--- 0.1709752082824707 seconds for one epoch ---
--- 0.24096441268920898 seconds for one epoch ---
--- 0.622687816619873 seconds for one epoch ---
--- 0.1926114559173584 seconds for one epoch ---
--- 0.6420652866363525 seconds for one epoch ---
--- 0.21661663055419922 seconds for one epoch ---
--- 0.6661226749420166 seconds for one epoch ---
--- 0.2982320785522461 seconds for one epoch ---
--- 0.6816210746765137 seconds for one epoch ---
--- 0.20507192611694336 seconds for one epoch ---
--- 0.6039292812347412 seconds for one epoch ---
--- 0.20364594459533691 seconds for one epoch ---
--- 0.6747395992279053 seconds for one epoch ---
--- 0.19921565055847168 seconds for one epoch ---
--- 0.6358256340026855 seconds for one epoch ---
--- 0.19467401504516602 seconds for one epoch ---
--- 0.6238226890563965 seconds for one epoch ---
--- 0.19626760482788086 seconds for one epoch ---
--- 0.6248664855957031 seconds for one epoch ---
--- 0.19107890129089355 seconds for one epoch ---
--- 0.6715743541717529 seconds for one epoch ---
--- 0.17730212211608887 seconds for one epoch ---
--- 0.645867109298706 seconds for one epoch ---
--- 0.2024674415588379 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08693306]
 [0.        ]
 [0.        ]
 [0.04978845]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30679896]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.0041814]
 [ 0.       ]
 [-0.       ]
 [-1.2148364]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.1826143]
 [ 0.       ]]
--- 0.1556704044342041 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3767.371826171875, (1408.4763, 0.44964448, 2358.1785, 0.26740614)
   validation loss 1279.68408203125, (865.11005, 0.092139326, 414.2144, 0.26740614)
decoder loss ratio: 33515.865094, decoder SINDy loss  ratio: 0.894140
--- 0.21308493614196777 seconds for one epoch ---
--- 0.631629467010498 seconds for one epoch ---
--- 0.20450353622436523 seconds for one epoch ---
--- 0.6327178478240967 seconds for one epoch ---
--- 0.25394296646118164 seconds for one epoch ---
--- 0.6931335926055908 seconds for one epoch ---
--- 0.22753667831420898 seconds for one epoch ---
--- 0.6975381374359131 seconds for one epoch ---
--- 0.2499709129333496 seconds for one epoch ---
--- 0.6290676593780518 seconds for one epoch ---
--- 0.19876837730407715 seconds for one epoch ---
--- 0.6157820224761963 seconds for one epoch ---
--- 0.16093683242797852 seconds for one epoch ---
--- 0.6458272933959961 seconds for one epoch ---
--- 0.19107627868652344 seconds for one epoch ---
--- 0.6678507328033447 seconds for one epoch ---
--- 0.21431732177734375 seconds for one epoch ---
--- 0.6830120086669922 seconds for one epoch ---
--- 0.23161983489990234 seconds for one epoch ---
--- 0.6978006362915039 seconds for one epoch ---
--- 0.19344425201416016 seconds for one epoch ---
--- 0.6640830039978027 seconds for one epoch ---
--- 0.2401111125946045 seconds for one epoch ---
--- 0.6470117568969727 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08426499]
 [0.        ]
 [0.        ]
 [0.05000498]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31198043]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.9610282]
 [ 0.       ]
 [-0.       ]
 [-1.2250372]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.2199445]
 [ 0.       ]]
--- 0.23107385635375977 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4222.69970703125, (2039.2739, 3.8428848, 2179.315, 0.26814213)
   validation loss 1126.7667236328125, (779.1375, 0.09396713, 347.26697, 0.26814213)
decoder loss ratio: 30185.139865, decoder SINDy loss  ratio: 0.749625
--- 0.16905522346496582 seconds for one epoch ---
--- 0.1786789894104004 seconds for one epoch ---
--- 0.6337008476257324 seconds for one epoch ---
--- 0.21618318557739258 seconds for one epoch ---
--- 0.6384546756744385 seconds for one epoch ---
--- 0.22985529899597168 seconds for one epoch ---
--- 0.611649751663208 seconds for one epoch ---
--- 0.18814849853515625 seconds for one epoch ---
--- 0.7318508625030518 seconds for one epoch ---
--- 0.298107385635376 seconds for one epoch ---
--- 0.6261119842529297 seconds for one epoch ---
--- 0.23542118072509766 seconds for one epoch ---
--- 0.621574878692627 seconds for one epoch ---
--- 0.21176409721374512 seconds for one epoch ---
--- 0.6571204662322998 seconds for one epoch ---
--- 0.22264647483825684 seconds for one epoch ---
--- 0.6646332740783691 seconds for one epoch ---
--- 0.19489455223083496 seconds for one epoch ---
--- 0.6800131797790527 seconds for one epoch ---
--- 0.17511224746704102 seconds for one epoch ---
--- 0.6592578887939453 seconds for one epoch ---
--- 0.15410351753234863 seconds for one epoch ---
--- 0.6928327083587646 seconds for one epoch ---
--- 0.18614983558654785 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08215386]
 [0.        ]
 [0.        ]
 [0.04902967]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3148463 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.9264288]
 [ 0.       ]
 [-0.       ]
 [-1.2020674]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.240754 ]
 [ 0.       ]]
--- 0.15582561492919922 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7319.16162109375, (1221.3422, 2.288294, 6095.2637, 0.2677311)
   validation loss 1321.9349365234375, (910.2203, 0.1201435, 411.3269, 0.2677311)
decoder loss ratio: 35263.513699, decoder SINDy loss  ratio: 0.887907
--- 0.22774004936218262 seconds for one epoch ---
--- 0.6672730445861816 seconds for one epoch ---
--- 0.15429186820983887 seconds for one epoch ---
--- 0.658806324005127 seconds for one epoch ---
--- 0.20837974548339844 seconds for one epoch ---
--- 0.6410927772521973 seconds for one epoch ---
--- 0.21938252449035645 seconds for one epoch ---
--- 0.7227094173431396 seconds for one epoch ---
--- 0.1726837158203125 seconds for one epoch ---
--- 0.6713342666625977 seconds for one epoch ---
--- 0.21373248100280762 seconds for one epoch ---
--- 0.6822967529296875 seconds for one epoch ---
--- 0.19605064392089844 seconds for one epoch ---
--- 0.6909036636352539 seconds for one epoch ---
--- 0.2129991054534912 seconds for one epoch ---
--- 0.6960875988006592 seconds for one epoch ---
--- 0.2340238094329834 seconds for one epoch ---
--- 0.6831145286560059 seconds for one epoch ---
--- 0.1877286434173584 seconds for one epoch ---
--- 0.6277437210083008 seconds for one epoch ---
--- 0.2265312671661377 seconds for one epoch ---
--- 0.6873188018798828 seconds for one epoch ---
--- 0.18774986267089844 seconds for one epoch ---
--- 0.6539041996002197 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08053927]
 [0.        ]
 [0.        ]
 [0.04903955]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32339165]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.8995225]
 [ 0.       ]
 [-0.       ]
 [-1.2053727]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.300758 ]
 [ 0.       ]]
--- 0.251845121383667 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6126.74609375, (2417.931, 2.465682, 3706.081, 0.26877436)
   validation loss 1140.54736328125, (799.2411, 0.096755885, 340.9408, 0.26877436)
decoder loss ratio: 30963.987326, decoder SINDy loss  ratio: 0.735969
--- 0.1733698844909668 seconds for one epoch ---
--- 0.1858370304107666 seconds for one epoch ---
--- 0.7043492794036865 seconds for one epoch ---
--- 0.21959733963012695 seconds for one epoch ---
--- 0.6535773277282715 seconds for one epoch ---
--- 0.2519083023071289 seconds for one epoch ---
--- 0.680854082107544 seconds for one epoch ---
--- 0.18507862091064453 seconds for one epoch ---
--- 0.7192802429199219 seconds for one epoch ---
--- 0.20819759368896484 seconds for one epoch ---
--- 0.6452617645263672 seconds for one epoch ---
--- 0.1988070011138916 seconds for one epoch ---
--- 0.697709321975708 seconds for one epoch ---
--- 0.3926513195037842 seconds for one epoch ---
--- 0.6806018352508545 seconds for one epoch ---
--- 0.21789956092834473 seconds for one epoch ---
--- 0.7029550075531006 seconds for one epoch ---
--- 0.2190096378326416 seconds for one epoch ---
--- 0.6913352012634277 seconds for one epoch ---
--- 0.2217574119567871 seconds for one epoch ---
--- 0.6677308082580566 seconds for one epoch ---
--- 0.16670942306518555 seconds for one epoch ---
--- 0.650080680847168 seconds for one epoch ---
--- 0.17859959602355957 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.0785915 ]
 [0.        ]
 [0.        ]
 [0.04834978]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33152252]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.8659272]
 [ 0.       ]
 [-0.       ]
 [-1.1889539]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.3572464]
 [ 0.       ]]
--- 0.1639394760131836 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4686.8642578125, (2040.4625, 4.605029, 2641.5278, 0.26922724)
   validation loss 1142.99072265625, (736.98914, 0.13763821, 405.59464, 0.26922724)
decoder loss ratio: 28552.238588, decoder SINDy loss  ratio: 0.875533
--- 0.21919846534729004 seconds for one epoch ---
--- 0.7136595249176025 seconds for one epoch ---
--- 0.16339397430419922 seconds for one epoch ---
--- 0.6622648239135742 seconds for one epoch ---
--- 0.18126583099365234 seconds for one epoch ---
--- 0.7628602981567383 seconds for one epoch ---
--- 0.19916057586669922 seconds for one epoch ---
--- 0.6750056743621826 seconds for one epoch ---
--- 0.20108294486999512 seconds for one epoch ---
--- 0.7408585548400879 seconds for one epoch ---
--- 0.21696686744689941 seconds for one epoch ---
--- 0.6842927932739258 seconds for one epoch ---
--- 0.19761896133422852 seconds for one epoch ---
--- 0.6819777488708496 seconds for one epoch ---
--- 0.21474933624267578 seconds for one epoch ---
--- 0.725226640701294 seconds for one epoch ---
--- 0.18562674522399902 seconds for one epoch ---
--- 0.693810224533081 seconds for one epoch ---
--- 0.18608498573303223 seconds for one epoch ---
--- 0.7109024524688721 seconds for one epoch ---
--- 0.19268536567687988 seconds for one epoch ---
--- 0.7311875820159912 seconds for one epoch ---
--- 0.23700261116027832 seconds for one epoch ---
--- 0.6853070259094238 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.07676401]
 [0.        ]
 [0.        ]
 [0.04802325]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33631936]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.8335102]
 [ 0.       ]
 [-0.       ]
 [-1.181975 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.39041  ]
 [ 0.       ]]
--- 0.21613383293151855 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3505.8740234375, (1752.687, 3.7235246, 1749.1945, 0.26913673)
   validation loss 1175.327392578125, (800.6394, 0.1413097, 374.27753, 0.26913673)
decoder loss ratio: 31018.160494, decoder SINDy loss  ratio: 0.807931
--- 0.17018437385559082 seconds for one epoch ---
--- 0.2096695899963379 seconds for one epoch ---
--- 0.7367908954620361 seconds for one epoch ---
--- 0.22578787803649902 seconds for one epoch ---
--- 0.7661652565002441 seconds for one epoch ---
--- 0.24474310874938965 seconds for one epoch ---
--- 0.7359218597412109 seconds for one epoch ---
--- 0.20801281929016113 seconds for one epoch ---
--- 0.6847174167633057 seconds for one epoch ---
--- 0.23301100730895996 seconds for one epoch ---
--- 0.6913747787475586 seconds for one epoch ---
--- 0.21568822860717773 seconds for one epoch ---
--- 0.7139401435852051 seconds for one epoch ---
--- 0.2222754955291748 seconds for one epoch ---
--- 0.703394889831543 seconds for one epoch ---
--- 0.18044638633728027 seconds for one epoch ---
--- 0.6914165019989014 seconds for one epoch ---
--- 0.212723970413208 seconds for one epoch ---
--- 0.6757063865661621 seconds for one epoch ---
--- 0.1846613883972168 seconds for one epoch ---
--- 0.7359440326690674 seconds for one epoch ---
--- 0.16801214218139648 seconds for one epoch ---
--- 0.7880442142486572 seconds for one epoch ---
--- 0.2167067527770996 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.07696267]
 [0.        ]
 [0.        ]
 [0.04800667]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3462402 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.8385026]
 [ 0.       ]
 [-0.       ]
 [-1.1835092]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.4580426]
 [ 0.       ]]
--- 0.20268964767456055 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3575.47802734375, (1584.2565, 1.3475988, 1989.6031, 0.27066323)
   validation loss 1067.7127685546875, (730.9623, 0.08268496, 336.39716, 0.27066323)
decoder loss ratio: 28318.747744, decoder SINDy loss  ratio: 0.726161
--- 0.20121264457702637 seconds for one epoch ---
--- 0.6668734550476074 seconds for one epoch ---
--- 0.2127077579498291 seconds for one epoch ---
--- 0.7058780193328857 seconds for one epoch ---
--- 0.2135303020477295 seconds for one epoch ---
--- 0.6806161403656006 seconds for one epoch ---
--- 0.19594120979309082 seconds for one epoch ---
--- 0.6902287006378174 seconds for one epoch ---
--- 0.2037351131439209 seconds for one epoch ---
--- 0.7078258991241455 seconds for one epoch ---
--- 0.18364667892456055 seconds for one epoch ---
--- 0.6685833930969238 seconds for one epoch ---
--- 0.20270037651062012 seconds for one epoch ---
--- 0.6631731986999512 seconds for one epoch ---
--- 0.19401836395263672 seconds for one epoch ---
--- 0.6703650951385498 seconds for one epoch ---
--- 0.20148038864135742 seconds for one epoch ---
--- 0.6882898807525635 seconds for one epoch ---
--- 0.18899035453796387 seconds for one epoch ---
--- 0.6895112991333008 seconds for one epoch ---
--- 0.22055935859680176 seconds for one epoch ---
--- 0.726057767868042 seconds for one epoch ---
--- 0.1721358299255371 seconds for one epoch ---
--- 0.766338586807251 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.07544236]
 [0.        ]
 [0.        ]
 [0.0482492 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35227433]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.8109715]
 [ 0.       ]
 [-0.       ]
 [-1.1918558]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.4989114]
 [ 0.       ]]
--- 0.1923367977142334 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3437.890869140625, (1559.6931, 0.45224637, 1877.4752, 0.27031142)
   validation loss 1248.882568359375, (899.9031, 0.11722252, 348.592, 0.27031142)
decoder loss ratio: 34863.807471, decoder SINDy loss  ratio: 0.752485
THRESHOLDING: 1 active coefficients
--- 0.7682278156280518 seconds for one epoch ---
--- 0.187469482421875 seconds for one epoch ---
--- 0.7141213417053223 seconds for one epoch ---
--- 0.17039823532104492 seconds for one epoch ---
--- 0.7273736000061035 seconds for one epoch ---
--- 0.22819781303405762 seconds for one epoch ---
--- 0.7096214294433594 seconds for one epoch ---
--- 0.18975329399108887 seconds for one epoch ---
--- 0.7123227119445801 seconds for one epoch ---
--- 0.2256302833557129 seconds for one epoch ---
--- 0.7392666339874268 seconds for one epoch ---
--- 0.20144248008728027 seconds for one epoch ---
--- 0.6878180503845215 seconds for one epoch ---
--- 0.1897568702697754 seconds for one epoch ---
--- 0.7328536510467529 seconds for one epoch ---
--- 0.2282850742340088 seconds for one epoch ---
--- 0.7595093250274658 seconds for one epoch ---
--- 0.21229791641235352 seconds for one epoch ---
--- 0.735274076461792 seconds for one epoch ---
--- 0.20139050483703613 seconds for one epoch ---
--- 0.7214653491973877 seconds for one epoch ---
--- 0.20443010330200195 seconds for one epoch ---
--- 0.7163493633270264 seconds for one epoch ---
--- 0.18295502662658691 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39837226]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.803355]
 [ 0.      ]]
--- 0.17882895469665527 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2468.51025390625, (1553.5923, 0.69563663, 914.05206, 0.17023616)
   validation loss 1170.122314453125, (773.47253, 0.13506119, 396.34445, 0.17023616)
decoder loss ratio: 29965.668781, decoder SINDy loss  ratio: 0.855565
--- 0.22808313369750977 seconds for one epoch ---
--- 0.7347047328948975 seconds for one epoch ---
--- 0.21537995338439941 seconds for one epoch ---
--- 0.7254643440246582 seconds for one epoch ---
--- 0.1934194564819336 seconds for one epoch ---
--- 0.70943284034729 seconds for one epoch ---
--- 0.20269489288330078 seconds for one epoch ---
--- 0.7241861820220947 seconds for one epoch ---
--- 0.19996953010559082 seconds for one epoch ---
--- 0.7011570930480957 seconds for one epoch ---
--- 0.18684959411621094 seconds for one epoch ---
--- 0.7121875286102295 seconds for one epoch ---
--- 0.20057988166809082 seconds for one epoch ---
--- 0.7059178352355957 seconds for one epoch ---
--- 0.18527555465698242 seconds for one epoch ---
--- 0.7395899295806885 seconds for one epoch ---
--- 0.18630337715148926 seconds for one epoch ---
--- 0.860327959060669 seconds for one epoch ---
--- 0.2064206600189209 seconds for one epoch ---
--- 0.7686562538146973 seconds for one epoch ---
--- 0.19846296310424805 seconds for one epoch ---
--- 0.7518763542175293 seconds for one epoch ---
--- 0.2204580307006836 seconds for one epoch ---
--- 0.8510849475860596 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.44129872]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-5.081076]
 [ 0.      ]]
--- 0.20233559608459473 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2938.662353515625, (1631.8749, 1.5048985, 1305.1013, 0.18130825)
   validation loss 2311.483154296875, (1825.0497, 0.1963999, 486.05563, 0.18130825)
decoder loss ratio: 70705.593130, decoder SINDy loss  ratio: 1.049219
--- 0.1473677158355713 seconds for one epoch ---
--- 0.16621875762939453 seconds for one epoch ---
--- 0.7812590599060059 seconds for one epoch ---
--- 0.21963095664978027 seconds for one epoch ---
--- 0.7871174812316895 seconds for one epoch ---
--- 0.24084019660949707 seconds for one epoch ---
--- 0.697638988494873 seconds for one epoch ---
--- 0.1923818588256836 seconds for one epoch ---
--- 0.776170015335083 seconds for one epoch ---
--- 0.16799020767211914 seconds for one epoch ---
--- 0.7251591682434082 seconds for one epoch ---
--- 0.15892910957336426 seconds for one epoch ---
--- 0.7468838691711426 seconds for one epoch ---
--- 0.21469664573669434 seconds for one epoch ---
--- 0.7064657211303711 seconds for one epoch ---
--- 0.20264291763305664 seconds for one epoch ---
--- 0.7152013778686523 seconds for one epoch ---
--- 0.17575383186340332 seconds for one epoch ---
--- 0.7851402759552002 seconds for one epoch ---
--- 0.3148529529571533 seconds for one epoch ---
--- 0.7162671089172363 seconds for one epoch ---
--- 0.21807217597961426 seconds for one epoch ---
--- 0.8138635158538818 seconds for one epoch ---
--- 0.2241370677947998 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.48224345]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.3451066]
 [ 0.       ]]
--- 0.1861584186553955 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2577.349853515625, (1295.8944, 0.9213243, 1280.3428, 0.19128983)
   validation loss 1298.0457763671875, (887.82086, 0.15574431, 409.87787, 0.19128983)
decoder loss ratio: 34395.721512, decoder SINDy loss  ratio: 0.884779
--- 0.19400548934936523 seconds for one epoch ---
--- 0.7920582294464111 seconds for one epoch ---
--- 0.21620821952819824 seconds for one epoch ---
--- 0.8521318435668945 seconds for one epoch ---
--- 0.1701068878173828 seconds for one epoch ---
--- 0.7468078136444092 seconds for one epoch ---
--- 0.190626859664917 seconds for one epoch ---
--- 0.7704758644104004 seconds for one epoch ---
--- 0.19954204559326172 seconds for one epoch ---
--- 0.7402634620666504 seconds for one epoch ---
--- 0.19772601127624512 seconds for one epoch ---
--- 0.7233872413635254 seconds for one epoch ---
--- 0.17957520484924316 seconds for one epoch ---
--- 0.7314362525939941 seconds for one epoch ---
--- 0.21405911445617676 seconds for one epoch ---
--- 0.8239045143127441 seconds for one epoch ---
--- 0.2520313262939453 seconds for one epoch ---
--- 0.7413332462310791 seconds for one epoch ---
--- 0.20937776565551758 seconds for one epoch ---
--- 0.7712669372558594 seconds for one epoch ---
--- 0.18694686889648438 seconds for one epoch ---
--- 0.791985034942627 seconds for one epoch ---
--- 0.2161574363708496 seconds for one epoch ---
--- 0.7738277912139893 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.52477616]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.6225424]
 [ 0.       ]]
--- 0.19599199295043945 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3435.0615234375, (1639.1704, 3.0152187, 1792.6742, 0.20161562)
   validation loss 988.4403076171875, (633.7643, 0.14907783, 354.32538, 0.20161562)
decoder loss ratio: 24553.128557, decoder SINDy loss  ratio: 0.764861
--- 0.20061612129211426 seconds for one epoch ---
--- 0.23456096649169922 seconds for one epoch ---
--- 0.732694149017334 seconds for one epoch ---
--- 0.2222459316253662 seconds for one epoch ---
--- 0.7492854595184326 seconds for one epoch ---
--- 0.19643950462341309 seconds for one epoch ---
--- 0.7689089775085449 seconds for one epoch ---
--- 0.1879580020904541 seconds for one epoch ---
--- 0.8079373836517334 seconds for one epoch ---
--- 0.17178058624267578 seconds for one epoch ---
--- 0.7513158321380615 seconds for one epoch ---
--- 0.210235595703125 seconds for one epoch ---
--- 0.8509654998779297 seconds for one epoch ---
--- 0.3101365566253662 seconds for one epoch ---
--- 0.7529623508453369 seconds for one epoch ---
--- 0.2341470718383789 seconds for one epoch ---
--- 0.7627112865447998 seconds for one epoch ---
--- 0.19256329536437988 seconds for one epoch ---
--- 0.7426853179931641 seconds for one epoch ---
--- 0.19342994689941406 seconds for one epoch ---
--- 0.7857997417449951 seconds for one epoch ---
--- 0.18654704093933105 seconds for one epoch ---
--- 0.8152563571929932 seconds for one epoch ---
--- 0.22159457206726074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.56320095]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.8795557]
 [ 0.       ]]
--- 0.1461658477783203 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4933.33349609375, (1442.0778, 9.525503, 3481.5193, 0.21084009)
   validation loss 976.568359375, (640.33484, 0.110357836, 335.91232, 0.21084009)
decoder loss ratio: 24807.683328, decoder SINDy loss  ratio: 0.725114
--- 0.16832995414733887 seconds for one epoch ---
--- 0.7333309650421143 seconds for one epoch ---
--- 0.2114408016204834 seconds for one epoch ---
--- 0.7522237300872803 seconds for one epoch ---
--- 0.20481085777282715 seconds for one epoch ---
--- 0.7901849746704102 seconds for one epoch ---
--- 0.22239923477172852 seconds for one epoch ---
--- 0.7351408004760742 seconds for one epoch ---
--- 0.19452881813049316 seconds for one epoch ---
--- 0.7602813243865967 seconds for one epoch ---
--- 0.19716763496398926 seconds for one epoch ---
--- 0.7954270839691162 seconds for one epoch ---
--- 0.21370291709899902 seconds for one epoch ---
--- 0.8064160346984863 seconds for one epoch ---
--- 0.18710803985595703 seconds for one epoch ---
--- 0.765509843826294 seconds for one epoch ---
--- 0.21726727485656738 seconds for one epoch ---
--- 0.7806980609893799 seconds for one epoch ---
--- 0.20836234092712402 seconds for one epoch ---
--- 0.8073360919952393 seconds for one epoch ---
--- 0.2061607837677002 seconds for one epoch ---
--- 0.7867145538330078 seconds for one epoch ---
--- 0.19924306869506836 seconds for one epoch ---
--- 0.8025262355804443 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.59649765]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-6.110011]
 [-0.      ]]
--- 0.2136859893798828 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2854.153076171875, (1173.0848, 1.7616998, 1679.0875, 0.21906804)
   validation loss 1028.208251953125, (647.85474, 0.14386116, 379.99054, 0.21906804)
decoder loss ratio: 25099.017211, decoder SINDy loss  ratio: 0.820263
--- 0.15604233741760254 seconds for one epoch ---
--- 0.2188432216644287 seconds for one epoch ---
--- 0.7660143375396729 seconds for one epoch ---
--- 0.17304158210754395 seconds for one epoch ---
--- 0.8616290092468262 seconds for one epoch ---
--- 0.23739123344421387 seconds for one epoch ---
--- 0.7577610015869141 seconds for one epoch ---
--- 0.15700316429138184 seconds for one epoch ---
--- 0.8025617599487305 seconds for one epoch ---
--- 0.18578171730041504 seconds for one epoch ---
--- 0.7721498012542725 seconds for one epoch ---
--- 0.2327725887298584 seconds for one epoch ---
--- 0.8619017601013184 seconds for one epoch ---
--- 0.21087169647216797 seconds for one epoch ---
--- 0.78302001953125 seconds for one epoch ---
--- 0.20226621627807617 seconds for one epoch ---
--- 0.8033878803253174 seconds for one epoch ---
--- 0.19234204292297363 seconds for one epoch ---
--- 0.7642290592193604 seconds for one epoch ---
--- 0.18765544891357422 seconds for one epoch ---
--- 0.8103861808776855 seconds for one epoch ---
--- 0.2060098648071289 seconds for one epoch ---
--- 0.7884609699249268 seconds for one epoch ---
--- 0.17866110801696777 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6285897]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.3416104]
 [-0.       ]]
--- 0.1635274887084961 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5507.98681640625, (1893.216, 1.6528581, 3612.891, 0.22712098)
   validation loss 1028.443603515625, (692.15125, 0.1427822, 335.92242, 0.22712098)
decoder loss ratio: 26815.140863, decoder SINDy loss  ratio: 0.725136
--- 0.17962384223937988 seconds for one epoch ---
--- 0.7745485305786133 seconds for one epoch ---
--- 0.21843957901000977 seconds for one epoch ---
--- 0.7572641372680664 seconds for one epoch ---
--- 0.22144460678100586 seconds for one epoch ---
--- 0.8048038482666016 seconds for one epoch ---
--- 0.2187352180480957 seconds for one epoch ---
--- 0.7547526359558105 seconds for one epoch ---
--- 0.19646358489990234 seconds for one epoch ---
--- 0.8010573387145996 seconds for one epoch ---
--- 0.20273447036743164 seconds for one epoch ---
--- 0.8083868026733398 seconds for one epoch ---
--- 0.1803886890411377 seconds for one epoch ---
--- 0.8200335502624512 seconds for one epoch ---
--- 0.20992469787597656 seconds for one epoch ---
--- 0.810157060623169 seconds for one epoch ---
--- 0.1968080997467041 seconds for one epoch ---
--- 0.8282148838043213 seconds for one epoch ---
--- 0.20624399185180664 seconds for one epoch ---
--- 0.7939114570617676 seconds for one epoch ---
--- 0.2053210735321045 seconds for one epoch ---
--- 0.908444881439209 seconds for one epoch ---
--- 0.20447945594787598 seconds for one epoch ---
--- 0.8674039840698242 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6602011]
 [0.       ]]
[[ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-6.58176]
 [-0.     ]]
--- 0.18446898460388184 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2548.98876953125, (940.78357, 2.249906, 1605.7203, 0.23488484)
   validation loss 982.1729125976562, (656.40234, 0.102076195, 325.43365, 0.23488484)
decoder loss ratio: 25430.166361, decoder SINDy loss  ratio: 0.702494
--- 0.15190577507019043 seconds for one epoch ---
--- 0.1847841739654541 seconds for one epoch ---
--- 0.7954509258270264 seconds for one epoch ---
--- 0.18795204162597656 seconds for one epoch ---
--- 0.8179230690002441 seconds for one epoch ---
--- 0.23528361320495605 seconds for one epoch ---
--- 0.8264553546905518 seconds for one epoch ---
--- 0.22104191780090332 seconds for one epoch ---
--- 0.7889478206634521 seconds for one epoch ---
--- 0.18096113204956055 seconds for one epoch ---
--- 0.8607792854309082 seconds for one epoch ---
--- 0.21548867225646973 seconds for one epoch ---
--- 0.8689594268798828 seconds for one epoch ---
--- 0.18016362190246582 seconds for one epoch ---
--- 0.8110716342926025 seconds for one epoch ---
--- 0.18422627449035645 seconds for one epoch ---
--- 0.805992841720581 seconds for one epoch ---
--- 0.17939424514770508 seconds for one epoch ---
--- 0.8199522495269775 seconds for one epoch ---
--- 0.23107337951660156 seconds for one epoch ---
--- 0.8578596115112305 seconds for one epoch ---
--- 0.21824955940246582 seconds for one epoch ---
--- 0.7973883152008057 seconds for one epoch ---
--- 0.1967775821685791 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6902613]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-6.824466]
 [ 0.      ]]
--- 0.1812589168548584 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2935.823486328125, (1376.519, 1.2599714, 1557.8018, 0.24261127)
   validation loss 915.8720092773438, (606.9114, 0.08342845, 308.6346, 0.24261127)
decoder loss ratio: 23512.800388, decoder SINDy loss  ratio: 0.666231
--- 0.21025323867797852 seconds for one epoch ---
--- 0.8313894271850586 seconds for one epoch ---
--- 0.16761493682861328 seconds for one epoch ---
--- 0.8700876235961914 seconds for one epoch ---
--- 0.31372976303100586 seconds for one epoch ---
--- 0.7893822193145752 seconds for one epoch ---
--- 0.18232226371765137 seconds for one epoch ---
--- 0.8652040958404541 seconds for one epoch ---
--- 0.22400999069213867 seconds for one epoch ---
--- 0.8331563472747803 seconds for one epoch ---
--- 0.1746690273284912 seconds for one epoch ---
--- 0.8195202350616455 seconds for one epoch ---
--- 0.21305131912231445 seconds for one epoch ---
--- 0.8096561431884766 seconds for one epoch ---
--- 0.16205358505249023 seconds for one epoch ---
--- 0.8542189598083496 seconds for one epoch ---
--- 0.22526144981384277 seconds for one epoch ---
--- 0.8037753105163574 seconds for one epoch ---
--- 0.22698259353637695 seconds for one epoch ---
--- 0.8201351165771484 seconds for one epoch ---
--- 0.17062830924987793 seconds for one epoch ---
--- 0.8217551708221436 seconds for one epoch ---
--- 0.2133021354675293 seconds for one epoch ---
--- 0.8903939723968506 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7176683]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-7.061332]
 [ 0.      ]]
--- 0.20978403091430664 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2524.960205078125, (1534.467, 0.5749856, 989.6687, 0.24954581)
   validation loss 900.3319702148438, (611.93024, 0.09357416, 288.05862, 0.24954581)
decoder loss ratio: 23707.239732, decoder SINDy loss  ratio: 0.621815
--- 0.269700288772583 seconds for one epoch ---
--- 0.2485666275024414 seconds for one epoch ---
--- 0.827129602432251 seconds for one epoch ---
--- 0.21999788284301758 seconds for one epoch ---
--- 0.85133957862854 seconds for one epoch ---
--- 0.2052006721496582 seconds for one epoch ---
--- 0.8287074565887451 seconds for one epoch ---
--- 0.19392776489257812 seconds for one epoch ---
--- 0.850273609161377 seconds for one epoch ---
--- 0.1604304313659668 seconds for one epoch ---
--- 0.8382711410522461 seconds for one epoch ---
--- 0.1929471492767334 seconds for one epoch ---
--- 0.9154632091522217 seconds for one epoch ---
--- 0.2171027660369873 seconds for one epoch ---
--- 0.8306229114532471 seconds for one epoch ---
--- 0.21608424186706543 seconds for one epoch ---
--- 0.8564984798431396 seconds for one epoch ---
--- 0.4003159999847412 seconds for one epoch ---
--- 0.8464469909667969 seconds for one epoch ---
--- 0.20143795013427734 seconds for one epoch ---
--- 0.9217886924743652 seconds for one epoch ---
--- 0.21431469917297363 seconds for one epoch ---
--- 0.9051322937011719 seconds for one epoch ---
--- 0.23050284385681152 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7414574]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-7.282119]
 [ 0.      ]]
--- 0.16384077072143555 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2651.184326171875, (989.2793, 1.9505552, 1659.6986, 0.25581083)
   validation loss 962.9600219726562, (626.68396, 0.10115768, 335.9191, 0.25581083)
decoder loss ratio: 24278.824580, decoder SINDy loss  ratio: 0.725129
--- 0.21903276443481445 seconds for one epoch ---
--- 0.9155895709991455 seconds for one epoch ---
--- 0.17591500282287598 seconds for one epoch ---
--- 0.8218753337860107 seconds for one epoch ---
--- 0.22896552085876465 seconds for one epoch ---
--- 0.8630959987640381 seconds for one epoch ---
--- 0.18402814865112305 seconds for one epoch ---
--- 0.8327460289001465 seconds for one epoch ---
--- 0.22295522689819336 seconds for one epoch ---
--- 0.8577406406402588 seconds for one epoch ---
--- 0.20659446716308594 seconds for one epoch ---
--- 0.8397741317749023 seconds for one epoch ---
--- 0.23571014404296875 seconds for one epoch ---
--- 0.9013056755065918 seconds for one epoch ---
--- 0.21813702583312988 seconds for one epoch ---
--- 0.8964688777923584 seconds for one epoch ---
--- 0.24674606323242188 seconds for one epoch ---
--- 0.961127519607544 seconds for one epoch ---
--- 0.2223503589630127 seconds for one epoch ---
--- 0.9145326614379883 seconds for one epoch ---
--- 0.1996924877166748 seconds for one epoch ---
--- 0.9270279407501221 seconds for one epoch ---
--- 0.18318462371826172 seconds for one epoch ---
--- 0.8915612697601318 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7636379]
 [0.       ]]
[[ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-7.50382]
 [-0.     ]]
--- 0.2008960247039795 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3264.435302734375, (1431.7328, 6.2655764, 1826.1749, 0.26205847)
   validation loss 1453.4144287109375, (1138.7819, 0.119699255, 314.25076, 0.26205847)
decoder loss ratio: 44118.386282, decoder SINDy loss  ratio: 0.678354
--- 0.16112756729125977 seconds for one epoch ---
--- 0.20616579055786133 seconds for one epoch ---
--- 0.9369986057281494 seconds for one epoch ---
--- 0.1733231544494629 seconds for one epoch ---
--- 0.898871660232544 seconds for one epoch ---
--- 0.24079227447509766 seconds for one epoch ---
--- 0.894240140914917 seconds for one epoch ---
--- 0.19101929664611816 seconds for one epoch ---
--- 0.9198639392852783 seconds for one epoch ---
--- 0.17793893814086914 seconds for one epoch ---
--- 0.9471964836120605 seconds for one epoch ---
--- 0.2137765884399414 seconds for one epoch ---
--- 0.8700768947601318 seconds for one epoch ---
--- 0.19010448455810547 seconds for one epoch ---
--- 0.952568769454956 seconds for one epoch ---
--- 0.16968679428100586 seconds for one epoch ---
--- 0.916022539138794 seconds for one epoch ---
--- 0.22264361381530762 seconds for one epoch ---
--- 0.8342266082763672 seconds for one epoch ---
--- 0.18645453453063965 seconds for one epoch ---
--- 0.8351001739501953 seconds for one epoch ---
--- 0.22729825973510742 seconds for one epoch ---
--- 0.8787076473236084 seconds for one epoch ---
--- 0.18805766105651855 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.78315115]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.7144294]
 [-0.       ]]
--- 0.1560196876525879 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1511.5616455078125, (942.34174, 0.8547919, 568.09753, 0.26756203)
   validation loss 1126.63232421875, (769.6881, 0.11186893, 356.56473, 0.26756203)
decoder loss ratio: 29819.053632, decoder SINDy loss  ratio: 0.769695
--- 0.17912936210632324 seconds for one epoch ---
--- 0.815669059753418 seconds for one epoch ---
--- 0.19050240516662598 seconds for one epoch ---
--- 0.9588513374328613 seconds for one epoch ---
--- 0.29807591438293457 seconds for one epoch ---
--- 0.8689587116241455 seconds for one epoch ---
--- 0.20566272735595703 seconds for one epoch ---
--- 0.8575451374053955 seconds for one epoch ---
--- 0.20631194114685059 seconds for one epoch ---
--- 0.8777370452880859 seconds for one epoch ---
--- 0.22191786766052246 seconds for one epoch ---
--- 0.866607666015625 seconds for one epoch ---
--- 0.1857469081878662 seconds for one epoch ---
--- 0.8972575664520264 seconds for one epoch ---
--- 0.23414111137390137 seconds for one epoch ---
--- 0.9417831897735596 seconds for one epoch ---
--- 0.3020656108856201 seconds for one epoch ---
--- 0.9210083484649658 seconds for one epoch ---
--- 0.3042178153991699 seconds for one epoch ---
--- 0.9416804313659668 seconds for one epoch ---
--- 0.30255794525146484 seconds for one epoch ---
--- 0.9231851100921631 seconds for one epoch ---
--- 0.29405665397644043 seconds for one epoch ---
--- 0.935694694519043 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.80055964]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.917386]
 [-0.      ]]
--- 0.29728174209594727 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2198.639404296875, (1220.434, 1.4505239, 976.4823, 0.27275428)
   validation loss 1238.5560302734375, (909.7984, 0.12816118, 328.35672, 0.27275428)
decoder loss ratio: 35247.169530, decoder SINDy loss  ratio: 0.708804
--- 0.27179694175720215 seconds for one epoch ---
--- 0.30327844619750977 seconds for one epoch ---
--- 0.871246337890625 seconds for one epoch ---
--- 0.3070807456970215 seconds for one epoch ---
--- 0.9356448650360107 seconds for one epoch ---
--- 0.3106498718261719 seconds for one epoch ---
--- 0.9058916568756104 seconds for one epoch ---
--- 0.31146764755249023 seconds for one epoch ---
--- 0.9417529106140137 seconds for one epoch ---
--- 0.303708553314209 seconds for one epoch ---
--- 0.9622395038604736 seconds for one epoch ---
--- 0.30083632469177246 seconds for one epoch ---
--- 0.9116969108581543 seconds for one epoch ---
--- 0.29617834091186523 seconds for one epoch ---
--- 0.9147396087646484 seconds for one epoch ---
--- 0.300814151763916 seconds for one epoch ---
--- 0.9267764091491699 seconds for one epoch ---
--- 0.29331207275390625 seconds for one epoch ---
--- 0.9083919525146484 seconds for one epoch ---
--- 0.30141687393188477 seconds for one epoch ---
--- 0.9214949607849121 seconds for one epoch ---
--- 0.31998419761657715 seconds for one epoch ---
--- 0.9117043018341064 seconds for one epoch ---
--- 0.32508087158203125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.81817675]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.140466]
 [ 0.      ]]
--- 0.25905394554138184 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4011.88916015625, (1742.7827, 1.9205271, 2266.9075, 0.27830216)
   validation loss 1138.31640625, (835.42755, 0.1280597, 302.48248, 0.27830216)
decoder loss ratio: 32365.913702, decoder SINDy loss  ratio: 0.652951
--- 0.30054426193237305 seconds for one epoch ---
--- 0.9051918983459473 seconds for one epoch ---
--- 0.307619571685791 seconds for one epoch ---
--- 0.9044177532196045 seconds for one epoch ---
--- 0.32242369651794434 seconds for one epoch ---
--- 0.9206821918487549 seconds for one epoch ---
--- 0.3166317939758301 seconds for one epoch ---
--- 0.9230465888977051 seconds for one epoch ---
--- 0.3328874111175537 seconds for one epoch ---
--- 0.9445226192474365 seconds for one epoch ---
--- 0.33055639266967773 seconds for one epoch ---
--- 0.9629199504852295 seconds for one epoch ---
--- 0.3459315299987793 seconds for one epoch ---
--- 0.9639606475830078 seconds for one epoch ---
--- 0.3594179153442383 seconds for one epoch ---
--- 0.962498664855957 seconds for one epoch ---
--- 0.33060693740844727 seconds for one epoch ---
--- 0.9547085762023926 seconds for one epoch ---
--- 0.3214564323425293 seconds for one epoch ---
--- 0.9292330741882324 seconds for one epoch ---
--- 0.336561918258667 seconds for one epoch ---
--- 0.9675369262695312 seconds for one epoch ---
--- 0.32468438148498535 seconds for one epoch ---
--- 0.9690449237823486 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8323282]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.335351]
 [ 0.      ]]
--- 0.31168413162231445 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4131.12548828125, (2016.6707, 2.6217852, 2111.5505, 0.28269956)
   validation loss 1071.54052734375, (770.166, 0.107744835, 300.984, 0.28269956)
decoder loss ratio: 29837.568512, decoder SINDy loss  ratio: 0.649716
--- 0.2698512077331543 seconds for one epoch ---
--- 0.3499143123626709 seconds for one epoch ---
--- 0.9296116828918457 seconds for one epoch ---
--- 0.33261728286743164 seconds for one epoch ---
--- 0.9381775856018066 seconds for one epoch ---
--- 0.3305022716522217 seconds for one epoch ---
--- 0.9676599502563477 seconds for one epoch ---
--- 0.34218597412109375 seconds for one epoch ---
--- 0.959479570388794 seconds for one epoch ---
--- 0.32735753059387207 seconds for one epoch ---
--- 0.9744596481323242 seconds for one epoch ---
--- 0.3106987476348877 seconds for one epoch ---
--- 0.9683864116668701 seconds for one epoch ---
--- 0.3085300922393799 seconds for one epoch ---
--- 0.9511325359344482 seconds for one epoch ---
--- 0.3151102066040039 seconds for one epoch ---
--- 0.9512200355529785 seconds for one epoch ---
--- 0.3051319122314453 seconds for one epoch ---
--- 0.9364042282104492 seconds for one epoch ---
--- 0.3038368225097656 seconds for one epoch ---
--- 0.9433703422546387 seconds for one epoch ---
--- 0.2995734214782715 seconds for one epoch ---
--- 0.9423949718475342 seconds for one epoch ---
--- 0.29701876640319824 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.844435]
 [0.      ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.515452]
 [ 0.      ]]
--- 0.27895069122314453 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3273.583984375, (1446.0869, 1.3973498, 1825.8129, 0.28680974)
   validation loss 897.6654663085938, (571.4328, 0.12933844, 325.81656, 0.28680974)
decoder loss ratio: 22138.298734, decoder SINDy loss  ratio: 0.703321
--- 0.31065821647644043 seconds for one epoch ---
--- 0.9457249641418457 seconds for one epoch ---
--- 0.3196225166320801 seconds for one epoch ---
--- 0.9586799144744873 seconds for one epoch ---
--- 0.3102419376373291 seconds for one epoch ---
--- 0.9611043930053711 seconds for one epoch ---
--- 0.3022451400756836 seconds for one epoch ---
--- 0.9293107986450195 seconds for one epoch ---
--- 0.30615854263305664 seconds for one epoch ---
--- 0.9466941356658936 seconds for one epoch ---
--- 0.317518949508667 seconds for one epoch ---
--- 0.9671401977539062 seconds for one epoch ---
--- 0.3053255081176758 seconds for one epoch ---
--- 0.9520285129547119 seconds for one epoch ---
--- 0.30130767822265625 seconds for one epoch ---
--- 0.9398713111877441 seconds for one epoch ---
--- 0.29831814765930176 seconds for one epoch ---
--- 0.955939769744873 seconds for one epoch ---
--- 0.3043689727783203 seconds for one epoch ---
--- 0.9399194717407227 seconds for one epoch ---
--- 0.3085167407989502 seconds for one epoch ---
--- 0.9682826995849609 seconds for one epoch ---
--- 0.3002500534057617 seconds for one epoch ---
--- 0.9621322154998779 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8543289]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.673486]
 [-0.      ]]
--- 0.3020460605621338 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1997.7955322265625, (940.75287, 1.5142922, 1055.2383, 0.2902021)
   validation loss 1272.6793212890625, (913.4933, 0.102454334, 358.79346, 0.2902021)
decoder loss ratio: 35390.315799, decoder SINDy loss  ratio: 0.774506
--- 0.2689216136932373 seconds for one epoch ---
--- 0.2960536479949951 seconds for one epoch ---
--- 0.9649074077606201 seconds for one epoch ---
--- 0.30995965003967285 seconds for one epoch ---
--- 0.9588994979858398 seconds for one epoch ---
--- 0.31964802742004395 seconds for one epoch ---
--- 0.9590392112731934 seconds for one epoch ---
--- 0.29622936248779297 seconds for one epoch ---
--- 0.9467909336090088 seconds for one epoch ---
--- 0.3043088912963867 seconds for one epoch ---
--- 0.9460170269012451 seconds for one epoch ---
--- 0.3052332401275635 seconds for one epoch ---
--- 0.9549741744995117 seconds for one epoch ---
--- 0.31627368927001953 seconds for one epoch ---
--- 0.9648129940032959 seconds for one epoch ---
--- 0.32123899459838867 seconds for one epoch ---
--- 0.9807565212249756 seconds for one epoch ---
--- 0.32723164558410645 seconds for one epoch ---
--- 0.9920985698699951 seconds for one epoch ---
--- 0.3010716438293457 seconds for one epoch ---
--- 0.9706466197967529 seconds for one epoch ---
--- 0.30646181106567383 seconds for one epoch ---
--- 0.9686610698699951 seconds for one epoch ---
--- 0.30594897270202637 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8642502]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.843444]
 [-0.      ]]
--- 0.2641890048980713 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2730.650634765625, (1276.4631, 1.2367944, 1452.6571, 0.29373938)
   validation loss 804.1057739257812, (499.641, 0.1267943, 304.0442, 0.29373938)
decoder loss ratio: 19356.959414, decoder SINDy loss  ratio: 0.656322
--- 0.2988710403442383 seconds for one epoch ---
--- 0.9628410339355469 seconds for one epoch ---
--- 0.3151683807373047 seconds for one epoch ---
--- 0.9671201705932617 seconds for one epoch ---
--- 0.3139500617980957 seconds for one epoch ---
--- 0.9746682643890381 seconds for one epoch ---
--- 0.33794236183166504 seconds for one epoch ---
--- 0.9741115570068359 seconds for one epoch ---
--- 0.3406054973602295 seconds for one epoch ---
--- 0.9964923858642578 seconds for one epoch ---
--- 0.33576011657714844 seconds for one epoch ---
--- 1.0134563446044922 seconds for one epoch ---
--- 0.31236934661865234 seconds for one epoch ---
--- 1.006361484527588 seconds for one epoch ---
--- 0.31028199195861816 seconds for one epoch ---
--- 0.9772484302520752 seconds for one epoch ---
--- 0.30344653129577637 seconds for one epoch ---
--- 0.9565374851226807 seconds for one epoch ---
--- 0.30349183082580566 seconds for one epoch ---
--- 0.9717466831207275 seconds for one epoch ---
--- 0.29982447624206543 seconds for one epoch ---
--- 0.9877378940582275 seconds for one epoch ---
--- 0.29294300079345703 seconds for one epoch ---
--- 0.9510586261749268 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.87353617]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-9.0147085]
 [-0.       ]]
--- 0.31554079055786133 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2718.3076171875, (1497.7222, 1.6117278, 1218.677, 0.2969336)
   validation loss 1348.54443359375, (1013.2111, 0.11982419, 334.91656, 0.2969336)
decoder loss ratio: 39253.557824, decoder SINDy loss  ratio: 0.722965
THRESHOLDING: 1 active coefficients
--- 0.2608671188354492 seconds for one epoch ---
--- 0.2991805076599121 seconds for one epoch ---
--- 0.9619190692901611 seconds for one epoch ---
--- 0.29806041717529297 seconds for one epoch ---
--- 0.9661087989807129 seconds for one epoch ---
--- 0.2973010540008545 seconds for one epoch ---
--- 0.9618117809295654 seconds for one epoch ---
--- 0.2988295555114746 seconds for one epoch ---
--- 0.9877324104309082 seconds for one epoch ---
--- 0.30225658416748047 seconds for one epoch ---
--- 0.9428529739379883 seconds for one epoch ---
--- 0.30353617668151855 seconds for one epoch ---
--- 0.9970300197601318 seconds for one epoch ---
--- 0.3022949695587158 seconds for one epoch ---
--- 1.0089514255523682 seconds for one epoch ---
--- 0.28992748260498047 seconds for one epoch ---
--- 0.972078800201416 seconds for one epoch ---
--- 0.30094385147094727 seconds for one epoch ---
--- 0.9993138313293457 seconds for one epoch ---
--- 0.2989470958709717 seconds for one epoch ---
--- 1.0015008449554443 seconds for one epoch ---
--- 0.3197202682495117 seconds for one epoch ---
--- 1.014815092086792 seconds for one epoch ---
--- 0.31835007667541504 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8812956]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.168361]
 [ 0.      ]]
--- 0.2633702754974365 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2693.36962890625, (1247.284, 1.3796989, 1444.4327, 0.27326283)
   validation loss 1060.0628662109375, (711.1634, 0.10452265, 348.52164, 0.27326283)
decoder loss ratio: 27551.704406, decoder SINDy loss  ratio: 0.752333
--- 0.30129194259643555 seconds for one epoch ---
--- 0.9995346069335938 seconds for one epoch ---
--- 0.3247721195220947 seconds for one epoch ---
--- 0.9847452640533447 seconds for one epoch ---
--- 0.30404162406921387 seconds for one epoch ---
--- 1.0227086544036865 seconds for one epoch ---
--- 0.30278468132019043 seconds for one epoch ---
--- 0.9977841377258301 seconds for one epoch ---
--- 0.30884718894958496 seconds for one epoch ---
--- 1.0148632526397705 seconds for one epoch ---
--- 0.3013887405395508 seconds for one epoch ---
--- 0.9961750507354736 seconds for one epoch ---
--- 0.31011438369750977 seconds for one epoch ---
--- 0.9859504699707031 seconds for one epoch ---
--- 0.3069038391113281 seconds for one epoch ---
--- 0.989729642868042 seconds for one epoch ---
--- 0.30321526527404785 seconds for one epoch ---
--- 0.9843931198120117 seconds for one epoch ---
--- 0.30255722999572754 seconds for one epoch ---
--- 0.9974591732025146 seconds for one epoch ---
--- 0.2990269660949707 seconds for one epoch ---
--- 1.0022130012512207 seconds for one epoch ---
--- 0.29706501960754395 seconds for one epoch ---
--- 0.9970788955688477 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8886645]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-9.324609]
 [ 0.      ]]
--- 0.3158259391784668 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4234.5400390625, (1150.2781, 1.214133, 3082.7717, 0.27657843)
   validation loss 903.8456420898438, (601.6833, 0.14064683, 301.74515, 0.27657843)
decoder loss ratio: 23310.255167, decoder SINDy loss  ratio: 0.651359
--- 0.2796974182128906 seconds for one epoch ---
--- 0.3372316360473633 seconds for one epoch ---
--- 1.037041187286377 seconds for one epoch ---
--- 0.3525834083557129 seconds for one epoch ---
--- 0.996457576751709 seconds for one epoch ---
--- 0.3430347442626953 seconds for one epoch ---
--- 1.0114328861236572 seconds for one epoch ---
--- 0.3321971893310547 seconds for one epoch ---
--- 1.007786750793457 seconds for one epoch ---
--- 0.32969188690185547 seconds for one epoch ---
--- 1.0306503772735596 seconds for one epoch ---
--- 0.31242918968200684 seconds for one epoch ---
--- 1.0373578071594238 seconds for one epoch ---
--- 0.3056521415710449 seconds for one epoch ---
--- 1.024266004562378 seconds for one epoch ---
--- 0.2988779544830322 seconds for one epoch ---
--- 1.0253617763519287 seconds for one epoch ---
--- 0.3051481246948242 seconds for one epoch ---
--- 0.9991505146026611 seconds for one epoch ---
--- 0.2961456775665283 seconds for one epoch ---
--- 0.9946298599243164 seconds for one epoch ---
--- 0.29840588569641113 seconds for one epoch ---
--- 1.000133752822876 seconds for one epoch ---
--- 0.2971024513244629 seconds for one epoch ---
=========================
[[0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.8944]
 [0.    ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.454207]
 [ 0.      ]]
--- 0.26149916648864746 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3236.771484375, (1334.7739, 0.5432519, 1901.1752, 0.2792532)
   validation loss 1030.1953125, (693.4216, 0.0834076, 336.411, 0.2792532)
decoder loss ratio: 26864.355448, decoder SINDy loss  ratio: 0.726190
--- 0.33834362030029297 seconds for one epoch ---
--- 1.005843162536621 seconds for one epoch ---
--- 0.33086276054382324 seconds for one epoch ---
--- 1.0354835987091064 seconds for one epoch ---
--- 0.3373680114746094 seconds for one epoch ---
--- 1.041858434677124 seconds for one epoch ---
--- 0.3439927101135254 seconds for one epoch ---
--- 1.0187339782714844 seconds for one epoch ---
--- 0.33952975273132324 seconds for one epoch ---
--- 1.0241901874542236 seconds for one epoch ---
--- 0.31824636459350586 seconds for one epoch ---
--- 1.0344479084014893 seconds for one epoch ---
--- 0.3215665817260742 seconds for one epoch ---
--- 1.0139086246490479 seconds for one epoch ---
--- 0.31224560737609863 seconds for one epoch ---
--- 1.0186185836791992 seconds for one epoch ---
--- 0.3117058277130127 seconds for one epoch ---
--- 1.0240824222564697 seconds for one epoch ---
--- 0.3070390224456787 seconds for one epoch ---
--- 1.0411620140075684 seconds for one epoch ---
--- 0.3024265766143799 seconds for one epoch ---
--- 1.0409796237945557 seconds for one epoch ---
--- 0.30574917793273926 seconds for one epoch ---
--- 1.0138556957244873 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8997021]
 [0.       ]]
[[ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-9.58108]
 [-0.     ]]
--- 0.29704737663269043 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6707.12353515625, (1896.7808, 11.663004, 4798.398, 0.28179792)
   validation loss 1198.560546875, (861.4232, 0.07740339, 336.77826, 0.28179792)
decoder loss ratio: 33373.030953, decoder SINDy loss  ratio: 0.726983
--- 0.2601587772369385 seconds for one epoch ---
--- 0.31268978118896484 seconds for one epoch ---
--- 1.0138146877288818 seconds for one epoch ---
--- 0.3183450698852539 seconds for one epoch ---
--- 1.0324769020080566 seconds for one epoch ---
--- 0.3259105682373047 seconds for one epoch ---
--- 1.0246713161468506 seconds for one epoch ---
--- 0.3313710689544678 seconds for one epoch ---
--- 1.048027515411377 seconds for one epoch ---
--- 0.33843016624450684 seconds for one epoch ---
--- 1.0667521953582764 seconds for one epoch ---
--- 0.3517110347747803 seconds for one epoch ---
--- 1.067284345626831 seconds for one epoch ---
--- 0.3566110134124756 seconds for one epoch ---
--- 1.0624980926513672 seconds for one epoch ---
--- 0.33770108222961426 seconds for one epoch ---
--- 1.0653469562530518 seconds for one epoch ---
--- 0.34711742401123047 seconds for one epoch ---
--- 1.0385398864746094 seconds for one epoch ---
--- 0.32027292251586914 seconds for one epoch ---
--- 1.012657642364502 seconds for one epoch ---
--- 0.3218545913696289 seconds for one epoch ---
--- 1.0644187927246094 seconds for one epoch ---
--- 0.3278772830963135 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.90532553]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.724022]
 [-0.      ]]
--- 0.27163267135620117 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2952.571533203125, (965.5466, 2.604964, 1984.1354, 0.2846719)
   validation loss 1797.684814453125, (1403.5125, 0.110642284, 393.77707, 0.2846719)
decoder loss ratio: 54374.508963, decoder SINDy loss  ratio: 0.850023
--- 0.31088924407958984 seconds for one epoch ---
--- 1.0470364093780518 seconds for one epoch ---
--- 0.3049466609954834 seconds for one epoch ---
--- 1.055267095565796 seconds for one epoch ---
--- 0.3114504814147949 seconds for one epoch ---
--- 1.0313169956207275 seconds for one epoch ---
--- 0.32218050956726074 seconds for one epoch ---
--- 1.0408940315246582 seconds for one epoch ---
--- 0.2965700626373291 seconds for one epoch ---
--- 1.0537989139556885 seconds for one epoch ---
--- 0.3107130527496338 seconds for one epoch ---
--- 1.037536859512329 seconds for one epoch ---
--- 0.34070587158203125 seconds for one epoch ---
--- 1.0601468086242676 seconds for one epoch ---
--- 0.31498098373413086 seconds for one epoch ---
--- 1.0883190631866455 seconds for one epoch ---
--- 0.321683406829834 seconds for one epoch ---
--- 1.0724070072174072 seconds for one epoch ---
--- 0.30129384994506836 seconds for one epoch ---
--- 1.0564754009246826 seconds for one epoch ---
--- 0.2984182834625244 seconds for one epoch ---
--- 1.0957362651824951 seconds for one epoch ---
--- 0.31940579414367676 seconds for one epoch ---
--- 1.041830062866211 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91056395]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.866021]
 [-0.      ]]
--- 0.29298830032348633 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2341.11474609375, (1184.3839, 2.0579782, 1154.3851, 0.28750452)
   validation loss 1078.9453125, (741.0645, 0.12208343, 337.47125, 0.28750452)
decoder loss ratio: 28710.125823, decoder SINDy loss  ratio: 0.728479
--- 0.2794952392578125 seconds for one epoch ---
--- 0.2976393699645996 seconds for one epoch ---
--- 1.0453641414642334 seconds for one epoch ---
--- 0.3016352653503418 seconds for one epoch ---
--- 1.0700085163116455 seconds for one epoch ---
--- 0.3132188320159912 seconds for one epoch ---
--- 1.0046899318695068 seconds for one epoch ---
--- 0.3004872798919678 seconds for one epoch ---
--- 1.0334930419921875 seconds for one epoch ---
--- 0.3031430244445801 seconds for one epoch ---
--- 1.0941355228424072 seconds for one epoch ---
--- 0.30484557151794434 seconds for one epoch ---
--- 1.0502309799194336 seconds for one epoch ---
--- 0.32315635681152344 seconds for one epoch ---
--- 1.0746924877166748 seconds for one epoch ---
--- 0.3036158084869385 seconds for one epoch ---
--- 1.058875322341919 seconds for one epoch ---
--- 0.29987406730651855 seconds for one epoch ---
--- 1.0723955631256104 seconds for one epoch ---
--- 0.29886555671691895 seconds for one epoch ---
--- 1.0483360290527344 seconds for one epoch ---
--- 0.29956579208374023 seconds for one epoch ---
--- 1.0505650043487549 seconds for one epoch ---
--- 0.2982816696166992 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91586137]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.019492]
 [  0.      ]]
--- 0.2628655433654785 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3560.810546875, (1667.9547, 4.280059, 1888.2854, 0.29046723)
   validation loss 1160.555419921875, (793.11115, 0.22554314, 366.92825, 0.29046723)
decoder loss ratio: 30726.502660, decoder SINDy loss  ratio: 0.792066
--- 0.30234217643737793 seconds for one epoch ---
--- 1.0702943801879883 seconds for one epoch ---
--- 0.30278897285461426 seconds for one epoch ---
--- 1.0762712955474854 seconds for one epoch ---
--- 0.30460286140441895 seconds for one epoch ---
--- 1.0284769535064697 seconds for one epoch ---
--- 0.297588586807251 seconds for one epoch ---
--- 1.0408494472503662 seconds for one epoch ---
--- 0.2978708744049072 seconds for one epoch ---
--- 1.0484378337860107 seconds for one epoch ---
--- 0.29970574378967285 seconds for one epoch ---
--- 1.0794711112976074 seconds for one epoch ---
--- 0.2989184856414795 seconds for one epoch ---
--- 1.0543525218963623 seconds for one epoch ---
--- 0.3012731075286865 seconds for one epoch ---
--- 1.0330727100372314 seconds for one epoch ---
--- 0.29811668395996094 seconds for one epoch ---
--- 1.0721092224121094 seconds for one epoch ---
--- 0.2956812381744385 seconds for one epoch ---
--- 1.0900874137878418 seconds for one epoch ---
--- 0.3027627468109131 seconds for one epoch ---
--- 1.0682127475738525 seconds for one epoch ---
--- 0.29728198051452637 seconds for one epoch ---
--- 1.0708518028259277 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91967905]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.137114]
 [  0.      ]]
--- 0.28921985626220703 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3662.755859375, (1509.599, 2.1360562, 2150.728, 0.2927695)
   validation loss 1057.3160400390625, (716.92944, 0.10811661, 339.98578, 0.2927695)
decoder loss ratio: 27775.091280, decoder SINDy loss  ratio: 0.733907
--- 0.2624244689941406 seconds for one epoch ---
--- 0.299879789352417 seconds for one epoch ---
--- 1.0235683917999268 seconds for one epoch ---
--- 0.2826664447784424 seconds for one epoch ---
--- 1.0915133953094482 seconds for one epoch ---
--- 0.3266336917877197 seconds for one epoch ---
--- 1.0791690349578857 seconds for one epoch ---
--- 0.3209068775177002 seconds for one epoch ---
--- 1.1101741790771484 seconds for one epoch ---
--- 0.31751537322998047 seconds for one epoch ---
--- 1.0867531299591064 seconds for one epoch ---
--- 0.5249934196472168 seconds for one epoch ---
--- 1.071784257888794 seconds for one epoch ---
--- 0.3136410713195801 seconds for one epoch ---
--- 1.0894322395324707 seconds for one epoch ---
--- 0.30998754501342773 seconds for one epoch ---
--- 1.0872337818145752 seconds for one epoch ---
--- 0.31116580963134766 seconds for one epoch ---
--- 1.1004106998443604 seconds for one epoch ---
--- 0.3064429759979248 seconds for one epoch ---
--- 1.0985116958618164 seconds for one epoch ---
--- 0.3137540817260742 seconds for one epoch ---
--- 1.0773110389709473 seconds for one epoch ---
--- 0.3297569751739502 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9240633]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.280384]
 [  0.      ]]
--- 0.26756906509399414 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5470.67333984375, (2547.0498, 6.330649, 2916.9978, 0.29559848)
   validation loss 1393.234619140625, (1011.3971, 0.20476945, 381.33707, 0.29559848)
decoder loss ratio: 39183.279312, decoder SINDy loss  ratio: 0.823170
--- 0.29828500747680664 seconds for one epoch ---
--- 1.034163236618042 seconds for one epoch ---
--- 0.30382847785949707 seconds for one epoch ---
--- 1.1095647811889648 seconds for one epoch ---
--- 0.32768678665161133 seconds for one epoch ---
--- 1.1273162364959717 seconds for one epoch ---
--- 0.3104989528656006 seconds for one epoch ---
--- 1.1103637218475342 seconds for one epoch ---
--- 0.30282092094421387 seconds for one epoch ---
--- 1.1076171398162842 seconds for one epoch ---
--- 0.2955498695373535 seconds for one epoch ---
--- 1.0894591808319092 seconds for one epoch ---
--- 0.3072779178619385 seconds for one epoch ---
--- 1.0720229148864746 seconds for one epoch ---
--- 0.2977409362792969 seconds for one epoch ---
--- 1.067129373550415 seconds for one epoch ---
--- 0.30681371688842773 seconds for one epoch ---
--- 1.082000732421875 seconds for one epoch ---
--- 0.30284547805786133 seconds for one epoch ---
--- 1.077052116394043 seconds for one epoch ---
--- 0.311112642288208 seconds for one epoch ---
--- 1.1017975807189941 seconds for one epoch ---
--- 0.3081328868865967 seconds for one epoch ---
--- 1.0776498317718506 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92783165]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.411397]
 [ -0.      ]]
--- 0.29503345489501953 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5493.29638671875, (1479.1815, 1.3039298, 4012.5132, 0.29808265)
   validation loss 1048.984130859375, (697.90906, 0.20579071, 350.5711, 0.29808265)
decoder loss ratio: 27038.208515, decoder SINDy loss  ratio: 0.756757
--- 0.2678415775299072 seconds for one epoch ---
--- 0.3213672637939453 seconds for one epoch ---
--- 1.0877480506896973 seconds for one epoch ---
--- 0.33954691886901855 seconds for one epoch ---
--- 1.1387414932250977 seconds for one epoch ---
--- 0.32038092613220215 seconds for one epoch ---
--- 1.1458258628845215 seconds for one epoch ---
--- 0.3173243999481201 seconds for one epoch ---
--- 1.133667230606079 seconds for one epoch ---
--- 0.3219635486602783 seconds for one epoch ---
--- 1.1335210800170898 seconds for one epoch ---
--- 0.3220663070678711 seconds for one epoch ---
--- 1.128037691116333 seconds for one epoch ---
--- 0.31197023391723633 seconds for one epoch ---
--- 1.106825828552246 seconds for one epoch ---
--- 0.319716215133667 seconds for one epoch ---
--- 1.113990306854248 seconds for one epoch ---
--- 0.306781530380249 seconds for one epoch ---
--- 1.1236498355865479 seconds for one epoch ---
--- 0.3022727966308594 seconds for one epoch ---
--- 1.0867438316345215 seconds for one epoch ---
--- 0.2875843048095703 seconds for one epoch ---
--- 1.116760492324829 seconds for one epoch ---
--- 0.3006017208099365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93126357]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.537887]
 [ -0.      ]]
--- 0.2590463161468506 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2627.257080078125, (968.6761, 2.5524688, 1655.728, 0.30052233)
   validation loss 1067.508056640625, (699.3002, 0.11893986, 367.78833, 0.30052233)
decoder loss ratio: 27092.102659, decoder SINDy loss  ratio: 0.793923
--- 0.31314611434936523 seconds for one epoch ---
--- 1.1033155918121338 seconds for one epoch ---
--- 0.3390543460845947 seconds for one epoch ---
--- 1.1026339530944824 seconds for one epoch ---
--- 0.3413257598876953 seconds for one epoch ---
--- 1.1259241104125977 seconds for one epoch ---
--- 0.34124183654785156 seconds for one epoch ---
--- 1.1275875568389893 seconds for one epoch ---
--- 0.3424081802368164 seconds for one epoch ---
--- 1.1503973007202148 seconds for one epoch ---
--- 0.3370378017425537 seconds for one epoch ---
--- 1.1137464046478271 seconds for one epoch ---
--- 0.34014153480529785 seconds for one epoch ---
--- 1.136254072189331 seconds for one epoch ---
--- 0.3161900043487549 seconds for one epoch ---
--- 1.1475839614868164 seconds for one epoch ---
--- 0.3126718997955322 seconds for one epoch ---
--- 1.174393653869629 seconds for one epoch ---
--- 0.3151729106903076 seconds for one epoch ---
--- 1.1478095054626465 seconds for one epoch ---
--- 0.3101387023925781 seconds for one epoch ---
--- 1.1155471801757812 seconds for one epoch ---
--- 0.2997419834136963 seconds for one epoch ---
--- 1.1298589706420898 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.934111]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.648646]
 [ -0.      ]]
--- 0.3358426094055176 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2739.094482421875, (973.8828, 0.80020505, 1764.1088, 0.30268642)
   validation loss 735.5811767578125, (445.89297, 0.123300776, 289.26224, 0.30268642)
decoder loss ratio: 17274.667950, decoder SINDy loss  ratio: 0.624413
--- 0.28236961364746094 seconds for one epoch ---
--- 0.34122633934020996 seconds for one epoch ---
--- 1.156144380569458 seconds for one epoch ---
--- 0.32057714462280273 seconds for one epoch ---
--- 1.1397802829742432 seconds for one epoch ---
--- 0.320279598236084 seconds for one epoch ---
--- 1.1304237842559814 seconds for one epoch ---
--- 0.306396484375 seconds for one epoch ---
--- 1.1329731941223145 seconds for one epoch ---
--- 0.3095426559448242 seconds for one epoch ---
--- 1.1394319534301758 seconds for one epoch ---
--- 0.32555222511291504 seconds for one epoch ---
--- 1.1431639194488525 seconds for one epoch ---
--- 0.32216906547546387 seconds for one epoch ---
--- 1.171022891998291 seconds for one epoch ---
--- 0.30806708335876465 seconds for one epoch ---
--- 1.1812894344329834 seconds for one epoch ---
--- 0.3274226188659668 seconds for one epoch ---
--- 1.1487655639648438 seconds for one epoch ---
--- 0.30007410049438477 seconds for one epoch ---
--- 1.1546869277954102 seconds for one epoch ---
--- 0.3046598434448242 seconds for one epoch ---
--- 1.1518006324768066 seconds for one epoch ---
--- 0.3030400276184082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93710387]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.771347]
 [  0.      ]]
--- 0.28368473052978516 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1676.7752685546875, (807.1454, 1.1810725, 868.1438, 0.30506203)
   validation loss 1386.5548095703125, (1012.4169, 0.11078046, 373.72208, 0.30506203)
decoder loss ratio: 39222.787181, decoder SINDy loss  ratio: 0.806732
--- 0.3173670768737793 seconds for one epoch ---
--- 1.1652729511260986 seconds for one epoch ---
--- 0.31249570846557617 seconds for one epoch ---
--- 1.1939928531646729 seconds for one epoch ---
--- 0.29683876037597656 seconds for one epoch ---
--- 1.153214931488037 seconds for one epoch ---
--- 0.308305025100708 seconds for one epoch ---
--- 1.1798126697540283 seconds for one epoch ---
--- 0.3121771812438965 seconds for one epoch ---
--- 1.1543595790863037 seconds for one epoch ---
--- 0.30621957778930664 seconds for one epoch ---
--- 1.163273572921753 seconds for one epoch ---
--- 0.3112783432006836 seconds for one epoch ---
--- 1.1237859725952148 seconds for one epoch ---
--- 0.29941773414611816 seconds for one epoch ---
--- 1.1526529788970947 seconds for one epoch ---
--- 0.29712343215942383 seconds for one epoch ---
--- 1.1598150730133057 seconds for one epoch ---
--- 0.29604434967041016 seconds for one epoch ---
--- 1.13608980178833 seconds for one epoch ---
--- 0.32010865211486816 seconds for one epoch ---
--- 1.1649253368377686 seconds for one epoch ---
--- 0.298473596572876 seconds for one epoch ---
--- 1.163379430770874 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94019103]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.905463]
 [  0.      ]]
--- 0.29875802993774414 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2476.3359375, (1098.8706, 1.0954655, 1376.0623, 0.3076652)
   validation loss 1001.0293579101562, (668.01, 0.1417394, 332.56995, 0.3076652)
decoder loss ratio: 25879.867495, decoder SINDy loss  ratio: 0.717899
--- 0.2681717872619629 seconds for one epoch ---
--- 0.3011794090270996 seconds for one epoch ---
--- 1.1539685726165771 seconds for one epoch ---
--- 0.29994821548461914 seconds for one epoch ---
--- 1.12660813331604 seconds for one epoch ---
--- 0.30449724197387695 seconds for one epoch ---
--- 1.125983476638794 seconds for one epoch ---
--- 0.30211329460144043 seconds for one epoch ---
--- 1.1416599750518799 seconds for one epoch ---
--- 0.29756927490234375 seconds for one epoch ---
--- 1.1550626754760742 seconds for one epoch ---
--- 0.3081855773925781 seconds for one epoch ---
--- 1.1456646919250488 seconds for one epoch ---
--- 0.297717809677124 seconds for one epoch ---
--- 1.1507604122161865 seconds for one epoch ---
--- 0.2967875003814697 seconds for one epoch ---
--- 1.1493730545043945 seconds for one epoch ---
--- 0.2994041442871094 seconds for one epoch ---
--- 1.152489423751831 seconds for one epoch ---
--- 0.296558141708374 seconds for one epoch ---
--- 1.1544244289398193 seconds for one epoch ---
--- 0.2992701530456543 seconds for one epoch ---
--- 1.1557672023773193 seconds for one epoch ---
--- 0.30191779136657715 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9428691]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.028783]
 [  0.      ]]
--- 0.2535536289215088 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3014.108154296875, (1657.8156, 0.945901, 1355.0366, 0.30994865)
   validation loss 1193.50244140625, (862.3126, 0.087039, 330.79288, 0.30994865)
decoder loss ratio: 33407.488020, decoder SINDy loss  ratio: 0.714063
--- 0.34094977378845215 seconds for one epoch ---
--- 1.1777501106262207 seconds for one epoch ---
--- 0.35149693489074707 seconds for one epoch ---
--- 1.154876708984375 seconds for one epoch ---
--- 0.3467748165130615 seconds for one epoch ---
--- 1.1538093090057373 seconds for one epoch ---
--- 0.3343977928161621 seconds for one epoch ---
--- 1.176318645477295 seconds for one epoch ---
--- 0.3390932083129883 seconds for one epoch ---
--- 1.1953842639923096 seconds for one epoch ---
--- 0.33922433853149414 seconds for one epoch ---
--- 1.1904850006103516 seconds for one epoch ---
--- 0.31642937660217285 seconds for one epoch ---
--- 1.1959247589111328 seconds for one epoch ---
--- 0.30971503257751465 seconds for one epoch ---
--- 1.1634328365325928 seconds for one epoch ---
--- 0.3066079616546631 seconds for one epoch ---
--- 1.1607861518859863 seconds for one epoch ---
--- 0.31740760803222656 seconds for one epoch ---
--- 1.175459861755371 seconds for one epoch ---
--- 0.3031759262084961 seconds for one epoch ---
--- 1.1834726333618164 seconds for one epoch ---
--- 0.30715036392211914 seconds for one epoch ---
--- 1.1802003383636475 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94540733]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-11.15227]
 [ -0.     ]]
--- 0.33424830436706543 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4002.662841796875, (1709.3136, 2.3820784, 2290.655, 0.3123023)
   validation loss 1408.4456787109375, (1036.2036, 0.17683586, 371.75293, 0.3123023)
decoder loss ratio: 40144.326907, decoder SINDy loss  ratio: 0.802481
--- 0.28913068771362305 seconds for one epoch ---
--- 0.3354332447052002 seconds for one epoch ---
--- 1.169651985168457 seconds for one epoch ---
--- 0.32789087295532227 seconds for one epoch ---
--- 1.1822798252105713 seconds for one epoch ---
--- 0.3210880756378174 seconds for one epoch ---
--- 1.1772220134735107 seconds for one epoch ---
--- 0.30713319778442383 seconds for one epoch ---
--- 1.1976053714752197 seconds for one epoch ---
--- 0.3089909553527832 seconds for one epoch ---
--- 1.2082607746124268 seconds for one epoch ---
--- 0.3126065731048584 seconds for one epoch ---
--- 1.1758992671966553 seconds for one epoch ---
--- 0.30324625968933105 seconds for one epoch ---
--- 1.1827898025512695 seconds for one epoch ---
--- 0.31572484970092773 seconds for one epoch ---
--- 1.1910367012023926 seconds for one epoch ---
--- 0.30213141441345215 seconds for one epoch ---
--- 1.194373607635498 seconds for one epoch ---
--- 0.3148181438446045 seconds for one epoch ---
--- 1.1911389827728271 seconds for one epoch ---
--- 0.30763936042785645 seconds for one epoch ---
--- 1.1873934268951416 seconds for one epoch ---
--- 0.30686521530151367 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94764376]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.267064]
 [ -0.      ]]
--- 0.29856300354003906 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3588.323974609375, (1773.8148, 1.4431045, 1812.7516, 0.31456527)
   validation loss 810.6337890625, (497.2726, 0.08989507, 312.9567, 0.31456527)
decoder loss ratio: 19265.204351, decoder SINDy loss  ratio: 0.675561
--- 0.30744409561157227 seconds for one epoch ---
--- 1.181365728378296 seconds for one epoch ---
--- 0.31801795959472656 seconds for one epoch ---
--- 1.1617584228515625 seconds for one epoch ---
--- 0.31491732597351074 seconds for one epoch ---
--- 1.1616370677947998 seconds for one epoch ---
--- 0.32054877281188965 seconds for one epoch ---
--- 1.1855807304382324 seconds for one epoch ---
--- 0.32146191596984863 seconds for one epoch ---
--- 1.221714735031128 seconds for one epoch ---
--- 0.30971574783325195 seconds for one epoch ---
--- 1.193246603012085 seconds for one epoch ---
--- 0.30213141441345215 seconds for one epoch ---
--- 1.1694633960723877 seconds for one epoch ---
--- 0.29944729804992676 seconds for one epoch ---
--- 1.1802690029144287 seconds for one epoch ---
--- 0.30199217796325684 seconds for one epoch ---
--- 1.179075002670288 seconds for one epoch ---
--- 0.30686450004577637 seconds for one epoch ---
--- 1.1920928955078125 seconds for one epoch ---
--- 0.30257487297058105 seconds for one epoch ---
--- 1.1394469738006592 seconds for one epoch ---
--- 0.3048398494720459 seconds for one epoch ---
--- 1.190983533859253 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9498425]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.385982]
 [ -0.      ]]
--- 0.3089110851287842 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2641.8525390625, (1332.6182, 1.0155827, 1307.9019, 0.31688815)
   validation loss 942.540771484375, (642.16754, 0.11598759, 299.94034, 0.31688815)
decoder loss ratio: 24878.685410, decoder SINDy loss  ratio: 0.647463
--- 0.2733590602874756 seconds for one epoch ---
--- 0.3250296115875244 seconds for one epoch ---
--- 1.2388179302215576 seconds for one epoch ---
--- 0.3411860466003418 seconds for one epoch ---
--- 1.2439525127410889 seconds for one epoch ---
--- 0.33668088912963867 seconds for one epoch ---
--- 1.223759651184082 seconds for one epoch ---
--- 0.3309135437011719 seconds for one epoch ---
--- 1.2273662090301514 seconds for one epoch ---
--- 0.32556796073913574 seconds for one epoch ---
--- 1.2090153694152832 seconds for one epoch ---
--- 0.30826497077941895 seconds for one epoch ---
--- 1.2030763626098633 seconds for one epoch ---
--- 0.3064448833465576 seconds for one epoch ---
--- 1.2159137725830078 seconds for one epoch ---
--- 0.3090207576751709 seconds for one epoch ---
--- 1.2042372226715088 seconds for one epoch ---
--- 0.30568909645080566 seconds for one epoch ---
--- 1.23317551612854 seconds for one epoch ---
--- 0.2982981204986572 seconds for one epoch ---
--- 1.1516318321228027 seconds for one epoch ---
--- 0.3005867004394531 seconds for one epoch ---
--- 1.186826467514038 seconds for one epoch ---
--- 0.33215808868408203 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9520196]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.510292]
 [  0.      ]]
--- 0.28147411346435547 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3653.92138671875, (1467.6874, 3.3054276, 2182.6094, 0.31925422)
   validation loss 1299.934814453125, (950.5046, 0.103611104, 349.00742, 0.31925422)
decoder loss ratio: 36824.197486, decoder SINDy loss  ratio: 0.753382
--- 0.32314419746398926 seconds for one epoch ---
--- 1.2153830528259277 seconds for one epoch ---
--- 0.32146763801574707 seconds for one epoch ---
--- 1.1997230052947998 seconds for one epoch ---
--- 0.3182713985443115 seconds for one epoch ---
--- 1.2068793773651123 seconds for one epoch ---
--- 0.3177835941314697 seconds for one epoch ---
--- 1.1720049381256104 seconds for one epoch ---
--- 0.3133871555328369 seconds for one epoch ---
--- 1.2264270782470703 seconds for one epoch ---
--- 0.3174552917480469 seconds for one epoch ---
--- 1.2119104862213135 seconds for one epoch ---
--- 0.3098475933074951 seconds for one epoch ---
--- 1.2294933795928955 seconds for one epoch ---
--- 0.3096587657928467 seconds for one epoch ---
--- 1.2392144203186035 seconds for one epoch ---
--- 0.29367756843566895 seconds for one epoch ---
--- 1.1830065250396729 seconds for one epoch ---
--- 0.28925251960754395 seconds for one epoch ---
--- 1.2156319618225098 seconds for one epoch ---
--- 0.32321667671203613 seconds for one epoch ---
--- 1.2288620471954346 seconds for one epoch ---
--- 0.34620189666748047 seconds for one epoch ---
--- 1.2373549938201904 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95414984]
 [0.        ]]
[[  0.   ]
 [ -0.   ]
 [ -0.   ]
 [  0.   ]
 [ -0.   ]
 [  0.   ]
 [  0.   ]
 [ -0.   ]
 [  0.   ]
 [-11.639]
 [  0.   ]]
--- 0.3205897808074951 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3561.845703125, (1301.8616, 1.3882295, 2258.2742, 0.3217139)
   validation loss 1112.5660400390625, (777.576, 0.090244554, 334.57806, 0.3217139)
decoder loss ratio: 30124.643736, decoder SINDy loss  ratio: 0.722234
THRESHOLDING: 1 active coefficients
--- 1.2300493717193604 seconds for one epoch ---
--- 0.3085141181945801 seconds for one epoch ---
--- 1.1587481498718262 seconds for one epoch ---
--- 0.30111026763916016 seconds for one epoch ---
--- 1.2222728729248047 seconds for one epoch ---
--- 0.2979288101196289 seconds for one epoch ---
--- 1.2800722122192383 seconds for one epoch ---
--- 0.3099703788757324 seconds for one epoch ---
--- 1.248164176940918 seconds for one epoch ---
--- 0.29971766471862793 seconds for one epoch ---
--- 1.2540671825408936 seconds for one epoch ---
--- 0.27454376220703125 seconds for one epoch ---
--- 1.2950360774993896 seconds for one epoch ---
--- 0.30574631690979004 seconds for one epoch ---
--- 1.3383171558380127 seconds for one epoch ---
--- 0.34290027618408203 seconds for one epoch ---
--- 1.3208177089691162 seconds for one epoch ---
--- 0.31348514556884766 seconds for one epoch ---
--- 1.1700019836425781 seconds for one epoch ---
--- 0.1958484649658203 seconds for one epoch ---
--- 1.2321784496307373 seconds for one epoch ---
--- 0.22213411331176758 seconds for one epoch ---
--- 1.1971442699432373 seconds for one epoch ---
--- 0.21973228454589844 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95580846]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.744492]
 [  0.      ]]
--- 0.14919543266296387 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2574.62109375, (1218.1263, 3.1373193, 1353.0338, 0.32377306)
   validation loss 1341.89013671875, (993.4127, 0.08247307, 348.07117, 0.32377306)
decoder loss ratio: 38486.533403, decoder SINDy loss  ratio: 0.751361
--- 0.25508570671081543 seconds for one epoch ---
--- 1.2198560237884521 seconds for one epoch ---
--- 0.18197989463806152 seconds for one epoch ---
--- 1.237947702407837 seconds for one epoch ---
--- 0.17433619499206543 seconds for one epoch ---
--- 1.2791168689727783 seconds for one epoch ---
--- 0.20270991325378418 seconds for one epoch ---
--- 1.2297194004058838 seconds for one epoch ---
--- 0.2298269271850586 seconds for one epoch ---
--- 1.2001233100891113 seconds for one epoch ---
--- 0.16499614715576172 seconds for one epoch ---
--- 1.2547645568847656 seconds for one epoch ---
--- 0.15340399742126465 seconds for one epoch ---
--- 1.284374713897705 seconds for one epoch ---
--- 0.1821296215057373 seconds for one epoch ---
--- 1.4271094799041748 seconds for one epoch ---
--- 0.1899113655090332 seconds for one epoch ---
--- 1.267390489578247 seconds for one epoch ---
--- 0.17051148414611816 seconds for one epoch ---
--- 1.2792596817016602 seconds for one epoch ---
--- 0.18381643295288086 seconds for one epoch ---
--- 1.2663700580596924 seconds for one epoch ---
--- 0.18377017974853516 seconds for one epoch ---
--- 1.3044700622558594 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95744383]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.853534]
 [ -0.      ]]
--- 0.17245173454284668 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2768.856689453125, (1434.6239, 0.5405398, 1333.3665, 0.32587296)
   validation loss 932.9824829101562, (618.29834, 0.08769783, 314.27057, 0.32587296)
decoder loss ratio: 23953.951099, decoder SINDy loss  ratio: 0.678397
--- 0.20454764366149902 seconds for one epoch ---
--- 0.18191289901733398 seconds for one epoch ---
--- 1.3105967044830322 seconds for one epoch ---
--- 0.23965764045715332 seconds for one epoch ---
--- 1.2155792713165283 seconds for one epoch ---
--- 0.1951582431793213 seconds for one epoch ---
--- 1.210625410079956 seconds for one epoch ---
--- 0.26288366317749023 seconds for one epoch ---
--- 1.2315599918365479 seconds for one epoch ---
--- 0.18385720252990723 seconds for one epoch ---
--- 1.24188232421875 seconds for one epoch ---
--- 0.17759203910827637 seconds for one epoch ---
--- 1.2565414905548096 seconds for one epoch ---
--- 0.19825005531311035 seconds for one epoch ---
--- 1.2430717945098877 seconds for one epoch ---
--- 0.1950244903564453 seconds for one epoch ---
--- 1.2336995601654053 seconds for one epoch ---
--- 0.16103386878967285 seconds for one epoch ---
--- 1.6295437812805176 seconds for one epoch ---
--- 0.17899131774902344 seconds for one epoch ---
--- 1.2732646465301514 seconds for one epoch ---
--- 0.2150883674621582 seconds for one epoch ---
--- 1.3478071689605713 seconds for one epoch ---
--- 0.1980116367340088 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9589304]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-11.95751]
 [ -0.     ]]
--- 0.14644312858581543 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4041.578857421875, (1726.9109, 3.1509447, 2311.1892, 0.32794517)
   validation loss 1490.587158203125, (1109.6211, 0.08099268, 380.55713, 0.32794517)
decoder loss ratio: 42988.647559, decoder SINDy loss  ratio: 0.821486
--- 0.19800758361816406 seconds for one epoch ---
--- 1.2621920108795166 seconds for one epoch ---
--- 0.21982479095458984 seconds for one epoch ---
--- 1.3003299236297607 seconds for one epoch ---
--- 0.18565797805786133 seconds for one epoch ---
--- 1.2265605926513672 seconds for one epoch ---
--- 0.18527460098266602 seconds for one epoch ---
--- 1.4861252307891846 seconds for one epoch ---
--- 0.21473026275634766 seconds for one epoch ---
--- 1.2702093124389648 seconds for one epoch ---
--- 0.19225168228149414 seconds for one epoch ---
--- 1.2494585514068604 seconds for one epoch ---
--- 0.1833338737487793 seconds for one epoch ---
--- 1.2865560054779053 seconds for one epoch ---
--- 0.21299290657043457 seconds for one epoch ---
--- 1.3354120254516602 seconds for one epoch ---
--- 0.18010687828063965 seconds for one epoch ---
--- 1.3307647705078125 seconds for one epoch ---
--- 0.19258904457092285 seconds for one epoch ---
--- 1.3087472915649414 seconds for one epoch ---
--- 0.21081781387329102 seconds for one epoch ---
--- 1.2996928691864014 seconds for one epoch ---
--- 0.20214295387268066 seconds for one epoch ---
--- 1.303349494934082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96027386]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-12.05561]
 [ -0.     ]]
--- 0.1865859031677246 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2749.980224609375, (1404.6428, 1.6029701, 1343.4045, 0.32988596)
   validation loss 770.4225463867188, (494.8634, 0.099334754, 275.12988, 0.32988596)
decoder loss ratio: 19171.867365, decoder SINDy loss  ratio: 0.593907
--- 0.17539310455322266 seconds for one epoch ---
--- 0.22314929962158203 seconds for one epoch ---
--- 1.3126888275146484 seconds for one epoch ---
--- 0.22924351692199707 seconds for one epoch ---
--- 1.3770155906677246 seconds for one epoch ---
--- 0.2075212001800537 seconds for one epoch ---
--- 1.2513995170593262 seconds for one epoch ---
--- 0.20168638229370117 seconds for one epoch ---
--- 1.2282495498657227 seconds for one epoch ---
--- 0.26778602600097656 seconds for one epoch ---
--- 1.2460134029388428 seconds for one epoch ---
--- 0.17718052864074707 seconds for one epoch ---
--- 1.370225191116333 seconds for one epoch ---
--- 0.19041037559509277 seconds for one epoch ---
--- 1.4240827560424805 seconds for one epoch ---
--- 0.16746902465820312 seconds for one epoch ---
--- 1.2815892696380615 seconds for one epoch ---
--- 0.1918654441833496 seconds for one epoch ---
--- 1.2827050685882568 seconds for one epoch ---
--- 0.20033502578735352 seconds for one epoch ---
--- 1.3013074398040771 seconds for one epoch ---
--- 0.20614981651306152 seconds for one epoch ---
--- 1.324676275253296 seconds for one epoch ---
--- 0.18170547485351562 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9614389]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.144321]
 [  0.      ]]
--- 0.16449403762817383 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3787.051513671875, (1485.3053, 1.1134211, 2300.3013, 0.3316013)
   validation loss 1189.304443359375, (883.87427, 0.08760958, 305.01102, 0.3316013)
decoder loss ratio: 34242.823599, decoder SINDy loss  ratio: 0.658409
--- 0.2002880573272705 seconds for one epoch ---
--- 1.253305196762085 seconds for one epoch ---
--- 0.16730332374572754 seconds for one epoch ---
--- 1.2833731174468994 seconds for one epoch ---
--- 0.21702837944030762 seconds for one epoch ---
--- 1.495246171951294 seconds for one epoch ---
--- 0.30401015281677246 seconds for one epoch ---
--- 1.3260626792907715 seconds for one epoch ---
--- 0.2208859920501709 seconds for one epoch ---
--- 1.2681162357330322 seconds for one epoch ---
--- 0.2114851474761963 seconds for one epoch ---
--- 1.252176284790039 seconds for one epoch ---
--- 0.20370912551879883 seconds for one epoch ---
--- 1.2795543670654297 seconds for one epoch ---
--- 0.19677495956420898 seconds for one epoch ---
--- 1.390984296798706 seconds for one epoch ---
--- 0.21376943588256836 seconds for one epoch ---
--- 1.2870748043060303 seconds for one epoch ---
--- 0.21350955963134766 seconds for one epoch ---
--- 1.2862019538879395 seconds for one epoch ---
--- 0.21132731437683105 seconds for one epoch ---
--- 1.2742011547088623 seconds for one epoch ---
--- 0.1851344108581543 seconds for one epoch ---
--- 1.316105604171753 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.962625]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.238307]
 [  0.      ]]
--- 0.20631909370422363 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3020.258544921875, (1695.259, 2.5497284, 1322.1163, 0.33338127)
   validation loss 954.4644775390625, (629.5946, 0.09351371, 324.44296, 0.33338127)
decoder loss ratio: 24391.588002, decoder SINDy loss  ratio: 0.700356
--- 0.16764593124389648 seconds for one epoch ---
--- 0.17743873596191406 seconds for one epoch ---
--- 1.343618392944336 seconds for one epoch ---
--- 0.17506861686706543 seconds for one epoch ---
--- 1.3573992252349854 seconds for one epoch ---
--- 0.2022843360900879 seconds for one epoch ---
--- 1.2588508129119873 seconds for one epoch ---
--- 0.1983776092529297 seconds for one epoch ---
--- 1.3106591701507568 seconds for one epoch ---
--- 0.20893383026123047 seconds for one epoch ---
--- 1.3067138195037842 seconds for one epoch ---
--- 0.2243185043334961 seconds for one epoch ---
--- 1.3260698318481445 seconds for one epoch ---
--- 0.24831151962280273 seconds for one epoch ---
--- 1.2740397453308105 seconds for one epoch ---
--- 0.19341135025024414 seconds for one epoch ---
--- 1.3055076599121094 seconds for one epoch ---
--- 0.20684528350830078 seconds for one epoch ---
--- 1.338641881942749 seconds for one epoch ---
--- 0.24192404747009277 seconds for one epoch ---
--- 1.286694049835205 seconds for one epoch ---
--- 0.2160501480102539 seconds for one epoch ---
--- 1.4001884460449219 seconds for one epoch ---
--- 0.1712172031402588 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9637317]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-12.3295355]
 [  0.       ]]
--- 0.1512899398803711 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2770.17041015625, (1369.0061, 5.139745, 1395.689, 0.335328)
   validation loss 915.36865234375, (627.03394, 0.09234664, 287.90707, 0.335328)
decoder loss ratio: 24292.383242, decoder SINDy loss  ratio: 0.621488
--- 0.18905258178710938 seconds for one epoch ---
--- 1.2889363765716553 seconds for one epoch ---
--- 0.21675944328308105 seconds for one epoch ---
--- 1.354877233505249 seconds for one epoch ---
--- 0.19811749458312988 seconds for one epoch ---
--- 1.308868169784546 seconds for one epoch ---
--- 0.22191071510314941 seconds for one epoch ---
--- 1.3191783428192139 seconds for one epoch ---
--- 0.20041394233703613 seconds for one epoch ---
--- 1.3132286071777344 seconds for one epoch ---
--- 0.2022390365600586 seconds for one epoch ---
--- 1.365271806716919 seconds for one epoch ---
--- 0.2164168357849121 seconds for one epoch ---
--- 1.2958617210388184 seconds for one epoch ---
--- 0.19964933395385742 seconds for one epoch ---
--- 1.313730001449585 seconds for one epoch ---
--- 0.22545170783996582 seconds for one epoch ---
--- 1.3701772689819336 seconds for one epoch ---
--- 0.18729925155639648 seconds for one epoch ---
--- 1.3253490924835205 seconds for one epoch ---
--- 0.20865130424499512 seconds for one epoch ---
--- 1.2970194816589355 seconds for one epoch ---
--- 0.25085973739624023 seconds for one epoch ---
--- 1.4030814170837402 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96489006]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.429044]
 [ -0.      ]]
--- 0.18950939178466797 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1238.551025390625, (569.56384, 0.55063576, 668.0994, 0.3371122)
   validation loss 765.1173095703125, (493.98486, 0.09591652, 270.69943, 0.3371122)
decoder loss ratio: 19137.831199, decoder SINDy loss  ratio: 0.584343
--- 0.16260814666748047 seconds for one epoch ---
--- 0.2062549591064453 seconds for one epoch ---
--- 1.2959823608398438 seconds for one epoch ---
--- 0.21476531028747559 seconds for one epoch ---
--- 1.4475412368774414 seconds for one epoch ---
--- 0.1977243423461914 seconds for one epoch ---
--- 1.3012523651123047 seconds for one epoch ---
--- 0.205352783203125 seconds for one epoch ---
--- 1.3189966678619385 seconds for one epoch ---
--- 0.17149758338928223 seconds for one epoch ---
--- 1.3718314170837402 seconds for one epoch ---
--- 0.1816089153289795 seconds for one epoch ---
--- 1.3349833488464355 seconds for one epoch ---
--- 0.19224882125854492 seconds for one epoch ---
--- 1.4693868160247803 seconds for one epoch ---
--- 0.19398927688598633 seconds for one epoch ---
--- 1.2948133945465088 seconds for one epoch ---
--- 0.19310665130615234 seconds for one epoch ---
--- 1.3697528839111328 seconds for one epoch ---
--- 0.21950268745422363 seconds for one epoch ---
--- 1.4913334846496582 seconds for one epoch ---
--- 0.24035930633544922 seconds for one epoch ---
--- 1.441291332244873 seconds for one epoch ---
--- 0.22657036781311035 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9658806]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.517695]
 [ -0.      ]]
--- 0.1836700439453125 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1951.0687255859375, (760.4532, 1.9724247, 1188.3041, 0.33897978)
   validation loss 1410.0218505859375, (1069.801, 0.069471575, 339.81235, 0.33897978)
decoder loss ratio: 41445.948980, decoder SINDy loss  ratio: 0.733533
--- 0.17862367630004883 seconds for one epoch ---
--- 1.3677310943603516 seconds for one epoch ---
--- 0.19830918312072754 seconds for one epoch ---
--- 1.3438589572906494 seconds for one epoch ---
--- 0.18219709396362305 seconds for one epoch ---
--- 1.3659915924072266 seconds for one epoch ---
--- 0.19581055641174316 seconds for one epoch ---
--- 1.3060598373413086 seconds for one epoch ---
--- 0.19501137733459473 seconds for one epoch ---
--- 1.372549057006836 seconds for one epoch ---
--- 0.1775834560394287 seconds for one epoch ---
--- 1.3253812789916992 seconds for one epoch ---
--- 0.22266030311584473 seconds for one epoch ---
--- 1.3151836395263672 seconds for one epoch ---
--- 0.20255112648010254 seconds for one epoch ---
--- 1.4320013523101807 seconds for one epoch ---
--- 0.2882084846496582 seconds for one epoch ---
--- 1.3506546020507812 seconds for one epoch ---
--- 0.24654221534729004 seconds for one epoch ---
--- 1.3689568042755127 seconds for one epoch ---
--- 0.18369436264038086 seconds for one epoch ---
--- 1.323735237121582 seconds for one epoch ---
--- 0.22929930686950684 seconds for one epoch ---
--- 1.51088547706604 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96694624]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.617034]
 [ -0.      ]]
--- 0.205094575881958 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3761.6162109375, (1187.514, 4.196594, 2569.5647, 0.3409042)
   validation loss 744.9961547851562, (461.26956, 0.10673351, 283.279, 0.3409042)
decoder loss ratio: 17870.383622, decoder SINDy loss  ratio: 0.611498
--- 0.17743873596191406 seconds for one epoch ---
--- 0.1789991855621338 seconds for one epoch ---
--- 1.4176509380340576 seconds for one epoch ---
--- 0.3016178607940674 seconds for one epoch ---
--- 1.333254098892212 seconds for one epoch ---
--- 0.18616294860839844 seconds for one epoch ---
--- 1.330559253692627 seconds for one epoch ---
--- 0.19154930114746094 seconds for one epoch ---
--- 1.451162338256836 seconds for one epoch ---
--- 0.45835399627685547 seconds for one epoch ---
--- 1.3607392311096191 seconds for one epoch ---
--- 0.21226954460144043 seconds for one epoch ---
--- 1.3363327980041504 seconds for one epoch ---
--- 0.2060844898223877 seconds for one epoch ---
--- 1.3941669464111328 seconds for one epoch ---
--- 0.17227506637573242 seconds for one epoch ---
--- 1.412674903869629 seconds for one epoch ---
--- 0.19557642936706543 seconds for one epoch ---
--- 1.497891902923584 seconds for one epoch ---
--- 0.27007365226745605 seconds for one epoch ---
--- 1.3937828540802002 seconds for one epoch ---
--- 0.21951651573181152 seconds for one epoch ---
--- 1.3226118087768555 seconds for one epoch ---
--- 0.17856287956237793 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9678319]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-12.70289]
 [  0.     ]]
--- 0.16047883033752441 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2533.412841796875, (937.03925, 1.1763201, 1594.8549, 0.34258336)
   validation loss 788.3673706054688, (526.0729, 0.12963828, 261.82224, 0.34258336)
decoder loss ratio: 20380.976518, decoder SINDy loss  ratio: 0.565180
--- 0.24486756324768066 seconds for one epoch ---
--- 1.423086166381836 seconds for one epoch ---
--- 0.21902751922607422 seconds for one epoch ---
--- 1.3766660690307617 seconds for one epoch ---
--- 0.1943514347076416 seconds for one epoch ---
--- 1.3843469619750977 seconds for one epoch ---
--- 0.18473553657531738 seconds for one epoch ---
--- 1.4095654487609863 seconds for one epoch ---
--- 0.2722353935241699 seconds for one epoch ---
--- 1.3312468528747559 seconds for one epoch ---
--- 0.24760031700134277 seconds for one epoch ---
--- 1.3497483730316162 seconds for one epoch ---
--- 0.2042222023010254 seconds for one epoch ---
--- 1.4667234420776367 seconds for one epoch ---
--- 0.18874311447143555 seconds for one epoch ---
--- 1.3517086505889893 seconds for one epoch ---
--- 0.17168641090393066 seconds for one epoch ---
--- 1.3954317569732666 seconds for one epoch ---
--- 0.20306897163391113 seconds for one epoch ---
--- 1.3764512538909912 seconds for one epoch ---
--- 0.21830344200134277 seconds for one epoch ---
--- 1.4279944896697998 seconds for one epoch ---
--- 0.1889786720275879 seconds for one epoch ---
--- 1.3632581233978271 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9686395]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.784014]
 [  0.      ]]
--- 0.1938166618347168 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2252.062744140625, (1147.7465, 0.9843105, 1102.9878, 0.34423596)
   validation loss 903.3203125, (606.8987, 0.11918503, 295.95816, 0.34423596)
decoder loss ratio: 23512.308549, decoder SINDy loss  ratio: 0.638867
--- 0.14835190773010254 seconds for one epoch ---
--- 0.18899178504943848 seconds for one epoch ---
--- 1.3604612350463867 seconds for one epoch ---
--- 0.18027901649475098 seconds for one epoch ---
--- 1.3661680221557617 seconds for one epoch ---
--- 0.18439769744873047 seconds for one epoch ---
--- 1.6130435466766357 seconds for one epoch ---
--- 0.25601768493652344 seconds for one epoch ---
--- 1.4230947494506836 seconds for one epoch ---
--- 0.18999481201171875 seconds for one epoch ---
--- 1.4171924591064453 seconds for one epoch ---
--- 0.16788792610168457 seconds for one epoch ---
--- 1.3649001121520996 seconds for one epoch ---
--- 0.18291020393371582 seconds for one epoch ---
--- 1.4645564556121826 seconds for one epoch ---
--- 0.21500086784362793 seconds for one epoch ---
--- 1.4205214977264404 seconds for one epoch ---
--- 0.17970967292785645 seconds for one epoch ---
--- 1.3911514282226562 seconds for one epoch ---
--- 0.19254779815673828 seconds for one epoch ---
--- 1.338813066482544 seconds for one epoch ---
--- 0.17041230201721191 seconds for one epoch ---
--- 1.3826351165771484 seconds for one epoch ---
--- 0.19533824920654297 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9694054]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.863668]
 [  0.      ]]
--- 0.1622767448425293 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2447.064453125, (1642.8668, 0.31091586, 803.5411, 0.34580308)
   validation loss 991.9617309570312, (701.68066, 0.104780465, 289.83044, 0.34580308)
decoder loss ratio: 27184.327097, decoder SINDy loss  ratio: 0.625640
--- 0.2218165397644043 seconds for one epoch ---
--- 1.4712955951690674 seconds for one epoch ---
--- 0.26230478286743164 seconds for one epoch ---
--- 1.442516803741455 seconds for one epoch ---
--- 0.23829317092895508 seconds for one epoch ---
--- 1.4392364025115967 seconds for one epoch ---
--- 0.18535733222961426 seconds for one epoch ---
--- 1.4114813804626465 seconds for one epoch ---
--- 0.17485880851745605 seconds for one epoch ---
--- 1.389497995376587 seconds for one epoch ---
--- 0.20959162712097168 seconds for one epoch ---
--- 1.4295930862426758 seconds for one epoch ---
--- 0.24628901481628418 seconds for one epoch ---
--- 1.3674647808074951 seconds for one epoch ---
--- 0.1972348690032959 seconds for one epoch ---
--- 1.3744091987609863 seconds for one epoch ---
--- 0.19732356071472168 seconds for one epoch ---
--- 1.4022161960601807 seconds for one epoch ---
--- 0.19774222373962402 seconds for one epoch ---
--- 1.394366979598999 seconds for one epoch ---
--- 0.19781804084777832 seconds for one epoch ---
--- 1.378011703491211 seconds for one epoch ---
--- 0.17405390739440918 seconds for one epoch ---
--- 1.4710044860839844 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9702286]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.952352]
 [ -0.      ]]
--- 0.18244266510009766 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2016.34521484375, (1108.9702, 1.2702314, 905.757, 0.34760967)
   validation loss 766.7440795898438, (476.1933, 0.111855, 290.09137, 0.34760967)
decoder loss ratio: 18448.555086, decoder SINDy loss  ratio: 0.626203
--- 0.19663548469543457 seconds for one epoch ---
--- 0.232496976852417 seconds for one epoch ---
--- 1.3547489643096924 seconds for one epoch ---
--- 0.1933133602142334 seconds for one epoch ---
--- 1.4194438457489014 seconds for one epoch ---
--- 0.17699241638183594 seconds for one epoch ---
--- 1.3933777809143066 seconds for one epoch ---
--- 0.24181389808654785 seconds for one epoch ---
--- 1.4148838520050049 seconds for one epoch ---
--- 0.24088025093078613 seconds for one epoch ---
--- 1.4292283058166504 seconds for one epoch ---
--- 0.20587491989135742 seconds for one epoch ---
--- 1.4198496341705322 seconds for one epoch ---
--- 0.216447114944458 seconds for one epoch ---
--- 1.3653199672698975 seconds for one epoch ---
--- 0.21515274047851562 seconds for one epoch ---
--- 1.4115560054779053 seconds for one epoch ---
--- 0.18964076042175293 seconds for one epoch ---
--- 1.3778584003448486 seconds for one epoch ---
--- 0.2517201900482178 seconds for one epoch ---
--- 1.3651537895202637 seconds for one epoch ---
--- 0.17037510871887207 seconds for one epoch ---
--- 1.4447569847106934 seconds for one epoch ---
--- 0.1963033676147461 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9709247]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.030129]
 [ -0.      ]]
--- 0.1428375244140625 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6813.4111328125, (1341.0211, 5.8259478, 5466.215, 0.34918013)
   validation loss 942.5844116210938, (646.7104, 0.13332087, 295.39154, 0.34918013)
decoder loss ratio: 25054.683177, decoder SINDy loss  ratio: 0.637644
--- 0.21503567695617676 seconds for one epoch ---
--- 1.3999419212341309 seconds for one epoch ---
--- 0.21597671508789062 seconds for one epoch ---
--- 1.3727195262908936 seconds for one epoch ---
--- 0.19438385963439941 seconds for one epoch ---
--- 1.4494194984436035 seconds for one epoch ---
--- 0.19762134552001953 seconds for one epoch ---
--- 1.4077515602111816 seconds for one epoch ---
--- 0.19611048698425293 seconds for one epoch ---
--- 1.4441452026367188 seconds for one epoch ---
--- 0.19598031044006348 seconds for one epoch ---
--- 1.422987461090088 seconds for one epoch ---
--- 0.21923613548278809 seconds for one epoch ---
--- 1.5936098098754883 seconds for one epoch ---
--- 0.19129204750061035 seconds for one epoch ---
--- 1.410006046295166 seconds for one epoch ---
--- 0.18593859672546387 seconds for one epoch ---
--- 1.4305939674377441 seconds for one epoch ---
--- 0.1996605396270752 seconds for one epoch ---
--- 1.4891045093536377 seconds for one epoch ---
--- 0.17349696159362793 seconds for one epoch ---
--- 1.4817273616790771 seconds for one epoch ---
--- 0.21329069137573242 seconds for one epoch ---
--- 1.4454739093780518 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9716432]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.113104]
 [ -0.      ]]
--- 0.19522619247436523 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2000.169189453125, (1190.7516, 1.8760571, 807.1906, 0.35081103)
   validation loss 765.4228515625, (483.4331, 0.14559816, 281.49335, 0.35081103)
decoder loss ratio: 18729.037783, decoder SINDy loss  ratio: 0.607643
--- 0.16118741035461426 seconds for one epoch ---
--- 0.20839858055114746 seconds for one epoch ---
--- 1.5258440971374512 seconds for one epoch ---
--- 0.3186204433441162 seconds for one epoch ---
--- 1.4696149826049805 seconds for one epoch ---
--- 0.2048637866973877 seconds for one epoch ---
--- 1.4514904022216797 seconds for one epoch ---
--- 0.2364645004272461 seconds for one epoch ---
--- 1.4895398616790771 seconds for one epoch ---
--- 0.21568632125854492 seconds for one epoch ---
--- 1.4399590492248535 seconds for one epoch ---
--- 0.20646023750305176 seconds for one epoch ---
--- 1.4887938499450684 seconds for one epoch ---
--- 0.20728421211242676 seconds for one epoch ---
--- 1.448307991027832 seconds for one epoch ---
--- 0.15387988090515137 seconds for one epoch ---
--- 1.7154462337493896 seconds for one epoch ---
--- 0.19948101043701172 seconds for one epoch ---
--- 1.5478994846343994 seconds for one epoch ---
--- 0.19960808753967285 seconds for one epoch ---
--- 1.4071471691131592 seconds for one epoch ---
--- 0.17332220077514648 seconds for one epoch ---
--- 1.3884551525115967 seconds for one epoch ---
--- 0.22164106369018555 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9723165]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.193513]
 [  0.      ]]
--- 0.2695577144622803 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2942.38916015625, (1426.9474, 3.629858, 1511.4594, 0.3524507)
   validation loss 863.8932495117188, (564.4239, 0.13859244, 298.97824, 0.3524507)
decoder loss ratio: 21866.761349, decoder SINDy loss  ratio: 0.645387
--- 0.1763312816619873 seconds for one epoch ---
--- 1.4540140628814697 seconds for one epoch ---
--- 0.19742584228515625 seconds for one epoch ---
--- 1.5292048454284668 seconds for one epoch ---
--- 0.3062417507171631 seconds for one epoch ---
--- 1.4450960159301758 seconds for one epoch ---
--- 0.17609024047851562 seconds for one epoch ---
--- 1.431753396987915 seconds for one epoch ---
--- 0.20013904571533203 seconds for one epoch ---
--- 1.490574836730957 seconds for one epoch ---
--- 0.1955702304840088 seconds for one epoch ---
--- 1.4620749950408936 seconds for one epoch ---
--- 0.2134566307067871 seconds for one epoch ---
--- 1.4942898750305176 seconds for one epoch ---
--- 0.17950868606567383 seconds for one epoch ---
--- 1.4838039875030518 seconds for one epoch ---
--- 0.17063069343566895 seconds for one epoch ---
--- 1.4611852169036865 seconds for one epoch ---
--- 0.19042062759399414 seconds for one epoch ---
--- 1.412332534790039 seconds for one epoch ---
--- 0.16597270965576172 seconds for one epoch ---
--- 1.4478068351745605 seconds for one epoch ---
--- 0.24394536018371582 seconds for one epoch ---
--- 1.4287078380584717 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97297466]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.274866]
 [  0.      ]]
--- 0.22616171836853027 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1964.0416259765625, (1022.95996, 0.7199325, 940.0077, 0.35414538)
   validation loss 1266.4044189453125, (957.70026, 0.1421991, 308.20776, 0.35414538)
decoder loss ratio: 37102.970572, decoder SINDy loss  ratio: 0.665310
--- 0.1917893886566162 seconds for one epoch ---
--- 0.16492915153503418 seconds for one epoch ---
--- 1.461106300354004 seconds for one epoch ---
--- 0.2021803855895996 seconds for one epoch ---
--- 1.4523072242736816 seconds for one epoch ---
--- 0.18897485733032227 seconds for one epoch ---
--- 1.5793919563293457 seconds for one epoch ---
--- 0.2672386169433594 seconds for one epoch ---
--- 1.4904513359069824 seconds for one epoch ---
--- 0.20232391357421875 seconds for one epoch ---
--- 1.5400338172912598 seconds for one epoch ---
--- 0.19182324409484863 seconds for one epoch ---
--- 1.447737693786621 seconds for one epoch ---
--- 0.20650005340576172 seconds for one epoch ---
--- 1.4210143089294434 seconds for one epoch ---
--- 0.1953108310699463 seconds for one epoch ---
--- 1.411266565322876 seconds for one epoch ---
--- 0.16132402420043945 seconds for one epoch ---
--- 1.403963327407837 seconds for one epoch ---
--- 0.19719982147216797 seconds for one epoch ---
--- 1.4702048301696777 seconds for one epoch ---
--- 0.1914045810699463 seconds for one epoch ---
--- 1.487349033355713 seconds for one epoch ---
--- 0.1959071159362793 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9736024]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.355235]
 [  0.      ]]
--- 0.17384052276611328 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3263.6416015625, (1350.1141, 4.224882, 1908.9469, 0.35567662)
   validation loss 1050.070068359375, (742.36835, 0.12776305, 307.21823, 0.35567662)
decoder loss ratio: 28760.638577, decoder SINDy loss  ratio: 0.663174
--- 0.17227935791015625 seconds for one epoch ---
--- 1.5922610759735107 seconds for one epoch ---
--- 0.28671956062316895 seconds for one epoch ---
--- 1.464742660522461 seconds for one epoch ---
--- 0.21267986297607422 seconds for one epoch ---
--- 1.4642174243927002 seconds for one epoch ---
--- 0.21735048294067383 seconds for one epoch ---
--- 1.4649057388305664 seconds for one epoch ---
--- 0.16869854927062988 seconds for one epoch ---
--- 1.5217790603637695 seconds for one epoch ---
--- 0.18040800094604492 seconds for one epoch ---
--- 1.645259141921997 seconds for one epoch ---
--- 0.16457915306091309 seconds for one epoch ---
--- 1.5093040466308594 seconds for one epoch ---
--- 0.1985306739807129 seconds for one epoch ---
--- 1.4818592071533203 seconds for one epoch ---
--- 0.19379472732543945 seconds for one epoch ---
--- 1.4569575786590576 seconds for one epoch ---
--- 0.1859602928161621 seconds for one epoch ---
--- 1.5479531288146973 seconds for one epoch ---
--- 0.22769498825073242 seconds for one epoch ---
--- 1.489689588546753 seconds for one epoch ---
--- 0.21034932136535645 seconds for one epoch ---
--- 1.4243791103363037 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9741932]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.433326]
 [ -0.      ]]
--- 0.1627485752105713 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1936.3336181640625, (971.9544, 0.7584793, 963.2633, 0.357388)
   validation loss 1233.0504150390625, (893.5052, 0.13593952, 339.05188, 0.357388)
decoder loss ratio: 34615.942176, decoder SINDy loss  ratio: 0.731891
THRESHOLDING: 1 active coefficients
--- 1.4693598747253418 seconds for one epoch ---
--- 0.22452020645141602 seconds for one epoch ---
--- 1.5356221199035645 seconds for one epoch ---
--- 0.19077324867248535 seconds for one epoch ---
--- 1.5780670642852783 seconds for one epoch ---
--- 0.24435043334960938 seconds for one epoch ---
--- 1.6707220077514648 seconds for one epoch ---
--- 0.20129823684692383 seconds for one epoch ---
--- 1.5089757442474365 seconds for one epoch ---
--- 0.21319222450256348 seconds for one epoch ---
--- 1.4986729621887207 seconds for one epoch ---
--- 0.2319324016571045 seconds for one epoch ---
--- 1.5300872325897217 seconds for one epoch ---
--- 0.19334816932678223 seconds for one epoch ---
--- 1.4854190349578857 seconds for one epoch ---
--- 0.20694184303283691 seconds for one epoch ---
--- 1.478198766708374 seconds for one epoch ---
--- 0.2093663215637207 seconds for one epoch ---
--- 1.4883649349212646 seconds for one epoch ---
--- 0.22657132148742676 seconds for one epoch ---
--- 1.4963653087615967 seconds for one epoch ---
--- 0.18194794654846191 seconds for one epoch ---
--- 1.6807353496551514 seconds for one epoch ---
--- 0.2086944580078125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97472966]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.506649]
 [ -0.      ]]
--- 0.1829843521118164 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3568.49951171875, (952.7812, 2.6024992, 2612.757, 0.35891682)
   validation loss 850.1792602539062, (537.0866, 0.15922087, 312.57452, 0.35891682)
decoder loss ratio: 20807.667652, decoder SINDy loss  ratio: 0.674736
--- 0.29166507720947266 seconds for one epoch ---
--- 1.5457608699798584 seconds for one epoch ---
--- 0.1876358985900879 seconds for one epoch ---
--- 1.5115318298339844 seconds for one epoch ---
--- 0.21445250511169434 seconds for one epoch ---
--- 1.5117740631103516 seconds for one epoch ---
--- 0.20867133140563965 seconds for one epoch ---
--- 1.4985671043395996 seconds for one epoch ---
--- 0.20069646835327148 seconds for one epoch ---
--- 1.4630839824676514 seconds for one epoch ---
--- 0.16532182693481445 seconds for one epoch ---
--- 1.554894208908081 seconds for one epoch ---
--- 0.18552780151367188 seconds for one epoch ---
--- 1.443819284439087 seconds for one epoch ---
--- 0.18572425842285156 seconds for one epoch ---
--- 1.490502119064331 seconds for one epoch ---
--- 0.2336733341217041 seconds for one epoch ---
--- 1.4676461219787598 seconds for one epoch ---
--- 0.22168207168579102 seconds for one epoch ---
--- 1.475522756576538 seconds for one epoch ---
--- 0.20350432395935059 seconds for one epoch ---
--- 1.4348821640014648 seconds for one epoch ---
--- 0.20519351959228516 seconds for one epoch ---
--- 1.633535623550415 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9752693]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.582596]
 [ -0.      ]]
--- 0.17906546592712402 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8518.0244140625, (957.9724, 3.4385972, 7556.2534, 0.3604599)
   validation loss 914.0259399414062, (630.29565, 0.14372873, 283.22607, 0.3604599)
decoder loss ratio: 24418.747889, decoder SINDy loss  ratio: 0.611383
--- 0.1526927947998047 seconds for one epoch ---
--- 0.23257756233215332 seconds for one epoch ---
--- 1.4991354942321777 seconds for one epoch ---
--- 0.21133804321289062 seconds for one epoch ---
--- 1.5581068992614746 seconds for one epoch ---
--- 0.20522046089172363 seconds for one epoch ---
--- 1.5830209255218506 seconds for one epoch ---
--- 0.19079351425170898 seconds for one epoch ---
--- 1.5222272872924805 seconds for one epoch ---
--- 0.20436596870422363 seconds for one epoch ---
--- 1.490703821182251 seconds for one epoch ---
--- 0.20105433464050293 seconds for one epoch ---
--- 1.4922690391540527 seconds for one epoch ---
--- 0.18293428421020508 seconds for one epoch ---
--- 1.4721767902374268 seconds for one epoch ---
--- 0.18392157554626465 seconds for one epoch ---
--- 1.6413941383361816 seconds for one epoch ---
--- 0.21609973907470703 seconds for one epoch ---
--- 1.8059494495391846 seconds for one epoch ---
--- 0.22528338432312012 seconds for one epoch ---
--- 1.5858981609344482 seconds for one epoch ---
--- 0.2087864875793457 seconds for one epoch ---
--- 1.5750224590301514 seconds for one epoch ---
--- 0.21999359130859375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97576493]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.654568]
 [  0.      ]]
--- 0.17043709754943848 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4028.193359375, (1236.969, 0.87107605, 2789.9915, 0.36193705)
   validation loss 940.1334838867188, (626.27075, 0.18150637, 313.31927, 0.36193705)
decoder loss ratio: 24262.816185, decoder SINDy loss  ratio: 0.676344
--- 0.18991851806640625 seconds for one epoch ---
--- 1.4716506004333496 seconds for one epoch ---
--- 0.18146991729736328 seconds for one epoch ---
--- 1.481053113937378 seconds for one epoch ---
--- 0.1798686981201172 seconds for one epoch ---
--- 1.5222008228302002 seconds for one epoch ---
--- 0.19441485404968262 seconds for one epoch ---
--- 1.4882161617279053 seconds for one epoch ---
--- 0.17786407470703125 seconds for one epoch ---
--- 1.463371992111206 seconds for one epoch ---
--- 0.1952805519104004 seconds for one epoch ---
--- 1.4985096454620361 seconds for one epoch ---
--- 0.18359088897705078 seconds for one epoch ---
--- 1.5427660942077637 seconds for one epoch ---
--- 0.2068643569946289 seconds for one epoch ---
--- 1.4748878479003906 seconds for one epoch ---
--- 0.1808147430419922 seconds for one epoch ---
--- 1.5905413627624512 seconds for one epoch ---
--- 0.20090866088867188 seconds for one epoch ---
--- 1.5198423862457275 seconds for one epoch ---
--- 0.19746971130371094 seconds for one epoch ---
--- 1.5263762474060059 seconds for one epoch ---
--- 0.1837773323059082 seconds for one epoch ---
--- 1.5569136142730713 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9762431]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.725896]
 [  0.      ]]
--- 0.17404627799987793 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2349.2373046875, (1501.1666, 1.571964, 846.1352, 0.36349937)
   validation loss 1287.848876953125, (972.0042, 0.15214689, 315.32895, 0.36349937)
decoder loss ratio: 37657.130624, decoder SINDy loss  ratio: 0.680682
--- 0.15232229232788086 seconds for one epoch ---
--- 0.1701650619506836 seconds for one epoch ---
--- 1.5276298522949219 seconds for one epoch ---
--- 0.18387079238891602 seconds for one epoch ---
--- 1.5122406482696533 seconds for one epoch ---
--- 0.21875548362731934 seconds for one epoch ---
--- 1.5941331386566162 seconds for one epoch ---
--- 0.2201852798461914 seconds for one epoch ---
--- 1.5535328388214111 seconds for one epoch ---
--- 0.17115473747253418 seconds for one epoch ---
--- 1.4759395122528076 seconds for one epoch ---
--- 0.1879122257232666 seconds for one epoch ---
--- 1.482933521270752 seconds for one epoch ---
--- 0.17712688446044922 seconds for one epoch ---
--- 1.520780086517334 seconds for one epoch ---
--- 0.2044997215270996 seconds for one epoch ---
--- 1.49951171875 seconds for one epoch ---
--- 0.21203207969665527 seconds for one epoch ---
--- 1.6184754371643066 seconds for one epoch ---
--- 0.17130494117736816 seconds for one epoch ---
--- 1.4866745471954346 seconds for one epoch ---
--- 0.19288945198059082 seconds for one epoch ---
--- 1.489917278289795 seconds for one epoch ---
--- 0.19500350952148438 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9766487]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.788192]
 [  0.      ]]
--- 0.17907333374023438 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1945.2403564453125, (936.3443, 1.6723504, 1006.85895, 0.36469766)
   validation loss 904.78515625, (606.87787, 0.1736711, 297.36896, 0.36469766)
decoder loss ratio: 23511.502218, decoder SINDy loss  ratio: 0.641913
--- 0.16364693641662598 seconds for one epoch ---
--- 1.4930012226104736 seconds for one epoch ---
--- 0.15911054611206055 seconds for one epoch ---
--- 1.5632975101470947 seconds for one epoch ---
--- 0.16812992095947266 seconds for one epoch ---
--- 1.5750131607055664 seconds for one epoch ---
--- 0.1974501609802246 seconds for one epoch ---
--- 1.584296464920044 seconds for one epoch ---
--- 0.17323994636535645 seconds for one epoch ---
--- 1.5458974838256836 seconds for one epoch ---
--- 0.17899513244628906 seconds for one epoch ---
--- 1.5194730758666992 seconds for one epoch ---
--- 0.2089979648590088 seconds for one epoch ---
--- 1.5318489074707031 seconds for one epoch ---
--- 0.22082924842834473 seconds for one epoch ---
--- 1.573974370956421 seconds for one epoch ---
--- 0.18533873558044434 seconds for one epoch ---
--- 1.6679949760437012 seconds for one epoch ---
--- 0.21764612197875977 seconds for one epoch ---
--- 1.5636050701141357 seconds for one epoch ---
--- 0.1916790008544922 seconds for one epoch ---
--- 1.540343999862671 seconds for one epoch ---
--- 0.22661566734313965 seconds for one epoch ---
--- 1.5427186489105225 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9771155]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.861825]
 [ -0.      ]]
--- 0.21625089645385742 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3932.844482421875, (1583.6743, 0.8950244, 2347.909, 0.3662853)
   validation loss 1172.7860107421875, (874.66364, 0.16106999, 297.595, 0.3662853)
decoder loss ratio: 33885.987713, decoder SINDy loss  ratio: 0.642401
--- 0.15154337882995605 seconds for one epoch ---
--- 0.17800116539001465 seconds for one epoch ---
--- 1.559229850769043 seconds for one epoch ---
--- 0.20425724983215332 seconds for one epoch ---
--- 1.5519640445709229 seconds for one epoch ---
--- 0.19791483879089355 seconds for one epoch ---
--- 1.5692451000213623 seconds for one epoch ---
--- 0.1801753044128418 seconds for one epoch ---
--- 1.5202314853668213 seconds for one epoch ---
--- 0.16625356674194336 seconds for one epoch ---
--- 1.534705638885498 seconds for one epoch ---
--- 0.18076682090759277 seconds for one epoch ---
--- 1.591174840927124 seconds for one epoch ---
--- 0.2403888702392578 seconds for one epoch ---
--- 1.5463438034057617 seconds for one epoch ---
--- 0.2535581588745117 seconds for one epoch ---
--- 1.5453441143035889 seconds for one epoch ---
--- 0.1918501853942871 seconds for one epoch ---
--- 1.5486209392547607 seconds for one epoch ---
--- 0.24459028244018555 seconds for one epoch ---
--- 1.686793327331543 seconds for one epoch ---
--- 0.19529104232788086 seconds for one epoch ---
--- 1.6163580417633057 seconds for one epoch ---
--- 0.22751355171203613 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9774366]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.913946]
 [ -0.      ]]
--- 0.1552417278289795 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2600.253173828125, (1472.7406, 2.4756365, 1124.6697, 0.3673484)
   validation loss 929.5172729492188, (660.18445, 0.14899051, 268.81644, 0.3673484)
decoder loss ratio: 25576.691656, decoder SINDy loss  ratio: 0.580278
--- 0.2141869068145752 seconds for one epoch ---
--- 1.5679500102996826 seconds for one epoch ---
--- 0.19412946701049805 seconds for one epoch ---
--- 1.556771993637085 seconds for one epoch ---
--- 0.22321510314941406 seconds for one epoch ---
--- 1.586601734161377 seconds for one epoch ---
--- 0.2189171314239502 seconds for one epoch ---
--- 1.5843439102172852 seconds for one epoch ---
--- 0.21319890022277832 seconds for one epoch ---
--- 1.5890140533447266 seconds for one epoch ---
--- 0.18965435028076172 seconds for one epoch ---
--- 1.5399072170257568 seconds for one epoch ---
--- 0.2047252655029297 seconds for one epoch ---
--- 1.5217797756195068 seconds for one epoch ---
--- 0.19835281372070312 seconds for one epoch ---
--- 1.5555896759033203 seconds for one epoch ---
--- 0.22772836685180664 seconds for one epoch ---
--- 1.564249038696289 seconds for one epoch ---
--- 0.26314234733581543 seconds for one epoch ---
--- 1.5693440437316895 seconds for one epoch ---
--- 0.1738579273223877 seconds for one epoch ---
--- 1.6010961532592773 seconds for one epoch ---
--- 0.2118699550628662 seconds for one epoch ---
--- 1.5431008338928223 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9778885]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.988987]
 [ -0.      ]]
--- 0.2395634651184082 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4620.541015625, (1955.9866, 8.297313, 2655.888, 0.36902046)
   validation loss 769.52001953125, (495.01868, 0.17212681, 273.9602, 0.36902046)
decoder loss ratio: 19177.882928, decoder SINDy loss  ratio: 0.591382
--- 0.18490219116210938 seconds for one epoch ---
--- 0.2172548770904541 seconds for one epoch ---
--- 1.6080563068389893 seconds for one epoch ---
--- 0.2149975299835205 seconds for one epoch ---
--- 1.577944278717041 seconds for one epoch ---
--- 0.23907136917114258 seconds for one epoch ---
--- 1.6129803657531738 seconds for one epoch ---
--- 0.16751956939697266 seconds for one epoch ---
--- 1.5901331901550293 seconds for one epoch ---
--- 0.19226360321044922 seconds for one epoch ---
--- 1.6300172805786133 seconds for one epoch ---
--- 0.19595813751220703 seconds for one epoch ---
--- 1.626143455505371 seconds for one epoch ---
--- 0.2660961151123047 seconds for one epoch ---
--- 1.556779384613037 seconds for one epoch ---
--- 0.1874241828918457 seconds for one epoch ---
--- 1.5608925819396973 seconds for one epoch ---
--- 0.19253087043762207 seconds for one epoch ---
--- 1.5559837818145752 seconds for one epoch ---
--- 0.19887518882751465 seconds for one epoch ---
--- 1.5893454551696777 seconds for one epoch ---
--- 0.22037458419799805 seconds for one epoch ---
--- 1.5446922779083252 seconds for one epoch ---
--- 0.18692326545715332 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9781995]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.042148]
 [  0.      ]]
--- 0.16952157020568848 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4272.5966796875, (1905.3423, 1.6844767, 2365.1997, 0.37014553)
   validation loss 1123.176513671875, (818.0239, 0.16431223, 304.6181, 0.37014553)
decoder loss ratio: 31691.667037, decoder SINDy loss  ratio: 0.657561
--- 0.2257983684539795 seconds for one epoch ---
--- 1.6013717651367188 seconds for one epoch ---
--- 0.23064374923706055 seconds for one epoch ---
--- 1.5819666385650635 seconds for one epoch ---
--- 0.20383429527282715 seconds for one epoch ---
--- 1.6839897632598877 seconds for one epoch ---
--- 0.23422670364379883 seconds for one epoch ---
--- 1.618044137954712 seconds for one epoch ---
--- 0.21155214309692383 seconds for one epoch ---
--- 1.5948851108551025 seconds for one epoch ---
--- 0.17894816398620605 seconds for one epoch ---
--- 1.5514640808105469 seconds for one epoch ---
--- 0.23018431663513184 seconds for one epoch ---
--- 1.6186747550964355 seconds for one epoch ---
--- 0.1831052303314209 seconds for one epoch ---
--- 1.5953540802001953 seconds for one epoch ---
--- 0.22711443901062012 seconds for one epoch ---
--- 1.604625940322876 seconds for one epoch ---
--- 0.17356348037719727 seconds for one epoch ---
--- 1.584118366241455 seconds for one epoch ---
--- 0.1881561279296875 seconds for one epoch ---
--- 1.5892021656036377 seconds for one epoch ---
--- 0.20800256729125977 seconds for one epoch ---
--- 1.5742979049682617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97861546]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.115373]
 [  0.      ]]
--- 0.2102518081665039 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2494.82373046875, (1348.8462, 1.635371, 1143.9705, 0.37155327)
   validation loss 797.9378662109375, (507.51038, 0.18962267, 289.8663, 0.37155327)
decoder loss ratio: 19661.833042, decoder SINDy loss  ratio: 0.625717
--- 0.17198419570922852 seconds for one epoch ---
--- 0.1938462257385254 seconds for one epoch ---
--- 1.5541019439697266 seconds for one epoch ---
--- 0.22687864303588867 seconds for one epoch ---
--- 1.6332743167877197 seconds for one epoch ---
--- 0.2256150245666504 seconds for one epoch ---
--- 1.5834376811981201 seconds for one epoch ---
--- 0.17635202407836914 seconds for one epoch ---
--- 1.767892837524414 seconds for one epoch ---
--- 0.23010563850402832 seconds for one epoch ---
--- 1.594320297241211 seconds for one epoch ---
--- 0.23065876960754395 seconds for one epoch ---
--- 1.7799561023712158 seconds for one epoch ---
--- 0.18602657318115234 seconds for one epoch ---
--- 1.610367774963379 seconds for one epoch ---
--- 0.21193408966064453 seconds for one epoch ---
--- 1.602971076965332 seconds for one epoch ---
--- 0.2347567081451416 seconds for one epoch ---
--- 1.5907542705535889 seconds for one epoch ---
--- 0.20600104331970215 seconds for one epoch ---
--- 1.5973780155181885 seconds for one epoch ---
--- 0.1833498477935791 seconds for one epoch ---
--- 1.6316146850585938 seconds for one epoch ---
--- 0.2328190803527832 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9789524]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-14.17585]
 [  0.     ]]
--- 0.16378402709960938 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3010.92578125, (1910.2135, 0.68154263, 1099.6578, 0.37298548)
   validation loss 848.5643920898438, (540.1329, 0.23422614, 307.82428, 0.37298548)
decoder loss ratio: 20925.685233, decoder SINDy loss  ratio: 0.664482
--- 0.18788433074951172 seconds for one epoch ---
--- 1.6153528690338135 seconds for one epoch ---
--- 0.1791670322418213 seconds for one epoch ---
--- 1.6052913665771484 seconds for one epoch ---
--- 0.19126057624816895 seconds for one epoch ---
--- 1.6407558917999268 seconds for one epoch ---
--- 0.1651291847229004 seconds for one epoch ---
--- 1.644819736480713 seconds for one epoch ---
--- 0.20561599731445312 seconds for one epoch ---
--- 1.5819227695465088 seconds for one epoch ---
--- 0.16434764862060547 seconds for one epoch ---
--- 1.6132891178131104 seconds for one epoch ---
--- 0.24264979362487793 seconds for one epoch ---
--- 1.6048696041107178 seconds for one epoch ---
--- 0.18866801261901855 seconds for one epoch ---
--- 1.691119909286499 seconds for one epoch ---
--- 0.21728801727294922 seconds for one epoch ---
--- 1.8046207427978516 seconds for one epoch ---
--- 0.18640398979187012 seconds for one epoch ---
--- 1.6459038257598877 seconds for one epoch ---
--- 0.17151832580566406 seconds for one epoch ---
--- 1.6382102966308594 seconds for one epoch ---
--- 0.200423002243042 seconds for one epoch ---
--- 1.6201858520507812 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9793531]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.249935]
 [ -0.      ]]
--- 0.17930841445922852 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3124.5322265625, (896.41394, 2.167196, 2225.5767, 0.37450337)
   validation loss 1168.8265380859375, (857.1107, 0.19445558, 311.14682, 0.37450337)
decoder loss ratio: 33205.957216, decoder SINDy loss  ratio: 0.671654
--- 0.19830751419067383 seconds for one epoch ---
--- 0.192826509475708 seconds for one epoch ---
--- 1.6139986515045166 seconds for one epoch ---
--- 0.19906306266784668 seconds for one epoch ---
--- 1.6144421100616455 seconds for one epoch ---
--- 0.16558384895324707 seconds for one epoch ---
--- 1.642411470413208 seconds for one epoch ---
--- 0.20210671424865723 seconds for one epoch ---
--- 1.6314070224761963 seconds for one epoch ---
--- 0.14948701858520508 seconds for one epoch ---
--- 1.6634652614593506 seconds for one epoch ---
--- 0.2099776268005371 seconds for one epoch ---
--- 1.6653344631195068 seconds for one epoch ---
--- 0.20094013214111328 seconds for one epoch ---
--- 1.6830127239227295 seconds for one epoch ---
--- 0.2203207015991211 seconds for one epoch ---
--- 1.6756680011749268 seconds for one epoch ---
--- 0.2695434093475342 seconds for one epoch ---
--- 1.586540937423706 seconds for one epoch ---
--- 0.18546152114868164 seconds for one epoch ---
--- 1.6067919731140137 seconds for one epoch ---
--- 0.18536758422851562 seconds for one epoch ---
--- 1.6758124828338623 seconds for one epoch ---
--- 0.16510438919067383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97966456]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-14.3089285]
 [ -0.       ]]
--- 0.16933584213256836 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1553.91162109375, (642.7959, 1.5012282, 909.2387, 0.37576017)
   validation loss 960.250732421875, (609.2433, 0.21777925, 350.41394, 0.37576017)
decoder loss ratio: 23603.142598, decoder SINDy loss  ratio: 0.756418
--- 0.24310612678527832 seconds for one epoch ---
--- 1.6477653980255127 seconds for one epoch ---
--- 0.21673583984375 seconds for one epoch ---
--- 1.6605315208435059 seconds for one epoch ---
--- 0.18992280960083008 seconds for one epoch ---
--- 1.6628541946411133 seconds for one epoch ---
--- 0.21488475799560547 seconds for one epoch ---
--- 1.6309223175048828 seconds for one epoch ---
--- 0.20938873291015625 seconds for one epoch ---
--- 1.620102882385254 seconds for one epoch ---
--- 0.2065412998199463 seconds for one epoch ---
--- 1.595564365386963 seconds for one epoch ---
--- 0.26217126846313477 seconds for one epoch ---
--- 1.6212682723999023 seconds for one epoch ---
--- 0.24237990379333496 seconds for one epoch ---
--- 1.6664001941680908 seconds for one epoch ---
--- 0.19151949882507324 seconds for one epoch ---
--- 1.7370312213897705 seconds for one epoch ---
--- 0.2130734920501709 seconds for one epoch ---
--- 1.6257662773132324 seconds for one epoch ---
--- 0.2145092487335205 seconds for one epoch ---
--- 1.6519715785980225 seconds for one epoch ---
--- 0.22627711296081543 seconds for one epoch ---
--- 1.6742165088653564 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9799148]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-14.35772]
 [ -0.     ]]
--- 0.21242260932922363 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2623.46533203125, (1068.2654, 1.9488199, 1552.874, 0.3768799)
   validation loss 907.9907836914062, (606.11334, 0.22506125, 301.27554, 0.3768799)
decoder loss ratio: 23481.883139, decoder SINDy loss  ratio: 0.650346
--- 0.17659211158752441 seconds for one epoch ---
--- 0.2083134651184082 seconds for one epoch ---
--- 1.6688504219055176 seconds for one epoch ---
--- 0.21521592140197754 seconds for one epoch ---
--- 1.5973329544067383 seconds for one epoch ---
--- 0.19475865364074707 seconds for one epoch ---
--- 1.6989641189575195 seconds for one epoch ---
--- 0.20897269248962402 seconds for one epoch ---
--- 1.8251769542694092 seconds for one epoch ---
--- 0.20119214057922363 seconds for one epoch ---
--- 1.6928277015686035 seconds for one epoch ---
--- 0.18656253814697266 seconds for one epoch ---
--- 1.618462324142456 seconds for one epoch ---
--- 0.18148112297058105 seconds for one epoch ---
--- 1.6864564418792725 seconds for one epoch ---
--- 0.19611430168151855 seconds for one epoch ---
--- 1.851858139038086 seconds for one epoch ---
--- 0.17887616157531738 seconds for one epoch ---
--- 1.6245841979980469 seconds for one epoch ---
--- 0.18608856201171875 seconds for one epoch ---
--- 1.6862518787384033 seconds for one epoch ---
--- 0.20938825607299805 seconds for one epoch ---
--- 1.695319414138794 seconds for one epoch ---
--- 0.18849611282348633 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.980173]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.408924]
 [  0.      ]]
--- 0.18154239654541016 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1680.1080322265625, (770.06006, 0.56587905, 909.1042, 0.3779501)
   validation loss 997.463134765625, (698.9312, 0.21579482, 297.9382, 0.3779501)
decoder loss ratio: 27077.808604, decoder SINDy loss  ratio: 0.643142
--- 0.1851942539215088 seconds for one epoch ---
--- 1.64064621925354 seconds for one epoch ---
--- 0.20956850051879883 seconds for one epoch ---
--- 1.6772897243499756 seconds for one epoch ---
--- 0.1811223030090332 seconds for one epoch ---
--- 1.6652326583862305 seconds for one epoch ---
--- 0.18427085876464844 seconds for one epoch ---
--- 1.7417094707489014 seconds for one epoch ---
--- 0.1952807903289795 seconds for one epoch ---
--- 1.6894993782043457 seconds for one epoch ---
--- 0.2097945213317871 seconds for one epoch ---
--- 1.6928303241729736 seconds for one epoch ---
--- 0.21048617362976074 seconds for one epoch ---
--- 1.7022981643676758 seconds for one epoch ---
--- 0.22030258178710938 seconds for one epoch ---
--- 1.6774556636810303 seconds for one epoch ---
--- 0.18244171142578125 seconds for one epoch ---
--- 1.5917892456054688 seconds for one epoch ---
--- 0.216264009475708 seconds for one epoch ---
--- 1.6759617328643799 seconds for one epoch ---
--- 0.2131054401397705 seconds for one epoch ---
--- 1.6301376819610596 seconds for one epoch ---
--- 0.1825118064880371 seconds for one epoch ---
--- 1.690648078918457 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9804293]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.460592]
 [  0.      ]]
--- 0.1755814552307129 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4649.5068359375, (1650.1877, 1.6844351, 2997.2556, 0.37904078)
   validation loss 1357.41650390625, (1046.9861, 0.2213855, 309.83, 0.37904078)
decoder loss ratio: 40562.058541, decoder SINDy loss  ratio: 0.668812
--- 0.164703369140625 seconds for one epoch ---
--- 0.1651442050933838 seconds for one epoch ---
--- 1.684248924255371 seconds for one epoch ---
--- 0.19660377502441406 seconds for one epoch ---
--- 1.7239477634429932 seconds for one epoch ---
--- 0.18349623680114746 seconds for one epoch ---
--- 1.8025023937225342 seconds for one epoch ---
--- 0.22968149185180664 seconds for one epoch ---
--- 1.7645962238311768 seconds for one epoch ---
--- 0.22917866706848145 seconds for one epoch ---
--- 1.693225383758545 seconds for one epoch ---
--- 0.21680545806884766 seconds for one epoch ---
--- 1.6191136837005615 seconds for one epoch ---
--- 0.20369267463684082 seconds for one epoch ---
--- 1.6994245052337646 seconds for one epoch ---
--- 0.2501692771911621 seconds for one epoch ---
--- 1.6491639614105225 seconds for one epoch ---
--- 0.20697259902954102 seconds for one epoch ---
--- 1.627208948135376 seconds for one epoch ---
--- 0.2188272476196289 seconds for one epoch ---
--- 1.7318024635314941 seconds for one epoch ---
--- 0.18489575386047363 seconds for one epoch ---
--- 1.6519172191619873 seconds for one epoch ---
--- 0.16288399696350098 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9806371]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.503605]
 [  0.      ]]
--- 0.20694184303283691 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3270.31640625, (1433.8663, 3.1313996, 1832.9386, 0.38003066)
   validation loss 1455.2435302734375, (1135.694, 0.25172004, 318.91782, 0.38003066)
decoder loss ratio: 43998.756039, decoder SINDy loss  ratio: 0.688429
--- 0.214385986328125 seconds for one epoch ---
--- 1.743034839630127 seconds for one epoch ---
--- 0.22095990180969238 seconds for one epoch ---
--- 1.6312272548675537 seconds for one epoch ---
--- 0.20090341567993164 seconds for one epoch ---
--- 1.7068796157836914 seconds for one epoch ---
--- 0.17457127571105957 seconds for one epoch ---
--- 1.6766111850738525 seconds for one epoch ---
--- 0.23127269744873047 seconds for one epoch ---
--- 1.748366355895996 seconds for one epoch ---
--- 0.2774393558502197 seconds for one epoch ---
--- 1.714763879776001 seconds for one epoch ---
--- 0.19939517974853516 seconds for one epoch ---
--- 1.7244937419891357 seconds for one epoch ---
--- 0.1785140037536621 seconds for one epoch ---
--- 1.6965548992156982 seconds for one epoch ---
--- 0.1885533332824707 seconds for one epoch ---
--- 1.7355525493621826 seconds for one epoch ---
--- 0.48575425148010254 seconds for one epoch ---
--- 1.7014312744140625 seconds for one epoch ---
--- 0.18752503395080566 seconds for one epoch ---
--- 1.7535784244537354 seconds for one epoch ---
--- 0.21598482131958008 seconds for one epoch ---
--- 1.7770276069641113 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9809443]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.568135]
 [ -0.      ]]
--- 0.21462154388427734 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1812.377685546875, (1006.6212, 0.41558847, 804.9594, 0.3814499)
   validation loss 888.2918701171875, (591.1453, 0.20062731, 296.56442, 0.3814499)
decoder loss ratio: 22901.996153, decoder SINDy loss  ratio: 0.640176
--- 0.26615214347839355 seconds for one epoch ---
--- 0.24443721771240234 seconds for one epoch ---
--- 1.766850471496582 seconds for one epoch ---
--- 0.20539450645446777 seconds for one epoch ---
--- 1.6814324855804443 seconds for one epoch ---
--- 0.19811439514160156 seconds for one epoch ---
--- 1.7353456020355225 seconds for one epoch ---
--- 0.22452259063720703 seconds for one epoch ---
--- 1.7182998657226562 seconds for one epoch ---
--- 0.22127699851989746 seconds for one epoch ---
--- 1.6748580932617188 seconds for one epoch ---
--- 0.19588708877563477 seconds for one epoch ---
--- 1.7130563259124756 seconds for one epoch ---
--- 0.1953418254852295 seconds for one epoch ---
--- 1.7435739040374756 seconds for one epoch ---
--- 0.26436853408813477 seconds for one epoch ---
--- 1.6829652786254883 seconds for one epoch ---
--- 0.21280264854431152 seconds for one epoch ---
--- 1.6916828155517578 seconds for one epoch ---
--- 0.16221308708190918 seconds for one epoch ---
--- 1.752964973449707 seconds for one epoch ---
--- 0.19503068923950195 seconds for one epoch ---
--- 1.7348315715789795 seconds for one epoch ---
--- 0.22084808349609375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98120314]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.624148]
 [ -0.      ]]
--- 0.15334653854370117 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1680.6168212890625, (950.57605, 0.32877314, 729.3293, 0.38268)
   validation loss 836.0133056640625, (542.80804, 0.19429299, 292.62833, 0.38268)
decoder loss ratio: 21029.325998, decoder SINDy loss  ratio: 0.631679
--- 0.21158361434936523 seconds for one epoch ---
--- 1.7112202644348145 seconds for one epoch ---
--- 0.18435978889465332 seconds for one epoch ---
--- 1.8253109455108643 seconds for one epoch ---
--- 0.18895697593688965 seconds for one epoch ---
--- 1.820293664932251 seconds for one epoch ---
--- 0.1972641944885254 seconds for one epoch ---
--- 1.7935173511505127 seconds for one epoch ---
--- 0.2160024642944336 seconds for one epoch ---
--- 1.700498104095459 seconds for one epoch ---
--- 0.21481919288635254 seconds for one epoch ---
--- 1.6780037879943848 seconds for one epoch ---
--- 0.218034029006958 seconds for one epoch ---
--- 1.749023675918579 seconds for one epoch ---
--- 0.1791985034942627 seconds for one epoch ---
--- 1.7075624465942383 seconds for one epoch ---
--- 0.23293042182922363 seconds for one epoch ---
--- 1.7598724365234375 seconds for one epoch ---
--- 0.18358397483825684 seconds for one epoch ---
--- 2.001330614089966 seconds for one epoch ---
--- 0.19989252090454102 seconds for one epoch ---
--- 1.72542142868042 seconds for one epoch ---
--- 0.19596338272094727 seconds for one epoch ---
--- 1.6908459663391113 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98145485]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.679541]
 [ -0.      ]]
--- 0.22728300094604492 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3503.796875, (1550.5424, 3.5910144, 1949.2795, 0.3838496)
   validation loss 764.4525756835938, (476.02087, 0.2325916, 287.81525, 0.3838496)
decoder loss ratio: 18441.875068, decoder SINDy loss  ratio: 0.621290
THRESHOLDING: 1 active coefficients
--- 0.17372393608093262 seconds for one epoch ---
--- 0.19871282577514648 seconds for one epoch ---
--- 1.759338617324829 seconds for one epoch ---
--- 0.22501683235168457 seconds for one epoch ---
--- 1.7685136795043945 seconds for one epoch ---
--- 0.2085862159729004 seconds for one epoch ---
--- 1.8687098026275635 seconds for one epoch ---
--- 0.20982789993286133 seconds for one epoch ---
--- 1.7858617305755615 seconds for one epoch ---
--- 0.16162943840026855 seconds for one epoch ---
--- 1.761988639831543 seconds for one epoch ---
--- 0.19286370277404785 seconds for one epoch ---
--- 1.8272535800933838 seconds for one epoch ---
--- 0.17580699920654297 seconds for one epoch ---
--- 1.7798802852630615 seconds for one epoch ---
--- 0.19134140014648438 seconds for one epoch ---
--- 1.7590243816375732 seconds for one epoch ---
--- 0.18231201171875 seconds for one epoch ---
--- 1.849987506866455 seconds for one epoch ---
--- 0.2022712230682373 seconds for one epoch ---
--- 1.8159763813018799 seconds for one epoch ---
--- 0.2519237995147705 seconds for one epoch ---
--- 1.771937370300293 seconds for one epoch ---
--- 0.22176122665405273 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98169863]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.734692]
 [  0.      ]]
--- 0.14876008033752441 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3839.2451171875, (1701.8726, 2.478195, 2134.5093, 0.38517362)
   validation loss 794.4843139648438, (518.51666, 0.21374765, 275.36874, 0.38517362)
decoder loss ratio: 20088.235694, decoder SINDy loss  ratio: 0.594422
--- 0.2511715888977051 seconds for one epoch ---
--- 1.723252296447754 seconds for one epoch ---
--- 0.20773530006408691 seconds for one epoch ---
--- 1.7354404926300049 seconds for one epoch ---
--- 0.22454380989074707 seconds for one epoch ---
--- 1.7839758396148682 seconds for one epoch ---
--- 0.2963392734527588 seconds for one epoch ---
--- 1.7116880416870117 seconds for one epoch ---
--- 0.17135357856750488 seconds for one epoch ---
--- 1.6926906108856201 seconds for one epoch ---
--- 0.21654796600341797 seconds for one epoch ---
--- 1.7350671291351318 seconds for one epoch ---
--- 0.1621837615966797 seconds for one epoch ---
--- 1.778566837310791 seconds for one epoch ---
--- 0.18754100799560547 seconds for one epoch ---
--- 1.7755239009857178 seconds for one epoch ---
--- 0.21368932723999023 seconds for one epoch ---
--- 1.7141790390014648 seconds for one epoch ---
--- 0.18454527854919434 seconds for one epoch ---
--- 1.7358028888702393 seconds for one epoch ---
--- 0.20703434944152832 seconds for one epoch ---
--- 1.933861255645752 seconds for one epoch ---
--- 0.18785977363586426 seconds for one epoch ---
--- 1.817204475402832 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9818991]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.780865]
 [  0.      ]]
--- 0.18999528884887695 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1840.2564697265625, (965.04816, 3.09195, 871.7303, 0.3860871)
   validation loss 824.6982421875, (525.4575, 0.20299523, 298.65158, 0.3860871)
decoder loss ratio: 20357.136541, decoder SINDy loss  ratio: 0.644681
--- 0.1626873016357422 seconds for one epoch ---
--- 0.21294283866882324 seconds for one epoch ---
--- 1.7720344066619873 seconds for one epoch ---
--- 0.21483230590820312 seconds for one epoch ---
--- 1.777806282043457 seconds for one epoch ---
--- 0.21068048477172852 seconds for one epoch ---
--- 1.7462222576141357 seconds for one epoch ---
--- 0.21052908897399902 seconds for one epoch ---
--- 1.760383129119873 seconds for one epoch ---
--- 0.18185162544250488 seconds for one epoch ---
--- 1.7959353923797607 seconds for one epoch ---
--- 0.20920896530151367 seconds for one epoch ---
--- 2.0102763175964355 seconds for one epoch ---
--- 0.19343972206115723 seconds for one epoch ---
--- 1.8164172172546387 seconds for one epoch ---
--- 0.23823976516723633 seconds for one epoch ---
--- 1.7460527420043945 seconds for one epoch ---
--- 0.21667695045471191 seconds for one epoch ---
--- 1.7623858451843262 seconds for one epoch ---
--- 0.1960773468017578 seconds for one epoch ---
--- 1.8035774230957031 seconds for one epoch ---
--- 0.22264790534973145 seconds for one epoch ---
--- 1.7642054557800293 seconds for one epoch ---
--- 0.21475815773010254 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982124]
 [0.      ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-14.83371]
 [  0.     ]]
--- 0.17870593070983887 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3099.88525390625, (2158.0059, 3.6152198, 937.877, 0.38729867)
   validation loss 931.7886962890625, (625.3967, 0.23136853, 305.77322, 0.38729867)
decoder loss ratio: 24228.954999, decoder SINDy loss  ratio: 0.660055
--- 0.21846413612365723 seconds for one epoch ---
--- 1.7645273208618164 seconds for one epoch ---
--- 0.20282936096191406 seconds for one epoch ---
--- 1.7055516242980957 seconds for one epoch ---
--- 0.19138550758361816 seconds for one epoch ---
--- 1.7526741027832031 seconds for one epoch ---
--- 0.1746983528137207 seconds for one epoch ---
--- 1.7491505146026611 seconds for one epoch ---
--- 0.21553850173950195 seconds for one epoch ---
--- 1.7150063514709473 seconds for one epoch ---
--- 0.20099997520446777 seconds for one epoch ---
--- 1.720489501953125 seconds for one epoch ---
--- 0.21731853485107422 seconds for one epoch ---
--- 1.8294901847839355 seconds for one epoch ---
--- 0.21303510665893555 seconds for one epoch ---
--- 1.8146891593933105 seconds for one epoch ---
--- 0.20158624649047852 seconds for one epoch ---
--- 1.7934627532958984 seconds for one epoch ---
--- 0.20822358131408691 seconds for one epoch ---
--- 1.821260690689087 seconds for one epoch ---
--- 0.2181718349456787 seconds for one epoch ---
--- 1.8748092651367188 seconds for one epoch ---
--- 0.30030322074890137 seconds for one epoch ---
--- 1.8001389503479004 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98226744]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.8680525]
 [ -0.       ]]
--- 0.2213742733001709 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1840.0968017578125, (900.01886, 0.9458328, 938.7441, 0.38802907)
   validation loss 1095.326416015625, (780.23456, 0.19876355, 314.50504, 0.38802907)
decoder loss ratio: 30227.641328, decoder SINDy loss  ratio: 0.678903
--- 0.1812429428100586 seconds for one epoch ---
--- 0.19962811470031738 seconds for one epoch ---
--- 1.7682077884674072 seconds for one epoch ---
--- 0.17681503295898438 seconds for one epoch ---
--- 1.6867241859436035 seconds for one epoch ---
--- 0.21368789672851562 seconds for one epoch ---
--- 1.78375244140625 seconds for one epoch ---
--- 0.1861872673034668 seconds for one epoch ---
--- 1.7708640098571777 seconds for one epoch ---
--- 0.22495126724243164 seconds for one epoch ---
--- 1.787816047668457 seconds for one epoch ---
--- 0.24321889877319336 seconds for one epoch ---
--- 1.7815706729888916 seconds for one epoch ---
--- 0.18790245056152344 seconds for one epoch ---
--- 1.8234615325927734 seconds for one epoch ---
--- 0.20726585388183594 seconds for one epoch ---
--- 1.7728958129882812 seconds for one epoch ---
--- 0.27454185485839844 seconds for one epoch ---
--- 1.8002161979675293 seconds for one epoch ---
--- 0.22486066818237305 seconds for one epoch ---
--- 1.7529385089874268 seconds for one epoch ---
--- 0.19361639022827148 seconds for one epoch ---
--- 1.8102924823760986 seconds for one epoch ---
--- 0.19397354125976562 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9824327]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.908052]
 [ -0.      ]]
--- 0.17348885536193848 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2971.421142578125, (1254.6765, 0.30767557, 1716.0481, 0.38888192)
   validation loss 919.97802734375, (594.7032, 0.21172202, 324.67426, 0.38888192)
decoder loss ratio: 23039.833877, decoder SINDy loss  ratio: 0.700855
--- 0.19723033905029297 seconds for one epoch ---
--- 1.8230857849121094 seconds for one epoch ---
--- 0.19884061813354492 seconds for one epoch ---
--- 1.7458763122558594 seconds for one epoch ---
--- 0.21646857261657715 seconds for one epoch ---
--- 1.8321094512939453 seconds for one epoch ---
--- 0.1918938159942627 seconds for one epoch ---
--- 1.7549488544464111 seconds for one epoch ---
--- 0.21443676948547363 seconds for one epoch ---
--- 1.8243491649627686 seconds for one epoch ---
--- 0.1746842861175537 seconds for one epoch ---
--- 1.7946887016296387 seconds for one epoch ---
--- 0.21643686294555664 seconds for one epoch ---
--- 1.804598093032837 seconds for one epoch ---
--- 0.22622394561767578 seconds for one epoch ---
--- 1.8253300189971924 seconds for one epoch ---
--- 0.19746780395507812 seconds for one epoch ---
--- 1.8180546760559082 seconds for one epoch ---
--- 0.22070741653442383 seconds for one epoch ---
--- 1.742288589477539 seconds for one epoch ---
--- 0.23772001266479492 seconds for one epoch ---
--- 1.7582154273986816 seconds for one epoch ---
--- 0.19418096542358398 seconds for one epoch ---
--- 1.8034999370574951 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9826036]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.950174]
 [ -0.      ]]
--- 0.1731870174407959 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2953.941650390625, (1314.6864, 2.0862079, 1636.7792, 0.38979802)
   validation loss 782.6188354492188, (501.69073, 0.19490393, 280.3434, 0.38979802)
decoder loss ratio: 19436.370042, decoder SINDy loss  ratio: 0.605161
--- 0.189741849899292 seconds for one epoch ---
--- 0.2225489616394043 seconds for one epoch ---
--- 1.7516214847564697 seconds for one epoch ---
--- 0.2330033779144287 seconds for one epoch ---
--- 1.884753942489624 seconds for one epoch ---
--- 0.2011873722076416 seconds for one epoch ---
--- 1.8532209396362305 seconds for one epoch ---
--- 0.17232942581176758 seconds for one epoch ---
--- 1.855210304260254 seconds for one epoch ---
--- 0.20633602142333984 seconds for one epoch ---
--- 1.798032522201538 seconds for one epoch ---
--- 0.2041482925415039 seconds for one epoch ---
--- 1.8536381721496582 seconds for one epoch ---
--- 0.20178937911987305 seconds for one epoch ---
--- 1.7999930381774902 seconds for one epoch ---
--- 0.19315099716186523 seconds for one epoch ---
--- 1.8787412643432617 seconds for one epoch ---
--- 0.1864926815032959 seconds for one epoch ---
--- 1.7651495933532715 seconds for one epoch ---
--- 0.20641255378723145 seconds for one epoch ---
--- 1.7507212162017822 seconds for one epoch ---
--- 0.1957237720489502 seconds for one epoch ---
--- 1.890345811843872 seconds for one epoch ---
--- 0.1985337734222412 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9827662]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.99102]
 [  0.     ]]
--- 0.16405224800109863 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3360.19970703125, (1441.4867, 1.3514769, 1916.9711, 0.39072374)
   validation loss 930.78466796875, (640.86536, 0.19702236, 289.3315, 0.39072374)
decoder loss ratio: 24828.236500, decoder SINDy loss  ratio: 0.624563
--- 0.21451854705810547 seconds for one epoch ---
--- 1.7946653366088867 seconds for one epoch ---
--- 0.20728373527526855 seconds for one epoch ---
--- 1.8042340278625488 seconds for one epoch ---
--- 0.18552398681640625 seconds for one epoch ---
--- 1.8601269721984863 seconds for one epoch ---
--- 0.20311522483825684 seconds for one epoch ---
--- 1.7744126319885254 seconds for one epoch ---
--- 0.20492839813232422 seconds for one epoch ---
--- 1.832035779953003 seconds for one epoch ---
--- 0.18610262870788574 seconds for one epoch ---
--- 1.8601939678192139 seconds for one epoch ---
--- 0.2676563262939453 seconds for one epoch ---
--- 1.8977253437042236 seconds for one epoch ---
--- 0.18158578872680664 seconds for one epoch ---
--- 1.9005331993103027 seconds for one epoch ---
--- 0.21547722816467285 seconds for one epoch ---
--- 1.807959794998169 seconds for one epoch ---
--- 0.19135499000549316 seconds for one epoch ---
--- 1.8899211883544922 seconds for one epoch ---
--- 0.20646238327026367 seconds for one epoch ---
--- 1.9885585308074951 seconds for one epoch ---
--- 0.31252527236938477 seconds for one epoch ---
--- 1.826258897781372 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982913]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.028518]
 [  0.      ]]
--- 0.20128750801086426 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2255.10693359375, (1030.2301, 1.722902, 1222.7625, 0.39159593)
   validation loss 799.412353515625, (514.29364, 0.19205719, 284.535, 0.39159593)
decoder loss ratio: 19924.628472, decoder SINDy loss  ratio: 0.614209
--- 0.14550328254699707 seconds for one epoch ---
--- 0.20723891258239746 seconds for one epoch ---
--- 1.8229162693023682 seconds for one epoch ---
--- 0.18156051635742188 seconds for one epoch ---
--- 1.8203456401824951 seconds for one epoch ---
--- 0.20459485054016113 seconds for one epoch ---
--- 1.904731035232544 seconds for one epoch ---
--- 0.3014981746673584 seconds for one epoch ---
--- 1.963439702987671 seconds for one epoch ---
--- 0.19251585006713867 seconds for one epoch ---
--- 1.8588335514068604 seconds for one epoch ---
--- 0.18309378623962402 seconds for one epoch ---
--- 1.9497427940368652 seconds for one epoch ---
--- 0.23013949394226074 seconds for one epoch ---
--- 1.8623583316802979 seconds for one epoch ---
--- 0.23651647567749023 seconds for one epoch ---
--- 1.8486263751983643 seconds for one epoch ---
--- 0.1962599754333496 seconds for one epoch ---
--- 1.8895394802093506 seconds for one epoch ---
--- 0.19929099082946777 seconds for one epoch ---
--- 1.8672068119049072 seconds for one epoch ---
--- 0.20067167282104492 seconds for one epoch ---
--- 1.8655028343200684 seconds for one epoch ---
--- 0.1773970127105713 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98305297]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.064704]
 [  0.      ]]
--- 0.1594245433807373 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3410.814697265625, (1584.5057, 1.6500853, 1824.2667, 0.39244083)
   validation loss 858.1773681640625, (565.441, 0.17957696, 292.16434, 0.39244083)
decoder loss ratio: 21906.165175, decoder SINDy loss  ratio: 0.630678
--- 0.19348740577697754 seconds for one epoch ---
--- 1.9990525245666504 seconds for one epoch ---
--- 0.2007308006286621 seconds for one epoch ---
--- 1.8136539459228516 seconds for one epoch ---
--- 0.18288350105285645 seconds for one epoch ---
--- 1.7938978672027588 seconds for one epoch ---
--- 0.20406103134155273 seconds for one epoch ---
--- 1.8863797187805176 seconds for one epoch ---
--- 0.1823420524597168 seconds for one epoch ---
--- 1.8371589183807373 seconds for one epoch ---
--- 0.2141273021697998 seconds for one epoch ---
--- 1.915891170501709 seconds for one epoch ---
--- 0.2756977081298828 seconds for one epoch ---
--- 1.8160693645477295 seconds for one epoch ---
--- 0.19507193565368652 seconds for one epoch ---
--- 1.8395862579345703 seconds for one epoch ---
--- 0.22542142868041992 seconds for one epoch ---
--- 1.8588895797729492 seconds for one epoch ---
--- 0.18946027755737305 seconds for one epoch ---
--- 1.8229050636291504 seconds for one epoch ---
--- 0.2241971492767334 seconds for one epoch ---
--- 1.874140977859497 seconds for one epoch ---
--- 0.18461060523986816 seconds for one epoch ---
--- 2.0644638538360596 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98322153]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.108862]
 [ -0.      ]]
--- 0.1835627555847168 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3353.810546875, (1108.4117, 1.751123, 2243.2544, 0.39339325)
   validation loss 800.6093139648438, (522.5229, 0.20061721, 277.49246, 0.39339325)
decoder loss ratio: 20243.443828, decoder SINDy loss  ratio: 0.599007
--- 0.18403363227844238 seconds for one epoch ---
--- 0.2518351078033447 seconds for one epoch ---
--- 1.8929436206817627 seconds for one epoch ---
--- 0.23150420188903809 seconds for one epoch ---
--- 2.065309524536133 seconds for one epoch ---
--- 0.21478796005249023 seconds for one epoch ---
--- 2.105391025543213 seconds for one epoch ---
--- 0.26484131813049316 seconds for one epoch ---
--- 2.1019678115844727 seconds for one epoch ---
--- 0.23331809043884277 seconds for one epoch ---
--- 2.080979585647583 seconds for one epoch ---
--- 0.20131301879882812 seconds for one epoch ---
--- 2.1090688705444336 seconds for one epoch ---
--- 0.19367694854736328 seconds for one epoch ---
--- 2.043778896331787 seconds for one epoch ---
--- 0.17139697074890137 seconds for one epoch ---
--- 2.2457616329193115 seconds for one epoch ---
--- 0.23387861251831055 seconds for one epoch ---
--- 2.201232433319092 seconds for one epoch ---
--- 0.232008695602417 seconds for one epoch ---
--- 2.167663812637329 seconds for one epoch ---
--- 0.25745272636413574 seconds for one epoch ---
--- 2.2120842933654785 seconds for one epoch ---
--- 0.21072745323181152 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9833791]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.150842]
 [ -0.      ]]
--- 0.1764228343963623 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2839.003662109375, (1022.4589, 1.3445584, 1814.806, 0.39434537)
   validation loss 852.7007446289062, (577.2078, 0.21448772, 274.88406, 0.39434537)
decoder loss ratio: 22362.033206, decoder SINDy loss  ratio: 0.593376
--- 0.25507354736328125 seconds for one epoch ---
--- 2.065208911895752 seconds for one epoch ---
--- 0.23774147033691406 seconds for one epoch ---
--- 2.058891534805298 seconds for one epoch ---
--- 0.2190408706665039 seconds for one epoch ---
--- 2.3913886547088623 seconds for one epoch ---
--- 0.17708683013916016 seconds for one epoch ---
--- 2.1659982204437256 seconds for one epoch ---
--- 0.2067577838897705 seconds for one epoch ---
--- 2.24753999710083 seconds for one epoch ---
--- 0.1819908618927002 seconds for one epoch ---
--- 2.0830228328704834 seconds for one epoch ---
--- 0.19326138496398926 seconds for one epoch ---
--- 2.2085466384887695 seconds for one epoch ---
--- 0.17651104927062988 seconds for one epoch ---
--- 2.092092990875244 seconds for one epoch ---
--- 0.24071121215820312 seconds for one epoch ---
--- 2.0715863704681396 seconds for one epoch ---
--- 0.21349787712097168 seconds for one epoch ---
--- 2.275299072265625 seconds for one epoch ---
--- 0.2194666862487793 seconds for one epoch ---
--- 2.127934217453003 seconds for one epoch ---
--- 0.21523475646972656 seconds for one epoch ---
--- 2.3067240715026855 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9835251]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.190294]
 [ -0.      ]]
--- 0.2197730541229248 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5594.4072265625, (2584.9214, 1.6938254, 3007.397, 0.39524785)
   validation loss 886.040771484375, (591.3762, 0.21252859, 294.05673, 0.39524785)
decoder loss ratio: 22910.941464, decoder SINDy loss  ratio: 0.634763
--- 0.14523005485534668 seconds for one epoch ---
--- 0.23406529426574707 seconds for one epoch ---
--- 1.931645393371582 seconds for one epoch ---
--- 0.21746039390563965 seconds for one epoch ---
--- 1.9138712882995605 seconds for one epoch ---
--- 0.19409775733947754 seconds for one epoch ---
--- 1.952129602432251 seconds for one epoch ---
--- 0.18025469779968262 seconds for one epoch ---
--- 1.877798080444336 seconds for one epoch ---
--- 0.29207515716552734 seconds for one epoch ---
--- 1.9149401187896729 seconds for one epoch ---
--- 0.21676039695739746 seconds for one epoch ---
--- 1.870671272277832 seconds for one epoch ---
--- 0.22391176223754883 seconds for one epoch ---
--- 2.085113286972046 seconds for one epoch ---
--- 0.264113187789917 seconds for one epoch ---
--- 1.8785820007324219 seconds for one epoch ---
--- 0.20195984840393066 seconds for one epoch ---
--- 1.875359296798706 seconds for one epoch ---
--- 0.18164944648742676 seconds for one epoch ---
--- 1.9254710674285889 seconds for one epoch ---
--- 0.21163654327392578 seconds for one epoch ---
--- 1.9305894374847412 seconds for one epoch ---
--- 0.21063899993896484 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98367685]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.232354]
 [  0.      ]]
--- 0.15082097053527832 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1325.093505859375, (667.5908, 1.7197795, 655.3868, 0.39616185)
   validation loss 754.5619506835938, (479.9478, 0.23497202, 273.98294, 0.39616185)
decoder loss ratio: 18594.011577, decoder SINDy loss  ratio: 0.591431
--- 0.1767747402191162 seconds for one epoch ---
--- 2.255781412124634 seconds for one epoch ---
--- 0.18504571914672852 seconds for one epoch ---
--- 2.260236978530884 seconds for one epoch ---
--- 0.19815778732299805 seconds for one epoch ---
--- 2.1446211338043213 seconds for one epoch ---
--- 0.26104140281677246 seconds for one epoch ---
--- 2.0871741771698 seconds for one epoch ---
--- 0.22869563102722168 seconds for one epoch ---
--- 2.0858895778656006 seconds for one epoch ---
--- 0.21821880340576172 seconds for one epoch ---
--- 2.1413958072662354 seconds for one epoch ---
--- 0.18215489387512207 seconds for one epoch ---
--- 2.270723342895508 seconds for one epoch ---
--- 0.21312499046325684 seconds for one epoch ---
--- 2.276031255722046 seconds for one epoch ---
--- 0.22933316230773926 seconds for one epoch ---
--- 2.2606420516967773 seconds for one epoch ---
--- 0.19147253036499023 seconds for one epoch ---
--- 2.241536855697632 seconds for one epoch ---
--- 0.21879243850708008 seconds for one epoch ---
--- 2.132233142852783 seconds for one epoch ---
--- 0.21645617485046387 seconds for one epoch ---
--- 2.3272271156311035 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98380667]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.268793]
 [  0.      ]]
--- 0.15343499183654785 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1780.1541748046875, (1209.0046, 0.8970112, 569.8556, 0.39696)
   validation loss 821.706298828125, (551.8514, 0.26072502, 269.1972, 0.39696)
decoder loss ratio: 21379.680494, decoder SINDy loss  ratio: 0.581100
--- 0.16910624504089355 seconds for one epoch ---
--- 0.20847225189208984 seconds for one epoch ---
--- 1.8251004219055176 seconds for one epoch ---
--- 0.19312286376953125 seconds for one epoch ---
--- 1.8631207942962646 seconds for one epoch ---
--- 0.20725178718566895 seconds for one epoch ---
--- 1.992436408996582 seconds for one epoch ---
--- 0.2287132740020752 seconds for one epoch ---
--- 1.9401087760925293 seconds for one epoch ---
--- 0.20055818557739258 seconds for one epoch ---
--- 1.9069194793701172 seconds for one epoch ---
--- 0.24092602729797363 seconds for one epoch ---
--- 1.9085593223571777 seconds for one epoch ---
--- 0.19705414772033691 seconds for one epoch ---
--- 1.8825585842132568 seconds for one epoch ---
--- 0.19191741943359375 seconds for one epoch ---
--- 1.9587788581848145 seconds for one epoch ---
--- 0.2158958911895752 seconds for one epoch ---
--- 2.057051420211792 seconds for one epoch ---
--- 0.20363068580627441 seconds for one epoch ---
--- 1.9081354141235352 seconds for one epoch ---
--- 0.22614645957946777 seconds for one epoch ---
--- 1.9051003456115723 seconds for one epoch ---
--- 0.21861886978149414 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9839475]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.308638]
 [  0.      ]]
--- 0.18530011177062988 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1743.608154296875, (911.7677, 1.8722314, 829.5702, 0.39793345)
   validation loss 930.8857421875, (650.96857, 0.22821666, 279.29102, 0.39793345)
decoder loss ratio: 25219.652413, decoder SINDy loss  ratio: 0.602889
--- 0.2280898094177246 seconds for one epoch ---
--- 1.9067919254302979 seconds for one epoch ---
--- 0.1786487102508545 seconds for one epoch ---
--- 1.8917477130889893 seconds for one epoch ---
--- 0.19808149337768555 seconds for one epoch ---
--- 2.0088346004486084 seconds for one epoch ---
--- 0.22900104522705078 seconds for one epoch ---
--- 1.982173204421997 seconds for one epoch ---
--- 0.23963618278503418 seconds for one epoch ---
--- 1.8914551734924316 seconds for one epoch ---
--- 0.22005796432495117 seconds for one epoch ---
--- 1.8708207607269287 seconds for one epoch ---
--- 0.17185258865356445 seconds for one epoch ---
--- 2.030268669128418 seconds for one epoch ---
--- 0.22458815574645996 seconds for one epoch ---
--- 1.9292869567871094 seconds for one epoch ---
--- 0.18111109733581543 seconds for one epoch ---
--- 1.9527759552001953 seconds for one epoch ---
--- 0.1805107593536377 seconds for one epoch ---
--- 1.8695893287658691 seconds for one epoch ---
--- 0.17424249649047852 seconds for one epoch ---
--- 1.9683451652526855 seconds for one epoch ---
--- 0.2219250202178955 seconds for one epoch ---
--- 1.994206428527832 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98404664]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.336994]
 [ -0.      ]]
--- 0.22501754760742188 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1646.0240478515625, (770.04504, 2.548999, 873.03143, 0.39854726)
   validation loss 738.7073974609375, (460.78522, 0.22704594, 277.29657, 0.39854726)
decoder loss ratio: 17851.619276, decoder SINDy loss  ratio: 0.598584
--- 0.19257164001464844 seconds for one epoch ---
--- 0.2029430866241455 seconds for one epoch ---
--- 1.9940567016601562 seconds for one epoch ---
--- 0.1662602424621582 seconds for one epoch ---
--- 1.9327130317687988 seconds for one epoch ---
--- 0.2202138900756836 seconds for one epoch ---
--- 1.9512178897857666 seconds for one epoch ---
--- 0.20901823043823242 seconds for one epoch ---
--- 2.0574283599853516 seconds for one epoch ---
--- 0.17515110969543457 seconds for one epoch ---
--- 1.9658823013305664 seconds for one epoch ---
--- 0.2031421661376953 seconds for one epoch ---
--- 2.0530991554260254 seconds for one epoch ---
--- 0.20325088500976562 seconds for one epoch ---
--- 1.9369935989379883 seconds for one epoch ---
--- 0.21351861953735352 seconds for one epoch ---
--- 1.9904348850250244 seconds for one epoch ---
--- 0.1795346736907959 seconds for one epoch ---
--- 1.9665837287902832 seconds for one epoch ---
--- 0.22659850120544434 seconds for one epoch ---
--- 1.913344144821167 seconds for one epoch ---
--- 0.15804219245910645 seconds for one epoch ---
--- 1.9782896041870117 seconds for one epoch ---
--- 0.18016505241394043 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98416996]
 [0.        ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.3732815]
 [ -0.       ]]
--- 0.19925570487976074 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3900.49267578125, (1584.4071, 6.631207, 2309.055, 0.3993938)
   validation loss 867.1019287109375, (590.9019, 0.2167373, 275.58383, 0.3993938)
decoder loss ratio: 22892.566096, decoder SINDy loss  ratio: 0.594886
--- 0.2444465160369873 seconds for one epoch ---
--- 2.0739853382110596 seconds for one epoch ---
--- 0.2286386489868164 seconds for one epoch ---
--- 1.9311962127685547 seconds for one epoch ---
--- 0.22199606895446777 seconds for one epoch ---
--- 1.9750041961669922 seconds for one epoch ---
--- 0.2073383331298828 seconds for one epoch ---
--- 1.9144577980041504 seconds for one epoch ---
--- 0.18102622032165527 seconds for one epoch ---
--- 1.9554691314697266 seconds for one epoch ---
--- 0.20417499542236328 seconds for one epoch ---
--- 2.007894277572632 seconds for one epoch ---
--- 0.19833803176879883 seconds for one epoch ---
--- 1.9313979148864746 seconds for one epoch ---
--- 0.18827390670776367 seconds for one epoch ---
--- 2.0877602100372314 seconds for one epoch ---
--- 0.24425268173217773 seconds for one epoch ---
--- 1.9974126815795898 seconds for one epoch ---
--- 0.18286705017089844 seconds for one epoch ---
--- 1.9449810981750488 seconds for one epoch ---
--- 0.19858694076538086 seconds for one epoch ---
--- 1.9827959537506104 seconds for one epoch ---
--- 0.19655299186706543 seconds for one epoch ---
--- 1.9597225189208984 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9843141]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.415965]
 [ -0.      ]]
--- 0.2827026844024658 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4313.2177734375, (1380.926, 1.330609, 2930.5605, 0.40036145)
   validation loss 849.6312255859375, (564.40845, 0.22871718, 284.5937, 0.40036145)
decoder loss ratio: 21866.163103, decoder SINDy loss  ratio: 0.614336
--- 0.17881178855895996 seconds for one epoch ---
--- 0.17964720726013184 seconds for one epoch ---
--- 2.228734016418457 seconds for one epoch ---
--- 0.20076847076416016 seconds for one epoch ---
--- 2.0292837619781494 seconds for one epoch ---
--- 0.18476200103759766 seconds for one epoch ---
--- 2.2053887844085693 seconds for one epoch ---
--- 0.20714139938354492 seconds for one epoch ---
--- 2.088202953338623 seconds for one epoch ---
--- 0.20427823066711426 seconds for one epoch ---
--- 1.966266393661499 seconds for one epoch ---
--- 0.20751667022705078 seconds for one epoch ---
--- 2.202634334564209 seconds for one epoch ---
--- 0.17691540718078613 seconds for one epoch ---
--- 2.3341550827026367 seconds for one epoch ---
--- 0.221663236618042 seconds for one epoch ---
--- 2.268590211868286 seconds for one epoch ---
--- 0.2306041717529297 seconds for one epoch ---
--- 2.236936569213867 seconds for one epoch ---
--- 0.19060468673706055 seconds for one epoch ---
--- 2.2728629112243652 seconds for one epoch ---
--- 0.190077543258667 seconds for one epoch ---
--- 2.21724534034729 seconds for one epoch ---
--- 0.239915132522583 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9844328]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.451404]
 [  0.      ]]
--- 0.17738866806030273 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1964.17236328125, (899.8003, 0.8910633, 1063.0798, 0.40113375)
   validation loss 796.4609375, (530.1914, 0.25047168, 265.61795, 0.40113375)
decoder loss ratio: 20540.535531, decoder SINDy loss  ratio: 0.573374
--- 0.1782064437866211 seconds for one epoch ---
--- 2.203810214996338 seconds for one epoch ---
--- 0.2835690975189209 seconds for one epoch ---
--- 2.230719566345215 seconds for one epoch ---
--- 0.18311429023742676 seconds for one epoch ---
--- 2.1466994285583496 seconds for one epoch ---
--- 0.21616363525390625 seconds for one epoch ---
--- 2.042577028274536 seconds for one epoch ---
--- 0.17737174034118652 seconds for one epoch ---
--- 1.9781479835510254 seconds for one epoch ---
--- 0.23662471771240234 seconds for one epoch ---
--- 2.0550856590270996 seconds for one epoch ---
--- 0.2297506332397461 seconds for one epoch ---
--- 2.202605962753296 seconds for one epoch ---
--- 0.20208358764648438 seconds for one epoch ---
--- 2.166787624359131 seconds for one epoch ---
--- 0.18148303031921387 seconds for one epoch ---
--- 2.0497236251831055 seconds for one epoch ---
--- 0.3049960136413574 seconds for one epoch ---
--- 2.0272598266601562 seconds for one epoch ---
--- 0.2587733268737793 seconds for one epoch ---
--- 2.0183894634246826 seconds for one epoch ---
--- 0.1969759464263916 seconds for one epoch ---
--- 2.087341547012329 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98454154]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.48459]
 [  0.     ]]
--- 0.19507670402526855 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4504.55517578125, (1278.1089, 4.444559, 3221.5999, 0.40189996)
   validation loss 764.7182006835938, (480.4982, 0.2714927, 283.5466, 0.40189996)
decoder loss ratio: 18615.334429, decoder SINDy loss  ratio: 0.612075
THRESHOLDING: 1 active coefficients
--- 2.2614259719848633 seconds for one epoch ---
--- 0.24642395973205566 seconds for one epoch ---
--- 2.0978524684906006 seconds for one epoch ---
--- 0.16700482368469238 seconds for one epoch ---
--- 1.983666181564331 seconds for one epoch ---
--- 0.21857881546020508 seconds for one epoch ---
--- 2.115574359893799 seconds for one epoch ---
--- 0.23024678230285645 seconds for one epoch ---
--- 2.058102607727051 seconds for one epoch ---
--- 0.2347567081451416 seconds for one epoch ---
--- 1.9892737865447998 seconds for one epoch ---
--- 0.21195149421691895 seconds for one epoch ---
--- 2.0767440795898438 seconds for one epoch ---
--- 0.22063684463500977 seconds for one epoch ---
--- 1.993809461593628 seconds for one epoch ---
--- 0.20195865631103516 seconds for one epoch ---
--- 2.0458059310913086 seconds for one epoch ---
--- 0.23798227310180664 seconds for one epoch ---
--- 2.2144031524658203 seconds for one epoch ---
--- 0.1876819133758545 seconds for one epoch ---
--- 2.201180934906006 seconds for one epoch ---
--- 0.19716167449951172 seconds for one epoch ---
--- 2.4587998390197754 seconds for one epoch ---
--- 0.21888422966003418 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98462975]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.512134]
 [  0.      ]]
--- 0.17353463172912598 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2948.304931640625, (1772.5792, 0.60342616, 1174.7198, 0.40263245)
   validation loss 799.7971801757812, (529.70575, 0.25051016, 269.4383, 0.40263245)
decoder loss ratio: 20521.720346, decoder SINDy loss  ratio: 0.581620
--- 0.18153142929077148 seconds for one epoch ---
--- 2.0122108459472656 seconds for one epoch ---
--- 0.1850590705871582 seconds for one epoch ---
--- 1.985917091369629 seconds for one epoch ---
--- 0.20487546920776367 seconds for one epoch ---
--- 1.9727051258087158 seconds for one epoch ---
--- 0.20445656776428223 seconds for one epoch ---
--- 1.985121250152588 seconds for one epoch ---
--- 0.19595694541931152 seconds for one epoch ---
--- 1.9789960384368896 seconds for one epoch ---
--- 0.1643059253692627 seconds for one epoch ---
--- 2.0519680976867676 seconds for one epoch ---
--- 0.21111011505126953 seconds for one epoch ---
--- 2.085736036300659 seconds for one epoch ---
--- 0.2122342586517334 seconds for one epoch ---
--- 2.0434682369232178 seconds for one epoch ---
--- 0.18599319458007812 seconds for one epoch ---
--- 2.1737546920776367 seconds for one epoch ---
--- 0.21157097816467285 seconds for one epoch ---
--- 2.0589773654937744 seconds for one epoch ---
--- 0.21105527877807617 seconds for one epoch ---
--- 2.0423805713653564 seconds for one epoch ---
--- 0.1984856128692627 seconds for one epoch ---
--- 2.1108877658843994 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9847326]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.544345]
 [ -0.      ]]
--- 0.17248129844665527 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2531.986328125, (1142.4731, 1.227404, 1387.8823, 0.4032929)
   validation loss 932.3679809570312, (635.3072, 0.2560888, 296.40137, 0.4032929)
decoder loss ratio: 24612.903480, decoder SINDy loss  ratio: 0.639824
--- 0.16828703880310059 seconds for one epoch ---
--- 0.19843244552612305 seconds for one epoch ---
--- 2.1094932556152344 seconds for one epoch ---
--- 0.2349381446838379 seconds for one epoch ---
--- 1.9927582740783691 seconds for one epoch ---
--- 0.1835472583770752 seconds for one epoch ---
--- 2.1498076915740967 seconds for one epoch ---
--- 0.18043231964111328 seconds for one epoch ---
--- 1.968620777130127 seconds for one epoch ---
--- 0.19390082359313965 seconds for one epoch ---
--- 2.160600423812866 seconds for one epoch ---
--- 0.23860549926757812 seconds for one epoch ---
--- 2.0784006118774414 seconds for one epoch ---
--- 0.1726837158203125 seconds for one epoch ---
--- 2.2440345287323 seconds for one epoch ---
--- 0.20280027389526367 seconds for one epoch ---
--- 2.3413641452789307 seconds for one epoch ---
--- 0.1654338836669922 seconds for one epoch ---
--- 2.4337923526763916 seconds for one epoch ---
--- 0.24999785423278809 seconds for one epoch ---
--- 2.4350461959838867 seconds for one epoch ---
--- 0.2285008430480957 seconds for one epoch ---
--- 2.2333812713623047 seconds for one epoch ---
--- 0.19755315780639648 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9848249]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.573613]
 [ -0.      ]]
--- 0.20286130905151367 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1830.4202880859375, (1050.4398, 0.46968246, 779.10675, 0.40398023)
   validation loss 797.1149291992188, (469.84378, 0.27751446, 326.58966, 0.40398023)
decoder loss ratio: 18202.563742, decoder SINDy loss  ratio: 0.704990
--- 0.23505544662475586 seconds for one epoch ---
--- 2.3281781673431396 seconds for one epoch ---
--- 0.2142925262451172 seconds for one epoch ---
--- 2.246347188949585 seconds for one epoch ---
--- 0.18396687507629395 seconds for one epoch ---
--- 2.3465521335601807 seconds for one epoch ---
--- 0.17974281311035156 seconds for one epoch ---
--- 2.086277723312378 seconds for one epoch ---
--- 0.1968519687652588 seconds for one epoch ---
--- 2.149961233139038 seconds for one epoch ---
--- 0.2089996337890625 seconds for one epoch ---
--- 2.070206642150879 seconds for one epoch ---
--- 0.20393824577331543 seconds for one epoch ---
--- 2.0457799434661865 seconds for one epoch ---
--- 0.18645524978637695 seconds for one epoch ---
--- 2.1301841735839844 seconds for one epoch ---
--- 0.2320241928100586 seconds for one epoch ---
--- 2.1740529537200928 seconds for one epoch ---
--- 0.16890239715576172 seconds for one epoch ---
--- 1.9980533123016357 seconds for one epoch ---
--- 0.20148348808288574 seconds for one epoch ---
--- 2.0793440341949463 seconds for one epoch ---
--- 0.1915283203125 seconds for one epoch ---
--- 2.151925802230835 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9849112]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.601072]
 [ -0.      ]]
--- 0.1740550994873047 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1914.228759765625, (960.9102, 0.73900485, 952.1749, 0.40459225)
   validation loss 892.6453247070312, (615.43097, 0.27100042, 276.5388, 0.40459225)
decoder loss ratio: 23842.864183, decoder SINDy loss  ratio: 0.596948
--- 0.17061948776245117 seconds for one epoch ---
--- 0.23883533477783203 seconds for one epoch ---
--- 2.2737069129943848 seconds for one epoch ---
--- 0.20168066024780273 seconds for one epoch ---
--- 2.2911033630371094 seconds for one epoch ---
--- 0.20881319046020508 seconds for one epoch ---
--- 2.2832231521606445 seconds for one epoch ---
--- 0.20288944244384766 seconds for one epoch ---
--- 2.467775583267212 seconds for one epoch ---
--- 0.22602510452270508 seconds for one epoch ---
--- 2.2656004428863525 seconds for one epoch ---
--- 0.23271775245666504 seconds for one epoch ---
--- 2.2371881008148193 seconds for one epoch ---
--- 0.19968366622924805 seconds for one epoch ---
--- 2.3747425079345703 seconds for one epoch ---
--- 0.21213936805725098 seconds for one epoch ---
--- 2.242274761199951 seconds for one epoch ---
--- 0.2185988426208496 seconds for one epoch ---
--- 2.3717799186706543 seconds for one epoch ---
--- 0.19320178031921387 seconds for one epoch ---
--- 2.4884908199310303 seconds for one epoch ---
--- 0.19616198539733887 seconds for one epoch ---
--- 2.480849027633667 seconds for one epoch ---
--- 0.22579622268676758 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98501384]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.634058]
 [  0.      ]]
--- 0.19101428985595703 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2165.35986328125, (1317.8304, 1.2443224, 845.88, 0.40539417)
   validation loss 825.7923583984375, (541.7533, 0.31541052, 283.31827, 0.40539417)
decoder loss ratio: 20988.463208, decoder SINDy loss  ratio: 0.611582
--- 0.20514559745788574 seconds for one epoch ---
--- 2.156484365463257 seconds for one epoch ---
--- 0.24588346481323242 seconds for one epoch ---
--- 2.131720781326294 seconds for one epoch ---
--- 0.2018146514892578 seconds for one epoch ---
--- 2.052887201309204 seconds for one epoch ---
--- 0.20025849342346191 seconds for one epoch ---
--- 2.1084036827087402 seconds for one epoch ---
--- 0.2403719425201416 seconds for one epoch ---
--- 2.1143581867218018 seconds for one epoch ---
--- 0.22377586364746094 seconds for one epoch ---
--- 2.096057176589966 seconds for one epoch ---
--- 0.20497512817382812 seconds for one epoch ---
--- 2.108323097229004 seconds for one epoch ---
--- 0.20209455490112305 seconds for one epoch ---
--- 2.0493197441101074 seconds for one epoch ---
--- 0.21617364883422852 seconds for one epoch ---
--- 2.1277904510498047 seconds for one epoch ---
--- 0.20272588729858398 seconds for one epoch ---
--- 2.084256172180176 seconds for one epoch ---
--- 0.24077820777893066 seconds for one epoch ---
--- 2.130147695541382 seconds for one epoch ---
--- 0.20392870903015137 seconds for one epoch ---
--- 2.110769271850586 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98510987]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.665889]
 [  0.      ]]
--- 0.22556805610656738 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4683.5966796875, (1116.6196, 1.8573517, 3564.7134, 0.4060895)
   validation loss 732.4424438476562, (457.4416, 0.3190713, 274.27576, 0.4060895)
decoder loss ratio: 17722.081325, decoder SINDy loss  ratio: 0.592063
--- 0.14628386497497559 seconds for one epoch ---
--- 0.1722426414489746 seconds for one epoch ---
--- 2.1653952598571777 seconds for one epoch ---
--- 0.22134852409362793 seconds for one epoch ---
--- 2.019289255142212 seconds for one epoch ---
--- 0.18435192108154297 seconds for one epoch ---
--- 2.0779922008514404 seconds for one epoch ---
--- 0.20787858963012695 seconds for one epoch ---
--- 2.1759517192840576 seconds for one epoch ---
--- 0.1642594337463379 seconds for one epoch ---
--- 2.1836509704589844 seconds for one epoch ---
--- 0.2104651927947998 seconds for one epoch ---
--- 2.1219139099121094 seconds for one epoch ---
--- 0.23256468772888184 seconds for one epoch ---
--- 2.067042350769043 seconds for one epoch ---
--- 0.23191094398498535 seconds for one epoch ---
--- 2.0642354488372803 seconds for one epoch ---
--- 0.19012951850891113 seconds for one epoch ---
--- 2.1438419818878174 seconds for one epoch ---
--- 0.2056276798248291 seconds for one epoch ---
--- 2.131150960922241 seconds for one epoch ---
--- 0.2452526092529297 seconds for one epoch ---
--- 2.115602493286133 seconds for one epoch ---
--- 0.19634437561035156 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98521215]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.699611]
 [  0.      ]]
--- 0.18496370315551758 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4932.37841796875, (1746.8705, 1.1187772, 3183.9827, 0.4069213)
   validation loss 873.9081420898438, (588.92975, 0.3102869, 284.2612, 0.4069213)
decoder loss ratio: 22816.160885, decoder SINDy loss  ratio: 0.613618
--- 0.16950106620788574 seconds for one epoch ---
--- 2.36226224899292 seconds for one epoch ---
--- 0.2119917869567871 seconds for one epoch ---
--- 2.657632827758789 seconds for one epoch ---
--- 0.25984930992126465 seconds for one epoch ---
--- 2.284085988998413 seconds for one epoch ---
--- 0.1895885467529297 seconds for one epoch ---
--- 2.387906074523926 seconds for one epoch ---
--- 0.18851423263549805 seconds for one epoch ---
--- 2.4438719749450684 seconds for one epoch ---
--- 0.20065808296203613 seconds for one epoch ---
--- 2.4049010276794434 seconds for one epoch ---
--- 0.21836256980895996 seconds for one epoch ---
--- 2.353271245956421 seconds for one epoch ---
--- 0.18924927711486816 seconds for one epoch ---
--- 2.060670852661133 seconds for one epoch ---
--- 0.19367384910583496 seconds for one epoch ---
--- 2.090552568435669 seconds for one epoch ---
--- 0.2275831699371338 seconds for one epoch ---
--- 2.245225667953491 seconds for one epoch ---
--- 0.19823408126831055 seconds for one epoch ---
--- 2.1579179763793945 seconds for one epoch ---
--- 0.18209314346313477 seconds for one epoch ---
--- 2.1420300006866455 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98530656]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.731141]
 [ -0.      ]]
--- 0.2611992359161377 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1346.380615234375, (522.98157, 0.844285, 822.14703, 0.40767667)
   validation loss 762.2966918945312, (463.35547, 0.3109397, 298.22266, 0.40767667)
decoder loss ratio: 17951.195280, decoder SINDy loss  ratio: 0.643756
--- 0.17470216751098633 seconds for one epoch ---
--- 0.19915080070495605 seconds for one epoch ---
--- 2.168789863586426 seconds for one epoch ---
--- 0.2051701545715332 seconds for one epoch ---
--- 2.0803496837615967 seconds for one epoch ---
--- 0.21025776863098145 seconds for one epoch ---
--- 2.175449848175049 seconds for one epoch ---
--- 0.308319091796875 seconds for one epoch ---
--- 2.1239993572235107 seconds for one epoch ---
--- 0.19182586669921875 seconds for one epoch ---
--- 2.145253896713257 seconds for one epoch ---
--- 0.2074127197265625 seconds for one epoch ---
--- 2.1501004695892334 seconds for one epoch ---
--- 0.19966793060302734 seconds for one epoch ---
--- 2.0612688064575195 seconds for one epoch ---
--- 0.21761345863342285 seconds for one epoch ---
--- 2.1568191051483154 seconds for one epoch ---
--- 0.25120973587036133 seconds for one epoch ---
--- 2.102818250656128 seconds for one epoch ---
--- 0.2194957733154297 seconds for one epoch ---
--- 2.161303758621216 seconds for one epoch ---
--- 0.23062705993652344 seconds for one epoch ---
--- 2.0924055576324463 seconds for one epoch ---
--- 0.19875860214233398 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9853877]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.759009]
 [ -0.      ]]
--- 0.1461777687072754 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2281.612060546875, (979.87195, 1.2057261, 1300.1261, 0.4083233)
   validation loss 1285.1077880859375, (962.7564, 0.30853793, 321.63458, 0.4083233)
decoder loss ratio: 37298.854691, decoder SINDy loss  ratio: 0.694293
--- 0.22542548179626465 seconds for one epoch ---
--- 2.2766008377075195 seconds for one epoch ---
--- 0.24222445487976074 seconds for one epoch ---
--- 2.5700623989105225 seconds for one epoch ---
--- 0.20273566246032715 seconds for one epoch ---
--- 2.3743364810943604 seconds for one epoch ---
--- 0.2119579315185547 seconds for one epoch ---
--- 2.4016311168670654 seconds for one epoch ---
--- 0.22533130645751953 seconds for one epoch ---
--- 2.4449806213378906 seconds for one epoch ---
--- 0.22818899154663086 seconds for one epoch ---
--- 2.454000234603882 seconds for one epoch ---
--- 0.19259119033813477 seconds for one epoch ---
--- 2.504572868347168 seconds for one epoch ---
--- 0.20031213760375977 seconds for one epoch ---
--- 2.216200351715088 seconds for one epoch ---
--- 0.26898622512817383 seconds for one epoch ---
--- 2.336148977279663 seconds for one epoch ---
--- 0.18207001686096191 seconds for one epoch ---
--- 2.224395513534546 seconds for one epoch ---
--- 0.2303330898284912 seconds for one epoch ---
--- 2.1829240322113037 seconds for one epoch ---
--- 0.18909931182861328 seconds for one epoch ---
--- 2.2088027000427246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98546267]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.784496]
 [ -0.      ]]
--- 0.2711617946624756 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2784.429443359375, (1195.7418, 1.700237, 1586.5784, 0.4088223)
   validation loss 840.69921875, (549.8825, 0.3106939, 290.0972, 0.4088223)
decoder loss ratio: 21303.402972, decoder SINDy loss  ratio: 0.626216
--- 0.2458646297454834 seconds for one epoch ---
--- 0.17911219596862793 seconds for one epoch ---
--- 2.2974026203155518 seconds for one epoch ---
--- 0.20669889450073242 seconds for one epoch ---
--- 2.62296724319458 seconds for one epoch ---
--- 0.20602178573608398 seconds for one epoch ---
--- 2.5785202980041504 seconds for one epoch ---
--- 0.24126052856445312 seconds for one epoch ---
--- 2.4464821815490723 seconds for one epoch ---
--- 0.24494671821594238 seconds for one epoch ---
--- 2.4408559799194336 seconds for one epoch ---
--- 0.23153352737426758 seconds for one epoch ---
--- 2.3773300647735596 seconds for one epoch ---
--- 0.23910188674926758 seconds for one epoch ---
--- 2.5164906978607178 seconds for one epoch ---
--- 0.21935081481933594 seconds for one epoch ---
--- 2.5461480617523193 seconds for one epoch ---
--- 0.1807117462158203 seconds for one epoch ---
--- 2.3595011234283447 seconds for one epoch ---
--- 0.2143700122833252 seconds for one epoch ---
--- 2.209536552429199 seconds for one epoch ---
--- 0.2483234405517578 seconds for one epoch ---
--- 2.1205689907073975 seconds for one epoch ---
--- 0.19759535789489746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9855297]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.808112]
 [  0.      ]]
--- 0.16538405418395996 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4911.9814453125, (3110.2144, 2.179744, 1799.1783, 0.40940648)
   validation loss 804.3621826171875, (509.313, 0.29559183, 294.3442, 0.40940648)
decoder loss ratio: 19731.669372, decoder SINDy loss  ratio: 0.635383
--- 0.2460784912109375 seconds for one epoch ---
--- 2.233876943588257 seconds for one epoch ---
--- 0.19488120079040527 seconds for one epoch ---
--- 2.296828031539917 seconds for one epoch ---
--- 0.23829984664916992 seconds for one epoch ---
--- 2.0938198566436768 seconds for one epoch ---
--- 0.18143510818481445 seconds for one epoch ---
--- 2.1428723335266113 seconds for one epoch ---
--- 0.19700908660888672 seconds for one epoch ---
--- 2.322946548461914 seconds for one epoch ---
--- 0.23649001121520996 seconds for one epoch ---
--- 2.253401041030884 seconds for one epoch ---
--- 0.23708152770996094 seconds for one epoch ---
--- 2.260748863220215 seconds for one epoch ---
--- 0.17475461959838867 seconds for one epoch ---
--- 2.2432284355163574 seconds for one epoch ---
--- 0.1935124397277832 seconds for one epoch ---
--- 2.2239060401916504 seconds for one epoch ---
--- 0.20774435997009277 seconds for one epoch ---
--- 2.205925464630127 seconds for one epoch ---
--- 0.17742490768432617 seconds for one epoch ---
--- 2.119180679321289 seconds for one epoch ---
--- 0.5794613361358643 seconds for one epoch ---
--- 2.187725067138672 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9855999]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.83244]
 [  0.     ]]
--- 0.2049860954284668 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2031.0357666015625, (739.175, 1.3280729, 1290.1228, 0.40996018)
   validation loss 749.8574829101562, (455.86472, 0.3132105, 293.26956, 0.40996018)
decoder loss ratio: 17660.990497, decoder SINDy loss  ratio: 0.633064
--- 0.17981505393981934 seconds for one epoch ---
--- 0.21599054336547852 seconds for one epoch ---
--- 2.392021417617798 seconds for one epoch ---
--- 0.23480796813964844 seconds for one epoch ---
--- 2.437781810760498 seconds for one epoch ---
--- 0.1594545841217041 seconds for one epoch ---
--- 2.4299850463867188 seconds for one epoch ---
--- 0.18114995956420898 seconds for one epoch ---
--- 2.539273500442505 seconds for one epoch ---
--- 0.19272780418395996 seconds for one epoch ---
--- 2.440756320953369 seconds for one epoch ---
--- 0.17882585525512695 seconds for one epoch ---
--- 2.47790265083313 seconds for one epoch ---
--- 0.25290775299072266 seconds for one epoch ---
--- 2.492767810821533 seconds for one epoch ---
--- 0.18961071968078613 seconds for one epoch ---
--- 2.498187303543091 seconds for one epoch ---
--- 0.24614477157592773 seconds for one epoch ---
--- 2.536329507827759 seconds for one epoch ---
--- 0.24725842475891113 seconds for one epoch ---
--- 2.438276529312134 seconds for one epoch ---
--- 0.22507929801940918 seconds for one epoch ---
--- 2.4696238040924072 seconds for one epoch ---
--- 0.17964482307434082 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9856734]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.858748]
 [  0.      ]]
--- 0.1603837013244629 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2994.492431640625, (1592.0383, 0.4647249, 1401.5787, 0.41059828)
   validation loss 908.1400756835938, (590.54755, 0.31279257, 316.86914, 0.41059828)
decoder loss ratio: 22878.837183, decoder SINDy loss  ratio: 0.684007
--- 0.17079710960388184 seconds for one epoch ---
--- 2.237757682800293 seconds for one epoch ---
--- 0.21657490730285645 seconds for one epoch ---
--- 2.2005672454833984 seconds for one epoch ---
--- 0.20521211624145508 seconds for one epoch ---
--- 2.1858630180358887 seconds for one epoch ---
--- 0.21491098403930664 seconds for one epoch ---
--- 2.258314609527588 seconds for one epoch ---
--- 0.27652859687805176 seconds for one epoch ---
--- 2.1424448490142822 seconds for one epoch ---
--- 0.1900479793548584 seconds for one epoch ---
--- 2.2007532119750977 seconds for one epoch ---
--- 0.2230226993560791 seconds for one epoch ---
--- 2.163651704788208 seconds for one epoch ---
--- 0.23205161094665527 seconds for one epoch ---
--- 2.220782995223999 seconds for one epoch ---
--- 0.19800806045532227 seconds for one epoch ---
--- 2.2389979362487793 seconds for one epoch ---
--- 0.18497109413146973 seconds for one epoch ---
--- 2.2758522033691406 seconds for one epoch ---
--- 0.203948974609375 seconds for one epoch ---
--- 2.199831008911133 seconds for one epoch ---
--- 0.20300817489624023 seconds for one epoch ---
--- 2.1777656078338623 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9857528]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.887274]
 [ -0.      ]]
--- 0.1945195198059082 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2118.48193359375, (602.31494, 2.809909, 1512.9457, 0.41126606)
   validation loss 923.6262817382812, (602.00964, 0.33290938, 320.8725, 0.41126606)
decoder loss ratio: 23322.898726, decoder SINDy loss  ratio: 0.692648
--- 0.1570127010345459 seconds for one epoch ---
--- 0.17713499069213867 seconds for one epoch ---
--- 2.1910924911499023 seconds for one epoch ---
--- 0.23730111122131348 seconds for one epoch ---
--- 2.2645153999328613 seconds for one epoch ---
--- 0.19025278091430664 seconds for one epoch ---
--- 2.3284852504730225 seconds for one epoch ---
--- 0.1863541603088379 seconds for one epoch ---
--- 2.2354767322540283 seconds for one epoch ---
--- 0.18821167945861816 seconds for one epoch ---
--- 2.2158162593841553 seconds for one epoch ---
--- 0.18026113510131836 seconds for one epoch ---
--- 2.514423131942749 seconds for one epoch ---
--- 0.19481801986694336 seconds for one epoch ---
--- 2.7052385807037354 seconds for one epoch ---
--- 0.17894792556762695 seconds for one epoch ---
--- 2.471240758895874 seconds for one epoch ---
--- 0.196486234664917 seconds for one epoch ---
--- 2.479511022567749 seconds for one epoch ---
--- 0.19026899337768555 seconds for one epoch ---
--- 2.776634454727173 seconds for one epoch ---
--- 0.16977429389953613 seconds for one epoch ---
--- 2.450212001800537 seconds for one epoch ---
--- 0.1990363597869873 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9858341]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.916454]
 [ -0.      ]]
--- 0.19694828987121582 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1808.7525634765625, (646.3469, 1.9834341, 1160.0103, 0.41197672)
   validation loss 866.4898071289062, (583.6001, 0.3061513, 282.17157, 0.41197672)
decoder loss ratio: 22609.680958, decoder SINDy loss  ratio: 0.609107
--- 0.1965794563293457 seconds for one epoch ---
--- 2.4622323513031006 seconds for one epoch ---
--- 0.23984217643737793 seconds for one epoch ---
--- 2.5203845500946045 seconds for one epoch ---
--- 0.24125289916992188 seconds for one epoch ---
--- 2.2512450218200684 seconds for one epoch ---
--- 0.21011924743652344 seconds for one epoch ---
--- 2.353529930114746 seconds for one epoch ---
--- 0.21753573417663574 seconds for one epoch ---
--- 2.2242326736450195 seconds for one epoch ---
--- 0.19654417037963867 seconds for one epoch ---
--- 2.2030344009399414 seconds for one epoch ---
--- 0.23738455772399902 seconds for one epoch ---
--- 2.2344956398010254 seconds for one epoch ---
--- 0.19472455978393555 seconds for one epoch ---
--- 2.2690236568450928 seconds for one epoch ---
--- 0.18885302543640137 seconds for one epoch ---
--- 2.201329231262207 seconds for one epoch ---
--- 0.19882440567016602 seconds for one epoch ---
--- 2.2260470390319824 seconds for one epoch ---
--- 0.22392940521240234 seconds for one epoch ---
--- 2.1564652919769287 seconds for one epoch ---
--- 0.19622039794921875 seconds for one epoch ---
--- 2.3087849617004395 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98589325]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.937959]
 [ -0.      ]]
--- 0.23716497421264648 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2731.27685546875, (1434.9054, 1.9580746, 1294.0006, 0.41249308)
   validation loss 830.301025390625, (531.8128, 0.35900646, 297.71677, 0.41249308)
decoder loss ratio: 20603.351340, decoder SINDy loss  ratio: 0.642664
--- 1.0759942531585693 seconds for one epoch ---
--- 0.18923449516296387 seconds for one epoch ---
--- 2.53415584564209 seconds for one epoch ---
--- 0.19525551795959473 seconds for one epoch ---
--- 2.595583438873291 seconds for one epoch ---
--- 0.21794390678405762 seconds for one epoch ---
--- 2.5538408756256104 seconds for one epoch ---
--- 0.2025606632232666 seconds for one epoch ---
--- 2.559171438217163 seconds for one epoch ---
--- 0.20835161209106445 seconds for one epoch ---
--- 2.6167049407958984 seconds for one epoch ---
--- 0.25359034538269043 seconds for one epoch ---
--- 2.514779806137085 seconds for one epoch ---
--- 0.22062468528747559 seconds for one epoch ---
--- 2.614082098007202 seconds for one epoch ---
--- 0.20331501960754395 seconds for one epoch ---
--- 2.776078224182129 seconds for one epoch ---
--- 0.19901299476623535 seconds for one epoch ---
--- 2.580057382583618 seconds for one epoch ---
--- 0.23301935195922852 seconds for one epoch ---
--- 2.5568349361419678 seconds for one epoch ---
--- 0.2227480411529541 seconds for one epoch ---
--- 2.437863826751709 seconds for one epoch ---
--- 0.29072999954223633 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98596597]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.964768]
 [  0.      ]]
--- 0.13843059539794922 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5274.65869140625, (2167.849, 1.0070889, 3105.3894, 0.4130942)
   validation loss 948.56298828125, (666.3293, 0.33386782, 281.4868, 0.4130942)
decoder loss ratio: 25814.753287, decoder SINDy loss  ratio: 0.607629
--- 0.1748485565185547 seconds for one epoch ---
--- 2.2387149333953857 seconds for one epoch ---
--- 0.19503283500671387 seconds for one epoch ---
--- 2.308652639389038 seconds for one epoch ---
--- 0.21894311904907227 seconds for one epoch ---
--- 2.265977621078491 seconds for one epoch ---
--- 0.21109867095947266 seconds for one epoch ---
--- 2.3733973503112793 seconds for one epoch ---
--- 0.22879314422607422 seconds for one epoch ---
--- 2.295673370361328 seconds for one epoch ---
--- 0.23822283744812012 seconds for one epoch ---
--- 2.3060994148254395 seconds for one epoch ---
--- 0.1838359832763672 seconds for one epoch ---
--- 2.252516508102417 seconds for one epoch ---
--- 0.17736482620239258 seconds for one epoch ---
--- 2.25820255279541 seconds for one epoch ---
--- 0.18682050704956055 seconds for one epoch ---
--- 2.3996357917785645 seconds for one epoch ---
--- 0.23653793334960938 seconds for one epoch ---
--- 2.260003089904785 seconds for one epoch ---
--- 0.19034385681152344 seconds for one epoch ---
--- 2.266444683074951 seconds for one epoch ---
--- 0.2311396598815918 seconds for one epoch ---
--- 2.382169723510742 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9860401]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.992583]
 [  0.      ]]
--- 0.22463726997375488 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3162.588134765625, (1666.4401, 1.6067232, 1494.1276, 0.4137418)
   validation loss 796.5859985351562, (509.63498, 0.32434663, 286.21292, 0.4137418)
decoder loss ratio: 19744.143861, decoder SINDy loss  ratio: 0.617831
--- 0.1497209072113037 seconds for one epoch ---
--- 0.17792558670043945 seconds for one epoch ---
--- 2.5137715339660645 seconds for one epoch ---
--- 0.22315597534179688 seconds for one epoch ---
--- 2.4399802684783936 seconds for one epoch ---
--- 0.19213247299194336 seconds for one epoch ---
--- 2.5411171913146973 seconds for one epoch ---
--- 0.2418503761291504 seconds for one epoch ---
--- 2.698554754257202 seconds for one epoch ---
--- 0.19460320472717285 seconds for one epoch ---
--- 2.6541085243225098 seconds for one epoch ---
--- 0.29926466941833496 seconds for one epoch ---
--- 2.433755874633789 seconds for one epoch ---
--- 0.17158937454223633 seconds for one epoch ---
--- 2.6584837436676025 seconds for one epoch ---
--- 0.18248891830444336 seconds for one epoch ---
--- 2.5795950889587402 seconds for one epoch ---
--- 0.25649452209472656 seconds for one epoch ---
--- 2.5290825366973877 seconds for one epoch ---
--- 0.22504782676696777 seconds for one epoch ---
--- 2.4367401599884033 seconds for one epoch ---
--- 0.21131420135498047 seconds for one epoch ---
--- 2.5156359672546387 seconds for one epoch ---
--- 0.19663262367248535 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9861013]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.015947]
 [  0.      ]]
--- 0.144089937210083 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2272.9541015625, (1167.0092, 1.5212562, 1104.0094, 0.41432333)
   validation loss 912.8016357421875, (590.86066, 0.32169032, 321.205, 0.41432333)
decoder loss ratio: 22890.967621, decoder SINDy loss  ratio: 0.693366
--- 0.19696497917175293 seconds for one epoch ---
--- 2.3869833946228027 seconds for one epoch ---
--- 0.22401857376098633 seconds for one epoch ---
--- 2.289984941482544 seconds for one epoch ---
--- 0.2089536190032959 seconds for one epoch ---
--- 2.413534641265869 seconds for one epoch ---
--- 0.1789076328277588 seconds for one epoch ---
--- 2.2928900718688965 seconds for one epoch ---
--- 0.2433321475982666 seconds for one epoch ---
--- 2.2775285243988037 seconds for one epoch ---
--- 0.18897724151611328 seconds for one epoch ---
--- 2.2863597869873047 seconds for one epoch ---
--- 0.2265944480895996 seconds for one epoch ---
--- 2.4450206756591797 seconds for one epoch ---
--- 0.2944912910461426 seconds for one epoch ---
--- 2.2417001724243164 seconds for one epoch ---
--- 0.19633078575134277 seconds for one epoch ---
--- 2.247734785079956 seconds for one epoch ---
--- 0.19988298416137695 seconds for one epoch ---
--- 2.3178789615631104 seconds for one epoch ---
--- 0.19980788230895996 seconds for one epoch ---
--- 2.363673686981201 seconds for one epoch ---
--- 0.18376779556274414 seconds for one epoch ---
--- 2.2743544578552246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98615074]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.03407]
 [ -0.     ]]
--- 0.19351410865783691 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2318.542236328125, (1018.91766, 0.9171418, 1298.2927, 0.41472808)
   validation loss 1142.4918212890625, (837.0455, 0.32674086, 304.70496, 0.41472808)
decoder loss ratio: 32428.594729, decoder SINDy loss  ratio: 0.657749
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9861522]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.034807]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1190.43701171875, (630.5707, 0.6746749, 559.1917, 0.41477242)
   validation loss 816.9476318359375, (539.06836, 0.31512535, 277.56415, 0.41477242)
decoder loss ratio: 20884.444106, decoder SINDy loss  ratio: 0.599161
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98619264]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.04935]
 [  0.     ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1313.6632080078125, (805.7499, 0.43236074, 507.481, 0.4150629)
   validation loss 1049.4249267578125, (788.47644, 0.09703424, 260.8514, 0.4150629)
decoder loss ratio: 30546.946158, decoder SINDy loss  ratio: 0.563084
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98601156]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.994788]
 [  0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.6861572265625, (337.06723, 0.26341906, 496.35553, 0.4134159)
   validation loss 469.44464111328125, (251.4685, 0.07146621, 217.90465, 0.4134159)
decoder loss ratio: 9742.326486, decoder SINDy loss  ratio: 0.470378
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98574626]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.867163]
 [ -0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.1756591796875, (286.54327, 0.21578643, 478.4166, 0.41109964)
   validation loss 446.3109436035156, (224.75273, 0.07178903, 221.48642, 0.41109964)
decoder loss ratio: 8707.310999, decoder SINDy loss  ratio: 0.478110
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98544645]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.72699]
 [  0.     ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 965.6285400390625, (489.81924, 0.20798892, 475.60135, 0.40862295)
   validation loss 649.7509765625, (417.6441, 0.06520888, 232.04167, 0.40862295)
decoder loss ratio: 16180.257651, decoder SINDy loss  ratio: 0.500895
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98515797]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.631705]
 [  0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.0902099609375, (265.77722, 0.1782461, 472.13477, 0.40634432)
   validation loss 416.60302734375, (198.01868, 0.068666, 218.51567, 0.40634432)
decoder loss ratio: 7671.587313, decoder SINDy loss  ratio: 0.471697
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98484874]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.557381]
 [ -0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.5150146484375, (254.3148, 0.16704403, 471.0332, 0.40403667)
   validation loss 404.58734130859375, (187.53557, 0.06415438, 216.98761, 0.40403667)
decoder loss ratio: 7265.453490, decoder SINDy loss  ratio: 0.468398
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9845668]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.499211]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.9528198242188, (243.12793, 0.15504004, 471.66986, 0.40200374)
   validation loss 390.84674072265625, (175.02245, 0.07020407, 215.7541, 0.40200374)
decoder loss ratio: 6780.673398, decoder SINDy loss  ratio: 0.465736
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9842892]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.425712]
 [  0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.6068115234375, (429.41492, 0.16131793, 467.03058, 0.40007773)
   validation loss 569.479736328125, (343.84042, 0.06756618, 225.57176, 0.40007773)
decoder loss ratio: 13320.974943, decoder SINDy loss  ratio: 0.486928
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98403615]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.33689]
 [ -0.     ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.5750732421875, (239.50299, 0.16151665, 467.91058, 0.39839122)
   validation loss 389.68084716796875, (173.8697, 0.07344461, 215.73769, 0.39839122)
decoder loss ratio: 6736.014231, decoder SINDy loss  ratio: 0.465700
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.983786]
 [0.      ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.27718]
 [  0.     ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 933.864501953125, (468.127, 0.15958217, 465.5779, 0.39677313)
   validation loss 602.8764038085938, (375.9345, 0.07172112, 226.87018, 0.39677313)
decoder loss ratio: 14564.355540, decoder SINDy loss  ratio: 0.489731
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9835532]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.138583]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 808.3729248046875, (341.6369, 0.19708373, 466.53894, 0.39537796)
   validation loss 466.52056884765625, (250.42177, 0.060836535, 216.03798, 0.39537796)
decoder loss ratio: 9701.774051, decoder SINDy loss  ratio: 0.466348
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9833479]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.13402]
 [  0.     ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 858.3060302734375, (367.3825, 0.15607381, 490.7675, 0.39408365)
   validation loss 516.174560546875, (299.1066, 0.07396462, 216.99397, 0.39408365)
decoder loss ratio: 11587.908875, decoder SINDy loss  ratio: 0.468412
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98313713]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.086426]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.4657592773438, (280.69183, 0.13777749, 461.63614, 0.39282426)
   validation loss 427.6250915527344, (208.85709, 0.07527922, 218.69273, 0.39282426)
decoder loss ratio: 8091.486111, decoder SINDy loss  ratio: 0.472079
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829972]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.985637]
 [  0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.8964233398438, (230.84721, 0.15098536, 464.89822, 0.39200392)
   validation loss 384.5714416503906, (169.6097, 0.07713259, 214.88461, 0.39200392)
decoder loss ratio: 6570.974057, decoder SINDy loss  ratio: 0.463859
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828508]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.903695]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.5052490234375, (482.33707, 0.149398, 460.0188, 0.39115372)
   validation loss 612.0499267578125, (385.64127, 0.08124072, 226.32742, 0.39115372)
decoder loss ratio: 14940.412142, decoder SINDy loss  ratio: 0.488560
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9826795]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.977734]
 [  0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1064.1044921875, (601.1833, 0.14116709, 462.7801, 0.39020482)
   validation loss 728.5413818359375, (496.04865, 0.076198585, 232.41655, 0.39020482)
decoder loss ratio: 19217.785686, decoder SINDy loss  ratio: 0.501704
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98258406]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.961102]
 [ -0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.212646484375, (247.70833, 0.140575, 459.3637, 0.38967547)
   validation loss 394.1748046875, (177.30745, 0.079924725, 216.78745, 0.38967547)
decoder loss ratio: 6869.198407, decoder SINDy loss  ratio: 0.467966
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98247504]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.929912]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.8802490234375, (258.93185, 0.13878286, 458.80957, 0.38907328)
   validation loss 407.60888671875, (190.40395, 0.07507293, 217.12988, 0.38907328)
decoder loss ratio: 7376.579421, decoder SINDy loss  ratio: 0.468705
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98238075]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.875834]
 [  0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 917.9269409179688, (465.02875, 0.14156161, 452.75662, 0.38856992)
   validation loss 600.101806640625, (374.09967, 0.07725833, 225.92488, 0.38856992)
decoder loss ratio: 14493.270697, decoder SINDy loss  ratio: 0.487691
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823236]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.873304]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.5247802734375, (410.32922, 0.13833492, 457.05722, 0.3882813)
   validation loss 542.470947265625, (317.11462, 0.0818898, 225.27444, 0.3882813)
decoder loss ratio: 12285.571070, decoder SINDy loss  ratio: 0.486287
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98226166]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.924408]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1677.0343017578125, (1198.4939, 0.13951112, 478.4009, 0.38795233)
   validation loss 1315.661376953125, (1059.5729, 0.08651724, 256.0019, 0.38795233)
decoder loss ratio: 41049.692715, decoder SINDy loss  ratio: 0.552616
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821959]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.8711605]
 [ -0.       ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.0147705078125, (255.12683, 0.14574187, 466.7422, 0.38761613)
   validation loss 406.66400146484375, (190.33107, 0.07051867, 216.26239, 0.38761613)
decoder loss ratio: 7373.756079, decoder SINDy loss  ratio: 0.466833
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821906]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.803935]
 [ -0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.5101318359375, (308.56604, 0.14139964, 452.8027, 0.3875632)
   validation loss 448.82958984375, (229.37476, 0.07819831, 219.37663, 0.3875632)
decoder loss ratio: 8886.376254, decoder SINDy loss  ratio: 0.473555
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98216575]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.826035]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.7017822265625, (243.50893, 0.1471741, 457.04565, 0.38742933)
   validation loss 391.6783142089844, (175.79964, 0.073493555, 215.80519, 0.38742933)
decoder loss ratio: 6810.783133, decoder SINDy loss  ratio: 0.465846
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98215485]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.851567]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.282958984375, (229.66241, 0.14927712, 458.47128, 0.38737544)
   validation loss 378.12750244140625, (162.75482, 0.080250494, 215.29245, 0.38737544)
decoder loss ratio: 6305.404350, decoder SINDy loss  ratio: 0.464739
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98212355]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.851299]
 [  0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.759033203125, (235.21667, 0.14511424, 461.39728, 0.38721606)
   validation loss 386.68792724609375, (170.91646, 0.074462086, 215.69699, 0.38721606)
decoder loss ratio: 6621.600312, decoder SINDy loss  ratio: 0.465612
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821149]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.870594]
 [ -0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.4378051757812, (231.23854, 0.14837027, 456.0509, 0.38716817)
   validation loss 379.55413818359375, (164.33556, 0.079103135, 215.13948, 0.38716817)
decoder loss ratio: 6366.644740, decoder SINDy loss  ratio: 0.464409
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9820913]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.823229]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.2857666015625, (269.36203, 0.14323197, 452.78055, 0.38705564)
   validation loss 409.7367248535156, (191.95473, 0.07635803, 217.70564, 0.38705564)
decoder loss ratio: 7436.659379, decoder SINDy loss  ratio: 0.469948
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9820795]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.845896]
 [ -0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.8018798828125, (260.92654, 0.13933952, 451.73596, 0.38697663)
   validation loss 403.0469055175781, (186.22372, 0.0733648, 216.74982, 0.38697663)
decoder loss ratio: 7214.630381, decoder SINDy loss  ratio: 0.467885
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9820903]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.766926]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.150634765625, (281.99786, 0.14185202, 450.01096, 0.38704416)
   validation loss 420.99310302734375, (203.37509, 0.076489344, 217.54153, 0.38704416)
decoder loss ratio: 7879.104121, decoder SINDy loss  ratio: 0.469594
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9820936]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.782552]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1677.220458984375, (1201.4934, 0.14141509, 475.58566, 0.38707295)
   validation loss 1282.4888916015625, (1028.0017, 0.08127275, 254.40587, 0.38707295)
decoder loss ratio: 39826.570896, decoder SINDy loss  ratio: 0.549171
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821076]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.809593]
 [ -0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.3079833984375, (228.23965, 0.15524797, 457.91312, 0.38712636)
   validation loss 384.1263122558594, (169.77501, 0.07593453, 214.27538, 0.38712636)
decoder loss ratio: 6577.378597, decoder SINDy loss  ratio: 0.462544
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821169]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.820604]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1261.4036865234375, (803.46857, 0.14561005, 457.7895, 0.38717774)
   validation loss 905.2427978515625, (667.543, 0.07732794, 237.62245, 0.38717774)
decoder loss ratio: 25861.775880, decoder SINDy loss  ratio: 0.512941
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9820782]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.824971]
 [ -0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 875.1234130859375, (427.73776, 0.13991661, 447.2457, 0.38697943)
   validation loss 563.8277587890625, (339.2259, 0.07178842, 224.53008, 0.38697943)
decoder loss ratio: 13142.199944, decoder SINDy loss  ratio: 0.484680
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9820969]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.906506]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.9354858398438, (235.98087, 0.15977159, 455.79483, 0.3870725)
   validation loss 388.6258544921875, (174.50461, 0.072217256, 214.04901, 0.3870725)
decoder loss ratio: 6760.611473, decoder SINDy loss  ratio: 0.462055
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821182]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.891425]
 [  0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.7269897460938, (281.2862, 0.15683514, 447.28397, 0.3871892)
   validation loss 416.30230712890625, (199.9911, 0.07365939, 216.23755, 0.3871892)
decoder loss ratio: 7748.002574, decoder SINDy loss  ratio: 0.466779
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982132]
 [0.      ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.91677]
 [  0.     ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.0111083984375, (242.91809, 0.15110059, 459.9419, 0.38726035)
   validation loss 397.73992919921875, (183.01279, 0.07261603, 214.65453, 0.38726035)
decoder loss ratio: 7090.233087, decoder SINDy loss  ratio: 0.463362
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98213685]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.841111]
 [ -0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.1424560546875, (352.79074, 0.14451624, 445.20715, 0.38726592)
   validation loss 482.91455078125, (264.10153, 0.06864431, 218.74438, 0.38726592)
decoder loss ratio: 10231.751849, decoder SINDy loss  ratio: 0.472191
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98209816]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.849743]
 [ -0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.7362670898438, (246.97057, 0.14191711, 447.62378, 0.38707706)
   validation loss 391.79180908203125, (175.83453, 0.06699062, 215.8903, 0.38707706)
decoder loss ratio: 6812.135097, decoder SINDy loss  ratio: 0.466030
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982106]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.853696]
 [  0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.8839721679688, (251.03676, 0.1417659, 446.70544, 0.3871263)
   validation loss 393.10272216796875, (177.29738, 0.06839305, 215.73695, 0.3871263)
decoder loss ratio: 6868.808246, decoder SINDy loss  ratio: 0.465699
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821209]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.826751]
 [  0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1191.5869140625, (742.2184, 0.14353742, 449.225, 0.38720948)
   validation loss 848.3442993164062, (615.0562, 0.07046047, 233.21767, 0.38720948)
decoder loss ratio: 23828.345491, decoder SINDy loss  ratio: 0.503433
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821151]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.706664]
 [  0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.7490234375, (315.55203, 0.15156098, 469.0454, 0.38716933)
   validation loss 482.03631591796875, (265.1443, 0.06626376, 216.82578, 0.38716933)
decoder loss ratio: 10272.149993, decoder SINDy loss  ratio: 0.468049
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98216915]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.845758]
 [ -0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.0767211914062, (250.09125, 0.16574496, 447.81973, 0.38746256)
   validation loss 391.5955810546875, (177.11168, 0.06964813, 214.41426, 0.38746256)
decoder loss ratio: 6861.613927, decoder SINDy loss  ratio: 0.462843
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821891]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.75693]
 [ -0.     ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.8053588867188, (237.23921, 0.15765241, 447.4085, 0.38756025)
   validation loss 380.49591064453125, (167.07483, 0.06770849, 213.35338, 0.38756025)
decoder loss ratio: 6472.768934, decoder SINDy loss  ratio: 0.460553
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98220056]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.903884]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.358154296875, (224.80444, 0.14965697, 451.40402, 0.38762623)
   validation loss 377.86492919921875, (164.23048, 0.067239, 213.56718, 0.38762623)
decoder loss ratio: 6362.574067, decoder SINDy loss  ratio: 0.461015
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9821959]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.828597]
 [  0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.4050903320312, (433.02472, 0.14000815, 444.24036, 0.3875998)
   validation loss 546.8851318359375, (324.04764, 0.065754384, 222.77171, 0.3875998)
decoder loss ratio: 12554.168065, decoder SINDy loss  ratio: 0.480884
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98219836]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.765918]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.8358764648438, (306.67032, 0.17775133, 471.9878, 0.38766226)
   validation loss 451.71368408203125, (235.50737, 0.06499995, 216.1413, 0.38766226)
decoder loss ratio: 9123.964372, decoder SINDy loss  ratio: 0.466571
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9822142]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.873458]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 915.6407470703125, (438.7955, 0.15846558, 476.68674, 0.3877233)
   validation loss 615.5404052734375, (396.3281, 0.067748055, 219.14458, 0.3877233)
decoder loss ratio: 15354.438436, decoder SINDy loss  ratio: 0.473054
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98222125]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.824416]
 [  0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 895.7469482421875, (452.73987, 0.14232995, 442.86472, 0.387731)
   validation loss 574.1577758789062, (350.6735, 0.06422155, 223.42006, 0.387731)
decoder loss ratio: 13585.699893, decoder SINDy loss  ratio: 0.482284
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98220956]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.879747]
 [  0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1658.501708984375, (1109.8926, 0.16672933, 548.4423, 0.38767287)
   validation loss 1286.78173828125, (1040.3142, 0.059339184, 246.40823, 0.38767287)
decoder loss ratio: 40303.578521, decoder SINDy loss  ratio: 0.531907
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9822542]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.853874]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1062.7567138671875, (566.1099, 0.1801714, 496.4666, 0.38795787)
   validation loss 736.763916015625, (512.77606, 0.06534797, 223.92252, 0.38795787)
decoder loss ratio: 19865.834861, decoder SINDy loss  ratio: 0.483368
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823034]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.8940525]
 [ -0.       ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.0079956054688, (245.42693, 0.15506288, 443.42603, 0.38816443)
   validation loss 386.059814453125, (172.46768, 0.06376647, 213.52835, 0.38816443)
decoder loss ratio: 6681.697413, decoder SINDy loss  ratio: 0.460931
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823167]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.912442]
 [ -0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.0875244140625, (226.19379, 0.14844762, 450.74527, 0.38824525)
   validation loss 381.4045104980469, (167.82799, 0.06431972, 213.5122, 0.38824525)
decoder loss ratio: 6501.947605, decoder SINDy loss  ratio: 0.460896
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98232156]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.871985]
 [  0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.607666015625, (236.20515, 0.14580894, 446.2567, 0.38825732)
   validation loss 384.39849853515625, (170.72601, 0.060659338, 213.61185, 0.38825732)
decoder loss ratio: 6614.222144, decoder SINDy loss  ratio: 0.461111
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823177]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.836202]
 [ -0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.232177734375, (290.20502, 0.14111632, 440.88608, 0.38823444)
   validation loss 419.0709228515625, (202.73299, 0.05952376, 216.27841, 0.38823444)
decoder loss ratio: 7854.227855, decoder SINDy loss  ratio: 0.466867
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9822784]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.826079]
 [  0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 836.013916015625, (395.13745, 0.13987936, 440.73654, 0.38804117)
   validation loss 515.9625244140625, (294.68, 0.061695255, 221.22081, 0.38804117)
decoder loss ratio: 11416.414503, decoder SINDy loss  ratio: 0.477536
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98229176]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.87757]
 [ -0.     ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.3787841796875, (237.9416, 0.14090256, 442.2963, 0.38811108)
   validation loss 379.9490966796875, (165.64682, 0.058741607, 214.24352, 0.38811108)
decoder loss ratio: 6417.445385, decoder SINDy loss  ratio: 0.462475
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98231006]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.862544]
 [ -0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 791.2300415039062, (350.63574, 0.14082791, 440.45346, 0.38822183)
   validation loss 473.46380615234375, (254.79794, 0.06194238, 218.60394, 0.38822183)
decoder loss ratio: 9871.314665, decoder SINDy loss  ratio: 0.471887
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98228574]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.831282]
 [ -0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.4010009765625, (326.43945, 0.14314482, 437.81836, 0.38806716)
   validation loss 453.97491455078125, (235.84818, 0.055755608, 218.07098, 0.38806716)
decoder loss ratio: 9137.167752, decoder SINDy loss  ratio: 0.470737
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823054]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.887659]
 [ -0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.16650390625, (353.8305, 0.15165305, 468.18433, 0.3881831)
   validation loss 533.7003173828125, (316.06577, 0.058035642, 217.5765, 0.3881831)
decoder loss ratio: 12244.936465, decoder SINDy loss  ratio: 0.469669
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98231953]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.923878]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 864.4298095703125, (424.08234, 0.14327721, 440.20422, 0.38826594)
   validation loss 536.96728515625, (314.53384, 0.05938397, 222.37407, 0.38826594)
decoder loss ratio: 12185.587171, decoder SINDy loss  ratio: 0.480026
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823448]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.863966]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1195.0067138671875, (749.0337, 0.14083289, 445.8322, 0.38842046)
   validation loss 840.2984008789062, (607.32196, 0.06206721, 232.91438, 0.38842046)
decoder loss ratio: 23528.707105, decoder SINDy loss  ratio: 0.502778
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823526]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.966448]
 [  0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.9202270507812, (349.18796, 0.15350217, 464.57877, 0.3884481)
   validation loss 530.2549438476562, (313.64185, 0.059002098, 216.55412, 0.3884481)
decoder loss ratio: 12151.029609, decoder SINDy loss  ratio: 0.467463
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9823668]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.936202]
 [  0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.5257568359375, (285.13776, 0.15026815, 459.23776, 0.3885176)
   validation loss 456.02288818359375, (240.8209, 0.054957226, 215.147, 0.3885176)
decoder loss ratio: 9329.820044, decoder SINDy loss  ratio: 0.464425
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9824071]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.916196]
 [ -0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.710693359375, (224.92589, 0.14530239, 443.63953, 0.3887367)
   validation loss 373.7008972167969, (160.10565, 0.057825718, 213.53741, 0.3887367)
decoder loss ratio: 6202.770909, decoder SINDy loss  ratio: 0.460951
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9824394]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.896289]
 [  0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.562744140625, (229.78001, 0.14649664, 441.63623, 0.38890153)
   validation loss 377.1748046875, (163.9305, 0.055817865, 213.1885, 0.38890153)
decoder loss ratio: 6350.952019, decoder SINDy loss  ratio: 0.460197
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98241466]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.942738]
 [  0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1692.0283203125, (1224.8347, 0.13927083, 467.05435, 0.38878572)
   validation loss 1276.7413330078125, (1021.8542, 0.06268983, 254.8245, 0.38878572)
decoder loss ratio: 39588.405222, decoder SINDy loss  ratio: 0.550075
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982435]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.920204]
 [ -0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.4578857421875, (221.61783, 0.15208295, 442.688, 0.38888797)
   validation loss 374.90435791015625, (162.48714, 0.056022186, 212.36122, 0.38888797)
decoder loss ratio: 6295.033771, decoder SINDy loss  ratio: 0.458412
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98247695]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.913473]
 [ -0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.3509521484375, (278.9709, 0.14949767, 437.23056, 0.38910866)
   validation loss 407.13824462890625, (192.68353, 0.05633204, 214.39839, 0.38910866)
decoder loss ratio: 7464.894571, decoder SINDy loss  ratio: 0.462809
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98250145]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.859904]
 [ -0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.5765380859375, (230.37581, 0.14870976, 448.05203, 0.38924548)
   validation loss 391.2496643066406, (178.27502, 0.055872995, 212.91876, 0.38924548)
decoder loss ratio: 6906.683945, decoder SINDy loss  ratio: 0.459615
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9825194]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.961611]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.6796264648438, (316.51715, 0.14083208, 437.02164, 0.3893408)
   validation loss 436.1151123046875, (219.71672, 0.057109557, 216.34128, 0.3893408)
decoder loss ratio: 8512.207200, decoder SINDy loss  ratio: 0.467003
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98251975]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.959499]
 [  0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.3533325195312, (256.36075, 0.14402145, 438.84857, 0.3893374)
   validation loss 394.65362548828125, (181.2286, 0.05389914, 213.37114, 0.3893374)
decoder loss ratio: 7021.110869, decoder SINDy loss  ratio: 0.460592
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982496]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.974662]
 [ -0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1016.52734375, (577.2944, 0.14051685, 439.09247, 0.3892134)
   validation loss 672.2687377929688, (444.76794, 0.053654674, 227.44713, 0.3892134)
decoder loss ratio: 17231.082315, decoder SINDy loss  ratio: 0.490977
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9825128]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.986885]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.1077880859375, (234.91884, 0.1461347, 448.04282, 0.38931495)
   validation loss 396.55340576171875, (182.77809, 0.053689487, 213.7216, 0.38931495)
decoder loss ratio: 7081.140579, decoder SINDy loss  ratio: 0.461348
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982547]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.891399]
 [ -0.      ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.3003540039062, (230.99722, 0.14167279, 439.16147, 0.38949504)
   validation loss 372.49456787109375, (159.31734, 0.054030444, 213.1232, 0.38949504)
decoder loss ratio: 6172.230224, decoder SINDy loss  ratio: 0.460056
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9825686]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.912902]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.144775390625, (252.88438, 0.1477533, 452.11267, 0.3896179)
   validation loss 417.80706787109375, (204.05035, 0.05256197, 213.70413, 0.3896179)
decoder loss ratio: 7905.264961, decoder SINDy loss  ratio: 0.461310
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98259705]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.960485]
 [ -0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.30712890625, (250.01407, 0.14341216, 437.14966, 0.38975477)
   validation loss 385.96923828125, (172.94185, 0.051261887, 212.97614, 0.38975477)
decoder loss ratio: 6700.067461, decoder SINDy loss  ratio: 0.459739
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98263645]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.973517]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.64013671875, (243.66072, 0.14948519, 436.82996, 0.3899859)
   validation loss 382.4337158203125, (170.58853, 0.056819335, 211.78836, 0.3899859)
decoder loss ratio: 6608.895865, decoder SINDy loss  ratio: 0.457175
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98265773]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.045013]
 [ -0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.246826171875, (238.26584, 0.1547195, 439.82626, 0.39010888)
   validation loss 375.7960205078125, (163.6947, 0.058172245, 212.04315, 0.39010888)
decoder loss ratio: 6341.816948, decoder SINDy loss  ratio: 0.457725
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9826431]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.991486]
 [  0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.6605224609375, (228.51527, 0.14064145, 441.0046, 0.39003804)
   validation loss 378.07659912109375, (165.2011, 0.053770244, 212.82173, 0.39003804)
decoder loss ratio: 6400.177245, decoder SINDy loss  ratio: 0.459406
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98266894]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.076924]
 [ -0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.4716796875, (225.85925, 0.14012928, 440.47226, 0.39016753)
   validation loss 371.5260009765625, (158.89108, 0.05136058, 212.58354, 0.39016753)
decoder loss ratio: 6155.716393, decoder SINDy loss  ratio: 0.458891
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98268396]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.964008]
 [  0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.8499755859375, (329.9421, 0.14894079, 460.7589, 0.39026985)
   validation loss 511.3611145019531, (295.79608, 0.054461975, 215.51056, 0.39026985)
decoder loss ratio: 11459.653724, decoder SINDy loss  ratio: 0.465210
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982692]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.993117]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.921142578125, (256.29147, 0.14582215, 451.4839, 0.3902917)
   validation loss 425.0422668457031, (211.7726, 0.051646292, 213.21802, 0.3902917)
decoder loss ratio: 8204.438110, decoder SINDy loss  ratio: 0.460261
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9827168]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.974825]
 [  0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.5973510742188, (250.32878, 0.13629381, 436.13226, 0.39044824)
   validation loss 385.98638916015625, (172.67874, 0.053348534, 213.25429, 0.39044824)
decoder loss ratio: 6689.874227, decoder SINDy loss  ratio: 0.460339
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9827298]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [-14.9574]
 [ -0.    ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.2604370117188, (237.38449, 0.14160918, 447.73434, 0.3905108)
   validation loss 397.01776123046875, (184.5506, 0.051961243, 212.4152, 0.3905108)
decoder loss ratio: 7149.810566, decoder SINDy loss  ratio: 0.458528
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98274493]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.016005]
 [ -0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1091.533447265625, (655.1046, 0.13416503, 436.29465, 0.3906145)
   validation loss 744.376220703125, (518.70874, 0.054893468, 225.61264, 0.3906145)
decoder loss ratio: 20095.677115, decoder SINDy loss  ratio: 0.487017
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98274505]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.966824]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 897.8372802734375, (428.306, 0.14897613, 469.38226, 0.39060935)
   validation loss 623.6539306640625, (406.24954, 0.054637473, 217.34978, 0.39060935)
decoder loss ratio: 15738.812546, decoder SINDy loss  ratio: 0.469180
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98274237]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.945177]
 [  0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.7899780273438, (265.10394, 0.13431123, 435.55173, 0.39057693)
   validation loss 398.1463317871094, (184.88893, 0.05151396, 213.20589, 0.39057693)
decoder loss ratio: 7162.918179, decoder SINDy loss  ratio: 0.460235
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98276246]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.023617]
 [ -0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.4625244140625, (336.27396, 0.1329442, 433.05563, 0.39069375)
   validation loss 452.1131896972656, (235.7537, 0.051184222, 216.30832, 0.39069375)
decoder loss ratio: 9133.507339, decoder SINDy loss  ratio: 0.466932
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98279554]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.949703]
 [ -0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.8843383789062, (350.10272, 0.16790465, 471.6137, 0.39092344)
   validation loss 519.690185546875, (302.88156, 0.051815007, 216.7568, 0.39092344)
decoder loss ratio: 11734.157509, decoder SINDy loss  ratio: 0.467900
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98282194]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.043498]
 [ -0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.5338134765625, (232.19029, 0.13791971, 436.2056, 0.3910211)
   validation loss 373.98040771484375, (162.73326, 0.05142119, 211.19574, 0.3910211)
decoder loss ratio: 6304.569053, decoder SINDy loss  ratio: 0.455896
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828268]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.020471]
 [ -0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.1592407226562, (236.34985, 0.13566682, 436.6737, 0.39107275)
   validation loss 376.2606201171875, (164.28455, 0.053574994, 211.9225, 0.39107275)
decoder loss ratio: 6364.668519, decoder SINDy loss  ratio: 0.457465
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828337]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.048101]
 [  0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.3099365234375, (223.8392, 0.13735706, 438.33334, 0.39107656)
   validation loss 372.0576477050781, (161.14062, 0.049222827, 210.8678, 0.39107656)
decoder loss ratio: 6242.867565, decoder SINDy loss  ratio: 0.455188
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982821]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.964283]
 [  0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.9508056640625, (468.84274, 0.12849288, 433.97958, 0.39102483)
   validation loss 566.8479614257812, (345.83783, 0.053188287, 220.95695, 0.39102483)
decoder loss ratio: 13398.357919, decoder SINDy loss  ratio: 0.476967
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9827858]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.024049]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1567.47802734375, (1024.8362, 0.16463727, 542.47723, 0.39087123)
   validation loss 1193.2041015625, (949.8935, 0.05142088, 243.25917, 0.39087123)
decoder loss ratio: 36800.523032, decoder SINDy loss  ratio: 0.525109
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828015]
 [0.       ]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-15.0104685]
 [ -0.       ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 887.6605834960938, (425.15958, 0.14237677, 462.35864, 0.3909503)
   validation loss 616.837890625, (400.72394, 0.05182738, 216.06213, 0.3909503)
decoder loss ratio: 15524.741045, decoder SINDy loss  ratio: 0.466401
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828168]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.020446]
 [ -0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.141845703125, (238.1941, 0.1358495, 435.81186, 0.39100966)
   validation loss 379.516357421875, (166.87877, 0.05119095, 212.58641, 0.39100966)
decoder loss ratio: 6465.173222, decoder SINDy loss  ratio: 0.458898
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828333]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.01594]
 [  0.     ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.6160888671875, (223.4653, 0.13543756, 438.01535, 0.39111033)
   validation loss 374.003662109375, (162.43108, 0.050336868, 211.52223, 0.39111033)
decoder loss ratio: 6292.861879, decoder SINDy loss  ratio: 0.456600
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98284996]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.056639]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 759.6060180664062, (303.55435, 0.14201249, 455.90967, 0.39118573)
   validation loss 482.97906494140625, (269.0119, 0.04875736, 213.9184, 0.39118573)
decoder loss ratio: 10421.988103, decoder SINDy loss  ratio: 0.461773
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828567]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.958683]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.4630126953125, (231.52386, 0.13691097, 439.80222, 0.39122725)
   validation loss 385.38671875, (174.11116, 0.050139267, 211.22542, 0.39122725)
decoder loss ratio: 6745.368619, decoder SINDy loss  ratio: 0.455960
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98287314]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.049494]
 [ -0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.3158569335938, (226.95187, 0.13003907, 434.23395, 0.39132538)
   validation loss 367.5218811035156, (155.8117, 0.0499438, 211.66023, 0.39132538)
decoder loss ratio: 6036.416012, decoder SINDy loss  ratio: 0.456898
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828823]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.055981]
 [ -0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.9159545898438, (234.26083, 0.1361513, 441.51895, 0.3913931)
   validation loss 395.88726806640625, (184.60506, 0.05133789, 211.23088, 0.3913931)
decoder loss ratio: 7151.920387, decoder SINDy loss  ratio: 0.455972
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98287755]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.976578]
 [  0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.0884399414062, (290.60553, 0.13937205, 453.34354, 0.39134738)
   validation loss 467.13043212890625, (253.49963, 0.04844742, 213.58235, 0.39134738)
decoder loss ratio: 9821.015908, decoder SINDy loss  ratio: 0.461048
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828999]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.039708]
 [ -0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 752.9857788085938, (303.0542, 0.13993004, 449.79166, 0.39150673)
   validation loss 480.8911437988281, (268.26663, 0.05207957, 212.57242, 0.39150673)
decoder loss ratio: 10393.115058, decoder SINDy loss  ratio: 0.458867
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9828999]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.088581]
 [  0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.9578857421875, (251.479, 0.13436237, 433.3445, 0.39147052)
   validation loss 386.1182861328125, (173.90382, 0.046472788, 212.16797, 0.39147052)
decoder loss ratio: 6737.336046, decoder SINDy loss  ratio: 0.457994
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829083]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.97433]
 [ -0.     ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.194091796875, (234.07784, 0.12958917, 438.9867, 0.39153835)
   validation loss 389.9619445800781, (179.21811, 0.049132444, 210.6947, 0.39153835)
decoder loss ratio: 6943.220684, decoder SINDy loss  ratio: 0.454814
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98291725]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.977727]
 [ -0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.4883422851562, (240.07196, 0.12984511, 433.28653, 0.39157584)
   validation loss 379.94580078125, (168.7765, 0.04884767, 211.12044, 0.39157584)
decoder loss ratio: 6538.694794, decoder SINDy loss  ratio: 0.455733
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98291886]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.069931]
 [  0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.8480834960938, (261.20944, 0.1366676, 447.50198, 0.39155456)
   validation loss 431.1305236816406, (219.13895, 0.044991355, 211.94658, 0.39155456)
decoder loss ratio: 8489.823231, decoder SINDy loss  ratio: 0.457517
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829524]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.00373]
 [ -0.     ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1116.3648681640625, (681.13745, 0.124274924, 435.10318, 0.3917728)
   validation loss 746.389404296875, (519.011, 0.050509956, 227.32787, 0.3917728)
decoder loss ratio: 20107.386653, decoder SINDy loss  ratio: 0.490719
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98295474]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.055431]
 [  0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.1558837890625, (225.8081, 0.12609732, 433.22168, 0.39179096)
   validation loss 366.55487060546875, (155.49832, 0.04875623, 211.00781, 0.39179096)
decoder loss ratio: 6024.274933, decoder SINDy loss  ratio: 0.455490
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98295784]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-14.99863]
 [ -0.     ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.4772338867188, (246.00554, 0.13409305, 444.3376, 0.3918182)
   validation loss 415.8381042480469, (204.34042, 0.048366204, 211.44931, 0.3918182)
decoder loss ratio: 7916.502760, decoder SINDy loss  ratio: 0.456443
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.982953]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.985142]
 [  0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.3250122070312, (246.91042, 0.13163374, 445.28296, 0.39178482)
   validation loss 415.0539245605469, (203.16226, 0.047725312, 211.84393, 0.39178482)
decoder loss ratio: 7870.858734, decoder SINDy loss  ratio: 0.457295
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98296773]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.102718]
 [  0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.438720703125, (233.2131, 0.1255521, 432.1001, 0.39187804)
   validation loss 373.26214599609375, (162.1361, 0.048954275, 211.07712, 0.39187804)
decoder loss ratio: 6281.433729, decoder SINDy loss  ratio: 0.455640
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829509]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.043531]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.4324951171875, (289.9575, 0.12372261, 428.35132, 0.39175376)
   validation loss 410.989501953125, (198.1523, 0.049253985, 212.78795, 0.39175376)
decoder loss ratio: 7676.764031, decoder SINDy loss  ratio: 0.459333
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829512]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.072185]
 [  0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.6135864257812, (272.73166, 0.1294002, 431.75253, 0.39177242)
   validation loss 404.623291015625, (190.632, 0.04727256, 213.94402, 0.39177242)
decoder loss ratio: 7385.414778, decoder SINDy loss  ratio: 0.461828
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98296034]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.080219]
 [  0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.9774169921875, (232.28339, 0.12291391, 430.57114, 0.39183724)
   validation loss 371.00897216796875, (159.54834, 0.046726923, 211.41391, 0.39183724)
decoder loss ratio: 6181.179674, decoder SINDy loss  ratio: 0.456367
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829756]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.027038]
 [ -0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.2199096679688, (324.07364, 0.12091031, 430.02536, 0.3919432)
   validation loss 431.7162170410156, (216.66905, 0.049494322, 214.99767, 0.3919432)
decoder loss ratio: 8394.135233, decoder SINDy loss  ratio: 0.464103
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829862]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.027001]
 [ -0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.040771484375, (340.79703, 0.12089866, 429.12286, 0.39198992)
   validation loss 454.0885009765625, (237.88611, 0.047931734, 216.15445, 0.39198992)
decoder loss ratio: 9216.120828, decoder SINDy loss  ratio: 0.466600
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9829873]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.109851]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 984.1578369140625, (550.5556, 0.116637945, 433.4856, 0.39198697)
   validation loss 624.6912231445312, (400.1978, 0.049547363, 224.44386, 0.39198697)
decoder loss ratio: 15504.358125, decoder SINDy loss  ratio: 0.484494
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98301005]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.10952]
 [  0.     ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.875732421875, (231.9192, 0.12631378, 431.8302, 0.39211956)
   validation loss 373.0714111328125, (161.13199, 0.044776194, 211.89464, 0.39211956)
decoder loss ratio: 6242.532973, decoder SINDy loss  ratio: 0.457404
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98302907]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.024932]
 [  0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 979.3232421875, (549.4119, 0.12455144, 429.7867, 0.3922145)
   validation loss 636.314453125, (413.24786, 0.047176246, 223.01942, 0.3922145)
decoder loss ratio: 16009.939672, decoder SINDy loss  ratio: 0.481419
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98300225]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.142921]
 [  0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 895.9249877929688, (431.5918, 0.14924337, 464.18396, 0.3920767)
   validation loss 623.8271484375, (405.94843, 0.046634868, 217.83209, 0.3920767)
decoder loss ratio: 15727.146753, decoder SINDy loss  ratio: 0.470221
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830365]
 [0.       ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-15.0014]
 [  0.    ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 855.336181640625, (386.40915, 0.14662988, 468.7804, 0.3922169)
   validation loss 569.1627197265625, (351.38855, 0.039442603, 217.73473, 0.3922169)
decoder loss ratio: 13613.402457, decoder SINDy loss  ratio: 0.470011
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830386]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.025654]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 883.8522338867188, (420.2043, 0.14190482, 463.506, 0.39233106)
   validation loss 608.9664306640625, (392.2625, 0.04806944, 216.65585, 0.39233106)
decoder loss ratio: 15196.930721, decoder SINDy loss  ratio: 0.467682
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830355]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.153786]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.8250122070312, (261.04404, 0.12201052, 427.65897, 0.3922289)
   validation loss 389.19854736328125, (177.21404, 0.04561684, 211.9389, 0.3922289)
decoder loss ratio: 6865.579374, decoder SINDy loss  ratio: 0.457500
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830327]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.072188]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.8075561523438, (221.48576, 0.1255849, 436.1962, 0.39224058)
   validation loss 378.2601318359375, (167.60017, 0.046068445, 210.61389, 0.39224058)
decoder loss ratio: 6493.121706, decoder SINDy loss  ratio: 0.454640
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830495]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.099632]
 [  0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.1275634765625, (378.47488, 0.1203774, 427.5323, 0.3923353)
   validation loss 481.4124755859375, (265.8263, 0.046354547, 215.53983, 0.3923353)
decoder loss ratio: 10298.572122, decoder SINDy loss  ratio: 0.465273
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98304045]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.089974]
 [  0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.75390625, (450.34082, 0.11477452, 427.29834, 0.39229184)
   validation loss 544.6011962890625, (325.21313, 0.046436407, 219.34163, 0.39229184)
decoder loss ratio: 12599.321436, decoder SINDy loss  ratio: 0.473480
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830439]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.09716]
 [  0.     ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.294921875, (241.49757, 0.12051361, 429.67682, 0.39231694)
   validation loss 377.9456787109375, (166.34447, 0.043977514, 211.55724, 0.39231694)
decoder loss ratio: 6444.473445, decoder SINDy loss  ratio: 0.456676
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830545]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.140325]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.8507080078125, (361.23282, 0.121089056, 426.49683, 0.392356)
   validation loss 471.68646240234375, (256.6236, 0.04421862, 215.01863, 0.392356)
decoder loss ratio: 9942.043635, decoder SINDy loss  ratio: 0.464148
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98303956]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.046698]
 [ -0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.3233642578125, (335.52658, 0.13375168, 451.66302, 0.3922976)
   validation loss 523.0014038085938, (309.79657, 0.045835312, 213.15901, 0.3922976)
decoder loss ratio: 12002.056945, decoder SINDy loss  ratio: 0.460134
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830508]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.037927]
 [  0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.6192016601562, (237.33836, 0.1196613, 428.1612, 0.39234087)
   validation loss 376.4652099609375, (166.6545, 0.048456404, 209.76227, 0.39234087)
decoder loss ratio: 6456.484470, decoder SINDy loss  ratio: 0.452801
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98303854]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.112284]
 [ -0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 920.11279296875, (491.6104, 0.11769496, 428.3847, 0.39227325)
   validation loss 581.988037109375, (360.974, 0.04635938, 220.9677, 0.39227325)
decoder loss ratio: 13984.759401, decoder SINDy loss  ratio: 0.476990
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830376]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.066789]
 [  0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 899.2103271484375, (469.4002, 0.112754926, 429.69733, 0.39228478)
   validation loss 556.0780029296875, (335.5424, 0.0472408, 220.48836, 0.39228478)
decoder loss ratio: 12999.494674, decoder SINDy loss  ratio: 0.475955
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98305994]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.01517]
 [  0.     ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.426513671875, (226.0507, 0.12097948, 430.25482, 0.3923957)
   validation loss 366.7749328613281, (155.83325, 0.04250351, 210.89917, 0.3923957)
decoder loss ratio: 6037.250719, decoder SINDy loss  ratio: 0.455256
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98306304]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.094092]
 [ -0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 840.2391357421875, (410.5486, 0.11339541, 429.57715, 0.3924491)
   validation loss 502.8848876953125, (283.82, 0.046527207, 219.01833, 0.3924491)
decoder loss ratio: 10995.679817, decoder SINDy loss  ratio: 0.472782
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830972]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.052367]
 [ -0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.945556640625, (289.8889, 0.12329398, 426.93338, 0.39262122)
   validation loss 407.5025634765625, (194.86382, 0.04885609, 212.58987, 0.39262122)
decoder loss ratio: 7549.362503, decoder SINDy loss  ratio: 0.458905
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98310125]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.095877]
 [  0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.5092163085938, (229.26865, 0.12947708, 438.1111, 0.39264962)
   validation loss 392.6378173828125, (182.01384, 0.044644207, 210.57932, 0.39264962)
decoder loss ratio: 7051.532141, decoder SINDy loss  ratio: 0.454565
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830998]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.116378]
 [  0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 811.9512329101562, (353.70288, 0.13468927, 458.11368, 0.39261806)
   validation loss 541.2208251953125, (326.44034, 0.042931326, 214.73755, 0.39261806)
decoder loss ratio: 12646.865425, decoder SINDy loss  ratio: 0.463541
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98309207]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.062008]
 [ -0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.90966796875, (281.62146, 0.13046172, 448.15775, 0.39257845)
   validation loss 457.08282470703125, (245.15608, 0.043424364, 211.88332, 0.39257845)
decoder loss ratio: 9497.772232, decoder SINDy loss  ratio: 0.457380
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830777]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.049848]
 [ -0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1018.8021240234375, (541.1851, 0.14562112, 477.47137, 0.3925594)
   validation loss 737.6132202148438, (516.079, 0.044763245, 221.48949, 0.3925594)
decoder loss ratio: 19993.795618, decoder SINDy loss  ratio: 0.478116
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830835]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.158952]
 [ -0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.0740966796875, (368.52258, 0.14001828, 458.41153, 0.39257416)
   validation loss 554.5037841796875, (339.25296, 0.04514906, 215.20569, 0.39257416)
decoder loss ratio: 13143.248647, decoder SINDy loss  ratio: 0.464552
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98307717]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.115513]
 [  0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.6041870117188, (219.25554, 0.11944543, 432.22922, 0.39248577)
   validation loss 372.31573486328125, (162.8214, 0.044712644, 209.44963, 0.39248577)
decoder loss ratio: 6307.983547, decoder SINDy loss  ratio: 0.452126
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830762]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.111087]
 [ -0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.9599609375, (225.10541, 0.11712679, 429.7374, 0.39250425)
   validation loss 366.931640625, (156.40863, 0.043127783, 210.47989, 0.39250425)
decoder loss ratio: 6059.541878, decoder SINDy loss  ratio: 0.454350
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98306036]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.052516]
 [ -0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.9658813476562, (224.9984, 0.11792488, 430.84958, 0.3924005)
   validation loss 373.09185791015625, (163.39784, 0.044383015, 209.64963, 0.3924005)
decoder loss ratio: 6330.316086, decoder SINDy loss  ratio: 0.452558
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98307496]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.056035]
 [ -0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.9420166015625, (220.62912, 0.12103027, 434.1919, 0.3924914)
   validation loss 378.1552734375, (168.06061, 0.043294825, 210.05139, 0.3924914)
decoder loss ratio: 6510.959716, decoder SINDy loss  ratio: 0.453425
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830799]
 [0.       ]]
[[ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.1120825]
 [  0.       ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.2921752929688, (234.80762, 0.12065834, 428.36392, 0.39251003)
   validation loss 373.293212890625, (163.04482, 0.044554297, 210.20384, 0.39251003)
decoder loss ratio: 6316.639194, decoder SINDy loss  ratio: 0.453755
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9831041]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.029812]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.4804077148438, (226.10266, 0.11710293, 428.26065, 0.39266333)
   validation loss 366.8472595214844, (157.01888, 0.043927208, 209.78445, 0.39266333)
decoder loss ratio: 6083.183819, decoder SINDy loss  ratio: 0.452849
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9831081]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.116674]
 [ -0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.4446411132812, (223.12744, 0.119618356, 429.19757, 0.39269227)
   validation loss 368.01361083984375, (158.13797, 0.044138756, 209.83151, 0.39269227)
decoder loss ratio: 6126.539496, decoder SINDy loss  ratio: 0.452951
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98311126]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.049234]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.6068115234375, (230.11128, 0.12381867, 437.37167, 0.39270073)
   validation loss 393.9677429199219, (183.9731, 0.042841166, 209.9518, 0.39270073)
decoder loss ratio: 7127.437237, decoder SINDy loss  ratio: 0.453210
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9831192]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.106852]
 [  0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 941.9473876953125, (515.00574, 0.106770985, 426.83487, 0.3927265)
   validation loss 589.8880004882812, (370.65845, 0.0453596, 219.1842, 0.3927265)
decoder loss ratio: 14359.951738, decoder SINDy loss  ratio: 0.473140
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98311263]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.065286]
 [ -0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 824.970947265625, (363.35135, 0.13832895, 461.48123, 0.3927414)
   validation loss 546.6532592773438, (330.1277, 0.043371126, 216.48221, 0.3927414)
decoder loss ratio: 12789.719665, decoder SINDy loss  ratio: 0.467307
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98310757]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.066128]
 [  0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.879150390625, (220.9988, 0.11666644, 430.7637, 0.39267543)
   validation loss 370.70404052734375, (161.49757, 0.04305597, 209.16342, 0.39267543)
decoder loss ratio: 6256.696383, decoder SINDy loss  ratio: 0.451509
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9831126]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.108836]
 [ -0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.5525512695312, (248.01604, 0.11161787, 425.4249, 0.39269987)
   validation loss 377.02838134765625, (167.13107, 0.045554508, 209.85176, 0.39269987)
decoder loss ratio: 6474.947920, decoder SINDy loss  ratio: 0.452995
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98309934]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.060675]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.316650390625, (222.58682, 0.11944661, 432.61038, 0.3926464)
   validation loss 375.99322509765625, (166.04408, 0.043897472, 209.90523, 0.3926464)
decoder loss ratio: 6432.836027, decoder SINDy loss  ratio: 0.453110
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830998]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.059409]
 [  0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.8115234375, (317.60593, 0.12878455, 452.07678, 0.39262328)
   validation loss 501.4910888671875, (288.1744, 0.041281693, 213.27539, 0.39262328)
decoder loss ratio: 11164.376857, decoder SINDy loss  ratio: 0.460385
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9830947]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.994304]
 [ -0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.3113403320312, (224.37167, 0.12536165, 434.8143, 0.39258933)
   validation loss 379.27301025390625, (169.70381, 0.04143398, 209.52779, 0.39258933)
decoder loss ratio: 6574.620282, decoder SINDy loss  ratio: 0.452295
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.983101]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.085465]
 [  0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1339.5076904296875, (905.7042, 0.10330221, 433.70013, 0.392647)
   validation loss 951.65673828125, (718.9649, 0.044576537, 232.64728, 0.392647)
decoder loss ratio: 27853.948589, decoder SINDy loss  ratio: 0.502202
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.98307]
 [0.     ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.1112795]
 [  0.       ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.634765625, (234.058, 0.11085247, 428.46588, 0.39248747)
   validation loss 373.3961486816406, (162.87138, 0.043443512, 210.48132, 0.39248747)
decoder loss ratio: 6309.920160, decoder SINDy loss  ratio: 0.454354
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98308206]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.005862]
 [  0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.7750854492188, (217.96649, 0.11353868, 429.69504, 0.39252853)
   validation loss 365.68902587890625, (156.16194, 0.041679338, 209.4854, 0.39252853)
decoder loss ratio: 6049.984724, decoder SINDy loss  ratio: 0.452204
params['save_name']
pendulum_2023_10_25_16_35_58_925745
