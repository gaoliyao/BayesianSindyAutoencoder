nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-29 04:58:29.834185: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-29 04:58:29.841841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-29 04:58:29.843437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56079729b670 executing computations on platform Host. Devices:
2023-10-29 04:58:29.843485: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-29 04:58:29.845353: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-29 04:58:29.959378: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56079893f6a0 executing computations on platform CUDA. Devices:
2023-10-29 04:58:29.959444: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-29 04:58:29.960436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2023-10-29 04:58:29.961022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-29 04:58:29.963219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-29 04:58:29.964742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-29 04:58:29.965051: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-29 04:58:29.966668: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-29 04:58:29.967558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-29 04:58:29.970777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-29 04:58:29.971428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-29 04:58:29.971464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-29 04:58:29.971803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-29 04:58:29.971812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-29 04:58:29.971817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-29 04:58:29.972378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2023-10-29 04:58:31.166477: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.025, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8908429145812988 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 108383.40625, (99599.47, 0.011987475, 8766.731, 2.5317822)
   validation loss 98060.25, (96842.3, 0.0043071522, 1200.7548, 2.5317822)
decoder loss ratio: 3751838.706558, decoder SINDy loss  ratio: 2.591998
--- 0.27356505393981934 seconds for one epoch ---
--- 0.32434511184692383 seconds for one epoch ---
--- 0.3361074924468994 seconds for one epoch ---
--- 0.3154923915863037 seconds for one epoch ---
--- 0.33246541023254395 seconds for one epoch ---
--- 0.32020044326782227 seconds for one epoch ---
--- 0.3207521438598633 seconds for one epoch ---
--- 0.32895684242248535 seconds for one epoch ---
--- 0.32495665550231934 seconds for one epoch ---
--- 0.3471646308898926 seconds for one epoch ---
--- 0.35674476623535156 seconds for one epoch ---
--- 0.3222618103027344 seconds for one epoch ---
--- 0.341141939163208 seconds for one epoch ---
--- 0.33293819427490234 seconds for one epoch ---
--- 0.3315889835357666 seconds for one epoch ---
--- 0.3075120449066162 seconds for one epoch ---
--- 0.34427738189697266 seconds for one epoch ---
--- 0.3226799964904785 seconds for one epoch ---
--- 0.3635110855102539 seconds for one epoch ---
--- 0.325455904006958 seconds for one epoch ---
--- 0.3319697380065918 seconds for one epoch ---
--- 0.3271949291229248 seconds for one epoch ---
--- 0.34386515617370605 seconds for one epoch ---
--- 0.33814120292663574 seconds for one epoch ---
=========================
[[1.        ]
 [0.99997526]
 [1.        ]
 [1.        ]
 [0.7714875 ]
 [1.        ]
 [0.9999999 ]
 [0.77181375]
 [0.771373  ]
 [1.        ]
 [0.7906377 ]]
[[ 0.5978678 ]
 [ 0.42392415]
 [-1.1095868 ]
 [-0.73332566]
 [-0.02373458]
 [-0.90440017]
 [ 0.5557581 ]
 [-0.04549282]
 [ 0.00709311]
 [-1.5406823 ]
 [ 0.1361613 ]]
--- 0.29725193977355957 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 65208.7734375, (59659.508, 77.556496, 5432.4453, 2.531741)
   validation loss 52642.8125, (51244.4, 20.702963, 1338.4456, 2.531741)
decoder loss ratio: 1985296.959657, decoder SINDy loss  ratio: 2.889223
--- 0.3276095390319824 seconds for one epoch ---
--- 0.3427095413208008 seconds for one epoch ---
--- 0.332338809967041 seconds for one epoch ---
--- 0.33409595489501953 seconds for one epoch ---
--- 0.3368659019470215 seconds for one epoch ---
--- 0.3478269577026367 seconds for one epoch ---
--- 0.3341562747955322 seconds for one epoch ---
--- 0.342745304107666 seconds for one epoch ---
--- 0.33847999572753906 seconds for one epoch ---
--- 0.3511340618133545 seconds for one epoch ---
--- 0.3322138786315918 seconds for one epoch ---
--- 0.32452940940856934 seconds for one epoch ---
--- 0.3298003673553467 seconds for one epoch ---
--- 0.3481459617614746 seconds for one epoch ---
--- 0.33551883697509766 seconds for one epoch ---
--- 0.3496675491333008 seconds for one epoch ---
--- 0.3164486885070801 seconds for one epoch ---
--- 0.33196282386779785 seconds for one epoch ---
--- 0.29906296730041504 seconds for one epoch ---
--- 0.3337736129760742 seconds for one epoch ---
--- 0.34094786643981934 seconds for one epoch ---
--- 0.3331186771392822 seconds for one epoch ---
--- 0.34786438941955566 seconds for one epoch ---
--- 0.3479938507080078 seconds for one epoch ---
=========================
[[1.        ]
 [0.6509492 ]
 [1.        ]
 [0.999997  ]
 [0.61027735]
 [1.        ]
 [0.99921304]
 [0.65392053]
 [0.60884964]
 [1.        ]
 [0.6225513 ]]
[[ 1.1987549 ]
 [ 0.14288759]
 [-1.0241735 ]
 [-0.4958586 ]
 [ 0.0586536 ]
 [-1.3448908 ]
 [ 0.35088375]
 [ 0.14479887]
 [ 0.00592354]
 [-0.58132184]
 [ 0.11310716]]
--- 0.3064754009246826 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 45363.51953125, (37348.12, 70.125404, 7885.4355, 2.5317304)
   validation loss 42923.84375, (41710.273, 5.642473, 1148.0916, 2.5317304)
decoder loss ratio: 1615928.405188, decoder SINDy loss  ratio: 2.478317
--- 0.2899661064147949 seconds for one epoch ---
--- 0.3391561508178711 seconds for one epoch ---
--- 0.35443758964538574 seconds for one epoch ---
--- 0.3317122459411621 seconds for one epoch ---
--- 0.36724352836608887 seconds for one epoch ---
--- 0.3379340171813965 seconds for one epoch ---
--- 0.37293219566345215 seconds for one epoch ---
--- 0.33656740188598633 seconds for one epoch ---
--- 0.37385010719299316 seconds for one epoch ---
--- 0.33694934844970703 seconds for one epoch ---
--- 0.335357666015625 seconds for one epoch ---
--- 0.3392922878265381 seconds for one epoch ---
--- 0.3565046787261963 seconds for one epoch ---
--- 0.33833765983581543 seconds for one epoch ---
--- 0.3614077568054199 seconds for one epoch ---
--- 0.43552255630493164 seconds for one epoch ---
--- 0.3356311321258545 seconds for one epoch ---
--- 0.33545541763305664 seconds for one epoch ---
--- 0.34265756607055664 seconds for one epoch ---
--- 0.3051927089691162 seconds for one epoch ---
--- 0.34562253952026367 seconds for one epoch ---
--- 0.33181142807006836 seconds for one epoch ---
--- 0.3561267852783203 seconds for one epoch ---
--- 0.32556724548339844 seconds for one epoch ---
=========================
[[1.        ]
 [0.48101482]
 [1.        ]
 [0.999867  ]
 [0.47972217]
 [1.        ]
 [0.8852916 ]
 [0.7481645 ]
 [0.47267842]
 [0.47289398]
 [0.47309905]]
[[ 1.4059564e+00]
 [-9.3018129e-02]
 [-1.1884882e+00]
 [-4.0285480e-01]
 [ 8.8862419e-02]
 [-1.7432071e+00]
 [ 2.2768217e-01]
 [ 1.9792350e-01]
 [ 1.2140889e-03]
 [-1.8257387e-02]
 [ 2.7881464e-02]]
--- 0.263256311416626 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 38620.78125, (31412.55, 26.567862, 7104.2295, 2.5317454)
   validation loss 19114.86328125, (17949.936, 0.68022233, 1086.8143, 2.5317454)
decoder loss ratio: 695411.665544, decoder SINDy loss  ratio: 2.346042
--- 0.3215656280517578 seconds for one epoch ---
--- 0.3585374355316162 seconds for one epoch ---
--- 0.3437354564666748 seconds for one epoch ---
--- 0.3689258098602295 seconds for one epoch ---
--- 0.31638503074645996 seconds for one epoch ---
--- 0.3581535816192627 seconds for one epoch ---
--- 0.334026575088501 seconds for one epoch ---
--- 0.36229634284973145 seconds for one epoch ---
--- 0.3375375270843506 seconds for one epoch ---
--- 0.36758947372436523 seconds for one epoch ---
--- 0.33923864364624023 seconds for one epoch ---
--- 0.345289945602417 seconds for one epoch ---
--- 0.3211684226989746 seconds for one epoch ---
--- 0.34919214248657227 seconds for one epoch ---
--- 0.331981897354126 seconds for one epoch ---
--- 0.3633382320404053 seconds for one epoch ---
--- 0.3202364444732666 seconds for one epoch ---
--- 0.37063002586364746 seconds for one epoch ---
--- 0.3086819648742676 seconds for one epoch ---
--- 0.3813009262084961 seconds for one epoch ---
--- 0.3261570930480957 seconds for one epoch ---
--- 0.36662745475769043 seconds for one epoch ---
--- 0.30376434326171875 seconds for one epoch ---
--- 0.37623095512390137 seconds for one epoch ---
=========================
[[1.        ]
 [0.46067324]
 [1.        ]
 [0.9878185 ]
 [0.38018054]
 [1.        ]
 [0.5805023 ]
 [0.6915943 ]
 [0.37531596]
 [0.4715244 ]
 [0.37531292]]
[[ 1.2876419e+00]
 [-1.4964303e-01]
 [-1.5029042e+00]
 [-2.9363486e-01]
 [ 7.5804606e-02]
 [-2.1380351e+00]
 [ 1.7780998e-01]
 [ 1.9631058e-01]
 [ 1.9512768e-03]
 [ 1.5313444e-01]
 [-1.6726085e-03]]
--- 0.31578874588012695 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 22959.90625, (15449.605, 1.1772089, 7416.774, 2.5317686)
   validation loss 11381.5419921875, (10343.622, 0.33536816, 945.2333, 2.5317686)
decoder loss ratio: 400729.876322, decoder SINDy loss  ratio: 2.040419
--- 0.2730998992919922 seconds for one epoch ---
--- 0.33917808532714844 seconds for one epoch ---
--- 0.38819313049316406 seconds for one epoch ---
--- 0.3348250389099121 seconds for one epoch ---
--- 0.3757057189941406 seconds for one epoch ---
--- 0.3208177089691162 seconds for one epoch ---
--- 0.38860082626342773 seconds for one epoch ---
--- 0.3269820213317871 seconds for one epoch ---
--- 0.36635732650756836 seconds for one epoch ---
--- 0.35233116149902344 seconds for one epoch ---
--- 0.378831148147583 seconds for one epoch ---
--- 0.3313312530517578 seconds for one epoch ---
--- 0.37723517417907715 seconds for one epoch ---
--- 0.33078551292419434 seconds for one epoch ---
--- 0.3635108470916748 seconds for one epoch ---
--- 0.32129836082458496 seconds for one epoch ---
--- 0.3730323314666748 seconds for one epoch ---
--- 0.3016643524169922 seconds for one epoch ---
--- 0.39856791496276855 seconds for one epoch ---
--- 0.2978386878967285 seconds for one epoch ---
--- 0.37737107276916504 seconds for one epoch ---
--- 0.3100898265838623 seconds for one epoch ---
--- 0.38038063049316406 seconds for one epoch ---
--- 0.31290340423583984 seconds for one epoch ---
=========================
[[1.        ]
 [0.9092834 ]
 [1.        ]
 [0.81207156]
 [0.29438147]
 [1.        ]
 [0.4145884 ]
 [0.797127  ]
 [0.29329053]
 [0.60484457]
 [0.2932445 ]]
[[ 1.1433421e+00]
 [-2.4357051e-01]
 [-1.7626143e+00]
 [-2.2106583e-01]
 [ 4.0483575e-02]
 [-2.4632297e+00]
 [ 1.5636879e-01]
 [ 2.1842203e-01]
 [-4.0646484e-03]
 [ 1.8974183e-01]
 [ 3.1838843e-04]]
--- 0.2595822811126709 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12312.5234375, (7334.898, 1.9646683, 4868.768, 2.531791)
   validation loss 9397.3046875, (8449.319, 0.16494794, 840.929, 2.531791)
decoder loss ratio: 327341.299738, decoder SINDy loss  ratio: 1.815264
--- 0.3221771717071533 seconds for one epoch ---
--- 0.3793978691101074 seconds for one epoch ---
--- 0.32813501358032227 seconds for one epoch ---
--- 0.37456417083740234 seconds for one epoch ---
--- 0.3108024597167969 seconds for one epoch ---
--- 0.38936614990234375 seconds for one epoch ---
--- 0.2971479892730713 seconds for one epoch ---
--- 0.3858003616333008 seconds for one epoch ---
--- 0.31358981132507324 seconds for one epoch ---
--- 0.4029655456542969 seconds for one epoch ---
--- 0.31980085372924805 seconds for one epoch ---
--- 0.3901793956756592 seconds for one epoch ---
--- 0.3094780445098877 seconds for one epoch ---
--- 0.38369297981262207 seconds for one epoch ---
--- 0.3315267562866211 seconds for one epoch ---
--- 0.3897101879119873 seconds for one epoch ---
--- 0.3218801021575928 seconds for one epoch ---
--- 0.3874845504760742 seconds for one epoch ---
--- 0.3322567939758301 seconds for one epoch ---
--- 0.37879371643066406 seconds for one epoch ---
--- 0.3255002498626709 seconds for one epoch ---
--- 0.37458157539367676 seconds for one epoch ---
--- 0.3388042449951172 seconds for one epoch ---
--- 0.3769798278808594 seconds for one epoch ---
=========================
[[1.        ]
 [0.98614764]
 [1.        ]
 [0.7671328 ]
 [0.23537397]
 [1.        ]
 [0.3094964 ]
 [0.8596602 ]
 [0.23420604]
 [0.2348024 ]
 [0.2690653 ]]
[[ 8.82304251e-01]
 [-2.95548618e-01]
 [-1.91668248e+00]
 [-2.16375902e-01]
 [ 3.94952893e-02]
 [-2.72812176e+00]
 [ 1.40352130e-01]
 [ 2.33039901e-01]
 [ 6.76640135e-04]
 [ 2.72995122e-02]
 [ 1.19796254e-01]]
--- 0.33362245559692383 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 17343.751953125, (11636.062, 2.4402943, 5585.6353, 2.5318046)
   validation loss 4726.44482421875, (3854.7932, 0.14116009, 751.8939, 2.5318046)
decoder loss ratio: 149341.381283, decoder SINDy loss  ratio: 1.623069
--- 0.2693188190460205 seconds for one epoch ---
--- 0.3044009208679199 seconds for one epoch ---
--- 0.38439393043518066 seconds for one epoch ---
--- 0.28988170623779297 seconds for one epoch ---
--- 0.38246679306030273 seconds for one epoch ---
--- 0.3158555030822754 seconds for one epoch ---
--- 0.3965461254119873 seconds for one epoch ---
--- 0.3238365650177002 seconds for one epoch ---
--- 0.40197062492370605 seconds for one epoch ---
--- 0.32311177253723145 seconds for one epoch ---
--- 0.38518548011779785 seconds for one epoch ---
--- 0.32491159439086914 seconds for one epoch ---
--- 0.3830070495605469 seconds for one epoch ---
--- 0.32155275344848633 seconds for one epoch ---
--- 0.35663318634033203 seconds for one epoch ---
--- 0.34355998039245605 seconds for one epoch ---
--- 0.37656211853027344 seconds for one epoch ---
--- 0.3162572383880615 seconds for one epoch ---
--- 0.3915853500366211 seconds for one epoch ---
--- 0.32003045082092285 seconds for one epoch ---
--- 0.3987913131713867 seconds for one epoch ---
--- 0.3239750862121582 seconds for one epoch ---
--- 0.3938922882080078 seconds for one epoch ---
--- 0.31002020835876465 seconds for one epoch ---
=========================
[[0.99999905]
 [0.99957323]
 [1.        ]
 [0.19983017]
 [0.18996155]
 [1.        ]
 [0.21159102]
 [0.8715882 ]
 [0.18418406]
 [0.84449637]
 [0.8281766 ]]
[[ 5.5744457e-01]
 [-3.8461325e-01]
 [-2.0588956e+00]
 [-9.7852543e-02]
 [ 7.3587477e-02]
 [-2.9932938e+00]
 [ 1.1199432e-01]
 [ 2.3762329e-01]
 [-2.6790767e-03]
 [-2.3183163e-01]
 [ 2.2871056e-01]]
--- 0.2777533531188965 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9378.0234375, (4728.1777, 2.8980374, 4516.99, 2.5318248)
   validation loss 5126.1123046875, (4388.443, 0.1693549, 607.5434, 2.5318248)
decoder loss ratio: 170015.895498, decoder SINDy loss  ratio: 1.311468
--- 0.30353355407714844 seconds for one epoch ---
--- 0.38663315773010254 seconds for one epoch ---
--- 0.31761693954467773 seconds for one epoch ---
--- 0.3999154567718506 seconds for one epoch ---
--- 0.30391788482666016 seconds for one epoch ---
--- 0.4157845973968506 seconds for one epoch ---
--- 0.3416423797607422 seconds for one epoch ---
--- 0.3922088146209717 seconds for one epoch ---
--- 0.34059953689575195 seconds for one epoch ---
--- 0.39316749572753906 seconds for one epoch ---
--- 0.312347412109375 seconds for one epoch ---
--- 0.40150952339172363 seconds for one epoch ---
--- 0.31132960319519043 seconds for one epoch ---
--- 0.414334774017334 seconds for one epoch ---
--- 0.3145458698272705 seconds for one epoch ---
--- 0.3954954147338867 seconds for one epoch ---
--- 0.3247392177581787 seconds for one epoch ---
--- 0.39852380752563477 seconds for one epoch ---
--- 0.32184576988220215 seconds for one epoch ---
--- 0.40363621711730957 seconds for one epoch ---
--- 0.3280344009399414 seconds for one epoch ---
--- 0.41675662994384766 seconds for one epoch ---
--- 0.3126850128173828 seconds for one epoch ---
--- 0.4306449890136719 seconds for one epoch ---
=========================
[[0.9951049 ]
 [0.99984884]
 [1.        ]
 [0.16571921]
 [0.15175587]
 [1.        ]
 [0.2459336 ]
 [0.88169104]
 [0.14797089]
 [0.99997693]
 [0.9707119 ]]
[[ 0.3245453 ]
 [-0.41163146]
 [-2.2308922 ]
 [-0.09993166]
 [ 0.0627927 ]
 [-3.1370642 ]
 [ 0.1447274 ]
 [ 0.24130298]
 [-0.00343917]
 [-0.45915917]
 [ 0.2790772 ]]
--- 0.31333017349243164 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10089.42578125, (6197.412, 5.6913524, 3747.1226, 2.5318425)
   validation loss 2706.470947265625, (2027.2184, 0.14077032, 539.9135, 2.5318425)
decoder loss ratio: 78537.959594, decoder SINDy loss  ratio: 1.165479
--- 0.2723500728607178 seconds for one epoch ---
--- 0.30846357345581055 seconds for one epoch ---
--- 0.39330148696899414 seconds for one epoch ---
--- 0.3122234344482422 seconds for one epoch ---
--- 0.3965787887573242 seconds for one epoch ---
--- 0.30752134323120117 seconds for one epoch ---
--- 0.3859889507293701 seconds for one epoch ---
--- 0.3115513324737549 seconds for one epoch ---
--- 0.39801669120788574 seconds for one epoch ---
--- 0.30855607986450195 seconds for one epoch ---
--- 0.42548060417175293 seconds for one epoch ---
--- 0.3302903175354004 seconds for one epoch ---
--- 0.41472721099853516 seconds for one epoch ---
--- 0.31676220893859863 seconds for one epoch ---
--- 0.3966696262359619 seconds for one epoch ---
--- 0.39096975326538086 seconds for one epoch ---
--- 0.40198636054992676 seconds for one epoch ---
--- 0.30499792098999023 seconds for one epoch ---
--- 0.4196805953979492 seconds for one epoch ---
--- 0.31978845596313477 seconds for one epoch ---
--- 0.42575836181640625 seconds for one epoch ---
--- 0.31323719024658203 seconds for one epoch ---
--- 0.41603970527648926 seconds for one epoch ---
--- 0.30559706687927246 seconds for one epoch ---
=========================
[[0.17465197]
 [0.99996924]
 [1.        ]
 [0.1356855 ]
 [0.11838217]
 [1.        ]
 [0.28378096]
 [0.88781685]
 [0.11703938]
 [1.        ]
 [0.99663615]]
[[ 1.2925127e-01]
 [-4.5140606e-01]
 [-2.3372076e+00]
 [-1.0021225e-01]
 [ 3.9366357e-02]
 [-3.2033384e+00]
 [ 1.5926756e-01]
 [ 2.4386284e-01]
 [-3.3504961e-04]
 [-6.8376940e-01]
 [ 3.3486226e-01]]
--- 0.2789950370788574 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6798.7373046875, (3939.2085, 0.8129115, 2711.6255, 2.5318556)
   validation loss 1847.6041259765625, (1209.5004, 0.16943705, 490.8438, 2.5318556)
decoder loss ratio: 46858.143972, decoder SINDy loss  ratio: 1.059555
--- 0.312955379486084 seconds for one epoch ---
--- 0.42130327224731445 seconds for one epoch ---
--- 0.3230173587799072 seconds for one epoch ---
--- 0.4131443500518799 seconds for one epoch ---
--- 0.32095885276794434 seconds for one epoch ---
--- 0.4173576831817627 seconds for one epoch ---
--- 0.3272819519042969 seconds for one epoch ---
--- 0.4283421039581299 seconds for one epoch ---
--- 0.31508946418762207 seconds for one epoch ---
--- 0.4293336868286133 seconds for one epoch ---
--- 0.31859421730041504 seconds for one epoch ---
--- 0.41669631004333496 seconds for one epoch ---
--- 0.31819605827331543 seconds for one epoch ---
--- 0.4127504825592041 seconds for one epoch ---
--- 0.3173232078552246 seconds for one epoch ---
--- 0.4322671890258789 seconds for one epoch ---
--- 0.3048980236053467 seconds for one epoch ---
--- 0.43573665618896484 seconds for one epoch ---
--- 0.31423139572143555 seconds for one epoch ---
--- 0.44422101974487305 seconds for one epoch ---
--- 0.32407665252685547 seconds for one epoch ---
--- 0.42406320571899414 seconds for one epoch ---
--- 0.3151693344116211 seconds for one epoch ---
--- 0.4207003116607666 seconds for one epoch ---
=========================
[[0.09529617]
 [0.99998987]
 [1.        ]
 [0.13283941]
 [0.09553473]
 [1.        ]
 [0.29149494]
 [0.8571228 ]
 [0.09462361]
 [1.        ]
 [0.9996922 ]]
[[-0.02799165]
 [-0.48246244]
 [-2.3986177 ]
 [-0.11788006]
 [ 0.03287697]
 [-3.19427   ]
 [ 0.1636932 ]
 [ 0.23754776]
 [-0.00458873]
 [-0.90161884]
 [ 0.39538556]]
--- 0.29845190048217773 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7491.361328125, (2900.1262, 1.9171226, 4435.0366, 2.5318637)
   validation loss 2030.8553466796875, (1420.7874, 0.19573638, 455.5911, 2.5318637)
decoder loss ratio: 55043.768671, decoder SINDy loss  ratio: 0.983457
--- 0.2782022953033447 seconds for one epoch ---
--- 0.3208274841308594 seconds for one epoch ---
--- 0.42726802825927734 seconds for one epoch ---
--- 0.3293941020965576 seconds for one epoch ---
--- 0.4312102794647217 seconds for one epoch ---
--- 0.3241119384765625 seconds for one epoch ---
--- 0.41162586212158203 seconds for one epoch ---
--- 0.33585286140441895 seconds for one epoch ---
--- 0.43047046661376953 seconds for one epoch ---
--- 0.312424898147583 seconds for one epoch ---
--- 0.41614556312561035 seconds for one epoch ---
--- 0.2935516834259033 seconds for one epoch ---
--- 0.43558192253112793 seconds for one epoch ---
--- 0.33309507369995117 seconds for one epoch ---
--- 0.4364902973175049 seconds for one epoch ---
--- 0.318652868270874 seconds for one epoch ---
--- 0.4416530132293701 seconds for one epoch ---
--- 0.32674551010131836 seconds for one epoch ---
--- 0.45181751251220703 seconds for one epoch ---
--- 0.33990907669067383 seconds for one epoch ---
--- 0.45177721977233887 seconds for one epoch ---
--- 0.32187771797180176 seconds for one epoch ---
--- 0.4615802764892578 seconds for one epoch ---
--- 0.3372459411621094 seconds for one epoch ---
=========================
[[0.4664113 ]
 [0.9999966 ]
 [1.        ]
 [0.15076613]
 [0.07719454]
 [1.        ]
 [0.26021674]
 [0.901513  ]
 [0.07536338]
 [1.        ]
 [0.9999151 ]]
[[-0.18791698]
 [-0.52242845]
 [-2.4331813 ]
 [-0.13526362]
 [ 0.0456764 ]
 [-3.1644952 ]
 [ 0.16104506]
 [ 0.24885602]
 [-0.00546581]
 [-1.1300268 ]
 [ 0.4281899 ]]
--- 0.2690091133117676 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6636.15283203125, (3987.5713, 7.654132, 2480.8062, 2.5318735)
   validation loss 1801.1019287109375, (1196.619, 0.1433321, 444.21783, 2.5318735)
decoder loss ratio: 46359.098201, decoder SINDy loss  ratio: 0.958907
--- 0.3199129104614258 seconds for one epoch ---
--- 0.43166255950927734 seconds for one epoch ---
--- 0.32517504692077637 seconds for one epoch ---
--- 0.4327065944671631 seconds for one epoch ---
--- 0.3334486484527588 seconds for one epoch ---
--- 0.45624876022338867 seconds for one epoch ---
--- 0.328662633895874 seconds for one epoch ---
--- 0.43213915824890137 seconds for one epoch ---
--- 0.3374209403991699 seconds for one epoch ---
--- 0.4286372661590576 seconds for one epoch ---
--- 0.34771203994750977 seconds for one epoch ---
--- 0.43111324310302734 seconds for one epoch ---
--- 0.3080286979675293 seconds for one epoch ---
--- 0.42765259742736816 seconds for one epoch ---
--- 0.29314708709716797 seconds for one epoch ---
--- 0.4222748279571533 seconds for one epoch ---
--- 0.336902379989624 seconds for one epoch ---
--- 0.45174527168273926 seconds for one epoch ---
--- 0.3406360149383545 seconds for one epoch ---
--- 0.4308927059173584 seconds for one epoch ---
--- 0.34096765518188477 seconds for one epoch ---
--- 0.4398322105407715 seconds for one epoch ---
--- 0.32368016242980957 seconds for one epoch ---
--- 0.44689059257507324 seconds for one epoch ---
=========================
[[0.9963404 ]
 [0.9999989 ]
 [1.        ]
 [0.22598043]
 [0.0624817 ]
 [1.        ]
 [0.3968877 ]
 [0.9326224 ]
 [0.0613118 ]
 [1.        ]
 [0.9999896 ]]
[[-0.33428863]
 [-0.56252134]
 [-2.4532208 ]
 [-0.15704028]
 [ 0.03775543]
 [-3.1317878 ]
 [ 0.18103896]
 [ 0.25968066]
 [-0.00843855]
 [-1.3372486 ]
 [ 0.48422423]]
--- 0.3312523365020752 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3527.172119140625, (2077.2537, 0.87221307, 1283.7145, 2.5318835)
   validation loss 2293.009521484375, (1700.4109, 0.13315788, 427.13354, 2.5318835)
decoder loss ratio: 65876.869870, decoder SINDy loss  ratio: 0.922028
--- 0.25001025199890137 seconds for one epoch ---
--- 0.33115053176879883 seconds for one epoch ---
--- 0.4461097717285156 seconds for one epoch ---
--- 0.3326709270477295 seconds for one epoch ---
--- 0.44460272789001465 seconds for one epoch ---
--- 0.3244760036468506 seconds for one epoch ---
--- 0.4580349922180176 seconds for one epoch ---
--- 0.33414125442504883 seconds for one epoch ---
--- 0.4403254985809326 seconds for one epoch ---
--- 0.3181180953979492 seconds for one epoch ---
--- 0.4379425048828125 seconds for one epoch ---
--- 0.3175928592681885 seconds for one epoch ---
--- 0.46387696266174316 seconds for one epoch ---
--- 0.30698633193969727 seconds for one epoch ---
--- 0.45804691314697266 seconds for one epoch ---
--- 0.3198699951171875 seconds for one epoch ---
--- 0.4357891082763672 seconds for one epoch ---
--- 0.2999873161315918 seconds for one epoch ---
--- 0.4464528560638428 seconds for one epoch ---
--- 0.306227445602417 seconds for one epoch ---
--- 0.475344181060791 seconds for one epoch ---
--- 0.2941629886627197 seconds for one epoch ---
--- 0.47112226486206055 seconds for one epoch ---
--- 0.31330323219299316 seconds for one epoch ---
=========================
[[0.99998945]
 [1.        ]
 [1.        ]
 [0.09343523]
 [0.05065326]
 [1.        ]
 [0.480655  ]
 [0.8071806 ]
 [0.04906696]
 [1.        ]
 [0.9999965 ]]
[[-0.48333672]
 [-0.58729357]
 [-2.4579055 ]
 [-0.12047169]
 [ 0.04204158]
 [-3.0905225 ]
 [ 0.19105682]
 [ 0.2299081 ]
 [-0.00431662]
 [-1.5573112 ]
 [ 0.50086296]]
--- 0.2563018798828125 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7183.76171875, (4240.0215, 7.3716717, 2767.0334, 2.5318913)
   validation loss 1703.636474609375, (1129.0558, 0.18763536, 405.05795, 2.5318913)
decoder loss ratio: 43741.581282, decoder SINDy loss  ratio: 0.874375
--- 0.3222312927246094 seconds for one epoch ---
--- 0.4660501480102539 seconds for one epoch ---
--- 0.3360631465911865 seconds for one epoch ---
--- 0.454420804977417 seconds for one epoch ---
--- 0.3403470516204834 seconds for one epoch ---
--- 0.4460580348968506 seconds for one epoch ---
--- 0.333881139755249 seconds for one epoch ---
--- 0.4600675106048584 seconds for one epoch ---
--- 0.34320998191833496 seconds for one epoch ---
--- 0.44621849060058594 seconds for one epoch ---
--- 0.3245575428009033 seconds for one epoch ---
--- 0.46018123626708984 seconds for one epoch ---
--- 0.32346296310424805 seconds for one epoch ---
--- 0.4747004508972168 seconds for one epoch ---
--- 0.3139040470123291 seconds for one epoch ---
--- 0.46089935302734375 seconds for one epoch ---
--- 0.313446044921875 seconds for one epoch ---
--- 0.4547581672668457 seconds for one epoch ---
--- 0.30471205711364746 seconds for one epoch ---
--- 0.4642059803009033 seconds for one epoch ---
--- 0.3322446346282959 seconds for one epoch ---
--- 0.46022701263427734 seconds for one epoch ---
--- 0.3261709213256836 seconds for one epoch ---
--- 0.4612085819244385 seconds for one epoch ---
=========================
[[1.        ]
 [0.9999999 ]
 [1.        ]
 [0.06100211]
 [0.04073362]
 [1.        ]
 [0.5472885 ]
 [0.86176157]
 [0.04014813]
 [1.        ]
 [0.9999964 ]]
[[-0.6151763 ]
 [-0.5798225 ]
 [-2.4741116 ]
 [-0.10104451]
 [ 0.0258184 ]
 [-3.0191424 ]
 [ 0.19852206]
 [ 0.2402409 ]
 [-0.00616608]
 [-1.7714692 ]
 [ 0.5102388 ]]
--- 0.28734612464904785 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4447.56689453125, (2266.7075, 0.61299, 2006.2457, 2.5318983)
   validation loss 2062.111328125, (1480.4528, 0.18349302, 407.4747, 2.5318983)
decoder loss ratio: 57355.310055, decoder SINDy loss  ratio: 0.879591
--- 0.2882678508758545 seconds for one epoch ---
--- 0.3092164993286133 seconds for one epoch ---
--- 0.4491114616394043 seconds for one epoch ---
--- 0.3334391117095947 seconds for one epoch ---
--- 0.4672365188598633 seconds for one epoch ---
--- 0.3396928310394287 seconds for one epoch ---
--- 0.5007874965667725 seconds for one epoch ---
--- 0.35423922538757324 seconds for one epoch ---
--- 0.47904300689697266 seconds for one epoch ---
--- 0.34158825874328613 seconds for one epoch ---
--- 0.49218273162841797 seconds for one epoch ---
--- 0.3297090530395508 seconds for one epoch ---
--- 0.47275209426879883 seconds for one epoch ---
--- 0.3541746139526367 seconds for one epoch ---
--- 0.4576411247253418 seconds for one epoch ---
--- 0.319943904876709 seconds for one epoch ---
--- 0.487346887588501 seconds for one epoch ---
--- 0.31847167015075684 seconds for one epoch ---
--- 0.47898077964782715 seconds for one epoch ---
--- 0.29744863510131836 seconds for one epoch ---
--- 0.4618699550628662 seconds for one epoch ---
--- 0.2972443103790283 seconds for one epoch ---
--- 0.48250484466552734 seconds for one epoch ---
--- 0.3007369041442871 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.0472759 ]
 [0.03337887]
 [1.        ]
 [0.4988793 ]
 [0.86558634]
 [0.03232795]
 [1.        ]
 [0.9999989 ]]
[[-7.4731606e-01]
 [-6.0983539e-01]
 [-2.4608958e+00]
 [-9.2491955e-02]
 [ 3.3690240e-02]
 [-2.9649932e+00]
 [ 1.9389498e-01]
 [ 2.4129251e-01]
 [-2.9351311e-03]
 [-1.9840776e+00]
 [ 5.7074457e-01]]
--- 0.2734649181365967 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7428.484375, (4200.4194, 4.2261004, 3045.9453, 2.5319078)
   validation loss 1803.34228515625, (1216.12, 0.1726929, 409.156, 2.5319078)
decoder loss ratio: 47114.599888, decoder SINDy loss  ratio: 0.883221
--- 0.33572816848754883 seconds for one epoch ---
--- 0.47841668128967285 seconds for one epoch ---
--- 0.334179162979126 seconds for one epoch ---
--- 0.4978320598602295 seconds for one epoch ---
--- 0.33278775215148926 seconds for one epoch ---
--- 0.47463035583496094 seconds for one epoch ---
--- 0.33797740936279297 seconds for one epoch ---
--- 0.4889681339263916 seconds for one epoch ---
--- 0.3521406650543213 seconds for one epoch ---
--- 0.4858105182647705 seconds for one epoch ---
--- 0.3246734142303467 seconds for one epoch ---
--- 0.4964284896850586 seconds for one epoch ---
--- 0.33229804039001465 seconds for one epoch ---
--- 0.4783458709716797 seconds for one epoch ---
--- 0.3381180763244629 seconds for one epoch ---
--- 0.4851222038269043 seconds for one epoch ---
--- 0.3386547565460205 seconds for one epoch ---
--- 0.48944544792175293 seconds for one epoch ---
--- 0.3340158462524414 seconds for one epoch ---
--- 0.4789104461669922 seconds for one epoch ---
--- 0.302196741104126 seconds for one epoch ---
--- 0.48016977310180664 seconds for one epoch ---
--- 0.29332661628723145 seconds for one epoch ---
--- 0.48802947998046875 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.02961829]
 [0.02728154]
 [1.        ]
 [0.27718288]
 [0.83373284]
 [0.02656434]
 [1.        ]
 [1.        ]]
[[-8.7636125e-01]
 [-6.2634045e-01]
 [-2.4644423e+00]
 [-5.4803841e-02]
 [ 2.6767502e-02]
 [-2.9049561e+00]
 [ 1.6921505e-01]
 [ 2.3517880e-01]
 [-1.7005986e-03]
 [-2.1965806e+00]
 [ 6.8164080e-01]]
--- 0.40436553955078125 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4308.6162109375, (2149.8257, 0.60500264, 1976.3499, 2.5319192)
   validation loss 1985.76318359375, (1435.9355, 0.1804961, 367.81128, 2.5319192)
decoder loss ratio: 55630.635980, decoder SINDy loss  ratio: 0.793972
--- 0.25852084159851074 seconds for one epoch ---
--- 0.3181588649749756 seconds for one epoch ---
--- 0.46962618827819824 seconds for one epoch ---
--- 0.3212864398956299 seconds for one epoch ---
--- 0.49315476417541504 seconds for one epoch ---
--- 0.3010830879211426 seconds for one epoch ---
--- 0.49879884719848633 seconds for one epoch ---
--- 0.2984902858734131 seconds for one epoch ---
--- 0.5002362728118896 seconds for one epoch ---
--- 0.31942319869995117 seconds for one epoch ---
--- 0.49491333961486816 seconds for one epoch ---
--- 0.3136172294616699 seconds for one epoch ---
--- 0.4994997978210449 seconds for one epoch ---
--- 0.30460524559020996 seconds for one epoch ---
--- 0.5270788669586182 seconds for one epoch ---
--- 0.3182950019836426 seconds for one epoch ---
--- 0.5070703029632568 seconds for one epoch ---
--- 0.3240797519683838 seconds for one epoch ---
--- 0.5076537132263184 seconds for one epoch ---
--- 0.32994866371154785 seconds for one epoch ---
--- 0.5205056667327881 seconds for one epoch ---
--- 0.30288243293762207 seconds for one epoch ---
--- 0.5090107917785645 seconds for one epoch ---
--- 0.29970574378967285 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.02566236]
 [0.02258042]
 [1.        ]
 [0.12167075]
 [0.8127182 ]
 [0.02153995]
 [1.        ]
 [1.        ]]
[[-1.0039915e+00]
 [-6.4177918e-01]
 [-2.4377651e+00]
 [-6.1308783e-02]
 [ 3.2593962e-02]
 [-2.8616345e+00]
 [ 1.4146024e-01]
 [ 2.3170201e-01]
 [-4.1300216e-04]
 [-2.3958061e+00]
 [ 7.7693623e-01]]
--- 0.269423246383667 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3879.009521484375, (1831.5569, 0.31668004, 1862.4882, 2.531931)
   validation loss 1296.3111572265625, (767.7336, 0.13250549, 343.79718, 2.531931)
decoder loss ratio: 29743.331793, decoder SINDy loss  ratio: 0.742135
--- 0.309342622756958 seconds for one epoch ---
--- 0.5175862312316895 seconds for one epoch ---
--- 0.3243582248687744 seconds for one epoch ---
--- 0.47708606719970703 seconds for one epoch ---
--- 0.32121753692626953 seconds for one epoch ---
--- 0.4943058490753174 seconds for one epoch ---
--- 0.3093726634979248 seconds for one epoch ---
--- 0.4854762554168701 seconds for one epoch ---
--- 0.308762788772583 seconds for one epoch ---
--- 0.5209803581237793 seconds for one epoch ---
--- 0.2918522357940674 seconds for one epoch ---
--- 0.502347469329834 seconds for one epoch ---
--- 0.2966322898864746 seconds for one epoch ---
--- 0.46975255012512207 seconds for one epoch ---
--- 0.30242419242858887 seconds for one epoch ---
--- 0.5230691432952881 seconds for one epoch ---
--- 0.3119347095489502 seconds for one epoch ---
--- 0.5215516090393066 seconds for one epoch ---
--- 0.30604028701782227 seconds for one epoch ---
--- 0.5253787040710449 seconds for one epoch ---
--- 0.3033158779144287 seconds for one epoch ---
--- 0.5105013847351074 seconds for one epoch ---
--- 0.3313584327697754 seconds for one epoch ---
--- 0.5119419097900391 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.02560876]
 [0.01866419]
 [1.        ]
 [0.11690067]
 [0.7838872 ]
 [0.01786408]
 [1.        ]
 [1.        ]]
[[-1.1216158 ]
 [-0.6684386 ]
 [-2.410975  ]
 [-0.07616768]
 [ 0.02888712]
 [-2.8007665 ]
 [ 0.14106306]
 [ 0.22731553]
 [-0.00312332]
 [-2.5948813 ]
 [ 0.83076406]]
--- 0.3077969551086426 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3929.090576171875, (1715.441, 3.263152, 2022.0385, 2.5319412)
   validation loss 1464.3695068359375, (948.1882, 0.13020965, 327.70328, 2.5319412)
decoder loss ratio: 36734.455887, decoder SINDy loss  ratio: 0.707394
--- 0.2709958553314209 seconds for one epoch ---
--- 0.29796600341796875 seconds for one epoch ---
--- 0.5037403106689453 seconds for one epoch ---
--- 0.3263683319091797 seconds for one epoch ---
--- 0.5066897869110107 seconds for one epoch ---
--- 0.2979724407196045 seconds for one epoch ---
--- 0.5086443424224854 seconds for one epoch ---
--- 0.31082940101623535 seconds for one epoch ---
--- 0.5100312232971191 seconds for one epoch ---
--- 0.3005385398864746 seconds for one epoch ---
--- 0.5037052631378174 seconds for one epoch ---
--- 0.30745434761047363 seconds for one epoch ---
--- 0.5102968215942383 seconds for one epoch ---
--- 0.3175013065338135 seconds for one epoch ---
--- 0.5118582248687744 seconds for one epoch ---
--- 0.3033409118652344 seconds for one epoch ---
--- 0.529517412185669 seconds for one epoch ---
--- 0.30772900581359863 seconds for one epoch ---
--- 0.5171964168548584 seconds for one epoch ---
--- 0.30670833587646484 seconds for one epoch ---
--- 0.5180747509002686 seconds for one epoch ---
--- 0.3402128219604492 seconds for one epoch ---
--- 0.5176305770874023 seconds for one epoch ---
--- 0.308290958404541 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.02047186]
 [0.01532407]
 [1.        ]
 [0.10927664]
 [0.805684  ]
 [0.01456176]
 [1.        ]
 [1.        ]]
[[-1.2095026e+00]
 [-6.7107391e-01]
 [-2.3925831e+00]
 [-6.9528796e-02]
 [ 2.7143715e-02]
 [-2.7273114e+00]
 [ 1.3972655e-01]
 [ 2.3077844e-01]
 [ 5.5397971e-04]
 [-2.7528791e+00]
 [ 8.9023197e-01]]
--- 0.2808520793914795 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3090.436279296875, (1730.1683, 4.2695107, 1164.8235, 2.53195)
   validation loss 1345.0244140625, (789.49695, 0.13707483, 364.21518, 2.53195)
decoder loss ratio: 30586.482402, decoder SINDy loss  ratio: 0.786210
--- 0.3206601142883301 seconds for one epoch ---
--- 0.5401499271392822 seconds for one epoch ---
--- 0.3135554790496826 seconds for one epoch ---
--- 0.532806396484375 seconds for one epoch ---
--- 0.31432652473449707 seconds for one epoch ---
--- 0.5379548072814941 seconds for one epoch ---
--- 0.30747032165527344 seconds for one epoch ---
--- 0.5167751312255859 seconds for one epoch ---
--- 0.2952537536621094 seconds for one epoch ---
--- 0.5075383186340332 seconds for one epoch ---
--- 0.3021824359893799 seconds for one epoch ---
--- 0.530064582824707 seconds for one epoch ---
--- 0.3283369541168213 seconds for one epoch ---
--- 0.5173366069793701 seconds for one epoch ---
--- 0.32122230529785156 seconds for one epoch ---
--- 0.5204617977142334 seconds for one epoch ---
--- 0.3073439598083496 seconds for one epoch ---
--- 0.5244386196136475 seconds for one epoch ---
--- 0.30024290084838867 seconds for one epoch ---
--- 0.5239443778991699 seconds for one epoch ---
--- 0.31508398056030273 seconds for one epoch ---
--- 0.5387513637542725 seconds for one epoch ---
--- 0.2914915084838867 seconds for one epoch ---
--- 0.5204243659973145 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.01457187]
 [0.01287672]
 [1.        ]
 [0.23442087]
 [0.74409604]
 [0.01225111]
 [1.        ]
 [1.        ]]
[[-1.353095  ]
 [-0.6555251 ]
 [-2.3325968 ]
 [-0.04949461]
 [ 0.02686338]
 [-2.705916  ]
 [ 0.1647831 ]
 [ 0.22195172]
 [-0.00733283]
 [-2.960239  ]
 [ 0.9318958 ]]
--- 0.2765944004058838 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2813.09716796875, (1384.6763, 1.4954289, 1232.8776, 2.5319629)
   validation loss 1705.265380859375, (1134.3975, 0.15266879, 376.66724, 2.5319629)
decoder loss ratio: 43948.527037, decoder SINDy loss  ratio: 0.813089
THRESHOLDING: 8 active coefficients
--- 0.5435163974761963 seconds for one epoch ---
--- 0.3127720355987549 seconds for one epoch ---
--- 0.5285613536834717 seconds for one epoch ---
--- 0.316009521484375 seconds for one epoch ---
--- 0.5246469974517822 seconds for one epoch ---
--- 0.3014504909515381 seconds for one epoch ---
--- 0.5155594348907471 seconds for one epoch ---
--- 0.3021516799926758 seconds for one epoch ---
--- 0.527449369430542 seconds for one epoch ---
--- 0.3306453227996826 seconds for one epoch ---
--- 0.5355620384216309 seconds for one epoch ---
--- 0.3115956783294678 seconds for one epoch ---
--- 0.5259180068969727 seconds for one epoch ---
--- 0.3089756965637207 seconds for one epoch ---
--- 0.5262713432312012 seconds for one epoch ---
--- 0.3209986686706543 seconds for one epoch ---
--- 0.5285072326660156 seconds for one epoch ---
--- 0.30612802505493164 seconds for one epoch ---
--- 0.541609525680542 seconds for one epoch ---
--- 0.3102850914001465 seconds for one epoch ---
--- 0.5312936305999756 seconds for one epoch ---
--- 0.30759572982788086 seconds for one epoch ---
--- 0.5343987941741943 seconds for one epoch ---
--- 0.31084585189819336 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.02247353]
 [0.76170033]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-1.4907515 ]
 [-0.6851288 ]
 [-2.2016687 ]
 [-0.        ]
 [ 0.        ]
 [-2.552679  ]
 [ 0.08744145]
 [ 0.22439925]
 [-0.        ]
 [-3.2191088 ]
 [ 0.9726667 ]]
--- 0.2628028392791748 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3688.642822265625, (1769.5118, 0.31779873, 1917.1368, 1.6764765)
   validation loss 1685.01904296875, (1326.3005, 0.18175015, 356.86017, 1.6764765)
decoder loss ratio: 51383.185367, decoder SINDy loss  ratio: 0.770333
--- 0.3053162097930908 seconds for one epoch ---
--- 0.5221831798553467 seconds for one epoch ---
--- 0.3072938919067383 seconds for one epoch ---
--- 0.5250821113586426 seconds for one epoch ---
--- 0.314755916595459 seconds for one epoch ---
--- 0.5458328723907471 seconds for one epoch ---
--- 0.33079099655151367 seconds for one epoch ---
--- 0.5243895053863525 seconds for one epoch ---
--- 0.3199195861816406 seconds for one epoch ---
--- 0.5251617431640625 seconds for one epoch ---
--- 0.31511378288269043 seconds for one epoch ---
--- 0.542823314666748 seconds for one epoch ---
--- 0.3209254741668701 seconds for one epoch ---
--- 0.5605175495147705 seconds for one epoch ---
--- 0.3089566230773926 seconds for one epoch ---
--- 0.5618391036987305 seconds for one epoch ---
--- 0.31822752952575684 seconds for one epoch ---
--- 0.5716524124145508 seconds for one epoch ---
--- 0.3056764602661133 seconds for one epoch ---
--- 0.5463962554931641 seconds for one epoch ---
--- 0.3054039478302002 seconds for one epoch ---
--- 0.5398421287536621 seconds for one epoch ---
--- 0.3036508560180664 seconds for one epoch ---
--- 0.5690004825592041 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.04478012]
 [0.6234196 ]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-1.6625078 ]
 [-0.7339721 ]
 [-2.0957153 ]
 [-0.        ]
 [ 0.        ]
 [-2.4781861 ]
 [ 0.1142449 ]
 [ 0.20794219]
 [-0.        ]
 [-3.4806025 ]
 [ 1.0366534 ]]
--- 0.30995893478393555 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5927.45751953125, (3191.7876, 1.764882, 2732.2188, 1.6862643)
   validation loss 1163.248046875, (813.01917, 0.23529157, 348.30734, 1.6862643)
decoder loss ratio: 31497.773917, decoder SINDy loss  ratio: 0.751870
--- 0.26251840591430664 seconds for one epoch ---
--- 0.3049170970916748 seconds for one epoch ---
--- 0.5253736972808838 seconds for one epoch ---
--- 0.3012406826019287 seconds for one epoch ---
--- 0.5413248538970947 seconds for one epoch ---
--- 0.29258298873901367 seconds for one epoch ---
--- 0.5578899383544922 seconds for one epoch ---
--- 0.3342292308807373 seconds for one epoch ---
--- 0.5364170074462891 seconds for one epoch ---
--- 0.3163034915924072 seconds for one epoch ---
--- 0.5419294834136963 seconds for one epoch ---
--- 0.3119392395019531 seconds for one epoch ---
--- 0.5710849761962891 seconds for one epoch ---
--- 0.30873560905456543 seconds for one epoch ---
--- 0.5503005981445312 seconds for one epoch ---
--- 0.28861546516418457 seconds for one epoch ---
--- 0.5490829944610596 seconds for one epoch ---
--- 0.28968167304992676 seconds for one epoch ---
--- 0.5753867626190186 seconds for one epoch ---
--- 0.29813218116760254 seconds for one epoch ---
--- 0.5606338977813721 seconds for one epoch ---
--- 0.3207693099975586 seconds for one epoch ---
--- 0.5587790012359619 seconds for one epoch ---
--- 0.32332754135131836 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.06296709]
 [0.6146959 ]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-1.8276887 ]
 [-0.7189871 ]
 [-1.9811974 ]
 [-0.        ]
 [ 0.        ]
 [-2.4405887 ]
 [ 0.12540302]
 [ 0.20707119]
 [-0.        ]
 [-3.7154312 ]
 [ 1.0862645 ]]
--- 0.25611233711242676 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2054.72216796875, (1026.7896, 1.3661991, 1024.8812, 1.6849507)
   validation loss 2039.9017333984375, (1712.2147, 0.20389538, 325.79816, 1.6849507)
decoder loss ratio: 66334.170853, decoder SINDy loss  ratio: 0.703281
--- 0.2954239845275879 seconds for one epoch ---
--- 0.5662064552307129 seconds for one epoch ---
--- 0.3063793182373047 seconds for one epoch ---
--- 0.5354478359222412 seconds for one epoch ---
--- 0.30924034118652344 seconds for one epoch ---
--- 0.5606722831726074 seconds for one epoch ---
--- 0.29697132110595703 seconds for one epoch ---
--- 0.5598196983337402 seconds for one epoch ---
--- 0.2939016819000244 seconds for one epoch ---
--- 0.5631208419799805 seconds for one epoch ---
--- 0.31551146507263184 seconds for one epoch ---
--- 0.5690407752990723 seconds for one epoch ---
--- 0.3103482723236084 seconds for one epoch ---
--- 0.6069173812866211 seconds for one epoch ---
--- 0.31883931159973145 seconds for one epoch ---
--- 0.604947566986084 seconds for one epoch ---
--- 0.3375704288482666 seconds for one epoch ---
--- 0.5865771770477295 seconds for one epoch ---
--- 0.3213155269622803 seconds for one epoch ---
--- 0.5941276550292969 seconds for one epoch ---
--- 0.3310999870300293 seconds for one epoch ---
--- 0.6063981056213379 seconds for one epoch ---
--- 0.32012176513671875 seconds for one epoch ---
--- 0.5948371887207031 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.01867854]
 [0.70169336]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-1.9214342 ]
 [-0.703559  ]
 [-1.8814917 ]
 [-0.        ]
 [ 0.        ]
 [-2.3268754 ]
 [ 0.08795149]
 [ 0.21685225]
 [-0.        ]
 [-3.8821921 ]
 [ 1.0910641 ]]
--- 0.31848740577697754 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3178.546142578125, (1516.7228, 1.6740453, 1658.4778, 1.6716006)
   validation loss 1746.087890625, (1389.5416, 0.22091232, 354.65372, 1.6716006)
decoder loss ratio: 53833.254941, decoder SINDy loss  ratio: 0.765570
--- 0.29001712799072266 seconds for one epoch ---
--- 0.33298611640930176 seconds for one epoch ---
--- 0.5850574970245361 seconds for one epoch ---
--- 0.33545756340026855 seconds for one epoch ---
--- 0.5772600173950195 seconds for one epoch ---
--- 0.3104708194732666 seconds for one epoch ---
--- 0.566272497177124 seconds for one epoch ---
--- 0.30094480514526367 seconds for one epoch ---
--- 0.574291467666626 seconds for one epoch ---
--- 0.3065178394317627 seconds for one epoch ---
--- 0.5922584533691406 seconds for one epoch ---
--- 0.3204050064086914 seconds for one epoch ---
--- 0.6085925102233887 seconds for one epoch ---
--- 0.3303830623626709 seconds for one epoch ---
--- 0.6003005504608154 seconds for one epoch ---
--- 0.3336029052734375 seconds for one epoch ---
--- 0.582963228225708 seconds for one epoch ---
--- 0.3515307903289795 seconds for one epoch ---
--- 0.5961916446685791 seconds for one epoch ---
--- 0.3365049362182617 seconds for one epoch ---
--- 0.5925431251525879 seconds for one epoch ---
--- 0.33339667320251465 seconds for one epoch ---
--- 0.5544774532318115 seconds for one epoch ---
--- 0.3389101028442383 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.02876132]
 [0.41729322]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.0169778 ]
 [-0.7345169 ]
 [-1.8350037 ]
 [-0.        ]
 [ 0.        ]
 [-2.1982224 ]
 [ 0.10339294]
 [ 0.1870383 ]
 [-0.        ]
 [-4.06154   ]
 [ 1.1519235 ]]
--- 0.26949119567871094 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2168.207275390625, (1406.2467, 3.9421234, 756.37164, 1.6466564)
   validation loss 1695.2642822265625, (1290.3478, 0.16035566, 403.10947, 1.6466564)
decoder loss ratio: 49990.313074, decoder SINDy loss  ratio: 0.870168
--- 0.28819727897644043 seconds for one epoch ---
--- 0.5856482982635498 seconds for one epoch ---
--- 0.43967127799987793 seconds for one epoch ---
--- 0.5739121437072754 seconds for one epoch ---
--- 0.28960466384887695 seconds for one epoch ---
--- 0.5701580047607422 seconds for one epoch ---
--- 0.30412936210632324 seconds for one epoch ---
--- 0.5813772678375244 seconds for one epoch ---
--- 0.2984919548034668 seconds for one epoch ---
--- 0.5746867656707764 seconds for one epoch ---
--- 0.29897022247314453 seconds for one epoch ---
--- 0.602475643157959 seconds for one epoch ---
--- 0.3163180351257324 seconds for one epoch ---
--- 0.5910933017730713 seconds for one epoch ---
--- 0.3130178451538086 seconds for one epoch ---
--- 0.5992567539215088 seconds for one epoch ---
--- 0.3056786060333252 seconds for one epoch ---
--- 0.6060106754302979 seconds for one epoch ---
--- 0.3218545913696289 seconds for one epoch ---
--- 0.5999438762664795 seconds for one epoch ---
--- 0.3042478561401367 seconds for one epoch ---
--- 0.5973525047302246 seconds for one epoch ---
--- 0.339735746383667 seconds for one epoch ---
--- 0.5886721611022949 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.02791885]
 [0.47020003]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.1357808 ]
 [-0.7825398 ]
 [-1.7277348 ]
 [-0.        ]
 [ 0.        ]
 [-2.1466115 ]
 [ 0.10324966]
 [ 0.19247279]
 [-0.        ]
 [-4.2347317 ]
 [ 1.2354203 ]]
--- 0.3060328960418701 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2603.602783203125, (1195.9148, 0.52264625, 1405.5143, 1.6512355)
   validation loss 1173.7122802734375, (852.5054, 0.15107024, 319.40463, 1.6512355)
decoder loss ratio: 33027.538091, decoder SINDy loss  ratio: 0.689480
--- 0.25867152214050293 seconds for one epoch ---
--- 0.3280205726623535 seconds for one epoch ---
--- 0.600322961807251 seconds for one epoch ---
--- 0.328951358795166 seconds for one epoch ---
--- 0.6021728515625 seconds for one epoch ---
--- 0.3126378059387207 seconds for one epoch ---
--- 0.5918498039245605 seconds for one epoch ---
--- 0.3002619743347168 seconds for one epoch ---
--- 0.5998399257659912 seconds for one epoch ---
--- 0.3003382682800293 seconds for one epoch ---
--- 0.6120278835296631 seconds for one epoch ---
--- 0.2998213768005371 seconds for one epoch ---
--- 0.5827209949493408 seconds for one epoch ---
--- 0.29781055450439453 seconds for one epoch ---
--- 0.5971536636352539 seconds for one epoch ---
--- 0.3033277988433838 seconds for one epoch ---
--- 0.5935401916503906 seconds for one epoch ---
--- 0.30747461318969727 seconds for one epoch ---
--- 0.61995530128479 seconds for one epoch ---
--- 0.29778504371643066 seconds for one epoch ---
--- 0.6043474674224854 seconds for one epoch ---
--- 0.30622076988220215 seconds for one epoch ---
--- 0.6239168643951416 seconds for one epoch ---
--- 0.3009059429168701 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.11009355]
 [0.40954715]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.2060933 ]
 [-0.7806106 ]
 [-1.6443183 ]
 [-0.        ]
 [ 0.        ]
 [-2.050874  ]
 [ 0.14268245]
 [ 0.186319  ]
 [-0.        ]
 [-4.3500004 ]
 [ 1.291826  ]]
--- 0.27522969245910645 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3296.96337890625, (1997.7255, 2.5036826, 1295.0508, 1.6835836)
   validation loss 1198.438720703125, (885.0984, 0.120488815, 311.5363, 1.6835836)
decoder loss ratio: 34290.248176, decoder SINDy loss  ratio: 0.672495
--- 0.32509875297546387 seconds for one epoch ---
--- 0.6237761974334717 seconds for one epoch ---
--- 0.332411527633667 seconds for one epoch ---
--- 0.6247260570526123 seconds for one epoch ---
--- 0.3408050537109375 seconds for one epoch ---
--- 0.6094479560852051 seconds for one epoch ---
--- 0.34644365310668945 seconds for one epoch ---
--- 0.6153628826141357 seconds for one epoch ---
--- 0.31120991706848145 seconds for one epoch ---
--- 0.6032850742340088 seconds for one epoch ---
--- 0.2936980724334717 seconds for one epoch ---
--- 0.6070408821105957 seconds for one epoch ---
--- 0.3037147521972656 seconds for one epoch ---
--- 0.5846953392028809 seconds for one epoch ---
--- 0.30521440505981445 seconds for one epoch ---
--- 0.6085894107818604 seconds for one epoch ---
--- 0.3008885383605957 seconds for one epoch ---
--- 0.6080000400543213 seconds for one epoch ---
--- 0.31359028816223145 seconds for one epoch ---
--- 0.6058323383331299 seconds for one epoch ---
--- 0.3038604259490967 seconds for one epoch ---
--- 0.6071164608001709 seconds for one epoch ---
--- 0.2926063537597656 seconds for one epoch ---
--- 0.6221902370452881 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.05246609]
 [0.3128281 ]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.2739305 ]
 [-0.80409586]
 [-1.5807799 ]
 [-0.        ]
 [ 0.        ]
 [-1.9629599 ]
 [ 0.12201162]
 [ 0.17576976]
 [-0.        ]
 [-4.457403  ]
 [ 1.3022299 ]]
--- 0.3005356788635254 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2813.561279296875, (1802.3147, 0.89291054, 1008.71185, 1.6419362)
   validation loss 1188.8472900390625, (870.93225, 0.18270907, 316.0904, 1.6419362)
decoder loss ratio: 33741.427408, decoder SINDy loss  ratio: 0.682326
--- 0.2938089370727539 seconds for one epoch ---
--- 0.29846930503845215 seconds for one epoch ---
--- 0.6184778213500977 seconds for one epoch ---
--- 0.32380151748657227 seconds for one epoch ---
--- 0.6400086879730225 seconds for one epoch ---
--- 0.3242647647857666 seconds for one epoch ---
--- 0.6435956954956055 seconds for one epoch ---
--- 0.317903995513916 seconds for one epoch ---
--- 0.6223466396331787 seconds for one epoch ---
--- 0.32599401473999023 seconds for one epoch ---
--- 0.6131253242492676 seconds for one epoch ---
--- 0.3000185489654541 seconds for one epoch ---
--- 0.6315486431121826 seconds for one epoch ---
--- 0.305330753326416 seconds for one epoch ---
--- 0.6292450428009033 seconds for one epoch ---
--- 0.29614782333374023 seconds for one epoch ---
--- 0.6347734928131104 seconds for one epoch ---
--- 0.33513545989990234 seconds for one epoch ---
--- 0.6206514835357666 seconds for one epoch ---
--- 0.3303349018096924 seconds for one epoch ---
--- 0.6242344379425049 seconds for one epoch ---
--- 0.3286881446838379 seconds for one epoch ---
--- 0.6187899112701416 seconds for one epoch ---
--- 0.32956624031066895 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.07962044]
 [0.40768373]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.3318229 ]
 [-0.82138836]
 [-1.5266213 ]
 [-0.        ]
 [ 0.        ]
 [-1.8725786 ]
 [ 0.13375941]
 [ 0.18618302]
 [-0.        ]
 [-4.5579433 ]
 [ 1.2736808 ]]
--- 0.2598252296447754 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4162.95751953125, (2103.892, 0.53339326, 2056.8577, 1.674281)
   validation loss 1325.7584228515625, (1009.341, 0.14867936, 314.59445, 1.674281)
decoder loss ratio: 39103.622765, decoder SINDy loss  ratio: 0.679096
--- 0.3035717010498047 seconds for one epoch ---
--- 0.6306731700897217 seconds for one epoch ---
--- 0.29848480224609375 seconds for one epoch ---
--- 0.624819278717041 seconds for one epoch ---
--- 0.30680060386657715 seconds for one epoch ---
--- 0.6245832443237305 seconds for one epoch ---
--- 0.29237961769104004 seconds for one epoch ---
--- 0.6541070938110352 seconds for one epoch ---
--- 0.30155038833618164 seconds for one epoch ---
--- 0.6447527408599854 seconds for one epoch ---
--- 0.29975390434265137 seconds for one epoch ---
--- 0.623955488204956 seconds for one epoch ---
--- 0.3036336898803711 seconds for one epoch ---
--- 0.6492056846618652 seconds for one epoch ---
--- 0.3038804531097412 seconds for one epoch ---
--- 0.6443865299224854 seconds for one epoch ---
--- 0.2987985610961914 seconds for one epoch ---
--- 0.61747145652771 seconds for one epoch ---
--- 0.3377494812011719 seconds for one epoch ---
--- 0.6475932598114014 seconds for one epoch ---
--- 0.3279554843902588 seconds for one epoch ---
--- 0.6488370895385742 seconds for one epoch ---
--- 0.33984804153442383 seconds for one epoch ---
--- 0.6514725685119629 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.05315556]
 [0.2703136 ]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.418975  ]
 [-0.8767348 ]
 [-1.4747636 ]
 [-0.        ]
 [ 0.        ]
 [-1.8373636 ]
 [ 0.12275665]
 [ 0.17065553]
 [-0.        ]
 [-4.661003  ]
 [ 1.2264735 ]]
--- 0.3214449882507324 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3401.97265625, (947.2172, 2.0208247, 2451.09, 1.6444844)
   validation loss 1009.244384765625, (720.1955, 0.11123025, 287.2932, 1.6444844)
decoder loss ratio: 27901.623814, decoder SINDy loss  ratio: 0.620163
--- 0.2767519950866699 seconds for one epoch ---
--- 0.3409426212310791 seconds for one epoch ---
--- 0.6490659713745117 seconds for one epoch ---
--- 0.33207273483276367 seconds for one epoch ---
--- 0.6326260566711426 seconds for one epoch ---
--- 0.3293318748474121 seconds for one epoch ---
--- 0.6318535804748535 seconds for one epoch ---
--- 0.32938075065612793 seconds for one epoch ---
--- 0.6558091640472412 seconds for one epoch ---
--- 0.3281686305999756 seconds for one epoch ---
--- 0.6373038291931152 seconds for one epoch ---
--- 0.3143000602722168 seconds for one epoch ---
--- 0.6860988140106201 seconds for one epoch ---
--- 0.31183648109436035 seconds for one epoch ---
--- 0.6468322277069092 seconds for one epoch ---
--- 0.2982017993927002 seconds for one epoch ---
--- 0.6352741718292236 seconds for one epoch ---
--- 0.2969682216644287 seconds for one epoch ---
--- 0.6203420162200928 seconds for one epoch ---
--- 0.30926012992858887 seconds for one epoch ---
--- 0.6487929821014404 seconds for one epoch ---
--- 0.3010108470916748 seconds for one epoch ---
--- 0.6505155563354492 seconds for one epoch ---
--- 0.2984504699707031 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.12007897]
 [0.19436823]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.537914  ]
 [-0.8317193 ]
 [-1.4446872 ]
 [-0.        ]
 [ 0.        ]
 [-1.8033221 ]
 [ 0.14553137]
 [ 0.1599043 ]
 [-0.        ]
 [-4.7978306 ]
 [ 1.2314258 ]]
--- 0.2649059295654297 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7827.9326171875, (4556.9277, 2.1463106, 3267.2188, 1.6394681)
   validation loss 2312.3056640625, (2025.0482, 0.14607787, 285.47202, 1.6394681)
decoder loss ratio: 78453.883595, decoder SINDy loss  ratio: 0.616231
--- 0.3004591464996338 seconds for one epoch ---
--- 0.656329870223999 seconds for one epoch ---
--- 0.3070857524871826 seconds for one epoch ---
--- 0.6614594459533691 seconds for one epoch ---
--- 0.3027989864349365 seconds for one epoch ---
--- 0.6579844951629639 seconds for one epoch ---
--- 0.3096272945404053 seconds for one epoch ---
--- 0.6631865501403809 seconds for one epoch ---
--- 0.3067936897277832 seconds for one epoch ---
--- 0.6757192611694336 seconds for one epoch ---
--- 0.32511115074157715 seconds for one epoch ---
--- 0.6879751682281494 seconds for one epoch ---
--- 0.33060765266418457 seconds for one epoch ---
--- 0.649587869644165 seconds for one epoch ---
--- 0.30296993255615234 seconds for one epoch ---
--- 0.6575908660888672 seconds for one epoch ---
--- 0.30928802490234375 seconds for one epoch ---
--- 0.6561145782470703 seconds for one epoch ---
--- 0.30129408836364746 seconds for one epoch ---
--- 0.6354358196258545 seconds for one epoch ---
--- 0.30604076385498047 seconds for one epoch ---
--- 0.6605641841888428 seconds for one epoch ---
--- 0.31293392181396484 seconds for one epoch ---
--- 0.6840078830718994 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.06281807]
 [0.18037021]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.6201024 ]
 [-0.8962414 ]
 [-1.3778982 ]
 [-0.        ]
 [ 0.        ]
 [-1.7647449 ]
 [ 0.12754859]
 [ 0.15762171]
 [-0.        ]
 [-4.8963733 ]
 [ 1.1451945 ]]
--- 0.31874847412109375 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3840.437255859375, (1610.8992, 1.0529076, 2226.8462, 1.6389264)
   validation loss 850.4723510742188, (546.3019, 0.19056393, 302.341, 1.6389264)
decoder loss ratio: 21164.683248, decoder SINDy loss  ratio: 0.652646
--- 0.2624697685241699 seconds for one epoch ---
--- 0.3145487308502197 seconds for one epoch ---
--- 0.6602497100830078 seconds for one epoch ---
--- 0.30415987968444824 seconds for one epoch ---
--- 0.6758382320404053 seconds for one epoch ---
--- 0.287883996963501 seconds for one epoch ---
--- 0.6589090824127197 seconds for one epoch ---
--- 0.29721832275390625 seconds for one epoch ---
--- 0.6601734161376953 seconds for one epoch ---
--- 0.3102757930755615 seconds for one epoch ---
--- 0.6539325714111328 seconds for one epoch ---
--- 0.30173611640930176 seconds for one epoch ---
--- 0.6849000453948975 seconds for one epoch ---
--- 0.2981603145599365 seconds for one epoch ---
--- 0.6649837493896484 seconds for one epoch ---
--- 0.29898977279663086 seconds for one epoch ---
--- 0.6969711780548096 seconds for one epoch ---
--- 0.3060035705566406 seconds for one epoch ---
--- 0.6707141399383545 seconds for one epoch ---
--- 0.3005070686340332 seconds for one epoch ---
--- 0.6680645942687988 seconds for one epoch ---
--- 0.30115580558776855 seconds for one epoch ---
--- 0.6823692321777344 seconds for one epoch ---
--- 0.32445335388183594 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.03851722]
 [0.23167266]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.699522  ]
 [-0.8724925 ]
 [-1.3689166 ]
 [-0.        ]
 [ 0.        ]
 [-1.7126915 ]
 [ 0.1144779 ]
 [ 0.16556072]
 [-0.        ]
 [-4.993407  ]
 [ 1.1160232 ]]
--- 0.27400803565979004 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3548.049560546875, (2124.9888, 18.113144, 1403.3208, 1.6270059)
   validation loss 1515.4501953125, (1135.7396, 0.124060065, 377.9596, 1.6270059)
decoder loss ratio: 44000.524765, decoder SINDy loss  ratio: 0.815879
--- 0.315584659576416 seconds for one epoch ---
--- 0.6829297542572021 seconds for one epoch ---
--- 0.32148313522338867 seconds for one epoch ---
--- 0.6817858219146729 seconds for one epoch ---
--- 0.32218384742736816 seconds for one epoch ---
--- 0.6966710090637207 seconds for one epoch ---
--- 0.3317885398864746 seconds for one epoch ---
--- 0.6821093559265137 seconds for one epoch ---
--- 0.33289146423339844 seconds for one epoch ---
--- 0.7144925594329834 seconds for one epoch ---
--- 0.33217406272888184 seconds for one epoch ---
--- 0.6867990493774414 seconds for one epoch ---
--- 0.32885241508483887 seconds for one epoch ---
--- 0.6857953071594238 seconds for one epoch ---
--- 0.34550905227661133 seconds for one epoch ---
--- 0.6902773380279541 seconds for one epoch ---
--- 0.3097548484802246 seconds for one epoch ---
--- 0.7031784057617188 seconds for one epoch ---
--- 0.3031597137451172 seconds for one epoch ---
--- 0.6978011131286621 seconds for one epoch ---
--- 0.3017854690551758 seconds for one epoch ---
--- 0.7001237869262695 seconds for one epoch ---
--- 0.2942202091217041 seconds for one epoch ---
--- 0.711904764175415 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.22776403]
 [0.19825965]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.782822  ]
 [-0.8403125 ]
 [-1.3208723 ]
 [-0.        ]
 [ 0.        ]
 [-1.6928796 ]
 [ 0.16502434]
 [ 0.16060232]
 [-0.        ]
 [-5.0674405 ]
 [ 1.1772903 ]]
--- 0.3123006820678711 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3758.380615234375, (1736.5879, 4.4246254, 2015.6871, 1.6809845)
   validation loss 976.8287963867188, (665.46436, 0.09613809, 309.58737, 1.6809845)
decoder loss ratio: 25781.244428, decoder SINDy loss  ratio: 0.668288
--- 0.26181769371032715 seconds for one epoch ---
--- 0.294536828994751 seconds for one epoch ---
--- 0.6682446002960205 seconds for one epoch ---
--- 0.3027791976928711 seconds for one epoch ---
--- 0.6591219902038574 seconds for one epoch ---
--- 0.3006463050842285 seconds for one epoch ---
--- 0.6708874702453613 seconds for one epoch ---
--- 0.2998802661895752 seconds for one epoch ---
--- 0.7016310691833496 seconds for one epoch ---
--- 0.31147122383117676 seconds for one epoch ---
--- 0.6863434314727783 seconds for one epoch ---
--- 0.312044620513916 seconds for one epoch ---
--- 0.7073972225189209 seconds for one epoch ---
--- 0.3156909942626953 seconds for one epoch ---
--- 0.700528621673584 seconds for one epoch ---
--- 0.3336656093597412 seconds for one epoch ---
--- 0.7163572311401367 seconds for one epoch ---
--- 0.32800889015197754 seconds for one epoch ---
--- 0.6885025501251221 seconds for one epoch ---
--- 0.30742883682250977 seconds for one epoch ---
--- 0.7022585868835449 seconds for one epoch ---
--- 0.3022325038909912 seconds for one epoch ---
--- 0.7139031887054443 seconds for one epoch ---
--- 0.31591296195983887 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.03983017]
 [0.20673539]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.862417  ]
 [-0.8435687 ]
 [-1.2932111 ]
 [-0.        ]
 [ 0.        ]
 [-1.6569815 ]
 [ 0.11557524]
 [ 0.16193776]
 [-0.        ]
 [-5.1464453 ]
 [ 1.1100903 ]]
--- 0.26162219047546387 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4295.5302734375, (1554.1847, 0.78429127, 2738.9292, 1.6319445)
   validation loss 1172.83837890625, (886.1239, 0.101504445, 284.98105, 1.6319445)
decoder loss ratio: 34329.978318, decoder SINDy loss  ratio: 0.615172
--- 0.3054046630859375 seconds for one epoch ---
--- 0.6938812732696533 seconds for one epoch ---
--- 0.27529191970825195 seconds for one epoch ---
--- 0.685070276260376 seconds for one epoch ---
--- 0.2994534969329834 seconds for one epoch ---
--- 0.6816771030426025 seconds for one epoch ---
--- 0.3031184673309326 seconds for one epoch ---
--- 0.7032537460327148 seconds for one epoch ---
--- 0.29513001441955566 seconds for one epoch ---
--- 0.7064926624298096 seconds for one epoch ---
--- 0.28559041023254395 seconds for one epoch ---
--- 0.6893739700317383 seconds for one epoch ---
--- 0.31253719329833984 seconds for one epoch ---
--- 0.7125084400177002 seconds for one epoch ---
--- 0.3060722351074219 seconds for one epoch ---
--- 0.7120814323425293 seconds for one epoch ---
--- 0.2962679862976074 seconds for one epoch ---
--- 0.7216250896453857 seconds for one epoch ---
--- 0.3202395439147949 seconds for one epoch ---
--- 0.7164671421051025 seconds for one epoch ---
--- 0.3105738162994385 seconds for one epoch ---
--- 0.7168042659759521 seconds for one epoch ---
--- 0.3039722442626953 seconds for one epoch ---
--- 0.703819751739502 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.06104571]
 [0.16689211]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-2.958471  ]
 [-0.87131906]
 [-1.2594384 ]
 [-0.        ]
 [ 0.        ]
 [-1.648997  ]
 [ 0.12703596]
 [ 0.15535325]
 [-0.        ]
 [-5.2365775 ]
 [ 1.0790097 ]]
--- 0.32627391815185547 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4789.25341796875, (2603.393, 6.555745, 2177.6792, 1.6256497)
   validation loss 1514.01171875, (1127.9822, 0.15767011, 384.2462, 1.6256497)
decoder loss ratio: 43699.987829, decoder SINDy loss  ratio: 0.829449
--- 0.2712376117706299 seconds for one epoch ---
--- 0.328657865524292 seconds for one epoch ---
--- 0.7058842182159424 seconds for one epoch ---
--- 0.34228992462158203 seconds for one epoch ---
--- 0.7059898376464844 seconds for one epoch ---
--- 0.34236598014831543 seconds for one epoch ---
--- 0.6982142925262451 seconds for one epoch ---
--- 0.34238576889038086 seconds for one epoch ---
--- 0.719667911529541 seconds for one epoch ---
--- 0.34289050102233887 seconds for one epoch ---
--- 0.7048914432525635 seconds for one epoch ---
--- 0.3267350196838379 seconds for one epoch ---
--- 0.7173256874084473 seconds for one epoch ---
--- 0.4907071590423584 seconds for one epoch ---
--- 0.7104120254516602 seconds for one epoch ---
--- 0.33014750480651855 seconds for one epoch ---
--- 0.7207398414611816 seconds for one epoch ---
--- 0.32880234718322754 seconds for one epoch ---
--- 0.7354183197021484 seconds for one epoch ---
--- 0.33641910552978516 seconds for one epoch ---
--- 0.7286040782928467 seconds for one epoch ---
--- 0.3014712333679199 seconds for one epoch ---
--- 0.7049655914306641 seconds for one epoch ---
--- 0.2993149757385254 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.12287965]
 [0.18124798]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-3.038884  ]
 [-0.884108  ]
 [-1.2502773 ]
 [-0.        ]
 [ 0.        ]
 [-1.603812  ]
 [ 0.14639568]
 [ 0.1578739 ]
 [-0.        ]
 [-5.330795  ]
 [ 1.1292202 ]]
--- 0.2666471004486084 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3471.424072265625, (1544.9509, 2.1671362, 1922.6516, 1.6545495)
   validation loss 1504.1734619140625, (1106.1528, 0.15707368, 396.20898, 1.6545495)
decoder loss ratio: 42854.281079, decoder SINDy loss  ratio: 0.855273
--- 0.30099058151245117 seconds for one epoch ---
--- 0.7200431823730469 seconds for one epoch ---
--- 0.29427337646484375 seconds for one epoch ---
--- 0.7082695960998535 seconds for one epoch ---
--- 0.29543137550354004 seconds for one epoch ---
--- 0.715325117111206 seconds for one epoch ---
--- 0.2978541851043701 seconds for one epoch ---
--- 0.7332777976989746 seconds for one epoch ---
--- 0.295931339263916 seconds for one epoch ---
--- 0.7612926959991455 seconds for one epoch ---
--- 0.3007833957672119 seconds for one epoch ---
--- 0.7570736408233643 seconds for one epoch ---
--- 0.310516357421875 seconds for one epoch ---
--- 0.7554409503936768 seconds for one epoch ---
--- 0.30922746658325195 seconds for one epoch ---
--- 0.7295167446136475 seconds for one epoch ---
--- 0.30390477180480957 seconds for one epoch ---
--- 0.7446038722991943 seconds for one epoch ---
--- 0.30675649642944336 seconds for one epoch ---
--- 0.7366764545440674 seconds for one epoch ---
--- 0.31796717643737793 seconds for one epoch ---
--- 0.7108907699584961 seconds for one epoch ---
--- 0.307049036026001 seconds for one epoch ---
--- 0.745065450668335 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.10030539]
 [0.15598676]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-3.1017609 ]
 [-0.8756717 ]
 [-1.2405937 ]
 [-0.        ]
 [ 0.        ]
 [-1.5577048 ]
 [ 0.14067854]
 [ 0.15336117]
 [-0.        ]
 [-5.3923473 ]
 [ 1.0469131 ]]
--- 0.29842662811279297 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4140.701171875, (1758.0474, 1.5357646, 2379.4836, 1.6342013)
   validation loss 1515.4822998046875, (1135.9965, 0.17823806, 377.67346, 1.6342013)
decoder loss ratio: 44010.475035, decoder SINDy loss  ratio: 0.815261
--- 0.24201703071594238 seconds for one epoch ---
--- 0.3039116859436035 seconds for one epoch ---
--- 0.7323572635650635 seconds for one epoch ---
--- 0.3121800422668457 seconds for one epoch ---
--- 0.7132041454315186 seconds for one epoch ---
--- 0.29774951934814453 seconds for one epoch ---
--- 0.7412948608398438 seconds for one epoch ---
--- 0.33395862579345703 seconds for one epoch ---
--- 0.7502233982086182 seconds for one epoch ---
--- 0.3266737461090088 seconds for one epoch ---
--- 0.761486291885376 seconds for one epoch ---
--- 0.3372306823730469 seconds for one epoch ---
--- 0.7439870834350586 seconds for one epoch ---
--- 0.3353583812713623 seconds for one epoch ---
--- 0.7766079902648926 seconds for one epoch ---
--- 0.33612847328186035 seconds for one epoch ---
--- 0.7753422260284424 seconds for one epoch ---
--- 0.33696532249450684 seconds for one epoch ---
--- 0.7648627758026123 seconds for one epoch ---
--- 0.3318467140197754 seconds for one epoch ---
--- 0.7741858959197998 seconds for one epoch ---
--- 0.3197596073150635 seconds for one epoch ---
--- 0.7516725063323975 seconds for one epoch ---
--- 0.3293018341064453 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.10334634]
 [0.11835699]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-3.1782894 ]
 [-0.8944868 ]
 [-1.2261276 ]
 [-0.        ]
 [ 0.        ]
 [-1.5357981 ]
 [ 0.14153181]
 [ 0.14535807]
 [-0.        ]
 [-5.4570055 ]
 [ 1.012856  ]]
--- 0.25866007804870605 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4946.20458984375, (2605.518, 1.5556284, 2337.497, 1.6339401)
   validation loss 2782.841796875, (2291.1367, 0.08378657, 489.9872, 1.6339401)
decoder loss ratio: 88762.614073, decoder SINDy loss  ratio: 1.057706
--- 0.29631686210632324 seconds for one epoch ---
--- 0.7201051712036133 seconds for one epoch ---
--- 0.3038480281829834 seconds for one epoch ---
--- 0.7307729721069336 seconds for one epoch ---
--- 0.29356908798217773 seconds for one epoch ---
--- 0.7260415554046631 seconds for one epoch ---
--- 0.30257344245910645 seconds for one epoch ---
--- 0.7292971611022949 seconds for one epoch ---
--- 0.29758715629577637 seconds for one epoch ---
--- 0.7533767223358154 seconds for one epoch ---
--- 0.2898848056793213 seconds for one epoch ---
--- 0.7429914474487305 seconds for one epoch ---
--- 0.30961036682128906 seconds for one epoch ---
--- 0.7463901042938232 seconds for one epoch ---
--- 0.2988929748535156 seconds for one epoch ---
--- 0.764385461807251 seconds for one epoch ---
--- 0.30013585090637207 seconds for one epoch ---
--- 0.7238783836364746 seconds for one epoch ---
--- 0.3181605339050293 seconds for one epoch ---
--- 0.7586891651153564 seconds for one epoch ---
--- 0.3379662036895752 seconds for one epoch ---
--- 0.7572853565216064 seconds for one epoch ---
--- 0.34723782539367676 seconds for one epoch ---
--- 0.7380015850067139 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.04514482]
 [0.10440532]
 [0.        ]
 [1.        ]
 [1.        ]]
[[-3.2715213 ]
 [-0.8541161 ]
 [-1.2190155 ]
 [-0.        ]
 [ 0.        ]
 [-1.5268615 ]
 [ 0.11914995]
 [ 0.14183134]
 [-0.        ]
 [-5.5443015 ]
 [ 1.0213975 ]]
--- 0.2856450080871582 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5723.3359375, (3098.6543, 1.144542, 2621.937, 1.6002144)
   validation loss 1655.302001953125, (1274.3658, 0.11342447, 379.2225, 1.6002144)
decoder loss ratio: 49371.145221, decoder SINDy loss  ratio: 0.818605
THRESHOLDING: 6 active coefficients
--- 0.7523949146270752 seconds for one epoch ---
--- 0.31131982803344727 seconds for one epoch ---
--- 0.744013786315918 seconds for one epoch ---
--- 0.3039724826812744 seconds for one epoch ---
--- 0.745398998260498 seconds for one epoch ---
--- 0.3011901378631592 seconds for one epoch ---
--- 0.7472681999206543 seconds for one epoch ---
--- 0.30211687088012695 seconds for one epoch ---
--- 0.7487244606018066 seconds for one epoch ---
--- 0.3012855052947998 seconds for one epoch ---
--- 0.7566554546356201 seconds for one epoch ---
--- 0.3240180015563965 seconds for one epoch ---
--- 0.7536587715148926 seconds for one epoch ---
--- 0.32993602752685547 seconds for one epoch ---
--- 0.7895731925964355 seconds for one epoch ---
--- 0.337282657623291 seconds for one epoch ---
--- 0.775324821472168 seconds for one epoch ---
--- 0.33199310302734375 seconds for one epoch ---
--- 0.7676541805267334 seconds for one epoch ---
--- 0.34482526779174805 seconds for one epoch ---
--- 0.7933180332183838 seconds for one epoch ---
--- 0.3396782875061035 seconds for one epoch ---
--- 0.7752969264984131 seconds for one epoch ---
--- 0.33828043937683105 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.7680526 ]
 [-0.81755567]
 [-1.2598804 ]
 [-0.        ]
 [ 0.        ]
 [-0.9213196 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-5.2330804 ]
 [ 0.9896745 ]]
--- 0.27514052391052246 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5651.66552734375, (2150.7764, 2.5739176, 3496.8772, 1.4379514)
   validation loss 2369.4248046875, (1935.746, 0.19494978, 432.0459, 1.4379514)
decoder loss ratio: 74994.159546, decoder SINDy loss  ratio: 0.932632
--- 0.30567002296447754 seconds for one epoch ---
--- 0.7750673294067383 seconds for one epoch ---
--- 0.347933292388916 seconds for one epoch ---
--- 0.7594225406646729 seconds for one epoch ---
--- 0.33694887161254883 seconds for one epoch ---
--- 0.767866849899292 seconds for one epoch ---
--- 0.32742905616760254 seconds for one epoch ---
--- 0.7837398052215576 seconds for one epoch ---
--- 0.326312780380249 seconds for one epoch ---
--- 0.7654953002929688 seconds for one epoch ---
--- 0.3228037357330322 seconds for one epoch ---
--- 0.7664604187011719 seconds for one epoch ---
--- 0.30698180198669434 seconds for one epoch ---
--- 0.7580881118774414 seconds for one epoch ---
--- 0.31736087799072266 seconds for one epoch ---
--- 0.7650110721588135 seconds for one epoch ---
--- 0.3151662349700928 seconds for one epoch ---
--- 0.7631146907806396 seconds for one epoch ---
--- 0.3105955123901367 seconds for one epoch ---
--- 0.7669522762298584 seconds for one epoch ---
--- 0.3032712936401367 seconds for one epoch ---
--- 0.7869703769683838 seconds for one epoch ---
--- 0.3172130584716797 seconds for one epoch ---
--- 0.7570226192474365 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.551183  ]
 [-0.72956276]
 [-1.1855109 ]
 [-0.        ]
 [ 0.        ]
 [-0.7928116 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.9889    ]
 [ 0.98011523]]
--- 0.2877535820007324 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3171.111572265625, (1503.6848, 1.0634764, 1664.9283, 1.4349338)
   validation loss 2341.364990234375, (2037.9896, 0.14743596, 301.79306, 1.4349338)
decoder loss ratio: 78955.256140, decoder SINDy loss  ratio: 0.651463
--- 0.2657487392425537 seconds for one epoch ---
--- 0.30567455291748047 seconds for one epoch ---
--- 0.7632975578308105 seconds for one epoch ---
--- 0.32251501083374023 seconds for one epoch ---
--- 0.7745771408081055 seconds for one epoch ---
--- 0.3146476745605469 seconds for one epoch ---
--- 0.78118896484375 seconds for one epoch ---
--- 0.31398868560791016 seconds for one epoch ---
--- 0.7750930786132812 seconds for one epoch ---
--- 0.33908987045288086 seconds for one epoch ---
--- 0.7743239402770996 seconds for one epoch ---
--- 0.3421974182128906 seconds for one epoch ---
--- 0.7772693634033203 seconds for one epoch ---
--- 0.33292245864868164 seconds for one epoch ---
--- 0.7862997055053711 seconds for one epoch ---
--- 0.33173084259033203 seconds for one epoch ---
--- 0.8056111335754395 seconds for one epoch ---
--- 0.3332188129425049 seconds for one epoch ---
--- 0.778895378112793 seconds for one epoch ---
--- 0.3355247974395752 seconds for one epoch ---
--- 0.7861537933349609 seconds for one epoch ---
--- 0.32568836212158203 seconds for one epoch ---
--- 0.797083854675293 seconds for one epoch ---
--- 0.33377838134765625 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.4372344]
 [-0.7812036]
 [-1.125098 ]
 [-0.       ]
 [ 0.       ]
 [-0.7843459]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7809095]
 [ 0.8555004]]
--- 0.2631101608276367 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4384.27001953125, (1386.2037, 0.7167131, 2995.9163, 1.4328629)
   validation loss 827.7830200195312, (562.343, 0.15583174, 263.85132, 1.4328629)
decoder loss ratio: 21786.144771, decoder SINDy loss  ratio: 0.569560
--- 0.3086283206939697 seconds for one epoch ---
--- 0.7927045822143555 seconds for one epoch ---
--- 0.30341529846191406 seconds for one epoch ---
--- 0.7805218696594238 seconds for one epoch ---
--- 0.31139183044433594 seconds for one epoch ---
--- 0.7744622230529785 seconds for one epoch ---
--- 0.2891874313354492 seconds for one epoch ---
--- 0.7759833335876465 seconds for one epoch ---
--- 0.30165672302246094 seconds for one epoch ---
--- 0.7818772792816162 seconds for one epoch ---
--- 0.3054513931274414 seconds for one epoch ---
--- 0.7859632968902588 seconds for one epoch ---
--- 0.3004162311553955 seconds for one epoch ---
--- 0.8037409782409668 seconds for one epoch ---
--- 0.3101177215576172 seconds for one epoch ---
--- 0.8077971935272217 seconds for one epoch ---
--- 0.2967238426208496 seconds for one epoch ---
--- 0.775688648223877 seconds for one epoch ---
--- 0.2967190742492676 seconds for one epoch ---
--- 0.7794685363769531 seconds for one epoch ---
--- 0.2927975654602051 seconds for one epoch ---
--- 0.8124339580535889 seconds for one epoch ---
--- 0.3020620346069336 seconds for one epoch ---
--- 0.7869534492492676 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.3458571]
 [-0.81292  ]
 [-1.0996777]
 [-0.       ]
 [ 0.       ]
 [-0.7845026]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.604891 ]
 [ 0.8418548]]
--- 0.29802751541137695 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4094.017333984375, (1594.1235, 1.7476074, 2496.715, 1.43127)
   validation loss 1323.0665283203125, (975.289, 0.13717568, 346.20914, 1.43127)
decoder loss ratio: 37784.389093, decoder SINDy loss  ratio: 0.747341
--- 0.26309895515441895 seconds for one epoch ---
--- 0.3019602298736572 seconds for one epoch ---
--- 0.7762496471405029 seconds for one epoch ---
--- 0.28830862045288086 seconds for one epoch ---
--- 0.7829535007476807 seconds for one epoch ---
--- 0.3223600387573242 seconds for one epoch ---
--- 0.8028829097747803 seconds for one epoch ---
--- 0.31885242462158203 seconds for one epoch ---
--- 0.7933833599090576 seconds for one epoch ---
--- 0.32103633880615234 seconds for one epoch ---
--- 0.8234455585479736 seconds for one epoch ---
--- 0.3224468231201172 seconds for one epoch ---
--- 0.812000036239624 seconds for one epoch ---
--- 0.31997084617614746 seconds for one epoch ---
--- 0.8047187328338623 seconds for one epoch ---
--- 0.32909703254699707 seconds for one epoch ---
--- 0.8410022258758545 seconds for one epoch ---
--- 0.338062047958374 seconds for one epoch ---
--- 0.8148539066314697 seconds for one epoch ---
--- 0.34335756301879883 seconds for one epoch ---
--- 0.8015146255493164 seconds for one epoch ---
--- 0.34064412117004395 seconds for one epoch ---
--- 0.7986924648284912 seconds for one epoch ---
--- 0.338040828704834 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.26228   ]
 [-0.80984503]
 [-1.0610285 ]
 [ 0.        ]
 [ 0.        ]
 [-0.778722  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.4403505 ]
 [ 0.77962285]]
--- 0.26804637908935547 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5386.1396484375, (2279.9907, 2.3173063, 3102.402, 1.4298707)
   validation loss 1126.3671875, (844.5012, 0.114054285, 280.3219, 1.4298707)
decoder loss ratio: 32717.443409, decoder SINDy loss  ratio: 0.605114
--- 0.29708123207092285 seconds for one epoch ---
--- 0.7807295322418213 seconds for one epoch ---
--- 0.3023560047149658 seconds for one epoch ---
--- 0.788219690322876 seconds for one epoch ---
--- 0.30611705780029297 seconds for one epoch ---
--- 0.7952635288238525 seconds for one epoch ---
--- 0.30852627754211426 seconds for one epoch ---
--- 0.8038253784179688 seconds for one epoch ---
--- 0.29679083824157715 seconds for one epoch ---
--- 0.7974956035614014 seconds for one epoch ---
--- 0.29598331451416016 seconds for one epoch ---
--- 0.7976901531219482 seconds for one epoch ---
--- 0.29198122024536133 seconds for one epoch ---
--- 0.8094415664672852 seconds for one epoch ---
--- 0.3038465976715088 seconds for one epoch ---
--- 0.8464994430541992 seconds for one epoch ---
--- 0.28199076652526855 seconds for one epoch ---
--- 0.8278124332427979 seconds for one epoch ---
--- 0.29641199111938477 seconds for one epoch ---
--- 0.851588249206543 seconds for one epoch ---
--- 0.2978332042694092 seconds for one epoch ---
--- 0.8021998405456543 seconds for one epoch ---
--- 0.30671262741088867 seconds for one epoch ---
--- 0.8266284465789795 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.212603  ]
 [-0.7751511 ]
 [-1.025992  ]
 [-0.        ]
 [ 0.        ]
 [-0.79363483]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3118067 ]
 [ 0.7467353 ]]
--- 0.2870297431945801 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4131.5595703125, (1884.4377, 0.5514816, 2245.1416, 1.428739)
   validation loss 1499.15478515625, (1201.3107, 0.14998317, 296.26532, 1.428739)
decoder loss ratio: 46540.860882, decoder SINDy loss  ratio: 0.639530
--- 0.24963808059692383 seconds for one epoch ---
--- 0.30211853981018066 seconds for one epoch ---
--- 0.8122994899749756 seconds for one epoch ---
--- 0.30550360679626465 seconds for one epoch ---
--- 0.8088314533233643 seconds for one epoch ---
--- 0.2845156192779541 seconds for one epoch ---
--- 0.8133039474487305 seconds for one epoch ---
--- 0.3310511112213135 seconds for one epoch ---
--- 0.8406276702880859 seconds for one epoch ---
--- 0.32085108757019043 seconds for one epoch ---
--- 0.8299927711486816 seconds for one epoch ---
--- 0.3377807140350342 seconds for one epoch ---
--- 0.8217329978942871 seconds for one epoch ---
--- 0.3404238224029541 seconds for one epoch ---
--- 0.8219199180603027 seconds for one epoch ---
--- 0.34503173828125 seconds for one epoch ---
--- 0.818777322769165 seconds for one epoch ---
--- 0.34166693687438965 seconds for one epoch ---
--- 0.8249201774597168 seconds for one epoch ---
--- 0.32715702056884766 seconds for one epoch ---
--- 0.8272833824157715 seconds for one epoch ---
--- 0.3308236598968506 seconds for one epoch ---
--- 0.8246774673461914 seconds for one epoch ---
--- 0.32970166206359863 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.1648464 ]
 [-0.7652449 ]
 [-1.0094764 ]
 [ 0.        ]
 [ 0.        ]
 [-0.80226547]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.190213  ]
 [ 0.69598556]]
--- 0.2580373287200928 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4476.349609375, (1641.2515, 1.0096167, 2832.661, 1.427812)
   validation loss 1002.1744995117188, (713.7543, 0.19398905, 286.79846, 1.427812)
decoder loss ratio: 27652.079647, decoder SINDy loss  ratio: 0.619095
--- 0.2978386878967285 seconds for one epoch ---
--- 0.8201470375061035 seconds for one epoch ---
--- 0.29639577865600586 seconds for one epoch ---
--- 0.8108103275299072 seconds for one epoch ---
--- 0.2997572422027588 seconds for one epoch ---
--- 0.8174741268157959 seconds for one epoch ---
--- 0.29825305938720703 seconds for one epoch ---
--- 0.8092069625854492 seconds for one epoch ---
--- 0.3025658130645752 seconds for one epoch ---
--- 0.8360025882720947 seconds for one epoch ---
--- 0.3042116165161133 seconds for one epoch ---
--- 0.8604955673217773 seconds for one epoch ---
--- 0.30251240730285645 seconds for one epoch ---
--- 0.867955207824707 seconds for one epoch ---
--- 0.28127527236938477 seconds for one epoch ---
--- 0.8384318351745605 seconds for one epoch ---
--- 0.313953161239624 seconds for one epoch ---
--- 0.8434255123138428 seconds for one epoch ---
--- 0.3114588260650635 seconds for one epoch ---
--- 0.8795113563537598 seconds for one epoch ---
--- 0.30216097831726074 seconds for one epoch ---
--- 0.8498318195343018 seconds for one epoch ---
--- 0.30824756622314453 seconds for one epoch ---
--- 0.8579568862915039 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]]
[[-2.142386 ]
 [-0.799972 ]
 [-1.0062473]
 [-0.       ]
 [ 0.       ]
 [-0.8081129]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.0966196]
 [ 0.6412029]]
--- 0.2850308418273926 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5000.984375, (1642.0609, 0.861481, 3356.6348, 1.4271386)
   validation loss 886.5731201171875, (629.4374, 0.24605209, 255.4626, 1.4271386)
decoder loss ratio: 24385.496772, decoder SINDy loss  ratio: 0.551452
--- 0.2646958827972412 seconds for one epoch ---
--- 0.3000938892364502 seconds for one epoch ---
--- 0.835796594619751 seconds for one epoch ---
--- 0.3063185214996338 seconds for one epoch ---
--- 0.8067293167114258 seconds for one epoch ---
--- 0.29895615577697754 seconds for one epoch ---
--- 0.8363890647888184 seconds for one epoch ---
--- 0.29611730575561523 seconds for one epoch ---
--- 0.8384795188903809 seconds for one epoch ---
--- 0.2976837158203125 seconds for one epoch ---
--- 0.8372287750244141 seconds for one epoch ---
--- 0.2897372245788574 seconds for one epoch ---
--- 0.8365194797515869 seconds for one epoch ---
--- 0.3041963577270508 seconds for one epoch ---
--- 0.8318402767181396 seconds for one epoch ---
--- 0.317169189453125 seconds for one epoch ---
--- 0.8415927886962891 seconds for one epoch ---
--- 0.28690648078918457 seconds for one epoch ---
--- 0.8484025001525879 seconds for one epoch ---
--- 0.2988717555999756 seconds for one epoch ---
--- 0.850050687789917 seconds for one epoch ---
--- 0.2979419231414795 seconds for one epoch ---
--- 0.8429841995239258 seconds for one epoch ---
--- 0.30611634254455566 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99999976]]
[[-2.1016014 ]
 [-0.82124305]
 [-0.9925505 ]
 [-0.        ]
 [ 0.        ]
 [-0.8137147 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.9842262 ]
 [ 0.5915117 ]]
--- 0.2661590576171875 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3631.217529296875, (1768.801, 1.2314055, 1859.7588, 1.426322)
   validation loss 996.14892578125, (721.95575, 0.25019935, 272.51666, 1.426322)
decoder loss ratio: 27969.819106, decoder SINDy loss  ratio: 0.588266
--- 0.3005406856536865 seconds for one epoch ---
--- 0.819434642791748 seconds for one epoch ---
--- 0.2995874881744385 seconds for one epoch ---
--- 0.8631930351257324 seconds for one epoch ---
--- 0.2920393943786621 seconds for one epoch ---
--- 0.8379299640655518 seconds for one epoch ---
--- 0.2954750061035156 seconds for one epoch ---
--- 0.838688850402832 seconds for one epoch ---
--- 0.30323195457458496 seconds for one epoch ---
--- 0.8497779369354248 seconds for one epoch ---
--- 0.2861621379852295 seconds for one epoch ---
--- 0.8681118488311768 seconds for one epoch ---
--- 0.29886388778686523 seconds for one epoch ---
--- 0.851595401763916 seconds for one epoch ---
--- 0.30396175384521484 seconds for one epoch ---
--- 0.8657634258270264 seconds for one epoch ---
--- 0.3058617115020752 seconds for one epoch ---
--- 0.8584940433502197 seconds for one epoch ---
--- 0.30098700523376465 seconds for one epoch ---
--- 0.8592245578765869 seconds for one epoch ---
--- 0.29747843742370605 seconds for one epoch ---
--- 0.8611602783203125 seconds for one epoch ---
--- 0.2951827049255371 seconds for one epoch ---
--- 0.871941328048706 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99999464]]
[[-2.077764  ]
 [-0.78545487]
 [-0.9758429 ]
 [-0.        ]
 [-0.        ]
 [-0.81092495]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.903689  ]
 [ 0.5455884 ]]
--- 0.31825685501098633 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4462.02978515625, (1428.2788, 2.0889738, 3030.236, 1.4257214)
   validation loss 1718.1444091796875, (1433.6064, 0.2305356, 282.88156, 1.4257214)
decoder loss ratio: 55540.402542, decoder SINDy loss  ratio: 0.610640
--- 0.2662692070007324 seconds for one epoch ---
--- 0.3339545726776123 seconds for one epoch ---
--- 0.8803160190582275 seconds for one epoch ---
--- 0.31917476654052734 seconds for one epoch ---
--- 0.8638482093811035 seconds for one epoch ---
--- 0.30530738830566406 seconds for one epoch ---
--- 0.857306718826294 seconds for one epoch ---
--- 0.29997730255126953 seconds for one epoch ---
--- 0.8807313442230225 seconds for one epoch ---
--- 0.29766154289245605 seconds for one epoch ---
--- 0.859006404876709 seconds for one epoch ---
--- 0.2698366641998291 seconds for one epoch ---
--- 0.8602380752563477 seconds for one epoch ---
--- 0.32278990745544434 seconds for one epoch ---
--- 0.8716273307800293 seconds for one epoch ---
--- 0.34055423736572266 seconds for one epoch ---
--- 0.8961465358734131 seconds for one epoch ---
--- 0.4988584518432617 seconds for one epoch ---
--- 0.8824965953826904 seconds for one epoch ---
--- 0.3154420852661133 seconds for one epoch ---
--- 0.902775764465332 seconds for one epoch ---
--- 0.3085489273071289 seconds for one epoch ---
--- 0.9046018123626709 seconds for one epoch ---
--- 0.29897165298461914 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99998313]]
[[-2.0542972 ]
 [-0.78504646]
 [-0.9476686 ]
 [ 0.        ]
 [ 0.        ]
 [-0.8203109 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.8128874 ]
 [ 0.47487316]]
--- 0.2565927505493164 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3210.34619140625, (1625.9052, 3.284123, 1579.7318, 1.4250607)
   validation loss 1777.91552734375, (1483.9872, 0.26418686, 292.23907, 1.4250607)
decoder loss ratio: 57492.239770, decoder SINDy loss  ratio: 0.630839
--- 0.30816102027893066 seconds for one epoch ---
--- 0.8691263198852539 seconds for one epoch ---
--- 0.3223729133605957 seconds for one epoch ---
--- 0.874931812286377 seconds for one epoch ---
--- 0.29840707778930664 seconds for one epoch ---
--- 0.8787322044372559 seconds for one epoch ---
--- 0.30763983726501465 seconds for one epoch ---
--- 0.8584821224212646 seconds for one epoch ---
--- 0.2820415496826172 seconds for one epoch ---
--- 0.8838169574737549 seconds for one epoch ---
--- 0.306957483291626 seconds for one epoch ---
--- 0.8628549575805664 seconds for one epoch ---
--- 0.3048074245452881 seconds for one epoch ---
--- 0.8770349025726318 seconds for one epoch ---
--- 0.3099534511566162 seconds for one epoch ---
--- 0.9036059379577637 seconds for one epoch ---
--- 0.2938086986541748 seconds for one epoch ---
--- 0.8905792236328125 seconds for one epoch ---
--- 0.3085978031158447 seconds for one epoch ---
--- 0.8863060474395752 seconds for one epoch ---
--- 0.2977876663208008 seconds for one epoch ---
--- 0.8776147365570068 seconds for one epoch ---
--- 0.3131825923919678 seconds for one epoch ---
--- 0.9021933078765869 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.9994668]]
[[-2.0461977 ]
 [-0.7416648 ]
 [-0.9658119 ]
 [ 0.        ]
 [ 0.        ]
 [-0.8067772 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7614443 ]
 [ 0.38414022]]
--- 0.29571056365966797 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3141.54736328125, (1228.0981, 0.59076715, 1911.4338, 1.4246069)
   validation loss 1273.806884765625, (945.2004, 0.11708805, 327.06485, 1.4246069)
decoder loss ratio: 36618.703600, decoder SINDy loss  ratio: 0.706015
--- 0.28335142135620117 seconds for one epoch ---
--- 0.2941722869873047 seconds for one epoch ---
--- 0.9027621746063232 seconds for one epoch ---
--- 0.31221938133239746 seconds for one epoch ---
--- 0.8808765411376953 seconds for one epoch ---
--- 0.29647397994995117 seconds for one epoch ---
--- 0.8883390426635742 seconds for one epoch ---
--- 0.29044103622436523 seconds for one epoch ---
--- 0.8893241882324219 seconds for one epoch ---
--- 0.2966601848602295 seconds for one epoch ---
--- 0.890233039855957 seconds for one epoch ---
--- 0.30387377738952637 seconds for one epoch ---
--- 0.8724410533905029 seconds for one epoch ---
--- 0.2907741069793701 seconds for one epoch ---
--- 0.8894522190093994 seconds for one epoch ---
--- 0.3088552951812744 seconds for one epoch ---
--- 0.9391920566558838 seconds for one epoch ---
--- 0.3351268768310547 seconds for one epoch ---
--- 0.9137001037597656 seconds for one epoch ---
--- 0.3263249397277832 seconds for one epoch ---
--- 0.8875105381011963 seconds for one epoch ---
--- 0.30681419372558594 seconds for one epoch ---
--- 0.8830749988555908 seconds for one epoch ---
--- 0.3279597759246826 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99635756]]
[[-2.0289974 ]
 [-0.7231068 ]
 [-0.9507639 ]
 [-0.        ]
 [ 0.        ]
 [-0.7914912 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6982596 ]
 [ 0.33597755]]
--- 0.25771546363830566 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2912.349853515625, (1218.1108, 2.8442254, 1689.9708, 1.4241512)
   validation loss 1269.6751708984375, (991.81464, 0.19702213, 276.23932, 1.4241512)
decoder loss ratio: 38424.620873, decoder SINDy loss  ratio: 0.596301
--- 0.3050518035888672 seconds for one epoch ---
--- 0.9091870784759521 seconds for one epoch ---
--- 0.31936144828796387 seconds for one epoch ---
--- 0.9006803035736084 seconds for one epoch ---
--- 0.3162040710449219 seconds for one epoch ---
--- 0.915858268737793 seconds for one epoch ---
--- 0.3098750114440918 seconds for one epoch ---
--- 0.8959040641784668 seconds for one epoch ---
--- 0.2918994426727295 seconds for one epoch ---
--- 0.8961629867553711 seconds for one epoch ---
--- 0.2994840145111084 seconds for one epoch ---
--- 0.9100112915039062 seconds for one epoch ---
--- 0.30422258377075195 seconds for one epoch ---
--- 0.8971672058105469 seconds for one epoch ---
--- 0.2932703495025635 seconds for one epoch ---
--- 0.8900151252746582 seconds for one epoch ---
--- 0.3055133819580078 seconds for one epoch ---
--- 0.8884842395782471 seconds for one epoch ---
--- 0.2941877841949463 seconds for one epoch ---
--- 0.8710300922393799 seconds for one epoch ---
--- 0.3001065254211426 seconds for one epoch ---
--- 0.8858237266540527 seconds for one epoch ---
--- 0.29277539253234863 seconds for one epoch ---
--- 0.9419729709625244 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.99053633]]
[[-2.0430763 ]
 [-0.7513313 ]
 [-0.9315631 ]
 [-0.        ]
 [-0.        ]
 [-0.803052  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6537979 ]
 [ 0.31195682]]
--- 0.2931084632873535 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3305.3544921875, (1206.6819, 3.7218034, 2093.5269, 1.4238867)
   validation loss 1240.4281005859375, (992.4469, 0.2285278, 246.32887, 1.4238867)
decoder loss ratio: 38449.115847, decoder SINDy loss  ratio: 0.531736
--- 0.27274179458618164 seconds for one epoch ---
--- 0.31739282608032227 seconds for one epoch ---
--- 0.8865773677825928 seconds for one epoch ---
--- 0.30218958854675293 seconds for one epoch ---
--- 0.9110214710235596 seconds for one epoch ---
--- 0.3182339668273926 seconds for one epoch ---
--- 0.8966524600982666 seconds for one epoch ---
--- 0.29120945930480957 seconds for one epoch ---
--- 0.9255928993225098 seconds for one epoch ---
--- 0.29930853843688965 seconds for one epoch ---
--- 0.9101271629333496 seconds for one epoch ---
--- 0.29543399810791016 seconds for one epoch ---
--- 0.9169549942016602 seconds for one epoch ---
--- 0.3057425022125244 seconds for one epoch ---
--- 0.8814687728881836 seconds for one epoch ---
--- 0.2963106632232666 seconds for one epoch ---
--- 0.9293472766876221 seconds for one epoch ---
--- 0.3061482906341553 seconds for one epoch ---
--- 0.9197604656219482 seconds for one epoch ---
--- 0.32431674003601074 seconds for one epoch ---
--- 0.9354081153869629 seconds for one epoch ---
--- 0.3231346607208252 seconds for one epoch ---
--- 0.9396605491638184 seconds for one epoch ---
--- 0.3102736473083496 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.94049454]]
[[-2.0466955 ]
 [-0.75714356]
 [-0.9309774 ]
 [ 0.        ]
 [-0.        ]
 [-0.8122814 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.6013563 ]
 [ 0.26468232]]
--- 0.27091360092163086 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3401.685791015625, (1379.5271, 1.4904009, 2019.2472, 1.4211484)
   validation loss 2935.917724609375, (2657.17, 0.3639001, 276.96274, 1.4211484)
decoder loss ratio: 102943.375823, decoder SINDy loss  ratio: 0.597863
--- 0.30855369567871094 seconds for one epoch ---
--- 0.9168746471405029 seconds for one epoch ---
--- 0.30994677543640137 seconds for one epoch ---
--- 0.9425065517425537 seconds for one epoch ---
--- 0.31298828125 seconds for one epoch ---
--- 0.9455525875091553 seconds for one epoch ---
--- 0.33658933639526367 seconds for one epoch ---
--- 0.8898851871490479 seconds for one epoch ---
--- 0.30019545555114746 seconds for one epoch ---
--- 0.9234492778778076 seconds for one epoch ---
--- 0.29732370376586914 seconds for one epoch ---
--- 0.928133487701416 seconds for one epoch ---
--- 0.2997303009033203 seconds for one epoch ---
--- 0.9502274990081787 seconds for one epoch ---
--- 0.3060176372528076 seconds for one epoch ---
--- 0.925304651260376 seconds for one epoch ---
--- 0.2942230701446533 seconds for one epoch ---
--- 0.9257547855377197 seconds for one epoch ---
--- 0.31894946098327637 seconds for one epoch ---
--- 0.9296219348907471 seconds for one epoch ---
--- 0.3303818702697754 seconds for one epoch ---
--- 0.9200682640075684 seconds for one epoch ---
--- 0.31137895584106445 seconds for one epoch ---
--- 0.9390687942504883 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.8091761]]
[[-2.0604076 ]
 [-0.73061264]
 [-0.92595714]
 [ 0.        ]
 [-0.        ]
 [-0.80866265]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.5882542 ]
 [ 0.23178211]]
--- 0.32819700241088867 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3450.9873046875, (1571.1793, 2.4336073, 1875.9615, 1.4127897)
   validation loss 920.9954833984375, (604.60205, 0.23029828, 314.75037, 1.4127897)
decoder loss ratio: 23423.333083, decoder SINDy loss  ratio: 0.679433
--- 0.26336073875427246 seconds for one epoch ---
--- 0.318434476852417 seconds for one epoch ---
--- 0.9132969379425049 seconds for one epoch ---
--- 0.33458876609802246 seconds for one epoch ---
--- 0.9132251739501953 seconds for one epoch ---
--- 0.3112061023712158 seconds for one epoch ---
--- 0.9118959903717041 seconds for one epoch ---
--- 0.31166982650756836 seconds for one epoch ---
--- 0.929168701171875 seconds for one epoch ---
--- 0.2989203929901123 seconds for one epoch ---
--- 0.919053316116333 seconds for one epoch ---
--- 0.3020594120025635 seconds for one epoch ---
--- 0.9322640895843506 seconds for one epoch ---
--- 0.29666805267333984 seconds for one epoch ---
--- 0.9592428207397461 seconds for one epoch ---
--- 0.30010485649108887 seconds for one epoch ---
--- 0.8790948390960693 seconds for one epoch ---
--- 0.31033825874328613 seconds for one epoch ---
--- 0.9407734870910645 seconds for one epoch ---
--- 0.3049185276031494 seconds for one epoch ---
--- 0.9488570690155029 seconds for one epoch ---
--- 0.30000853538513184 seconds for one epoch ---
--- 0.9720523357391357 seconds for one epoch ---
--- 0.30164074897766113 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.50612324]]
[[-2.0848467 ]
 [-0.7424705 ]
 [-0.9106132 ]
 [-0.        ]
 [ 0.        ]
 [-0.8053874 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.5844045 ]
 [ 0.19626969]]
--- 0.2661607265472412 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3178.8623046875, (1484.6483, 1.66433, 1691.1589, 1.3906612)
   validation loss 903.7686157226562, (622.1605, 0.18116833, 280.03622, 1.3906612)
decoder loss ratio: 24103.578758, decoder SINDy loss  ratio: 0.604498
--- 0.2995615005493164 seconds for one epoch ---
--- 0.9744565486907959 seconds for one epoch ---
--- 0.2940793037414551 seconds for one epoch ---
--- 0.9850497245788574 seconds for one epoch ---
--- 0.29708266258239746 seconds for one epoch ---
--- 0.9485230445861816 seconds for one epoch ---
--- 0.29605627059936523 seconds for one epoch ---
--- 0.9553556442260742 seconds for one epoch ---
--- 0.3236253261566162 seconds for one epoch ---
--- 0.9409847259521484 seconds for one epoch ---
--- 0.30519914627075195 seconds for one epoch ---
--- 0.9470481872558594 seconds for one epoch ---
--- 0.294574499130249 seconds for one epoch ---
--- 0.9298193454742432 seconds for one epoch ---
--- 0.28755784034729004 seconds for one epoch ---
--- 0.9494540691375732 seconds for one epoch ---
--- 0.3141353130340576 seconds for one epoch ---
--- 0.9048817157745361 seconds for one epoch ---
--- 0.2919442653656006 seconds for one epoch ---
--- 0.9552483558654785 seconds for one epoch ---
--- 0.3100855350494385 seconds for one epoch ---
--- 0.9486963748931885 seconds for one epoch ---
--- 0.31859779357910156 seconds for one epoch ---
--- 0.9577469825744629 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.17999934]]
[[-2.1107514 ]
 [-0.7488551 ]
 [-0.89929396]
 [-0.        ]
 [-0.        ]
 [-0.8053698 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.576001  ]
 [ 0.15773907]]
--- 0.30952906608581543 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3781.7900390625, (1738.0721, 0.7138544, 2041.6796, 1.3243412)
   validation loss 1398.2353515625, (1110.2316, 0.14592107, 286.53354, 1.3243412)
decoder loss ratio: 43012.298367, decoder SINDy loss  ratio: 0.618523
--- 0.285388708114624 seconds for one epoch ---
--- 0.3369603157043457 seconds for one epoch ---
--- 0.9489614963531494 seconds for one epoch ---
--- 0.3259155750274658 seconds for one epoch ---
--- 0.9738078117370605 seconds for one epoch ---
--- 0.3531806468963623 seconds for one epoch ---
--- 0.9849264621734619 seconds for one epoch ---
--- 0.3251376152038574 seconds for one epoch ---
--- 0.9508676528930664 seconds for one epoch ---
--- 0.31723904609680176 seconds for one epoch ---
--- 0.9604265689849854 seconds for one epoch ---
--- 0.29610276222229004 seconds for one epoch ---
--- 0.9563641548156738 seconds for one epoch ---
--- 0.29936885833740234 seconds for one epoch ---
--- 0.9626955986022949 seconds for one epoch ---
--- 0.3100728988647461 seconds for one epoch ---
--- 0.9719905853271484 seconds for one epoch ---
--- 0.28675246238708496 seconds for one epoch ---
--- 0.935091495513916 seconds for one epoch ---
--- 0.2906672954559326 seconds for one epoch ---
--- 0.9543190002441406 seconds for one epoch ---
--- 0.292156457901001 seconds for one epoch ---
--- 0.9570415019989014 seconds for one epoch ---
--- 0.30068397521972656 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.02440644]]
[[-2.1206815 ]
 [-0.74267566]
 [-0.8803793 ]
 [ 0.        ]
 [ 0.        ]
 [-0.8052594 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.541836  ]
 [ 0.10341156]]
--- 0.26288843154907227 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5262.2470703125, (1971.486, 4.918936, 3284.5718, 1.270587)
   validation loss 1120.8636474609375, (803.2927, 0.25008836, 316.05026, 1.270587)
decoder loss ratio: 31120.954729, decoder SINDy loss  ratio: 0.682239
--- 0.28781843185424805 seconds for one epoch ---
--- 0.9424881935119629 seconds for one epoch ---
--- 0.303027868270874 seconds for one epoch ---
--- 0.9663949012756348 seconds for one epoch ---
--- 0.3067495822906494 seconds for one epoch ---
--- 0.9536576271057129 seconds for one epoch ---
--- 0.3081543445587158 seconds for one epoch ---
--- 0.9486322402954102 seconds for one epoch ---
--- 0.2919013500213623 seconds for one epoch ---
--- 0.9859120845794678 seconds for one epoch ---
--- 0.28484439849853516 seconds for one epoch ---
--- 0.9684097766876221 seconds for one epoch ---
--- 0.3032693862915039 seconds for one epoch ---
--- 0.9906270503997803 seconds for one epoch ---
--- 0.29617810249328613 seconds for one epoch ---
--- 0.9469811916351318 seconds for one epoch ---
--- 0.30599308013916016 seconds for one epoch ---
--- 0.9988553524017334 seconds for one epoch ---
--- 0.30184173583984375 seconds for one epoch ---
--- 0.9914579391479492 seconds for one epoch ---
--- 0.30530643463134766 seconds for one epoch ---
--- 0.9641101360321045 seconds for one epoch ---
--- 0.2797553539276123 seconds for one epoch ---
--- 0.9789173603057861 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.00271939]]
[[-2.1330943 ]
 [-0.71326697]
 [-0.8843339 ]
 [ 0.        ]
 [ 0.        ]
 [-0.79048264]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.5265386 ]
 [ 0.04779501]]
--- 0.3006885051727295 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2741.710205078125, (1270.2839, 8.102043, 1462.0961, 1.2282857)
   validation loss 902.60595703125, (661.79785, 0.20407894, 239.3757, 1.2282857)
decoder loss ratio: 25639.197701, decoder SINDy loss  ratio: 0.516726
THRESHOLDING: 5 active coefficients
--- 0.259108304977417 seconds for one epoch ---
--- 0.31580519676208496 seconds for one epoch ---
--- 0.9775691032409668 seconds for one epoch ---
--- 0.30138564109802246 seconds for one epoch ---
--- 0.9941506385803223 seconds for one epoch ---
--- 0.3376936912536621 seconds for one epoch ---
--- 1.0152451992034912 seconds for one epoch ---
--- 0.31952571868896484 seconds for one epoch ---
--- 1.0026447772979736 seconds for one epoch ---
--- 0.3284289836883545 seconds for one epoch ---
--- 1.0049412250518799 seconds for one epoch ---
--- 0.3398473262786865 seconds for one epoch ---
--- 0.9923481941223145 seconds for one epoch ---
--- 0.323075532913208 seconds for one epoch ---
--- 1.001404047012329 seconds for one epoch ---
--- 0.3408334255218506 seconds for one epoch ---
--- 0.9896221160888672 seconds for one epoch ---
--- 0.33482813835144043 seconds for one epoch ---
--- 0.9793963432312012 seconds for one epoch ---
--- 0.3329470157623291 seconds for one epoch ---
--- 0.9825820922851562 seconds for one epoch ---
--- 0.32659435272216797 seconds for one epoch ---
--- 1.0060961246490479 seconds for one epoch ---
--- 0.33151960372924805 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.1545482]
 [-0.7307125]
 [-0.89095  ]
 [-0.       ]
 [-0.       ]
 [-0.7896543]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5159695]
 [ 0.       ]]
--- 0.22145652770996094 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2452.55908203125, (997.47186, 0.32285082, 1453.599, 1.1652536)
   validation loss 917.4437255859375, (619.7021, 0.20927963, 296.36707, 1.1652536)
decoder loss ratio: 24008.334716, decoder SINDy loss  ratio: 0.639750
--- 0.3141610622406006 seconds for one epoch ---
--- 0.9826042652130127 seconds for one epoch ---
--- 0.3040146827697754 seconds for one epoch ---
--- 0.9795281887054443 seconds for one epoch ---
--- 0.3050353527069092 seconds for one epoch ---
--- 0.9747312068939209 seconds for one epoch ---
--- 0.31429290771484375 seconds for one epoch ---
--- 0.9825170040130615 seconds for one epoch ---
--- 0.29135656356811523 seconds for one epoch ---
--- 0.967695951461792 seconds for one epoch ---
--- 0.2910294532775879 seconds for one epoch ---
--- 0.965386152267456 seconds for one epoch ---
--- 0.29851818084716797 seconds for one epoch ---
--- 0.9811744689941406 seconds for one epoch ---
--- 0.293992280960083 seconds for one epoch ---
--- 0.9792685508728027 seconds for one epoch ---
--- 0.29570698738098145 seconds for one epoch ---
--- 0.9888050556182861 seconds for one epoch ---
--- 0.31672048568725586 seconds for one epoch ---
--- 1.002587080001831 seconds for one epoch ---
--- 0.2991037368774414 seconds for one epoch ---
--- 0.9648621082305908 seconds for one epoch ---
--- 0.30463385581970215 seconds for one epoch ---
--- 0.9896156787872314 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.17522  ]
 [-0.7454746]
 [-0.8864388]
 [-0.       ]
 [ 0.       ]
 [-0.7903357]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4979568]
 [ 0.       ]]
--- 0.27903270721435547 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4801.8486328125, (2544.2356, 1.8236566, 2254.6245, 1.1652594)
   validation loss 1009.006591796875, (717.42145, 0.14097401, 290.27884, 1.1652594)
decoder loss ratio: 27794.152384, decoder SINDy loss  ratio: 0.626608
--- 0.2658219337463379 seconds for one epoch ---
--- 0.288128137588501 seconds for one epoch ---
--- 0.9831373691558838 seconds for one epoch ---
--- 0.2888495922088623 seconds for one epoch ---
--- 0.9843297004699707 seconds for one epoch ---
--- 0.30106139183044434 seconds for one epoch ---
--- 0.9961085319519043 seconds for one epoch ---
--- 0.31133508682250977 seconds for one epoch ---
--- 1.0008065700531006 seconds for one epoch ---
--- 0.3146355152130127 seconds for one epoch ---
--- 1.022665023803711 seconds for one epoch ---
--- 0.3060321807861328 seconds for one epoch ---
--- 1.0133335590362549 seconds for one epoch ---
--- 0.3047678470611572 seconds for one epoch ---
--- 1.0111761093139648 seconds for one epoch ---
--- 0.2924633026123047 seconds for one epoch ---
--- 0.9885547161102295 seconds for one epoch ---
--- 0.3053123950958252 seconds for one epoch ---
--- 0.9903566837310791 seconds for one epoch ---
--- 0.3056654930114746 seconds for one epoch ---
--- 1.0048398971557617 seconds for one epoch ---
--- 0.2943129539489746 seconds for one epoch ---
--- 0.9871611595153809 seconds for one epoch ---
--- 0.28778648376464844 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.2045207]
 [-0.7141665]
 [-0.8802619]
 [ 0.       ]
 [-0.       ]
 [-0.7846352]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5083513]
 [ 0.       ]]
--- 0.2476215362548828 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2596.412109375, (1254.3029, 0.6871697, 1340.2568, 1.1653584)
   validation loss 855.2371215820312, (610.5181, 0.17646667, 243.37723, 1.1653584)
decoder loss ratio: 23652.532163, decoder SINDy loss  ratio: 0.525364
--- 0.32476043701171875 seconds for one epoch ---
--- 1.0206913948059082 seconds for one epoch ---
--- 0.3144838809967041 seconds for one epoch ---
--- 1.015604019165039 seconds for one epoch ---
--- 0.3258960247039795 seconds for one epoch ---
--- 1.0146467685699463 seconds for one epoch ---
--- 0.32778072357177734 seconds for one epoch ---
--- 1.0250308513641357 seconds for one epoch ---
--- 0.31797003746032715 seconds for one epoch ---
--- 1.0144968032836914 seconds for one epoch ---
--- 0.3314034938812256 seconds for one epoch ---
--- 1.0137858390808105 seconds for one epoch ---
--- 0.32764768600463867 seconds for one epoch ---
--- 1.02250075340271 seconds for one epoch ---
--- 0.28867459297180176 seconds for one epoch ---
--- 1.003166913986206 seconds for one epoch ---
--- 0.29375624656677246 seconds for one epoch ---
--- 1.0262079238891602 seconds for one epoch ---
--- 0.3015587329864502 seconds for one epoch ---
--- 1.0250742435455322 seconds for one epoch ---
--- 0.29829955101013184 seconds for one epoch ---
--- 1.0208489894866943 seconds for one epoch ---
--- 0.29416656494140625 seconds for one epoch ---
--- 0.9835166931152344 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.2553117 ]
 [-0.66881496]
 [-0.8590211 ]
 [ 0.        ]
 [-0.        ]
 [-0.7959503 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.53408   ]
 [ 0.        ]]
--- 0.28922486305236816 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3190.81787109375, (1446.3176, 6.2987547, 1737.036, 1.1655582)
   validation loss 1892.71484375, (1578.7104, 0.17828622, 312.66052, 1.1655582)
decoder loss ratio: 61161.983565, decoder SINDy loss  ratio: 0.674922
--- 0.24575090408325195 seconds for one epoch ---
--- 0.2910759449005127 seconds for one epoch ---
--- 1.00897216796875 seconds for one epoch ---
--- 0.2922530174255371 seconds for one epoch ---
--- 1.0102760791778564 seconds for one epoch ---
--- 0.2988722324371338 seconds for one epoch ---
--- 1.0049817562103271 seconds for one epoch ---
--- 0.3040311336517334 seconds for one epoch ---
--- 1.0033016204833984 seconds for one epoch ---
--- 0.29166316986083984 seconds for one epoch ---
--- 1.0050945281982422 seconds for one epoch ---
--- 0.2922694683074951 seconds for one epoch ---
--- 1.0116865634918213 seconds for one epoch ---
--- 0.29504966735839844 seconds for one epoch ---
--- 1.030573844909668 seconds for one epoch ---
--- 0.2967698574066162 seconds for one epoch ---
--- 1.0328643321990967 seconds for one epoch ---
--- 0.29471278190612793 seconds for one epoch ---
--- 1.0298209190368652 seconds for one epoch ---
--- 0.3038675785064697 seconds for one epoch ---
--- 1.03255295753479 seconds for one epoch ---
--- 0.29770636558532715 seconds for one epoch ---
--- 1.0260975360870361 seconds for one epoch ---
--- 0.2938568592071533 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.2708323]
 [-0.6869081]
 [-0.8761782]
 [-0.       ]
 [-0.       ]
 [-0.7681672]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5442085]
 [ 0.       ]]
--- 0.2836942672729492 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4646.90673828125, (2526.6228, 7.345729, 2111.773, 1.165674)
   validation loss 2261.4287109375, (1857.038, 0.24480033, 402.98022, 1.165674)
decoder loss ratio: 71944.874680, decoder SINDy loss  ratio: 0.869889
--- 0.30037379264831543 seconds for one epoch ---
--- 1.0315985679626465 seconds for one epoch ---
--- 0.28832340240478516 seconds for one epoch ---
--- 1.0185601711273193 seconds for one epoch ---
--- 0.29813146591186523 seconds for one epoch ---
--- 1.0388927459716797 seconds for one epoch ---
--- 0.30672144889831543 seconds for one epoch ---
--- 1.0445528030395508 seconds for one epoch ---
--- 0.29398202896118164 seconds for one epoch ---
--- 1.0414707660675049 seconds for one epoch ---
--- 0.29825758934020996 seconds for one epoch ---
--- 1.0683071613311768 seconds for one epoch ---
--- 0.3058147430419922 seconds for one epoch ---
--- 1.0605533123016357 seconds for one epoch ---
--- 0.31214141845703125 seconds for one epoch ---
--- 1.036912441253662 seconds for one epoch ---
--- 0.2737250328063965 seconds for one epoch ---
--- 1.0354361534118652 seconds for one epoch ---
--- 0.2986013889312744 seconds for one epoch ---
--- 1.0233674049377441 seconds for one epoch ---
--- 0.3005812168121338 seconds for one epoch ---
--- 1.0565204620361328 seconds for one epoch ---
--- 0.29895472526550293 seconds for one epoch ---
--- 1.077300786972046 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.3071597 ]
 [-0.68137723]
 [-0.87396616]
 [-0.        ]
 [ 0.        ]
 [-0.7826583 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.5491395 ]
 [ 0.        ]]
--- 0.30545639991760254 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2290.579833984375, (1103.8965, 0.47509462, 1185.0426, 1.1658465)
   validation loss 714.7586059570312, (481.8363, 0.28700903, 231.46948, 1.1658465)
decoder loss ratio: 18667.174910, decoder SINDy loss  ratio: 0.499659
--- 0.26593661308288574 seconds for one epoch ---
--- 0.3295121192932129 seconds for one epoch ---
--- 1.026946783065796 seconds for one epoch ---
--- 0.33097290992736816 seconds for one epoch ---
--- 1.0349328517913818 seconds for one epoch ---
--- 0.3482239246368408 seconds for one epoch ---
--- 1.0400676727294922 seconds for one epoch ---
--- 0.3295261859893799 seconds for one epoch ---
--- 1.0533113479614258 seconds for one epoch ---
--- 0.32378077507019043 seconds for one epoch ---
--- 1.043440580368042 seconds for one epoch ---
--- 0.3185155391693115 seconds for one epoch ---
--- 1.0209271907806396 seconds for one epoch ---
--- 0.3243143558502197 seconds for one epoch ---
--- 1.0482800006866455 seconds for one epoch ---
--- 0.3183882236480713 seconds for one epoch ---
--- 1.0529005527496338 seconds for one epoch ---
--- 0.29569435119628906 seconds for one epoch ---
--- 1.058715581893921 seconds for one epoch ---
--- 0.288348913192749 seconds for one epoch ---
--- 1.0395114421844482 seconds for one epoch ---
--- 0.29865527153015137 seconds for one epoch ---
--- 1.0422072410583496 seconds for one epoch ---
--- 0.299222469329834 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.3143256 ]
 [-0.6550001 ]
 [-0.8690014 ]
 [ 0.        ]
 [-0.        ]
 [-0.75714666]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.5470378 ]
 [ 0.        ]]
--- 0.2613377571105957 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2686.680419921875, (1462.6906, 2.077049, 1220.7471, 1.1658219)
   validation loss 838.5870971679688, (568.29333, 0.24407975, 268.88382, 1.1658219)
decoder loss ratio: 22016.670397, decoder SINDy loss  ratio: 0.580424
--- 0.2900393009185791 seconds for one epoch ---
--- 1.0739734172821045 seconds for one epoch ---
--- 0.30008482933044434 seconds for one epoch ---
--- 1.044797658920288 seconds for one epoch ---
--- 0.29564929008483887 seconds for one epoch ---
--- 1.055121660232544 seconds for one epoch ---
--- 0.3170948028564453 seconds for one epoch ---
--- 1.041106939315796 seconds for one epoch ---
--- 0.30362367630004883 seconds for one epoch ---
--- 1.0538933277130127 seconds for one epoch ---
--- 0.31714820861816406 seconds for one epoch ---
--- 1.0885021686553955 seconds for one epoch ---
--- 0.3242611885070801 seconds for one epoch ---
--- 1.0874478816986084 seconds for one epoch ---
--- 0.3148834705352783 seconds for one epoch ---
--- 1.0597248077392578 seconds for one epoch ---
--- 0.3182356357574463 seconds for one epoch ---
--- 1.0546987056732178 seconds for one epoch ---
--- 0.2880728244781494 seconds for one epoch ---
--- 1.0812828540802002 seconds for one epoch ---
--- 0.27916979789733887 seconds for one epoch ---
--- 1.084932804107666 seconds for one epoch ---
--- 0.29244470596313477 seconds for one epoch ---
--- 1.061333179473877 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.3332293 ]
 [-0.6616215 ]
 [-0.85001105]
 [ 0.        ]
 [ 0.        ]
 [-0.7619104 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.5387375 ]
 [ 0.        ]]
--- 0.3210303783416748 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5203.74609375, (1471.9965, 0.8937207, 3729.6902, 1.1658243)
   validation loss 1726.5218505859375, (1367.2366, 0.44411367, 357.67538, 1.1658243)
decoder loss ratio: 52969.118437, decoder SINDy loss  ratio: 0.772093
--- 0.2656736373901367 seconds for one epoch ---
--- 0.3319094181060791 seconds for one epoch ---
--- 1.0574579238891602 seconds for one epoch ---
--- 0.31598615646362305 seconds for one epoch ---
--- 1.0636606216430664 seconds for one epoch ---
--- 0.3215343952178955 seconds for one epoch ---
--- 1.0605101585388184 seconds for one epoch ---
--- 0.3093433380126953 seconds for one epoch ---
--- 1.0999417304992676 seconds for one epoch ---
--- 0.3358316421508789 seconds for one epoch ---
--- 1.0636930465698242 seconds for one epoch ---
--- 0.5583620071411133 seconds for one epoch ---
--- 1.0822153091430664 seconds for one epoch ---
--- 0.32762813568115234 seconds for one epoch ---
--- 1.0922558307647705 seconds for one epoch ---
--- 0.3352043628692627 seconds for one epoch ---
--- 1.0753803253173828 seconds for one epoch ---
--- 0.3261125087738037 seconds for one epoch ---
--- 1.0926997661590576 seconds for one epoch ---
--- 0.2789933681488037 seconds for one epoch ---
--- 1.0881614685058594 seconds for one epoch ---
--- 0.29483675956726074 seconds for one epoch ---
--- 1.0902600288391113 seconds for one epoch ---
--- 0.2978200912475586 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.3622043 ]
 [-0.7156002 ]
 [-0.8482416 ]
 [-0.        ]
 [ 0.        ]
 [-0.75660115]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.556261  ]
 [ 0.        ]]
--- 0.2573716640472412 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3693.7626953125, (1428.5593, 2.101699, 2261.9358, 1.1660633)
   validation loss 1273.484375, (1022.74194, 0.21678574, 249.3596, 1.1660633)
decoder loss ratio: 39622.798444, decoder SINDy loss  ratio: 0.538278
--- 0.31291747093200684 seconds for one epoch ---
--- 1.0797743797302246 seconds for one epoch ---
--- 0.3239762783050537 seconds for one epoch ---
--- 1.0767974853515625 seconds for one epoch ---
--- 0.30971837043762207 seconds for one epoch ---
--- 1.0958971977233887 seconds for one epoch ---
--- 0.33762693405151367 seconds for one epoch ---
--- 1.087113857269287 seconds for one epoch ---
--- 0.32317233085632324 seconds for one epoch ---
--- 1.0769445896148682 seconds for one epoch ---
--- 0.3124840259552002 seconds for one epoch ---
--- 1.1147756576538086 seconds for one epoch ---
--- 0.2992057800292969 seconds for one epoch ---
--- 1.105459451675415 seconds for one epoch ---
--- 0.3155069351196289 seconds for one epoch ---
--- 1.1006481647491455 seconds for one epoch ---
--- 0.29366183280944824 seconds for one epoch ---
--- 1.0767664909362793 seconds for one epoch ---
--- 0.2938394546508789 seconds for one epoch ---
--- 1.1021406650543213 seconds for one epoch ---
--- 0.31283092498779297 seconds for one epoch ---
--- 1.0672943592071533 seconds for one epoch ---
--- 0.29912781715393066 seconds for one epoch ---
--- 1.067082166671753 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.3898273 ]
 [-0.7113938 ]
 [-0.8353255 ]
 [-0.        ]
 [-0.        ]
 [-0.75671285]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.5653172 ]
 [ 0.        ]]
--- 0.2819821834564209 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1754.8609619140625, (807.75574, 0.26179427, 945.67725, 1.1661526)
   validation loss 933.0693359375, (659.7884, 0.2456476, 271.86914, 1.1661526)
decoder loss ratio: 25561.347715, decoder SINDy loss  ratio: 0.586868
--- 0.2589247226715088 seconds for one epoch ---
--- 0.2887258529663086 seconds for one epoch ---
--- 1.0785133838653564 seconds for one epoch ---
--- 0.29688572883605957 seconds for one epoch ---
--- 1.103567361831665 seconds for one epoch ---
--- 0.28478074073791504 seconds for one epoch ---
--- 1.0869250297546387 seconds for one epoch ---
--- 0.29889488220214844 seconds for one epoch ---
--- 1.114300012588501 seconds for one epoch ---
--- 0.2817850112915039 seconds for one epoch ---
--- 1.0970618724822998 seconds for one epoch ---
--- 0.29389190673828125 seconds for one epoch ---
--- 1.0966181755065918 seconds for one epoch ---
--- 0.3012704849243164 seconds for one epoch ---
--- 1.1098673343658447 seconds for one epoch ---
--- 0.29688119888305664 seconds for one epoch ---
--- 1.1113345623016357 seconds for one epoch ---
--- 0.3027665615081787 seconds for one epoch ---
--- 1.0959625244140625 seconds for one epoch ---
--- 0.30513477325439453 seconds for one epoch ---
--- 1.1010088920593262 seconds for one epoch ---
--- 0.3036942481994629 seconds for one epoch ---
--- 1.0985660552978516 seconds for one epoch ---
--- 0.2953641414642334 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.4123785]
 [-0.7606988]
 [-0.8263127]
 [ 0.       ]
 [ 0.       ]
 [-0.7496955]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5746698]
 [ 0.       ]]
--- 0.28928279876708984 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3068.441162109375, (1614.7312, 2.4794405, 1450.0641, 1.1663281)
   validation loss 1039.9320068359375, (747.5158, 0.20111892, 291.04877, 1.1663281)
decoder loss ratio: 28960.060151, decoder SINDy loss  ratio: 0.628270
--- 0.3112466335296631 seconds for one epoch ---
--- 1.107424259185791 seconds for one epoch ---
--- 0.3327360153198242 seconds for one epoch ---
--- 1.1036269664764404 seconds for one epoch ---
--- 0.3237752914428711 seconds for one epoch ---
--- 1.1089696884155273 seconds for one epoch ---
--- 0.32566189765930176 seconds for one epoch ---
--- 1.144859790802002 seconds for one epoch ---
--- 0.3238518238067627 seconds for one epoch ---
--- 1.1280546188354492 seconds for one epoch ---
--- 0.329174280166626 seconds for one epoch ---
--- 1.112070083618164 seconds for one epoch ---
--- 0.3011200428009033 seconds for one epoch ---
--- 1.1542041301727295 seconds for one epoch ---
--- 0.32013940811157227 seconds for one epoch ---
--- 1.1463208198547363 seconds for one epoch ---
--- 0.31766700744628906 seconds for one epoch ---
--- 1.1045305728912354 seconds for one epoch ---
--- 0.3265817165374756 seconds for one epoch ---
--- 1.1081631183624268 seconds for one epoch ---
--- 0.29461097717285156 seconds for one epoch ---
--- 1.1392343044281006 seconds for one epoch ---
--- 0.29109835624694824 seconds for one epoch ---
--- 1.1248815059661865 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.4408953 ]
 [-0.7590673 ]
 [-0.81951463]
 [ 0.        ]
 [-0.        ]
 [-0.7432723 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.5988724 ]
 [ 0.        ]]
--- 0.3161356449127197 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3666.69140625, (1321.1466, 0.5132126, 2343.865, 1.1664857)
   validation loss 990.093505859375, (708.7068, 0.26071805, 279.95944, 1.1664857)
decoder loss ratio: 27456.531302, decoder SINDy loss  ratio: 0.604332
--- 0.2624659538269043 seconds for one epoch ---
--- 0.34720277786254883 seconds for one epoch ---
--- 1.1051268577575684 seconds for one epoch ---
--- 0.3290891647338867 seconds for one epoch ---
--- 1.1055107116699219 seconds for one epoch ---
--- 0.3221547603607178 seconds for one epoch ---
--- 1.1056015491485596 seconds for one epoch ---
--- 0.32318949699401855 seconds for one epoch ---
--- 1.1265392303466797 seconds for one epoch ---
--- 0.3208284378051758 seconds for one epoch ---
--- 1.1292827129364014 seconds for one epoch ---
--- 0.3273928165435791 seconds for one epoch ---
--- 1.1472787857055664 seconds for one epoch ---
--- 0.30269384384155273 seconds for one epoch ---
--- 1.1235105991363525 seconds for one epoch ---
--- 0.32582664489746094 seconds for one epoch ---
--- 1.1451404094696045 seconds for one epoch ---
--- 0.3147892951965332 seconds for one epoch ---
--- 1.1391584873199463 seconds for one epoch ---
--- 0.31354403495788574 seconds for one epoch ---
--- 1.120837688446045 seconds for one epoch ---
--- 0.2949073314666748 seconds for one epoch ---
--- 1.1228725910186768 seconds for one epoch ---
--- 0.28055882453918457 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.4785326 ]
 [-0.77952397]
 [-0.81882626]
 [-0.        ]
 [-0.        ]
 [-0.7403493 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.6316764 ]
 [ 0.        ]]
--- 0.253734827041626 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3552.942626953125, (1663.7446, 3.7934628, 1884.2378, 1.1668084)
   validation loss 1040.6051025390625, (777.7082, 0.16216293, 261.568, 1.1668084)
decoder loss ratio: 30129.765477, decoder SINDy loss  ratio: 0.564631
--- 0.29381656646728516 seconds for one epoch ---
--- 1.1508638858795166 seconds for one epoch ---
--- 0.3057746887207031 seconds for one epoch ---
--- 1.1447393894195557 seconds for one epoch ---
--- 0.29554295539855957 seconds for one epoch ---
--- 1.135615348815918 seconds for one epoch ---
--- 0.30124950408935547 seconds for one epoch ---
--- 1.1332852840423584 seconds for one epoch ---
--- 0.3004724979400635 seconds for one epoch ---
--- 1.1334807872772217 seconds for one epoch ---
--- 0.3025805950164795 seconds for one epoch ---
--- 1.1460182666778564 seconds for one epoch ---
--- 0.29219508171081543 seconds for one epoch ---
--- 1.142796277999878 seconds for one epoch ---
--- 0.3042464256286621 seconds for one epoch ---
--- 1.1239712238311768 seconds for one epoch ---
--- 0.2877016067504883 seconds for one epoch ---
--- 1.1812846660614014 seconds for one epoch ---
--- 0.3005790710449219 seconds for one epoch ---
--- 1.1468284130096436 seconds for one epoch ---
--- 0.3133869171142578 seconds for one epoch ---
--- 1.1574575901031494 seconds for one epoch ---
--- 0.2877848148345947 seconds for one epoch ---
--- 1.1435413360595703 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.5003254]
 [-0.7578908]
 [-0.81641  ]
 [-0.       ]
 [-0.       ]
 [-0.7307835]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.6443276]
 [ 0.       ]]
--- 0.2800865173339844 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2729.8720703125, (1716.3635, 2.1174552, 1010.22424, 1.1668836)
   validation loss 1248.433349609375, (962.46643, 0.25296244, 284.5471, 1.1668836)
decoder loss ratio: 37287.620439, decoder SINDy loss  ratio: 0.614235
--- 0.26328420639038086 seconds for one epoch ---
--- 0.2994728088378906 seconds for one epoch ---
--- 1.1203320026397705 seconds for one epoch ---
--- 0.30349159240722656 seconds for one epoch ---
--- 1.1478607654571533 seconds for one epoch ---
--- 0.29046177864074707 seconds for one epoch ---
--- 1.133979320526123 seconds for one epoch ---
--- 0.29151058197021484 seconds for one epoch ---
--- 1.1464900970458984 seconds for one epoch ---
--- 0.29175472259521484 seconds for one epoch ---
--- 1.146453619003296 seconds for one epoch ---
--- 0.2976548671722412 seconds for one epoch ---
--- 1.1307547092437744 seconds for one epoch ---
--- 0.28645873069763184 seconds for one epoch ---
--- 1.143770456314087 seconds for one epoch ---
--- 0.2957792282104492 seconds for one epoch ---
--- 1.1682384014129639 seconds for one epoch ---
--- 0.3096597194671631 seconds for one epoch ---
--- 1.1700763702392578 seconds for one epoch ---
--- 0.30443501472473145 seconds for one epoch ---
--- 1.1614060401916504 seconds for one epoch ---
--- 0.30064868927001953 seconds for one epoch ---
--- 1.1512210369110107 seconds for one epoch ---
--- 0.2933206558227539 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.5395625 ]
 [-0.7493518 ]
 [-0.81752217]
 [ 0.        ]
 [ 0.        ]
 [-0.73728293]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6673887 ]
 [ 0.        ]]
--- 0.2713332176208496 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1917.62255859375, (858.54974, 1.4048873, 1056.5009, 1.1670516)
   validation loss 1187.3714599609375, (953.6162, 0.24576567, 232.34244, 1.1670516)
decoder loss ratio: 36944.747562, decoder SINDy loss  ratio: 0.501544
--- 0.3028757572174072 seconds for one epoch ---
--- 1.1603879928588867 seconds for one epoch ---
--- 0.30400705337524414 seconds for one epoch ---
--- 1.1609127521514893 seconds for one epoch ---
--- 0.2999563217163086 seconds for one epoch ---
--- 1.1849751472473145 seconds for one epoch ---
--- 0.29725217819213867 seconds for one epoch ---
--- 1.22149658203125 seconds for one epoch ---
--- 0.3040146827697754 seconds for one epoch ---
--- 1.1490309238433838 seconds for one epoch ---
--- 0.30235838890075684 seconds for one epoch ---
--- 1.211136817932129 seconds for one epoch ---
--- 0.29955577850341797 seconds for one epoch ---
--- 1.161827802658081 seconds for one epoch ---
--- 0.29739975929260254 seconds for one epoch ---
--- 1.1931612491607666 seconds for one epoch ---
--- 0.29455065727233887 seconds for one epoch ---
--- 1.2138376235961914 seconds for one epoch ---
--- 0.29891252517700195 seconds for one epoch ---
--- 1.231942892074585 seconds for one epoch ---
--- 0.2764766216278076 seconds for one epoch ---
--- 1.1585533618927002 seconds for one epoch ---
--- 0.2979879379272461 seconds for one epoch ---
--- 1.180821418762207 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.5693853 ]
 [-0.69389284]
 [-0.81331253]
 [ 0.        ]
 [-0.        ]
 [-0.72884214]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.699282  ]
 [ 0.        ]]
--- 0.3119468688964844 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3111.114990234375, (1223.186, 2.8236938, 1883.9381, 1.167189)
   validation loss 790.676513671875, (501.07355, 0.23307993, 288.2027, 1.167189)
decoder loss ratio: 19412.459127, decoder SINDy loss  ratio: 0.622126
--- 0.2714204788208008 seconds for one epoch ---
--- 0.3195607662200928 seconds for one epoch ---
--- 1.1773655414581299 seconds for one epoch ---
--- 0.32875728607177734 seconds for one epoch ---
--- 1.1658275127410889 seconds for one epoch ---
--- 0.3346726894378662 seconds for one epoch ---
--- 1.1590657234191895 seconds for one epoch ---
--- 0.323974609375 seconds for one epoch ---
--- 1.212702989578247 seconds for one epoch ---
--- 0.3313124179840088 seconds for one epoch ---
--- 1.1918983459472656 seconds for one epoch ---
--- 0.34383440017700195 seconds for one epoch ---
--- 1.2154467105865479 seconds for one epoch ---
--- 0.34757232666015625 seconds for one epoch ---
--- 1.1850910186767578 seconds for one epoch ---
--- 0.330075740814209 seconds for one epoch ---
--- 1.1821322441101074 seconds for one epoch ---
--- 0.3475677967071533 seconds for one epoch ---
--- 1.209181785583496 seconds for one epoch ---
--- 0.33521342277526855 seconds for one epoch ---
--- 1.181807279586792 seconds for one epoch ---
--- 0.32034945487976074 seconds for one epoch ---
--- 1.1958184242248535 seconds for one epoch ---
--- 0.3033161163330078 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.590594 ]
 [-0.7214455]
 [-0.7933908]
 [-0.       ]
 [ 0.       ]
 [-0.7196182]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.7076514]
 [ 0.       ]]
--- 0.2579307556152344 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3315.531982421875, (1531.5251, 0.89821804, 1781.9413, 1.16718)
   validation loss 1022.4236450195312, (696.463, 0.24101835, 324.55243, 1.16718)
decoder loss ratio: 26982.186225, decoder SINDy loss  ratio: 0.700592
--- 0.30252790451049805 seconds for one epoch ---
--- 1.1271347999572754 seconds for one epoch ---
--- 0.30157995223999023 seconds for one epoch ---
--- 1.1717853546142578 seconds for one epoch ---
--- 0.2892897129058838 seconds for one epoch ---
--- 1.1579997539520264 seconds for one epoch ---
--- 0.2986299991607666 seconds for one epoch ---
--- 1.1463570594787598 seconds for one epoch ---
--- 0.2925570011138916 seconds for one epoch ---
--- 1.1938848495483398 seconds for one epoch ---
--- 0.3054623603820801 seconds for one epoch ---
--- 1.163360595703125 seconds for one epoch ---
--- 0.30331993103027344 seconds for one epoch ---
--- 1.1779639720916748 seconds for one epoch ---
--- 0.30318117141723633 seconds for one epoch ---
--- 1.1939270496368408 seconds for one epoch ---
--- 0.2945215702056885 seconds for one epoch ---
--- 1.2001371383666992 seconds for one epoch ---
--- 0.2959015369415283 seconds for one epoch ---
--- 1.1726820468902588 seconds for one epoch ---
--- 0.29805421829223633 seconds for one epoch ---
--- 1.173914909362793 seconds for one epoch ---
--- 0.28566622734069824 seconds for one epoch ---
--- 1.1761794090270996 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.6319592 ]
 [-0.7125004 ]
 [-0.77538455]
 [-0.        ]
 [ 0.        ]
 [-0.7286296 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.7364094 ]
 [ 0.        ]]
--- 0.31293511390686035 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2208.014892578125, (860.1867, 1.1646101, 1345.4961, 1.1673602)
   validation loss 1152.259033203125, (847.91956, 0.18046877, 302.9916, 1.1673602)
decoder loss ratio: 32849.875640, decoder SINDy loss  ratio: 0.654050
--- 0.28421473503112793 seconds for one epoch ---
--- 0.3160560131072998 seconds for one epoch ---
--- 1.2076795101165771 seconds for one epoch ---
--- 0.31412220001220703 seconds for one epoch ---
--- 1.1771323680877686 seconds for one epoch ---
--- 0.3144402503967285 seconds for one epoch ---
--- 1.2147526741027832 seconds for one epoch ---
--- 0.3180544376373291 seconds for one epoch ---
--- 1.2181344032287598 seconds for one epoch ---
--- 0.32261204719543457 seconds for one epoch ---
--- 1.191004753112793 seconds for one epoch ---
--- 0.3341381549835205 seconds for one epoch ---
--- 1.1798439025878906 seconds for one epoch ---
--- 0.324190616607666 seconds for one epoch ---
--- 1.207207202911377 seconds for one epoch ---
--- 0.32897090911865234 seconds for one epoch ---
--- 1.1970734596252441 seconds for one epoch ---
--- 0.3359396457672119 seconds for one epoch ---
--- 1.2454233169555664 seconds for one epoch ---
--- 0.3111743927001953 seconds for one epoch ---
--- 1.2024705410003662 seconds for one epoch ---
--- 0.3335988521575928 seconds for one epoch ---
--- 1.2205758094787598 seconds for one epoch ---
--- 0.3052046298980713 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.652593  ]
 [-0.7093259 ]
 [-0.792002  ]
 [ 0.        ]
 [-0.        ]
 [-0.71231663]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.7590911 ]
 [ 0.        ]]
--- 0.2570209503173828 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1557.769775390625, (860.97064, 0.20221744, 695.4295, 1.1674758)
   validation loss 1199.19189453125, (914.4138, 0.18032798, 283.4303, 1.1674758)
decoder loss ratio: 35425.978815, decoder SINDy loss  ratio: 0.611824
--- 0.2930929660797119 seconds for one epoch ---
--- 1.201575517654419 seconds for one epoch ---
--- 0.2837224006652832 seconds for one epoch ---
--- 1.189246654510498 seconds for one epoch ---
--- 0.29489684104919434 seconds for one epoch ---
--- 1.1540932655334473 seconds for one epoch ---
--- 0.3071708679199219 seconds for one epoch ---
--- 1.1920616626739502 seconds for one epoch ---
--- 0.3021574020385742 seconds for one epoch ---
--- 1.1734166145324707 seconds for one epoch ---
--- 0.31588196754455566 seconds for one epoch ---
--- 1.1707730293273926 seconds for one epoch ---
--- 0.3036971092224121 seconds for one epoch ---
--- 1.2279131412506104 seconds for one epoch ---
--- 0.2827420234680176 seconds for one epoch ---
--- 1.2289478778839111 seconds for one epoch ---
--- 0.2879331111907959 seconds for one epoch ---
--- 1.1956086158752441 seconds for one epoch ---
--- 0.3030886650085449 seconds for one epoch ---
--- 1.2250304222106934 seconds for one epoch ---
--- 0.282975435256958 seconds for one epoch ---
--- 1.2246308326721191 seconds for one epoch ---
--- 0.29411959648132324 seconds for one epoch ---
--- 1.2197680473327637 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.679747  ]
 [-0.70039755]
 [-0.80188775]
 [ 0.        ]
 [ 0.        ]
 [-0.70220387]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.7860587 ]
 [ 0.        ]]
--- 0.27356767654418945 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3737.406494140625, (1585.8574, 3.337496, 2147.0437, 1.1676686)
   validation loss 1424.31591796875, (1166.0817, 0.24293305, 256.82364, 1.1676686)
decoder loss ratio: 45176.028110, decoder SINDy loss  ratio: 0.554390
THRESHOLDING: 5 active coefficients
--- 1.188699722290039 seconds for one epoch ---
--- 0.29797935485839844 seconds for one epoch ---
--- 1.207869529724121 seconds for one epoch ---
--- 0.3002326488494873 seconds for one epoch ---
--- 1.1992247104644775 seconds for one epoch ---
--- 0.3029963970184326 seconds for one epoch ---
--- 1.1928648948669434 seconds for one epoch ---
--- 0.3007190227508545 seconds for one epoch ---
--- 1.1959962844848633 seconds for one epoch ---
--- 0.2909543514251709 seconds for one epoch ---
--- 1.2168846130371094 seconds for one epoch ---
--- 0.29845738410949707 seconds for one epoch ---
--- 1.21024489402771 seconds for one epoch ---
--- 0.3021547794342041 seconds for one epoch ---
--- 1.1977720260620117 seconds for one epoch ---
--- 0.3016846179962158 seconds for one epoch ---
--- 1.1786653995513916 seconds for one epoch ---
--- 0.2928290367126465 seconds for one epoch ---
--- 1.2173664569854736 seconds for one epoch ---
--- 0.3199961185455322 seconds for one epoch ---
--- 1.2335777282714844 seconds for one epoch ---
--- 0.31172943115234375 seconds for one epoch ---
--- 1.2497141361236572 seconds for one epoch ---
--- 0.3129923343658447 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.708203  ]
 [-0.6846787 ]
 [-0.77871203]
 [-0.        ]
 [-0.        ]
 [-0.70250267]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.8086154 ]
 [ 0.        ]]
--- 0.2439279556274414 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2093.43701171875, (742.14734, 1.4526913, 1348.6693, 1.1677951)
   validation loss 712.44873046875, (457.79526, 0.2646854, 253.22102, 1.1677951)
decoder loss ratio: 17735.783046, decoder SINDy loss  ratio: 0.546613
--- 0.2886314392089844 seconds for one epoch ---
--- 1.2022347450256348 seconds for one epoch ---
--- 0.3074812889099121 seconds for one epoch ---
--- 1.215057611465454 seconds for one epoch ---
--- 0.3033761978149414 seconds for one epoch ---
--- 1.2013680934906006 seconds for one epoch ---
--- 0.3139355182647705 seconds for one epoch ---
--- 1.2183926105499268 seconds for one epoch ---
--- 0.2891530990600586 seconds for one epoch ---
--- 1.2361199855804443 seconds for one epoch ---
--- 0.29746007919311523 seconds for one epoch ---
--- 1.2338004112243652 seconds for one epoch ---
--- 0.30025362968444824 seconds for one epoch ---
--- 1.218738079071045 seconds for one epoch ---
--- 0.29842185974121094 seconds for one epoch ---
--- 1.2370858192443848 seconds for one epoch ---
--- 0.29360485076904297 seconds for one epoch ---
--- 1.2247023582458496 seconds for one epoch ---
--- 0.307861328125 seconds for one epoch ---
--- 1.2443041801452637 seconds for one epoch ---
--- 0.3052029609680176 seconds for one epoch ---
--- 1.2288625240325928 seconds for one epoch ---
--- 0.28656458854675293 seconds for one epoch ---
--- 1.2173666954040527 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.7528203 ]
 [-0.67684615]
 [-0.76494473]
 [-0.        ]
 [-0.        ]
 [-0.7095277 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.847736  ]
 [ 0.        ]]
--- 0.296588659286499 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3304.359375, (1590.4291, 1.3351451, 1711.4269, 1.1681552)
   validation loss 1169.016357421875, (894.2448, 0.20690931, 273.39645, 1.1681552)
decoder loss ratio: 34644.596495, decoder SINDy loss  ratio: 0.590165
--- 0.2640049457550049 seconds for one epoch ---
--- 0.3026769161224365 seconds for one epoch ---
--- 1.2368848323822021 seconds for one epoch ---
--- 0.2975955009460449 seconds for one epoch ---
--- 1.2111155986785889 seconds for one epoch ---
--- 0.30147218704223633 seconds for one epoch ---
--- 1.2030439376831055 seconds for one epoch ---
--- 0.3023066520690918 seconds for one epoch ---
--- 1.214545488357544 seconds for one epoch ---
--- 0.3016321659088135 seconds for one epoch ---
--- 1.2340495586395264 seconds for one epoch ---
--- 0.2988557815551758 seconds for one epoch ---
--- 1.2508454322814941 seconds for one epoch ---
--- 0.289104700088501 seconds for one epoch ---
--- 1.200383186340332 seconds for one epoch ---
--- 0.3049952983856201 seconds for one epoch ---
--- 1.242753028869629 seconds for one epoch ---
--- 0.30166196823120117 seconds for one epoch ---
--- 1.2441902160644531 seconds for one epoch ---
--- 0.30251598358154297 seconds for one epoch ---
--- 1.2554550170898438 seconds for one epoch ---
--- 0.29566335678100586 seconds for one epoch ---
--- 1.2420616149902344 seconds for one epoch ---
--- 0.30578064918518066 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.7743697 ]
 [-0.66166455]
 [-0.7554525 ]
 [ 0.        ]
 [-0.        ]
 [-0.69914544]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.865826  ]
 [ 0.        ]]
--- 0.26784181594848633 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4996.59814453125, (3033.205, 1.1141872, 1961.1101, 1.1682962)
   validation loss 1372.0247802734375, (1053.517, 0.26355052, 317.07596, 1.1682962)
decoder loss ratio: 40815.076317, decoder SINDy loss  ratio: 0.684453
--- 0.2898986339569092 seconds for one epoch ---
--- 1.1979272365570068 seconds for one epoch ---
--- 0.2911045551300049 seconds for one epoch ---
--- 1.2506766319274902 seconds for one epoch ---
--- 0.28832316398620605 seconds for one epoch ---
--- 1.2625691890716553 seconds for one epoch ---
--- 0.3009016513824463 seconds for one epoch ---
--- 1.2705929279327393 seconds for one epoch ---
--- 0.2849845886230469 seconds for one epoch ---
--- 1.2793776988983154 seconds for one epoch ---
--- 0.31307411193847656 seconds for one epoch ---
--- 1.2683324813842773 seconds for one epoch ---
--- 0.3194906711578369 seconds for one epoch ---
--- 1.2422268390655518 seconds for one epoch ---
--- 0.3065450191497803 seconds for one epoch ---
--- 1.2501983642578125 seconds for one epoch ---
--- 0.3183579444885254 seconds for one epoch ---
--- 1.2699646949768066 seconds for one epoch ---
--- 0.305661678314209 seconds for one epoch ---
--- 1.246506929397583 seconds for one epoch ---
--- 0.32436585426330566 seconds for one epoch ---
--- 1.2826449871063232 seconds for one epoch ---
--- 0.34995102882385254 seconds for one epoch ---
--- 1.275763750076294 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.802376  ]
 [-0.6496529 ]
 [-0.73956245]
 [ 0.        ]
 [ 0.        ]
 [-0.6950362 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.8852625 ]
 [-0.        ]]
--- 0.2953920364379883 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3038.15966796875, (1157.1118, 4.564215, 1875.3152, 1.1684648)
   validation loss 607.7197875976562, (372.68744, 0.2933169, 233.57057, 1.1684648)
decoder loss ratio: 14438.558399, decoder SINDy loss  ratio: 0.504195
--- 0.2586486339569092 seconds for one epoch ---
--- 0.2861807346343994 seconds for one epoch ---
--- 1.2664704322814941 seconds for one epoch ---
--- 0.3040163516998291 seconds for one epoch ---
--- 1.2709720134735107 seconds for one epoch ---
--- 0.3014233112335205 seconds for one epoch ---
--- 1.2678484916687012 seconds for one epoch ---
--- 0.30914974212646484 seconds for one epoch ---
--- 1.268014907836914 seconds for one epoch ---
--- 0.28896617889404297 seconds for one epoch ---
--- 1.282313346862793 seconds for one epoch ---
--- 0.3177340030670166 seconds for one epoch ---
--- 1.2983250617980957 seconds for one epoch ---
--- 0.29802417755126953 seconds for one epoch ---
--- 1.279458999633789 seconds for one epoch ---
--- 0.31220340728759766 seconds for one epoch ---
--- 1.2922375202178955 seconds for one epoch ---
--- 0.2900815010070801 seconds for one epoch ---
--- 1.2586650848388672 seconds for one epoch ---
--- 0.31336498260498047 seconds for one epoch ---
--- 1.2649664878845215 seconds for one epoch ---
--- 0.2955441474914551 seconds for one epoch ---
--- 1.257025957107544 seconds for one epoch ---
--- 0.2922389507293701 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.8172581 ]
 [-0.666997  ]
 [-0.7395252 ]
 [-0.        ]
 [-0.        ]
 [-0.67542607]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.9123003 ]
 [ 0.        ]]
--- 0.25919461250305176 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2986.609619140625, (1013.93176, 0.27600536, 1971.2332, 1.1687084)
   validation loss 1133.58544921875, (900.4828, 0.3084193, 231.6256, 1.1687084)
decoder loss ratio: 34886.266517, decoder SINDy loss  ratio: 0.499996
--- 0.29587578773498535 seconds for one epoch ---
--- 1.2581312656402588 seconds for one epoch ---
--- 0.2979466915130615 seconds for one epoch ---
--- 1.2819631099700928 seconds for one epoch ---
--- 0.3166007995605469 seconds for one epoch ---
--- 1.2915565967559814 seconds for one epoch ---
--- 0.31553030014038086 seconds for one epoch ---
--- 1.294489860534668 seconds for one epoch ---
--- 0.3031468391418457 seconds for one epoch ---
--- 1.2736129760742188 seconds for one epoch ---
--- 0.33983325958251953 seconds for one epoch ---
--- 1.2684345245361328 seconds for one epoch ---
--- 0.31633830070495605 seconds for one epoch ---
--- 1.282435417175293 seconds for one epoch ---
--- 0.2969346046447754 seconds for one epoch ---
--- 1.2756187915802002 seconds for one epoch ---
--- 0.2803785800933838 seconds for one epoch ---
--- 1.2936320304870605 seconds for one epoch ---
--- 0.31673216819763184 seconds for one epoch ---
--- 1.2860534191131592 seconds for one epoch ---
--- 0.30800843238830566 seconds for one epoch ---
--- 1.2961361408233643 seconds for one epoch ---
--- 0.2968292236328125 seconds for one epoch ---
--- 1.2582061290740967 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.848801  ]
 [-0.68356836]
 [-0.7376426 ]
 [-0.        ]
 [ 0.        ]
 [-0.6805672 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9350972 ]
 [ 0.        ]]
--- 0.2775766849517822 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3831.95556640625, (1946.6298, 3.7410154, 1880.4158, 1.1689689)
   validation loss 1096.3486328125, (823.6055, 0.32457486, 271.2496, 1.1689689)
decoder loss ratio: 31907.908066, decoder SINDy loss  ratio: 0.585530
--- 0.2623763084411621 seconds for one epoch ---
--- 0.29108738899230957 seconds for one epoch ---
--- 1.260373830795288 seconds for one epoch ---
--- 0.28948378562927246 seconds for one epoch ---
--- 1.2733075618743896 seconds for one epoch ---
--- 0.30128002166748047 seconds for one epoch ---
--- 1.2733800411224365 seconds for one epoch ---
--- 0.2949252128601074 seconds for one epoch ---
--- 1.2545561790466309 seconds for one epoch ---
--- 0.30303382873535156 seconds for one epoch ---
--- 1.2927942276000977 seconds for one epoch ---
--- 0.2797229290008545 seconds for one epoch ---
--- 1.300764799118042 seconds for one epoch ---
--- 0.31310415267944336 seconds for one epoch ---
--- 1.277921199798584 seconds for one epoch ---
--- 0.29364895820617676 seconds for one epoch ---
--- 1.292680025100708 seconds for one epoch ---
--- 0.29791998863220215 seconds for one epoch ---
--- 1.3072504997253418 seconds for one epoch ---
--- 0.29108548164367676 seconds for one epoch ---
--- 1.301278829574585 seconds for one epoch ---
--- 0.28803062438964844 seconds for one epoch ---
--- 1.3013339042663574 seconds for one epoch ---
--- 0.30501246452331543 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.8698876 ]
 [-0.6928672 ]
 [-0.72864026]
 [ 0.        ]
 [ 0.        ]
 [-0.67228734]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.9605274 ]
 [-0.        ]]
--- 0.2560594081878662 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2982.744140625, (1021.6107, 1.4053769, 1958.5588, 1.169228)
   validation loss 1041.23388671875, (808.7117, 0.22894436, 231.12408, 1.169228)
decoder loss ratio: 31330.894078, decoder SINDy loss  ratio: 0.498914
--- 0.29344820976257324 seconds for one epoch ---
--- 1.2214062213897705 seconds for one epoch ---
--- 0.2993896007537842 seconds for one epoch ---
--- 1.261157512664795 seconds for one epoch ---
--- 0.3096897602081299 seconds for one epoch ---
--- 1.3314049243927002 seconds for one epoch ---
--- 0.34564709663391113 seconds for one epoch ---
--- 1.3067641258239746 seconds for one epoch ---
--- 0.3437979221343994 seconds for one epoch ---
--- 1.3146560192108154 seconds for one epoch ---
--- 0.36110424995422363 seconds for one epoch ---
--- 1.2838311195373535 seconds for one epoch ---
--- 0.34093499183654785 seconds for one epoch ---
--- 1.296837568283081 seconds for one epoch ---
--- 0.3327937126159668 seconds for one epoch ---
--- 1.3009684085845947 seconds for one epoch ---
--- 0.33149051666259766 seconds for one epoch ---
--- 1.326291799545288 seconds for one epoch ---
--- 0.33420825004577637 seconds for one epoch ---
--- 1.273554801940918 seconds for one epoch ---
--- 0.3179285526275635 seconds for one epoch ---
--- 1.2914607524871826 seconds for one epoch ---
--- 0.31746387481689453 seconds for one epoch ---
--- 1.2964656352996826 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.8923113 ]
 [-0.6852854 ]
 [-0.72588515]
 [ 0.        ]
 [-0.        ]
 [-0.67098653]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9750915 ]
 [-0.        ]]
--- 0.291156530380249 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3089.779541015625, (1496.5924, 0.4233434, 1591.5944, 1.1694083)
   validation loss 682.755615234375, (448.56406, 0.23320246, 232.78888, 1.1694083)
decoder loss ratio: 17378.150286, decoder SINDy loss  ratio: 0.502508
--- 0.2448132038116455 seconds for one epoch ---
--- 0.29747676849365234 seconds for one epoch ---
--- 1.2691371440887451 seconds for one epoch ---
--- 0.2988014221191406 seconds for one epoch ---
--- 1.2966303825378418 seconds for one epoch ---
--- 0.29552364349365234 seconds for one epoch ---
--- 1.308021068572998 seconds for one epoch ---
--- 0.2977426052093506 seconds for one epoch ---
--- 1.3113555908203125 seconds for one epoch ---
--- 0.28301334381103516 seconds for one epoch ---
--- 1.3092827796936035 seconds for one epoch ---
--- 0.2911529541015625 seconds for one epoch ---
--- 1.3120651245117188 seconds for one epoch ---
--- 0.29970741271972656 seconds for one epoch ---
--- 1.2909026145935059 seconds for one epoch ---
--- 0.2876157760620117 seconds for one epoch ---
--- 1.3276317119598389 seconds for one epoch ---
--- 0.29276537895202637 seconds for one epoch ---
--- 1.306215763092041 seconds for one epoch ---
--- 0.28780603408813477 seconds for one epoch ---
--- 1.3314902782440186 seconds for one epoch ---
--- 0.2988755702972412 seconds for one epoch ---
--- 1.327531337738037 seconds for one epoch ---
--- 0.29554247856140137 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.9367995 ]
 [-0.69298106]
 [-0.71522975]
 [-0.        ]
 [ 0.        ]
 [-0.6659965 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.0308113 ]
 [ 0.        ]]
--- 0.26474785804748535 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3811.53759765625, (1317.6553, 5.011968, 2487.7004, 1.1698861)
   validation loss 952.9486694335938, (684.30426, 0.29693475, 267.1776, 1.1698861)
decoder loss ratio: 26511.135047, decoder SINDy loss  ratio: 0.576740
--- 0.29928135871887207 seconds for one epoch ---
--- 1.2698018550872803 seconds for one epoch ---
--- 0.29738426208496094 seconds for one epoch ---
--- 1.2842440605163574 seconds for one epoch ---
--- 0.29228901863098145 seconds for one epoch ---
--- 1.314563512802124 seconds for one epoch ---
--- 0.31790637969970703 seconds for one epoch ---
--- 1.3026583194732666 seconds for one epoch ---
--- 0.2996249198913574 seconds for one epoch ---
--- 1.3252193927764893 seconds for one epoch ---
--- 0.2835562229156494 seconds for one epoch ---
--- 1.322352409362793 seconds for one epoch ---
--- 0.31693506240844727 seconds for one epoch ---
--- 1.3322958946228027 seconds for one epoch ---
--- 0.295731782913208 seconds for one epoch ---
--- 1.3358337879180908 seconds for one epoch ---
--- 0.30373144149780273 seconds for one epoch ---
--- 1.332693338394165 seconds for one epoch ---
--- 0.29486656188964844 seconds for one epoch ---
--- 1.3255548477172852 seconds for one epoch ---
--- 0.2932298183441162 seconds for one epoch ---
--- 1.3220608234405518 seconds for one epoch ---
--- 0.2965104579925537 seconds for one epoch ---
--- 1.3284311294555664 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.9531362 ]
 [-0.70292485]
 [-0.7200621 ]
 [-0.        ]
 [-0.        ]
 [-0.65729433]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.047151  ]
 [ 0.        ]]
--- 0.29309606552124023 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2734.6552734375, (1193.7694, 1.2727696, 1538.4429, 1.1700516)
   validation loss 1119.6671142578125, (875.79144, 0.308785, 242.3968, 1.1700516)
decoder loss ratio: 33929.680938, decoder SINDy loss  ratio: 0.523248
--- 0.25104761123657227 seconds for one epoch ---
--- 0.30167222023010254 seconds for one epoch ---
--- 1.315981149673462 seconds for one epoch ---
--- 0.2953968048095703 seconds for one epoch ---
--- 1.2969143390655518 seconds for one epoch ---
--- 0.2665400505065918 seconds for one epoch ---
--- 1.3467800617218018 seconds for one epoch ---
--- 0.31297850608825684 seconds for one epoch ---
--- 1.3173739910125732 seconds for one epoch ---
--- 0.5537059307098389 seconds for one epoch ---
--- 1.3318030834197998 seconds for one epoch ---
--- 0.30606675148010254 seconds for one epoch ---
--- 1.3217308521270752 seconds for one epoch ---
--- 0.30704474449157715 seconds for one epoch ---
--- 1.3316023349761963 seconds for one epoch ---
--- 0.3040437698364258 seconds for one epoch ---
--- 1.3309414386749268 seconds for one epoch ---
--- 0.3008406162261963 seconds for one epoch ---
--- 1.325230360031128 seconds for one epoch ---
--- 0.2805490493774414 seconds for one epoch ---
--- 1.3456084728240967 seconds for one epoch ---
--- 0.310779333114624 seconds for one epoch ---
--- 1.3923792839050293 seconds for one epoch ---
--- 0.3106653690338135 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-2.974647  ]
 [-0.69913304]
 [-0.71402776]
 [ 0.        ]
 [-0.        ]
 [-0.6561558 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0610685 ]
 [-0.        ]]
--- 0.26883912086486816 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3331.179931640625, (823.4762, 3.5634093, 2502.9702, 1.1702516)
   validation loss 841.9263305664062, (584.53644, 0.3500685, 255.86958, 1.1702516)
decoder loss ratio: 22645.956408, decoder SINDy loss  ratio: 0.552330
--- 0.29408693313598633 seconds for one epoch ---
--- 1.316577672958374 seconds for one epoch ---
--- 0.3004426956176758 seconds for one epoch ---
--- 1.2999863624572754 seconds for one epoch ---
--- 0.2668137550354004 seconds for one epoch ---
--- 1.3159351348876953 seconds for one epoch ---
--- 0.29428553581237793 seconds for one epoch ---
--- 1.352067232131958 seconds for one epoch ---
--- 0.31936049461364746 seconds for one epoch ---
--- 1.3324449062347412 seconds for one epoch ---
--- 0.29711174964904785 seconds for one epoch ---
--- 1.3686614036560059 seconds for one epoch ---
--- 0.28989219665527344 seconds for one epoch ---
--- 1.3431334495544434 seconds for one epoch ---
--- 0.30292749404907227 seconds for one epoch ---
--- 1.333824634552002 seconds for one epoch ---
--- 0.3008739948272705 seconds for one epoch ---
--- 1.353480339050293 seconds for one epoch ---
--- 0.28817129135131836 seconds for one epoch ---
--- 1.3546545505523682 seconds for one epoch ---
--- 0.2984640598297119 seconds for one epoch ---
--- 1.3317115306854248 seconds for one epoch ---
--- 0.30247926712036133 seconds for one epoch ---
--- 1.3338866233825684 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.0221725 ]
 [-0.7160337 ]
 [-0.71459824]
 [ 0.        ]
 [-0.        ]
 [-0.6618592 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.116116  ]
 [-0.        ]]
--- 0.2814469337463379 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3213.865966796875, (1794.3215, 0.25218785, 1418.1216, 1.1707416)
   validation loss 989.3717651367188, (721.7522, 0.2812385, 266.16763, 1.1707416)
decoder loss ratio: 27961.933139, decoder SINDy loss  ratio: 0.574560
--- 0.25875353813171387 seconds for one epoch ---
--- 0.29380130767822266 seconds for one epoch ---
--- 1.3243305683135986 seconds for one epoch ---
--- 0.2901911735534668 seconds for one epoch ---
--- 1.3194096088409424 seconds for one epoch ---
--- 0.3018679618835449 seconds for one epoch ---
--- 1.3677551746368408 seconds for one epoch ---
--- 0.288189172744751 seconds for one epoch ---
--- 1.3373637199401855 seconds for one epoch ---
--- 0.3007528781890869 seconds for one epoch ---
--- 1.3488340377807617 seconds for one epoch ---
--- 0.2968878746032715 seconds for one epoch ---
--- 1.369147777557373 seconds for one epoch ---
--- 0.29429101943969727 seconds for one epoch ---
--- 1.364896535873413 seconds for one epoch ---
--- 0.2944023609161377 seconds for one epoch ---
--- 1.3507182598114014 seconds for one epoch ---
--- 0.3034980297088623 seconds for one epoch ---
--- 1.3428940773010254 seconds for one epoch ---
--- 0.29355549812316895 seconds for one epoch ---
--- 1.3799288272857666 seconds for one epoch ---
--- 0.2979738712310791 seconds for one epoch ---
--- 1.3812944889068604 seconds for one epoch ---
--- 0.29782724380493164 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.0404372 ]
 [-0.70761395]
 [-0.7187796 ]
 [-0.        ]
 [ 0.        ]
 [-0.6518064 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.140626  ]
 [ 0.        ]]
--- 0.2436356544494629 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2176.503662109375, (1380.5717, 0.60110825, 794.16003, 1.1709943)
   validation loss 854.9774169921875, (595.4247, 0.23424506, 258.1475, 1.1709943)
decoder loss ratio: 23067.785907, decoder SINDy loss  ratio: 0.557248
--- 0.28276753425598145 seconds for one epoch ---
--- 1.3475172519683838 seconds for one epoch ---
--- 0.29285120964050293 seconds for one epoch ---
--- 1.3337087631225586 seconds for one epoch ---
--- 0.2949180603027344 seconds for one epoch ---
--- 1.3206665515899658 seconds for one epoch ---
--- 0.2905111312866211 seconds for one epoch ---
--- 1.36445951461792 seconds for one epoch ---
--- 0.2924013137817383 seconds for one epoch ---
--- 1.3713798522949219 seconds for one epoch ---
--- 0.3004610538482666 seconds for one epoch ---
--- 1.3600499629974365 seconds for one epoch ---
--- 0.3079812526702881 seconds for one epoch ---
--- 1.363623857498169 seconds for one epoch ---
--- 0.31209421157836914 seconds for one epoch ---
--- 1.3631165027618408 seconds for one epoch ---
--- 0.32372593879699707 seconds for one epoch ---
--- 1.3927288055419922 seconds for one epoch ---
--- 0.3139932155609131 seconds for one epoch ---
--- 1.3852732181549072 seconds for one epoch ---
--- 0.30604004859924316 seconds for one epoch ---
--- 1.4018962383270264 seconds for one epoch ---
--- 0.320845365524292 seconds for one epoch ---
--- 1.3958396911621094 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.0640693 ]
 [-0.71676284]
 [-0.7045925 ]
 [-0.        ]
 [-0.        ]
 [-0.65065664]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.161444  ]
 [ 0.        ]]
--- 0.2877061367034912 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2599.990478515625, (1210.6929, 1.6384271, 1386.488, 1.1712269)
   validation loss 755.2705078125, (494.85873, 0.2838424, 258.95673, 1.1712269)
decoder loss ratio: 19171.686473, decoder SINDy loss  ratio: 0.558995
--- 0.25369787216186523 seconds for one epoch ---
--- 0.3026413917541504 seconds for one epoch ---
--- 1.3794996738433838 seconds for one epoch ---
--- 0.2981541156768799 seconds for one epoch ---
--- 1.338942050933838 seconds for one epoch ---
--- 0.3018195629119873 seconds for one epoch ---
--- 1.3585326671600342 seconds for one epoch ---
--- 0.2999448776245117 seconds for one epoch ---
--- 1.3828318119049072 seconds for one epoch ---
--- 0.31488656997680664 seconds for one epoch ---
--- 1.4075665473937988 seconds for one epoch ---
--- 0.30322813987731934 seconds for one epoch ---
--- 1.4024755954742432 seconds for one epoch ---
--- 0.31754612922668457 seconds for one epoch ---
--- 1.4031050205230713 seconds for one epoch ---
--- 0.31708240509033203 seconds for one epoch ---
--- 1.4139635562896729 seconds for one epoch ---
--- 0.29951953887939453 seconds for one epoch ---
--- 1.3982510566711426 seconds for one epoch ---
--- 0.31029295921325684 seconds for one epoch ---
--- 1.3962476253509521 seconds for one epoch ---
--- 0.3196299076080322 seconds for one epoch ---
--- 1.4017114639282227 seconds for one epoch ---
--- 0.33726000785827637 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.0989528 ]
 [-0.73659223]
 [-0.70777893]
 [ 0.        ]
 [ 0.        ]
 [-0.6548481 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.194962  ]
 [-0.        ]]
--- 0.262209415435791 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2098.626708984375, (990.89886, 1.5107516, 1105.0454, 1.1716129)
   validation loss 1402.5523681640625, (1091.7826, 0.17060184, 309.42746, 1.1716129)
decoder loss ratio: 42297.553062, decoder SINDy loss  ratio: 0.667943
--- 0.2995767593383789 seconds for one epoch ---
--- 1.3788952827453613 seconds for one epoch ---
--- 0.2986142635345459 seconds for one epoch ---
--- 1.3210761547088623 seconds for one epoch ---
--- 0.3008852005004883 seconds for one epoch ---
--- 1.3435916900634766 seconds for one epoch ---
--- 0.288224458694458 seconds for one epoch ---
--- 1.3728983402252197 seconds for one epoch ---
--- 0.2934105396270752 seconds for one epoch ---
--- 1.394810438156128 seconds for one epoch ---
--- 0.27999448776245117 seconds for one epoch ---
--- 1.4090569019317627 seconds for one epoch ---
--- 0.30673861503601074 seconds for one epoch ---
--- 1.3908624649047852 seconds for one epoch ---
--- 0.3055870532989502 seconds for one epoch ---
--- 1.408358097076416 seconds for one epoch ---
--- 0.29993629455566406 seconds for one epoch ---
--- 1.3912100791931152 seconds for one epoch ---
--- 0.28377199172973633 seconds for one epoch ---
--- 1.3919734954833984 seconds for one epoch ---
--- 0.295609712600708 seconds for one epoch ---
--- 1.3811354637145996 seconds for one epoch ---
--- 0.2904655933380127 seconds for one epoch ---
--- 1.4026410579681396 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.1342545 ]
 [-0.7187346 ]
 [-0.69471747]
 [ 0.        ]
 [ 0.        ]
 [-0.66065437]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.2261844 ]
 [-0.        ]]
--- 0.2843961715698242 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2763.72314453125, (1707.5099, 1.8410654, 1053.2004, 1.1719216)
   validation loss 782.7356567382812, (532.3924, 0.19026138, 248.98108, 1.1719216)
decoder loss ratio: 20625.805657, decoder SINDy loss  ratio: 0.537461
--- 0.2684178352355957 seconds for one epoch ---
--- 0.2964167594909668 seconds for one epoch ---
--- 1.4349830150604248 seconds for one epoch ---
--- 0.3010389804840088 seconds for one epoch ---
--- 1.3772778511047363 seconds for one epoch ---
--- 0.2816777229309082 seconds for one epoch ---
--- 1.3737494945526123 seconds for one epoch ---
--- 0.2905154228210449 seconds for one epoch ---
--- 1.4003252983093262 seconds for one epoch ---
--- 0.31371235847473145 seconds for one epoch ---
--- 1.4055335521697998 seconds for one epoch ---
--- 0.2930617332458496 seconds for one epoch ---
--- 1.3890960216522217 seconds for one epoch ---
--- 0.29996371269226074 seconds for one epoch ---
--- 1.4333782196044922 seconds for one epoch ---
--- 0.29671573638916016 seconds for one epoch ---
--- 1.3878796100616455 seconds for one epoch ---
--- 0.30881237983703613 seconds for one epoch ---
--- 1.3947770595550537 seconds for one epoch ---
--- 0.2941603660583496 seconds for one epoch ---
--- 1.398728370666504 seconds for one epoch ---
--- 0.3005545139312744 seconds for one epoch ---
--- 1.4014415740966797 seconds for one epoch ---
--- 0.2967827320098877 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.146999 ]
 [-0.7199721]
 [-0.695261 ]
 [-0.       ]
 [-0.       ]
 [-0.6472335]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.239505 ]
 [ 0.       ]]
--- 0.2534668445587158 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3643.817626953125, (1225.3806, 2.7501233, 2414.5146, 1.1720538)
   validation loss 794.5096435546875, (558.56476, 0.1683963, 234.60445, 1.1720538)
decoder loss ratio: 21639.768448, decoder SINDy loss  ratio: 0.506427
--- 0.30566883087158203 seconds for one epoch ---
--- 1.444375991821289 seconds for one epoch ---
--- 0.2951805591583252 seconds for one epoch ---
--- 1.368593454360962 seconds for one epoch ---
--- 0.2733032703399658 seconds for one epoch ---
--- 1.3886868953704834 seconds for one epoch ---
--- 0.3070361614227295 seconds for one epoch ---
--- 1.422929048538208 seconds for one epoch ---
--- 0.2948274612426758 seconds for one epoch ---
--- 1.4143741130828857 seconds for one epoch ---
--- 0.30985498428344727 seconds for one epoch ---
--- 1.3933968544006348 seconds for one epoch ---
--- 0.2951183319091797 seconds for one epoch ---
--- 1.3839836120605469 seconds for one epoch ---
--- 0.29540276527404785 seconds for one epoch ---
--- 1.3950095176696777 seconds for one epoch ---
--- 0.3008267879486084 seconds for one epoch ---
--- 1.3880424499511719 seconds for one epoch ---
--- 0.3073701858520508 seconds for one epoch ---
--- 1.4277844429016113 seconds for one epoch ---
--- 0.30092573165893555 seconds for one epoch ---
--- 1.4253294467926025 seconds for one epoch ---
--- 0.30248379707336426 seconds for one epoch ---
--- 1.419632911682129 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.1719286 ]
 [-0.7532787 ]
 [-0.67042494]
 [-0.        ]
 [ 0.        ]
 [-0.64572614]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.2615256 ]
 [ 0.        ]]
--- 0.30492496490478516 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3108.91015625, (1581.7283, 3.2657862, 1522.7438, 1.1723359)
   validation loss 764.0780029296875, (532.91974, 0.24218656, 229.74374, 1.1723359)
decoder loss ratio: 20646.235869, decoder SINDy loss  ratio: 0.495934
--- 0.2594029903411865 seconds for one epoch ---
--- 0.30349302291870117 seconds for one epoch ---
--- 1.4496204853057861 seconds for one epoch ---
--- 0.29381418228149414 seconds for one epoch ---
--- 1.3998594284057617 seconds for one epoch ---
--- 0.2927970886230469 seconds for one epoch ---
--- 1.4066517353057861 seconds for one epoch ---
--- 0.28320860862731934 seconds for one epoch ---
--- 1.413451910018921 seconds for one epoch ---
--- 0.2878127098083496 seconds for one epoch ---
--- 1.405083179473877 seconds for one epoch ---
--- 0.2958860397338867 seconds for one epoch ---
--- 1.3966035842895508 seconds for one epoch ---
--- 0.29256153106689453 seconds for one epoch ---
--- 1.4053153991699219 seconds for one epoch ---
--- 0.29496240615844727 seconds for one epoch ---
--- 1.4065616130828857 seconds for one epoch ---
--- 0.3005690574645996 seconds for one epoch ---
--- 1.4119508266448975 seconds for one epoch ---
--- 0.29268527030944824 seconds for one epoch ---
--- 1.427839756011963 seconds for one epoch ---
--- 0.2932002544403076 seconds for one epoch ---
--- 1.4291045665740967 seconds for one epoch ---
--- 0.29877305030822754 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.1884308 ]
 [-0.7512014 ]
 [-0.67369694]
 [ 0.        ]
 [-0.        ]
 [-0.6385132 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.27515   ]
 [-0.        ]]
--- 0.26270484924316406 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3832.6015625, (1680.9054, 3.8841214, 2146.6396, 1.1724514)
   validation loss 991.9927368164062, (726.46674, 0.34230688, 264.01132, 1.1724514)
decoder loss ratio: 28144.582548, decoder SINDy loss  ratio: 0.569906
--- 0.29571533203125 seconds for one epoch ---
--- 1.4556348323822021 seconds for one epoch ---
--- 0.309023380279541 seconds for one epoch ---
--- 1.4029273986816406 seconds for one epoch ---
--- 0.30939507484436035 seconds for one epoch ---
--- 1.4019498825073242 seconds for one epoch ---
--- 0.3063373565673828 seconds for one epoch ---
--- 1.4385793209075928 seconds for one epoch ---
--- 0.2935919761657715 seconds for one epoch ---
--- 1.4599428176879883 seconds for one epoch ---
--- 0.30855321884155273 seconds for one epoch ---
--- 1.4570295810699463 seconds for one epoch ---
--- 0.30455470085144043 seconds for one epoch ---
--- 1.4270670413970947 seconds for one epoch ---
--- 0.30069780349731445 seconds for one epoch ---
--- 1.435441017150879 seconds for one epoch ---
--- 0.2982614040374756 seconds for one epoch ---
--- 1.4517822265625 seconds for one epoch ---
--- 0.29668641090393066 seconds for one epoch ---
--- 1.4790804386138916 seconds for one epoch ---
--- 0.27339649200439453 seconds for one epoch ---
--- 1.4045734405517578 seconds for one epoch ---
--- 0.2839698791503906 seconds for one epoch ---
--- 1.4300575256347656 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.2062294 ]
 [-0.71068054]
 [-0.6660315 ]
 [ 0.        ]
 [-0.        ]
 [-0.6307307 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.2958803 ]
 [-0.        ]]
--- 0.2984793186187744 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1711.63916015625, (897.6102, 0.36345136, 812.49286, 1.172609)
   validation loss 1044.6473388671875, (773.40106, 0.3115864, 269.76205, 1.172609)
decoder loss ratio: 29962.899826, decoder SINDy loss  ratio: 0.582319
THRESHOLDING: 5 active coefficients
--- 1.4264254570007324 seconds for one epoch ---
--- 0.29033613204956055 seconds for one epoch ---
--- 1.4566650390625 seconds for one epoch ---
--- 0.2940785884857178 seconds for one epoch ---
--- 1.411510705947876 seconds for one epoch ---
--- 0.29566168785095215 seconds for one epoch ---
--- 1.399470329284668 seconds for one epoch ---
--- 0.28612351417541504 seconds for one epoch ---
--- 1.4144864082336426 seconds for one epoch ---
--- 0.2912328243255615 seconds for one epoch ---
--- 1.4467494487762451 seconds for one epoch ---
--- 0.2933809757232666 seconds for one epoch ---
--- 1.4413671493530273 seconds for one epoch ---
--- 0.2987339496612549 seconds for one epoch ---
--- 1.438513994216919 seconds for one epoch ---
--- 0.2935492992401123 seconds for one epoch ---
--- 1.4400365352630615 seconds for one epoch ---
--- 0.30137038230895996 seconds for one epoch ---
--- 1.4442172050476074 seconds for one epoch ---
--- 0.28703904151916504 seconds for one epoch ---
--- 1.4474079608917236 seconds for one epoch ---
--- 0.2789449691772461 seconds for one epoch ---
--- 1.4621069431304932 seconds for one epoch ---
--- 0.2895374298095703 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.2327473 ]
 [-0.71868074]
 [-0.67550987]
 [-0.        ]
 [-0.        ]
 [-0.6259957 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.332352  ]
 [ 0.        ]]
--- 0.2531886100769043 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2701.89599609375, (1621.1818, 2.155058, 1077.3862, 1.172969)
   validation loss 1234.845947265625, (997.29626, 0.33188665, 236.04475, 1.172969)
decoder loss ratio: 38636.988675, decoder SINDy loss  ratio: 0.509536
--- 0.30077242851257324 seconds for one epoch ---
--- 1.4590675830841064 seconds for one epoch ---
--- 0.3116941452026367 seconds for one epoch ---
--- 1.4214251041412354 seconds for one epoch ---
--- 0.289076566696167 seconds for one epoch ---
--- 1.4079780578613281 seconds for one epoch ---
--- 0.29437828063964844 seconds for one epoch ---
--- 1.4526751041412354 seconds for one epoch ---
--- 0.2967696189880371 seconds for one epoch ---
--- 1.4588215351104736 seconds for one epoch ---
--- 0.3003103733062744 seconds for one epoch ---
--- 1.4658212661743164 seconds for one epoch ---
--- 0.2971646785736084 seconds for one epoch ---
--- 1.4610016345977783 seconds for one epoch ---
--- 0.29338693618774414 seconds for one epoch ---
--- 1.4487149715423584 seconds for one epoch ---
--- 0.30895066261291504 seconds for one epoch ---
--- 1.4710347652435303 seconds for one epoch ---
--- 0.2969508171081543 seconds for one epoch ---
--- 1.4957563877105713 seconds for one epoch ---
--- 0.2961082458496094 seconds for one epoch ---
--- 1.4771206378936768 seconds for one epoch ---
--- 0.28547024726867676 seconds for one epoch ---
--- 1.4755542278289795 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.2592514 ]
 [-0.70390576]
 [-0.6745295 ]
 [-0.        ]
 [ 0.        ]
 [-0.63423187]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.351398  ]
 [ 0.        ]]
--- 0.288449764251709 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2724.20751953125, (1090.1381, 12.304673, 1620.5914, 1.1732354)
   validation loss 1303.2237548828125, (1064.5269, 0.3263349, 237.19733, 1.1732354)
decoder loss ratio: 41241.618481, decoder SINDy loss  ratio: 0.512024
--- 0.2638981342315674 seconds for one epoch ---
--- 0.2917966842651367 seconds for one epoch ---
--- 1.4864230155944824 seconds for one epoch ---
--- 0.3069925308227539 seconds for one epoch ---
--- 1.4461214542388916 seconds for one epoch ---
--- 0.2991149425506592 seconds for one epoch ---
--- 1.4384288787841797 seconds for one epoch ---
--- 0.29535508155822754 seconds for one epoch ---
--- 1.4611504077911377 seconds for one epoch ---
--- 0.2999250888824463 seconds for one epoch ---
--- 1.5107626914978027 seconds for one epoch ---
--- 0.2824232578277588 seconds for one epoch ---
--- 1.4744212627410889 seconds for one epoch ---
--- 0.3052022457122803 seconds for one epoch ---
--- 1.4819378852844238 seconds for one epoch ---
--- 0.3086225986480713 seconds for one epoch ---
--- 1.492652416229248 seconds for one epoch ---
--- 0.3091239929199219 seconds for one epoch ---
--- 1.5212860107421875 seconds for one epoch ---
--- 0.3031296730041504 seconds for one epoch ---
--- 1.4828917980194092 seconds for one epoch ---
--- 0.2959177494049072 seconds for one epoch ---
--- 1.4993727207183838 seconds for one epoch ---
--- 0.2878546714782715 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.2778435 ]
 [-0.7155999 ]
 [-0.6788431 ]
 [ 0.        ]
 [-0.        ]
 [-0.63017964]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.3670077 ]
 [-0.        ]]
--- 0.26285290718078613 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4849.5078125, (965.3329, 3.3969066, 3879.6047, 1.1733989)
   validation loss 829.0897827148438, (587.5998, 0.35498735, 239.96158, 1.1733989)
decoder loss ratio: 22764.636079, decoder SINDy loss  ratio: 0.517991
--- 0.3143117427825928 seconds for one epoch ---
--- 1.4797720909118652 seconds for one epoch ---
--- 0.3009920120239258 seconds for one epoch ---
--- 1.5089142322540283 seconds for one epoch ---
--- 0.28589797019958496 seconds for one epoch ---
--- 1.4546384811401367 seconds for one epoch ---
--- 0.28902196884155273 seconds for one epoch ---
--- 1.441420555114746 seconds for one epoch ---
--- 0.31007814407348633 seconds for one epoch ---
--- 1.5042126178741455 seconds for one epoch ---
--- 0.3026885986328125 seconds for one epoch ---
--- 1.5045323371887207 seconds for one epoch ---
--- 0.2873518466949463 seconds for one epoch ---
--- 1.4847333431243896 seconds for one epoch ---
--- 0.29483866691589355 seconds for one epoch ---
--- 1.4763329029083252 seconds for one epoch ---
--- 0.30820631980895996 seconds for one epoch ---
--- 1.4727435111999512 seconds for one epoch ---
--- 0.2974834442138672 seconds for one epoch ---
--- 1.4776177406311035 seconds for one epoch ---
--- 0.2917795181274414 seconds for one epoch ---
--- 1.4755513668060303 seconds for one epoch ---
--- 0.2930748462677002 seconds for one epoch ---
--- 1.4615349769592285 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.2847724]
 [-0.7177617]
 [-0.6621771]
 [ 0.       ]
 [ 0.       ]
 [-0.6252946]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.368996 ]
 [-0.       ]]
--- 0.30187392234802246 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2220.519775390625, (1171.6415, 3.6606581, 1044.0443, 1.1734378)
   validation loss 791.5270385742188, (557.66504, 0.3484047, 232.34016, 1.1734378)
decoder loss ratio: 21604.911762, decoder SINDy loss  ratio: 0.501539
--- 0.26482295989990234 seconds for one epoch ---
--- 0.3016355037689209 seconds for one epoch ---
--- 1.495861530303955 seconds for one epoch ---
--- 0.3007490634918213 seconds for one epoch ---
--- 1.519524097442627 seconds for one epoch ---
--- 0.2994410991668701 seconds for one epoch ---
--- 1.4375669956207275 seconds for one epoch ---
--- 0.29410243034362793 seconds for one epoch ---
--- 1.4034955501556396 seconds for one epoch ---
--- 0.2754528522491455 seconds for one epoch ---
--- 1.4529716968536377 seconds for one epoch ---
--- 0.28560566902160645 seconds for one epoch ---
--- 1.5006356239318848 seconds for one epoch ---
--- 0.31871771812438965 seconds for one epoch ---
--- 1.5271105766296387 seconds for one epoch ---
--- 0.3267490863800049 seconds for one epoch ---
--- 1.537003517150879 seconds for one epoch ---
--- 0.32795143127441406 seconds for one epoch ---
--- 1.5068559646606445 seconds for one epoch ---
--- 0.33066654205322266 seconds for one epoch ---
--- 1.511225700378418 seconds for one epoch ---
--- 0.34020376205444336 seconds for one epoch ---
--- 1.5256562232971191 seconds for one epoch ---
--- 0.33786535263061523 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.3023226]
 [-0.7274111]
 [-0.651181 ]
 [-0.       ]
 [ 0.       ]
 [-0.6223356]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.3880043]
 [ 0.       ]]
--- 0.2560703754425049 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2127.4755859375, (1165.9235, 2.529149, 957.84937, 1.173681)
   validation loss 1111.5595703125, (857.9033, 0.41491532, 252.06767, 1.173681)
decoder loss ratio: 33236.664015, decoder SINDy loss  ratio: 0.544124
--- 0.2940835952758789 seconds for one epoch ---
--- 1.5039427280426025 seconds for one epoch ---
--- 0.29497313499450684 seconds for one epoch ---
--- 1.5367679595947266 seconds for one epoch ---
--- 0.30539751052856445 seconds for one epoch ---
--- 1.491981029510498 seconds for one epoch ---
--- 0.2905619144439697 seconds for one epoch ---
--- 1.493598222732544 seconds for one epoch ---
--- 0.3011190891265869 seconds for one epoch ---
--- 1.465174913406372 seconds for one epoch ---
--- 0.29910778999328613 seconds for one epoch ---
--- 1.5115764141082764 seconds for one epoch ---
--- 0.32146263122558594 seconds for one epoch ---
--- 1.528707504272461 seconds for one epoch ---
--- 0.32826828956604004 seconds for one epoch ---
--- 1.573932409286499 seconds for one epoch ---
--- 0.3348665237426758 seconds for one epoch ---
--- 1.5281648635864258 seconds for one epoch ---
--- 0.33359575271606445 seconds for one epoch ---
--- 1.5076391696929932 seconds for one epoch ---
--- 0.33849644660949707 seconds for one epoch ---
--- 1.5356221199035645 seconds for one epoch ---
--- 0.3155548572540283 seconds for one epoch ---
--- 1.5462806224822998 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.313118  ]
 [-0.7379037 ]
 [-0.6516748 ]
 [-0.        ]
 [-0.        ]
 [-0.62185407]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.3905168 ]
 [ 0.        ]]
--- 0.2900102138519287 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3409.586181640625, (1765.9855, 2.3223162, 1640.1046, 1.173746)
   validation loss 728.7570190429688, (486.2841, 0.2675033, 241.03168, 1.173746)
decoder loss ratio: 18839.489801, decoder SINDy loss  ratio: 0.520301
--- 0.2531397342681885 seconds for one epoch ---
--- 0.30441761016845703 seconds for one epoch ---
--- 1.4932301044464111 seconds for one epoch ---
--- 0.31238627433776855 seconds for one epoch ---
--- 1.5407612323760986 seconds for one epoch ---
--- 0.30884480476379395 seconds for one epoch ---
--- 1.5296244621276855 seconds for one epoch ---
--- 0.2928597927093506 seconds for one epoch ---
--- 1.434983491897583 seconds for one epoch ---
--- 0.29412245750427246 seconds for one epoch ---
--- 1.4811053276062012 seconds for one epoch ---
--- 0.2919185161590576 seconds for one epoch ---
--- 1.5115439891815186 seconds for one epoch ---
--- 0.29894018173217773 seconds for one epoch ---
--- 1.5060832500457764 seconds for one epoch ---
--- 0.2967336177825928 seconds for one epoch ---
--- 1.5334312915802002 seconds for one epoch ---
--- 0.30640459060668945 seconds for one epoch ---
--- 1.5078718662261963 seconds for one epoch ---
--- 0.29991841316223145 seconds for one epoch ---
--- 1.5509510040283203 seconds for one epoch ---
--- 0.30500054359436035 seconds for one epoch ---
--- 1.5428643226623535 seconds for one epoch ---
--- 0.29782938957214355 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.3334188 ]
 [-0.73859096]
 [-0.6490119 ]
 [ 0.        ]
 [ 0.        ]
 [-0.62509906]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.401331  ]
 [-0.        ]]
--- 0.2579021453857422 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1786.989990234375, (905.3921, 3.4024222, 877.02155, 1.1738974)
   validation loss 953.8386840820312, (701.3239, 0.33439094, 251.00647, 1.1738974)
decoder loss ratio: 27170.505964, decoder SINDy loss  ratio: 0.541833
--- 0.30298495292663574 seconds for one epoch ---
--- 1.5497708320617676 seconds for one epoch ---
--- 0.29561328887939453 seconds for one epoch ---
--- 1.539698839187622 seconds for one epoch ---
--- 0.3032076358795166 seconds for one epoch ---
--- 1.568697452545166 seconds for one epoch ---
--- 0.29157447814941406 seconds for one epoch ---
--- 1.5017991065979004 seconds for one epoch ---
--- 0.3001739978790283 seconds for one epoch ---
--- 1.5076837539672852 seconds for one epoch ---
--- 0.2899508476257324 seconds for one epoch ---
--- 1.546130895614624 seconds for one epoch ---
--- 0.2887740135192871 seconds for one epoch ---
--- 1.5538179874420166 seconds for one epoch ---
--- 0.3072972297668457 seconds for one epoch ---
--- 1.5606324672698975 seconds for one epoch ---
--- 0.31505727767944336 seconds for one epoch ---
--- 1.5552189350128174 seconds for one epoch ---
--- 0.2953672409057617 seconds for one epoch ---
--- 1.5424249172210693 seconds for one epoch ---
--- 0.3033599853515625 seconds for one epoch ---
--- 1.5429503917694092 seconds for one epoch ---
--- 0.27780842781066895 seconds for one epoch ---
--- 1.5068774223327637 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.3447669 ]
 [-0.75551665]
 [-0.65359807]
 [ 0.        ]
 [-0.        ]
 [-0.6160433 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.4147096 ]
 [-0.        ]]
--- 0.3040883541107178 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5165.2138671875, (1919.0797, 1.5748129, 3243.3857, 1.1740493)
   validation loss 1184.432861328125, (931.4263, 0.44071394, 251.39177, 1.1740493)
decoder loss ratio: 36085.070709, decoder SINDy loss  ratio: 0.542664
--- 0.2713758945465088 seconds for one epoch ---
--- 0.3204777240753174 seconds for one epoch ---
--- 1.5405025482177734 seconds for one epoch ---
--- 0.29921793937683105 seconds for one epoch ---
--- 1.5525639057159424 seconds for one epoch ---
--- 0.3061819076538086 seconds for one epoch ---
--- 1.5474977493286133 seconds for one epoch ---
--- 0.304398775100708 seconds for one epoch ---
--- 1.5129711627960205 seconds for one epoch ---
--- 0.29843974113464355 seconds for one epoch ---
--- 1.5062522888183594 seconds for one epoch ---
--- 0.29871320724487305 seconds for one epoch ---
--- 1.5162582397460938 seconds for one epoch ---
--- 0.29358744621276855 seconds for one epoch ---
--- 1.550260305404663 seconds for one epoch ---
--- 0.2838778495788574 seconds for one epoch ---
--- 1.5275304317474365 seconds for one epoch ---
--- 0.28733205795288086 seconds for one epoch ---
--- 1.540466070175171 seconds for one epoch ---
--- 0.31010985374450684 seconds for one epoch ---
--- 1.5218381881713867 seconds for one epoch ---
--- 0.29493236541748047 seconds for one epoch ---
--- 1.5495500564575195 seconds for one epoch ---
--- 0.2990720272064209 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.3727517 ]
 [-0.76207364]
 [-0.65018016]
 [-0.        ]
 [-0.        ]
 [-0.62122285]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.4403505 ]
 [ 0.        ]]
--- 0.2630589008331299 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2537.4140625, (1162.6282, 1.7773824, 1371.8341, 1.1744082)
   validation loss 684.9437255859375, (447.1019, 0.3698112, 236.29755, 1.1744082)
decoder loss ratio: 17321.503739, decoder SINDy loss  ratio: 0.510081
--- 0.29564619064331055 seconds for one epoch ---
--- 1.5143649578094482 seconds for one epoch ---
--- 0.298905611038208 seconds for one epoch ---
--- 1.5382773876190186 seconds for one epoch ---
--- 0.29834508895874023 seconds for one epoch ---
--- 1.552687168121338 seconds for one epoch ---
--- 0.30590367317199707 seconds for one epoch ---
--- 1.5188541412353516 seconds for one epoch ---
--- 0.28640127182006836 seconds for one epoch ---
--- 1.5070288181304932 seconds for one epoch ---
--- 0.29593682289123535 seconds for one epoch ---
--- 1.4929156303405762 seconds for one epoch ---
--- 0.283571720123291 seconds for one epoch ---
--- 1.566396951675415 seconds for one epoch ---
--- 0.30954670906066895 seconds for one epoch ---
--- 1.5543713569641113 seconds for one epoch ---
--- 0.29497456550598145 seconds for one epoch ---
--- 1.5740127563476562 seconds for one epoch ---
--- 0.313920259475708 seconds for one epoch ---
--- 1.5792975425720215 seconds for one epoch ---
--- 0.30193471908569336 seconds for one epoch ---
--- 1.5623729228973389 seconds for one epoch ---
--- 0.3272709846496582 seconds for one epoch ---
--- 1.5711123943328857 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.389489 ]
 [-0.7698876]
 [-0.651444 ]
 [-0.       ]
 [-0.       ]
 [-0.6198043]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.456801 ]
 [ 0.       ]]
--- 0.28850769996643066 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2323.86767578125, (820.51636, 1.0539725, 1501.1228, 1.1745437)
   validation loss 826.549072265625, (598.38275, 0.33470985, 226.65703, 1.1745437)
decoder loss ratio: 23182.386630, decoder SINDy loss  ratio: 0.489271
--- 0.2633202075958252 seconds for one epoch ---
--- 0.30068421363830566 seconds for one epoch ---
--- 1.5785455703735352 seconds for one epoch ---
--- 0.30349016189575195 seconds for one epoch ---
--- 1.5619964599609375 seconds for one epoch ---
--- 0.30891895294189453 seconds for one epoch ---
--- 1.5839385986328125 seconds for one epoch ---
--- 0.2960524559020996 seconds for one epoch ---
--- 1.5470998287200928 seconds for one epoch ---
--- 0.30608463287353516 seconds for one epoch ---
--- 1.5512738227844238 seconds for one epoch ---
--- 0.28958630561828613 seconds for one epoch ---
--- 1.550422191619873 seconds for one epoch ---
--- 0.2929191589355469 seconds for one epoch ---
--- 1.5290100574493408 seconds for one epoch ---
--- 0.31989049911499023 seconds for one epoch ---
--- 1.5900788307189941 seconds for one epoch ---
--- 0.3122291564941406 seconds for one epoch ---
--- 1.6013929843902588 seconds for one epoch ---
--- 0.29202985763549805 seconds for one epoch ---
--- 1.5988168716430664 seconds for one epoch ---
--- 0.3120536804199219 seconds for one epoch ---
--- 1.5978302955627441 seconds for one epoch ---
--- 0.29785609245300293 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.4156458 ]
 [-0.76091707]
 [-0.6570357 ]
 [ 0.        ]
 [ 0.        ]
 [-0.6196598 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.487244  ]
 [-0.        ]]
--- 0.25858092308044434 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2921.1455078125, (1715.3073, 0.75091493, 1203.9127, 1.17491)
   validation loss 689.318359375, (459.19888, 0.40356117, 228.54095, 1.17491)
decoder loss ratio: 17790.161934, decoder SINDy loss  ratio: 0.493338
--- 0.2960953712463379 seconds for one epoch ---
--- 1.5867459774017334 seconds for one epoch ---
--- 0.28980302810668945 seconds for one epoch ---
--- 1.5673320293426514 seconds for one epoch ---
--- 0.29555678367614746 seconds for one epoch ---
--- 1.5955491065979004 seconds for one epoch ---
--- 0.29484033584594727 seconds for one epoch ---
--- 1.557481288909912 seconds for one epoch ---
--- 0.2957487106323242 seconds for one epoch ---
--- 1.5524427890777588 seconds for one epoch ---
--- 0.2968466281890869 seconds for one epoch ---
--- 1.5496187210083008 seconds for one epoch ---
--- 0.28000974655151367 seconds for one epoch ---
--- 1.6721556186676025 seconds for one epoch ---
--- 0.29939770698547363 seconds for one epoch ---
--- 1.5487487316131592 seconds for one epoch ---
--- 0.29929542541503906 seconds for one epoch ---
--- 1.5485444068908691 seconds for one epoch ---
--- 0.28922605514526367 seconds for one epoch ---
--- 1.5664591789245605 seconds for one epoch ---
--- 0.29065394401550293 seconds for one epoch ---
--- 1.5828454494476318 seconds for one epoch ---
--- 0.2959003448486328 seconds for one epoch ---
--- 1.5785980224609375 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.4349473 ]
 [-0.74788314]
 [-0.6463841 ]
 [ 0.        ]
 [-0.        ]
 [-0.6261214 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.499926  ]
 [-0.        ]]
--- 0.2970237731933594 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2738.525634765625, (875.67053, 0.2646744, 1861.4154, 1.175085)
   validation loss 1203.3623046875, (950.9236, 0.33595565, 250.92776, 1.175085)
decoder loss ratio: 36840.430519, decoder SINDy loss  ratio: 0.541663
--- 0.2573103904724121 seconds for one epoch ---
--- 0.30098652839660645 seconds for one epoch ---
--- 1.577735424041748 seconds for one epoch ---
--- 0.3019099235534668 seconds for one epoch ---
--- 1.6019725799560547 seconds for one epoch ---
--- 0.29625868797302246 seconds for one epoch ---
--- 1.5904593467712402 seconds for one epoch ---
--- 0.3155059814453125 seconds for one epoch ---
--- 1.6142876148223877 seconds for one epoch ---
--- 0.2965250015258789 seconds for one epoch ---
--- 1.5803070068359375 seconds for one epoch ---
--- 0.29257845878601074 seconds for one epoch ---
--- 1.5494704246520996 seconds for one epoch ---
--- 0.2950584888458252 seconds for one epoch ---
--- 1.5651235580444336 seconds for one epoch ---
--- 0.3011507987976074 seconds for one epoch ---
--- 1.5961048603057861 seconds for one epoch ---
--- 0.30927491188049316 seconds for one epoch ---
--- 1.5982575416564941 seconds for one epoch ---
--- 0.2844235897064209 seconds for one epoch ---
--- 1.5768356323242188 seconds for one epoch ---
--- 0.2973337173461914 seconds for one epoch ---
--- 1.5791447162628174 seconds for one epoch ---
--- 0.2829420566558838 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.4480846 ]
 [-0.76433504]
 [-0.6446793 ]
 [-0.        ]
 [ 0.        ]
 [-0.6222934 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.510245  ]
 [ 0.        ]]
--- 0.24952268600463867 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2197.8564453125, (1104.2025, 2.1524773, 1090.3262, 1.175202)
   validation loss 747.3545532226562, (512.88007, 0.26877895, 233.03049, 1.175202)
decoder loss ratio: 19869.864153, decoder SINDy loss  ratio: 0.503029
--- 0.2882974147796631 seconds for one epoch ---
--- 1.591400384902954 seconds for one epoch ---
--- 0.31134629249572754 seconds for one epoch ---
--- 1.5990607738494873 seconds for one epoch ---
--- 0.3070857524871826 seconds for one epoch ---
--- 1.588085412979126 seconds for one epoch ---
--- 0.2849700450897217 seconds for one epoch ---
--- 1.61716628074646 seconds for one epoch ---
--- 0.30288171768188477 seconds for one epoch ---
--- 1.5720634460449219 seconds for one epoch ---
--- 0.29730868339538574 seconds for one epoch ---
--- 1.551351547241211 seconds for one epoch ---
--- 0.31551480293273926 seconds for one epoch ---
--- 1.5617499351501465 seconds for one epoch ---
--- 0.29734015464782715 seconds for one epoch ---
--- 1.599649429321289 seconds for one epoch ---
--- 0.2996342182159424 seconds for one epoch ---
--- 1.6003260612487793 seconds for one epoch ---
--- 0.29726719856262207 seconds for one epoch ---
--- 1.589613676071167 seconds for one epoch ---
--- 0.29975390434265137 seconds for one epoch ---
--- 1.600865364074707 seconds for one epoch ---
--- 0.28871703147888184 seconds for one epoch ---
--- 1.605315923690796 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.4617195 ]
 [-0.7571052 ]
 [-0.64649945]
 [-0.        ]
 [ 0.        ]
 [-0.6161264 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.528994  ]
 [ 0.        ]]
--- 0.2977910041809082 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2198.736328125, (1237.422, 2.7943387, 957.34467, 1.1753744)
   validation loss 776.9091186523438, (523.66235, 0.29768535, 251.77371, 1.1753744)
decoder loss ratio: 20287.588693, decoder SINDy loss  ratio: 0.543489
--- 0.26049232482910156 seconds for one epoch ---
--- 0.2950398921966553 seconds for one epoch ---
--- 1.6416542530059814 seconds for one epoch ---
--- 0.3060891628265381 seconds for one epoch ---
--- 1.6168720722198486 seconds for one epoch ---
--- 0.2887897491455078 seconds for one epoch ---
--- 1.6024715900421143 seconds for one epoch ---
--- 0.30269646644592285 seconds for one epoch ---
--- 1.639162540435791 seconds for one epoch ---
--- 0.302748441696167 seconds for one epoch ---
--- 1.5821642875671387 seconds for one epoch ---
--- 0.29838013648986816 seconds for one epoch ---
--- 1.5771372318267822 seconds for one epoch ---
--- 0.2935459613800049 seconds for one epoch ---
--- 1.6029441356658936 seconds for one epoch ---
--- 0.29236817359924316 seconds for one epoch ---
--- 1.625101089477539 seconds for one epoch ---
--- 0.30191993713378906 seconds for one epoch ---
--- 1.6338510513305664 seconds for one epoch ---
--- 0.30302906036376953 seconds for one epoch ---
--- 1.704216718673706 seconds for one epoch ---
--- 0.29653167724609375 seconds for one epoch ---
--- 1.6069815158843994 seconds for one epoch ---
--- 0.29903507232666016 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4741476]
 [-0.7569171]
 [-0.6539585]
 [ 0.       ]
 [-0.       ]
 [-0.608129 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.54075  ]
 [-0.       ]]
--- 0.25238823890686035 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5487.18310546875, (1628.143, 2.6636295, 3855.2007, 1.1755437)
   validation loss 889.46875, (642.7316, 0.30744004, 245.25412, 1.1755437)
decoder loss ratio: 24900.539116, decoder SINDy loss  ratio: 0.529416
--- 0.2856748104095459 seconds for one epoch ---
--- 1.6098644733428955 seconds for one epoch ---
--- 0.3013420104980469 seconds for one epoch ---
--- 1.6401631832122803 seconds for one epoch ---
--- 0.29268503189086914 seconds for one epoch ---
--- 1.6566996574401855 seconds for one epoch ---
--- 0.30382418632507324 seconds for one epoch ---
--- 1.6642820835113525 seconds for one epoch ---
--- 0.28285884857177734 seconds for one epoch ---
--- 1.583531379699707 seconds for one epoch ---
--- 0.29383325576782227 seconds for one epoch ---
--- 1.607163429260254 seconds for one epoch ---
--- 0.30210399627685547 seconds for one epoch ---
--- 1.637596607208252 seconds for one epoch ---
--- 0.286545991897583 seconds for one epoch ---
--- 1.6456687450408936 seconds for one epoch ---
--- 0.30586791038513184 seconds for one epoch ---
--- 1.6692893505096436 seconds for one epoch ---
--- 0.31610918045043945 seconds for one epoch ---
--- 1.6510536670684814 seconds for one epoch ---
--- 0.3126201629638672 seconds for one epoch ---
--- 1.6468193531036377 seconds for one epoch ---
--- 0.30660557746887207 seconds for one epoch ---
--- 1.6566472053527832 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4912617 ]
 [-0.7602201 ]
 [-0.65184027]
 [ 0.        ]
 [ 0.        ]
 [-0.60474277]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.561434  ]
 [-0.        ]]
--- 0.3051142692565918 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2227.051025390625, (1322.428, 0.99323094, 902.45404, 1.1757189)
   validation loss 819.9902954101562, (536.71063, 0.3358438, 281.76813, 1.1757189)
decoder loss ratio: 20793.101667, decoder SINDy loss  ratio: 0.608236
--- 0.25926804542541504 seconds for one epoch ---
--- 0.2951016426086426 seconds for one epoch ---
--- 1.6405303478240967 seconds for one epoch ---
--- 0.2990102767944336 seconds for one epoch ---
--- 1.642425775527954 seconds for one epoch ---
--- 0.30461692810058594 seconds for one epoch ---
--- 1.6712243556976318 seconds for one epoch ---
--- 0.29856157302856445 seconds for one epoch ---
--- 1.6369807720184326 seconds for one epoch ---
--- 0.3026463985443115 seconds for one epoch ---
--- 1.6025564670562744 seconds for one epoch ---
--- 0.3010091781616211 seconds for one epoch ---
--- 1.6282503604888916 seconds for one epoch ---
--- 0.30281949043273926 seconds for one epoch ---
--- 1.635028600692749 seconds for one epoch ---
--- 0.2997257709503174 seconds for one epoch ---
--- 1.6481497287750244 seconds for one epoch ---
--- 0.29294443130493164 seconds for one epoch ---
--- 1.651456594467163 seconds for one epoch ---
--- 0.28080105781555176 seconds for one epoch ---
--- 1.6358470916748047 seconds for one epoch ---
--- 0.29996204376220703 seconds for one epoch ---
--- 1.608199119567871 seconds for one epoch ---
--- 0.2935304641723633 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5063877 ]
 [-0.76327515]
 [-0.64292246]
 [-0.        ]
 [-0.        ]
 [-0.6080598 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.570846  ]
 [ 0.        ]]
--- 0.2641875743865967 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1818.2906494140625, (745.2918, 0.8197076, 1071.0033, 1.1759067)
   validation loss 814.111328125, (556.7741, 0.30919984, 255.85211, 1.1759067)
decoder loss ratio: 21570.395581, decoder SINDy loss  ratio: 0.552293
--- 0.28896188735961914 seconds for one epoch ---
--- 1.6763973236083984 seconds for one epoch ---
--- 0.29433679580688477 seconds for one epoch ---
--- 1.6609547138214111 seconds for one epoch ---
--- 0.2997465133666992 seconds for one epoch ---
--- 1.6676678657531738 seconds for one epoch ---
--- 0.30669069290161133 seconds for one epoch ---
--- 1.664466381072998 seconds for one epoch ---
--- 0.2938516139984131 seconds for one epoch ---
--- 1.6281509399414062 seconds for one epoch ---
--- 0.2902669906616211 seconds for one epoch ---
--- 1.614720106124878 seconds for one epoch ---
--- 0.3001859188079834 seconds for one epoch ---
--- 1.6483478546142578 seconds for one epoch ---
--- 0.29602766036987305 seconds for one epoch ---
--- 1.6808912754058838 seconds for one epoch ---
--- 0.2921867370605469 seconds for one epoch ---
--- 1.679236650466919 seconds for one epoch ---
--- 0.5947508811950684 seconds for one epoch ---
--- 1.655803918838501 seconds for one epoch ---
--- 0.2951841354370117 seconds for one epoch ---
--- 1.6574578285217285 seconds for one epoch ---
--- 0.29914307594299316 seconds for one epoch ---
--- 1.6567838191986084 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5279524]
 [-0.7743448]
 [-0.644189 ]
 [-0.       ]
 [-0.       ]
 [-0.6075512]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.593827 ]
 [ 0.       ]]
--- 0.27569150924682617 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2298.61328125, (874.7643, 4.317851, 1418.3549, 1.1761864)
   validation loss 783.4998168945312, (537.4196, 0.33193886, 244.5721, 1.1761864)
decoder loss ratio: 20820.568952, decoder SINDy loss  ratio: 0.527943
--- 0.2666027545928955 seconds for one epoch ---
--- 0.29964160919189453 seconds for one epoch ---
--- 1.658660650253296 seconds for one epoch ---
--- 0.2969839572906494 seconds for one epoch ---
--- 1.6692650318145752 seconds for one epoch ---
--- 0.2983536720275879 seconds for one epoch ---
--- 1.688061237335205 seconds for one epoch ---
--- 0.30738162994384766 seconds for one epoch ---
--- 1.629211664199829 seconds for one epoch ---
--- 0.30284643173217773 seconds for one epoch ---
--- 1.6352348327636719 seconds for one epoch ---
--- 0.28991198539733887 seconds for one epoch ---
--- 1.6177139282226562 seconds for one epoch ---
--- 0.297635555267334 seconds for one epoch ---
--- 1.682706594467163 seconds for one epoch ---
--- 0.29781198501586914 seconds for one epoch ---
--- 1.6447126865386963 seconds for one epoch ---
--- 0.30150914192199707 seconds for one epoch ---
--- 1.6618890762329102 seconds for one epoch ---
--- 0.29929304122924805 seconds for one epoch ---
--- 1.6471753120422363 seconds for one epoch ---
--- 0.29550743103027344 seconds for one epoch ---
--- 1.656761884689331 seconds for one epoch ---
--- 0.30462169647216797 seconds for one epoch ---
=========================
[[1.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-3.5507903 ]
 [-0.76666546]
 [-0.64006174]
 [ 0.        ]
 [-0.        ]
 [-0.6158723 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.6082706 ]
 [-0.        ]]
--- 0.25638842582702637 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3748.8212890625, (1935.8594, 2.1792502, 1809.6063, 1.1763572)
   validation loss 721.0027465820312, (479.58148, 0.296, 239.94894, 1.1763572)
decoder loss ratio: 18579.819200, decoder SINDy loss  ratio: 0.517964
--- 0.2885117530822754 seconds for one epoch ---
--- 1.687504768371582 seconds for one epoch ---
--- 0.29824328422546387 seconds for one epoch ---
--- 1.6926593780517578 seconds for one epoch ---
--- 0.28269004821777344 seconds for one epoch ---
--- 1.7085926532745361 seconds for one epoch ---
--- 0.30402684211730957 seconds for one epoch ---
--- 1.6578443050384521 seconds for one epoch ---
--- 0.2861511707305908 seconds for one epoch ---
--- 1.644496202468872 seconds for one epoch ---
--- 0.2924351692199707 seconds for one epoch ---
--- 1.6511001586914062 seconds for one epoch ---
--- 0.2923851013183594 seconds for one epoch ---
--- 1.693795919418335 seconds for one epoch ---
--- 0.2937777042388916 seconds for one epoch ---
--- 1.6871414184570312 seconds for one epoch ---
--- 0.29898810386657715 seconds for one epoch ---
--- 1.685593605041504 seconds for one epoch ---
--- 0.2998545169830322 seconds for one epoch ---
--- 1.6960670948028564 seconds for one epoch ---
--- 0.3084437847137451 seconds for one epoch ---
--- 1.667907476425171 seconds for one epoch ---
--- 0.29984545707702637 seconds for one epoch ---
--- 1.6930809020996094 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.549594  ]
 [-0.75330853]
 [-0.6442655 ]
 [ 0.        ]
 [ 0.        ]
 [-0.59903765]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6121645 ]
 [-0.        ]]
--- 0.3022725582122803 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2731.687255859375, (1144.6523, 3.2990773, 1582.5596, 1.1763595)
   validation loss 954.344970703125, (708.253, 0.2785787, 244.63707, 1.1763595)
decoder loss ratio: 27438.950442, decoder SINDy loss  ratio: 0.528084
THRESHOLDING: 5 active coefficients
--- 0.2555067539215088 seconds for one epoch ---
--- 0.2900736331939697 seconds for one epoch ---
--- 1.6623244285583496 seconds for one epoch ---
--- 0.28801727294921875 seconds for one epoch ---
--- 1.6679532527923584 seconds for one epoch ---
--- 0.29763364791870117 seconds for one epoch ---
--- 1.6722183227539062 seconds for one epoch ---
--- 0.29756641387939453 seconds for one epoch ---
--- 1.6440246105194092 seconds for one epoch ---
--- 0.29065799713134766 seconds for one epoch ---
--- 1.6478374004364014 seconds for one epoch ---
--- 0.2894742488861084 seconds for one epoch ---
--- 1.6501634120941162 seconds for one epoch ---
--- 0.2967381477355957 seconds for one epoch ---
--- 1.7619702816009521 seconds for one epoch ---
--- 0.29225802421569824 seconds for one epoch ---
--- 1.706547737121582 seconds for one epoch ---
--- 0.29723381996154785 seconds for one epoch ---
--- 1.7076778411865234 seconds for one epoch ---
--- 0.294811487197876 seconds for one epoch ---
--- 1.6692461967468262 seconds for one epoch ---
--- 0.2838294506072998 seconds for one epoch ---
--- 1.665268898010254 seconds for one epoch ---
--- 0.2946310043334961 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5637653 ]
 [-0.74779916]
 [-0.64438355]
 [-0.        ]
 [-0.        ]
 [-0.59425116]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.620618  ]
 [ 0.        ]]
--- 0.26020216941833496 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3867.250244140625, (1926.5977, 0.51923466, 1938.9567, 1.1764959)
   validation loss 795.7091064453125, (556.10547, 0.3482314, 238.07889, 1.1764959)
decoder loss ratio: 21544.491301, decoder SINDy loss  ratio: 0.513927
--- 0.2878997325897217 seconds for one epoch ---
--- 1.6978414058685303 seconds for one epoch ---
--- 0.30001211166381836 seconds for one epoch ---
--- 1.7083287239074707 seconds for one epoch ---
--- 0.3051924705505371 seconds for one epoch ---
--- 1.7128143310546875 seconds for one epoch ---
--- 0.3104064464569092 seconds for one epoch ---
--- 1.6881210803985596 seconds for one epoch ---
--- 0.29488110542297363 seconds for one epoch ---
--- 1.6784682273864746 seconds for one epoch ---
--- 0.2946181297302246 seconds for one epoch ---
--- 1.6674563884735107 seconds for one epoch ---
--- 0.299471378326416 seconds for one epoch ---
--- 1.661128044128418 seconds for one epoch ---
--- 0.2954590320587158 seconds for one epoch ---
--- 1.6924221515655518 seconds for one epoch ---
--- 0.297544002532959 seconds for one epoch ---
--- 1.7297346591949463 seconds for one epoch ---
--- 0.3133718967437744 seconds for one epoch ---
--- 1.7137727737426758 seconds for one epoch ---
--- 0.3192412853240967 seconds for one epoch ---
--- 1.711829662322998 seconds for one epoch ---
--- 0.33202433586120605 seconds for one epoch ---
--- 1.710521936416626 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5869658 ]
 [-0.7476398 ]
 [-0.63939905]
 [-0.        ]
 [ 0.        ]
 [-0.6019164 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.6404233 ]
 [ 0.        ]]
--- 0.2977917194366455 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2626.919921875, (1176.8296, 1.6464165, 1447.2671, 1.1767622)
   validation loss 826.003662109375, (566.6697, 0.4349985, 257.7222, 1.1767622)
decoder loss ratio: 21953.767097, decoder SINDy loss  ratio: 0.556330
--- 0.25713276863098145 seconds for one epoch ---
--- 0.29637670516967773 seconds for one epoch ---
--- 1.7031183242797852 seconds for one epoch ---
--- 0.29311108589172363 seconds for one epoch ---
--- 1.704200029373169 seconds for one epoch ---
--- 0.29068994522094727 seconds for one epoch ---
--- 1.6937482357025146 seconds for one epoch ---
--- 0.30362510681152344 seconds for one epoch ---
--- 1.7183761596679688 seconds for one epoch ---
--- 0.2910916805267334 seconds for one epoch ---
--- 1.676482915878296 seconds for one epoch ---
--- 0.3004720211029053 seconds for one epoch ---
--- 1.67710280418396 seconds for one epoch ---
--- 0.30268406867980957 seconds for one epoch ---
--- 1.6713411808013916 seconds for one epoch ---
--- 0.2867143154144287 seconds for one epoch ---
--- 1.6887900829315186 seconds for one epoch ---
--- 0.2974064350128174 seconds for one epoch ---
--- 1.725999355316162 seconds for one epoch ---
--- 0.2906355857849121 seconds for one epoch ---
--- 1.7474000453948975 seconds for one epoch ---
--- 0.311664342880249 seconds for one epoch ---
--- 1.7429754734039307 seconds for one epoch ---
--- 0.299774169921875 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5923328 ]
 [-0.7385638 ]
 [-0.65061295]
 [ 0.        ]
 [ 0.        ]
 [-0.59091276]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.6501374 ]
 [-0.        ]]
--- 0.26535558700561523 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3995.169189453125, (1356.2875, 1.6194485, 2636.0854, 1.1768011)
   validation loss 817.6934204101562, (534.5303, 0.39677623, 281.58954, 1.1768011)
decoder loss ratio: 20708.630778, decoder SINDy loss  ratio: 0.607851
--- 0.29481029510498047 seconds for one epoch ---
--- 1.7264072895050049 seconds for one epoch ---
--- 0.2967853546142578 seconds for one epoch ---
--- 1.7340562343597412 seconds for one epoch ---
--- 0.30087804794311523 seconds for one epoch ---
--- 1.7284297943115234 seconds for one epoch ---
--- 0.30892300605773926 seconds for one epoch ---
--- 1.7563233375549316 seconds for one epoch ---
--- 0.3027324676513672 seconds for one epoch ---
--- 1.691955804824829 seconds for one epoch ---
--- 0.295487642288208 seconds for one epoch ---
--- 1.7011597156524658 seconds for one epoch ---
--- 0.3144254684448242 seconds for one epoch ---
--- 1.7007741928100586 seconds for one epoch ---
--- 0.3008081912994385 seconds for one epoch ---
--- 1.7207956314086914 seconds for one epoch ---
--- 0.2900216579437256 seconds for one epoch ---
--- 1.7091233730316162 seconds for one epoch ---
--- 0.2813129425048828 seconds for one epoch ---
--- 1.6972146034240723 seconds for one epoch ---
--- 0.2967836856842041 seconds for one epoch ---
--- 1.720397710800171 seconds for one epoch ---
--- 0.2948312759399414 seconds for one epoch ---
--- 1.7349376678466797 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6193738 ]
 [-0.7503895 ]
 [-0.6381607 ]
 [ 0.        ]
 [-0.        ]
 [-0.60144085]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.668793  ]
 [-0.        ]]
--- 0.30623650550842285 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4264.64892578125, (1166.5249, 3.888823, 3093.058, 1.1770734)
   validation loss 780.0372314453125, (530.0549, 0.3636973, 248.4416, 1.1770734)
decoder loss ratio: 20535.245903, decoder SINDy loss  ratio: 0.536296
--- 0.2757430076599121 seconds for one epoch ---
--- 0.30707740783691406 seconds for one epoch ---
--- 1.725203275680542 seconds for one epoch ---
--- 0.30849599838256836 seconds for one epoch ---
--- 1.7349989414215088 seconds for one epoch ---
--- 0.2988297939300537 seconds for one epoch ---
--- 1.7393016815185547 seconds for one epoch ---
--- 0.29880714416503906 seconds for one epoch ---
--- 1.714972734451294 seconds for one epoch ---
--- 0.29616570472717285 seconds for one epoch ---
--- 1.706009864807129 seconds for one epoch ---
--- 0.29718017578125 seconds for one epoch ---
--- 1.6985981464385986 seconds for one epoch ---
--- 0.30097150802612305 seconds for one epoch ---
--- 1.7090656757354736 seconds for one epoch ---
--- 0.2986297607421875 seconds for one epoch ---
--- 1.6799910068511963 seconds for one epoch ---
--- 0.28775787353515625 seconds for one epoch ---
--- 1.7463698387145996 seconds for one epoch ---
--- 0.3107442855834961 seconds for one epoch ---
--- 1.7302050590515137 seconds for one epoch ---
--- 0.34015750885009766 seconds for one epoch ---
--- 1.7316920757293701 seconds for one epoch ---
--- 0.32613587379455566 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.629237 ]
 [-0.7569167]
 [-0.6315547]
 [-0.       ]
 [ 0.       ]
 [-0.6033962]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.6677923]
 [ 0.       ]]
--- 0.23197078704833984 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3440.680908203125, (1338.3679, 1.6266836, 2099.509, 1.1771791)
   validation loss 1124.5894775390625, (862.0438, 0.27863428, 261.08994, 1.1771791)
decoder loss ratio: 33397.074286, decoder SINDy loss  ratio: 0.563599
--- 0.2937045097351074 seconds for one epoch ---
--- 1.7268297672271729 seconds for one epoch ---
--- 0.2946970462799072 seconds for one epoch ---
--- 1.7189545631408691 seconds for one epoch ---
--- 0.30289363861083984 seconds for one epoch ---
--- 1.7415919303894043 seconds for one epoch ---
--- 0.3069629669189453 seconds for one epoch ---
--- 1.7347402572631836 seconds for one epoch ---
--- 0.30552244186401367 seconds for one epoch ---
--- 1.7414748668670654 seconds for one epoch ---
--- 0.30347657203674316 seconds for one epoch ---
--- 1.706171989440918 seconds for one epoch ---
--- 0.2953066825866699 seconds for one epoch ---
--- 1.715575933456421 seconds for one epoch ---
--- 0.30631303787231445 seconds for one epoch ---
--- 1.6800241470336914 seconds for one epoch ---
--- 0.30288004875183105 seconds for one epoch ---
--- 1.7477037906646729 seconds for one epoch ---
--- 0.29987072944641113 seconds for one epoch ---
--- 1.7694823741912842 seconds for one epoch ---
--- 0.3009450435638428 seconds for one epoch ---
--- 1.7627274990081787 seconds for one epoch ---
--- 0.29173803329467773 seconds for one epoch ---
--- 1.7624287605285645 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6461868 ]
 [-0.7740474 ]
 [-0.62927765]
 [-0.        ]
 [-0.        ]
 [-0.60688144]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.678091  ]
 [ 0.        ]]
--- 0.28876686096191406 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1693.2454833984375, (982.10693, 0.40328106, 709.55804, 1.1773034)
   validation loss 797.3712158203125, (558.7925, 0.31952503, 237.08192, 1.1773034)
decoder loss ratio: 21648.590800, decoder SINDy loss  ratio: 0.511775
--- 0.26859378814697266 seconds for one epoch ---
--- 0.29853081703186035 seconds for one epoch ---
--- 1.7547237873077393 seconds for one epoch ---
--- 0.30265021324157715 seconds for one epoch ---
--- 1.766906499862671 seconds for one epoch ---
--- 0.290924072265625 seconds for one epoch ---
--- 1.7693350315093994 seconds for one epoch ---
--- 0.29432034492492676 seconds for one epoch ---
--- 1.7942142486572266 seconds for one epoch ---
--- 0.29369449615478516 seconds for one epoch ---
--- 1.7539708614349365 seconds for one epoch ---
--- 0.2966799736022949 seconds for one epoch ---
--- 1.7395009994506836 seconds for one epoch ---
--- 0.29650044441223145 seconds for one epoch ---
--- 1.733102560043335 seconds for one epoch ---
--- 0.30904173851013184 seconds for one epoch ---
--- 1.7250111103057861 seconds for one epoch ---
--- 0.305617094039917 seconds for one epoch ---
--- 1.7675676345825195 seconds for one epoch ---
--- 0.32608914375305176 seconds for one epoch ---
--- 1.7704460620880127 seconds for one epoch ---
--- 0.2920658588409424 seconds for one epoch ---
--- 1.7444758415222168 seconds for one epoch ---
--- 0.31191301345825195 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6550214]
 [-0.7723758]
 [-0.6325154]
 [ 0.       ]
 [-0.       ]
 [-0.5931983]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.697138 ]
 [-0.       ]]
--- 0.25752925872802734 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3273.486083984375, (1593.2888, 1.7831705, 1677.2366, 1.1774653)
   validation loss 688.9842529296875, (449.29672, 0.28081656, 238.22922, 1.1774653)
decoder loss ratio: 17406.535040, decoder SINDy loss  ratio: 0.514251
--- 0.28977370262145996 seconds for one epoch ---
--- 1.748976230621338 seconds for one epoch ---
--- 0.2879796028137207 seconds for one epoch ---
--- 1.7356932163238525 seconds for one epoch ---
--- 0.2818586826324463 seconds for one epoch ---
--- 1.748532772064209 seconds for one epoch ---
--- 0.2967216968536377 seconds for one epoch ---
--- 1.7459282875061035 seconds for one epoch ---
--- 0.2959134578704834 seconds for one epoch ---
--- 1.7832493782043457 seconds for one epoch ---
--- 0.26951146125793457 seconds for one epoch ---
--- 1.729891061782837 seconds for one epoch ---
--- 0.2952873706817627 seconds for one epoch ---
--- 1.7394506931304932 seconds for one epoch ---
--- 0.29227757453918457 seconds for one epoch ---
--- 1.7426066398620605 seconds for one epoch ---
--- 0.30774521827697754 seconds for one epoch ---
--- 1.7926075458526611 seconds for one epoch ---
--- 0.2953009605407715 seconds for one epoch ---
--- 1.7925944328308105 seconds for one epoch ---
--- 0.2944495677947998 seconds for one epoch ---
--- 1.8216185569763184 seconds for one epoch ---
--- 0.287353515625 seconds for one epoch ---
--- 1.8146953582763672 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.673605  ]
 [-0.75340664]
 [-0.62854564]
 [ 0.        ]
 [-0.        ]
 [-0.5992007 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.7075844 ]
 [-0.        ]]
--- 0.2970597743988037 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2009.4681396484375, (979.77026, 1.442061, 1027.0781, 1.1776351)
   validation loss 1117.5950927734375, (826.60486, 0.29391196, 289.51877, 1.1776351)
decoder loss ratio: 32024.107263, decoder SINDy loss  ratio: 0.624967
--- 0.24889135360717773 seconds for one epoch ---
--- 0.2986159324645996 seconds for one epoch ---
--- 1.7895770072937012 seconds for one epoch ---
--- 0.30065178871154785 seconds for one epoch ---
--- 1.8004209995269775 seconds for one epoch ---
--- 0.3048896789550781 seconds for one epoch ---
--- 1.7934720516204834 seconds for one epoch ---
--- 0.3047659397125244 seconds for one epoch ---
--- 1.812737226486206 seconds for one epoch ---
--- 0.2979905605316162 seconds for one epoch ---
--- 1.7982983589172363 seconds for one epoch ---
--- 0.30159640312194824 seconds for one epoch ---
--- 1.7541940212249756 seconds for one epoch ---
--- 0.2994356155395508 seconds for one epoch ---
--- 1.7761657238006592 seconds for one epoch ---
--- 0.28716421127319336 seconds for one epoch ---
--- 1.7544002532958984 seconds for one epoch ---
--- 0.30475640296936035 seconds for one epoch ---
--- 1.756152868270874 seconds for one epoch ---
--- 0.3031928539276123 seconds for one epoch ---
--- 1.7823376655578613 seconds for one epoch ---
--- 0.29633355140686035 seconds for one epoch ---
--- 1.7913827896118164 seconds for one epoch ---
--- 0.2892262935638428 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6857197 ]
 [-0.75050324]
 [-0.62813133]
 [-0.        ]
 [ 0.        ]
 [-0.594532  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.7213645 ]
 [ 0.        ]]
--- 0.2684056758880615 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4763.34814453125, (1844.7971, 2.1015477, 2915.2717, 1.1777973)
   validation loss 1286.4595947265625, (1028.6958, 0.2623571, 256.3236, 1.1777973)
decoder loss ratio: 39853.461217, decoder SINDy loss  ratio: 0.553311
--- 0.2854022979736328 seconds for one epoch ---
--- 1.7919971942901611 seconds for one epoch ---
--- 0.3035314083099365 seconds for one epoch ---
--- 1.796189785003662 seconds for one epoch ---
--- 0.29852724075317383 seconds for one epoch ---
--- 1.7837188243865967 seconds for one epoch ---
--- 0.3012878894805908 seconds for one epoch ---
--- 1.8127057552337646 seconds for one epoch ---
--- 0.29766178131103516 seconds for one epoch ---
--- 1.8383839130401611 seconds for one epoch ---
--- 0.29552555084228516 seconds for one epoch ---
--- 1.7660772800445557 seconds for one epoch ---
--- 0.29474329948425293 seconds for one epoch ---
--- 1.7746336460113525 seconds for one epoch ---
--- 0.28783512115478516 seconds for one epoch ---
--- 1.7580504417419434 seconds for one epoch ---
--- 0.2996077537536621 seconds for one epoch ---
--- 1.7905023097991943 seconds for one epoch ---
--- 0.3012735843658447 seconds for one epoch ---
--- 1.7936453819274902 seconds for one epoch ---
--- 0.29999589920043945 seconds for one epoch ---
--- 1.780836582183838 seconds for one epoch ---
--- 0.2938559055328369 seconds for one epoch ---
--- 1.8206212520599365 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6889114 ]
 [-0.73925877]
 [-0.62578213]
 [-0.        ]
 [-0.        ]
 [-0.58654666]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.7243433 ]
 [ 0.        ]]
--- 0.31176328659057617 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4521.60400390625, (1261.5469, 2.8460262, 3256.0334, 1.1777982)
   validation loss 771.0, (532.46497, 0.2699467, 237.08727, 1.1777982)
decoder loss ratio: 20628.617176, decoder SINDy loss  ratio: 0.511786
--- 0.25520896911621094 seconds for one epoch ---
--- 0.3026313781738281 seconds for one epoch ---
--- 1.7894022464752197 seconds for one epoch ---
--- 0.30307698249816895 seconds for one epoch ---
--- 1.7712068557739258 seconds for one epoch ---
--- 0.294574499130249 seconds for one epoch ---
--- 1.7712945938110352 seconds for one epoch ---
--- 0.3005380630493164 seconds for one epoch ---
--- 1.7801873683929443 seconds for one epoch ---
--- 0.3001866340637207 seconds for one epoch ---
--- 1.8269715309143066 seconds for one epoch ---
--- 0.3091733455657959 seconds for one epoch ---
--- 1.7721998691558838 seconds for one epoch ---
--- 0.29708051681518555 seconds for one epoch ---
--- 1.7739427089691162 seconds for one epoch ---
--- 0.30574965476989746 seconds for one epoch ---
--- 1.7467873096466064 seconds for one epoch ---
--- 0.3060469627380371 seconds for one epoch ---
--- 1.7452988624572754 seconds for one epoch ---
--- 0.301804780960083 seconds for one epoch ---
--- 1.7899582386016846 seconds for one epoch ---
--- 0.29242801666259766 seconds for one epoch ---
--- 1.7904269695281982 seconds for one epoch ---
--- 0.29941892623901367 seconds for one epoch ---
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6960554 ]
 [-0.73077416]
 [-0.62383765]
 [ 0.        ]
 [ 0.        ]
 [-0.58532834]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.7238717 ]
 [-0.        ]]
--- 0.2530648708343506 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2614.880859375, (992.04944, 4.8746824, 1616.7789, 1.1778374)
   validation loss 683.77099609375, (442.0691, 0.3620719, 240.16199, 1.1778374)
decoder loss ratio: 17126.524082, decoder SINDy loss  ratio: 0.518423
--- 0.3007848262786865 seconds for one epoch ---
--- 1.820115566253662 seconds for one epoch ---
--- 0.2817840576171875 seconds for one epoch ---
--- 1.7992122173309326 seconds for one epoch ---
--- 0.3024158477783203 seconds for one epoch ---
--- 1.7777249813079834 seconds for one epoch ---
--- 0.3031888008117676 seconds for one epoch ---
--- 1.7939071655273438 seconds for one epoch ---
--- 0.2987992763519287 seconds for one epoch ---
--- 1.7913782596588135 seconds for one epoch ---
--- 0.2916245460510254 seconds for one epoch ---
--- 1.8287203311920166 seconds for one epoch ---
--- 0.30298638343811035 seconds for one epoch ---
--- 1.7789020538330078 seconds for one epoch ---
--- 0.30022215843200684 seconds for one epoch ---
--- 1.7618839740753174 seconds for one epoch ---
--- 0.2940371036529541 seconds for one epoch ---
--- 1.7632198333740234 seconds for one epoch ---
--- 0.3097057342529297 seconds for one epoch ---
--- 1.7621276378631592 seconds for one epoch ---
--- 0.28232264518737793 seconds for one epoch ---
--- 1.8103578090667725 seconds for one epoch ---
--- 0.3141899108886719 seconds for one epoch ---
--- 1.8140037059783936 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7015722 ]
 [-0.7169619 ]
 [-0.6218068 ]
 [ 0.        ]
 [ 0.        ]
 [-0.58189917]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.727035  ]
 [-0.        ]]
--- 0.30510973930358887 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2625.5009765625, (1084.0416, 2.6439402, 1537.6378, 1.177837)
   validation loss 838.590087890625, (579.8522, 0.3891491, 257.1709, 1.177837)
decoder loss ratio: 22464.479844, decoder SINDy loss  ratio: 0.555140
--- 0.2661266326904297 seconds for one epoch ---
--- 0.31282806396484375 seconds for one epoch ---
--- 1.8180551528930664 seconds for one epoch ---
--- 0.2920048236846924 seconds for one epoch ---
--- 1.8024845123291016 seconds for one epoch ---
--- 0.30330872535705566 seconds for one epoch ---
--- 1.8122081756591797 seconds for one epoch ---
--- 0.30011796951293945 seconds for one epoch ---
--- 1.7956957817077637 seconds for one epoch ---
--- 0.2903146743774414 seconds for one epoch ---
--- 1.8076109886169434 seconds for one epoch ---
--- 0.30540037155151367 seconds for one epoch ---
--- 1.8377420902252197 seconds for one epoch ---
--- 0.3038008213043213 seconds for one epoch ---
--- 1.823901891708374 seconds for one epoch ---
--- 0.29504990577697754 seconds for one epoch ---
--- 1.7836861610412598 seconds for one epoch ---
--- 0.2685065269470215 seconds for one epoch ---
--- 1.798853874206543 seconds for one epoch ---
--- 0.2899813652038574 seconds for one epoch ---
--- 1.767845630645752 seconds for one epoch ---
--- 0.2832987308502197 seconds for one epoch ---
--- 1.8102171421051025 seconds for one epoch ---
--- 0.2840845584869385 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7197373 ]
 [-0.7080262 ]
 [-0.6146928 ]
 [-0.        ]
 [-0.        ]
 [-0.58330405]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.7506104 ]
 [ 0.        ]]
--- 0.2603747844696045 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2890.91455078125, (1371.2981, 1.8249323, 1516.6135, 1.1780971)
   validation loss 677.2449951171875, (429.13, 0.37154287, 246.5653, 1.1780971)
decoder loss ratio: 16625.241392, decoder SINDy loss  ratio: 0.532246
--- 0.2958333492279053 seconds for one epoch ---
--- 1.8323795795440674 seconds for one epoch ---
--- 0.29248881340026855 seconds for one epoch ---
--- 1.822805404663086 seconds for one epoch ---
--- 0.29629063606262207 seconds for one epoch ---
--- 1.8385789394378662 seconds for one epoch ---
--- 0.2968881130218506 seconds for one epoch ---
--- 1.8533966541290283 seconds for one epoch ---
--- 0.30986881256103516 seconds for one epoch ---
--- 1.8281214237213135 seconds for one epoch ---
--- 0.2931544780731201 seconds for one epoch ---
--- 1.8283264636993408 seconds for one epoch ---
--- 0.2918062210083008 seconds for one epoch ---
--- 1.8367714881896973 seconds for one epoch ---
--- 0.30217528343200684 seconds for one epoch ---
--- 1.7995927333831787 seconds for one epoch ---
--- 0.30298662185668945 seconds for one epoch ---
--- 1.784269094467163 seconds for one epoch ---
--- 0.29955077171325684 seconds for one epoch ---
--- 1.8018736839294434 seconds for one epoch ---
--- 0.29476261138916016 seconds for one epoch ---
--- 1.7839367389678955 seconds for one epoch ---
--- 0.30935120582580566 seconds for one epoch ---
--- 1.8371031284332275 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7329624 ]
 [-0.7134595 ]
 [-0.61764175]
 [-0.        ]
 [ 0.        ]
 [-0.58401966]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.764626  ]
 [ 0.        ]]
--- 0.2943732738494873 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2495.394287109375, (1043.6123, 7.430787, 1443.173, 1.1783301)
   validation loss 1078.370849609375, (812.7723, 0.39311138, 264.02707, 1.1783301)
decoder loss ratio: 31488.209078, decoder SINDy loss  ratio: 0.569940
--- 0.2555830478668213 seconds for one epoch ---
--- 0.2904689311981201 seconds for one epoch ---
--- 1.8706321716308594 seconds for one epoch ---
--- 0.2920699119567871 seconds for one epoch ---
--- 1.8571727275848389 seconds for one epoch ---
--- 0.3033607006072998 seconds for one epoch ---
--- 1.824793815612793 seconds for one epoch ---
--- 0.2967972755432129 seconds for one epoch ---
--- 1.8690297603607178 seconds for one epoch ---
--- 0.295515775680542 seconds for one epoch ---
--- 1.8610749244689941 seconds for one epoch ---
--- 0.30197787284851074 seconds for one epoch ---
--- 1.8849945068359375 seconds for one epoch ---
--- 0.2936849594116211 seconds for one epoch ---
--- 1.8906166553497314 seconds for one epoch ---
--- 0.2959411144256592 seconds for one epoch ---
--- 1.8313069343566895 seconds for one epoch ---
--- 0.29445338249206543 seconds for one epoch ---
--- 1.807433843612671 seconds for one epoch ---
--- 0.2948026657104492 seconds for one epoch ---
--- 1.829026222229004 seconds for one epoch ---
--- 0.2638561725616455 seconds for one epoch ---
--- 1.829817771911621 seconds for one epoch ---
--- 0.30155420303344727 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7406144 ]
 [-0.70892715]
 [-0.6173257 ]
 [ 0.        ]
 [-0.        ]
 [-0.5785503 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.780351  ]
 [-0.        ]]
--- 0.30003976821899414 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4157.98291015625, (1146.1937, 1.6610273, 3008.9497, 1.1784337)
   validation loss 802.9285278320312, (537.30096, 0.40163493, 264.04758, 1.1784337)
decoder loss ratio: 20815.972155, decoder SINDy loss  ratio: 0.569984
--- 0.2828030586242676 seconds for one epoch ---
--- 1.8400046825408936 seconds for one epoch ---
--- 0.296978235244751 seconds for one epoch ---
--- 1.8334851264953613 seconds for one epoch ---
--- 0.29733729362487793 seconds for one epoch ---
--- 1.8401849269866943 seconds for one epoch ---
--- 0.29901957511901855 seconds for one epoch ---
--- 1.823415994644165 seconds for one epoch ---
--- 0.30207014083862305 seconds for one epoch ---
--- 1.8251838684082031 seconds for one epoch ---
--- 0.29635143280029297 seconds for one epoch ---
--- 1.8510019779205322 seconds for one epoch ---
--- 0.2875552177429199 seconds for one epoch ---
--- 1.8714194297790527 seconds for one epoch ---
--- 0.2939598560333252 seconds for one epoch ---
--- 1.8578965663909912 seconds for one epoch ---
--- 0.3035714626312256 seconds for one epoch ---
--- 1.8201396465301514 seconds for one epoch ---
--- 0.3050999641418457 seconds for one epoch ---
--- 1.8328430652618408 seconds for one epoch ---
--- 0.2947399616241455 seconds for one epoch ---
--- 1.820934534072876 seconds for one epoch ---
--- 0.2976665496826172 seconds for one epoch ---
--- 1.846708059310913 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7476132 ]
 [-0.6897792 ]
 [-0.616657  ]
 [ 0.        ]
 [-0.        ]
 [-0.57716966]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.786045  ]
 [-0.        ]]
--- 0.30188488960266113 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2784.696533203125, (1133.7793, 1.8984743, 1647.8402, 1.1784812)
   validation loss 1615.7252197265625, (1350.1088, 0.41453564, 264.0234, 1.1784812)
decoder loss ratio: 52305.557434, decoder SINDy loss  ratio: 0.569932
--- 0.2416832447052002 seconds for one epoch ---
--- 0.31183815002441406 seconds for one epoch ---
--- 1.8859598636627197 seconds for one epoch ---
--- 0.32845568656921387 seconds for one epoch ---
--- 1.8831510543823242 seconds for one epoch ---
--- 0.30030298233032227 seconds for one epoch ---
--- 1.889477252960205 seconds for one epoch ---
--- 0.2933783531188965 seconds for one epoch ---
--- 1.8665990829467773 seconds for one epoch ---
--- 0.2896895408630371 seconds for one epoch ---
--- 1.8478672504425049 seconds for one epoch ---
--- 0.27227282524108887 seconds for one epoch ---
--- 1.8950004577636719 seconds for one epoch ---
--- 0.30146217346191406 seconds for one epoch ---
--- 1.8976216316223145 seconds for one epoch ---
--- 0.28456807136535645 seconds for one epoch ---
--- 1.8393278121948242 seconds for one epoch ---
--- 0.2929394245147705 seconds for one epoch ---
--- 1.826082706451416 seconds for one epoch ---
--- 0.3007931709289551 seconds for one epoch ---
--- 1.848999261856079 seconds for one epoch ---
--- 0.29657459259033203 seconds for one epoch ---
--- 1.8544530868530273 seconds for one epoch ---
--- 0.29799556732177734 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7580898 ]
 [-0.68645287]
 [-0.6096986 ]
 [-0.        ]
 [-0.        ]
 [-0.5811627 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.7878475 ]
 [ 0.        ]]
--- 0.257570743560791 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4707.6943359375, (1631.3407, 6.9898047, 3068.185, 1.1785387)
   validation loss 857.6767578125, (614.6298, 0.3853621, 241.48302, 1.1785387)
decoder loss ratio: 23811.826340, decoder SINDy loss  ratio: 0.521275
--- 0.30028557777404785 seconds for one epoch ---
--- 1.9133617877960205 seconds for one epoch ---
--- 0.28498172760009766 seconds for one epoch ---
--- 1.887535810470581 seconds for one epoch ---
--- 0.31789064407348633 seconds for one epoch ---
--- 1.8896870613098145 seconds for one epoch ---
--- 0.3143584728240967 seconds for one epoch ---
--- 1.8861618041992188 seconds for one epoch ---
--- 0.30489182472229004 seconds for one epoch ---
--- 1.8936288356781006 seconds for one epoch ---
--- 0.3094968795776367 seconds for one epoch ---
--- 1.8947396278381348 seconds for one epoch ---
--- 0.31450724601745605 seconds for one epoch ---
--- 1.9261589050292969 seconds for one epoch ---
--- 0.3069891929626465 seconds for one epoch ---
--- 1.8530757427215576 seconds for one epoch ---
--- 0.27900052070617676 seconds for one epoch ---
--- 1.8669073581695557 seconds for one epoch ---
--- 0.29270386695861816 seconds for one epoch ---
--- 1.8897874355316162 seconds for one epoch ---
--- 0.2760469913482666 seconds for one epoch ---
--- 1.8766391277313232 seconds for one epoch ---
--- 0.27696919441223145 seconds for one epoch ---
--- 1.9158363342285156 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7663333]
 [-0.6998686]
 [-0.6052455]
 [-0.       ]
 [ 0.       ]
 [-0.5815772]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7935824]
 [ 0.       ]]
--- 0.2897334098815918 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2731.08251953125, (1410.5778, 1.3533856, 1317.9725, 1.1786507)
   validation loss 713.2080078125, (469.14767, 0.43158573, 242.45009, 1.1786507)
decoder loss ratio: 18175.595389, decoder SINDy loss  ratio: 0.523363
--- 0.26360249519348145 seconds for one epoch ---
--- 0.30466318130493164 seconds for one epoch ---
--- 1.8697423934936523 seconds for one epoch ---
--- 0.29631495475769043 seconds for one epoch ---
--- 1.8890998363494873 seconds for one epoch ---
--- 0.3024585247039795 seconds for one epoch ---
--- 1.880084753036499 seconds for one epoch ---
--- 0.29767680168151855 seconds for one epoch ---
--- 1.8670833110809326 seconds for one epoch ---
--- 0.29259181022644043 seconds for one epoch ---
--- 1.8683507442474365 seconds for one epoch ---
--- 0.305722713470459 seconds for one epoch ---
--- 1.8653779029846191 seconds for one epoch ---
--- 0.3004627227783203 seconds for one epoch ---
--- 1.9054522514343262 seconds for one epoch ---
--- 0.2944512367248535 seconds for one epoch ---
--- 1.8324787616729736 seconds for one epoch ---
--- 0.2953040599822998 seconds for one epoch ---
--- 1.8623971939086914 seconds for one epoch ---
--- 0.2844862937927246 seconds for one epoch ---
--- 1.8264601230621338 seconds for one epoch ---
--- 0.2933351993560791 seconds for one epoch ---
--- 1.8591923713684082 seconds for one epoch ---
--- 0.2959113121032715 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.771891 ]
 [-0.6916424]
 [-0.6044372]
 [ 0.       ]
 [-0.       ]
 [-0.5772629]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.798057 ]
 [-0.       ]]
--- 0.26117777824401855 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2058.0654296875, (1011.66656, 1.746655, 1043.4735, 1.1786894)
   validation loss 769.9188842773438, (531.77203, 0.42536044, 236.54279, 1.1786894)
decoder loss ratio: 20601.771782, decoder SINDy loss  ratio: 0.510611
--- 0.3203754425048828 seconds for one epoch ---
--- 1.9446816444396973 seconds for one epoch ---
--- 0.3364694118499756 seconds for one epoch ---
--- 1.902564287185669 seconds for one epoch ---
--- 0.3057289123535156 seconds for one epoch ---
--- 1.9243223667144775 seconds for one epoch ---
--- 0.30474066734313965 seconds for one epoch ---
--- 1.8846242427825928 seconds for one epoch ---
--- 0.2882111072540283 seconds for one epoch ---
--- 1.9136054515838623 seconds for one epoch ---
--- 0.3056449890136719 seconds for one epoch ---
--- 1.9119932651519775 seconds for one epoch ---
--- 0.29288315773010254 seconds for one epoch ---
--- 1.939201831817627 seconds for one epoch ---
--- 0.3030710220336914 seconds for one epoch ---
--- 1.9155008792877197 seconds for one epoch ---
--- 0.2922797203063965 seconds for one epoch ---
--- 1.9019265174865723 seconds for one epoch ---
--- 0.29950737953186035 seconds for one epoch ---
--- 1.8899455070495605 seconds for one epoch ---
--- 0.31082987785339355 seconds for one epoch ---
--- 1.8669452667236328 seconds for one epoch ---
--- 0.2933311462402344 seconds for one epoch ---
--- 1.9222521781921387 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99999785]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7792742]
 [-0.6886273]
 [-0.6125702]
 [ 0.       ]
 [ 0.       ]
 [-0.572919 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.809369 ]
 [-0.       ]]
--- 0.29065680503845215 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2191.9853515625, (1167.2489, 1.2518953, 1022.3059, 1.178826)
   validation loss 991.04541015625, (724.699, 0.49543828, 264.67215, 1.178826)
decoder loss ratio: 28076.096409, decoder SINDy loss  ratio: 0.571332
THRESHOLDING: 5 active coefficients
--- 1.870682954788208 seconds for one epoch ---
--- 0.287583589553833 seconds for one epoch ---
--- 1.9351203441619873 seconds for one epoch ---
--- 0.2754380702972412 seconds for one epoch ---
--- 1.8984992504119873 seconds for one epoch ---
--- 0.2983849048614502 seconds for one epoch ---
--- 1.932755708694458 seconds for one epoch ---
--- 0.29721736907958984 seconds for one epoch ---
--- 1.9284272193908691 seconds for one epoch ---
--- 0.29879093170166016 seconds for one epoch ---
--- 1.9356639385223389 seconds for one epoch ---
--- 0.2984127998352051 seconds for one epoch ---
--- 1.924025058746338 seconds for one epoch ---
--- 0.30321741104125977 seconds for one epoch ---
--- 1.9579722881317139 seconds for one epoch ---
--- 0.2964510917663574 seconds for one epoch ---
--- 1.894378662109375 seconds for one epoch ---
--- 0.300586462020874 seconds for one epoch ---
--- 1.8842401504516602 seconds for one epoch ---
--- 0.28932642936706543 seconds for one epoch ---
--- 1.9109957218170166 seconds for one epoch ---
--- 0.27478599548339844 seconds for one epoch ---
--- 1.9150664806365967 seconds for one epoch ---
--- 0.2790093421936035 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8011088 ]
 [-0.69789404]
 [-0.60622126]
 [-0.        ]
 [ 0.        ]
 [-0.5788037 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.82648   ]
 [ 0.        ]]
--- 0.2591872215270996 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1768.4671630859375, (950.3689, 6.1482177, 810.77094, 1.1790732)
   validation loss 771.4467163085938, (521.3115, 0.4916204, 248.4645, 1.1790732)
decoder loss ratio: 20196.513455, decoder SINDy loss  ratio: 0.536346
--- 0.31577157974243164 seconds for one epoch ---
--- 1.952958106994629 seconds for one epoch ---
--- 0.30992674827575684 seconds for one epoch ---
--- 1.9693500995635986 seconds for one epoch ---
--- 0.30652713775634766 seconds for one epoch ---
--- 1.949444055557251 seconds for one epoch ---
--- 0.3022582530975342 seconds for one epoch ---
--- 1.9465570449829102 seconds for one epoch ---
--- 0.28525233268737793 seconds for one epoch ---
--- 1.9486489295959473 seconds for one epoch ---
--- 0.30202412605285645 seconds for one epoch ---
--- 1.9941349029541016 seconds for one epoch ---
--- 0.30961060523986816 seconds for one epoch ---
--- 1.9533588886260986 seconds for one epoch ---
--- 0.29308485984802246 seconds for one epoch ---
--- 1.922684669494629 seconds for one epoch ---
--- 0.29117655754089355 seconds for one epoch ---
--- 1.9357197284698486 seconds for one epoch ---
--- 0.29897356033325195 seconds for one epoch ---
--- 1.9198260307312012 seconds for one epoch ---
--- 0.2936084270477295 seconds for one epoch ---
--- 1.9390480518341064 seconds for one epoch ---
--- 0.29724764823913574 seconds for one epoch ---
--- 1.9747366905212402 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8119714 ]
 [-0.70549786]
 [-0.606964  ]
 [-0.        ]
 [-0.        ]
 [-0.57839817]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.8343477 ]
 [ 0.        ]]
--- 0.29109716415405273 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2635.190673828125, (1321.9884, 0.9425577, 1311.0806, 1.1792063)
   validation loss 816.0807495117188, (548.1292, 0.42404246, 266.34827, 1.1792063)
decoder loss ratio: 21235.477245, decoder SINDy loss  ratio: 0.574950
--- 0.26786065101623535 seconds for one epoch ---
--- 0.3002283573150635 seconds for one epoch ---
--- 1.9961004257202148 seconds for one epoch ---
--- 0.3060762882232666 seconds for one epoch ---
--- 1.987577199935913 seconds for one epoch ---
--- 0.29422760009765625 seconds for one epoch ---
--- 1.97265625 seconds for one epoch ---
--- 0.3027355670928955 seconds for one epoch ---
--- 1.98038649559021 seconds for one epoch ---
--- 0.30327367782592773 seconds for one epoch ---
--- 1.9649477005004883 seconds for one epoch ---
--- 0.305269718170166 seconds for one epoch ---
--- 1.9997401237487793 seconds for one epoch ---
--- 0.31543612480163574 seconds for one epoch ---
--- 1.9823181629180908 seconds for one epoch ---
--- 0.2939023971557617 seconds for one epoch ---
--- 1.952071189880371 seconds for one epoch ---
--- 0.2993893623352051 seconds for one epoch ---
--- 1.9427921772003174 seconds for one epoch ---
--- 0.30960559844970703 seconds for one epoch ---
--- 1.9433085918426514 seconds for one epoch ---
--- 0.303469181060791 seconds for one epoch ---
--- 1.959223747253418 seconds for one epoch ---
--- 0.28754687309265137 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8282003 ]
 [-0.71715504]
 [-0.6105062 ]
 [ 0.        ]
 [ 0.        ]
 [-0.5830631 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.8463063 ]
 [-0.        ]]
--- 0.2737619876861572 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1903.8931884765625, (1022.99274, 1.441813, 878.2792, 1.1793827)
   validation loss 789.3612670898438, (536.4421, 0.45107087, 251.28876, 1.1793827)
decoder loss ratio: 20782.697392, decoder SINDy loss  ratio: 0.542442
--- 0.31348633766174316 seconds for one epoch ---
--- 1.936260461807251 seconds for one epoch ---
--- 0.30370545387268066 seconds for one epoch ---
--- 1.993786334991455 seconds for one epoch ---
--- 0.29558467864990234 seconds for one epoch ---
--- 2.0023226737976074 seconds for one epoch ---
--- 0.3136732578277588 seconds for one epoch ---
--- 1.9816341400146484 seconds for one epoch ---
--- 0.30280208587646484 seconds for one epoch ---
--- 2.016636848449707 seconds for one epoch ---
--- 0.297487735748291 seconds for one epoch ---
--- 2.0237245559692383 seconds for one epoch ---
--- 0.3018321990966797 seconds for one epoch ---
--- 1.9729199409484863 seconds for one epoch ---
--- 0.2975766658782959 seconds for one epoch ---
--- 1.9699645042419434 seconds for one epoch ---
--- 0.2915663719177246 seconds for one epoch ---
--- 1.944678783416748 seconds for one epoch ---
--- 0.29172587394714355 seconds for one epoch ---
--- 1.9590325355529785 seconds for one epoch ---
--- 0.305497407913208 seconds for one epoch ---
--- 1.9757931232452393 seconds for one epoch ---
--- 0.2973897457122803 seconds for one epoch ---
--- 2.0203123092651367 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8313875 ]
 [-0.7216608 ]
 [-0.60823715]
 [ 0.        ]
 [-0.        ]
 [-0.57695436]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.8491216 ]
 [-0.        ]]
--- 0.29569387435913086 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8018.02001953125, (2843.4006, 2.641838, 5170.7983, 1.179428)
   validation loss 921.109375, (656.8557, 0.36772266, 262.70645, 1.179428)
decoder loss ratio: 25447.730669, decoder SINDy loss  ratio: 0.567089
--- 0.2578747272491455 seconds for one epoch ---
--- 0.30556750297546387 seconds for one epoch ---
--- 1.9864647388458252 seconds for one epoch ---
--- 0.29889845848083496 seconds for one epoch ---
--- 1.9924044609069824 seconds for one epoch ---
--- 0.29686927795410156 seconds for one epoch ---
--- 1.9974255561828613 seconds for one epoch ---
--- 0.2972686290740967 seconds for one epoch ---
--- 1.9675490856170654 seconds for one epoch ---
--- 0.29978227615356445 seconds for one epoch ---
--- 1.9783341884613037 seconds for one epoch ---
--- 0.30615806579589844 seconds for one epoch ---
--- 1.9933366775512695 seconds for one epoch ---
--- 0.297168493270874 seconds for one epoch ---
--- 1.9187722206115723 seconds for one epoch ---
--- 0.3043849468231201 seconds for one epoch ---
--- 1.9267535209655762 seconds for one epoch ---
--- 0.3015599250793457 seconds for one epoch ---
--- 1.927011489868164 seconds for one epoch ---
--- 0.29529571533203125 seconds for one epoch ---
--- 1.941863775253296 seconds for one epoch ---
--- 0.29265642166137695 seconds for one epoch ---
--- 1.9557898044586182 seconds for one epoch ---
--- 0.29259395599365234 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8412833]
 [-0.7153575]
 [-0.6079699]
 [-0.       ]
 [-0.       ]
 [-0.5773989]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.857233 ]
 [ 0.       ]]
--- 0.2608914375305176 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2890.550537109375, (961.63904, 4.115611, 1923.6166, 1.1795384)
   validation loss 775.0657348632812, (538.82275, 0.44907528, 234.6143, 1.1795384)
decoder loss ratio: 20874.928924, decoder SINDy loss  ratio: 0.506448
--- 0.3236851692199707 seconds for one epoch ---
--- 1.9750282764434814 seconds for one epoch ---
--- 0.3143932819366455 seconds for one epoch ---
--- 2.0006215572357178 seconds for one epoch ---
--- 0.29540419578552246 seconds for one epoch ---
--- 1.960622787475586 seconds for one epoch ---
--- 0.29754185676574707 seconds for one epoch ---
--- 1.9863357543945312 seconds for one epoch ---
--- 0.3033571243286133 seconds for one epoch ---
--- 1.9812872409820557 seconds for one epoch ---
--- 0.3062570095062256 seconds for one epoch ---
--- 1.9735326766967773 seconds for one epoch ---
--- 0.3035445213317871 seconds for one epoch ---
--- 1.9960594177246094 seconds for one epoch ---
--- 0.303938627243042 seconds for one epoch ---
--- 1.958975076675415 seconds for one epoch ---
--- 0.3002488613128662 seconds for one epoch ---
--- 1.9443833827972412 seconds for one epoch ---
--- 0.3009827136993408 seconds for one epoch ---
--- 1.9583344459533691 seconds for one epoch ---
--- 0.2949337959289551 seconds for one epoch ---
--- 1.9357199668884277 seconds for one epoch ---
--- 0.30406880378723145 seconds for one epoch ---
--- 1.9988250732421875 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8451028]
 [-0.7338099]
 [-0.606829 ]
 [-0.       ]
 [-0.       ]
 [-0.5717541]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.865479 ]
 [ 0.       ]]
--- 0.29398036003112793 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4353.408203125, (1477.1348, 1.0749166, 2874.0186, 1.1796229)
   validation loss 826.5330200195312, (580.38513, 0.3760406, 244.5922, 1.1796229)
decoder loss ratio: 22485.127600, decoder SINDy loss  ratio: 0.527987
--- 0.2629683017730713 seconds for one epoch ---
--- 0.32863664627075195 seconds for one epoch ---
--- 1.9924423694610596 seconds for one epoch ---
--- 0.29976415634155273 seconds for one epoch ---
--- 2.029832363128662 seconds for one epoch ---
--- 0.3032569885253906 seconds for one epoch ---
--- 2.0105652809143066 seconds for one epoch ---
--- 0.30672597885131836 seconds for one epoch ---
--- 2.0316264629364014 seconds for one epoch ---
--- 0.29486584663391113 seconds for one epoch ---
--- 2.00734281539917 seconds for one epoch ---
--- 0.28859472274780273 seconds for one epoch ---
--- 2.044440269470215 seconds for one epoch ---
--- 0.29405689239501953 seconds for one epoch ---
--- 2.0122451782226562 seconds for one epoch ---
--- 0.30005431175231934 seconds for one epoch ---
--- 1.988551139831543 seconds for one epoch ---
--- 0.2945084571838379 seconds for one epoch ---
--- 1.9876480102539062 seconds for one epoch ---
--- 0.2961912155151367 seconds for one epoch ---
--- 1.9958596229553223 seconds for one epoch ---
--- 0.3015456199645996 seconds for one epoch ---
--- 1.985069751739502 seconds for one epoch ---
--- 0.2973761558532715 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8651993 ]
 [-0.71660703]
 [-0.60674036]
 [ 0.        ]
 [ 0.        ]
 [-0.5792122 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.882477  ]
 [-0.        ]]
--- 0.2623255252838135 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2641.213134765625, (1051.6973, 2.684035, 1585.652, 1.1798344)
   validation loss 845.7223510742188, (586.1744, 0.3577602, 258.01038, 1.1798344)
decoder loss ratio: 22709.413026, decoder SINDy loss  ratio: 0.556952
--- 0.2976365089416504 seconds for one epoch ---
--- 2.040788412094116 seconds for one epoch ---
--- 0.30619192123413086 seconds for one epoch ---
--- 2.034935235977173 seconds for one epoch ---
--- 0.30230236053466797 seconds for one epoch ---
--- 2.0243544578552246 seconds for one epoch ---
--- 0.29988789558410645 seconds for one epoch ---
--- 2.043288230895996 seconds for one epoch ---
--- 0.30113792419433594 seconds for one epoch ---
--- 2.035675525665283 seconds for one epoch ---
--- 0.290600061416626 seconds for one epoch ---
--- 2.0418994426727295 seconds for one epoch ---
--- 0.29688572883605957 seconds for one epoch ---
--- 2.0127053260803223 seconds for one epoch ---
--- 0.3017139434814453 seconds for one epoch ---
--- 1.9861385822296143 seconds for one epoch ---
--- 0.2895357608795166 seconds for one epoch ---
--- 1.9674437046051025 seconds for one epoch ---
--- 0.3004453182220459 seconds for one epoch ---
--- 1.9762661457061768 seconds for one epoch ---
--- 0.29689598083496094 seconds for one epoch ---
--- 2.0082027912139893 seconds for one epoch ---
--- 0.29613423347473145 seconds for one epoch ---
--- 2.016472339630127 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8727248]
 [-0.7188533]
 [-0.6024236]
 [ 0.       ]
 [-0.       ]
 [-0.5773368]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.888699 ]
 [-0.       ]]
--- 0.30606818199157715 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2240.902099609375, (1043.1403, 2.6422536, 1193.9396, 1.1799128)
   validation loss 774.9616088867188, (516.1174, 0.3620581, 257.30225, 1.1799128)
decoder loss ratio: 19995.282956, decoder SINDy loss  ratio: 0.555423
--- 0.2684791088104248 seconds for one epoch ---
--- 0.3329319953918457 seconds for one epoch ---
--- 2.044440746307373 seconds for one epoch ---
--- 0.29366326332092285 seconds for one epoch ---
--- 2.0442426204681396 seconds for one epoch ---
--- 0.29923224449157715 seconds for one epoch ---
--- 2.0501480102539062 seconds for one epoch ---
--- 0.30417561531066895 seconds for one epoch ---
--- 2.0383923053741455 seconds for one epoch ---
--- 0.2996664047241211 seconds for one epoch ---
--- 2.0266730785369873 seconds for one epoch ---
--- 0.30661964416503906 seconds for one epoch ---
--- 2.0525424480438232 seconds for one epoch ---
--- 0.3087162971496582 seconds for one epoch ---
--- 2.051405191421509 seconds for one epoch ---
--- 0.3015632629394531 seconds for one epoch ---
--- 2.0196263790130615 seconds for one epoch ---
--- 0.29143476486206055 seconds for one epoch ---
--- 2.0154764652252197 seconds for one epoch ---
--- 0.29778075218200684 seconds for one epoch ---
--- 2.0181727409362793 seconds for one epoch ---
--- 0.2983851432800293 seconds for one epoch ---
--- 2.0004212856292725 seconds for one epoch ---
--- 0.3060331344604492 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8772151 ]
 [-0.7260374 ]
 [-0.59988487]
 [-0.        ]
 [ 0.        ]
 [-0.572458  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.89333   ]
 [ 0.        ]]
--- 0.22993826866149902 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3767.035888671875, (1411.33, 2.1736684, 2352.3523, 1.1799958)
   validation loss 686.3650512695312, (451.29605, 0.38365844, 233.50537, 1.1799958)
decoder loss ratio: 17483.992501, decoder SINDy loss  ratio: 0.504054
--- 0.3018183708190918 seconds for one epoch ---
--- 2.0376546382904053 seconds for one epoch ---
--- 0.2969698905944824 seconds for one epoch ---
--- 2.048086404800415 seconds for one epoch ---
--- 0.29984569549560547 seconds for one epoch ---
--- 2.054032802581787 seconds for one epoch ---
--- 0.3022487163543701 seconds for one epoch ---
--- 2.0629465579986572 seconds for one epoch ---
--- 0.2963123321533203 seconds for one epoch ---
--- 2.04140567779541 seconds for one epoch ---
--- 0.29561758041381836 seconds for one epoch ---
--- 2.052633285522461 seconds for one epoch ---
--- 0.3040933609008789 seconds for one epoch ---
--- 2.061208724975586 seconds for one epoch ---
--- 0.30492711067199707 seconds for one epoch ---
--- 1.9913194179534912 seconds for one epoch ---
--- 0.298642635345459 seconds for one epoch ---
--- 1.9893345832824707 seconds for one epoch ---
--- 0.2883486747741699 seconds for one epoch ---
--- 2.0254135131835938 seconds for one epoch ---
--- 0.28092169761657715 seconds for one epoch ---
--- 2.006225109100342 seconds for one epoch ---
--- 0.30041956901550293 seconds for one epoch ---
--- 2.049074172973633 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8889968 ]
 [-0.7281386 ]
 [-0.6008946 ]
 [-0.        ]
 [ 0.        ]
 [-0.57594067]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.9026747 ]
 [ 0.        ]]
--- 0.31751585006713867 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1969.393310546875, (815.0829, 0.5429574, 1152.5873, 1.1801428)
   validation loss 904.3865356445312, (652.7686, 0.37028715, 250.06747, 1.1801428)
decoder loss ratio: 25289.389429, decoder SINDy loss  ratio: 0.539806
--- 0.28745436668395996 seconds for one epoch ---
--- 0.3205990791320801 seconds for one epoch ---
--- 2.096158742904663 seconds for one epoch ---
--- 0.33125734329223633 seconds for one epoch ---
--- 2.0965065956115723 seconds for one epoch ---
--- 0.29877471923828125 seconds for one epoch ---
--- 2.080291271209717 seconds for one epoch ---
--- 0.29753923416137695 seconds for one epoch ---
--- 2.077965497970581 seconds for one epoch ---
--- 0.2881326675415039 seconds for one epoch ---
--- 2.0848095417022705 seconds for one epoch ---
--- 0.29961681365966797 seconds for one epoch ---
--- 2.0760157108306885 seconds for one epoch ---
--- 0.3090860843658447 seconds for one epoch ---
--- 2.111003875732422 seconds for one epoch ---
--- 0.30513763427734375 seconds for one epoch ---
--- 2.067481517791748 seconds for one epoch ---
--- 0.29810237884521484 seconds for one epoch ---
--- 2.049393653869629 seconds for one epoch ---
--- 0.29862046241760254 seconds for one epoch ---
--- 2.0284557342529297 seconds for one epoch ---
--- 0.29450297355651855 seconds for one epoch ---
--- 2.058828115463257 seconds for one epoch ---
--- 0.31125450134277344 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8930871 ]
 [-0.7184821 ]
 [-0.60645527]
 [ 0.        ]
 [-0.        ]
 [-0.5705075 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.909005  ]
 [-0.        ]]
--- 0.26097774505615234 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2628.0458984375, (1008.6377, 3.708106, 1614.52, 1.1801704)
   validation loss 746.52587890625, (505.1526, 0.38935626, 239.80379, 1.1801704)
decoder loss ratio: 19570.488238, decoder SINDy loss  ratio: 0.517650
--- 0.2960219383239746 seconds for one epoch ---
--- 2.0390830039978027 seconds for one epoch ---
--- 0.311290979385376 seconds for one epoch ---
--- 2.069622755050659 seconds for one epoch ---
--- 0.29874467849731445 seconds for one epoch ---
--- 2.0784189701080322 seconds for one epoch ---
--- 0.2927992343902588 seconds for one epoch ---
--- 2.088873863220215 seconds for one epoch ---
--- 0.29209280014038086 seconds for one epoch ---
--- 2.06301212310791 seconds for one epoch ---
--- 0.29740047454833984 seconds for one epoch ---
--- 2.0500142574310303 seconds for one epoch ---
--- 0.30049896240234375 seconds for one epoch ---
--- 2.088783025741577 seconds for one epoch ---
--- 0.2997143268585205 seconds for one epoch ---
--- 2.064260721206665 seconds for one epoch ---
--- 0.30380797386169434 seconds for one epoch ---
--- 2.0364370346069336 seconds for one epoch ---
--- 0.296494722366333 seconds for one epoch ---
--- 2.045238733291626 seconds for one epoch ---
--- 0.2967844009399414 seconds for one epoch ---
--- 2.0315160751342773 seconds for one epoch ---
--- 0.6519510746002197 seconds for one epoch ---
--- 2.0291919708251953 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9023829 ]
 [-0.70561606]
 [-0.6036498 ]
 [ 0.        ]
 [ 0.        ]
 [-0.5692376 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.9188027 ]
 [-0.        ]]
--- 0.2932736873626709 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3968.33544921875, (1719.0321, 0.7594948, 2247.3635, 1.1802877)
   validation loss 670.670166015625, (438.44354, 0.38827333, 230.65808, 1.1802877)
decoder loss ratio: 16986.064007, decoder SINDy loss  ratio: 0.497908
--- 0.26065540313720703 seconds for one epoch ---
--- 0.29643797874450684 seconds for one epoch ---
--- 2.0918939113616943 seconds for one epoch ---
--- 0.3105947971343994 seconds for one epoch ---
--- 2.0702106952667236 seconds for one epoch ---
--- 0.29892611503601074 seconds for one epoch ---
--- 2.076040744781494 seconds for one epoch ---
--- 0.2896718978881836 seconds for one epoch ---
--- 2.078561305999756 seconds for one epoch ---
--- 0.2948296070098877 seconds for one epoch ---
--- 2.0860774517059326 seconds for one epoch ---
--- 0.2972714900970459 seconds for one epoch ---
--- 2.034738302230835 seconds for one epoch ---
--- 0.30074429512023926 seconds for one epoch ---
--- 2.0682334899902344 seconds for one epoch ---
--- 0.2862217426300049 seconds for one epoch ---
--- 2.124833106994629 seconds for one epoch ---
--- 0.29039430618286133 seconds for one epoch ---
--- 2.044938087463379 seconds for one epoch ---
--- 0.2922787666320801 seconds for one epoch ---
--- 2.053658962249756 seconds for one epoch ---
--- 0.2902226448059082 seconds for one epoch ---
--- 2.043972969055176 seconds for one epoch ---
--- 0.2960233688354492 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9086933]
 [-0.7041025]
 [-0.6046016]
 [-0.       ]
 [-0.       ]
 [-0.5696904]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.922194 ]
 [ 0.       ]]
--- 0.25899434089660645 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2186.285888671875, (966.0667, 0.7698716, 1218.2689, 1.1803483)
   validation loss 686.1358032226562, (446.14648, 0.39414486, 238.41486, 1.1803483)
decoder loss ratio: 17284.489349, decoder SINDy loss  ratio: 0.514652
--- 0.29392409324645996 seconds for one epoch ---
--- 2.147296905517578 seconds for one epoch ---
--- 0.3082106113433838 seconds for one epoch ---
--- 2.1211729049682617 seconds for one epoch ---
--- 0.30591607093811035 seconds for one epoch ---
--- 2.104875326156616 seconds for one epoch ---
--- 0.3051414489746094 seconds for one epoch ---
--- 2.0456960201263428 seconds for one epoch ---
--- 0.29855799674987793 seconds for one epoch ---
--- 2.099684476852417 seconds for one epoch ---
--- 0.3135838508605957 seconds for one epoch ---
--- 2.078806161880493 seconds for one epoch ---
--- 0.3116767406463623 seconds for one epoch ---
--- 2.0958569049835205 seconds for one epoch ---
--- 0.29296135902404785 seconds for one epoch ---
--- 2.1211493015289307 seconds for one epoch ---
--- 0.2951977252960205 seconds for one epoch ---
--- 2.0972652435302734 seconds for one epoch ---
--- 0.28853392601013184 seconds for one epoch ---
--- 2.047451972961426 seconds for one epoch ---
--- 0.300156831741333 seconds for one epoch ---
--- 2.0669076442718506 seconds for one epoch ---
--- 0.293046236038208 seconds for one epoch ---
--- 2.067681074142456 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9145677 ]
 [-0.714336  ]
 [-0.6021083 ]
 [-0.        ]
 [-0.        ]
 [-0.56958646]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.9285355 ]
 [ 0.        ]]
--- 0.3045945167541504 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3020.110107421875, (1203.9752, 3.350736, 1811.6038, 1.1804137)
   validation loss 718.2957763671875, (455.7726, 0.3843978, 260.95837, 1.1804137)
decoder loss ratio: 17657.422304, decoder SINDy loss  ratio: 0.563315
--- 0.26728200912475586 seconds for one epoch ---
--- 0.2879483699798584 seconds for one epoch ---
--- 2.1388630867004395 seconds for one epoch ---
--- 0.28724217414855957 seconds for one epoch ---
--- 2.1179616451263428 seconds for one epoch ---
--- 0.2981729507446289 seconds for one epoch ---
--- 2.1503899097442627 seconds for one epoch ---
--- 0.30666327476501465 seconds for one epoch ---
--- 2.1166815757751465 seconds for one epoch ---
--- 0.3010401725769043 seconds for one epoch ---
--- 2.1476354598999023 seconds for one epoch ---
--- 0.3190782070159912 seconds for one epoch ---
--- 2.12420392036438 seconds for one epoch ---
--- 0.3166689872741699 seconds for one epoch ---
--- 2.151029109954834 seconds for one epoch ---
--- 0.2986266613006592 seconds for one epoch ---
--- 2.1532251834869385 seconds for one epoch ---
--- 0.29190754890441895 seconds for one epoch ---
--- 2.1581931114196777 seconds for one epoch ---
--- 0.30716371536254883 seconds for one epoch ---
--- 2.0910141468048096 seconds for one epoch ---
--- 0.29133009910583496 seconds for one epoch ---
--- 2.0942463874816895 seconds for one epoch ---
--- 0.2931098937988281 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9208705 ]
 [-0.7278742 ]
 [-0.60456854]
 [ 0.        ]
 [-0.        ]
 [-0.5654524 ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.935759  ]
 [-0.        ]]
--- 0.2742018699645996 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3913.977294921875, (1823.724, 4.4492726, 2084.6235, 1.1805003)
   validation loss 816.1200561523438, (565.6175, 0.3861803, 248.93591, 1.1805003)
decoder loss ratio: 21913.003621, decoder SINDy loss  ratio: 0.537363
--- 0.29200124740600586 seconds for one epoch ---
--- 2.1350467205047607 seconds for one epoch ---
--- 0.3215909004211426 seconds for one epoch ---
--- 2.1559951305389404 seconds for one epoch ---
--- 0.3204519748687744 seconds for one epoch ---
--- 2.159818410873413 seconds for one epoch ---
--- 0.2894737720489502 seconds for one epoch ---
--- 2.1100995540618896 seconds for one epoch ---
--- 0.2958822250366211 seconds for one epoch ---
--- 2.1079461574554443 seconds for one epoch ---
--- 0.2857816219329834 seconds for one epoch ---
--- 2.094714403152466 seconds for one epoch ---
--- 0.2913022041320801 seconds for one epoch ---
--- 2.1106979846954346 seconds for one epoch ---
--- 0.29911088943481445 seconds for one epoch ---
--- 2.1352951526641846 seconds for one epoch ---
--- 0.2991964817047119 seconds for one epoch ---
--- 2.1080574989318848 seconds for one epoch ---
--- 0.2959926128387451 seconds for one epoch ---
--- 2.0862975120544434 seconds for one epoch ---
--- 0.30057835578918457 seconds for one epoch ---
--- 2.0741121768951416 seconds for one epoch ---
--- 0.3023808002471924 seconds for one epoch ---
--- 2.105506181716919 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9394019 ]
 [-0.7302576 ]
 [-0.60019124]
 [ 0.        ]
 [ 0.        ]
 [-0.5725842 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.95273   ]
 [-0.        ]]
--- 0.29001426696777344 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2492.041748046875, (1062.1666, 0.35237718, 1428.342, 1.180734)
   validation loss 934.1541137695312, (668.1191, 0.3612932, 264.493, 1.180734)
decoder loss ratio: 25884.093049, decoder SINDy loss  ratio: 0.570945
--- 0.9968307018280029 seconds for one epoch ---
--- 0.30298376083374023 seconds for one epoch ---
--- 2.126575469970703 seconds for one epoch ---
--- 0.28585100173950195 seconds for one epoch ---
--- 2.125969886779785 seconds for one epoch ---
--- 0.2996809482574463 seconds for one epoch ---
--- 2.163844108581543 seconds for one epoch ---
--- 0.30301952362060547 seconds for one epoch ---
--- 2.1272709369659424 seconds for one epoch ---
--- 0.3029160499572754 seconds for one epoch ---
--- 2.1201775074005127 seconds for one epoch ---
--- 0.3151106834411621 seconds for one epoch ---
--- 2.126132011413574 seconds for one epoch ---
--- 0.2925302982330322 seconds for one epoch ---
--- 2.119112968444824 seconds for one epoch ---
--- 0.3013441562652588 seconds for one epoch ---
--- 2.14105486869812 seconds for one epoch ---
--- 0.2980525493621826 seconds for one epoch ---
--- 2.153822422027588 seconds for one epoch ---
--- 0.3061974048614502 seconds for one epoch ---
--- 2.099088430404663 seconds for one epoch ---
--- 0.2905240058898926 seconds for one epoch ---
--- 2.0760445594787598 seconds for one epoch ---
--- 0.2983274459838867 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999475]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9448273 ]
 [-0.7189784 ]
 [-0.6001952 ]
 [-0.        ]
 [-0.        ]
 [-0.56976116]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.957146  ]
 [ 0.        ]]
--- 0.26453065872192383 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3111.019775390625, (1604.8373, 0.9001751, 1504.1014, 1.1808219)
   validation loss 770.1271362304688, (522.86664, 0.3844444, 245.69519, 1.1808219)
decoder loss ratio: 20256.761300, decoder SINDy loss  ratio: 0.530368
--- 0.2993812561035156 seconds for one epoch ---
--- 2.140392780303955 seconds for one epoch ---
--- 0.29216766357421875 seconds for one epoch ---
--- 2.1525299549102783 seconds for one epoch ---
--- 0.3050236701965332 seconds for one epoch ---
--- 2.1417906284332275 seconds for one epoch ---
--- 0.2978038787841797 seconds for one epoch ---
--- 2.166933059692383 seconds for one epoch ---
--- 0.29999852180480957 seconds for one epoch ---
--- 2.1796438694000244 seconds for one epoch ---
--- 0.3053417205810547 seconds for one epoch ---
--- 2.178715467453003 seconds for one epoch ---
--- 0.28899693489074707 seconds for one epoch ---
--- 2.14996075630188 seconds for one epoch ---
--- 0.2981839179992676 seconds for one epoch ---
--- 2.178724527359009 seconds for one epoch ---
--- 0.2983584403991699 seconds for one epoch ---
--- 2.2136929035186768 seconds for one epoch ---
--- 0.29877448081970215 seconds for one epoch ---
--- 2.167147159576416 seconds for one epoch ---
--- 0.30489301681518555 seconds for one epoch ---
--- 2.1366658210754395 seconds for one epoch ---
--- 0.2947726249694824 seconds for one epoch ---
--- 2.1268980503082275 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999994 ]
 [0.        ]
 [0.        ]
 [0.99999774]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9632351 ]
 [-0.7163322 ]
 [-0.60514957]
 [-0.        ]
 [ 0.        ]
 [-0.5742165 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.9742928 ]
 [ 0.        ]]
--- 0.2995889186859131 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2921.781494140625, (1633.4658, 3.976132, 1283.1588, 1.1810262)
   validation loss 805.7608642578125, (543.7238, 0.39039943, 260.46567, 1.1810262)
decoder loss ratio: 21064.804575, decoder SINDy loss  ratio: 0.562252
--- 0.2642781734466553 seconds for one epoch ---
--- 0.29726171493530273 seconds for one epoch ---
--- 2.1702640056610107 seconds for one epoch ---
--- 0.28949522972106934 seconds for one epoch ---
--- 2.1473140716552734 seconds for one epoch ---
--- 0.30181217193603516 seconds for one epoch ---
--- 2.1426210403442383 seconds for one epoch ---
--- 0.3076150417327881 seconds for one epoch ---
--- 2.1558053493499756 seconds for one epoch ---
--- 0.30818629264831543 seconds for one epoch ---
--- 2.146155595779419 seconds for one epoch ---
--- 0.3054623603820801 seconds for one epoch ---
--- 2.164743423461914 seconds for one epoch ---
--- 0.2871713638305664 seconds for one epoch ---
--- 2.141947031021118 seconds for one epoch ---
--- 0.29816627502441406 seconds for one epoch ---
--- 2.156870126724243 seconds for one epoch ---
--- 0.3131551742553711 seconds for one epoch ---
--- 2.191563844680786 seconds for one epoch ---
--- 0.3120229244232178 seconds for one epoch ---
--- 2.111940860748291 seconds for one epoch ---
--- 0.29760074615478516 seconds for one epoch ---
--- 2.117629051208496 seconds for one epoch ---
--- 0.30286192893981934 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99999464]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9711013 ]
 [-0.7063388 ]
 [-0.60931265]
 [ 0.        ]
 [ 0.        ]
 [-0.5700076 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.983742  ]
 [-0.        ]]
--- 0.29311442375183105 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3308.2255859375, (1756.5701, 3.8348367, 1546.6396, 1.1811166)
   validation loss 818.7139282226562, (558.17566, 0.42282948, 258.9343, 1.1811166)
decoder loss ratio: 21624.694072, decoder SINDy loss  ratio: 0.558946
--- 0.289783239364624 seconds for one epoch ---
--- 2.167306661605835 seconds for one epoch ---
--- 0.2959566116333008 seconds for one epoch ---
--- 2.1900148391723633 seconds for one epoch ---
--- 0.3211205005645752 seconds for one epoch ---
--- 2.1836185455322266 seconds for one epoch ---
--- 0.3063499927520752 seconds for one epoch ---
--- 2.1473376750946045 seconds for one epoch ---
--- 0.30910611152648926 seconds for one epoch ---
--- 2.213894844055176 seconds for one epoch ---
--- 0.3043067455291748 seconds for one epoch ---
--- 2.191986322402954 seconds for one epoch ---
--- 0.29901123046875 seconds for one epoch ---
--- 2.1857540607452393 seconds for one epoch ---
--- 0.27741456031799316 seconds for one epoch ---
--- 2.1846721172332764 seconds for one epoch ---
--- 0.2995798587799072 seconds for one epoch ---
--- 2.217097759246826 seconds for one epoch ---
--- 0.30275964736938477 seconds for one epoch ---
--- 2.1887717247009277 seconds for one epoch ---
--- 0.30502891540527344 seconds for one epoch ---
--- 2.1541266441345215 seconds for one epoch ---
--- 0.2942471504211426 seconds for one epoch ---
--- 2.164038896560669 seconds for one epoch ---
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.970443  ]
 [-0.6955048 ]
 [-0.61042166]
 [ 0.        ]
 [-0.        ]
 [-0.5614121 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.9857726 ]
 [-0.        ]]
--- 0.2938079833984375 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2227.2060546875, (1561.0001, 2.8185616, 662.2063, 1.1811324)
   validation loss 780.3153076171875, (532.377, 0.48313075, 246.274, 1.1811324)
decoder loss ratio: 20625.209776, decoder SINDy loss  ratio: 0.531617
THRESHOLDING: 5 active coefficients
REFINEMENT
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9710302 ]
 [-0.69581115]
 [-0.6093282 ]
 [-0.        ]
 [-0.        ]
 [-0.56288475]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.9842434 ]
 [ 0.        ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1153.044677734375, (610.36426, 0.4753926, 542.205, 1.1810956)
   validation loss 747.1307983398438, (498.84647, 0.2715595, 248.01279, 1.1810956)
decoder loss ratio: 19326.178131, decoder SINDy loss  ratio: 0.535370
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9458122]
 [-0.7948304]
 [-0.5825951]
 [-0.       ]
 [ 0.       ]
 [-0.5079403]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.891429 ]
 [-0.       ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 895.9166870117188, (381.25308, 0.23752248, 514.4261, 1.1809012)
   validation loss 552.5946044921875, (332.4686, 0.3002337, 219.82578, 1.1809012)
decoder loss ratio: 12880.410655, decoder SINDy loss  ratio: 0.474525
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99998313]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9122307 ]
 [-0.6436013 ]
 [-0.5968518 ]
 [ 0.        ]
 [-0.        ]
 [-0.59250987]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.9075184 ]
 [ 0.        ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.3955078125, (288.0154, 0.2304227, 508.14966, 1.1796807)
   validation loss 444.70611572265625, (231.23712, 0.22314331, 213.24585, 1.1796807)
decoder loss ratio: 8958.527535, decoder SINDy loss  ratio: 0.460321
=========================
[[1.        ]
 [0.99999166]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.9999794 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8705552 ]
 [-0.54467267]
 [-0.54400957]
 [-0.        ]
 [-0.        ]
 [-0.5093936 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.7888374 ]
 [-0.        ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1274.3876953125, (727.78394, 0.3036673, 546.3002, 1.1784014)
   validation loss 840.3624877929688, (613.7891, 0.17698117, 226.39635, 1.1784014)
decoder loss ratio: 23779.256231, decoder SINDy loss  ratio: 0.488708
=========================
[[1.       ]
 [0.9999846]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999794]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.7364962 ]
 [-0.48185217]
 [-0.6357223 ]
 [-0.        ]
 [-0.        ]
 [-0.4517865 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.564245  ]
 [-0.        ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 986.0269775390625, (485.3322, 0.27733952, 500.41742, 1.1772141)
   validation loss 645.2514038085938, (426.69666, 0.15741242, 218.39732, 1.1772141)
decoder loss ratio: 16530.969203, decoder SINDy loss  ratio: 0.471441
=========================
[[1.        ]
 [0.99998295]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.9999794 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.69481   ]
 [-0.45222485]
 [-0.6577388 ]
 [ 0.        ]
 [ 0.        ]
 [-0.49456134]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-4.4185376 ]
 [-0.        ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.2583618164062, (281.75717, 0.2966026, 497.2046, 1.1761433)
   validation loss 427.562744140625, (219.03261, 0.14560178, 208.38455, 1.1761433)
decoder loss ratio: 8485.703492, decoder SINDy loss  ratio: 0.449827
=========================
[[1.        ]
 [0.99998116]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.9999813 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7814455 ]
 [-0.56307065]
 [-0.49295574]
 [-0.        ]
 [-0.        ]
 [-0.5604034 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.292023  ]
 [ 0.        ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 923.1920776367188, (428.86478, 0.29956463, 494.02774, 1.1752557)
   validation loss 585.6915283203125, (370.2345, 0.13439785, 215.32266, 1.1752557)
decoder loss ratio: 14343.527172, decoder SINDy loss  ratio: 0.464804
=========================
[[1.        ]
 [0.9999869 ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998116]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6420693 ]
 [-0.565377  ]
 [-0.6189137 ]
 [ 0.        ]
 [-0.        ]
 [-0.49450547]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.2877727 ]
 [-0.        ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 874.1436767578125, (381.59937, 0.32491386, 492.21936, 1.1744443)
   validation loss 530.3699951171875, (318.05145, 0.12690108, 212.19167, 1.1744443)
decoder loss ratio: 12321.865437, decoder SINDy loss  ratio: 0.458046
=========================
[[1.        ]
 [0.9999877 ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998116]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6353662 ]
 [-0.52906525]
 [-0.6190707 ]
 [-0.        ]
 [-0.        ]
 [-0.41998285]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.156171  ]
 [-0.        ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.5470581054688, (307.48627, 0.3380414, 490.72275, 1.1736764)
   validation loss 454.7005615234375, (244.89061, 0.13008645, 209.67989, 1.1736764)
decoder loss ratio: 9487.487370, decoder SINDy loss  ratio: 0.452624
=========================
[[1.        ]
 [0.99999166]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998176]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6351192 ]
 [-0.55277395]
 [-0.6554643 ]
 [-0.        ]
 [ 0.        ]
 [-0.49039692]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-4.0660963 ]
 [-0.        ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.7523193359375, (409.7141, 0.33302426, 490.70514, 1.1730165)
   validation loss 558.1699829101562, (344.3499, 0.13118199, 213.68889, 1.1730165)
decoder loss ratio: 13340.713507, decoder SINDy loss  ratio: 0.461278
=========================
[[1.        ]
 [0.99999166]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6170964 ]
 [-0.6420793 ]
 [-0.63460845]
 [-0.        ]
 [-0.        ]
 [-0.5024983 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.097462  ]
 [ 0.        ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.0260009765625, (338.21982, 0.36137235, 511.44485, 1.172461)
   validation loss 468.33544921875, (256.77936, 0.12822022, 211.42784, 1.172461)
decoder loss ratio: 9948.078114, decoder SINDy loss  ratio: 0.456397
=========================
[[1.       ]
 [0.9999975]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6526663 ]
 [-0.5605677 ]
 [-0.6054286 ]
 [ 0.        ]
 [ 0.        ]
 [-0.55202156]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.9578192 ]
 [ 0.        ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.3187866210938, (285.33203, 0.40597582, 491.58078, 1.1719936)
   validation loss 440.4496765136719, (231.3933, 0.14383367, 208.91255, 1.1719936)
decoder loss ratio: 8964.577976, decoder SINDy loss  ratio: 0.450967
=========================
[[1.       ]
 [0.9999993]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999839]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6211152 ]
 [-0.6301817 ]
 [-0.6302638 ]
 [-0.        ]
 [ 0.        ]
 [-0.48948517]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.8734646 ]
 [ 0.        ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1294.613037109375, (798.7912, 0.3409204, 495.48093, 1.171508)
   validation loss 958.747802734375, (730.82983, 0.14416698, 227.77379, 1.171508)
decoder loss ratio: 28313.616545, decoder SINDy loss  ratio: 0.491682
=========================
[[1.       ]
 [0.9999993]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.999984 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5245438]
 [-0.6036695]
 [-0.6475324]
 [ 0.       ]
 [-0.       ]
 [-0.5161409]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7749119]
 [ 0.       ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.03515625, (255.79303, 0.35978684, 493.8824, 1.1711141)
   validation loss 398.70391845703125, (188.51309, 0.13302577, 210.05782, 1.1711141)
decoder loss ratio: 7303.324459, decoder SINDy loss  ratio: 0.453439
=========================
[[1.        ]
 [0.9999993 ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5367825 ]
 [-0.5968947 ]
 [-0.67282504]
 [ 0.        ]
 [-0.        ]
 [-0.49512702]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.7260876 ]
 [-0.        ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.912109375, (281.58493, 0.36516002, 496.962, 1.1708239)
   validation loss 427.5830383300781, (217.1038, 0.13963313, 210.3396, 1.1708239)
decoder loss ratio: 8410.978335, decoder SINDy loss  ratio: 0.454048
=========================
[[1.       ]
 [0.9999993]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4359179 ]
 [-0.61016846]
 [-0.6876919 ]
 [ 0.        ]
 [ 0.        ]
 [-0.56886345]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.6919801 ]
 [-0.        ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 889.8783569335938, (403.53275, 0.3375725, 486.00803, 1.1705015)
   validation loss 551.3219604492188, (335.92294, 0.14479099, 215.2542, 1.1705015)
decoder loss ratio: 13014.238004, decoder SINDy loss  ratio: 0.464656
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998546]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5105147 ]
 [-0.58508515]
 [-0.6130294 ]
 [ 0.        ]
 [-0.        ]
 [-0.5497154 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.615789  ]
 [ 0.        ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.9690551757812, (246.58572, 0.36033425, 490.023, 1.1702679)
   validation loss 394.54998779296875, (184.15541, 0.1485741, 210.24599, 1.1702679)
decoder loss ratio: 7134.500321, decoder SINDy loss  ratio: 0.453846
=========================
[[1.       ]
 [0.9999993]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4842825]
 [-0.6374852]
 [-0.596927 ]
 [-0.       ]
 [ 0.       ]
 [-0.6098206]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.6012852]
 [-0.       ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 875.84033203125, (392.8364, 0.3324497, 482.67148, 1.1700351)
   validation loss 540.7048950195312, (327.0628, 0.15455636, 213.4875, 1.1700351)
decoder loss ratio: 12670.980879, decoder SINDy loss  ratio: 0.460843
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5642805]
 [-0.6650232]
 [-0.6814208]
 [-0.       ]
 [ 0.       ]
 [-0.4832014]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-3.5985134]
 [-0.       ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1445.41650390625, (887.8901, 0.39953423, 557.12683, 1.1698478)
   validation loss 990.8933715820312, (751.91284, 0.1490474, 238.83147, 1.1698478)
decoder loss ratio: 29130.408869, decoder SINDy loss  ratio: 0.515551
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999844]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4972866]
 [-0.5724866]
 [-0.6599784]
 [ 0.       ]
 [ 0.       ]
 [-0.4478665]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.5875926]
 [ 0.       ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.0418701171875, (245.8691, 0.33879048, 487.83398, 1.1696692)
   validation loss 392.51409912109375, (179.9677, 0.15783112, 212.38857, 1.1696692)
decoder loss ratio: 6972.261025, decoder SINDy loss  ratio: 0.458471
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5699513 ]
 [-0.6454178 ]
 [-0.59445554]
 [-0.        ]
 [ 0.        ]
 [-0.5644606 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.548736  ]
 [ 0.        ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.106201171875, (347.54932, 0.34230456, 482.21457, 1.1695623)
   validation loss 503.25823974609375, (288.46497, 0.15439744, 214.63889, 1.1695623)
decoder loss ratio: 11175.633573, decoder SINDy loss  ratio: 0.463328
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4743679]
 [-0.4939863]
 [-0.5870368]
 [-0.       ]
 [-0.       ]
 [-0.5053225]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.522325 ]
 [ 0.       ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.0172729492188, (242.5409, 0.35389605, 488.1225, 1.1694467)
   validation loss 395.07421875, (182.0354, 0.16212694, 212.87671, 1.1694467)
decoder loss ratio: 7052.367438, decoder SINDy loss  ratio: 0.459524
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4466293 ]
 [-0.71059704]
 [-0.6121461 ]
 [ 0.        ]
 [-0.        ]
 [-0.52761644]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.4433978 ]
 [-0.        ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 993.8163452148438, (510.97083, 0.3265644, 482.51895, 1.1693478)
   validation loss 653.3009643554688, (433.43402, 0.16585867, 219.7011, 1.1693478)
decoder loss ratio: 16791.986448, decoder SINDy loss  ratio: 0.474256
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4675786 ]
 [-0.6513678 ]
 [-0.61755335]
 [-0.        ]
 [ 0.        ]
 [-0.55000025]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.4339316 ]
 [-0.        ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.6544799804688, (240.68408, 0.34429175, 483.6261, 1.169272)
   validation loss 390.0956115722656, (177.09969, 0.1673187, 212.82861, 1.169272)
decoder loss ratio: 6861.149281, decoder SINDy loss  ratio: 0.459420
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999846]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5934744 ]
 [-0.646362  ]
 [-0.59043515]
 [ 0.        ]
 [ 0.        ]
 [-0.52154106]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.395936  ]
 [-0.        ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2016.27099609375, (1502.4203, 0.32141772, 513.52924, 1.1692339)
   validation loss 1632.0562744140625, (1379.8717, 0.17593896, 252.00862, 1.1692339)
decoder loss ratio: 53458.625380, decoder SINDy loss  ratio: 0.543996
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999844]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.4825165 ]
 [-0.60958165]
 [-0.59321386]
 [ 0.        ]
 [ 0.        ]
 [-0.47079954]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.4649093 ]
 [-0.        ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 929.410400390625, (411.79352, 0.33548975, 517.2814, 1.1691548)
   validation loss 534.9929809570312, (310.78772, 0.17566256, 224.02959, 1.1691548)
decoder loss ratio: 12040.455813, decoder SINDy loss  ratio: 0.483599
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999844]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.562434  ]
 [-0.735102  ]
 [-0.57437724]
 [ 0.        ]
 [ 0.        ]
 [-0.47592038]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3823411 ]
 [-0.        ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 884.746826171875, (406.40338, 0.32732853, 478.01614, 1.169125)
   validation loss 553.4368286132812, (335.7727, 0.17687044, 217.48726, 1.169125)
decoder loss ratio: 13008.417522, decoder SINDy loss  ratio: 0.469477
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.549956  ]
 [-0.604849  ]
 [-0.68626267]
 [ 0.        ]
 [ 0.        ]
 [-0.44833744]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.42456   ]
 [ 0.        ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.4608154296875, (287.14584, 0.3342923, 474.98065, 1.1691049)
   validation loss 433.27264404296875, (219.58092, 0.17843962, 213.51329, 1.1691049)
decoder loss ratio: 8506.945948, decoder SINDy loss  ratio: 0.460898
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999851]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.5904877 ]
 [-0.571331  ]
 [-0.57218754]
 [-0.        ]
 [-0.        ]
 [-0.51186705]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3991573 ]
 [-0.        ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.3546752929688, (245.77489, 0.33901376, 477.24078, 1.169089)
   validation loss 396.62347412109375, (182.72198, 0.18342967, 213.71806, 1.169089)
decoder loss ratio: 7078.966913, decoder SINDy loss  ratio: 0.461341
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6098971 ]
 [-0.6318844 ]
 [-0.63076246]
 [ 0.        ]
 [ 0.        ]
 [-0.46214557]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.289873  ]
 [-0.        ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1198.88232421875, (717.6651, 0.3360189, 480.88123, 1.169087)
   validation loss 856.5912475585938, (631.21136, 0.17740332, 225.20245, 1.169087)
decoder loss ratio: 24454.224101, decoder SINDy loss  ratio: 0.486131
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998313]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5953884]
 [-0.5978056]
 [-0.6301784]
 [ 0.       ]
 [-0.       ]
 [-0.5290994]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.3973584]
 [-0.       ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.6417236328125, (288.70898, 0.31823045, 495.61447, 1.1690476)
   validation loss 433.67449951171875, (213.22855, 0.18936679, 220.25658, 1.1690476)
decoder loss ratio: 8260.844059, decoder SINDy loss  ratio: 0.475455
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7038767 ]
 [-0.66002077]
 [-0.66602373]
 [ 0.        ]
 [ 0.        ]
 [-0.50551575]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.4382665 ]
 [ 0.        ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 932.7261352539062, (456.15576, 0.3158245, 476.25455, 1.1690524)
   validation loss 594.4783325195312, (374.78864, 0.18935996, 219.50035, 1.1690524)
decoder loss ratio: 14519.962391, decoder SINDy loss  ratio: 0.473822
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999839]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6035128 ]
 [-0.6599002 ]
 [-0.6744572 ]
 [ 0.        ]
 [ 0.        ]
 [-0.47522625]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3735533 ]
 [ 0.        ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 825.2882690429688, (325.86734, 0.3117095, 499.10922, 1.1690477)
   validation loss 463.98577880859375, (242.41585, 0.19031352, 221.37961, 1.1690477)
decoder loss ratio: 9391.610795, decoder SINDy loss  ratio: 0.477879
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998295]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.5955062 ]
 [-0.6828624 ]
 [-0.56184506]
 [-0.        ]
 [-0.        ]
 [-0.48811096]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.3157947 ]
 [-0.        ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.6656494140625, (243.99825, 0.30113828, 475.36627, 1.1690657)
   validation loss 400.7024230957031, (184.16333, 0.19298957, 216.3461, 1.1690657)
decoder loss ratio: 7134.807129, decoder SINDy loss  ratio: 0.467013
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998313]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7152817 ]
 [-0.60253793]
 [-0.57266283]
 [-0.        ]
 [-0.        ]
 [-0.53363156]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.3002865 ]
 [ 0.        ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 805.093017578125, (334.0294, 0.30098113, 470.76263, 1.1690744)
   validation loss 478.53570556640625, (261.62402, 0.19728152, 216.71437, 1.1690744)
decoder loss ratio: 10135.768867, decoder SINDy loss  ratio: 0.467808
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6789804]
 [-0.6952303]
 [-0.6814476]
 [-0.       ]
 [ 0.       ]
 [-0.5960397]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3182564]
 [-0.       ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.5521850585938, (245.62344, 0.32289466, 471.60587, 1.1690814)
   validation loss 395.3763427734375, (180.06284, 0.20315214, 215.11035, 1.1690814)
decoder loss ratio: 6975.946858, decoder SINDy loss  ratio: 0.464346
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998486]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.687612  ]
 [-0.62931174]
 [-0.6422032 ]
 [ 0.        ]
 [-0.        ]
 [-0.5472491 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.307088  ]
 [-0.        ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.9312133789062, (241.47675, 0.372487, 475.08197, 1.1691349)
   validation loss 394.0069580078125, (177.97498, 0.20588857, 215.82611, 1.1691349)
decoder loss ratio: 6895.059532, decoder SINDy loss  ratio: 0.465891
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999827]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6908689 ]
 [-0.69365454]
 [-0.6198012 ]
 [-0.        ]
 [ 0.        ]
 [-0.5269471 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.1942832 ]
 [-0.        ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 937.461181640625, (438.17126, 0.33403027, 498.95584, 1.1691049)
   validation loss 593.6637573242188, (367.12094, 0.20352858, 226.33931, 1.1691049)
decoder loss ratio: 14222.902611, decoder SINDy loss  ratio: 0.488585
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999844]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.712753 ]
 [-0.6720161]
 [-0.6665535]
 [ 0.       ]
 [ 0.       ]
 [-0.5355517]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2711482]
 [ 0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.345947265625, (257.28238, 0.3666116, 479.697, 1.1691738)
   validation loss 416.3213195800781, (198.27199, 0.20567411, 217.84366, 1.1691738)
decoder loss ratio: 7681.401027, decoder SINDy loss  ratio: 0.470246
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998176]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.6842635 ]
 [-0.6400799 ]
 [-0.66546315]
 [-0.        ]
 [ 0.        ]
 [-0.51053345]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.2256894 ]
 [ 0.        ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.3329467773438, (262.84186, 0.31193623, 483.17914, 1.1691483)
   validation loss 420.7621765136719, (199.5697, 0.21166308, 220.9808, 1.1691483)
decoder loss ratio: 7731.676729, decoder SINDy loss  ratio: 0.477018
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99998295]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7477305 ]
 [-0.7137888 ]
 [-0.6510717 ]
 [ 0.        ]
 [-0.        ]
 [-0.56784266]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.2126791 ]
 [ 0.        ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1217.0921630859375, (681.94666, 0.37192544, 534.77356, 1.1691957)
   validation loss 806.0848388671875, (565.2211, 0.2121833, 240.65158, 1.1691957)
decoder loss ratio: 21897.647858, decoder SINDy loss  ratio: 0.519480
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999807]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.6388326 ]
 [-0.57913333]
 [-0.63743937]
 [ 0.        ]
 [-0.        ]
 [-0.46451056]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.137748  ]
 [ 0.        ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 908.53466796875, (439.18347, 0.29308638, 469.05814, 1.1691947)
   validation loss 576.396728515625, (355.8128, 0.21263325, 220.37126, 1.1691947)
decoder loss ratio: 13784.805791, decoder SINDy loss  ratio: 0.475702
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999807]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.7502348 ]
 [-0.7002131 ]
 [-0.5980773 ]
 [-0.        ]
 [ 0.        ]
 [-0.49956897]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.1825361 ]
 [-0.        ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.4579467773438, (270.887, 0.29806298, 465.2729, 1.1691979)
   validation loss 417.1845397949219, (201.26978, 0.21366684, 215.7011, 1.1691979)
decoder loss ratio: 7797.540518, decoder SINDy loss  ratio: 0.465621
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998355]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7528703 ]
 [-0.64066935]
 [-0.57513136]
 [ 0.        ]
 [-0.        ]
 [-0.5225104 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.1592436 ]
 [ 0.        ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.0169677734375, (236.62892, 0.32904214, 467.059, 1.1692414)
   validation loss 391.96636962890625, (175.85655, 0.21607155, 215.89377, 1.1692414)
decoder loss ratio: 6812.988130, decoder SINDy loss  ratio: 0.466037
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99998236]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.785508 ]
 [-0.6340174]
 [-0.5595369]
 [-0.       ]
 [-0.       ]
 [-0.6045896]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.223421 ]
 [ 0.       ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1700.0478515625, (1116.1201, 0.3959493, 583.5318, 1.1692586)
   validation loss 1221.440185546875, (956.411, 0.21983093, 264.8094, 1.1692586)
decoder loss ratio: 37053.022959, decoder SINDy loss  ratio: 0.571628
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999796]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8112347 ]
 [-0.6700278 ]
 [-0.6298279 ]
 [ 0.        ]
 [-0.        ]
 [-0.49095094]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.0941498 ]
 [-0.        ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.660888671875, (293.6976, 0.29656497, 464.66675, 1.1692251)
   validation loss 444.26025390625, (226.642, 0.21826705, 217.39998, 1.1692251)
decoder loss ratio: 8780.504482, decoder SINDy loss  ratio: 0.469288
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999796]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.779185  ]
 [-0.60882914]
 [-0.62739235]
 [-0.        ]
 [ 0.        ]
 [-0.544013  ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.2139587 ]
 [ 0.        ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.9508056640625, (331.2358, 0.28277203, 463.43222, 1.1692322)
   validation loss 477.2841491699219, (259.01553, 0.21475434, 218.05386, 1.1692322)
decoder loss ratio: 10034.711436, decoder SINDy loss  ratio: 0.470700
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999794]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.779517 ]
 [-0.6710238]
 [-0.6116557]
 [ 0.       ]
 [ 0.       ]
 [-0.547123 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1831005]
 [-0.       ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.11767578125, (255.94589, 0.29675636, 462.87506, 1.169228)
   validation loss 404.6726989746094, (187.81464, 0.2234277, 216.63463, 1.169228)
decoder loss ratio: 7276.265068, decoder SINDy loss  ratio: 0.467636
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999815]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8001947 ]
 [-0.6379532 ]
 [-0.62214494]
 [-0.        ]
 [ 0.        ]
 [-0.55143064]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.1750858 ]
 [ 0.        ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.8941040039062, (232.2626, 0.3184629, 468.31305, 1.1692411)
   validation loss 389.92138671875, (172.39157, 0.22169675, 217.30814, 1.1692411)
decoder loss ratio: 6678.748747, decoder SINDy loss  ratio: 0.469090
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999795]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8279037]
 [-0.6905027]
 [-0.589004 ]
 [-0.       ]
 [ 0.       ]
 [-0.5506179]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.1407895]
 [-0.       ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 953.8319091796875, (458.57654, 0.31731787, 494.93802, 1.1692282)
   validation loss 631.6619873046875, (400.46652, 0.22998498, 230.96548, 1.1692282)
decoder loss ratio: 15514.768311, decoder SINDy loss  ratio: 0.498571
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997926]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.850667 ]
 [-0.5345557]
 [-0.6397265]
 [-0.       ]
 [-0.       ]
 [-0.4748065]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.1295846]
 [ 0.       ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.3076171875, (273.20926, 0.28632286, 482.81207, 1.1692308)
   validation loss 427.52362060546875, (203.24898, 0.22557458, 224.04906, 1.1692308)
decoder loss ratio: 7874.218250, decoder SINDy loss  ratio: 0.483641
=========================
[[1.      ]
 [1.      ]
 [1.      ]
 [0.      ]
 [0.      ]
 [0.999979]
 [0.      ]
 [0.      ]
 [0.      ]
 [1.      ]
 [0.      ]]
[[-3.851413  ]
 [-0.63895875]
 [-0.6348389 ]
 [ 0.        ]
 [-0.        ]
 [-0.46876672]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.1515656 ]
 [ 0.        ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.7774658203125, (260.3552, 0.28166127, 460.14066, 1.1692429)
   validation loss 407.85675048828125, (191.1263, 0.22329104, 216.50714, 1.1692429)
decoder loss ratio: 7404.564556, decoder SINDy loss  ratio: 0.467361
=========================
[[1.        ]
 [1.        ]
 [1.        ]
 [0.        ]
 [0.        ]
 [0.99997926]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.7961493 ]
 [-0.6749295 ]
 [-0.64684725]
 [ 0.        ]
 [ 0.        ]
 [-0.5078173 ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.173641  ]
 [ 0.        ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.828125, (286.10498, 0.29853055, 459.42462, 1.1692642)
   validation loss 432.04364013671875, (214.75157, 0.23146743, 217.06061, 1.1692642)
decoder loss ratio: 8319.848711, decoder SINDy loss  ratio: 0.468556
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999815]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8804505 ]
 [-0.63613003]
 [-0.5756064 ]
 [ 0.        ]
 [-0.        ]
 [-0.50358397]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-3.1530364 ]
 [ 0.        ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.691162109375, (235.70326, 0.33114755, 464.65677, 1.1693141)
   validation loss 398.0860595703125, (181.31018, 0.22392084, 216.55196, 1.1693141)
decoder loss ratio: 7024.271167, decoder SINDy loss  ratio: 0.467458
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999786]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.8885255]
 [-0.5758384]
 [-0.660749 ]
 [-0.       ]
 [ 0.       ]
 [-0.4950506]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.0768943]
 [-0.       ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.16162109375, (265.5704, 0.30171287, 476.28946, 1.1692781)
   validation loss 430.8378601074219, (207.32832, 0.23115014, 223.27838, 1.1692781)
decoder loss ratio: 8032.259185, decoder SINDy loss  ratio: 0.481978
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999979 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.7812824 ]
 [-0.6718541 ]
 [-0.6466593 ]
 [-0.        ]
 [-0.        ]
 [-0.48290083]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.0631063 ]
 [ 0.        ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.2506713867188, (238.61578, 0.27782342, 465.35706, 1.1692959)
   validation loss 392.861572265625, (173.60136, 0.22397532, 219.03622, 1.1692959)
decoder loss ratio: 6725.618232, decoder SINDy loss  ratio: 0.472820
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997836]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.8718007 ]
 [-0.6407783 ]
 [-0.6268063 ]
 [-0.        ]
 [ 0.        ]
 [-0.48439178]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0500784 ]
 [ 0.        ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 884.484619140625, (425.0586, 0.2751837, 459.15085, 1.1692951)
   validation loss 550.9228515625, (330.9735, 0.22980832, 219.71951, 1.1692951)
decoder loss ratio: 12822.488401, decoder SINDy loss  ratio: 0.474295
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997854]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9584498 ]
 [-0.67357194]
 [-0.64907736]
 [-0.        ]
 [-0.        ]
 [-0.56431764]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-3.1224623 ]
 [ 0.        ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.041015625, (230.2245, 0.3009519, 461.51553, 1.1693088)
   validation loss 384.28472900390625, (166.33311, 0.23387915, 217.71774, 1.1693088)
decoder loss ratio: 6444.033628, decoder SINDy loss  ratio: 0.469974
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999796]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.012965  ]
 [-0.5977    ]
 [-0.5898162 ]
 [ 0.        ]
 [-0.        ]
 [-0.49287683]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0587125 ]
 [ 0.        ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1181.17578125, (655.6381, 0.39188552, 525.1457, 1.1693611)
   validation loss 815.0957641601562, (571.18, 0.23899406, 243.67677, 1.1693611)
decoder loss ratio: 22128.504528, decoder SINDy loss  ratio: 0.526011
=========================
[[1.       ]
 [1.       ]
 [1.       ]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9035757]
 [-0.6503661]
 [-0.6429164]
 [ 0.       ]
 [ 0.       ]
 [-0.5109516]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0102081]
 [ 0.       ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.9065551757812, (284.8775, 0.30747622, 476.7216, 1.1693208)
   validation loss 455.9644775390625, (230.96692, 0.23476471, 224.76277, 1.1693208)
decoder loss ratio: 8948.059416, decoder SINDy loss  ratio: 0.485182
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999783]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9806197 ]
 [-0.6877135 ]
 [-0.70055825]
 [-0.        ]
 [ 0.        ]
 [-0.5522857 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.0827694 ]
 [ 0.        ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.3425903320312, (238.49011, 0.2766582, 464.57584, 1.1693296)
   validation loss 393.2144775390625, (173.25981, 0.22545455, 219.7292, 1.1693296)
decoder loss ratio: 6712.385886, decoder SINDy loss  ratio: 0.474316
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.027541  ]
 [-0.6710738 ]
 [-0.59710455]
 [-0.        ]
 [-0.        ]
 [-0.48427358]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.0286617 ]
 [ 0.        ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.121337890625, (235.85445, 0.27747828, 458.98944, 1.1693184)
   validation loss 386.2835693359375, (168.58034, 0.22795106, 217.47528, 1.1693184)
decoder loss ratio: 6531.094944, decoder SINDy loss  ratio: 0.469451
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-3.9852633 ]
 [-0.69129235]
 [-0.57973015]
 [-0.        ]
 [ 0.        ]
 [-0.55616   ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8972454 ]
 [ 0.        ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.5991821289062, (285.76715, 0.28324163, 454.5488, 1.1693277)
   validation loss 428.4943542480469, (211.05518, 0.23587103, 217.20331, 1.1693277)
decoder loss ratio: 8176.643918, decoder SINDy loss  ratio: 0.468864
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997926]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9552186]
 [-0.6380654]
 [-0.649701 ]
 [ 0.       ]
 [-0.       ]
 [-0.5450559]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.9665995]
 [-0.       ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.85205078125, (256.1601, 0.32157117, 464.37036, 1.1693579)
   validation loss 424.23480224609375, (205.51114, 0.22737189, 218.4963, 1.1693579)
decoder loss ratio: 7961.858305, decoder SINDy loss  ratio: 0.471655
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9163089 ]
 [-0.67740655]
 [-0.5958837 ]
 [-0.        ]
 [-0.        ]
 [-0.47760856]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9698339 ]
 [ 0.        ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.457275390625, (232.37404, 0.27820203, 460.80502, 1.1693078)
   validation loss 392.2813720703125, (172.14621, 0.23399118, 219.90118, 1.1693078)
decoder loss ratio: 6669.243023, decoder SINDy loss  ratio: 0.474688
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.123287  ]
 [-0.6133932 ]
 [-0.640568  ]
 [-0.        ]
 [ 0.        ]
 [-0.50133216]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9816077 ]
 [ 0.        ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.988525390625, (238.64066, 0.27254862, 459.07532, 1.1693069)
   validation loss 389.2584228515625, (170.72728, 0.22848837, 218.30266, 1.1693069)
decoder loss ratio: 6614.271210, decoder SINDy loss  ratio: 0.471237
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.0321293 ]
 [-0.6705386 ]
 [-0.6415268 ]
 [-0.        ]
 [ 0.        ]
 [-0.51608694]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-3.0146267 ]
 [ 0.        ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.2608642578125, (264.2696, 0.27681065, 453.71445, 1.1693348)
   validation loss 411.3332214355469, (193.7033, 0.23609318, 217.39383, 1.1693348)
decoder loss ratio: 7504.401849, decoder SINDy loss  ratio: 0.469275
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.0088763 ]
 [-0.59998554]
 [-0.6105974 ]
 [ 0.        ]
 [ 0.        ]
 [-0.44019553]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.8802695 ]
 [-0.        ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1084.50634765625, (628.8372, 0.25947255, 455.40964, 1.1693767)
   validation loss 736.4165649414062, (512.95984, 0.22852549, 223.22823, 1.1693767)
decoder loss ratio: 19872.954695, decoder SINDy loss  ratio: 0.481870
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-3.9710093]
 [-0.6768767]
 [-0.6725372]
 [-0.       ]
 [-0.       ]
 [-0.4886091]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.89951  ]
 [-0.       ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1080.6923828125, (557.05225, 0.28665087, 523.3536, 1.1693199)
   validation loss 695.7296752929688, (449.6904, 0.24018945, 245.79907, 1.1693199)
decoder loss ratio: 17421.786761, decoder SINDy loss  ratio: 0.530592
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.04553   ]
 [-0.6763084 ]
 [-0.58240306]
 [-0.        ]
 [-0.        ]
 [-0.53146136]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8900216 ]
 [-0.        ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.2544555664062, (250.60876, 0.26188812, 452.38382, 1.1693308)
   validation loss 398.6270751953125, (180.74176, 0.23189625, 217.6534, 1.1693308)
decoder loss ratio: 7002.249574, decoder SINDy loss  ratio: 0.469835
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0380187 ]
 [-0.6389979 ]
 [-0.62117964]
 [ 0.        ]
 [ 0.        ]
 [-0.50078475]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7982764 ]
 [ 0.        ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.69287109375, (271.8303, 0.27721658, 451.5854, 1.1693248)
   validation loss 417.76507568359375, (199.79247, 0.24001345, 217.73257, 1.1693248)
decoder loss ratio: 7740.306957, decoder SINDy loss  ratio: 0.470006
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999782]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.112957  ]
 [-0.6285295 ]
 [-0.59004426]
 [ 0.        ]
 [-0.        ]
 [-0.57070535]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8251433 ]
 [ 0.        ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.0297241210938, (230.79518, 0.30081284, 457.93375, 1.1693429)
   validation loss 394.6927490234375, (175.78676, 0.23217502, 218.67381, 1.1693429)
decoder loss ratio: 6810.284201, decoder SINDy loss  ratio: 0.472038
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0942    ]
 [-0.6439133 ]
 [-0.6729273 ]
 [ 0.        ]
 [ 0.        ]
 [-0.50112075]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7879004 ]
 [-0.        ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.2064208984375, (251.45018, 0.29548404, 463.46072, 1.1693263)
   validation loss 421.335205078125, (198.55807, 0.23701371, 222.5401, 1.1693263)
decoder loss ratio: 7692.484536, decoder SINDy loss  ratio: 0.480384
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.131506  ]
 [-0.65248   ]
 [-0.58074814]
 [ 0.        ]
 [ 0.        ]
 [-0.42616206]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8531156 ]
 [ 0.        ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.2628173828125, (239.01369, 0.25005242, 457.99905, 1.1693065)
   validation loss 390.5450439453125, (170.29346, 0.22618149, 220.02539, 1.1693065)
decoder loss ratio: 6597.464168, decoder SINDy loss  ratio: 0.474956
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.089017  ]
 [-0.66832227]
 [-0.62632483]
 [ 0.        ]
 [ 0.        ]
 [-0.47314805]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8022387 ]
 [ 0.        ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.0294189453125, (271.39554, 0.2739598, 450.35992, 1.169318)
   validation loss 415.23492431640625, (196.77293, 0.2442309, 218.21777, 1.169318)
decoder loss ratio: 7623.325074, decoder SINDy loss  ratio: 0.471054
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1016784 ]
 [-0.67095643]
 [-0.69154435]
 [ 0.        ]
 [-0.        ]
 [-0.42466092]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.804591  ]
 [ 0.        ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.6286010742188, (235.32364, 0.3089901, 458.99597, 1.169341)
   validation loss 403.52490234375, (183.12418, 0.2392122, 220.16151, 1.169341)
decoder loss ratio: 7094.548497, decoder SINDy loss  ratio: 0.475250
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1119137 ]
 [-0.71747935]
 [-0.64889175]
 [ 0.        ]
 [-0.        ]
 [-0.4912927 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.778717  ]
 [ 0.        ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.2448120117188, (363.7195, 0.25404313, 449.27127, 1.169329)
   validation loss 487.775390625, (268.8516, 0.23204929, 218.69176, 1.169329)
decoder loss ratio: 10415.777460, decoder SINDy loss  ratio: 0.472077
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.090916  ]
 [-0.5884809 ]
 [-0.63591707]
 [-0.        ]
 [-0.        ]
 [-0.5059963 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7227645 ]
 [ 0.        ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.2446899414062, (235.83412, 0.2661642, 454.1444, 1.1693016)
   validation loss 388.0312194824219, (168.52226, 0.23470004, 219.27426, 1.1693016)
decoder loss ratio: 6528.845020, decoder SINDy loss  ratio: 0.473334
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.191889  ]
 [-0.62433994]
 [-0.629552  ]
 [-0.        ]
 [-0.        ]
 [-0.48321116]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7186825 ]
 [ 0.        ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.4805908203125, (235.91386, 0.2742407, 450.2925, 1.1693044)
   validation loss 388.287841796875, (170.0662, 0.24068086, 217.98096, 1.1693044)
decoder loss ratio: 6588.659550, decoder SINDy loss  ratio: 0.470543
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1566205 ]
 [-0.6724651 ]
 [-0.59566194]
 [-0.        ]
 [-0.        ]
 [-0.42092872]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7705264 ]
 [-0.        ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.4495239257812, (419.24643, 0.26688364, 447.93622, 1.16931)
   validation loss 542.6116943359375, (323.2124, 0.24481823, 219.15448, 1.16931)
decoder loss ratio: 12521.809588, decoder SINDy loss  ratio: 0.473076
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.193868  ]
 [-0.5692942 ]
 [-0.55947113]
 [-0.        ]
 [-0.        ]
 [-0.51728636]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.7310128 ]
 [ 0.        ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.7586059570312, (250.58609, 0.30628484, 458.8662, 1.1693316)
   validation loss 422.32244873046875, (202.00893, 0.23477754, 220.07874, 1.1693316)
decoder loss ratio: 7826.176511, decoder SINDy loss  ratio: 0.475071
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.198006  ]
 [-0.55433756]
 [-0.5309923 ]
 [-0.        ]
 [-0.        ]
 [-0.46579418]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7460105 ]
 [ 0.        ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.832275390625, (262.2857, 0.2632028, 450.2834, 1.1692802)
   validation loss 416.0150146484375, (196.33061, 0.23590459, 219.4485, 1.1692802)
decoder loss ratio: 7606.188761, decoder SINDy loss  ratio: 0.473710
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.0919557 ]
 [-0.69261205]
 [-0.6410901 ]
 [-0.        ]
 [ 0.        ]
 [-0.5008801 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.7291381 ]
 [ 0.        ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.0244140625, (235.11368, 0.26499343, 454.64572, 1.1692749)
   validation loss 390.123779296875, (169.78627, 0.23229426, 220.10522, 1.1692749)
decoder loss ratio: 6577.814867, decoder SINDy loss  ratio: 0.475128
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.147753  ]
 [-0.69912946]
 [-0.5524926 ]
 [-0.        ]
 [ 0.        ]
 [-0.38637802]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.706832  ]
 [ 0.        ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.603759765625, (340.21448, 0.26617283, 447.12314, 1.1693077)
   validation loss 471.4996337890625, (253.07318, 0.24247138, 218.18398, 1.1693077)
decoder loss ratio: 9804.494392, decoder SINDy loss  ratio: 0.470981
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1579833 ]
 [-0.63092023]
 [-0.59082896]
 [-0.        ]
 [-0.        ]
 [-0.54193354]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6488006 ]
 [ 0.        ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.1643676757812, (228.16045, 0.2876578, 451.71628, 1.1693273)
   validation loss 391.1214599609375, (172.4303, 0.23487186, 218.4563, 1.1693273)
decoder loss ratio: 6680.249091, decoder SINDy loss  ratio: 0.471569
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2136693 ]
 [-0.6232243 ]
 [-0.5910455 ]
 [ 0.        ]
 [ 0.        ]
 [-0.48663718]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6327062 ]
 [ 0.        ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.9164428710938, (245.22197, 0.33905464, 457.35544, 1.1693509)
   validation loss 415.3973083496094, (194.92743, 0.25094742, 220.21893, 1.1693509)
decoder loss ratio: 7551.827016, decoder SINDy loss  ratio: 0.475374
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.1774926 ]
 [-0.64059967]
 [-0.65595514]
 [ 0.        ]
 [ 0.        ]
 [-0.44700348]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.6321223 ]
 [-0.        ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.69677734375, (275.3075, 0.25986463, 448.12943, 1.1692964)
   validation loss 421.8090515136719, (202.85982, 0.23708564, 218.71214, 1.1692964)
decoder loss ratio: 7859.141510, decoder SINDy loss  ratio: 0.472121
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.229158  ]
 [-0.61446565]
 [-0.628107  ]
 [ 0.        ]
 [-0.        ]
 [-0.4207507 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.6191823 ]
 [-0.        ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 820.4500732421875, (373.7404, 0.24870591, 446.46097, 1.1692827)
   validation loss 504.9318542480469, (285.57935, 0.23587997, 219.11664, 1.1692827)
decoder loss ratio: 11063.839640, decoder SINDy loss  ratio: 0.472994
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.1879535]
 [-0.5792643]
 [-0.6286986]
 [-0.       ]
 [-0.       ]
 [-0.4780158]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.5688732]
 [ 0.       ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.3365478515625, (287.51468, 0.2561427, 444.56577, 1.169298)
   validation loss 424.5927734375, (207.02585, 0.2346453, 217.33229, 1.169298)
decoder loss ratio: 8020.540779, decoder SINDy loss  ratio: 0.469142
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2175837]
 [-0.5777208]
 [-0.6202455]
 [-0.       ]
 [-0.       ]
 [-0.5200014]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.5935204]
 [-0.       ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.32958984375, (227.62051, 0.27124324, 449.43784, 1.1693181)
   validation loss 388.827880859375, (169.50475, 0.2401114, 219.08301, 1.1693181)
decoder loss ratio: 6566.908113, decoder SINDy loss  ratio: 0.472921
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.231379  ]
 [-0.57336265]
 [-0.62889534]
 [-0.        ]
 [ 0.        ]
 [-0.41455844]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5702615 ]
 [-0.        ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1648.89990234375, (1097.5669, 0.3236908, 551.0093, 1.1692713)
   validation loss 1276.272216796875, (1009.5551, 0.24425946, 266.47287, 1.1692713)
decoder loss ratio: 39111.917810, decoder SINDy loss  ratio: 0.575219
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.2937818 ]
 [-0.7180668 ]
 [-0.66615146]
 [-0.        ]
 [-0.        ]
 [-0.43614256]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5704906 ]
 [ 0.        ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 801.58837890625, (354.84232, 0.24544077, 446.5006, 1.1692966)
   validation loss 491.0557556152344, (270.88797, 0.2398582, 219.92792, 1.1692966)
decoder loss ratio: 10494.670239, decoder SINDy loss  ratio: 0.474745
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.2984962 ]
 [-0.68123734]
 [-0.5739717 ]
 [ 0.        ]
 [ 0.        ]
 [-0.35698482]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.556044  ]
 [ 0.        ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.5026245117188, (238.2371, 0.2534785, 446.01205, 1.1693066)
   validation loss 389.18792724609375, (170.55609, 0.23332323, 218.39851, 1.1693066)
decoder loss ratio: 6607.639076, decoder SINDy loss  ratio: 0.471444
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.2707887 ]
 [-0.5904489 ]
 [-0.6139289 ]
 [ 0.        ]
 [-0.        ]
 [-0.46381396]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.5327294 ]
 [ 0.        ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.9674072265625, (258.89963, 0.26230785, 444.8055, 1.1693081)
   validation loss 404.8338623046875, (186.4124, 0.2425611, 218.1789, 1.1693081)
decoder loss ratio: 7221.939975, decoder SINDy loss  ratio: 0.470970
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99997807]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2814035 ]
 [-0.62479407]
 [-0.5720705 ]
 [-0.        ]
 [-0.        ]
 [-0.3619753 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.4724414 ]
 [-0.        ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.4551391601562, (231.75352, 0.2977565, 454.40384, 1.1693336)
   validation loss 404.482666015625, (183.26685, 0.24074218, 220.9751, 1.1693336)
decoder loss ratio: 7100.075768, decoder SINDy loss  ratio: 0.477006
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.217576  ]
 [-0.62027246]
 [-0.6384197 ]
 [-0.        ]
 [-0.        ]
 [-0.40732843]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5166852 ]
 [ 0.        ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.0604248046875, (238.7245, 0.25672567, 456.0792, 1.1693151)
   validation loss 399.1065368652344, (175.64758, 0.23466508, 223.22429, 1.1693151)
decoder loss ratio: 6804.892303, decoder SINDy loss  ratio: 0.481861
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99996877]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.2214894 ]
 [-0.6457929 ]
 [-0.6563975 ]
 [-0.        ]
 [-0.        ]
 [-0.45822966]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.4248738 ]
 [-0.        ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.0126953125, (301.18866, 0.24340744, 443.5806, 1.1693053)
   validation loss 443.8002014160156, (224.7507, 0.23704797, 218.81245, 1.1693053)
decoder loss ratio: 8707.232376, decoder SINDy loss  ratio: 0.472337
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.292439  ]
 [-0.584184  ]
 [-0.62008154]
 [-0.        ]
 [ 0.        ]
 [-0.48888758]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.5395062 ]
 [-0.        ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.3802490234375, (228.72575, 0.26842618, 448.38608, 1.1693354)
   validation loss 384.0659484863281, (164.31389, 0.2375207, 219.51454, 1.1693354)
decoder loss ratio: 6365.805304, decoder SINDy loss  ratio: 0.473853
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.3261604 ]
 [-0.6397596 ]
 [-0.54436517]
 [-0.        ]
 [ 0.        ]
 [-0.5838342 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.4109707 ]
 [ 0.        ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 876.955322265625, (433.29675, 0.2393059, 443.41925, 1.1693316)
   validation loss 549.9295654296875, (330.71582, 0.22820766, 218.98553, 1.1693316)
decoder loss ratio: 12812.505027, decoder SINDy loss  ratio: 0.472711
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.3471737 ]
 [-0.6100258 ]
 [-0.58270884]
 [ 0.        ]
 [ 0.        ]
 [-0.38721722]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.437745  ]
 [-0.        ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.9507446289062, (249.68286, 0.29526672, 458.9726, 1.169372)
   validation loss 428.18994140625, (204.15999, 0.24633339, 223.78362, 1.169372)
decoder loss ratio: 7909.512388, decoder SINDy loss  ratio: 0.483068
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99995315]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3085384 ]
 [-0.6695526 ]
 [-0.54989624]
 [-0.        ]
 [ 0.        ]
 [-0.43148762]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.482409  ]
 [-0.        ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1030.6094970703125, (577.15234, 0.22692338, 453.23026, 1.1693554)
   validation loss 666.701904296875, (442.04932, 0.23567092, 224.41696, 1.1693554)
decoder loss ratio: 17125.757949, decoder SINDy loss  ratio: 0.484436
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99995565]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3622556 ]
 [-0.6130291 ]
 [-0.56259894]
 [-0.        ]
 [-0.        ]
 [-0.45478007]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.4292245 ]
 [ 0.        ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.2138671875, (230.95554, 0.25449303, 449.00385, 1.1693519)
   validation loss 388.16241455078125, (167.14499, 0.2334469, 220.784, 1.1693519)
decoder loss ratio: 6475.487051, decoder SINDy loss  ratio: 0.476593
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99996924]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.394973  ]
 [-0.6201445 ]
 [-0.5962835 ]
 [ 0.        ]
 [-0.        ]
 [-0.44894192]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.4534204 ]
 [-0.        ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.143310546875, (298.59293, 0.2546392, 442.29578, 1.1693838)
   validation loss 432.2020568847656, (213.86108, 0.24053726, 218.10043, 1.1693838)
decoder loss ratio: 8285.349673, decoder SINDy loss  ratio: 0.470800
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.441014  ]
 [-0.61987346]
 [-0.5848373 ]
 [-0.        ]
 [-0.        ]
 [-0.4918705 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3525252 ]
 [-0.        ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.4564208984375, (223.57503, 0.2855659, 449.59583, 1.1693991)
   validation loss 388.888916015625, (168.22719, 0.2450739, 220.41667, 1.1693991)
decoder loss ratio: 6517.413323, decoder SINDy loss  ratio: 0.475800
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99996924]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.3676844]
 [-0.6109065]
 [-0.5054714]
 [ 0.       ]
 [-0.       ]
 [-0.4842774]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.3106961]
 [ 0.       ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 965.34814453125, (481.43155, 0.30859905, 483.60803, 1.1694037)
   validation loss 673.523681640625, (436.79547, 0.24558386, 236.4826, 1.1694037)
decoder loss ratio: 16922.214864, decoder SINDy loss  ratio: 0.510481
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999485]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.3958845 ]
 [-0.680061  ]
 [-0.52434856]
 [-0.        ]
 [-0.        ]
 [-0.4714495 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.3390164 ]
 [ 0.        ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.8981323242188, (353.4988, 0.24554579, 442.15378, 1.1694094)
   validation loss 486.11962890625, (266.80945, 0.2381299, 219.07207, 1.1694094)
decoder loss ratio: 10336.661226, decoder SINDy loss  ratio: 0.472898
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999496]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.449364  ]
 [-0.62405753]
 [-0.60391366]
 [ 0.        ]
 [-0.        ]
 [-0.45393628]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-2.3100793 ]
 [ 0.        ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.2147216796875, (353.2793, 0.25041777, 440.68497, 1.169432)
   validation loss 480.0067138671875, (261.3999, 0.23924628, 218.36754, 1.169432)
decoder loss ratio: 10127.086027, decoder SINDy loss  ratio: 0.471377
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999567]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.3679447 ]
 [-0.617452  ]
 [-0.6582303 ]
 [ 0.        ]
 [ 0.        ]
 [-0.42244682]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.287313  ]
 [ 0.        ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.6839599609375, (224.06155, 0.28229436, 449.34015, 1.169453)
   validation loss 391.56182861328125, (170.79109, 0.24297994, 220.52777, 1.169453)
decoder loss ratio: 6616.743407, decoder SINDy loss  ratio: 0.476040
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999978 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.39871   ]
 [-0.54370475]
 [-0.63455784]
 [ 0.        ]
 [-0.        ]
 [-0.41692743]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.2821949 ]
 [-0.        ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.947509765625, (231.79576, 0.30857694, 453.84314, 1.1694883)
   validation loss 403.247314453125, (180.68016, 0.25271744, 222.31445, 1.1694883)
decoder loss ratio: 6999.863093, decoder SINDy loss  ratio: 0.479897
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999517]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.4243674 ]
 [-0.64365166]
 [-0.623873  ]
 [-0.        ]
 [-0.        ]
 [-0.50939256]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.3355336 ]
 [ 0.        ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1370.5137939453125, (917.7782, 0.22672717, 452.50885, 1.1694866)
   validation loss 996.939697265625, (766.78424, 0.23143256, 229.92404, 1.1694866)
decoder loss ratio: 29706.552682, decoder SINDy loss  ratio: 0.496323
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999422]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.403259 ]
 [-0.6193734]
 [-0.60154  ]
 [ 0.       ]
 [-0.       ]
 [-0.4669434]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.2662947]
 [-0.       ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.7232666015625, (423.31952, 0.2334693, 443.1703, 1.1694621)
   validation loss 536.62353515625, (316.42285, 0.23256743, 219.96808, 1.1694621)
decoder loss ratio: 12258.770604, decoder SINDy loss  ratio: 0.474832
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99994075]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.399773 ]
 [-0.6238517]
 [-0.5768768]
 [-0.       ]
 [-0.       ]
 [-0.4027328]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3347332]
 [-0.       ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.0032958984375, (286.141, 0.25087652, 439.6114, 1.1694632)
   validation loss 424.99578857421875, (206.83139, 0.23818932, 217.92621, 1.1694632)
decoder loss ratio: 8013.007138, decoder SINDy loss  ratio: 0.470424
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999647]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.3981504 ]
 [-0.67459106]
 [-0.6165669 ]
 [ 0.        ]
 [-0.        ]
 [-0.486146  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2179773 ]
 [ 0.        ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.8570556640625, (287.46378, 0.34502742, 467.04825, 1.169525)
   validation loss 465.15069580078125, (237.69164, 0.26313823, 227.1959, 1.169525)
decoder loss ratio: 9208.586596, decoder SINDy loss  ratio: 0.490434
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.999937 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.489623  ]
 [-0.62810653]
 [-0.5112185 ]
 [ 0.        ]
 [-0.        ]
 [-0.39608002]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.2093842 ]
 [-0.        ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1064.263916015625, (569.3741, 0.32277665, 494.5671, 1.1694714)
   validation loss 764.4847412109375, (521.7553, 0.24546406, 242.48395, 1.1694714)
decoder loss ratio: 20213.706519, decoder SINDy loss  ratio: 0.523436
=========================
[[1.        ]
 [1.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.99993885]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.353444  ]
 [-0.6684071 ]
 [-0.6094675 ]
 [-0.        ]
 [-0.        ]
 [-0.46481362]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2052603 ]
 [ 0.        ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1022.5499267578125, (526.7221, 0.35616314, 495.4717, 1.1694894)
   validation loss 697.6472778320312, (455.92972, 0.2611484, 241.45642, 1.1694894)
decoder loss ratio: 17663.508805, decoder SINDy loss  ratio: 0.521218
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99993443]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.4758677 ]
 [-0.6338666 ]
 [-0.49161673]
 [ 0.        ]
 [ 0.        ]
 [-0.47570974]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.1957765 ]
 [ 0.        ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.0206298828125, (236.40692, 0.24152558, 440.3722, 1.1694837)
   validation loss 386.62738037109375, (167.81375, 0.22972372, 218.5839, 1.1694837)
decoder loss ratio: 6501.396060, decoder SINDy loss  ratio: 0.471844
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999356]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.4834275]
 [-0.602615 ]
 [-0.6338795]
 [-0.       ]
 [-0.       ]
 [-0.349199 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.1272113]
 [-0.       ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.1636962890625, (355.52405, 0.24270009, 439.39697, 1.1694909)
   validation loss 484.0299072265625, (264.86688, 0.23790756, 218.92511, 1.1694909)
decoder loss ratio: 10261.402850, decoder SINDy loss  ratio: 0.472581
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999398]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.494382  ]
 [-0.61036485]
 [-0.6685019 ]
 [ 0.        ]
 [ 0.        ]
 [-0.44585118]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.079519  ]
 [-0.        ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.3920288085938, (222.26215, 0.27494648, 444.85492, 1.1695211)
   validation loss 386.37176513671875, (166.09077, 0.24425307, 220.03676, 1.1695211)
decoder loss ratio: 6434.644952, decoder SINDy loss  ratio: 0.474980
=========================
[[1.        ]
 [1.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.99993837]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.4452133 ]
 [-0.66802263]
 [-0.6604874 ]
 [ 0.        ]
 [-0.        ]
 [-0.4732817 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.196241  ]
 [ 0.        ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 817.4993896484375, (340.96234, 0.3515257, 476.1855, 1.1695546)
   validation loss 518.9896850585938, (287.3097, 0.26189932, 231.4181, 1.1695546)
decoder loss ratio: 11130.876274, decoder SINDy loss  ratio: 0.499549
=========================
[[1.       ]
 [1.       ]
 [0.9999993]
 [0.       ]
 [0.       ]
 [0.9999223]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.5611467 ]
 [-0.619072  ]
 [-0.55597746]
 [-0.        ]
 [-0.        ]
 [-0.5444894 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-2.1487453 ]
 [-0.        ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.0315551757812, (228.37325, 0.25951815, 445.39877, 1.1695144)
   validation loss 391.4204406738281, (170.492, 0.2384943, 220.68994, 1.1695144)
decoder loss ratio: 6605.156237, decoder SINDy loss  ratio: 0.476390
=========================
[[1.        ]
 [1.        ]
 [0.9999993 ]
 [0.        ]
 [0.        ]
 [0.99993205]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.521757 ]
 [-0.5934884]
 [-0.5912437]
 [-0.       ]
 [-0.       ]
 [-0.4895447]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.1356688]
 [ 0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 801.4942626953125, (362.0521, 0.24184506, 439.20035, 1.1695486)
   validation loss 483.8338623046875, (264.91147, 0.23556347, 218.68684, 1.1695486)
decoder loss ratio: 10263.130196, decoder SINDy loss  ratio: 0.472066
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9999312]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.5593586]
 [-0.5915963]
 [-0.6112478]
 [-0.       ]
 [ 0.       ]
 [-0.5340385]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-2.0195117]
 [ 0.       ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.28662109375, (286.68564, 0.25108957, 436.34988, 1.1695596)
   validation loss 421.18280029296875, (203.74005, 0.22611088, 217.21666, 1.1695596)
decoder loss ratio: 7893.243294, decoder SINDy loss  ratio: 0.468893
=========================
[[1.        ]
 [1.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.99993527]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5806327 ]
 [-0.7392985 ]
 [-0.63861406]
 [-0.        ]
 [-0.        ]
 [-0.48026198]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-2.05647   ]
 [-0.        ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.4948120117188, (223.02122, 0.27624053, 446.19733, 1.1695957)
   validation loss 393.667724609375, (172.60542, 0.2410605, 220.82124, 1.1695957)
decoder loss ratio: 6687.033742, decoder SINDy loss  ratio: 0.476674
=========================
[[1.        ]
 [1.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.99992555]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.5398164 ]
 [-0.69317555]
 [-0.55440885]
 [-0.        ]
 [ 0.        ]
 [-0.39249605]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.0256798 ]
 [-0.        ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1095.3729248046875, (594.8296, 0.3560424, 500.18735, 1.1696177)
   validation loss 783.760009765625, (538.9042, 0.25568467, 244.60016, 1.1696177)
decoder loss ratio: 20878.083311, decoder SINDy loss  ratio: 0.528004
=========================
[[1.        ]
 [1.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.99990284]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.506152 ]
 [-0.6553888]
 [-0.5427054]
 [ 0.       ]
 [ 0.       ]
 [-0.4905806]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.1250331]
 [-0.       ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.1376953125, (242.25247, 0.27049673, 452.61472, 1.1695919)
   validation loss 419.355224609375, (195.12909, 0.23856449, 223.98758, 1.1695919)
decoder loss ratio: 7559.639681, decoder SINDy loss  ratio: 0.483509
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9999119]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.6090465 ]
 [-0.61479867]
 [-0.5176451 ]
 [ 0.        ]
 [ 0.        ]
 [-0.3745998 ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.9574347 ]
 [-0.        ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.1035766601562, (225.55878, 0.25408792, 441.2907, 1.1696281)
   validation loss 381.625244140625, (162.43497, 0.22920959, 218.96107, 1.1696281)
decoder loss ratio: 6293.012623, decoder SINDy loss  ratio: 0.472658
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9999068]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.5711837 ]
 [-0.6341529 ]
 [-0.5765304 ]
 [-0.        ]
 [ 0.        ]
 [-0.39747232]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.0024488 ]
 [-0.        ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.834716796875, (336.04013, 0.23004529, 437.56458, 1.1696317)
   validation loss 464.78521728515625, (246.59505, 0.22429074, 217.9659, 1.1696317)
decoder loss ratio: 9553.520228, decoder SINDy loss  ratio: 0.470510
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9999107]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.5475984 ]
 [-0.6512823 ]
 [-0.5796683 ]
 [-0.        ]
 [-0.        ]
 [-0.39304477]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.9531325 ]
 [-0.        ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.8599853515625, (230.80644, 0.26911658, 449.78445, 1.1696671)
   validation loss 408.48431396484375, (185.40071, 0.2407993, 222.84279, 1.1696671)
decoder loss ratio: 7182.745416, decoder SINDy loss  ratio: 0.481038
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9998996]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.618926  ]
 [-0.6899539 ]
 [-0.54974365]
 [ 0.        ]
 [-0.        ]
 [-0.44970348]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.9947922 ]
 [ 0.        ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1182.3570556640625, (675.6916, 0.3814702, 506.28397, 1.1696895)
   validation loss 865.276611328125, (616.0851, 0.26194793, 248.92955, 1.1696895)
decoder loss ratio: 23868.205686, decoder SINDy loss  ratio: 0.537349
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9998915]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.6130238]
 [-0.6149952]
 [-0.538548 ]
 [ 0.       ]
 [ 0.       ]
 [-0.4633617]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.0021327]
 [ 0.       ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.1246948242188, (243.84526, 0.23508304, 437.04437, 1.1696881)
   validation loss 389.06414794921875, (170.53012, 0.22692439, 218.30708, 1.1696881)
decoder loss ratio: 6606.632935, decoder SINDy loss  ratio: 0.471247
=========================
[[1.        ]
 [1.        ]
 [0.9999975 ]
 [0.        ]
 [0.        ]
 [0.99989605]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.621031  ]
 [-0.62387735]
 [-0.6467407 ]
 [ 0.        ]
 [-0.        ]
 [-0.42038935]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.9135519 ]
 [ 0.        ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.23876953125, (230.56776, 0.2514888, 442.41953, 1.1696949)
   validation loss 391.8111877441406, (171.50435, 0.23125337, 220.07559, 1.1696949)
decoder loss ratio: 6644.376215, decoder SINDy loss  ratio: 0.475064
=========================
[[1.       ]
 [1.       ]
 [0.9999975]
 [0.       ]
 [0.       ]
 [0.9998911]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.6661386 ]
 [-0.5729338 ]
 [-0.5845456 ]
 [-0.        ]
 [ 0.        ]
 [-0.39286557]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.8371022 ]
 [-0.        ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.3787841796875, (320.30035, 0.2419356, 436.83646, 1.1697377)
   validation loss 446.935302734375, (228.52301, 0.23225977, 218.18005, 1.1697377)
decoder loss ratio: 8853.378151, decoder SINDy loss  ratio: 0.470972
=========================
[[1.        ]
 [1.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.99989665]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.609193 ]
 [-0.7035408]
 [-0.5536294]
 [ 0.       ]
 [-0.       ]
 [-0.3874048]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.8219634]
 [-0.       ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.1290893554688, (231.05846, 0.26281455, 438.8078, 1.1697603)
   validation loss 382.67376708984375, (164.01387, 0.23310481, 218.42677, 1.1697603)
decoder loss ratio: 6354.182074, decoder SINDy loss  ratio: 0.471505
=========================
[[1.       ]
 [1.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.9999118]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.662585  ]
 [-0.6344396 ]
 [-0.59275115]
 [-0.        ]
 [ 0.        ]
 [-0.46170795]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.9271909 ]
 [-0.        ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.3959350585938, (222.51703, 0.27635804, 442.60254, 1.1697943)
   validation loss 386.544189453125, (166.73274, 0.23310058, 219.57835, 1.1697943)
decoder loss ratio: 6459.515898, decoder SINDy loss  ratio: 0.473991
=========================
[[1.       ]
 [1.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.9999107]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.6095576 ]
 [-0.6791186 ]
 [-0.5952643 ]
 [ 0.        ]
 [ 0.        ]
 [-0.35291994]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.9628217 ]
 [-0.        ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.196533203125, (260.82922, 0.26502576, 440.10233, 1.1698334)
   validation loss 408.52117919921875, (189.17447, 0.23190087, 219.11479, 1.1698334)
decoder loss ratio: 7328.947350, decoder SINDy loss  ratio: 0.472990
=========================
[[1.        ]
 [1.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.99989665]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.755501  ]
 [-0.5401791 ]
 [-0.59647727]
 [-0.        ]
 [-0.        ]
 [-0.47883922]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.8854401 ]
 [-0.        ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.8360595703125, (277.83835, 0.3310897, 452.66663, 1.1698666)
   validation loss 458.1001281738281, (235.71147, 0.26202285, 222.12663, 1.1698666)
decoder loss ratio: 9131.871621, decoder SINDy loss  ratio: 0.479492
=========================
[[1.       ]
 [1.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.9998518]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.70381   ]
 [-0.68650085]
 [-0.586527  ]
 [-0.        ]
 [ 0.        ]
 [-0.403145  ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.8029642 ]
 [ 0.        ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.6392822265625, (331.31036, 0.23455453, 436.0944, 1.169823)
   validation loss 463.854736328125, (244.84068, 0.22554663, 218.78851, 1.169823)
decoder loss ratio: 9485.553121, decoder SINDy loss  ratio: 0.472286
=========================
[[1.       ]
 [1.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.9998567]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.7313857]
 [-0.7476829]
 [-0.6500745]
 [-0.       ]
 [-0.       ]
 [-0.4424298]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.8023838]
 [-0.       ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.9522705078125, (228.1563, 0.24872382, 440.54727, 1.1698436)
   validation loss 384.6468505859375, (164.69737, 0.2219708, 219.72752, 1.1698436)
decoder loss ratio: 6380.662135, decoder SINDy loss  ratio: 0.474313
=========================
[[1.        ]
 [1.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.99986386]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.726212  ]
 [-0.6655272 ]
 [-0.6369542 ]
 [ 0.        ]
 [ 0.        ]
 [-0.40434703]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.8261987 ]
 [ 0.        ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.78759765625, (293.4948, 0.24515352, 436.04764, 1.1698779)
   validation loss 425.7001953125, (207.57928, 0.22874115, 217.89215, 1.1698779)
decoder loss ratio: 8041.981862, decoder SINDy loss  ratio: 0.470351
=========================
[[1.       ]
 [1.       ]
 [0.9999945]
 [0.       ]
 [0.       ]
 [0.9998896]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.6958203 ]
 [-0.73465735]
 [-0.5281636 ]
 [ 0.        ]
 [ 0.        ]
 [-0.46041495]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.770311  ]
 [ 0.        ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.59423828125, (239.52708, 0.28652117, 448.7806, 1.1699098)
   validation loss 415.06536865234375, (192.56229, 0.23263995, 222.27045, 1.1699098)
decoder loss ratio: 7460.197277, decoder SINDy loss  ratio: 0.479802
=========================
[[1.        ]
 [1.        ]
 [0.9999945 ]
 [0.        ]
 [0.        ]
 [0.99986035]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.710271  ]
 [-0.66850734]
 [-0.56965303]
 [-0.        ]
 [-0.        ]
 [-0.40136895]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.7787656 ]
 [ 0.        ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.436767578125, (300.87216, 0.29220447, 468.27237, 1.1699157)
   validation loss 476.39862060546875, (244.41125, 0.23644814, 231.75092, 1.1699157)
decoder loss ratio: 9468.916331, decoder SINDy loss  ratio: 0.500267
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9998498 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.744749  ]
 [-0.69118744]
 [-0.5690872 ]
 [ 0.        ]
 [-0.        ]
 [-0.4424105 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.7941698 ]
 [ 0.        ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.7578125, (426.3627, 0.27824378, 477.1169, 1.169916)
   validation loss 618.1180419921875, (381.82034, 0.2297589, 236.06792, 1.169916)
decoder loss ratio: 14792.382958, decoder SINDy loss  ratio: 0.509586
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9998229 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.742929  ]
 [-0.61171514]
 [-0.5956981 ]
 [ 0.        ]
 [ 0.        ]
 [-0.45116657]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.7624005 ]
 [-0.        ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 825.996337890625, (389.4104, 0.22438698, 436.3615, 1.1699622)
   validation loss 506.72186279296875, (287.0148, 0.2247642, 219.48228, 1.1699622)
decoder loss ratio: 11119.451671, decoder SINDy loss  ratio: 0.473783
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.99984276]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.732456  ]
 [-0.6342914 ]
 [-0.54145795]
 [ 0.        ]
 [ 0.        ]
 [-0.39766863]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.7554533 ]
 [-0.        ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.126220703125, (218.82507, 0.263244, 441.0379, 1.1700076)
   validation loss 381.79681396484375, (161.35294, 0.2312691, 220.21263, 1.1700076)
decoder loss ratio: 6251.092854, decoder SINDy loss  ratio: 0.475360
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9998556 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7182083 ]
 [-0.61674803]
 [-0.59421504]
 [-0.        ]
 [ 0.        ]
 [-0.39276075]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.619514  ]
 [-0.        ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.0684204101562, (225.49522, 0.2809925, 445.2922, 1.17005)
   validation loss 398.0123291015625, (176.22037, 0.23281422, 221.55914, 1.17005)
decoder loss ratio: 6827.082966, decoder SINDy loss  ratio: 0.478267
=========================
[[1.       ]
 [1.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.9998522]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.7096143 ]
 [-0.58042777]
 [-0.57551986]
 [-0.        ]
 [ 0.        ]
 [-0.39735863]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.6954118 ]
 [-0.        ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.4309692382812, (241.73575, 0.250687, 436.44455, 1.1700678)
   validation loss 389.689697265625, (171.70084, 0.22133057, 217.76755, 1.1700678)
decoder loss ratio: 6651.988479, decoder SINDy loss  ratio: 0.470082
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9998493 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.796984  ]
 [-0.7090205 ]
 [-0.58418673]
 [-0.        ]
 [-0.        ]
 [-0.42522335]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.6854997 ]
 [-0.        ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.781005859375, (246.54584, 0.28294778, 450.9522, 1.1701008)
   validation loss 427.8917236328125, (203.71779, 0.23448007, 223.93947, 1.1701008)
decoder loss ratio: 7892.380804, decoder SINDy loss  ratio: 0.483405
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9997664 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.749771 ]
 [-0.6241106]
 [-0.5449257]
 [-0.       ]
 [-0.       ]
 [-0.4165424]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.6283189]
 [-0.       ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 820.4171142578125, (382.4971, 0.22385386, 437.6962, 1.1701106)
   validation loss 500.2427978515625, (280.3955, 0.22498706, 219.6223, 1.1701106)
decoder loss ratio: 10863.008761, decoder SINDy loss  ratio: 0.474086
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9997622 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7973843 ]
 [-0.6340212 ]
 [-0.5285198 ]
 [-0.        ]
 [-0.        ]
 [-0.41813305]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.6266006 ]
 [-0.        ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.8934326171875, (223.3751, 0.25198352, 440.26636, 1.1701126)
   validation loss 381.2808532714844, (160.55421, 0.22143476, 220.5052, 1.1701126)
decoder loss ratio: 6220.149003, decoder SINDy loss  ratio: 0.475991
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.99980557]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.7945046 ]
 [-0.625957  ]
 [-0.52369255]
 [ 0.        ]
 [ 0.        ]
 [-0.34838355]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.5565363 ]
 [-0.        ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.8082275390625, (397.54242, 0.23603328, 436.0298, 1.1701628)
   validation loss 512.338623046875, (293.1223, 0.22317216, 218.99313, 1.1701628)
decoder loss ratio: 11356.067345, decoder SINDy loss  ratio: 0.472727
=========================
[[1.        ]
 [1.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.99976915]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8461385 ]
 [-0.66319734]
 [-0.58776397]
 [ 0.        ]
 [ 0.        ]
 [-0.35420543]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.6192857 ]
 [-0.        ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.8252563476562, (248.2505, 0.24761692, 434.32712, 1.1701697)
   validation loss 392.8941345214844, (174.80254, 0.2193593, 217.87224, 1.1701697)
decoder loss ratio: 6772.153716, decoder SINDy loss  ratio: 0.470308
=========================
[[1.        ]
 [1.        ]
 [0.99999166]
 [0.        ]
 [0.        ]
 [0.9997507 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.804796  ]
 [-0.6403463 ]
 [-0.5199327 ]
 [ 0.        ]
 [ 0.        ]
 [-0.48018754]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-1.5833255 ]
 [ 0.        ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 887.2180786132812, (452.06717, 0.22426987, 434.92664, 1.170174)
   validation loss 561.9957275390625, (342.13663, 0.21282741, 219.6463, 1.170174)
decoder loss ratio: 13254.966913, decoder SINDy loss  ratio: 0.474137
=========================
[[1.        ]
 [1.        ]
 [0.9999895 ]
 [0.        ]
 [0.        ]
 [0.99977016]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.851767  ]
 [-0.6855072 ]
 [-0.5556048 ]
 [ 0.        ]
 [-0.        ]
 [-0.40340787]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.5883673 ]
 [-0.        ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.80810546875, (230.06238, 0.23786135, 434.50784, 1.1702145)
   validation loss 382.02191162109375, (163.66708, 0.21971333, 218.1351, 1.1702145)
decoder loss ratio: 6340.746963, decoder SINDy loss  ratio: 0.470875
=========================
[[1.       ]
 [1.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.9997944]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.758077  ]
 [-0.6811228 ]
 [-0.48623142]
 [-0.        ]
 [-0.        ]
 [-0.34907457]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-1.5269198 ]
 [-0.        ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.3759765625, (221.43188, 0.28067505, 442.66345, 1.1702503)
   validation loss 391.365234375, (170.05269, 0.2303686, 221.0822, 1.1702503)
decoder loss ratio: 6588.136381, decoder SINDy loss  ratio: 0.477237
=========================
[[1.        ]
 [1.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.9997698 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8458385 ]
 [-0.68424857]
 [-0.5498795 ]
 [-0.        ]
 [ 0.        ]
 [-0.4360342 ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-1.5509306 ]
 [ 0.        ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1652.5682373046875, (1107.8391, 0.33974302, 544.3894, 1.1702532)
   validation loss 1310.2098388671875, (1039.311, 0.2392415, 270.65958, 1.1702532)
decoder loss ratio: 40264.713825, decoder SINDy loss  ratio: 0.584257
=========================
[[1.       ]
 [1.       ]
 [0.9999895]
 [0.       ]
 [0.       ]
 [0.9997159]
 [0.       ]
 [0.       ]
 [0.       ]
 [1.       ]
 [0.       ]]
[[-4.8324423 ]
 [-0.65771794]
 [-0.54931366]
 [-0.        ]
 [-0.        ]
 [-0.33576074]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.4947017 ]
 [ 0.        ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.9686889648438, (326.71344, 0.2379621, 434.01727, 1.1702852)
   validation loss 460.9831848144531, (242.18843, 0.22239399, 218.57236, 1.1702852)
decoder loss ratio: 9382.800266, decoder SINDy loss  ratio: 0.471819
=========================
[[1.        ]
 [1.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.99974114]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.8094115]
 [-0.6604094]
 [-0.5458808]
 [ 0.       ]
 [ 0.       ]
 [-0.4351908]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5301192]
 [-0.       ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.0791015625, (280.76367, 0.22962424, 433.0858, 1.1703113)
   validation loss 419.1123962402344, (200.95035, 0.21731122, 217.94473, 1.1703113)
decoder loss ratio: 7785.165343, decoder SINDy loss  ratio: 0.470464
=========================
[[1.        ]
 [1.        ]
 [0.9999877 ]
 [0.        ]
 [0.        ]
 [0.99974215]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.9104724]
 [-0.6454277]
 [-0.4930488]
 [-0.       ]
 [ 0.       ]
 [-0.4636358]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.4103388]
 [-0.       ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.8858642578125, (233.52, 0.24961488, 436.11627, 1.1703618)
   validation loss 386.023681640625, (166.71959, 0.22653627, 219.07755, 1.1703618)
decoder loss ratio: 6459.006325, decoder SINDy loss  ratio: 0.472910
=========================
[[1.        ]
 [1.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.9997901 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.9199967 ]
 [-0.6702402 ]
 [-0.54705596]
 [-0.        ]
 [-0.        ]
 [-0.44112834]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-1.4246662 ]
 [ 0.        ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.4949951171875, (229.7793, 0.29917088, 440.41653, 1.1704113)
   validation loss 397.67401123046875, (178.06409, 0.23106891, 219.37886, 1.1704113)
decoder loss ratio: 6898.511860, decoder SINDy loss  ratio: 0.473560
=========================
[[1.        ]
 [1.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.99970883]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.890725  ]
 [-0.62622   ]
 [-0.5853404 ]
 [-0.        ]
 [ 0.        ]
 [-0.35126266]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.5407245 ]
 [ 0.        ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1143.6025390625, (645.92065, 0.34725395, 497.3346, 1.170414)
   validation loss 841.0283203125, (594.65704, 0.24494056, 246.12636, 1.170414)
decoder loss ratio: 23038.046234, decoder SINDy loss  ratio: 0.531298
=========================
[[1.        ]
 [1.        ]
 [0.99998856]
 [0.        ]
 [0.        ]
 [0.99966705]
 [0.        ]
 [0.        ]
 [0.        ]
 [1.        ]
 [0.        ]]
[[-4.902174  ]
 [-0.7204508 ]
 [-0.59000874]
 [-0.        ]
 [ 0.        ]
 [-0.33448663]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-1.5087866 ]
 [ 0.        ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 869.8986206054688, (434.4949, 0.22446409, 435.17926, 1.1704366)
   validation loss 552.3067626953125, (331.7787, 0.22327809, 220.30478, 1.1704366)
decoder loss ratio: 12853.682309, decoder SINDy loss  ratio: 0.475559
params['save_name']
pendulum_2023_10_29_04_58_27_748054
