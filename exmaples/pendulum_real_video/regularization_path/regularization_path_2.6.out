nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-26 04:58:02.206302: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-26 04:58:02.213886: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-26 04:58:02.215660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560cd2df84c0 executing computations on platform Host. Devices:
2023-10-26 04:58:02.215763: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-26 04:58:02.217632: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-26 04:58:02.336189: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560cd2eed0d0 executing computations on platform CUDA. Devices:
2023-10-26 04:58:02.336253: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-26 04:58:02.337234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-26 04:58:02.337831: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-26 04:58:02.339518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-26 04:58:02.340946: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-26 04:58:02.341205: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-26 04:58:02.342898: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-26 04:58:02.343754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-26 04:58:02.347009: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-26 04:58:02.347605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-26 04:58:02.347636: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-26 04:58:02.347967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-26 04:58:02.347976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-26 04:58:02.347981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-26 04:58:02.348552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-26 04:58:03.436931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 2.6, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.841850996017456 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 116164.09375, (108556.4, 0.003863857, 7588.7563, 2.5317829)
   validation loss 95350.0859375, (94130.4, 0.0031845935, 1200.7526, 2.5317829)
decoder loss ratio: 3646775.053027, decoder SINDy loss  ratio: 2.591993
--- 0.26836466789245605 seconds for one epoch ---
--- 0.3321382999420166 seconds for one epoch ---
--- 0.3314075469970703 seconds for one epoch ---
--- 0.3303556442260742 seconds for one epoch ---
--- 0.3399229049682617 seconds for one epoch ---
--- 0.30805158615112305 seconds for one epoch ---
--- 0.33472156524658203 seconds for one epoch ---
--- 0.3219919204711914 seconds for one epoch ---
--- 0.31556177139282227 seconds for one epoch ---
--- 0.3326122760772705 seconds for one epoch ---
--- 0.2934591770172119 seconds for one epoch ---
--- 0.31055760383605957 seconds for one epoch ---
--- 0.32015395164489746 seconds for one epoch ---
--- 0.32717180252075195 seconds for one epoch ---
--- 0.3392322063446045 seconds for one epoch ---
--- 0.31698179244995117 seconds for one epoch ---
--- 0.3189668655395508 seconds for one epoch ---
--- 0.3201141357421875 seconds for one epoch ---
--- 0.3348979949951172 seconds for one epoch ---
--- 0.3278157711029053 seconds for one epoch ---
--- 0.32055234909057617 seconds for one epoch ---
--- 0.30957508087158203 seconds for one epoch ---
--- 0.31000709533691406 seconds for one epoch ---
--- 0.3179318904876709 seconds for one epoch ---
=========================
[[0.7819693 ]
 [0.7829136 ]
 [0.7835785 ]
 [0.78386515]
 [0.7806907 ]
 [0.78415376]
 [0.78448915]
 [0.78136677]
 [0.7803882 ]
 [0.7882511 ]
 [0.78203315]]
[[ 0.4484562 ]
 [ 0.69389963]
 [-0.8593291 ]
 [-0.92909   ]
 [-0.09294093]
 [-0.9982946 ]
 [ 1.0776317 ]
 [-0.28454763]
 [ 0.00416622]
 [-1.9013532 ]
 [ 0.46547177]]
--- 0.25881290435791016 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 64196.671875, (59538.652, 18.471395, 4599.1304, 2.531779)
   validation loss 49319.51171875, (47972.676, 11.012425, 1295.4045, 2.531779)
decoder loss ratio: 1858544.743993, decoder SINDy loss  ratio: 2.796313
--- 0.3223690986633301 seconds for one epoch ---
--- 0.3293774127960205 seconds for one epoch ---
--- 0.31524658203125 seconds for one epoch ---
--- 0.33179712295532227 seconds for one epoch ---
--- 0.3159902095794678 seconds for one epoch ---
--- 0.3435649871826172 seconds for one epoch ---
--- 0.323075532913208 seconds for one epoch ---
--- 0.35158324241638184 seconds for one epoch ---
--- 0.2930889129638672 seconds for one epoch ---
--- 0.34002065658569336 seconds for one epoch ---
--- 0.3259403705596924 seconds for one epoch ---
--- 0.3283705711364746 seconds for one epoch ---
--- 0.31435441970825195 seconds for one epoch ---
--- 0.33462095260620117 seconds for one epoch ---
--- 0.3232142925262451 seconds for one epoch ---
--- 0.3449709415435791 seconds for one epoch ---
--- 0.3228306770324707 seconds for one epoch ---
--- 0.32787036895751953 seconds for one epoch ---
--- 0.3196890354156494 seconds for one epoch ---
--- 0.35084080696105957 seconds for one epoch ---
--- 0.32632923126220703 seconds for one epoch ---
--- 0.3428986072540283 seconds for one epoch ---
--- 0.3134584426879883 seconds for one epoch ---
--- 0.3396129608154297 seconds for one epoch ---
=========================
[[0.633495  ]
 [0.6270727 ]
 [0.62879544]
 [0.628791  ]
 [0.6245934 ]
 [0.62913024]
 [0.62985134]
 [0.62444717]
 [0.62436455]
 [0.62973875]
 [0.626753  ]]
[[ 1.3712151 ]
 [ 0.46170846]
 [-0.7222218 ]
 [-0.72158176]
 [-0.05772352]
 [-0.77123755]
 [ 0.8751937 ]
 [-0.03261381]
 [ 0.0183704 ]
 [-0.85907704]
 [ 0.41167453]]
--- 0.30413103103637695 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 50180.890625, (40345.605, 49.029034, 9725.161, 2.5317388)
   validation loss 42150.6171875, (40853.836, 5.9877563, 1229.6943, 2.5317388)
decoder loss ratio: 1582748.529597, decoder SINDy loss  ratio: 2.654468
--- 0.2730441093444824 seconds for one epoch ---
--- 0.3337264060974121 seconds for one epoch ---
--- 0.3493635654449463 seconds for one epoch ---
--- 0.311995267868042 seconds for one epoch ---
--- 0.3397023677825928 seconds for one epoch ---
--- 0.29961681365966797 seconds for one epoch ---
--- 0.32023096084594727 seconds for one epoch ---
--- 0.3000805377960205 seconds for one epoch ---
--- 0.3199012279510498 seconds for one epoch ---
--- 0.30077481269836426 seconds for one epoch ---
--- 0.3302421569824219 seconds for one epoch ---
--- 0.2874155044555664 seconds for one epoch ---
--- 0.34067773818969727 seconds for one epoch ---
--- 0.29738593101501465 seconds for one epoch ---
--- 0.3476746082305908 seconds for one epoch ---
--- 0.3871135711669922 seconds for one epoch ---
--- 0.32487940788269043 seconds for one epoch ---
--- 0.2907707691192627 seconds for one epoch ---
--- 0.33763933181762695 seconds for one epoch ---
--- 0.2982490062713623 seconds for one epoch ---
--- 0.34926939010620117 seconds for one epoch ---
--- 0.31570935249328613 seconds for one epoch ---
--- 0.3508415222167969 seconds for one epoch ---
--- 0.3059358596801758 seconds for one epoch ---
=========================
[[0.50944346]
 [0.49389547]
 [0.4972581 ]
 [0.49764556]
 [0.49396968]
 [0.50122494]
 [0.4978679 ]
 [0.49498573]
 [0.4935349 ]
 [0.49651065]
 [0.4960619 ]]
[[ 1.7005432 ]
 [ 0.05119554]
 [-0.4581345 ]
 [-0.5026711 ]
 [-0.06064611]
 [-0.89526415]
 [ 0.52805793]
 [ 0.18752183]
 [ 0.0051351 ]
 [-0.37098253]
 [ 0.31777287]]
--- 0.2689976692199707 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 26469.97265625, (21383.97, 25.465971, 4983.3926, 2.5317228)
   validation loss 18376.69140625, (17207.396, 0.54327124, 1091.6093, 2.5317228)
decoder loss ratio: 666644.413159, decoder SINDy loss  ratio: 2.356392
--- 0.33008289337158203 seconds for one epoch ---
--- 0.36701202392578125 seconds for one epoch ---
--- 0.3241910934448242 seconds for one epoch ---
--- 0.3667008876800537 seconds for one epoch ---
--- 0.33446621894836426 seconds for one epoch ---
--- 0.3698430061340332 seconds for one epoch ---
--- 0.3194448947906494 seconds for one epoch ---
--- 0.39142441749572754 seconds for one epoch ---
--- 0.3141212463378906 seconds for one epoch ---
--- 0.37459325790405273 seconds for one epoch ---
--- 0.3188948631286621 seconds for one epoch ---
--- 0.36473751068115234 seconds for one epoch ---
--- 0.3218226432800293 seconds for one epoch ---
--- 0.37339353561401367 seconds for one epoch ---
--- 0.31704187393188477 seconds for one epoch ---
--- 0.3585801124572754 seconds for one epoch ---
--- 0.3309047222137451 seconds for one epoch ---
--- 0.35961389541625977 seconds for one epoch ---
--- 0.3417689800262451 seconds for one epoch ---
--- 0.356550931930542 seconds for one epoch ---
--- 0.3130004405975342 seconds for one epoch ---
--- 0.35589098930358887 seconds for one epoch ---
--- 0.3300457000732422 seconds for one epoch ---
--- 0.3849165439605713 seconds for one epoch ---
=========================
[[0.4155873 ]
 [0.4014216 ]
 [0.40140533]
 [0.40335974]
 [0.40048054]
 [0.41547674]
 [0.403783  ]
 [0.40254894]
 [0.39998493]
 [0.40382522]
 [0.4025793 ]]
[[ 1.441631  ]
 [-0.15485966]
 [-0.15312222]
 [-0.3528706 ]
 [-0.0551865 ]
 [-1.4326884 ]
 [ 0.39490795]
 [ 0.2711243 ]
 [-0.00169968]
 [-0.39908868]
 [ 0.27421662]]
--- 0.2998473644256592 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 19757.8359375, (16612.64, 6.8484716, 3046.5696, 2.5317228)
   validation loss 9256.5771484375, (8288.662, 0.42819843, 875.7089, 2.5317228)
decoder loss ratio: 321117.159867, decoder SINDy loss  ratio: 1.890341
--- 0.2697296142578125 seconds for one epoch ---
--- 0.3273153305053711 seconds for one epoch ---
--- 0.34416675567626953 seconds for one epoch ---
--- 0.31100010871887207 seconds for one epoch ---
--- 0.364948034286499 seconds for one epoch ---
--- 0.31406354904174805 seconds for one epoch ---
--- 0.3765416145324707 seconds for one epoch ---
--- 0.32376575469970703 seconds for one epoch ---
--- 0.3677830696105957 seconds for one epoch ---
--- 0.3193778991699219 seconds for one epoch ---
--- 0.36623454093933105 seconds for one epoch ---
--- 0.3166954517364502 seconds for one epoch ---
--- 0.37854528427124023 seconds for one epoch ---
--- 0.32369494438171387 seconds for one epoch ---
--- 0.3885188102722168 seconds for one epoch ---
--- 0.33035969734191895 seconds for one epoch ---
--- 0.3692746162414551 seconds for one epoch ---
--- 0.3190269470214844 seconds for one epoch ---
--- 0.35518431663513184 seconds for one epoch ---
--- 0.31374096870422363 seconds for one epoch ---
--- 0.38588643074035645 seconds for one epoch ---
--- 0.31375908851623535 seconds for one epoch ---
--- 0.3613576889038086 seconds for one epoch ---
--- 0.33467841148376465 seconds for one epoch ---
=========================
[[0.33285052]
 [0.32373714]
 [0.3222667 ]
 [0.3225584 ]
 [0.3214069 ]
 [0.34680822]
 [0.32515353]
 [0.32459033]
 [0.3211832 ]
 [0.3284834 ]
 [0.32457507]]
[[ 0.9992738 ]
 [-0.24078162]
 [ 0.10539767]
 [-0.1325932 ]
 [-0.02412735]
 [-1.9878678 ]
 [ 0.36717644]
 [ 0.31735024]
 [-0.0027169 ]
 [-0.6509707 ]
 [ 0.31598625]]
--- 0.2521975040435791 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 20612.095703125, (14795.3545, 56.44961, 5653.441, 2.5317345)
   validation loss 6514.677734375, (5654.741, 0.16707571, 752.9184, 2.5317345)
decoder loss ratio: 219074.491574, decoder SINDy loss  ratio: 1.625280
--- 0.3300940990447998 seconds for one epoch ---
--- 0.382265567779541 seconds for one epoch ---
--- 0.3208169937133789 seconds for one epoch ---
--- 0.3442091941833496 seconds for one epoch ---
--- 0.3313028812408447 seconds for one epoch ---
--- 0.36625099182128906 seconds for one epoch ---
--- 0.34685587882995605 seconds for one epoch ---
--- 0.37238645553588867 seconds for one epoch ---
--- 0.3088564872741699 seconds for one epoch ---
--- 0.36699509620666504 seconds for one epoch ---
--- 0.3131101131439209 seconds for one epoch ---
--- 0.3611025810241699 seconds for one epoch ---
--- 0.32592320442199707 seconds for one epoch ---
--- 0.38999199867248535 seconds for one epoch ---
--- 0.33641529083251953 seconds for one epoch ---
--- 0.38047337532043457 seconds for one epoch ---
--- 0.3235301971435547 seconds for one epoch ---
--- 0.3552570343017578 seconds for one epoch ---
--- 0.3038005828857422 seconds for one epoch ---
--- 0.3740096092224121 seconds for one epoch ---
--- 0.34328413009643555 seconds for one epoch ---
--- 0.38020968437194824 seconds for one epoch ---
--- 0.3304610252380371 seconds for one epoch ---
--- 0.3686048984527588 seconds for one epoch ---
=========================
[[0.27015495]
 [0.26782325]
 [0.2677343 ]
 [0.26542062]
 [0.26471227]
 [0.3017303 ]
 [0.26845315]
 [0.26795524]
 [0.26450336]
 [0.2773612 ]
 [0.26891044]]
[[ 0.4777288 ]
 [-0.28911278]
 [ 0.28173372]
 [-0.08568746]
 [-0.02374762]
 [-2.5464966 ]
 [ 0.34088653]
 [ 0.30002022]
 [-0.00529008]
 [-1.0166695 ]
 [ 0.37804842]]
--- 0.30619239807128906 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10174.1083984375, (6186.98, 0.7920231, 3866.3352, 2.5317628)
   validation loss 6445.10107421875, (5709.769, 0.1219014, 615.20935, 2.5317628)
decoder loss ratio: 221206.365320, decoder SINDy loss  ratio: 1.328016
--- 0.27135467529296875 seconds for one epoch ---
--- 0.29673051834106445 seconds for one epoch ---
--- 0.37102603912353516 seconds for one epoch ---
--- 0.3222777843475342 seconds for one epoch ---
--- 0.3730051517486572 seconds for one epoch ---
--- 0.3376178741455078 seconds for one epoch ---
--- 0.3894047737121582 seconds for one epoch ---
--- 0.3147914409637451 seconds for one epoch ---
--- 0.40596556663513184 seconds for one epoch ---
--- 0.3237943649291992 seconds for one epoch ---
--- 0.3830277919769287 seconds for one epoch ---
--- 0.32569217681884766 seconds for one epoch ---
--- 0.39742112159729004 seconds for one epoch ---
--- 0.31307053565979004 seconds for one epoch ---
--- 0.379321813583374 seconds for one epoch ---
--- 0.3056776523590088 seconds for one epoch ---
--- 0.3861241340637207 seconds for one epoch ---
--- 0.3218801021575928 seconds for one epoch ---
--- 0.40042757987976074 seconds for one epoch ---
--- 0.3150660991668701 seconds for one epoch ---
--- 0.40814828872680664 seconds for one epoch ---
--- 0.30646491050720215 seconds for one epoch ---
--- 0.39263296127319336 seconds for one epoch ---
--- 0.3185460567474365 seconds for one epoch ---
=========================
[[0.2174347 ]
 [0.22082756]
 [0.22212343]
 [0.21691409]
 [0.2164462 ]
 [0.26450664]
 [0.22054358]
 [0.22037883]
 [0.21645603]
 [0.23442869]
 [0.2222107 ]]
[[ 0.08761421]
 [-0.3551086 ]
 [ 0.4530469 ]
 [-0.04499828]
 [-0.00635049]
 [-2.990076  ]
 [ 0.33335057]
 [ 0.3206757 ]
 [-0.00715148]
 [-1.2954279 ]
 [ 0.45956758]]
--- 0.2789347171783447 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12907.3447265625, (9171.972, 3.8263004, 3600.1182, 2.5317965)
   validation loss 4280.15966796875, (3545.9316, 0.0694119, 602.731, 2.5317965)
decoder loss ratio: 137375.547766, decoder SINDy loss  ratio: 1.301080
--- 0.3122518062591553 seconds for one epoch ---
--- 0.3805356025695801 seconds for one epoch ---
--- 0.30156588554382324 seconds for one epoch ---
--- 0.39205098152160645 seconds for one epoch ---
--- 0.3162086009979248 seconds for one epoch ---
--- 0.39020442962646484 seconds for one epoch ---
--- 0.31421399116516113 seconds for one epoch ---
--- 0.40309762954711914 seconds for one epoch ---
--- 0.3189096450805664 seconds for one epoch ---
--- 0.41380739212036133 seconds for one epoch ---
--- 0.30740857124328613 seconds for one epoch ---
--- 0.41156911849975586 seconds for one epoch ---
--- 0.307492733001709 seconds for one epoch ---
--- 0.42128801345825195 seconds for one epoch ---
--- 0.31031274795532227 seconds for one epoch ---
--- 0.39395833015441895 seconds for one epoch ---
--- 0.3300015926361084 seconds for one epoch ---
--- 0.4157700538635254 seconds for one epoch ---
--- 0.33432674407958984 seconds for one epoch ---
--- 0.4109830856323242 seconds for one epoch ---
--- 0.33657264709472656 seconds for one epoch ---
--- 0.39367079734802246 seconds for one epoch ---
--- 0.34182143211364746 seconds for one epoch ---
--- 0.4033811092376709 seconds for one epoch ---
=========================
[[0.18421958]
 [0.18655385]
 [0.18975389]
 [0.18166117]
 [0.1815765 ]
 [0.23818989]
 [0.18582012]
 [0.1858243 ]
 [0.18159206]
 [0.2042624 ]
 [0.18902558]]
[[-2.0545179e-01]
 [-3.7873709e-01]
 [ 6.0578465e-01]
 [-6.8955794e-03]
 [ 1.7322093e-04]
 [-3.3025062e+00]
 [ 3.2501075e-01]
 [ 3.2530850e-01]
 [-1.4070343e-03]
 [-1.5230321e+00]
 [ 5.5508280e-01]]
--- 0.3001523017883301 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7804.70654296875, (3559.6567, 0.5010965, 4104.493, 2.5318313)
   validation loss 2169.104736328125, (1529.0675, 0.055559233, 499.92612, 2.5318313)
decoder loss ratio: 59238.729717, decoder SINDy loss  ratio: 1.079161
--- 0.27111029624938965 seconds for one epoch ---
--- 0.32502079010009766 seconds for one epoch ---
--- 0.4277493953704834 seconds for one epoch ---
--- 0.306133508682251 seconds for one epoch ---
--- 0.3895144462585449 seconds for one epoch ---
--- 0.31337738037109375 seconds for one epoch ---
--- 0.4239006042480469 seconds for one epoch ---
--- 0.31141114234924316 seconds for one epoch ---
--- 0.4158895015716553 seconds for one epoch ---
--- 0.3197622299194336 seconds for one epoch ---
--- 0.39180755615234375 seconds for one epoch ---
--- 0.3264048099517822 seconds for one epoch ---
--- 0.39765095710754395 seconds for one epoch ---
--- 0.3027186393737793 seconds for one epoch ---
--- 0.4184906482696533 seconds for one epoch ---
--- 0.4170711040496826 seconds for one epoch ---
--- 0.3967113494873047 seconds for one epoch ---
--- 0.3147273063659668 seconds for one epoch ---
--- 0.41728830337524414 seconds for one epoch ---
--- 0.3239586353302002 seconds for one epoch ---
--- 0.42075347900390625 seconds for one epoch ---
--- 0.31995081901550293 seconds for one epoch ---
--- 0.40927672386169434 seconds for one epoch ---
--- 0.31734752655029297 seconds for one epoch ---
=========================
[[0.15855163]
 [0.15807205]
 [0.1625799 ]
 [0.15217037]
 [0.15194175]
 [0.21580638]
 [0.15550183]
 [0.15626709]
 [0.15193562]
 [0.18003654]
 [0.16081592]]
[[-4.8173609e-01]
 [-4.4870248e-01]
 [ 7.5024670e-01]
 [-2.0124411e-02]
 [-2.5996852e-03]
 [-3.5483072e+00]
 [ 2.6733404e-01]
 [ 3.2213485e-01]
 [-2.1131132e-03]
 [-1.7782348e+00]
 [ 6.3454688e-01]]
--- 0.2834324836730957 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7769.67138671875, (5444.591, 2.8802621, 2173.415, 2.5318682)
   validation loss 2471.2392578125, (1881.4717, 0.04018086, 440.94202, 2.5318682)
decoder loss ratio: 72891.479250, decoder SINDy loss  ratio: 0.951835
--- 0.3158407211303711 seconds for one epoch ---
--- 0.4171023368835449 seconds for one epoch ---
--- 0.3279094696044922 seconds for one epoch ---
--- 0.44767165184020996 seconds for one epoch ---
--- 0.3258042335510254 seconds for one epoch ---
--- 0.4195058345794678 seconds for one epoch ---
--- 0.31499552726745605 seconds for one epoch ---
--- 0.4414958953857422 seconds for one epoch ---
--- 0.32674360275268555 seconds for one epoch ---
--- 0.405620813369751 seconds for one epoch ---
--- 0.3187367916107178 seconds for one epoch ---
--- 0.42997026443481445 seconds for one epoch ---
--- 0.3048880100250244 seconds for one epoch ---
--- 0.4250068664550781 seconds for one epoch ---
--- 0.3014109134674072 seconds for one epoch ---
--- 0.42761731147766113 seconds for one epoch ---
--- 0.3010413646697998 seconds for one epoch ---
--- 0.42195558547973633 seconds for one epoch ---
--- 0.31032896041870117 seconds for one epoch ---
--- 0.4218716621398926 seconds for one epoch ---
--- 0.30428647994995117 seconds for one epoch ---
--- 0.42074084281921387 seconds for one epoch ---
--- 0.3092169761657715 seconds for one epoch ---
--- 0.4452390670776367 seconds for one epoch ---
=========================
[[0.14004959]
 [0.13750991]
 [0.14348266]
 [0.1306487 ]
 [0.13045727]
 [0.19865659]
 [0.13366954]
 [0.13488422]
 [0.13032083]
 [0.16291524]
 [0.13928822]]
[[-6.7340112e-01]
 [-5.0742388e-01]
 [ 8.8901776e-01]
 [ 2.5151890e-02]
 [-1.0859559e-02]
 [-3.6768572e+00]
 [ 2.4423477e-01]
 [ 3.2919481e-01]
 [ 6.4232637e-04]
 [-1.9743558e+00]
 [ 6.2425184e-01]]
--- 0.32155942916870117 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7838.8759765625, (5796.1616, 10.730204, 1875.0996, 2.5318944)
   validation loss 13101.9736328125, (12144.323, 0.042012323, 800.7236, 2.5318944)
decoder loss ratio: 470492.165875, decoder SINDy loss  ratio: 1.728474
--- 0.2547943592071533 seconds for one epoch ---
--- 0.3101634979248047 seconds for one epoch ---
--- 0.4420948028564453 seconds for one epoch ---
--- 0.3285102844238281 seconds for one epoch ---
--- 0.4522566795349121 seconds for one epoch ---
--- 0.3145308494567871 seconds for one epoch ---
--- 0.42816734313964844 seconds for one epoch ---
--- 0.3286418914794922 seconds for one epoch ---
--- 0.44913458824157715 seconds for one epoch ---
--- 0.3138265609741211 seconds for one epoch ---
--- 0.41492390632629395 seconds for one epoch ---
--- 0.3166842460632324 seconds for one epoch ---
--- 0.45167970657348633 seconds for one epoch ---
--- 0.32057976722717285 seconds for one epoch ---
--- 0.42244410514831543 seconds for one epoch ---
--- 0.32398271560668945 seconds for one epoch ---
--- 0.41082143783569336 seconds for one epoch ---
--- 0.31038451194763184 seconds for one epoch ---
--- 0.4215090274810791 seconds for one epoch ---
--- 0.32962894439697266 seconds for one epoch ---
--- 0.45984816551208496 seconds for one epoch ---
--- 0.3322887420654297 seconds for one epoch ---
--- 0.42371463775634766 seconds for one epoch ---
--- 0.3117339611053467 seconds for one epoch ---
=========================
[[0.12431052]
 [0.11941855]
 [0.12742583]
 [0.11285564]
 [0.11186527]
 [0.182927  ]
 [0.11535432]
 [0.1162982 ]
 [0.11181059]
 [0.14870226]
 [0.12146685]]
[[-8.3234656e-01]
 [-5.2507514e-01]
 [ 1.0185083e+00]
 [ 7.7045649e-02]
 [ 5.0811497e-03]
 [-3.7362130e+00]
 [ 2.5318098e-01]
 [ 3.1783888e-01]
 [-1.0654948e-03]
 [-2.1543703e+00]
 [ 6.5614796e-01]]
--- 0.2606470584869385 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6649.29736328125, (3661.2695, 1.162075, 2823.4097, 2.5319145)
   validation loss 4544.96484375, (3952.6338, 0.033547804, 428.8413, 2.5319145)
decoder loss ratio: 153131.895062, decoder SINDy loss  ratio: 0.925714
--- 0.3148808479309082 seconds for one epoch ---
--- 0.4410288333892822 seconds for one epoch ---
--- 0.31511545181274414 seconds for one epoch ---
--- 0.4533350467681885 seconds for one epoch ---
--- 0.34452033042907715 seconds for one epoch ---
--- 0.4369239807128906 seconds for one epoch ---
--- 0.3089616298675537 seconds for one epoch ---
--- 0.4377131462097168 seconds for one epoch ---
--- 0.29567480087280273 seconds for one epoch ---
--- 0.40770506858825684 seconds for one epoch ---
--- 0.3212118148803711 seconds for one epoch ---
--- 0.4657113552093506 seconds for one epoch ---
--- 0.3148484230041504 seconds for one epoch ---
--- 0.4504685401916504 seconds for one epoch ---
--- 0.3200671672821045 seconds for one epoch ---
--- 0.4393734931945801 seconds for one epoch ---
--- 0.3469352722167969 seconds for one epoch ---
--- 0.4655187129974365 seconds for one epoch ---
--- 0.32700276374816895 seconds for one epoch ---
--- 0.44322991371154785 seconds for one epoch ---
--- 0.3129730224609375 seconds for one epoch ---
--- 0.4645555019378662 seconds for one epoch ---
--- 0.3163895606994629 seconds for one epoch ---
--- 0.4561455249786377 seconds for one epoch ---
=========================
[[0.11304625]
 [0.1063313 ]
 [0.1157646 ]
 [0.09948632]
 [0.0984414 ]
 [0.17022432]
 [0.10146773]
 [0.10290917]
 [0.09831144]
 [0.13903171]
 [0.10885511]]
[[-0.956653  ]
 [-0.5474608 ]
 [ 1.1133305 ]
 [ 0.08900873]
 [-0.0144249 ]
 [-3.7259555 ]
 [ 0.22682479]
 [ 0.32431993]
 [-0.0050537 ]
 [-2.3142962 ]
 [ 0.70531577]]
--- 0.3001115322113037 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7164.75634765625, (3485.0557, 3.4503746, 3507.3896, 2.5319293)
   validation loss 2629.216796875, (2076.87, 0.031466078, 383.4539, 2.5319293)
decoder loss ratio: 80461.553945, decoder SINDy loss  ratio: 0.827739
--- 0.2675597667694092 seconds for one epoch ---
--- 0.3271753787994385 seconds for one epoch ---
--- 0.4361581802368164 seconds for one epoch ---
--- 0.3219718933105469 seconds for one epoch ---
--- 0.45906567573547363 seconds for one epoch ---
--- 0.31222033500671387 seconds for one epoch ---
--- 0.4591352939605713 seconds for one epoch ---
--- 0.3009488582611084 seconds for one epoch ---
--- 0.44373321533203125 seconds for one epoch ---
--- 0.3090815544128418 seconds for one epoch ---
--- 0.4496769905090332 seconds for one epoch ---
--- 0.3135838508605957 seconds for one epoch ---
--- 0.45252513885498047 seconds for one epoch ---
--- 0.33443260192871094 seconds for one epoch ---
--- 0.4459855556488037 seconds for one epoch ---
--- 0.31702113151550293 seconds for one epoch ---
--- 0.44290924072265625 seconds for one epoch ---
--- 0.3211493492126465 seconds for one epoch ---
--- 0.4541130065917969 seconds for one epoch ---
--- 0.31029772758483887 seconds for one epoch ---
--- 0.4456188678741455 seconds for one epoch ---
--- 0.3137814998626709 seconds for one epoch ---
--- 0.46880149841308594 seconds for one epoch ---
--- 0.32192373275756836 seconds for one epoch ---
=========================
[[0.10334377]
 [0.0953462 ]
 [0.10615353]
 [0.08807781]
 [0.08678405]
 [0.15805848]
 [0.08961239]
 [0.0913207 ]
 [0.08662318]
 [0.13125011]
 [0.0975481 ]]
[[-1.0590913 ]
 [-0.58471304]
 [ 1.2159756 ]
 [ 0.10717224]
 [-0.01623755]
 [-3.664681  ]
 [ 0.21249734]
 [ 0.32672873]
 [-0.00478619]
 [-2.4720757 ]
 [ 0.7199246 ]]
--- 0.26058316230773926 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6482.1201171875, (4100.056, 3.1266968, 2206.3953, 2.53194)
   validation loss 1897.5865478515625, (1393.9464, 0.037975803, 331.06018, 2.53194)
decoder loss ratio: 54003.903965, decoder SINDy loss  ratio: 0.714640
--- 0.30496644973754883 seconds for one epoch ---
--- 0.4615762233734131 seconds for one epoch ---
--- 0.3112363815307617 seconds for one epoch ---
--- 0.44821834564208984 seconds for one epoch ---
--- 0.301577091217041 seconds for one epoch ---
--- 0.454298734664917 seconds for one epoch ---
--- 0.3062725067138672 seconds for one epoch ---
--- 0.46121835708618164 seconds for one epoch ---
--- 0.30808568000793457 seconds for one epoch ---
--- 0.4770052433013916 seconds for one epoch ---
--- 0.30515003204345703 seconds for one epoch ---
--- 0.47196292877197266 seconds for one epoch ---
--- 0.302567720413208 seconds for one epoch ---
--- 0.4522664546966553 seconds for one epoch ---
--- 0.3093845844268799 seconds for one epoch ---
--- 0.4694969654083252 seconds for one epoch ---
--- 0.3009486198425293 seconds for one epoch ---
--- 0.4842343330383301 seconds for one epoch ---
--- 0.3076927661895752 seconds for one epoch ---
--- 0.4617958068847656 seconds for one epoch ---
--- 0.30639171600341797 seconds for one epoch ---
--- 0.47812724113464355 seconds for one epoch ---
--- 0.3313877582550049 seconds for one epoch ---
--- 0.44891858100891113 seconds for one epoch ---
=========================
[[0.09660901]
 [0.08727442]
 [0.0993197 ]
 [0.08015238]
 [0.0783482 ]
 [0.14864531]
 [0.08096494]
 [0.0825372 ]
 [0.07804324]
 [0.12639049]
 [0.08974441]]
[[-1.1541039 ]
 [-0.6121674 ]
 [ 1.3016552 ]
 [ 0.15245894]
 [-0.02769138]
 [-3.6008108 ]
 [ 0.2074348 ]
 [ 0.31182447]
 [-0.00621949]
 [-2.623567  ]
 [ 0.76136005]]
--- 0.30790209770202637 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4901.2880859375, (2489.7148, 4.679725, 2229.5793, 2.5319507)
   validation loss 1287.048095703125, (754.8634, 0.026920674, 354.8429, 2.5319507)
decoder loss ratio: 29244.718745, decoder SINDy loss  ratio: 0.765978
--- 0.2911968231201172 seconds for one epoch ---
--- 0.3013343811035156 seconds for one epoch ---
--- 0.4509139060974121 seconds for one epoch ---
--- 0.29202771186828613 seconds for one epoch ---
--- 0.4475066661834717 seconds for one epoch ---
--- 0.3220651149749756 seconds for one epoch ---
--- 0.4775521755218506 seconds for one epoch ---
--- 0.3052797317504883 seconds for one epoch ---
--- 0.4810762405395508 seconds for one epoch ---
--- 0.3174872398376465 seconds for one epoch ---
--- 0.4754140377044678 seconds for one epoch ---
--- 0.2982947826385498 seconds for one epoch ---
--- 0.4628119468688965 seconds for one epoch ---
--- 0.3169698715209961 seconds for one epoch ---
--- 0.4783005714416504 seconds for one epoch ---
--- 0.31240129470825195 seconds for one epoch ---
--- 0.4606173038482666 seconds for one epoch ---
--- 0.2911229133605957 seconds for one epoch ---
--- 0.47889184951782227 seconds for one epoch ---
--- 0.3128929138183594 seconds for one epoch ---
--- 0.4816904067993164 seconds for one epoch ---
--- 0.3123631477355957 seconds for one epoch ---
--- 0.4840054512023926 seconds for one epoch ---
--- 0.3053252696990967 seconds for one epoch ---
=========================
[[0.09085703]
 [0.08001631]
 [0.09369005]
 [0.07310547]
 [0.07101396]
 [0.13981321]
 [0.07326002]
 [0.07510135]
 [0.07057527]
 [0.12256591]
 [0.08321977]]
[[-1.2383633 ]
 [-0.61953956]
 [ 1.3890853 ]
 [ 0.1787117 ]
 [-0.03584419]
 [-3.517562  ]
 [ 0.18907602]
 [ 0.3106371 ]
 [ 0.00522847]
 [-2.7682889 ]
 [ 0.81035924]]
--- 0.2735590934753418 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8158.64453125, (1673.3032, 1.5837712, 6303.3633, 2.5319595)
   validation loss 1260.32275390625, (771.0848, 0.027503716, 308.81537, 2.5319595)
decoder loss ratio: 29873.162955, decoder SINDy loss  ratio: 0.666621
--- 0.32792139053344727 seconds for one epoch ---
--- 0.4685699939727783 seconds for one epoch ---
--- 0.3058145046234131 seconds for one epoch ---
--- 0.4629364013671875 seconds for one epoch ---
--- 0.32232069969177246 seconds for one epoch ---
--- 0.48250365257263184 seconds for one epoch ---
--- 0.33350539207458496 seconds for one epoch ---
--- 0.4666280746459961 seconds for one epoch ---
--- 0.31449413299560547 seconds for one epoch ---
--- 0.46406054496765137 seconds for one epoch ---
--- 0.32165074348449707 seconds for one epoch ---
--- 0.47721052169799805 seconds for one epoch ---
--- 0.33592677116394043 seconds for one epoch ---
--- 0.4941270351409912 seconds for one epoch ---
--- 0.33083224296569824 seconds for one epoch ---
--- 0.49862122535705566 seconds for one epoch ---
--- 0.32356905937194824 seconds for one epoch ---
--- 0.5119466781616211 seconds for one epoch ---
--- 0.3162996768951416 seconds for one epoch ---
--- 0.49141645431518555 seconds for one epoch ---
--- 0.3257746696472168 seconds for one epoch ---
--- 0.48486852645874023 seconds for one epoch ---
--- 0.3170204162597656 seconds for one epoch ---
--- 0.49785757064819336 seconds for one epoch ---
=========================
[[0.08712263]
 [0.07480773]
 [0.09011678]
 [0.06746477]
 [0.06540187]
 [0.13291737]
 [0.06761129]
 [0.06919735]
 [0.06505539]
 [0.12064577]
 [0.07819062]]
[[-1.3266704 ]
 [-0.6346783 ]
 [ 1.4826385 ]
 [ 0.16935304]
 [-0.02898633]
 [-3.4413533 ]
 [ 0.17913531]
 [ 0.28368142]
 [ 0.00492712]
 [-2.91269   ]
 [ 0.834188  ]]
--- 0.39848923683166504 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4171.45947265625, (2011.1189, 0.38731208, 1976.3661, 2.5319686)
   validation loss 1435.4664306640625, (959.056, 0.029371, 292.7939, 2.5319686)
decoder loss ratio: 37155.495607, decoder SINDy loss  ratio: 0.632037
--- 0.2641031742095947 seconds for one epoch ---
--- 0.29377126693725586 seconds for one epoch ---
--- 0.48805761337280273 seconds for one epoch ---
--- 0.2982621192932129 seconds for one epoch ---
--- 0.49721479415893555 seconds for one epoch ---
--- 0.3263099193572998 seconds for one epoch ---
--- 0.4793398380279541 seconds for one epoch ---
--- 0.32216691970825195 seconds for one epoch ---
--- 0.4897913932800293 seconds for one epoch ---
--- 0.3217339515686035 seconds for one epoch ---
--- 0.4816465377807617 seconds for one epoch ---
--- 0.336702823638916 seconds for one epoch ---
--- 0.4793827533721924 seconds for one epoch ---
--- 0.32207322120666504 seconds for one epoch ---
--- 0.4810781478881836 seconds for one epoch ---
--- 0.313046932220459 seconds for one epoch ---
--- 0.5027825832366943 seconds for one epoch ---
--- 0.3333890438079834 seconds for one epoch ---
--- 0.49960827827453613 seconds for one epoch ---
--- 0.32608890533447266 seconds for one epoch ---
--- 0.5113351345062256 seconds for one epoch ---
--- 0.3211679458618164 seconds for one epoch ---
--- 0.5157327651977539 seconds for one epoch ---
--- 0.32450032234191895 seconds for one epoch ---
=========================
[[0.08392366]
 [0.07061742]
 [0.08649054]
 [0.06293969]
 [0.06073178]
 [0.12670209]
 [0.06247563]
 [0.06464734]
 [0.06019136]
 [0.11916926]
 [0.07443754]]
[[-1.4045470e+00]
 [-6.6841131e-01]
 [ 1.5361582e+00]
 [ 1.8715093e-01]
 [-3.8185474e-02]
 [-3.3667397e+00]
 [ 1.5628384e-01]
 [ 2.9883042e-01]
 [ 8.7554473e-04]
 [-3.0444846e+00]
 [ 8.9050293e-01]]
--- 0.2658534049987793 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4006.775146484375, (1570.1381, 0.43491971, 2249.4446, 2.5319788)
   validation loss 1993.2005615234375, (1447.5443, 0.01843321, 358.88034, 2.5319788)
decoder loss ratio: 56080.379676, decoder SINDy loss  ratio: 0.774694
--- 0.30455517768859863 seconds for one epoch ---
--- 0.49741077423095703 seconds for one epoch ---
--- 0.31029558181762695 seconds for one epoch ---
--- 0.4933462142944336 seconds for one epoch ---
--- 0.30184221267700195 seconds for one epoch ---
--- 0.5059633255004883 seconds for one epoch ---
--- 0.29362916946411133 seconds for one epoch ---
--- 0.5018057823181152 seconds for one epoch ---
--- 0.300076961517334 seconds for one epoch ---
--- 0.4938838481903076 seconds for one epoch ---
--- 0.3122732639312744 seconds for one epoch ---
--- 0.5010192394256592 seconds for one epoch ---
--- 0.29943084716796875 seconds for one epoch ---
--- 0.5089268684387207 seconds for one epoch ---
--- 0.30344486236572266 seconds for one epoch ---
--- 0.49844813346862793 seconds for one epoch ---
--- 0.3004605770111084 seconds for one epoch ---
--- 0.5270092487335205 seconds for one epoch ---
--- 0.30966734886169434 seconds for one epoch ---
--- 0.53183913230896 seconds for one epoch ---
--- 0.3116118907928467 seconds for one epoch ---
--- 0.5335180759429932 seconds for one epoch ---
--- 0.30574631690979004 seconds for one epoch ---
--- 0.4937472343444824 seconds for one epoch ---
=========================
[[0.08209194]
 [0.06743085]
 [0.08377764]
 [0.05964405]
 [0.05715695]
 [0.1225986 ]
 [0.0590163 ]
 [0.06104392]
 [0.05665458]
 [0.11873358]
 [0.07188725]]
[[-1.4892744 ]
 [-0.6890089 ]
 [ 1.5745416 ]
 [ 0.20483454]
 [-0.03802094]
 [-3.3336222 ]
 [ 0.16336688]
 [ 0.29587853]
 [ 0.00348212]
 [-3.169285  ]
 [ 0.9451593 ]]
--- 0.29589390754699707 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4603.11669921875, (2877.565, 3.699534, 1532.5167, 2.5319915)
   validation loss 1497.238037109375, (1006.9425, 0.02065149, 300.93958, 2.5319915)
decoder loss ratio: 39010.700768, decoder SINDy loss  ratio: 0.649620
--- 0.27222323417663574 seconds for one epoch ---
--- 0.3235149383544922 seconds for one epoch ---
--- 0.5118250846862793 seconds for one epoch ---
--- 0.3372306823730469 seconds for one epoch ---
--- 0.5391745567321777 seconds for one epoch ---
--- 0.32123756408691406 seconds for one epoch ---
--- 0.5190048217773438 seconds for one epoch ---
--- 0.32061314582824707 seconds for one epoch ---
--- 0.5274646282196045 seconds for one epoch ---
--- 0.33254075050354004 seconds for one epoch ---
--- 0.5284926891326904 seconds for one epoch ---
--- 0.31409740447998047 seconds for one epoch ---
--- 0.5239853858947754 seconds for one epoch ---
--- 0.3123288154602051 seconds for one epoch ---
--- 0.503760576248169 seconds for one epoch ---
--- 0.3180055618286133 seconds for one epoch ---
--- 0.5172967910766602 seconds for one epoch ---
--- 0.3150186538696289 seconds for one epoch ---
--- 0.5251772403717041 seconds for one epoch ---
--- 0.30655956268310547 seconds for one epoch ---
--- 0.5250952243804932 seconds for one epoch ---
--- 0.29554152488708496 seconds for one epoch ---
--- 0.5043880939483643 seconds for one epoch ---
--- 0.29781055450439453 seconds for one epoch ---
=========================
[[0.08051199]
 [0.06463025]
 [0.08151744]
 [0.05701478]
 [0.05385038]
 [0.11806016]
 [0.0554429 ]
 [0.05790081]
 [0.05354766]
 [0.11876439]
 [0.06921358]]
[[-1.563234  ]
 [-0.70625156]
 [ 1.6134828 ]
 [ 0.23687991]
 [-0.0258473 ]
 [-3.2648141 ]
 [ 0.13340026]
 [ 0.29411042]
 [ 0.00507589]
 [-3.2946186 ]
 [ 0.96778584]]
--- 0.26145172119140625 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4473.20751953125, (1430.8541, 0.7393873, 2849.6536, 2.5320003)
   validation loss 2146.41259765625, (1591.608, 0.017977279, 362.8265, 2.5320003)
decoder loss ratio: 61661.658322, decoder SINDy loss  ratio: 0.783212
--- 0.30381035804748535 seconds for one epoch ---
--- 0.5229225158691406 seconds for one epoch ---
--- 0.3098111152648926 seconds for one epoch ---
--- 0.5311036109924316 seconds for one epoch ---
--- 0.30173683166503906 seconds for one epoch ---
--- 0.5576169490814209 seconds for one epoch ---
--- 0.32953858375549316 seconds for one epoch ---
--- 0.5241219997406006 seconds for one epoch ---
--- 0.32204365730285645 seconds for one epoch ---
--- 0.5132744312286377 seconds for one epoch ---
--- 0.32802820205688477 seconds for one epoch ---
--- 0.5329060554504395 seconds for one epoch ---
--- 0.32726120948791504 seconds for one epoch ---
--- 0.5358109474182129 seconds for one epoch ---
--- 0.33899855613708496 seconds for one epoch ---
--- 0.5413732528686523 seconds for one epoch ---
--- 0.3159761428833008 seconds for one epoch ---
--- 0.5264706611633301 seconds for one epoch ---
--- 0.32223963737487793 seconds for one epoch ---
--- 0.5336816310882568 seconds for one epoch ---
--- 0.31915736198425293 seconds for one epoch ---
--- 0.5282948017120361 seconds for one epoch ---
--- 0.303241491317749 seconds for one epoch ---
--- 0.4982109069824219 seconds for one epoch ---
=========================
[[0.07987969]
 [0.06274099]
 [0.07930811]
 [0.05475529]
 [0.05166561]
 [0.11504304]
 [0.05291648]
 [0.05557914]
 [0.05118321]
 [0.11935745]
 [0.06726708]]
[[-1.6448402e+00]
 [-7.3092115e-01]
 [ 1.6165318e+00]
 [ 2.4153112e-01]
 [-3.6369085e-02]
 [-3.2294321e+00]
 [ 1.2066185e-01]
 [ 2.9458401e-01]
 [-3.3838095e-03]
 [-3.4113066e+00]
 [ 9.8742080e-01]]
--- 0.2948939800262451 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4520.58251953125, (1571.9442, 1.1370186, 2752.0396, 2.53201)
   validation loss 2007.196044921875, (1478.1716, 0.020913247, 333.54196, 2.53201)
decoder loss ratio: 57266.935198, decoder SINDy loss  ratio: 0.719997
THRESHOLDING: 2 active coefficients
--- 0.5391407012939453 seconds for one epoch ---
--- 0.30813169479370117 seconds for one epoch ---
--- 0.5208375453948975 seconds for one epoch ---
--- 0.30121302604675293 seconds for one epoch ---
--- 0.514716386795044 seconds for one epoch ---
--- 0.2977142333984375 seconds for one epoch ---
--- 0.5351054668426514 seconds for one epoch ---
--- 0.30367207527160645 seconds for one epoch ---
--- 0.5123300552368164 seconds for one epoch ---
--- 0.2938218116760254 seconds for one epoch ---
--- 0.5230808258056641 seconds for one epoch ---
--- 0.2831306457519531 seconds for one epoch ---
--- 0.5410418510437012 seconds for one epoch ---
--- 0.3006479740142822 seconds for one epoch ---
--- 0.5405983924865723 seconds for one epoch ---
--- 0.2932605743408203 seconds for one epoch ---
--- 0.531543493270874 seconds for one epoch ---
--- 0.29989147186279297 seconds for one epoch ---
--- 0.5270373821258545 seconds for one epoch ---
--- 0.291942834854126 seconds for one epoch ---
--- 0.5471374988555908 seconds for one epoch ---
--- 0.3020195960998535 seconds for one epoch ---
--- 0.5381608009338379 seconds for one epoch ---
--- 0.2964742183685303 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08879896]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10720505]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-2.164136]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-2.977979]
 [ 0.      ]]
--- 0.25328946113586426 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3312.054443359375, (1936.1719, 2.1541014, 1373.5264, 0.20206077)
   validation loss 3142.004150390625, (2722.2244, 0.052967675, 419.52472, 0.20206077)
decoder loss ratio: 105463.697899, decoder SINDy loss  ratio: 0.905603
--- 0.32254481315612793 seconds for one epoch ---
--- 0.5125532150268555 seconds for one epoch ---
--- 0.3237471580505371 seconds for one epoch ---
--- 0.5460269451141357 seconds for one epoch ---
--- 0.3324854373931885 seconds for one epoch ---
--- 0.5301117897033691 seconds for one epoch ---
--- 0.33396148681640625 seconds for one epoch ---
--- 0.5375280380249023 seconds for one epoch ---
--- 0.32764673233032227 seconds for one epoch ---
--- 0.5359528064727783 seconds for one epoch ---
--- 0.3079264163970947 seconds for one epoch ---
--- 0.5336616039276123 seconds for one epoch ---
--- 0.2960796356201172 seconds for one epoch ---
--- 0.5492231845855713 seconds for one epoch ---
--- 0.3151576519012451 seconds for one epoch ---
--- 0.5357017517089844 seconds for one epoch ---
--- 0.30744361877441406 seconds for one epoch ---
--- 0.5344698429107666 seconds for one epoch ---
--- 0.3050670623779297 seconds for one epoch ---
--- 0.5221130847930908 seconds for one epoch ---
--- 0.31542229652404785 seconds for one epoch ---
--- 0.558035135269165 seconds for one epoch ---
--- 0.32260680198669434 seconds for one epoch ---
--- 0.5572035312652588 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07776602]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10173763]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.712621 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8054311]
 [ 0.       ]]
--- 0.2863788604736328 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3662.486572265625, (1700.8536, 0.43521464, 1961.0021, 0.19563282)
   validation loss 3777.40283203125, (3249.0906, 0.06743368, 528.0494, 0.19563282)
decoder loss ratio: 125875.409590, decoder SINDy loss  ratio: 1.139869
--- 0.2845766544342041 seconds for one epoch ---
--- 0.30226874351501465 seconds for one epoch ---
--- 0.5597472190856934 seconds for one epoch ---
--- 0.30173230171203613 seconds for one epoch ---
--- 0.5706522464752197 seconds for one epoch ---
--- 0.30667901039123535 seconds for one epoch ---
--- 0.5370161533355713 seconds for one epoch ---
--- 0.2963287830352783 seconds for one epoch ---
--- 0.5501163005828857 seconds for one epoch ---
--- 0.2882506847381592 seconds for one epoch ---
--- 0.5289981365203857 seconds for one epoch ---
--- 0.2951204776763916 seconds for one epoch ---
--- 0.5427186489105225 seconds for one epoch ---
--- 0.3097701072692871 seconds for one epoch ---
--- 0.5606999397277832 seconds for one epoch ---
--- 0.3035116195678711 seconds for one epoch ---
--- 0.5453472137451172 seconds for one epoch ---
--- 0.3156416416168213 seconds for one epoch ---
--- 0.5443179607391357 seconds for one epoch ---
--- 0.29831433296203613 seconds for one epoch ---
--- 0.5689401626586914 seconds for one epoch ---
--- 0.3021049499511719 seconds for one epoch ---
--- 0.5665082931518555 seconds for one epoch ---
--- 0.30066370964050293 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07254718]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09968621]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.520313]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-2.772532]
 [ 0.      ]]
--- 0.26843762397766113 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3834.182373046875, (1630.9795, 6.906468, 2196.103, 0.19333641)
   validation loss 5736.10546875, (5119.5547, 0.048684694, 616.30853, 0.19333641)
decoder loss ratio: 198340.436532, decoder SINDy loss  ratio: 1.330389
--- 0.3061790466308594 seconds for one epoch ---
--- 0.5655171871185303 seconds for one epoch ---
--- 0.32419490814208984 seconds for one epoch ---
--- 0.5802154541015625 seconds for one epoch ---
--- 0.30734896659851074 seconds for one epoch ---
--- 0.5572736263275146 seconds for one epoch ---
--- 0.3170657157897949 seconds for one epoch ---
--- 0.5768308639526367 seconds for one epoch ---
--- 0.32834792137145996 seconds for one epoch ---
--- 0.5622661113739014 seconds for one epoch ---
--- 0.3154420852661133 seconds for one epoch ---
--- 0.5688965320587158 seconds for one epoch ---
--- 0.32410168647766113 seconds for one epoch ---
--- 0.5661802291870117 seconds for one epoch ---
--- 0.3203396797180176 seconds for one epoch ---
--- 0.5652744770050049 seconds for one epoch ---
--- 0.31580400466918945 seconds for one epoch ---
--- 0.5673282146453857 seconds for one epoch ---
--- 0.2987833023071289 seconds for one epoch ---
--- 0.5552072525024414 seconds for one epoch ---
--- 0.28574419021606445 seconds for one epoch ---
--- 0.558974027633667 seconds for one epoch ---
--- 0.3142697811126709 seconds for one epoch ---
--- 0.5514547824859619 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0695013 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09848439]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.417259]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-2.762713]
 [ 0.      ]]
--- 0.307849645614624 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2945.481689453125, (1297.1436, 0.646878, 1647.499, 0.19210492)
   validation loss 1447.0010986328125, (1130.2897, 0.052544035, 316.46683, 0.19210492)
decoder loss ratio: 43789.384195, decoder SINDy loss  ratio: 0.683138
--- 0.2728233337402344 seconds for one epoch ---
--- 0.30043792724609375 seconds for one epoch ---
--- 0.5788419246673584 seconds for one epoch ---
--- 0.29018282890319824 seconds for one epoch ---
--- 0.5614750385284424 seconds for one epoch ---
--- 0.3052387237548828 seconds for one epoch ---
--- 0.5612115859985352 seconds for one epoch ---
--- 0.2946586608886719 seconds for one epoch ---
--- 0.5780737400054932 seconds for one epoch ---
--- 0.3059983253479004 seconds for one epoch ---
--- 0.563697099685669 seconds for one epoch ---
--- 0.30750393867492676 seconds for one epoch ---
--- 0.5727963447570801 seconds for one epoch ---
--- 0.314023494720459 seconds for one epoch ---
--- 0.5965209007263184 seconds for one epoch ---
--- 0.3211486339569092 seconds for one epoch ---
--- 0.5778505802154541 seconds for one epoch ---
--- 0.29045915603637695 seconds for one epoch ---
--- 0.5733356475830078 seconds for one epoch ---
--- 0.295393705368042 seconds for one epoch ---
--- 0.5845003128051758 seconds for one epoch ---
--- 0.29593849182128906 seconds for one epoch ---
--- 0.6042447090148926 seconds for one epoch ---
--- 0.29963111877441406 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06831695]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09813184]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.4024837]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7848964]
 [ 0.       ]]
--- 0.2709953784942627 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2689.304931640625, (1512.5807, 0.33046272, 1176.2015, 0.19220956)
   validation loss 3462.990478515625, (2985.009, 0.07415892, 477.71518, 0.19220956)
decoder loss ratio: 115644.432150, decoder SINDy loss  ratio: 1.031215
--- 0.32823848724365234 seconds for one epoch ---
--- 0.6083164215087891 seconds for one epoch ---
--- 0.454087495803833 seconds for one epoch ---
--- 0.590888261795044 seconds for one epoch ---
--- 0.30867576599121094 seconds for one epoch ---
--- 0.5964322090148926 seconds for one epoch ---
--- 0.31035304069519043 seconds for one epoch ---
--- 0.584036111831665 seconds for one epoch ---
--- 0.2939019203186035 seconds for one epoch ---
--- 0.6021039485931396 seconds for one epoch ---
--- 0.29985880851745605 seconds for one epoch ---
--- 0.5995581150054932 seconds for one epoch ---
--- 0.3070693016052246 seconds for one epoch ---
--- 0.6007578372955322 seconds for one epoch ---
--- 0.3022606372833252 seconds for one epoch ---
--- 0.5804698467254639 seconds for one epoch ---
--- 0.2974534034729004 seconds for one epoch ---
--- 0.5795164108276367 seconds for one epoch ---
--- 0.29622340202331543 seconds for one epoch ---
--- 0.5801200866699219 seconds for one epoch ---
--- 0.3007683753967285 seconds for one epoch ---
--- 0.6156554222106934 seconds for one epoch ---
--- 0.3371002674102783 seconds for one epoch ---
--- 0.5986847877502441 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06745796]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09704455]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3932716]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7663155]
 [ 0.       ]]
--- 0.30231189727783203 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4362.48681640625, (1783.2286, 1.3551131, 2577.7114, 0.19207688)
   validation loss 2378.3056640625, (1927.4137, 0.07549585, 450.62433, 0.19207688)
decoder loss ratio: 74671.352732, decoder SINDy loss  ratio: 0.972736
--- 0.2667999267578125 seconds for one epoch ---
--- 0.3121373653411865 seconds for one epoch ---
--- 0.5782802104949951 seconds for one epoch ---
--- 0.3090498447418213 seconds for one epoch ---
--- 0.5994269847869873 seconds for one epoch ---
--- 0.29679203033447266 seconds for one epoch ---
--- 0.590634822845459 seconds for one epoch ---
--- 0.3195521831512451 seconds for one epoch ---
--- 0.590864896774292 seconds for one epoch ---
--- 0.33136844635009766 seconds for one epoch ---
--- 0.6082768440246582 seconds for one epoch ---
--- 0.32306528091430664 seconds for one epoch ---
--- 0.61849045753479 seconds for one epoch ---
--- 0.3330984115600586 seconds for one epoch ---
--- 0.6090326309204102 seconds for one epoch ---
--- 0.3065969944000244 seconds for one epoch ---
--- 0.5997204780578613 seconds for one epoch ---
--- 0.30122900009155273 seconds for one epoch ---
--- 0.5899162292480469 seconds for one epoch ---
--- 0.29527735710144043 seconds for one epoch ---
--- 0.6163060665130615 seconds for one epoch ---
--- 0.30291032791137695 seconds for one epoch ---
--- 0.6224119663238525 seconds for one epoch ---
--- 0.2990860939025879 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06659061]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09740636]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3799139]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8071678]
 [ 0.       ]]
--- 0.27475404739379883 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2510.52197265625, (1155.34, 2.5160666, 1352.4734, 0.19232178)
   validation loss 1747.380859375, (1440.6925, 0.104153015, 306.39188, 0.19232178)
decoder loss ratio: 55814.928791, decoder SINDy loss  ratio: 0.661390
--- 0.3161008358001709 seconds for one epoch ---
--- 0.6061222553253174 seconds for one epoch ---
--- 0.3113570213317871 seconds for one epoch ---
--- 0.6137490272521973 seconds for one epoch ---
--- 0.30445075035095215 seconds for one epoch ---
--- 0.6123573780059814 seconds for one epoch ---
--- 0.31020426750183105 seconds for one epoch ---
--- 0.621941328048706 seconds for one epoch ---
--- 0.2977726459503174 seconds for one epoch ---
--- 0.6154115200042725 seconds for one epoch ---
--- 0.29376792907714844 seconds for one epoch ---
--- 0.6054139137268066 seconds for one epoch ---
--- 0.31171560287475586 seconds for one epoch ---
--- 0.6065421104431152 seconds for one epoch ---
--- 0.28084468841552734 seconds for one epoch ---
--- 0.6045184135437012 seconds for one epoch ---
--- 0.2910807132720947 seconds for one epoch ---
--- 0.6049351692199707 seconds for one epoch ---
--- 0.29268479347229004 seconds for one epoch ---
--- 0.6195473670959473 seconds for one epoch ---
--- 0.3188495635986328 seconds for one epoch ---
--- 0.6089153289794922 seconds for one epoch ---
--- 0.3156559467315674 seconds for one epoch ---
--- 0.6136989593505859 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06584605]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09727351]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3654408]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8206384]
 [ 0.       ]]
--- 0.3002903461456299 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2577.12548828125, (1299.4347, 0.20808439, 1277.2904, 0.19242667)
   validation loss 1629.820556640625, (1269.7002, 0.0604047, 359.86752, 0.19242667)
decoder loss ratio: 49190.389863, decoder SINDy loss  ratio: 0.776825
--- 0.25547337532043457 seconds for one epoch ---
--- 0.30442333221435547 seconds for one epoch ---
--- 0.6171765327453613 seconds for one epoch ---
--- 0.3413658142089844 seconds for one epoch ---
--- 0.6168959140777588 seconds for one epoch ---
--- 0.3119974136352539 seconds for one epoch ---
--- 0.6158747673034668 seconds for one epoch ---
--- 0.337022066116333 seconds for one epoch ---
--- 0.6128616333007812 seconds for one epoch ---
--- 0.3220980167388916 seconds for one epoch ---
--- 0.6179244518280029 seconds for one epoch ---
--- 0.3228721618652344 seconds for one epoch ---
--- 0.6374363899230957 seconds for one epoch ---
--- 0.2966294288635254 seconds for one epoch ---
--- 0.6201927661895752 seconds for one epoch ---
--- 0.3034532070159912 seconds for one epoch ---
--- 0.628190279006958 seconds for one epoch ---
--- 0.3034217357635498 seconds for one epoch ---
--- 0.6534674167633057 seconds for one epoch ---
--- 0.3226480484008789 seconds for one epoch ---
--- 0.6522681713104248 seconds for one epoch ---
--- 0.3283991813659668 seconds for one epoch ---
--- 0.6575725078582764 seconds for one epoch ---
--- 0.3297731876373291 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06557713]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09809045]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3728536]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8727934]
 [ 0.       ]]
--- 0.2751903533935547 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6424.7802734375, (932.0235, 1.6098831, 5490.954, 0.19298631)
   validation loss 1082.7576904296875, (778.3732, 0.07778319, 304.11377, 0.19298631)
decoder loss ratio: 30155.530245, decoder SINDy loss  ratio: 0.656472
--- 0.31252098083496094 seconds for one epoch ---
--- 0.6147899627685547 seconds for one epoch ---
--- 0.30391597747802734 seconds for one epoch ---
--- 0.642080545425415 seconds for one epoch ---
--- 0.31701183319091797 seconds for one epoch ---
--- 0.6171615123748779 seconds for one epoch ---
--- 0.3075215816497803 seconds for one epoch ---
--- 0.627394437789917 seconds for one epoch ---
--- 0.3018810749053955 seconds for one epoch ---
--- 0.6566126346588135 seconds for one epoch ---
--- 0.3081068992614746 seconds for one epoch ---
--- 0.6360185146331787 seconds for one epoch ---
--- 0.29803919792175293 seconds for one epoch ---
--- 0.6414079666137695 seconds for one epoch ---
--- 0.3020660877227783 seconds for one epoch ---
--- 0.6466071605682373 seconds for one epoch ---
--- 0.30231475830078125 seconds for one epoch ---
--- 0.6437084674835205 seconds for one epoch ---
--- 0.28424930572509766 seconds for one epoch ---
--- 0.6342315673828125 seconds for one epoch ---
--- 0.306135892868042 seconds for one epoch ---
--- 0.6390101909637451 seconds for one epoch ---
--- 0.298297643661499 seconds for one epoch ---
--- 0.6534433364868164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06478659]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09877615]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3485956]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9151254]
 [ 0.       ]]
--- 0.30894947052001953 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3216.43115234375, (866.1108, 1.014669, 2349.1125, 0.19310725)
   validation loss 1212.722412109375, (878.94196, 0.03996168, 333.5474, 0.19310725)
decoder loss ratio: 34051.737269, decoder SINDy loss  ratio: 0.720009
--- 0.24976634979248047 seconds for one epoch ---
--- 0.3090229034423828 seconds for one epoch ---
--- 0.6137850284576416 seconds for one epoch ---
--- 0.30685877799987793 seconds for one epoch ---
--- 0.6332964897155762 seconds for one epoch ---
--- 0.308246374130249 seconds for one epoch ---
--- 0.6258950233459473 seconds for one epoch ---
--- 0.3119323253631592 seconds for one epoch ---
--- 0.6327848434448242 seconds for one epoch ---
--- 0.302825927734375 seconds for one epoch ---
--- 0.6192424297332764 seconds for one epoch ---
--- 0.3032701015472412 seconds for one epoch ---
--- 0.6343848705291748 seconds for one epoch ---
--- 0.2967393398284912 seconds for one epoch ---
--- 0.6495673656463623 seconds for one epoch ---
--- 0.3006002902984619 seconds for one epoch ---
--- 0.6418359279632568 seconds for one epoch ---
--- 0.3040785789489746 seconds for one epoch ---
--- 0.6911416053771973 seconds for one epoch ---
--- 0.32112622261047363 seconds for one epoch ---
--- 0.6527454853057861 seconds for one epoch ---
--- 0.3224163055419922 seconds for one epoch ---
--- 0.6636314392089844 seconds for one epoch ---
--- 0.3201732635498047 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06404636]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10005248]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3252243]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9811165]
 [ 0.       ]]
--- 0.26094532012939453 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4526.91064453125, (2539.4316, 0.7698545, 1986.5156, 0.19372451)
   validation loss 1404.6837158203125, (1135.4563, 0.163548, 268.87012, 0.19372451)
decoder loss ratio: 43989.548255, decoder SINDy loss  ratio: 0.580394
--- 0.31016087532043457 seconds for one epoch ---
--- 0.6682796478271484 seconds for one epoch ---
--- 0.3188958168029785 seconds for one epoch ---
--- 0.6489746570587158 seconds for one epoch ---
--- 0.301450252532959 seconds for one epoch ---
--- 0.6844210624694824 seconds for one epoch ---
--- 0.29682254791259766 seconds for one epoch ---
--- 0.658118724822998 seconds for one epoch ---
--- 0.30756330490112305 seconds for one epoch ---
--- 0.6719422340393066 seconds for one epoch ---
--- 0.29824066162109375 seconds for one epoch ---
--- 0.6482284069061279 seconds for one epoch ---
--- 0.2933516502380371 seconds for one epoch ---
--- 0.6675045490264893 seconds for one epoch ---
--- 0.2874331474304199 seconds for one epoch ---
--- 0.6482081413269043 seconds for one epoch ---
--- 0.28004002571105957 seconds for one epoch ---
--- 0.6800577640533447 seconds for one epoch ---
--- 0.3144798278808594 seconds for one epoch ---
--- 0.677147388458252 seconds for one epoch ---
--- 0.2937319278717041 seconds for one epoch ---
--- 0.6976618766784668 seconds for one epoch ---
--- 0.30799150466918945 seconds for one epoch ---
--- 0.6568412780761719 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06411026]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10108081]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.339787]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-3.033625]
 [ 0.      ]]
--- 0.2966325283050537 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4222.3837890625, (1359.8174, 0.4679317, 2861.9043, 0.19430654)
   validation loss 1102.28466796875, (802.43744, 0.053710703, 299.5992, 0.19430654)
decoder loss ratio: 31087.819478, decoder SINDy loss  ratio: 0.646727
--- 0.2782630920410156 seconds for one epoch ---
--- 0.3158590793609619 seconds for one epoch ---
--- 0.6609995365142822 seconds for one epoch ---
--- 0.3103787899017334 seconds for one epoch ---
--- 0.6627058982849121 seconds for one epoch ---
--- 0.32447147369384766 seconds for one epoch ---
--- 0.6803009510040283 seconds for one epoch ---
--- 0.3170654773712158 seconds for one epoch ---
--- 0.6863877773284912 seconds for one epoch ---
--- 0.2955329418182373 seconds for one epoch ---
--- 0.6482679843902588 seconds for one epoch ---
--- 0.30338478088378906 seconds for one epoch ---
--- 0.652113676071167 seconds for one epoch ---
--- 0.2816600799560547 seconds for one epoch ---
--- 0.6352453231811523 seconds for one epoch ---
--- 0.3002760410308838 seconds for one epoch ---
--- 0.6705136299133301 seconds for one epoch ---
--- 0.29375433921813965 seconds for one epoch ---
--- 0.6771218776702881 seconds for one epoch ---
--- 0.3266925811767578 seconds for one epoch ---
--- 0.6789982318878174 seconds for one epoch ---
--- 0.31435108184814453 seconds for one epoch ---
--- 0.673276424407959 seconds for one epoch ---
--- 0.30967092514038086 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06352621]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10206009]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3199598]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.0830297]
 [ 0.       ]]
--- 0.27888941764831543 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5735.64501953125, (2363.5269, 2.16011, 3369.763, 0.19468261)
   validation loss 991.5671997070312, (722.744, 0.116283834, 268.5122, 0.19468261)
decoder loss ratio: 28000.358018, decoder SINDy loss  ratio: 0.579621
--- 0.3186633586883545 seconds for one epoch ---
--- 0.66977858543396 seconds for one epoch ---
--- 0.32099294662475586 seconds for one epoch ---
--- 0.6745150089263916 seconds for one epoch ---
--- 0.31619882583618164 seconds for one epoch ---
--- 0.6784384250640869 seconds for one epoch ---
--- 0.3272716999053955 seconds for one epoch ---
--- 0.687126636505127 seconds for one epoch ---
--- 0.29675984382629395 seconds for one epoch ---
--- 0.6701614856719971 seconds for one epoch ---
--- 0.29711246490478516 seconds for one epoch ---
--- 0.6741690635681152 seconds for one epoch ---
--- 0.3000774383544922 seconds for one epoch ---
--- 0.661522626876831 seconds for one epoch ---
--- 0.28944826126098633 seconds for one epoch ---
--- 0.6939184665679932 seconds for one epoch ---
--- 0.3197314739227295 seconds for one epoch ---
--- 0.6875607967376709 seconds for one epoch ---
--- 0.292804479598999 seconds for one epoch ---
--- 0.6824784278869629 seconds for one epoch ---
--- 0.29729175567626953 seconds for one epoch ---
--- 0.6824908256530762 seconds for one epoch ---
--- 0.3069124221801758 seconds for one epoch ---
--- 0.6934647560119629 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06276584]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10322785]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2886039]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.1383839]
 [ 0.       ]]
--- 0.29714465141296387 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2155.91357421875, (1566.3094, 1.8622831, 587.5468, 0.19494766)
   validation loss 971.3364868164062, (710.65704, 0.10729413, 260.3772, 0.19494766)
decoder loss ratio: 27532.087618, decoder SINDy loss  ratio: 0.562061
--- 0.24465703964233398 seconds for one epoch ---
--- 0.298292875289917 seconds for one epoch ---
--- 0.6668491363525391 seconds for one epoch ---
--- 0.29849743843078613 seconds for one epoch ---
--- 0.6982159614562988 seconds for one epoch ---
--- 0.3096485137939453 seconds for one epoch ---
--- 0.6857619285583496 seconds for one epoch ---
--- 0.29883742332458496 seconds for one epoch ---
--- 0.7049472332000732 seconds for one epoch ---
--- 0.29677867889404297 seconds for one epoch ---
--- 0.6870565414428711 seconds for one epoch ---
--- 0.2961392402648926 seconds for one epoch ---
--- 0.6826167106628418 seconds for one epoch ---
--- 0.29776859283447266 seconds for one epoch ---
--- 0.6917247772216797 seconds for one epoch ---
--- 0.30979180335998535 seconds for one epoch ---
--- 0.7204763889312744 seconds for one epoch ---
--- 0.3029649257659912 seconds for one epoch ---
--- 0.7011888027191162 seconds for one epoch ---
--- 0.30301976203918457 seconds for one epoch ---
--- 0.6871316432952881 seconds for one epoch ---
--- 0.2954888343811035 seconds for one epoch ---
--- 0.7068359851837158 seconds for one epoch ---
--- 0.29483485221862793 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06278097]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10455028]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2965912]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.19948  ]
 [ 0.       ]]
--- 0.2571711540222168 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4240.63720703125, (1485.7849, 0.25139034, 2754.405, 0.19557542)
   validation loss 2097.965087890625, (1751.9061, 0.047353353, 345.81598, 0.19557542)
decoder loss ratio: 67871.884839, decoder SINDy loss  ratio: 0.746492
--- 0.3342618942260742 seconds for one epoch ---
--- 0.710233211517334 seconds for one epoch ---
--- 0.3155539035797119 seconds for one epoch ---
--- 0.6732308864593506 seconds for one epoch ---
--- 0.3249058723449707 seconds for one epoch ---
--- 0.709352970123291 seconds for one epoch ---
--- 0.2980649471282959 seconds for one epoch ---
--- 0.683375358581543 seconds for one epoch ---
--- 0.2975594997406006 seconds for one epoch ---
--- 0.6917893886566162 seconds for one epoch ---
--- 0.29454636573791504 seconds for one epoch ---
--- 0.6710178852081299 seconds for one epoch ---
--- 0.29956889152526855 seconds for one epoch ---
--- 0.6968698501586914 seconds for one epoch ---
--- 0.3101232051849365 seconds for one epoch ---
--- 0.7149133682250977 seconds for one epoch ---
--- 0.31207799911499023 seconds for one epoch ---
--- 0.7036428451538086 seconds for one epoch ---
--- 0.30409979820251465 seconds for one epoch ---
--- 0.7045691013336182 seconds for one epoch ---
--- 0.3107776641845703 seconds for one epoch ---
--- 0.7131295204162598 seconds for one epoch ---
--- 0.29875755310058594 seconds for one epoch ---
--- 0.7204313278198242 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06261078]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10620841]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2933669]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2731552]
 [ 0.       ]]
--- 0.2982625961303711 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2232.0654296875, (928.98486, 0.52089566, 1302.3633, 0.1962779)
   validation loss 1174.821533203125, (894.0634, 0.10005597, 280.46176, 0.1962779)
decoder loss ratio: 34637.568880, decoder SINDy loss  ratio: 0.605416
--- 0.25702810287475586 seconds for one epoch ---
--- 0.29700732231140137 seconds for one epoch ---
--- 0.6826963424682617 seconds for one epoch ---
--- 0.31026482582092285 seconds for one epoch ---
--- 0.6961145401000977 seconds for one epoch ---
--- 0.297534704208374 seconds for one epoch ---
--- 0.7016122341156006 seconds for one epoch ---
--- 0.30815863609313965 seconds for one epoch ---
--- 0.7325198650360107 seconds for one epoch ---
--- 0.3214447498321533 seconds for one epoch ---
--- 0.7198295593261719 seconds for one epoch ---
--- 0.3019096851348877 seconds for one epoch ---
--- 0.7156121730804443 seconds for one epoch ---
--- 0.4739968776702881 seconds for one epoch ---
--- 0.7213864326477051 seconds for one epoch ---
--- 0.29811620712280273 seconds for one epoch ---
--- 0.7197871208190918 seconds for one epoch ---
--- 0.3015177249908447 seconds for one epoch ---
--- 0.7236301898956299 seconds for one epoch ---
--- 0.2961409091949463 seconds for one epoch ---
--- 0.7242903709411621 seconds for one epoch ---
--- 0.28724122047424316 seconds for one epoch ---
--- 0.7073872089385986 seconds for one epoch ---
--- 0.286151647567749 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06276465]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10776871]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3063941]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.342137 ]
 [ 0.       ]]
--- 0.2734870910644531 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2920.478515625, (1217.1858, 0.7667957, 1702.3291, 0.19684169)
   validation loss 1077.611328125, (767.8306, 0.09580191, 309.48795, 0.19684169)
decoder loss ratio: 29747.091520, decoder SINDy loss  ratio: 0.668073
--- 0.31511878967285156 seconds for one epoch ---
--- 0.6952691078186035 seconds for one epoch ---
--- 0.3229513168334961 seconds for one epoch ---
--- 0.7203118801116943 seconds for one epoch ---
--- 0.29307055473327637 seconds for one epoch ---
--- 0.7284529209136963 seconds for one epoch ---
--- 0.2978689670562744 seconds for one epoch ---
--- 0.7306675910949707 seconds for one epoch ---
--- 0.2933156490325928 seconds for one epoch ---
--- 0.7044496536254883 seconds for one epoch ---
--- 0.2994260787963867 seconds for one epoch ---
--- 0.7245616912841797 seconds for one epoch ---
--- 0.3021693229675293 seconds for one epoch ---
--- 0.7219316959381104 seconds for one epoch ---
--- 0.31926918029785156 seconds for one epoch ---
--- 0.7240686416625977 seconds for one epoch ---
--- 0.29987549781799316 seconds for one epoch ---
--- 0.7259693145751953 seconds for one epoch ---
--- 0.31033849716186523 seconds for one epoch ---
--- 0.722811222076416 seconds for one epoch ---
--- 0.30562615394592285 seconds for one epoch ---
--- 0.7215394973754883 seconds for one epoch ---
--- 0.3084754943847656 seconds for one epoch ---
--- 0.7229888439178467 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06242413]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11106761]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2927582]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4822068]
 [ 0.       ]]
--- 0.29560279846191406 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2596.43212890625, (1439.668, 0.54728556, 1156.019, 0.1978225)
   validation loss 1036.39501953125, (741.3245, 0.15186468, 294.72076, 0.1978225)
decoder loss ratio: 28720.199053, decoder SINDy loss  ratio: 0.636196
--- 0.26769351959228516 seconds for one epoch ---
--- 0.3050801753997803 seconds for one epoch ---
--- 0.7435166835784912 seconds for one epoch ---
--- 0.29335880279541016 seconds for one epoch ---
--- 0.7287437915802002 seconds for one epoch ---
--- 0.29320549964904785 seconds for one epoch ---
--- 0.7327566146850586 seconds for one epoch ---
--- 0.28943681716918945 seconds for one epoch ---
--- 0.7301466464996338 seconds for one epoch ---
--- 0.2934377193450928 seconds for one epoch ---
--- 0.7262346744537354 seconds for one epoch ---
--- 0.33608508110046387 seconds for one epoch ---
--- 0.7384121417999268 seconds for one epoch ---
--- 0.3263578414916992 seconds for one epoch ---
--- 0.7615659236907959 seconds for one epoch ---
--- 0.3339855670928955 seconds for one epoch ---
--- 0.7374927997589111 seconds for one epoch ---
--- 0.33524060249328613 seconds for one epoch ---
--- 0.752680778503418 seconds for one epoch ---
--- 0.33185315132141113 seconds for one epoch ---
--- 0.7829859256744385 seconds for one epoch ---
--- 0.3314833641052246 seconds for one epoch ---
--- 0.7458317279815674 seconds for one epoch ---
--- 0.32053279876708984 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06181595]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11319864]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2648674]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.573187 ]
 [ 0.       ]]
--- 0.2651355266571045 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2171.234130859375, (963.92145, 1.2877667, 1205.827, 0.19805746)
   validation loss 2220.67138671875, (1878.4417, 0.089671195, 341.9421, 0.19805746)
decoder loss ratio: 72774.090654, decoder SINDy loss  ratio: 0.738130
--- 0.3224930763244629 seconds for one epoch ---
--- 0.7519643306732178 seconds for one epoch ---
--- 0.30540895462036133 seconds for one epoch ---
--- 0.736093282699585 seconds for one epoch ---
--- 0.2961893081665039 seconds for one epoch ---
--- 0.7304928302764893 seconds for one epoch ---
--- 0.3067169189453125 seconds for one epoch ---
--- 0.7306554317474365 seconds for one epoch ---
--- 0.3088979721069336 seconds for one epoch ---
--- 0.7496416568756104 seconds for one epoch ---
--- 0.30207300186157227 seconds for one epoch ---
--- 0.748093843460083 seconds for one epoch ---
--- 0.30602073669433594 seconds for one epoch ---
--- 0.7422268390655518 seconds for one epoch ---
--- 0.29854679107666016 seconds for one epoch ---
--- 0.7563326358795166 seconds for one epoch ---
--- 0.2989072799682617 seconds for one epoch ---
--- 0.7723672389984131 seconds for one epoch ---
--- 0.2922554016113281 seconds for one epoch ---
--- 0.7464108467102051 seconds for one epoch ---
--- 0.302440881729126 seconds for one epoch ---
--- 0.7468867301940918 seconds for one epoch ---
--- 0.30068016052246094 seconds for one epoch ---
--- 0.7448713779449463 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0621889 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11547491]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2870489]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.6693673]
 [ 0.       ]]
--- 0.3045384883880615 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4182.9921875, (1856.6685, 0.49142405, 2325.634, 0.1983954)
   validation loss 1656.822998046875, (1333.8402, 0.15065436, 322.6338, 0.1983954)
decoder loss ratio: 51675.285382, decoder SINDy loss  ratio: 0.696450
THRESHOLDING: 1 active coefficients
--- 0.7369344234466553 seconds for one epoch ---
--- 0.29794907569885254 seconds for one epoch ---
--- 0.7420060634613037 seconds for one epoch ---
--- 0.2831764221191406 seconds for one epoch ---
--- 0.7472307682037354 seconds for one epoch ---
--- 0.3047502040863037 seconds for one epoch ---
--- 0.7530612945556641 seconds for one epoch ---
--- 0.3038010597229004 seconds for one epoch ---
--- 0.7307696342468262 seconds for one epoch ---
--- 0.29874491691589355 seconds for one epoch ---
--- 0.7657411098480225 seconds for one epoch ---
--- 0.2903022766113281 seconds for one epoch ---
--- 0.7505271434783936 seconds for one epoch ---
--- 0.2881479263305664 seconds for one epoch ---
--- 0.7555985450744629 seconds for one epoch ---
--- 0.29219555854797363 seconds for one epoch ---
--- 0.7502856254577637 seconds for one epoch ---
--- 0.30174970626831055 seconds for one epoch ---
--- 0.7662606239318848 seconds for one epoch ---
--- 0.2982168197631836 seconds for one epoch ---
--- 0.7579166889190674 seconds for one epoch ---
--- 0.29678845405578613 seconds for one epoch ---
--- 0.7819314002990723 seconds for one epoch ---
--- 0.3117549419403076 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12609974]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.109466]
 [ 0.      ]]
--- 0.23980331420898438 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3189.338623046875, (1616.4778, 4.9311385, 1567.8599, 0.06991352)
   validation loss 933.5360717773438, (647.1555, 0.11704945, 286.1936, 0.06991352)
decoder loss ratio: 25071.928262, decoder SINDy loss  ratio: 0.617789
--- 0.3062398433685303 seconds for one epoch ---
--- 0.7636404037475586 seconds for one epoch ---
--- 0.3254106044769287 seconds for one epoch ---
--- 0.768773078918457 seconds for one epoch ---
--- 0.32488012313842773 seconds for one epoch ---
--- 0.7774913311004639 seconds for one epoch ---
--- 0.3180680274963379 seconds for one epoch ---
--- 0.7583045959472656 seconds for one epoch ---
--- 0.31197452545166016 seconds for one epoch ---
--- 0.7664368152618408 seconds for one epoch ---
--- 0.34479594230651855 seconds for one epoch ---
--- 0.7506141662597656 seconds for one epoch ---
--- 0.30812692642211914 seconds for one epoch ---
--- 0.7847964763641357 seconds for one epoch ---
--- 0.331742525100708 seconds for one epoch ---
--- 0.7919447422027588 seconds for one epoch ---
--- 0.3186454772949219 seconds for one epoch ---
--- 0.7912130355834961 seconds for one epoch ---
--- 0.31968069076538086 seconds for one epoch ---
--- 0.786332368850708 seconds for one epoch ---
--- 0.31938886642456055 seconds for one epoch ---
--- 0.7779428958892822 seconds for one epoch ---
--- 0.32836103439331055 seconds for one epoch ---
--- 0.7430341243743896 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13713375]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.5695796]
 [ 0.       ]]
--- 0.3025240898132324 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2961.41552734375, (1258.5432, 1.9286832, 1700.8682, 0.07541815)
   validation loss 989.0027465820312, (653.2206, 0.1435793, 335.56317, 0.07541815)
decoder loss ratio: 25306.899351, decoder SINDy loss  ratio: 0.724360
--- 0.2577664852142334 seconds for one epoch ---
--- 0.2990868091583252 seconds for one epoch ---
--- 0.7642624378204346 seconds for one epoch ---
--- 0.30041933059692383 seconds for one epoch ---
--- 0.76206374168396 seconds for one epoch ---
--- 0.2979464530944824 seconds for one epoch ---
--- 0.7720332145690918 seconds for one epoch ---
--- 0.2913858890533447 seconds for one epoch ---
--- 0.7395451068878174 seconds for one epoch ---
--- 0.28577351570129395 seconds for one epoch ---
--- 0.7540786266326904 seconds for one epoch ---
--- 0.31072473526000977 seconds for one epoch ---
--- 0.7736613750457764 seconds for one epoch ---
--- 0.31620144844055176 seconds for one epoch ---
--- 0.781212329864502 seconds for one epoch ---
--- 0.31311774253845215 seconds for one epoch ---
--- 0.7731480598449707 seconds for one epoch ---
--- 0.30655860900878906 seconds for one epoch ---
--- 0.7706570625305176 seconds for one epoch ---
--- 0.312363862991333 seconds for one epoch ---
--- 0.793093204498291 seconds for one epoch ---
--- 0.3321826457977295 seconds for one epoch ---
--- 0.7818024158477783 seconds for one epoch ---
--- 0.319063663482666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14681429]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.9822807]
 [ 0.       ]]
--- 0.26209020614624023 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3296.56591796875, (1128.2177, 3.7625988, 2164.5054, 0.08035459)
   validation loss 1115.462158203125, (834.44104, 0.18096428, 280.75983, 0.08035459)
decoder loss ratio: 32327.694544, decoder SINDy loss  ratio: 0.606060
--- 0.29786014556884766 seconds for one epoch ---
--- 0.7891683578491211 seconds for one epoch ---
--- 0.3083169460296631 seconds for one epoch ---
--- 0.7919917106628418 seconds for one epoch ---
--- 0.29549312591552734 seconds for one epoch ---
--- 0.7851262092590332 seconds for one epoch ---
--- 0.29753565788269043 seconds for one epoch ---
--- 0.775629997253418 seconds for one epoch ---
--- 0.31711864471435547 seconds for one epoch ---
--- 0.7933578491210938 seconds for one epoch ---
--- 0.32220005989074707 seconds for one epoch ---
--- 0.8091723918914795 seconds for one epoch ---
--- 0.3393371105194092 seconds for one epoch ---
--- 0.7947690486907959 seconds for one epoch ---
--- 0.3183774948120117 seconds for one epoch ---
--- 0.7994718551635742 seconds for one epoch ---
--- 0.3269333839416504 seconds for one epoch ---
--- 0.8052566051483154 seconds for one epoch ---
--- 0.3196909427642822 seconds for one epoch ---
--- 0.7814352512359619 seconds for one epoch ---
--- 0.3253774642944336 seconds for one epoch ---
--- 0.7969999313354492 seconds for one epoch ---
--- 0.32581663131713867 seconds for one epoch ---
--- 0.7886598110198975 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15618171]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.3956103]
 [ 0.       ]]
--- 0.29406023025512695 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3539.880615234375, (1509.8029, 1.7329209, 2028.2596, 0.08525965)
   validation loss 1026.6558837890625, (751.53864, 0.17853488, 274.85352, 0.08525965)
decoder loss ratio: 29115.911458, decoder SINDy loss  ratio: 0.593310
--- 0.2621500492095947 seconds for one epoch ---
--- 0.29497432708740234 seconds for one epoch ---
--- 0.8032112121582031 seconds for one epoch ---
--- 0.2977883815765381 seconds for one epoch ---
--- 0.804614782333374 seconds for one epoch ---
--- 0.2965261936187744 seconds for one epoch ---
--- 0.7839860916137695 seconds for one epoch ---
--- 0.3041110038757324 seconds for one epoch ---
--- 0.7832958698272705 seconds for one epoch ---
--- 0.29903459548950195 seconds for one epoch ---
--- 0.7766571044921875 seconds for one epoch ---
--- 0.3022942543029785 seconds for one epoch ---
--- 0.7921860218048096 seconds for one epoch ---
--- 0.29091310501098633 seconds for one epoch ---
--- 0.8100860118865967 seconds for one epoch ---
--- 0.2998175621032715 seconds for one epoch ---
--- 0.8047828674316406 seconds for one epoch ---
--- 0.30640435218811035 seconds for one epoch ---
--- 0.8051867485046387 seconds for one epoch ---
--- 0.2976047992706299 seconds for one epoch ---
--- 0.7932324409484863 seconds for one epoch ---
--- 0.3064560890197754 seconds for one epoch ---
--- 0.8092796802520752 seconds for one epoch ---
--- 0.3001675605773926 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1644583]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.7787395]
 [-0.       ]]
--- 0.25867700576782227 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2600.910888671875, (1082.6979, 1.1404405, 1516.9828, 0.089732885)
   validation loss 967.9087524414062, (661.35657, 0.14252393, 306.31995, 0.089732885)
decoder loss ratio: 25622.101586, decoder SINDy loss  ratio: 0.661235
--- 0.28252696990966797 seconds for one epoch ---
--- 0.7716865539550781 seconds for one epoch ---
--- 0.28139424324035645 seconds for one epoch ---
--- 0.7855472564697266 seconds for one epoch ---
--- 0.2938210964202881 seconds for one epoch ---
--- 0.7866694927215576 seconds for one epoch ---
--- 0.2957596778869629 seconds for one epoch ---
--- 0.8051357269287109 seconds for one epoch ---
--- 0.310382604598999 seconds for one epoch ---
--- 0.7845523357391357 seconds for one epoch ---
--- 0.2936868667602539 seconds for one epoch ---
--- 0.8047122955322266 seconds for one epoch ---
--- 0.29799699783325195 seconds for one epoch ---
--- 0.8194088935852051 seconds for one epoch ---
--- 0.3051590919494629 seconds for one epoch ---
--- 0.8207926750183105 seconds for one epoch ---
--- 0.31133270263671875 seconds for one epoch ---
--- 0.8085672855377197 seconds for one epoch ---
--- 0.2988579273223877 seconds for one epoch ---
--- 0.8332555294036865 seconds for one epoch ---
--- 0.3061089515686035 seconds for one epoch ---
--- 0.808570384979248 seconds for one epoch ---
--- 0.3074169158935547 seconds for one epoch ---
--- 0.8320200443267822 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17142974]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.120185]
 [ 0.      ]]
--- 0.2928009033203125 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5399.37109375, (1597.6112, 1.985475, 3799.6807, 0.09378869)
   validation loss 912.41650390625, (601.4623, 0.1096984, 310.75073, 0.09378869)
decoder loss ratio: 23301.692922, decoder SINDy loss  ratio: 0.670799
--- 0.2616159915924072 seconds for one epoch ---
--- 0.2995178699493408 seconds for one epoch ---
--- 0.7938761711120605 seconds for one epoch ---
--- 0.2817814350128174 seconds for one epoch ---
--- 0.7967839241027832 seconds for one epoch ---
--- 0.284346342086792 seconds for one epoch ---
--- 0.8064157962799072 seconds for one epoch ---
--- 0.3113119602203369 seconds for one epoch ---
--- 0.8111200332641602 seconds for one epoch ---
--- 0.3115224838256836 seconds for one epoch ---
--- 0.8142848014831543 seconds for one epoch ---
--- 0.30209803581237793 seconds for one epoch ---
--- 0.8351006507873535 seconds for one epoch ---
--- 0.30136680603027344 seconds for one epoch ---
--- 0.8214941024780273 seconds for one epoch ---
--- 0.3188958168029785 seconds for one epoch ---
--- 0.816025972366333 seconds for one epoch ---
--- 0.3200695514678955 seconds for one epoch ---
--- 0.8075838088989258 seconds for one epoch ---
--- 0.3307836055755615 seconds for one epoch ---
--- 0.819936990737915 seconds for one epoch ---
--- 0.3334794044494629 seconds for one epoch ---
--- 0.8380439281463623 seconds for one epoch ---
--- 0.3175833225250244 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17849234]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.490931]
 [ 0.      ]]
--- 0.2620832920074463 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4473.56005859375, (2221.7861, 0.61418587, 2251.0613, 0.097955406)
   validation loss 2032.3375244140625, (1704.1704, 0.0768223, 327.99246, 0.097955406)
decoder loss ratio: 66022.520259, decoder SINDy loss  ratio: 0.708018
--- 0.30725622177124023 seconds for one epoch ---
--- 0.8074479103088379 seconds for one epoch ---
--- 0.3131833076477051 seconds for one epoch ---
--- 0.8409907817840576 seconds for one epoch ---
--- 0.295412540435791 seconds for one epoch ---
--- 0.825141429901123 seconds for one epoch ---
--- 0.3272569179534912 seconds for one epoch ---
--- 0.8517489433288574 seconds for one epoch ---
--- 0.3166501522064209 seconds for one epoch ---
--- 0.8332200050354004 seconds for one epoch ---
--- 0.3221564292907715 seconds for one epoch ---
--- 0.8353056907653809 seconds for one epoch ---
--- 0.3295176029205322 seconds for one epoch ---
--- 0.858217716217041 seconds for one epoch ---
--- 0.33095884323120117 seconds for one epoch ---
--- 0.8458783626556396 seconds for one epoch ---
--- 0.332763671875 seconds for one epoch ---
--- 0.8519093990325928 seconds for one epoch ---
--- 0.3358910083770752 seconds for one epoch ---
--- 0.8475086688995361 seconds for one epoch ---
--- 0.31783103942871094 seconds for one epoch ---
--- 0.8694829940795898 seconds for one epoch ---
--- 0.33458805084228516 seconds for one epoch ---
--- 0.8477737903594971 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18465386]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.8435054]
 [-0.       ]]
--- 0.3053460121154785 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2029.8690185546875, (1041.1005, 0.29150727, 988.3751, 0.101973906)
   validation loss 1476.5968017578125, (1174.9529, 0.1511951, 301.39072, 0.101973906)
decoder loss ratio: 45519.714412, decoder SINDy loss  ratio: 0.650594
--- 0.2646639347076416 seconds for one epoch ---
--- 0.3105142116546631 seconds for one epoch ---
--- 0.8413894176483154 seconds for one epoch ---
--- 0.2956230640411377 seconds for one epoch ---
--- 0.8087873458862305 seconds for one epoch ---
--- 0.2871890068054199 seconds for one epoch ---
--- 0.857684850692749 seconds for one epoch ---
--- 0.3044607639312744 seconds for one epoch ---
--- 0.854905366897583 seconds for one epoch ---
--- 0.30020761489868164 seconds for one epoch ---
--- 0.850426435470581 seconds for one epoch ---
--- 0.29613757133483887 seconds for one epoch ---
--- 0.8376622200012207 seconds for one epoch ---
--- 0.2946658134460449 seconds for one epoch ---
--- 0.8237700462341309 seconds for one epoch ---
--- 0.2939286231994629 seconds for one epoch ---
--- 0.8604891300201416 seconds for one epoch ---
--- 0.29584503173828125 seconds for one epoch ---
--- 0.8502850532531738 seconds for one epoch ---
--- 0.2986302375793457 seconds for one epoch ---
--- 0.8466284275054932 seconds for one epoch ---
--- 0.29520273208618164 seconds for one epoch ---
--- 0.8561012744903564 seconds for one epoch ---
--- 0.3005671501159668 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19029194]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.201365]
 [ 0.      ]]
--- 0.2536330223083496 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2930.251953125, (1345.949, 1.8220091, 1582.3749, 0.10584142)
   validation loss 1286.5185546875, (901.3398, 0.070130125, 385.0028, 0.10584142)
decoder loss ratio: 34919.467977, decoder SINDy loss  ratio: 0.831083
--- 0.29199934005737305 seconds for one epoch ---
--- 0.8509628772735596 seconds for one epoch ---
--- 0.30136680603027344 seconds for one epoch ---
--- 0.8413591384887695 seconds for one epoch ---
--- 0.30298304557800293 seconds for one epoch ---
--- 0.8335609436035156 seconds for one epoch ---
--- 0.2923605442047119 seconds for one epoch ---
--- 0.8386037349700928 seconds for one epoch ---
--- 0.2963294982910156 seconds for one epoch ---
--- 0.8563919067382812 seconds for one epoch ---
--- 0.29152941703796387 seconds for one epoch ---
--- 0.8656094074249268 seconds for one epoch ---
--- 0.2903873920440674 seconds for one epoch ---
--- 0.8418431282043457 seconds for one epoch ---
--- 0.2807502746582031 seconds for one epoch ---
--- 0.8455419540405273 seconds for one epoch ---
--- 0.2986607551574707 seconds for one epoch ---
--- 0.8475949764251709 seconds for one epoch ---
--- 0.294705867767334 seconds for one epoch ---
--- 0.8615224361419678 seconds for one epoch ---
--- 0.2963724136352539 seconds for one epoch ---
--- 0.8598678112030029 seconds for one epoch ---
--- 0.2994973659515381 seconds for one epoch ---
--- 0.8610048294067383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19505939]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.5438504]
 [-0.       ]]
--- 0.29216456413269043 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5496.10546875, (2325.1187, 3.260489, 3167.6167, 0.10954157)
   validation loss 931.836181640625, (635.19586, 0.12011356, 296.41064, 0.10954157)
decoder loss ratio: 24608.590435, decoder SINDy loss  ratio: 0.639844
--- 0.25121259689331055 seconds for one epoch ---
--- 0.29511094093322754 seconds for one epoch ---
--- 0.8426826000213623 seconds for one epoch ---
--- 0.29619765281677246 seconds for one epoch ---
--- 0.8356561660766602 seconds for one epoch ---
--- 0.29538869857788086 seconds for one epoch ---
--- 0.8561105728149414 seconds for one epoch ---
--- 0.30642056465148926 seconds for one epoch ---
--- 0.850609540939331 seconds for one epoch ---
--- 0.29084277153015137 seconds for one epoch ---
--- 0.8448193073272705 seconds for one epoch ---
--- 0.3026449680328369 seconds for one epoch ---
--- 0.8469743728637695 seconds for one epoch ---
--- 0.3002443313598633 seconds for one epoch ---
--- 0.866809606552124 seconds for one epoch ---
--- 0.2980632781982422 seconds for one epoch ---
--- 0.8615593910217285 seconds for one epoch ---
--- 0.4661693572998047 seconds for one epoch ---
--- 0.862882137298584 seconds for one epoch ---
--- 0.303668737411499 seconds for one epoch ---
--- 0.8590888977050781 seconds for one epoch ---
--- 0.3048367500305176 seconds for one epoch ---
--- 0.8719768524169922 seconds for one epoch ---
--- 0.31583690643310547 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19889538]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.8617034]
 [ 0.       ]]
--- 0.24810266494750977 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2373.1982421875, (1217.476, 2.6107795, 1152.9985, 0.11285069)
   validation loss 1934.5308837890625, (1573.2875, 0.16166073, 360.96902, 0.11285069)
decoder loss ratio: 60951.888151, decoder SINDy loss  ratio: 0.779202
--- 0.2977914810180664 seconds for one epoch ---
--- 0.8724491596221924 seconds for one epoch ---
--- 0.29662108421325684 seconds for one epoch ---
--- 0.85373854637146 seconds for one epoch ---
--- 0.30852842330932617 seconds for one epoch ---
--- 0.8524374961853027 seconds for one epoch ---
--- 0.3142404556274414 seconds for one epoch ---
--- 0.8647828102111816 seconds for one epoch ---
--- 0.32213425636291504 seconds for one epoch ---
--- 0.8743603229522705 seconds for one epoch ---
--- 0.3211090564727783 seconds for one epoch ---
--- 0.871706485748291 seconds for one epoch ---
--- 0.3195798397064209 seconds for one epoch ---
--- 0.8802130222320557 seconds for one epoch ---
--- 0.3256371021270752 seconds for one epoch ---
--- 0.8886771202087402 seconds for one epoch ---
--- 0.31929588317871094 seconds for one epoch ---
--- 0.8771359920501709 seconds for one epoch ---
--- 0.33905959129333496 seconds for one epoch ---
--- 0.8837230205535889 seconds for one epoch ---
--- 0.31133413314819336 seconds for one epoch ---
--- 0.9034087657928467 seconds for one epoch ---
--- 0.3303971290588379 seconds for one epoch ---
--- 0.8892428874969482 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20222619]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.189156]
 [-0.      ]]
--- 0.29027295112609863 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3561.862548828125, (1554.4316, 2.1873794, 2005.1273, 0.116167665)
   validation loss 1180.911376953125, (871.40234, 0.15934114, 309.2334, 0.116167665)
decoder loss ratio: 33759.639618, decoder SINDy loss  ratio: 0.667524
--- 0.2646975517272949 seconds for one epoch ---
--- 0.30475878715515137 seconds for one epoch ---
--- 0.8541371822357178 seconds for one epoch ---
--- 0.2993202209472656 seconds for one epoch ---
--- 0.8829014301300049 seconds for one epoch ---
--- 0.31942272186279297 seconds for one epoch ---
--- 0.9003064632415771 seconds for one epoch ---
--- 0.32113122940063477 seconds for one epoch ---
--- 0.9180343151092529 seconds for one epoch ---
--- 0.31456613540649414 seconds for one epoch ---
--- 0.8745198249816895 seconds for one epoch ---
--- 0.3281519412994385 seconds for one epoch ---
--- 0.8936593532562256 seconds for one epoch ---
--- 0.3335416316986084 seconds for one epoch ---
--- 0.8821229934692383 seconds for one epoch ---
--- 0.3205869197845459 seconds for one epoch ---
--- 0.8901474475860596 seconds for one epoch ---
--- 0.3043038845062256 seconds for one epoch ---
--- 0.9136216640472412 seconds for one epoch ---
--- 0.314162015914917 seconds for one epoch ---
--- 0.8994688987731934 seconds for one epoch ---
--- 0.30663442611694336 seconds for one epoch ---
--- 0.9039351940155029 seconds for one epoch ---
--- 0.32434844970703125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20475349]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-8.496396]
 [-0.      ]]
--- 0.25260472297668457 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2579.17822265625, (1080.0295, 0.32862398, 1498.701, 0.11919496)
   validation loss 2015.867919921875, (1701.0634, 0.14162913, 314.54388, 0.11919496)
decoder loss ratio: 65902.147529, decoder SINDy loss  ratio: 0.678987
--- 0.3006260395050049 seconds for one epoch ---
--- 0.8281300067901611 seconds for one epoch ---
--- 0.288790225982666 seconds for one epoch ---
--- 0.9027318954467773 seconds for one epoch ---
--- 0.2902188301086426 seconds for one epoch ---
--- 0.8951895236968994 seconds for one epoch ---
--- 0.31312108039855957 seconds for one epoch ---
--- 0.9101462364196777 seconds for one epoch ---
--- 0.29750490188598633 seconds for one epoch ---
--- 0.933821439743042 seconds for one epoch ---
--- 0.30883169174194336 seconds for one epoch ---
--- 0.8937671184539795 seconds for one epoch ---
--- 0.3086268901824951 seconds for one epoch ---
--- 0.9105725288391113 seconds for one epoch ---
--- 0.289764404296875 seconds for one epoch ---
--- 0.9126167297363281 seconds for one epoch ---
--- 0.28755927085876465 seconds for one epoch ---
--- 0.9312281608581543 seconds for one epoch ---
--- 0.29819560050964355 seconds for one epoch ---
--- 0.9043583869934082 seconds for one epoch ---
--- 0.2999229431152344 seconds for one epoch ---
--- 0.9095973968505859 seconds for one epoch ---
--- 0.28748321533203125 seconds for one epoch ---
--- 0.9011971950531006 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20665339]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-8.797471]
 [ 0.      ]]
--- 0.28853416442871094 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2583.48193359375, (1139.8313, 1.609295, 1441.9192, 0.12205944)
   validation loss 1245.30029296875, (935.8542, 0.12059821, 309.20346, 0.12205944)
decoder loss ratio: 36256.615919, decoder SINDy loss  ratio: 0.667459
--- 0.2598576545715332 seconds for one epoch ---
--- 0.29568052291870117 seconds for one epoch ---
--- 0.8897428512573242 seconds for one epoch ---
--- 0.29116249084472656 seconds for one epoch ---
--- 0.905592679977417 seconds for one epoch ---
--- 0.2984490394592285 seconds for one epoch ---
--- 0.8900189399719238 seconds for one epoch ---
--- 0.29460954666137695 seconds for one epoch ---
--- 0.9142272472381592 seconds for one epoch ---
--- 0.3003270626068115 seconds for one epoch ---
--- 0.8648903369903564 seconds for one epoch ---
--- 0.29200315475463867 seconds for one epoch ---
--- 0.8971133232116699 seconds for one epoch ---
--- 0.2949042320251465 seconds for one epoch ---
--- 0.9035675525665283 seconds for one epoch ---
--- 0.2912173271179199 seconds for one epoch ---
--- 0.8994522094726562 seconds for one epoch ---
--- 0.3098480701446533 seconds for one epoch ---
--- 0.881791353225708 seconds for one epoch ---
--- 0.29696035385131836 seconds for one epoch ---
--- 0.9043533802032471 seconds for one epoch ---
--- 0.2978987693786621 seconds for one epoch ---
--- 0.9227311611175537 seconds for one epoch ---
--- 0.30966973304748535 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20788829]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.075398]
 [ 0.      ]]
--- 0.24710679054260254 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2179.7197265625, (1045.3618, 3.8396745, 1130.3936, 0.124548666)
   validation loss 959.4927978515625, (690.3923, 0.18808058, 268.78784, 0.124548666)
decoder loss ratio: 26746.995228, decoder SINDy loss  ratio: 0.580216
--- 0.30950427055358887 seconds for one epoch ---
--- 0.8787271976470947 seconds for one epoch ---
--- 0.2985265254974365 seconds for one epoch ---
--- 0.9305775165557861 seconds for one epoch ---
--- 0.2956540584564209 seconds for one epoch ---
--- 0.9234323501586914 seconds for one epoch ---
--- 0.2911369800567627 seconds for one epoch ---
--- 0.9368207454681396 seconds for one epoch ---
--- 0.2936713695526123 seconds for one epoch ---
--- 0.9025897979736328 seconds for one epoch ---
--- 0.2906007766723633 seconds for one epoch ---
--- 0.8973846435546875 seconds for one epoch ---
--- 0.29260873794555664 seconds for one epoch ---
--- 0.9074509143829346 seconds for one epoch ---
--- 0.29749131202697754 seconds for one epoch ---
--- 0.9292457103729248 seconds for one epoch ---
--- 0.27605485916137695 seconds for one epoch ---
--- 0.95632004737854 seconds for one epoch ---
--- 0.301663875579834 seconds for one epoch ---
--- 0.9208459854125977 seconds for one epoch ---
--- 0.29964780807495117 seconds for one epoch ---
--- 0.9265732765197754 seconds for one epoch ---
--- 0.29267263412475586 seconds for one epoch ---
--- 0.9358181953430176 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20860381]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.344727]
 [-0.      ]]
--- 0.28868937492370605 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7148.65673828125, (2299.5535, 1.2561986, 4847.72, 0.12700582)
   validation loss 1152.4052734375, (860.85425, 0.18004763, 291.24396, 0.12700582)
decoder loss ratio: 33350.988078, decoder SINDy loss  ratio: 0.628691
--- 0.27097630500793457 seconds for one epoch ---
--- 0.283707857131958 seconds for one epoch ---
--- 0.8986208438873291 seconds for one epoch ---
--- 0.31320881843566895 seconds for one epoch ---
--- 0.9282529354095459 seconds for one epoch ---
--- 0.2912478446960449 seconds for one epoch ---
--- 0.9213695526123047 seconds for one epoch ---
--- 0.29640769958496094 seconds for one epoch ---
--- 0.9607946872711182 seconds for one epoch ---
--- 0.3049013614654541 seconds for one epoch ---
--- 0.93280029296875 seconds for one epoch ---
--- 0.2952842712402344 seconds for one epoch ---
--- 0.9496703147888184 seconds for one epoch ---
--- 0.3059816360473633 seconds for one epoch ---
--- 0.9465441703796387 seconds for one epoch ---
--- 0.33203125 seconds for one epoch ---
--- 0.9407830238342285 seconds for one epoch ---
--- 0.31548047065734863 seconds for one epoch ---
--- 0.9508111476898193 seconds for one epoch ---
--- 0.3208320140838623 seconds for one epoch ---
--- 0.9361057281494141 seconds for one epoch ---
--- 0.32109880447387695 seconds for one epoch ---
--- 0.9440948963165283 seconds for one epoch ---
--- 0.3319740295410156 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20884117]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.630077]
 [-0.      ]]
--- 0.2563917636871338 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2035.538818359375, (855.7215, 0.52089685, 1179.1671, 0.12943631)
   validation loss 968.2546997070312, (641.01495, 0.14379483, 326.96646, 0.12943631)
decoder loss ratio: 24834.032154, decoder SINDy loss  ratio: 0.705803
--- 0.29815053939819336 seconds for one epoch ---
--- 0.9144551753997803 seconds for one epoch ---
--- 0.31134629249572754 seconds for one epoch ---
--- 0.9513919353485107 seconds for one epoch ---
--- 0.3376455307006836 seconds for one epoch ---
--- 0.9631204605102539 seconds for one epoch ---
--- 0.33756494522094727 seconds for one epoch ---
--- 0.9786150455474854 seconds for one epoch ---
--- 0.32848310470581055 seconds for one epoch ---
--- 0.9941082000732422 seconds for one epoch ---
--- 0.3300495147705078 seconds for one epoch ---
--- 0.9566700458526611 seconds for one epoch ---
--- 0.3442502021789551 seconds for one epoch ---
--- 0.9877855777740479 seconds for one epoch ---
--- 0.3198659420013428 seconds for one epoch ---
--- 1.0008196830749512 seconds for one epoch ---
--- 0.3132922649383545 seconds for one epoch ---
--- 0.956458568572998 seconds for one epoch ---
--- 0.32208847999572754 seconds for one epoch ---
--- 0.9736783504486084 seconds for one epoch ---
--- 0.30982542037963867 seconds for one epoch ---
--- 0.9318547248840332 seconds for one epoch ---
--- 0.32277584075927734 seconds for one epoch ---
--- 0.9555840492248535 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20855986]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.906009]
 [ 0.      ]]
--- 0.2886962890625 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2876.07861328125, (1680.067, 2.051145, 1193.8289, 0.13169287)
   validation loss 931.9122314453125, (666.27374, 0.21334216, 265.2935, 0.13169287)
decoder loss ratio: 25812.601493, decoder SINDy loss  ratio: 0.572673
--- 0.25441670417785645 seconds for one epoch ---
--- 0.2972447872161865 seconds for one epoch ---
--- 0.9411530494689941 seconds for one epoch ---
--- 0.29418182373046875 seconds for one epoch ---
--- 0.959463357925415 seconds for one epoch ---
--- 0.2967996597290039 seconds for one epoch ---
--- 0.9323194026947021 seconds for one epoch ---
--- 0.3074774742126465 seconds for one epoch ---
--- 0.9597353935241699 seconds for one epoch ---
--- 0.3023509979248047 seconds for one epoch ---
--- 0.955014705657959 seconds for one epoch ---
--- 0.2983078956604004 seconds for one epoch ---
--- 0.9558093547821045 seconds for one epoch ---
--- 0.2973470687866211 seconds for one epoch ---
--- 0.9628393650054932 seconds for one epoch ---
--- 0.30408501625061035 seconds for one epoch ---
--- 0.971926212310791 seconds for one epoch ---
--- 0.28865933418273926 seconds for one epoch ---
--- 0.9677958488464355 seconds for one epoch ---
--- 0.2989540100097656 seconds for one epoch ---
--- 0.9452419281005859 seconds for one epoch ---
--- 0.2968013286590576 seconds for one epoch ---
--- 0.9466609954833984 seconds for one epoch ---
--- 0.30351948738098145 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20778766]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.179142]
 [ -0.      ]]
--- 0.26619839668273926 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3896.385009765625, (2055.4424, 0.74771136, 1840.061, 0.13382092)
   validation loss 1033.8515625, (709.84534, 0.23239052, 323.64008, 0.13382092)
decoder loss ratio: 27500.640698, decoder SINDy loss  ratio: 0.698623
--- 0.30405426025390625 seconds for one epoch ---
--- 0.947230339050293 seconds for one epoch ---
--- 0.314960241317749 seconds for one epoch ---
--- 0.9554235935211182 seconds for one epoch ---
--- 0.3169405460357666 seconds for one epoch ---
--- 0.9655869007110596 seconds for one epoch ---
--- 0.32625436782836914 seconds for one epoch ---
--- 0.964857816696167 seconds for one epoch ---
--- 0.3186476230621338 seconds for one epoch ---
--- 0.9849462509155273 seconds for one epoch ---
--- 0.345125675201416 seconds for one epoch ---
--- 0.965651273727417 seconds for one epoch ---
--- 0.33047032356262207 seconds for one epoch ---
--- 0.979447603225708 seconds for one epoch ---
--- 0.32569313049316406 seconds for one epoch ---
--- 0.9664864540100098 seconds for one epoch ---
--- 0.3284282684326172 seconds for one epoch ---
--- 0.9785242080688477 seconds for one epoch ---
--- 0.3285670280456543 seconds for one epoch ---
--- 0.9768795967102051 seconds for one epoch ---
--- 0.3132972717285156 seconds for one epoch ---
--- 0.9951136112213135 seconds for one epoch ---
--- 0.3215317726135254 seconds for one epoch ---
--- 0.9865260124206543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20661001]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.437318]
 [  0.      ]]
--- 0.2950737476348877 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3795.274169921875, (955.95447, 3.276296, 2835.9077, 0.13569811)
   validation loss 1031.215576171875, (717.5859, 0.25652328, 313.23746, 0.13569811)
decoder loss ratio: 27800.522638, decoder SINDy loss  ratio: 0.676167
THRESHOLDING: 1 active coefficients
--- 0.2697763442993164 seconds for one epoch ---
--- 0.3025527000427246 seconds for one epoch ---
--- 0.9880924224853516 seconds for one epoch ---
--- 0.29840660095214844 seconds for one epoch ---
--- 0.9980759620666504 seconds for one epoch ---
--- 0.30208301544189453 seconds for one epoch ---
--- 1.0029296875 seconds for one epoch ---
--- 0.29726600646972656 seconds for one epoch ---
--- 0.9898436069488525 seconds for one epoch ---
--- 0.29956793785095215 seconds for one epoch ---
--- 0.9800617694854736 seconds for one epoch ---
--- 0.2919924259185791 seconds for one epoch ---
--- 0.9867839813232422 seconds for one epoch ---
--- 0.2973489761352539 seconds for one epoch ---
--- 0.9585299491882324 seconds for one epoch ---
--- 0.3157954216003418 seconds for one epoch ---
--- 0.9713156223297119 seconds for one epoch ---
--- 0.2953007221221924 seconds for one epoch ---
--- 0.9698853492736816 seconds for one epoch ---
--- 0.28678250312805176 seconds for one epoch ---
--- 0.9996051788330078 seconds for one epoch ---
--- 0.306978702545166 seconds for one epoch ---
--- 0.981532096862793 seconds for one epoch ---
--- 0.30578017234802246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20507604]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.685011]
 [  0.      ]]
--- 0.2643411159515381 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2119.4755859375, (1359.6189, 0.79262596, 758.9403, 0.12365989)
   validation loss 1664.7608642578125, (1328.9233, 0.15492053, 335.55893, 0.12365989)
decoder loss ratio: 51484.797298, decoder SINDy loss  ratio: 0.724351
--- 0.29508543014526367 seconds for one epoch ---
--- 0.9758191108703613 seconds for one epoch ---
--- 0.2957909107208252 seconds for one epoch ---
--- 1.0026218891143799 seconds for one epoch ---
--- 0.29410552978515625 seconds for one epoch ---
--- 1.001871109008789 seconds for one epoch ---
--- 0.29532408714294434 seconds for one epoch ---
--- 1.0027186870574951 seconds for one epoch ---
--- 0.29657912254333496 seconds for one epoch ---
--- 0.9863333702087402 seconds for one epoch ---
--- 0.3109130859375 seconds for one epoch ---
--- 0.9946379661560059 seconds for one epoch ---
--- 0.30385780334472656 seconds for one epoch ---
--- 0.9803180694580078 seconds for one epoch ---
--- 0.3004012107849121 seconds for one epoch ---
--- 0.9788494110107422 seconds for one epoch ---
--- 0.3087339401245117 seconds for one epoch ---
--- 1.0302767753601074 seconds for one epoch ---
--- 0.2959749698638916 seconds for one epoch ---
--- 0.9647376537322998 seconds for one epoch ---
--- 0.2930607795715332 seconds for one epoch ---
--- 1.0133857727050781 seconds for one epoch ---
--- 0.30991196632385254 seconds for one epoch ---
--- 0.9964382648468018 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20317653]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-10.93001]
 [ -0.     ]]
--- 0.2906768321990967 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4160.474609375, (1741.7133, 2.6290917, 2416.0068, 0.12540658)
   validation loss 956.6151733398438, (629.48987, 0.16511428, 326.83478, 0.12540658)
decoder loss ratio: 24387.530335, decoder SINDy loss  ratio: 0.705519
--- 0.26875805854797363 seconds for one epoch ---
--- 0.3138003349304199 seconds for one epoch ---
--- 0.9879622459411621 seconds for one epoch ---
--- 0.31592321395874023 seconds for one epoch ---
--- 1.0096497535705566 seconds for one epoch ---
--- 0.30225253105163574 seconds for one epoch ---
--- 0.9979352951049805 seconds for one epoch ---
--- 0.3025777339935303 seconds for one epoch ---
--- 0.9872434139251709 seconds for one epoch ---
--- 0.31178712844848633 seconds for one epoch ---
--- 1.0129554271697998 seconds for one epoch ---
--- 0.31484436988830566 seconds for one epoch ---
--- 1.0077617168426514 seconds for one epoch ---
--- 0.3088555335998535 seconds for one epoch ---
--- 1.0233442783355713 seconds for one epoch ---
--- 0.3027353286743164 seconds for one epoch ---
--- 1.0559136867523193 seconds for one epoch ---
--- 0.3020517826080322 seconds for one epoch ---
--- 1.0231845378875732 seconds for one epoch ---
--- 0.2944025993347168 seconds for one epoch ---
--- 1.0198378562927246 seconds for one epoch ---
--- 0.3003709316253662 seconds for one epoch ---
--- 1.014286756515503 seconds for one epoch ---
--- 0.30806970596313477 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2009954]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.165858]
 [  0.      ]]
--- 0.2523496150970459 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3103.2490234375, (1782.2251, 2.3564556, 1318.5405, 0.12686141)
   validation loss 1151.0372314453125, (809.8023, 0.13379821, 340.97433, 0.12686141)
decoder loss ratio: 31373.147257, decoder SINDy loss  ratio: 0.736041
--- 0.30364274978637695 seconds for one epoch ---
--- 1.0196547508239746 seconds for one epoch ---
--- 0.3012874126434326 seconds for one epoch ---
--- 0.9995143413543701 seconds for one epoch ---
--- 0.29042887687683105 seconds for one epoch ---
--- 0.9859449863433838 seconds for one epoch ---
--- 0.2964670658111572 seconds for one epoch ---
--- 1.0435962677001953 seconds for one epoch ---
--- 0.27798986434936523 seconds for one epoch ---
--- 1.009850263595581 seconds for one epoch ---
--- 0.3112521171569824 seconds for one epoch ---
--- 1.0144951343536377 seconds for one epoch ---
--- 0.29364967346191406 seconds for one epoch ---
--- 1.0302948951721191 seconds for one epoch ---
--- 0.3024415969848633 seconds for one epoch ---
--- 1.0342421531677246 seconds for one epoch ---
--- 0.2956507205963135 seconds for one epoch ---
--- 1.0528969764709473 seconds for one epoch ---
--- 0.3137516975402832 seconds for one epoch ---
--- 1.0196995735168457 seconds for one epoch ---
--- 0.3105297088623047 seconds for one epoch ---
--- 1.0203838348388672 seconds for one epoch ---
--- 0.30916619300842285 seconds for one epoch ---
--- 1.0193920135498047 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19884978]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-11.36877]
 [ -0.     ]]
--- 0.3174922466278076 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2769.2470703125, (1559.6819, 1.6232232, 1207.8138, 0.12814747)
   validation loss 2427.390380859375, (2051.9492, 0.086684264, 375.2262, 0.12814747)
decoder loss ratio: 79496.075075, decoder SINDy loss  ratio: 0.809979
--- 0.26374363899230957 seconds for one epoch ---
--- 0.31650543212890625 seconds for one epoch ---
--- 1.0259580612182617 seconds for one epoch ---
--- 0.31977248191833496 seconds for one epoch ---
--- 1.0273995399475098 seconds for one epoch ---
--- 0.302321195602417 seconds for one epoch ---
--- 1.0255346298217773 seconds for one epoch ---
--- 0.32572340965270996 seconds for one epoch ---
--- 1.051866054534912 seconds for one epoch ---
--- 0.33065223693847656 seconds for one epoch ---
--- 1.0155422687530518 seconds for one epoch ---
--- 0.33204197883605957 seconds for one epoch ---
--- 1.022413730621338 seconds for one epoch ---
--- 0.3239264488220215 seconds for one epoch ---
--- 1.037078619003296 seconds for one epoch ---
--- 0.3372929096221924 seconds for one epoch ---
--- 1.043581485748291 seconds for one epoch ---
--- 0.31696152687072754 seconds for one epoch ---
--- 1.0194473266601562 seconds for one epoch ---
--- 0.32927608489990234 seconds for one epoch ---
--- 1.0150465965270996 seconds for one epoch ---
--- 0.323453426361084 seconds for one epoch ---
--- 1.0251092910766602 seconds for one epoch ---
--- 0.30968451499938965 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19634187]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.581304]
 [  0.      ]]
--- 0.28463053703308105 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3418.65771484375, (1527.4429, 1.9238173, 1889.1616, 0.12943022)
   validation loss 994.6077880859375, (738.4055, 0.19936138, 255.87349, 0.12943022)
decoder loss ratio: 28607.111679, decoder SINDy loss  ratio: 0.552339
--- 0.30953001976013184 seconds for one epoch ---
--- 1.030670404434204 seconds for one epoch ---
--- 0.31809258460998535 seconds for one epoch ---
--- 1.0256140232086182 seconds for one epoch ---
--- 0.3139476776123047 seconds for one epoch ---
--- 1.0434174537658691 seconds for one epoch ---
--- 0.328747034072876 seconds for one epoch ---
--- 1.0481696128845215 seconds for one epoch ---
--- 0.31442761421203613 seconds for one epoch ---
--- 1.0761690139770508 seconds for one epoch ---
--- 0.32114720344543457 seconds for one epoch ---
--- 1.009202003479004 seconds for one epoch ---
--- 0.31154489517211914 seconds for one epoch ---
--- 1.0659401416778564 seconds for one epoch ---
--- 0.31807422637939453 seconds for one epoch ---
--- 1.0617728233337402 seconds for one epoch ---
--- 0.3286304473876953 seconds for one epoch ---
--- 1.0648643970489502 seconds for one epoch ---
--- 0.30652594566345215 seconds for one epoch ---
--- 1.0649924278259277 seconds for one epoch ---
--- 0.31842041015625 seconds for one epoch ---
--- 1.0940542221069336 seconds for one epoch ---
--- 0.31413722038269043 seconds for one epoch ---
--- 1.0625169277191162 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19355987]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.795026]
 [ -0.      ]]
--- 0.3190441131591797 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2892.166259765625, (1296.4622, 0.62728465, 1594.946, 0.13065843)
   validation loss 2548.86181640625, (2210.3086, 0.20371717, 338.2189, 0.13065843)
decoder loss ratio: 85631.192186, decoder SINDy loss  ratio: 0.730093
--- 0.2558596134185791 seconds for one epoch ---
--- 0.2785625457763672 seconds for one epoch ---
--- 1.0259077548980713 seconds for one epoch ---
--- 0.3002793788909912 seconds for one epoch ---
--- 1.0366764068603516 seconds for one epoch ---
--- 0.2922019958496094 seconds for one epoch ---
--- 1.0170049667358398 seconds for one epoch ---
--- 0.29741716384887695 seconds for one epoch ---
--- 1.0221953392028809 seconds for one epoch ---
--- 0.2996854782104492 seconds for one epoch ---
--- 1.0370464324951172 seconds for one epoch ---
--- 0.2886791229248047 seconds for one epoch ---
--- 1.0522465705871582 seconds for one epoch ---
--- 0.29238200187683105 seconds for one epoch ---
--- 1.0511162281036377 seconds for one epoch ---
--- 0.30345916748046875 seconds for one epoch ---
--- 1.0350911617279053 seconds for one epoch ---
--- 0.2896299362182617 seconds for one epoch ---
--- 1.0442125797271729 seconds for one epoch ---
--- 0.29010510444641113 seconds for one epoch ---
--- 1.0633161067962646 seconds for one epoch ---
--- 0.2968170642852783 seconds for one epoch ---
--- 1.051748275756836 seconds for one epoch ---
--- 0.29553794860839844 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19075403]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.993254]
 [ -0.      ]]
--- 0.2750670909881592 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2799.965087890625, (1484.3982, 1.0085188, 1314.4265, 0.13174225)
   validation loss 1467.7706298828125, (1179.2317, 0.16267069, 288.24457, 0.13174225)
decoder loss ratio: 45685.482886, decoder SINDy loss  ratio: 0.622216
--- 0.29163503646850586 seconds for one epoch ---
--- 1.0470080375671387 seconds for one epoch ---
--- 0.2972378730773926 seconds for one epoch ---
--- 1.0540618896484375 seconds for one epoch ---
--- 0.2944455146789551 seconds for one epoch ---
--- 1.0494518280029297 seconds for one epoch ---
--- 0.30716490745544434 seconds for one epoch ---
--- 1.0450620651245117 seconds for one epoch ---
--- 0.2791712284088135 seconds for one epoch ---
--- 1.0701265335083008 seconds for one epoch ---
--- 0.29167795181274414 seconds for one epoch ---
--- 1.0363807678222656 seconds for one epoch ---
--- 0.29813218116760254 seconds for one epoch ---
--- 1.0516164302825928 seconds for one epoch ---
--- 0.296067476272583 seconds for one epoch ---
--- 1.0577635765075684 seconds for one epoch ---
--- 0.3043179512023926 seconds for one epoch ---
--- 1.0525093078613281 seconds for one epoch ---
--- 0.2919137477874756 seconds for one epoch ---
--- 1.0819370746612549 seconds for one epoch ---
--- 0.29608941078186035 seconds for one epoch ---
--- 1.06685471534729 seconds for one epoch ---
--- 0.29851794242858887 seconds for one epoch ---
--- 1.075087070465088 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1878616]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-12.18373]
 [  0.     ]]
--- 0.29249119758605957 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2231.689697265625, (875.0963, 1.3555822, 1355.105, 0.13271604)
   validation loss 1010.6298828125, (730.78754, 0.19906574, 279.5106, 0.13271604)
decoder loss ratio: 28311.977872, decoder SINDy loss  ratio: 0.603363
--- 0.24718070030212402 seconds for one epoch ---
--- 0.28997039794921875 seconds for one epoch ---
--- 1.067892074584961 seconds for one epoch ---
--- 0.30209946632385254 seconds for one epoch ---
--- 1.0596129894256592 seconds for one epoch ---
--- 0.297670841217041 seconds for one epoch ---
--- 1.060941219329834 seconds for one epoch ---
--- 0.29784202575683594 seconds for one epoch ---
--- 1.0597598552703857 seconds for one epoch ---
--- 0.2963109016418457 seconds for one epoch ---
--- 1.0947489738464355 seconds for one epoch ---
--- 0.503441572189331 seconds for one epoch ---
--- 1.0675508975982666 seconds for one epoch ---
--- 0.29700303077697754 seconds for one epoch ---
--- 1.0918922424316406 seconds for one epoch ---
--- 0.3052701950073242 seconds for one epoch ---
--- 1.077976942062378 seconds for one epoch ---
--- 0.30205774307250977 seconds for one epoch ---
--- 1.0662007331848145 seconds for one epoch ---
--- 0.29116225242614746 seconds for one epoch ---
--- 1.0958597660064697 seconds for one epoch ---
--- 0.2925992012023926 seconds for one epoch ---
--- 1.0875515937805176 seconds for one epoch ---
--- 0.2978036403656006 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18490668]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.366832]
 [  0.      ]]
--- 0.25492095947265625 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3336.685791015625, (1351.8724, 1.2576689, 1983.422, 0.13362989)
   validation loss 955.0144653320312, (686.1382, 0.1758353, 268.56683, 0.13362989)
decoder loss ratio: 26582.184421, decoder SINDy loss  ratio: 0.579739
--- 0.28402209281921387 seconds for one epoch ---
--- 1.0811562538146973 seconds for one epoch ---
--- 0.2941446304321289 seconds for one epoch ---
--- 1.0708670616149902 seconds for one epoch ---
--- 0.29875755310058594 seconds for one epoch ---
--- 1.0706331729888916 seconds for one epoch ---
--- 0.30756354331970215 seconds for one epoch ---
--- 1.0625097751617432 seconds for one epoch ---
--- 0.29115748405456543 seconds for one epoch ---
--- 1.1850440502166748 seconds for one epoch ---
--- 0.2932605743408203 seconds for one epoch ---
--- 1.0824847221374512 seconds for one epoch ---
--- 0.2962334156036377 seconds for one epoch ---
--- 1.0826005935668945 seconds for one epoch ---
--- 0.29601573944091797 seconds for one epoch ---
--- 1.08027982711792 seconds for one epoch ---
--- 0.3031325340270996 seconds for one epoch ---
--- 1.0842492580413818 seconds for one epoch ---
--- 0.29493045806884766 seconds for one epoch ---
--- 1.0824270248413086 seconds for one epoch ---
--- 0.300764799118042 seconds for one epoch ---
--- 1.0861213207244873 seconds for one epoch ---
--- 0.3081085681915283 seconds for one epoch ---
--- 1.109696626663208 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18162504]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.559285]
 [ -0.      ]]
--- 0.30733752250671387 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4488.623046875, (1308.183, 3.8456612, 3176.46, 0.1345121)
   validation loss 828.5022583007812, (587.0177, 0.20478864, 241.14526, 0.1345121)
decoder loss ratio: 22742.084813, decoder SINDy loss  ratio: 0.520546
--- 0.26494383811950684 seconds for one epoch ---
--- 0.30423545837402344 seconds for one epoch ---
--- 1.0849697589874268 seconds for one epoch ---
--- 0.3001677989959717 seconds for one epoch ---
--- 1.0955829620361328 seconds for one epoch ---
--- 0.2902381420135498 seconds for one epoch ---
--- 1.0765881538391113 seconds for one epoch ---
--- 0.3027315139770508 seconds for one epoch ---
--- 1.0935568809509277 seconds for one epoch ---
--- 0.31209373474121094 seconds for one epoch ---
--- 1.0834763050079346 seconds for one epoch ---
--- 0.2876462936401367 seconds for one epoch ---
--- 1.1122722625732422 seconds for one epoch ---
--- 0.2923603057861328 seconds for one epoch ---
--- 1.076350450515747 seconds for one epoch ---
--- 0.29120373725891113 seconds for one epoch ---
--- 1.1012637615203857 seconds for one epoch ---
--- 0.2799386978149414 seconds for one epoch ---
--- 1.0933799743652344 seconds for one epoch ---
--- 0.299849271774292 seconds for one epoch ---
--- 1.1281001567840576 seconds for one epoch ---
--- 0.28974437713623047 seconds for one epoch ---
--- 1.1350688934326172 seconds for one epoch ---
--- 0.29329609870910645 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17868349]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.723786]
 [ -0.      ]]
--- 0.25240540504455566 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2434.20556640625, (1289.5435, 1.0796089, 1143.4473, 0.13524126)
   validation loss 957.4119873046875, (688.09515, 0.22092257, 268.96063, 0.13524126)
decoder loss ratio: 26658.000844, decoder SINDy loss  ratio: 0.580589
--- 0.28933238983154297 seconds for one epoch ---
--- 1.1210355758666992 seconds for one epoch ---
--- 0.2927889823913574 seconds for one epoch ---
--- 1.1143996715545654 seconds for one epoch ---
--- 0.3153877258300781 seconds for one epoch ---
--- 1.096247911453247 seconds for one epoch ---
--- 0.3106234073638916 seconds for one epoch ---
--- 1.1107497215270996 seconds for one epoch ---
--- 0.31431007385253906 seconds for one epoch ---
--- 1.1068425178527832 seconds for one epoch ---
--- 0.2893803119659424 seconds for one epoch ---
--- 1.1376831531524658 seconds for one epoch ---
--- 0.3031439781188965 seconds for one epoch ---
--- 1.1076111793518066 seconds for one epoch ---
--- 0.2906811237335205 seconds for one epoch ---
--- 1.1231539249420166 seconds for one epoch ---
--- 0.32505083084106445 seconds for one epoch ---
--- 1.127680778503418 seconds for one epoch ---
--- 0.3107156753540039 seconds for one epoch ---
--- 1.1252870559692383 seconds for one epoch ---
--- 0.30957746505737305 seconds for one epoch ---
--- 1.1347236633300781 seconds for one epoch ---
--- 0.2960038185119629 seconds for one epoch ---
--- 1.10841965675354 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17538755]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.900665]
 [  0.      ]]
--- 0.3040645122528076 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4259.52197265625, (1257.82, 0.8128649, 3000.7532, 0.13600087)
   validation loss 917.4793701171875, (644.1008, 0.18235986, 273.06015, 0.13600087)
decoder loss ratio: 24953.584365, decoder SINDy loss  ratio: 0.589439
--- 0.2652475833892822 seconds for one epoch ---
--- 0.31218957901000977 seconds for one epoch ---
--- 1.12556791305542 seconds for one epoch ---
--- 0.32389235496520996 seconds for one epoch ---
--- 1.1210298538208008 seconds for one epoch ---
--- 0.3141319751739502 seconds for one epoch ---
--- 1.0999836921691895 seconds for one epoch ---
--- 0.31392765045166016 seconds for one epoch ---
--- 1.130185604095459 seconds for one epoch ---
--- 0.32876062393188477 seconds for one epoch ---
--- 1.129145860671997 seconds for one epoch ---
--- 0.3135983943939209 seconds for one epoch ---
--- 1.1280131340026855 seconds for one epoch ---
--- 0.3290119171142578 seconds for one epoch ---
--- 1.1546056270599365 seconds for one epoch ---
--- 0.3252084255218506 seconds for one epoch ---
--- 1.1414573192596436 seconds for one epoch ---
--- 0.33269762992858887 seconds for one epoch ---
--- 1.1170635223388672 seconds for one epoch ---
--- 0.3368949890136719 seconds for one epoch ---
--- 1.1536610126495361 seconds for one epoch ---
--- 0.3155543804168701 seconds for one epoch ---
--- 1.1569900512695312 seconds for one epoch ---
--- 0.30313730239868164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17217554]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.066687]
 [ -0.      ]]
--- 0.27937960624694824 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2966.89501953125, (1479.1134, 0.79693526, 1486.8479, 0.1366446)
   validation loss 1114.554443359375, (839.99634, 0.21822053, 274.2033, 0.1366446)
decoder loss ratio: 32542.916428, decoder SINDy loss  ratio: 0.591906
--- 0.2919118404388428 seconds for one epoch ---
--- 1.1409499645233154 seconds for one epoch ---
--- 0.3024256229400635 seconds for one epoch ---
--- 1.133986473083496 seconds for one epoch ---
--- 0.30181074142456055 seconds for one epoch ---
--- 1.1480040550231934 seconds for one epoch ---
--- 0.3008284568786621 seconds for one epoch ---
--- 1.1420388221740723 seconds for one epoch ---
--- 0.29732394218444824 seconds for one epoch ---
--- 1.1203727722167969 seconds for one epoch ---
--- 0.29767346382141113 seconds for one epoch ---
--- 1.1400699615478516 seconds for one epoch ---
--- 0.3024332523345947 seconds for one epoch ---
--- 1.123274803161621 seconds for one epoch ---
--- 0.3118247985839844 seconds for one epoch ---
--- 1.1274237632751465 seconds for one epoch ---
--- 0.30476856231689453 seconds for one epoch ---
--- 1.1620032787322998 seconds for one epoch ---
--- 0.3007674217224121 seconds for one epoch ---
--- 1.1528804302215576 seconds for one epoch ---
--- 0.293912410736084 seconds for one epoch ---
--- 1.162886619567871 seconds for one epoch ---
--- 0.29183006286621094 seconds for one epoch ---
--- 1.1536836624145508 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1688661]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.232199]
 [  0.      ]]
--- 0.28989505767822266 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3391.00537109375, (1805.0167, 2.0767837, 1583.7747, 0.13726152)
   validation loss 1029.81591796875, (785.0223, 0.17373365, 244.48276, 0.13726152)
decoder loss ratio: 30413.125902, decoder SINDy loss  ratio: 0.527750
--- 0.2566516399383545 seconds for one epoch ---
--- 0.30082082748413086 seconds for one epoch ---
--- 1.128584623336792 seconds for one epoch ---
--- 0.28902125358581543 seconds for one epoch ---
--- 1.1417715549468994 seconds for one epoch ---
--- 0.29833364486694336 seconds for one epoch ---
--- 1.1391651630401611 seconds for one epoch ---
--- 0.2920541763305664 seconds for one epoch ---
--- 1.1599807739257812 seconds for one epoch ---
--- 0.29787135124206543 seconds for one epoch ---
--- 1.1423273086547852 seconds for one epoch ---
--- 0.29253602027893066 seconds for one epoch ---
--- 1.146787405014038 seconds for one epoch ---
--- 0.2800717353820801 seconds for one epoch ---
--- 1.155569314956665 seconds for one epoch ---
--- 0.2835350036621094 seconds for one epoch ---
--- 1.1457784175872803 seconds for one epoch ---
--- 0.2855675220489502 seconds for one epoch ---
--- 1.1434948444366455 seconds for one epoch ---
--- 0.30187082290649414 seconds for one epoch ---
--- 1.1481635570526123 seconds for one epoch ---
--- 0.2986791133880615 seconds for one epoch ---
--- 1.1721839904785156 seconds for one epoch ---
--- 0.29576969146728516 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16614571]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.364601]
 [  0.      ]]
--- 0.2651972770690918 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2440.10986328125, (1054.4154, 1.1890713, 1384.3678, 0.13773826)
   validation loss 1730.036865234375, (1370.7676, 0.19079989, 358.94083, 0.13773826)
decoder loss ratio: 53105.915734, decoder SINDy loss  ratio: 0.774824
--- 0.3107733726501465 seconds for one epoch ---
--- 1.171233892440796 seconds for one epoch ---
--- 0.3154020309448242 seconds for one epoch ---
--- 1.1603779792785645 seconds for one epoch ---
--- 0.33541131019592285 seconds for one epoch ---
--- 1.1396970748901367 seconds for one epoch ---
--- 0.3157923221588135 seconds for one epoch ---
--- 1.1821343898773193 seconds for one epoch ---
--- 0.3201615810394287 seconds for one epoch ---
--- 1.1709115505218506 seconds for one epoch ---
--- 0.31992554664611816 seconds for one epoch ---
--- 1.2039799690246582 seconds for one epoch ---
--- 0.3237271308898926 seconds for one epoch ---
--- 1.193129539489746 seconds for one epoch ---
--- 0.308758020401001 seconds for one epoch ---
--- 1.1890850067138672 seconds for one epoch ---
--- 0.30989742279052734 seconds for one epoch ---
--- 1.188765287399292 seconds for one epoch ---
--- 0.30179548263549805 seconds for one epoch ---
--- 1.1522948741912842 seconds for one epoch ---
--- 0.2913031578063965 seconds for one epoch ---
--- 1.1329498291015625 seconds for one epoch ---
--- 0.2954671382904053 seconds for one epoch ---
--- 1.1402051448822021 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16292745]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.517589]
 [ -0.      ]]
--- 0.29695701599121094 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2313.77392578125, (934.05426, 0.7495055, 1378.832, 0.13827756)
   validation loss 789.4957275390625, (552.3293, 0.19703063, 236.8311, 0.13827756)
decoder loss ratio: 21398.195374, decoder SINDy loss  ratio: 0.511233
--- 0.2715775966644287 seconds for one epoch ---
--- 0.3231770992279053 seconds for one epoch ---
--- 1.1445670127868652 seconds for one epoch ---
--- 0.3171045780181885 seconds for one epoch ---
--- 1.1408562660217285 seconds for one epoch ---
--- 0.3293299674987793 seconds for one epoch ---
--- 1.1498658657073975 seconds for one epoch ---
--- 0.3236210346221924 seconds for one epoch ---
--- 1.2058749198913574 seconds for one epoch ---
--- 0.33710813522338867 seconds for one epoch ---
--- 1.1791470050811768 seconds for one epoch ---
--- 0.3354978561401367 seconds for one epoch ---
--- 1.1674859523773193 seconds for one epoch ---
--- 0.3175480365753174 seconds for one epoch ---
--- 1.163815975189209 seconds for one epoch ---
--- 0.3207364082336426 seconds for one epoch ---
--- 1.1703126430511475 seconds for one epoch ---
--- 0.3167729377746582 seconds for one epoch ---
--- 1.1636979579925537 seconds for one epoch ---
--- 0.31818485260009766 seconds for one epoch ---
--- 1.1760447025299072 seconds for one epoch ---
--- 0.3016383647918701 seconds for one epoch ---
--- 1.183985948562622 seconds for one epoch ---
--- 0.2933485507965088 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16011895]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-13.64823]
 [  0.     ]]
--- 0.2804558277130127 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4167.91455078125, (1817.2908, 0.94117683, 2349.544, 0.13870111)
   validation loss 968.11083984375, (674.3416, 0.20946711, 293.42108, 0.13870111)
decoder loss ratio: 26125.164826, decoder SINDy loss  ratio: 0.633391
--- 0.3042891025543213 seconds for one epoch ---
--- 1.1867647171020508 seconds for one epoch ---
--- 0.30769777297973633 seconds for one epoch ---
--- 1.1810123920440674 seconds for one epoch ---
--- 0.30112171173095703 seconds for one epoch ---
--- 1.2196333408355713 seconds for one epoch ---
--- 0.30000948905944824 seconds for one epoch ---
--- 1.2005832195281982 seconds for one epoch ---
--- 0.2994532585144043 seconds for one epoch ---
--- 1.1980805397033691 seconds for one epoch ---
--- 0.2881917953491211 seconds for one epoch ---
--- 1.177724838256836 seconds for one epoch ---
--- 0.2963385581970215 seconds for one epoch ---
--- 1.1750342845916748 seconds for one epoch ---
--- 0.28591370582580566 seconds for one epoch ---
--- 1.19557785987854 seconds for one epoch ---
--- 0.29561948776245117 seconds for one epoch ---
--- 1.2271044254302979 seconds for one epoch ---
--- 0.2869274616241455 seconds for one epoch ---
--- 1.188459873199463 seconds for one epoch ---
--- 0.29600977897644043 seconds for one epoch ---
--- 1.1890344619750977 seconds for one epoch ---
--- 0.2922787666320801 seconds for one epoch ---
--- 1.1798923015594482 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1571331]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.784605]
 [ -0.      ]]
--- 0.28955578804016113 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2640.81298828125, (967.7182, 2.3474665, 1670.6083, 0.13913433)
   validation loss 936.7000732421875, (661.67163, 0.16811872, 274.7212, 0.13913433)
decoder loss ratio: 25634.307692, decoder SINDy loss  ratio: 0.593024
--- 0.26995158195495605 seconds for one epoch ---
--- 0.298687219619751 seconds for one epoch ---
--- 1.213620662689209 seconds for one epoch ---
--- 0.2915375232696533 seconds for one epoch ---
--- 1.2103819847106934 seconds for one epoch ---
--- 0.29132604598999023 seconds for one epoch ---
--- 1.2234933376312256 seconds for one epoch ---
--- 0.2923281192779541 seconds for one epoch ---
--- 1.2151801586151123 seconds for one epoch ---
--- 0.2977478504180908 seconds for one epoch ---
--- 1.2089126110076904 seconds for one epoch ---
--- 0.3012425899505615 seconds for one epoch ---
--- 1.1941564083099365 seconds for one epoch ---
--- 0.3047933578491211 seconds for one epoch ---
--- 1.231034755706787 seconds for one epoch ---
--- 0.2932548522949219 seconds for one epoch ---
--- 1.202666997909546 seconds for one epoch ---
--- 0.2931697368621826 seconds for one epoch ---
--- 1.208575963973999 seconds for one epoch ---
--- 0.2972605228424072 seconds for one epoch ---
--- 1.1961677074432373 seconds for one epoch ---
--- 0.2939021587371826 seconds for one epoch ---
--- 1.1934974193572998 seconds for one epoch ---
--- 0.29429101943969727 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15401292]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-13.92467]
 [  0.     ]]
--- 0.25260472297668457 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3720.328369140625, (1177.9907, 3.721496, 2538.4766, 0.13953333)
   validation loss 817.1292724609375, (568.7626, 0.121170655, 248.10605, 0.13953333)
decoder loss ratio: 22034.849503, decoder SINDy loss  ratio: 0.535572
--- 0.28981804847717285 seconds for one epoch ---
--- 1.1653056144714355 seconds for one epoch ---
--- 0.2973334789276123 seconds for one epoch ---
--- 1.2017896175384521 seconds for one epoch ---
--- 0.2966341972351074 seconds for one epoch ---
--- 1.185955286026001 seconds for one epoch ---
--- 0.3027162551879883 seconds for one epoch ---
--- 1.197530746459961 seconds for one epoch ---
--- 0.29556846618652344 seconds for one epoch ---
--- 1.213334321975708 seconds for one epoch ---
--- 0.2910916805267334 seconds for one epoch ---
--- 1.1865239143371582 seconds for one epoch ---
--- 0.2861976623535156 seconds for one epoch ---
--- 1.1818230152130127 seconds for one epoch ---
--- 0.29204750061035156 seconds for one epoch ---
--- 1.2084197998046875 seconds for one epoch ---
--- 0.29776692390441895 seconds for one epoch ---
--- 1.193526268005371 seconds for one epoch ---
--- 0.29912686347961426 seconds for one epoch ---
--- 1.2049927711486816 seconds for one epoch ---
--- 0.2859334945678711 seconds for one epoch ---
--- 1.1754705905914307 seconds for one epoch ---
--- 0.29402923583984375 seconds for one epoch ---
--- 1.190281629562378 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15089893]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.062281]
 [ -0.      ]]
--- 0.2921431064605713 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2015.21533203125, (1016.68146, 2.2834084, 996.11066, 0.13991652)
   validation loss 922.0867919921875, (647.3554, 0.13459253, 274.45688, 0.13991652)
decoder loss ratio: 25079.672353, decoder SINDy loss  ratio: 0.592454
THRESHOLDING: 1 active coefficients
--- 1.214503288269043 seconds for one epoch ---
--- 0.3339393138885498 seconds for one epoch ---
--- 1.1918561458587646 seconds for one epoch ---
--- 0.32024478912353516 seconds for one epoch ---
--- 1.2197539806365967 seconds for one epoch ---
--- 0.3167760372161865 seconds for one epoch ---
--- 1.2256088256835938 seconds for one epoch ---
--- 0.3023838996887207 seconds for one epoch ---
--- 1.206993818283081 seconds for one epoch ---
--- 0.2971787452697754 seconds for one epoch ---
--- 1.2115106582641602 seconds for one epoch ---
--- 0.29721975326538086 seconds for one epoch ---
--- 1.22157883644104 seconds for one epoch ---
--- 0.30235934257507324 seconds for one epoch ---
--- 1.1801352500915527 seconds for one epoch ---
--- 0.2948465347290039 seconds for one epoch ---
--- 1.1697697639465332 seconds for one epoch ---
--- 0.29520487785339355 seconds for one epoch ---
--- 1.2286572456359863 seconds for one epoch ---
--- 0.30768537521362305 seconds for one epoch ---
--- 1.23018479347229 seconds for one epoch ---
--- 0.29854369163513184 seconds for one epoch ---
--- 1.2369205951690674 seconds for one epoch ---
--- 0.29958510398864746 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14770257]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.201578]
 [ -0.      ]]
--- 0.26848268508911133 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2674.979736328125, (1406.9572, 3.1045125, 1264.7776, 0.14030729)
   validation loss 1106.9166259765625, (832.3021, 0.13624522, 274.338, 0.14030729)
decoder loss ratio: 32244.829225, decoder SINDy loss  ratio: 0.592197
--- 0.29836320877075195 seconds for one epoch ---
--- 1.2101795673370361 seconds for one epoch ---
--- 0.30699706077575684 seconds for one epoch ---
--- 1.19926118850708 seconds for one epoch ---
--- 0.30364084243774414 seconds for one epoch ---
--- 1.2284235954284668 seconds for one epoch ---
--- 0.2898707389831543 seconds for one epoch ---
--- 1.2222986221313477 seconds for one epoch ---
--- 0.2989778518676758 seconds for one epoch ---
--- 1.2117526531219482 seconds for one epoch ---
--- 0.3011054992675781 seconds for one epoch ---
--- 1.1736772060394287 seconds for one epoch ---
--- 0.2964801788330078 seconds for one epoch ---
--- 1.2303709983825684 seconds for one epoch ---
--- 0.312788724899292 seconds for one epoch ---
--- 1.2300212383270264 seconds for one epoch ---
--- 0.29453349113464355 seconds for one epoch ---
--- 1.2272264957427979 seconds for one epoch ---
--- 0.29985737800598145 seconds for one epoch ---
--- 1.2193512916564941 seconds for one epoch ---
--- 0.29479122161865234 seconds for one epoch ---
--- 1.2235016822814941 seconds for one epoch ---
--- 0.2692580223083496 seconds for one epoch ---
--- 1.2419912815093994 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14490628]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.322021]
 [  0.      ]]
--- 0.2930765151977539 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2222.403076171875, (1046.2169, 1.1088836, 1174.9366, 0.14061977)
   validation loss 1097.85400390625, (856.12933, 0.24469975, 241.33936, 0.14061977)
decoder loss ratio: 33167.936686, decoder SINDy loss  ratio: 0.520965
--- 0.2564413547515869 seconds for one epoch ---
--- 0.27968502044677734 seconds for one epoch ---
--- 1.2039637565612793 seconds for one epoch ---
--- 0.2973320484161377 seconds for one epoch ---
--- 1.2005093097686768 seconds for one epoch ---
--- 0.2949364185333252 seconds for one epoch ---
--- 1.1982953548431396 seconds for one epoch ---
--- 0.29615354537963867 seconds for one epoch ---
--- 1.2479865550994873 seconds for one epoch ---
--- 0.29270243644714355 seconds for one epoch ---
--- 1.2409296035766602 seconds for one epoch ---
--- 0.3038351535797119 seconds for one epoch ---
--- 1.227339744567871 seconds for one epoch ---
--- 0.2968459129333496 seconds for one epoch ---
--- 1.2605364322662354 seconds for one epoch ---
--- 0.29097509384155273 seconds for one epoch ---
--- 1.2619233131408691 seconds for one epoch ---
--- 0.30001330375671387 seconds for one epoch ---
--- 1.2278721332550049 seconds for one epoch ---
--- 0.3008079528808594 seconds for one epoch ---
--- 1.2628822326660156 seconds for one epoch ---
--- 0.3061504364013672 seconds for one epoch ---
--- 1.2326946258544922 seconds for one epoch ---
--- 0.3043811321258545 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14172843]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.457556]
 [  0.      ]]
--- 0.2610917091369629 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2756.543212890625, (1415.7157, 1.6363722, 1339.0503, 0.14094591)
   validation loss 815.2914428710938, (573.474, 0.19788735, 241.4786, 0.14094591)
decoder loss ratio: 22217.378317, decoder SINDy loss  ratio: 0.521266
--- 0.29958033561706543 seconds for one epoch ---
--- 1.246126413345337 seconds for one epoch ---
--- 0.303680419921875 seconds for one epoch ---
--- 1.2356858253479004 seconds for one epoch ---
--- 0.2990736961364746 seconds for one epoch ---
--- 1.2361598014831543 seconds for one epoch ---
--- 0.28957629203796387 seconds for one epoch ---
--- 1.2337121963500977 seconds for one epoch ---
--- 0.3048536777496338 seconds for one epoch ---
--- 1.2510297298431396 seconds for one epoch ---
--- 0.29297542572021484 seconds for one epoch ---
--- 1.2576501369476318 seconds for one epoch ---
--- 0.2959463596343994 seconds for one epoch ---
--- 1.271712064743042 seconds for one epoch ---
--- 0.29723644256591797 seconds for one epoch ---
--- 1.2760624885559082 seconds for one epoch ---
--- 0.29808831214904785 seconds for one epoch ---
--- 1.2622463703155518 seconds for one epoch ---
--- 0.29724740982055664 seconds for one epoch ---
--- 1.2596392631530762 seconds for one epoch ---
--- 0.2981100082397461 seconds for one epoch ---
--- 1.244807243347168 seconds for one epoch ---
--- 0.2962965965270996 seconds for one epoch ---
--- 1.2293250560760498 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13924074]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.562783]
 [ -0.      ]]
--- 0.30023789405822754 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3730.911376953125, (2266.4307, 1.9796832, 1462.3599, 0.1411888)
   validation loss 1092.2083740234375, (812.9956, 0.26353857, 278.808, 0.1411888)
decoder loss ratio: 31496.861178, decoder SINDy loss  ratio: 0.601846
--- 0.26715087890625 seconds for one epoch ---
--- 0.3061492443084717 seconds for one epoch ---
--- 1.2744560241699219 seconds for one epoch ---
--- 0.30432963371276855 seconds for one epoch ---
--- 1.247910976409912 seconds for one epoch ---
--- 0.29593682289123535 seconds for one epoch ---
--- 1.2812821865081787 seconds for one epoch ---
--- 0.3052947521209717 seconds for one epoch ---
--- 1.2715868949890137 seconds for one epoch ---
--- 0.2987065315246582 seconds for one epoch ---
--- 1.272524356842041 seconds for one epoch ---
--- 0.2993204593658447 seconds for one epoch ---
--- 1.2772667407989502 seconds for one epoch ---
--- 0.2835822105407715 seconds for one epoch ---
--- 1.2594125270843506 seconds for one epoch ---
--- 0.2917029857635498 seconds for one epoch ---
--- 1.267073392868042 seconds for one epoch ---
--- 0.2947807312011719 seconds for one epoch ---
--- 1.2626619338989258 seconds for one epoch ---
--- 0.2958672046661377 seconds for one epoch ---
--- 1.2750816345214844 seconds for one epoch ---
--- 0.30851006507873535 seconds for one epoch ---
--- 1.2778127193450928 seconds for one epoch ---
--- 0.3169066905975342 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13671044]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.669137]
 [ -0.      ]]
--- 0.25864577293395996 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3237.276611328125, (1504.5154, 1.255665, 1731.3643, 0.141418)
   validation loss 1113.11767578125, (851.8741, 0.19047092, 260.91168, 0.141418)
decoder loss ratio: 33003.080951, decoder SINDy loss  ratio: 0.563215
--- 0.30238986015319824 seconds for one epoch ---
--- 1.2468585968017578 seconds for one epoch ---
--- 0.3084602355957031 seconds for one epoch ---
--- 1.276388168334961 seconds for one epoch ---
--- 0.29901719093322754 seconds for one epoch ---
--- 1.282425880432129 seconds for one epoch ---
--- 0.3097677230834961 seconds for one epoch ---
--- 1.2908132076263428 seconds for one epoch ---
--- 0.29905009269714355 seconds for one epoch ---
--- 1.3002455234527588 seconds for one epoch ---
--- 0.27983927726745605 seconds for one epoch ---
--- 1.284876823425293 seconds for one epoch ---
--- 0.29460930824279785 seconds for one epoch ---
--- 1.2660925388336182 seconds for one epoch ---
--- 0.2902803421020508 seconds for one epoch ---
--- 1.2594690322875977 seconds for one epoch ---
--- 0.29677677154541016 seconds for one epoch ---
--- 1.2594084739685059 seconds for one epoch ---
--- 0.29581427574157715 seconds for one epoch ---
--- 1.2914941310882568 seconds for one epoch ---
--- 0.2973165512084961 seconds for one epoch ---
--- 1.2858374118804932 seconds for one epoch ---
--- 0.2867159843444824 seconds for one epoch ---
--- 1.279524803161621 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13422379]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.773099]
 [  0.      ]]
--- 0.2966756820678711 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4099.79541015625, (1445.9534, 1.9090648, 2651.7915, 0.14165144)
   validation loss 844.0029907226562, (578.7266, 0.16127339, 264.97342, 0.14165144)
decoder loss ratio: 22420.874109, decoder SINDy loss  ratio: 0.571982
--- 0.2650721073150635 seconds for one epoch ---
--- 0.28977155685424805 seconds for one epoch ---
--- 1.2866649627685547 seconds for one epoch ---
--- 0.3011171817779541 seconds for one epoch ---
--- 1.2904577255249023 seconds for one epoch ---
--- 0.29911231994628906 seconds for one epoch ---
--- 1.2820863723754883 seconds for one epoch ---
--- 0.29575657844543457 seconds for one epoch ---
--- 1.2813446521759033 seconds for one epoch ---
--- 0.29819774627685547 seconds for one epoch ---
--- 1.2832825183868408 seconds for one epoch ---
--- 0.3001420497894287 seconds for one epoch ---
--- 1.2801306247711182 seconds for one epoch ---
--- 0.29560017585754395 seconds for one epoch ---
--- 1.2779138088226318 seconds for one epoch ---
--- 0.2890498638153076 seconds for one epoch ---
--- 1.2853538990020752 seconds for one epoch ---
--- 0.28438663482666016 seconds for one epoch ---
--- 1.3018968105316162 seconds for one epoch ---
--- 0.2960357666015625 seconds for one epoch ---
--- 1.2908740043640137 seconds for one epoch ---
--- 0.2827565670013428 seconds for one epoch ---
--- 1.2781147956848145 seconds for one epoch ---
--- 0.2940034866333008 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1320276]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.864529]
 [ -0.      ]]
--- 0.26070570945739746 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3518.057861328125, (1052.6108, 0.49491346, 2464.8103, 0.141834)
   validation loss 743.9824829101562, (506.60492, 0.17275216, 237.06297, 0.141834)
decoder loss ratio: 19626.754084, decoder SINDy loss  ratio: 0.511734
--- 0.3050272464752197 seconds for one epoch ---
--- 1.299264669418335 seconds for one epoch ---
--- 0.3215525150299072 seconds for one epoch ---
--- 1.3058123588562012 seconds for one epoch ---
--- 0.31516528129577637 seconds for one epoch ---
--- 1.3071646690368652 seconds for one epoch ---
--- 0.33087944984436035 seconds for one epoch ---
--- 1.2936170101165771 seconds for one epoch ---
--- 0.3176710605621338 seconds for one epoch ---
--- 1.3196601867675781 seconds for one epoch ---
--- 0.31865787506103516 seconds for one epoch ---
--- 1.2859017848968506 seconds for one epoch ---
--- 0.3107750415802002 seconds for one epoch ---
--- 1.3161420822143555 seconds for one epoch ---
--- 0.31075167655944824 seconds for one epoch ---
--- 1.3120331764221191 seconds for one epoch ---
--- 0.32424211502075195 seconds for one epoch ---
--- 1.2914035320281982 seconds for one epoch ---
--- 0.30071163177490234 seconds for one epoch ---
--- 1.2816717624664307 seconds for one epoch ---
--- 0.2998065948486328 seconds for one epoch ---
--- 1.2962348461151123 seconds for one epoch ---
--- 0.3006100654602051 seconds for one epoch ---
--- 1.3080878257751465 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12965333]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.963036]
 [  0.      ]]
--- 0.30963635444641113 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2341.8203125, (1356.9453, 0.15780964, 984.5752, 0.14203584)
   validation loss 827.0654907226562, (576.69354, 0.17918484, 250.0507, 0.14203584)
decoder loss ratio: 22342.109020, decoder SINDy loss  ratio: 0.539770
--- 0.25949954986572266 seconds for one epoch ---
--- 0.30105066299438477 seconds for one epoch ---
--- 1.3282504081726074 seconds for one epoch ---
--- 0.3178417682647705 seconds for one epoch ---
--- 1.2997198104858398 seconds for one epoch ---
--- 0.30350470542907715 seconds for one epoch ---
--- 1.3382995128631592 seconds for one epoch ---
--- 0.3054642677307129 seconds for one epoch ---
--- 1.304765224456787 seconds for one epoch ---
--- 0.31162524223327637 seconds for one epoch ---
--- 1.2876205444335938 seconds for one epoch ---
--- 0.3202171325683594 seconds for one epoch ---
--- 1.3049499988555908 seconds for one epoch ---
--- 0.29526257514953613 seconds for one epoch ---
--- 1.3045485019683838 seconds for one epoch ---
--- 0.30959558486938477 seconds for one epoch ---
--- 1.312260627746582 seconds for one epoch ---
--- 0.31404566764831543 seconds for one epoch ---
--- 1.315814733505249 seconds for one epoch ---
--- 0.28409481048583984 seconds for one epoch ---
--- 1.299302339553833 seconds for one epoch ---
--- 0.2904632091522217 seconds for one epoch ---
--- 1.3218927383422852 seconds for one epoch ---
--- 0.2975599765777588 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12696998]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.074044]
 [  0.      ]]
--- 0.2579526901245117 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2235.465087890625, (1185.2896, 0.9751422, 1049.058, 0.14223865)
   validation loss 769.60888671875, (509.05554, 0.15891916, 260.25223, 0.14223865)
decoder loss ratio: 19721.695456, decoder SINDy loss  ratio: 0.561791
--- 0.2982022762298584 seconds for one epoch ---
--- 1.3337831497192383 seconds for one epoch ---
--- 0.3077218532562256 seconds for one epoch ---
--- 1.330000638961792 seconds for one epoch ---
--- 0.31270694732666016 seconds for one epoch ---
--- 1.3322741985321045 seconds for one epoch ---
--- 0.3106112480163574 seconds for one epoch ---
--- 1.3428516387939453 seconds for one epoch ---
--- 0.310272216796875 seconds for one epoch ---
--- 1.3128798007965088 seconds for one epoch ---
--- 0.3140246868133545 seconds for one epoch ---
--- 1.328833818435669 seconds for one epoch ---
--- 0.3168983459472656 seconds for one epoch ---
--- 1.3489551544189453 seconds for one epoch ---
--- 0.3281874656677246 seconds for one epoch ---
--- 1.3098137378692627 seconds for one epoch ---
--- 0.3095223903656006 seconds for one epoch ---
--- 1.3347358703613281 seconds for one epoch ---
--- 0.29500532150268555 seconds for one epoch ---
--- 1.3501269817352295 seconds for one epoch ---
--- 0.30217647552490234 seconds for one epoch ---
--- 1.327477216720581 seconds for one epoch ---
--- 0.3007674217224121 seconds for one epoch ---
--- 1.3435251712799072 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12441245]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.179609]
 [ -0.      ]]
--- 0.29831814765930176 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2880.328369140625, (1456.0511, 1.522311, 1422.6124, 0.14243446)
   validation loss 711.6505126953125, (467.90933, 0.23325151, 243.36546, 0.14243446)
decoder loss ratio: 18127.619859, decoder SINDy loss  ratio: 0.525339
--- 0.2855086326599121 seconds for one epoch ---
--- 0.30226707458496094 seconds for one epoch ---
--- 1.3345532417297363 seconds for one epoch ---
--- 0.31287360191345215 seconds for one epoch ---
--- 1.322190284729004 seconds for one epoch ---
--- 0.302783727645874 seconds for one epoch ---
--- 1.3597252368927002 seconds for one epoch ---
--- 0.30231475830078125 seconds for one epoch ---
--- 1.36130952835083 seconds for one epoch ---
--- 0.5596046447753906 seconds for one epoch ---
--- 1.3360137939453125 seconds for one epoch ---
--- 0.30501365661621094 seconds for one epoch ---
--- 1.354637622833252 seconds for one epoch ---
--- 0.29562950134277344 seconds for one epoch ---
--- 1.3400428295135498 seconds for one epoch ---
--- 0.3103795051574707 seconds for one epoch ---
--- 1.3314015865325928 seconds for one epoch ---
--- 0.2947366237640381 seconds for one epoch ---
--- 1.3400852680206299 seconds for one epoch ---
--- 0.29636478424072266 seconds for one epoch ---
--- 1.3378453254699707 seconds for one epoch ---
--- 0.2985830307006836 seconds for one epoch ---
--- 1.343902349472046 seconds for one epoch ---
--- 0.30881261825561523 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12220761]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.270502]
 [  0.      ]]
--- 0.26484251022338867 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3999.0498046875, (2017.5306, 2.256932, 1979.1198, 0.1425967)
   validation loss 673.24853515625, (447.3913, 0.20491977, 225.50977, 0.1425967)
decoder loss ratio: 17332.715527, decoder SINDy loss  ratio: 0.486795
--- 0.3036534786224365 seconds for one epoch ---
--- 1.3638107776641846 seconds for one epoch ---
--- 0.31568431854248047 seconds for one epoch ---
--- 1.3639802932739258 seconds for one epoch ---
--- 0.30001091957092285 seconds for one epoch ---
--- 1.3399429321289062 seconds for one epoch ---
--- 0.32123565673828125 seconds for one epoch ---
--- 1.3674428462982178 seconds for one epoch ---
--- 0.30289220809936523 seconds for one epoch ---
--- 1.3610239028930664 seconds for one epoch ---
--- 0.3073396682739258 seconds for one epoch ---
--- 1.3675718307495117 seconds for one epoch ---
--- 0.2912015914916992 seconds for one epoch ---
--- 1.3713405132293701 seconds for one epoch ---
--- 0.3086972236633301 seconds for one epoch ---
--- 1.357428789138794 seconds for one epoch ---
--- 0.31163835525512695 seconds for one epoch ---
--- 1.3402953147888184 seconds for one epoch ---
--- 0.3030276298522949 seconds for one epoch ---
--- 1.3624329566955566 seconds for one epoch ---
--- 0.30614686012268066 seconds for one epoch ---
--- 1.3514821529388428 seconds for one epoch ---
--- 0.2986030578613281 seconds for one epoch ---
--- 1.3425450325012207 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12005243]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.359299]
 [ -0.      ]]
--- 0.3207981586456299 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5715.791015625, (2052.9314, 3.1938918, 3659.5234, 0.14274411)
   validation loss 666.8245849609375, (427.1842, 0.22824477, 239.2694, 0.14274411)
decoder loss ratio: 16549.857691, decoder SINDy loss  ratio: 0.516497
--- 0.29253244400024414 seconds for one epoch ---
--- 0.3170437812805176 seconds for one epoch ---
--- 1.367966651916504 seconds for one epoch ---
--- 0.30935049057006836 seconds for one epoch ---
--- 1.3812103271484375 seconds for one epoch ---
--- 0.3011152744293213 seconds for one epoch ---
--- 1.380680799484253 seconds for one epoch ---
--- 0.3021824359893799 seconds for one epoch ---
--- 1.3749973773956299 seconds for one epoch ---
--- 0.31795668601989746 seconds for one epoch ---
--- 1.36968994140625 seconds for one epoch ---
--- 0.26229190826416016 seconds for one epoch ---
--- 1.3713927268981934 seconds for one epoch ---
--- 0.291323184967041 seconds for one epoch ---
--- 1.3868036270141602 seconds for one epoch ---
--- 0.30489563941955566 seconds for one epoch ---
--- 1.366541862487793 seconds for one epoch ---
--- 0.3025786876678467 seconds for one epoch ---
--- 1.372211217880249 seconds for one epoch ---
--- 0.2892646789550781 seconds for one epoch ---
--- 1.3572793006896973 seconds for one epoch ---
--- 0.30029964447021484 seconds for one epoch ---
--- 1.3827486038208008 seconds for one epoch ---
--- 0.2957637310028076 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11802578]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.442802]
 [  0.      ]]
--- 0.25702834129333496 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2205.205810546875, (1046.1906, 5.185186, 1153.6871, 0.14289153)
   validation loss 1020.09326171875, (752.319, 0.22242492, 267.409, 0.14289153)
decoder loss ratio: 29146.142970, decoder SINDy loss  ratio: 0.577240
--- 0.29903292655944824 seconds for one epoch ---
--- 1.363013744354248 seconds for one epoch ---
--- 0.2994966506958008 seconds for one epoch ---
--- 1.3609504699707031 seconds for one epoch ---
--- 0.27691173553466797 seconds for one epoch ---
--- 1.3565242290496826 seconds for one epoch ---
--- 0.2843925952911377 seconds for one epoch ---
--- 1.3738884925842285 seconds for one epoch ---
--- 0.3041560649871826 seconds for one epoch ---
--- 1.3882067203521729 seconds for one epoch ---
--- 0.30059146881103516 seconds for one epoch ---
--- 1.3921949863433838 seconds for one epoch ---
--- 0.2964930534362793 seconds for one epoch ---
--- 1.3732144832611084 seconds for one epoch ---
--- 0.29808902740478516 seconds for one epoch ---
--- 1.3746702671051025 seconds for one epoch ---
--- 0.29463744163513184 seconds for one epoch ---
--- 1.4001314640045166 seconds for one epoch ---
--- 0.30905580520629883 seconds for one epoch ---
--- 1.3855726718902588 seconds for one epoch ---
--- 0.2988858222961426 seconds for one epoch ---
--- 1.392387866973877 seconds for one epoch ---
--- 0.2910575866699219 seconds for one epoch ---
--- 1.396347999572754 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11566179]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.540279]
 [ -0.      ]]
--- 0.3166499137878418 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2623.6865234375, (1259.7993, 2.3044555, 1361.4396, 0.1430393)
   validation loss 1245.6993408203125, (960.6366, 0.17047499, 284.74924, 0.1430393)
decoder loss ratio: 37216.729494, decoder SINDy loss  ratio: 0.614671
--- 0.2577190399169922 seconds for one epoch ---
--- 0.3310530185699463 seconds for one epoch ---
--- 1.3753576278686523 seconds for one epoch ---
--- 0.3191845417022705 seconds for one epoch ---
--- 1.3691291809082031 seconds for one epoch ---
--- 0.3294074535369873 seconds for one epoch ---
--- 1.3889567852020264 seconds for one epoch ---
--- 0.3313617706298828 seconds for one epoch ---
--- 1.3979685306549072 seconds for one epoch ---
--- 0.32518982887268066 seconds for one epoch ---
--- 1.4081141948699951 seconds for one epoch ---
--- 0.3305368423461914 seconds for one epoch ---
--- 1.3713123798370361 seconds for one epoch ---
--- 0.3278939723968506 seconds for one epoch ---
--- 1.3823537826538086 seconds for one epoch ---
--- 0.2872297763824463 seconds for one epoch ---
--- 1.4103398323059082 seconds for one epoch ---
--- 0.3056316375732422 seconds for one epoch ---
--- 1.4042956829071045 seconds for one epoch ---
--- 0.29060792922973633 seconds for one epoch ---
--- 1.4018754959106445 seconds for one epoch ---
--- 0.3009672164916992 seconds for one epoch ---
--- 1.3971748352050781 seconds for one epoch ---
--- 0.3053724765777588 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11379066]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.617504]
 [ -0.      ]]
--- 0.257159948348999 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2674.19775390625, (1016.6153, 2.779983, 1654.6595, 0.14316209)
   validation loss 698.6513061523438, (450.0127, 0.23034175, 248.26509, 0.14316209)
decoder loss ratio: 17434.273073, decoder SINDy loss  ratio: 0.535915
--- 0.2867434024810791 seconds for one epoch ---
--- 1.394385576248169 seconds for one epoch ---
--- 0.30341339111328125 seconds for one epoch ---
--- 1.4033889770507812 seconds for one epoch ---
--- 0.2788233757019043 seconds for one epoch ---
--- 1.398172378540039 seconds for one epoch ---
--- 0.309063196182251 seconds for one epoch ---
--- 1.407010793685913 seconds for one epoch ---
--- 0.298173189163208 seconds for one epoch ---
--- 1.4017727375030518 seconds for one epoch ---
--- 0.28435826301574707 seconds for one epoch ---
--- 1.421945571899414 seconds for one epoch ---
--- 0.3044753074645996 seconds for one epoch ---
--- 1.3978807926177979 seconds for one epoch ---
--- 0.3019065856933594 seconds for one epoch ---
--- 1.4246649742126465 seconds for one epoch ---
--- 0.30371880531311035 seconds for one epoch ---
--- 1.4092044830322266 seconds for one epoch ---
--- 0.2965269088745117 seconds for one epoch ---
--- 1.4177582263946533 seconds for one epoch ---
--- 0.30092382431030273 seconds for one epoch ---
--- 1.3989346027374268 seconds for one epoch ---
--- 0.3149704933166504 seconds for one epoch ---
--- 1.431321382522583 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11172641]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.702841]
 [  0.      ]]
--- 0.30055809020996094 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3097.926513671875, (1490.9957, 0.65331554, 1606.134, 0.1432981)
   validation loss 1007.874267578125, (760.41425, 0.32309183, 246.99362, 0.1432981)
decoder loss ratio: 29459.768012, decoder SINDy loss  ratio: 0.533170
--- 0.2638859748840332 seconds for one epoch ---
--- 0.3009157180786133 seconds for one epoch ---
--- 1.4160399436950684 seconds for one epoch ---
--- 0.30467700958251953 seconds for one epoch ---
--- 1.4024004936218262 seconds for one epoch ---
--- 0.30340147018432617 seconds for one epoch ---
--- 1.3763799667358398 seconds for one epoch ---
--- 0.30010271072387695 seconds for one epoch ---
--- 1.4092910289764404 seconds for one epoch ---
--- 0.2950108051300049 seconds for one epoch ---
--- 1.4336659908294678 seconds for one epoch ---
--- 0.29846978187561035 seconds for one epoch ---
--- 1.4157202243804932 seconds for one epoch ---
--- 0.28399181365966797 seconds for one epoch ---
--- 1.4156537055969238 seconds for one epoch ---
--- 0.2900238037109375 seconds for one epoch ---
--- 1.407820463180542 seconds for one epoch ---
--- 0.3019368648529053 seconds for one epoch ---
--- 1.4126369953155518 seconds for one epoch ---
--- 0.29918837547302246 seconds for one epoch ---
--- 1.4118096828460693 seconds for one epoch ---
--- 0.30271291732788086 seconds for one epoch ---
--- 1.4397122859954834 seconds for one epoch ---
--- 0.2931540012359619 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10954747]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.793117]
 [  0.      ]]
--- 0.26782989501953125 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2401.907470703125, (1368.6263, 3.134314, 1030.0034, 0.14343183)
   validation loss 660.0238037109375, (430.45795, 0.2828866, 229.13954, 0.14343183)
decoder loss ratio: 16676.688166, decoder SINDy loss  ratio: 0.494630
--- 0.31088948249816895 seconds for one epoch ---
--- 1.426511526107788 seconds for one epoch ---
--- 0.3173189163208008 seconds for one epoch ---
--- 1.4332211017608643 seconds for one epoch ---
--- 0.3186509609222412 seconds for one epoch ---
--- 1.4319274425506592 seconds for one epoch ---
--- 0.31902575492858887 seconds for one epoch ---
--- 1.429833173751831 seconds for one epoch ---
--- 0.3209347724914551 seconds for one epoch ---
--- 1.397852897644043 seconds for one epoch ---
--- 0.3249998092651367 seconds for one epoch ---
--- 1.4165797233581543 seconds for one epoch ---
--- 0.32707834243774414 seconds for one epoch ---
--- 1.4262595176696777 seconds for one epoch ---
--- 0.2946958541870117 seconds for one epoch ---
--- 1.432685375213623 seconds for one epoch ---
--- 0.2975633144378662 seconds for one epoch ---
--- 1.419771671295166 seconds for one epoch ---
--- 0.29904699325561523 seconds for one epoch ---
--- 1.4290733337402344 seconds for one epoch ---
--- 0.29903411865234375 seconds for one epoch ---
--- 1.4387965202331543 seconds for one epoch ---
--- 0.304823637008667 seconds for one epoch ---
--- 1.4341003894805908 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10784089]
 [0.        ]]
[[  0.   ]
 [ -0.   ]
 [  0.   ]
 [  0.   ]
 [ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [-15.864]
 [ -0.   ]]
--- 0.2968108654022217 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3717.8095703125, (1707.2351, 0.68834627, 2009.7427, 0.14353739)
   validation loss 730.7791137695312, (471.98135, 0.22605285, 258.42816, 0.14353739)
decoder loss ratio: 18285.377040, decoder SINDy loss  ratio: 0.557854
--- 0.25505852699279785 seconds for one epoch ---
--- 0.29428815841674805 seconds for one epoch ---
--- 1.4326608180999756 seconds for one epoch ---
--- 0.2895658016204834 seconds for one epoch ---
--- 1.4172847270965576 seconds for one epoch ---
--- 0.28473401069641113 seconds for one epoch ---
--- 1.4090166091918945 seconds for one epoch ---
--- 0.30393028259277344 seconds for one epoch ---
--- 1.4216763973236084 seconds for one epoch ---
--- 0.3002793788909912 seconds for one epoch ---
--- 1.4150989055633545 seconds for one epoch ---
--- 0.2946741580963135 seconds for one epoch ---
--- 1.4339241981506348 seconds for one epoch ---
--- 0.2898590564727783 seconds for one epoch ---
--- 1.4113357067108154 seconds for one epoch ---
--- 0.30074596405029297 seconds for one epoch ---
--- 1.4397242069244385 seconds for one epoch ---
--- 0.2971165180206299 seconds for one epoch ---
--- 1.4411015510559082 seconds for one epoch ---
--- 0.29811573028564453 seconds for one epoch ---
--- 1.4342217445373535 seconds for one epoch ---
--- 0.29349303245544434 seconds for one epoch ---
--- 1.4082658290863037 seconds for one epoch ---
--- 0.2828538417816162 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10621145]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.931841]
 [ -0.      ]]
--- 0.25379300117492676 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2707.620361328125, (1275.4924, 3.9568748, 1428.0275, 0.14363056)
   validation loss 705.338134765625, (482.27103, 0.21623732, 222.70724, 0.14363056)
decoder loss ratio: 18684.016830, decoder SINDy loss  ratio: 0.480745
--- 0.31183481216430664 seconds for one epoch ---
--- 1.4169566631317139 seconds for one epoch ---
--- 0.31209826469421387 seconds for one epoch ---
--- 1.4359538555145264 seconds for one epoch ---
--- 0.3294491767883301 seconds for one epoch ---
--- 1.4605941772460938 seconds for one epoch ---
--- 0.31348252296447754 seconds for one epoch ---
--- 1.4530739784240723 seconds for one epoch ---
--- 0.3245711326599121 seconds for one epoch ---
--- 1.4581873416900635 seconds for one epoch ---
--- 0.3289146423339844 seconds for one epoch ---
--- 1.4145429134368896 seconds for one epoch ---
--- 0.28725314140319824 seconds for one epoch ---
--- 1.429711103439331 seconds for one epoch ---
--- 0.299727201461792 seconds for one epoch ---
--- 1.4072644710540771 seconds for one epoch ---
--- 0.3006770610809326 seconds for one epoch ---
--- 1.4225380420684814 seconds for one epoch ---
--- 0.2990870475769043 seconds for one epoch ---
--- 1.451080560684204 seconds for one epoch ---
--- 0.2897005081176758 seconds for one epoch ---
--- 1.47092866897583 seconds for one epoch ---
--- 0.3042609691619873 seconds for one epoch ---
--- 1.3925354480743408 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10449517]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.003496]
 [  0.      ]]
--- 0.29210615158081055 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3111.1875, (1540.6697, 1.3270352, 1569.047, 0.1437282)
   validation loss 1091.0018310546875, (865.6815, 0.24090914, 224.93575, 0.1437282)
decoder loss ratio: 33538.004918, decoder SINDy loss  ratio: 0.485555
THRESHOLDING: 1 active coefficients
--- 1.4315237998962402 seconds for one epoch ---
--- 0.29874515533447266 seconds for one epoch ---
--- 1.4464552402496338 seconds for one epoch ---
--- 0.3093392848968506 seconds for one epoch ---
--- 1.4806239604949951 seconds for one epoch ---
--- 0.2720682621002197 seconds for one epoch ---
--- 1.4229373931884766 seconds for one epoch ---
--- 0.2947847843170166 seconds for one epoch ---
--- 1.434786081314087 seconds for one epoch ---
--- 0.2997744083404541 seconds for one epoch ---
--- 1.4215025901794434 seconds for one epoch ---
--- 0.29728102684020996 seconds for one epoch ---
--- 1.4413526058197021 seconds for one epoch ---
--- 0.27597975730895996 seconds for one epoch ---
--- 1.4464631080627441 seconds for one epoch ---
--- 0.29491257667541504 seconds for one epoch ---
--- 1.4249451160430908 seconds for one epoch ---
--- 0.2961850166320801 seconds for one epoch ---
--- 1.4403250217437744 seconds for one epoch ---
--- 0.3006300926208496 seconds for one epoch ---
--- 1.4277241230010986 seconds for one epoch ---
--- 0.30042052268981934 seconds for one epoch ---
--- 1.4555883407592773 seconds for one epoch ---
--- 0.29456472396850586 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10263656]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.081375]
 [ -0.      ]]
--- 0.2579195499420166 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2869.826416015625, (1227.7892, 1.0085988, 1640.885, 0.14384249)
   validation loss 616.084716796875, (397.04895, 0.22820397, 218.66371, 0.14384249)
decoder loss ratio: 15382.365638, decoder SINDy loss  ratio: 0.472016
--- 0.2935471534729004 seconds for one epoch ---
--- 1.4028279781341553 seconds for one epoch ---
--- 0.2988932132720947 seconds for one epoch ---
--- 1.4089796543121338 seconds for one epoch ---
--- 0.2810213565826416 seconds for one epoch ---
--- 1.4079058170318604 seconds for one epoch ---
--- 0.29396867752075195 seconds for one epoch ---
--- 1.4881958961486816 seconds for one epoch ---
--- 0.30053210258483887 seconds for one epoch ---
--- 1.4663360118865967 seconds for one epoch ---
--- 0.2975788116455078 seconds for one epoch ---
--- 1.423802137374878 seconds for one epoch ---
--- 0.2985069751739502 seconds for one epoch ---
--- 1.43831467628479 seconds for one epoch ---
--- 0.27806663513183594 seconds for one epoch ---
--- 1.461801290512085 seconds for one epoch ---
--- 0.29833459854125977 seconds for one epoch ---
--- 1.4673376083374023 seconds for one epoch ---
--- 0.2931795120239258 seconds for one epoch ---
--- 1.470665693283081 seconds for one epoch ---
--- 0.2997472286224365 seconds for one epoch ---
--- 1.4773459434509277 seconds for one epoch ---
--- 0.3003416061401367 seconds for one epoch ---
--- 1.4629967212677002 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10074806]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.16082]
 [  0.     ]]
--- 0.2968926429748535 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2866.21533203125, (1556.8525, 1.4182659, 1307.8004, 0.14394723)
   validation loss 763.1339721679688, (530.2003, 0.25033665, 232.53938, 0.14394723)
decoder loss ratio: 20540.880764, decoder SINDy loss  ratio: 0.501969
--- 0.26775312423706055 seconds for one epoch ---
--- 0.3108036518096924 seconds for one epoch ---
--- 1.4777991771697998 seconds for one epoch ---
--- 0.2878885269165039 seconds for one epoch ---
--- 1.4761850833892822 seconds for one epoch ---
--- 0.2977416515350342 seconds for one epoch ---
--- 1.4719579219818115 seconds for one epoch ---
--- 0.30397677421569824 seconds for one epoch ---
--- 1.4874553680419922 seconds for one epoch ---
--- 0.29444289207458496 seconds for one epoch ---
--- 1.478381633758545 seconds for one epoch ---
--- 0.26553940773010254 seconds for one epoch ---
--- 1.4599487781524658 seconds for one epoch ---
--- 0.30171680450439453 seconds for one epoch ---
--- 1.4641902446746826 seconds for one epoch ---
--- 0.28916120529174805 seconds for one epoch ---
--- 1.4774198532104492 seconds for one epoch ---
--- 0.2978384494781494 seconds for one epoch ---
--- 1.4774508476257324 seconds for one epoch ---
--- 0.29436397552490234 seconds for one epoch ---
--- 1.4683763980865479 seconds for one epoch ---
--- 0.3112778663635254 seconds for one epoch ---
--- 1.4692974090576172 seconds for one epoch ---
--- 0.3122527599334717 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09931266]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.221432]
 [  0.      ]]
--- 0.2624855041503906 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3218.4814453125, (1335.1262, 1.7112876, 1881.5, 0.14403735)
   validation loss 1238.592041015625, (995.9246, 0.27687144, 242.2465, 0.14403735)
decoder loss ratio: 38583.848841, decoder SINDy loss  ratio: 0.522923
--- 0.3082442283630371 seconds for one epoch ---
--- 1.4829001426696777 seconds for one epoch ---
--- 0.3101234436035156 seconds for one epoch ---
--- 1.4523956775665283 seconds for one epoch ---
--- 0.274249792098999 seconds for one epoch ---
--- 1.5006043910980225 seconds for one epoch ---
--- 0.30266404151916504 seconds for one epoch ---
--- 1.4961888790130615 seconds for one epoch ---
--- 0.29506349563598633 seconds for one epoch ---
--- 1.5119571685791016 seconds for one epoch ---
--- 0.2922534942626953 seconds for one epoch ---
--- 1.5146949291229248 seconds for one epoch ---
--- 0.2974061965942383 seconds for one epoch ---
--- 1.4869647026062012 seconds for one epoch ---
--- 0.302570104598999 seconds for one epoch ---
--- 1.4977459907531738 seconds for one epoch ---
--- 0.30156707763671875 seconds for one epoch ---
--- 1.4865162372589111 seconds for one epoch ---
--- 0.29625868797302246 seconds for one epoch ---
--- 1.4965229034423828 seconds for one epoch ---
--- 0.3075723648071289 seconds for one epoch ---
--- 1.5180106163024902 seconds for one epoch ---
--- 0.29248046875 seconds for one epoch ---
--- 1.4793365001678467 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09776612]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.287003]
 [ -0.      ]]
--- 0.29930949211120605 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2937.0986328125, (1016.3175, 1.2384028, 1919.3988, 0.14412443)
   validation loss 602.458984375, (383.76532, 0.21174997, 218.3378, 0.14412443)
decoder loss ratio: 14867.734736, decoder SINDy loss  ratio: 0.471313
--- 0.2606339454650879 seconds for one epoch ---
--- 0.2978091239929199 seconds for one epoch ---
--- 1.480396032333374 seconds for one epoch ---
--- 0.28522205352783203 seconds for one epoch ---
--- 1.49876070022583 seconds for one epoch ---
--- 0.28760719299316406 seconds for one epoch ---
--- 1.4789378643035889 seconds for one epoch ---
--- 0.29398393630981445 seconds for one epoch ---
--- 1.500523328781128 seconds for one epoch ---
--- 0.30112624168395996 seconds for one epoch ---
--- 1.491471290588379 seconds for one epoch ---
--- 0.3033573627471924 seconds for one epoch ---
--- 1.5235064029693604 seconds for one epoch ---
--- 0.30025362968444824 seconds for one epoch ---
--- 1.508763313293457 seconds for one epoch ---
--- 0.30049657821655273 seconds for one epoch ---
--- 1.5067408084869385 seconds for one epoch ---
--- 0.3013291358947754 seconds for one epoch ---
--- 1.506425380706787 seconds for one epoch ---
--- 0.29524946212768555 seconds for one epoch ---
--- 1.5098183155059814 seconds for one epoch ---
--- 0.29958581924438477 seconds for one epoch ---
--- 1.4856805801391602 seconds for one epoch ---
--- 0.2942686080932617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09636538]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.346619]
 [  0.      ]]
--- 0.2801539897918701 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2264.565185546875, (1027.0123, 0.32745433, 1237.0809, 0.14420688)
   validation loss 1118.8167724609375, (851.74756, 0.22105584, 266.70395, 0.14420688)
decoder loss ratio: 32998.179119, decoder SINDy loss  ratio: 0.575718
--- 0.31205272674560547 seconds for one epoch ---
--- 1.5467183589935303 seconds for one epoch ---
--- 0.31597352027893066 seconds for one epoch ---
--- 1.5339572429656982 seconds for one epoch ---
--- 0.3091847896575928 seconds for one epoch ---
--- 1.5478332042694092 seconds for one epoch ---
--- 0.2979705333709717 seconds for one epoch ---
--- 1.5148439407348633 seconds for one epoch ---
--- 0.29729366302490234 seconds for one epoch ---
--- 1.5136210918426514 seconds for one epoch ---
--- 0.31217384338378906 seconds for one epoch ---
--- 1.5088355541229248 seconds for one epoch ---
--- 0.3042893409729004 seconds for one epoch ---
--- 1.5047731399536133 seconds for one epoch ---
--- 0.2836034297943115 seconds for one epoch ---
--- 1.4845690727233887 seconds for one epoch ---
--- 0.2979257106781006 seconds for one epoch ---
--- 1.5237152576446533 seconds for one epoch ---
--- 0.2989957332611084 seconds for one epoch ---
--- 1.5170795917510986 seconds for one epoch ---
--- 0.2903175354003906 seconds for one epoch ---
--- 1.516953706741333 seconds for one epoch ---
--- 0.2909111976623535 seconds for one epoch ---
--- 1.4984169006347656 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09468545]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.418453]
 [ -0.      ]]
--- 0.3174736499786377 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2544.91064453125, (1210.4207, 1.1104016, 1333.2354, 0.14430098)
   validation loss 728.1209716796875, (498.05804, 0.23076987, 229.68788, 0.14430098)
decoder loss ratio: 19295.633308, decoder SINDy loss  ratio: 0.495814
--- 0.27965712547302246 seconds for one epoch ---
--- 0.3214566707611084 seconds for one epoch ---
--- 1.549159049987793 seconds for one epoch ---
--- 0.31720900535583496 seconds for one epoch ---
--- 1.5267996788024902 seconds for one epoch ---
--- 0.332669734954834 seconds for one epoch ---
--- 1.5621435642242432 seconds for one epoch ---
--- 0.3439154624938965 seconds for one epoch ---
--- 1.5559449195861816 seconds for one epoch ---
--- 0.33911657333374023 seconds for one epoch ---
--- 1.508237361907959 seconds for one epoch ---
--- 0.3018453121185303 seconds for one epoch ---
--- 1.5312938690185547 seconds for one epoch ---
--- 0.2980339527130127 seconds for one epoch ---
--- 1.4928932189941406 seconds for one epoch ---
--- 0.28749728202819824 seconds for one epoch ---
--- 1.500328540802002 seconds for one epoch ---
--- 0.2959575653076172 seconds for one epoch ---
--- 1.5157020092010498 seconds for one epoch ---
--- 0.3043403625488281 seconds for one epoch ---
--- 1.5241484642028809 seconds for one epoch ---
--- 0.30311131477355957 seconds for one epoch ---
--- 1.4732325077056885 seconds for one epoch ---
--- 0.29416394233703613 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09335787]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.475483]
 [  0.      ]]
--- 0.25801563262939453 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2065.366455078125, (941.935, 2.0382884, 1121.2489, 0.14437553)
   validation loss 692.0576782226562, (473.74295, 0.2668938, 217.9035, 0.14437553)
decoder loss ratio: 18353.624354, decoder SINDy loss  ratio: 0.470375
--- 0.28879404067993164 seconds for one epoch ---
--- 1.525545597076416 seconds for one epoch ---
--- 0.30370068550109863 seconds for one epoch ---
--- 1.5377871990203857 seconds for one epoch ---
--- 0.2940340042114258 seconds for one epoch ---
--- 1.5438790321350098 seconds for one epoch ---
--- 0.30034804344177246 seconds for one epoch ---
--- 1.5069382190704346 seconds for one epoch ---
--- 0.29902195930480957 seconds for one epoch ---
--- 1.5394446849822998 seconds for one epoch ---
--- 0.30073070526123047 seconds for one epoch ---
--- 1.5418267250061035 seconds for one epoch ---
--- 0.30040407180786133 seconds for one epoch ---
--- 1.5255873203277588 seconds for one epoch ---
--- 0.30542683601379395 seconds for one epoch ---
--- 1.5299835205078125 seconds for one epoch ---
--- 0.30971837043762207 seconds for one epoch ---
--- 1.5112941265106201 seconds for one epoch ---
--- 0.30915069580078125 seconds for one epoch ---
--- 1.5260276794433594 seconds for one epoch ---
--- 0.2930624485015869 seconds for one epoch ---
--- 1.5406298637390137 seconds for one epoch ---
--- 0.3053476810455322 seconds for one epoch ---
--- 1.529517650604248 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09207286]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.53093]
 [ -0.     ]]
--- 0.291980504989624 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3368.48583984375, (1843.2643, 1.2162547, 1523.8607, 0.14444855)
   validation loss 632.3510131835938, (391.70038, 0.26957533, 240.23662, 0.14444855)
decoder loss ratio: 15175.152682, decoder SINDy loss  ratio: 0.518585
--- 0.2631087303161621 seconds for one epoch ---
--- 0.3102560043334961 seconds for one epoch ---
--- 1.528921127319336 seconds for one epoch ---
--- 0.30123066902160645 seconds for one epoch ---
--- 1.545583724975586 seconds for one epoch ---
--- 0.29862499237060547 seconds for one epoch ---
--- 1.525801420211792 seconds for one epoch ---
--- 0.29670071601867676 seconds for one epoch ---
--- 1.50026535987854 seconds for one epoch ---
--- 0.28226208686828613 seconds for one epoch ---
--- 1.5326476097106934 seconds for one epoch ---
--- 0.2709059715270996 seconds for one epoch ---
--- 1.5485780239105225 seconds for one epoch ---
--- 0.2836191654205322 seconds for one epoch ---
--- 1.5521411895751953 seconds for one epoch ---
--- 0.29609012603759766 seconds for one epoch ---
--- 1.5579240322113037 seconds for one epoch ---
--- 0.30464982986450195 seconds for one epoch ---
--- 1.5374419689178467 seconds for one epoch ---
--- 0.28455233573913574 seconds for one epoch ---
--- 1.5517876148223877 seconds for one epoch ---
--- 0.2993168830871582 seconds for one epoch ---
--- 1.5576047897338867 seconds for one epoch ---
--- 0.2987089157104492 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09078716]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.586664]
 [ -0.      ]]
--- 0.26100587844848633 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2045.421630859375, (635.83124, 0.6131053, 1408.8328, 0.14452103)
   validation loss 720.402099609375, (488.58636, 0.2726314, 231.39859, 0.14452103)
decoder loss ratio: 18928.683993, decoder SINDy loss  ratio: 0.499506
--- 0.3290750980377197 seconds for one epoch ---
--- 1.572700023651123 seconds for one epoch ---
--- 0.3272130489349365 seconds for one epoch ---
--- 1.536895513534546 seconds for one epoch ---
--- 0.3265247344970703 seconds for one epoch ---
--- 1.554253101348877 seconds for one epoch ---
--- 0.33518028259277344 seconds for one epoch ---
--- 1.5684452056884766 seconds for one epoch ---
--- 0.31573057174682617 seconds for one epoch ---
--- 1.5774996280670166 seconds for one epoch ---
--- 0.34414076805114746 seconds for one epoch ---
--- 1.571866750717163 seconds for one epoch ---
--- 0.31240177154541016 seconds for one epoch ---
--- 1.5531542301177979 seconds for one epoch ---
--- 0.29673099517822266 seconds for one epoch ---
--- 1.5522751808166504 seconds for one epoch ---
--- 0.2884666919708252 seconds for one epoch ---
--- 1.5704975128173828 seconds for one epoch ---
--- 0.30369043350219727 seconds for one epoch ---
--- 1.5764110088348389 seconds for one epoch ---
--- 0.28569722175598145 seconds for one epoch ---
--- 1.5842549800872803 seconds for one epoch ---
--- 0.29546666145324707 seconds for one epoch ---
--- 1.5469694137573242 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08955339]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.640387]
 [  0.      ]]
--- 0.2906198501586914 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2611.071533203125, (1089.0397, 0.7196974, 1521.1676, 0.14459579)
   validation loss 898.2120361328125, (646.74335, 0.32276773, 251.00133, 0.14459579)
decoder loss ratio: 25055.960065, decoder SINDy loss  ratio: 0.541822
--- 0.26265597343444824 seconds for one epoch ---
--- 0.29860711097717285 seconds for one epoch ---
--- 1.5954604148864746 seconds for one epoch ---
--- 0.3032395839691162 seconds for one epoch ---
--- 1.5744960308074951 seconds for one epoch ---
--- 0.29067492485046387 seconds for one epoch ---
--- 1.5569522380828857 seconds for one epoch ---
--- 0.2876620292663574 seconds for one epoch ---
--- 1.6168954372406006 seconds for one epoch ---
--- 0.30362701416015625 seconds for one epoch ---
--- 1.5629589557647705 seconds for one epoch ---
--- 0.29960155487060547 seconds for one epoch ---
--- 1.5638887882232666 seconds for one epoch ---
--- 0.30023717880249023 seconds for one epoch ---
--- 1.5743918418884277 seconds for one epoch ---
--- 0.2980775833129883 seconds for one epoch ---
--- 1.5691263675689697 seconds for one epoch ---
--- 0.30173444747924805 seconds for one epoch ---
--- 1.58766770362854 seconds for one epoch ---
--- 0.3037285804748535 seconds for one epoch ---
--- 1.5675420761108398 seconds for one epoch ---
--- 0.28916001319885254 seconds for one epoch ---
--- 1.5398213863372803 seconds for one epoch ---
--- 0.30458593368530273 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08804943]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.706217]
 [  0.      ]]
--- 0.2580230236053467 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4506.541015625, (1234.344, 1.4837996, 3270.5686, 0.14467643)
   validation loss 704.5950317382812, (468.86618, 0.27071267, 235.31348, 0.14467643)
decoder loss ratio: 18164.689817, decoder SINDy loss  ratio: 0.507957
--- 0.3211851119995117 seconds for one epoch ---
--- 1.5919694900512695 seconds for one epoch ---
--- 0.32930994033813477 seconds for one epoch ---
--- 1.579357624053955 seconds for one epoch ---
--- 0.3124659061431885 seconds for one epoch ---
--- 1.5991413593292236 seconds for one epoch ---
--- 0.34543347358703613 seconds for one epoch ---
--- 1.5880837440490723 seconds for one epoch ---
--- 0.3250393867492676 seconds for one epoch ---
--- 1.5687813758850098 seconds for one epoch ---
--- 0.31241321563720703 seconds for one epoch ---
--- 1.5757255554199219 seconds for one epoch ---
--- 0.3030586242675781 seconds for one epoch ---
--- 1.5901048183441162 seconds for one epoch ---
--- 0.3058955669403076 seconds for one epoch ---
--- 1.585430383682251 seconds for one epoch ---
--- 0.29168128967285156 seconds for one epoch ---
--- 1.5861055850982666 seconds for one epoch ---
--- 0.30095672607421875 seconds for one epoch ---
--- 1.577981948852539 seconds for one epoch ---
--- 0.29259419441223145 seconds for one epoch ---
--- 1.548095703125 seconds for one epoch ---
--- 0.29369521141052246 seconds for one epoch ---
--- 1.556607723236084 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08666427]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.767216]
 [ -0.      ]]
--- 0.29860353469848633 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2861.852294921875, (943.8578, 1.2101047, 1916.6396, 0.14476043)
   validation loss 1072.86767578125, (803.9105, 0.24710083, 268.56528, 0.14476043)
decoder loss ratio: 31144.889290, decoder SINDy loss  ratio: 0.579736
--- 0.2630019187927246 seconds for one epoch ---
--- 0.2991631031036377 seconds for one epoch ---
--- 1.56634521484375 seconds for one epoch ---
--- 0.29097533226013184 seconds for one epoch ---
--- 1.587669849395752 seconds for one epoch ---
--- 0.2989814281463623 seconds for one epoch ---
--- 1.5540533065795898 seconds for one epoch ---
--- 0.3048884868621826 seconds for one epoch ---
--- 1.59708571434021 seconds for one epoch ---
--- 0.2997629642486572 seconds for one epoch ---
--- 1.586172103881836 seconds for one epoch ---
--- 0.29817771911621094 seconds for one epoch ---
--- 1.5888257026672363 seconds for one epoch ---
--- 0.3015010356903076 seconds for one epoch ---
--- 1.5788426399230957 seconds for one epoch ---
--- 0.2981750965118408 seconds for one epoch ---
--- 1.5768003463745117 seconds for one epoch ---
--- 0.29969167709350586 seconds for one epoch ---
--- 1.6035845279693604 seconds for one epoch ---
--- 0.30266261100769043 seconds for one epoch ---
--- 1.5632929801940918 seconds for one epoch ---
--- 0.28728771209716797 seconds for one epoch ---
--- 1.5395479202270508 seconds for one epoch ---
--- 0.282071590423584 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08579922]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.805489]
 [ -0.      ]]
--- 0.2601771354675293 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2231.998046875, (998.5691, 0.40010175, 1232.884, 0.14480919)
   validation loss 1004.0734252929688, (723.2883, 0.33633712, 280.3039, 0.14480919)
decoder loss ratio: 28021.445591, decoder SINDy loss  ratio: 0.605075
--- 0.2987504005432129 seconds for one epoch ---
--- 1.574995994567871 seconds for one epoch ---
--- 0.2803537845611572 seconds for one epoch ---
--- 1.5861647129058838 seconds for one epoch ---
--- 0.3082907199859619 seconds for one epoch ---
--- 1.5762355327606201 seconds for one epoch ---
--- 0.2971913814544678 seconds for one epoch ---
--- 1.6091079711914062 seconds for one epoch ---
--- 0.2946438789367676 seconds for one epoch ---
--- 1.6184468269348145 seconds for one epoch ---
--- 0.2883265018463135 seconds for one epoch ---
--- 1.6333086490631104 seconds for one epoch ---
--- 0.3004188537597656 seconds for one epoch ---
--- 1.6199898719787598 seconds for one epoch ---
--- 0.3033280372619629 seconds for one epoch ---
--- 1.6001932621002197 seconds for one epoch ---
--- 0.29314637184143066 seconds for one epoch ---
--- 1.5915210247039795 seconds for one epoch ---
--- 0.29346609115600586 seconds for one epoch ---
--- 1.6348142623901367 seconds for one epoch ---
--- 0.28946638107299805 seconds for one epoch ---
--- 1.5923824310302734 seconds for one epoch ---
--- 0.29530954360961914 seconds for one epoch ---
--- 1.568368911743164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08485597]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.847385]
 [  0.      ]]
--- 0.32500243186950684 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2571.485107421875, (996.65564, 0.5858278, 1574.0989, 0.14486627)
   validation loss 850.634033203125, (608.17346, 0.3053739, 242.01036, 0.14486627)
decoder loss ratio: 23561.695750, decoder SINDy loss  ratio: 0.522413
--- 0.26783061027526855 seconds for one epoch ---
--- 0.33702731132507324 seconds for one epoch ---
--- 1.6477298736572266 seconds for one epoch ---
--- 0.3381049633026123 seconds for one epoch ---
--- 1.643895149230957 seconds for one epoch ---
--- 0.33463096618652344 seconds for one epoch ---
--- 1.6485271453857422 seconds for one epoch ---
--- 0.33689284324645996 seconds for one epoch ---
--- 1.6268248558044434 seconds for one epoch ---
--- 0.3058922290802002 seconds for one epoch ---
--- 1.634235143661499 seconds for one epoch ---
--- 0.2993607521057129 seconds for one epoch ---
--- 1.6113972663879395 seconds for one epoch ---
--- 0.29297780990600586 seconds for one epoch ---
--- 1.636084794998169 seconds for one epoch ---
--- 0.3026454448699951 seconds for one epoch ---
--- 1.62105131149292 seconds for one epoch ---
--- 0.3005714416503906 seconds for one epoch ---
--- 1.6561548709869385 seconds for one epoch ---
--- 0.2950718402862549 seconds for one epoch ---
--- 1.5880227088928223 seconds for one epoch ---
--- 0.29428887367248535 seconds for one epoch ---
--- 1.597881555557251 seconds for one epoch ---
--- 0.29532551765441895 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08378914]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.894993]
 [ -0.      ]]
--- 0.2916100025177002 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2082.341796875, (1130.4734, 0.62043667, 951.103, 0.14492516)
   validation loss 835.66943359375, (566.25244, 0.439291, 268.83282, 0.14492516)
decoder loss ratio: 21937.602638, decoder SINDy loss  ratio: 0.580313
--- 0.2975950241088867 seconds for one epoch ---
--- 1.6386375427246094 seconds for one epoch ---
--- 0.29749488830566406 seconds for one epoch ---
--- 1.6546132564544678 seconds for one epoch ---
--- 0.29557108879089355 seconds for one epoch ---
--- 1.6178431510925293 seconds for one epoch ---
--- 0.29531121253967285 seconds for one epoch ---
--- 1.6171672344207764 seconds for one epoch ---
--- 0.29672694206237793 seconds for one epoch ---
--- 1.613417625427246 seconds for one epoch ---
--- 0.2985978126525879 seconds for one epoch ---
--- 1.6195287704467773 seconds for one epoch ---
--- 0.2969059944152832 seconds for one epoch ---
--- 1.6464457511901855 seconds for one epoch ---
--- 0.2897026538848877 seconds for one epoch ---
--- 1.637843370437622 seconds for one epoch ---
--- 0.2976241111755371 seconds for one epoch ---
--- 1.6275148391723633 seconds for one epoch ---
--- 0.29595088958740234 seconds for one epoch ---
--- 1.6615605354309082 seconds for one epoch ---
--- 0.29631757736206055 seconds for one epoch ---
--- 1.5736310482025146 seconds for one epoch ---
--- 0.30687594413757324 seconds for one epoch ---
--- 1.582728624343872 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08280077]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.93932]
 [  0.     ]]
--- 0.3091135025024414 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3087.69921875, (1427.56, 0.9203094, 1659.0739, 0.14498827)
   validation loss 771.8993530273438, (521.2171, 0.3190043, 250.21829, 0.14498827)
decoder loss ratio: 20192.855406, decoder SINDy loss  ratio: 0.540131
--- 0.27149438858032227 seconds for one epoch ---
--- 0.3004581928253174 seconds for one epoch ---
--- 1.6457288265228271 seconds for one epoch ---
--- 0.29401254653930664 seconds for one epoch ---
--- 1.6291477680206299 seconds for one epoch ---
--- 0.316556453704834 seconds for one epoch ---
--- 1.6215460300445557 seconds for one epoch ---
--- 0.3314208984375 seconds for one epoch ---
--- 1.6416871547698975 seconds for one epoch ---
--- 0.30725622177124023 seconds for one epoch ---
--- 1.6595003604888916 seconds for one epoch ---
--- 0.2962052822113037 seconds for one epoch ---
--- 1.6346888542175293 seconds for one epoch ---
--- 0.2986621856689453 seconds for one epoch ---
--- 1.6427664756774902 seconds for one epoch ---
--- 0.29642772674560547 seconds for one epoch ---
--- 1.63299560546875 seconds for one epoch ---
--- 0.3133509159088135 seconds for one epoch ---
--- 1.6672101020812988 seconds for one epoch ---
--- 0.2952454090118408 seconds for one epoch ---
--- 1.5993568897247314 seconds for one epoch ---
--- 0.2918508052825928 seconds for one epoch ---
--- 1.603484869003296 seconds for one epoch ---
--- 0.30052995681762695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08173073]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.987535]
 [  0.      ]]
--- 0.2640371322631836 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3229.0986328125, (1563.4784, 1.1486702, 1664.3264, 0.1450513)
   validation loss 1536.8275146484375, (1249.039, 0.35731766, 287.28625, 0.1450513)
decoder loss ratio: 48389.936979, decoder SINDy loss  ratio: 0.620148
--- 0.3088417053222656 seconds for one epoch ---
--- 1.673478364944458 seconds for one epoch ---
--- 0.3136169910430908 seconds for one epoch ---
--- 1.635528802871704 seconds for one epoch ---
--- 0.3245103359222412 seconds for one epoch ---
--- 1.6431396007537842 seconds for one epoch ---
--- 0.3135097026824951 seconds for one epoch ---
--- 1.6441011428833008 seconds for one epoch ---
--- 0.30831480026245117 seconds for one epoch ---
--- 1.6606225967407227 seconds for one epoch ---
--- 0.29886555671691895 seconds for one epoch ---
--- 1.6557481288909912 seconds for one epoch ---
--- 0.29463911056518555 seconds for one epoch ---
--- 1.6406562328338623 seconds for one epoch ---
--- 0.3020956516265869 seconds for one epoch ---
--- 1.6486444473266602 seconds for one epoch ---
--- 0.2987537384033203 seconds for one epoch ---
--- 1.6606426239013672 seconds for one epoch ---
--- 0.6043884754180908 seconds for one epoch ---
--- 1.6873180866241455 seconds for one epoch ---
--- 0.29988765716552734 seconds for one epoch ---
--- 1.6116032600402832 seconds for one epoch ---
--- 0.29273486137390137 seconds for one epoch ---
--- 1.6252145767211914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08074793]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.032051]
 [ -0.      ]]
--- 0.28729701042175293 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2818.49560546875, (1160.93, 1.2012405, 1656.2191, 0.14511178)
   validation loss 759.4573974609375, (520.3634, 0.34178692, 238.60703, 0.14511178)
decoder loss ratio: 20159.781635, decoder SINDy loss  ratio: 0.515067
--- 0.24691343307495117 seconds for one epoch ---
--- 0.28647351264953613 seconds for one epoch ---
--- 1.6669223308563232 seconds for one epoch ---
--- 0.29581737518310547 seconds for one epoch ---
--- 1.6962518692016602 seconds for one epoch ---
--- 0.2856776714324951 seconds for one epoch ---
--- 1.6771843433380127 seconds for one epoch ---
--- 0.2886960506439209 seconds for one epoch ---
--- 1.6824324131011963 seconds for one epoch ---
--- 0.2962493896484375 seconds for one epoch ---
--- 1.6865818500518799 seconds for one epoch ---
--- 0.3002195358276367 seconds for one epoch ---
--- 1.6624503135681152 seconds for one epoch ---
--- 0.2783021926879883 seconds for one epoch ---
--- 1.6908836364746094 seconds for one epoch ---
--- 0.2930335998535156 seconds for one epoch ---
--- 1.6625027656555176 seconds for one epoch ---
--- 0.29352736473083496 seconds for one epoch ---
--- 1.7022929191589355 seconds for one epoch ---
--- 0.3008708953857422 seconds for one epoch ---
--- 1.673835039138794 seconds for one epoch ---
--- 0.29964685440063477 seconds for one epoch ---
--- 1.6513285636901855 seconds for one epoch ---
--- 0.29907941818237305 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07971481]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.079092]
 [  0.      ]]
--- 0.25970911979675293 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2233.38623046875, (1062.3494, 1.342799, 1169.5488, 0.14517526)
   validation loss 716.8952026367188, (494.48752, 0.367904, 221.89459, 0.14517526)
decoder loss ratio: 19157.304927, decoder SINDy loss  ratio: 0.478991
--- 0.28018665313720703 seconds for one epoch ---
--- 1.6935465335845947 seconds for one epoch ---
--- 0.3062911033630371 seconds for one epoch ---
--- 1.6956052780151367 seconds for one epoch ---
--- 0.29358792304992676 seconds for one epoch ---
--- 1.6805415153503418 seconds for one epoch ---
--- 0.29403257369995117 seconds for one epoch ---
--- 1.6705830097198486 seconds for one epoch ---
--- 0.2984027862548828 seconds for one epoch ---
--- 1.6858513355255127 seconds for one epoch ---
--- 0.29663681983947754 seconds for one epoch ---
--- 1.6953177452087402 seconds for one epoch ---
--- 0.2936878204345703 seconds for one epoch ---
--- 1.6793429851531982 seconds for one epoch ---
--- 0.29033541679382324 seconds for one epoch ---
--- 1.701568365097046 seconds for one epoch ---
--- 0.29729175567626953 seconds for one epoch ---
--- 1.6825692653656006 seconds for one epoch ---
--- 0.3106200695037842 seconds for one epoch ---
--- 1.7207252979278564 seconds for one epoch ---
--- 0.2908451557159424 seconds for one epoch ---
--- 1.6387643814086914 seconds for one epoch ---
--- 0.27538275718688965 seconds for one epoch ---
--- 1.665924310684204 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07860054]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.13013]
 [ -0.     ]]
--- 0.2917900085449219 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1731.0035400390625, (978.58203, 0.33089498, 751.9454, 0.14524178)
   validation loss 1112.99169921875, (839.0827, 0.30975553, 273.454, 0.14524178)
decoder loss ratio: 32507.520612, decoder SINDy loss  ratio: 0.590289
THRESHOLDING: 0 active coefficients
--- 0.2514650821685791 seconds for one epoch ---
--- 0.2895028591156006 seconds for one epoch ---
--- 1.6574516296386719 seconds for one epoch ---
--- 0.30438852310180664 seconds for one epoch ---
--- 1.6401622295379639 seconds for one epoch ---
--- 0.2875542640686035 seconds for one epoch ---
--- 1.6951496601104736 seconds for one epoch ---
--- 0.31685543060302734 seconds for one epoch ---
--- 1.6922848224639893 seconds for one epoch ---
--- 0.2856252193450928 seconds for one epoch ---
--- 1.6780457496643066 seconds for one epoch ---
--- 0.30507636070251465 seconds for one epoch ---
--- 1.6713588237762451 seconds for one epoch ---
--- 0.31577014923095703 seconds for one epoch ---
--- 1.6770844459533691 seconds for one epoch ---
--- 0.31689906120300293 seconds for one epoch ---
--- 1.677973985671997 seconds for one epoch ---
--- 0.30580782890319824 seconds for one epoch ---
--- 1.7048850059509277 seconds for one epoch ---
--- 0.288374662399292 seconds for one epoch ---
--- 1.6805040836334229 seconds for one epoch ---
--- 0.2932314872741699 seconds for one epoch ---
--- 1.6521501541137695 seconds for one epoch ---
--- 0.27520227432250977 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24431705474853516 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3586.7587890625, (1817.6797, 1.5462954, 1767.5146, 0.018080754)
   validation loss 776.9512939453125, (494.8608, 0.26989138, 281.80252, 0.018080754)
decoder loss ratio: 19171.766869, decoder SINDy loss  ratio: 0.608310
--- 0.3001224994659424 seconds for one epoch ---
--- 1.6942167282104492 seconds for one epoch ---
--- 0.2757887840270996 seconds for one epoch ---
--- 1.7106246948242188 seconds for one epoch ---
--- 0.29303550720214844 seconds for one epoch ---
--- 1.676361083984375 seconds for one epoch ---
--- 0.29518580436706543 seconds for one epoch ---
--- 1.6449298858642578 seconds for one epoch ---
--- 0.2957746982574463 seconds for one epoch ---
--- 1.6487364768981934 seconds for one epoch ---
--- 0.29541850090026855 seconds for one epoch ---
--- 1.6856918334960938 seconds for one epoch ---
--- 0.3009982109069824 seconds for one epoch ---
--- 1.693946123123169 seconds for one epoch ---
--- 0.28823161125183105 seconds for one epoch ---
--- 1.7503786087036133 seconds for one epoch ---
--- 0.3026444911956787 seconds for one epoch ---
--- 1.7170641422271729 seconds for one epoch ---
--- 0.2952408790588379 seconds for one epoch ---
--- 1.7273485660552979 seconds for one epoch ---
--- 0.30187439918518066 seconds for one epoch ---
--- 1.7147769927978516 seconds for one epoch ---
--- 0.29143261909484863 seconds for one epoch ---
--- 1.7366313934326172 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28120875358581543 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5126.29150390625, (2328.6387, 3.4600248, 2794.1746, 0.018080754)
   validation loss 801.666015625, (511.03235, 0.26241723, 290.35315, 0.018080754)
decoder loss ratio: 19798.280377, decoder SINDy loss  ratio: 0.626768
--- 0.26612186431884766 seconds for one epoch ---
--- 0.28150224685668945 seconds for one epoch ---
--- 1.712085485458374 seconds for one epoch ---
--- 0.283130407333374 seconds for one epoch ---
--- 1.744518756866455 seconds for one epoch ---
--- 0.2966156005859375 seconds for one epoch ---
--- 1.7036595344543457 seconds for one epoch ---
--- 0.3017458915710449 seconds for one epoch ---
--- 1.7124934196472168 seconds for one epoch ---
--- 0.3021690845489502 seconds for one epoch ---
--- 1.762631893157959 seconds for one epoch ---
--- 0.29498720169067383 seconds for one epoch ---
--- 1.6977922916412354 seconds for one epoch ---
--- 0.28405046463012695 seconds for one epoch ---
--- 1.7312486171722412 seconds for one epoch ---
--- 0.2984185218811035 seconds for one epoch ---
--- 1.6999859809875488 seconds for one epoch ---
--- 0.2792782783508301 seconds for one epoch ---
--- 1.6986961364746094 seconds for one epoch ---
--- 0.29730796813964844 seconds for one epoch ---
--- 1.7100987434387207 seconds for one epoch ---
--- 0.29650402069091797 seconds for one epoch ---
--- 1.7509136199951172 seconds for one epoch ---
--- 0.29812049865722656 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26176929473876953 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2138.751708984375, (1192.3928, 1.4292451, 944.91156, 0.018080754)
   validation loss 908.9814453125, (619.1683, 0.25240687, 289.5427, 0.018080754)
decoder loss ratio: 23987.653855, decoder SINDy loss  ratio: 0.625019
--- 0.2966015338897705 seconds for one epoch ---
--- 1.6874425411224365 seconds for one epoch ---
--- 0.29635071754455566 seconds for one epoch ---
--- 1.6979737281799316 seconds for one epoch ---
--- 0.3020343780517578 seconds for one epoch ---
--- 1.681323528289795 seconds for one epoch ---
--- 0.29645419120788574 seconds for one epoch ---
--- 1.7148797512054443 seconds for one epoch ---
--- 0.29775309562683105 seconds for one epoch ---
--- 1.7214651107788086 seconds for one epoch ---
--- 0.2926299571990967 seconds for one epoch ---
--- 1.7283129692077637 seconds for one epoch ---
--- 0.31359148025512695 seconds for one epoch ---
--- 1.7391657829284668 seconds for one epoch ---
--- 0.29913854598999023 seconds for one epoch ---
--- 1.7441949844360352 seconds for one epoch ---
--- 0.3004000186920166 seconds for one epoch ---
--- 1.7535555362701416 seconds for one epoch ---
--- 0.298917293548584 seconds for one epoch ---
--- 1.7506046295166016 seconds for one epoch ---
--- 0.30225491523742676 seconds for one epoch ---
--- 1.7431704998016357 seconds for one epoch ---
--- 0.29997682571411133 seconds for one epoch ---
--- 1.7657160758972168 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2985556125640869 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2086.54345703125, (950.26984, 1.7533029, 1134.5023, 0.018080754)
   validation loss 760.5709228515625, (478.42853, 0.2872609, 281.83704, 0.018080754)
decoder loss ratio: 18535.151757, decoder SINDy loss  ratio: 0.608385
--- 0.26654887199401855 seconds for one epoch ---
--- 0.30196666717529297 seconds for one epoch ---
--- 1.7721951007843018 seconds for one epoch ---
--- 0.2964637279510498 seconds for one epoch ---
--- 1.7668039798736572 seconds for one epoch ---
--- 0.2944319248199463 seconds for one epoch ---
--- 1.779005527496338 seconds for one epoch ---
--- 0.2932877540588379 seconds for one epoch ---
--- 1.794351577758789 seconds for one epoch ---
--- 0.29081177711486816 seconds for one epoch ---
--- 1.708714246749878 seconds for one epoch ---
--- 0.28823089599609375 seconds for one epoch ---
--- 1.7153046131134033 seconds for one epoch ---
--- 0.29787278175354004 seconds for one epoch ---
--- 1.7318484783172607 seconds for one epoch ---
--- 0.29415440559387207 seconds for one epoch ---
--- 1.7401165962219238 seconds for one epoch ---
--- 0.3205101490020752 seconds for one epoch ---
--- 1.7544755935668945 seconds for one epoch ---
--- 0.3172903060913086 seconds for one epoch ---
--- 1.7719287872314453 seconds for one epoch ---
--- 0.33100318908691406 seconds for one epoch ---
--- 1.7917864322662354 seconds for one epoch ---
--- 0.3394503593444824 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26271700859069824 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1572.9197998046875, (842.24426, 0.3688021, 730.2887, 0.018080754)
   validation loss 882.8370361328125, (593.60095, 0.24718334, 288.97083, 0.018080754)
decoder loss ratio: 22997.131423, decoder SINDy loss  ratio: 0.623784
--- 0.2948267459869385 seconds for one epoch ---
--- 1.7792208194732666 seconds for one epoch ---
--- 0.30582427978515625 seconds for one epoch ---
--- 1.7926075458526611 seconds for one epoch ---
--- 0.303023099899292 seconds for one epoch ---
--- 1.7745285034179688 seconds for one epoch ---
--- 0.31166553497314453 seconds for one epoch ---
--- 1.7891101837158203 seconds for one epoch ---
--- 0.3053884506225586 seconds for one epoch ---
--- 1.791247844696045 seconds for one epoch ---
--- 0.2994980812072754 seconds for one epoch ---
--- 1.7775466442108154 seconds for one epoch ---
--- 0.29805469512939453 seconds for one epoch ---
--- 1.799989938735962 seconds for one epoch ---
--- 0.3041107654571533 seconds for one epoch ---
--- 1.8096275329589844 seconds for one epoch ---
--- 0.30188870429992676 seconds for one epoch ---
--- 1.746453046798706 seconds for one epoch ---
--- 0.29120802879333496 seconds for one epoch ---
--- 1.744386911392212 seconds for one epoch ---
--- 0.29320383071899414 seconds for one epoch ---
--- 1.7369577884674072 seconds for one epoch ---
--- 0.3005380630493164 seconds for one epoch ---
--- 1.7821505069732666 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29105424880981445 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3431.614013671875, (1507.5502, 0.33394483, 1923.7118, 0.018080754)
   validation loss 756.9576416015625, (460.42462, 0.22847265, 296.28644, 0.018080754)
decoder loss ratio: 17837.649172, decoder SINDy loss  ratio: 0.639576
--- 0.2554788589477539 seconds for one epoch ---
--- 0.29686784744262695 seconds for one epoch ---
--- 1.7819478511810303 seconds for one epoch ---
--- 0.28855276107788086 seconds for one epoch ---
--- 1.7930402755737305 seconds for one epoch ---
--- 0.3049006462097168 seconds for one epoch ---
--- 1.7676055431365967 seconds for one epoch ---
--- 0.30695533752441406 seconds for one epoch ---
--- 1.8169806003570557 seconds for one epoch ---
--- 0.2958793640136719 seconds for one epoch ---
--- 1.7737016677856445 seconds for one epoch ---
--- 0.30521345138549805 seconds for one epoch ---
--- 1.806182861328125 seconds for one epoch ---
--- 0.30031895637512207 seconds for one epoch ---
--- 1.803006649017334 seconds for one epoch ---
--- 0.2948436737060547 seconds for one epoch ---
--- 1.8128478527069092 seconds for one epoch ---
--- 0.2982330322265625 seconds for one epoch ---
--- 1.8090567588806152 seconds for one epoch ---
--- 0.3026764392852783 seconds for one epoch ---
--- 1.8099305629730225 seconds for one epoch ---
--- 0.29672837257385254 seconds for one epoch ---
--- 1.8340365886688232 seconds for one epoch ---
--- 0.30819249153137207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25063610076904297 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3249.14892578125, (1120.5775, 1.4056281, 2127.1477, 0.01808468)
   validation loss 916.635986328125, (632.1215, 0.25456992, 284.2418, 0.01808468)
decoder loss ratio: 24489.485135, decoder SINDy loss  ratio: 0.613576
--- 0.31997251510620117 seconds for one epoch ---
--- 1.8003554344177246 seconds for one epoch ---
--- 0.3111400604248047 seconds for one epoch ---
--- 1.7810616493225098 seconds for one epoch ---
--- 0.31377744674682617 seconds for one epoch ---
--- 1.795797348022461 seconds for one epoch ---
--- 0.3227882385253906 seconds for one epoch ---
--- 1.8188722133636475 seconds for one epoch ---
--- 0.32986879348754883 seconds for one epoch ---
--- 1.7804114818572998 seconds for one epoch ---
--- 0.3294682502746582 seconds for one epoch ---
--- 1.838341474533081 seconds for one epoch ---
--- 0.37472081184387207 seconds for one epoch ---
--- 1.7986738681793213 seconds for one epoch ---
--- 0.3093099594116211 seconds for one epoch ---
--- 1.8128325939178467 seconds for one epoch ---
--- 0.3257322311401367 seconds for one epoch ---
--- 1.8338394165039062 seconds for one epoch ---
--- 0.3399007320404053 seconds for one epoch ---
--- 1.8069472312927246 seconds for one epoch ---
--- 0.3067195415496826 seconds for one epoch ---
--- 1.810805082321167 seconds for one epoch ---
--- 0.2958238124847412 seconds for one epoch ---
--- 1.7804250717163086 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2941737174987793 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3011.1298828125, (1210.0856, 0.8443859, 1800.182, 0.01809374)
   validation loss 1223.0408935546875, (933.72534, 0.27172342, 289.02576, 0.01809374)
decoder loss ratio: 36174.140760, decoder SINDy loss  ratio: 0.623903
--- 0.255556583404541 seconds for one epoch ---
--- 0.2832760810852051 seconds for one epoch ---
--- 1.8037047386169434 seconds for one epoch ---
--- 0.2977278232574463 seconds for one epoch ---
--- 1.7910099029541016 seconds for one epoch ---
--- 0.31040167808532715 seconds for one epoch ---
--- 1.8000192642211914 seconds for one epoch ---
--- 0.300487756729126 seconds for one epoch ---
--- 1.8062305450439453 seconds for one epoch ---
--- 0.2942931652069092 seconds for one epoch ---
--- 1.7959790229797363 seconds for one epoch ---
--- 0.3094182014465332 seconds for one epoch ---
--- 1.7977979183197021 seconds for one epoch ---
--- 0.2936875820159912 seconds for one epoch ---
--- 1.8044118881225586 seconds for one epoch ---
--- 0.2994368076324463 seconds for one epoch ---
--- 1.8145639896392822 seconds for one epoch ---
--- 0.2992391586303711 seconds for one epoch ---
--- 1.8037505149841309 seconds for one epoch ---
--- 0.293018102645874 seconds for one epoch ---
--- 1.7795140743255615 seconds for one epoch ---
--- 0.2862858772277832 seconds for one epoch ---
--- 1.8223583698272705 seconds for one epoch ---
--- 0.28842592239379883 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2484903335571289 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2791.53271484375, (1129.924, 2.6279674, 1658.9628, 0.018103395)
   validation loss 916.8744506835938, (611.82623, 0.2826386, 304.7474, 0.018103395)
decoder loss ratio: 23703.210440, decoder SINDy loss  ratio: 0.657840
--- 0.2925581932067871 seconds for one epoch ---
--- 1.794978141784668 seconds for one epoch ---
--- 0.2996244430541992 seconds for one epoch ---
--- 1.8322420120239258 seconds for one epoch ---
--- 0.3012051582336426 seconds for one epoch ---
--- 1.7763774394989014 seconds for one epoch ---
--- 0.28255462646484375 seconds for one epoch ---
--- 1.7730128765106201 seconds for one epoch ---
--- 0.27658891677856445 seconds for one epoch ---
--- 1.7681596279144287 seconds for one epoch ---
--- 0.2953948974609375 seconds for one epoch ---
--- 1.8144128322601318 seconds for one epoch ---
--- 0.3008854389190674 seconds for one epoch ---
--- 1.8640596866607666 seconds for one epoch ---
--- 0.29357481002807617 seconds for one epoch ---
--- 1.8234801292419434 seconds for one epoch ---
--- 0.2998955249786377 seconds for one epoch ---
--- 1.8006689548492432 seconds for one epoch ---
--- 0.2941277027130127 seconds for one epoch ---
--- 1.820960521697998 seconds for one epoch ---
--- 0.3008856773376465 seconds for one epoch ---
--- 1.8312060832977295 seconds for one epoch ---
--- 0.28164100646972656 seconds for one epoch ---
--- 1.7987704277038574 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3155195713043213 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2077.90234375, (909.3739, 0.68923086, 1167.821, 0.018121565)
   validation loss 944.1538696289062, (670.95337, 0.34401432, 272.83838, 0.018121565)
decoder loss ratio: 25993.898347, decoder SINDy loss  ratio: 0.588960
--- 0.26362085342407227 seconds for one epoch ---
--- 0.3262639045715332 seconds for one epoch ---
--- 1.8247580528259277 seconds for one epoch ---
--- 0.29672932624816895 seconds for one epoch ---
--- 1.8246991634368896 seconds for one epoch ---
--- 0.31377673149108887 seconds for one epoch ---
--- 1.8052656650543213 seconds for one epoch ---
--- 0.2888057231903076 seconds for one epoch ---
--- 1.8422856330871582 seconds for one epoch ---
--- 0.29888200759887695 seconds for one epoch ---
--- 1.8601422309875488 seconds for one epoch ---
--- 0.30770087242126465 seconds for one epoch ---
--- 1.809281587600708 seconds for one epoch ---
--- 0.3037288188934326 seconds for one epoch ---
--- 1.7890846729278564 seconds for one epoch ---
--- 0.29581594467163086 seconds for one epoch ---
--- 1.8094165325164795 seconds for one epoch ---
--- 0.297116756439209 seconds for one epoch ---
--- 1.8241159915924072 seconds for one epoch ---
--- 0.3064885139465332 seconds for one epoch ---
--- 1.85005521774292 seconds for one epoch ---
--- 0.31882190704345703 seconds for one epoch ---
--- 1.8632481098175049 seconds for one epoch ---
--- 0.31612277030944824 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26633477210998535 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3730.427978515625, (2137.3215, 1.3675857, 1591.7207, 0.018150486)
   validation loss 738.9779663085938, (451.37082, 0.30487588, 287.28412, 0.018150486)
decoder loss ratio: 17486.889146, decoder SINDy loss  ratio: 0.620143
--- 0.2951962947845459 seconds for one epoch ---
--- 1.8318486213684082 seconds for one epoch ---
--- 0.28406834602355957 seconds for one epoch ---
--- 1.8279736042022705 seconds for one epoch ---
--- 0.29852914810180664 seconds for one epoch ---
--- 1.8242807388305664 seconds for one epoch ---
--- 0.29982686042785645 seconds for one epoch ---
--- 1.8739683628082275 seconds for one epoch ---
--- 0.30320048332214355 seconds for one epoch ---
--- 1.8617734909057617 seconds for one epoch ---
--- 0.29572606086730957 seconds for one epoch ---
--- 1.857105016708374 seconds for one epoch ---
--- 0.3012113571166992 seconds for one epoch ---
--- 1.8510973453521729 seconds for one epoch ---
--- 0.295421838760376 seconds for one epoch ---
--- 1.8476934432983398 seconds for one epoch ---
--- 0.3052053451538086 seconds for one epoch ---
--- 1.817967414855957 seconds for one epoch ---
--- 0.29622817039489746 seconds for one epoch ---
--- 1.8680942058563232 seconds for one epoch ---
--- 0.2865633964538574 seconds for one epoch ---
--- 1.8587696552276611 seconds for one epoch ---
--- 0.30776429176330566 seconds for one epoch ---
--- 1.809004545211792 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3036010265350342 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3358.522216796875, (2205.0522, 0.866508, 1152.5851, 0.018195385)
   validation loss 904.90283203125, (610.6933, 0.27730122, 293.9141, 0.018195385)
decoder loss ratio: 23659.318588, decoder SINDy loss  ratio: 0.634455
--- 0.27977585792541504 seconds for one epoch ---
--- 0.29827022552490234 seconds for one epoch ---
--- 1.8884482383728027 seconds for one epoch ---
--- 0.2986111640930176 seconds for one epoch ---
--- 1.8422772884368896 seconds for one epoch ---
--- 0.29828476905822754 seconds for one epoch ---
--- 1.9088613986968994 seconds for one epoch ---
--- 0.3005075454711914 seconds for one epoch ---
--- 1.8824050426483154 seconds for one epoch ---
--- 0.30258965492248535 seconds for one epoch ---
--- 1.8840575218200684 seconds for one epoch ---
--- 0.2966604232788086 seconds for one epoch ---
--- 1.8653814792633057 seconds for one epoch ---
--- 0.29923534393310547 seconds for one epoch ---
--- 1.8451242446899414 seconds for one epoch ---
--- 0.29741573333740234 seconds for one epoch ---
--- 1.856226921081543 seconds for one epoch ---
--- 0.2875640392303467 seconds for one epoch ---
--- 1.8656702041625977 seconds for one epoch ---
--- 0.29922008514404297 seconds for one epoch ---
--- 1.8705966472625732 seconds for one epoch ---
--- 0.30139732360839844 seconds for one epoch ---
--- 1.873805046081543 seconds for one epoch ---
--- 0.28418970108032227 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2523765563964844 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1885.306884765625, (766.00616, 0.9844748, 1118.298, 0.018266754)
   validation loss 686.6188354492188, (408.27344, 0.2700499, 278.05713, 0.018266754)
decoder loss ratio: 15817.221763, decoder SINDy loss  ratio: 0.600225
--- 0.2961099147796631 seconds for one epoch ---
--- 1.8864200115203857 seconds for one epoch ---
--- 0.29714083671569824 seconds for one epoch ---
--- 1.9012725353240967 seconds for one epoch ---
--- 0.2843945026397705 seconds for one epoch ---
--- 1.8922498226165771 seconds for one epoch ---
--- 0.2843310832977295 seconds for one epoch ---
--- 1.8801004886627197 seconds for one epoch ---
--- 0.2906310558319092 seconds for one epoch ---
--- 1.862334966659546 seconds for one epoch ---
--- 0.28400158882141113 seconds for one epoch ---
--- 1.863776445388794 seconds for one epoch ---
--- 0.3065788745880127 seconds for one epoch ---
--- 1.8518579006195068 seconds for one epoch ---
--- 0.3013429641723633 seconds for one epoch ---
--- 1.8800044059753418 seconds for one epoch ---
--- 0.29578280448913574 seconds for one epoch ---
--- 1.8507294654846191 seconds for one epoch ---
--- 0.2982161045074463 seconds for one epoch ---
--- 1.881723165512085 seconds for one epoch ---
--- 0.2984790802001953 seconds for one epoch ---
--- 1.868842363357544 seconds for one epoch ---
--- 0.2997477054595947 seconds for one epoch ---
--- 1.8773984909057617 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29825353622436523 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2762.302734375, (1302.1583, 0.973285, 1459.1528, 0.018380044)
   validation loss 1743.6478271484375, (1430.1904, 0.24993378, 313.18903, 0.018380044)
decoder loss ratio: 55408.060166, decoder SINDy loss  ratio: 0.676063
--- 0.26361870765686035 seconds for one epoch ---
--- 0.2964057922363281 seconds for one epoch ---
--- 1.8423354625701904 seconds for one epoch ---
--- 0.2904214859008789 seconds for one epoch ---
--- 1.8721213340759277 seconds for one epoch ---
--- 0.29717493057250977 seconds for one epoch ---
--- 1.8572514057159424 seconds for one epoch ---
--- 0.29070401191711426 seconds for one epoch ---
--- 1.8921051025390625 seconds for one epoch ---
--- 0.29677605628967285 seconds for one epoch ---
--- 1.9142580032348633 seconds for one epoch ---
--- 0.30460643768310547 seconds for one epoch ---
--- 1.8993275165557861 seconds for one epoch ---
--- 0.28020572662353516 seconds for one epoch ---
--- 1.8644447326660156 seconds for one epoch ---
--- 0.2990090847015381 seconds for one epoch ---
--- 1.878676414489746 seconds for one epoch ---
--- 0.28685855865478516 seconds for one epoch ---
--- 1.8486714363098145 seconds for one epoch ---
--- 0.30116987228393555 seconds for one epoch ---
--- 1.8743896484375 seconds for one epoch ---
--- 0.30073046684265137 seconds for one epoch ---
--- 1.897726058959961 seconds for one epoch ---
--- 0.2932450771331787 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25074076652526855 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2035.088623046875, (754.2451, 7.443295, 1273.3816, 0.018560013)
   validation loss 831.96826171875, (556.3736, 0.272165, 275.30396, 0.018560013)
decoder loss ratio: 21554.879023, decoder SINDy loss  ratio: 0.594282
--- 0.29352664947509766 seconds for one epoch ---
--- 1.8912787437438965 seconds for one epoch ---
--- 0.28737401962280273 seconds for one epoch ---
--- 1.88749098777771 seconds for one epoch ---
--- 0.29641222953796387 seconds for one epoch ---
--- 1.9039256572723389 seconds for one epoch ---
--- 0.3074455261230469 seconds for one epoch ---
--- 1.9334604740142822 seconds for one epoch ---
--- 0.3197906017303467 seconds for one epoch ---
--- 1.8338592052459717 seconds for one epoch ---
--- 0.28933119773864746 seconds for one epoch ---
--- 1.8646361827850342 seconds for one epoch ---
--- 0.2965719699859619 seconds for one epoch ---
--- 1.8642241954803467 seconds for one epoch ---
--- 0.2955741882324219 seconds for one epoch ---
--- 1.8372044563293457 seconds for one epoch ---
--- 0.29560375213623047 seconds for one epoch ---
--- 1.9417321681976318 seconds for one epoch ---
--- 0.3227717876434326 seconds for one epoch ---
--- 1.900644063949585 seconds for one epoch ---
--- 0.3141639232635498 seconds for one epoch ---
--- 1.9432179927825928 seconds for one epoch ---
--- 0.31160402297973633 seconds for one epoch ---
--- 1.8797338008880615 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29594850540161133 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5921.95947265625, (1460.4805, 2.798479, 4458.6616, 0.018844)
   validation loss 734.3252563476562, (425.50534, 0.28284812, 308.51822, 0.018844)
decoder loss ratio: 16484.815604, decoder SINDy loss  ratio: 0.665980
--- 0.25597500801086426 seconds for one epoch ---
--- 0.3087131977081299 seconds for one epoch ---
--- 1.8930308818817139 seconds for one epoch ---
--- 0.2961554527282715 seconds for one epoch ---
--- 1.893920660018921 seconds for one epoch ---
--- 0.3098416328430176 seconds for one epoch ---
--- 1.916036605834961 seconds for one epoch ---
--- 0.3012418746948242 seconds for one epoch ---
--- 1.9386558532714844 seconds for one epoch ---
--- 0.2944912910461426 seconds for one epoch ---
--- 1.9176061153411865 seconds for one epoch ---
--- 0.30320119857788086 seconds for one epoch ---
--- 1.9064536094665527 seconds for one epoch ---
--- 0.3013756275177002 seconds for one epoch ---
--- 1.9144034385681152 seconds for one epoch ---
--- 0.30444812774658203 seconds for one epoch ---
--- 1.9318454265594482 seconds for one epoch ---
--- 0.2847421169281006 seconds for one epoch ---
--- 1.881458044052124 seconds for one epoch ---
--- 0.30142664909362793 seconds for one epoch ---
--- 1.871459722518921 seconds for one epoch ---
--- 0.30974507331848145 seconds for one epoch ---
--- 1.86065673828125 seconds for one epoch ---
--- 0.2907538414001465 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2583925724029541 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2763.115478515625, (1361.6243, 0.78450406, 1400.6873, 0.019286586)
   validation loss 697.05712890625, (410.11066, 0.31981376, 286.6074, 0.019286586)
decoder loss ratio: 15888.398825, decoder SINDy loss  ratio: 0.618682
--- 0.2924211025238037 seconds for one epoch ---
--- 1.9383747577667236 seconds for one epoch ---
--- 0.29900479316711426 seconds for one epoch ---
--- 1.937455415725708 seconds for one epoch ---
--- 0.2942225933074951 seconds for one epoch ---
--- 1.9377367496490479 seconds for one epoch ---
--- 0.29080724716186523 seconds for one epoch ---
--- 1.9334087371826172 seconds for one epoch ---
--- 0.293834924697876 seconds for one epoch ---
--- 1.9444806575775146 seconds for one epoch ---
--- 0.29127025604248047 seconds for one epoch ---
--- 1.933056354522705 seconds for one epoch ---
--- 0.28684067726135254 seconds for one epoch ---
--- 1.9640562534332275 seconds for one epoch ---
--- 0.2876110076904297 seconds for one epoch ---
--- 1.9552717208862305 seconds for one epoch ---
--- 0.2954854965209961 seconds for one epoch ---
--- 1.9690678119659424 seconds for one epoch ---
--- 0.2977476119995117 seconds for one epoch ---
--- 1.9414844512939453 seconds for one epoch ---
--- 0.28801679611206055 seconds for one epoch ---
--- 1.9386544227600098 seconds for one epoch ---
--- 0.2973923683166504 seconds for one epoch ---
--- 1.969724178314209 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2876303195953369 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2969.63427734375, (1423.3141, 2.9807756, 1543.3192, 0.019956926)
   validation loss 1491.1483154296875, (1224.6826, 0.28736544, 266.15845, 0.019956926)
decoder loss ratio: 47446.330732, decoder SINDy loss  ratio: 0.574540
--- 0.25806403160095215 seconds for one epoch ---
--- 0.3012526035308838 seconds for one epoch ---
--- 1.9117634296417236 seconds for one epoch ---
--- 0.2901477813720703 seconds for one epoch ---
--- 1.8957993984222412 seconds for one epoch ---
--- 0.29387760162353516 seconds for one epoch ---
--- 1.9295988082885742 seconds for one epoch ---
--- 0.29517531394958496 seconds for one epoch ---
--- 1.9284870624542236 seconds for one epoch ---
--- 0.28989148139953613 seconds for one epoch ---
--- 1.9432024955749512 seconds for one epoch ---
--- 0.2967073917388916 seconds for one epoch ---
--- 1.9442532062530518 seconds for one epoch ---
--- 0.2939152717590332 seconds for one epoch ---
--- 1.9535737037658691 seconds for one epoch ---
--- 0.2910647392272949 seconds for one epoch ---
--- 1.9341061115264893 seconds for one epoch ---
--- 0.29421567916870117 seconds for one epoch ---
--- 1.959712028503418 seconds for one epoch ---
--- 0.296248197555542 seconds for one epoch ---
--- 1.9767825603485107 seconds for one epoch ---
--- 0.2856299877166748 seconds for one epoch ---
--- 1.9403350353240967 seconds for one epoch ---
--- 0.300473690032959 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25781846046447754 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3927.532958984375, (1330.096, 3.3857796, 2594.0303, 0.02091437)
   validation loss 742.5606079101562, (437.75653, 0.28711444, 304.496, 0.02091437)
decoder loss ratio: 16959.447980, decoder SINDy loss  ratio: 0.657297
--- 0.30930113792419434 seconds for one epoch ---
--- 1.8787951469421387 seconds for one epoch ---
--- 0.2941477298736572 seconds for one epoch ---
--- 1.9082715511322021 seconds for one epoch ---
--- 0.29225969314575195 seconds for one epoch ---
--- 1.8874475955963135 seconds for one epoch ---
--- 0.3013584613800049 seconds for one epoch ---
--- 1.97511887550354 seconds for one epoch ---
--- 0.31009697914123535 seconds for one epoch ---
--- 1.9345252513885498 seconds for one epoch ---
--- 0.33641743659973145 seconds for one epoch ---
--- 2.0104591846466064 seconds for one epoch ---
--- 0.3316807746887207 seconds for one epoch ---
--- 1.9891364574432373 seconds for one epoch ---
--- 0.30777764320373535 seconds for one epoch ---
--- 1.9956870079040527 seconds for one epoch ---
--- 0.2992885112762451 seconds for one epoch ---
--- 1.9410462379455566 seconds for one epoch ---
--- 0.29601263999938965 seconds for one epoch ---
--- 1.9778480529785156 seconds for one epoch ---
--- 0.2958052158355713 seconds for one epoch ---
--- 1.973846673965454 seconds for one epoch ---
--- 0.297466516494751 seconds for one epoch ---
--- 1.967803716659546 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2962653636932373 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2127.3720703125, (1199.684, 0.7237468, 926.9421, 0.02216186)
   validation loss 964.1797485351562, (663.7612, 0.31893864, 300.07742, 0.02216186)
decoder loss ratio: 25715.262409, decoder SINDy loss  ratio: 0.647759
THRESHOLDING: 0 active coefficients
--- 1.8992891311645508 seconds for one epoch ---
--- 0.3041059970855713 seconds for one epoch ---
--- 1.91973876953125 seconds for one epoch ---
--- 0.2962007522583008 seconds for one epoch ---
--- 1.9526431560516357 seconds for one epoch ---
--- 0.29455041885375977 seconds for one epoch ---
--- 1.9725873470306396 seconds for one epoch ---
--- 0.29335999488830566 seconds for one epoch ---
--- 1.9928476810455322 seconds for one epoch ---
--- 0.29520153999328613 seconds for one epoch ---
--- 1.9974656105041504 seconds for one epoch ---
--- 0.30038022994995117 seconds for one epoch ---
--- 1.974524974822998 seconds for one epoch ---
--- 0.28989124298095703 seconds for one epoch ---
--- 1.9907581806182861 seconds for one epoch ---
--- 0.2938549518585205 seconds for one epoch ---
--- 1.983879566192627 seconds for one epoch ---
--- 0.29735279083251953 seconds for one epoch ---
--- 1.9997951984405518 seconds for one epoch ---
--- 0.32893896102905273 seconds for one epoch ---
--- 1.997265338897705 seconds for one epoch ---
--- 0.3227517604827881 seconds for one epoch ---
--- 2.004472494125366 seconds for one epoch ---
--- 0.3304145336151123 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2588083744049072 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3596.706298828125, (1561.265, 2.0324438, 2033.4088, 0.0)
   validation loss 770.10791015625, (493.79398, 0.33209717, 275.98184, 0.0)
decoder loss ratio: 19130.435888, decoder SINDy loss  ratio: 0.595746
--- 0.28027939796447754 seconds for one epoch ---
--- 2.0210835933685303 seconds for one epoch ---
--- 0.3028295040130615 seconds for one epoch ---
--- 2.0361557006835938 seconds for one epoch ---
--- 0.28316402435302734 seconds for one epoch ---
--- 1.9882097244262695 seconds for one epoch ---
--- 0.29461050033569336 seconds for one epoch ---
--- 2.0088906288146973 seconds for one epoch ---
--- 0.2938816547393799 seconds for one epoch ---
--- 2.0088796615600586 seconds for one epoch ---
--- 0.29973936080932617 seconds for one epoch ---
--- 2.0276260375976562 seconds for one epoch ---
--- 0.29135799407958984 seconds for one epoch ---
--- 2.0116183757781982 seconds for one epoch ---
--- 0.29731059074401855 seconds for one epoch ---
--- 2.0257346630096436 seconds for one epoch ---
--- 0.294879674911499 seconds for one epoch ---
--- 2.0291812419891357 seconds for one epoch ---
--- 0.2966189384460449 seconds for one epoch ---
--- 2.0175082683563232 seconds for one epoch ---
--- 0.2978861331939697 seconds for one epoch ---
--- 2.006974458694458 seconds for one epoch ---
--- 0.30362629890441895 seconds for one epoch ---
--- 1.9991192817687988 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2916605472564697 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2736.757568359375, (1491.116, 1.3683082, 1244.2733, 0.0)
   validation loss 866.296875, (538.44183, 0.26850605, 327.58652, 0.0)
decoder loss ratio: 20860.171406, decoder SINDy loss  ratio: 0.707142
--- 0.25980544090270996 seconds for one epoch ---
--- 0.2895162105560303 seconds for one epoch ---
--- 1.958672046661377 seconds for one epoch ---
--- 0.29334449768066406 seconds for one epoch ---
--- 1.9758281707763672 seconds for one epoch ---
--- 0.3005204200744629 seconds for one epoch ---
--- 1.9531183242797852 seconds for one epoch ---
--- 0.28107404708862305 seconds for one epoch ---
--- 2.0229804515838623 seconds for one epoch ---
--- 0.3138749599456787 seconds for one epoch ---
--- 2.0199673175811768 seconds for one epoch ---
--- 0.3246018886566162 seconds for one epoch ---
--- 2.041473150253296 seconds for one epoch ---
--- 0.3453187942504883 seconds for one epoch ---
--- 2.0386745929718018 seconds for one epoch ---
--- 0.32491207122802734 seconds for one epoch ---
--- 2.0578248500823975 seconds for one epoch ---
--- 0.306445837020874 seconds for one epoch ---
--- 2.021428346633911 seconds for one epoch ---
--- 0.26808619499206543 seconds for one epoch ---
--- 2.0001416206359863 seconds for one epoch ---
--- 0.2949106693267822 seconds for one epoch ---
--- 2.028184175491333 seconds for one epoch ---
--- 0.27944040298461914 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26244688034057617 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3282.432861328125, (1827.9867, 1.459423, 1452.9867, 0.0)
   validation loss 795.4327392578125, (506.92993, 0.33542857, 288.16742, 0.0)
decoder loss ratio: 19639.345621, decoder SINDy loss  ratio: 0.622050
--- 0.299360990524292 seconds for one epoch ---
--- 1.9946153163909912 seconds for one epoch ---
--- 0.29250073432922363 seconds for one epoch ---
--- 2.00685977935791 seconds for one epoch ---
--- 0.2858920097351074 seconds for one epoch ---
--- 2.0323355197906494 seconds for one epoch ---
--- 0.28226351737976074 seconds for one epoch ---
--- 2.025799036026001 seconds for one epoch ---
--- 0.30153894424438477 seconds for one epoch ---
--- 1.9996404647827148 seconds for one epoch ---
--- 0.2941925525665283 seconds for one epoch ---
--- 1.9887261390686035 seconds for one epoch ---
--- 0.28509068489074707 seconds for one epoch ---
--- 1.9863429069519043 seconds for one epoch ---
--- 0.28513169288635254 seconds for one epoch ---
--- 1.9722588062286377 seconds for one epoch ---
--- 0.28765177726745605 seconds for one epoch ---
--- 2.0097529888153076 seconds for one epoch ---
--- 0.2739415168762207 seconds for one epoch ---
--- 2.067840099334717 seconds for one epoch ---
--- 0.3008430004119873 seconds for one epoch ---
--- 2.0226948261260986 seconds for one epoch ---
--- 0.29699158668518066 seconds for one epoch ---
--- 2.036158323287964 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29375195503234863 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4127.0810546875, (1348.5065, 2.0969543, 2776.4775, 0.0)
   validation loss 883.8545532226562, (610.44543, 0.32955518, 273.0796, 0.0)
decoder loss ratio: 23649.715915, decoder SINDy loss  ratio: 0.589481
--- 0.26448750495910645 seconds for one epoch ---
--- 0.2984898090362549 seconds for one epoch ---
--- 2.052535057067871 seconds for one epoch ---
--- 0.29801273345947266 seconds for one epoch ---
--- 2.0840532779693604 seconds for one epoch ---
--- 0.28615713119506836 seconds for one epoch ---
--- 2.0302987098693848 seconds for one epoch ---
--- 0.2940714359283447 seconds for one epoch ---
--- 2.036741256713867 seconds for one epoch ---
--- 0.2960972785949707 seconds for one epoch ---
--- 2.0283641815185547 seconds for one epoch ---
--- 0.29006361961364746 seconds for one epoch ---
--- 2.025587320327759 seconds for one epoch ---
--- 0.28561878204345703 seconds for one epoch ---
--- 2.063500165939331 seconds for one epoch ---
--- 0.2863175868988037 seconds for one epoch ---
--- 2.0604844093322754 seconds for one epoch ---
--- 0.29215312004089355 seconds for one epoch ---
--- 1.9842159748077393 seconds for one epoch ---
--- 0.29310107231140137 seconds for one epoch ---
--- 2.0033624172210693 seconds for one epoch ---
--- 0.2953648567199707 seconds for one epoch ---
--- 1.9848425388336182 seconds for one epoch ---
--- 0.2985348701477051 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2578446865081787 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2563.58935546875, (1224.3164, 1.9907529, 1337.2821, 0.0)
   validation loss 1081.038818359375, (815.2615, 0.3583232, 265.41904, 0.0)
decoder loss ratio: 31584.644883, decoder SINDy loss  ratio: 0.572944
--- 0.29726743698120117 seconds for one epoch ---
--- 2.051508903503418 seconds for one epoch ---
--- 0.29538512229919434 seconds for one epoch ---
--- 2.0690605640411377 seconds for one epoch ---
--- 0.28015828132629395 seconds for one epoch ---
--- 1.9843146800994873 seconds for one epoch ---
--- 0.2840402126312256 seconds for one epoch ---
--- 1.997220754623413 seconds for one epoch ---
--- 0.2927665710449219 seconds for one epoch ---
--- 1.992994785308838 seconds for one epoch ---
--- 0.3006865978240967 seconds for one epoch ---
--- 1.9946446418762207 seconds for one epoch ---
--- 0.2983367443084717 seconds for one epoch ---
--- 2.073671579360962 seconds for one epoch ---
--- 0.2969844341278076 seconds for one epoch ---
--- 2.07430362701416 seconds for one epoch ---
--- 0.2949538230895996 seconds for one epoch ---
--- 2.068969964981079 seconds for one epoch ---
--- 0.29856014251708984 seconds for one epoch ---
--- 2.063584566116333 seconds for one epoch ---
--- 0.29297685623168945 seconds for one epoch ---
--- 2.054929494857788 seconds for one epoch ---
--- 0.2950170040130615 seconds for one epoch ---
--- 2.0777699947357178 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28868722915649414 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3951.0732421875, (1787.5599, 0.7716067, 2162.7417, 0.0)
   validation loss 835.625244140625, (554.91364, 0.35623744, 280.35538, 0.0)
decoder loss ratio: 21498.317602, decoder SINDy loss  ratio: 0.605187
--- 0.2609870433807373 seconds for one epoch ---
--- 0.2967500686645508 seconds for one epoch ---
--- 2.0517704486846924 seconds for one epoch ---
--- 0.29523301124572754 seconds for one epoch ---
--- 2.0481090545654297 seconds for one epoch ---
--- 0.29535484313964844 seconds for one epoch ---
--- 2.048492908477783 seconds for one epoch ---
--- 0.2982451915740967 seconds for one epoch ---
--- 2.0460855960845947 seconds for one epoch ---
--- 0.2821543216705322 seconds for one epoch ---
--- 2.092517614364624 seconds for one epoch ---
--- 0.29758238792419434 seconds for one epoch ---
--- 2.087193727493286 seconds for one epoch ---
--- 0.2938117980957031 seconds for one epoch ---
--- 2.078202486038208 seconds for one epoch ---
--- 0.29971766471862793 seconds for one epoch ---
--- 2.0719189643859863 seconds for one epoch ---
--- 0.29149389266967773 seconds for one epoch ---
--- 2.0607573986053467 seconds for one epoch ---
--- 0.2959251403808594 seconds for one epoch ---
--- 2.0528719425201416 seconds for one epoch ---
--- 0.3030812740325928 seconds for one epoch ---
--- 2.0697269439697266 seconds for one epoch ---
--- 0.298581600189209 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2549920082092285 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3612.24609375, (1993.0381, 1.1177753, 1618.0903, 0.0)
   validation loss 892.6923828125, (607.6199, 0.32595837, 284.7465, 0.0)
decoder loss ratio: 23540.248756, decoder SINDy loss  ratio: 0.614665
--- 0.3197176456451416 seconds for one epoch ---
--- 2.11855149269104 seconds for one epoch ---
--- 0.3017585277557373 seconds for one epoch ---
--- 2.083890676498413 seconds for one epoch ---
--- 0.30153584480285645 seconds for one epoch ---
--- 2.0917887687683105 seconds for one epoch ---
--- 0.30750083923339844 seconds for one epoch ---
--- 2.0699775218963623 seconds for one epoch ---
--- 0.30817198753356934 seconds for one epoch ---
--- 2.0939383506774902 seconds for one epoch ---
--- 0.2961537837982178 seconds for one epoch ---
--- 2.1232590675354004 seconds for one epoch ---
--- 0.29500770568847656 seconds for one epoch ---
--- 2.1075496673583984 seconds for one epoch ---
--- 0.29517507553100586 seconds for one epoch ---
--- 2.104266881942749 seconds for one epoch ---
--- 0.2835879325866699 seconds for one epoch ---
--- 2.086791753768921 seconds for one epoch ---
--- 0.29863452911376953 seconds for one epoch ---
--- 2.1184630393981934 seconds for one epoch ---
--- 0.29752087593078613 seconds for one epoch ---
--- 2.1395516395568848 seconds for one epoch ---
--- 0.2928180694580078 seconds for one epoch ---
--- 2.1004080772399902 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2925586700439453 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2871.341552734375, (1199.4452, 1.1044166, 1670.792, 0.0)
   validation loss 724.775146484375, (437.0572, 0.3368816, 287.38107, 0.0)
decoder loss ratio: 16932.354303, decoder SINDy loss  ratio: 0.620352
--- 0.26187872886657715 seconds for one epoch ---
--- 0.298663854598999 seconds for one epoch ---
--- 2.1242361068725586 seconds for one epoch ---
--- 0.29022955894470215 seconds for one epoch ---
--- 2.1175453662872314 seconds for one epoch ---
--- 0.2941162586212158 seconds for one epoch ---
--- 2.1050705909729004 seconds for one epoch ---
--- 0.3061959743499756 seconds for one epoch ---
--- 2.1017611026763916 seconds for one epoch ---
--- 0.2978024482727051 seconds for one epoch ---
--- 2.118459463119507 seconds for one epoch ---
--- 0.31993913650512695 seconds for one epoch ---
--- 2.092515468597412 seconds for one epoch ---
--- 0.3328549861907959 seconds for one epoch ---
--- 2.152573585510254 seconds for one epoch ---
--- 0.29553675651550293 seconds for one epoch ---
--- 2.1425890922546387 seconds for one epoch ---
--- 0.31696009635925293 seconds for one epoch ---
--- 2.1473467350006104 seconds for one epoch ---
--- 0.3078486919403076 seconds for one epoch ---
--- 2.1125571727752686 seconds for one epoch ---
--- 0.2954704761505127 seconds for one epoch ---
--- 2.102938413619995 seconds for one epoch ---
--- 0.30080723762512207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25589656829833984 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3880.4775390625, (1457.3763, 1.3278891, 2421.7734, 0.0)
   validation loss 977.2701416015625, (695.4632, 0.28968963, 281.5173, 0.0)
decoder loss ratio: 26943.451583, decoder SINDy loss  ratio: 0.607695
--- 0.2957451343536377 seconds for one epoch ---
--- 2.153001546859741 seconds for one epoch ---
--- 0.2856278419494629 seconds for one epoch ---
--- 2.146416425704956 seconds for one epoch ---
--- 0.2945370674133301 seconds for one epoch ---
--- 2.1296255588531494 seconds for one epoch ---
--- 0.29607272148132324 seconds for one epoch ---
--- 2.1407153606414795 seconds for one epoch ---
--- 0.29397010803222656 seconds for one epoch ---
--- 2.1566178798675537 seconds for one epoch ---
--- 0.2933964729309082 seconds for one epoch ---
--- 2.1714415550231934 seconds for one epoch ---
--- 0.29419445991516113 seconds for one epoch ---
--- 2.1431820392608643 seconds for one epoch ---
--- 0.29433608055114746 seconds for one epoch ---
--- 2.1362874507904053 seconds for one epoch ---
--- 0.30788254737854004 seconds for one epoch ---
--- 2.1399829387664795 seconds for one epoch ---
--- 0.30092906951904297 seconds for one epoch ---
--- 2.164179563522339 seconds for one epoch ---
--- 0.31304287910461426 seconds for one epoch ---
--- 2.13742995262146 seconds for one epoch ---
--- 0.2661018371582031 seconds for one epoch ---
--- 2.157069683074951 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3211534023284912 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3390.30810546875, (1429.286, 1.0041293, 1960.0181, 0.0)
   validation loss 823.3184814453125, (534.7539, 0.3072307, 288.25735, 0.0)
decoder loss ratio: 20717.294702, decoder SINDy loss  ratio: 0.622244
--- 0.2856259346008301 seconds for one epoch ---
--- 0.31708788871765137 seconds for one epoch ---
--- 2.1614317893981934 seconds for one epoch ---
--- 0.30526185035705566 seconds for one epoch ---
--- 2.1220953464508057 seconds for one epoch ---
--- 0.2900733947753906 seconds for one epoch ---
--- 2.162970542907715 seconds for one epoch ---
--- 0.30377912521362305 seconds for one epoch ---
--- 2.1765027046203613 seconds for one epoch ---
--- 0.30365991592407227 seconds for one epoch ---
--- 2.161393165588379 seconds for one epoch ---
--- 0.2960948944091797 seconds for one epoch ---
--- 2.1541969776153564 seconds for one epoch ---
--- 0.29312658309936523 seconds for one epoch ---
--- 2.142585515975952 seconds for one epoch ---
--- 0.3044700622558594 seconds for one epoch ---
--- 2.1473872661590576 seconds for one epoch ---
--- 0.2925591468811035 seconds for one epoch ---
--- 2.124891996383667 seconds for one epoch ---
--- 0.30251169204711914 seconds for one epoch ---
--- 2.145904064178467 seconds for one epoch ---
--- 0.29474353790283203 seconds for one epoch ---
--- 2.128363847732544 seconds for one epoch ---
--- 0.28536152839660645 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26677560806274414 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2306.0869140625, (795.4516, 3.7457588, 1506.8896, 0.0)
   validation loss 866.59228515625, (592.11115, 0.35517496, 274.126, 0.0)
decoder loss ratio: 22939.413708, decoder SINDy loss  ratio: 0.591740
--- 0.29526281356811523 seconds for one epoch ---
--- 2.143385410308838 seconds for one epoch ---
--- 0.28763842582702637 seconds for one epoch ---
--- 2.1204535961151123 seconds for one epoch ---
--- 0.305647611618042 seconds for one epoch ---
--- 2.1203718185424805 seconds for one epoch ---
--- 0.29810142517089844 seconds for one epoch ---
--- 2.138477087020874 seconds for one epoch ---
--- 0.29999589920043945 seconds for one epoch ---
--- 2.129964828491211 seconds for one epoch ---
--- 0.29833221435546875 seconds for one epoch ---
--- 2.128361940383911 seconds for one epoch ---
--- 0.3004162311553955 seconds for one epoch ---
--- 2.1096949577331543 seconds for one epoch ---
--- 0.29845452308654785 seconds for one epoch ---
--- 2.1130385398864746 seconds for one epoch ---
--- 0.2911214828491211 seconds for one epoch ---
--- 2.1208558082580566 seconds for one epoch ---
--- 0.29888463020324707 seconds for one epoch ---
--- 2.1862659454345703 seconds for one epoch ---
--- 0.298372745513916 seconds for one epoch ---
--- 2.153825521469116 seconds for one epoch ---
--- 0.6729187965393066 seconds for one epoch ---
--- 2.1611340045928955 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2881205081939697 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4879.3994140625, (1884.4835, 2.6334505, 2992.2827, 0.0)
   validation loss 884.004150390625, (552.00745, 0.30874023, 331.688, 0.0)
decoder loss ratio: 21385.726796, decoder SINDy loss  ratio: 0.715995
--- 0.2625160217285156 seconds for one epoch ---
--- 0.2980835437774658 seconds for one epoch ---
--- 2.169731378555298 seconds for one epoch ---
--- 0.30614161491394043 seconds for one epoch ---
--- 2.1592609882354736 seconds for one epoch ---
--- 0.297199010848999 seconds for one epoch ---
--- 2.141232490539551 seconds for one epoch ---
--- 0.2782101631164551 seconds for one epoch ---
--- 2.191304922103882 seconds for one epoch ---
--- 0.2908294200897217 seconds for one epoch ---
--- 2.1841440200805664 seconds for one epoch ---
--- 0.2942061424255371 seconds for one epoch ---
--- 2.148913860321045 seconds for one epoch ---
--- 0.295229434967041 seconds for one epoch ---
--- 2.145697832107544 seconds for one epoch ---
--- 0.28208255767822266 seconds for one epoch ---
--- 2.148298978805542 seconds for one epoch ---
--- 0.2876408100128174 seconds for one epoch ---
--- 2.1673762798309326 seconds for one epoch ---
--- 0.28826022148132324 seconds for one epoch ---
--- 2.140444755554199 seconds for one epoch ---
--- 0.29880213737487793 seconds for one epoch ---
--- 2.1402108669281006 seconds for one epoch ---
--- 0.29501938819885254 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24159646034240723 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3059.42041015625, (1252.1655, 1.7242539, 1805.5306, 0.0)
   validation loss 692.0272216796875, (394.49405, 0.34812403, 297.18503, 0.0)
decoder loss ratio: 15283.384333, decoder SINDy loss  ratio: 0.641516
--- 0.29865264892578125 seconds for one epoch ---
--- 2.1492371559143066 seconds for one epoch ---
--- 0.3003249168395996 seconds for one epoch ---
--- 2.1392972469329834 seconds for one epoch ---
--- 0.2815229892730713 seconds for one epoch ---
--- 2.195931911468506 seconds for one epoch ---
--- 0.29902172088623047 seconds for one epoch ---
--- 2.193959951400757 seconds for one epoch ---
--- 0.2979736328125 seconds for one epoch ---
--- 2.204296350479126 seconds for one epoch ---
--- 0.29927515983581543 seconds for one epoch ---
--- 2.2213351726531982 seconds for one epoch ---
--- 0.29373741149902344 seconds for one epoch ---
--- 2.1557440757751465 seconds for one epoch ---
--- 0.30251574516296387 seconds for one epoch ---
--- 2.201996088027954 seconds for one epoch ---
--- 0.3012363910675049 seconds for one epoch ---
--- 2.2213525772094727 seconds for one epoch ---
--- 0.2946488857269287 seconds for one epoch ---
--- 2.183387517929077 seconds for one epoch ---
--- 0.30119895935058594 seconds for one epoch ---
--- 2.192533493041992 seconds for one epoch ---
--- 0.29595494270324707 seconds for one epoch ---
--- 2.2149834632873535 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2846944332122803 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3384.4443359375, (1097.6868, 2.3656344, 2284.392, 0.0)
   validation loss 950.306396484375, (654.95105, 0.38431153, 294.971, 0.0)
decoder loss ratio: 25373.940714, decoder SINDy loss  ratio: 0.636736
--- 0.2606532573699951 seconds for one epoch ---
--- 0.29219627380371094 seconds for one epoch ---
--- 2.202115297317505 seconds for one epoch ---
--- 0.2959432601928711 seconds for one epoch ---
--- 2.2090530395507812 seconds for one epoch ---
--- 0.316967248916626 seconds for one epoch ---
--- 2.221566677093506 seconds for one epoch ---
--- 0.2921571731567383 seconds for one epoch ---
--- 2.1905007362365723 seconds for one epoch ---
--- 0.2921891212463379 seconds for one epoch ---
--- 2.21504282951355 seconds for one epoch ---
--- 0.30259084701538086 seconds for one epoch ---
--- 2.197270393371582 seconds for one epoch ---
--- 0.30234289169311523 seconds for one epoch ---
--- 2.2261669635772705 seconds for one epoch ---
--- 0.28804850578308105 seconds for one epoch ---
--- 2.2067370414733887 seconds for one epoch ---
--- 0.300382137298584 seconds for one epoch ---
--- 2.214627742767334 seconds for one epoch ---
--- 0.29615044593811035 seconds for one epoch ---
--- 2.2176690101623535 seconds for one epoch ---
--- 0.2985341548919678 seconds for one epoch ---
--- 2.228912830352783 seconds for one epoch ---
--- 0.30023741722106934 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2720341682434082 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2912.68505859375, (1070.8958, 2.6380336, 1839.1511, 0.0)
   validation loss 1393.10791015625, (1102.1425, 0.36493093, 290.6004, 0.0)
decoder loss ratio: 42698.912151, decoder SINDy loss  ratio: 0.627302
--- 0.32620859146118164 seconds for one epoch ---
--- 2.248011827468872 seconds for one epoch ---
--- 0.35506391525268555 seconds for one epoch ---
--- 2.2038230895996094 seconds for one epoch ---
--- 0.32105326652526855 seconds for one epoch ---
--- 2.247657537460327 seconds for one epoch ---
--- 0.3090071678161621 seconds for one epoch ---
--- 2.1928391456604004 seconds for one epoch ---
--- 0.2868497371673584 seconds for one epoch ---
--- 2.2065882682800293 seconds for one epoch ---
--- 0.2971510887145996 seconds for one epoch ---
--- 2.1994879245758057 seconds for one epoch ---
--- 0.29979801177978516 seconds for one epoch ---
--- 2.175299644470215 seconds for one epoch ---
--- 0.3015573024749756 seconds for one epoch ---
--- 2.1876089572906494 seconds for one epoch ---
--- 0.2996103763580322 seconds for one epoch ---
--- 2.1917121410369873 seconds for one epoch ---
--- 0.2934753894805908 seconds for one epoch ---
--- 2.186511278152466 seconds for one epoch ---
--- 0.2904164791107178 seconds for one epoch ---
--- 2.215688943862915 seconds for one epoch ---
--- 0.29358744621276855 seconds for one epoch ---
--- 2.1918797492980957 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29266858100891113 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2169.37841796875, (909.77484, 1.0468885, 1258.5568, 0.0)
   validation loss 675.3114624023438, (379.81458, 0.33792025, 295.15897, 0.0)
decoder loss ratio: 14714.676030, decoder SINDy loss  ratio: 0.637142
--- 1.0155653953552246 seconds for one epoch ---
--- 0.30929017066955566 seconds for one epoch ---
--- 2.2397356033325195 seconds for one epoch ---
--- 0.30236005783081055 seconds for one epoch ---
--- 2.199028968811035 seconds for one epoch ---
--- 0.29300475120544434 seconds for one epoch ---
--- 2.2080864906311035 seconds for one epoch ---
--- 0.28551292419433594 seconds for one epoch ---
--- 2.2052125930786133 seconds for one epoch ---
--- 0.2964596748352051 seconds for one epoch ---
--- 2.187958240509033 seconds for one epoch ---
--- 0.3007979393005371 seconds for one epoch ---
--- 2.204167604446411 seconds for one epoch ---
--- 0.2952566146850586 seconds for one epoch ---
--- 2.212674379348755 seconds for one epoch ---
--- 0.29662394523620605 seconds for one epoch ---
--- 2.211824655532837 seconds for one epoch ---
--- 0.28246307373046875 seconds for one epoch ---
--- 2.1938087940216064 seconds for one epoch ---
--- 0.294189453125 seconds for one epoch ---
--- 2.2084145545959473 seconds for one epoch ---
--- 0.29955577850341797 seconds for one epoch ---
--- 2.1924843788146973 seconds for one epoch ---
--- 0.29577016830444336 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2597367763519287 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2387.869873046875, (1466.3214, 1.6925943, 919.8558, 0.0)
   validation loss 898.775390625, (571.80054, 0.28760538, 326.6873, 0.0)
decoder loss ratio: 22152.545497, decoder SINDy loss  ratio: 0.705200
--- 0.3009157180786133 seconds for one epoch ---
--- 2.222048759460449 seconds for one epoch ---
--- 0.29502105712890625 seconds for one epoch ---
--- 2.21972918510437 seconds for one epoch ---
--- 0.29142260551452637 seconds for one epoch ---
--- 2.200140953063965 seconds for one epoch ---
--- 0.28954267501831055 seconds for one epoch ---
--- 2.2466237545013428 seconds for one epoch ---
--- 0.29903674125671387 seconds for one epoch ---
--- 2.2210264205932617 seconds for one epoch ---
--- 0.29910922050476074 seconds for one epoch ---
--- 2.211721181869507 seconds for one epoch ---
--- 0.2957725524902344 seconds for one epoch ---
--- 2.2262179851531982 seconds for one epoch ---
--- 0.2950923442840576 seconds for one epoch ---
--- 2.2335779666900635 seconds for one epoch ---
--- 0.2870783805847168 seconds for one epoch ---
--- 2.2187235355377197 seconds for one epoch ---
--- 0.295133113861084 seconds for one epoch ---
--- 2.198349714279175 seconds for one epoch ---
--- 0.2948579788208008 seconds for one epoch ---
--- 2.226196050643921 seconds for one epoch ---
--- 0.28972792625427246 seconds for one epoch ---
--- 2.2499947547912598 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29883503913879395 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3333.303466796875, (1983.5195, 2.6925738, 1347.0913, 0.0)
   validation loss 911.4863891601562, (563.5825, 0.36597532, 347.5379, 0.0)
decoder loss ratio: 21834.165229, decoder SINDy loss  ratio: 0.750209
--- 0.26293158531188965 seconds for one epoch ---
--- 0.2900724411010742 seconds for one epoch ---
--- 2.2631661891937256 seconds for one epoch ---
--- 0.29609227180480957 seconds for one epoch ---
--- 2.260194778442383 seconds for one epoch ---
--- 0.3018615245819092 seconds for one epoch ---
--- 2.2264811992645264 seconds for one epoch ---
--- 0.3076000213623047 seconds for one epoch ---
--- 2.2499704360961914 seconds for one epoch ---
--- 0.3179585933685303 seconds for one epoch ---
--- 2.233337879180908 seconds for one epoch ---
--- 0.31084489822387695 seconds for one epoch ---
--- 2.2281672954559326 seconds for one epoch ---
--- 0.30134034156799316 seconds for one epoch ---
--- 2.2358105182647705 seconds for one epoch ---
--- 0.2960851192474365 seconds for one epoch ---
--- 2.24845814704895 seconds for one epoch ---
--- 0.3026556968688965 seconds for one epoch ---
--- 2.210692882537842 seconds for one epoch ---
--- 0.3002908229827881 seconds for one epoch ---
--- 2.2305102348327637 seconds for one epoch ---
--- 0.30144190788269043 seconds for one epoch ---
--- 2.235935926437378 seconds for one epoch ---
--- 0.3162834644317627 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2620267868041992 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3231.43505859375, (1378.12, 3.6001124, 1849.7148, 0.0)
   validation loss 883.1981201171875, (604.2373, 0.4142463, 278.5466, 0.0)
decoder loss ratio: 23409.202186, decoder SINDy loss  ratio: 0.601282
--- 0.31726741790771484 seconds for one epoch ---
--- 2.314201593399048 seconds for one epoch ---
--- 0.3238382339477539 seconds for one epoch ---
--- 2.2751834392547607 seconds for one epoch ---
--- 0.31789374351501465 seconds for one epoch ---
--- 2.2679173946380615 seconds for one epoch ---
--- 0.30892443656921387 seconds for one epoch ---
--- 2.2636077404022217 seconds for one epoch ---
--- 0.307326078414917 seconds for one epoch ---
--- 2.269383430480957 seconds for one epoch ---
--- 0.3022291660308838 seconds for one epoch ---
--- 2.2649478912353516 seconds for one epoch ---
--- 0.29495954513549805 seconds for one epoch ---
--- 2.2342467308044434 seconds for one epoch ---
--- 0.2924153804779053 seconds for one epoch ---
--- 2.2510788440704346 seconds for one epoch ---
--- 0.2852926254272461 seconds for one epoch ---
--- 2.23856258392334 seconds for one epoch ---
--- 0.2928628921508789 seconds for one epoch ---
--- 2.2480576038360596 seconds for one epoch ---
--- 0.2953462600708008 seconds for one epoch ---
--- 2.2301278114318848 seconds for one epoch ---
--- 0.29259490966796875 seconds for one epoch ---
--- 2.2466588020324707 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28015613555908203 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3863.755615234375, (916.19867, 0.76125675, 2946.7957, 0.0)
   validation loss 890.599365234375, (611.6363, 0.35782185, 278.60526, 0.0)
decoder loss ratio: 23695.851780, decoder SINDy loss  ratio: 0.601409
THRESHOLDING: 0 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1103.330322265625, (537.37317, 0.39245498, 565.56476, 0.0)
   validation loss 721.9290771484375, (433.25162, 0.28205723, 288.3954, 0.0)
decoder loss ratio: 16784.919817, decoder SINDy loss  ratio: 0.622542
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.9569091796875, (298.56192, 0.28738832, 487.10764, 0.0)
   validation loss 488.77777099609375, (224.02742, 0.1920605, 264.5583, 0.0)
decoder loss ratio: 8679.211181, decoder SINDy loss  ratio: 0.571086
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.4744262695312, (258.3051, 0.23767094, 466.93164, 0.0)
   validation loss 457.09661865234375, (199.87752, 0.20645805, 257.01266, 0.0)
decoder loss ratio: 7743.602038, decoder SINDy loss  ratio: 0.554798
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 847.8782958984375, (377.3559, 0.19189227, 470.3305, 0.0)
   validation loss 587.6239624023438, (326.6943, 0.2097103, 260.71994, 0.0)
decoder loss ratio: 12656.704558, decoder SINDy loss  ratio: 0.562801
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.4155883789062, (273.1486, 0.18288605, 414.0841, 0.0)
   validation loss 470.8463134765625, (229.6449, 0.20699905, 240.99443, 0.0)
decoder loss ratio: 8896.842009, decoder SINDy loss  ratio: 0.520220
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.7774658203125, (311.66016, 0.17751938, 411.93976, 0.0)
   validation loss 466.1658020019531, (226.65073, 0.20676179, 239.30832, 0.0)
decoder loss ratio: 8780.842621, decoder SINDy loss  ratio: 0.516581
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.2913208007812, (300.72183, 0.17946504, 401.39, 0.0)
   validation loss 473.43048095703125, (237.18431, 0.1998509, 236.04633, 0.0)
decoder loss ratio: 9188.931975, decoder SINDy loss  ratio: 0.509539
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.904296875, (381.86948, 0.17690076, 391.85788, 0.0)
   validation loss 555.574951171875, (320.4178, 0.19661957, 234.96053, 0.0)
decoder loss ratio: 12413.541286, decoder SINDy loss  ratio: 0.507195
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.04638671875, (459.88022, 0.17274123, 388.9934, 0.0)
   validation loss 603.132568359375, (368.2196, 0.19752775, 234.71545, 0.0)
decoder loss ratio: 14265.466735, decoder SINDy loss  ratio: 0.506666
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 937.4518432617188, (554.0898, 0.16760722, 383.19446, 0.0)
   validation loss 701.70166015625, (465.13498, 0.19719066, 236.36948, 0.0)
decoder loss ratio: 18020.136606, decoder SINDy loss  ratio: 0.510237
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1116.102783203125, (733.7519, 0.16391362, 382.1869, 0.0)
   validation loss 875.5283813476562, (632.556, 0.19084561, 242.78148, 0.0)
decoder loss ratio: 24506.318778, decoder SINDy loss  ratio: 0.524078
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.0638427734375, (458.131, 0.16248623, 382.77036, 0.0)
   validation loss 607.3250122070312, (371.85126, 0.1954677, 235.2783, 0.0)
decoder loss ratio: 14406.163271, decoder SINDy loss  ratio: 0.507881
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.0423583984375, (372.1012, 0.16297182, 385.7782, 0.0)
   validation loss 532.7047119140625, (297.89322, 0.19838388, 234.6131, 0.0)
decoder loss ratio: 11540.900469, decoder SINDy loss  ratio: 0.506445
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.1172485351562, (339.19888, 0.17765148, 392.74072, 0.0)
   validation loss 485.7996826171875, (250.33545, 0.19546376, 235.26877, 0.0)
decoder loss ratio: 9698.429904, decoder SINDy loss  ratio: 0.507861
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.147216796875, (461.45508, 0.16236109, 379.52982, 0.0)
   validation loss 622.3792114257812, (386.2166, 0.19879086, 235.96379, 0.0)
decoder loss ratio: 14962.702119, decoder SINDy loss  ratio: 0.509361
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.7841796875, (327.27533, 0.16043362, 386.34845, 0.0)
   validation loss 493.0527038574219, (257.93588, 0.20210654, 234.9147, 0.0)
decoder loss ratio: 9992.883887, decoder SINDy loss  ratio: 0.507096
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 947.8330078125, (570.13745, 0.15971158, 377.5358, 0.0)
   validation loss 706.6321411132812, (468.68213, 0.20360759, 237.74638, 0.0)
decoder loss ratio: 18157.559342, decoder SINDy loss  ratio: 0.513209
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.3507080078125, (370.0112, 0.1626506, 383.17685, 0.0)
   validation loss 526.2930297851562, (291.46695, 0.20606513, 234.62001, 0.0)
decoder loss ratio: 11291.935631, decoder SINDy loss  ratio: 0.506460
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.7735595703125, (375.4272, 0.16442612, 382.18195, 0.0)
   validation loss 531.2560424804688, (296.28564, 0.20768715, 234.76273, 0.0)
decoder loss ratio: 11478.620244, decoder SINDy loss  ratio: 0.506768
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.1317138671875, (410.34897, 0.1622485, 379.62045, 0.0)
   validation loss 563.8717041015625, (328.20493, 0.20900771, 235.45776, 0.0)
decoder loss ratio: 12715.228604, decoder SINDy loss  ratio: 0.508269
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.6162109375, (336.0654, 0.1631538, 384.3877, 0.0)
   validation loss 495.0186767578125, (260.24835, 0.20996635, 234.56035, 0.0)
decoder loss ratio: 10082.472969, decoder SINDy loss  ratio: 0.506332
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.7320556640625, (408.23615, 0.16134526, 388.3346, 0.0)
   validation loss 532.1878051757812, (293.0433, 0.20384516, 238.94066, 0.0)
decoder loss ratio: 11353.006360, decoder SINDy loss  ratio: 0.515787
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1070.628173828125, (687.89136, 0.17113894, 382.5657, 0.0)
   validation loss 802.6400146484375, (559.1818, 0.21192971, 243.24626, 0.0)
decoder loss ratio: 21663.674634, decoder SINDy loss  ratio: 0.525081
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1095.134765625, (639.46265, 0.16647944, 455.50568, 0.0)
   validation loss 894.6668701171875, (632.7272, 0.20568603, 261.73398, 0.0)
decoder loss ratio: 24512.949139, decoder SINDy loss  ratio: 0.564990
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.3929443359375, (246.7033, 0.17588206, 429.51376, 0.0)
   validation loss 412.66510009765625, (168.78618, 0.21737997, 243.66154, 0.0)
decoder loss ratio: 6539.069584, decoder SINDy loss  ratio: 0.525978
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 925.9939575195312, (460.1379, 0.16880375, 465.68726, 0.0)
   validation loss 667.2754516601562, (406.0678, 0.21182898, 260.99582, 0.0)
decoder loss ratio: 15731.771926, decoder SINDy loss  ratio: 0.563396
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1462.022705078125, (1086.1984, 0.16414529, 375.66016, 0.0)
   validation loss 1180.236083984375, (931.5881, 0.21676686, 248.43123, 0.0)
decoder loss ratio: 36091.339284, decoder SINDy loss  ratio: 0.536274
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1533.7744140625, (1137.1, 0.15959918, 396.51495, 0.0)
   validation loss 1185.4217529296875, (926.89343, 0.214179, 258.31415, 0.0)
decoder loss ratio: 35909.460737, decoder SINDy loss  ratio: 0.557607
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 848.0697021484375, (472.16248, 0.16555254, 375.74164, 0.0)
   validation loss 610.4918823242188, (375.95355, 0.2166259, 234.3217, 0.0)
decoder loss ratio: 14565.093298, decoder SINDy loss  ratio: 0.505816
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.4334716796875, (320.07294, 0.16515619, 384.19534, 0.0)
   validation loss 467.6824951171875, (234.27411, 0.21798672, 233.1904, 0.0)
decoder loss ratio: 9076.185696, decoder SINDy loss  ratio: 0.503374
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.5120849609375, (218.34222, 0.16409084, 403.00574, 0.0)
   validation loss 391.3084716796875, (154.27429, 0.21760055, 236.81657, 0.0)
decoder loss ratio: 5976.853904, decoder SINDy loss  ratio: 0.511202
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.71875, (349.6824, 0.16090891, 380.8754, 0.0)
   validation loss 495.10675048828125, (261.4972, 0.21971923, 233.38982, 0.0)
decoder loss ratio: 10130.855212, decoder SINDy loss  ratio: 0.503805
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.8876342773438, (220.4067, 0.1637511, 404.31717, 0.0)
   validation loss 391.18939208984375, (153.8758, 0.21956263, 237.09402, 0.0)
decoder loss ratio: 5961.415379, decoder SINDy loss  ratio: 0.511801
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.2874755859375, (289.63556, 0.17210752, 388.4798, 0.0)
   validation loss 447.3816833496094, (214.64786, 0.220451, 232.51338, 0.0)
decoder loss ratio: 8315.830651, decoder SINDy loss  ratio: 0.501913
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.1983642578125, (259.86017, 0.17074877, 429.16742, 0.0)
   validation loss 453.3502502441406, (208.69937, 0.22087514, 244.43001, 0.0)
decoder loss ratio: 8085.375964, decoder SINDy loss  ratio: 0.527637
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 859.78173828125, (483.3206, 0.16139713, 376.2997, 0.0)
   validation loss 614.1123046875, (378.40283, 0.21843469, 235.49101, 0.0)
decoder loss ratio: 14659.982649, decoder SINDy loss  ratio: 0.508340
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.1717529296875, (305.76917, 0.16755448, 384.23502, 0.0)
   validation loss 456.6180419921875, (224.32968, 0.22163159, 232.06674, 0.0)
decoder loss ratio: 8690.921311, decoder SINDy loss  ratio: 0.500949
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.10986328125, (216.80411, 0.16425043, 409.1415, 0.0)
   validation loss 394.6619567871094, (156.20726, 0.2215268, 238.23317, 0.0)
decoder loss ratio: 6051.740445, decoder SINDy loss  ratio: 0.514260
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 886.207275390625, (512.80084, 0.16218932, 373.24426, 0.0)
   validation loss 633.8687744140625, (400.53183, 0.22351396, 233.11345, 0.0)
decoder loss ratio: 15517.298442, decoder SINDy loss  ratio: 0.503208
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.9302978515625, (221.88177, 0.16239302, 415.88614, 0.0)
   validation loss 405.87066650390625, (165.32141, 0.22144608, 240.32782, 0.0)
decoder loss ratio: 6404.838478, decoder SINDy loss  ratio: 0.518781
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.5390014648438, (219.26788, 0.15828648, 404.11282, 0.0)
   validation loss 390.55926513671875, (153.09167, 0.22112586, 237.24644, 0.0)
decoder loss ratio: 5931.037261, decoder SINDy loss  ratio: 0.512130
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.2011108398438, (279.9421, 0.16368943, 436.0953, 0.0)
   validation loss 458.8072509765625, (211.72432, 0.22399402, 246.85895, 0.0)
decoder loss ratio: 8202.567705, decoder SINDy loss  ratio: 0.532880
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1044.0980224609375, (674.93616, 0.16128354, 369.00064, 0.0)
   validation loss 797.43994140625, (562.9295, 0.2286498, 234.2818, 0.0)
decoder loss ratio: 21808.866289, decoder SINDy loss  ratio: 0.505730
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.9319458007812, (408.1949, 0.16099487, 379.57608, 0.0)
   validation loss 548.787109375, (316.24884, 0.22904667, 232.30923, 0.0)
decoder loss ratio: 12252.029107, decoder SINDy loss  ratio: 0.501472
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.61474609375, (526.11053, 0.15361252, 376.35056, 0.0)
   validation loss 632.0550537109375, (394.7763, 0.22214086, 237.05664, 0.0)
decoder loss ratio: 15294.319462, decoder SINDy loss  ratio: 0.511720
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.6705932617188, (229.15302, 0.16331269, 413.35428, 0.0)
   validation loss 428.7218017578125, (187.98073, 0.22380915, 240.51724, 0.0)
decoder loss ratio: 7282.699757, decoder SINDy loss  ratio: 0.519190
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 805.3310546875, (423.10257, 0.15804313, 382.07047, 0.0)
   validation loss 537.6860961914062, (301.5877, 0.2222897, 235.87611, 0.0)
decoder loss ratio: 11684.031369, decoder SINDy loss  ratio: 0.509172
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1352.73681640625, (841.5204, 0.15809241, 511.05832, 0.0)
   validation loss 1073.314208984375, (791.2999, 0.2222762, 281.79196, 0.0)
decoder loss ratio: 30656.332920, decoder SINDy loss  ratio: 0.608288
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 801.7593994140625, (427.24142, 0.15535957, 374.36264, 0.0)
   validation loss 550.4861450195312, (318.6776, 0.2263166, 231.5822, 0.0)
decoder loss ratio: 12346.123949, decoder SINDy loss  ratio: 0.499903
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.8406982421875, (229.87404, 0.15175255, 395.81488, 0.0)
   validation loss 395.389404296875, (160.17793, 0.22532238, 234.98616, 0.0)
decoder loss ratio: 6205.571195, decoder SINDy loss  ratio: 0.507251
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.1729125976562, (356.582, 0.15136677, 378.43954, 0.0)
   validation loss 490.84197998046875, (258.4146, 0.22664721, 232.20073, 0.0)
decoder loss ratio: 10011.430689, decoder SINDy loss  ratio: 0.501238
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.3516845703125, (210.0746, 0.15562035, 408.12146, 0.0)
   validation loss 387.4907531738281, (149.54686, 0.22534521, 237.71855, 0.0)
decoder loss ratio: 5793.704971, decoder SINDy loss  ratio: 0.513149
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.6019287109375, (285.82645, 0.15654364, 386.6189, 0.0)
   validation loss 431.1007080078125, (198.36305, 0.22639574, 232.51128, 0.0)
decoder loss ratio: 7684.929022, decoder SINDy loss  ratio: 0.501908
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.3267822265625, (229.8719, 0.15204729, 395.30283, 0.0)
   validation loss 394.79840087890625, (160.01036, 0.22594696, 234.5621, 0.0)
decoder loss ratio: 6199.079164, decoder SINDy loss  ratio: 0.506335
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.8676147460938, (322.76065, 0.15250383, 380.95447, 0.0)
   validation loss 460.53948974609375, (228.40184, 0.22656952, 231.9111, 0.0)
decoder loss ratio: 8848.683813, decoder SINDy loss  ratio: 0.500613
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.6644287109375, (296.06778, 0.1515578, 383.44513, 0.0)
   validation loss 445.84625244140625, (213.03928, 0.22782527, 232.57913, 0.0)
decoder loss ratio: 8253.511409, decoder SINDy loss  ratio: 0.502055
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 955.41943359375, (584.1526, 0.14926581, 371.11752, 0.0)
   validation loss 687.7623291015625, (452.1237, 0.22628291, 235.41232, 0.0)
decoder loss ratio: 17516.056584, decoder SINDy loss  ratio: 0.508171
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.9490966796875, (232.33609, 0.15383893, 393.45914, 0.0)
   validation loss 396.0685729980469, (161.9309, 0.22784795, 233.90984, 0.0)
decoder loss ratio: 6273.483917, decoder SINDy loss  ratio: 0.504927
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1079.4188232421875, (711.47034, 0.15145095, 367.79703, 0.0)
   validation loss 810.9793701171875, (573.3162, 0.22816393, 237.43498, 0.0)
decoder loss ratio: 22211.265805, decoder SINDy loss  ratio: 0.512537
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.2464599609375, (280.0582, 0.15309826, 431.0352, 0.0)
   validation loss 479.91900634765625, (233.07451, 0.22535576, 246.61914, 0.0)
decoder loss ratio: 9029.711101, decoder SINDy loss  ratio: 0.532362
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.5767822265625, (293.80472, 0.15764749, 431.61444, 0.0)
   validation loss 507.47186279296875, (259.77762, 0.224776, 247.4695, 0.0)
decoder loss ratio: 10064.235931, decoder SINDy loss  ratio: 0.534198
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.4144897460938, (237.5634, 0.15271091, 388.6984, 0.0)
   validation loss 399.70159912109375, (166.50621, 0.22755222, 232.96782, 0.0)
decoder loss ratio: 6450.739656, decoder SINDy loss  ratio: 0.502894
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.658203125, (480.4403, 0.1513302, 372.0666, 0.0)
   validation loss 596.53369140625, (364.0421, 0.22778144, 232.26378, 0.0)
decoder loss ratio: 14103.623511, decoder SINDy loss  ratio: 0.501374
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.1475219726562, (220.6029, 0.15138984, 411.39322, 0.0)
   validation loss 402.00836181640625, (162.58913, 0.22659257, 239.19263, 0.0)
decoder loss ratio: 6298.985031, decoder SINDy loss  ratio: 0.516331
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.3302612304688, (312.23373, 0.15271375, 381.94382, 0.0)
   validation loss 450.7021484375, (218.63821, 0.22810136, 231.83585, 0.0)
decoder loss ratio: 8470.423987, decoder SINDy loss  ratio: 0.500450
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.2374267578125, (221.23291, 0.15349573, 400.851, 0.0)
   validation loss 389.329833984375, (153.44182, 0.22756447, 235.66043, 0.0)
decoder loss ratio: 5944.602425, decoder SINDy loss  ratio: 0.508706
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.2603759765625, (288.9989, 0.15442275, 385.10706, 0.0)
   validation loss 432.0938415527344, (199.92656, 0.22828344, 231.939, 0.0)
decoder loss ratio: 7745.502001, decoder SINDy loss  ratio: 0.500673
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.5706787109375, (338.37186, 0.15409763, 440.0447, 0.0)
   validation loss 550.2841186523438, (299.6593, 0.22434242, 250.40048, 0.0)
decoder loss ratio: 11609.321582, decoder SINDy loss  ratio: 0.540525
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.26220703125, (240.49284, 0.15260923, 390.61676, 0.0)
   validation loss 395.1465148925781, (161.86891, 0.22659189, 233.05101, 0.0)
decoder loss ratio: 6271.082658, decoder SINDy loss  ratio: 0.503073
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 983.720947265625, (512.87415, 0.15720493, 470.68958, 0.0)
   validation loss 730.13134765625, (466.9885, 0.22668178, 262.91617, 0.0)
decoder loss ratio: 18091.945019, decoder SINDy loss  ratio: 0.567542
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.6875610351562, (375.18292, 0.14943555, 376.3552, 0.0)
   validation loss 500.19842529296875, (268.02896, 0.22708791, 231.94238, 0.0)
decoder loss ratio: 10383.907275, decoder SINDy loss  ratio: 0.500680
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 616.2294921875, (210.54073, 0.15358111, 405.53522, 0.0)
   validation loss 390.3707580566406, (153.26485, 0.2265934, 236.87932, 0.0)
decoder loss ratio: 5937.746245, decoder SINDy loss  ratio: 0.511337
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.2509765625, (234.5607, 0.15555571, 409.5347, 0.0)
   validation loss 431.74951171875, (191.44366, 0.22438556, 240.08145, 0.0)
decoder loss ratio: 7416.859926, decoder SINDy loss  ratio: 0.518250
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.5031127929688, (273.61548, 0.15268989, 426.73495, 0.0)
   validation loss 471.772705078125, (226.69205, 0.22652338, 244.85414, 0.0)
decoder loss ratio: 8782.443460, decoder SINDy loss  ratio: 0.528552
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.1207275390625, (304.22098, 0.15047912, 381.74927, 0.0)
   validation loss 443.1050109863281, (211.388, 0.22811268, 231.48889, 0.0)
decoder loss ratio: 8189.538125, decoder SINDy loss  ratio: 0.499701
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 975.2662353515625, (521.9451, 0.15043479, 453.17065, 0.0)
   validation loss 766.2619018554688, (507.16544, 0.22364701, 258.87283, 0.0)
decoder loss ratio: 19648.469460, decoder SINDy loss  ratio: 0.558813
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1166.892578125, (687.91046, 0.15017885, 478.83185, 0.0)
   validation loss 957.1114501953125, (687.4118, 0.22263867, 269.47696, 0.0)
decoder loss ratio: 26631.526694, decoder SINDy loss  ratio: 0.581704
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1842.193115234375, (1293.0515, 0.1509561, 548.99054, 0.0)
   validation loss 1605.256103515625, (1301.5433, 0.22113344, 303.49155, 0.0)
decoder loss ratio: 50424.048375, decoder SINDy loss  ratio: 0.655129
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.722900390625, (427.4471, 0.15389997, 373.12186, 0.0)
   validation loss 544.881103515625, (313.3465, 0.22777973, 231.3068, 0.0)
decoder loss ratio: 12139.587271, decoder SINDy loss  ratio: 0.499308
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.1298828125, (219.06488, 0.15199797, 398.91302, 0.0)
   validation loss 385.93975830078125, (150.58556, 0.22640632, 235.12779, 0.0)
decoder loss ratio: 5833.945869, decoder SINDy loss  ratio: 0.507556
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.815673828125, (241.03548, 0.15449955, 391.6257, 0.0)
   validation loss 394.6832580566406, (161.69533, 0.22640756, 232.76152, 0.0)
decoder loss ratio: 6264.357713, decoder SINDy loss  ratio: 0.502448
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.447509765625, (247.3452, 0.15758273, 422.9447, 0.0)
   validation loss 425.17803955078125, (182.67458, 0.22739863, 242.27608, 0.0)
decoder loss ratio: 7077.130204, decoder SINDy loss  ratio: 0.522987
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.4195556640625, (389.3662, 0.15344472, 373.8999, 0.0)
   validation loss 512.276611328125, (281.34543, 0.22601408, 230.70517, 0.0)
decoder loss ratio: 10899.810336, decoder SINDy loss  ratio: 0.498010
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 879.3343505859375, (440.62448, 0.15005764, 438.55978, 0.0)
   validation loss 689.314453125, (437.00775, 0.22041708, 252.08629, 0.0)
decoder loss ratio: 16930.438971, decoder SINDy loss  ratio: 0.544164
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.210205078125, (322.6453, 0.15117013, 378.41376, 0.0)
   validation loss 456.3760986328125, (225.22597, 0.22632578, 230.9238, 0.0)
decoder loss ratio: 8725.644987, decoder SINDy loss  ratio: 0.498481
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.911865234375, (213.68306, 0.14918928, 409.07965, 0.0)
   validation loss 397.6084899902344, (159.05077, 0.22495896, 238.33276, 0.0)
decoder loss ratio: 6161.902799, decoder SINDy loss  ratio: 0.514475
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.55859375, (425.7353, 0.14865373, 371.67465, 0.0)
   validation loss 542.3236694335938, (311.06796, 0.22627982, 231.02942, 0.0)
decoder loss ratio: 12051.312911, decoder SINDy loss  ratio: 0.498709
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 606.5992431640625, (207.15422, 0.14867222, 399.29636, 0.0)
   validation loss 382.82171630859375, (147.23569, 0.2253436, 235.3607, 0.0)
decoder loss ratio: 5704.166137, decoder SINDy loss  ratio: 0.508059
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 874.464599609375, (505.22076, 0.1487154, 369.0951, 0.0)
   validation loss 611.068359375, (379.2954, 0.22723562, 231.5457, 0.0)
decoder loss ratio: 14694.562675, decoder SINDy loss  ratio: 0.499824
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.8530883789062, (240.71072, 0.14879493, 419.99356, 0.0)
   validation loss 435.4998474121094, (193.08696, 0.22516134, 242.18773, 0.0)
decoder loss ratio: 7480.524038, decoder SINDy loss  ratio: 0.522796
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.3012084960938, (390.3233, 0.14739348, 372.8305, 0.0)
   validation loss 511.25604248046875, (280.11572, 0.22617795, 230.91414, 0.0)
decoder loss ratio: 10852.169398, decoder SINDy loss  ratio: 0.498461
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 614.6019287109375, (213.43309, 0.15085658, 401.01797, 0.0)
   validation loss 384.4628601074219, (148.52347, 0.22703959, 235.71236, 0.0)
decoder loss ratio: 5754.056999, decoder SINDy loss  ratio: 0.508818
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.2071533203125, (247.91245, 0.14556476, 419.14914, 0.0)
   validation loss 435.62066650390625, (193.62152, 0.22598861, 241.77318, 0.0)
decoder loss ratio: 7501.233865, decoder SINDy loss  ratio: 0.521901
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 810.3363647460938, (440.01056, 0.14755723, 370.17825, 0.0)
   validation loss 557.6008911132812, (326.22058, 0.22889672, 231.15144, 0.0)
decoder loss ratio: 12638.351654, decoder SINDy loss  ratio: 0.498973
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 604.1019287109375, (212.24294, 0.14591669, 391.7131, 0.0)
   validation loss 382.30206298828125, (148.46553, 0.22686005, 233.60966, 0.0)
decoder loss ratio: 5751.812395, decoder SINDy loss  ratio: 0.504279
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 922.3353881835938, (554.4154, 0.1457169, 367.7743, 0.0)
   validation loss 654.6326904296875, (420.2889, 0.227935, 234.11586, 0.0)
decoder loss ratio: 16282.722024, decoder SINDy loss  ratio: 0.505372
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.9954833984375, (210.36548, 0.14653012, 405.48346, 0.0)
   validation loss 391.871826171875, (154.30075, 0.22697255, 237.34409, 0.0)
decoder loss ratio: 5977.878961, decoder SINDy loss  ratio: 0.512341
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 923.2977294921875, (555.50134, 0.14623255, 367.65012, 0.0)
   validation loss 657.242919921875, (423.18164, 0.22847548, 233.83276, 0.0)
decoder loss ratio: 16394.791433, decoder SINDy loss  ratio: 0.504761
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.8350830078125, (227.9772, 0.14639294, 414.71146, 0.0)
   validation loss 416.70086669921875, (176.09122, 0.22658668, 240.38306, 0.0)
decoder loss ratio: 6822.079456, decoder SINDy loss  ratio: 0.518901
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.6246948242188, (367.02612, 0.14672494, 372.45184, 0.0)
   validation loss 494.51300048828125, (263.36395, 0.22824617, 230.92082, 0.0)
decoder loss ratio: 10203.176745, decoder SINDy loss  ratio: 0.498475
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 636.9697265625, (252.25151, 0.14975488, 384.56848, 0.0)
   validation loss 398.9461669921875, (167.08081, 0.22937728, 231.636, 0.0)
decoder loss ratio: 6473.000666, decoder SINDy loss  ratio: 0.500019
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1029.47802734375, (665.0193, 0.14943406, 364.30933, 0.0)
   validation loss 760.326416015625, (527.1388, 0.23231986, 232.95534, 0.0)
decoder loss ratio: 20422.272031, decoder SINDy loss  ratio: 0.502867
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.37744140625, (308.59467, 0.14953183, 439.63327, 0.0)
   validation loss 497.694091796875, (248.50583, 0.22786428, 248.96042, 0.0)
decoder loss ratio: 9627.547235, decoder SINDy loss  ratio: 0.537416
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.0986938476562, (230.02577, 0.1465435, 387.92636, 0.0)
   validation loss 386.90179443359375, (153.83192, 0.22807114, 232.84178, 0.0)
decoder loss ratio: 5959.715817, decoder SINDy loss  ratio: 0.502622
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.60302734375, (330.0535, 0.14607969, 376.40344, 0.0)
   validation loss 465.70556640625, (233.74771, 0.22860502, 231.72923, 0.0)
decoder loss ratio: 9055.792135, decoder SINDy loss  ratio: 0.500220
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.0477294921875, (468.23526, 0.1440416, 370.6684, 0.0)
   validation loss 577.62841796875, (342.72565, 0.22848237, 234.67426, 0.0)
decoder loss ratio: 13277.786562, decoder SINDy loss  ratio: 0.506577
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1168.3575439453125, (797.6767, 0.14427389, 370.5366, 0.0)
   validation loss 866.641845703125, (624.84424, 0.22914821, 241.56848, 0.0)
decoder loss ratio: 24207.550568, decoder SINDy loss  ratio: 0.521460
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1415.68408203125, (898.76764, 0.14310583, 516.7733, 0.0)
   validation loss 1143.1884765625, (858.1657, 0.22520493, 284.7975, 0.0)
decoder loss ratio: 33246.829464, decoder SINDy loss  ratio: 0.614775
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1137.431884765625, (770.4556, 0.1454133, 366.83084, 0.0)
   validation loss 854.330322265625, (614.9255, 0.23065126, 239.17418, 0.0)
decoder loss ratio: 23823.280501, decoder SINDy loss  ratio: 0.516291
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.806396484375, (470.82678, 0.14530452, 370.83432, 0.0)
   validation loss 587.6371459960938, (353.13336, 0.23184428, 234.27194, 0.0)
decoder loss ratio: 13680.999503, decoder SINDy loss  ratio: 0.505709
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.02490234375, (395.99112, 0.14582539, 371.88797, 0.0)
   validation loss 522.2139892578125, (289.277, 0.22946206, 232.7075, 0.0)
decoder loss ratio: 11207.093499, decoder SINDy loss  ratio: 0.502332
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 985.5890502929688, (506.9288, 0.1499002, 478.51035, 0.0)
   validation loss 701.66552734375, (436.95938, 0.22854045, 264.47757, 0.0)
decoder loss ratio: 16928.565019, decoder SINDy loss  ratio: 0.570912
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 921.5106201171875, (551.7812, 0.14461374, 369.58484, 0.0)
   validation loss 649.7373046875, (414.10785, 0.22961885, 235.39987, 0.0)
decoder loss ratio: 16043.256998, decoder SINDy loss  ratio: 0.508144
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 607.40869140625, (211.35066, 0.146657, 395.91135, 0.0)
   validation loss 382.91552734375, (148.1501, 0.22943239, 234.53598, 0.0)
decoder loss ratio: 5739.592101, decoder SINDy loss  ratio: 0.506279
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.0144653320312, (364.00937, 0.14485149, 372.86026, 0.0)
   validation loss 493.839111328125, (262.31763, 0.22982265, 231.29166, 0.0)
decoder loss ratio: 10162.640272, decoder SINDy loss  ratio: 0.499276
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.9666137695312, (231.4045, 0.14785485, 384.41425, 0.0)
   validation loss 387.8076171875, (155.51636, 0.2288091, 232.06247, 0.0)
decoder loss ratio: 6024.973675, decoder SINDy loss  ratio: 0.500939
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.22412109375, (344.20535, 0.1448436, 373.87396, 0.0)
   validation loss 480.2654724121094, (247.72656, 0.23039131, 232.30852, 0.0)
decoder loss ratio: 9597.357103, decoder SINDy loss  ratio: 0.501471
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.9055786132812, (234.75584, 0.14569734, 409.00403, 0.0)
   validation loss 410.342529296875, (172.59978, 0.22894506, 237.5138, 0.0)
decoder loss ratio: 6686.815016, decoder SINDy loss  ratio: 0.512707
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.5680541992188, (487.9607, 0.1484081, 368.45895, 0.0)
   validation loss 610.94091796875, (377.5807, 0.23135258, 233.12885, 0.0)
decoder loss ratio: 14628.131380, decoder SINDy loss  ratio: 0.503241
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.4947509765625, (243.1106, 0.14642607, 418.23776, 0.0)
   validation loss 432.1810607910156, (190.31496, 0.22698711, 241.63911, 0.0)
decoder loss ratio: 7373.131822, decoder SINDy loss  ratio: 0.521612
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 924.6238403320312, (558.1312, 0.14447592, 366.34814, 0.0)
   validation loss 660.9989013671875, (426.3593, 0.22946234, 234.4101, 0.0)
decoder loss ratio: 16517.900015, decoder SINDy loss  ratio: 0.506007
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 608.239501953125, (221.65466, 0.14441067, 386.4404, 0.0)
   validation loss 386.7081604003906, (154.17957, 0.22818075, 232.30042, 0.0)
decoder loss ratio: 5973.184032, decoder SINDy loss  ratio: 0.501453
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.1431884765625, (367.88098, 0.1449724, 371.11722, 0.0)
   validation loss 497.67022705078125, (266.35284, 0.22958869, 231.0878, 0.0)
decoder loss ratio: 10318.971595, decoder SINDy loss  ratio: 0.498836
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 604.79248046875, (212.53581, 0.1484974, 392.10815, 0.0)
   validation loss 388.1477355957031, (153.97815, 0.23022614, 233.93936, 0.0)
decoder loss ratio: 5965.380826, decoder SINDy loss  ratio: 0.504991
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 865.368896484375, (496.55576, 0.14684074, 368.66626, 0.0)
   validation loss 614.4312744140625, (382.07187, 0.23351929, 232.12592, 0.0)
decoder loss ratio: 14802.127507, decoder SINDy loss  ratio: 0.501076
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.0000610351562, (234.57732, 0.14389902, 414.27884, 0.0)
   validation loss 423.1414794921875, (182.39624, 0.22773495, 240.51749, 0.0)
decoder loss ratio: 7066.347000, decoder SINDy loss  ratio: 0.519191
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 817.0152587890625, (449.1507, 0.14509135, 367.7195, 0.0)
   validation loss 571.5263061523438, (338.49142, 0.23071474, 232.80417, 0.0)
decoder loss ratio: 13113.745434, decoder SINDy loss  ratio: 0.502541
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 606.3955078125, (208.15677, 0.1436472, 398.09512, 0.0)
   validation loss 383.3661193847656, (147.95576, 0.2287166, 235.18164, 0.0)
decoder loss ratio: 5732.063190, decoder SINDy loss  ratio: 0.507673
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 965.4988403320312, (599.643, 0.14520745, 365.71063, 0.0)
   validation loss 702.0795288085938, (466.55527, 0.2317035, 235.29257, 0.0)
decoder loss ratio: 18075.161032, decoder SINDy loss  ratio: 0.507912
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.3328247070312, (212.93219, 0.14384086, 405.25677, 0.0)
   validation loss 393.30023193359375, (155.7767, 0.22841701, 237.2951, 0.0)
decoder loss ratio: 6035.059910, decoder SINDy loss  ratio: 0.512235
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.0013427734375, (231.83018, 0.14608462, 388.0251, 0.0)
   validation loss 392.99468994140625, (160.11163, 0.2307266, 232.65233, 0.0)
decoder loss ratio: 6203.002640, decoder SINDy loss  ratio: 0.502213
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.994140625, (347.90378, 0.14325745, 438.9471, 0.0)
   validation loss 556.8355712890625, (306.46176, 0.22655302, 250.14726, 0.0)
decoder loss ratio: 11872.860681, decoder SINDy loss  ratio: 0.539978
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 602.38525390625, (204.93307, 0.14470324, 397.30746, 0.0)
   validation loss 381.2616271972656, (146.02019, 0.22836912, 235.01308, 0.0)
decoder loss ratio: 5657.075561, decoder SINDy loss  ratio: 0.507309
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.24365234375, (266.54416, 0.14458352, 423.55493, 0.0)
   validation loss 463.53985595703125, (219.63626, 0.227458, 243.67613, 0.0)
decoder loss ratio: 8509.090056, decoder SINDy loss  ratio: 0.526009
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.35986328125, (366.27692, 0.147787, 372.93518, 0.0)
   validation loss 498.9253234863281, (268.41306, 0.2307913, 230.28146, 0.0)
decoder loss ratio: 10398.787753, decoder SINDy loss  ratio: 0.497095
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.9812622070312, (375.40652, 0.14711691, 372.4276, 0.0)
   validation loss 504.3923645019531, (273.76886, 0.22950307, 230.39401, 0.0)
decoder loss ratio: 10606.280915, decoder SINDy loss  ratio: 0.497338
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.5510864257812, (215.25514, 0.15197374, 400.14395, 0.0)
   validation loss 402.3155212402344, (166.4641, 0.22847597, 235.62296, 0.0)
decoder loss ratio: 6449.108076, decoder SINDy loss  ratio: 0.508625
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1063.13818359375, (699.0224, 0.1488549, 363.9669, 0.0)
   validation loss 797.094970703125, (562.10345, 0.23211327, 234.75941, 0.0)
decoder loss ratio: 21776.863685, decoder SINDy loss  ratio: 0.506761
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 828.1636962890625, (460.02417, 0.14563598, 367.9939, 0.0)
   validation loss 576.015625, (344.01813, 0.22898161, 231.76851, 0.0)
decoder loss ratio: 13327.859499, decoder SINDy loss  ratio: 0.500305
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.6476440429688, (276.98572, 0.14722626, 378.5147, 0.0)
   validation loss 426.11383056640625, (195.59517, 0.22822389, 230.29044, 0.0)
decoder loss ratio: 7577.696418, decoder SINDy loss  ratio: 0.497114
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.523681640625, (336.76752, 0.14253858, 373.61362, 0.0)
   validation loss 472.14398193359375, (241.43784, 0.2282153, 230.47792, 0.0)
decoder loss ratio: 9353.720909, decoder SINDy loss  ratio: 0.497519
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 616.1861572265625, (230.29134, 0.14748226, 385.74734, 0.0)
   validation loss 385.5347900390625, (153.75363, 0.22851089, 231.55264, 0.0)
decoder loss ratio: 5956.682616, decoder SINDy loss  ratio: 0.499839
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 899.267578125, (531.28326, 0.14384072, 367.84048, 0.0)
   validation loss 640.981201171875, (407.40778, 0.2328053, 233.3406, 0.0)
decoder loss ratio: 15783.684529, decoder SINDy loss  ratio: 0.503699
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1182.13916015625, (813.8097, 0.14418903, 368.18527, 0.0)
   validation loss 881.8614501953125, (640.6731, 0.229621, 240.95876, 0.0)
decoder loss ratio: 24820.787985, decoder SINDy loss  ratio: 0.520143
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 608.738037109375, (214.63445, 0.14462985, 393.95895, 0.0)
   validation loss 381.01007080078125, (147.35185, 0.22783469, 233.4304, 0.0)
decoder loss ratio: 5708.666577, decoder SINDy loss  ratio: 0.503892
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.2764282226562, (306.41544, 0.1448454, 374.71616, 0.0)
   validation loss 448.31878662109375, (217.72789, 0.22873423, 230.36218, 0.0)
decoder loss ratio: 8435.156451, decoder SINDy loss  ratio: 0.497269
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.0889282226562, (287.18375, 0.14559184, 377.75958, 0.0)
   validation loss 431.9200744628906, (201.4925, 0.2279934, 230.19958, 0.0)
decoder loss ratio: 7806.168973, decoder SINDy loss  ratio: 0.496918
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.5386962890625, (329.81265, 0.14803952, 373.578, 0.0)
   validation loss 461.3126220703125, (231.2916, 0.22976747, 229.79124, 0.0)
decoder loss ratio: 8960.637948, decoder SINDy loss  ratio: 0.496037
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.6448974609375, (214.88101, 0.14760086, 390.61627, 0.0)
   validation loss 383.97381591796875, (151.60901, 0.22599997, 232.13882, 0.0)
decoder loss ratio: 5873.596205, decoder SINDy loss  ratio: 0.501104
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 824.1904296875, (370.551, 0.15214553, 453.48724, 0.0)
   validation loss 557.5967407226562, (303.51428, 0.22691518, 253.85555, 0.0)
decoder loss ratio: 11758.670217, decoder SINDy loss  ratio: 0.547983
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 889.2930908203125, (521.56445, 0.15000579, 367.57864, 0.0)
   validation loss 638.6611938476562, (408.445, 0.23125105, 229.98494, 0.0)
decoder loss ratio: 15823.868675, decoder SINDy loss  ratio: 0.496455
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.49951171875, (356.69843, 0.14291784, 438.65817, 0.0)
   validation loss 546.817626953125, (297.8663, 0.22477485, 248.72655, 0.0)
decoder loss ratio: 11539.857677, decoder SINDy loss  ratio: 0.536911
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1647.2567138671875, (1278.0598, 0.14825717, 369.04858, 0.0)
   validation loss 1323.9451904296875, (1074.8442, 0.23304282, 248.86795, 0.0)
decoder loss ratio: 41641.331803, decoder SINDy loss  ratio: 0.537216
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.9698486328125, (331.15643, 0.14370014, 443.6697, 0.0)
   validation loss 519.2120971679688, (268.96692, 0.22693154, 250.01823, 0.0)
decoder loss ratio: 10420.245387, decoder SINDy loss  ratio: 0.539700
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.2930908203125, (283.42584, 0.14388871, 379.7234, 0.0)
   validation loss 428.6107482910156, (197.74835, 0.23018835, 230.6322, 0.0)
decoder loss ratio: 7661.114465, decoder SINDy loss  ratio: 0.497852
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.94921875, (408.70078, 0.14336945, 369.1051, 0.0)
   validation loss 534.6318359375, (303.5942, 0.22972123, 230.8079, 0.0)
decoder loss ratio: 11761.766671, decoder SINDy loss  ratio: 0.498231
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 632.2139282226562, (249.17484, 0.1464963, 382.89258, 0.0)
   validation loss 398.69903564453125, (167.6842, 0.22952163, 230.7853, 0.0)
decoder loss ratio: 6496.377179, decoder SINDy loss  ratio: 0.498183
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.5013427734375, (287.36108, 0.1421097, 379.99817, 0.0)
   validation loss 432.2247314453125, (201.04349, 0.2314352, 230.94981, 0.0)
decoder loss ratio: 7788.773734, decoder SINDy loss  ratio: 0.498538
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 895.784423828125, (527.9951, 0.1424235, 367.64694, 0.0)
   validation loss 638.2581176757812, (404.13, 0.2312315, 233.89688, 0.0)
decoder loss ratio: 15656.697990, decoder SINDy loss  ratio: 0.504899
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 609.642578125, (225.20969, 0.1404695, 384.29245, 0.0)
   validation loss 386.53662109375, (154.73854, 0.2268551, 231.57123, 0.0)
decoder loss ratio: 5994.839703, decoder SINDy loss  ratio: 0.499879
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.919677734375, (380.0197, 0.14074448, 368.75925, 0.0)
   validation loss 509.9527587890625, (278.79364, 0.22894792, 230.93016, 0.0)
decoder loss ratio: 10800.949626, decoder SINDy loss  ratio: 0.498495
params['save_name']
pendulum_2023_10_26_04_58_00_274689
