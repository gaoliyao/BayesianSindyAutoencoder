nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-11-11 07:52:25.647013: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-11-11 07:52:25.654637: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-11-11 07:52:25.656456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564536b26fe0 executing computations on platform Host. Devices:
2023-11-11 07:52:25.656494: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-11-11 07:52:25.658460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-11-11 07:52:25.764891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564536b49950 executing computations on platform CUDA. Devices:
2023-11-11 07:52:25.764955: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-11-11 07:52:25.765936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:19:00.0
2023-11-11 07:52:25.766527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-11 07:52:25.774623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-11-11 07:52:25.778392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-11-11 07:52:25.780360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-11-11 07:52:25.785050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-11-11 07:52:25.788338: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-11-11 07:52:25.797531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-11-11 07:52:25.798597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-11-11 07:52:25.798664: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-11 07:52:25.799249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-11-11 07:52:25.799267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-11-11 07:52:25.799278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-11-11 07:52:25.800255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:19:00.0, compute capability: 7.5)
2023-11-11 07:52:27.062046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 2.0, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.9135499000549316 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 106600.5078125, (100004.01, 0.0088986065, 6578.1733, 2.531782)
   validation loss 89190.71875, (87971.63, 0.010213214, 1200.7593, 2.531782)
decoder loss ratio: 3408173.780627, decoder SINDy loss  ratio: 2.592008
--- 0.2529721260070801 seconds for one epoch ---
--- 0.26444172859191895 seconds for one epoch ---
--- 0.2651815414428711 seconds for one epoch ---
--- 0.27572154998779297 seconds for one epoch ---
--- 0.31626152992248535 seconds for one epoch ---
--- 0.2626326084136963 seconds for one epoch ---
--- 0.3099055290222168 seconds for one epoch ---
--- 0.2852919101715088 seconds for one epoch ---
--- 0.3089146614074707 seconds for one epoch ---
--- 0.2946963310241699 seconds for one epoch ---
--- 0.3113822937011719 seconds for one epoch ---
--- 0.29535531997680664 seconds for one epoch ---
--- 0.3090231418609619 seconds for one epoch ---
--- 0.29561853408813477 seconds for one epoch ---
--- 0.31189441680908203 seconds for one epoch ---
--- 0.29182958602905273 seconds for one epoch ---
--- 0.3268578052520752 seconds for one epoch ---
--- 0.2719902992248535 seconds for one epoch ---
--- 0.31457090377807617 seconds for one epoch ---
--- 0.21434450149536133 seconds for one epoch ---
--- 0.3017096519470215 seconds for one epoch ---
--- 0.28130292892456055 seconds for one epoch ---
--- 0.3138003349304199 seconds for one epoch ---
--- 0.28937458992004395 seconds for one epoch ---
=========================
[[0.7800732 ]
 [0.780213  ]
 [0.78378755]
 [0.7813158 ]
 [0.7788903 ]
 [0.78126717]
 [0.78091145]
 [0.77876395]
 [0.7783646 ]
 [0.7854586 ]
 [0.77913857]]
[[ 0.46352065]
 [ 0.49755192]
 [-1.254777  ]
 [-0.7525106 ]
 [-0.1572258 ]
 [-0.7417165 ]
 [ 0.6616507 ]
 [-0.12235616]
 [ 0.00889508]
 [-1.5542142 ]
 [ 0.22449623]]
--- 0.2474658489227295 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 69157.828125, (58464.547, 176.03386, 10475.388, 2.5317457)
   validation loss 49485.25390625, (48152.273, 23.325066, 1267.8018, 2.5317457)
decoder loss ratio: 1865502.668992, decoder SINDy loss  ratio: 2.736728
--- 0.28637242317199707 seconds for one epoch ---
--- 0.31255125999450684 seconds for one epoch ---
--- 0.27925825119018555 seconds for one epoch ---
--- 0.31240034103393555 seconds for one epoch ---
--- 0.29128026962280273 seconds for one epoch ---
--- 0.30594897270202637 seconds for one epoch ---
--- 0.29306530952453613 seconds for one epoch ---
--- 0.3196985721588135 seconds for one epoch ---
--- 0.2956733703613281 seconds for one epoch ---
--- 0.2992265224456787 seconds for one epoch ---
--- 0.2924032211303711 seconds for one epoch ---
--- 0.26929521560668945 seconds for one epoch ---
--- 0.14355254173278809 seconds for one epoch ---
--- 0.30890798568725586 seconds for one epoch ---
--- 0.24739527702331543 seconds for one epoch ---
--- 0.3508133888244629 seconds for one epoch ---
--- 0.2898094654083252 seconds for one epoch ---
--- 0.3206295967102051 seconds for one epoch ---
--- 0.29025793075561523 seconds for one epoch ---
--- 0.32621288299560547 seconds for one epoch ---
--- 0.2876262664794922 seconds for one epoch ---
--- 0.32485294342041016 seconds for one epoch ---
--- 0.29608750343322754 seconds for one epoch ---
--- 0.3273165225982666 seconds for one epoch ---
=========================
[[0.62892276]
 [0.6230477 ]
 [0.6300959 ]
 [0.62281156]
 [0.6213445 ]
 [0.62900424]
 [0.62367314]
 [0.6214157 ]
 [0.6208201 ]
 [0.62390566]
 [0.6218864 ]]
[[ 1.1231654 ]
 [ 0.36204174]
 [-1.2545234 ]
 [-0.3267757 ]
 [-0.09632365]
 [-1.1324573 ]
 [ 0.45340875]
 [ 0.1079563 ]
 [ 0.00877713]
 [-0.48659608]
 [ 0.18375845]]
--- 0.28569865226745605 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 55358.23828125, (48099.47, 28.335463, 7168.9116, 2.5317285)
   validation loss 42744.16796875, (41514.832, 5.639048, 1162.171, 2.5317285)
decoder loss ratio: 1608356.665809, decoder SINDy loss  ratio: 2.508710
--- 0.2566680908203125 seconds for one epoch ---
--- 0.2690551280975342 seconds for one epoch ---
--- 0.3199491500854492 seconds for one epoch ---
--- 0.28511738777160645 seconds for one epoch ---
--- 0.3282468318939209 seconds for one epoch ---
--- 0.2739992141723633 seconds for one epoch ---
--- 0.3216075897216797 seconds for one epoch ---
--- 0.29088449478149414 seconds for one epoch ---
--- 0.3252542018890381 seconds for one epoch ---
--- 0.2876417636871338 seconds for one epoch ---
--- 0.32662105560302734 seconds for one epoch ---
--- 0.2843136787414551 seconds for one epoch ---
--- 0.3211696147918701 seconds for one epoch ---
--- 0.2727844715118408 seconds for one epoch ---
--- 0.32564806938171387 seconds for one epoch ---
--- 0.37485456466674805 seconds for one epoch ---
--- 0.33593130111694336 seconds for one epoch ---
--- 0.2939591407775879 seconds for one epoch ---
--- 0.3336467742919922 seconds for one epoch ---
--- 0.29160451889038086 seconds for one epoch ---
--- 0.25481486320495605 seconds for one epoch ---
--- 0.1717848777770996 seconds for one epoch ---
--- 0.3368511199951172 seconds for one epoch ---
--- 0.2944967746734619 seconds for one epoch ---
=========================
[[0.50230527]
 [0.49133536]
 [0.49944937]
 [0.48970672]
 [0.4895231 ]
 [0.5058932 ]
 [0.49200213]
 [0.49058962]
 [0.48879772]
 [0.4897681 ]
 [0.49027827]]
[[ 1.3301840e+00]
 [ 3.0324441e-01]
 [-1.0947639e+00]
 [-1.1327577e-01]
 [-9.0956174e-02]
 [-1.6037973e+00]
 [ 3.7734258e-01]
 [ 2.1794179e-01]
 [-9.4937417e-04]
 [ 1.2069289e-01]
 [ 1.8147901e-01]]
--- 0.2609822750091553 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 28322.607421875, (21790.336, 108.50533, 6344.9526, 2.5317369)
   validation loss 19685.771484375, (18506.41, 0.37969005, 1100.1694, 2.5317369)
decoder loss ratio: 716970.457994, decoder SINDy loss  ratio: 2.374870
--- 0.2941122055053711 seconds for one epoch ---
--- 0.3379943370819092 seconds for one epoch ---
--- 0.28461718559265137 seconds for one epoch ---
--- 0.36080431938171387 seconds for one epoch ---
--- 0.28218746185302734 seconds for one epoch ---
--- 0.3273177146911621 seconds for one epoch ---
--- 0.29923319816589355 seconds for one epoch ---
--- 0.3450767993927002 seconds for one epoch ---
--- 0.28775954246520996 seconds for one epoch ---
--- 0.3389148712158203 seconds for one epoch ---
--- 0.2898557186126709 seconds for one epoch ---
--- 0.31056761741638184 seconds for one epoch ---
--- 0.1469728946685791 seconds for one epoch ---
--- 0.3389699459075928 seconds for one epoch ---
--- 0.27222728729248047 seconds for one epoch ---
--- 0.3604927062988281 seconds for one epoch ---
--- 0.29145336151123047 seconds for one epoch ---
--- 0.3394136428833008 seconds for one epoch ---
--- 0.2944777011871338 seconds for one epoch ---
--- 0.3418910503387451 seconds for one epoch ---
--- 0.2974252700805664 seconds for one epoch ---
--- 0.34865689277648926 seconds for one epoch ---
--- 0.303164005279541 seconds for one epoch ---
--- 0.36874866485595703 seconds for one epoch ---
=========================
[[0.40636718]
 [0.39648563]
 [0.40186578]
 [0.39478332]
 [0.3946883 ]
 [0.42331988]
 [0.39784658]
 [0.39659616]
 [0.39442298]
 [0.39618057]
 [0.3967487 ]]
[[ 1.0470268 ]
 [ 0.21385896]
 [-0.69722795]
 [-0.04100626]
 [-0.03102553]
 [-2.103277  ]
 [ 0.34438807]
 [ 0.22472154]
 [-0.00290706]
 [ 0.18370457]
 [ 0.23961706]]
--- 0.3001058101654053 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 21535.0859375, (16536.24, 0.8305013, 4902.0317, 2.5317385)
   validation loss 11594.6640625, (10576.68, 0.3305102, 921.6694, 2.5317385)
decoder loss ratio: 409758.933017, decoder SINDy loss  ratio: 1.989553
--- 0.2771751880645752 seconds for one epoch ---
--- 0.3002352714538574 seconds for one epoch ---
--- 0.27053213119506836 seconds for one epoch ---
--- 0.23258638381958008 seconds for one epoch ---
--- 0.3374640941619873 seconds for one epoch ---
--- 0.28730320930480957 seconds for one epoch ---
--- 0.33940792083740234 seconds for one epoch ---
--- 0.29117345809936523 seconds for one epoch ---
--- 0.36798787117004395 seconds for one epoch ---
--- 0.29206275939941406 seconds for one epoch ---
--- 0.3489222526550293 seconds for one epoch ---
--- 0.28819775581359863 seconds for one epoch ---
--- 0.3470602035522461 seconds for one epoch ---
--- 0.3009378910064697 seconds for one epoch ---
--- 0.35791873931884766 seconds for one epoch ---
--- 0.296558141708374 seconds for one epoch ---
--- 0.35682153701782227 seconds for one epoch ---
--- 0.3020954132080078 seconds for one epoch ---
--- 0.3458542823791504 seconds for one epoch ---
--- 0.17922520637512207 seconds for one epoch ---
--- 0.34408044815063477 seconds for one epoch ---
--- 0.2674694061279297 seconds for one epoch ---
--- 0.3489346504211426 seconds for one epoch ---
--- 0.2828350067138672 seconds for one epoch ---
=========================
[[0.32394496]
 [0.31559595]
 [0.3198901 ]
 [0.3156529 ]
 [0.31528553]
 [0.35663384]
 [0.3182218 ]
 [0.31756455]
 [0.31487885]
 [0.31567484]
 [0.3185328 ]]
[[ 0.74381626]
 [ 0.06943627]
 [-0.4368472 ]
 [ 0.07466262]
 [ 0.04079188]
 [-2.51414   ]
 [ 0.30002257]
 [ 0.24414094]
 [-0.00278145]
 [ 0.07666735]
 [ 0.32609332]]
--- 0.262667179107666 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 20096.0625, (14060.32, 5.897214, 5918.8843, 2.5317452)
   validation loss 9554.9765625, (8672.047, 0.19619954, 771.77246, 2.5317452)
decoder loss ratio: 335970.151273, decoder SINDy loss  ratio: 1.665979
--- 0.2961897850036621 seconds for one epoch ---
--- 0.3368051052093506 seconds for one epoch ---
--- 0.2869291305541992 seconds for one epoch ---
--- 0.3540365695953369 seconds for one epoch ---
--- 0.3011474609375 seconds for one epoch ---
--- 0.34781908988952637 seconds for one epoch ---
--- 0.28085899353027344 seconds for one epoch ---
--- 0.35950565338134766 seconds for one epoch ---
--- 0.2854890823364258 seconds for one epoch ---
--- 0.28266191482543945 seconds for one epoch ---
--- 0.21803998947143555 seconds for one epoch ---
--- 0.35996389389038086 seconds for one epoch ---
--- 0.28839540481567383 seconds for one epoch ---
--- 0.3594496250152588 seconds for one epoch ---
--- 0.2823503017425537 seconds for one epoch ---
--- 0.342177152633667 seconds for one epoch ---
--- 0.2938225269317627 seconds for one epoch ---
--- 0.35781240463256836 seconds for one epoch ---
--- 0.3007540702819824 seconds for one epoch ---
--- 0.3720674514770508 seconds for one epoch ---
--- 0.29796528816223145 seconds for one epoch ---
--- 0.35886526107788086 seconds for one epoch ---
--- 0.2882497310638428 seconds for one epoch ---
--- 0.3462059497833252 seconds for one epoch ---
=========================
[[0.26302412]
 [0.25776914]
 [0.26122433]
 [0.25912976]
 [0.2580183 ]
 [0.31282955]
 [0.26053518]
 [0.26061454]
 [0.25769094]
 [0.25872427]
 [0.2623312 ]]
[[ 0.43323022]
 [-0.01368064]
 [-0.29682496]
 [ 0.12885177]
 [ 0.0351561 ]
 [-2.8943834 ]
 [ 0.24273822]
 [ 0.24900672]
 [-0.0069021 ]
 [-0.09506763]
 [ 0.38150817]]
--- 0.19547176361083984 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14795.6494140625, (11823.643, 69.04358, 2780.048, 2.5317593)
   validation loss 5150.6552734375, (4396.762, 0.09231274, 630.8862, 2.5317593)
decoder loss ratio: 170338.201015, decoder SINDy loss  ratio: 1.361857
--- 0.2442762851715088 seconds for one epoch ---
--- 0.274852991104126 seconds for one epoch ---
--- 0.3660600185394287 seconds for one epoch ---
--- 0.29500913619995117 seconds for one epoch ---
--- 0.35996460914611816 seconds for one epoch ---
--- 0.2765834331512451 seconds for one epoch ---
--- 0.35751819610595703 seconds for one epoch ---
--- 0.2955191135406494 seconds for one epoch ---
--- 0.37486815452575684 seconds for one epoch ---
--- 0.28927087783813477 seconds for one epoch ---
--- 0.379352331161499 seconds for one epoch ---
--- 0.3003106117248535 seconds for one epoch ---
--- 0.38587093353271484 seconds for one epoch ---
--- 0.2931511402130127 seconds for one epoch ---
--- 0.3591732978820801 seconds for one epoch ---
--- 0.23052716255187988 seconds for one epoch ---
--- 0.3789963722229004 seconds for one epoch ---
--- 0.2769653797149658 seconds for one epoch ---
--- 0.37719225883483887 seconds for one epoch ---
--- 0.28267979621887207 seconds for one epoch ---
--- 0.3747067451477051 seconds for one epoch ---
--- 0.29241085052490234 seconds for one epoch ---
--- 0.3709280490875244 seconds for one epoch ---
--- 0.29565858840942383 seconds for one epoch ---
=========================
[[0.21159893]
 [0.21020326]
 [0.21223302]
 [0.21100624]
 [0.20937036]
 [0.27587578]
 [0.2115061 ]
 [0.2127649 ]
 [0.20916195]
 [0.21238445]
 [0.21489893]]
[[ 0.19713001]
 [-0.08923788]
 [-0.24471898]
 [ 0.15186639]
 [ 0.02269114]
 [-3.1618574 ]
 [ 0.19010164]
 [ 0.2839989 ]
 [-0.00574701]
 [-0.25597537]
 [ 0.4360722 ]]
--- 0.250171422958374 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13130.232421875, (10609.886, 9.330682, 2377.9355, 2.5317762)
   validation loss 3302.733154296875, (2597.3691, 0.059285704, 572.2247, 2.5317762)
decoder loss ratio: 100626.589739, decoder SINDy loss  ratio: 1.235227
--- 0.2822725772857666 seconds for one epoch ---
--- 0.36336636543273926 seconds for one epoch ---
--- 0.30462646484375 seconds for one epoch ---
--- 0.3793034553527832 seconds for one epoch ---
--- 0.23165297508239746 seconds for one epoch ---
--- 0.39227914810180664 seconds for one epoch ---
--- 0.27342700958251953 seconds for one epoch ---
--- 0.36987733840942383 seconds for one epoch ---
--- 0.2684183120727539 seconds for one epoch ---
--- 0.37681102752685547 seconds for one epoch ---
--- 0.2852590084075928 seconds for one epoch ---
--- 0.37103271484375 seconds for one epoch ---
--- 0.293079137802124 seconds for one epoch ---
--- 0.3830437660217285 seconds for one epoch ---
--- 0.28472232818603516 seconds for one epoch ---
--- 0.37969160079956055 seconds for one epoch ---
--- 0.29076170921325684 seconds for one epoch ---
--- 0.3737976551055908 seconds for one epoch ---
--- 0.2942328453063965 seconds for one epoch ---
--- 0.37624359130859375 seconds for one epoch ---
--- 0.21248173713684082 seconds for one epoch ---
--- 0.3887042999267578 seconds for one epoch ---
--- 0.2902851104736328 seconds for one epoch ---
--- 0.37718939781188965 seconds for one epoch ---
=========================
[[0.17450194]
 [0.17576359]
 [0.17702058]
 [0.17553611]
 [0.17406036]
 [0.25161892]
 [0.17619954]
 [0.17779008]
 [0.17397454]
 [0.18022425]
 [0.18056542]]
[[-4.1077595e-02]
 [-1.3640396e-01]
 [-2.2806452e-01]
 [ 1.1947175e-01]
 [ 6.8477588e-03]
 [-3.4044337e+00]
 [ 1.6855846e-01]
 [ 2.8265125e-01]
 [ 1.4980945e-04]
 [-4.4841158e-01]
 [ 4.7087109e-01]]
--- 0.29054760932922363 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6778.20166015625, (2827.2878, 0.3647535, 3808.6206, 2.5317945)
   validation loss 2296.064697265625, (1678.1371, 0.05080493, 475.9487, 2.5317945)
decoder loss ratio: 65013.944045, decoder SINDy loss  ratio: 1.027402
--- 0.2581658363342285 seconds for one epoch ---
--- 0.29543590545654297 seconds for one epoch ---
--- 0.38498926162719727 seconds for one epoch ---
--- 0.2984507083892822 seconds for one epoch ---
--- 0.3680250644683838 seconds for one epoch ---
--- 0.29166126251220703 seconds for one epoch ---
--- 0.3912162780761719 seconds for one epoch ---
--- 0.2870216369628906 seconds for one epoch ---
--- 0.3540372848510742 seconds for one epoch ---
--- 0.14663386344909668 seconds for one epoch ---
--- 0.3895268440246582 seconds for one epoch ---
--- 0.2817561626434326 seconds for one epoch ---
--- 0.3760039806365967 seconds for one epoch ---
--- 0.256136417388916 seconds for one epoch ---
--- 0.4425201416015625 seconds for one epoch ---
--- 0.37981104850769043 seconds for one epoch ---
--- 0.4044818878173828 seconds for one epoch ---
--- 0.30176591873168945 seconds for one epoch ---
--- 0.43292784690856934 seconds for one epoch ---
--- 0.3156430721282959 seconds for one epoch ---
--- 0.4171028137207031 seconds for one epoch ---
--- 0.25899386405944824 seconds for one epoch ---
--- 0.43210625648498535 seconds for one epoch ---
--- 0.2963089942932129 seconds for one epoch ---
=========================
[[0.1475991 ]
 [0.1465997 ]
 [0.14730962]
 [0.14613342]
 [0.14412159]
 [0.23088999]
 [0.14614294]
 [0.14835392]
 [0.14413078]
 [0.15375987]
 [0.15166537]]
[[-0.25627315]
 [-0.18697484]
 [-0.23638684]
 [ 0.15402408]
 [ 0.00685171]
 [-3.5875278 ]
 [ 0.1547047 ]
 [ 0.30743325]
 [-0.00755216]
 [-0.64838934]
 [ 0.5211967 ]]
--- 0.25227952003479004 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8715.00390625, (4228.2227, 2.8142438, 4333.204, 2.5318162)
   validation loss 1830.476806640625, (1225.246, 0.055775505, 454.4131, 2.5318162)
decoder loss ratio: 47468.156063, decoder SINDy loss  ratio: 0.980915
--- 0.28250789642333984 seconds for one epoch ---
--- 0.4089343547821045 seconds for one epoch ---
--- 0.2994241714477539 seconds for one epoch ---
--- 0.4421353340148926 seconds for one epoch ---
--- 0.28070974349975586 seconds for one epoch ---
--- 0.4025228023529053 seconds for one epoch ---
--- 0.2942945957183838 seconds for one epoch ---
--- 0.4202725887298584 seconds for one epoch ---
--- 0.30919885635375977 seconds for one epoch ---
--- 0.38436341285705566 seconds for one epoch ---
--- 0.3009977340698242 seconds for one epoch ---
--- 0.41964006423950195 seconds for one epoch ---
--- 0.28949546813964844 seconds for one epoch ---
--- 0.4445774555206299 seconds for one epoch ---
--- 0.3185746669769287 seconds for one epoch ---
--- 0.41507840156555176 seconds for one epoch ---
--- 0.2978556156158447 seconds for one epoch ---
--- 0.40443897247314453 seconds for one epoch ---
--- 0.29499268531799316 seconds for one epoch ---
--- 0.4423179626464844 seconds for one epoch ---
--- 0.30481672286987305 seconds for one epoch ---
--- 0.4235236644744873 seconds for one epoch ---
--- 0.29250431060791016 seconds for one epoch ---
--- 0.41321611404418945 seconds for one epoch ---
=========================
[[0.1288619 ]
 [0.1262302 ]
 [0.12551785]
 [0.12482207]
 [0.12228701]
 [0.21679422]
 [0.12441541]
 [0.12687364]
 [0.12226079]
 [0.1354998 ]
 [0.13057762]]
[[-4.4744569e-01]
 [-2.7864400e-01]
 [-2.3107548e-01]
 [ 1.8377542e-01]
 [-3.8814435e-03]
 [-3.7368414e+00]
 [ 1.5573549e-01]
 [ 3.2089204e-01]
 [ 1.9593793e-03]
 [-8.3281201e-01]
 [ 5.5217457e-01]]
--- 0.2941858768463135 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6000.5009765625, (2617.3247, 4.4107428, 3220.704, 2.531837)
   validation loss 1655.36083984375, (1101.1935, 0.03338185, 396.0722, 2.531837)
decoder loss ratio: 42662.147227, decoder SINDy loss  ratio: 0.854978
--- 0.24556994438171387 seconds for one epoch ---
--- 0.28795838356018066 seconds for one epoch ---
--- 0.4121360778808594 seconds for one epoch ---
--- 0.2949056625366211 seconds for one epoch ---
--- 0.43428826332092285 seconds for one epoch ---
--- 0.30695295333862305 seconds for one epoch ---
--- 0.41666340827941895 seconds for one epoch ---
--- 0.30371832847595215 seconds for one epoch ---
--- 0.4566037654876709 seconds for one epoch ---
--- 0.28944873809814453 seconds for one epoch ---
--- 0.4100477695465088 seconds for one epoch ---
--- 0.27507972717285156 seconds for one epoch ---
--- 0.4341292381286621 seconds for one epoch ---
--- 0.2869434356689453 seconds for one epoch ---
--- 0.4214448928833008 seconds for one epoch ---
--- 0.3000667095184326 seconds for one epoch ---
--- 0.4254937171936035 seconds for one epoch ---
--- 0.2997455596923828 seconds for one epoch ---
--- 0.42682528495788574 seconds for one epoch ---
--- 0.303882360458374 seconds for one epoch ---
--- 0.43658018112182617 seconds for one epoch ---
--- 0.2966799736022949 seconds for one epoch ---
--- 0.4275479316711426 seconds for one epoch ---
--- 0.3108546733856201 seconds for one epoch ---
=========================
[[0.11307792]
 [0.10846577]
 [0.10770613]
 [0.10619995]
 [0.10358287]
 [0.20264453]
 [0.10599553]
 [0.10832043]
 [0.10363451]
 [0.12059303]
 [0.11355615]]
[[-6.1086333e-01]
 [-3.3245450e-01]
 [-2.8375947e-01]
 [ 1.8451686e-01]
 [ 2.6512961e-03]
 [-3.8030729e+00]
 [ 1.7075936e-01]
 [ 3.2320717e-01]
 [-6.3709952e-03]
 [-1.0134492e+00]
 [ 6.3820601e-01]]
--- 0.26364684104919434 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7590.99951171875, (3420.3535, 5.186506, 4001.1829, 2.5318522)
   validation loss 1346.02783203125, (806.1753, 0.037986565, 375.53745, 2.5318522)
decoder loss ratio: 31232.630431, decoder SINDy loss  ratio: 0.810650
--- 0.29789042472839355 seconds for one epoch ---
--- 0.4395291805267334 seconds for one epoch ---
--- 0.299147367477417 seconds for one epoch ---
--- 0.41832947731018066 seconds for one epoch ---
--- 0.25214457511901855 seconds for one epoch ---
--- 0.44068336486816406 seconds for one epoch ---
--- 0.3007519245147705 seconds for one epoch ---
--- 0.406599760055542 seconds for one epoch ---
--- 0.2639918327331543 seconds for one epoch ---
--- 0.40532994270324707 seconds for one epoch ---
--- 0.17194890975952148 seconds for one epoch ---
--- 0.44212770462036133 seconds for one epoch ---
--- 0.2876276969909668 seconds for one epoch ---
--- 0.4395177364349365 seconds for one epoch ---
--- 0.2879641056060791 seconds for one epoch ---
--- 0.43566346168518066 seconds for one epoch ---
--- 0.29344701766967773 seconds for one epoch ---
--- 0.4373481273651123 seconds for one epoch ---
--- 0.3087339401245117 seconds for one epoch ---
--- 0.4637794494628906 seconds for one epoch ---
--- 0.29231810569763184 seconds for one epoch ---
--- 0.44771409034729004 seconds for one epoch ---
--- 0.27939343452453613 seconds for one epoch ---
--- 0.416184663772583 seconds for one epoch ---
=========================
[[0.10146045]
 [0.0952941 ]
 [0.09559241]
 [0.09323779]
 [0.08991911]
 [0.19097312]
 [0.09254767]
 [0.09454671]
 [0.089968  ]
 [0.10973174]
 [0.10016968]]
[[-7.1735352e-01]
 [-3.5945353e-01]
 [-3.7785682e-01]
 [ 2.2895959e-01]
 [ 3.7908666e-03]
 [-3.8158343e+00]
 [ 1.8369894e-01]
 [ 3.1274563e-01]
 [-7.2507081e-03]
 [-1.1372272e+00]
 [ 6.4609802e-01]]
--- 0.2914466857910156 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5529.19287109375, (2730.8484, 1.2931441, 2627.4924, 2.531862)
   validation loss 2094.1142578125, (1547.8127, 0.06940743, 376.67282, 2.531862)
decoder loss ratio: 59964.952829, decoder SINDy loss  ratio: 0.813101
--- 0.2556569576263428 seconds for one epoch ---
--- 0.29958271980285645 seconds for one epoch ---
--- 0.43609189987182617 seconds for one epoch ---
--- 0.29069972038269043 seconds for one epoch ---
--- 0.44765400886535645 seconds for one epoch ---
--- 0.3224365711212158 seconds for one epoch ---
--- 0.42554259300231934 seconds for one epoch ---
--- 0.2952229976654053 seconds for one epoch ---
--- 0.4492988586425781 seconds for one epoch ---
--- 0.302518367767334 seconds for one epoch ---
--- 0.46216273307800293 seconds for one epoch ---
--- 0.2801473140716553 seconds for one epoch ---
--- 0.4615037441253662 seconds for one epoch ---
--- 0.275315523147583 seconds for one epoch ---
--- 0.42847728729248047 seconds for one epoch ---
--- 0.292464017868042 seconds for one epoch ---
--- 0.44444847106933594 seconds for one epoch ---
--- 0.2948586940765381 seconds for one epoch ---
--- 0.47100162506103516 seconds for one epoch ---
--- 0.2845790386199951 seconds for one epoch ---
--- 0.4543163776397705 seconds for one epoch ---
--- 0.3023505210876465 seconds for one epoch ---
--- 0.4305541515350342 seconds for one epoch ---
--- 0.2995586395263672 seconds for one epoch ---
=========================
[[0.09158685]
 [0.0843103 ]
 [0.08544216]
 [0.08167173]
 [0.07815296]
 [0.1788523 ]
 [0.08066654]
 [0.083065  ]
 [0.07813915]
 [0.10102083]
 [0.08856361]]
[[-0.81111085]
 [-0.404323  ]
 [-0.4715849 ]
 [ 0.24076349]
 [-0.00568381]
 [-3.7742312 ]
 [ 0.17571825]
 [ 0.32835472]
 [-0.00472144]
 [-1.2668178 ]
 [ 0.6490976 ]]
--- 0.2519512176513672 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3970.979248046875, (2623.5776, 0.37078235, 1172.4956, 2.5318677)
   validation loss 1881.467529296875, (1242.577, 0.042744324, 464.3126, 2.5318677)
decoder loss ratio: 48139.591210, decoder SINDy loss  ratio: 1.002284
--- 0.2917659282684326 seconds for one epoch ---
--- 0.45764780044555664 seconds for one epoch ---
--- 0.2936110496520996 seconds for one epoch ---
--- 0.46291160583496094 seconds for one epoch ---
--- 0.3032066822052002 seconds for one epoch ---
--- 0.5014004707336426 seconds for one epoch ---
--- 0.3036801815032959 seconds for one epoch ---
--- 0.5036439895629883 seconds for one epoch ---
--- 0.2905433177947998 seconds for one epoch ---
--- 0.4733917713165283 seconds for one epoch ---
--- 0.3056979179382324 seconds for one epoch ---
--- 0.4510223865509033 seconds for one epoch ---
--- 0.23885226249694824 seconds for one epoch ---
--- 0.4645252227783203 seconds for one epoch ---
--- 0.28698158264160156 seconds for one epoch ---
--- 0.4607868194580078 seconds for one epoch ---
--- 0.2908909320831299 seconds for one epoch ---
--- 0.4351844787597656 seconds for one epoch ---
--- 0.2916688919067383 seconds for one epoch ---
--- 0.46378064155578613 seconds for one epoch ---
--- 0.2965221405029297 seconds for one epoch ---
--- 0.4548609256744385 seconds for one epoch ---
--- 0.29778289794921875 seconds for one epoch ---
--- 0.45447707176208496 seconds for one epoch ---
=========================
[[0.0848387 ]
 [0.07566369]
 [0.07815135]
 [0.07314855]
 [0.06941078]
 [0.1696696 ]
 [0.0721461 ]
 [0.07417054]
 [0.06944617]
 [0.0954122 ]
 [0.0800835 ]]
[[-9.0290445e-01]
 [-4.0285578e-01]
 [-5.4734695e-01]
 [ 2.4857306e-01]
 [ 1.3792386e-03]
 [-3.7374961e+00]
 [ 1.8452443e-01]
 [ 3.1232899e-01]
 [ 3.8286459e-03]
 [-1.3915529e+00]
 [ 6.5465754e-01]]
--- 0.29654979705810547 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8425.1318359375, (3373.2698, 0.567058, 4872.563, 2.531872)
   validation loss 1734.8941650390625, (1202.986, 0.059542563, 353.1177, 2.531872)
decoder loss ratio: 46605.764640, decoder SINDy loss  ratio: 0.762254
--- 0.26441192626953125 seconds for one epoch ---
--- 0.29448795318603516 seconds for one epoch ---
--- 0.5027220249176025 seconds for one epoch ---
--- 0.29007530212402344 seconds for one epoch ---
--- 0.466937780380249 seconds for one epoch ---
--- 0.2944815158843994 seconds for one epoch ---
--- 0.47197532653808594 seconds for one epoch ---
--- 0.2728099822998047 seconds for one epoch ---
--- 0.4707469940185547 seconds for one epoch ---
--- 0.2984437942504883 seconds for one epoch ---
--- 0.5397090911865234 seconds for one epoch ---
--- 0.24083805084228516 seconds for one epoch ---
--- 0.4883580207824707 seconds for one epoch ---
--- 0.2940225601196289 seconds for one epoch ---
--- 0.4683067798614502 seconds for one epoch ---
--- 0.28240180015563965 seconds for one epoch ---
--- 0.4829692840576172 seconds for one epoch ---
--- 0.30699896812438965 seconds for one epoch ---
--- 0.4794933795928955 seconds for one epoch ---
--- 0.28678345680236816 seconds for one epoch ---
--- 0.4697263240814209 seconds for one epoch ---
--- 0.2790358066558838 seconds for one epoch ---
--- 0.49592113494873047 seconds for one epoch ---
--- 0.28624653816223145 seconds for one epoch ---
=========================
[[0.07948549]
 [0.06848423]
 [0.07190245]
 [0.06562979]
 [0.06199531]
 [0.1617989 ]
 [0.06448285]
 [0.06667734]
 [0.06187526]
 [0.09131017]
 [0.07181941]]
[[-1.0028361e+00]
 [-4.2017257e-01]
 [-6.1416817e-01]
 [ 2.4699426e-01]
 [ 8.8126864e-03]
 [-3.7082901e+00]
 [ 1.7413050e-01]
 [ 3.1184065e-01]
 [-5.5846706e-04]
 [-1.5253514e+00]
 [ 6.0960919e-01]]
--- 0.25461459159851074 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3238.6904296875, (1526.6733, 0.47332475, 1528.467, 2.5318785)
   validation loss 1671.860595703125, (1146.38, 0.06653336, 342.33752, 2.5318785)
decoder loss ratio: 44412.751592, decoder SINDy loss  ratio: 0.738984
--- 0.29293346405029297 seconds for one epoch ---
--- 0.4849212169647217 seconds for one epoch ---
--- 0.29430246353149414 seconds for one epoch ---
--- 0.48732733726501465 seconds for one epoch ---
--- 0.2902226448059082 seconds for one epoch ---
--- 0.47359299659729004 seconds for one epoch ---
--- 0.293445348739624 seconds for one epoch ---
--- 0.464141845703125 seconds for one epoch ---
--- 0.29474425315856934 seconds for one epoch ---
--- 0.5537190437316895 seconds for one epoch ---
--- 0.29290270805358887 seconds for one epoch ---
--- 0.4860835075378418 seconds for one epoch ---
--- 0.31137537956237793 seconds for one epoch ---
--- 0.49552345275878906 seconds for one epoch ---
--- 0.30261969566345215 seconds for one epoch ---
--- 0.4980769157409668 seconds for one epoch ---
--- 0.2884092330932617 seconds for one epoch ---
--- 0.4781639575958252 seconds for one epoch ---
--- 0.29752612113952637 seconds for one epoch ---
--- 0.5017597675323486 seconds for one epoch ---
--- 0.2828552722930908 seconds for one epoch ---
--- 0.515230655670166 seconds for one epoch ---
--- 0.28194665908813477 seconds for one epoch ---
--- 0.5013368129730225 seconds for one epoch ---
=========================
[[0.07618107]
 [0.06340483]
 [0.06740565]
 [0.05995143]
 [0.05638243]
 [0.1552786 ]
 [0.05873188]
 [0.06130847]
 [0.05631418]
 [0.08946685]
 [0.06700967]]
[[-1.1042361e+00]
 [-4.4625738e-01]
 [-6.6874826e-01]
 [ 2.3866551e-01]
 [ 5.6431256e-03]
 [-3.6693227e+00]
 [ 1.6134356e-01]
 [ 3.2214886e-01]
 [ 9.8141679e-04]
 [-1.6665275e+00]
 [ 6.4749259e-01]]
--- 0.3888566493988037 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3433.689453125, (1339.1526, 0.35162112, 1907.1467, 2.5318854)
   validation loss 1438.9366455078125, (887.5926, 0.050184183, 364.2553, 2.5318854)
decoder loss ratio: 34386.877878, decoder SINDy loss  ratio: 0.786296
--- 0.2655055522918701 seconds for one epoch ---
--- 0.2882084846496582 seconds for one epoch ---
--- 0.5137462615966797 seconds for one epoch ---
--- 0.31738877296447754 seconds for one epoch ---
--- 0.47557902336120605 seconds for one epoch ---
--- 0.16181111335754395 seconds for one epoch ---
--- 0.5038297176361084 seconds for one epoch ---
--- 0.27389025688171387 seconds for one epoch ---
--- 0.5217771530151367 seconds for one epoch ---
--- 0.31896424293518066 seconds for one epoch ---
--- 0.5279724597930908 seconds for one epoch ---
--- 0.3161771297454834 seconds for one epoch ---
--- 0.5009143352508545 seconds for one epoch ---
--- 0.27743077278137207 seconds for one epoch ---
--- 0.4825565814971924 seconds for one epoch ---
--- 0.30962347984313965 seconds for one epoch ---
--- 0.47935962677001953 seconds for one epoch ---
--- 0.27822041511535645 seconds for one epoch ---
--- 0.4722862243652344 seconds for one epoch ---
--- 0.2908210754394531 seconds for one epoch ---
--- 0.5392229557037354 seconds for one epoch ---
--- 0.2983419895172119 seconds for one epoch ---
--- 0.5148105621337891 seconds for one epoch ---
--- 0.28768420219421387 seconds for one epoch ---
=========================
[[0.073356  ]
 [0.05888999]
 [0.0641496 ]
 [0.05539409]
 [0.05163478]
 [0.14833568]
 [0.05390402]
 [0.05616039]
 [0.05145188]
 [0.08833581]
 [0.06247554]]
[[-1.1914551e+00]
 [-4.6343622e-01]
 [-7.4941063e-01]
 [ 2.5566903e-01]
 [ 1.2598149e-02]
 [-3.6035984e+00]
 [ 1.6199426e-01]
 [ 3.0259579e-01]
 [ 1.7441875e-04]
 [-1.8015598e+00]
 [ 6.6146630e-01]]
--- 0.25666379928588867 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7040.00048828125, (2908.0347, 0.4856666, 3940.935, 2.5318909)
   validation loss 1253.384521484375, (727.86273, 0.055542894, 334.9209, 2.5318909)
decoder loss ratio: 28198.665860, decoder SINDy loss  ratio: 0.722974
--- 0.19623684883117676 seconds for one epoch ---
--- 0.5291295051574707 seconds for one epoch ---
--- 0.2943847179412842 seconds for one epoch ---
--- 0.5128827095031738 seconds for one epoch ---
--- 0.2936723232269287 seconds for one epoch ---
--- 0.5200912952423096 seconds for one epoch ---
--- 0.29039835929870605 seconds for one epoch ---
--- 0.5025851726531982 seconds for one epoch ---
--- 0.2979772090911865 seconds for one epoch ---
--- 0.5075585842132568 seconds for one epoch ---
--- 0.29192137718200684 seconds for one epoch ---
--- 0.500359058380127 seconds for one epoch ---
--- 0.2609705924987793 seconds for one epoch ---
--- 0.5053043365478516 seconds for one epoch ---
--- 0.28444766998291016 seconds for one epoch ---
--- 0.48690128326416016 seconds for one epoch ---
--- 0.2951545715332031 seconds for one epoch ---
--- 0.5118083953857422 seconds for one epoch ---
--- 0.2982351779937744 seconds for one epoch ---
--- 0.5127465724945068 seconds for one epoch ---
--- 0.28856635093688965 seconds for one epoch ---
--- 0.503685474395752 seconds for one epoch ---
--- 0.28926587104797363 seconds for one epoch ---
--- 0.4633505344390869 seconds for one epoch ---
=========================
[[0.07194489]
 [0.0562014 ]
 [0.06161244]
 [0.05229285]
 [0.04791084]
 [0.14257863]
 [0.04937516]
 [0.05265566]
 [0.04789514]
 [0.08874775]
 [0.05866186]]
[[-1.284255  ]
 [-0.5137679 ]
 [-0.801637  ]
 [ 0.28574556]
 [-0.00469529]
 [-3.5395987 ]
 [ 0.10200369]
 [ 0.3077393 ]
 [-0.0036298 ]
 [-1.9431047 ]
 [ 0.64826715]]
--- 0.2684671878814697 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3160.248291015625, (1327.9294, 0.71647877, 1637.7566, 2.531897)
   validation loss 1322.739990234375, (781.5753, 0.049715392, 347.269, 2.531897)
decoder loss ratio: 30279.584670, decoder SINDy loss  ratio: 0.749629
--- 0.2496497631072998 seconds for one epoch ---
--- 0.28571557998657227 seconds for one epoch ---
--- 0.557797908782959 seconds for one epoch ---
--- 0.2839784622192383 seconds for one epoch ---
--- 0.5009629726409912 seconds for one epoch ---
--- 0.29879236221313477 seconds for one epoch ---
--- 0.5317354202270508 seconds for one epoch ---
--- 0.2937779426574707 seconds for one epoch ---
--- 0.5357522964477539 seconds for one epoch ---
--- 0.2891726493835449 seconds for one epoch ---
--- 0.5195755958557129 seconds for one epoch ---
--- 0.2655324935913086 seconds for one epoch ---
--- 0.5382182598114014 seconds for one epoch ---
--- 0.2808997631072998 seconds for one epoch ---
--- 0.5251829624176025 seconds for one epoch ---
--- 0.2675201892852783 seconds for one epoch ---
--- 0.5033473968505859 seconds for one epoch ---
--- 0.2607595920562744 seconds for one epoch ---
--- 0.5311839580535889 seconds for one epoch ---
--- 0.30521583557128906 seconds for one epoch ---
--- 0.5581426620483398 seconds for one epoch ---
--- 0.31493210792541504 seconds for one epoch ---
--- 0.5302963256835938 seconds for one epoch ---
--- 0.2821156978607178 seconds for one epoch ---
=========================
[[0.07058757]
 [0.05335413]
 [0.05962059]
 [0.0487729 ]
 [0.04481161]
 [0.13695173]
 [0.0465912 ]
 [0.04932089]
 [0.04475084]
 [0.08910049]
 [0.05591081]]
[[-1.3576988 ]
 [-0.5295917 ]
 [-0.85771567]
 [ 0.26288414]
 [ 0.00873408]
 [-3.4683664 ]
 [ 0.12596336]
 [ 0.29619384]
 [ 0.00463487]
 [-2.0617013 ]
 [ 0.6680117 ]]
--- 0.24706411361694336 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3167.39892578125, (1471.3724, 0.7259654, 1498.7754, 2.5319014)
   validation loss 1842.0108642578125, (1324.1527, 0.05071102, 321.28235, 2.5319014)
decoder loss ratio: 51299.974814, decoder SINDy loss  ratio: 0.693533
--- 0.2959623336791992 seconds for one epoch ---
--- 0.515939474105835 seconds for one epoch ---
--- 0.26951146125793457 seconds for one epoch ---
--- 0.5310895442962646 seconds for one epoch ---
--- 0.32260918617248535 seconds for one epoch ---
--- 0.5633304119110107 seconds for one epoch ---
--- 0.29596877098083496 seconds for one epoch ---
--- 0.521803617477417 seconds for one epoch ---
--- 0.3142881393432617 seconds for one epoch ---
--- 0.5316598415374756 seconds for one epoch ---
--- 0.2949972152709961 seconds for one epoch ---
--- 0.580315113067627 seconds for one epoch ---
--- 0.29488039016723633 seconds for one epoch ---
--- 0.5566983222961426 seconds for one epoch ---
--- 0.29094767570495605 seconds for one epoch ---
--- 0.5314922332763672 seconds for one epoch ---
--- 0.2852175235748291 seconds for one epoch ---
--- 0.5184731483459473 seconds for one epoch ---
--- 0.3017768859863281 seconds for one epoch ---
--- 0.5536179542541504 seconds for one epoch ---
--- 0.29647350311279297 seconds for one epoch ---
--- 0.5718810558319092 seconds for one epoch ---
--- 0.27959752082824707 seconds for one epoch ---
--- 0.554335355758667 seconds for one epoch ---
=========================
[[0.06968127]
 [0.05117135]
 [0.0584475 ]
 [0.04608211]
 [0.04249662]
 [0.13206741]
 [0.04464833]
 [0.04692316]
 [0.04235103]
 [0.08978943]
 [0.05419941]]
[[-1.4157284e+00]
 [-5.3829634e-01]
 [-9.1406929e-01]
 [ 2.4210948e-01]
 [-1.1854458e-02]
 [-3.3973024e+00]
 [ 1.5244131e-01]
 [ 2.9333574e-01]
 [ 2.0610425e-03]
 [-2.1618729e+00]
 [ 7.0064706e-01]]
--- 0.2933778762817383 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5533.974609375, (3290.5093, 0.98727065, 2042.9148, 2.5319054)
   validation loss 1326.3626708984375, (762.6596, 0.055308763, 364.08426, 2.5319054)
decoder loss ratio: 29546.757208, decoder SINDy loss  ratio: 0.785927
THRESHOLDING: 1 active coefficients
--- 0.552626371383667 seconds for one epoch ---
--- 0.30666399002075195 seconds for one epoch ---
--- 0.5211942195892334 seconds for one epoch ---
--- 0.29326581954956055 seconds for one epoch ---
--- 0.5590782165527344 seconds for one epoch ---
--- 0.2858920097351074 seconds for one epoch ---
--- 0.5347764492034912 seconds for one epoch ---
--- 0.29473376274108887 seconds for one epoch ---
--- 0.5386042594909668 seconds for one epoch ---
--- 0.291579008102417 seconds for one epoch ---
--- 0.5350823402404785 seconds for one epoch ---
--- 0.2867114543914795 seconds for one epoch ---
--- 0.5450215339660645 seconds for one epoch ---
--- 0.29180383682250977 seconds for one epoch ---
--- 0.5540380477905273 seconds for one epoch ---
--- 0.269559383392334 seconds for one epoch ---
--- 0.5224382877349854 seconds for one epoch ---
--- 0.2981441020965576 seconds for one epoch ---
--- 0.5306186676025391 seconds for one epoch ---
--- 0.3025858402252197 seconds for one epoch ---
--- 0.47725439071655273 seconds for one epoch ---
--- 0.18471288681030273 seconds for one epoch ---
--- 0.5527868270874023 seconds for one epoch ---
--- 0.289278507232666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09218999]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3061204]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.244309663772583 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6105.5810546875, (3116.4097, 0.48673636, 2988.5217, 0.16318306)
   validation loss 3059.45263671875, (2689.3206, 0.063716024, 369.9054, 0.16318306)
decoder loss ratio: 104188.947230, decoder SINDy loss  ratio: 0.798493
--- 0.30673909187316895 seconds for one epoch ---
--- 0.5523011684417725 seconds for one epoch ---
--- 0.2934293746948242 seconds for one epoch ---
--- 0.5361378192901611 seconds for one epoch ---
--- 0.3033573627471924 seconds for one epoch ---
--- 0.5549712181091309 seconds for one epoch ---
--- 0.30124497413635254 seconds for one epoch ---
--- 0.5829589366912842 seconds for one epoch ---
--- 0.31982421875 seconds for one epoch ---
--- 0.5654280185699463 seconds for one epoch ---
--- 0.2859313488006592 seconds for one epoch ---
--- 0.5425198078155518 seconds for one epoch ---
--- 0.27270007133483887 seconds for one epoch ---
--- 0.5642151832580566 seconds for one epoch ---
--- 0.31297898292541504 seconds for one epoch ---
--- 0.5756642818450928 seconds for one epoch ---
--- 0.3010246753692627 seconds for one epoch ---
--- 0.5603146553039551 seconds for one epoch ---
--- 0.2827329635620117 seconds for one epoch ---
--- 0.5663676261901855 seconds for one epoch ---
--- 0.2907569408416748 seconds for one epoch ---
--- 0.5531880855560303 seconds for one epoch ---
--- 0.2712221145629883 seconds for one epoch ---
--- 0.5584735870361328 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07609043]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.802546]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.3269195556640625 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4051.102294921875, (1158.808, 0.40650252, 2891.7312, 0.15643643)
   validation loss 1083.468505859375, (729.03345, 0.11583504, 354.16275, 0.15643643)
decoder loss ratio: 28244.021405, decoder SINDy loss  ratio: 0.764510
--- 0.24675250053405762 seconds for one epoch ---
--- 0.2984442710876465 seconds for one epoch ---
--- 0.5544722080230713 seconds for one epoch ---
--- 0.296173095703125 seconds for one epoch ---
--- 0.5573616027832031 seconds for one epoch ---
--- 0.29872775077819824 seconds for one epoch ---
--- 0.560244083404541 seconds for one epoch ---
--- 0.3005373477935791 seconds for one epoch ---
--- 0.5653398036956787 seconds for one epoch ---
--- 0.3160712718963623 seconds for one epoch ---
--- 0.5427753925323486 seconds for one epoch ---
--- 0.2970132827758789 seconds for one epoch ---
--- 0.6043684482574463 seconds for one epoch ---
--- 0.2892289161682129 seconds for one epoch ---
--- 0.5878822803497314 seconds for one epoch ---
--- 0.29852294921875 seconds for one epoch ---
--- 0.6266987323760986 seconds for one epoch ---
--- 0.29482579231262207 seconds for one epoch ---
--- 0.632704496383667 seconds for one epoch ---
--- 0.29521894454956055 seconds for one epoch ---
--- 0.6062047481536865 seconds for one epoch ---
--- 0.30205440521240234 seconds for one epoch ---
--- 0.5706400871276855 seconds for one epoch ---
--- 0.3089268207550049 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06785959]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5390867]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.27071523666381836 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3611.587158203125, (1807.5784, 0.88714117, 1802.9684, 0.15320401)
   validation loss 1914.5767822265625, (1606.5299, 0.09625989, 307.79733, 0.15320401)
decoder loss ratio: 62239.757665, decoder SINDy loss  ratio: 0.664424
--- 0.26891112327575684 seconds for one epoch ---
--- 0.5432448387145996 seconds for one epoch ---
--- 0.2815279960632324 seconds for one epoch ---
--- 0.6125297546386719 seconds for one epoch ---
--- 0.30402421951293945 seconds for one epoch ---
--- 0.5709741115570068 seconds for one epoch ---
--- 0.29877233505249023 seconds for one epoch ---
--- 0.5686373710632324 seconds for one epoch ---
--- 0.31150388717651367 seconds for one epoch ---
--- 0.6041116714477539 seconds for one epoch ---
--- 0.3030080795288086 seconds for one epoch ---
--- 0.567960262298584 seconds for one epoch ---
--- 0.28650546073913574 seconds for one epoch ---
--- 0.5441970825195312 seconds for one epoch ---
--- 0.29779863357543945 seconds for one epoch ---
--- 0.572922945022583 seconds for one epoch ---
--- 0.3044159412384033 seconds for one epoch ---
--- 0.5762174129486084 seconds for one epoch ---
--- 0.2902030944824219 seconds for one epoch ---
--- 0.5609660148620605 seconds for one epoch ---
--- 0.29825639724731445 seconds for one epoch ---
--- 0.5665278434753418 seconds for one epoch ---
--- 0.28797197341918945 seconds for one epoch ---
--- 0.5608186721801758 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06371245]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.4124817]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2972872257232666 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3400.921630859375, (1309.6564, 1.3380504, 2089.7756, 0.15154018)
   validation loss 1899.9949951171875, (1551.9032, 0.1315583, 347.80872, 0.15154018)
decoder loss ratio: 60123.424122, decoder SINDy loss  ratio: 0.750794
--- 0.26708269119262695 seconds for one epoch ---
--- 0.2878420352935791 seconds for one epoch ---
--- 0.5904853343963623 seconds for one epoch ---
--- 0.29532647132873535 seconds for one epoch ---
--- 0.5879991054534912 seconds for one epoch ---
--- 0.30523681640625 seconds for one epoch ---
--- 0.602449893951416 seconds for one epoch ---
--- 0.28722691535949707 seconds for one epoch ---
--- 0.5745086669921875 seconds for one epoch ---
--- 0.30719804763793945 seconds for one epoch ---
--- 0.567068338394165 seconds for one epoch ---
--- 0.16897988319396973 seconds for one epoch ---
--- 0.59529709815979 seconds for one epoch ---
--- 0.28836536407470703 seconds for one epoch ---
--- 0.6213972568511963 seconds for one epoch ---
--- 0.30044078826904297 seconds for one epoch ---
--- 0.5917770862579346 seconds for one epoch ---
--- 0.28731679916381836 seconds for one epoch ---
--- 0.6130449771881104 seconds for one epoch ---
--- 0.2969951629638672 seconds for one epoch ---
--- 0.6144692897796631 seconds for one epoch ---
--- 0.29860448837280273 seconds for one epoch ---
--- 0.5725541114807129 seconds for one epoch ---
--- 0.2868616580963135 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06083787]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3303381]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.25317835807800293 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3753.004638671875, (1379.1239, 1.2219799, 2372.508, 0.15054516)
   validation loss 1583.2901611328125, (1258.7273, 0.10000638, 324.31232, 0.15054516)
decoder loss ratio: 48765.280652, decoder SINDy loss  ratio: 0.700074
--- 0.2072298526763916 seconds for one epoch ---
--- 0.5713644027709961 seconds for one epoch ---
--- 0.45151209831237793 seconds for one epoch ---
--- 0.6116132736206055 seconds for one epoch ---
--- 0.2841780185699463 seconds for one epoch ---
--- 0.6226797103881836 seconds for one epoch ---
--- 0.3157334327697754 seconds for one epoch ---
--- 0.6029424667358398 seconds for one epoch ---
--- 0.2907834053039551 seconds for one epoch ---
--- 0.6200428009033203 seconds for one epoch ---
--- 0.29210615158081055 seconds for one epoch ---
--- 0.5952978134155273 seconds for one epoch ---
--- 0.30738210678100586 seconds for one epoch ---
--- 0.6399343013763428 seconds for one epoch ---
--- 0.22036504745483398 seconds for one epoch ---
--- 0.5512945652008057 seconds for one epoch ---
--- 0.2980482578277588 seconds for one epoch ---
--- 0.5866942405700684 seconds for one epoch ---
--- 0.29027867317199707 seconds for one epoch ---
--- 0.6344695091247559 seconds for one epoch ---
--- 0.28610658645629883 seconds for one epoch ---
--- 0.6463351249694824 seconds for one epoch ---
--- 0.31484079360961914 seconds for one epoch ---
--- 0.6015810966491699 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05894742]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2791501]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.29387950897216797 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3298.7822265625, (1370.4299, 0.33877602, 1927.8638, 0.14981847)
   validation loss 1100.0435791015625, (755.71967, 0.11382179, 344.0603, 0.14981847)
decoder loss ratio: 29277.891830, decoder SINDy loss  ratio: 0.742703
--- 0.24431777000427246 seconds for one epoch ---
--- 0.2858867645263672 seconds for one epoch ---
--- 0.5756072998046875 seconds for one epoch ---
--- 0.17612195014953613 seconds for one epoch ---
--- 0.5904226303100586 seconds for one epoch ---
--- 0.28403234481811523 seconds for one epoch ---
--- 0.7132947444915771 seconds for one epoch ---
--- 0.2820718288421631 seconds for one epoch ---
--- 0.6440463066101074 seconds for one epoch ---
--- 0.2930762767791748 seconds for one epoch ---
--- 0.6099832057952881 seconds for one epoch ---
--- 0.2714381217956543 seconds for one epoch ---
--- 0.6130483150482178 seconds for one epoch ---
--- 0.2935349941253662 seconds for one epoch ---
--- 0.6146345138549805 seconds for one epoch ---
--- 0.2883155345916748 seconds for one epoch ---
--- 0.6091723442077637 seconds for one epoch ---
--- 0.2761714458465576 seconds for one epoch ---
--- 0.6533346176147461 seconds for one epoch ---
--- 0.31117725372314453 seconds for one epoch ---
--- 0.6166388988494873 seconds for one epoch ---
--- 0.30800843238830566 seconds for one epoch ---
--- 0.6503257751464844 seconds for one epoch ---
--- 0.28609418869018555 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05807681]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2680446]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.24771642684936523 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3970.926025390625, (1646.3268, 0.33210942, 2324.1174, 0.14969184)
   validation loss 1133.7720947265625, (774.3641, 0.15797246, 359.1004, 0.14969184)
decoder loss ratio: 30000.208609, decoder SINDy loss  ratio: 0.775169
--- 0.3077061176300049 seconds for one epoch ---
--- 0.6191513538360596 seconds for one epoch ---
--- 0.30689263343811035 seconds for one epoch ---
--- 0.6012628078460693 seconds for one epoch ---
--- 0.2898216247558594 seconds for one epoch ---
--- 0.672224760055542 seconds for one epoch ---
--- 0.3005332946777344 seconds for one epoch ---
--- 0.6158952713012695 seconds for one epoch ---
--- 0.29456114768981934 seconds for one epoch ---
--- 0.645805835723877 seconds for one epoch ---
--- 0.288891077041626 seconds for one epoch ---
--- 0.6013078689575195 seconds for one epoch ---
--- 0.30580759048461914 seconds for one epoch ---
--- 0.6550519466400146 seconds for one epoch ---
--- 0.29808568954467773 seconds for one epoch ---
--- 0.6062347888946533 seconds for one epoch ---
--- 0.30426931381225586 seconds for one epoch ---
--- 0.644514799118042 seconds for one epoch ---
--- 0.2791600227355957 seconds for one epoch ---
--- 0.6199336051940918 seconds for one epoch ---
--- 0.3075752258300781 seconds for one epoch ---
--- 0.6492328643798828 seconds for one epoch ---
--- 0.29129743576049805 seconds for one epoch ---
--- 0.6412577629089355 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05733438]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2561647]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.28165173530578613 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4091.973388671875, (1690.44, 0.90175575, 2400.4822, 0.14954345)
   validation loss 1587.3551025390625, (1134.532, 0.12716179, 452.54633, 0.14954345)
decoder loss ratio: 43953.738633, decoder SINDy loss  ratio: 0.976885
--- 0.2604851722717285 seconds for one epoch ---
--- 0.2806706428527832 seconds for one epoch ---
--- 0.6438875198364258 seconds for one epoch ---
--- 0.29755187034606934 seconds for one epoch ---
--- 0.6253499984741211 seconds for one epoch ---
--- 0.28664660453796387 seconds for one epoch ---
--- 0.6309685707092285 seconds for one epoch ---
--- 0.19559669494628906 seconds for one epoch ---
--- 0.6190111637115479 seconds for one epoch ---
--- 0.2727651596069336 seconds for one epoch ---
--- 0.6246631145477295 seconds for one epoch ---
--- 0.2937474250793457 seconds for one epoch ---
--- 0.6371970176696777 seconds for one epoch ---
--- 0.28729987144470215 seconds for one epoch ---
--- 0.619981050491333 seconds for one epoch ---
--- 0.2682805061340332 seconds for one epoch ---
--- 0.6560149192810059 seconds for one epoch ---
--- 0.28480100631713867 seconds for one epoch ---
--- 0.6143248081207275 seconds for one epoch ---
--- 0.3053114414215088 seconds for one epoch ---
--- 0.723261833190918 seconds for one epoch ---
--- 0.2997438907623291 seconds for one epoch ---
--- 0.6302580833435059 seconds for one epoch ---
--- 0.28786635398864746 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05595323]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2144691]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2479557991027832 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4895.00732421875, (3016.153, 0.7869474, 1877.9182, 0.14906967)
   validation loss 1419.20751953125, (1000.4946, 0.20044464, 418.3634, 0.14906967)
decoder loss ratio: 38760.898859, decoder SINDy loss  ratio: 0.903096
--- 0.29115915298461914 seconds for one epoch ---
--- 0.6313767433166504 seconds for one epoch ---
--- 0.2974388599395752 seconds for one epoch ---
--- 0.6257777214050293 seconds for one epoch ---
--- 0.29726123809814453 seconds for one epoch ---
--- 0.6306869983673096 seconds for one epoch ---
--- 0.283597469329834 seconds for one epoch ---
--- 0.6400909423828125 seconds for one epoch ---
--- 0.30335021018981934 seconds for one epoch ---
--- 0.6524293422698975 seconds for one epoch ---
--- 0.2877357006072998 seconds for one epoch ---
--- 0.6536514759063721 seconds for one epoch ---
--- 0.26979899406433105 seconds for one epoch ---
--- 0.778911828994751 seconds for one epoch ---
--- 0.28168153762817383 seconds for one epoch ---
--- 0.6434698104858398 seconds for one epoch ---
--- 0.28267788887023926 seconds for one epoch ---
--- 0.6655011177062988 seconds for one epoch ---
--- 0.2914266586303711 seconds for one epoch ---
--- 0.6318697929382324 seconds for one epoch ---
--- 0.280792236328125 seconds for one epoch ---
--- 0.630894660949707 seconds for one epoch ---
--- 0.2786247730255127 seconds for one epoch ---
--- 0.6609814167022705 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05538175]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2034969]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.29817771911621094 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3923.212646484375, (2027.1406, 0.29074982, 1895.6324, 0.14878738)
   validation loss 2367.991943359375, (1915.8317, 0.1476311, 451.8639, 0.14878738)
decoder loss ratio: 74222.644734, decoder SINDy loss  ratio: 0.975412
--- 0.27384161949157715 seconds for one epoch ---
--- 0.299243688583374 seconds for one epoch ---
--- 0.6609692573547363 seconds for one epoch ---
--- 0.29267191886901855 seconds for one epoch ---
--- 0.6419284343719482 seconds for one epoch ---
--- 0.26894211769104004 seconds for one epoch ---
--- 0.6505844593048096 seconds for one epoch ---
--- 0.2655205726623535 seconds for one epoch ---
--- 0.6615183353424072 seconds for one epoch ---
--- 0.27729177474975586 seconds for one epoch ---
--- 0.6922688484191895 seconds for one epoch ---
--- 0.26564979553222656 seconds for one epoch ---
--- 0.7245621681213379 seconds for one epoch ---
--- 0.2805647850036621 seconds for one epoch ---
--- 0.6617045402526855 seconds for one epoch ---
--- 0.16016650199890137 seconds for one epoch ---
--- 0.6641664505004883 seconds for one epoch ---
--- 0.27940845489501953 seconds for one epoch ---
--- 0.6722002029418945 seconds for one epoch ---
--- 0.29148292541503906 seconds for one epoch ---
--- 0.6733801364898682 seconds for one epoch ---
--- 0.30026793479919434 seconds for one epoch ---
--- 0.6684091091156006 seconds for one epoch ---
--- 0.2863893508911133 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05466796]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-1.18485]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]]
--- 0.2570304870605469 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2997.308837890625, (1729.4209, 0.40782773, 1267.3315, 0.14861935)
   validation loss 1359.167236328125, (1025.7433, 0.19962502, 333.0758, 0.14861935)
decoder loss ratio: 39739.075673, decoder SINDy loss  ratio: 0.718991
--- 0.3027768135070801 seconds for one epoch ---
--- 0.6866345405578613 seconds for one epoch ---
--- 0.2818753719329834 seconds for one epoch ---
--- 0.6542084217071533 seconds for one epoch ---
--- 0.30456089973449707 seconds for one epoch ---
--- 0.6982207298278809 seconds for one epoch ---
--- 0.28174281120300293 seconds for one epoch ---
--- 0.6556081771850586 seconds for one epoch ---
--- 0.29863476753234863 seconds for one epoch ---
--- 0.6652185916900635 seconds for one epoch ---
--- 0.28608012199401855 seconds for one epoch ---
--- 0.6590349674224854 seconds for one epoch ---
--- 0.27815794944763184 seconds for one epoch ---
--- 0.6956632137298584 seconds for one epoch ---
--- 0.27606964111328125 seconds for one epoch ---
--- 0.6991870403289795 seconds for one epoch ---
--- 0.16435599327087402 seconds for one epoch ---
--- 0.7054839134216309 seconds for one epoch ---
--- 0.2842223644256592 seconds for one epoch ---
--- 0.675926685333252 seconds for one epoch ---
--- 0.2891826629638672 seconds for one epoch ---
--- 0.6542484760284424 seconds for one epoch ---
--- 0.27850985527038574 seconds for one epoch ---
--- 0.6795916557312012 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05461851]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1924059]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2969198226928711 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3112.118896484375, (1868.4142, 0.35663292, 1243.1992, 0.14863478)
   validation loss 1534.232666015625, (1148.426, 0.20555818, 385.4524, 0.14863478)
decoder loss ratio: 44492.017979, decoder SINDy loss  ratio: 0.832053
--- 0.2584800720214844 seconds for one epoch ---
--- 0.2966763973236084 seconds for one epoch ---
--- 0.6863894462585449 seconds for one epoch ---
--- 0.2891123294830322 seconds for one epoch ---
--- 0.6974985599517822 seconds for one epoch ---
--- 0.2882673740386963 seconds for one epoch ---
--- 0.7024760246276855 seconds for one epoch ---
--- 0.26202869415283203 seconds for one epoch ---
--- 0.7250185012817383 seconds for one epoch ---
--- 0.29197001457214355 seconds for one epoch ---
--- 0.6832997798919678 seconds for one epoch ---
--- 0.30284833908081055 seconds for one epoch ---
--- 0.72538161277771 seconds for one epoch ---
--- 0.2949371337890625 seconds for one epoch ---
--- 0.6749353408813477 seconds for one epoch ---
--- 0.24089813232421875 seconds for one epoch ---
--- 0.71842360496521 seconds for one epoch ---
--- 0.3123044967651367 seconds for one epoch ---
--- 0.6857476234436035 seconds for one epoch ---
--- 0.3001406192779541 seconds for one epoch ---
--- 0.6884331703186035 seconds for one epoch ---
--- 0.2841062545776367 seconds for one epoch ---
--- 0.685422420501709 seconds for one epoch ---
--- 0.29693174362182617 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0543177]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1880037]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2709674835205078 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3670.3359375, (1371.6371, 0.584777, 2297.9656, 0.14841026)
   validation loss 1147.3824462890625, (720.1403, 0.20251699, 426.89114, 0.14841026)
decoder loss ratio: 27899.486209, decoder SINDy loss  ratio: 0.921505
--- 0.29839611053466797 seconds for one epoch ---
--- 0.6755852699279785 seconds for one epoch ---
--- 0.30777525901794434 seconds for one epoch ---
--- 0.7099452018737793 seconds for one epoch ---
--- 0.31250524520874023 seconds for one epoch ---
--- 0.7265534400939941 seconds for one epoch ---
--- 0.27989768981933594 seconds for one epoch ---
--- 0.6929721832275391 seconds for one epoch ---
--- 0.31105613708496094 seconds for one epoch ---
--- 0.693352222442627 seconds for one epoch ---
--- 0.2895023822784424 seconds for one epoch ---
--- 0.712684154510498 seconds for one epoch ---
--- 0.3032679557800293 seconds for one epoch ---
--- 0.7433273792266846 seconds for one epoch ---
--- 0.2821767330169678 seconds for one epoch ---
--- 0.6878681182861328 seconds for one epoch ---
--- 0.2603919506072998 seconds for one epoch ---
--- 0.6729705333709717 seconds for one epoch ---
--- 0.26139402389526367 seconds for one epoch ---
--- 0.6675896644592285 seconds for one epoch ---
--- 0.24414634704589844 seconds for one epoch ---
--- 0.7054235935211182 seconds for one epoch ---
--- 0.3049123287200928 seconds for one epoch ---
--- 0.6939702033996582 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05354187]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1606336]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.31623291969299316 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4157.51708984375, (2157.827, 1.0963638, 1998.4458, 0.14803173)
   validation loss 2019.7869873046875, (1602.7697, 0.104570284, 416.7647, 0.14803173)
decoder loss ratio: 62094.078900, decoder SINDy loss  ratio: 0.899645
--- 0.2514004707336426 seconds for one epoch ---
--- 0.29677486419677734 seconds for one epoch ---
--- 0.6962270736694336 seconds for one epoch ---
--- 0.26883912086486816 seconds for one epoch ---
--- 0.7015843391418457 seconds for one epoch ---
--- 0.2674980163574219 seconds for one epoch ---
--- 0.684823751449585 seconds for one epoch ---
--- 0.30219435691833496 seconds for one epoch ---
--- 0.6915285587310791 seconds for one epoch ---
--- 0.2996964454650879 seconds for one epoch ---
--- 0.7175638675689697 seconds for one epoch ---
--- 0.30238842964172363 seconds for one epoch ---
--- 0.6732609272003174 seconds for one epoch ---
--- 0.31618785858154297 seconds for one epoch ---
--- 0.7859883308410645 seconds for one epoch ---
--- 0.27376270294189453 seconds for one epoch ---
--- 0.7230277061462402 seconds for one epoch ---
--- 0.29091620445251465 seconds for one epoch ---
--- 0.6918919086456299 seconds for one epoch ---
--- 0.28970789909362793 seconds for one epoch ---
--- 0.7126214504241943 seconds for one epoch ---
--- 0.27837109565734863 seconds for one epoch ---
--- 0.698678731918335 seconds for one epoch ---
--- 0.28855466842651367 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05379405]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1779652]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.23175406455993652 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2316.368408203125, (1244.14, 0.9361108, 1071.1442, 0.14808011)
   validation loss 1094.2918701171875, (785.957, 0.14645724, 308.0403, 0.14808011)
decoder loss ratio: 30449.337507, decoder SINDy loss  ratio: 0.664948
--- 0.2897355556488037 seconds for one epoch ---
--- 0.7045719623565674 seconds for one epoch ---
--- 0.3127126693725586 seconds for one epoch ---
--- 0.7134969234466553 seconds for one epoch ---
--- 0.28241419792175293 seconds for one epoch ---
--- 0.7362058162689209 seconds for one epoch ---
--- 0.3131277561187744 seconds for one epoch ---
--- 0.696929931640625 seconds for one epoch ---
--- 0.2788968086242676 seconds for one epoch ---
--- 0.7541549205780029 seconds for one epoch ---
--- 0.2888665199279785 seconds for one epoch ---
--- 0.7210144996643066 seconds for one epoch ---
--- 0.2938418388366699 seconds for one epoch ---
--- 0.7041826248168945 seconds for one epoch ---
--- 0.2957437038421631 seconds for one epoch ---
--- 0.7151856422424316 seconds for one epoch ---
--- 0.2886197566986084 seconds for one epoch ---
--- 0.7174572944641113 seconds for one epoch ---
--- 0.2846653461456299 seconds for one epoch ---
--- 0.7042391300201416 seconds for one epoch ---
--- 0.2853379249572754 seconds for one epoch ---
--- 0.6884012222290039 seconds for one epoch ---
--- 0.1675570011138916 seconds for one epoch ---
--- 0.7143208980560303 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05300019]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1476824]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.29919862747192383 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5031.3193359375, (1831.2988, 2.2872422, 3197.5857, 0.14738421)
   validation loss 1436.52099609375, (1085.3468, 0.17548488, 350.85132, 0.14738421)
decoder loss ratio: 42048.219345, decoder SINDy loss  ratio: 0.757362
--- 0.2643766403198242 seconds for one epoch ---
--- 0.2837390899658203 seconds for one epoch ---
--- 0.7061097621917725 seconds for one epoch ---
--- 0.30478739738464355 seconds for one epoch ---
--- 0.6908557415008545 seconds for one epoch ---
--- 0.31069493293762207 seconds for one epoch ---
--- 0.6094818115234375 seconds for one epoch ---
--- 0.25325465202331543 seconds for one epoch ---
--- 0.7466254234313965 seconds for one epoch ---
--- 0.3135349750518799 seconds for one epoch ---
--- 0.7295992374420166 seconds for one epoch ---
--- 0.29219961166381836 seconds for one epoch ---
--- 0.729048490524292 seconds for one epoch ---
--- 0.4608480930328369 seconds for one epoch ---
--- 0.72831130027771 seconds for one epoch ---
--- 0.28818535804748535 seconds for one epoch ---
--- 0.718132495880127 seconds for one epoch ---
--- 0.28389549255371094 seconds for one epoch ---
--- 0.7492382526397705 seconds for one epoch ---
--- 0.22919631004333496 seconds for one epoch ---
--- 0.7687468528747559 seconds for one epoch ---
--- 0.2949233055114746 seconds for one epoch ---
--- 0.7816729545593262 seconds for one epoch ---
--- 0.2883036136627197 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05262538]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1354234]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2555811405181885 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3212.454833984375, (1198.7944, 0.96920985, 2012.5443, 0.14682983)
   validation loss 1873.575927734375, (1448.6904, 0.17347968, 424.56516, 0.14682983)
decoder loss ratio: 56124.782283, decoder SINDy loss  ratio: 0.916484
--- 0.2963087558746338 seconds for one epoch ---
--- 0.7309932708740234 seconds for one epoch ---
--- 0.2800633907318115 seconds for one epoch ---
--- 0.7419891357421875 seconds for one epoch ---
--- 0.31420350074768066 seconds for one epoch ---
--- 0.8130292892456055 seconds for one epoch ---
--- 0.2961277961730957 seconds for one epoch ---
--- 0.7993412017822266 seconds for one epoch ---
--- 0.2817726135253906 seconds for one epoch ---
--- 0.7357802391052246 seconds for one epoch ---
--- 0.2979462146759033 seconds for one epoch ---
--- 0.7416946887969971 seconds for one epoch ---
--- 0.2846543788909912 seconds for one epoch ---
--- 0.7436645030975342 seconds for one epoch ---
--- 0.26639246940612793 seconds for one epoch ---
--- 0.6535804271697998 seconds for one epoch ---
--- 0.266864538192749 seconds for one epoch ---
--- 0.7247893810272217 seconds for one epoch ---
--- 0.29087090492248535 seconds for one epoch ---
--- 0.747899055480957 seconds for one epoch ---
--- 0.27880859375 seconds for one epoch ---
--- 0.738940954208374 seconds for one epoch ---
--- 0.30913472175598145 seconds for one epoch ---
--- 0.7076928615570068 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05267701]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1411686]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.31055164337158203 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3091.919921875, (1889.1642, 1.9737685, 1200.636, 0.14610972)
   validation loss 1243.8563232421875, (915.30786, 0.16360559, 328.2387, 0.14610972)
decoder loss ratio: 35460.615592, decoder SINDy loss  ratio: 0.708549
--- 0.2552516460418701 seconds for one epoch ---
--- 0.31151652336120605 seconds for one epoch ---
--- 0.7747068405151367 seconds for one epoch ---
--- 0.2969377040863037 seconds for one epoch ---
--- 0.8161211013793945 seconds for one epoch ---
--- 0.30605602264404297 seconds for one epoch ---
--- 0.7466411590576172 seconds for one epoch ---
--- 0.29860424995422363 seconds for one epoch ---
--- 0.7559645175933838 seconds for one epoch ---
--- 0.30005598068237305 seconds for one epoch ---
--- 0.7431788444519043 seconds for one epoch ---
--- 0.21765685081481934 seconds for one epoch ---
--- 0.7736363410949707 seconds for one epoch ---
--- 0.2968318462371826 seconds for one epoch ---
--- 0.8166735172271729 seconds for one epoch ---
--- 0.29097986221313477 seconds for one epoch ---
--- 0.7640831470489502 seconds for one epoch ---
--- 0.28792500495910645 seconds for one epoch ---
--- 0.7773547172546387 seconds for one epoch ---
--- 0.2872903347015381 seconds for one epoch ---
--- 0.9043540954589844 seconds for one epoch ---
--- 0.30326414108276367 seconds for one epoch ---
--- 0.8181116580963135 seconds for one epoch ---
--- 0.28705596923828125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05212732]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1197863]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2635807991027832 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3894.3310546875, (2338.6523, 1.1946361, 1554.3394, 0.14466499)
   validation loss 1276.7545166015625, (950.2858, 0.19121252, 326.13284, 0.14466499)
decoder loss ratio: 36815.722731, decoder SINDy loss  ratio: 0.704004
--- 0.2970559597015381 seconds for one epoch ---
--- 0.761437177658081 seconds for one epoch ---
--- 0.30088305473327637 seconds for one epoch ---
--- 0.7834815979003906 seconds for one epoch ---
--- 0.29849791526794434 seconds for one epoch ---
--- 0.746962308883667 seconds for one epoch ---
--- 0.29981207847595215 seconds for one epoch ---
--- 0.7562282085418701 seconds for one epoch ---
--- 0.2889745235443115 seconds for one epoch ---
--- 0.7572617530822754 seconds for one epoch ---
--- 0.29778480529785156 seconds for one epoch ---
--- 0.7694871425628662 seconds for one epoch ---
--- 0.29204726219177246 seconds for one epoch ---
--- 0.7579100131988525 seconds for one epoch ---
--- 0.2988574504852295 seconds for one epoch ---
--- 0.7704510688781738 seconds for one epoch ---
--- 0.2879481315612793 seconds for one epoch ---
--- 0.7785336971282959 seconds for one epoch ---
--- 0.281724214553833 seconds for one epoch ---
--- 0.7767479419708252 seconds for one epoch ---
--- 0.29595160484313965 seconds for one epoch ---
--- 0.7639553546905518 seconds for one epoch ---
--- 0.28818249702453613 seconds for one epoch ---
--- 0.7693142890930176 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05218823]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1249896]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.3021054267883301 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4720.11865234375, (2156.3271, 1.1271924, 2562.5215, 0.14318714)
   validation loss 2082.16015625, (1700.7284, 0.12040349, 381.16846, 0.14318714)
decoder loss ratio: 65889.170561, decoder SINDy loss  ratio: 0.822806
THRESHOLDING: 0 active coefficients
--- 0.7677657604217529 seconds for one epoch ---
--- 0.2751777172088623 seconds for one epoch ---
--- 0.7459485530853271 seconds for one epoch ---
--- 0.22093868255615234 seconds for one epoch ---
--- 0.7999937534332275 seconds for one epoch ---
--- 0.2872345447540283 seconds for one epoch ---
--- 0.7577049732208252 seconds for one epoch ---
--- 0.27810168266296387 seconds for one epoch ---
--- 0.7679421901702881 seconds for one epoch ---
--- 0.3002309799194336 seconds for one epoch ---
--- 0.7635014057159424 seconds for one epoch ---
--- 0.28151679039001465 seconds for one epoch ---
--- 0.7557976245880127 seconds for one epoch ---
--- 0.2943596839904785 seconds for one epoch ---
--- 0.7811908721923828 seconds for one epoch ---
--- 0.2872884273529053 seconds for one epoch ---
--- 0.9529478549957275 seconds for one epoch ---
--- 0.295804500579834 seconds for one epoch ---
--- 0.8727340698242188 seconds for one epoch ---
--- 0.2733588218688965 seconds for one epoch ---
--- 0.7945718765258789 seconds for one epoch ---
--- 0.28660154342651367 seconds for one epoch ---
--- 0.7504754066467285 seconds for one epoch ---
--- 0.29885125160217285 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.14115643501281738 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3705.509033203125, (1472.0605, 1.1320101, 2232.3047, 0.01203554)
   validation loss 1093.3453369140625, (708.0004, 0.32580075, 385.007, 0.01203554)
decoder loss ratio: 27429.165694, decoder SINDy loss  ratio: 0.831092
--- 0.2931854724884033 seconds for one epoch ---
--- 0.7949624061584473 seconds for one epoch ---
--- 0.2909567356109619 seconds for one epoch ---
--- 0.8542783260345459 seconds for one epoch ---
--- 0.2892885208129883 seconds for one epoch ---
--- 0.796799898147583 seconds for one epoch ---
--- 0.2605297565460205 seconds for one epoch ---
--- 0.7962815761566162 seconds for one epoch ---
--- 0.28377223014831543 seconds for one epoch ---
--- 0.8157923221588135 seconds for one epoch ---
--- 0.2981553077697754 seconds for one epoch ---
--- 0.8276917934417725 seconds for one epoch ---
--- 0.29776763916015625 seconds for one epoch ---
--- 0.8332915306091309 seconds for one epoch ---
--- 0.2971673011779785 seconds for one epoch ---
--- 0.8042750358581543 seconds for one epoch ---
--- 0.28556275367736816 seconds for one epoch ---
--- 0.8553571701049805 seconds for one epoch ---
--- 0.30152106285095215 seconds for one epoch ---
--- 0.7838518619537354 seconds for one epoch ---
--- 0.2813386917114258 seconds for one epoch ---
--- 0.7785868644714355 seconds for one epoch ---
--- 0.30322813987731934 seconds for one epoch ---
--- 0.807244062423706 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3083362579345703 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2939.929443359375, (1456.9589, 1.2582351, 1481.7004, 0.01203554)
   validation loss 1712.2906494140625, (1236.8463, 0.25994864, 475.17233, 0.01203554)
decoder loss ratio: 47917.573444, decoder SINDy loss  ratio: 1.025726
--- 0.2708866596221924 seconds for one epoch ---
--- 0.3125133514404297 seconds for one epoch ---
--- 0.7974121570587158 seconds for one epoch ---
--- 0.3057420253753662 seconds for one epoch ---
--- 0.79744553565979 seconds for one epoch ---
--- 0.3009450435638428 seconds for one epoch ---
--- 0.7934229373931885 seconds for one epoch ---
--- 0.3090217113494873 seconds for one epoch ---
--- 0.802515983581543 seconds for one epoch ---
--- 0.326458215713501 seconds for one epoch ---
--- 0.7773606777191162 seconds for one epoch ---
--- 0.27727437019348145 seconds for one epoch ---
--- 0.8577425479888916 seconds for one epoch ---
--- 0.3149731159210205 seconds for one epoch ---
--- 0.8009462356567383 seconds for one epoch ---
--- 0.30004072189331055 seconds for one epoch ---
--- 0.8262579441070557 seconds for one epoch ---
--- 0.28546929359436035 seconds for one epoch ---
--- 0.8286130428314209 seconds for one epoch ---
--- 0.2801997661590576 seconds for one epoch ---
--- 0.8292887210845947 seconds for one epoch ---
--- 0.2806282043457031 seconds for one epoch ---
--- 0.7621722221374512 seconds for one epoch ---
--- 0.14389705657958984 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27005934715270996 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3003.974365234375, (1513.1729, 2.2950332, 1488.4946, 0.01203554)
   validation loss 1287.8856201171875, (968.05585, 0.34927282, 319.4685, 0.01203554)
decoder loss ratio: 37504.164138, decoder SINDy loss  ratio: 0.689618
--- 0.2949635982513428 seconds for one epoch ---
--- 0.8138227462768555 seconds for one epoch ---
--- 0.286283016204834 seconds for one epoch ---
--- 0.8061752319335938 seconds for one epoch ---
--- 0.27147936820983887 seconds for one epoch ---
--- 0.8231687545776367 seconds for one epoch ---
--- 0.3040485382080078 seconds for one epoch ---
--- 0.840996503829956 seconds for one epoch ---
--- 0.29691028594970703 seconds for one epoch ---
--- 0.8112609386444092 seconds for one epoch ---
--- 0.29143691062927246 seconds for one epoch ---
--- 0.8633017539978027 seconds for one epoch ---
--- 0.29453229904174805 seconds for one epoch ---
--- 0.854839563369751 seconds for one epoch ---
--- 0.28860974311828613 seconds for one epoch ---
--- 0.7941703796386719 seconds for one epoch ---
--- 0.2933347225189209 seconds for one epoch ---
--- 0.798325777053833 seconds for one epoch ---
--- 0.23501968383789062 seconds for one epoch ---
--- 0.8595306873321533 seconds for one epoch ---
--- 0.27662229537963867 seconds for one epoch ---
--- 0.7933952808380127 seconds for one epoch ---
--- 0.2855381965637207 seconds for one epoch ---
--- 0.8199052810668945 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3028569221496582 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2399.579833984375, (1104.1248, 2.3189452, 1293.1243, 0.01203554)
   validation loss 987.1621704101562, (628.26416, 0.32637945, 358.55963, 0.01203554)
decoder loss ratio: 24340.044279, decoder SINDy loss  ratio: 0.774001
--- 0.2706751823425293 seconds for one epoch ---
--- 0.2987937927246094 seconds for one epoch ---
--- 0.8622128963470459 seconds for one epoch ---
--- 0.29842281341552734 seconds for one epoch ---
--- 0.8161935806274414 seconds for one epoch ---
--- 0.28221964836120605 seconds for one epoch ---
--- 0.8207488059997559 seconds for one epoch ---
--- 0.28548669815063477 seconds for one epoch ---
--- 0.846466064453125 seconds for one epoch ---
--- 0.26000237464904785 seconds for one epoch ---
--- 0.8901124000549316 seconds for one epoch ---
--- 0.2821199893951416 seconds for one epoch ---
--- 0.801992654800415 seconds for one epoch ---
--- 0.2538168430328369 seconds for one epoch ---
--- 0.8410041332244873 seconds for one epoch ---
--- 0.28699564933776855 seconds for one epoch ---
--- 0.8200795650482178 seconds for one epoch ---
--- 0.27918529510498047 seconds for one epoch ---
--- 0.8246359825134277 seconds for one epoch ---
--- 0.30689072608947754 seconds for one epoch ---
--- 0.8248181343078613 seconds for one epoch ---
--- 0.2871546745300293 seconds for one epoch ---
--- 0.7989640235900879 seconds for one epoch ---
--- 0.2740051746368408 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24223971366882324 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2958.581787109375, (1286.4155, 1.1585767, 1670.9956, 0.01203554)
   validation loss 1019.9620971679688, (696.2802, 0.2180954, 323.45175, 0.01203554)
decoder loss ratio: 26975.104224, decoder SINDy loss  ratio: 0.698216
--- 0.29396748542785645 seconds for one epoch ---
--- 0.9084100723266602 seconds for one epoch ---
--- 0.28513526916503906 seconds for one epoch ---
--- 0.8381991386413574 seconds for one epoch ---
--- 0.29640960693359375 seconds for one epoch ---
--- 0.814185380935669 seconds for one epoch ---
--- 0.29561638832092285 seconds for one epoch ---
--- 0.845970869064331 seconds for one epoch ---
--- 0.29109787940979004 seconds for one epoch ---
--- 0.8527083396911621 seconds for one epoch ---
--- 0.31420230865478516 seconds for one epoch ---
--- 0.8426196575164795 seconds for one epoch ---
--- 0.30494236946105957 seconds for one epoch ---
--- 0.838789701461792 seconds for one epoch ---
--- 0.3117518424987793 seconds for one epoch ---
--- 0.859717607498169 seconds for one epoch ---
--- 0.2882411479949951 seconds for one epoch ---
--- 0.8656594753265381 seconds for one epoch ---
--- 0.3036317825317383 seconds for one epoch ---
--- 0.8425710201263428 seconds for one epoch ---
--- 0.2843198776245117 seconds for one epoch ---
--- 0.8299212455749512 seconds for one epoch ---
--- 0.26819849014282227 seconds for one epoch ---
--- 0.8767504692077637 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.30411219596862793 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1903.3333740234375, (638.72156, 7.7124066, 1256.8873, 0.01203554)
   validation loss 1194.401123046875, (841.8975, 0.21284558, 352.27866, 0.01203554)
decoder loss ratio: 32616.571600, decoder SINDy loss  ratio: 0.760443
--- 0.24906420707702637 seconds for one epoch ---
--- 0.29483890533447266 seconds for one epoch ---
--- 0.8529088497161865 seconds for one epoch ---
--- 0.30064845085144043 seconds for one epoch ---
--- 0.8744885921478271 seconds for one epoch ---
--- 0.27465009689331055 seconds for one epoch ---
--- 0.8252551555633545 seconds for one epoch ---
--- 0.2757987976074219 seconds for one epoch ---
--- 0.8361632823944092 seconds for one epoch ---
--- 0.28467392921447754 seconds for one epoch ---
--- 0.8522694110870361 seconds for one epoch ---
--- 0.2932460308074951 seconds for one epoch ---
--- 0.8280038833618164 seconds for one epoch ---
--- 0.31812429428100586 seconds for one epoch ---
--- 0.8658936023712158 seconds for one epoch ---
--- 0.3078606128692627 seconds for one epoch ---
--- 0.8462986946105957 seconds for one epoch ---
--- 0.30303311347961426 seconds for one epoch ---
--- 0.9109036922454834 seconds for one epoch ---
--- 0.3027040958404541 seconds for one epoch ---
--- 0.8685863018035889 seconds for one epoch ---
--- 0.2972848415374756 seconds for one epoch ---
--- 0.8751099109649658 seconds for one epoch ---
--- 0.3079845905303955 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25559473037719727 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2513.4228515625, (1286.4718, 0.86851084, 1226.0706, 0.01203554)
   validation loss 1534.1363525390625, (1167.1973, 0.1810736, 366.7459, 0.01203554)
decoder loss ratio: 45219.248414, decoder SINDy loss  ratio: 0.791673
--- 0.3192625045776367 seconds for one epoch ---
--- 0.8620491027832031 seconds for one epoch ---
--- 0.28859686851501465 seconds for one epoch ---
--- 0.872267484664917 seconds for one epoch ---
--- 0.29177045822143555 seconds for one epoch ---
--- 0.8933291435241699 seconds for one epoch ---
--- 0.29273343086242676 seconds for one epoch ---
--- 0.8840169906616211 seconds for one epoch ---
--- 0.2773258686065674 seconds for one epoch ---
--- 0.8515625 seconds for one epoch ---
--- 0.3020462989807129 seconds for one epoch ---
--- 0.876227617263794 seconds for one epoch ---
--- 0.2895340919494629 seconds for one epoch ---
--- 0.8794615268707275 seconds for one epoch ---
--- 0.29601359367370605 seconds for one epoch ---
--- 0.8766021728515625 seconds for one epoch ---
--- 0.28499746322631836 seconds for one epoch ---
--- 0.8700532913208008 seconds for one epoch ---
--- 0.29517316818237305 seconds for one epoch ---
--- 0.8766686916351318 seconds for one epoch ---
--- 0.2802109718322754 seconds for one epoch ---
--- 0.8604767322540283 seconds for one epoch ---
--- 0.29389286041259766 seconds for one epoch ---
--- 0.8726742267608643 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2983725070953369 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4418.69287109375, (1198.351, 9.50522, 3210.8245, 0.01203554)
   validation loss 968.1343383789062, (623.5476, 0.2793914, 344.29526, 0.01203554)
decoder loss ratio: 24157.316838, decoder SINDy loss  ratio: 0.743210
--- 0.26337170600891113 seconds for one epoch ---
--- 0.29283595085144043 seconds for one epoch ---
--- 0.8792028427124023 seconds for one epoch ---
--- 0.28724217414855957 seconds for one epoch ---
--- 0.8681211471557617 seconds for one epoch ---
--- 0.29727673530578613 seconds for one epoch ---
--- 0.8746726512908936 seconds for one epoch ---
--- 0.29923391342163086 seconds for one epoch ---
--- 0.8972668647766113 seconds for one epoch ---
--- 0.3042764663696289 seconds for one epoch ---
--- 0.937114953994751 seconds for one epoch ---
--- 0.2861168384552002 seconds for one epoch ---
--- 0.9044783115386963 seconds for one epoch ---
--- 0.2955613136291504 seconds for one epoch ---
--- 0.8979818820953369 seconds for one epoch ---
--- 0.28745222091674805 seconds for one epoch ---
--- 0.9051370620727539 seconds for one epoch ---
--- 0.2800922393798828 seconds for one epoch ---
--- 0.8985624313354492 seconds for one epoch ---
--- 0.2813694477081299 seconds for one epoch ---
--- 0.8840320110321045 seconds for one epoch ---
--- 0.27082133293151855 seconds for one epoch ---
--- 0.9035470485687256 seconds for one epoch ---
--- 0.29060888290405273 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26706552505493164 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4475.783203125, (2660.1313, 2.1345243, 1813.505, 0.01203554)
   validation loss 1770.4874267578125, (1264.444, 0.43862817, 505.59277, 0.01203554)
decoder loss ratio: 48986.754558, decoder SINDy loss  ratio: 1.091393
--- 0.3065495491027832 seconds for one epoch ---
--- 0.8779909610748291 seconds for one epoch ---
--- 0.29485297203063965 seconds for one epoch ---
--- 0.8560049533843994 seconds for one epoch ---
--- 0.2771334648132324 seconds for one epoch ---
--- 0.8821165561676025 seconds for one epoch ---
--- 0.2917013168334961 seconds for one epoch ---
--- 0.8763294219970703 seconds for one epoch ---
--- 0.29151105880737305 seconds for one epoch ---
--- 0.9200773239135742 seconds for one epoch ---
--- 0.2964601516723633 seconds for one epoch ---
--- 0.8899490833282471 seconds for one epoch ---
--- 0.28795790672302246 seconds for one epoch ---
--- 0.9032297134399414 seconds for one epoch ---
--- 0.32093238830566406 seconds for one epoch ---
--- 0.9214985370635986 seconds for one epoch ---
--- 0.29216909408569336 seconds for one epoch ---
--- 0.8893604278564453 seconds for one epoch ---
--- 0.3069446086883545 seconds for one epoch ---
--- 0.9316284656524658 seconds for one epoch ---
--- 0.28249573707580566 seconds for one epoch ---
--- 0.9102432727813721 seconds for one epoch ---
--- 0.29563045501708984 seconds for one epoch ---
--- 0.9013299942016602 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29521799087524414 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2944.313232421875, (1110.6238, 1.2324268, 1832.4451, 0.012035004)
   validation loss 1320.4530029296875, (1003.5269, 0.33935004, 316.57468, 0.012035004)
decoder loss ratio: 38878.374945, decoder SINDy loss  ratio: 0.683371
--- 0.22974467277526855 seconds for one epoch ---
--- 0.26007604598999023 seconds for one epoch ---
--- 0.8996682167053223 seconds for one epoch ---
--- 0.27807068824768066 seconds for one epoch ---
--- 0.9212982654571533 seconds for one epoch ---
--- 0.282055139541626 seconds for one epoch ---
--- 0.8918654918670654 seconds for one epoch ---
--- 0.29910874366760254 seconds for one epoch ---
--- 0.9084973335266113 seconds for one epoch ---
--- 0.27970218658447266 seconds for one epoch ---
--- 0.9140539169311523 seconds for one epoch ---
--- 0.29326629638671875 seconds for one epoch ---
--- 0.942007303237915 seconds for one epoch ---
--- 0.2963087558746338 seconds for one epoch ---
--- 0.9385025501251221 seconds for one epoch ---
--- 0.21922659873962402 seconds for one epoch ---
--- 0.9343574047088623 seconds for one epoch ---
--- 0.4631655216217041 seconds for one epoch ---
--- 0.8950424194335938 seconds for one epoch ---
--- 0.2835555076599121 seconds for one epoch ---
--- 0.9530923366546631 seconds for one epoch ---
--- 0.28856706619262695 seconds for one epoch ---
--- 0.8973958492279053 seconds for one epoch ---
--- 0.28827953338623047 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24932622909545898 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4009.871826171875, (2025.958, 2.2317636, 1981.67, 0.012034416)
   validation loss 1176.7757568359375, (794.568, 0.22572841, 381.97003, 0.012034416)
decoder loss ratio: 30782.943486, decoder SINDy loss  ratio: 0.824536
--- 0.28671908378601074 seconds for one epoch ---
--- 0.9025275707244873 seconds for one epoch ---
--- 0.29183411598205566 seconds for one epoch ---
--- 0.9067404270172119 seconds for one epoch ---
--- 0.2838122844696045 seconds for one epoch ---
--- 0.9206736087799072 seconds for one epoch ---
--- 0.28066539764404297 seconds for one epoch ---
--- 0.8974425792694092 seconds for one epoch ---
--- 0.27872514724731445 seconds for one epoch ---
--- 0.9186501502990723 seconds for one epoch ---
--- 0.28322863578796387 seconds for one epoch ---
--- 0.9195897579193115 seconds for one epoch ---
--- 0.2733454704284668 seconds for one epoch ---
--- 0.9098165035247803 seconds for one epoch ---
--- 0.2865724563598633 seconds for one epoch ---
--- 0.9196388721466064 seconds for one epoch ---
--- 0.2870643138885498 seconds for one epoch ---
--- 0.858123779296875 seconds for one epoch ---
--- 0.20159173011779785 seconds for one epoch ---
--- 0.9489748477935791 seconds for one epoch ---
--- 0.30278563499450684 seconds for one epoch ---
--- 0.9430723190307617 seconds for one epoch ---
--- 0.28983139991760254 seconds for one epoch ---
--- 0.9228780269622803 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2806246280670166 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5410.65869140625, (2415.6199, 8.511991, 2986.515, 0.012033528)
   validation loss 999.9255981445312, (642.6162, 0.41450527, 356.88284, 0.012033528)
decoder loss ratio: 24896.067643, decoder SINDy loss  ratio: 0.770382
--- 0.26692938804626465 seconds for one epoch ---
--- 0.27193737030029297 seconds for one epoch ---
--- 0.8943371772766113 seconds for one epoch ---
--- 0.28856706619262695 seconds for one epoch ---
--- 0.9192595481872559 seconds for one epoch ---
--- 0.30014967918395996 seconds for one epoch ---
--- 0.9277286529541016 seconds for one epoch ---
--- 0.3101837635040283 seconds for one epoch ---
--- 0.9989798069000244 seconds for one epoch ---
--- 0.2854797840118408 seconds for one epoch ---
--- 0.960270881652832 seconds for one epoch ---
--- 0.3000938892364502 seconds for one epoch ---
--- 0.9430558681488037 seconds for one epoch ---
--- 0.2909722328186035 seconds for one epoch ---
--- 1.0307424068450928 seconds for one epoch ---
--- 0.278306245803833 seconds for one epoch ---
--- 0.9492940902709961 seconds for one epoch ---
--- 0.26761651039123535 seconds for one epoch ---
--- 0.9278149604797363 seconds for one epoch ---
--- 0.27586793899536133 seconds for one epoch ---
--- 1.0102100372314453 seconds for one epoch ---
--- 0.2864220142364502 seconds for one epoch ---
--- 0.9506151676177979 seconds for one epoch ---
--- 0.31673526763916016 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24417471885681152 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2730.573486328125, (1155.031, 2.4784954, 1573.0521, 0.012032093)
   validation loss 1341.4256591796875, (942.0895, 0.365804, 398.9583, 0.012032093)
decoder loss ratio: 36498.181899, decoder SINDy loss  ratio: 0.861208
--- 0.29299163818359375 seconds for one epoch ---
--- 0.9538567066192627 seconds for one epoch ---
--- 0.29172730445861816 seconds for one epoch ---
--- 0.9683823585510254 seconds for one epoch ---
--- 0.2802445888519287 seconds for one epoch ---
--- 0.9485626220703125 seconds for one epoch ---
--- 0.31714367866516113 seconds for one epoch ---
--- 0.9682705402374268 seconds for one epoch ---
--- 0.19318842887878418 seconds for one epoch ---
--- 0.9793174266815186 seconds for one epoch ---
--- 0.27971959114074707 seconds for one epoch ---
--- 0.9537239074707031 seconds for one epoch ---
--- 0.2720677852630615 seconds for one epoch ---
--- 0.9501917362213135 seconds for one epoch ---
--- 0.28944945335388184 seconds for one epoch ---
--- 1.0543172359466553 seconds for one epoch ---
--- 0.293987512588501 seconds for one epoch ---
--- 1.0281898975372314 seconds for one epoch ---
--- 0.3094654083251953 seconds for one epoch ---
--- 0.9581212997436523 seconds for one epoch ---
--- 0.23649859428405762 seconds for one epoch ---
--- 0.9671335220336914 seconds for one epoch ---
--- 0.29065442085266113 seconds for one epoch ---
--- 0.9847047328948975 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2778770923614502 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2497.4150390625, (1245.1403, 0.8618706, 1251.401, 0.012029819)
   validation loss 1214.1385498046875, (841.3449, 0.27081123, 372.5107, 0.012029819)
decoder loss ratio: 32595.162440, decoder SINDy loss  ratio: 0.804117
--- 0.24697399139404297 seconds for one epoch ---
--- 0.29247045516967773 seconds for one epoch ---
--- 0.9505870342254639 seconds for one epoch ---
--- 0.27716708183288574 seconds for one epoch ---
--- 0.9397993087768555 seconds for one epoch ---
--- 0.30274343490600586 seconds for one epoch ---
--- 0.9333465099334717 seconds for one epoch ---
--- 0.295961856842041 seconds for one epoch ---
--- 0.9581799507141113 seconds for one epoch ---
--- 0.18597698211669922 seconds for one epoch ---
--- 0.9654569625854492 seconds for one epoch ---
--- 0.26566362380981445 seconds for one epoch ---
--- 0.9622514247894287 seconds for one epoch ---
--- 0.28859663009643555 seconds for one epoch ---
--- 1.0022830963134766 seconds for one epoch ---
--- 0.27302026748657227 seconds for one epoch ---
--- 1.0517218112945557 seconds for one epoch ---
--- 0.29335808753967285 seconds for one epoch ---
--- 0.9671506881713867 seconds for one epoch ---
--- 0.27692508697509766 seconds for one epoch ---
--- 0.970005989074707 seconds for one epoch ---
--- 0.15254449844360352 seconds for one epoch ---
--- 1.053612232208252 seconds for one epoch ---
--- 0.2878577709197998 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23932337760925293 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4920.8046875, (1859.5736, 2.25737, 3058.9614, 0.012026205)
   validation loss 1300.9071044921875, (950.7737, 0.25404617, 349.86734, 0.012026205)
decoder loss ratio: 36834.623042, decoder SINDy loss  ratio: 0.755238
--- 0.30025267601013184 seconds for one epoch ---
--- 1.025813102722168 seconds for one epoch ---
--- 0.2884032726287842 seconds for one epoch ---
--- 0.9695019721984863 seconds for one epoch ---
--- 0.30565762519836426 seconds for one epoch ---
--- 0.9999198913574219 seconds for one epoch ---
--- 0.3031132221221924 seconds for one epoch ---
--- 0.9863078594207764 seconds for one epoch ---
--- 0.30658841133117676 seconds for one epoch ---
--- 0.9918313026428223 seconds for one epoch ---
--- 0.3035910129547119 seconds for one epoch ---
--- 0.9799041748046875 seconds for one epoch ---
--- 0.30707693099975586 seconds for one epoch ---
--- 1.0380725860595703 seconds for one epoch ---
--- 0.294248104095459 seconds for one epoch ---
--- 0.9940593242645264 seconds for one epoch ---
--- 0.2881333827972412 seconds for one epoch ---
--- 1.001053810119629 seconds for one epoch ---
--- 0.3114337921142578 seconds for one epoch ---
--- 0.9750299453735352 seconds for one epoch ---
--- 0.27143168449401855 seconds for one epoch ---
--- 1.0306251049041748 seconds for one epoch ---
--- 0.3057856559753418 seconds for one epoch ---
--- 0.9877574443817139 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27937889099121094 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3756.693603515625, (1748.2715, 0.562248, 2007.8478, 0.012020472)
   validation loss 1021.9551391601562, (681.79095, 0.2915969, 339.8605, 0.012020472)
decoder loss ratio: 26413.765222, decoder SINDy loss  ratio: 0.733637
--- 0.25203394889831543 seconds for one epoch ---
--- 0.28947877883911133 seconds for one epoch ---
--- 1.0230908393859863 seconds for one epoch ---
--- 0.27409839630126953 seconds for one epoch ---
--- 1.0627846717834473 seconds for one epoch ---
--- 0.28525257110595703 seconds for one epoch ---
--- 0.995140552520752 seconds for one epoch ---
--- 0.30167436599731445 seconds for one epoch ---
--- 1.0343973636627197 seconds for one epoch ---
--- 0.31847500801086426 seconds for one epoch ---
--- 0.9933075904846191 seconds for one epoch ---
--- 0.2910189628601074 seconds for one epoch ---
--- 1.0075428485870361 seconds for one epoch ---
--- 0.29470014572143555 seconds for one epoch ---
--- 1.0029029846191406 seconds for one epoch ---
--- 0.3007819652557373 seconds for one epoch ---
--- 1.0061416625976562 seconds for one epoch ---
--- 0.31945085525512695 seconds for one epoch ---
--- 0.9227035045623779 seconds for one epoch ---
--- 0.21031570434570312 seconds for one epoch ---
--- 0.992363452911377 seconds for one epoch ---
--- 0.28420519828796387 seconds for one epoch ---
--- 0.9986495971679688 seconds for one epoch ---
--- 0.3074159622192383 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25697970390319824 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2401.466064453125, (925.64874, 0.3719999, 1475.4335, 0.012011367)
   validation loss 867.6068725585938, (551.7899, 0.31547177, 315.48944, 0.012011367)
decoder loss ratio: 21377.299334, decoder SINDy loss  ratio: 0.681028
--- 0.31153035163879395 seconds for one epoch ---
--- 1.012824535369873 seconds for one epoch ---
--- 0.2965426445007324 seconds for one epoch ---
--- 1.007091999053955 seconds for one epoch ---
--- 0.2810642719268799 seconds for one epoch ---
--- 0.9971425533294678 seconds for one epoch ---
--- 0.2782261371612549 seconds for one epoch ---
--- 1.0169646739959717 seconds for one epoch ---
--- 0.28865981101989746 seconds for one epoch ---
--- 1.0197978019714355 seconds for one epoch ---
--- 0.28110361099243164 seconds for one epoch ---
--- 1.028517246246338 seconds for one epoch ---
--- 0.28763723373413086 seconds for one epoch ---
--- 1.009265422821045 seconds for one epoch ---
--- 0.28014421463012695 seconds for one epoch ---
--- 0.9916436672210693 seconds for one epoch ---
--- 0.2837209701538086 seconds for one epoch ---
--- 1.009099006652832 seconds for one epoch ---
--- 0.19556498527526855 seconds for one epoch ---
--- 1.0490145683288574 seconds for one epoch ---
--- 0.2968266010284424 seconds for one epoch ---
--- 1.0022666454315186 seconds for one epoch ---
--- 0.29009032249450684 seconds for one epoch ---
--- 1.0189919471740723 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29793405532836914 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4032.122802734375, (1496.5798, 1.1180576, 2534.413, 0.011996921)
   validation loss 829.0800170898438, (499.96094, 0.34359354, 328.7635, 0.011996921)
decoder loss ratio: 19369.354689, decoder SINDy loss  ratio: 0.709682
--- 0.2607078552246094 seconds for one epoch ---
--- 0.31993699073791504 seconds for one epoch ---
--- 0.9949357509613037 seconds for one epoch ---
--- 0.2970559597015381 seconds for one epoch ---
--- 0.9580533504486084 seconds for one epoch ---
--- 0.1885828971862793 seconds for one epoch ---
--- 1.0016827583312988 seconds for one epoch ---
--- 0.3047759532928467 seconds for one epoch ---
--- 1.0192241668701172 seconds for one epoch ---
--- 0.3005497455596924 seconds for one epoch ---
--- 1.0042712688446045 seconds for one epoch ---
--- 0.2812051773071289 seconds for one epoch ---
--- 1.0343127250671387 seconds for one epoch ---
--- 0.2892181873321533 seconds for one epoch ---
--- 1.009261131286621 seconds for one epoch ---
--- 0.2898678779602051 seconds for one epoch ---
--- 0.925670862197876 seconds for one epoch ---
--- 0.284757137298584 seconds for one epoch ---
--- 1.0113856792449951 seconds for one epoch ---
--- 0.281156063079834 seconds for one epoch ---
--- 1.0431313514709473 seconds for one epoch ---
--- 0.28215575218200684 seconds for one epoch ---
--- 1.0404636859893799 seconds for one epoch ---
--- 0.28174901008605957 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25188136100769043 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3901.518310546875, (2334.06, 1.7135582, 1565.7325, 0.0119740805)
   validation loss 1103.7171630859375, (716.1484, 0.36131975, 387.19547, 0.0119740805)
decoder loss ratio: 27744.831393, decoder SINDy loss  ratio: 0.835816
--- 0.2795557975769043 seconds for one epoch ---
--- 1.035107135772705 seconds for one epoch ---
--- 0.294675350189209 seconds for one epoch ---
--- 0.9455804824829102 seconds for one epoch ---
--- 0.3081791400909424 seconds for one epoch ---
--- 1.027930498123169 seconds for one epoch ---
--- 0.29228806495666504 seconds for one epoch ---
--- 1.042238473892212 seconds for one epoch ---
--- 0.2939646244049072 seconds for one epoch ---
--- 1.0282397270202637 seconds for one epoch ---
--- 0.2854783535003662 seconds for one epoch ---
--- 1.0269639492034912 seconds for one epoch ---
--- 0.29385924339294434 seconds for one epoch ---
--- 1.0465619564056396 seconds for one epoch ---
--- 0.28462719917297363 seconds for one epoch ---
--- 1.0645112991333008 seconds for one epoch ---
--- 0.3066427707672119 seconds for one epoch ---
--- 1.0508742332458496 seconds for one epoch ---
--- 0.285567045211792 seconds for one epoch ---
--- 1.048030138015747 seconds for one epoch ---
--- 0.29336118698120117 seconds for one epoch ---
--- 1.0504906177520752 seconds for one epoch ---
--- 0.3016946315765381 seconds for one epoch ---
--- 1.0509591102600098 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27226924896240234 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2628.510009765625, (1098.6027, 3.238661, 1526.6569, 0.011937971)
   validation loss 1002.5979614257812, (651.2938, 0.3614193, 350.9308, 0.011937971)
decoder loss ratio: 25232.253408, decoder SINDy loss  ratio: 0.757533
THRESHOLDING: 0 active coefficients
--- 0.26433682441711426 seconds for one epoch ---
--- 0.3073601722717285 seconds for one epoch ---
--- 1.0432853698730469 seconds for one epoch ---
--- 0.2869598865509033 seconds for one epoch ---
--- 1.0678532123565674 seconds for one epoch ---
--- 0.2687358856201172 seconds for one epoch ---
--- 1.066843032836914 seconds for one epoch ---
--- 0.3105967044830322 seconds for one epoch ---
--- 1.0404255390167236 seconds for one epoch ---
--- 0.29360055923461914 seconds for one epoch ---
--- 1.0586044788360596 seconds for one epoch ---
--- 0.2985715866088867 seconds for one epoch ---
--- 1.0392098426818848 seconds for one epoch ---
--- 0.2804691791534424 seconds for one epoch ---
--- 1.0572926998138428 seconds for one epoch ---
--- 0.2193160057067871 seconds for one epoch ---
--- 1.0895285606384277 seconds for one epoch ---
--- 0.28499770164489746 seconds for one epoch ---
--- 1.070523977279663 seconds for one epoch ---
--- 0.2906010150909424 seconds for one epoch ---
--- 1.0573132038116455 seconds for one epoch ---
--- 0.28476572036743164 seconds for one epoch ---
--- 1.0645582675933838 seconds for one epoch ---
--- 0.29218006134033203 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24619674682617188 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3416.5419921875, (1313.8073, 4.1241665, 2098.6106, 0.0)
   validation loss 1559.0264892578125, (1161.0554, 0.29976434, 397.67126, 0.0)
decoder loss ratio: 44981.302649, decoder SINDy loss  ratio: 0.858429
--- 0.2764585018157959 seconds for one epoch ---
--- 1.043428659439087 seconds for one epoch ---
--- 0.30332183837890625 seconds for one epoch ---
--- 1.0565555095672607 seconds for one epoch ---
--- 0.28051018714904785 seconds for one epoch ---
--- 1.0558366775512695 seconds for one epoch ---
--- 0.28379321098327637 seconds for one epoch ---
--- 1.0355033874511719 seconds for one epoch ---
--- 0.28392481803894043 seconds for one epoch ---
--- 1.0406560897827148 seconds for one epoch ---
--- 0.27967119216918945 seconds for one epoch ---
--- 1.0441718101501465 seconds for one epoch ---
--- 0.16345643997192383 seconds for one epoch ---
--- 1.0914480686187744 seconds for one epoch ---
--- 0.28525376319885254 seconds for one epoch ---
--- 1.016892671585083 seconds for one epoch ---
--- 0.2786879539489746 seconds for one epoch ---
--- 1.0789570808410645 seconds for one epoch ---
--- 0.28688955307006836 seconds for one epoch ---
--- 1.0553689002990723 seconds for one epoch ---
--- 0.28925275802612305 seconds for one epoch ---
--- 1.065453290939331 seconds for one epoch ---
--- 0.28299522399902344 seconds for one epoch ---
--- 1.0969479084014893 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2973966598510742 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3897.32861328125, (2527.359, 1.9972433, 1367.9725, 0.0)
   validation loss 1756.7593994140625, (1452.4755, 0.30963016, 303.97433, 0.0)
decoder loss ratio: 56271.421079, decoder SINDy loss  ratio: 0.656171
--- 0.17568278312683105 seconds for one epoch ---
--- 0.21724510192871094 seconds for one epoch ---
--- 1.045686960220337 seconds for one epoch ---
--- 0.2934095859527588 seconds for one epoch ---
--- 1.062838077545166 seconds for one epoch ---
--- 0.27475786209106445 seconds for one epoch ---
--- 1.0529966354370117 seconds for one epoch ---
--- 0.2884938716888428 seconds for one epoch ---
--- 1.0227525234222412 seconds for one epoch ---
--- 0.1507563591003418 seconds for one epoch ---
--- 1.0841906070709229 seconds for one epoch ---
--- 0.28092169761657715 seconds for one epoch ---
--- 1.073251485824585 seconds for one epoch ---
--- 0.29831385612487793 seconds for one epoch ---
--- 1.1537091732025146 seconds for one epoch ---
--- 0.27796268463134766 seconds for one epoch ---
--- 1.0807106494903564 seconds for one epoch ---
--- 0.2910141944885254 seconds for one epoch ---
--- 1.1074120998382568 seconds for one epoch ---
--- 0.1925337314605713 seconds for one epoch ---
--- 1.0789148807525635 seconds for one epoch ---
--- 0.2791788578033447 seconds for one epoch ---
--- 1.0762810707092285 seconds for one epoch ---
--- 0.2898590564727783 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23417234420776367 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2371.732666015625, (1049.1733, 2.2275531, 1320.3318, 0.0)
   validation loss 870.922119140625, (538.7644, 0.3641075, 331.79355, 0.0)
decoder loss ratio: 20872.668359, decoder SINDy loss  ratio: 0.716223
--- 0.2875838279724121 seconds for one epoch ---
--- 1.0731382369995117 seconds for one epoch ---
--- 0.28838229179382324 seconds for one epoch ---
--- 1.0692706108093262 seconds for one epoch ---
--- 0.2881786823272705 seconds for one epoch ---
--- 1.05464506149292 seconds for one epoch ---
--- 0.14927935600280762 seconds for one epoch ---
--- 1.101477861404419 seconds for one epoch ---
--- 0.27605557441711426 seconds for one epoch ---
--- 1.0917840003967285 seconds for one epoch ---
--- 0.2857968807220459 seconds for one epoch ---
--- 1.0784528255462646 seconds for one epoch ---
--- 0.3061683177947998 seconds for one epoch ---
--- 1.0661594867706299 seconds for one epoch ---
--- 0.287581205368042 seconds for one epoch ---
--- 1.1533818244934082 seconds for one epoch ---
--- 0.1616976261138916 seconds for one epoch ---
--- 1.0998525619506836 seconds for one epoch ---
--- 0.29465222358703613 seconds for one epoch ---
--- 1.0944595336914062 seconds for one epoch ---
--- 0.29404306411743164 seconds for one epoch ---
--- 1.0836801528930664 seconds for one epoch ---
--- 0.2934691905975342 seconds for one epoch ---
--- 1.089695692062378 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.30782556533813477 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4056.89306640625, (1595.619, 2.790638, 2458.4834, 0.0)
   validation loss 1211.7900390625, (800.1788, 0.30448627, 411.30676, 0.0)
decoder loss ratio: 31000.314798, decoder SINDy loss  ratio: 0.887864
--- 0.2591817378997803 seconds for one epoch ---
--- 0.28064727783203125 seconds for one epoch ---
--- 1.090003490447998 seconds for one epoch ---
--- 0.1927635669708252 seconds for one epoch ---
--- 1.1040318012237549 seconds for one epoch ---
--- 0.29157471656799316 seconds for one epoch ---
--- 1.1040394306182861 seconds for one epoch ---
--- 0.2655069828033447 seconds for one epoch ---
--- 1.092832088470459 seconds for one epoch ---
--- 0.2692699432373047 seconds for one epoch ---
--- 1.1091630458831787 seconds for one epoch ---
--- 0.21965456008911133 seconds for one epoch ---
--- 1.1586496829986572 seconds for one epoch ---
--- 0.27741217613220215 seconds for one epoch ---
--- 1.0885610580444336 seconds for one epoch ---
--- 0.2614939212799072 seconds for one epoch ---
--- 1.1436183452606201 seconds for one epoch ---
--- 0.288693904876709 seconds for one epoch ---
--- 1.0831420421600342 seconds for one epoch ---
--- 0.2896292209625244 seconds for one epoch ---
--- 1.1785709857940674 seconds for one epoch ---
--- 0.3086073398590088 seconds for one epoch ---
--- 1.0835986137390137 seconds for one epoch ---
--- 0.2800722122192383 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2227020263671875 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2139.7734375, (1260.0902, 0.7096036, 878.9736, 0.0)
   validation loss 1087.882568359375, (735.0316, 0.24756242, 352.60342, 0.0)
decoder loss ratio: 28476.400883, decoder SINDy loss  ratio: 0.761144
--- 0.2773592472076416 seconds for one epoch ---
--- 1.1103708744049072 seconds for one epoch ---
--- 0.2921018600463867 seconds for one epoch ---
--- 1.1040916442871094 seconds for one epoch ---
--- 0.3021109104156494 seconds for one epoch ---
--- 1.2285990715026855 seconds for one epoch ---
--- 0.30463695526123047 seconds for one epoch ---
--- 1.0836942195892334 seconds for one epoch ---
--- 0.1529521942138672 seconds for one epoch ---
--- 1.1109631061553955 seconds for one epoch ---
--- 0.29382753372192383 seconds for one epoch ---
--- 1.1148204803466797 seconds for one epoch ---
--- 0.2818412780761719 seconds for one epoch ---
--- 1.0858814716339111 seconds for one epoch ---
--- 0.2992889881134033 seconds for one epoch ---
--- 1.0741820335388184 seconds for one epoch ---
--- 0.22624659538269043 seconds for one epoch ---
--- 1.1531422138214111 seconds for one epoch ---
--- 0.2914862632751465 seconds for one epoch ---
--- 1.1167407035827637 seconds for one epoch ---
--- 0.29044556617736816 seconds for one epoch ---
--- 1.1078076362609863 seconds for one epoch ---
--- 0.2870311737060547 seconds for one epoch ---
--- 1.1302146911621094 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2925097942352295 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3509.53125, (1953.8026, 1.419227, 1554.3093, 0.0)
   validation loss 1244.756591796875, (885.33826, 0.22856519, 359.18976, 0.0)
decoder loss ratio: 34299.541085, decoder SINDy loss  ratio: 0.775362
--- 0.246870756149292 seconds for one epoch ---
--- 0.28320789337158203 seconds for one epoch ---
--- 1.1059291362762451 seconds for one epoch ---
--- 0.28132104873657227 seconds for one epoch ---
--- 1.0855462551116943 seconds for one epoch ---
--- 0.285550594329834 seconds for one epoch ---
--- 1.127314567565918 seconds for one epoch ---
--- 0.2927730083465576 seconds for one epoch ---
--- 1.111363172531128 seconds for one epoch ---
--- 0.2944917678833008 seconds for one epoch ---
--- 1.119215488433838 seconds for one epoch ---
--- 0.29952430725097656 seconds for one epoch ---
--- 1.146521806716919 seconds for one epoch ---
--- 0.29665637016296387 seconds for one epoch ---
--- 1.1252200603485107 seconds for one epoch ---
--- 0.2867445945739746 seconds for one epoch ---
--- 1.1280720233917236 seconds for one epoch ---
--- 0.28676366806030273 seconds for one epoch ---
--- 1.1008374691009521 seconds for one epoch ---
--- 0.14325976371765137 seconds for one epoch ---
--- 1.1310703754425049 seconds for one epoch ---
--- 0.2898895740509033 seconds for one epoch ---
--- 1.1304733753204346 seconds for one epoch ---
--- 0.3011631965637207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2616140842437744 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3138.44482421875, (1087.1512, 2.1144965, 2049.1792, 0.0)
   validation loss 1319.59033203125, (953.06146, 0.2397022, 366.28912, 0.0)
decoder loss ratio: 36923.255641, decoder SINDy loss  ratio: 0.790687
--- 0.30752015113830566 seconds for one epoch ---
--- 1.1218767166137695 seconds for one epoch ---
--- 0.28244590759277344 seconds for one epoch ---
--- 1.1365618705749512 seconds for one epoch ---
--- 0.30193448066711426 seconds for one epoch ---
--- 1.1880967617034912 seconds for one epoch ---
--- 0.2967038154602051 seconds for one epoch ---
--- 1.1367413997650146 seconds for one epoch ---
--- 0.2854499816894531 seconds for one epoch ---
--- 1.186202049255371 seconds for one epoch ---
--- 0.29407191276550293 seconds for one epoch ---
--- 1.1432099342346191 seconds for one epoch ---
--- 0.2990140914916992 seconds for one epoch ---
--- 1.164799451828003 seconds for one epoch ---
--- 0.2957019805908203 seconds for one epoch ---
--- 1.1484549045562744 seconds for one epoch ---
--- 0.2942187786102295 seconds for one epoch ---
--- 1.1397011280059814 seconds for one epoch ---
--- 0.2866225242614746 seconds for one epoch ---
--- 1.164290428161621 seconds for one epoch ---
--- 0.2985520362854004 seconds for one epoch ---
--- 1.1371161937713623 seconds for one epoch ---
--- 0.17286968231201172 seconds for one epoch ---
--- 1.1492927074432373 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23449420928955078 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3975.091552734375, (1927.5089, 0.7581093, 2046.8246, 0.0)
   validation loss 1016.8643188476562, (691.32214, 0.24623486, 325.29596, 0.0)
decoder loss ratio: 26783.020029, decoder SINDy loss  ratio: 0.702197
--- 0.23391151428222656 seconds for one epoch ---
--- 0.23626470565795898 seconds for one epoch ---
--- 1.1717205047607422 seconds for one epoch ---
--- 0.2502024173736572 seconds for one epoch ---
--- 1.1173095703125 seconds for one epoch ---
--- 0.2973160743713379 seconds for one epoch ---
--- 1.1304972171783447 seconds for one epoch ---
--- 0.2929069995880127 seconds for one epoch ---
--- 1.1693437099456787 seconds for one epoch ---
--- 0.2800939083099365 seconds for one epoch ---
--- 1.1811795234680176 seconds for one epoch ---
--- 0.5102057456970215 seconds for one epoch ---
--- 1.1583836078643799 seconds for one epoch ---
--- 0.2914724349975586 seconds for one epoch ---
--- 1.1592676639556885 seconds for one epoch ---
--- 0.2926313877105713 seconds for one epoch ---
--- 1.1586337089538574 seconds for one epoch ---
--- 0.2815978527069092 seconds for one epoch ---
--- 1.173743486404419 seconds for one epoch ---
--- 0.2842075824737549 seconds for one epoch ---
--- 1.1515028476715088 seconds for one epoch ---
--- 0.2949962615966797 seconds for one epoch ---
--- 1.1895763874053955 seconds for one epoch ---
--- 0.2964334487915039 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2529454231262207 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2685.39013671875, (1454.7047, 1.0193611, 1229.666, 0.0)
   validation loss 841.1539916992188, (492.25803, 0.38332227, 348.51263, 0.0)
decoder loss ratio: 19070.930530, decoder SINDy loss  ratio: 0.752314
--- 0.2901909351348877 seconds for one epoch ---
--- 1.1715576648712158 seconds for one epoch ---
--- 0.2986874580383301 seconds for one epoch ---
--- 1.1739883422851562 seconds for one epoch ---
--- 0.28278374671936035 seconds for one epoch ---
--- 1.1566367149353027 seconds for one epoch ---
--- 0.3025195598602295 seconds for one epoch ---
--- 1.1656858921051025 seconds for one epoch ---
--- 0.30248260498046875 seconds for one epoch ---
--- 1.1730518341064453 seconds for one epoch ---
--- 0.3050532341003418 seconds for one epoch ---
--- 1.1389844417572021 seconds for one epoch ---
--- 0.159989595413208 seconds for one epoch ---
--- 1.180753469467163 seconds for one epoch ---
--- 0.3071134090423584 seconds for one epoch ---
--- 1.1988499164581299 seconds for one epoch ---
--- 0.27300095558166504 seconds for one epoch ---
--- 1.1430559158325195 seconds for one epoch ---
--- 0.2859361171722412 seconds for one epoch ---
--- 1.234292984008789 seconds for one epoch ---
--- 0.2857499122619629 seconds for one epoch ---
--- 1.200899362564087 seconds for one epoch ---
--- 0.28496766090393066 seconds for one epoch ---
--- 1.182049036026001 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28155946731567383 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3582.9033203125, (1216.0775, 0.60367197, 2366.2222, 0.0)
   validation loss 994.002685546875, (616.9923, 0.41112337, 376.5992, 0.0)
decoder loss ratio: 23903.353219, decoder SINDy loss  ratio: 0.812942
--- 0.24152112007141113 seconds for one epoch ---
--- 0.2788083553314209 seconds for one epoch ---
--- 1.1784555912017822 seconds for one epoch ---
--- 0.29801225662231445 seconds for one epoch ---
--- 1.1687138080596924 seconds for one epoch ---
--- 0.2567403316497803 seconds for one epoch ---
--- 1.2624285221099854 seconds for one epoch ---
--- 0.26581859588623047 seconds for one epoch ---
--- 1.1958093643188477 seconds for one epoch ---
--- 0.2859625816345215 seconds for one epoch ---
--- 1.2120966911315918 seconds for one epoch ---
--- 0.2943601608276367 seconds for one epoch ---
--- 1.2177486419677734 seconds for one epoch ---
--- 0.2963435649871826 seconds for one epoch ---
--- 1.277773141860962 seconds for one epoch ---
--- 0.29264068603515625 seconds for one epoch ---
--- 1.1981475353240967 seconds for one epoch ---
--- 0.29977989196777344 seconds for one epoch ---
--- 1.2243800163269043 seconds for one epoch ---
--- 0.28635382652282715 seconds for one epoch ---
--- 1.2198090553283691 seconds for one epoch ---
--- 0.2447049617767334 seconds for one epoch ---
--- 1.2928011417388916 seconds for one epoch ---
--- 0.2936551570892334 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23432040214538574 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3532.03564453125, (1710.7858, 0.98868144, 1820.2611, 0.0)
   validation loss 1119.2974853515625, (754.1664, 0.33940732, 364.79172, 0.0)
decoder loss ratio: 29217.714923, decoder SINDy loss  ratio: 0.787454
--- 0.26862454414367676 seconds for one epoch ---
--- 1.1957883834838867 seconds for one epoch ---
--- 0.28958916664123535 seconds for one epoch ---
--- 1.1919050216674805 seconds for one epoch ---
--- 0.2855687141418457 seconds for one epoch ---
--- 1.183398962020874 seconds for one epoch ---
--- 0.27651143074035645 seconds for one epoch ---
--- 1.2063162326812744 seconds for one epoch ---
--- 0.26366686820983887 seconds for one epoch ---
--- 1.2107329368591309 seconds for one epoch ---
--- 0.29731273651123047 seconds for one epoch ---
--- 1.2245805263519287 seconds for one epoch ---
--- 0.28687262535095215 seconds for one epoch ---
--- 1.1805801391601562 seconds for one epoch ---
--- 0.2852914333343506 seconds for one epoch ---
--- 1.2294020652770996 seconds for one epoch ---
--- 0.2997760772705078 seconds for one epoch ---
--- 1.1956331729888916 seconds for one epoch ---
--- 0.29660820960998535 seconds for one epoch ---
--- 1.2420401573181152 seconds for one epoch ---
--- 0.30823731422424316 seconds for one epoch ---
--- 1.2323596477508545 seconds for one epoch ---
--- 0.29727697372436523 seconds for one epoch ---
--- 1.226639986038208 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.19882917404174805 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2983.8818359375, (1376.1343, 0.7210789, 1607.0266, 0.0)
   validation loss 1086.0126953125, (711.0763, 0.28418782, 374.65216, 0.0)
decoder loss ratio: 27548.330110, decoder SINDy loss  ratio: 0.808739
--- 0.25676655769348145 seconds for one epoch ---
--- 0.28832340240478516 seconds for one epoch ---
--- 1.2135412693023682 seconds for one epoch ---
--- 0.28760457038879395 seconds for one epoch ---
--- 1.1850464344024658 seconds for one epoch ---
--- 0.28699707984924316 seconds for one epoch ---
--- 1.1970727443695068 seconds for one epoch ---
--- 0.2791311740875244 seconds for one epoch ---
--- 1.2998676300048828 seconds for one epoch ---
--- 0.2953202724456787 seconds for one epoch ---
--- 1.229801893234253 seconds for one epoch ---
--- 0.2794003486633301 seconds for one epoch ---
--- 1.1981730461120605 seconds for one epoch ---
--- 0.30002546310424805 seconds for one epoch ---
--- 1.2320504188537598 seconds for one epoch ---
--- 0.1983656883239746 seconds for one epoch ---
--- 1.2071247100830078 seconds for one epoch ---
--- 0.26848602294921875 seconds for one epoch ---
--- 1.1993184089660645 seconds for one epoch ---
--- 0.29142165184020996 seconds for one epoch ---
--- 1.2300565242767334 seconds for one epoch ---
--- 0.29501914978027344 seconds for one epoch ---
--- 1.2236647605895996 seconds for one epoch ---
--- 0.28130650520324707 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24992632865905762 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4721.97509765625, (1943.0219, 1.0777892, 2777.8755, 0.0)
   validation loss 1543.922119140625, (1207.1213, 0.24995688, 336.55084, 0.0)
decoder loss ratio: 46765.976285, decoder SINDy loss  ratio: 0.726492
--- 0.1912086009979248 seconds for one epoch ---
--- 1.1935200691223145 seconds for one epoch ---
--- 0.28771424293518066 seconds for one epoch ---
--- 1.2237837314605713 seconds for one epoch ---
--- 0.29672789573669434 seconds for one epoch ---
--- 1.2456889152526855 seconds for one epoch ---
--- 0.29097819328308105 seconds for one epoch ---
--- 1.3300423622131348 seconds for one epoch ---
--- 0.2865316867828369 seconds for one epoch ---
--- 1.2425520420074463 seconds for one epoch ---
--- 0.2914459705352783 seconds for one epoch ---
--- 1.2297890186309814 seconds for one epoch ---
--- 0.288524866104126 seconds for one epoch ---
--- 1.240492820739746 seconds for one epoch ---
--- 0.2875940799713135 seconds for one epoch ---
--- 1.2306838035583496 seconds for one epoch ---
--- 0.29239487648010254 seconds for one epoch ---
--- 1.2280349731445312 seconds for one epoch ---
--- 0.30785703659057617 seconds for one epoch ---
--- 1.2453558444976807 seconds for one epoch ---
--- 0.28226327896118164 seconds for one epoch ---
--- 1.2348108291625977 seconds for one epoch ---
--- 0.3068654537200928 seconds for one epoch ---
--- 1.2489371299743652 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2760038375854492 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2931.19189453125, (1110.3055, 1.7427853, 1819.1437, 0.0)
   validation loss 1115.4700927734375, (757.6237, 0.32735282, 357.51907, 0.0)
decoder loss ratio: 29351.658138, decoder SINDy loss  ratio: 0.771755
--- 0.24579071998596191 seconds for one epoch ---
--- 0.28125667572021484 seconds for one epoch ---
--- 1.2264823913574219 seconds for one epoch ---
--- 0.27828073501586914 seconds for one epoch ---
--- 1.2306110858917236 seconds for one epoch ---
--- 0.2993783950805664 seconds for one epoch ---
--- 1.2343268394470215 seconds for one epoch ---
--- 0.28796958923339844 seconds for one epoch ---
--- 1.2239477634429932 seconds for one epoch ---
--- 0.28576207160949707 seconds for one epoch ---
--- 1.2618129253387451 seconds for one epoch ---
--- 0.27836084365844727 seconds for one epoch ---
--- 1.2586805820465088 seconds for one epoch ---
--- 0.28655576705932617 seconds for one epoch ---
--- 1.2602083683013916 seconds for one epoch ---
--- 0.2872140407562256 seconds for one epoch ---
--- 1.2784569263458252 seconds for one epoch ---
--- 0.2766842842102051 seconds for one epoch ---
--- 1.3084559440612793 seconds for one epoch ---
--- 0.28078770637512207 seconds for one epoch ---
--- 1.2650513648986816 seconds for one epoch ---
--- 0.2827420234680176 seconds for one epoch ---
--- 1.2209844589233398 seconds for one epoch ---
--- 0.2834434509277344 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23690128326416016 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1847.874267578125, (811.304, 4.472311, 1032.098, 0.0)
   validation loss 970.5029296875, (636.08875, 0.3897605, 334.02444, 0.0)
decoder loss ratio: 24643.182284, decoder SINDy loss  ratio: 0.721039
--- 0.2830507755279541 seconds for one epoch ---
--- 1.2311267852783203 seconds for one epoch ---
--- 0.25945305824279785 seconds for one epoch ---
--- 1.2874677181243896 seconds for one epoch ---
--- 0.29443788528442383 seconds for one epoch ---
--- 1.2355153560638428 seconds for one epoch ---
--- 0.29459571838378906 seconds for one epoch ---
--- 1.2283687591552734 seconds for one epoch ---
--- 0.29871606826782227 seconds for one epoch ---
--- 1.2410697937011719 seconds for one epoch ---
--- 0.17659711837768555 seconds for one epoch ---
--- 1.242105484008789 seconds for one epoch ---
--- 0.28672146797180176 seconds for one epoch ---
--- 1.2636630535125732 seconds for one epoch ---
--- 0.283766508102417 seconds for one epoch ---
--- 1.2638602256774902 seconds for one epoch ---
--- 0.30187082290649414 seconds for one epoch ---
--- 1.2165534496307373 seconds for one epoch ---
--- 0.14647865295410156 seconds for one epoch ---
--- 1.2720069885253906 seconds for one epoch ---
--- 0.2918581962585449 seconds for one epoch ---
--- 1.2650835514068604 seconds for one epoch ---
--- 0.2627880573272705 seconds for one epoch ---
--- 1.2803757190704346 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2832498550415039 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5471.85693359375, (1485.6041, 7.042723, 3979.2102, 0.0)
   validation loss 1012.0543212890625, (657.45245, 0.33043525, 354.27145, 0.0)
decoder loss ratio: 25470.849441, decoder SINDy loss  ratio: 0.764745
--- 0.27408409118652344 seconds for one epoch ---
--- 0.30007433891296387 seconds for one epoch ---
--- 1.1285386085510254 seconds for one epoch ---
--- 0.2972099781036377 seconds for one epoch ---
--- 1.254772663116455 seconds for one epoch ---
--- 0.29805707931518555 seconds for one epoch ---
--- 1.2552437782287598 seconds for one epoch ---
--- 0.29149389266967773 seconds for one epoch ---
--- 1.2835028171539307 seconds for one epoch ---
--- 0.312652587890625 seconds for one epoch ---
--- 1.3213801383972168 seconds for one epoch ---
--- 0.2975773811340332 seconds for one epoch ---
--- 1.2903952598571777 seconds for one epoch ---
--- 0.30099058151245117 seconds for one epoch ---
--- 1.292748212814331 seconds for one epoch ---
--- 0.2940187454223633 seconds for one epoch ---
--- 1.2885968685150146 seconds for one epoch ---
--- 0.27823424339294434 seconds for one epoch ---
--- 1.284379243850708 seconds for one epoch ---
--- 0.28374195098876953 seconds for one epoch ---
--- 1.260371446609497 seconds for one epoch ---
--- 0.2950613498687744 seconds for one epoch ---
--- 1.2819263935089111 seconds for one epoch ---
--- 0.28408026695251465 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24901390075683594 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6158.9169921875, (2032.0359, 1.0294428, 4125.8516, 0.0)
   validation loss 925.7777099609375, (543.6548, 0.39113897, 381.73178, 0.0)
decoder loss ratio: 21062.130203, decoder SINDy loss  ratio: 0.824022
--- 0.2960774898529053 seconds for one epoch ---
--- 1.313948392868042 seconds for one epoch ---
--- 0.2892146110534668 seconds for one epoch ---
--- 1.303342580795288 seconds for one epoch ---
--- 0.28647851943969727 seconds for one epoch ---
--- 1.25649094581604 seconds for one epoch ---
--- 0.28456592559814453 seconds for one epoch ---
--- 1.2751214504241943 seconds for one epoch ---
--- 0.30416321754455566 seconds for one epoch ---
--- 1.2690293788909912 seconds for one epoch ---
--- 0.18100404739379883 seconds for one epoch ---
--- 1.3268609046936035 seconds for one epoch ---
--- 0.29184865951538086 seconds for one epoch ---
--- 1.2759876251220703 seconds for one epoch ---
--- 0.2894444465637207 seconds for one epoch ---
--- 1.2847917079925537 seconds for one epoch ---
--- 0.29757189750671387 seconds for one epoch ---
--- 1.1789774894714355 seconds for one epoch ---
--- 0.20541596412658691 seconds for one epoch ---
--- 1.2728400230407715 seconds for one epoch ---
--- 0.28667378425598145 seconds for one epoch ---
--- 1.2733936309814453 seconds for one epoch ---
--- 0.27983617782592773 seconds for one epoch ---
--- 1.4151878356933594 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28077268600463867 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2687.94970703125, (1725.1322, 0.5571633, 962.2605, 0.0)
   validation loss 1571.00537109375, (1235.9755, 0.3725443, 334.65732, 0.0)
decoder loss ratio: 47883.835218, decoder SINDy loss  ratio: 0.722405
--- 0.2295989990234375 seconds for one epoch ---
--- 0.25990867614746094 seconds for one epoch ---
--- 1.3449938297271729 seconds for one epoch ---
--- 0.28951144218444824 seconds for one epoch ---
--- 1.3131537437438965 seconds for one epoch ---
--- 0.29325079917907715 seconds for one epoch ---
--- 1.3115813732147217 seconds for one epoch ---
--- 0.2540159225463867 seconds for one epoch ---
--- 1.2853400707244873 seconds for one epoch ---
--- 0.14892816543579102 seconds for one epoch ---
--- 1.257594347000122 seconds for one epoch ---
--- 0.2882661819458008 seconds for one epoch ---
--- 1.3077590465545654 seconds for one epoch ---
--- 0.2979099750518799 seconds for one epoch ---
--- 1.3177165985107422 seconds for one epoch ---
--- 0.2959325313568115 seconds for one epoch ---
--- 1.2622933387756348 seconds for one epoch ---
--- 0.27869486808776855 seconds for one epoch ---
--- 1.3052568435668945 seconds for one epoch ---
--- 0.28923535346984863 seconds for one epoch ---
--- 1.3028573989868164 seconds for one epoch ---
--- 0.31099414825439453 seconds for one epoch ---
--- 1.290313482284546 seconds for one epoch ---
--- 0.291961669921875 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25683116912841797 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2507.5625, (1105.2506, 1.5973243, 1400.7146, 0.0)
   validation loss 1110.218994140625, (771.8783, 0.30247247, 338.0382, 0.0)
decoder loss ratio: 29903.905223, decoder SINDy loss  ratio: 0.729703
--- 0.304811954498291 seconds for one epoch ---
--- 1.3112688064575195 seconds for one epoch ---
--- 0.27396178245544434 seconds for one epoch ---
--- 1.2631454467773438 seconds for one epoch ---
--- 0.286146879196167 seconds for one epoch ---
--- 1.3295693397521973 seconds for one epoch ---
--- 0.2863297462463379 seconds for one epoch ---
--- 1.3103060722351074 seconds for one epoch ---
--- 0.2695167064666748 seconds for one epoch ---
--- 1.3851025104522705 seconds for one epoch ---
--- 0.29737329483032227 seconds for one epoch ---
--- 1.3225271701812744 seconds for one epoch ---
--- 0.28707194328308105 seconds for one epoch ---
--- 1.322725772857666 seconds for one epoch ---
--- 0.2857847213745117 seconds for one epoch ---
--- 1.378654956817627 seconds for one epoch ---
--- 0.28429746627807617 seconds for one epoch ---
--- 1.365804672241211 seconds for one epoch ---
--- 0.2675204277038574 seconds for one epoch ---
--- 1.3202967643737793 seconds for one epoch ---
--- 0.28055810928344727 seconds for one epoch ---
--- 1.3795104026794434 seconds for one epoch ---
--- 0.28577518463134766 seconds for one epoch ---
--- 1.3606984615325928 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.19499826431274414 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1816.17919921875, (598.6199, 1.805145, 1215.7542, 0.0)
   validation loss 1197.9949951171875, (816.1436, 0.31629622, 381.5351, 0.0)
decoder loss ratio: 31618.820561, decoder SINDy loss  ratio: 0.823597
THRESHOLDING: 0 active coefficients
--- 1.2876055240631104 seconds for one epoch ---
--- 0.29105567932128906 seconds for one epoch ---
--- 1.2995316982269287 seconds for one epoch ---
--- 0.28377270698547363 seconds for one epoch ---
--- 1.3308308124542236 seconds for one epoch ---
--- 0.28872203826904297 seconds for one epoch ---
--- 1.2651004791259766 seconds for one epoch ---
--- 0.29395365715026855 seconds for one epoch ---
--- 1.3303391933441162 seconds for one epoch ---
--- 0.2904644012451172 seconds for one epoch ---
--- 1.3435852527618408 seconds for one epoch ---
--- 0.2582554817199707 seconds for one epoch ---
--- 1.314950942993164 seconds for one epoch ---
--- 0.28936338424682617 seconds for one epoch ---
--- 1.281841516494751 seconds for one epoch ---
--- 0.1473696231842041 seconds for one epoch ---
--- 1.337773084640503 seconds for one epoch ---
--- 0.2979543209075928 seconds for one epoch ---
--- 1.3144948482513428 seconds for one epoch ---
--- 0.28454089164733887 seconds for one epoch ---
--- 1.328970193862915 seconds for one epoch ---
--- 0.29149675369262695 seconds for one epoch ---
--- 1.3249242305755615 seconds for one epoch ---
--- 0.29726409912109375 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24326801300048828 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1813.0712890625, (860.6162, 0.553669, 951.90137, 0.0)
   validation loss 794.4400634765625, (465.91956, 0.45511976, 328.0654, 0.0)
decoder loss ratio: 18050.532458, decoder SINDy loss  ratio: 0.708175
--- 0.28158044815063477 seconds for one epoch ---
--- 1.3559038639068604 seconds for one epoch ---
--- 0.2881629467010498 seconds for one epoch ---
--- 1.398409128189087 seconds for one epoch ---
--- 0.1950087547302246 seconds for one epoch ---
--- 1.3514885902404785 seconds for one epoch ---
--- 0.2877309322357178 seconds for one epoch ---
--- 1.3658864498138428 seconds for one epoch ---
--- 0.2751576900482178 seconds for one epoch ---
--- 1.3347413539886475 seconds for one epoch ---
--- 0.2854318618774414 seconds for one epoch ---
--- 1.350358486175537 seconds for one epoch ---
--- 0.29999375343322754 seconds for one epoch ---
--- 1.3737645149230957 seconds for one epoch ---
--- 0.2846219539642334 seconds for one epoch ---
--- 1.3339571952819824 seconds for one epoch ---
--- 0.2790548801422119 seconds for one epoch ---
--- 1.3411431312561035 seconds for one epoch ---
--- 0.2943720817565918 seconds for one epoch ---
--- 1.3406589031219482 seconds for one epoch ---
--- 0.3080258369445801 seconds for one epoch ---
--- 1.37959885597229 seconds for one epoch ---
--- 0.27836108207702637 seconds for one epoch ---
--- 1.3511312007904053 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3078174591064453 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1667.165771484375, (940.1185, 1.1091082, 725.9381, 0.0)
   validation loss 971.52001953125, (621.93994, 0.40547964, 349.1746, 0.0)
decoder loss ratio: 24095.033065, decoder SINDy loss  ratio: 0.753742
--- 0.23644471168518066 seconds for one epoch ---
--- 0.27416229248046875 seconds for one epoch ---
--- 1.3688368797302246 seconds for one epoch ---
--- 0.28853750228881836 seconds for one epoch ---
--- 1.3141987323760986 seconds for one epoch ---
--- 0.276806116104126 seconds for one epoch ---
--- 1.317755937576294 seconds for one epoch ---
--- 0.29314088821411133 seconds for one epoch ---
--- 1.3485803604125977 seconds for one epoch ---
--- 0.2897958755493164 seconds for one epoch ---
--- 1.386502742767334 seconds for one epoch ---
--- 0.27385878562927246 seconds for one epoch ---
--- 1.3839993476867676 seconds for one epoch ---
--- 0.30446839332580566 seconds for one epoch ---
--- 1.3744070529937744 seconds for one epoch ---
--- 0.29140472412109375 seconds for one epoch ---
--- 1.3598241806030273 seconds for one epoch ---
--- 0.28690648078918457 seconds for one epoch ---
--- 1.35976243019104 seconds for one epoch ---
--- 0.30974531173706055 seconds for one epoch ---
--- 1.3421919345855713 seconds for one epoch ---
--- 0.26932811737060547 seconds for one epoch ---
--- 1.3439021110534668 seconds for one epoch ---
--- 0.301227331161499 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27397871017456055 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2523.397216796875, (1137.7496, 0.73326415, 1384.9143, 0.0)
   validation loss 994.5452880859375, (650.6234, 0.39001366, 343.53183, 0.0)
decoder loss ratio: 25206.280555, decoder SINDy loss  ratio: 0.741562
--- 0.3006749153137207 seconds for one epoch ---
--- 1.339371919631958 seconds for one epoch ---
--- 0.2909853458404541 seconds for one epoch ---
--- 1.357320785522461 seconds for one epoch ---
--- 0.2816791534423828 seconds for one epoch ---
--- 1.3770899772644043 seconds for one epoch ---
--- 0.2965199947357178 seconds for one epoch ---
--- 1.3725972175598145 seconds for one epoch ---
--- 0.27333736419677734 seconds for one epoch ---
--- 1.3618507385253906 seconds for one epoch ---
--- 0.3070650100708008 seconds for one epoch ---
--- 1.3860890865325928 seconds for one epoch ---
--- 0.2848362922668457 seconds for one epoch ---
--- 1.4008688926696777 seconds for one epoch ---
--- 0.28957366943359375 seconds for one epoch ---
--- 1.40309476852417 seconds for one epoch ---
--- 0.2881200313568115 seconds for one epoch ---
--- 1.389611005783081 seconds for one epoch ---
--- 0.2926454544067383 seconds for one epoch ---
--- 1.3850600719451904 seconds for one epoch ---
--- 0.29760098457336426 seconds for one epoch ---
--- 1.2676174640655518 seconds for one epoch ---
--- 0.18928813934326172 seconds for one epoch ---
--- 1.352092981338501 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3124508857727051 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6950.958984375, (2296.2534, 2.1384604, 4652.5674, 0.0)
   validation loss 1032.5791015625, (675.5037, 0.41393396, 356.66147, 0.0)
decoder loss ratio: 26170.186961, decoder SINDy loss  ratio: 0.769904
--- 0.23972558975219727 seconds for one epoch ---
--- 0.3003973960876465 seconds for one epoch ---
--- 1.4588854312896729 seconds for one epoch ---
--- 0.2939338684082031 seconds for one epoch ---
--- 1.3558070659637451 seconds for one epoch ---
--- 0.2519834041595459 seconds for one epoch ---
--- 1.3676245212554932 seconds for one epoch ---
--- 0.25574254989624023 seconds for one epoch ---
--- 1.4152030944824219 seconds for one epoch ---
--- 0.29160094261169434 seconds for one epoch ---
--- 1.4480817317962646 seconds for one epoch ---
--- 0.30074453353881836 seconds for one epoch ---
--- 1.3675005435943604 seconds for one epoch ---
--- 0.30263519287109375 seconds for one epoch ---
--- 1.3525457382202148 seconds for one epoch ---
--- 0.27694153785705566 seconds for one epoch ---
--- 1.36354660987854 seconds for one epoch ---
--- 0.2713930606842041 seconds for one epoch ---
--- 1.403219223022461 seconds for one epoch ---
--- 0.28926873207092285 seconds for one epoch ---
--- 1.3976349830627441 seconds for one epoch ---
--- 0.2827026844024658 seconds for one epoch ---
--- 1.3852827548980713 seconds for one epoch ---
--- 0.2841179370880127 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2363109588623047 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2977.720703125, (1308.5677, 2.1758065, 1666.9772, 0.0)
   validation loss 1118.0281982421875, (709.55255, 0.35784107, 408.11783, 0.0)
decoder loss ratio: 27489.297674, decoder SINDy loss  ratio: 0.880980
--- 0.2749671936035156 seconds for one epoch ---
--- 1.3792848587036133 seconds for one epoch ---
--- 0.2773702144622803 seconds for one epoch ---
--- 1.3602068424224854 seconds for one epoch ---
--- 0.2730903625488281 seconds for one epoch ---
--- 1.3528335094451904 seconds for one epoch ---
--- 0.14543390274047852 seconds for one epoch ---
--- 1.4020178318023682 seconds for one epoch ---
--- 0.26629638671875 seconds for one epoch ---
--- 1.3856947422027588 seconds for one epoch ---
--- 0.30588555335998535 seconds for one epoch ---
--- 1.4112839698791504 seconds for one epoch ---
--- 0.3159658908843994 seconds for one epoch ---
--- 1.3968677520751953 seconds for one epoch ---
--- 0.2948801517486572 seconds for one epoch ---
--- 1.4077680110931396 seconds for one epoch ---
--- 0.3029630184173584 seconds for one epoch ---
--- 1.3978681564331055 seconds for one epoch ---
--- 0.2897036075592041 seconds for one epoch ---
--- 1.4204390048980713 seconds for one epoch ---
--- 0.2829551696777344 seconds for one epoch ---
--- 1.3896501064300537 seconds for one epoch ---
--- 0.30341291427612305 seconds for one epoch ---
--- 1.4190902709960938 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2610604763031006 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3560.0400390625, (1549.1132, 3.8044584, 2007.1224, 0.0)
   validation loss 1098.15283203125, (752.1675, 0.43598753, 345.54935, 0.0)
decoder loss ratio: 29140.274014, decoder SINDy loss  ratio: 0.745917
--- 0.23970842361450195 seconds for one epoch ---
--- 0.276151180267334 seconds for one epoch ---
--- 1.3647782802581787 seconds for one epoch ---
--- 0.19365143775939941 seconds for one epoch ---
--- 1.4209299087524414 seconds for one epoch ---
--- 0.2783019542694092 seconds for one epoch ---
--- 1.3775265216827393 seconds for one epoch ---
--- 0.2886466979980469 seconds for one epoch ---
--- 1.400566816329956 seconds for one epoch ---
--- 0.2754364013671875 seconds for one epoch ---
--- 1.4179742336273193 seconds for one epoch ---
--- 0.298004150390625 seconds for one epoch ---
--- 1.4300801753997803 seconds for one epoch ---
--- 0.29489874839782715 seconds for one epoch ---
--- 1.3965463638305664 seconds for one epoch ---
--- 0.29482221603393555 seconds for one epoch ---
--- 1.4167394638061523 seconds for one epoch ---
--- 0.2871229648590088 seconds for one epoch ---
--- 1.493617057800293 seconds for one epoch ---
--- 0.2795398235321045 seconds for one epoch ---
--- 1.4309453964233398 seconds for one epoch ---
--- 0.29889392852783203 seconds for one epoch ---
--- 1.4349112510681152 seconds for one epoch ---
--- 0.2871425151824951 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.1947469711303711 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3011.75146484375, (1448.2249, 1.0733799, 1562.4531, 0.0)
   validation loss 1081.6463623046875, (721.41364, 0.37347245, 359.85928, 0.0)
decoder loss ratio: 27948.816659, decoder SINDy loss  ratio: 0.776807
--- 0.16370940208435059 seconds for one epoch ---
--- 1.3933837413787842 seconds for one epoch ---
--- 0.2795450687408447 seconds for one epoch ---
--- 1.4142167568206787 seconds for one epoch ---
--- 0.2942683696746826 seconds for one epoch ---
--- 1.41518235206604 seconds for one epoch ---
--- 0.24232101440429688 seconds for one epoch ---
--- 1.422811508178711 seconds for one epoch ---
--- 0.2610313892364502 seconds for one epoch ---
--- 1.3992433547973633 seconds for one epoch ---
--- 0.2556788921356201 seconds for one epoch ---
--- 1.4277677536010742 seconds for one epoch ---
--- 0.2913820743560791 seconds for one epoch ---
--- 1.3412621021270752 seconds for one epoch ---
--- 0.18883943557739258 seconds for one epoch ---
--- 1.5054166316986084 seconds for one epoch ---
--- 0.2893028259277344 seconds for one epoch ---
--- 1.4346213340759277 seconds for one epoch ---
--- 0.30461907386779785 seconds for one epoch ---
--- 1.4377810955047607 seconds for one epoch ---
--- 0.2808871269226074 seconds for one epoch ---
--- 1.3142614364624023 seconds for one epoch ---
--- 0.20251750946044922 seconds for one epoch ---
--- 1.430295467376709 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2818262577056885 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3203.81298828125, (1642.5919, 0.6214229, 1560.5996, 0.0)
   validation loss 938.455810546875, (591.7056, 0.48146668, 346.2687, 0.0)
decoder loss ratio: 22923.703253, decoder SINDy loss  ratio: 0.747470
--- 0.25731348991394043 seconds for one epoch ---
--- 0.2807140350341797 seconds for one epoch ---
--- 1.4194605350494385 seconds for one epoch ---
--- 0.28690648078918457 seconds for one epoch ---
--- 1.5004024505615234 seconds for one epoch ---
--- 0.28351402282714844 seconds for one epoch ---
--- 1.4444844722747803 seconds for one epoch ---
--- 0.30756282806396484 seconds for one epoch ---
--- 1.4369845390319824 seconds for one epoch ---
--- 0.27408456802368164 seconds for one epoch ---
--- 1.4620919227600098 seconds for one epoch ---
--- 0.2918739318847656 seconds for one epoch ---
--- 1.4480059146881104 seconds for one epoch ---
--- 0.2904508113861084 seconds for one epoch ---
--- 1.4268620014190674 seconds for one epoch ---
--- 0.28342509269714355 seconds for one epoch ---
--- 1.4559550285339355 seconds for one epoch ---
--- 0.2801671028137207 seconds for one epoch ---
--- 1.422846794128418 seconds for one epoch ---
--- 0.31558728218078613 seconds for one epoch ---
--- 1.5079560279846191 seconds for one epoch ---
--- 0.3101513385772705 seconds for one epoch ---
--- 1.495405912399292 seconds for one epoch ---
--- 0.30823421478271484 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24935317039489746 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3590.83984375, (1302.0098, 1.7800009, 2287.05, 0.0)
   validation loss 874.2952880859375, (526.2706, 0.50071955, 347.5239, 0.0)
decoder loss ratio: 20388.637848, decoder SINDy loss  ratio: 0.750179
--- 0.2910311222076416 seconds for one epoch ---
--- 1.4351906776428223 seconds for one epoch ---
--- 0.29175877571105957 seconds for one epoch ---
--- 1.4366123676300049 seconds for one epoch ---
--- 0.2957797050476074 seconds for one epoch ---
--- 1.4542787075042725 seconds for one epoch ---
--- 0.2881903648376465 seconds for one epoch ---
--- 1.4799158573150635 seconds for one epoch ---
--- 0.28685998916625977 seconds for one epoch ---
--- 1.531158208847046 seconds for one epoch ---
--- 0.29845452308654785 seconds for one epoch ---
--- 1.4332976341247559 seconds for one epoch ---
--- 0.1999661922454834 seconds for one epoch ---
--- 1.4264965057373047 seconds for one epoch ---
--- 0.23679089546203613 seconds for one epoch ---
--- 1.4336864948272705 seconds for one epoch ---
--- 0.28807735443115234 seconds for one epoch ---
--- 1.4213526248931885 seconds for one epoch ---
--- 0.2739448547363281 seconds for one epoch ---
--- 1.4652202129364014 seconds for one epoch ---
--- 0.20560050010681152 seconds for one epoch ---
--- 1.462975263595581 seconds for one epoch ---
--- 0.2867424488067627 seconds for one epoch ---
--- 1.462571382522583 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2823514938354492 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4325.912109375, (1499.5145, 2.805273, 2823.5925, 0.0)
   validation loss 2585.79638671875, (2112.2246, 0.33620062, 473.23547, 0.0)
decoder loss ratio: 81831.248350, decoder SINDy loss  ratio: 1.021545
--- 0.2516350746154785 seconds for one epoch ---
--- 0.2798497676849365 seconds for one epoch ---
--- 1.4825255870819092 seconds for one epoch ---
--- 0.30162978172302246 seconds for one epoch ---
--- 1.4660768508911133 seconds for one epoch ---
--- 0.2956376075744629 seconds for one epoch ---
--- 1.464350700378418 seconds for one epoch ---
--- 0.2950620651245117 seconds for one epoch ---
--- 1.5396144390106201 seconds for one epoch ---
--- 0.558154821395874 seconds for one epoch ---
--- 1.4274399280548096 seconds for one epoch ---
--- 0.25849223136901855 seconds for one epoch ---
--- 1.4430065155029297 seconds for one epoch ---
--- 0.30802106857299805 seconds for one epoch ---
--- 1.4539806842803955 seconds for one epoch ---
--- 0.2792375087738037 seconds for one epoch ---
--- 1.421844244003296 seconds for one epoch ---
--- 0.30190086364746094 seconds for one epoch ---
--- 1.4470322132110596 seconds for one epoch ---
--- 0.27887821197509766 seconds for one epoch ---
--- 1.500840425491333 seconds for one epoch ---
--- 0.2870934009552002 seconds for one epoch ---
--- 1.5039033889770508 seconds for one epoch ---
--- 0.2899293899536133 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2442638874053955 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4183.7841796875, (2101.8826, 2.6992302, 2079.2024, 0.0)
   validation loss 881.0760498046875, (547.81854, 0.48979667, 332.76767, 0.0)
decoder loss ratio: 21223.441391, decoder SINDy loss  ratio: 0.718326
--- 0.28545141220092773 seconds for one epoch ---
--- 1.4773776531219482 seconds for one epoch ---
--- 0.29842090606689453 seconds for one epoch ---
--- 1.5083985328674316 seconds for one epoch ---
--- 0.2893211841583252 seconds for one epoch ---
--- 1.4544131755828857 seconds for one epoch ---
--- 0.2901449203491211 seconds for one epoch ---
--- 1.4804420471191406 seconds for one epoch ---
--- 0.2929253578186035 seconds for one epoch ---
--- 1.5129845142364502 seconds for one epoch ---
--- 0.2903769016265869 seconds for one epoch ---
--- 1.4863193035125732 seconds for one epoch ---
--- 0.2866239547729492 seconds for one epoch ---
--- 1.478515386581421 seconds for one epoch ---
--- 0.3012058734893799 seconds for one epoch ---
--- 1.5085184574127197 seconds for one epoch ---
--- 0.2965419292449951 seconds for one epoch ---
--- 1.4856667518615723 seconds for one epoch ---
--- 0.3012268543243408 seconds for one epoch ---
--- 1.4811632633209229 seconds for one epoch ---
--- 0.2890055179595947 seconds for one epoch ---
--- 1.6377520561218262 seconds for one epoch ---
--- 0.29518628120422363 seconds for one epoch ---
--- 1.4588189125061035 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2648963928222656 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2222.1240234375, (1075.3578, 0.94376385, 1145.8225, 0.0)
   validation loss 1286.7012939453125, (910.6357, 0.46264437, 375.603, 0.0)
decoder loss ratio: 35279.607221, decoder SINDy loss  ratio: 0.810792
--- 0.2354602813720703 seconds for one epoch ---
--- 0.28351354598999023 seconds for one epoch ---
--- 1.4716596603393555 seconds for one epoch ---
--- 0.2805638313293457 seconds for one epoch ---
--- 1.4752392768859863 seconds for one epoch ---
--- 0.2776165008544922 seconds for one epoch ---
--- 1.4761152267456055 seconds for one epoch ---
--- 0.30665063858032227 seconds for one epoch ---
--- 1.5034170150756836 seconds for one epoch ---
--- 0.28443431854248047 seconds for one epoch ---
--- 1.5317435264587402 seconds for one epoch ---
--- 0.1942455768585205 seconds for one epoch ---
--- 1.4695770740509033 seconds for one epoch ---
--- 0.2570023536682129 seconds for one epoch ---
--- 1.5330684185028076 seconds for one epoch ---
--- 0.30063676834106445 seconds for one epoch ---
--- 1.476363182067871 seconds for one epoch ---
--- 0.2871685028076172 seconds for one epoch ---
--- 1.4857704639434814 seconds for one epoch ---
--- 0.290834903717041 seconds for one epoch ---
--- 1.5508008003234863 seconds for one epoch ---
--- 0.3178236484527588 seconds for one epoch ---
--- 1.5134813785552979 seconds for one epoch ---
--- 0.31493139266967773 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24350357055664062 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2174.372314453125, (1013.1905, 1.7069335, 1159.4749, 0.0)
   validation loss 1203.64013671875, (880.5975, 0.4485954, 322.59412, 0.0)
decoder loss ratio: 34115.874894, decoder SINDy loss  ratio: 0.696365
--- 0.3052361011505127 seconds for one epoch ---
--- 1.5309743881225586 seconds for one epoch ---
--- 0.2892618179321289 seconds for one epoch ---
--- 1.5012495517730713 seconds for one epoch ---
--- 0.28618526458740234 seconds for one epoch ---
--- 1.570228099822998 seconds for one epoch ---
--- 0.29460978507995605 seconds for one epoch ---
--- 1.4975817203521729 seconds for one epoch ---
--- 0.3049600124359131 seconds for one epoch ---
--- 1.5187840461730957 seconds for one epoch ---
--- 0.2940483093261719 seconds for one epoch ---
--- 1.5140883922576904 seconds for one epoch ---
--- 0.2921888828277588 seconds for one epoch ---
--- 1.5141234397888184 seconds for one epoch ---
--- 0.27611637115478516 seconds for one epoch ---
--- 1.5237629413604736 seconds for one epoch ---
--- 0.28876590728759766 seconds for one epoch ---
--- 1.5407490730285645 seconds for one epoch ---
--- 0.2731361389160156 seconds for one epoch ---
--- 1.5351171493530273 seconds for one epoch ---
--- 0.16710638999938965 seconds for one epoch ---
--- 1.498298168182373 seconds for one epoch ---
--- 0.3049321174621582 seconds for one epoch ---
--- 1.5232999324798584 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2574503421783447 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2710.084716796875, (1234.2517, 2.2461653, 1473.5868, 0.0)
   validation loss 1344.182373046875, (981.539, 0.37036616, 362.27295, 0.0)
decoder loss ratio: 38026.524943, decoder SINDy loss  ratio: 0.782017
--- 0.25205469131469727 seconds for one epoch ---
--- 0.2805814743041992 seconds for one epoch ---
--- 1.5243206024169922 seconds for one epoch ---
--- 0.29378414154052734 seconds for one epoch ---
--- 1.5148305892944336 seconds for one epoch ---
--- 0.2832307815551758 seconds for one epoch ---
--- 1.414912462234497 seconds for one epoch ---
--- 0.2580413818359375 seconds for one epoch ---
--- 1.4945306777954102 seconds for one epoch ---
--- 0.28269100189208984 seconds for one epoch ---
--- 1.5308189392089844 seconds for one epoch ---
--- 0.2830672264099121 seconds for one epoch ---
--- 1.5031096935272217 seconds for one epoch ---
--- 0.27660560607910156 seconds for one epoch ---
--- 1.5794389247894287 seconds for one epoch ---
--- 0.2739686965942383 seconds for one epoch ---
--- 1.5277633666992188 seconds for one epoch ---
--- 0.287182092666626 seconds for one epoch ---
--- 1.528000831604004 seconds for one epoch ---
--- 0.28562259674072266 seconds for one epoch ---
--- 1.5493614673614502 seconds for one epoch ---
--- 0.22899484634399414 seconds for one epoch ---
--- 1.5844557285308838 seconds for one epoch ---
--- 0.2596397399902344 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24936866760253906 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3340.48486328125, (1125.9703, 2.7120223, 2211.8025, 0.0)
   validation loss 960.0035400390625, (628.9949, 0.4502074, 330.55844, 0.0)
decoder loss ratio: 24368.353365, decoder SINDy loss  ratio: 0.713557
--- 0.28849244117736816 seconds for one epoch ---
--- 1.5667245388031006 seconds for one epoch ---
--- 0.2638275623321533 seconds for one epoch ---
--- 1.5955560207366943 seconds for one epoch ---
--- 0.2910349369049072 seconds for one epoch ---
--- 1.5292978286743164 seconds for one epoch ---
--- 0.2911384105682373 seconds for one epoch ---
--- 1.5532445907592773 seconds for one epoch ---
--- 0.28684496879577637 seconds for one epoch ---
--- 1.5471398830413818 seconds for one epoch ---
--- 0.27841830253601074 seconds for one epoch ---
--- 1.5518653392791748 seconds for one epoch ---
--- 0.26650381088256836 seconds for one epoch ---
--- 1.5433738231658936 seconds for one epoch ---
--- 0.2563910484313965 seconds for one epoch ---
--- 1.5744149684906006 seconds for one epoch ---
--- 0.2852919101715088 seconds for one epoch ---
--- 1.5446350574493408 seconds for one epoch ---
--- 0.2948629856109619 seconds for one epoch ---
--- 1.523383617401123 seconds for one epoch ---
--- 0.27995944023132324 seconds for one epoch ---
--- 1.4966304302215576 seconds for one epoch ---
--- 0.29155898094177246 seconds for one epoch ---
--- 1.5361905097961426 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29505395889282227 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2437.45947265625, (1181.0176, 1.3154427, 1255.1263, 0.0)
   validation loss 945.265380859375, (571.98236, 0.46406737, 372.81894, 0.0)
decoder loss ratio: 22159.589664, decoder SINDy loss  ratio: 0.804782
--- 0.1299905776977539 seconds for one epoch ---
--- 0.29085326194763184 seconds for one epoch ---
--- 1.5123276710510254 seconds for one epoch ---
--- 0.26142096519470215 seconds for one epoch ---
--- 1.5458917617797852 seconds for one epoch ---
--- 0.28499722480773926 seconds for one epoch ---
--- 1.5685415267944336 seconds for one epoch ---
--- 0.29201555252075195 seconds for one epoch ---
--- 1.6139891147613525 seconds for one epoch ---
--- 0.2752187252044678 seconds for one epoch ---
--- 1.5102076530456543 seconds for one epoch ---
--- 0.26947784423828125 seconds for one epoch ---
--- 1.525177240371704 seconds for one epoch ---
--- 0.29127979278564453 seconds for one epoch ---
--- 1.496952772140503 seconds for one epoch ---
--- 0.1635453701019287 seconds for one epoch ---
--- 1.5216007232666016 seconds for one epoch ---
--- 0.27161431312561035 seconds for one epoch ---
--- 1.4986107349395752 seconds for one epoch ---
--- 0.2936820983886719 seconds for one epoch ---
--- 1.5487785339355469 seconds for one epoch ---
--- 0.29001855850219727 seconds for one epoch ---
--- 1.5860750675201416 seconds for one epoch ---
--- 0.2708725929260254 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.267561674118042 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2470.966796875, (1315.9547, 1.283631, 1153.7285, 0.0)
   validation loss 995.211669921875, (646.8894, 0.55483425, 347.76746, 0.0)
decoder loss ratio: 25061.618572, decoder SINDy loss  ratio: 0.750705
--- 0.3005106449127197 seconds for one epoch ---
--- 1.5530214309692383 seconds for one epoch ---
--- 0.29007697105407715 seconds for one epoch ---
--- 1.555105447769165 seconds for one epoch ---
--- 0.2989027500152588 seconds for one epoch ---
--- 1.5345094203948975 seconds for one epoch ---
--- 0.3090677261352539 seconds for one epoch ---
--- 1.5568323135375977 seconds for one epoch ---
--- 0.22049403190612793 seconds for one epoch ---
--- 1.5326261520385742 seconds for one epoch ---
--- 0.2888376712799072 seconds for one epoch ---
--- 1.586918830871582 seconds for one epoch ---
--- 0.2885324954986572 seconds for one epoch ---
--- 1.5958471298217773 seconds for one epoch ---
--- 0.2857215404510498 seconds for one epoch ---
--- 1.5722317695617676 seconds for one epoch ---
--- 0.3088855743408203 seconds for one epoch ---
--- 1.5399000644683838 seconds for one epoch ---
--- 0.28876161575317383 seconds for one epoch ---
--- 1.5790424346923828 seconds for one epoch ---
--- 0.30326104164123535 seconds for one epoch ---
--- 1.5827946662902832 seconds for one epoch ---
--- 0.17016816139221191 seconds for one epoch ---
--- 1.5474326610565186 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2755298614501953 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2688.9287109375, (1298.5862, 2.227523, 1388.1151, 0.0)
   validation loss 856.008056640625, (497.61163, 0.5379302, 357.8585, 0.0)
decoder loss ratio: 19278.338566, decoder SINDy loss  ratio: 0.772488
--- 0.17758703231811523 seconds for one epoch ---
--- 0.19576478004455566 seconds for one epoch ---
--- 1.5893337726593018 seconds for one epoch ---
--- 0.2778003215789795 seconds for one epoch ---
--- 1.5621521472930908 seconds for one epoch ---
--- 0.30579185485839844 seconds for one epoch ---
--- 1.5389032363891602 seconds for one epoch ---
--- 0.2947204113006592 seconds for one epoch ---
--- 1.5876481533050537 seconds for one epoch ---
--- 0.2945678234100342 seconds for one epoch ---
--- 1.580899953842163 seconds for one epoch ---
--- 0.27762913703918457 seconds for one epoch ---
--- 1.5520694255828857 seconds for one epoch ---
--- 0.2974269390106201 seconds for one epoch ---
--- 1.587860345840454 seconds for one epoch ---
--- 0.28195738792419434 seconds for one epoch ---
--- 1.5852704048156738 seconds for one epoch ---
--- 0.26892590522766113 seconds for one epoch ---
--- 1.5709514617919922 seconds for one epoch ---
--- 0.2888345718383789 seconds for one epoch ---
--- 1.619218111038208 seconds for one epoch ---
--- 0.29847121238708496 seconds for one epoch ---
--- 1.6201050281524658 seconds for one epoch ---
--- 0.2762477397918701 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.21361351013183594 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2482.31884765625, (1322.804, 1.118251, 1158.3965, 0.0)
   validation loss 860.76171875, (486.6134, 0.553146, 373.59515, 0.0)
decoder loss ratio: 18852.248043, decoder SINDy loss  ratio: 0.806458
--- 0.21978235244750977 seconds for one epoch ---
--- 1.5536370277404785 seconds for one epoch ---
--- 0.2871832847595215 seconds for one epoch ---
--- 1.5895953178405762 seconds for one epoch ---
--- 0.2970879077911377 seconds for one epoch ---
--- 1.5877296924591064 seconds for one epoch ---
--- 0.28571653366088867 seconds for one epoch ---
--- 1.670046091079712 seconds for one epoch ---
--- 0.28957080841064453 seconds for one epoch ---
--- 1.5685479640960693 seconds for one epoch ---
--- 0.2789900302886963 seconds for one epoch ---
--- 1.5956289768218994 seconds for one epoch ---
--- 0.2787446975708008 seconds for one epoch ---
--- 1.4926612377166748 seconds for one epoch ---
--- 0.17370057106018066 seconds for one epoch ---
--- 1.5766127109527588 seconds for one epoch ---
--- 0.28974151611328125 seconds for one epoch ---
--- 1.6238772869110107 seconds for one epoch ---
--- 0.27768373489379883 seconds for one epoch ---
--- 1.579366683959961 seconds for one epoch ---
--- 0.28434157371520996 seconds for one epoch ---
--- 1.576592206954956 seconds for one epoch ---
--- 0.2809288501739502 seconds for one epoch ---
--- 1.5928175449371338 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2809290885925293 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4772.6806640625, (1752.29, 3.5190277, 3016.8716, 0.0)
   validation loss 1003.7727661132812, (679.28265, 0.5683992, 323.9217, 0.0)
decoder loss ratio: 26316.589295, decoder SINDy loss  ratio: 0.699231
THRESHOLDING: 0 active coefficients
--- 1.580580234527588 seconds for one epoch ---
--- 0.2911264896392822 seconds for one epoch ---
--- 1.6021125316619873 seconds for one epoch ---
--- 0.2811446189880371 seconds for one epoch ---
--- 1.6003587245941162 seconds for one epoch ---
--- 0.24624943733215332 seconds for one epoch ---
--- 1.627429723739624 seconds for one epoch ---
--- 0.28847289085388184 seconds for one epoch ---
--- 1.575591802597046 seconds for one epoch ---
--- 0.2943918704986572 seconds for one epoch ---
--- 1.5862984657287598 seconds for one epoch ---
--- 0.2870769500732422 seconds for one epoch ---
--- 1.6803643703460693 seconds for one epoch ---
--- 0.3069174289703369 seconds for one epoch ---
--- 1.6272737979888916 seconds for one epoch ---
--- 0.2887918949127197 seconds for one epoch ---
--- 1.64329195022583 seconds for one epoch ---
--- 0.28630733489990234 seconds for one epoch ---
--- 1.6032812595367432 seconds for one epoch ---
--- 0.29688382148742676 seconds for one epoch ---
--- 1.6225183010101318 seconds for one epoch ---
--- 0.28119397163391113 seconds for one epoch ---
--- 1.5868256092071533 seconds for one epoch ---
--- 0.2996242046356201 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2474827766418457 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2539.21533203125, (924.7047, 1.6653005, 1612.8455, 0.0)
   validation loss 1373.9423828125, (985.6297, 0.5497726, 387.76297, 0.0)
decoder loss ratio: 38185.005695, decoder SINDy loss  ratio: 0.837041
--- 0.1949784755706787 seconds for one epoch ---
--- 1.5551083087921143 seconds for one epoch ---
--- 0.27399373054504395 seconds for one epoch ---
--- 1.5858054161071777 seconds for one epoch ---
--- 0.29454684257507324 seconds for one epoch ---
--- 1.5526385307312012 seconds for one epoch ---
--- 0.29573774337768555 seconds for one epoch ---
--- 1.673915147781372 seconds for one epoch ---
--- 0.28121042251586914 seconds for one epoch ---
--- 1.5990571975708008 seconds for one epoch ---
--- 0.27295589447021484 seconds for one epoch ---
--- 1.584242582321167 seconds for one epoch ---
--- 0.2958552837371826 seconds for one epoch ---
--- 1.5953598022460938 seconds for one epoch ---
--- 0.2847929000854492 seconds for one epoch ---
--- 1.594313621520996 seconds for one epoch ---
--- 0.27442216873168945 seconds for one epoch ---
--- 1.580484390258789 seconds for one epoch ---
--- 0.2904832363128662 seconds for one epoch ---
--- 1.648937702178955 seconds for one epoch ---
--- 0.2803194522857666 seconds for one epoch ---
--- 1.6597836017608643 seconds for one epoch ---
--- 0.2930178642272949 seconds for one epoch ---
--- 1.6232314109802246 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28885483741760254 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4733.462890625, (1913.7301, 8.532298, 2811.2007, 0.0)
   validation loss 1063.544921875, (729.90125, 0.6184535, 333.02524, 0.0)
decoder loss ratio: 28277.641400, decoder SINDy loss  ratio: 0.718882
--- 0.24822235107421875 seconds for one epoch ---
--- 0.2694053649902344 seconds for one epoch ---
--- 1.593198299407959 seconds for one epoch ---
--- 0.2868688106536865 seconds for one epoch ---
--- 1.620145559310913 seconds for one epoch ---
--- 0.28487253189086914 seconds for one epoch ---
--- 1.6574337482452393 seconds for one epoch ---
--- 0.28745603561401367 seconds for one epoch ---
--- 1.6310558319091797 seconds for one epoch ---
--- 0.29734182357788086 seconds for one epoch ---
--- 1.5559611320495605 seconds for one epoch ---
--- 0.15157246589660645 seconds for one epoch ---
--- 1.6661489009857178 seconds for one epoch ---
--- 0.24747014045715332 seconds for one epoch ---
--- 1.6282916069030762 seconds for one epoch ---
--- 0.27814698219299316 seconds for one epoch ---
--- 1.6104388236999512 seconds for one epoch ---
--- 0.17789912223815918 seconds for one epoch ---
--- 1.629629135131836 seconds for one epoch ---
--- 0.2852001190185547 seconds for one epoch ---
--- 1.6418085098266602 seconds for one epoch ---
--- 0.29387879371643066 seconds for one epoch ---
--- 1.6336569786071777 seconds for one epoch ---
--- 0.29269886016845703 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2426769733428955 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1657.1103515625, (748.45013, 1.6412681, 907.01886, 0.0)
   validation loss 1116.859130859375, (743.08636, 0.58048326, 373.1922, 0.0)
decoder loss ratio: 28788.455825, decoder SINDy loss  ratio: 0.805588
--- 0.29350709915161133 seconds for one epoch ---
--- 1.6221957206726074 seconds for one epoch ---
--- 0.29256582260131836 seconds for one epoch ---
--- 1.5446090698242188 seconds for one epoch ---
--- 0.24062681198120117 seconds for one epoch ---
--- 1.6563160419464111 seconds for one epoch ---
--- 0.2906179428100586 seconds for one epoch ---
--- 1.6275832653045654 seconds for one epoch ---
--- 0.2780935764312744 seconds for one epoch ---
--- 1.5768492221832275 seconds for one epoch ---
--- 0.21070122718811035 seconds for one epoch ---
--- 1.717036485671997 seconds for one epoch ---
--- 0.2888221740722656 seconds for one epoch ---
--- 1.6172962188720703 seconds for one epoch ---
--- 0.2868640422821045 seconds for one epoch ---
--- 1.5518708229064941 seconds for one epoch ---
--- 0.23879122734069824 seconds for one epoch ---
--- 1.6706600189208984 seconds for one epoch ---
--- 0.27890825271606445 seconds for one epoch ---
--- 1.6498486995697021 seconds for one epoch ---
--- 0.28337860107421875 seconds for one epoch ---
--- 1.6764719486236572 seconds for one epoch ---
--- 0.30708765983581543 seconds for one epoch ---
--- 1.6544477939605713 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3006014823913574 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3416.5595703125, (1746.6125, 5.715152, 1664.2318, 0.0)
   validation loss 1291.4879150390625, (921.7139, 0.51542234, 369.25854, 0.0)
decoder loss ratio: 35708.797745, decoder SINDy loss  ratio: 0.797097
--- 0.25913071632385254 seconds for one epoch ---
--- 0.3040120601654053 seconds for one epoch ---
--- 1.6335749626159668 seconds for one epoch ---
--- 0.2899463176727295 seconds for one epoch ---
--- 1.6642138957977295 seconds for one epoch ---
--- 0.2893240451812744 seconds for one epoch ---
--- 1.657381296157837 seconds for one epoch ---
--- 0.30286264419555664 seconds for one epoch ---
--- 1.6611785888671875 seconds for one epoch ---
--- 0.3209235668182373 seconds for one epoch ---
--- 1.6389386653900146 seconds for one epoch ---
--- 0.3084225654602051 seconds for one epoch ---
--- 1.6631505489349365 seconds for one epoch ---
--- 0.22066354751586914 seconds for one epoch ---
--- 1.6705398559570312 seconds for one epoch ---
--- 0.2927548885345459 seconds for one epoch ---
--- 1.6949119567871094 seconds for one epoch ---
--- 0.2838602066040039 seconds for one epoch ---
--- 1.7353053092956543 seconds for one epoch ---
--- 0.284226655960083 seconds for one epoch ---
--- 1.6559443473815918 seconds for one epoch ---
--- 0.2950615882873535 seconds for one epoch ---
--- 1.666959285736084 seconds for one epoch ---
--- 0.2512362003326416 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24961304664611816 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3780.7958984375, (1458.7361, 1.5861794, 2320.4736, 0.0)
   validation loss 1617.343017578125, (1186.7909, 0.60689807, 429.94516, 0.0)
decoder loss ratio: 45978.339576, decoder SINDy loss  ratio: 0.928097
--- 0.29541587829589844 seconds for one epoch ---
--- 1.6073753833770752 seconds for one epoch ---
--- 0.24784135818481445 seconds for one epoch ---
--- 1.6497764587402344 seconds for one epoch ---
--- 0.2634701728820801 seconds for one epoch ---
--- 1.674302577972412 seconds for one epoch ---
--- 0.2960813045501709 seconds for one epoch ---
--- 1.6830661296844482 seconds for one epoch ---
--- 0.2875709533691406 seconds for one epoch ---
--- 1.6827723979949951 seconds for one epoch ---
--- 0.29794764518737793 seconds for one epoch ---
--- 1.660405158996582 seconds for one epoch ---
--- 0.2833566665649414 seconds for one epoch ---
--- 1.659944772720337 seconds for one epoch ---
--- 0.30413246154785156 seconds for one epoch ---
--- 1.6838109493255615 seconds for one epoch ---
--- 0.2598295211791992 seconds for one epoch ---
--- 1.694889783859253 seconds for one epoch ---
--- 0.2799084186553955 seconds for one epoch ---
--- 1.6877853870391846 seconds for one epoch ---
--- 0.2906005382537842 seconds for one epoch ---
--- 1.7162330150604248 seconds for one epoch ---
--- 0.2808351516723633 seconds for one epoch ---
--- 1.6764743328094482 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28918027877807617 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2779.00732421875, (1115.0643, 1.2630326, 1662.6798, 0.0)
   validation loss 1017.9051513671875, (651.828, 0.63808984, 365.4391, 0.0)
decoder loss ratio: 25252.948457, decoder SINDy loss  ratio: 0.788852
--- 0.2577385902404785 seconds for one epoch ---
--- 0.2932884693145752 seconds for one epoch ---
--- 1.6528751850128174 seconds for one epoch ---
--- 0.2862265110015869 seconds for one epoch ---
--- 1.7372610569000244 seconds for one epoch ---
--- 0.20210599899291992 seconds for one epoch ---
--- 1.6878461837768555 seconds for one epoch ---
--- 0.29755306243896484 seconds for one epoch ---
--- 1.682274580001831 seconds for one epoch ---
--- 0.29354214668273926 seconds for one epoch ---
--- 1.6815826892852783 seconds for one epoch ---
--- 0.2961421012878418 seconds for one epoch ---
--- 1.7480432987213135 seconds for one epoch ---
--- 0.28974246978759766 seconds for one epoch ---
--- 1.7535316944122314 seconds for one epoch ---
--- 0.3015878200531006 seconds for one epoch ---
--- 1.674468755722046 seconds for one epoch ---
--- 0.300870418548584 seconds for one epoch ---
--- 1.7890098094940186 seconds for one epoch ---
--- 0.30162978172302246 seconds for one epoch ---
--- 1.7494840621948242 seconds for one epoch ---
--- 0.3076772689819336 seconds for one epoch ---
--- 1.675067663192749 seconds for one epoch ---
--- 0.29853367805480957 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26822900772094727 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1795.896728515625, (904.4639, 0.8585256, 890.5743, 0.0)
   validation loss 969.3050537109375, (647.4437, 0.6182888, 321.24307, 0.0)
decoder loss ratio: 25083.093941, decoder SINDy loss  ratio: 0.693448
--- 0.2841813564300537 seconds for one epoch ---
--- 1.7068424224853516 seconds for one epoch ---
--- 0.3060297966003418 seconds for one epoch ---
--- 1.7260410785675049 seconds for one epoch ---
--- 0.28635382652282715 seconds for one epoch ---
--- 1.6797385215759277 seconds for one epoch ---
--- 0.2923092842102051 seconds for one epoch ---
--- 1.6742446422576904 seconds for one epoch ---
--- 0.17027783393859863 seconds for one epoch ---
--- 1.6903877258300781 seconds for one epoch ---
--- 0.2864060401916504 seconds for one epoch ---
--- 1.7513220310211182 seconds for one epoch ---
--- 0.28565263748168945 seconds for one epoch ---
--- 1.687755823135376 seconds for one epoch ---
--- 0.2861614227294922 seconds for one epoch ---
--- 1.7355024814605713 seconds for one epoch ---
--- 0.29192018508911133 seconds for one epoch ---
--- 1.7117598056793213 seconds for one epoch ---
--- 0.3026132583618164 seconds for one epoch ---
--- 1.6959829330444336 seconds for one epoch ---
--- 0.2754647731781006 seconds for one epoch ---
--- 1.7609515190124512 seconds for one epoch ---
--- 0.30005478858947754 seconds for one epoch ---
--- 1.713075876235962 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28212881088256836 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2670.153564453125, (1737.3307, 1.2108527, 931.6121, 0.0)
   validation loss 962.836669921875, (636.019, 0.5896886, 326.228, 0.0)
decoder loss ratio: 24640.479538, decoder SINDy loss  ratio: 0.704209
--- 0.2519090175628662 seconds for one epoch ---
--- 0.29851388931274414 seconds for one epoch ---
--- 1.6815314292907715 seconds for one epoch ---
--- 0.2777884006500244 seconds for one epoch ---
--- 1.6804568767547607 seconds for one epoch ---
--- 0.23064374923706055 seconds for one epoch ---
--- 1.6836636066436768 seconds for one epoch ---
--- 0.26376867294311523 seconds for one epoch ---
--- 1.7013757228851318 seconds for one epoch ---
--- 0.2939937114715576 seconds for one epoch ---
--- 1.6984548568725586 seconds for one epoch ---
--- 0.2996695041656494 seconds for one epoch ---
--- 1.7065443992614746 seconds for one epoch ---
--- 0.3021402359008789 seconds for one epoch ---
--- 1.701474905014038 seconds for one epoch ---
--- 0.2754402160644531 seconds for one epoch ---
--- 1.7002921104431152 seconds for one epoch ---
--- 0.2899167537689209 seconds for one epoch ---
--- 1.7223820686340332 seconds for one epoch ---
--- 0.29572558403015137 seconds for one epoch ---
--- 1.668285846710205 seconds for one epoch ---
--- 0.29117465019226074 seconds for one epoch ---
--- 1.6937401294708252 seconds for one epoch ---
--- 0.277834415435791 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2515220642089844 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3436.051025390625, (1516.1156, 3.1974623, 1916.7379, 0.0)
   validation loss 855.555419921875, (538.95856, 0.6433666, 315.95352, 0.0)
decoder loss ratio: 20880.190176, decoder SINDy loss  ratio: 0.682030
--- 0.2961766719818115 seconds for one epoch ---
--- 1.6887977123260498 seconds for one epoch ---
--- 0.16402769088745117 seconds for one epoch ---
--- 1.7026166915893555 seconds for one epoch ---
--- 0.2925229072570801 seconds for one epoch ---
--- 1.7010681629180908 seconds for one epoch ---
--- 0.2782750129699707 seconds for one epoch ---
--- 1.7038183212280273 seconds for one epoch ---
--- 0.2998993396759033 seconds for one epoch ---
--- 1.7092318534851074 seconds for one epoch ---
--- 0.286801815032959 seconds for one epoch ---
--- 1.7336571216583252 seconds for one epoch ---
--- 0.2824416160583496 seconds for one epoch ---
--- 1.7201056480407715 seconds for one epoch ---
--- 0.27229762077331543 seconds for one epoch ---
--- 1.7659740447998047 seconds for one epoch ---
--- 0.2819805145263672 seconds for one epoch ---
--- 1.7309257984161377 seconds for one epoch ---
--- 0.2864241600036621 seconds for one epoch ---
--- 1.7386200428009033 seconds for one epoch ---
--- 0.29203057289123535 seconds for one epoch ---
--- 1.727266788482666 seconds for one epoch ---
--- 0.2853572368621826 seconds for one epoch ---
--- 1.7401268482208252 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29642295837402344 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2515.962158203125, (1037.1018, 3.4713347, 1475.389, 0.0)
   validation loss 855.1854248046875, (506.5823, 0.66396993, 347.93915, 0.0)
decoder loss ratio: 19625.877996, decoder SINDy loss  ratio: 0.751076
--- 0.24686312675476074 seconds for one epoch ---
--- 0.2892172336578369 seconds for one epoch ---
--- 1.6959540843963623 seconds for one epoch ---
--- 0.29920458793640137 seconds for one epoch ---
--- 1.6628313064575195 seconds for one epoch ---
--- 0.2801246643066406 seconds for one epoch ---
--- 1.7426719665527344 seconds for one epoch ---
--- 0.2810337543487549 seconds for one epoch ---
--- 1.7185869216918945 seconds for one epoch ---
--- 0.28591132164001465 seconds for one epoch ---
--- 1.722303867340088 seconds for one epoch ---
--- 0.19611620903015137 seconds for one epoch ---
--- 1.7459285259246826 seconds for one epoch ---
--- 0.3006446361541748 seconds for one epoch ---
--- 1.712627649307251 seconds for one epoch ---
--- 0.2795372009277344 seconds for one epoch ---
--- 1.8485569953918457 seconds for one epoch ---
--- 0.2835521697998047 seconds for one epoch ---
--- 1.7788209915161133 seconds for one epoch ---
--- 0.2933313846588135 seconds for one epoch ---
--- 1.8830139636993408 seconds for one epoch ---
--- 0.27576637268066406 seconds for one epoch ---
--- 1.725226879119873 seconds for one epoch ---
--- 0.19620752334594727 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23666167259216309 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5337.25, (3161.708, 2.2446692, 2173.2974, 0.0)
   validation loss 888.7839965820312, (548.4113, 0.6530194, 339.71967, 0.0)
decoder loss ratio: 21246.406463, decoder SINDy loss  ratio: 0.733333
--- 0.2723865509033203 seconds for one epoch ---
--- 1.7532825469970703 seconds for one epoch ---
--- 0.29582810401916504 seconds for one epoch ---
--- 1.7422924041748047 seconds for one epoch ---
--- 0.2858846187591553 seconds for one epoch ---
--- 1.7100803852081299 seconds for one epoch ---
--- 0.27935266494750977 seconds for one epoch ---
--- 1.810924768447876 seconds for one epoch ---
--- 0.27891063690185547 seconds for one epoch ---
--- 1.7605094909667969 seconds for one epoch ---
--- 0.28537845611572266 seconds for one epoch ---
--- 1.7403666973114014 seconds for one epoch ---
--- 0.2836306095123291 seconds for one epoch ---
--- 1.736511468887329 seconds for one epoch ---
--- 0.29335546493530273 seconds for one epoch ---
--- 1.751885175704956 seconds for one epoch ---
--- 0.28940558433532715 seconds for one epoch ---
--- 1.731377124786377 seconds for one epoch ---
--- 0.29328393936157227 seconds for one epoch ---
--- 1.6592118740081787 seconds for one epoch ---
--- 0.24742388725280762 seconds for one epoch ---
--- 1.804112434387207 seconds for one epoch ---
--- 0.26407504081726074 seconds for one epoch ---
--- 1.7183008193969727 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2914083003997803 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1749.0546875, (951.3929, 2.314253, 795.3476, 0.0)
   validation loss 950.4639892578125, (622.28424, 0.66346836, 327.51633, 0.0)
decoder loss ratio: 24108.371819, decoder SINDy loss  ratio: 0.706990
--- 0.24081158638000488 seconds for one epoch ---
--- 0.28939294815063477 seconds for one epoch ---
--- 1.7363827228546143 seconds for one epoch ---
--- 0.17012739181518555 seconds for one epoch ---
--- 1.7530627250671387 seconds for one epoch ---
--- 0.28255748748779297 seconds for one epoch ---
--- 1.7857043743133545 seconds for one epoch ---
--- 0.2985107898712158 seconds for one epoch ---
--- 1.7767066955566406 seconds for one epoch ---
--- 0.251239538192749 seconds for one epoch ---
--- 1.7891759872436523 seconds for one epoch ---
--- 0.2906382083892822 seconds for one epoch ---
--- 1.7578341960906982 seconds for one epoch ---
--- 0.2817652225494385 seconds for one epoch ---
--- 1.7369999885559082 seconds for one epoch ---
--- 0.2313854694366455 seconds for one epoch ---
--- 1.7862434387207031 seconds for one epoch ---
--- 0.2832980155944824 seconds for one epoch ---
--- 1.732168197631836 seconds for one epoch ---
--- 0.2798452377319336 seconds for one epoch ---
--- 1.7700555324554443 seconds for one epoch ---
--- 0.14795255661010742 seconds for one epoch ---
--- 1.7494049072265625 seconds for one epoch ---
--- 0.27643609046936035 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2516777515411377 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3601.87646484375, (1555.5323, 2.017653, 2044.3263, 0.0)
   validation loss 930.031982421875, (589.23083, 0.6381651, 340.16296, 0.0)
decoder loss ratio: 22827.825496, decoder SINDy loss  ratio: 0.734290
--- 0.30443406105041504 seconds for one epoch ---
--- 1.7384371757507324 seconds for one epoch ---
--- 0.2843141555786133 seconds for one epoch ---
--- 1.7818818092346191 seconds for one epoch ---
--- 0.33063578605651855 seconds for one epoch ---
--- 1.7783005237579346 seconds for one epoch ---
--- 0.27692413330078125 seconds for one epoch ---
--- 1.8008477687835693 seconds for one epoch ---
--- 0.2760903835296631 seconds for one epoch ---
--- 1.7842473983764648 seconds for one epoch ---
--- 0.2580530643463135 seconds for one epoch ---
--- 1.7805960178375244 seconds for one epoch ---
--- 0.3219478130340576 seconds for one epoch ---
--- 1.829106092453003 seconds for one epoch ---
--- 0.28368449211120605 seconds for one epoch ---
--- 1.7629199028015137 seconds for one epoch ---
--- 0.31536006927490234 seconds for one epoch ---
--- 1.8040566444396973 seconds for one epoch ---
--- 0.3074343204498291 seconds for one epoch ---
--- 1.799886703491211 seconds for one epoch ---
--- 0.29462671279907227 seconds for one epoch ---
--- 1.7731688022613525 seconds for one epoch ---
--- 0.19546031951904297 seconds for one epoch ---
--- 1.8041837215423584 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2950167655944824 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1862.7919921875, (891.0289, 2.8962705, 968.86694, 0.0)
   validation loss 836.9132080078125, (497.87997, 0.60193086, 338.4313, 0.0)
decoder loss ratio: 19288.734565, decoder SINDy loss  ratio: 0.730552
--- 0.28526997566223145 seconds for one epoch ---
--- 0.28923797607421875 seconds for one epoch ---
--- 1.8240959644317627 seconds for one epoch ---
--- 0.29529380798339844 seconds for one epoch ---
--- 1.77598237991333 seconds for one epoch ---
--- 0.24891948699951172 seconds for one epoch ---
--- 1.8412401676177979 seconds for one epoch ---
--- 0.2999131679534912 seconds for one epoch ---
--- 1.7957711219787598 seconds for one epoch ---
--- 0.2817549705505371 seconds for one epoch ---
--- 1.80985426902771 seconds for one epoch ---
--- 0.2843296527862549 seconds for one epoch ---
--- 1.7992780208587646 seconds for one epoch ---
--- 0.28020596504211426 seconds for one epoch ---
--- 1.791398525238037 seconds for one epoch ---
--- 0.29380321502685547 seconds for one epoch ---
--- 1.7722759246826172 seconds for one epoch ---
--- 0.2746701240539551 seconds for one epoch ---
--- 1.7906465530395508 seconds for one epoch ---
--- 0.282916784286499 seconds for one epoch ---
--- 1.8021998405456543 seconds for one epoch ---
--- 0.257061243057251 seconds for one epoch ---
--- 1.8312361240386963 seconds for one epoch ---
--- 0.21409869194030762 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25094079971313477 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2726.07080078125, (1387.3828, 2.6291268, 1336.059, 0.0)
   validation loss 942.0723876953125, (615.55896, 0.6276822, 325.88574, 0.0)
decoder loss ratio: 23847.822766, decoder SINDy loss  ratio: 0.703470
--- 0.26637721061706543 seconds for one epoch ---
--- 1.842522382736206 seconds for one epoch ---
--- 0.2998836040496826 seconds for one epoch ---
--- 1.7905220985412598 seconds for one epoch ---
--- 0.29908037185668945 seconds for one epoch ---
--- 1.7927238941192627 seconds for one epoch ---
--- 0.3028271198272705 seconds for one epoch ---
--- 1.8076326847076416 seconds for one epoch ---
--- 0.29787611961364746 seconds for one epoch ---
--- 1.7984180450439453 seconds for one epoch ---
--- 0.29511570930480957 seconds for one epoch ---
--- 1.9164793491363525 seconds for one epoch ---
--- 0.2728540897369385 seconds for one epoch ---
--- 1.8305366039276123 seconds for one epoch ---
--- 0.27317094802856445 seconds for one epoch ---
--- 1.7829768657684326 seconds for one epoch ---
--- 0.2860269546508789 seconds for one epoch ---
--- 1.812563180923462 seconds for one epoch ---
--- 0.28896450996398926 seconds for one epoch ---
--- 1.8247921466827393 seconds for one epoch ---
--- 0.2865564823150635 seconds for one epoch ---
--- 1.8291089534759521 seconds for one epoch ---
--- 0.29328036308288574 seconds for one epoch ---
--- 1.839561939239502 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29342174530029297 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2405.30859375, (1061.7223, 1.1236047, 1342.4625, 0.0)
   validation loss 928.1512451171875, (584.5776, 0.64078, 342.93286, 0.0)
decoder loss ratio: 22647.550153, decoder SINDy loss  ratio: 0.740269
--- 0.12593674659729004 seconds for one epoch ---
--- 0.26186680793762207 seconds for one epoch ---
--- 1.7804710865020752 seconds for one epoch ---
--- 0.281219482421875 seconds for one epoch ---
--- 1.8274850845336914 seconds for one epoch ---
--- 0.2812020778656006 seconds for one epoch ---
--- 1.7561769485473633 seconds for one epoch ---
--- 0.15122389793395996 seconds for one epoch ---
--- 1.8242194652557373 seconds for one epoch ---
--- 0.29072117805480957 seconds for one epoch ---
--- 1.8440909385681152 seconds for one epoch ---
--- 0.2825326919555664 seconds for one epoch ---
--- 1.8156602382659912 seconds for one epoch ---
--- 0.23415040969848633 seconds for one epoch ---
--- 1.8265106678009033 seconds for one epoch ---
--- 0.29430437088012695 seconds for one epoch ---
--- 1.818972110748291 seconds for one epoch ---
--- 0.2932469844818115 seconds for one epoch ---
--- 1.9333584308624268 seconds for one epoch ---
--- 0.16751861572265625 seconds for one epoch ---
--- 1.8099517822265625 seconds for one epoch ---
--- 0.29445862770080566 seconds for one epoch ---
--- 1.8336858749389648 seconds for one epoch ---
--- 0.29912495613098145 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2608978748321533 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1827.109375, (888.85223, 2.6895316, 935.5677, 0.0)
   validation loss 754.3953857421875, (437.3014, 0.73869866, 316.35526, 0.0)
decoder loss ratio: 16941.815099, decoder SINDy loss  ratio: 0.682897
--- 0.29491209983825684 seconds for one epoch ---
--- 1.8184075355529785 seconds for one epoch ---
--- 0.29590392112731934 seconds for one epoch ---
--- 1.8313324451446533 seconds for one epoch ---
--- 0.30591320991516113 seconds for one epoch ---
--- 1.9599568843841553 seconds for one epoch ---
--- 0.2778191566467285 seconds for one epoch ---
--- 1.870173692703247 seconds for one epoch ---
--- 0.27765345573425293 seconds for one epoch ---
--- 1.840299129486084 seconds for one epoch ---
--- 0.30226564407348633 seconds for one epoch ---
--- 1.852738857269287 seconds for one epoch ---
--- 0.28673815727233887 seconds for one epoch ---
--- 2.0303633213043213 seconds for one epoch ---
--- 0.27593231201171875 seconds for one epoch ---
--- 1.8432722091674805 seconds for one epoch ---
--- 0.2944149971008301 seconds for one epoch ---
--- 1.8355226516723633 seconds for one epoch ---
--- 0.6010401248931885 seconds for one epoch ---
--- 1.8519501686096191 seconds for one epoch ---
--- 0.2751631736755371 seconds for one epoch ---
--- 1.811854600906372 seconds for one epoch ---
--- 0.30349111557006836 seconds for one epoch ---
--- 1.8561995029449463 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2735414505004883 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2738.114990234375, (1339.4535, 2.107367, 1396.5541, 0.0)
   validation loss 1029.709228515625, (678.8174, 0.7295075, 350.1623, 0.0)
decoder loss ratio: 26298.563889, decoder SINDy loss  ratio: 0.755875
--- 0.243361234664917 seconds for one epoch ---
--- 0.2784566879272461 seconds for one epoch ---
--- 1.8282127380371094 seconds for one epoch ---
--- 0.2923703193664551 seconds for one epoch ---
--- 1.8580775260925293 seconds for one epoch ---
--- 0.2551577091217041 seconds for one epoch ---
--- 1.9350318908691406 seconds for one epoch ---
--- 0.2599458694458008 seconds for one epoch ---
--- 1.8280131816864014 seconds for one epoch ---
--- 0.2922348976135254 seconds for one epoch ---
--- 1.8241710662841797 seconds for one epoch ---
--- 0.27906346321105957 seconds for one epoch ---
--- 1.8592512607574463 seconds for one epoch ---
--- 0.2723815441131592 seconds for one epoch ---
--- 1.8251631259918213 seconds for one epoch ---
--- 0.29961514472961426 seconds for one epoch ---
--- 1.8528964519500732 seconds for one epoch ---
--- 0.28130006790161133 seconds for one epoch ---
--- 1.8969330787658691 seconds for one epoch ---
--- 0.28149867057800293 seconds for one epoch ---
--- 1.8308448791503906 seconds for one epoch ---
--- 0.29023146629333496 seconds for one epoch ---
--- 1.8181052207946777 seconds for one epoch ---
--- 0.15418791770935059 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25865745544433594 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3151.43603515625, (1596.5635, 0.590475, 1554.2821, 0.0)
   validation loss 789.8299560546875, (478.3204, 0.8266121, 310.68295, 0.0)
decoder loss ratio: 18530.962854, decoder SINDy loss  ratio: 0.670653
--- 0.2632179260253906 seconds for one epoch ---
--- 1.914496898651123 seconds for one epoch ---
--- 0.2915990352630615 seconds for one epoch ---
--- 1.8477883338928223 seconds for one epoch ---
--- 0.29768919944763184 seconds for one epoch ---
--- 1.8252840042114258 seconds for one epoch ---
--- 0.27526330947875977 seconds for one epoch ---
--- 1.8338689804077148 seconds for one epoch ---
--- 0.29482579231262207 seconds for one epoch ---
--- 1.8417279720306396 seconds for one epoch ---
--- 0.283571720123291 seconds for one epoch ---
--- 1.8572742938995361 seconds for one epoch ---
--- 0.30877256393432617 seconds for one epoch ---
--- 1.870915174484253 seconds for one epoch ---
--- 0.3067300319671631 seconds for one epoch ---
--- 1.833787202835083 seconds for one epoch ---
--- 0.28675246238708496 seconds for one epoch ---
--- 1.829531192779541 seconds for one epoch ---
--- 0.23812174797058105 seconds for one epoch ---
--- 1.8749699592590332 seconds for one epoch ---
--- 0.2829012870788574 seconds for one epoch ---
--- 1.8664360046386719 seconds for one epoch ---
--- 0.2510945796966553 seconds for one epoch ---
--- 1.837965726852417 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2630620002746582 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1711.66015625, (1036.5482, 0.5168242, 674.59503, 0.0)
   validation loss 789.1122436523438, (455.3069, 0.7857969, 333.01956, 0.0)
decoder loss ratio: 17639.379163, decoder SINDy loss  ratio: 0.718870
THRESHOLDING: 0 active coefficients
--- 0.25795698165893555 seconds for one epoch ---
--- 0.28444981575012207 seconds for one epoch ---
--- 1.8983383178710938 seconds for one epoch ---
--- 0.2890961170196533 seconds for one epoch ---
--- 1.8726749420166016 seconds for one epoch ---
--- 0.2801194190979004 seconds for one epoch ---
--- 1.853860855102539 seconds for one epoch ---
--- 0.2682065963745117 seconds for one epoch ---
--- 1.86672043800354 seconds for one epoch ---
--- 0.29671311378479004 seconds for one epoch ---
--- 1.854520559310913 seconds for one epoch ---
--- 0.2926912307739258 seconds for one epoch ---
--- 1.8885433673858643 seconds for one epoch ---
--- 0.29039955139160156 seconds for one epoch ---
--- 1.8716964721679688 seconds for one epoch ---
--- 0.27272701263427734 seconds for one epoch ---
--- 1.8629095554351807 seconds for one epoch ---
--- 0.28556132316589355 seconds for one epoch ---
--- 1.8188302516937256 seconds for one epoch ---
--- 0.30404090881347656 seconds for one epoch ---
--- 1.9720561504364014 seconds for one epoch ---
--- 0.29288768768310547 seconds for one epoch ---
--- 1.8814404010772705 seconds for one epoch ---
--- 0.29030346870422363 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2619025707244873 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2540.642578125, (1430.8362, 0.718469, 1109.088, 0.0)
   validation loss 1296.752197265625, (943.4941, 0.81006837, 352.44812, 0.0)
decoder loss ratio: 36552.598621, decoder SINDy loss  ratio: 0.760809
--- 0.27694106101989746 seconds for one epoch ---
--- 1.8605353832244873 seconds for one epoch ---
--- 0.2794654369354248 seconds for one epoch ---
--- 1.9654698371887207 seconds for one epoch ---
--- 0.2902202606201172 seconds for one epoch ---
--- 1.860358715057373 seconds for one epoch ---
--- 0.29462170600891113 seconds for one epoch ---
--- 1.9038639068603516 seconds for one epoch ---
--- 0.27735257148742676 seconds for one epoch ---
--- 1.8829424381256104 seconds for one epoch ---
--- 0.2922372817993164 seconds for one epoch ---
--- 1.8716421127319336 seconds for one epoch ---
--- 0.2873880863189697 seconds for one epoch ---
--- 1.9232313632965088 seconds for one epoch ---
--- 0.289839506149292 seconds for one epoch ---
--- 1.8558738231658936 seconds for one epoch ---
--- 0.2912178039550781 seconds for one epoch ---
--- 1.890550136566162 seconds for one epoch ---
--- 0.27221012115478516 seconds for one epoch ---
--- 1.9498517513275146 seconds for one epoch ---
--- 0.2851850986480713 seconds for one epoch ---
--- 1.8577985763549805 seconds for one epoch ---
--- 0.2881662845611572 seconds for one epoch ---
--- 1.8872604370117188 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2993581295013428 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2607.840087890625, (1067.712, 4.698252, 1535.4298, 0.0)
   validation loss 882.195068359375, (585.83844, 0.8819103, 295.47476, 0.0)
decoder loss ratio: 22696.398224, decoder SINDy loss  ratio: 0.637824
--- 0.26543426513671875 seconds for one epoch ---
--- 0.18927764892578125 seconds for one epoch ---
--- 1.8991000652313232 seconds for one epoch ---
--- 0.31480979919433594 seconds for one epoch ---
--- 1.8777291774749756 seconds for one epoch ---
--- 0.27707672119140625 seconds for one epoch ---
--- 1.9036791324615479 seconds for one epoch ---
--- 0.29184842109680176 seconds for one epoch ---
--- 1.8638360500335693 seconds for one epoch ---
--- 0.26178741455078125 seconds for one epoch ---
--- 1.8822853565216064 seconds for one epoch ---
--- 0.2940409183502197 seconds for one epoch ---
--- 1.8773207664489746 seconds for one epoch ---
--- 0.28487396240234375 seconds for one epoch ---
--- 1.9021003246307373 seconds for one epoch ---
--- 0.2782742977142334 seconds for one epoch ---
--- 1.8717951774597168 seconds for one epoch ---
--- 0.24861502647399902 seconds for one epoch ---
--- 1.9144723415374756 seconds for one epoch ---
--- 0.28692150115966797 seconds for one epoch ---
--- 1.9189767837524414 seconds for one epoch ---
--- 0.27915143966674805 seconds for one epoch ---
--- 1.8647677898406982 seconds for one epoch ---
--- 0.19046401977539062 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2321326732635498 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2822.12060546875, (1515.9023, 2.599943, 1303.6182, 0.0)
   validation loss 750.37158203125, (437.7427, 0.9092529, 311.71964, 0.0)
decoder loss ratio: 16958.912397, decoder SINDy loss  ratio: 0.672891
--- 0.2847738265991211 seconds for one epoch ---
--- 1.9001600742340088 seconds for one epoch ---
--- 0.26177048683166504 seconds for one epoch ---
--- 1.8985943794250488 seconds for one epoch ---
--- 0.2879776954650879 seconds for one epoch ---
--- 1.9119904041290283 seconds for one epoch ---
--- 0.2944049835205078 seconds for one epoch ---
--- 1.8853859901428223 seconds for one epoch ---
--- 0.24823832511901855 seconds for one epoch ---
--- 1.8554267883300781 seconds for one epoch ---
--- 0.29123616218566895 seconds for one epoch ---
--- 1.9092986583709717 seconds for one epoch ---
--- 0.2769606113433838 seconds for one epoch ---
--- 1.8808798789978027 seconds for one epoch ---
--- 0.27384376525878906 seconds for one epoch ---
--- 1.9532530307769775 seconds for one epoch ---
--- 0.30283045768737793 seconds for one epoch ---
--- 1.8728923797607422 seconds for one epoch ---
--- 0.2891068458557129 seconds for one epoch ---
--- 1.9307289123535156 seconds for one epoch ---
--- 0.2934291362762451 seconds for one epoch ---
--- 1.942072868347168 seconds for one epoch ---
--- 0.2915380001068115 seconds for one epoch ---
--- 1.8708417415618896 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28334808349609375 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2278.070556640625, (1337.465, 3.0284405, 937.5772, 0.0)
   validation loss 871.7570190429688, (518.24426, 0.86490273, 352.64783, 0.0)
decoder loss ratio: 20077.682448, decoder SINDy loss  ratio: 0.761240
--- 0.2623293399810791 seconds for one epoch ---
--- 0.2819709777832031 seconds for one epoch ---
--- 1.8673443794250488 seconds for one epoch ---
--- 0.29284238815307617 seconds for one epoch ---
--- 1.9046132564544678 seconds for one epoch ---
--- 0.2887458801269531 seconds for one epoch ---
--- 2.003814697265625 seconds for one epoch ---
--- 0.2816646099090576 seconds for one epoch ---
--- 1.9253623485565186 seconds for one epoch ---
--- 0.19205141067504883 seconds for one epoch ---
--- 1.9151790142059326 seconds for one epoch ---
--- 0.29048943519592285 seconds for one epoch ---
--- 1.8877065181732178 seconds for one epoch ---
--- 0.2872805595397949 seconds for one epoch ---
--- 1.9066307544708252 seconds for one epoch ---
--- 0.2712106704711914 seconds for one epoch ---
--- 1.92327880859375 seconds for one epoch ---
--- 0.289182186126709 seconds for one epoch ---
--- 1.850675344467163 seconds for one epoch ---
--- 0.18117666244506836 seconds for one epoch ---
--- 1.8644914627075195 seconds for one epoch ---
--- 0.2782886028289795 seconds for one epoch ---
--- 1.9028713703155518 seconds for one epoch ---
--- 0.2899007797241211 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26096510887145996 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7512.85693359375, (1719.929, 18.729658, 5774.198, 0.0)
   validation loss 899.7156372070312, (550.2354, 0.9063086, 348.5739, 0.0)
decoder loss ratio: 21317.075135, decoder SINDy loss  ratio: 0.752446
--- 0.3081638813018799 seconds for one epoch ---
--- 1.9472768306732178 seconds for one epoch ---
--- 0.287585973739624 seconds for one epoch ---
--- 1.897061824798584 seconds for one epoch ---
--- 0.29233765602111816 seconds for one epoch ---
--- 1.9294896125793457 seconds for one epoch ---
--- 0.2604484558105469 seconds for one epoch ---
--- 1.972977876663208 seconds for one epoch ---
--- 0.2682468891143799 seconds for one epoch ---
--- 1.8877437114715576 seconds for one epoch ---
--- 0.2919120788574219 seconds for one epoch ---
--- 1.9033401012420654 seconds for one epoch ---
--- 0.15020322799682617 seconds for one epoch ---
--- 1.8965234756469727 seconds for one epoch ---
--- 0.27595090866088867 seconds for one epoch ---
--- 1.924311876296997 seconds for one epoch ---
--- 0.2859776020050049 seconds for one epoch ---
--- 1.9137730598449707 seconds for one epoch ---
--- 0.2871890068054199 seconds for one epoch ---
--- 1.9390583038330078 seconds for one epoch ---
--- 0.2811424732208252 seconds for one epoch ---
--- 1.9259772300720215 seconds for one epoch ---
--- 0.2700071334838867 seconds for one epoch ---
--- 1.944154977798462 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27400994300842285 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4499.32861328125, (1706.012, 1.752786, 2791.5637, 0.0)
   validation loss 1939.0408935546875, (1594.615, 0.89545065, 343.53043, 0.0)
decoder loss ratio: 61778.153095, decoder SINDy loss  ratio: 0.741559
--- 0.23817968368530273 seconds for one epoch ---
--- 0.27448534965515137 seconds for one epoch ---
--- 1.929908037185669 seconds for one epoch ---
--- 0.2877495288848877 seconds for one epoch ---
--- 1.8101186752319336 seconds for one epoch ---
--- 0.24145174026489258 seconds for one epoch ---
--- 1.9544034004211426 seconds for one epoch ---
--- 0.28852033615112305 seconds for one epoch ---
--- 1.9373364448547363 seconds for one epoch ---
--- 0.28435540199279785 seconds for one epoch ---
--- 1.988628625869751 seconds for one epoch ---
--- 0.2897326946258545 seconds for one epoch ---
--- 1.9636080265045166 seconds for one epoch ---
--- 0.2956531047821045 seconds for one epoch ---
--- 1.9749834537506104 seconds for one epoch ---
--- 0.2760179042816162 seconds for one epoch ---
--- 1.9565041065216064 seconds for one epoch ---
--- 0.28824543952941895 seconds for one epoch ---
--- 1.9388453960418701 seconds for one epoch ---
--- 0.29165005683898926 seconds for one epoch ---
--- 1.83268141746521 seconds for one epoch ---
--- 0.2554614543914795 seconds for one epoch ---
--- 1.9267945289611816 seconds for one epoch ---
--- 0.2509787082672119 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2688302993774414 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2455.001220703125, (1200.6271, 0.77318585, 1253.601, 0.0)
   validation loss 863.6751708984375, (528.73334, 0.90143573, 334.04037, 0.0)
decoder loss ratio: 20484.047412, decoder SINDy loss  ratio: 0.721073
--- 0.2868483066558838 seconds for one epoch ---
--- 1.9200434684753418 seconds for one epoch ---
--- 0.3075263500213623 seconds for one epoch ---
--- 1.9362287521362305 seconds for one epoch ---
--- 0.29214048385620117 seconds for one epoch ---
--- 1.9394562244415283 seconds for one epoch ---
--- 0.2924227714538574 seconds for one epoch ---
--- 1.9373183250427246 seconds for one epoch ---
--- 0.2819843292236328 seconds for one epoch ---
--- 1.9518406391143799 seconds for one epoch ---
--- 0.2836763858795166 seconds for one epoch ---
--- 1.9228289127349854 seconds for one epoch ---
--- 0.30397915840148926 seconds for one epoch ---
--- 1.9682514667510986 seconds for one epoch ---
--- 0.1683511734008789 seconds for one epoch ---
--- 1.973097324371338 seconds for one epoch ---
--- 0.2871558666229248 seconds for one epoch ---
--- 1.9394171237945557 seconds for one epoch ---
--- 0.2895374298095703 seconds for one epoch ---
--- 1.988241195678711 seconds for one epoch ---
--- 0.2811274528503418 seconds for one epoch ---
--- 1.9496679306030273 seconds for one epoch ---
--- 0.3005068302154541 seconds for one epoch ---
--- 1.8854963779449463 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.277907133102417 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3331.91357421875, (1509.658, 1.410051, 1820.8457, 0.0)
   validation loss 844.3222045898438, (516.86523, 0.8623879, 326.5946, 0.0)
decoder loss ratio: 20024.256497, decoder SINDy loss  ratio: 0.705000
--- 0.2418656349182129 seconds for one epoch ---
--- 0.2872920036315918 seconds for one epoch ---
--- 1.9529342651367188 seconds for one epoch ---
--- 0.28192687034606934 seconds for one epoch ---
--- 1.948700189590454 seconds for one epoch ---
--- 0.28916335105895996 seconds for one epoch ---
--- 1.9724533557891846 seconds for one epoch ---
--- 0.3010246753692627 seconds for one epoch ---
--- 1.9827582836151123 seconds for one epoch ---
--- 0.2753875255584717 seconds for one epoch ---
--- 1.992664098739624 seconds for one epoch ---
--- 0.2842578887939453 seconds for one epoch ---
--- 2.032766103744507 seconds for one epoch ---
--- 0.28798556327819824 seconds for one epoch ---
--- 1.9495830535888672 seconds for one epoch ---
--- 0.29689908027648926 seconds for one epoch ---
--- 2.0118136405944824 seconds for one epoch ---
--- 0.168287992477417 seconds for one epoch ---
--- 2.010575532913208 seconds for one epoch ---
--- 0.27394890785217285 seconds for one epoch ---
--- 1.9680368900299072 seconds for one epoch ---
--- 0.2569150924682617 seconds for one epoch ---
--- 2.069796562194824 seconds for one epoch ---
--- 0.2908046245574951 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24633264541625977 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2216.518798828125, (1019.5303, 1.7990304, 1195.1895, 0.0)
   validation loss 1431.99365234375, (1051.3435, 0.87454003, 379.77557, 0.0)
decoder loss ratio: 40730.872630, decoder SINDy loss  ratio: 0.819799
--- 0.2991199493408203 seconds for one epoch ---
--- 1.9677772521972656 seconds for one epoch ---
--- 0.2921478748321533 seconds for one epoch ---
--- 1.9850056171417236 seconds for one epoch ---
--- 0.2870199680328369 seconds for one epoch ---
--- 1.9877455234527588 seconds for one epoch ---
--- 0.279404878616333 seconds for one epoch ---
--- 1.9670779705047607 seconds for one epoch ---
--- 0.2992093563079834 seconds for one epoch ---
--- 2.081796884536743 seconds for one epoch ---
--- 0.28685712814331055 seconds for one epoch ---
--- 1.9747734069824219 seconds for one epoch ---
--- 0.2665412425994873 seconds for one epoch ---
--- 1.9760873317718506 seconds for one epoch ---
--- 0.20853948593139648 seconds for one epoch ---
--- 1.961195707321167 seconds for one epoch ---
--- 0.2851433753967285 seconds for one epoch ---
--- 1.9898216724395752 seconds for one epoch ---
--- 0.2875981330871582 seconds for one epoch ---
--- 1.9741921424865723 seconds for one epoch ---
--- 0.30298614501953125 seconds for one epoch ---
--- 1.9741077423095703 seconds for one epoch ---
--- 0.29248785972595215 seconds for one epoch ---
--- 1.9191038608551025 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28226518630981445 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1427.225341796875, (713.35077, 1.2412547, 712.6333, 0.0)
   validation loss 832.5607299804688, (467.40997, 0.9407268, 364.21002, 0.0)
decoder loss ratio: 18108.273819, decoder SINDy loss  ratio: 0.786199
--- 0.2595815658569336 seconds for one epoch ---
--- 0.302401065826416 seconds for one epoch ---
--- 2.02164888381958 seconds for one epoch ---
--- 0.28594112396240234 seconds for one epoch ---
--- 1.9998741149902344 seconds for one epoch ---
--- 0.3105919361114502 seconds for one epoch ---
--- 2.010585069656372 seconds for one epoch ---
--- 0.2798006534576416 seconds for one epoch ---
--- 1.9687130451202393 seconds for one epoch ---
--- 0.28914594650268555 seconds for one epoch ---
--- 1.9649083614349365 seconds for one epoch ---
--- 0.21927523612976074 seconds for one epoch ---
--- 2.01405668258667 seconds for one epoch ---
--- 0.2839326858520508 seconds for one epoch ---
--- 2.000145435333252 seconds for one epoch ---
--- 0.288985013961792 seconds for one epoch ---
--- 2.049182653427124 seconds for one epoch ---
--- 0.28827381134033203 seconds for one epoch ---
--- 2.0208723545074463 seconds for one epoch ---
--- 0.28720998764038086 seconds for one epoch ---
--- 1.8961970806121826 seconds for one epoch ---
--- 0.2056276798248291 seconds for one epoch ---
--- 1.9838523864746094 seconds for one epoch ---
--- 0.2835574150085449 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25187015533447266 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6284.57177734375, (1025.9857, 5.3400803, 5253.246, 0.0)
   validation loss 801.5384521484375, (482.88257, 0.8836929, 317.7722, 0.0)
decoder loss ratio: 18707.709019, decoder SINDy loss  ratio: 0.685956
--- 0.30236077308654785 seconds for one epoch ---
--- 2.0213050842285156 seconds for one epoch ---
--- 0.20336699485778809 seconds for one epoch ---
--- 2.0245611667633057 seconds for one epoch ---
--- 0.27948498725891113 seconds for one epoch ---
--- 2.1226718425750732 seconds for one epoch ---
--- 0.29231715202331543 seconds for one epoch ---
--- 2.1133716106414795 seconds for one epoch ---
--- 0.2782261371612549 seconds for one epoch ---
--- 2.1716880798339844 seconds for one epoch ---
--- 0.28815126419067383 seconds for one epoch ---
--- 2.0249154567718506 seconds for one epoch ---
--- 0.28377246856689453 seconds for one epoch ---
--- 2.087658166885376 seconds for one epoch ---
--- 0.27984023094177246 seconds for one epoch ---
--- 2.022495985031128 seconds for one epoch ---
--- 0.28682494163513184 seconds for one epoch ---
--- 2.014906406402588 seconds for one epoch ---
--- 0.2747159004211426 seconds for one epoch ---
--- 2.0461204051971436 seconds for one epoch ---
--- 0.27794861793518066 seconds for one epoch ---
--- 2.0388522148132324 seconds for one epoch ---
--- 0.18468999862670898 seconds for one epoch ---
--- 2.040801763534546 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29326486587524414 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2004.798583984375, (1086.5176, 0.31673467, 917.9643, 0.0)
   validation loss 878.0955200195312, (555.35266, 0.9234945, 321.81934, 0.0)
decoder loss ratio: 21515.326227, decoder SINDy loss  ratio: 0.694692
--- 0.23284125328063965 seconds for one epoch ---
--- 0.28691768646240234 seconds for one epoch ---
--- 2.028743028640747 seconds for one epoch ---
--- 0.2900238037109375 seconds for one epoch ---
--- 2.0281922817230225 seconds for one epoch ---
--- 0.3060171604156494 seconds for one epoch ---
--- 2.058995246887207 seconds for one epoch ---
--- 0.2793114185333252 seconds for one epoch ---
--- 1.9573729038238525 seconds for one epoch ---
--- 0.1560814380645752 seconds for one epoch ---
--- 2.09782338142395 seconds for one epoch ---
--- 0.3063054084777832 seconds for one epoch ---
--- 2.0291907787323 seconds for one epoch ---
--- 0.2914595603942871 seconds for one epoch ---
--- 2.12747859954834 seconds for one epoch ---
--- 0.3111076354980469 seconds for one epoch ---
--- 2.1491928100585938 seconds for one epoch ---
--- 0.29462480545043945 seconds for one epoch ---
--- 2.0382349491119385 seconds for one epoch ---
--- 0.16234636306762695 seconds for one epoch ---
--- 1.98854398727417 seconds for one epoch ---
--- 0.2842445373535156 seconds for one epoch ---
--- 2.0521955490112305 seconds for one epoch ---
--- 0.2962377071380615 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24892091751098633 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3047.439208984375, (1391.7883, 2.275245, 1653.3756, 0.0)
   validation loss 877.2553100585938, (536.83734, 0.9931399, 339.4248, 0.0)
decoder loss ratio: 20798.010593, decoder SINDy loss  ratio: 0.732696
--- 0.276564359664917 seconds for one epoch ---
--- 2.012341260910034 seconds for one epoch ---
--- 0.3088696002960205 seconds for one epoch ---
--- 2.0457358360290527 seconds for one epoch ---
--- 0.28383469581604004 seconds for one epoch ---
--- 2.070352792739868 seconds for one epoch ---
--- 0.27481555938720703 seconds for one epoch ---
--- 2.036973237991333 seconds for one epoch ---
--- 0.2949368953704834 seconds for one epoch ---
--- 2.0464673042297363 seconds for one epoch ---
--- 0.3059225082397461 seconds for one epoch ---
--- 2.0585474967956543 seconds for one epoch ---
--- 0.28123903274536133 seconds for one epoch ---
--- 2.0595321655273438 seconds for one epoch ---
--- 0.2524070739746094 seconds for one epoch ---
--- 2.0416462421417236 seconds for one epoch ---
--- 0.25473999977111816 seconds for one epoch ---
--- 2.025902509689331 seconds for one epoch ---
--- 0.27261877059936523 seconds for one epoch ---
--- 2.0457406044006348 seconds for one epoch ---
--- 0.2823154926300049 seconds for one epoch ---
--- 2.0972819328308105 seconds for one epoch ---
--- 0.293743371963501 seconds for one epoch ---
--- 2.067249298095703 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29369473457336426 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7444.83203125, (1393.0997, 1.2708203, 6050.4614, 0.0)
   validation loss 777.3792724609375, (455.0508, 0.96591187, 321.36258, 0.0)
decoder loss ratio: 17629.458451, decoder SINDy loss  ratio: 0.693706
--- 0.23654484748840332 seconds for one epoch ---
--- 0.3034555912017822 seconds for one epoch ---
--- 2.1029670238494873 seconds for one epoch ---
--- 0.29439282417297363 seconds for one epoch ---
--- 2.0665700435638428 seconds for one epoch ---
--- 0.2899186611175537 seconds for one epoch ---
--- 2.109283447265625 seconds for one epoch ---
--- 0.24951529502868652 seconds for one epoch ---
--- 2.0683295726776123 seconds for one epoch ---
--- 0.2744605541229248 seconds for one epoch ---
--- 2.0472214221954346 seconds for one epoch ---
--- 0.25665903091430664 seconds for one epoch ---
--- 2.1045656204223633 seconds for one epoch ---
--- 0.2955460548400879 seconds for one epoch ---
--- 2.0584418773651123 seconds for one epoch ---
--- 0.2897331714630127 seconds for one epoch ---
--- 2.0708694458007812 seconds for one epoch ---
--- 0.293365478515625 seconds for one epoch ---
--- 2.0911221504211426 seconds for one epoch ---
--- 0.2911992073059082 seconds for one epoch ---
--- 2.0407497882843018 seconds for one epoch ---
--- 0.28670525550842285 seconds for one epoch ---
--- 2.091749429702759 seconds for one epoch ---
--- 0.2966289520263672 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25439953804016113 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2383.43115234375, (1218.3613, 0.44242588, 1164.6274, 0.0)
   validation loss 881.38134765625, (574.10016, 1.0409114, 306.2403, 0.0)
decoder loss ratio: 22241.636829, decoder SINDy loss  ratio: 0.661063
--- 0.2896099090576172 seconds for one epoch ---
--- 2.1154274940490723 seconds for one epoch ---
--- 0.30518054962158203 seconds for one epoch ---
--- 2.099069595336914 seconds for one epoch ---
--- 0.284287691116333 seconds for one epoch ---
--- 2.1070735454559326 seconds for one epoch ---
--- 0.2886924743652344 seconds for one epoch ---
--- 2.12294864654541 seconds for one epoch ---
--- 0.27445077896118164 seconds for one epoch ---
--- 2.064819574356079 seconds for one epoch ---
--- 0.2842884063720703 seconds for one epoch ---
--- 2.052457332611084 seconds for one epoch ---
--- 0.28404903411865234 seconds for one epoch ---
--- 2.0825114250183105 seconds for one epoch ---
--- 0.2950119972229004 seconds for one epoch ---
--- 2.1049256324768066 seconds for one epoch ---
--- 0.29009437561035156 seconds for one epoch ---
--- 2.086397647857666 seconds for one epoch ---
--- 0.28216052055358887 seconds for one epoch ---
--- 2.0752837657928467 seconds for one epoch ---
--- 0.29093384742736816 seconds for one epoch ---
--- 1.9923367500305176 seconds for one epoch ---
--- 0.2335803508758545 seconds for one epoch ---
--- 2.0217435359954834 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2658984661102295 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2864.490234375, (1091.4326, 2.0684566, 1770.9891, 0.0)
   validation loss 848.2501831054688, (530.9733, 0.981607, 316.29523, 0.0)
decoder loss ratio: 20570.828523, decoder SINDy loss  ratio: 0.682768
--- 0.23563265800476074 seconds for one epoch ---
--- 0.27627086639404297 seconds for one epoch ---
--- 2.0543782711029053 seconds for one epoch ---
--- 0.2498788833618164 seconds for one epoch ---
--- 2.058161735534668 seconds for one epoch ---
--- 0.3062150478363037 seconds for one epoch ---
--- 2.0856730937957764 seconds for one epoch ---
--- 0.29589223861694336 seconds for one epoch ---
--- 2.15236759185791 seconds for one epoch ---
--- 0.2900533676147461 seconds for one epoch ---
--- 2.118230104446411 seconds for one epoch ---
--- 0.2857222557067871 seconds for one epoch ---
--- 2.0875003337860107 seconds for one epoch ---
--- 0.16277456283569336 seconds for one epoch ---
--- 2.115961790084839 seconds for one epoch ---
--- 0.28898096084594727 seconds for one epoch ---
--- 2.0924227237701416 seconds for one epoch ---
--- 0.2916908264160156 seconds for one epoch ---
--- 2.0971522331237793 seconds for one epoch ---
--- 0.2899291515350342 seconds for one epoch ---
--- 2.102564811706543 seconds for one epoch ---
--- 0.29293298721313477 seconds for one epoch ---
--- 2.168769598007202 seconds for one epoch ---
--- 0.29815006256103516 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25705862045288086 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2961.27978515625, (1323.0172, 0.8215429, 1637.4412, 0.0)
   validation loss 982.5760498046875, (627.7284, 0.960223, 353.88748, 0.0)
decoder loss ratio: 24319.287751, decoder SINDy loss  ratio: 0.763916
--- 0.2739529609680176 seconds for one epoch ---
--- 2.1301252841949463 seconds for one epoch ---
--- 0.2827916145324707 seconds for one epoch ---
--- 2.1396484375 seconds for one epoch ---
--- 0.2909355163574219 seconds for one epoch ---
--- 2.121940851211548 seconds for one epoch ---
--- 0.2958261966705322 seconds for one epoch ---
--- 2.1007745265960693 seconds for one epoch ---
--- 0.16861438751220703 seconds for one epoch ---
--- 2.0955309867858887 seconds for one epoch ---
--- 0.2708706855773926 seconds for one epoch ---
--- 2.09391188621521 seconds for one epoch ---
--- 0.2941765785217285 seconds for one epoch ---
--- 2.107574224472046 seconds for one epoch ---
--- 0.26909303665161133 seconds for one epoch ---
--- 2.122298240661621 seconds for one epoch ---
--- 0.27968740463256836 seconds for one epoch ---
--- 2.0224483013153076 seconds for one epoch ---
--- 0.18456339836120605 seconds for one epoch ---
--- 2.122645139694214 seconds for one epoch ---
--- 0.29013943672180176 seconds for one epoch ---
--- 2.115363597869873 seconds for one epoch ---
--- 0.29866957664489746 seconds for one epoch ---
--- 2.2056007385253906 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2842996120452881 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1872.135498046875, (696.5189, 0.97143984, 1174.6451, 0.0)
   validation loss 905.333984375, (582.9562, 1.0565774, 321.32126, 0.0)
decoder loss ratio: 22584.734344, decoder SINDy loss  ratio: 0.693617
--- 0.2693488597869873 seconds for one epoch ---
--- 0.3042576313018799 seconds for one epoch ---
--- 2.146904468536377 seconds for one epoch ---
--- 0.2943844795227051 seconds for one epoch ---
--- 2.1482672691345215 seconds for one epoch ---
--- 0.28695058822631836 seconds for one epoch ---
--- 2.147948741912842 seconds for one epoch ---
--- 0.3012216091156006 seconds for one epoch ---
--- 2.110616445541382 seconds for one epoch ---
--- 0.2805607318878174 seconds for one epoch ---
--- 2.0918564796447754 seconds for one epoch ---
--- 0.29450488090515137 seconds for one epoch ---
--- 2.0971877574920654 seconds for one epoch ---
--- 0.2877376079559326 seconds for one epoch ---
--- 2.128281831741333 seconds for one epoch ---
--- 0.2983741760253906 seconds for one epoch ---
--- 2.1343111991882324 seconds for one epoch ---
--- 0.2934539318084717 seconds for one epoch ---
--- 2.1664187908172607 seconds for one epoch ---
--- 0.303539514541626 seconds for one epoch ---
--- 2.1223175525665283 seconds for one epoch ---
--- 0.2964437007904053 seconds for one epoch ---
--- 2.1314594745635986 seconds for one epoch ---
--- 0.2792963981628418 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2674236297607422 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3164.47900390625, (1612.2964, 3.2002757, 1548.9823, 0.0)
   validation loss 916.1319580078125, (577.914, 1.0755849, 337.14243, 0.0)
decoder loss ratio: 22389.391720, decoder SINDy loss  ratio: 0.727769
--- 0.2839653491973877 seconds for one epoch ---
--- 2.125206708908081 seconds for one epoch ---
--- 0.2874438762664795 seconds for one epoch ---
--- 2.166425943374634 seconds for one epoch ---
--- 0.2781493663787842 seconds for one epoch ---
--- 2.1877059936523438 seconds for one epoch ---
--- 0.25614023208618164 seconds for one epoch ---
--- 2.20922589302063 seconds for one epoch ---
--- 0.21999001502990723 seconds for one epoch ---
--- 2.2107768058776855 seconds for one epoch ---
--- 0.29572415351867676 seconds for one epoch ---
--- 2.122978687286377 seconds for one epoch ---
--- 0.28430843353271484 seconds for one epoch ---
--- 2.1451282501220703 seconds for one epoch ---
--- 0.2942690849304199 seconds for one epoch ---
--- 2.190688371658325 seconds for one epoch ---
--- 0.2899026870727539 seconds for one epoch ---
--- 2.1137943267822266 seconds for one epoch ---
--- 0.30143117904663086 seconds for one epoch ---
--- 2.1751561164855957 seconds for one epoch ---
--- 0.28063392639160156 seconds for one epoch ---
--- 2.1777572631835938 seconds for one epoch ---
--- 0.28964710235595703 seconds for one epoch ---
--- 2.2064170837402344 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28395533561706543 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2423.354248046875, (1198.29, 1.1590297, 1223.9052, 0.0)
   validation loss 1337.8431396484375, (969.43475, 1.0322022, 367.37616, 0.0)
decoder loss ratio: 37557.585360, decoder SINDy loss  ratio: 0.793033
THRESHOLDING: 0 active coefficients
--- 2.140284299850464 seconds for one epoch ---
--- 0.2579197883605957 seconds for one epoch ---
--- 2.215116262435913 seconds for one epoch ---
--- 0.2847874164581299 seconds for one epoch ---
--- 2.1445486545562744 seconds for one epoch ---
--- 0.2860832214355469 seconds for one epoch ---
--- 2.132904529571533 seconds for one epoch ---
--- 0.28795909881591797 seconds for one epoch ---
--- 2.180316925048828 seconds for one epoch ---
--- 0.304654598236084 seconds for one epoch ---
--- 2.150034189224243 seconds for one epoch ---
--- 0.29808640480041504 seconds for one epoch ---
--- 2.0962390899658203 seconds for one epoch ---
--- 0.22497248649597168 seconds for one epoch ---
--- 2.211731195449829 seconds for one epoch ---
--- 0.2875044345855713 seconds for one epoch ---
--- 2.1571640968322754 seconds for one epoch ---
--- 0.2868006229400635 seconds for one epoch ---
--- 2.1868393421173096 seconds for one epoch ---
--- 0.274914026260376 seconds for one epoch ---
--- 2.219339370727539 seconds for one epoch ---
--- 0.2833442687988281 seconds for one epoch ---
--- 2.2755770683288574 seconds for one epoch ---
--- 0.29476094245910645 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25724196434020996 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2506.034912109375, (1008.55743, 1.767948, 1495.7095, 0.0)
   validation loss 856.30908203125, (519.05554, 1.0946672, 336.1589, 0.0)
decoder loss ratio: 20109.112817, decoder SINDy loss  ratio: 0.725646
--- 0.3051786422729492 seconds for one epoch ---
--- 2.2237422466278076 seconds for one epoch ---
--- 0.28768181800842285 seconds for one epoch ---
--- 2.1599173545837402 seconds for one epoch ---
--- 0.2871897220611572 seconds for one epoch ---
--- 2.1243791580200195 seconds for one epoch ---
--- 0.26381778717041016 seconds for one epoch ---
--- 2.1938304901123047 seconds for one epoch ---
--- 0.2577848434448242 seconds for one epoch ---
--- 2.1848764419555664 seconds for one epoch ---
--- 0.2865748405456543 seconds for one epoch ---
--- 2.2522330284118652 seconds for one epoch ---
--- 0.2948622703552246 seconds for one epoch ---
--- 2.1647703647613525 seconds for one epoch ---
--- 0.2851700782775879 seconds for one epoch ---
--- 2.1048786640167236 seconds for one epoch ---
--- 0.2775261402130127 seconds for one epoch ---
--- 2.1842896938323975 seconds for one epoch ---
--- 0.2888011932373047 seconds for one epoch ---
--- 2.196493148803711 seconds for one epoch ---
--- 0.24860429763793945 seconds for one epoch ---
--- 2.192783832550049 seconds for one epoch ---
--- 0.2864954471588135 seconds for one epoch ---
--- 2.1910324096679688 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26334476470947266 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3020.7802734375, (1508.6528, 1.6669613, 1510.4606, 0.0)
   validation loss 1409.743408203125, (1037.8923, 1.0917073, 370.75946, 0.0)
decoder loss ratio: 40209.750879, decoder SINDy loss  ratio: 0.800336
--- 0.24866151809692383 seconds for one epoch ---
--- 0.29355692863464355 seconds for one epoch ---
--- 2.2710013389587402 seconds for one epoch ---
--- 0.28341197967529297 seconds for one epoch ---
--- 2.1746442317962646 seconds for one epoch ---
--- 0.19285368919372559 seconds for one epoch ---
--- 2.1587038040161133 seconds for one epoch ---
--- 0.26222991943359375 seconds for one epoch ---
--- 2.1789448261260986 seconds for one epoch ---
--- 0.2887146472930908 seconds for one epoch ---
--- 2.208876848220825 seconds for one epoch ---
--- 0.29421067237854004 seconds for one epoch ---
--- 2.202317714691162 seconds for one epoch ---
--- 0.29586243629455566 seconds for one epoch ---
--- 2.1701486110687256 seconds for one epoch ---
--- 0.20371747016906738 seconds for one epoch ---
--- 2.203329086303711 seconds for one epoch ---
--- 0.27784109115600586 seconds for one epoch ---
--- 2.193713426589966 seconds for one epoch ---
--- 0.26545286178588867 seconds for one epoch ---
--- 2.2243311405181885 seconds for one epoch ---
--- 0.28699493408203125 seconds for one epoch ---
--- 2.229548692703247 seconds for one epoch ---
--- 0.2877843379974365 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2402946949005127 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2113.3349609375, (1170.4915, 1.801112, 941.04236, 0.0)
   validation loss 914.8736572265625, (589.8556, 1.1815751, 323.83652, 0.0)
decoder loss ratio: 22852.029623, decoder SINDy loss  ratio: 0.699047
--- 0.29355359077453613 seconds for one epoch ---
--- 2.238607406616211 seconds for one epoch ---
--- 0.3015918731689453 seconds for one epoch ---
--- 2.225558280944824 seconds for one epoch ---
--- 0.27748727798461914 seconds for one epoch ---
--- 2.17698073387146 seconds for one epoch ---
--- 0.2903482913970947 seconds for one epoch ---
--- 2.1298296451568604 seconds for one epoch ---
--- 0.18039917945861816 seconds for one epoch ---
--- 2.2074639797210693 seconds for one epoch ---
--- 0.2729952335357666 seconds for one epoch ---
--- 2.244394063949585 seconds for one epoch ---
--- 0.29522252082824707 seconds for one epoch ---
--- 2.203611373901367 seconds for one epoch ---
--- 0.2881927490234375 seconds for one epoch ---
--- 2.223562002182007 seconds for one epoch ---
--- 0.2600719928741455 seconds for one epoch ---
--- 2.2169575691223145 seconds for one epoch ---
--- 0.28048229217529297 seconds for one epoch ---
--- 2.3516011238098145 seconds for one epoch ---
--- 0.29143786430358887 seconds for one epoch ---
--- 2.208979845046997 seconds for one epoch ---
--- 0.2537269592285156 seconds for one epoch ---
--- 2.2495009899139404 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26290225982666016 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2475.676025390625, (869.0129, 0.6744638, 1605.9888, 0.0)
   validation loss 948.2049560546875, (598.98596, 1.0919135, 348.12708, 0.0)
decoder loss ratio: 23205.756050, decoder SINDy loss  ratio: 0.751481
--- 0.2522151470184326 seconds for one epoch ---
--- 0.28523778915405273 seconds for one epoch ---
--- 2.2519688606262207 seconds for one epoch ---
--- 0.27539944648742676 seconds for one epoch ---
--- 2.218829393386841 seconds for one epoch ---
--- 0.2850329875946045 seconds for one epoch ---
--- 2.282655954360962 seconds for one epoch ---
--- 0.2841064929962158 seconds for one epoch ---
--- 2.246936798095703 seconds for one epoch ---
--- 0.29034948348999023 seconds for one epoch ---
--- 2.1935062408447266 seconds for one epoch ---
--- 0.23578715324401855 seconds for one epoch ---
--- 2.1827549934387207 seconds for one epoch ---
--- 0.27755236625671387 seconds for one epoch ---
--- 2.146545886993408 seconds for one epoch ---
--- 0.18709707260131836 seconds for one epoch ---
--- 2.186556339263916 seconds for one epoch ---
--- 0.28939104080200195 seconds for one epoch ---
--- 2.1986160278320312 seconds for one epoch ---
--- 0.2778031826019287 seconds for one epoch ---
--- 2.2752509117126465 seconds for one epoch ---
--- 0.265153169631958 seconds for one epoch ---
--- 2.3499226570129395 seconds for one epoch ---
--- 0.29018664360046387 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25426578521728516 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2355.861083984375, (1086.4528, 3.1783006, 1266.23, 0.0)
   validation loss 880.065185546875, (554.4158, 1.115652, 324.53372, 0.0)
decoder loss ratio: 21479.029495, decoder SINDy loss  ratio: 0.700552
--- 0.29586052894592285 seconds for one epoch ---
--- 2.317091226577759 seconds for one epoch ---
--- 0.3002758026123047 seconds for one epoch ---
--- 2.2449471950531006 seconds for one epoch ---
--- 0.2014317512512207 seconds for one epoch ---
--- 2.2094457149505615 seconds for one epoch ---
--- 0.26344895362854004 seconds for one epoch ---
--- 2.224412679672241 seconds for one epoch ---
--- 0.25980257987976074 seconds for one epoch ---
--- 2.2524774074554443 seconds for one epoch ---
--- 0.2920403480529785 seconds for one epoch ---
--- 2.2578747272491455 seconds for one epoch ---
--- 0.26728010177612305 seconds for one epoch ---
--- 2.2483458518981934 seconds for one epoch ---
--- 0.2967367172241211 seconds for one epoch ---
--- 2.210174560546875 seconds for one epoch ---
--- 0.2889974117279053 seconds for one epoch ---
--- 2.2698380947113037 seconds for one epoch ---
--- 0.29750752449035645 seconds for one epoch ---
--- 2.2428410053253174 seconds for one epoch ---
--- 0.3179922103881836 seconds for one epoch ---
--- 2.196915864944458 seconds for one epoch ---
--- 0.23235821723937988 seconds for one epoch ---
--- 2.313518762588501 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27964282035827637 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2828.3681640625, (900.4158, 1.0720931, 1926.8802, 0.0)
   validation loss 1159.403076171875, (784.7879, 1.0564619, 373.5587, 0.0)
decoder loss ratio: 30404.045807, decoder SINDy loss  ratio: 0.806379
--- 0.2486891746520996 seconds for one epoch ---
--- 0.2918832302093506 seconds for one epoch ---
--- 2.2326014041900635 seconds for one epoch ---
--- 0.2829422950744629 seconds for one epoch ---
--- 2.264444351196289 seconds for one epoch ---
--- 0.26972436904907227 seconds for one epoch ---
--- 2.292288303375244 seconds for one epoch ---
--- 0.19339299201965332 seconds for one epoch ---
--- 2.2723357677459717 seconds for one epoch ---
--- 0.2707407474517822 seconds for one epoch ---
--- 2.2353527545928955 seconds for one epoch ---
--- 0.29615116119384766 seconds for one epoch ---
--- 2.2838621139526367 seconds for one epoch ---
--- 0.2843167781829834 seconds for one epoch ---
--- 2.259599208831787 seconds for one epoch ---
--- 0.2855103015899658 seconds for one epoch ---
--- 2.2486038208007812 seconds for one epoch ---
--- 0.26045966148376465 seconds for one epoch ---
--- 2.284151077270508 seconds for one epoch ---
--- 0.28238749504089355 seconds for one epoch ---
--- 2.2503151893615723 seconds for one epoch ---
--- 0.28931713104248047 seconds for one epoch ---
--- 2.2490079402923584 seconds for one epoch ---
--- 0.28220558166503906 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23215413093566895 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2386.3427734375, (1161.0074, 1.5621079, 1223.7733, 0.0)
   validation loss 921.3037109375, (579.03754, 1.0765318, 341.18964, 0.0)
decoder loss ratio: 22432.919422, decoder SINDy loss  ratio: 0.736506
--- 0.2805912494659424 seconds for one epoch ---
--- 2.280819892883301 seconds for one epoch ---
--- 0.2941761016845703 seconds for one epoch ---
--- 2.2499732971191406 seconds for one epoch ---
--- 0.2904496192932129 seconds for one epoch ---
--- 2.2623190879821777 seconds for one epoch ---
--- 0.305194616317749 seconds for one epoch ---
--- 2.2288577556610107 seconds for one epoch ---
--- 0.2807648181915283 seconds for one epoch ---
--- 2.3211543560028076 seconds for one epoch ---
--- 0.28238868713378906 seconds for one epoch ---
--- 2.240532159805298 seconds for one epoch ---
--- 0.26446104049682617 seconds for one epoch ---
--- 2.1581368446350098 seconds for one epoch ---
--- 0.19798493385314941 seconds for one epoch ---
--- 2.252556324005127 seconds for one epoch ---
--- 0.29030418395996094 seconds for one epoch ---
--- 2.281419515609741 seconds for one epoch ---
--- 0.27728939056396484 seconds for one epoch ---
--- 2.303467035293579 seconds for one epoch ---
--- 0.27030515670776367 seconds for one epoch ---
--- 2.248037099838257 seconds for one epoch ---
--- 0.2620840072631836 seconds for one epoch ---
--- 2.3762447834014893 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2928469181060791 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4972.125, (1445.9977, 5.282153, 3520.845, 0.0)
   validation loss 888.34765625, (553.79407, 1.0753839, 333.47818, 0.0)
decoder loss ratio: 21454.943599, decoder SINDy loss  ratio: 0.719860
--- 0.26415467262268066 seconds for one epoch ---
--- 0.29183053970336914 seconds for one epoch ---
--- 2.2962939739227295 seconds for one epoch ---
--- 0.180466890335083 seconds for one epoch ---
--- 2.2864270210266113 seconds for one epoch ---
--- 0.28597164154052734 seconds for one epoch ---
--- 2.263007402420044 seconds for one epoch ---
--- 0.28864288330078125 seconds for one epoch ---
--- 2.2627501487731934 seconds for one epoch ---
--- 0.2883739471435547 seconds for one epoch ---
--- 2.2783143520355225 seconds for one epoch ---
--- 0.282745361328125 seconds for one epoch ---
--- 2.2735581398010254 seconds for one epoch ---
--- 0.2873697280883789 seconds for one epoch ---
--- 2.3065032958984375 seconds for one epoch ---
--- 0.29412198066711426 seconds for one epoch ---
--- 2.3458547592163086 seconds for one epoch ---
--- 0.2856454849243164 seconds for one epoch ---
--- 2.3402974605560303 seconds for one epoch ---
--- 0.29303741455078125 seconds for one epoch ---
--- 2.231682062149048 seconds for one epoch ---
--- 0.29135775566101074 seconds for one epoch ---
--- 2.263348340988159 seconds for one epoch ---
--- 0.2881777286529541 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27182650566101074 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2824.3447265625, (1468.2207, 0.89332926, 1355.2308, 0.0)
   validation loss 885.7880859375, (555.7474, 1.0456553, 328.99506, 0.0)
decoder loss ratio: 21530.618146, decoder SINDy loss  ratio: 0.710182
--- 0.28504109382629395 seconds for one epoch ---
--- 2.2960941791534424 seconds for one epoch ---
--- 0.297605037689209 seconds for one epoch ---
--- 2.330937385559082 seconds for one epoch ---
--- 0.30158424377441406 seconds for one epoch ---
--- 2.2819957733154297 seconds for one epoch ---
--- 0.29905271530151367 seconds for one epoch ---
--- 2.259291648864746 seconds for one epoch ---
--- 0.3107271194458008 seconds for one epoch ---
--- 2.338364601135254 seconds for one epoch ---
--- 0.30106544494628906 seconds for one epoch ---
--- 2.298649549484253 seconds for one epoch ---
--- 0.2627890110015869 seconds for one epoch ---
--- 2.184687376022339 seconds for one epoch ---
--- 0.1952345371246338 seconds for one epoch ---
--- 2.3376383781433105 seconds for one epoch ---
--- 0.2824554443359375 seconds for one epoch ---
--- 2.2948598861694336 seconds for one epoch ---
--- 0.28037428855895996 seconds for one epoch ---
--- 2.2998623847961426 seconds for one epoch ---
--- 0.269974946975708 seconds for one epoch ---
--- 2.3608651161193848 seconds for one epoch ---
--- 0.29337191581726074 seconds for one epoch ---
--- 2.324751853942871 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28381896018981934 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2754.8388671875, (1104.5013, 3.1517327, 1647.1858, 0.0)
   validation loss 768.1797485351562, (439.14777, 1.1112599, 327.92072, 0.0)
decoder loss ratio: 17013.346853, decoder SINDy loss  ratio: 0.707863
--- 0.25304484367370605 seconds for one epoch ---
--- 0.2908298969268799 seconds for one epoch ---
--- 2.3240365982055664 seconds for one epoch ---
--- 0.2879774570465088 seconds for one epoch ---
--- 2.3728928565979004 seconds for one epoch ---
--- 0.28780698776245117 seconds for one epoch ---
--- 2.3202638626098633 seconds for one epoch ---
--- 0.16289567947387695 seconds for one epoch ---
--- 2.3059945106506348 seconds for one epoch ---
--- 0.26020359992980957 seconds for one epoch ---
--- 2.3160741329193115 seconds for one epoch ---
--- 0.2521524429321289 seconds for one epoch ---
--- 2.3006532192230225 seconds for one epoch ---
--- 0.28365421295166016 seconds for one epoch ---
--- 2.312840700149536 seconds for one epoch ---
--- 0.2807042598724365 seconds for one epoch ---
--- 2.3210957050323486 seconds for one epoch ---
--- 0.28486180305480957 seconds for one epoch ---
--- 2.3083019256591797 seconds for one epoch ---
--- 0.2994108200073242 seconds for one epoch ---
--- 2.30631685256958 seconds for one epoch ---
--- 0.3023817539215088 seconds for one epoch ---
--- 2.331768274307251 seconds for one epoch ---
--- 0.282712459564209 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.18485379219055176 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4405.8046875, (1364.6741, 1.8502597, 3039.2803, 0.0)
   validation loss 1025.049072265625, (678.97375, 1.0417084, 345.03363, 0.0)
decoder loss ratio: 26304.622014, decoder SINDy loss  ratio: 0.744804
--- 0.27757859230041504 seconds for one epoch ---
--- 2.282261371612549 seconds for one epoch ---
--- 0.2845938205718994 seconds for one epoch ---
--- 2.395571231842041 seconds for one epoch ---
--- 0.25174450874328613 seconds for one epoch ---
--- 2.372404098510742 seconds for one epoch ---
--- 0.29283761978149414 seconds for one epoch ---
--- 2.3565309047698975 seconds for one epoch ---
--- 0.2849447727203369 seconds for one epoch ---
--- 2.3779985904693604 seconds for one epoch ---
--- 0.2878761291503906 seconds for one epoch ---
--- 2.322025775909424 seconds for one epoch ---
--- 0.2915835380554199 seconds for one epoch ---
--- 2.364952802658081 seconds for one epoch ---
--- 0.24982166290283203 seconds for one epoch ---
--- 2.343385696411133 seconds for one epoch ---
--- 0.2763664722442627 seconds for one epoch ---
--- 2.4034667015075684 seconds for one epoch ---
--- 0.2994661331176758 seconds for one epoch ---
--- 2.311404228210449 seconds for one epoch ---
--- 0.3010735511779785 seconds for one epoch ---
--- 2.3206946849823 seconds for one epoch ---
--- 0.6897768974304199 seconds for one epoch ---
--- 2.3521018028259277 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2874925136566162 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2320.511962890625, (1298.4175, 4.270477, 1017.82404, 0.0)
   validation loss 838.2935791015625, (512.6329, 1.064268, 324.5964, 0.0)
decoder loss ratio: 19860.287491, decoder SINDy loss  ratio: 0.700687
--- 0.22381377220153809 seconds for one epoch ---
--- 0.2941274642944336 seconds for one epoch ---
--- 2.3064699172973633 seconds for one epoch ---
--- 0.2826375961303711 seconds for one epoch ---
--- 2.3395307064056396 seconds for one epoch ---
--- 0.28863978385925293 seconds for one epoch ---
--- 2.374112367630005 seconds for one epoch ---
--- 0.29074835777282715 seconds for one epoch ---
--- 2.382556915283203 seconds for one epoch ---
--- 0.28922390937805176 seconds for one epoch ---
--- 2.3449223041534424 seconds for one epoch ---
--- 0.29248905181884766 seconds for one epoch ---
--- 2.3535430431365967 seconds for one epoch ---
--- 0.29296064376831055 seconds for one epoch ---
--- 2.387927293777466 seconds for one epoch ---
--- 0.3024327754974365 seconds for one epoch ---
--- 2.3826510906219482 seconds for one epoch ---
--- 0.29488253593444824 seconds for one epoch ---
--- 2.3618857860565186 seconds for one epoch ---
--- 0.2898702621459961 seconds for one epoch ---
--- 2.33897066116333 seconds for one epoch ---
--- 0.28325891494750977 seconds for one epoch ---
--- 2.36289381980896 seconds for one epoch ---
--- 0.2954597473144531 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23927521705627441 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2526.27587890625, (1194.9375, 0.7090191, 1330.6295, 0.0)
   validation loss 864.1083374023438, (527.381, 1.1284611, 335.59888, 0.0)
decoder loss ratio: 20431.654795, decoder SINDy loss  ratio: 0.724437
--- 0.29885411262512207 seconds for one epoch ---
--- 2.3826546669006348 seconds for one epoch ---
--- 0.2767348289489746 seconds for one epoch ---
--- 2.380124092102051 seconds for one epoch ---
--- 0.29527759552001953 seconds for one epoch ---
--- 2.37135648727417 seconds for one epoch ---
--- 0.2612729072570801 seconds for one epoch ---
--- 2.4356114864349365 seconds for one epoch ---
--- 0.27866268157958984 seconds for one epoch ---
--- 2.377638339996338 seconds for one epoch ---
--- 0.20204997062683105 seconds for one epoch ---
--- 2.37605881690979 seconds for one epoch ---
--- 0.27465343475341797 seconds for one epoch ---
--- 2.343636989593506 seconds for one epoch ---
--- 0.20430278778076172 seconds for one epoch ---
--- 2.435584783554077 seconds for one epoch ---
--- 0.2836582660675049 seconds for one epoch ---
--- 2.3696587085723877 seconds for one epoch ---
--- 0.29208827018737793 seconds for one epoch ---
--- 2.384423017501831 seconds for one epoch ---
--- 0.27848196029663086 seconds for one epoch ---
--- 2.379819393157959 seconds for one epoch ---
--- 0.2918257713317871 seconds for one epoch ---
--- 2.376850128173828 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2929713726043701 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3178.57666015625, (1087.7523, 2.9620523, 2087.8623, 0.0)
   validation loss 903.6693115234375, (548.00726, 1.0678837, 354.5942, 0.0)
decoder loss ratio: 21230.752758, decoder SINDy loss  ratio: 0.765441
--- 0.27532482147216797 seconds for one epoch ---
--- 0.29625630378723145 seconds for one epoch ---
--- 2.406620740890503 seconds for one epoch ---
--- 0.3021211624145508 seconds for one epoch ---
--- 2.4174487590789795 seconds for one epoch ---
--- 0.2863767147064209 seconds for one epoch ---
--- 2.2980306148529053 seconds for one epoch ---
--- 0.2817261219024658 seconds for one epoch ---
--- 2.376633644104004 seconds for one epoch ---
--- 0.2948873043060303 seconds for one epoch ---
--- 2.287033796310425 seconds for one epoch ---
--- 0.2785463333129883 seconds for one epoch ---
--- 2.3802950382232666 seconds for one epoch ---
--- 0.2990152835845947 seconds for one epoch ---
--- 2.27541446685791 seconds for one epoch ---
--- 0.2557487487792969 seconds for one epoch ---
--- 2.392738103866577 seconds for one epoch ---
--- 0.28673768043518066 seconds for one epoch ---
--- 2.3596975803375244 seconds for one epoch ---
--- 0.2873861789703369 seconds for one epoch ---
--- 2.398185968399048 seconds for one epoch ---
--- 0.2940354347229004 seconds for one epoch ---
--- 2.3820900917053223 seconds for one epoch ---
--- 0.292574405670166 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25330686569213867 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3426.6083984375, (1494.3064, 5.3364954, 1926.9653, 0.0)
   validation loss 1178.96044921875, (792.1265, 1.1736798, 385.66022, 0.0)
decoder loss ratio: 30688.356805, decoder SINDy loss  ratio: 0.832502
--- 0.28937816619873047 seconds for one epoch ---
--- 2.370975971221924 seconds for one epoch ---
--- 0.2827727794647217 seconds for one epoch ---
--- 2.449895143508911 seconds for one epoch ---
--- 0.26844072341918945 seconds for one epoch ---
--- 2.4625437259674072 seconds for one epoch ---
--- 0.2793605327606201 seconds for one epoch ---
--- 2.4318604469299316 seconds for one epoch ---
--- 0.2882380485534668 seconds for one epoch ---
--- 2.379995346069336 seconds for one epoch ---
--- 0.2941586971282959 seconds for one epoch ---
--- 2.4466092586517334 seconds for one epoch ---
--- 0.2998185157775879 seconds for one epoch ---
--- 2.3829855918884277 seconds for one epoch ---
--- 0.3123779296875 seconds for one epoch ---
--- 2.4537620544433594 seconds for one epoch ---
--- 0.3066835403442383 seconds for one epoch ---
--- 2.3688113689422607 seconds for one epoch ---
--- 0.30219268798828125 seconds for one epoch ---
--- 2.3905344009399414 seconds for one epoch ---
--- 0.30175304412841797 seconds for one epoch ---
--- 2.4080398082733154 seconds for one epoch ---
--- 0.31306886672973633 seconds for one epoch ---
--- 2.4456124305725098 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.1958303451538086 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3275.987548828125, (1112.7412, 1.5630467, 2161.6833, 0.0)
   validation loss 1570.6129150390625, (1202.8889, 1.1550884, 366.56897, 0.0)
decoder loss ratio: 46602.004913, decoder SINDy loss  ratio: 0.791291
--- 1.0656225681304932 seconds for one epoch ---
--- 0.28753113746643066 seconds for one epoch ---
--- 2.358163356781006 seconds for one epoch ---
--- 0.17647171020507812 seconds for one epoch ---
--- 2.4113049507141113 seconds for one epoch ---
--- 0.28515005111694336 seconds for one epoch ---
--- 2.38193678855896 seconds for one epoch ---
--- 0.29390501976013184 seconds for one epoch ---
--- 2.426194429397583 seconds for one epoch ---
--- 0.25008511543273926 seconds for one epoch ---
--- 2.414001941680908 seconds for one epoch ---
--- 0.22899198532104492 seconds for one epoch ---
--- 2.44155216217041 seconds for one epoch ---
--- 0.2865869998931885 seconds for one epoch ---
--- 2.4209647178649902 seconds for one epoch ---
--- 0.28101634979248047 seconds for one epoch ---
--- 2.4150655269622803 seconds for one epoch ---
--- 0.286726713180542 seconds for one epoch ---
--- 2.4675817489624023 seconds for one epoch ---
--- 0.2977108955383301 seconds for one epoch ---
--- 2.437443494796753 seconds for one epoch ---
--- 0.2964456081390381 seconds for one epoch ---
--- 2.4415946006774902 seconds for one epoch ---
--- 0.2942640781402588 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27593469619750977 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3756.937744140625, (1875.7147, 1.214526, 1880.0085, 0.0)
   validation loss 1511.2596435546875, (1148.0565, 1.1424572, 362.06067, 0.0)
decoder loss ratio: 44477.702643, decoder SINDy loss  ratio: 0.781559
--- 0.302201509475708 seconds for one epoch ---
--- 2.412837028503418 seconds for one epoch ---
--- 0.27196693420410156 seconds for one epoch ---
--- 2.441516399383545 seconds for one epoch ---
--- 0.28783154487609863 seconds for one epoch ---
--- 2.4329464435577393 seconds for one epoch ---
--- 0.2685978412628174 seconds for one epoch ---
--- 2.399418592453003 seconds for one epoch ---
--- 0.29055118560791016 seconds for one epoch ---
--- 2.4214255809783936 seconds for one epoch ---
--- 0.2714560031890869 seconds for one epoch ---
--- 2.438892364501953 seconds for one epoch ---
--- 0.27240705490112305 seconds for one epoch ---
--- 2.4261975288391113 seconds for one epoch ---
--- 0.2846794128417969 seconds for one epoch ---
--- 2.4384491443634033 seconds for one epoch ---
--- 0.2901768684387207 seconds for one epoch ---
--- 2.4213199615478516 seconds for one epoch ---
--- 0.29331278800964355 seconds for one epoch ---
--- 2.421658754348755 seconds for one epoch ---
--- 0.2754664421081543 seconds for one epoch ---
--- 2.3941516876220703 seconds for one epoch ---
--- 0.2806828022003174 seconds for one epoch ---
--- 2.428318738937378 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.1961040496826172 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8505.7265625, (1493.2743, 8.083426, 7004.369, 0.0)
   validation loss 852.035400390625, (521.63153, 1.1676273, 329.23627, 0.0)
decoder loss ratio: 20208.911094, decoder SINDy loss  ratio: 0.710703
--- 0.22316956520080566 seconds for one epoch ---
--- 0.25405287742614746 seconds for one epoch ---
--- 2.4105303287506104 seconds for one epoch ---
--- 0.2787141799926758 seconds for one epoch ---
--- 2.4345529079437256 seconds for one epoch ---
--- 0.29276394844055176 seconds for one epoch ---
--- 2.421799421310425 seconds for one epoch ---
--- 0.2831001281738281 seconds for one epoch ---
--- 2.4142940044403076 seconds for one epoch ---
--- 0.2934987545013428 seconds for one epoch ---
--- 2.4160566329956055 seconds for one epoch ---
--- 0.2691216468811035 seconds for one epoch ---
--- 2.4156816005706787 seconds for one epoch ---
--- 0.2756338119506836 seconds for one epoch ---
--- 2.460911273956299 seconds for one epoch ---
--- 0.28525280952453613 seconds for one epoch ---
--- 2.455850839614868 seconds for one epoch ---
--- 0.29119062423706055 seconds for one epoch ---
--- 2.436033248901367 seconds for one epoch ---
--- 0.28739333152770996 seconds for one epoch ---
--- 2.445861577987671 seconds for one epoch ---
--- 0.28450918197631836 seconds for one epoch ---
--- 2.469259262084961 seconds for one epoch ---
--- 0.2858564853668213 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25769853591918945 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2679.333984375, (1083.683, 1.2253901, 1594.4257, 0.0)
   validation loss 761.18505859375, (424.04507, 1.1501325, 335.98984, 0.0)
decoder loss ratio: 16428.242359, decoder SINDy loss  ratio: 0.725281
--- 0.2889714241027832 seconds for one epoch ---
--- 2.4674744606018066 seconds for one epoch ---
--- 0.29598021507263184 seconds for one epoch ---
--- 2.470959186553955 seconds for one epoch ---
--- 0.2871701717376709 seconds for one epoch ---
--- 2.4251554012298584 seconds for one epoch ---
--- 0.2847917079925537 seconds for one epoch ---
--- 2.4259233474731445 seconds for one epoch ---
--- 0.2862820625305176 seconds for one epoch ---
--- 2.43603777885437 seconds for one epoch ---
--- 0.29663801193237305 seconds for one epoch ---
--- 2.4636404514312744 seconds for one epoch ---
--- 0.28587841987609863 seconds for one epoch ---
--- 2.46178936958313 seconds for one epoch ---
--- 0.2780623435974121 seconds for one epoch ---
--- 2.516620635986328 seconds for one epoch ---
--- 0.2959284782409668 seconds for one epoch ---
--- 2.4587631225585938 seconds for one epoch ---
--- 0.25498342514038086 seconds for one epoch ---
--- 2.492523670196533 seconds for one epoch ---
--- 0.2775607109069824 seconds for one epoch ---
--- 2.5102319717407227 seconds for one epoch ---
--- 0.26929593086242676 seconds for one epoch ---
--- 2.47090482711792 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2733480930328369 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1913.588623046875, (756.01544, 1.757778, 1155.8154, 0.0)
   validation loss 795.7420654296875, (468.8211, 1.1898345, 325.7311, 0.0)
decoder loss ratio: 18162.943554, decoder SINDy loss  ratio: 0.703136
THRESHOLDING: 0 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1136.894287109375, (523.2289, 0.7495112, 612.91595, 0.0)
   validation loss 739.7015380859375, (437.1049, 1.0139205, 301.5827, 0.0)
decoder loss ratio: 16934.202244, decoder SINDy loss  ratio: 0.651009
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 874.6475830078125, (325.50137, 0.43548125, 548.71075, 0.0)
   validation loss 547.732666015625, (278.60822, 0.39917305, 268.72525, 0.0)
decoder loss ratio: 10793.765947, decoder SINDy loss  ratio: 0.580081
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 978.0416259765625, (453.50766, 0.3023755, 524.23157, 0.0)
   validation loss 706.5819702148438, (440.78128, 0.3264641, 265.4742, 0.0)
decoder loss ratio: 17076.632037, decoder SINDy loss  ratio: 0.573063
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1448.720703125, (927.82965, 0.2594349, 520.63165, 0.0)
   validation loss 1182.064208984375, (907.08374, 0.28763738, 274.69287, 0.0)
decoder loss ratio: 35141.998863, decoder SINDy loss  ratio: 0.592963
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.353271484375, (262.13083, 0.24788293, 530.97455, 0.0)
   validation loss 475.364501953125, (213.2791, 0.2673777, 261.81802, 0.0)
decoder loss ratio: 8262.802545, decoder SINDy loss  ratio: 0.565171
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 994.9459838867188, (489.52914, 0.2422435, 505.1746, 0.0)
   validation loss 720.315185546875, (457.71234, 0.26541817, 262.33743, 0.0)
decoder loss ratio: 17732.570726, decoder SINDy loss  ratio: 0.566292
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.520263671875, (271.236, 0.23959458, 514.0447, 0.0)
   validation loss 487.10650634765625, (226.34256, 0.26459318, 260.49936, 0.0)
decoder loss ratio: 8768.903715, decoder SINDy loss  ratio: 0.562325
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 834.8204345703125, (323.72867, 0.2530164, 510.83875, 0.0)
   validation loss 542.4807739257812, (281.26212, 0.26437357, 260.95428, 0.0)
decoder loss ratio: 10896.582646, decoder SINDy loss  ratio: 0.563307
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 891.927001953125, (334.51196, 0.27226707, 557.14276, 0.0)
   validation loss 508.662109375, (236.98267, 0.27196229, 271.40747, 0.0)
decoder loss ratio: 9181.119901, decoder SINDy loss  ratio: 0.585871
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1347.61962890625, (753.50616, 0.25086185, 593.8626, 0.0)
   validation loss 952.754638671875, (656.33356, 0.25750083, 296.16354, 0.0)
decoder loss ratio: 25427.501448, decoder SINDy loss  ratio: 0.639311
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.5496826171875, (258.12277, 0.25193533, 526.175, 0.0)
   validation loss 463.0361328125, (196.78236, 0.27049285, 265.98328, 0.0)
decoder loss ratio: 7623.690406, decoder SINDy loss  ratio: 0.574162
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 964.8128662109375, (470.48618, 0.24149765, 494.08517, 0.0)
   validation loss 687.7927856445312, (426.78726, 0.2753898, 260.73013, 0.0)
decoder loss ratio: 16534.479464, decoder SINDy loss  ratio: 0.562823
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.7811279296875, (254.2622, 0.25546873, 512.2634, 0.0)
   validation loss 463.7857666015625, (199.74922, 0.27241656, 263.76413, 0.0)
decoder loss ratio: 7738.631632, decoder SINDy loss  ratio: 0.569372
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.6166381835938, (355.93533, 0.24636483, 495.43494, 0.0)
   validation loss 570.9229736328125, (309.2358, 0.27757978, 261.4096, 0.0)
decoder loss ratio: 11980.332110, decoder SINDy loss  ratio: 0.564289
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.140625, (258.77026, 0.24515131, 523.12524, 0.0)
   validation loss 462.04925537109375, (194.19577, 0.2731668, 267.58032, 0.0)
decoder loss ratio: 7523.481279, decoder SINDy loss  ratio: 0.577610
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 944.0856323242188, (452.63803, 0.23572397, 491.21188, 0.0)
   validation loss 669.0874633789062, (407.03635, 0.27989846, 261.7712, 0.0)
decoder loss ratio: 15769.294707, decoder SINDy loss  ratio: 0.565070
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.895751953125, (258.30823, 0.24415429, 504.34338, 0.0)
   validation loss 474.5535888671875, (212.15625, 0.27458182, 262.12277, 0.0)
decoder loss ratio: 8219.301444, decoder SINDy loss  ratio: 0.565829
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.795654296875, (256.1795, 0.25166136, 504.36453, 0.0)
   validation loss 461.141845703125, (197.4035, 0.27815327, 263.4602, 0.0)
decoder loss ratio: 7647.754430, decoder SINDy loss  ratio: 0.568716
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1013.9348754882812, (526.4379, 0.24570243, 487.25122, 0.0)
   validation loss 745.3568115234375, (482.43515, 0.2853094, 262.63638, 0.0)
decoder loss ratio: 18690.375261, decoder SINDy loss  ratio: 0.566938
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1093.384033203125, (603.9755, 0.23885107, 489.16962, 0.0)
   validation loss 798.94873046875, (534.07495, 0.2864043, 264.5874, 0.0)
decoder loss ratio: 20690.990803, decoder SINDy loss  ratio: 0.571149
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.6378173828125, (256.33472, 0.22963862, 501.07346, 0.0)
   validation loss 468.44342041015625, (204.02454, 0.28172782, 264.13718, 0.0)
decoder loss ratio: 7904.264732, decoder SINDy loss  ratio: 0.570177
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 847.150390625, (356.8238, 0.227814, 490.0988, 0.0)
   validation loss 568.7402954101562, (307.32153, 0.28568903, 261.1331, 0.0)
decoder loss ratio: 11906.169730, decoder SINDy loss  ratio: 0.563692
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 828.733642578125, (336.94806, 0.23963942, 491.5459, 0.0)
   validation loss 531.14013671875, (267.8585, 0.28139803, 263.00027, 0.0)
decoder loss ratio: 10377.302925, decoder SINDy loss  ratio: 0.567723
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 972.6025390625, (485.2141, 0.23400952, 487.15445, 0.0)
   validation loss 675.152099609375, (411.8216, 0.28838047, 263.0421, 0.0)
decoder loss ratio: 15954.683515, decoder SINDy loss  ratio: 0.567813
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.408203125, (245.45186, 0.2291773, 502.72717, 0.0)
   validation loss 455.455810546875, (189.84465, 0.28346875, 265.3277, 0.0)
decoder loss ratio: 7354.911336, decoder SINDy loss  ratio: 0.572747
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.1455078125, (344.42004, 0.22657834, 488.4989, 0.0)
   validation loss 550.9747314453125, (288.99838, 0.28702492, 261.68933, 0.0)
decoder loss ratio: 11196.299064, decoder SINDy loss  ratio: 0.564893
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.7247924804688, (287.73013, 0.2325092, 511.76215, 0.0)
   validation loss 493.63360595703125, (222.95424, 0.27846894, 270.40088, 0.0)
decoder loss ratio: 8637.634280, decoder SINDy loss  ratio: 0.583698
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.919189453125, (366.44876, 0.23474562, 486.23566, 0.0)
   validation loss 571.0205078125, (308.44012, 0.29089087, 262.28952, 0.0)
decoder loss ratio: 11949.505899, decoder SINDy loss  ratio: 0.566189
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.2633666992188, (241.44167, 0.22827844, 508.5934, 0.0)
   validation loss 448.9901123046875, (180.5971, 0.2849539, 268.10806, 0.0)
decoder loss ratio: 6996.645453, decoder SINDy loss  ratio: 0.578749
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1065.515869140625, (583.2358, 0.22009355, 482.05994, 0.0)
   validation loss 776.2885131835938, (512.287, 0.2909354, 263.71057, 0.0)
decoder loss ratio: 19846.887258, decoder SINDy loss  ratio: 0.569256
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.005859375, (249.22708, 0.22603916, 497.55276, 0.0)
   validation loss 458.67608642578125, (193.29208, 0.28661588, 265.09738, 0.0)
decoder loss ratio: 7488.470894, decoder SINDy loss  ratio: 0.572250
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 873.981201171875, (388.71002, 0.2325375, 485.03864, 0.0)
   validation loss 567.0894775390625, (304.35724, 0.28874066, 262.4435, 0.0)
decoder loss ratio: 11791.327817, decoder SINDy loss  ratio: 0.566521
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.8292846679688, (249.91185, 0.23115268, 512.6863, 0.0)
   validation loss 454.6100158691406, (184.82393, 0.2862156, 269.49988, 0.0)
decoder loss ratio: 7160.399871, decoder SINDy loss  ratio: 0.581753
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 824.7335205078125, (339.64984, 0.22276846, 484.86087, 0.0)
   validation loss 543.6923828125, (280.94278, 0.28798252, 262.46158, 0.0)
decoder loss ratio: 10884.211018, decoder SINDy loss  ratio: 0.566560
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.3987426757812, (247.08203, 0.22472186, 507.092, 0.0)
   validation loss 462.8253173828125, (193.50139, 0.28161934, 269.0423, 0.0)
decoder loss ratio: 7496.579726, decoder SINDy loss  ratio: 0.580766
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1042.3583984375, (553.2578, 0.23533666, 488.8653, 0.0)
   validation loss 695.9193115234375, (430.8912, 0.28679937, 264.74133, 0.0)
decoder loss ratio: 16693.473335, decoder SINDy loss  ratio: 0.571481
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1084.4942626953125, (506.21432, 0.24621609, 578.0337, 0.0)
   validation loss 682.05908203125, (388.99805, 0.28415677, 292.7769, 0.0)
decoder loss ratio: 15070.459666, decoder SINDy loss  ratio: 0.632000
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1025.286376953125, (544.0231, 0.22108251, 481.04227, 0.0)
   validation loss 718.2281494140625, (453.819, 0.2912002, 264.11798, 0.0)
decoder loss ratio: 17581.735934, decoder SINDy loss  ratio: 0.570136
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.0719604492188, (245.88193, 0.2193436, 492.9707, 0.0)
   validation loss 455.36669921875, (189.84792, 0.28532037, 265.23346, 0.0)
decoder loss ratio: 7355.037843, decoder SINDy loss  ratio: 0.572544
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 885.1658935546875, (405.33032, 0.2188666, 479.61667, 0.0)
   validation loss 603.855224609375, (341.66443, 0.2902315, 261.90057, 0.0)
decoder loss ratio: 13236.673124, decoder SINDy loss  ratio: 0.565349
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.0780029296875, (239.70457, 0.22136542, 503.15204, 0.0)
   validation loss 456.65509033203125, (187.87163, 0.28295887, 268.50052, 0.0)
decoder loss ratio: 7278.473021, decoder SINDy loss  ratio: 0.579596
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1606.519287109375, (1131.3578, 0.22191411, 474.93964, 0.0)
   validation loss 1325.7896728515625, (1055.6226, 0.2989031, 269.86813, 0.0)
decoder loss ratio: 40896.650561, decoder SINDy loss  ratio: 0.582548
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.7116088867188, (254.92828, 0.2308559, 512.5525, 0.0)
   validation loss 456.7706604003906, (186.02145, 0.28536782, 270.46384, 0.0)
decoder loss ratio: 7206.794070, decoder SINDy loss  ratio: 0.583834
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 955.9868774414062, (479.59354, 0.21683739, 476.1765, 0.0)
   validation loss 667.7750244140625, (405.6004, 0.28894818, 261.88568, 0.0)
decoder loss ratio: 15713.663759, decoder SINDy loss  ratio: 0.565317
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.16552734375, (304.74222, 0.21288608, 482.21045, 0.0)
   validation loss 503.0029296875, (240.00192, 0.28006205, 262.72095, 0.0)
decoder loss ratio: 9298.091143, decoder SINDy loss  ratio: 0.567120
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 961.057373046875, (481.5863, 0.21236353, 479.2587, 0.0)
   validation loss 654.5432739257812, (390.68292, 0.2827847, 263.57758, 0.0)
decoder loss ratio: 15135.734668, decoder SINDy loss  ratio: 0.568969
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.9097900390625, (360.68237, 0.21019575, 481.01718, 0.0)
   validation loss 552.997314453125, (289.15442, 0.28042677, 263.56247, 0.0)
decoder loss ratio: 11202.344184, decoder SINDy loss  ratio: 0.568937
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 870.1707763671875, (390.46725, 0.21612248, 479.4874, 0.0)
   validation loss 584.9122924804688, (322.05093, 0.28406036, 262.5773, 0.0)
decoder loss ratio: 12476.812282, decoder SINDy loss  ratio: 0.566810
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1239.9061279296875, (766.5811, 0.21681699, 473.10822, 0.0)
   validation loss 951.69091796875, (686.5287, 0.28908613, 264.8732, 0.0)
decoder loss ratio: 26597.313182, decoder SINDy loss  ratio: 0.571766
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.2390747070312, (250.7866, 0.22363836, 489.22882, 0.0)
   validation loss 448.6612243652344, (183.13033, 0.28049862, 265.2504, 0.0)
decoder loss ratio: 7094.786731, decoder SINDy loss  ratio: 0.572580
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.8477783203125, (259.9698, 0.21995576, 496.65802, 0.0)
   validation loss 464.0266418457031, (197.08978, 0.2818566, 266.655, 0.0)
decoder loss ratio: 7635.600345, decoder SINDy loss  ratio: 0.575612
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.4400634765625, (467.49094, 0.21038769, 474.73877, 0.0)
   validation loss 648.50390625, (385.50906, 0.28406346, 262.71075, 0.0)
decoder loss ratio: 14935.290402, decoder SINDy loss  ratio: 0.567098
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.261962890625, (241.18149, 0.21498345, 488.8655, 0.0)
   validation loss 449.3084411621094, (183.64563, 0.27880606, 265.384, 0.0)
decoder loss ratio: 7114.750524, decoder SINDy loss  ratio: 0.572869
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1128.242431640625, (651.2201, 0.20816189, 476.81415, 0.0)
   validation loss 807.8648681640625, (541.96906, 0.28376406, 265.61206, 0.0)
decoder loss ratio: 20996.822097, decoder SINDy loss  ratio: 0.573361
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.356689453125, (259.8461, 0.21756804, 510.29306, 0.0)
   validation loss 471.48486328125, (198.19853, 0.2753583, 273.01096, 0.0)
decoder loss ratio: 7678.555222, decoder SINDy loss  ratio: 0.589333
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1020.1314697265625, (545.9739, 0.20812255, 473.94946, 0.0)
   validation loss 718.5738525390625, (454.57492, 0.28253517, 263.71637, 0.0)
decoder loss ratio: 17611.021603, decoder SINDy loss  ratio: 0.569269
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.9119262695312, (233.65437, 0.21242572, 496.04514, 0.0)
   validation loss 444.61138916015625, (175.9912, 0.27422443, 268.34595, 0.0)
decoder loss ratio: 6818.204455, decoder SINDy loss  ratio: 0.579262
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 874.0977783203125, (399.47598, 0.2107552, 474.41107, 0.0)
   validation loss 591.3333740234375, (329.02985, 0.2808271, 262.02267, 0.0)
decoder loss ratio: 12747.187462, decoder SINDy loss  ratio: 0.565613
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 919.2750244140625, (387.1779, 0.22334138, 531.8738, 0.0)
   validation loss 607.8292236328125, (325.91107, 0.2693241, 281.64886, 0.0)
decoder loss ratio: 12626.360727, decoder SINDy loss  ratio: 0.607979
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1019.7025146484375, (543.18933, 0.20916572, 476.304, 0.0)
   validation loss 704.9761962890625, (440.43158, 0.27797356, 264.2666, 0.0)
decoder loss ratio: 17063.084016, decoder SINDy loss  ratio: 0.570457
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.5623779296875, (284.67303, 0.2130659, 518.6763, 0.0)
   validation loss 491.91748046875, (215.49721, 0.26918802, 276.1511, 0.0)
decoder loss ratio: 8348.735944, decoder SINDy loss  ratio: 0.596111
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1089.4517822265625, (601.7884, 0.20267743, 487.4607, 0.0)
   validation loss 712.2109985351562, (443.30756, 0.27364725, 268.6298, 0.0)
decoder loss ratio: 17174.504341, decoder SINDy loss  ratio: 0.579875
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.3414306640625, (248.78052, 0.20264502, 488.35828, 0.0)
   validation loss 452.408935546875, (185.67517, 0.26865646, 266.46512, 0.0)
decoder loss ratio: 7193.378467, decoder SINDy loss  ratio: 0.575202
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1005.1876220703125, (523.9678, 0.20660287, 481.01324, 0.0)
   validation loss 663.3990478515625, (397.01773, 0.27373734, 266.10754, 0.0)
decoder loss ratio: 15381.156141, decoder SINDy loss  ratio: 0.574431
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 816.6180419921875, (294.2316, 0.21735717, 522.16907, 0.0)
   validation loss 500.769287109375, (222.59431, 0.26843745, 277.90652, 0.0)
decoder loss ratio: 8623.690187, decoder SINDy loss  ratio: 0.599900
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1017.592529296875, (546.6872, 0.2116886, 470.69366, 0.0)
   validation loss 724.4725341796875, (462.44052, 0.27649137, 261.75552, 0.0)
decoder loss ratio: 17915.748625, decoder SINDy loss  ratio: 0.565036
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.209228515625, (333.54474, 0.26107568, 533.4034, 0.0)
   validation loss 558.5299072265625, (278.13177, 0.27916, 280.11893, 0.0)
decoder loss ratio: 10775.307818, decoder SINDy loss  ratio: 0.604676
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.9470825195312, (246.70537, 0.2580695, 500.98364, 0.0)
   validation loss 453.4825744628906, (185.62453, 0.28299978, 267.57504, 0.0)
decoder loss ratio: 7191.416433, decoder SINDy loss  ratio: 0.577598
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.87548828125, (347.1245, 0.23356178, 483.5174, 0.0)
   validation loss 535.521484375, (274.04703, 0.27570018, 261.1988, 0.0)
decoder loss ratio: 10617.057615, decoder SINDy loss  ratio: 0.563834
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.6854248046875, (254.92766, 0.22754237, 508.53024, 0.0)
   validation loss 468.0362854003906, (197.5259, 0.26876065, 270.24164, 0.0)
decoder loss ratio: 7652.496060, decoder SINDy loss  ratio: 0.583355
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.7927856445312, (328.56186, 0.21587294, 476.01505, 0.0)
   validation loss 504.84429931640625, (244.13603, 0.2681156, 260.44016, 0.0)
decoder loss ratio: 9458.253723, decoder SINDy loss  ratio: 0.562197
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1643.264892578125, (1024.6754, 0.24691981, 618.3425, 0.0)
   validation loss 1255.02099609375, (940.99805, 0.25959834, 313.76343, 0.0)
decoder loss ratio: 36455.897980, decoder SINDy loss  ratio: 0.677302
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 955.5577392578125, (483.0242, 0.21041782, 472.3231, 0.0)
   validation loss 633.725830078125, (373.36594, 0.2690367, 260.09085, 0.0)
decoder loss ratio: 14464.844563, decoder SINDy loss  ratio: 0.561443
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.357421875, (230.24211, 0.21528545, 492.90005, 0.0)
   validation loss 436.4925231933594, (171.49773, 0.2656735, 264.72913, 0.0)
decoder loss ratio: 6644.119655, decoder SINDy loss  ratio: 0.571455
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.9261474609375, (231.28957, 0.23184101, 500.40475, 0.0)
   validation loss 454.246337890625, (186.85957, 0.2702405, 267.11652, 0.0)
decoder loss ratio: 7239.264275, decoder SINDy loss  ratio: 0.576609
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 929.315673828125, (408.79416, 0.21137083, 520.3101, 0.0)
   validation loss 659.5440673828125, (380.73062, 0.25816464, 278.5553, 0.0)
decoder loss ratio: 14750.165248, decoder SINDy loss  ratio: 0.601301
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.1128540039062, (382.32797, 0.21220878, 474.57266, 0.0)
   validation loss 542.23388671875, (281.94952, 0.26644725, 260.01794, 0.0)
decoder loss ratio: 10923.214043, decoder SINDy loss  ratio: 0.561285
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.0720825195312, (249.5944, 0.2127622, 506.26492, 0.0)
   validation loss 463.1854248046875, (193.37448, 0.2618513, 269.54907, 0.0)
decoder loss ratio: 7491.663115, decoder SINDy loss  ratio: 0.581860
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.9171142578125, (306.64856, 0.20659511, 476.06195, 0.0)
   validation loss 492.08258056640625, (232.03702, 0.2663458, 259.7792, 0.0)
decoder loss ratio: 8989.516904, decoder SINDy loss  ratio: 0.560770
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 985.9010620117188, (431.11414, 0.23601769, 554.5509, 0.0)
   validation loss 652.9779663085938, (366.13107, 0.2618704, 286.58502, 0.0)
decoder loss ratio: 14184.553399, decoder SINDy loss  ratio: 0.618634
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 916.7359619140625, (432.54196, 0.21058534, 483.9834, 0.0)
   validation loss 540.7005615234375, (277.67938, 0.2609288, 262.76025, 0.0)
decoder loss ratio: 10757.781344, decoder SINDy loss  ratio: 0.567205
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.0838623046875, (247.41438, 0.20865463, 502.46085, 0.0)
   validation loss 450.615478515625, (183.03293, 0.26037797, 267.32217, 0.0)
decoder loss ratio: 7091.013408, decoder SINDy loss  ratio: 0.577053
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.805908203125, (237.47316, 0.20843813, 493.12433, 0.0)
   validation loss 441.79241943359375, (176.46568, 0.26117665, 265.06555, 0.0)
decoder loss ratio: 6836.586917, decoder SINDy loss  ratio: 0.572181
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.1820068359375, (248.04369, 0.21152063, 481.92682, 0.0)
   validation loss 449.2569274902344, (187.04814, 0.26142132, 261.94736, 0.0)
decoder loss ratio: 7246.569731, decoder SINDy loss  ratio: 0.565450
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.4462890625, (374.4387, 0.20748328, 474.80014, 0.0)
   validation loss 559.4959716796875, (298.97354, 0.26820776, 260.25418, 0.0)
decoder loss ratio: 11582.754029, decoder SINDy loss  ratio: 0.561795
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1263.66650390625, (690.9284, 0.22239698, 572.51575, 0.0)
   validation loss 936.336669921875, (638.6091, 0.25548342, 297.47208, 0.0)
decoder loss ratio: 24740.824039, decoder SINDy loss  ratio: 0.642135
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.6573486328125, (328.2324, 0.2126488, 478.21228, 0.0)
   validation loss 492.69586181640625, (231.01254, 0.26305997, 261.42026, 0.0)
decoder loss ratio: 8949.826961, decoder SINDy loss  ratio: 0.564312
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.8081665039062, (358.86014, 0.21499299, 541.73303, 0.0)
   validation loss 561.0980834960938, (279.0417, 0.26051012, 281.7959, 0.0)
decoder loss ratio: 10810.559393, decoder SINDy loss  ratio: 0.608296
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 937.1114501953125, (468.1949, 0.19763252, 468.71896, 0.0)
   validation loss 626.3995361328125, (365.76318, 0.26463145, 260.37173, 0.0)
decoder loss ratio: 14170.300725, decoder SINDy loss  ratio: 0.562049
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.7232666015625, (302.2972, 0.18974555, 472.23633, 0.0)
   validation loss 483.89013671875, (223.07748, 0.2598046, 260.55283, 0.0)
decoder loss ratio: 8642.409015, decoder SINDy loss  ratio: 0.562440
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.0101318359375, (313.00433, 0.20155819, 474.80426, 0.0)
   validation loss 502.460693359375, (241.20691, 0.26316556, 260.99063, 0.0)
decoder loss ratio: 9344.774415, decoder SINDy loss  ratio: 0.563385
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.1151123046875, (250.81897, 0.21411026, 499.08203, 0.0)
   validation loss 474.964599609375, (204.92882, 0.25939104, 269.7764, 0.0)
decoder loss ratio: 7939.298172, decoder SINDy loss  ratio: 0.582350
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1110.570556640625, (644.2792, 0.1989197, 466.0924, 0.0)
   validation loss 795.4281005859375, (533.2435, 0.26758558, 261.91696, 0.0)
decoder loss ratio: 20658.780114, decoder SINDy loss  ratio: 0.565385
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1091.852294921875, (548.0787, 0.21433203, 543.5593, 0.0)
   validation loss 796.068115234375, (506.84406, 0.25701094, 288.96704, 0.0)
decoder loss ratio: 19636.018617, decoder SINDy loss  ratio: 0.623776
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1039.8544921875, (561.27966, 0.19884463, 478.37604, 0.0)
   validation loss 670.799072265625, (406.0393, 0.26450118, 264.49527, 0.0)
decoder loss ratio: 15730.667654, decoder SINDy loss  ratio: 0.570950
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 846.20703125, (377.13693, 0.1931407, 468.87695, 0.0)
   validation loss 556.16748046875, (295.60843, 0.26045966, 260.29858, 0.0)
decoder loss ratio: 11452.383737, decoder SINDy loss  ratio: 0.561891
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.15185546875, (240.62125, 0.22062778, 494.30997, 0.0)
   validation loss 451.66656494140625, (183.00163, 0.2620266, 268.4029, 0.0)
decoder loss ratio: 7089.800955, decoder SINDy loss  ratio: 0.579385
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.4981689453125, (235.38258, 0.21022233, 481.90533, 0.0)
   validation loss 440.5986328125, (176.47571, 0.2616825, 263.86124, 0.0)
decoder loss ratio: 6836.975304, decoder SINDy loss  ratio: 0.569582
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1133.728515625, (662.3604, 0.19751279, 471.17065, 0.0)
   validation loss 787.9412231445312, (523.1473, 0.26542544, 264.5285, 0.0)
decoder loss ratio: 20267.633767, decoder SINDy loss  ratio: 0.571022
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.2869873046875, (237.66376, 0.20523432, 496.41797, 0.0)
   validation loss 451.3367919921875, (181.92047, 0.25795677, 269.15836, 0.0)
decoder loss ratio: 7047.914882, decoder SINDy loss  ratio: 0.581016
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 953.705322265625, (485.42477, 0.19750522, 468.083, 0.0)
   validation loss 638.260009765625, (376.18088, 0.26303357, 261.81607, 0.0)
decoder loss ratio: 14573.900280, decoder SINDy loss  ratio: 0.565167
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.4011840820312, (266.65207, 0.19510013, 473.55402, 0.0)
   validation loss 458.86602783203125, (196.45683, 0.2586957, 262.15048, 0.0)
decoder loss ratio: 7611.078770, decoder SINDy loss  ratio: 0.565889
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 927.636474609375, (461.35098, 0.19512282, 466.0904, 0.0)
   validation loss 632.0557861328125, (370.25153, 0.26176935, 261.54245, 0.0)
decoder loss ratio: 14344.186897, decoder SINDy loss  ratio: 0.564576
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.39208984375, (352.87326, 0.19931024, 468.3195, 0.0)
   validation loss 539.5654296875, (277.94583, 0.25974128, 261.3599, 0.0)
decoder loss ratio: 10768.104040, decoder SINDy loss  ratio: 0.564182
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1056.9208984375, (593.6755, 0.19847418, 463.04688, 0.0)
   validation loss 752.9428100585938, (491.1215, 0.26532236, 261.556, 0.0)
decoder loss ratio: 19026.899166, decoder SINDy loss  ratio: 0.564605
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 936.51904296875, (414.99377, 0.2133375, 521.31195, 0.0)
   validation loss 658.7705688476562, (377.25934, 0.25508627, 281.25613, 0.0)
decoder loss ratio: 14615.681720, decoder SINDy loss  ratio: 0.607131
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1295.77490234375, (810.9, 0.19877227, 484.67615, 0.0)
   validation loss 878.367431640625, (607.3996, 0.2625807, 270.70526, 0.0)
decoder loss ratio: 23531.714886, decoder SINDy loss  ratio: 0.584355
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.8916625976562, (272.01694, 0.20479192, 479.66992, 0.0)
   validation loss 469.0167236328125, (205.54976, 0.25949, 263.2075, 0.0)
decoder loss ratio: 7963.354510, decoder SINDy loss  ratio: 0.568170
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 946.0171508789062, (479.26086, 0.20088674, 466.5554, 0.0)
   validation loss 638.58349609375, (376.616, 0.26098228, 261.70648, 0.0)
decoder loss ratio: 14590.757570, decoder SINDy loss  ratio: 0.564930
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.5950317382812, (229.8199, 0.20726877, 491.56784, 0.0)
   validation loss 446.6623229980469, (178.32788, 0.25455135, 268.0799, 0.0)
decoder loss ratio: 6908.731695, decoder SINDy loss  ratio: 0.578688
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 910.233154296875, (443.42535, 0.20248239, 466.60532, 0.0)
   validation loss 609.98046875, (348.4843, 0.2595554, 261.23657, 0.0)
decoder loss ratio: 13500.887318, decoder SINDy loss  ratio: 0.563916
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.9556884765625, (271.9749, 0.21186447, 503.76895, 0.0)
   validation loss 501.2222900390625, (228.16243, 0.25182986, 272.808, 0.0)
decoder loss ratio: 8839.408638, decoder SINDy loss  ratio: 0.588894
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1016.8289794921875, (542.82446, 0.19322625, 473.81125, 0.0)
   validation loss 660.7119140625, (395.55597, 0.25663546, 264.89932, 0.0)
decoder loss ratio: 15324.524964, decoder SINDy loss  ratio: 0.571822
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.377685546875, (267.57602, 0.19247226, 474.60922, 0.0)
   validation loss 459.1183776855469, (196.32532, 0.2528413, 262.54022, 0.0)
decoder loss ratio: 7605.983631, decoder SINDy loss  ratio: 0.566730
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.2654418945312, (235.22783, 0.21893668, 490.81866, 0.0)
   validation loss 442.98419189453125, (175.64261, 0.25594553, 267.08563, 0.0)
decoder loss ratio: 6804.699588, decoder SINDy loss  ratio: 0.576542
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.5272827148438, (233.56558, 0.21031137, 479.7514, 0.0)
   validation loss 440.601318359375, (176.69177, 0.25370228, 263.65582, 0.0)
decoder loss ratio: 6845.346016, decoder SINDy loss  ratio: 0.569138
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1162.3714599609375, (691.5022, 0.1975315, 470.67178, 0.0)
   validation loss 808.5517578125, (542.86304, 0.25757852, 265.43115, 0.0)
decoder loss ratio: 21031.456509, decoder SINDy loss  ratio: 0.572970
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.86083984375, (250.24008, 0.20570856, 497.41507, 0.0)
   validation loss 468.8819885253906, (198.60924, 0.24937724, 270.02338, 0.0)
decoder loss ratio: 7694.466668, decoder SINDy loss  ratio: 0.582883
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 918.2733764648438, (449.47327, 0.19776933, 468.60233, 0.0)
   validation loss 597.290771484375, (334.8667, 0.2537417, 262.1703, 0.0)
decoder loss ratio: 12973.317282, decoder SINDy loss  ratio: 0.565931
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.2991333007812, (279.32043, 0.19318067, 470.78552, 0.0)
   validation loss 468.4775695800781, (206.54025, 0.25054386, 261.68677, 0.0)
decoder loss ratio: 8001.727959, decoder SINDy loss  ratio: 0.564888
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.8694458007812, (359.10132, 0.20050475, 468.56763, 0.0)
   validation loss 542.2459106445312, (280.29636, 0.2533872, 261.69617, 0.0)
decoder loss ratio: 10859.167455, decoder SINDy loss  ratio: 0.564908
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.105712890625, (228.35406, 0.2132301, 484.5384, 0.0)
   validation loss 442.8167724609375, (177.4573, 0.249466, 265.11002, 0.0)
decoder loss ratio: 6875.004110, decoder SINDy loss  ratio: 0.572277
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1008.861572265625, (546.2004, 0.20195073, 462.4592, 0.0)
   validation loss 711.6161499023438, (450.19574, 0.25666738, 261.16376, 0.0)
decoder loss ratio: 17441.364532, decoder SINDy loss  ratio: 0.563759
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 845.626953125, (322.1642, 0.21363756, 523.2491, 0.0)
   validation loss 539.8392944335938, (261.37125, 0.24764346, 278.2204, 0.0)
decoder loss ratio: 10125.975844, decoder SINDy loss  ratio: 0.600578
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 867.534423828125, (399.87964, 0.20340116, 467.4514, 0.0)
   validation loss 563.59130859375, (302.66138, 0.25146154, 260.67847, 0.0)
decoder loss ratio: 11725.627186, decoder SINDy loss  ratio: 0.562711
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1352.09130859375, (759.04486, 0.26233736, 592.78406, 0.0)
   validation loss 1006.8516845703125, (699.21265, 0.25488764, 307.38412, 0.0)
decoder loss ratio: 27088.711811, decoder SINDy loss  ratio: 0.663532
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.1875, (232.6533, 0.24542317, 490.2888, 0.0)
   validation loss 443.62017822265625, (178.6328, 0.2578934, 264.7295, 0.0)
decoder loss ratio: 6920.544685, decoder SINDy loss  ratio: 0.571456
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.1492919921875, (266.37012, 0.23189774, 506.54727, 0.0)
   validation loss 488.2978820800781, (216.99683, 0.25022078, 271.05084, 0.0)
decoder loss ratio: 8406.833769, decoder SINDy loss  ratio: 0.585101
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.298828125, (229.42963, 0.23757428, 495.63165, 0.0)
   validation loss 446.1077880859375, (179.27605, 0.2525237, 266.57922, 0.0)
decoder loss ratio: 6945.465288, decoder SINDy loss  ratio: 0.575449
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.6199340820312, (231.32143, 0.22632594, 483.07217, 0.0)
   validation loss 436.67095947265625, (174.46574, 0.24557236, 261.95966, 0.0)
decoder loss ratio: 6759.105809, decoder SINDy loss  ratio: 0.565477
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 963.29248046875, (499.36377, 0.21222353, 463.71646, 0.0)
   validation loss 653.5244140625, (395.0012, 0.2485548, 258.27463, 0.0)
decoder loss ratio: 15303.031860, decoder SINDy loss  ratio: 0.557522
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 886.3331298828125, (361.66492, 0.21354516, 524.45465, 0.0)
   validation loss 598.4246826171875, (320.31802, 0.23927934, 277.86737, 0.0)
decoder loss ratio: 12409.676334, decoder SINDy loss  ratio: 0.599816
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.0979614257812, (330.31732, 0.20212919, 469.57852, 0.0)
   validation loss 508.47186279296875, (249.06252, 0.24599478, 259.16333, 0.0)
decoder loss ratio: 9649.114233, decoder SINDy loss  ratio: 0.559441
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.2493896484375, (291.26447, 0.2163644, 511.7686, 0.0)
   validation loss 525.0100708007812, (251.4882, 0.24028105, 273.2816, 0.0)
decoder loss ratio: 9743.089663, decoder SINDy loss  ratio: 0.589917
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 885.5892333984375, (413.75797, 0.20010996, 471.63113, 0.0)
   validation loss 538.5570068359375, (277.78082, 0.24434668, 260.53183, 0.0)
decoder loss ratio: 10761.711322, decoder SINDy loss  ratio: 0.562395
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.1993408203125, (294.40845, 0.18842582, 468.60248, 0.0)
   validation loss 473.19744873046875, (213.8807, 0.24287045, 259.07385, 0.0)
decoder loss ratio: 8286.109894, decoder SINDy loss  ratio: 0.559247
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1043.371337890625, (580.79205, 0.20117794, 462.37808, 0.0)
   validation loss 721.114013671875, (460.77994, 0.24958496, 260.0845, 0.0)
decoder loss ratio: 17851.414737, decoder SINDy loss  ratio: 0.561429
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 865.7784423828125, (349.94647, 0.20719352, 515.6248, 0.0)
   validation loss 588.6768798828125, (312.26932, 0.24015415, 276.1674, 0.0)
decoder loss ratio: 12097.855488, decoder SINDy loss  ratio: 0.596146
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.5435791015625, (316.86707, 0.20658381, 470.4699, 0.0)
   validation loss 498.910400390625, (238.78883, 0.2471693, 259.8744, 0.0)
decoder loss ratio: 9251.093970, decoder SINDy loss  ratio: 0.560975
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.015380859375, (243.44301, 0.21504878, 499.35733, 0.0)
   validation loss 466.3048095703125, (196.90767, 0.2430039, 269.15414, 0.0)
decoder loss ratio: 7628.544946, decoder SINDy loss  ratio: 0.581007
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1027.5738525390625, (555.73224, 0.19353731, 471.64807, 0.0)
   validation loss 653.8426513671875, (390.91678, 0.24521525, 262.68066, 0.0)
decoder loss ratio: 15144.794663, decoder SINDy loss  ratio: 0.567033
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 840.9151000976562, (377.512, 0.18911876, 463.214, 0.0)
   validation loss 545.3826904296875, (286.10287, 0.24560915, 259.0342, 0.0)
decoder loss ratio: 11084.122064, decoder SINDy loss  ratio: 0.559162
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.9796142578125, (365.1687, 0.20810659, 465.60284, 0.0)
   validation loss 540.595947265625, (281.28745, 0.24766806, 259.06085, 0.0)
decoder loss ratio: 10897.563958, decoder SINDy loss  ratio: 0.559219
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.5169677734375, (253.1144, 0.193544, 476.209, 0.0)
   validation loss 445.22174072265625, (183.47574, 0.24464972, 261.50137, 0.0)
decoder loss ratio: 7108.168638, decoder SINDy loss  ratio: 0.564487
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.7454223632812, (252.91043, 0.21268578, 482.62228, 0.0)
   validation loss 451.59002685546875, (188.0097, 0.2474576, 263.3329, 0.0)
decoder loss ratio: 7283.822355, decoder SINDy loss  ratio: 0.568441
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 865.719482421875, (348.427, 0.22219299, 517.0703, 0.0)
   validation loss 590.099365234375, (312.64142, 0.24203227, 277.21588, 0.0)
decoder loss ratio: 12112.271320, decoder SINDy loss  ratio: 0.598409
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 957.3671875, (487.15347, 0.19557482, 470.0181, 0.0)
   validation loss 601.0769653320312, (338.5867, 0.24578369, 262.24448, 0.0)
decoder loss ratio: 13117.436587, decoder SINDy loss  ratio: 0.566092
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.9716186523438, (283.2681, 0.19555175, 468.50797, 0.0)
   validation loss 468.568115234375, (208.38138, 0.24446072, 259.94226, 0.0)
decoder loss ratio: 8073.056356, decoder SINDy loss  ratio: 0.561122
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1260.115234375, (788.2427, 0.19323403, 471.67938, 0.0)
   validation loss 872.885986328125, (605.5892, 0.2482057, 267.04858, 0.0)
decoder loss ratio: 23461.575886, decoder SINDy loss  ratio: 0.576462
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.0404663085938, (248.17458, 0.19712864, 475.66876, 0.0)
   validation loss 442.48004150390625, (180.75085, 0.24369977, 261.4855, 0.0)
decoder loss ratio: 7002.601900, decoder SINDy loss  ratio: 0.564453
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1224.9078369140625, (760.866, 0.19715773, 463.84464, 0.0)
   validation loss 879.5244750976562, (614.7158, 0.24981977, 264.55884, 0.0)
decoder loss ratio: 23815.158073, decoder SINDy loss  ratio: 0.571087
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 935.73046875, (410.313, 0.2139867, 525.2035, 0.0)
   validation loss 649.6753540039062, (368.77823, 0.23981191, 280.65732, 0.0)
decoder loss ratio: 14287.108809, decoder SINDy loss  ratio: 0.605838
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.6380615234375, (293.12885, 0.21245693, 471.29672, 0.0)
   validation loss 480.058837890625, (219.26352, 0.24647626, 260.54883, 0.0)
decoder loss ratio: 8494.649395, decoder SINDy loss  ratio: 0.562431
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 825.1832275390625, (317.64978, 0.2136631, 507.31982, 0.0)
   validation loss 554.5363159179688, (280.07034, 0.24005763, 274.22592, 0.0)
decoder loss ratio: 10850.411312, decoder SINDy loss  ratio: 0.591955
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.136474609375, (273.1349, 0.21493429, 474.78668, 0.0)
   validation loss 467.20947265625, (205.0774, 0.24634917, 261.8857, 0.0)
decoder loss ratio: 7945.054218, decoder SINDy loss  ratio: 0.565317
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.2745361328125, (384.73297, 0.21535444, 517.3262, 0.0)
   validation loss 627.0587768554688, (348.46997, 0.23978095, 278.34903, 0.0)
decoder loss ratio: 13500.331636, decoder SINDy loss  ratio: 0.600856
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.058837890625, (364.54477, 0.20785122, 465.3062, 0.0)
   validation loss 541.5344848632812, (281.27158, 0.24634834, 260.01657, 0.0)
decoder loss ratio: 10896.949160, decoder SINDy loss  ratio: 0.561282
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 888.470458984375, (372.92526, 0.22002444, 515.3252, 0.0)
   validation loss 617.1546630859375, (339.4826, 0.2400714, 277.43195, 0.0)
decoder loss ratio: 13152.145485, decoder SINDy loss  ratio: 0.598876
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.972412109375, (317.8558, 0.21446948, 467.90216, 0.0)
   validation loss 498.9474182128906, (238.43103, 0.246461, 260.26993, 0.0)
decoder loss ratio: 9237.232047, decoder SINDy loss  ratio: 0.561829
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.126953125, (233.41125, 0.20860808, 492.50708, 0.0)
   validation loss 450.4765625, (182.24149, 0.24019414, 267.99487, 0.0)
decoder loss ratio: 7060.351537, decoder SINDy loss  ratio: 0.578505
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.4407958984375, (370.89868, 0.20736887, 468.33472, 0.0)
   validation loss 522.166748046875, (260.81088, 0.24486901, 261.11096, 0.0)
decoder loss ratio: 10104.266378, decoder SINDy loss  ratio: 0.563645
params['save_name']
pendulum_2023_11_11_07_52_23_517135
