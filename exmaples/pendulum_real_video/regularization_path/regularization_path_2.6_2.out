nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-11-11 19:27:07.864463: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-11-11 19:27:07.871897: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-11-11 19:27:07.873737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556601a05d30 executing computations on platform Host. Devices:
2023-11-11 19:27:07.873768: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-11-11 19:27:07.875660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-11-11 19:27:08.009431: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556601b79480 executing computations on platform CUDA. Devices:
2023-11-11 19:27:08.009499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-11-11 19:27:08.010570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:19:00.0
2023-11-11 19:27:08.011173: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-11 19:27:08.015847: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-11-11 19:27:08.019602: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-11-11 19:27:08.020354: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-11-11 19:27:08.024976: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-11-11 19:27:08.027207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-11-11 19:27:08.033510: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-11-11 19:27:08.034482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-11-11 19:27:08.034542: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-11 19:27:08.034977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-11-11 19:27:08.034990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-11-11 19:27:08.034998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-11-11 19:27:08.035721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:19:00.0, compute capability: 7.5)
2023-11-11 19:27:09.259235: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 2.6, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.9050168991088867 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 109783.8359375, (103751.336, 0.0038000373, 6015.4414, 2.5317802)
   validation loss 82435.8359375, (81218.02, 0.0035070148, 1200.7563, 2.5317802)
decoder loss ratio: 3146527.228658, decoder SINDy loss  ratio: 2.592001
--- 0.2706012725830078 seconds for one epoch ---
--- 0.31041574478149414 seconds for one epoch ---
--- 0.32642436027526855 seconds for one epoch ---
--- 0.29810523986816406 seconds for one epoch ---
--- 0.3189969062805176 seconds for one epoch ---
--- 0.29167771339416504 seconds for one epoch ---
--- 0.3179049491882324 seconds for one epoch ---
--- 0.2920036315917969 seconds for one epoch ---
--- 0.3201925754547119 seconds for one epoch ---
--- 0.28108739852905273 seconds for one epoch ---
--- 0.3267080783843994 seconds for one epoch ---
--- 0.3017873764038086 seconds for one epoch ---
--- 0.34203100204467773 seconds for one epoch ---
--- 0.3094193935394287 seconds for one epoch ---
--- 0.3362703323364258 seconds for one epoch ---
--- 0.30691003799438477 seconds for one epoch ---
--- 0.3339550495147705 seconds for one epoch ---
--- 0.18896484375 seconds for one epoch ---
--- 0.3301050662994385 seconds for one epoch ---
--- 0.3012211322784424 seconds for one epoch ---
--- 0.32384824752807617 seconds for one epoch ---
--- 0.3076467514038086 seconds for one epoch ---
--- 0.31580233573913574 seconds for one epoch ---
--- 0.3122706413269043 seconds for one epoch ---
=========================
[[0.7824068 ]
 [0.7825459 ]
 [0.7826743 ]
 [0.7831869 ]
 [0.78046983]
 [0.7828155 ]
 [0.78350884]
 [0.78048646]
 [0.7803906 ]
 [0.78743625]
 [0.7815523 ]]
[[ 0.56376755]
 [ 0.5998504 ]
 [-0.63290566]
 [-0.76259303]
 [-0.02837173]
 [-0.66892827]
 [ 0.8422826 ]
 [-0.03328764]
 [ 0.00485227]
 [-1.7315993 ]
 [ 0.33580095]]
--- 0.2564859390258789 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 64884.953125, (54922.31, 62.272522, 9865.79, 2.531743)
   validation loss 44644.41796875, (43384.43, 7.6307826, 1217.779, 2.531743)
decoder loss ratio: 1680788.124776, decoder SINDy loss  ratio: 2.628747
--- 0.3084883689880371 seconds for one epoch ---
--- 0.3339219093322754 seconds for one epoch ---
--- 0.3058662414550781 seconds for one epoch ---
--- 0.33277463912963867 seconds for one epoch ---
--- 0.3070554733276367 seconds for one epoch ---
--- 0.32204127311706543 seconds for one epoch ---
--- 0.2966792583465576 seconds for one epoch ---
--- 0.3268465995788574 seconds for one epoch ---
--- 0.30713939666748047 seconds for one epoch ---
--- 0.32158493995666504 seconds for one epoch ---
--- 0.30631399154663086 seconds for one epoch ---
--- 0.3231182098388672 seconds for one epoch ---
--- 0.3022747039794922 seconds for one epoch ---
--- 0.3329613208770752 seconds for one epoch ---
--- 0.30211520195007324 seconds for one epoch ---
--- 0.33155155181884766 seconds for one epoch ---
--- 0.3096804618835449 seconds for one epoch ---
--- 0.3415834903717041 seconds for one epoch ---
--- 0.30267763137817383 seconds for one epoch ---
--- 0.3351399898529053 seconds for one epoch ---
--- 0.2966310977935791 seconds for one epoch ---
--- 0.34432172775268555 seconds for one epoch ---
--- 0.30301690101623535 seconds for one epoch ---
--- 0.34157633781433105 seconds for one epoch ---
=========================
[[0.6309252 ]
 [0.62670964]
 [0.6271926 ]
 [0.6282019 ]
 [0.6242876 ]
 [0.6317467 ]
 [0.62836266]
 [0.624949  ]
 [0.6243017 ]
 [0.62939984]
 [0.6263732 ]]
[[ 1.0260912 ]
 [ 0.40483573]
 [-0.48030433]
 [-0.63406575]
 [-0.00504936]
 [-1.1387739 ]
 [ 0.65811557]
 [ 0.11805954]
 [ 0.00752664]
 [-0.8103484 ]
 [ 0.3515011 ]]
--- 0.29456520080566406 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 51591.5, (40787.4, 47.59454, 10705.748, 2.5317254)
   validation loss 37791.9921875, (36547.38, 8.649095, 1185.2052, 2.5317254)
decoder loss ratio: 1415908.907868, decoder SINDy loss  ratio: 2.558432
--- 0.14835143089294434 seconds for one epoch ---
--- 0.29332613945007324 seconds for one epoch ---
--- 0.3498208522796631 seconds for one epoch ---
--- 0.29497361183166504 seconds for one epoch ---
--- 0.3383016586303711 seconds for one epoch ---
--- 0.3050537109375 seconds for one epoch ---
--- 0.34144043922424316 seconds for one epoch ---
--- 0.31970763206481934 seconds for one epoch ---
--- 0.34442949295043945 seconds for one epoch ---
--- 0.3102433681488037 seconds for one epoch ---
--- 0.3401477336883545 seconds for one epoch ---
--- 0.2960987091064453 seconds for one epoch ---
--- 0.3330512046813965 seconds for one epoch ---
--- 0.30488038063049316 seconds for one epoch ---
--- 0.3351867198944092 seconds for one epoch ---
--- 0.37457704544067383 seconds for one epoch ---
--- 0.33100152015686035 seconds for one epoch ---
--- 0.31029725074768066 seconds for one epoch ---
--- 0.34775686264038086 seconds for one epoch ---
--- 0.30764245986938477 seconds for one epoch ---
--- 0.3486826419830322 seconds for one epoch ---
--- 0.3115067481994629 seconds for one epoch ---
--- 0.3473646640777588 seconds for one epoch ---
--- 0.3067045211791992 seconds for one epoch ---
=========================
[[0.50416017]
 [0.49531096]
 [0.4956989 ]
 [0.49826404]
 [0.49399945]
 [0.5085532 ]
 [0.4972415 ]
 [0.49503085]
 [0.49351415]
 [0.49488333]
 [0.49574956]]
[[ 1.195967  ]
 [ 0.22730988]
 [-0.27427903]
 [-0.57288367]
 [-0.06437816]
 [-1.6182698 ]
 [ 0.4562228 ]
 [ 0.19302796]
 [ 0.00247266]
 [-0.17484055]
 [ 0.28033724]]
--- 0.2661900520324707 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 31098.26171875, (25787.635, 12.640759, 5232.7793, 2.5317245)
   validation loss 19299.443359375, (18128.898, 1.2647332, 1104.0717, 2.5317245)
decoder loss ratio: 702344.998621, decoder SINDy loss  ratio: 2.383294
--- 0.29799532890319824 seconds for one epoch ---
--- 0.36479663848876953 seconds for one epoch ---
--- 0.31333398818969727 seconds for one epoch ---
--- 0.3510427474975586 seconds for one epoch ---
--- 0.31106066703796387 seconds for one epoch ---
--- 0.3630557060241699 seconds for one epoch ---
--- 0.3147761821746826 seconds for one epoch ---
--- 0.31164002418518066 seconds for one epoch ---
--- 0.23134732246398926 seconds for one epoch ---
--- 0.35597681999206543 seconds for one epoch ---
--- 0.3092966079711914 seconds for one epoch ---
--- 0.338714599609375 seconds for one epoch ---
--- 0.30878472328186035 seconds for one epoch ---
--- 0.35877203941345215 seconds for one epoch ---
--- 0.30809783935546875 seconds for one epoch ---
--- 0.3520388603210449 seconds for one epoch ---
--- 0.3015122413635254 seconds for one epoch ---
--- 0.3806774616241455 seconds for one epoch ---
--- 0.32212376594543457 seconds for one epoch ---
--- 0.3736851215362549 seconds for one epoch ---
--- 0.3009660243988037 seconds for one epoch ---
--- 0.35228943824768066 seconds for one epoch ---
--- 0.30562567710876465 seconds for one epoch ---
--- 0.34773993492126465 seconds for one epoch ---
=========================
[[0.41094813]
 [0.4021843 ]
 [0.4000314 ]
 [0.40412116]
 [0.40058553]
 [0.42445275]
 [0.40382257]
 [0.40208068]
 [0.40000322]
 [0.40042147]
 [0.4026194 ]]
[[ 1.0548873 ]
 [ 0.23384975]
 [ 0.00673769]
 [-0.42824483]
 [-0.06640699]
 [-2.121556  ]
 [ 0.3988323 ]
 [ 0.22322251]
 [-0.00372729]
 [ 0.0488342 ]
 [ 0.27828544]]
--- 0.2997756004333496 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 32283.537109375, (27735.592, 4.993056, 4463.3354, 2.531735)
   validation loss 12683.1416015625, (11681.562, 0.8618183, 921.0996, 2.531735)
decoder loss ratio: 452563.973501, decoder SINDy loss  ratio: 1.988323
--- 0.263477087020874 seconds for one epoch ---
--- 0.31670451164245605 seconds for one epoch ---
--- 0.3632974624633789 seconds for one epoch ---
--- 0.3048889636993408 seconds for one epoch ---
--- 0.3446371555328369 seconds for one epoch ---
--- 0.2937471866607666 seconds for one epoch ---
--- 0.35753464698791504 seconds for one epoch ---
--- 0.3077821731567383 seconds for one epoch ---
--- 0.352494478225708 seconds for one epoch ---
--- 0.31235575675964355 seconds for one epoch ---
--- 0.3564727306365967 seconds for one epoch ---
--- 0.27960681915283203 seconds for one epoch ---
--- 0.36693811416625977 seconds for one epoch ---
--- 0.29560303688049316 seconds for one epoch ---
--- 0.29194140434265137 seconds for one epoch ---
--- 0.3096601963043213 seconds for one epoch ---
--- 0.36229491233825684 seconds for one epoch ---
--- 0.29986023902893066 seconds for one epoch ---
--- 0.37369322776794434 seconds for one epoch ---
--- 0.31655335426330566 seconds for one epoch ---
--- 0.3637049198150635 seconds for one epoch ---
--- 0.30620384216308594 seconds for one epoch ---
--- 0.34438180923461914 seconds for one epoch ---
--- 0.3000621795654297 seconds for one epoch ---
=========================
[[0.32961226]
 [0.32301992]
 [0.3244383 ]
 [0.32408172]
 [0.32128447]
 [0.35443178]
 [0.32466808]
 [0.32365873]
 [0.3211963 ]
 [0.32228452]
 [0.3250212 ]]
[[ 0.74338025]
 [ 0.17531845]
 [ 0.30381787]
 [-0.2718719 ]
 [-0.01243041]
 [-2.4759314 ]
 [ 0.32427338]
 [ 0.23364471]
 [-0.00395016]
 [-0.10707004]
 [ 0.35553437]]
--- 0.2594027519226074 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18323.603515625, (11433.69, 15.369161, 6784.4014, 2.5317452)
   validation loss 9976.775390625, (9098.598, 0.5683068, 787.46704, 2.5317452)
decoder loss ratio: 352495.469063, decoder SINDy loss  ratio: 1.699858
--- 0.3031160831451416 seconds for one epoch ---
--- 0.38498973846435547 seconds for one epoch ---
--- 0.30161356925964355 seconds for one epoch ---
--- 0.36486077308654785 seconds for one epoch ---
--- 0.29856133460998535 seconds for one epoch ---
--- 0.38669276237487793 seconds for one epoch ---
--- 0.2893846035003662 seconds for one epoch ---
--- 0.36557459831237793 seconds for one epoch ---
--- 0.2993953227996826 seconds for one epoch ---
--- 0.3581054210662842 seconds for one epoch ---
--- 0.300093412399292 seconds for one epoch ---
--- 0.38128232955932617 seconds for one epoch ---
--- 0.3008759021759033 seconds for one epoch ---
--- 0.3574490547180176 seconds for one epoch ---
--- 0.31354761123657227 seconds for one epoch ---
--- 0.3694307804107666 seconds for one epoch ---
--- 0.29450011253356934 seconds for one epoch ---
--- 0.3740875720977783 seconds for one epoch ---
--- 0.3075063228607178 seconds for one epoch ---
--- 0.3053874969482422 seconds for one epoch ---
--- 0.17342090606689453 seconds for one epoch ---
--- 0.36459875106811523 seconds for one epoch ---
--- 0.2845320701599121 seconds for one epoch ---
--- 0.38010740280151367 seconds for one epoch ---
=========================
[[0.269534  ]
 [0.26594028]
 [0.27066493]
 [0.2662679 ]
 [0.26470426]
 [0.30633283]
 [0.26772547]
 [0.26720065]
 [0.26446697]
 [0.26846743]
 [0.2691855 ]]
[[ 4.2827559e-01]
 [ 1.3053614e-01]
 [ 5.1792270e-01]
 [-1.5853931e-01]
 [-2.3030138e-02]
 [-2.8068395e+00]
 [ 2.8102803e-01]
 [ 2.3733532e-01]
 [-2.0641172e-03]
 [-3.4201694e-01]
 [ 4.0029430e-01]]
--- 0.29955148696899414 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14191.3759765625, (9127.251, 1.7728676, 4961.9604, 2.5317628)
   validation loss 5573.484375, (4699.496, 0.17967382, 773.4179, 2.5317628)
decoder loss ratio: 182066.637356, decoder SINDy loss  ratio: 1.669531
--- 0.26931190490722656 seconds for one epoch ---
--- 0.3130342960357666 seconds for one epoch ---
--- 0.3674955368041992 seconds for one epoch ---
--- 0.31680893898010254 seconds for one epoch ---
--- 0.377422571182251 seconds for one epoch ---
--- 0.31389379501342773 seconds for one epoch ---
--- 0.4014301300048828 seconds for one epoch ---
--- 0.3141791820526123 seconds for one epoch ---
--- 0.3931095600128174 seconds for one epoch ---
--- 0.29965901374816895 seconds for one epoch ---
--- 0.3674778938293457 seconds for one epoch ---
--- 0.30292367935180664 seconds for one epoch ---
--- 0.3663475513458252 seconds for one epoch ---
--- 0.30096888542175293 seconds for one epoch ---
--- 0.3815500736236572 seconds for one epoch ---
--- 0.31742215156555176 seconds for one epoch ---
--- 0.3915574550628662 seconds for one epoch ---
--- 0.305757999420166 seconds for one epoch ---
--- 0.3762075901031494 seconds for one epoch ---
--- 0.30602049827575684 seconds for one epoch ---
--- 0.37994980812072754 seconds for one epoch ---
--- 0.29755353927612305 seconds for one epoch ---
--- 0.37749695777893066 seconds for one epoch ---
--- 0.25885677337646484 seconds for one epoch ---
=========================
[[0.21773982]
 [0.2169565 ]
 [0.22532573]
 [0.21765313]
 [0.21649581]
 [0.26670673]
 [0.21937382]
 [0.21953137]
 [0.21638963]
 [0.22417475]
 [0.22207788]]
[[ 1.12402245e-01]
 [ 4.85042669e-02]
 [ 6.86352491e-01]
 [-1.05376840e-01]
 [-1.04576619e-02]
 [-3.10387540e+00]
 [ 2.42566556e-01]
 [ 2.54905313e-01]
 [-1.63898978e-03]
 [-6.03833556e-01]
 [ 4.49640334e-01]]
--- 0.25463008880615234 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12865.9970703125, (8776.944, 4.1609206, 3974.2217, 2.5317843)
   validation loss 4792.56982421875, (3994.7446, 0.17736962, 686.9784, 2.5317843)
decoder loss ratio: 154763.342105, decoder SINDy loss  ratio: 1.482939
--- 0.29312562942504883 seconds for one epoch ---
--- 0.37801265716552734 seconds for one epoch ---
--- 0.3016207218170166 seconds for one epoch ---
--- 0.3820953369140625 seconds for one epoch ---
--- 0.2879934310913086 seconds for one epoch ---
--- 0.3841264247894287 seconds for one epoch ---
--- 0.294475793838501 seconds for one epoch ---
--- 0.3938422203063965 seconds for one epoch ---
--- 0.295421838760376 seconds for one epoch ---
--- 0.4046025276184082 seconds for one epoch ---
--- 0.3004720211029053 seconds for one epoch ---
--- 0.39030885696411133 seconds for one epoch ---
--- 0.29503798484802246 seconds for one epoch ---
--- 0.3879821300506592 seconds for one epoch ---
--- 0.3022010326385498 seconds for one epoch ---
--- 0.39217042922973633 seconds for one epoch ---
--- 0.31241559982299805 seconds for one epoch ---
--- 0.3938562870025635 seconds for one epoch ---
--- 0.2874755859375 seconds for one epoch ---
--- 0.394193172454834 seconds for one epoch ---
--- 0.29517078399658203 seconds for one epoch ---
--- 0.3930690288543701 seconds for one epoch ---
--- 0.3052327632904053 seconds for one epoch ---
--- 0.38063597679138184 seconds for one epoch ---
=========================
[[0.1834667 ]
 [0.18193452]
 [0.19361804]
 [0.18288352]
 [0.18181679]
 [0.23810124]
 [0.18410698]
 [0.1849574 ]
 [0.18167442]
 [0.19338301]
 [0.18909766]]
[[-0.1480113 ]
 [-0.0285845 ]
 [ 0.86607456]
 [-0.10295807]
 [-0.01926519]
 [-3.298173  ]
 [ 0.19688097]
 [ 0.26097652]
 [-0.00794915]
 [-0.8506302 ]
 [ 0.56012434]]
--- 0.3037526607513428 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10413.5810546875, (5042.5225, 2.7655315, 5249.557, 2.5318089)
   validation loss 4684.5263671875, (3962.4482, 0.122071594, 603.22125, 2.5318089)
decoder loss ratio: 153512.124015, decoder SINDy loss  ratio: 1.302138
--- 0.1989455223083496 seconds for one epoch ---
--- 0.18016362190246582 seconds for one epoch ---
--- 0.3973071575164795 seconds for one epoch ---
--- 0.3098158836364746 seconds for one epoch ---
--- 0.3811380863189697 seconds for one epoch ---
--- 0.3121676445007324 seconds for one epoch ---
--- 0.39169788360595703 seconds for one epoch ---
--- 0.3063538074493408 seconds for one epoch ---
--- 0.42255067825317383 seconds for one epoch ---
--- 0.2980003356933594 seconds for one epoch ---
--- 0.4203517436981201 seconds for one epoch ---
--- 0.3089933395385742 seconds for one epoch ---
--- 0.39680051803588867 seconds for one epoch ---
--- 0.30353379249572754 seconds for one epoch ---
--- 0.39733314514160156 seconds for one epoch ---
--- 0.40927910804748535 seconds for one epoch ---
--- 0.39312171936035156 seconds for one epoch ---
--- 0.2925403118133545 seconds for one epoch ---
--- 0.3979201316833496 seconds for one epoch ---
--- 0.2870795726776123 seconds for one epoch ---
--- 0.39282894134521484 seconds for one epoch ---
--- 0.2878751754760742 seconds for one epoch ---
--- 0.405794620513916 seconds for one epoch ---
--- 0.31276583671569824 seconds for one epoch ---
=========================
[[0.15639363]
 [0.15283659]
 [0.16730246]
 [0.152518  ]
 [0.15201294]
 [0.21182717]
 [0.15406784]
 [0.155604  ]
 [0.151986  ]
 [0.16760558]
 [0.16081962]]
[[-0.33112675]
 [-0.07076839]
 [ 1.0473506 ]
 [-0.04662498]
 [ 0.00805685]
 [-3.3614995 ]
 [ 0.1627319 ]
 [ 0.27469125]
 [-0.00599492]
 [-1.0658581 ]
 [ 0.63478833]]
--- 0.26522088050842285 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10723.44140625, (3957.22, 1.061497, 6639.09, 2.5318277)
   validation loss 4173.56103515625, (3455.621, 0.12094159, 591.749, 2.5318277)
decoder loss ratio: 133876.760394, decoder SINDy loss  ratio: 1.277374
--- 0.30336689949035645 seconds for one epoch ---
--- 0.39556145668029785 seconds for one epoch ---
--- 0.2142658233642578 seconds for one epoch ---
--- 0.4055318832397461 seconds for one epoch ---
--- 0.29767918586730957 seconds for one epoch ---
--- 0.3946213722229004 seconds for one epoch ---
--- 0.3079090118408203 seconds for one epoch ---
--- 0.4011497497558594 seconds for one epoch ---
--- 0.30674004554748535 seconds for one epoch ---
--- 0.4055917263031006 seconds for one epoch ---
--- 0.31362032890319824 seconds for one epoch ---
--- 0.4006829261779785 seconds for one epoch ---
--- 0.3157799243927002 seconds for one epoch ---
--- 0.4094984531402588 seconds for one epoch ---
--- 0.3231842517852783 seconds for one epoch ---
--- 0.40575194358825684 seconds for one epoch ---
--- 0.29443883895874023 seconds for one epoch ---
--- 0.4009706974029541 seconds for one epoch ---
--- 0.2820923328399658 seconds for one epoch ---
--- 0.4160776138305664 seconds for one epoch ---
--- 0.3002960681915283 seconds for one epoch ---
--- 0.41324853897094727 seconds for one epoch ---
--- 0.29892539978027344 seconds for one epoch ---
--- 0.4142448902130127 seconds for one epoch ---
=========================
[[0.137082  ]
 [0.13166462]
 [0.14840908]
 [0.13049825]
 [0.13059647]
 [0.19205548]
 [0.1326166 ]
 [0.13407367]
 [0.13031776]
 [0.14975832]
 [0.14130297]]
[[-4.7885746e-01]
 [-1.0013039e-01]
 [ 1.1833972e+00]
 [ 1.3921702e-02]
 [ 2.1259420e-02]
 [-3.3751934e+00]
 [ 1.6916415e-01]
 [ 2.7269024e-01]
 [ 4.2105978e-04]
 [-1.2613455e+00]
 [ 7.5322187e-01]]
--- 0.2932746410369873 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11506.65625, (6594.786, 1.2962209, 4777.483, 2.5318434)
   validation loss 2696.32958984375, (1999.616, 0.07175461, 563.552, 2.5318434)
decoder loss ratio: 77468.594040, decoder SINDy loss  ratio: 1.216506
--- 0.26366400718688965 seconds for one epoch ---
--- 0.26938915252685547 seconds for one epoch ---
--- 0.45131659507751465 seconds for one epoch ---
--- 0.29257774353027344 seconds for one epoch ---
--- 0.41942787170410156 seconds for one epoch ---
--- 0.3063547611236572 seconds for one epoch ---
--- 0.4276914596557617 seconds for one epoch ---
--- 0.30396485328674316 seconds for one epoch ---
--- 0.41802096366882324 seconds for one epoch ---
--- 0.29116249084472656 seconds for one epoch ---
--- 0.40518975257873535 seconds for one epoch ---
--- 0.29053258895874023 seconds for one epoch ---
--- 0.43300628662109375 seconds for one epoch ---
--- 0.30962181091308594 seconds for one epoch ---
--- 0.42293405532836914 seconds for one epoch ---
--- 0.30939674377441406 seconds for one epoch ---
--- 0.4295477867126465 seconds for one epoch ---
--- 0.29912543296813965 seconds for one epoch ---
--- 0.4325714111328125 seconds for one epoch ---
--- 0.3065364360809326 seconds for one epoch ---
--- 0.4001920223236084 seconds for one epoch ---
--- 0.3172037601470947 seconds for one epoch ---
--- 0.41467714309692383 seconds for one epoch ---
--- 0.3162376880645752 seconds for one epoch ---
=========================
[[0.12125366]
 [0.11374335]
 [0.13179456]
 [0.11299101]
 [0.11219624]
 [0.17601028]
 [0.11332842]
 [0.11556705]
 [0.11183867]
 [0.1352303 ]
 [0.12439106]]
[[-6.4268208e-01]
 [-1.4047106e-01]
 [ 1.2691102e+00]
 [ 8.6766854e-02]
 [ 2.9278006e-02]
 [-3.4271202e+00]
 [ 1.1094673e-01]
 [ 2.6783937e-01]
 [ 3.1312765e-03]
 [-1.4587842e+00]
 [ 8.3724046e-01]]
--- 0.2631058692932129 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9068.400390625, (3150.229, 40.59239, 5738.052, 2.5318613)
   validation loss 2948.343994140625, (2201.1946, 0.08014117, 607.542, 2.5318613)
decoder loss ratio: 85278.099474, decoder SINDy loss  ratio: 1.311465
--- 0.18254709243774414 seconds for one epoch ---
--- 0.41410040855407715 seconds for one epoch ---
--- 0.30565619468688965 seconds for one epoch ---
--- 0.4364199638366699 seconds for one epoch ---
--- 0.3026421070098877 seconds for one epoch ---
--- 0.4188838005065918 seconds for one epoch ---
--- 0.29910993576049805 seconds for one epoch ---
--- 0.436293363571167 seconds for one epoch ---
--- 0.30785679817199707 seconds for one epoch ---
--- 0.44612646102905273 seconds for one epoch ---
--- 0.31520843505859375 seconds for one epoch ---
--- 0.4331808090209961 seconds for one epoch ---
--- 0.30405235290527344 seconds for one epoch ---
--- 0.42282557487487793 seconds for one epoch ---
--- 0.30706262588500977 seconds for one epoch ---
--- 0.4462134838104248 seconds for one epoch ---
--- 0.29338788986206055 seconds for one epoch ---
--- 0.4359772205352783 seconds for one epoch ---
--- 0.31107425689697266 seconds for one epoch ---
--- 0.4199538230895996 seconds for one epoch ---
--- 0.30192065238952637 seconds for one epoch ---
--- 0.4210476875305176 seconds for one epoch ---
--- 0.3026289939880371 seconds for one epoch ---
--- 0.43733930587768555 seconds for one epoch ---
=========================
[[0.10968732]
 [0.10086536]
 [0.11946425]
 [0.09943144]
 [0.0984218 ]
 [0.16320027]
 [0.09954388]
 [0.10178918]
 [0.09824621]
 [0.1249605 ]
 [0.11253604]]
[[-7.5625247e-01]
 [-1.8540439e-01]
 [ 1.3196738e+00]
 [ 8.5118450e-02]
 [ 1.3015240e-02]
 [-3.4167130e+00]
 [ 9.3073279e-02]
 [ 2.4875988e-01]
 [-3.4117390e-04]
 [-1.6135824e+00]
 [ 9.2671531e-01]]
--- 0.3022449016571045 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7307.70947265625, (3550.572, 1.3064026, 3611.044, 2.5318735)
   validation loss 2250.808349609375, (1591.1935, 0.06622967, 514.76105, 2.5318735)
decoder loss ratio: 61645.597905, decoder SINDy loss  ratio: 1.111184
--- 0.2621643543243408 seconds for one epoch ---
--- 0.20742130279541016 seconds for one epoch ---
--- 0.4583394527435303 seconds for one epoch ---
--- 0.29578280448913574 seconds for one epoch ---
--- 0.4326324462890625 seconds for one epoch ---
--- 0.31186771392822266 seconds for one epoch ---
--- 0.43703317642211914 seconds for one epoch ---
--- 0.3127439022064209 seconds for one epoch ---
--- 0.42836642265319824 seconds for one epoch ---
--- 0.3085601329803467 seconds for one epoch ---
--- 0.4531266689300537 seconds for one epoch ---
--- 0.2998323440551758 seconds for one epoch ---
--- 0.4495818614959717 seconds for one epoch ---
--- 0.3005359172821045 seconds for one epoch ---
--- 0.44023776054382324 seconds for one epoch ---
--- 0.31664228439331055 seconds for one epoch ---
--- 0.44905638694763184 seconds for one epoch ---
--- 0.30094099044799805 seconds for one epoch ---
--- 0.45597147941589355 seconds for one epoch ---
--- 0.29782772064208984 seconds for one epoch ---
--- 0.44884824752807617 seconds for one epoch ---
--- 0.29703855514526367 seconds for one epoch ---
--- 0.4594099521636963 seconds for one epoch ---
--- 0.30834102630615234 seconds for one epoch ---
=========================
[[0.09958547]
 [0.0896863 ]
 [0.10912373]
 [0.08805434]
 [0.08676554]
 [0.15125826]
 [0.08718263]
 [0.09058838]
 [0.08658833]
 [0.11622903]
 [0.10290463]]
[[-8.4176117e-01]
 [-2.1750352e-01]
 [ 1.3772495e+00]
 [ 1.0554169e-01]
 [ 1.4924913e-02]
 [-3.3687432e+00]
 [ 4.4475596e-02]
 [ 2.7813077e-01]
 [ 2.2988389e-03]
 [-1.7467736e+00]
 [ 1.0341535e+00]]
--- 0.2607612609863281 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11631.4833984375, (8045.19, 3.1134102, 3433.1147, 2.5318825)
   validation loss 2494.070068359375, (1745.1041, 0.07684304, 598.8234, 2.5318825)
decoder loss ratio: 67608.363474, decoder SINDy loss  ratio: 1.292645
--- 0.1678624153137207 seconds for one epoch ---
--- 0.44728922843933105 seconds for one epoch ---
--- 0.30739665031433105 seconds for one epoch ---
--- 0.4420182704925537 seconds for one epoch ---
--- 0.2879638671875 seconds for one epoch ---
--- 0.45006322860717773 seconds for one epoch ---
--- 0.2818760871887207 seconds for one epoch ---
--- 0.4463222026824951 seconds for one epoch ---
--- 0.30695223808288574 seconds for one epoch ---
--- 0.47390079498291016 seconds for one epoch ---
--- 0.30976295471191406 seconds for one epoch ---
--- 0.46787309646606445 seconds for one epoch ---
--- 0.29511284828186035 seconds for one epoch ---
--- 0.45145535469055176 seconds for one epoch ---
--- 0.30646562576293945 seconds for one epoch ---
--- 0.46724629402160645 seconds for one epoch ---
--- 0.30583739280700684 seconds for one epoch ---
--- 0.45256519317626953 seconds for one epoch ---
--- 0.28977203369140625 seconds for one epoch ---
--- 0.4649178981781006 seconds for one epoch ---
--- 0.3300201892852783 seconds for one epoch ---
--- 0.4753105640411377 seconds for one epoch ---
--- 0.31957077980041504 seconds for one epoch ---
--- 0.45920705795288086 seconds for one epoch ---
=========================
[[0.09274603]
 [0.08123697]
 [0.10108691]
 [0.08002918]
 [0.07824884]
 [0.14236082]
 [0.0788857 ]
 [0.08169237]
 [0.07796438]
 [0.11073012]
 [0.09648544]]
[[-9.3675655e-01]
 [-2.2567715e-01]
 [ 1.3958737e+00]
 [ 1.4404735e-01]
 [ 2.0705052e-02]
 [-3.3294957e+00]
 [ 6.5258950e-02]
 [ 2.5604874e-01]
 [ 6.4346177e-04]
 [-1.8868380e+00]
 [ 1.1472892e+00]]
--- 0.30420947074890137 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5938.51123046875, (2403.521, 3.086535, 3377.5427, 2.5318916)
   validation loss 2467.70947265625, (1802.3104, 0.053411674, 510.98447, 2.5318916)
decoder loss ratio: 69824.634805, decoder SINDy loss  ratio: 1.103032
--- 0.2650880813598633 seconds for one epoch ---
--- 0.29638242721557617 seconds for one epoch ---
--- 0.5125021934509277 seconds for one epoch ---
--- 0.2892787456512451 seconds for one epoch ---
--- 0.4663715362548828 seconds for one epoch ---
--- 0.29742932319641113 seconds for one epoch ---
--- 0.46279263496398926 seconds for one epoch ---
--- 0.30580949783325195 seconds for one epoch ---
--- 0.4610750675201416 seconds for one epoch ---
--- 0.3084235191345215 seconds for one epoch ---
--- 0.46134138107299805 seconds for one epoch ---
--- 0.3014345169067383 seconds for one epoch ---
--- 0.4654366970062256 seconds for one epoch ---
--- 0.3117539882659912 seconds for one epoch ---
--- 0.48304152488708496 seconds for one epoch ---
--- 0.330089807510376 seconds for one epoch ---
--- 0.4527451992034912 seconds for one epoch ---
--- 0.29967379570007324 seconds for one epoch ---
--- 0.3988001346588135 seconds for one epoch ---
--- 0.2170863151550293 seconds for one epoch ---
--- 0.48360347747802734 seconds for one epoch ---
--- 0.31362342834472656 seconds for one epoch ---
--- 0.4647848606109619 seconds for one epoch ---
--- 0.30181026458740234 seconds for one epoch ---
=========================
[[0.08678575]
 [0.07411704]
 [0.09374862]
 [0.07221881]
 [0.0706948 ]
 [0.13425893]
 [0.07194295]
 [0.0742743 ]
 [0.07060088]
 [0.10609296]
 [0.09092092]]
[[-1.0145029 ]
 [-0.24609119]
 [ 1.3921658 ]
 [ 0.11875858]
 [ 0.01359082]
 [-3.2792065 ]
 [ 0.09991576]
 [ 0.25647077]
 [-0.00702289]
 [-2.0102856 ]
 [ 1.2418118 ]]
--- 0.2703428268432617 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6142.56787109375, (2474.23, 77.62144, 3431.9297, 2.5318992)
   validation loss 1789.00927734375, (1130.7478, 0.051164016, 499.42352, 2.5318992)
decoder loss ratio: 43807.132942, decoder SINDy loss  ratio: 1.078076
--- 0.31690287590026855 seconds for one epoch ---
--- 0.4685494899749756 seconds for one epoch ---
--- 0.317490816116333 seconds for one epoch ---
--- 0.48110032081604004 seconds for one epoch ---
--- 0.31514549255371094 seconds for one epoch ---
--- 0.4744088649749756 seconds for one epoch ---
--- 0.3172934055328369 seconds for one epoch ---
--- 0.5613343715667725 seconds for one epoch ---
--- 0.3118479251861572 seconds for one epoch ---
--- 0.4490828514099121 seconds for one epoch ---
--- 0.2973334789276123 seconds for one epoch ---
--- 0.47134852409362793 seconds for one epoch ---
--- 0.30179738998413086 seconds for one epoch ---
--- 0.403240442276001 seconds for one epoch ---
--- 0.1668701171875 seconds for one epoch ---
--- 0.5147840976715088 seconds for one epoch ---
--- 0.30544424057006836 seconds for one epoch ---
--- 0.49025607109069824 seconds for one epoch ---
--- 0.3095738887786865 seconds for one epoch ---
--- 0.47216272354125977 seconds for one epoch ---
--- 0.29557156562805176 seconds for one epoch ---
--- 0.48204636573791504 seconds for one epoch ---
--- 0.2985389232635498 seconds for one epoch ---
--- 0.49601244926452637 seconds for one epoch ---
=========================
[[0.08278558]
 [0.06907368]
 [0.08851039]
 [0.06676949]
 [0.06516747]
 [0.12714094]
 [0.06622323]
 [0.06891178]
 [0.06500784]
 [0.10380942]
 [0.08659566]]
[[-1.0931138e+00]
 [-2.7562258e-01]
 [ 1.3994565e+00]
 [ 1.2257774e-01]
 [ 1.2727895e-02]
 [-3.1941903e+00]
 [ 8.5456349e-02]
 [ 2.6504564e-01]
 [-1.6180113e-03]
 [-2.1531272e+00]
 [ 1.2987976e+00]]
--- 0.3948249816894531 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6603.392578125, (2748.057, 3.6332338, 3689.6357, 2.5319045)
   validation loss 3397.0498046875, (2741.4592, 0.059032988, 493.4651, 2.5319045)
decoder loss ratio: 106208.889895, decoder SINDy loss  ratio: 1.065214
--- 0.2652740478515625 seconds for one epoch ---
--- 0.2930266857147217 seconds for one epoch ---
--- 0.5381948947906494 seconds for one epoch ---
--- 0.31230783462524414 seconds for one epoch ---
--- 0.49625229835510254 seconds for one epoch ---
--- 0.2958848476409912 seconds for one epoch ---
--- 0.49468398094177246 seconds for one epoch ---
--- 0.2957606315612793 seconds for one epoch ---
--- 0.5526885986328125 seconds for one epoch ---
--- 0.30182981491088867 seconds for one epoch ---
--- 0.4916074275970459 seconds for one epoch ---
--- 0.1760110855102539 seconds for one epoch ---
--- 0.4914431571960449 seconds for one epoch ---
--- 0.2975475788116455 seconds for one epoch ---
--- 0.4885537624359131 seconds for one epoch ---
--- 0.30245399475097656 seconds for one epoch ---
--- 0.48261141777038574 seconds for one epoch ---
--- 0.3005490303039551 seconds for one epoch ---
--- 0.5007686614990234 seconds for one epoch ---
--- 0.30698513984680176 seconds for one epoch ---
--- 0.49022650718688965 seconds for one epoch ---
--- 0.30404138565063477 seconds for one epoch ---
--- 0.49333977699279785 seconds for one epoch ---
--- 0.2966461181640625 seconds for one epoch ---
=========================
[[0.07936908]
 [0.06476207]
 [0.08368761]
 [0.06240172]
 [0.06035586]
 [0.12088494]
 [0.06080114]
 [0.06405705]
 [0.06021463]
 [0.10205869]
 [0.08317174]]
[[-1.1636724e+00]
 [-3.0622834e-01]
 [ 1.3923073e+00]
 [ 1.5134615e-01]
 [ 1.2265355e-02]
 [-3.1183305e+00]
 [ 4.2946257e-02]
 [ 2.6055595e-01]
 [ 2.4920630e-03]
 [-2.2853007e+00]
 [ 1.3654599e+00]]
--- 0.2629563808441162 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4758.69140625, (1955.2872, 0.676856, 2635.8162, 2.5319104)
   validation loss 2467.795166015625, (1815.4183, 0.054053247, 485.41122, 2.5319104)
decoder loss ratio: 70332.458001, decoder SINDy loss  ratio: 1.047828
--- 0.2820887565612793 seconds for one epoch ---
--- 0.498340368270874 seconds for one epoch ---
--- 0.2953805923461914 seconds for one epoch ---
--- 0.4735245704650879 seconds for one epoch ---
--- 0.3027775287628174 seconds for one epoch ---
--- 0.5102589130401611 seconds for one epoch ---
--- 0.3000614643096924 seconds for one epoch ---
--- 0.5028104782104492 seconds for one epoch ---
--- 0.30669665336608887 seconds for one epoch ---
--- 0.49250173568725586 seconds for one epoch ---
--- 0.30538153648376465 seconds for one epoch ---
--- 0.49289655685424805 seconds for one epoch ---
--- 0.29252123832702637 seconds for one epoch ---
--- 0.504166841506958 seconds for one epoch ---
--- 0.298626184463501 seconds for one epoch ---
--- 0.5191035270690918 seconds for one epoch ---
--- 0.3070085048675537 seconds for one epoch ---
--- 0.5101113319396973 seconds for one epoch ---
--- 0.29842400550842285 seconds for one epoch ---
--- 0.49527597427368164 seconds for one epoch ---
--- 0.29812097549438477 seconds for one epoch ---
--- 0.5021607875823975 seconds for one epoch ---
--- 0.3040599822998047 seconds for one epoch ---
--- 0.5135016441345215 seconds for one epoch ---
=========================
[[0.07751404]
 [0.06159779]
 [0.07979449]
 [0.05880576]
 [0.05683113]
 [0.11636153]
 [0.05736483]
 [0.06033437]
 [0.05664377]
 [0.10182071]
 [0.08073343]]
[[-1.2515769e+00]
 [-3.3137408e-01]
 [ 1.3711677e+00]
 [ 1.4935684e-01]
 [ 1.5650025e-02]
 [-3.0677774e+00]
 [ 5.2227668e-02]
 [ 2.4997596e-01]
 [ 2.7350597e-03]
 [-2.4296417e+00]
 [ 1.4197090e+00]]
--- 0.2981605529785156 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4910.27587890625, (2102.2764, 0.63995314, 2636.5344, 2.5319188)
   validation loss 1991.825439453125, (1368.2563, 0.03683381, 452.7071, 2.5319188)
decoder loss ratio: 53008.626306, decoder SINDy loss  ratio: 0.977232
--- 0.2702326774597168 seconds for one epoch ---
--- 0.2984583377838135 seconds for one epoch ---
--- 0.49249958992004395 seconds for one epoch ---
--- 0.3093996047973633 seconds for one epoch ---
--- 0.5190346240997314 seconds for one epoch ---
--- 0.3067758083343506 seconds for one epoch ---
--- 0.50803542137146 seconds for one epoch ---
--- 0.31900954246520996 seconds for one epoch ---
--- 0.533353328704834 seconds for one epoch ---
--- 0.3058462142944336 seconds for one epoch ---
--- 0.5359785556793213 seconds for one epoch ---
--- 0.31412267684936523 seconds for one epoch ---
--- 0.4659159183502197 seconds for one epoch ---
--- 0.22259521484375 seconds for one epoch ---
--- 0.526247501373291 seconds for one epoch ---
--- 0.2922341823577881 seconds for one epoch ---
--- 0.4888949394226074 seconds for one epoch ---
--- 0.2950866222381592 seconds for one epoch ---
--- 0.5166559219360352 seconds for one epoch ---
--- 0.2886617183685303 seconds for one epoch ---
--- 0.526158332824707 seconds for one epoch ---
--- 0.3108053207397461 seconds for one epoch ---
--- 0.5130941867828369 seconds for one epoch ---
--- 0.29724693298339844 seconds for one epoch ---
=========================
[[0.07523526]
 [0.0590986 ]
 [0.07654908]
 [0.05532946]
 [0.05351238]
 [0.11119782]
 [0.05432666]
 [0.05704217]
 [0.05353327]
 [0.10124681]
 [0.07932496]]
[[-1.2927320e+00]
 [-3.7028724e-01]
 [ 1.3612173e+00]
 [ 1.2583140e-01]
 [ 2.6460902e-03]
 [-2.9720531e+00]
 [ 5.8312055e-02]
 [ 2.3865935e-01]
 [-4.0854360e-03]
 [-2.5372357e+00]
 [ 1.5034026e+00]]
--- 0.2653498649597168 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4718.4453125, (1970.2567, 1.6236866, 2572.87, 2.5319228)
   validation loss 1799.7882080078125, (1165.3369, 0.040187847, 460.71634, 2.5319228)
decoder loss ratio: 45147.175165, decoder SINDy loss  ratio: 0.994521
--- 0.29874396324157715 seconds for one epoch ---
--- 0.506422758102417 seconds for one epoch ---
--- 0.30355000495910645 seconds for one epoch ---
--- 0.4944267272949219 seconds for one epoch ---
--- 0.28325486183166504 seconds for one epoch ---
--- 0.5178451538085938 seconds for one epoch ---
--- 0.293109655380249 seconds for one epoch ---
--- 0.5303270816802979 seconds for one epoch ---
--- 0.30287599563598633 seconds for one epoch ---
--- 0.52089524269104 seconds for one epoch ---
--- 0.3040003776550293 seconds for one epoch ---
--- 0.5173354148864746 seconds for one epoch ---
--- 0.2997140884399414 seconds for one epoch ---
--- 0.5181770324707031 seconds for one epoch ---
--- 0.2921011447906494 seconds for one epoch ---
--- 0.5395634174346924 seconds for one epoch ---
--- 0.310544490814209 seconds for one epoch ---
--- 0.5316760540008545 seconds for one epoch ---
--- 0.2931632995605469 seconds for one epoch ---
--- 0.5652685165405273 seconds for one epoch ---
--- 0.30107617378234863 seconds for one epoch ---
--- 0.5391409397125244 seconds for one epoch ---
--- 0.30487918853759766 seconds for one epoch ---
--- 0.5663332939147949 seconds for one epoch ---
=========================
[[0.0739466 ]
 [0.05689877]
 [0.07397993]
 [0.05310503]
 [0.05113759]
 [0.10708141]
 [0.05209911]
 [0.05475545]
 [0.05116365]
 [0.10153661]
 [0.07804012]]
[[-1.3446760e+00]
 [-3.7822524e-01]
 [ 1.3464056e+00]
 [ 1.3321711e-01]
 [-2.5246840e-04]
 [-2.8894894e+00]
 [ 6.5780498e-02]
 [ 2.4154247e-01]
 [ 2.0403785e-03]
 [-2.6481452e+00]
 [ 1.5532860e+00]]
--- 0.3014235496520996 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4363.69775390625, (1659.8799, 0.79355115, 2525.6438, 2.5319273)
   validation loss 2722.7109375, (2099.9985, 0.04099605, 445.29068, 2.5319273)
decoder loss ratio: 81357.589010, decoder SINDy loss  ratio: 0.961223
THRESHOLDING: 2 active coefficients
--- 0.5249428749084473 seconds for one epoch ---
--- 0.3066258430480957 seconds for one epoch ---
--- 0.5596435070037842 seconds for one epoch ---
--- 0.31165337562561035 seconds for one epoch ---
--- 0.527958869934082 seconds for one epoch ---
--- 0.3060281276702881 seconds for one epoch ---
--- 0.5162549018859863 seconds for one epoch ---
--- 0.31313347816467285 seconds for one epoch ---
--- 0.5204629898071289 seconds for one epoch ---
--- 0.3011198043823242 seconds for one epoch ---
--- 0.5379962921142578 seconds for one epoch ---
--- 0.31149744987487793 seconds for one epoch ---
--- 0.638380765914917 seconds for one epoch ---
--- 0.2327895164489746 seconds for one epoch ---
--- 0.5721685886383057 seconds for one epoch ---
--- 0.3094806671142578 seconds for one epoch ---
--- 0.5129997730255127 seconds for one epoch ---
--- 0.29178905487060547 seconds for one epoch ---
--- 0.5172889232635498 seconds for one epoch ---
--- 0.31221699714660645 seconds for one epoch ---
--- 0.5235443115234375 seconds for one epoch ---
--- 0.29111623764038086 seconds for one epoch ---
--- 0.5277190208435059 seconds for one epoch ---
--- 0.30333757400512695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08360253]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09358001]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.921383 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3815641]
 [ 0.       ]]
--- 0.2656064033508301 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3801.477783203125, (2361.5513, 0.2817557, 1439.4541, 0.19066556)
   validation loss 1599.36474609375, (1190.9001, 0.064665064, 408.2092, 0.19066556)
decoder loss ratio: 46137.539168, decoder SINDy loss  ratio: 0.881177
--- 0.3036518096923828 seconds for one epoch ---
--- 0.5362026691436768 seconds for one epoch ---
--- 0.3009662628173828 seconds for one epoch ---
--- 0.5293784141540527 seconds for one epoch ---
--- 0.29596638679504395 seconds for one epoch ---
--- 0.5198793411254883 seconds for one epoch ---
--- 0.2889871597290039 seconds for one epoch ---
--- 0.5286970138549805 seconds for one epoch ---
--- 0.3040602207183838 seconds for one epoch ---
--- 0.5408153533935547 seconds for one epoch ---
--- 0.2923293113708496 seconds for one epoch ---
--- 0.5393495559692383 seconds for one epoch ---
--- 0.3104383945465088 seconds for one epoch ---
--- 0.5410282611846924 seconds for one epoch ---
--- 0.28650426864624023 seconds for one epoch ---
--- 0.5571837425231934 seconds for one epoch ---
--- 0.30471110343933105 seconds for one epoch ---
--- 0.5510687828063965 seconds for one epoch ---
--- 0.3037140369415283 seconds for one epoch ---
--- 0.5622851848602295 seconds for one epoch ---
--- 0.3107421398162842 seconds for one epoch ---
--- 0.5629844665527344 seconds for one epoch ---
--- 0.30764317512512207 seconds for one epoch ---
--- 0.5454413890838623 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07282432]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08981162]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.4672363]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.2780626]
 [ 0.       ]]
--- 0.2936224937438965 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4363.40869140625, (3151.9333, 1.9150296, 1209.3755, 0.18506841)
   validation loss 3161.830810546875, (2775.1597, 0.087633446, 386.39853, 0.18506841)
decoder loss ratio: 107514.503426, decoder SINDy loss  ratio: 0.834096
--- 0.26345109939575195 seconds for one epoch ---
--- 0.29545092582702637 seconds for one epoch ---
--- 0.5258617401123047 seconds for one epoch ---
--- 0.30935096740722656 seconds for one epoch ---
--- 0.5465569496154785 seconds for one epoch ---
--- 0.2856175899505615 seconds for one epoch ---
--- 0.5570621490478516 seconds for one epoch ---
--- 0.30724334716796875 seconds for one epoch ---
--- 0.5408062934875488 seconds for one epoch ---
--- 0.3017585277557373 seconds for one epoch ---
--- 0.5506124496459961 seconds for one epoch ---
--- 0.3130655288696289 seconds for one epoch ---
--- 0.5601625442504883 seconds for one epoch ---
--- 0.31011319160461426 seconds for one epoch ---
--- 0.5489017963409424 seconds for one epoch ---
--- 0.31355738639831543 seconds for one epoch ---
--- 0.5455739498138428 seconds for one epoch ---
--- 0.3070099353790283 seconds for one epoch ---
--- 0.5423130989074707 seconds for one epoch ---
--- 0.3255026340484619 seconds for one epoch ---
--- 0.5727622509002686 seconds for one epoch ---
--- 0.3158731460571289 seconds for one epoch ---
--- 0.5429742336273193 seconds for one epoch ---
--- 0.305072546005249 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06801775]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08883336]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2890303]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.2929666]
 [ 0.       ]]
--- 0.25794434547424316 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2129.562744140625, (1280.1056, 0.64346355, 848.63043, 0.18340161)
   validation loss 1164.364013671875, (802.979, 0.08480839, 361.11682, 0.18340161)
decoder loss ratio: 31108.800644, decoder SINDy loss  ratio: 0.779521
--- 0.2643122673034668 seconds for one epoch ---
--- 0.5690717697143555 seconds for one epoch ---
--- 0.3092219829559326 seconds for one epoch ---
--- 0.5487885475158691 seconds for one epoch ---
--- 0.2926502227783203 seconds for one epoch ---
--- 0.5678904056549072 seconds for one epoch ---
--- 0.31297945976257324 seconds for one epoch ---
--- 0.5611002445220947 seconds for one epoch ---
--- 0.3009316921234131 seconds for one epoch ---
--- 0.561023473739624 seconds for one epoch ---
--- 0.2913796901702881 seconds for one epoch ---
--- 0.5506093502044678 seconds for one epoch ---
--- 0.30089735984802246 seconds for one epoch ---
--- 0.5629899501800537 seconds for one epoch ---
--- 0.29099440574645996 seconds for one epoch ---
--- 0.5786576271057129 seconds for one epoch ---
--- 0.30560302734375 seconds for one epoch ---
--- 0.5657901763916016 seconds for one epoch ---
--- 0.28278326988220215 seconds for one epoch ---
--- 0.5617897510528564 seconds for one epoch ---
--- 0.2873375415802002 seconds for one epoch ---
--- 0.6263182163238525 seconds for one epoch ---
--- 0.2986714839935303 seconds for one epoch ---
--- 0.5531885623931885 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06474663]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08807447]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.170168 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3032446]
 [ 0.       ]]
--- 0.2694222927093506 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4611.5185546875, (1801.0457, 1.6311595, 2808.6592, 0.18254636)
   validation loss 1455.7371826171875, (1055.4332, 0.15041766, 399.97113, 0.18254636)
decoder loss ratio: 40889.315548, decoder SINDy loss  ratio: 0.863394
--- 0.2649953365325928 seconds for one epoch ---
--- 0.3080906867980957 seconds for one epoch ---
--- 0.5750529766082764 seconds for one epoch ---
--- 0.2997004985809326 seconds for one epoch ---
--- 0.5717995166778564 seconds for one epoch ---
--- 0.2947394847869873 seconds for one epoch ---
--- 0.5720288753509521 seconds for one epoch ---
--- 0.305042028427124 seconds for one epoch ---
--- 0.5547139644622803 seconds for one epoch ---
--- 0.26797986030578613 seconds for one epoch ---
--- 0.5893440246582031 seconds for one epoch ---
--- 0.3077051639556885 seconds for one epoch ---
--- 0.5817821025848389 seconds for one epoch ---
--- 0.30448317527770996 seconds for one epoch ---
--- 0.5833191871643066 seconds for one epoch ---
--- 0.30439209938049316 seconds for one epoch ---
--- 0.5889074802398682 seconds for one epoch ---
--- 0.3040032386779785 seconds for one epoch ---
--- 0.578096866607666 seconds for one epoch ---
--- 0.2967991828918457 seconds for one epoch ---
--- 0.597895622253418 seconds for one epoch ---
--- 0.29705190658569336 seconds for one epoch ---
--- 0.582496166229248 seconds for one epoch ---
--- 0.30226969718933105 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06300527]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0889198 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1252843]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3805606]
 [ 0.       ]]
--- 0.26810407638549805 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3852.202880859375, (1794.4204, 1.1124753, 2056.487, 0.1828659)
   validation loss 2457.397705078125, (2066.454, 0.1665764, 390.59415, 0.1828659)
decoder loss ratio: 80058.019417, decoder SINDy loss  ratio: 0.843152
--- 0.30159521102905273 seconds for one epoch ---
--- 0.5603513717651367 seconds for one epoch ---
--- 0.41411757469177246 seconds for one epoch ---
--- 0.5665388107299805 seconds for one epoch ---
--- 0.2852020263671875 seconds for one epoch ---
--- 0.5788238048553467 seconds for one epoch ---
--- 0.29181957244873047 seconds for one epoch ---
--- 0.5913634300231934 seconds for one epoch ---
--- 0.30584716796875 seconds for one epoch ---
--- 0.6230499744415283 seconds for one epoch ---
--- 0.31041646003723145 seconds for one epoch ---
--- 0.5837957859039307 seconds for one epoch ---
--- 0.297760009765625 seconds for one epoch ---
--- 0.5867996215820312 seconds for one epoch ---
--- 0.2864646911621094 seconds for one epoch ---
--- 0.4852468967437744 seconds for one epoch ---
--- 0.27301788330078125 seconds for one epoch ---
--- 0.5695712566375732 seconds for one epoch ---
--- 0.34052181243896484 seconds for one epoch ---
--- 0.6129574775695801 seconds for one epoch ---
--- 0.3199801445007324 seconds for one epoch ---
--- 0.592979907989502 seconds for one epoch ---
--- 0.30174732208251953 seconds for one epoch ---
--- 0.5924808979034424 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06195019]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08930586]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.1053172]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4273558]
 [ 0.       ]]
--- 0.3009681701660156 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3857.620361328125, (1578.678, 1.0795797, 2277.6797, 0.18303962)
   validation loss 1379.7412109375, (1033.5348, 0.10103624, 345.9224, 0.18303962)
decoder loss ratio: 40040.932061, decoder SINDy loss  ratio: 0.746722
--- 0.27182483673095703 seconds for one epoch ---
--- 0.30694079399108887 seconds for one epoch ---
--- 0.6547455787658691 seconds for one epoch ---
--- 0.30797243118286133 seconds for one epoch ---
--- 0.5972201824188232 seconds for one epoch ---
--- 0.25266289710998535 seconds for one epoch ---
--- 0.6284725666046143 seconds for one epoch ---
--- 0.30165958404541016 seconds for one epoch ---
--- 0.5934381484985352 seconds for one epoch ---
--- 0.297868013381958 seconds for one epoch ---
--- 0.605694055557251 seconds for one epoch ---
--- 0.30622196197509766 seconds for one epoch ---
--- 0.5916752815246582 seconds for one epoch ---
--- 0.3020179271697998 seconds for one epoch ---
--- 0.6058254241943359 seconds for one epoch ---
--- 0.30040860176086426 seconds for one epoch ---
--- 0.6010780334472656 seconds for one epoch ---
--- 0.3086204528808594 seconds for one epoch ---
--- 0.6032946109771729 seconds for one epoch ---
--- 0.3117077350616455 seconds for one epoch ---
--- 0.6064407825469971 seconds for one epoch ---
--- 0.3092823028564453 seconds for one epoch ---
--- 0.5925693511962891 seconds for one epoch ---
--- 0.2970125675201416 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06068352]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09046092]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0699618]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.5047088]
 [ 0.       ]]
--- 0.26671743392944336 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2715.93310546875, (1438.1553, 0.4518016, 1277.1425, 0.1836013)
   validation loss 1566.424072265625, (1203.1914, 0.11492153, 362.93417, 0.1836013)
decoder loss ratio: 46613.723910, decoder SINDy loss  ratio: 0.783444
--- 0.30590271949768066 seconds for one epoch ---
--- 0.6064643859863281 seconds for one epoch ---
--- 0.3014814853668213 seconds for one epoch ---
--- 0.6035647392272949 seconds for one epoch ---
--- 0.310990571975708 seconds for one epoch ---
--- 0.6359372138977051 seconds for one epoch ---
--- 0.3082122802734375 seconds for one epoch ---
--- 0.6250002384185791 seconds for one epoch ---
--- 0.2956559658050537 seconds for one epoch ---
--- 0.6059086322784424 seconds for one epoch ---
--- 0.19904637336730957 seconds for one epoch ---
--- 0.630885124206543 seconds for one epoch ---
--- 0.3047480583190918 seconds for one epoch ---
--- 0.6187214851379395 seconds for one epoch ---
--- 0.30065369606018066 seconds for one epoch ---
--- 0.6073064804077148 seconds for one epoch ---
--- 0.2906677722930908 seconds for one epoch ---
--- 0.6111505031585693 seconds for one epoch ---
--- 0.29249024391174316 seconds for one epoch ---
--- 0.6143734455108643 seconds for one epoch ---
--- 0.297152042388916 seconds for one epoch ---
--- 0.6198151111602783 seconds for one epoch ---
--- 0.29157161712646484 seconds for one epoch ---
--- 0.6205780506134033 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06007229]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09142217]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0620377]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.5667622]
 [ 0.       ]]
--- 0.29854464530944824 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3183.164306640625, (2291.3057, 0.399563, 891.2748, 0.18426327)
   validation loss 1023.533203125, (709.6198, 0.08854804, 313.64056, 0.18426327)
decoder loss ratio: 27491.903472, decoder SINDy loss  ratio: 0.677037
--- 0.2586047649383545 seconds for one epoch ---
--- 0.2986292839050293 seconds for one epoch ---
--- 0.6158695220947266 seconds for one epoch ---
--- 0.28592920303344727 seconds for one epoch ---
--- 0.6149723529815674 seconds for one epoch ---
--- 0.29639744758605957 seconds for one epoch ---
--- 0.6278924942016602 seconds for one epoch ---
--- 0.30707669258117676 seconds for one epoch ---
--- 0.6108973026275635 seconds for one epoch ---
--- 0.29030752182006836 seconds for one epoch ---
--- 0.6302063465118408 seconds for one epoch ---
--- 0.30236053466796875 seconds for one epoch ---
--- 0.6160678863525391 seconds for one epoch ---
--- 0.2964746952056885 seconds for one epoch ---
--- 0.5588231086730957 seconds for one epoch ---
--- 0.18489646911621094 seconds for one epoch ---
--- 0.6088945865631104 seconds for one epoch ---
--- 0.3021867275238037 seconds for one epoch ---
--- 0.6363985538482666 seconds for one epoch ---
--- 0.2940394878387451 seconds for one epoch ---
--- 0.6248137950897217 seconds for one epoch ---
--- 0.31274914741516113 seconds for one epoch ---
--- 0.621328592300415 seconds for one epoch ---
--- 0.3119328022003174 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06014771]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09293654]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0885261]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.650484 ]
 [ 0.       ]]
--- 0.2612922191619873 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5657.84619140625, (2799.6716, 2.0674708, 2855.9216, 0.18535383)
   validation loss 1335.7730712890625, (930.0878, 0.107574776, 405.39233, 0.18535383)
decoder loss ratio: 36033.217222, decoder SINDy loss  ratio: 0.875096
--- 0.31529903411865234 seconds for one epoch ---
--- 0.6206052303314209 seconds for one epoch ---
--- 0.23347854614257812 seconds for one epoch ---
--- 0.6420822143554688 seconds for one epoch ---
--- 0.29874086380004883 seconds for one epoch ---
--- 0.7098081111907959 seconds for one epoch ---
--- 0.3077256679534912 seconds for one epoch ---
--- 0.6230552196502686 seconds for one epoch ---
--- 0.2837996482849121 seconds for one epoch ---
--- 0.6387512683868408 seconds for one epoch ---
--- 0.2914254665374756 seconds for one epoch ---
--- 0.6320934295654297 seconds for one epoch ---
--- 0.2791886329650879 seconds for one epoch ---
--- 0.6117327213287354 seconds for one epoch ---
--- 0.30371975898742676 seconds for one epoch ---
--- 0.6453242301940918 seconds for one epoch ---
--- 0.30322837829589844 seconds for one epoch ---
--- 0.6510634422302246 seconds for one epoch ---
--- 0.21806073188781738 seconds for one epoch ---
--- 0.6303255558013916 seconds for one epoch ---
--- 0.3061552047729492 seconds for one epoch ---
--- 0.6442852020263672 seconds for one epoch ---
--- 0.3082258701324463 seconds for one epoch ---
--- 0.6581480503082275 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05922785]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09455556]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0561372]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.7340007]
 [ 0.       ]]
--- 0.30268335342407227 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3453.7373046875, (1621.908, 1.0723877, 1830.5708, 0.18606363)
   validation loss 1268.8648681640625, (868.3442, 0.13480556, 400.1998, 0.18606363)
decoder loss ratio: 33641.160938, decoder SINDy loss  ratio: 0.863888
--- 0.24330949783325195 seconds for one epoch ---
--- 0.30150890350341797 seconds for one epoch ---
--- 0.6291749477386475 seconds for one epoch ---
--- 0.3044862747192383 seconds for one epoch ---
--- 0.6254289150238037 seconds for one epoch ---
--- 0.24710416793823242 seconds for one epoch ---
--- 0.6817960739135742 seconds for one epoch ---
--- 0.2903122901916504 seconds for one epoch ---
--- 0.6553223133087158 seconds for one epoch ---
--- 0.30649805068969727 seconds for one epoch ---
--- 0.6715030670166016 seconds for one epoch ---
--- 0.300051212310791 seconds for one epoch ---
--- 0.6457779407501221 seconds for one epoch ---
--- 0.2919919490814209 seconds for one epoch ---
--- 0.6466591358184814 seconds for one epoch ---
--- 0.30484437942504883 seconds for one epoch ---
--- 0.6496093273162842 seconds for one epoch ---
--- 0.2919137477874756 seconds for one epoch ---
--- 0.6295139789581299 seconds for one epoch ---
--- 0.2987048625946045 seconds for one epoch ---
--- 0.641690731048584 seconds for one epoch ---
--- 0.20327377319335938 seconds for one epoch ---
--- 0.649207353591919 seconds for one epoch ---
--- 0.299466609954834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05805289]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0957921 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0079682]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.7991815]
 [ 0.       ]]
--- 0.2504901885986328 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8248.3515625, (1634.5934, 1.8106372, 6611.761, 0.18622789)
   validation loss 999.309326171875, (699.1815, 0.13851142, 299.8031, 0.18622789)
decoder loss ratio: 27087.505861, decoder SINDy loss  ratio: 0.647167
--- 0.305112361907959 seconds for one epoch ---
--- 0.6383445262908936 seconds for one epoch ---
--- 0.3062269687652588 seconds for one epoch ---
--- 0.6425416469573975 seconds for one epoch ---
--- 0.3152151107788086 seconds for one epoch ---
--- 0.6478872299194336 seconds for one epoch ---
--- 0.29835057258605957 seconds for one epoch ---
--- 0.6424469947814941 seconds for one epoch ---
--- 0.1815204620361328 seconds for one epoch ---
--- 0.6778273582458496 seconds for one epoch ---
--- 0.30150842666625977 seconds for one epoch ---
--- 0.637387752532959 seconds for one epoch ---
--- 0.30639123916625977 seconds for one epoch ---
--- 0.6628456115722656 seconds for one epoch ---
--- 0.30272746086120605 seconds for one epoch ---
--- 0.6692698001861572 seconds for one epoch ---
--- 0.3183252811431885 seconds for one epoch ---
--- 0.6492595672607422 seconds for one epoch ---
--- 0.2946455478668213 seconds for one epoch ---
--- 0.6708271503448486 seconds for one epoch ---
--- 0.29122328758239746 seconds for one epoch ---
--- 0.6845698356628418 seconds for one epoch ---
--- 0.2972402572631836 seconds for one epoch ---
--- 0.6711289882659912 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05820693]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09787144]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0283526]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8972878]
 [ 0.       ]]
--- 0.2915527820587158 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7607.56298828125, (2088.345, 1.5480964, 5517.4824, 0.18747285)
   validation loss 1558.017822265625, (1213.6357, 0.16559294, 344.02893, 0.18747285)
decoder loss ratio: 47018.355617, decoder SINDy loss  ratio: 0.742635
--- 0.26784372329711914 seconds for one epoch ---
--- 0.3015468120574951 seconds for one epoch ---
--- 0.6750776767730713 seconds for one epoch ---
--- 0.2993745803833008 seconds for one epoch ---
--- 0.6815023422241211 seconds for one epoch ---
--- 0.2925903797149658 seconds for one epoch ---
--- 0.672741174697876 seconds for one epoch ---
--- 0.30625295639038086 seconds for one epoch ---
--- 0.6768579483032227 seconds for one epoch ---
--- 0.31011366844177246 seconds for one epoch ---
--- 0.6786787509918213 seconds for one epoch ---
--- 0.30567026138305664 seconds for one epoch ---
--- 0.675225019454956 seconds for one epoch ---
--- 0.30849575996398926 seconds for one epoch ---
--- 0.6865384578704834 seconds for one epoch ---
--- 0.30875682830810547 seconds for one epoch ---
--- 0.691277265548706 seconds for one epoch ---
--- 0.3029978275299072 seconds for one epoch ---
--- 0.6744012832641602 seconds for one epoch ---
--- 0.29575324058532715 seconds for one epoch ---
--- 0.7037076950073242 seconds for one epoch ---
--- 0.3099353313446045 seconds for one epoch ---
--- 0.672337532043457 seconds for one epoch ---
--- 0.300173282623291 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05801095]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09992606]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0285523]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9927964]
 [ 0.       ]]
--- 0.26010847091674805 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5052.0849609375, (2333.507, 1.0400202, 2717.349, 0.18849388)
   validation loss 2420.696533203125, (1928.7936, 0.19027604, 491.52408, 0.18849388)
decoder loss ratio: 74724.811787, decoder SINDy loss  ratio: 1.061024
--- 0.3040344715118408 seconds for one epoch ---
--- 0.6748061180114746 seconds for one epoch ---
--- 0.2986786365509033 seconds for one epoch ---
--- 0.6623740196228027 seconds for one epoch ---
--- 0.28177404403686523 seconds for one epoch ---
--- 0.6962897777557373 seconds for one epoch ---
--- 0.30384087562561035 seconds for one epoch ---
--- 0.6827199459075928 seconds for one epoch ---
--- 0.3100106716156006 seconds for one epoch ---
--- 0.6812939643859863 seconds for one epoch ---
--- 0.30895090103149414 seconds for one epoch ---
--- 0.6983180046081543 seconds for one epoch ---
--- 0.28864526748657227 seconds for one epoch ---
--- 0.6954567432403564 seconds for one epoch ---
--- 0.309434175491333 seconds for one epoch ---
--- 0.7024636268615723 seconds for one epoch ---
--- 0.2988088130950928 seconds for one epoch ---
--- 0.6879680156707764 seconds for one epoch ---
--- 0.3046724796295166 seconds for one epoch ---
--- 0.6856987476348877 seconds for one epoch ---
--- 0.31615519523620605 seconds for one epoch ---
--- 0.6826508045196533 seconds for one epoch ---
--- 0.30193495750427246 seconds for one epoch ---
--- 0.6906402111053467 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05751968]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10275232]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0102253]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1183803]
 [ 0.       ]]
--- 0.2889370918273926 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3086.456787109375, (1520.4152, 0.30878437, 1565.5432, 0.18968327)
   validation loss 1276.430419921875, (930.0722, 0.27330706, 345.89514, 0.18968327)
decoder loss ratio: 36032.611882, decoder SINDy loss  ratio: 0.746663
--- 0.272594690322876 seconds for one epoch ---
--- 0.3018209934234619 seconds for one epoch ---
--- 0.6816599369049072 seconds for one epoch ---
--- 0.29253268241882324 seconds for one epoch ---
--- 0.7054548263549805 seconds for one epoch ---
--- 0.30032992362976074 seconds for one epoch ---
--- 0.6744167804718018 seconds for one epoch ---
--- 0.306624174118042 seconds for one epoch ---
--- 0.6941289901733398 seconds for one epoch ---
--- 0.30324625968933105 seconds for one epoch ---
--- 0.5777201652526855 seconds for one epoch ---
--- 0.22646188735961914 seconds for one epoch ---
--- 0.6760482788085938 seconds for one epoch ---
--- 0.31381964683532715 seconds for one epoch ---
--- 0.6921069622039795 seconds for one epoch ---
--- 0.3029613494873047 seconds for one epoch ---
--- 0.7096641063690186 seconds for one epoch ---
--- 0.2980387210845947 seconds for one epoch ---
--- 0.6866929531097412 seconds for one epoch ---
--- 0.31081104278564453 seconds for one epoch ---
--- 0.7043144702911377 seconds for one epoch ---
--- 0.3133113384246826 seconds for one epoch ---
--- 0.7777504920959473 seconds for one epoch ---
--- 0.3220205307006836 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05721106]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1052087 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0010394]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2270575]
 [ 0.       ]]
--- 0.2604951858520508 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3345.744384765625, (1566.2572, 0.5908147, 1778.7058, 0.19064493)
   validation loss 1077.5517578125, (762.7375, 0.227847, 314.3957, 0.19064493)
decoder loss ratio: 29549.774448, decoder SINDy loss  ratio: 0.678667
--- 0.28797125816345215 seconds for one epoch ---
--- 0.6979763507843018 seconds for one epoch ---
--- 0.2998931407928467 seconds for one epoch ---
--- 0.6928894519805908 seconds for one epoch ---
--- 0.30886149406433105 seconds for one epoch ---
--- 0.7077322006225586 seconds for one epoch ---
--- 0.30902910232543945 seconds for one epoch ---
--- 0.7406487464904785 seconds for one epoch ---
--- 0.3218507766723633 seconds for one epoch ---
--- 0.7106373310089111 seconds for one epoch ---
--- 0.2931497097015381 seconds for one epoch ---
--- 0.698218584060669 seconds for one epoch ---
--- 0.3078267574310303 seconds for one epoch ---
--- 0.7223730087280273 seconds for one epoch ---
--- 0.29239749908447266 seconds for one epoch ---
--- 0.7037343978881836 seconds for one epoch ---
--- 0.3106660842895508 seconds for one epoch ---
--- 0.7114496231079102 seconds for one epoch ---
--- 0.3245406150817871 seconds for one epoch ---
--- 0.6818015575408936 seconds for one epoch ---
--- 0.28421759605407715 seconds for one epoch ---
--- 0.7082829475402832 seconds for one epoch ---
--- 0.3024721145629883 seconds for one epoch ---
--- 0.7131500244140625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05687043]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10761806]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.988368 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3319628]
 [ 0.       ]]
--- 0.294344425201416 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5477.28076171875, (2511.7332, 1.8327615, 2963.5234, 0.1915879)
   validation loss 1166.6005859375, (815.11536, 0.25804815, 351.03568, 0.1915879)
decoder loss ratio: 31578.984011, decoder SINDy loss  ratio: 0.757760
--- 0.26395583152770996 seconds for one epoch ---
--- 0.30189943313598633 seconds for one epoch ---
--- 0.7119476795196533 seconds for one epoch ---
--- 0.3011515140533447 seconds for one epoch ---
--- 0.7085521221160889 seconds for one epoch ---
--- 0.3045356273651123 seconds for one epoch ---
--- 0.6127841472625732 seconds for one epoch ---
--- 0.17524075508117676 seconds for one epoch ---
--- 0.713153600692749 seconds for one epoch ---
--- 0.31650567054748535 seconds for one epoch ---
--- 0.7340750694274902 seconds for one epoch ---
--- 0.29631853103637695 seconds for one epoch ---
--- 0.7216830253601074 seconds for one epoch ---
--- 0.4670693874359131 seconds for one epoch ---
--- 0.7151670455932617 seconds for one epoch ---
--- 0.2834479808807373 seconds for one epoch ---
--- 0.7442770004272461 seconds for one epoch ---
--- 0.2939763069152832 seconds for one epoch ---
--- 0.7194623947143555 seconds for one epoch ---
--- 0.31803035736083984 seconds for one epoch ---
--- 0.7367911338806152 seconds for one epoch ---
--- 0.30649638175964355 seconds for one epoch ---
--- 0.6980800628662109 seconds for one epoch ---
--- 0.1611471176147461 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05654457]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1098147 ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.97595346]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.4272134 ]
 [ 0.        ]]
--- 0.2473306655883789 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3383.43798828125, (1608.2129, 0.7012845, 1774.3315, 0.192316)
   validation loss 1100.9974365234375, (774.90137, 0.24491523, 325.65884, 0.192316)
decoder loss ratio: 30021.024253, decoder SINDy loss  ratio: 0.702980
--- 0.29957032203674316 seconds for one epoch ---
--- 0.7314455509185791 seconds for one epoch ---
--- 0.29857587814331055 seconds for one epoch ---
--- 0.6843137741088867 seconds for one epoch ---
--- 0.2722609043121338 seconds for one epoch ---
--- 0.7190368175506592 seconds for one epoch ---
--- 0.2950284481048584 seconds for one epoch ---
--- 0.7401072978973389 seconds for one epoch ---
--- 0.2899336814880371 seconds for one epoch ---
--- 0.706298828125 seconds for one epoch ---
--- 0.2967221736907959 seconds for one epoch ---
--- 0.7386221885681152 seconds for one epoch ---
--- 0.29687070846557617 seconds for one epoch ---
--- 0.7267353534698486 seconds for one epoch ---
--- 0.29822301864624023 seconds for one epoch ---
--- 0.7352988719940186 seconds for one epoch ---
--- 0.3051726818084717 seconds for one epoch ---
--- 0.7322969436645508 seconds for one epoch ---
--- 0.30245184898376465 seconds for one epoch ---
--- 0.7155287265777588 seconds for one epoch ---
--- 0.19679808616638184 seconds for one epoch ---
--- 0.7401063442230225 seconds for one epoch ---
--- 0.2980921268463135 seconds for one epoch ---
--- 0.7377021312713623 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05616896]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11332777]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9595738]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5757844]
 [ 0.       ]]
--- 0.29646944999694824 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4180.82177734375, (2397.3655, 2.138356, 1781.1245, 0.19344074)
   validation loss 3274.703125, (2906.807, 0.2669133, 367.43597, 0.19344074)
decoder loss ratio: 112614.745154, decoder SINDy loss  ratio: 0.793162
--- 0.2697296142578125 seconds for one epoch ---
--- 0.30365490913391113 seconds for one epoch ---
--- 0.7476170063018799 seconds for one epoch ---
--- 0.2982790470123291 seconds for one epoch ---
--- 0.7299771308898926 seconds for one epoch ---
--- 0.2903571128845215 seconds for one epoch ---
--- 0.7197318077087402 seconds for one epoch ---
--- 0.2885730266571045 seconds for one epoch ---
--- 0.7339701652526855 seconds for one epoch ---
--- 0.301560640335083 seconds for one epoch ---
--- 0.7421352863311768 seconds for one epoch ---
--- 0.2926163673400879 seconds for one epoch ---
--- 0.7300705909729004 seconds for one epoch ---
--- 0.2492218017578125 seconds for one epoch ---
--- 0.7544193267822266 seconds for one epoch ---
--- 0.3013286590576172 seconds for one epoch ---
--- 0.7459073066711426 seconds for one epoch ---
--- 0.30393457412719727 seconds for one epoch ---
--- 0.7585234642028809 seconds for one epoch ---
--- 0.3019998073577881 seconds for one epoch ---
--- 0.771672248840332 seconds for one epoch ---
--- 0.30247926712036133 seconds for one epoch ---
--- 0.7368185520172119 seconds for one epoch ---
--- 0.30191802978515625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05599499]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11588023]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9538863]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.6839645]
 [ 0.       ]]
--- 0.2532658576965332 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2852.848876953125, (2108.646, 0.11956507, 743.8892, 0.19401821)
   validation loss 990.2835083007812, (691.3696, 0.38064948, 298.3392, 0.19401821)
decoder loss ratio: 26784.859694, decoder SINDy loss  ratio: 0.644007
--- 0.3080410957336426 seconds for one epoch ---
--- 0.7290103435516357 seconds for one epoch ---
--- 0.2992417812347412 seconds for one epoch ---
--- 0.7316129207611084 seconds for one epoch ---
--- 0.30348873138427734 seconds for one epoch ---
--- 0.7527251243591309 seconds for one epoch ---
--- 0.30024027824401855 seconds for one epoch ---
--- 0.7376284599304199 seconds for one epoch ---
--- 0.30704188346862793 seconds for one epoch ---
--- 0.7400245666503906 seconds for one epoch ---
--- 0.29351305961608887 seconds for one epoch ---
--- 0.7086431980133057 seconds for one epoch ---
--- 0.29253387451171875 seconds for one epoch ---
--- 0.7553825378417969 seconds for one epoch ---
--- 0.28502631187438965 seconds for one epoch ---
--- 0.7559170722961426 seconds for one epoch ---
--- 0.3031127452850342 seconds for one epoch ---
--- 0.7494425773620605 seconds for one epoch ---
--- 0.2982602119445801 seconds for one epoch ---
--- 0.7452836036682129 seconds for one epoch ---
--- 0.2911827564239502 seconds for one epoch ---
--- 0.7527470588684082 seconds for one epoch ---
--- 0.28627443313598633 seconds for one epoch ---
--- 0.7852728366851807 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05604133]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11942921]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9594646]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.8324559]
 [ 0.       ]]
--- 0.2894742488861084 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3676.345703125, (1883.8024, 0.73198384, 1791.6165, 0.19478518)
   validation loss 1767.59130859375, (1445.9834, 0.32054108, 321.0926, 0.19478518)
decoder loss ratio: 56019.907193, decoder SINDy loss  ratio: 0.693124
THRESHOLDING: 1 active coefficients
--- 0.7613320350646973 seconds for one epoch ---
--- 0.30524396896362305 seconds for one epoch ---
--- 0.7548208236694336 seconds for one epoch ---
--- 0.3026309013366699 seconds for one epoch ---
--- 0.7729308605194092 seconds for one epoch ---
--- 0.3014638423919678 seconds for one epoch ---
--- 0.768496036529541 seconds for one epoch ---
--- 0.30129003524780273 seconds for one epoch ---
--- 0.7530794143676758 seconds for one epoch ---
--- 0.3134293556213379 seconds for one epoch ---
--- 0.7706310749053955 seconds for one epoch ---
--- 0.23929524421691895 seconds for one epoch ---
--- 0.8092477321624756 seconds for one epoch ---
--- 0.3063478469848633 seconds for one epoch ---
--- 0.7552034854888916 seconds for one epoch ---
--- 0.28644657135009766 seconds for one epoch ---
--- 0.7723488807678223 seconds for one epoch ---
--- 0.2983832359313965 seconds for one epoch ---
--- 0.7576260566711426 seconds for one epoch ---
--- 0.2714250087738037 seconds for one epoch ---
--- 0.7551059722900391 seconds for one epoch ---
--- 0.3073611259460449 seconds for one epoch ---
--- 0.7723548412322998 seconds for one epoch ---
--- 0.3041501045227051 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.125608]
 [0.      ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.089167]
 [ 0.      ]]
--- 0.26282358169555664 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3438.853271484375, (1487.6395, 4.789703, 1946.3561, 0.0681444)
   validation loss 1057.8270263671875, (670.84906, 0.2684246, 386.64145, 0.0681444)
decoder loss ratio: 25989.857232, decoder SINDy loss  ratio: 0.834620
--- 0.3069641590118408 seconds for one epoch ---
--- 0.7571573257446289 seconds for one epoch ---
--- 0.3001382350921631 seconds for one epoch ---
--- 0.763157844543457 seconds for one epoch ---
--- 0.2934844493865967 seconds for one epoch ---
--- 0.805328369140625 seconds for one epoch ---
--- 0.29936814308166504 seconds for one epoch ---
--- 0.7552638053894043 seconds for one epoch ---
--- 0.30069518089294434 seconds for one epoch ---
--- 0.7894637584686279 seconds for one epoch ---
--- 0.3004176616668701 seconds for one epoch ---
--- 0.7650613784790039 seconds for one epoch ---
--- 0.3007352352142334 seconds for one epoch ---
--- 0.7947025299072266 seconds for one epoch ---
--- 0.3001394271850586 seconds for one epoch ---
--- 0.772526741027832 seconds for one epoch ---
--- 0.28915953636169434 seconds for one epoch ---
--- 0.7832298278808594 seconds for one epoch ---
--- 0.31698083877563477 seconds for one epoch ---
--- 0.7820072174072266 seconds for one epoch ---
--- 0.3149857521057129 seconds for one epoch ---
--- 0.7907650470733643 seconds for one epoch ---
--- 0.3076000213623047 seconds for one epoch ---
--- 0.7678773403167725 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13237926]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.371074]
 [ 0.      ]]
--- 0.30226826667785645 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4326.2900390625, (1683.2561, 2.654469, 2640.3076, 0.071564294)
   validation loss 1342.7239990234375, (1001.1747, 0.2720464, 341.20578, 0.071564294)
decoder loss ratio: 38787.245320, decoder SINDy loss  ratio: 0.736541
--- 0.26756739616394043 seconds for one epoch ---
--- 0.29685258865356445 seconds for one epoch ---
--- 0.6998953819274902 seconds for one epoch ---
--- 0.20267558097839355 seconds for one epoch ---
--- 0.8435788154602051 seconds for one epoch ---
--- 0.30829405784606934 seconds for one epoch ---
--- 0.8582968711853027 seconds for one epoch ---
--- 0.30437302589416504 seconds for one epoch ---
--- 0.7802939414978027 seconds for one epoch ---
--- 0.3042769432067871 seconds for one epoch ---
--- 0.7884979248046875 seconds for one epoch ---
--- 0.2933471202850342 seconds for one epoch ---
--- 0.7926065921783447 seconds for one epoch ---
--- 0.29502272605895996 seconds for one epoch ---
--- 0.798321008682251 seconds for one epoch ---
--- 0.3054525852203369 seconds for one epoch ---
--- 0.7945113182067871 seconds for one epoch ---
--- 0.2944045066833496 seconds for one epoch ---
--- 0.8146686553955078 seconds for one epoch ---
--- 0.2966279983520508 seconds for one epoch ---
--- 0.7921414375305176 seconds for one epoch ---
--- 0.3016080856323242 seconds for one epoch ---
--- 0.7919182777404785 seconds for one epoch ---
--- 0.3119659423828125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13873373]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.638214]
 [ 0.      ]]
--- 0.25948190689086914 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2778.7724609375, (1251.6017, 2.2441852, 1524.8519, 0.074717514)
   validation loss 1288.995361328125, (971.9823, 0.36475804, 316.57358, 0.074717514)
decoder loss ratio: 37656.281730, decoder SINDy loss  ratio: 0.683369
--- 0.3136880397796631 seconds for one epoch ---
--- 0.8054888248443604 seconds for one epoch ---
--- 0.310178279876709 seconds for one epoch ---
--- 0.7795250415802002 seconds for one epoch ---
--- 0.30141615867614746 seconds for one epoch ---
--- 0.7733864784240723 seconds for one epoch ---
--- 0.30836057662963867 seconds for one epoch ---
--- 0.8105912208557129 seconds for one epoch ---
--- 0.2938220500946045 seconds for one epoch ---
--- 0.7909939289093018 seconds for one epoch ---
--- 0.30551743507385254 seconds for one epoch ---
--- 0.811119794845581 seconds for one epoch ---
--- 0.29187583923339844 seconds for one epoch ---
--- 0.7993597984313965 seconds for one epoch ---
--- 0.3033730983734131 seconds for one epoch ---
--- 0.804119348526001 seconds for one epoch ---
--- 0.301027774810791 seconds for one epoch ---
--- 0.7873446941375732 seconds for one epoch ---
--- 0.29658031463623047 seconds for one epoch ---
--- 0.820831298828125 seconds for one epoch ---
--- 0.303879976272583 seconds for one epoch ---
--- 0.7903587818145752 seconds for one epoch ---
--- 0.30427050590515137 seconds for one epoch ---
--- 0.7982187271118164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14503975]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.9070935]
 [ 0.       ]]
--- 0.29569506645202637 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2277.307373046875, (1353.0248, 1.1491771, 923.05554, 0.077989)
   validation loss 857.983154296875, (553.86914, 0.34133002, 303.69467, 0.077989)
decoder loss ratio: 21457.852067, decoder SINDy loss  ratio: 0.655568
--- 0.2635385990142822 seconds for one epoch ---
--- 0.2920079231262207 seconds for one epoch ---
--- 0.8091251850128174 seconds for one epoch ---
--- 0.2871251106262207 seconds for one epoch ---
--- 0.828822135925293 seconds for one epoch ---
--- 0.2981746196746826 seconds for one epoch ---
--- 0.8081324100494385 seconds for one epoch ---
--- 0.30881810188293457 seconds for one epoch ---
--- 0.8157715797424316 seconds for one epoch ---
--- 0.3062291145324707 seconds for one epoch ---
--- 0.8070337772369385 seconds for one epoch ---
--- 0.31470656394958496 seconds for one epoch ---
--- 0.8084762096405029 seconds for one epoch ---
--- 0.30953073501586914 seconds for one epoch ---
--- 0.8134043216705322 seconds for one epoch ---
--- 0.30100202560424805 seconds for one epoch ---
--- 0.8139786720275879 seconds for one epoch ---
--- 0.30992627143859863 seconds for one epoch ---
--- 0.8162789344787598 seconds for one epoch ---
--- 0.31137681007385254 seconds for one epoch ---
--- 0.8077304363250732 seconds for one epoch ---
--- 0.31267666816711426 seconds for one epoch ---
--- 0.8035752773284912 seconds for one epoch ---
--- 0.30608510971069336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15117024]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.1739836]
 [ 0.       ]]
--- 0.2601184844970703 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3936.876953125, (1754.3601, 1.0827261, 2181.353, 0.08116037)
   validation loss 1519.5330810546875, (1161.7015, 0.3255718, 357.42487, 0.08116037)
decoder loss ratio: 45006.334388, decoder SINDy loss  ratio: 0.771552
--- 0.3060483932495117 seconds for one epoch ---
--- 0.7871956825256348 seconds for one epoch ---
--- 0.29229211807250977 seconds for one epoch ---
--- 0.806351900100708 seconds for one epoch ---
--- 0.30104899406433105 seconds for one epoch ---
--- 0.8012237548828125 seconds for one epoch ---
--- 0.3079075813293457 seconds for one epoch ---
--- 0.8099801540374756 seconds for one epoch ---
--- 0.30518150329589844 seconds for one epoch ---
--- 0.8131625652313232 seconds for one epoch ---
--- 0.2669670581817627 seconds for one epoch ---
--- 0.8371231555938721 seconds for one epoch ---
--- 0.2968461513519287 seconds for one epoch ---
--- 0.8173625469207764 seconds for one epoch ---
--- 0.2974376678466797 seconds for one epoch ---
--- 0.8599488735198975 seconds for one epoch ---
--- 0.3042757511138916 seconds for one epoch ---
--- 0.8387846946716309 seconds for one epoch ---
--- 0.302384614944458 seconds for one epoch ---
--- 0.8275105953216553 seconds for one epoch ---
--- 0.30412745475769043 seconds for one epoch ---
--- 0.8153200149536133 seconds for one epoch ---
--- 0.3028993606567383 seconds for one epoch ---
--- 0.8446247577667236 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15748876]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-5.456582]
 [-0.      ]]
--- 0.29662108421325684 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2787.56005859375, (1103.1627, 1.5713012, 1682.7416, 0.0845053)
   validation loss 1503.56298828125, (1083.2579, 0.43210164, 419.78848, 0.0845053)
decoder loss ratio: 41967.293004, decoder SINDy loss  ratio: 0.906172
--- 0.26232075691223145 seconds for one epoch ---
--- 0.295513391494751 seconds for one epoch ---
--- 0.8278045654296875 seconds for one epoch ---
--- 0.2742905616760254 seconds for one epoch ---
--- 0.824528694152832 seconds for one epoch ---
--- 0.2956068515777588 seconds for one epoch ---
--- 0.8099441528320312 seconds for one epoch ---
--- 0.2941935062408447 seconds for one epoch ---
--- 0.8307154178619385 seconds for one epoch ---
--- 0.2996225357055664 seconds for one epoch ---
--- 0.8482329845428467 seconds for one epoch ---
--- 0.3103666305541992 seconds for one epoch ---
--- 0.8406693935394287 seconds for one epoch ---
--- 0.29967570304870605 seconds for one epoch ---
--- 0.8497443199157715 seconds for one epoch ---
--- 0.2987544536590576 seconds for one epoch ---
--- 0.9111509323120117 seconds for one epoch ---
--- 0.3035745620727539 seconds for one epoch ---
--- 0.833073616027832 seconds for one epoch ---
--- 0.30295562744140625 seconds for one epoch ---
--- 0.8301787376403809 seconds for one epoch ---
--- 0.31244874000549316 seconds for one epoch ---
--- 0.8419482707977295 seconds for one epoch ---
--- 0.3162093162536621 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16293816]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.7086773]
 [ 0.       ]]
--- 0.2668790817260742 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5643.18994140625, (2461.0522, 1.0754308, 3180.975, 0.08743072)
   validation loss 1086.2001953125, (771.5035, 0.30756938, 314.30173, 0.08743072)
decoder loss ratio: 29889.384166, decoder SINDy loss  ratio: 0.678464
--- 0.29715538024902344 seconds for one epoch ---
--- 0.8287734985351562 seconds for one epoch ---
--- 0.3043181896209717 seconds for one epoch ---
--- 0.8431031703948975 seconds for one epoch ---
--- 0.30271339416503906 seconds for one epoch ---
--- 0.8341245651245117 seconds for one epoch ---
--- 0.30991601943969727 seconds for one epoch ---
--- 0.7696511745452881 seconds for one epoch ---
--- 0.3054203987121582 seconds for one epoch ---
--- 0.841975212097168 seconds for one epoch ---
--- 0.32723331451416016 seconds for one epoch ---
--- 0.8127856254577637 seconds for one epoch ---
--- 0.293245792388916 seconds for one epoch ---
--- 0.8448166847229004 seconds for one epoch ---
--- 0.30155014991760254 seconds for one epoch ---
--- 0.8460991382598877 seconds for one epoch ---
--- 0.30767321586608887 seconds for one epoch ---
--- 0.8388876914978027 seconds for one epoch ---
--- 0.29024457931518555 seconds for one epoch ---
--- 0.846160888671875 seconds for one epoch ---
--- 0.29857373237609863 seconds for one epoch ---
--- 0.8496973514556885 seconds for one epoch ---
--- 0.21608972549438477 seconds for one epoch ---
--- 0.8916373252868652 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16777661]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.9407024]
 [ 0.       ]]
--- 0.29110074043273926 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2998.195556640625, (1837.9205, 1.0468779, 1159.1381, 0.09017487)
   validation loss 1163.2840576171875, (804.91864, 0.28516313, 357.99002, 0.09017487)
decoder loss ratio: 31183.945519, decoder SINDy loss  ratio: 0.772772
--- 0.27304911613464355 seconds for one epoch ---
--- 0.28900957107543945 seconds for one epoch ---
--- 0.8321239948272705 seconds for one epoch ---
--- 0.2981376647949219 seconds for one epoch ---
--- 0.8541920185089111 seconds for one epoch ---
--- 0.3029935359954834 seconds for one epoch ---
--- 0.8575809001922607 seconds for one epoch ---
--- 0.2890045642852783 seconds for one epoch ---
--- 0.8530404567718506 seconds for one epoch ---
--- 0.3014199733734131 seconds for one epoch ---
--- 0.869483470916748 seconds for one epoch ---
--- 0.3048253059387207 seconds for one epoch ---
--- 0.8363223075866699 seconds for one epoch ---
--- 0.3122580051422119 seconds for one epoch ---
--- 0.8664553165435791 seconds for one epoch ---
--- 0.29381322860717773 seconds for one epoch ---
--- 0.8371987342834473 seconds for one epoch ---
--- 0.30350327491760254 seconds for one epoch ---
--- 0.8492431640625 seconds for one epoch ---
--- 0.2977919578552246 seconds for one epoch ---
--- 0.8359932899475098 seconds for one epoch ---
--- 0.30793023109436035 seconds for one epoch ---
--- 0.856558084487915 seconds for one epoch ---
--- 0.2995941638946533 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17218125]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-6.160411]
 [-0.      ]]
--- 0.23798346519470215 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3374.70849609375, (1389.7628, 3.2192047, 1981.6338, 0.09265579)
   validation loss 1227.8751220703125, (898.9874, 0.27937555, 328.51572, 0.09265579)
decoder loss ratio: 34828.333623, decoder SINDy loss  ratio: 0.709147
--- 0.3077378273010254 seconds for one epoch ---
--- 0.9323751926422119 seconds for one epoch ---
--- 0.3083677291870117 seconds for one epoch ---
--- 0.8426523208618164 seconds for one epoch ---
--- 0.29689502716064453 seconds for one epoch ---
--- 0.7733910083770752 seconds for one epoch ---
--- 0.19733572006225586 seconds for one epoch ---
--- 0.8502676486968994 seconds for one epoch ---
--- 0.28145933151245117 seconds for one epoch ---
--- 0.8518598079681396 seconds for one epoch ---
--- 0.29335880279541016 seconds for one epoch ---
--- 0.875504732131958 seconds for one epoch ---
--- 0.2980647087097168 seconds for one epoch ---
--- 0.9643583297729492 seconds for one epoch ---
--- 0.3015158176422119 seconds for one epoch ---
--- 0.9715583324432373 seconds for one epoch ---
--- 0.29490065574645996 seconds for one epoch ---
--- 0.9866485595703125 seconds for one epoch ---
--- 0.28858113288879395 seconds for one epoch ---
--- 1.0272972583770752 seconds for one epoch ---
--- 0.20235562324523926 seconds for one epoch ---
--- 0.8682224750518799 seconds for one epoch ---
--- 0.2978804111480713 seconds for one epoch ---
--- 0.8659429550170898 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17636177]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.3780823]
 [-0.       ]]
--- 0.291363000869751 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3107.821533203125, (1353.9562, 2.6716516, 1751.0985, 0.09518816)
   validation loss 1163.89794921875, (850.0012, 0.30161732, 313.49994, 0.09518816)
decoder loss ratio: 32930.522957, decoder SINDy loss  ratio: 0.676734
--- 0.27068138122558594 seconds for one epoch ---
--- 0.31159138679504395 seconds for one epoch ---
--- 0.9411108493804932 seconds for one epoch ---
--- 0.2908773422241211 seconds for one epoch ---
--- 0.9877333641052246 seconds for one epoch ---
--- 0.27417969703674316 seconds for one epoch ---
--- 0.9945712089538574 seconds for one epoch ---
--- 0.3099806308746338 seconds for one epoch ---
--- 0.9746286869049072 seconds for one epoch ---
--- 0.2758064270019531 seconds for one epoch ---
--- 0.9483733177185059 seconds for one epoch ---
--- 0.3139944076538086 seconds for one epoch ---
--- 0.8595607280731201 seconds for one epoch ---
--- 0.29938268661499023 seconds for one epoch ---
--- 0.8662679195404053 seconds for one epoch ---
--- 0.30684971809387207 seconds for one epoch ---
--- 0.8756780624389648 seconds for one epoch ---
--- 0.47737646102905273 seconds for one epoch ---
--- 0.8796463012695312 seconds for one epoch ---
--- 0.29393720626831055 seconds for one epoch ---
--- 0.8769474029541016 seconds for one epoch ---
--- 0.2639286518096924 seconds for one epoch ---
--- 0.8963360786437988 seconds for one epoch ---
--- 0.30304622650146484 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18055677]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.607779]
 [ 0.      ]]
--- 0.25876784324645996 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2045.399169921875, (1234.1305, 0.5212863, 810.64966, 0.09779861)
   validation loss 2806.884521484375, (2281.144, 0.24220796, 525.40027, 0.09779861)
decoder loss ratio: 88375.480465, decoder SINDy loss  ratio: 1.134150
--- 0.3042123317718506 seconds for one epoch ---
--- 0.8749406337738037 seconds for one epoch ---
--- 0.29424023628234863 seconds for one epoch ---
--- 0.8718218803405762 seconds for one epoch ---
--- 0.2988884449005127 seconds for one epoch ---
--- 0.86480712890625 seconds for one epoch ---
--- 0.29623937606811523 seconds for one epoch ---
--- 0.877178430557251 seconds for one epoch ---
--- 0.30060338973999023 seconds for one epoch ---
--- 0.9264688491821289 seconds for one epoch ---
--- 0.298828125 seconds for one epoch ---
--- 1.004831075668335 seconds for one epoch ---
--- 0.18097901344299316 seconds for one epoch ---
--- 0.9498727321624756 seconds for one epoch ---
--- 0.3029603958129883 seconds for one epoch ---
--- 0.8883905410766602 seconds for one epoch ---
--- 0.3014945983886719 seconds for one epoch ---
--- 0.9010875225067139 seconds for one epoch ---
--- 0.29885101318359375 seconds for one epoch ---
--- 0.890427827835083 seconds for one epoch ---
--- 0.29229187965393066 seconds for one epoch ---
--- 0.8972718715667725 seconds for one epoch ---
--- 0.2952396869659424 seconds for one epoch ---
--- 0.8992676734924316 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18401036]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-6.807495]
 [-0.      ]]
--- 0.30080246925354004 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2827.48291015625, (1177.5026, 4.291863, 1645.5883, 0.09998956)
   validation loss 832.0162353515625, (506.69186, 0.31800234, 324.90643, 0.09998956)
decoder loss ratio: 19630.122468, decoder SINDy loss  ratio: 0.701356
--- 0.27149224281311035 seconds for one epoch ---
--- 0.18001055717468262 seconds for one epoch ---
--- 0.8706648349761963 seconds for one epoch ---
--- 0.3126373291015625 seconds for one epoch ---
--- 0.8477754592895508 seconds for one epoch ---
--- 0.29512619972229004 seconds for one epoch ---
--- 0.8995664119720459 seconds for one epoch ---
--- 0.3015596866607666 seconds for one epoch ---
--- 0.9671862125396729 seconds for one epoch ---
--- 0.30830931663513184 seconds for one epoch ---
--- 1.0348186492919922 seconds for one epoch ---
--- 0.30675244331359863 seconds for one epoch ---
--- 1.004622220993042 seconds for one epoch ---
--- 0.31295323371887207 seconds for one epoch ---
--- 0.9088890552520752 seconds for one epoch ---
--- 0.29874324798583984 seconds for one epoch ---
--- 0.8996644020080566 seconds for one epoch ---
--- 0.2974715232849121 seconds for one epoch ---
--- 0.901526689529419 seconds for one epoch ---
--- 0.2863137722015381 seconds for one epoch ---
--- 0.9017612934112549 seconds for one epoch ---
--- 0.29874658584594727 seconds for one epoch ---
--- 0.9366879463195801 seconds for one epoch ---
--- 0.3027215003967285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18745731]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-7.018837]
 [ 0.      ]]
--- 0.24608397483825684 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4219.396484375, (1923.9661, 2.1113482, 2293.2168, 0.10234888)
   validation loss 875.3756103515625, (569.4534, 0.20217392, 305.61768, 0.10234888)
decoder loss ratio: 22061.614500, decoder SINDy loss  ratio: 0.659719
--- 0.2799980640411377 seconds for one epoch ---
--- 0.9060714244842529 seconds for one epoch ---
--- 0.3084392547607422 seconds for one epoch ---
--- 0.9469153881072998 seconds for one epoch ---
--- 0.31261181831359863 seconds for one epoch ---
--- 0.8821794986724854 seconds for one epoch ---
--- 0.32295942306518555 seconds for one epoch ---
--- 0.8943009376525879 seconds for one epoch ---
--- 0.30031275749206543 seconds for one epoch ---
--- 0.9067602157592773 seconds for one epoch ---
--- 0.29810023307800293 seconds for one epoch ---
--- 0.9077057838439941 seconds for one epoch ---
--- 0.29913830757141113 seconds for one epoch ---
--- 0.9237699508666992 seconds for one epoch ---
--- 0.3064088821411133 seconds for one epoch ---
--- 0.9377593994140625 seconds for one epoch ---
--- 0.2980518341064453 seconds for one epoch ---
--- 0.9375355243682861 seconds for one epoch ---
--- 0.2953205108642578 seconds for one epoch ---
--- 0.92716383934021 seconds for one epoch ---
--- 0.29520368576049805 seconds for one epoch ---
--- 0.9048881530761719 seconds for one epoch ---
--- 0.3099346160888672 seconds for one epoch ---
--- 0.9091274738311768 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.191018]
 [0.      ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.2532835]
 [ 0.       ]]
--- 0.28879499435424805 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2059.875244140625, (965.35925, 1.5012392, 1092.9098, 0.10487286)
   validation loss 956.7099609375, (638.8711, 0.2620215, 317.47195, 0.10487286)
decoder loss ratio: 24750.975301, decoder SINDy loss  ratio: 0.685308
--- 0.26931214332580566 seconds for one epoch ---
--- 0.3059365749359131 seconds for one epoch ---
--- 0.9065916538238525 seconds for one epoch ---
--- 0.26256513595581055 seconds for one epoch ---
--- 0.9620866775512695 seconds for one epoch ---
--- 0.28409337997436523 seconds for one epoch ---
--- 0.9454090595245361 seconds for one epoch ---
--- 0.30876684188842773 seconds for one epoch ---
--- 0.9209935665130615 seconds for one epoch ---
--- 0.30021238327026367 seconds for one epoch ---
--- 0.9629032611846924 seconds for one epoch ---
--- 0.32102537155151367 seconds for one epoch ---
--- 0.9218339920043945 seconds for one epoch ---
--- 0.3000946044921875 seconds for one epoch ---
--- 0.8590099811553955 seconds for one epoch ---
--- 0.1445484161376953 seconds for one epoch ---
--- 0.9206955432891846 seconds for one epoch ---
--- 0.30200839042663574 seconds for one epoch ---
--- 0.9562015533447266 seconds for one epoch ---
--- 0.2991814613342285 seconds for one epoch ---
--- 0.9226734638214111 seconds for one epoch ---
--- 0.29399847984313965 seconds for one epoch ---
--- 0.9351210594177246 seconds for one epoch ---
--- 0.3052067756652832 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1935564]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.4335217]
 [-0.       ]]
--- 0.2611231803894043 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5855.28759765625, (2143.6707, 2.1618414, 3709.3484, 0.10686617)
   validation loss 1388.566162109375, (1039.334, 0.21566395, 348.90964, 0.10686617)
decoder loss ratio: 40265.602918, decoder SINDy loss  ratio: 0.753171
--- 0.2943272590637207 seconds for one epoch ---
--- 0.9229192733764648 seconds for one epoch ---
--- 0.27911853790283203 seconds for one epoch ---
--- 0.8967854976654053 seconds for one epoch ---
--- 0.29903531074523926 seconds for one epoch ---
--- 0.9229650497436523 seconds for one epoch ---
--- 0.32073402404785156 seconds for one epoch ---
--- 0.9329800605773926 seconds for one epoch ---
--- 0.32934093475341797 seconds for one epoch ---
--- 0.9281167984008789 seconds for one epoch ---
--- 0.3022475242614746 seconds for one epoch ---
--- 0.9422955513000488 seconds for one epoch ---
--- 0.302501916885376 seconds for one epoch ---
--- 0.9331212043762207 seconds for one epoch ---
--- 0.24981999397277832 seconds for one epoch ---
--- 0.949568510055542 seconds for one epoch ---
--- 0.29622745513916016 seconds for one epoch ---
--- 0.9314701557159424 seconds for one epoch ---
--- 0.2919917106628418 seconds for one epoch ---
--- 0.9483077526092529 seconds for one epoch ---
--- 0.30703115463256836 seconds for one epoch ---
--- 0.9608776569366455 seconds for one epoch ---
--- 0.3263068199157715 seconds for one epoch ---
--- 0.953676700592041 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19583146]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.607018]
 [-0.      ]]
--- 0.30650782585144043 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3796.58935546875, (2275.1733, 6.4282403, 1514.8792, 0.10864689)
   validation loss 1066.2457275390625, (729.8926, 0.2860266, 335.95847, 0.10864689)
decoder loss ratio: 28277.305626, decoder SINDy loss  ratio: 0.725214
--- 0.26903510093688965 seconds for one epoch ---
--- 0.30646681785583496 seconds for one epoch ---
--- 0.8215291500091553 seconds for one epoch ---
--- 0.2752647399902344 seconds for one epoch ---
--- 0.9387531280517578 seconds for one epoch ---
--- 0.29850220680236816 seconds for one epoch ---
--- 0.9265124797821045 seconds for one epoch ---
--- 0.29967689514160156 seconds for one epoch ---
--- 0.9413325786590576 seconds for one epoch ---
--- 0.3122375011444092 seconds for one epoch ---
--- 0.9522478580474854 seconds for one epoch ---
--- 0.3065977096557617 seconds for one epoch ---
--- 0.9276432991027832 seconds for one epoch ---
--- 0.2961082458496094 seconds for one epoch ---
--- 0.9573221206665039 seconds for one epoch ---
--- 0.28415846824645996 seconds for one epoch ---
--- 0.9483215808868408 seconds for one epoch ---
--- 0.2992846965789795 seconds for one epoch ---
--- 0.9503467082977295 seconds for one epoch ---
--- 0.33089518547058105 seconds for one epoch ---
--- 0.9439048767089844 seconds for one epoch ---
--- 0.3159146308898926 seconds for one epoch ---
--- 0.9560928344726562 seconds for one epoch ---
--- 0.3084142208099365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19771986]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-7.762066]
 [ 0.      ]]
--- 0.24181389808654785 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5554.06640625, (1824.94, 2.4051363, 3726.611, 0.11021765)
   validation loss 1089.272705078125, (800.1209, 0.3020057, 288.73956, 0.11021765)
decoder loss ratio: 30998.073149, decoder SINDy loss  ratio: 0.623285
--- 0.306596040725708 seconds for one epoch ---
--- 0.9408812522888184 seconds for one epoch ---
--- 0.2529737949371338 seconds for one epoch ---
--- 0.9939365386962891 seconds for one epoch ---
--- 0.2935962677001953 seconds for one epoch ---
--- 0.9305248260498047 seconds for one epoch ---
--- 0.30243945121765137 seconds for one epoch ---
--- 0.9484031200408936 seconds for one epoch ---
--- 0.29798245429992676 seconds for one epoch ---
--- 0.9437403678894043 seconds for one epoch ---
--- 0.297130823135376 seconds for one epoch ---
--- 0.961716890335083 seconds for one epoch ---
--- 0.3035464286804199 seconds for one epoch ---
--- 0.9871981143951416 seconds for one epoch ---
--- 0.3074040412902832 seconds for one epoch ---
--- 0.9684298038482666 seconds for one epoch ---
--- 0.282895565032959 seconds for one epoch ---
--- 0.9607925415039062 seconds for one epoch ---
--- 0.30738234519958496 seconds for one epoch ---
--- 0.9497270584106445 seconds for one epoch ---
--- 0.28644442558288574 seconds for one epoch ---
--- 0.9646205902099609 seconds for one epoch ---
--- 0.28399181365966797 seconds for one epoch ---
--- 1.0181884765625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19954176]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.9238048]
 [-0.       ]]
--- 0.20009160041809082 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2547.520751953125, (1280.8142, 1.8942195, 1264.7002, 0.111987524)
   validation loss 2434.565673828125, (2092.4033, 0.28444448, 341.76575, 0.111987524)
decoder loss ratio: 81063.337201, decoder SINDy loss  ratio: 0.737749
--- 0.278839111328125 seconds for one epoch ---
--- 0.30708909034729004 seconds for one epoch ---
--- 0.9733266830444336 seconds for one epoch ---
--- 0.31167149543762207 seconds for one epoch ---
--- 0.9624841213226318 seconds for one epoch ---
--- 0.3171083927154541 seconds for one epoch ---
--- 0.9644060134887695 seconds for one epoch ---
--- 0.3012990951538086 seconds for one epoch ---
--- 0.9863152503967285 seconds for one epoch ---
--- 0.3093109130859375 seconds for one epoch ---
--- 0.8381648063659668 seconds for one epoch ---
--- 0.2396702766418457 seconds for one epoch ---
--- 0.9676814079284668 seconds for one epoch ---
--- 0.2985503673553467 seconds for one epoch ---
--- 0.9848809242248535 seconds for one epoch ---
--- 0.3034701347351074 seconds for one epoch ---
--- 0.9528067111968994 seconds for one epoch ---
--- 0.301135778427124 seconds for one epoch ---
--- 0.9903483390808105 seconds for one epoch ---
--- 0.2886643409729004 seconds for one epoch ---
--- 0.9752280712127686 seconds for one epoch ---
--- 0.30643200874328613 seconds for one epoch ---
--- 0.9761292934417725 seconds for one epoch ---
--- 0.30068302154541016 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2014027]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.105465]
 [ 0.      ]]
--- 0.2552974224090576 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4049.79296875, (1304.1698, 1.4711635, 2744.0383, 0.11375841)
   validation loss 808.7471923828125, (527.10034, 0.27684683, 281.25626, 0.11375841)
decoder loss ratio: 20420.782328, decoder SINDy loss  ratio: 0.607131
--- 0.30068087577819824 seconds for one epoch ---
--- 0.9848201274871826 seconds for one epoch ---
--- 0.293079137802124 seconds for one epoch ---
--- 0.9746904373168945 seconds for one epoch ---
--- 0.2993032932281494 seconds for one epoch ---
--- 0.8728528022766113 seconds for one epoch ---
--- 0.19027256965637207 seconds for one epoch ---
--- 0.9601812362670898 seconds for one epoch ---
--- 0.30097031593322754 seconds for one epoch ---
--- 0.9749691486358643 seconds for one epoch ---
--- 0.27947187423706055 seconds for one epoch ---
--- 0.9933481216430664 seconds for one epoch ---
--- 0.3023033142089844 seconds for one epoch ---
--- 1.0065622329711914 seconds for one epoch ---
--- 0.32158470153808594 seconds for one epoch ---
--- 1.0029215812683105 seconds for one epoch ---
--- 0.3060171604156494 seconds for one epoch ---
--- 0.8713443279266357 seconds for one epoch ---
--- 0.2582674026489258 seconds for one epoch ---
--- 0.9880027770996094 seconds for one epoch ---
--- 0.30265355110168457 seconds for one epoch ---
--- 1.0044374465942383 seconds for one epoch ---
--- 0.2964451313018799 seconds for one epoch ---
--- 0.9838669300079346 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20289356]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.267438]
 [ 0.      ]]
--- 0.29329895973205566 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5364.43994140625, (1573.688, 2.2815464, 3788.3552, 0.11540671)
   validation loss 1432.3575439453125, (1081.7738, 0.30972147, 350.15875, 0.11540671)
decoder loss ratio: 41909.795198, decoder SINDy loss  ratio: 0.755867
THRESHOLDING: 1 active coefficients
--- 0.2511012554168701 seconds for one epoch ---
--- 0.299379825592041 seconds for one epoch ---
--- 0.9866459369659424 seconds for one epoch ---
--- 0.2984917163848877 seconds for one epoch ---
--- 0.9925673007965088 seconds for one epoch ---
--- 0.3032341003417969 seconds for one epoch ---
--- 0.9780457019805908 seconds for one epoch ---
--- 0.3059666156768799 seconds for one epoch ---
--- 0.9773764610290527 seconds for one epoch ---
--- 0.28812193870544434 seconds for one epoch ---
--- 0.9993939399719238 seconds for one epoch ---
--- 0.3080098628997803 seconds for one epoch ---
--- 1.001175880432129 seconds for one epoch ---
--- 0.2902519702911377 seconds for one epoch ---
--- 1.003509759902954 seconds for one epoch ---
--- 0.3118259906768799 seconds for one epoch ---
--- 0.9776561260223389 seconds for one epoch ---
--- 0.2888162136077881 seconds for one epoch ---
--- 0.9871933460235596 seconds for one epoch ---
--- 0.28583860397338867 seconds for one epoch ---
--- 0.9935204982757568 seconds for one epoch ---
--- 0.2835733890533447 seconds for one epoch ---
--- 1.0036418437957764 seconds for one epoch ---
--- 0.2889595031738281 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20411916]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.416156]
 [-0.      ]]
--- 0.26833033561706543 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2283.080078125, (1014.32074, 1.6617181, 1266.993, 0.10437496)
   validation loss 885.5411376953125, (585.12976, 0.3561783, 299.95084, 0.10437496)
decoder loss ratio: 22668.942761, decoder SINDy loss  ratio: 0.647486
--- 0.2984898090362549 seconds for one epoch ---
--- 0.9874234199523926 seconds for one epoch ---
--- 0.2944176197052002 seconds for one epoch ---
--- 1.000178575515747 seconds for one epoch ---
--- 0.3092217445373535 seconds for one epoch ---
--- 0.9879083633422852 seconds for one epoch ---
--- 0.15610170364379883 seconds for one epoch ---
--- 0.9845888614654541 seconds for one epoch ---
--- 0.3092050552368164 seconds for one epoch ---
--- 0.9977021217346191 seconds for one epoch ---
--- 0.30815792083740234 seconds for one epoch ---
--- 1.011141061782837 seconds for one epoch ---
--- 0.3026566505432129 seconds for one epoch ---
--- 1.0100383758544922 seconds for one epoch ---
--- 0.3223588466644287 seconds for one epoch ---
--- 0.9971625804901123 seconds for one epoch ---
--- 0.2925403118133545 seconds for one epoch ---
--- 0.9391827583312988 seconds for one epoch ---
--- 0.22529077529907227 seconds for one epoch ---
--- 1.011185646057129 seconds for one epoch ---
--- 0.28690218925476074 seconds for one epoch ---
--- 1.0097100734710693 seconds for one epoch ---
--- 0.29447293281555176 seconds for one epoch ---
--- 1.0062668323516846 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20518243]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.561381]
 [-0.      ]]
--- 0.2920515537261963 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3412.66943359375, (1668.1422, 1.8471482, 1742.5743, 0.105808236)
   validation loss 754.3770751953125, (439.9978, 0.4215826, 313.85187, 0.105808236)
decoder loss ratio: 17046.278748, decoder SINDy loss  ratio: 0.677493
--- 0.26941561698913574 seconds for one epoch ---
--- 0.3013753890991211 seconds for one epoch ---
--- 1.0140721797943115 seconds for one epoch ---
--- 0.30768537521362305 seconds for one epoch ---
--- 1.0012712478637695 seconds for one epoch ---
--- 0.30614638328552246 seconds for one epoch ---
--- 0.9968345165252686 seconds for one epoch ---
--- 0.3002288341522217 seconds for one epoch ---
--- 1.012028694152832 seconds for one epoch ---
--- 0.30352282524108887 seconds for one epoch ---
--- 1.000220537185669 seconds for one epoch ---
--- 0.29691076278686523 seconds for one epoch ---
--- 0.9972505569458008 seconds for one epoch ---
--- 0.2987978458404541 seconds for one epoch ---
--- 1.0243370532989502 seconds for one epoch ---
--- 0.29122042655944824 seconds for one epoch ---
--- 1.0268287658691406 seconds for one epoch ---
--- 0.29393529891967773 seconds for one epoch ---
--- 1.0480449199676514 seconds for one epoch ---
--- 0.3033614158630371 seconds for one epoch ---
--- 1.0098426342010498 seconds for one epoch ---
--- 0.29569149017333984 seconds for one epoch ---
--- 1.0193347930908203 seconds for one epoch ---
--- 0.293363094329834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20614487]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.712151]
 [ 0.      ]]
--- 0.2657961845397949 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3819.215087890625, (1926.1057, 1.5985159, 1891.4038, 0.10719694)
   validation loss 970.2655029296875, (686.70294, 0.41458604, 283.04074, 0.10719694)
decoder loss ratio: 26604.064138, decoder SINDy loss  ratio: 0.610983
--- 0.3096446990966797 seconds for one epoch ---
--- 1.0491342544555664 seconds for one epoch ---
--- 0.29282045364379883 seconds for one epoch ---
--- 1.0397918224334717 seconds for one epoch ---
--- 0.30003809928894043 seconds for one epoch ---
--- 1.0453062057495117 seconds for one epoch ---
--- 0.30871129035949707 seconds for one epoch ---
--- 1.0236880779266357 seconds for one epoch ---
--- 0.2939438819885254 seconds for one epoch ---
--- 1.0758087635040283 seconds for one epoch ---
--- 0.3028578758239746 seconds for one epoch ---
--- 1.0396554470062256 seconds for one epoch ---
--- 0.2971985340118408 seconds for one epoch ---
--- 0.9979298114776611 seconds for one epoch ---
--- 0.2902247905731201 seconds for one epoch ---
--- 1.0191290378570557 seconds for one epoch ---
--- 0.29045605659484863 seconds for one epoch ---
--- 1.0131399631500244 seconds for one epoch ---
--- 0.2939643859863281 seconds for one epoch ---
--- 1.0241117477416992 seconds for one epoch ---
--- 0.18732500076293945 seconds for one epoch ---
--- 1.0245401859283447 seconds for one epoch ---
--- 0.2847251892089844 seconds for one epoch ---
--- 1.0285975933074951 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20690532]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.851649]
 [-0.      ]]
--- 0.2865116596221924 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1676.1728515625, (1004.2306, 1.8718548, 669.9619, 0.108468376)
   validation loss 1085.44287109375, (813.80365, 0.33526477, 271.19547, 0.108468376)
decoder loss ratio: 31528.166222, decoder SINDy loss  ratio: 0.585414
--- 0.2640228271484375 seconds for one epoch ---
--- 0.2905271053314209 seconds for one epoch ---
--- 1.033263921737671 seconds for one epoch ---
--- 0.272296667098999 seconds for one epoch ---
--- 1.0516178607940674 seconds for one epoch ---
--- 0.3051316738128662 seconds for one epoch ---
--- 1.043531894683838 seconds for one epoch ---
--- 0.3129720687866211 seconds for one epoch ---
--- 1.0281014442443848 seconds for one epoch ---
--- 0.3101162910461426 seconds for one epoch ---
--- 1.043694257736206 seconds for one epoch ---
--- 0.30323219299316406 seconds for one epoch ---
--- 1.0432884693145752 seconds for one epoch ---
--- 0.30330896377563477 seconds for one epoch ---
--- 1.0305867195129395 seconds for one epoch ---
--- 0.20116066932678223 seconds for one epoch ---
--- 1.0196588039398193 seconds for one epoch ---
--- 0.29888486862182617 seconds for one epoch ---
--- 1.0524775981903076 seconds for one epoch ---
--- 0.2872185707092285 seconds for one epoch ---
--- 1.0341746807098389 seconds for one epoch ---
--- 0.28586554527282715 seconds for one epoch ---
--- 1.033891201019287 seconds for one epoch ---
--- 0.3006458282470703 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20757478]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.999646]
 [ 0.      ]]
--- 0.25490641593933105 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2742.71044921875, (1056.0303, 1.4613323, 1685.1091, 0.109910965)
   validation loss 1037.638671875, (715.84784, 0.35615495, 321.32486, 0.109910965)
decoder loss ratio: 27733.188063, decoder SINDy loss  ratio: 0.693625
--- 0.2929270267486572 seconds for one epoch ---
--- 1.0023012161254883 seconds for one epoch ---
--- 0.29105067253112793 seconds for one epoch ---
--- 1.0327317714691162 seconds for one epoch ---
--- 0.31627368927001953 seconds for one epoch ---
--- 1.017883539199829 seconds for one epoch ---
--- 0.30013084411621094 seconds for one epoch ---
--- 1.0273771286010742 seconds for one epoch ---
--- 0.30692338943481445 seconds for one epoch ---
--- 0.9895572662353516 seconds for one epoch ---
--- 0.21218180656433105 seconds for one epoch ---
--- 1.044926404953003 seconds for one epoch ---
--- 0.3035140037536621 seconds for one epoch ---
--- 1.046553373336792 seconds for one epoch ---
--- 0.3097405433654785 seconds for one epoch ---
--- 1.0529263019561768 seconds for one epoch ---
--- 0.30121469497680664 seconds for one epoch ---
--- 1.0578830242156982 seconds for one epoch ---
--- 0.2978696823120117 seconds for one epoch ---
--- 1.0343570709228516 seconds for one epoch ---
--- 0.19171738624572754 seconds for one epoch ---
--- 1.033876657485962 seconds for one epoch ---
--- 0.2974236011505127 seconds for one epoch ---
--- 1.054905891418457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20806445]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.135703]
 [ 0.      ]]
--- 0.3040928840637207 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2760.5341796875, (1501.7461, 1.2904543, 1257.3866, 0.1111263)
   validation loss 919.0861206054688, (624.4309, 0.33374792, 294.21036, 0.1111263)
decoder loss ratio: 24191.537444, decoder SINDy loss  ratio: 0.635094
--- 0.2515132427215576 seconds for one epoch ---
--- 0.299515962600708 seconds for one epoch ---
--- 1.040907859802246 seconds for one epoch ---
--- 0.3202683925628662 seconds for one epoch ---
--- 0.9347121715545654 seconds for one epoch ---
--- 0.27947449684143066 seconds for one epoch ---
--- 1.0541043281555176 seconds for one epoch ---
--- 0.2905454635620117 seconds for one epoch ---
--- 1.0406744480133057 seconds for one epoch ---
--- 0.29646944999694824 seconds for one epoch ---
--- 1.0432071685791016 seconds for one epoch ---
--- 0.24566316604614258 seconds for one epoch ---
--- 1.1147665977478027 seconds for one epoch ---
--- 0.2996227741241455 seconds for one epoch ---
--- 1.0694355964660645 seconds for one epoch ---
--- 0.29757261276245117 seconds for one epoch ---
--- 1.0647010803222656 seconds for one epoch ---
--- 0.29871702194213867 seconds for one epoch ---
--- 1.0549137592315674 seconds for one epoch ---
--- 0.289778470993042 seconds for one epoch ---
--- 1.0728480815887451 seconds for one epoch ---
--- 0.2932760715484619 seconds for one epoch ---
--- 1.1004047393798828 seconds for one epoch ---
--- 0.29610633850097656 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20838416]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.250948]
 [-0.      ]]
--- 0.2598404884338379 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5535.4970703125, (2328.9526, 3.62982, 3202.802, 0.11216676)
   validation loss 1455.3370361328125, (1151.7339, 0.41397852, 303.0771, 0.11216676)
decoder loss ratio: 44620.170269, decoder SINDy loss  ratio: 0.654235
--- 0.31024932861328125 seconds for one epoch ---
--- 1.0663080215454102 seconds for one epoch ---
--- 0.30377912521362305 seconds for one epoch ---
--- 1.0776453018188477 seconds for one epoch ---
--- 0.311626672744751 seconds for one epoch ---
--- 1.0577754974365234 seconds for one epoch ---
--- 0.30635595321655273 seconds for one epoch ---
--- 1.071038007736206 seconds for one epoch ---
--- 0.2937750816345215 seconds for one epoch ---
--- 1.0928010940551758 seconds for one epoch ---
--- 0.2908167839050293 seconds for one epoch ---
--- 1.0543601512908936 seconds for one epoch ---
--- 0.29600048065185547 seconds for one epoch ---
--- 1.07649827003479 seconds for one epoch ---
--- 0.28727102279663086 seconds for one epoch ---
--- 1.067507028579712 seconds for one epoch ---
--- 0.28966212272644043 seconds for one epoch ---
--- 1.032832384109497 seconds for one epoch ---
--- 0.2999308109283447 seconds for one epoch ---
--- 1.0799822807312012 seconds for one epoch ---
--- 0.2970578670501709 seconds for one epoch ---
--- 1.072525978088379 seconds for one epoch ---
--- 0.2924680709838867 seconds for one epoch ---
--- 1.0827209949493408 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20863643]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.378436]
 [-0.      ]]
--- 0.2904491424560547 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4141.50537109375, (1761.0343, 1.2248229, 2379.133, 0.11330762)
   validation loss 1108.6937255859375, (801.40753, 0.3828868, 306.79004, 0.11330762)
decoder loss ratio: 31047.919084, decoder SINDy loss  ratio: 0.662249
--- 0.2652738094329834 seconds for one epoch ---
--- 0.31420135498046875 seconds for one epoch ---
--- 1.096714973449707 seconds for one epoch ---
--- 0.3044106960296631 seconds for one epoch ---
--- 1.0780012607574463 seconds for one epoch ---
--- 0.28775572776794434 seconds for one epoch ---
--- 1.0693509578704834 seconds for one epoch ---
--- 0.28930115699768066 seconds for one epoch ---
--- 1.077038049697876 seconds for one epoch ---
--- 0.2995929718017578 seconds for one epoch ---
--- 1.1074917316436768 seconds for one epoch ---
--- 0.5008418560028076 seconds for one epoch ---
--- 1.1029558181762695 seconds for one epoch ---
--- 0.2963263988494873 seconds for one epoch ---
--- 1.1017098426818848 seconds for one epoch ---
--- 0.3068511486053467 seconds for one epoch ---
--- 1.0911245346069336 seconds for one epoch ---
--- 0.3049142360687256 seconds for one epoch ---
--- 1.1063714027404785 seconds for one epoch ---
--- 0.30677175521850586 seconds for one epoch ---
--- 1.0937268733978271 seconds for one epoch ---
--- 0.2760910987854004 seconds for one epoch ---
--- 1.092240810394287 seconds for one epoch ---
--- 0.2831852436065674 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20879671]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.529866]
 [ 0.      ]]
--- 0.2697896957397461 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5467.95166015625, (1414.5468, 1.3998208, 4051.8906, 0.11459222)
   validation loss 1194.1236572265625, (862.8089, 0.32471865, 330.8755, 0.11459222)
decoder loss ratio: 33426.714647, decoder SINDy loss  ratio: 0.714241
--- 0.30289363861083984 seconds for one epoch ---
--- 1.092411994934082 seconds for one epoch ---
--- 0.3061816692352295 seconds for one epoch ---
--- 1.0673952102661133 seconds for one epoch ---
--- 0.3034043312072754 seconds for one epoch ---
--- 1.1141650676727295 seconds for one epoch ---
--- 0.2898576259613037 seconds for one epoch ---
--- 1.0819437503814697 seconds for one epoch ---
--- 0.30004453659057617 seconds for one epoch ---
--- 1.1099088191986084 seconds for one epoch ---
--- 0.2993278503417969 seconds for one epoch ---
--- 1.0988717079162598 seconds for one epoch ---
--- 0.30289196968078613 seconds for one epoch ---
--- 1.0356566905975342 seconds for one epoch ---
--- 0.27617359161376953 seconds for one epoch ---
--- 1.1104710102081299 seconds for one epoch ---
--- 0.3073759078979492 seconds for one epoch ---
--- 1.1102566719055176 seconds for one epoch ---
--- 0.31084728240966797 seconds for one epoch ---
--- 1.1071829795837402 seconds for one epoch ---
--- 0.3068885803222656 seconds for one epoch ---
--- 1.1058135032653809 seconds for one epoch ---
--- 0.2811770439147949 seconds for one epoch ---
--- 1.0815584659576416 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2088189]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.636653]
 [-0.      ]]
--- 0.291975736618042 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4382.4423828125, (996.8452, 1.4317914, 3384.0498, 0.11548475)
   validation loss 823.805908203125, (515.95416, 0.33398363, 307.40225, 0.11548475)
decoder loss ratio: 19988.959995, decoder SINDy loss  ratio: 0.663571
--- 0.2649803161621094 seconds for one epoch ---
--- 0.3012838363647461 seconds for one epoch ---
--- 1.1065149307250977 seconds for one epoch ---
--- 0.3009030818939209 seconds for one epoch ---
--- 1.0968942642211914 seconds for one epoch ---
--- 0.30786681175231934 seconds for one epoch ---
--- 1.0990591049194336 seconds for one epoch ---
--- 0.1737840175628662 seconds for one epoch ---
--- 1.1184706687927246 seconds for one epoch ---
--- 0.30886030197143555 seconds for one epoch ---
--- 1.1412224769592285 seconds for one epoch ---
--- 0.2964029312133789 seconds for one epoch ---
--- 1.1028296947479248 seconds for one epoch ---
--- 0.2980022430419922 seconds for one epoch ---
--- 1.1064751148223877 seconds for one epoch ---
--- 0.3055076599121094 seconds for one epoch ---
--- 1.128995656967163 seconds for one epoch ---
--- 0.3047821521759033 seconds for one epoch ---
--- 1.1567437648773193 seconds for one epoch ---
--- 0.3085625171661377 seconds for one epoch ---
--- 1.0941176414489746 seconds for one epoch ---
--- 0.30251479148864746 seconds for one epoch ---
--- 1.1269609928131104 seconds for one epoch ---
--- 0.3022646903991699 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2087539]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.756463]
 [ 0.      ]]
--- 0.25999021530151367 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1871.38720703125, (1272.3809, 5.106774, 593.78314, 0.11648176)
   validation loss 1539.1739501953125, (1183.7766, 0.35588387, 354.92502, 0.11648176)
decoder loss ratio: 45861.561049, decoder SINDy loss  ratio: 0.766156
--- 0.29891180992126465 seconds for one epoch ---
--- 1.1119372844696045 seconds for one epoch ---
--- 0.29762911796569824 seconds for one epoch ---
--- 1.1007177829742432 seconds for one epoch ---
--- 0.3005053997039795 seconds for one epoch ---
--- 1.098445177078247 seconds for one epoch ---
--- 0.2854273319244385 seconds for one epoch ---
--- 1.1196157932281494 seconds for one epoch ---
--- 0.30344104766845703 seconds for one epoch ---
--- 1.1064114570617676 seconds for one epoch ---
--- 0.29573655128479004 seconds for one epoch ---
--- 1.1068592071533203 seconds for one epoch ---
--- 0.29053544998168945 seconds for one epoch ---
--- 1.1166856288909912 seconds for one epoch ---
--- 0.29575276374816895 seconds for one epoch ---
--- 1.1315338611602783 seconds for one epoch ---
--- 0.3000192642211914 seconds for one epoch ---
--- 1.1726150512695312 seconds for one epoch ---
--- 0.2955653667449951 seconds for one epoch ---
--- 1.1357972621917725 seconds for one epoch ---
--- 0.2991185188293457 seconds for one epoch ---
--- 1.1219050884246826 seconds for one epoch ---
--- 0.28860020637512207 seconds for one epoch ---
--- 1.1508049964904785 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20859341]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.876767]
 [ 0.      ]]
--- 0.28777408599853516 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2501.386962890625, (1271.1593, 1.4430113, 1228.6671, 0.11746992)
   validation loss 2708.569091796875, (2262.783, 0.37768078, 445.29114, 0.11746992)
decoder loss ratio: 87664.140195, decoder SINDy loss  ratio: 0.961224
--- 0.26316046714782715 seconds for one epoch ---
--- 0.30155372619628906 seconds for one epoch ---
--- 1.1263349056243896 seconds for one epoch ---
--- 0.3054051399230957 seconds for one epoch ---
--- 1.1246213912963867 seconds for one epoch ---
--- 0.3039278984069824 seconds for one epoch ---
--- 1.1213247776031494 seconds for one epoch ---
--- 0.29369139671325684 seconds for one epoch ---
--- 1.1356616020202637 seconds for one epoch ---
--- 0.3056795597076416 seconds for one epoch ---
--- 1.160754919052124 seconds for one epoch ---
--- 0.3054325580596924 seconds for one epoch ---
--- 1.1130454540252686 seconds for one epoch ---
--- 0.29484057426452637 seconds for one epoch ---
--- 1.1450915336608887 seconds for one epoch ---
--- 0.30676913261413574 seconds for one epoch ---
--- 1.1599361896514893 seconds for one epoch ---
--- 0.30530881881713867 seconds for one epoch ---
--- 1.1475138664245605 seconds for one epoch ---
--- 0.2839961051940918 seconds for one epoch ---
--- 1.1285204887390137 seconds for one epoch ---
--- 0.2958097457885742 seconds for one epoch ---
--- 1.1608939170837402 seconds for one epoch ---
--- 0.2949695587158203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20838025]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.979702]
 [-0.      ]]
--- 0.20298075675964355 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2791.684326171875, (1236.994, 12.277326, 1542.2948, 0.11826866)
   validation loss 787.3258056640625, (498.83347, 0.30365425, 288.07043, 0.11826866)
decoder loss ratio: 19325.674469, decoder SINDy loss  ratio: 0.621841
--- 0.29999351501464844 seconds for one epoch ---
--- 1.1464850902557373 seconds for one epoch ---
--- 0.3016660213470459 seconds for one epoch ---
--- 1.130324363708496 seconds for one epoch ---
--- 0.2832067012786865 seconds for one epoch ---
--- 1.1358113288879395 seconds for one epoch ---
--- 0.2913036346435547 seconds for one epoch ---
--- 1.1452155113220215 seconds for one epoch ---
--- 0.2987334728240967 seconds for one epoch ---
--- 1.14732027053833 seconds for one epoch ---
--- 0.3051261901855469 seconds for one epoch ---
--- 1.1337838172912598 seconds for one epoch ---
--- 0.3053872585296631 seconds for one epoch ---
--- 1.1578197479248047 seconds for one epoch ---
--- 0.29924821853637695 seconds for one epoch ---
--- 1.1232624053955078 seconds for one epoch ---
--- 0.29494428634643555 seconds for one epoch ---
--- 1.1577510833740234 seconds for one epoch ---
--- 0.300952672958374 seconds for one epoch ---
--- 1.1782655715942383 seconds for one epoch ---
--- 0.3087007999420166 seconds for one epoch ---
--- 1.1606166362762451 seconds for one epoch ---
--- 0.30938196182250977 seconds for one epoch ---
--- 1.1495590209960938 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20805407]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.096571]
 [ -0.      ]]
--- 0.17121171951293945 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1670.1065673828125, (751.0569, 0.88810366, 918.0423, 0.119211845)
   validation loss 1092.7562255859375, (777.2812, 0.31641757, 315.0393, 0.119211845)
decoder loss ratio: 30113.222680, decoder SINDy loss  ratio: 0.680057
--- 0.2666618824005127 seconds for one epoch ---
--- 0.28217363357543945 seconds for one epoch ---
--- 1.1407296657562256 seconds for one epoch ---
--- 0.30434489250183105 seconds for one epoch ---
--- 1.154632568359375 seconds for one epoch ---
--- 0.30828380584716797 seconds for one epoch ---
--- 1.1436514854431152 seconds for one epoch ---
--- 0.29024171829223633 seconds for one epoch ---
--- 1.104884147644043 seconds for one epoch ---
--- 0.30818676948547363 seconds for one epoch ---
--- 1.1655254364013672 seconds for one epoch ---
--- 0.3052511215209961 seconds for one epoch ---
--- 1.1396968364715576 seconds for one epoch ---
--- 0.3016846179962158 seconds for one epoch ---
--- 1.159832239151001 seconds for one epoch ---
--- 0.30054187774658203 seconds for one epoch ---
--- 1.1742520332336426 seconds for one epoch ---
--- 0.30446481704711914 seconds for one epoch ---
--- 1.1644060611724854 seconds for one epoch ---
--- 0.17610454559326172 seconds for one epoch ---
--- 1.1682326793670654 seconds for one epoch ---
--- 0.2970402240753174 seconds for one epoch ---
--- 1.1774351596832275 seconds for one epoch ---
--- 0.3002772331237793 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20760646]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.221451]
 [  0.      ]]
--- 0.2641026973724365 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2091.031005859375, (1006.9623, 2.599951, 1081.3486, 0.1201994)
   validation loss 1020.2537841796875, (738.04785, 0.31908652, 281.76666, 0.1201994)
decoder loss ratio: 28593.255077, decoder SINDy loss  ratio: 0.608233
--- 0.30379509925842285 seconds for one epoch ---
--- 1.1421711444854736 seconds for one epoch ---
--- 0.2872285842895508 seconds for one epoch ---
--- 1.2909059524536133 seconds for one epoch ---
--- 0.2892475128173828 seconds for one epoch ---
--- 1.1503984928131104 seconds for one epoch ---
--- 0.30059027671813965 seconds for one epoch ---
--- 1.3082435131072998 seconds for one epoch ---
--- 0.1834721565246582 seconds for one epoch ---
--- 1.1581909656524658 seconds for one epoch ---
--- 0.27962803840637207 seconds for one epoch ---
--- 1.185955286026001 seconds for one epoch ---
--- 0.30479907989501953 seconds for one epoch ---
--- 1.1969048976898193 seconds for one epoch ---
--- 0.29698777198791504 seconds for one epoch ---
--- 1.1823697090148926 seconds for one epoch ---
--- 0.2931380271911621 seconds for one epoch ---
--- 1.1983296871185303 seconds for one epoch ---
--- 0.18251967430114746 seconds for one epoch ---
--- 1.2127397060394287 seconds for one epoch ---
--- 0.3157312870025635 seconds for one epoch ---
--- 1.1961100101470947 seconds for one epoch ---
--- 0.30226874351501465 seconds for one epoch ---
--- 1.1958589553833008 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20706736]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.344262]
 [ -0.      ]]
--- 0.2914130687713623 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2293.586181640625, (963.5293, 1.4949893, 1328.4408, 0.12116511)
   validation loss 952.7921142578125, (666.01013, 0.3274814, 286.33337, 0.12116511)
decoder loss ratio: 25802.388752, decoder SINDy loss  ratio: 0.618091
--- 0.27265429496765137 seconds for one epoch ---
--- 0.3013732433319092 seconds for one epoch ---
--- 1.1621546745300293 seconds for one epoch ---
--- 0.3028874397277832 seconds for one epoch ---
--- 1.1312816143035889 seconds for one epoch ---
--- 0.29200220108032227 seconds for one epoch ---
--- 1.170849084854126 seconds for one epoch ---
--- 0.2941172122955322 seconds for one epoch ---
--- 1.1943597793579102 seconds for one epoch ---
--- 0.29207634925842285 seconds for one epoch ---
--- 1.2267513275146484 seconds for one epoch ---
--- 0.30281734466552734 seconds for one epoch ---
--- 1.1843221187591553 seconds for one epoch ---
--- 0.30134129524230957 seconds for one epoch ---
--- 1.1983861923217773 seconds for one epoch ---
--- 0.3038797378540039 seconds for one epoch ---
--- 1.1786420345306396 seconds for one epoch ---
--- 0.3067142963409424 seconds for one epoch ---
--- 1.180530309677124 seconds for one epoch ---
--- 0.2991058826446533 seconds for one epoch ---
--- 1.2082417011260986 seconds for one epoch ---
--- 0.2750566005706787 seconds for one epoch ---
--- 1.198542594909668 seconds for one epoch ---
--- 0.29641127586364746 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20642133]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.468683]
 [  0.      ]]
--- 0.28817057609558105 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5236.31396484375, (1763.5023, 3.349953, 3469.3396, 0.12205503)
   validation loss 790.1240844726562, (499.38895, 0.29195216, 290.3211, 0.12205503)
decoder loss ratio: 19347.194766, decoder SINDy loss  ratio: 0.626699
--- 0.2923750877380371 seconds for one epoch ---
--- 1.1672124862670898 seconds for one epoch ---
--- 0.25252628326416016 seconds for one epoch ---
--- 1.1930530071258545 seconds for one epoch ---
--- 0.29303479194641113 seconds for one epoch ---
--- 1.184882402420044 seconds for one epoch ---
--- 0.301727294921875 seconds for one epoch ---
--- 1.17531418800354 seconds for one epoch ---
--- 0.29840707778930664 seconds for one epoch ---
--- 1.1762099266052246 seconds for one epoch ---
--- 0.15509033203125 seconds for one epoch ---
--- 1.1929094791412354 seconds for one epoch ---
--- 0.31282877922058105 seconds for one epoch ---
--- 1.1939570903778076 seconds for one epoch ---
--- 0.31489109992980957 seconds for one epoch ---
--- 1.182138442993164 seconds for one epoch ---
--- 0.3185131549835205 seconds for one epoch ---
--- 1.2271921634674072 seconds for one epoch ---
--- 0.31428098678588867 seconds for one epoch ---
--- 1.149939775466919 seconds for one epoch ---
--- 0.3020303249359131 seconds for one epoch ---
--- 1.2063050270080566 seconds for one epoch ---
--- 0.2953507900238037 seconds for one epoch ---
--- 1.1957073211669922 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20581317]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.571331]
 [  0.      ]]
--- 0.25188422203063965 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4030.180419921875, (1029.7422, 3.3919241, 2996.9236, 0.12280072)
   validation loss 1025.9879150390625, (740.3599, 0.3696242, 285.1356, 0.12280072)
decoder loss ratio: 28682.828789, decoder SINDy loss  ratio: 0.615505
--- 0.26352691650390625 seconds for one epoch ---
--- 0.29791879653930664 seconds for one epoch ---
--- 1.202711820602417 seconds for one epoch ---
--- 0.30265307426452637 seconds for one epoch ---
--- 1.2006680965423584 seconds for one epoch ---
--- 0.2975614070892334 seconds for one epoch ---
--- 1.195984125137329 seconds for one epoch ---
--- 0.20137500762939453 seconds for one epoch ---
--- 1.2118091583251953 seconds for one epoch ---
--- 0.3014957904815674 seconds for one epoch ---
--- 1.2082633972167969 seconds for one epoch ---
--- 0.29662275314331055 seconds for one epoch ---
--- 1.2040290832519531 seconds for one epoch ---
--- 0.29489755630493164 seconds for one epoch ---
--- 1.1895737648010254 seconds for one epoch ---
--- 0.2892155647277832 seconds for one epoch ---
--- 1.1151418685913086 seconds for one epoch ---
--- 0.21520590782165527 seconds for one epoch ---
--- 1.172755479812622 seconds for one epoch ---
--- 0.29125499725341797 seconds for one epoch ---
--- 1.1934900283813477 seconds for one epoch ---
--- 0.29757118225097656 seconds for one epoch ---
--- 1.2377443313598633 seconds for one epoch ---
--- 0.2901146411895752 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20506547]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.684374]
 [ -0.      ]]
--- 0.2577207088470459 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2644.4638671875, (1169.5533, 2.2316916, 1472.5552, 0.1236105)
   validation loss 949.2937622070312, (627.8306, 0.40684578, 320.9327, 0.1236105)
decoder loss ratio: 24323.248469, decoder SINDy loss  ratio: 0.692778
--- 0.2847778797149658 seconds for one epoch ---
--- 1.199821949005127 seconds for one epoch ---
--- 0.29810047149658203 seconds for one epoch ---
--- 1.211871862411499 seconds for one epoch ---
--- 0.3024322986602783 seconds for one epoch ---
--- 1.0975151062011719 seconds for one epoch ---
--- 0.22802448272705078 seconds for one epoch ---
--- 1.2130110263824463 seconds for one epoch ---
--- 0.2943685054779053 seconds for one epoch ---
--- 1.229750394821167 seconds for one epoch ---
--- 0.2930748462677002 seconds for one epoch ---
--- 1.232513189315796 seconds for one epoch ---
--- 0.306185245513916 seconds for one epoch ---
--- 1.2486028671264648 seconds for one epoch ---
--- 0.32196545600891113 seconds for one epoch ---
--- 1.2963006496429443 seconds for one epoch ---
--- 0.30437493324279785 seconds for one epoch ---
--- 1.2133960723876953 seconds for one epoch ---
--- 0.3143010139465332 seconds for one epoch ---
--- 1.2464802265167236 seconds for one epoch ---
--- 0.29679131507873535 seconds for one epoch ---
--- 1.213146686553955 seconds for one epoch ---
--- 0.3009505271911621 seconds for one epoch ---
--- 1.2304728031158447 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2041934]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.803065]
 [ -0.      ]]
--- 0.29541897773742676 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3708.8544921875, (1084.3812, 4.3603845, 2619.9885, 0.124457635)
   validation loss 869.3164672851562, (539.07666, 0.29863656, 329.8167, 0.124457635)
decoder loss ratio: 20884.765693, decoder SINDy loss  ratio: 0.711956
THRESHOLDING: 1 active coefficients
--- 1.238290786743164 seconds for one epoch ---
--- 0.29243016242980957 seconds for one epoch ---
--- 1.23195481300354 seconds for one epoch ---
--- 0.29993748664855957 seconds for one epoch ---
--- 1.2212464809417725 seconds for one epoch ---
--- 0.30176830291748047 seconds for one epoch ---
--- 1.2300324440002441 seconds for one epoch ---
--- 0.2767462730407715 seconds for one epoch ---
--- 1.2774012088775635 seconds for one epoch ---
--- 0.29591989517211914 seconds for one epoch ---
--- 1.2273991107940674 seconds for one epoch ---
--- 0.30336427688598633 seconds for one epoch ---
--- 1.231515645980835 seconds for one epoch ---
--- 0.30570507049560547 seconds for one epoch ---
--- 1.2263867855072021 seconds for one epoch ---
--- 0.29814720153808594 seconds for one epoch ---
--- 1.2926604747772217 seconds for one epoch ---
--- 0.2966420650482178 seconds for one epoch ---
--- 1.2246744632720947 seconds for one epoch ---
--- 0.29823732376098633 seconds for one epoch ---
--- 1.2516815662384033 seconds for one epoch ---
--- 0.3229200839996338 seconds for one epoch ---
--- 1.2178170680999756 seconds for one epoch ---
--- 0.3045504093170166 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20326084]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.918444]
 [  0.      ]]
--- 0.26616787910461426 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3579.884033203125, (1401.9965, 5.2847137, 2172.4775, 0.12527059)
   validation loss 854.5953369140625, (587.5212, 0.38046786, 266.56842, 0.12527059)
decoder loss ratio: 22761.590464, decoder SINDy loss  ratio: 0.575425
--- 0.30132174491882324 seconds for one epoch ---
--- 1.2679774761199951 seconds for one epoch ---
--- 0.3139045238494873 seconds for one epoch ---
--- 1.187638521194458 seconds for one epoch ---
--- 0.3007326126098633 seconds for one epoch ---
--- 1.2566752433776855 seconds for one epoch ---
--- 0.29456162452697754 seconds for one epoch ---
--- 1.2502024173736572 seconds for one epoch ---
--- 0.2987325191497803 seconds for one epoch ---
--- 1.2672104835510254 seconds for one epoch ---
--- 0.26601123809814453 seconds for one epoch ---
--- 1.2692253589630127 seconds for one epoch ---
--- 0.2790520191192627 seconds for one epoch ---
--- 1.2603797912597656 seconds for one epoch ---
--- 0.3053297996520996 seconds for one epoch ---
--- 1.2616002559661865 seconds for one epoch ---
--- 0.2990753650665283 seconds for one epoch ---
--- 1.2447776794433594 seconds for one epoch ---
--- 0.30594468116760254 seconds for one epoch ---
--- 1.2250759601593018 seconds for one epoch ---
--- 0.33231401443481445 seconds for one epoch ---
--- 1.2458410263061523 seconds for one epoch ---
--- 0.3115544319152832 seconds for one epoch ---
--- 1.2533814907073975 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20243783]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.012694]
 [ -0.      ]]
--- 0.2939331531524658 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4659.5185546875, (1100.718, 2.600921, 3556.0735, 0.12591204)
   validation loss 812.9304809570312, (518.6775, 0.31630662, 293.8108, 0.12591204)
decoder loss ratio: 20094.466435, decoder SINDy loss  ratio: 0.634232
--- 0.2693960666656494 seconds for one epoch ---
--- 0.30440735816955566 seconds for one epoch ---
--- 1.248302698135376 seconds for one epoch ---
--- 0.2977635860443115 seconds for one epoch ---
--- 1.2499315738677979 seconds for one epoch ---
--- 0.2996666431427002 seconds for one epoch ---
--- 1.300044298171997 seconds for one epoch ---
--- 0.29413843154907227 seconds for one epoch ---
--- 1.228407859802246 seconds for one epoch ---
--- 0.2992269992828369 seconds for one epoch ---
--- 1.2868695259094238 seconds for one epoch ---
--- 0.29271602630615234 seconds for one epoch ---
--- 1.2633907794952393 seconds for one epoch ---
--- 0.29190683364868164 seconds for one epoch ---
--- 1.255143165588379 seconds for one epoch ---
--- 0.30162477493286133 seconds for one epoch ---
--- 1.3013083934783936 seconds for one epoch ---
--- 0.331773042678833 seconds for one epoch ---
--- 1.2677841186523438 seconds for one epoch ---
--- 0.29597043991088867 seconds for one epoch ---
--- 1.2466051578521729 seconds for one epoch ---
--- 0.308896541595459 seconds for one epoch ---
--- 1.2708444595336914 seconds for one epoch ---
--- 0.29059934616088867 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2011778]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.146219]
 [  0.      ]]
--- 0.26192784309387207 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3244.470947265625, (1634.1813, 0.9221828, 1609.2407, 0.12677)
   validation loss 734.5765991210938, (445.61713, 0.3024379, 288.53027, 0.12677)
decoder loss ratio: 17263.981105, decoder SINDy loss  ratio: 0.622833
--- 0.3130197525024414 seconds for one epoch ---
--- 1.274585247039795 seconds for one epoch ---
--- 0.3036055564880371 seconds for one epoch ---
--- 1.254335880279541 seconds for one epoch ---
--- 0.30997371673583984 seconds for one epoch ---
--- 1.2658698558807373 seconds for one epoch ---
--- 0.3077404499053955 seconds for one epoch ---
--- 1.2686467170715332 seconds for one epoch ---
--- 0.29769372940063477 seconds for one epoch ---
--- 1.2740986347198486 seconds for one epoch ---
--- 0.28658318519592285 seconds for one epoch ---
--- 1.2984764575958252 seconds for one epoch ---
--- 0.3185904026031494 seconds for one epoch ---
--- 1.2714872360229492 seconds for one epoch ---
--- 0.306520938873291 seconds for one epoch ---
--- 1.264418601989746 seconds for one epoch ---
--- 0.3058164119720459 seconds for one epoch ---
--- 1.3291411399841309 seconds for one epoch ---
--- 0.3070335388183594 seconds for one epoch ---
--- 1.2994306087493896 seconds for one epoch ---
--- 0.3052339553833008 seconds for one epoch ---
--- 1.269925832748413 seconds for one epoch ---
--- 0.2816891670227051 seconds for one epoch ---
--- 1.2765302658081055 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20008403]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.253809]
 [  0.      ]]
--- 0.30039238929748535 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3801.457763671875, (2056.9282, 0.9544953, 1743.4475, 0.12745593)
   validation loss 1031.463134765625, (749.47034, 0.53989136, 281.32544, 0.12745593)
decoder loss ratio: 29035.781990, decoder SINDy loss  ratio: 0.607281
--- 0.2668476104736328 seconds for one epoch ---
--- 0.3154473304748535 seconds for one epoch ---
--- 1.2731304168701172 seconds for one epoch ---
--- 0.29769349098205566 seconds for one epoch ---
--- 1.3059499263763428 seconds for one epoch ---
--- 0.30556297302246094 seconds for one epoch ---
--- 1.3278555870056152 seconds for one epoch ---
--- 0.2885870933532715 seconds for one epoch ---
--- 1.2886879444122314 seconds for one epoch ---
--- 0.2969181537628174 seconds for one epoch ---
--- 1.2763612270355225 seconds for one epoch ---
--- 0.29654479026794434 seconds for one epoch ---
--- 1.157172441482544 seconds for one epoch ---
--- 0.277890682220459 seconds for one epoch ---
--- 1.280979871749878 seconds for one epoch ---
--- 0.2968027591705322 seconds for one epoch ---
--- 1.2650797367095947 seconds for one epoch ---
--- 0.3036484718322754 seconds for one epoch ---
--- 1.294057846069336 seconds for one epoch ---
--- 0.29953527450561523 seconds for one epoch ---
--- 1.282590389251709 seconds for one epoch ---
--- 0.29961252212524414 seconds for one epoch ---
--- 1.2994575500488281 seconds for one epoch ---
--- 0.3134784698486328 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19902745]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.351802]
 [ -0.      ]]
--- 0.26183152198791504 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4727.552734375, (2127.1292, 3.5240943, 2596.7715, 0.12807362)
   validation loss 810.669921875, (479.1962, 0.41495487, 330.93076, 0.12807362)
decoder loss ratio: 18564.892613, decoder SINDy loss  ratio: 0.714361
--- 0.2928125858306885 seconds for one epoch ---
--- 1.4197802543640137 seconds for one epoch ---
--- 0.29245638847351074 seconds for one epoch ---
--- 1.3310503959655762 seconds for one epoch ---
--- 0.28703832626342773 seconds for one epoch ---
--- 1.2811429500579834 seconds for one epoch ---
--- 0.28673219680786133 seconds for one epoch ---
--- 1.3150181770324707 seconds for one epoch ---
--- 0.30286645889282227 seconds for one epoch ---
--- 1.298172950744629 seconds for one epoch ---
--- 0.309476375579834 seconds for one epoch ---
--- 1.2968108654022217 seconds for one epoch ---
--- 0.3113982677459717 seconds for one epoch ---
--- 1.3076879978179932 seconds for one epoch ---
--- 0.17831897735595703 seconds for one epoch ---
--- 1.3038783073425293 seconds for one epoch ---
--- 0.2947983741760254 seconds for one epoch ---
--- 1.2916500568389893 seconds for one epoch ---
--- 0.3072507381439209 seconds for one epoch ---
--- 1.3146238327026367 seconds for one epoch ---
--- 0.2920377254486084 seconds for one epoch ---
--- 1.3293952941894531 seconds for one epoch ---
--- 0.17012667655944824 seconds for one epoch ---
--- 1.3538329601287842 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19802326]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.440385]
 [ -0.      ]]
--- 0.30350804328918457 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2779.085693359375, (1564.1722, 1.6244541, 1213.1603, 0.12860744)
   validation loss 956.7846069335938, (627.88855, 0.27927876, 328.4882, 0.12860744)
decoder loss ratio: 24325.492482, decoder SINDy loss  ratio: 0.709088
--- 0.2617006301879883 seconds for one epoch ---
--- 0.3119673728942871 seconds for one epoch ---
--- 1.3128063678741455 seconds for one epoch ---
--- 0.29479312896728516 seconds for one epoch ---
--- 1.3102900981903076 seconds for one epoch ---
--- 0.3041868209838867 seconds for one epoch ---
--- 1.3080995082855225 seconds for one epoch ---
--- 0.2975142002105713 seconds for one epoch ---
--- 1.311877727508545 seconds for one epoch ---
--- 0.303469181060791 seconds for one epoch ---
--- 1.297544002532959 seconds for one epoch ---
--- 0.2938868999481201 seconds for one epoch ---
--- 1.2960729598999023 seconds for one epoch ---
--- 0.2880229949951172 seconds for one epoch ---
--- 1.296213150024414 seconds for one epoch ---
--- 0.2535593509674072 seconds for one epoch ---
--- 1.3074219226837158 seconds for one epoch ---
--- 0.3042871952056885 seconds for one epoch ---
--- 1.2992229461669922 seconds for one epoch ---
--- 0.29148316383361816 seconds for one epoch ---
--- 1.2810359001159668 seconds for one epoch ---
--- 0.28992533683776855 seconds for one epoch ---
--- 1.296541452407837 seconds for one epoch ---
--- 0.2991774082183838 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19698863]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.527708]
 [  0.      ]]
--- 0.25194287300109863 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3795.824462890625, (1964.8738, 2.2371905, 1828.5842, 0.12910973)
   validation loss 942.6674194335938, (661.9383, 0.41164857, 280.1884, 0.12910973)
decoder loss ratio: 25644.638664, decoder SINDy loss  ratio: 0.604826
--- 0.2834599018096924 seconds for one epoch ---
--- 1.3103446960449219 seconds for one epoch ---
--- 0.2931225299835205 seconds for one epoch ---
--- 1.288198471069336 seconds for one epoch ---
--- 0.2967982292175293 seconds for one epoch ---
--- 1.316985845565796 seconds for one epoch ---
--- 0.29900097846984863 seconds for one epoch ---
--- 1.2871580123901367 seconds for one epoch ---
--- 0.1632702350616455 seconds for one epoch ---
--- 1.3126020431518555 seconds for one epoch ---
--- 0.30132389068603516 seconds for one epoch ---
--- 1.3330276012420654 seconds for one epoch ---
--- 0.289060115814209 seconds for one epoch ---
--- 1.3012700080871582 seconds for one epoch ---
--- 0.2666647434234619 seconds for one epoch ---
--- 1.3258748054504395 seconds for one epoch ---
--- 0.2946329116821289 seconds for one epoch ---
--- 1.3432724475860596 seconds for one epoch ---
--- 0.30580711364746094 seconds for one epoch ---
--- 1.4286954402923584 seconds for one epoch ---
--- 0.29640913009643555 seconds for one epoch ---
--- 1.327249526977539 seconds for one epoch ---
--- 0.29723143577575684 seconds for one epoch ---
--- 1.3334732055664062 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19593942]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.612704]
 [ -0.      ]]
--- 0.2936263084411621 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1910.2174072265625, (1033.7809, 3.60098, 872.70593, 0.12961632)
   validation loss 915.602294921875, (588.85156, 0.4041395, 326.21695, 0.12961632)
decoder loss ratio: 22813.131823, decoder SINDy loss  ratio: 0.704185
--- 0.2597372531890869 seconds for one epoch ---
--- 0.2707512378692627 seconds for one epoch ---
--- 1.3649647235870361 seconds for one epoch ---
--- 0.27980518341064453 seconds for one epoch ---
--- 1.3141992092132568 seconds for one epoch ---
--- 0.3085458278656006 seconds for one epoch ---
--- 1.3236074447631836 seconds for one epoch ---
--- 0.2980971336364746 seconds for one epoch ---
--- 1.3074913024902344 seconds for one epoch ---
--- 0.16558027267456055 seconds for one epoch ---
--- 1.310206413269043 seconds for one epoch ---
--- 0.30447983741760254 seconds for one epoch ---
--- 1.321977138519287 seconds for one epoch ---
--- 0.29575181007385254 seconds for one epoch ---
--- 1.3294692039489746 seconds for one epoch ---
--- 0.3008594512939453 seconds for one epoch ---
--- 1.339170217514038 seconds for one epoch ---
--- 0.3021049499511719 seconds for one epoch ---
--- 1.3878154754638672 seconds for one epoch ---
--- 0.30193209648132324 seconds for one epoch ---
--- 1.3207893371582031 seconds for one epoch ---
--- 0.2974209785461426 seconds for one epoch ---
--- 1.3196353912353516 seconds for one epoch ---
--- 0.3025856018066406 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19500095]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.686036]
 [  0.      ]]
--- 0.2700676918029785 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2363.329345703125, (792.2036, 3.5445309, 1567.451, 0.13004194)
   validation loss 1086.8875732421875, (739.88367, 0.3864058, 346.48746, 0.13004194)
decoder loss ratio: 28664.377754, decoder SINDy loss  ratio: 0.747942
--- 0.30293893814086914 seconds for one epoch ---
--- 1.2480485439300537 seconds for one epoch ---
--- 0.26432132720947266 seconds for one epoch ---
--- 1.3268890380859375 seconds for one epoch ---
--- 0.3150489330291748 seconds for one epoch ---
--- 1.321049451828003 seconds for one epoch ---
--- 0.3039276599884033 seconds for one epoch ---
--- 1.3376133441925049 seconds for one epoch ---
--- 0.30560922622680664 seconds for one epoch ---
--- 1.3390929698944092 seconds for one epoch ---
--- 0.303560733795166 seconds for one epoch ---
--- 1.3600802421569824 seconds for one epoch ---
--- 0.3107633590698242 seconds for one epoch ---
--- 1.3625552654266357 seconds for one epoch ---
--- 0.29336047172546387 seconds for one epoch ---
--- 1.3515899181365967 seconds for one epoch ---
--- 0.2992367744445801 seconds for one epoch ---
--- 1.3432321548461914 seconds for one epoch ---
--- 0.30563783645629883 seconds for one epoch ---
--- 1.3579318523406982 seconds for one epoch ---
--- 0.2957022190093994 seconds for one epoch ---
--- 1.3435590267181396 seconds for one epoch ---
--- 0.3162841796875 seconds for one epoch ---
--- 1.3306076526641846 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19399253]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.762375]
 [  0.      ]]
--- 0.2979395389556885 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3187.208740234375, (1206.2039, 5.0402155, 1975.8342, 0.13049792)
   validation loss 707.0685424804688, (439.03662, 0.4498217, 267.4516, 0.13049792)
decoder loss ratio: 17009.040902, decoder SINDy loss  ratio: 0.577332
--- 0.2593379020690918 seconds for one epoch ---
--- 0.28368139266967773 seconds for one epoch ---
--- 1.2559576034545898 seconds for one epoch ---
--- 0.3022270202636719 seconds for one epoch ---
--- 1.3346850872039795 seconds for one epoch ---
--- 0.2933359146118164 seconds for one epoch ---
--- 1.3620383739471436 seconds for one epoch ---
--- 0.2908158302307129 seconds for one epoch ---
--- 1.3535304069519043 seconds for one epoch ---
--- 0.5508525371551514 seconds for one epoch ---
--- 1.2346770763397217 seconds for one epoch ---
--- 0.20032382011413574 seconds for one epoch ---
--- 1.3518040180206299 seconds for one epoch ---
--- 0.31122612953186035 seconds for one epoch ---
--- 1.3545114994049072 seconds for one epoch ---
--- 0.29377055168151855 seconds for one epoch ---
--- 1.3687446117401123 seconds for one epoch ---
--- 0.282012939453125 seconds for one epoch ---
--- 1.359682559967041 seconds for one epoch ---
--- 0.22200918197631836 seconds for one epoch ---
--- 1.3823623657226562 seconds for one epoch ---
--- 0.313997745513916 seconds for one epoch ---
--- 1.374527931213379 seconds for one epoch ---
--- 0.30611395835876465 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19281432]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.848551]
 [ -0.      ]]
--- 0.2549917697906494 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2893.834716796875, (1247.8888, 4.728728, 1641.0863, 0.1309651)
   validation loss 922.1224365234375, (643.39764, 0.40007994, 278.19376, 0.1309651)
decoder loss ratio: 24926.341718, decoder SINDy loss  ratio: 0.600520
--- 0.3045222759246826 seconds for one epoch ---
--- 1.361203908920288 seconds for one epoch ---
--- 0.24714994430541992 seconds for one epoch ---
--- 1.3689484596252441 seconds for one epoch ---
--- 0.3007373809814453 seconds for one epoch ---
--- 1.3678982257843018 seconds for one epoch ---
--- 0.29271888732910156 seconds for one epoch ---
--- 1.368004560470581 seconds for one epoch ---
--- 0.3115980625152588 seconds for one epoch ---
--- 1.3451664447784424 seconds for one epoch ---
--- 0.2873241901397705 seconds for one epoch ---
--- 1.377408742904663 seconds for one epoch ---
--- 0.30408668518066406 seconds for one epoch ---
--- 1.3629212379455566 seconds for one epoch ---
--- 0.29075002670288086 seconds for one epoch ---
--- 1.3503103256225586 seconds for one epoch ---
--- 0.27683591842651367 seconds for one epoch ---
--- 1.3507764339447021 seconds for one epoch ---
--- 0.2684612274169922 seconds for one epoch ---
--- 1.3747847080230713 seconds for one epoch ---
--- 0.30197596549987793 seconds for one epoch ---
--- 1.368196964263916 seconds for one epoch ---
--- 0.29257678985595703 seconds for one epoch ---
--- 1.3543603420257568 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19174252]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.924508]
 [ -0.      ]]
--- 0.30207228660583496 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2750.5751953125, (1117.9755, 1.7253287, 1630.743, 0.13137673)
   validation loss 953.28515625, (664.80365, 0.41161895, 287.93857, 0.13137673)
decoder loss ratio: 25755.647547, decoder SINDy loss  ratio: 0.621556
--- 0.26985955238342285 seconds for one epoch ---
--- 0.3061234951019287 seconds for one epoch ---
--- 1.3731627464294434 seconds for one epoch ---
--- 0.3071751594543457 seconds for one epoch ---
--- 1.3962819576263428 seconds for one epoch ---
--- 0.2947983741760254 seconds for one epoch ---
--- 1.3434486389160156 seconds for one epoch ---
--- 0.31572675704956055 seconds for one epoch ---
--- 1.3783798217773438 seconds for one epoch ---
--- 0.3018779754638672 seconds for one epoch ---
--- 1.3829560279846191 seconds for one epoch ---
--- 0.2956888675689697 seconds for one epoch ---
--- 1.381763219833374 seconds for one epoch ---
--- 0.30123066902160645 seconds for one epoch ---
--- 1.3796043395996094 seconds for one epoch ---
--- 0.3055999279022217 seconds for one epoch ---
--- 1.376246690750122 seconds for one epoch ---
--- 0.289520263671875 seconds for one epoch ---
--- 1.3965089321136475 seconds for one epoch ---
--- 0.29600095748901367 seconds for one epoch ---
--- 1.3784406185150146 seconds for one epoch ---
--- 0.28808045387268066 seconds for one epoch ---
--- 1.3833303451538086 seconds for one epoch ---
--- 0.2875938415527344 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19078653]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-11.99048]
 [  0.     ]]
--- 0.26545023918151855 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5915.083984375, (1690.7623, 3.9141312, 4220.276, 0.13172211)
   validation loss 805.1409912109375, (493.84964, 0.39244747, 310.76715, 0.13172211)
decoder loss ratio: 19132.592410, decoder SINDy loss  ratio: 0.670835
--- 0.2871086597442627 seconds for one epoch ---
--- 1.3929846286773682 seconds for one epoch ---
--- 0.30676984786987305 seconds for one epoch ---
--- 1.378671646118164 seconds for one epoch ---
--- 0.30147480964660645 seconds for one epoch ---
--- 1.3801219463348389 seconds for one epoch ---
--- 0.30872678756713867 seconds for one epoch ---
--- 1.3723618984222412 seconds for one epoch ---
--- 0.2958409786224365 seconds for one epoch ---
--- 1.3686013221740723 seconds for one epoch ---
--- 0.2983853816986084 seconds for one epoch ---
--- 1.3829700946807861 seconds for one epoch ---
--- 0.3107614517211914 seconds for one epoch ---
--- 1.397531509399414 seconds for one epoch ---
--- 0.302720308303833 seconds for one epoch ---
--- 1.3907685279846191 seconds for one epoch ---
--- 0.29922962188720703 seconds for one epoch ---
--- 1.4199669361114502 seconds for one epoch ---
--- 0.2893526554107666 seconds for one epoch ---
--- 1.3923695087432861 seconds for one epoch ---
--- 0.297670841217041 seconds for one epoch ---
--- 1.3949975967407227 seconds for one epoch ---
--- 0.2816586494445801 seconds for one epoch ---
--- 1.411811351776123 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18946628]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.079082]
 [ -0.      ]]
--- 0.29546618461608887 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3078.846435546875, (1381.3131, 4.9240084, 1692.4773, 0.13218866)
   validation loss 807.8126220703125, (518.549, 0.45948866, 288.6719, 0.13218866)
decoder loss ratio: 20089.488936, decoder SINDy loss  ratio: 0.623139
--- 0.26732778549194336 seconds for one epoch ---
--- 0.29627180099487305 seconds for one epoch ---
--- 1.3946731090545654 seconds for one epoch ---
--- 0.30602335929870605 seconds for one epoch ---
--- 1.3807027339935303 seconds for one epoch ---
--- 0.28256821632385254 seconds for one epoch ---
--- 1.4382004737854004 seconds for one epoch ---
--- 0.29551100730895996 seconds for one epoch ---
--- 1.4024543762207031 seconds for one epoch ---
--- 0.2969825267791748 seconds for one epoch ---
--- 1.4048850536346436 seconds for one epoch ---
--- 0.2866082191467285 seconds for one epoch ---
--- 1.3950719833374023 seconds for one epoch ---
--- 0.3062293529510498 seconds for one epoch ---
--- 1.4147460460662842 seconds for one epoch ---
--- 0.3000917434692383 seconds for one epoch ---
--- 1.4051768779754639 seconds for one epoch ---
--- 0.3015284538269043 seconds for one epoch ---
--- 1.411787748336792 seconds for one epoch ---
--- 0.2988460063934326 seconds for one epoch ---
--- 1.3738594055175781 seconds for one epoch ---
--- 0.23152804374694824 seconds for one epoch ---
--- 1.4170808792114258 seconds for one epoch ---
--- 0.29320430755615234 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18825923]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-12.15778]
 [  0.     ]]
--- 0.2649989128112793 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4626.12158203125, (1653.695, 5.645495, 2966.6484, 0.13258891)
   validation loss 753.9713134765625, (482.42343, 0.4037404, 271.0116, 0.13258891)
decoder loss ratio: 18689.921256, decoder SINDy loss  ratio: 0.585017
--- 0.31906867027282715 seconds for one epoch ---
--- 1.3117594718933105 seconds for one epoch ---
--- 0.30710697174072266 seconds for one epoch ---
--- 1.41292405128479 seconds for one epoch ---
--- 0.29656100273132324 seconds for one epoch ---
--- 1.3908507823944092 seconds for one epoch ---
--- 0.29207420349121094 seconds for one epoch ---
--- 1.3936593532562256 seconds for one epoch ---
--- 0.2912428379058838 seconds for one epoch ---
--- 1.3960742950439453 seconds for one epoch ---
--- 0.16518425941467285 seconds for one epoch ---
--- 1.3834655284881592 seconds for one epoch ---
--- 0.27921557426452637 seconds for one epoch ---
--- 1.3977978229522705 seconds for one epoch ---
--- 0.3102083206176758 seconds for one epoch ---
--- 1.3948900699615479 seconds for one epoch ---
--- 0.3055284023284912 seconds for one epoch ---
--- 1.3965280055999756 seconds for one epoch ---
--- 0.30260801315307617 seconds for one epoch ---
--- 1.4556701183319092 seconds for one epoch ---
--- 0.3224632740020752 seconds for one epoch ---
--- 1.4271817207336426 seconds for one epoch ---
--- 0.31700921058654785 seconds for one epoch ---
--- 1.4266672134399414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18699808]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.237871]
 [  0.      ]]
--- 0.3028223514556885 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3476.633544921875, (890.32306, 6.2133374, 2579.964, 0.1330081)
   validation loss 753.8319702148438, (456.91602, 0.4808625, 296.30206, 0.1330081)
decoder loss ratio: 17701.719686, decoder SINDy loss  ratio: 0.639610
--- 0.27137184143066406 seconds for one epoch ---
--- 0.30574822425842285 seconds for one epoch ---
--- 1.425004482269287 seconds for one epoch ---
--- 0.30538177490234375 seconds for one epoch ---
--- 1.3973884582519531 seconds for one epoch ---
--- 0.2996351718902588 seconds for one epoch ---
--- 1.4081692695617676 seconds for one epoch ---
--- 0.22661685943603516 seconds for one epoch ---
--- 1.4349467754364014 seconds for one epoch ---
--- 0.3015284538269043 seconds for one epoch ---
--- 1.4295685291290283 seconds for one epoch ---
--- 0.30682373046875 seconds for one epoch ---
--- 1.4087607860565186 seconds for one epoch ---
--- 0.3037114143371582 seconds for one epoch ---
--- 1.4062650203704834 seconds for one epoch ---
--- 0.23116803169250488 seconds for one epoch ---
--- 1.430668592453003 seconds for one epoch ---
--- 0.30307769775390625 seconds for one epoch ---
--- 1.4364721775054932 seconds for one epoch ---
--- 0.30264949798583984 seconds for one epoch ---
--- 1.4358491897583008 seconds for one epoch ---
--- 0.3042256832122803 seconds for one epoch ---
--- 1.4741718769073486 seconds for one epoch ---
--- 0.28606605529785156 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18584386]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.309447]
 [ -0.      ]]
--- 0.2597682476043701 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2914.64111328125, (1803.543, 2.3909109, 1108.574, 0.13333149)
   validation loss 881.7207641601562, (610.53076, 0.45232022, 270.60434, 0.13333149)
decoder loss ratio: 23653.021637, decoder SINDy loss  ratio: 0.584138
--- 0.3086283206939697 seconds for one epoch ---
--- 1.4255256652832031 seconds for one epoch ---
--- 0.30020737648010254 seconds for one epoch ---
--- 1.4193460941314697 seconds for one epoch ---
--- 0.260317325592041 seconds for one epoch ---
--- 1.4806509017944336 seconds for one epoch ---
--- 0.3024294376373291 seconds for one epoch ---
--- 1.4245758056640625 seconds for one epoch ---
--- 0.3013722896575928 seconds for one epoch ---
--- 1.4459056854248047 seconds for one epoch ---
--- 0.31613802909851074 seconds for one epoch ---
--- 1.405879259109497 seconds for one epoch ---
--- 0.14738202095031738 seconds for one epoch ---
--- 1.4345312118530273 seconds for one epoch ---
--- 0.2937953472137451 seconds for one epoch ---
--- 1.4338960647583008 seconds for one epoch ---
--- 0.3007924556732178 seconds for one epoch ---
--- 1.4520320892333984 seconds for one epoch ---
--- 0.3064439296722412 seconds for one epoch ---
--- 1.4638779163360596 seconds for one epoch ---
--- 0.2912626266479492 seconds for one epoch ---
--- 1.4633986949920654 seconds for one epoch ---
--- 0.286388635635376 seconds for one epoch ---
--- 1.5394787788391113 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18464434]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.382206]
 [ -0.      ]]
--- 0.2946431636810303 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6085.099609375, (2461.5852, 3.2490504, 3620.1316, 0.13370034)
   validation loss 953.9993286132812, (633.1191, 0.5826133, 320.16385, 0.13370034)
decoder loss ratio: 24528.132286, decoder SINDy loss  ratio: 0.691119
--- 0.2801811695098877 seconds for one epoch ---
--- 0.30785417556762695 seconds for one epoch ---
--- 1.4427211284637451 seconds for one epoch ---
--- 0.3181338310241699 seconds for one epoch ---
--- 1.4543108940124512 seconds for one epoch ---
--- 0.3134136199951172 seconds for one epoch ---
--- 1.4568943977355957 seconds for one epoch ---
--- 0.28461337089538574 seconds for one epoch ---
--- 1.5338890552520752 seconds for one epoch ---
--- 0.30486297607421875 seconds for one epoch ---
--- 1.4420647621154785 seconds for one epoch ---
--- 0.2942023277282715 seconds for one epoch ---
--- 1.4540600776672363 seconds for one epoch ---
--- 0.30323314666748047 seconds for one epoch ---
--- 1.453484058380127 seconds for one epoch ---
--- 0.3032093048095703 seconds for one epoch ---
--- 1.4493262767791748 seconds for one epoch ---
--- 0.28237247467041016 seconds for one epoch ---
--- 1.4508843421936035 seconds for one epoch ---
--- 0.29802846908569336 seconds for one epoch ---
--- 1.4542956352233887 seconds for one epoch ---
--- 0.29440855979919434 seconds for one epoch ---
--- 1.4698708057403564 seconds for one epoch ---
--- 0.30047059059143066 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18354802]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.447389]
 [  0.      ]]
--- 0.26201391220092773 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2959.829833984375, (1140.8539, 2.049341, 1816.7927, 0.13401945)
   validation loss 906.6243896484375, (630.5179, 0.3498159, 275.62265, 0.13401945)
decoder loss ratio: 24427.357426, decoder SINDy loss  ratio: 0.594970
--- 0.302776575088501 seconds for one epoch ---
--- 1.464407205581665 seconds for one epoch ---
--- 0.30355191230773926 seconds for one epoch ---
--- 1.490821361541748 seconds for one epoch ---
--- 0.2984740734100342 seconds for one epoch ---
--- 1.447730302810669 seconds for one epoch ---
--- 0.29294610023498535 seconds for one epoch ---
--- 1.4468369483947754 seconds for one epoch ---
--- 0.2878844738006592 seconds for one epoch ---
--- 1.5094594955444336 seconds for one epoch ---
--- 0.3130760192871094 seconds for one epoch ---
--- 1.4588711261749268 seconds for one epoch ---
--- 0.2980782985687256 seconds for one epoch ---
--- 1.4501032829284668 seconds for one epoch ---
--- 0.31392407417297363 seconds for one epoch ---
--- 1.443202018737793 seconds for one epoch ---
--- 0.29711318016052246 seconds for one epoch ---
--- 1.4757444858551025 seconds for one epoch ---
--- 0.2883162498474121 seconds for one epoch ---
--- 1.4542992115020752 seconds for one epoch ---
--- 0.2867755889892578 seconds for one epoch ---
--- 1.4569425582885742 seconds for one epoch ---
--- 0.29227232933044434 seconds for one epoch ---
--- 1.4648237228393555 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18216738]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.527808]
 [ -0.      ]]
--- 0.2947878837585449 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2346.16845703125, (887.47955, 4.463545, 1454.0911, 0.13438551)
   validation loss 959.5275268554688, (667.4131, 0.31451187, 291.66553, 0.13438551)
decoder loss ratio: 25856.741629, decoder SINDy loss  ratio: 0.629601
THRESHOLDING: 1 active coefficients
--- 1.45936918258667 seconds for one epoch ---
--- 0.31832051277160645 seconds for one epoch ---
--- 1.4835398197174072 seconds for one epoch ---
--- 0.30140233039855957 seconds for one epoch ---
--- 1.3947668075561523 seconds for one epoch ---
--- 0.23517060279846191 seconds for one epoch ---
--- 1.46903657913208 seconds for one epoch ---
--- 0.3037691116333008 seconds for one epoch ---
--- 1.471972942352295 seconds for one epoch ---
--- 0.30704641342163086 seconds for one epoch ---
--- 1.4614918231964111 seconds for one epoch ---
--- 0.2968103885650635 seconds for one epoch ---
--- 1.4042611122131348 seconds for one epoch ---
--- 0.1939246654510498 seconds for one epoch ---
--- 1.4671528339385986 seconds for one epoch ---
--- 0.2987651824951172 seconds for one epoch ---
--- 1.4774796962738037 seconds for one epoch ---
--- 0.29657816886901855 seconds for one epoch ---
--- 1.4600636959075928 seconds for one epoch ---
--- 0.3051612377166748 seconds for one epoch ---
--- 1.4909749031066895 seconds for one epoch ---
--- 0.2935214042663574 seconds for one epoch ---
--- 1.4755682945251465 seconds for one epoch ---
--- 0.30241894721984863 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18086722]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.601968]
 [  0.      ]]
--- 0.26056337356567383 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3162.166259765625, (1354.0732, 8.27747, 1799.6808, 0.13471149)
   validation loss 789.9728393554688, (486.51407, 0.35813582, 302.9659, 0.13471149)
decoder loss ratio: 18848.399643, decoder SINDy loss  ratio: 0.653995
--- 0.2616868019104004 seconds for one epoch ---
--- 1.4859070777893066 seconds for one epoch ---
--- 0.2991909980773926 seconds for one epoch ---
--- 1.432784080505371 seconds for one epoch ---
--- 0.2689018249511719 seconds for one epoch ---
--- 1.4543027877807617 seconds for one epoch ---
--- 0.29333949089050293 seconds for one epoch ---
--- 1.4704439640045166 seconds for one epoch ---
--- 0.19149255752563477 seconds for one epoch ---
--- 1.5000033378601074 seconds for one epoch ---
--- 0.3006293773651123 seconds for one epoch ---
--- 1.4792606830596924 seconds for one epoch ---
--- 0.296541690826416 seconds for one epoch ---
--- 1.475722074508667 seconds for one epoch ---
--- 0.30905914306640625 seconds for one epoch ---
--- 1.3557636737823486 seconds for one epoch ---
--- 0.30587244033813477 seconds for one epoch ---
--- 1.502119541168213 seconds for one epoch ---
--- 0.29836463928222656 seconds for one epoch ---
--- 1.4947195053100586 seconds for one epoch ---
--- 0.293196439743042 seconds for one epoch ---
--- 1.4723868370056152 seconds for one epoch ---
--- 0.31064462661743164 seconds for one epoch ---
--- 1.3666718006134033 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17986211]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.658339]
 [  0.      ]]
--- 0.31690478324890137 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2590.626220703125, (1289.523, 2.2196553, 1298.7485, 0.13496761)
   validation loss 838.7234497070312, (566.4239, 0.48968953, 271.67493, 0.13496761)
decoder loss ratio: 21944.244821, decoder SINDy loss  ratio: 0.586449
--- 0.27262282371520996 seconds for one epoch ---
--- 0.31102633476257324 seconds for one epoch ---
--- 1.4884669780731201 seconds for one epoch ---
--- 0.22589516639709473 seconds for one epoch ---
--- 1.5300090312957764 seconds for one epoch ---
--- 0.2855410575866699 seconds for one epoch ---
--- 1.4769415855407715 seconds for one epoch ---
--- 0.2986335754394531 seconds for one epoch ---
--- 1.4928176403045654 seconds for one epoch ---
--- 0.29556751251220703 seconds for one epoch ---
--- 1.4903316497802734 seconds for one epoch ---
--- 0.25380611419677734 seconds for one epoch ---
--- 1.5244386196136475 seconds for one epoch ---
--- 0.297696590423584 seconds for one epoch ---
--- 1.4970061779022217 seconds for one epoch ---
--- 0.3032996654510498 seconds for one epoch ---
--- 1.5085902214050293 seconds for one epoch ---
--- 0.3224754333496094 seconds for one epoch ---
--- 1.4294333457946777 seconds for one epoch ---
--- 0.29677534103393555 seconds for one epoch ---
--- 1.5024631023406982 seconds for one epoch ---
--- 0.2989768981933594 seconds for one epoch ---
--- 1.4876363277435303 seconds for one epoch ---
--- 0.3015589714050293 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17867687]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.723827]
 [ -0.      ]]
--- 0.27437806129455566 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3181.160400390625, (1565.879, 1.716637, 1613.4294, 0.13525033)
   validation loss 1016.2362060546875, (718.29205, 0.28989285, 297.51895, 0.13525033)
decoder loss ratio: 27827.881152, decoder SINDy loss  ratio: 0.642237
--- 0.3033478260040283 seconds for one epoch ---
--- 1.5031538009643555 seconds for one epoch ---
--- 0.3103957176208496 seconds for one epoch ---
--- 1.4910588264465332 seconds for one epoch ---
--- 0.3067750930786133 seconds for one epoch ---
--- 1.5018715858459473 seconds for one epoch ---
--- 0.2904932498931885 seconds for one epoch ---
--- 1.490812063217163 seconds for one epoch ---
--- 0.29639577865600586 seconds for one epoch ---
--- 1.4958076477050781 seconds for one epoch ---
--- 0.2955465316772461 seconds for one epoch ---
--- 1.499157190322876 seconds for one epoch ---
--- 0.31278395652770996 seconds for one epoch ---
--- 1.5182397365570068 seconds for one epoch ---
--- 0.31296730041503906 seconds for one epoch ---
--- 1.50496244430542 seconds for one epoch ---
--- 0.2998542785644531 seconds for one epoch ---
--- 1.5237572193145752 seconds for one epoch ---
--- 0.2931506633758545 seconds for one epoch ---
--- 1.4225876331329346 seconds for one epoch ---
--- 0.22049808502197266 seconds for one epoch ---
--- 1.5225868225097656 seconds for one epoch ---
--- 0.30899572372436523 seconds for one epoch ---
--- 1.5229027271270752 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17744815]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.790638]
 [ -0.      ]]
--- 0.23488593101501465 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5330.1953125, (2426.279, 3.6152203, 2900.165, 0.13553761)
   validation loss 890.3665161132812, (604.2509, 0.49694368, 285.4831, 0.13553761)
decoder loss ratio: 23409.729493, decoder SINDy loss  ratio: 0.616255
--- 0.2714688777923584 seconds for one epoch ---
--- 0.29375648498535156 seconds for one epoch ---
--- 1.5480942726135254 seconds for one epoch ---
--- 0.2926371097564697 seconds for one epoch ---
--- 1.512385368347168 seconds for one epoch ---
--- 0.3116281032562256 seconds for one epoch ---
--- 1.5609264373779297 seconds for one epoch ---
--- 0.29212427139282227 seconds for one epoch ---
--- 1.5111429691314697 seconds for one epoch ---
--- 0.2931790351867676 seconds for one epoch ---
--- 1.5031921863555908 seconds for one epoch ---
--- 0.30373048782348633 seconds for one epoch ---
--- 1.5183477401733398 seconds for one epoch ---
--- 0.29354190826416016 seconds for one epoch ---
--- 1.5403051376342773 seconds for one epoch ---
--- 0.30598998069763184 seconds for one epoch ---
--- 1.5249576568603516 seconds for one epoch ---
--- 0.2878117561340332 seconds for one epoch ---
--- 1.5316047668457031 seconds for one epoch ---
--- 0.30983829498291016 seconds for one epoch ---
--- 1.5420467853546143 seconds for one epoch ---
--- 0.2898519039154053 seconds for one epoch ---
--- 1.5291624069213867 seconds for one epoch ---
--- 0.2857677936553955 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17601067]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.867488]
 [  0.      ]]
--- 0.2519843578338623 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3124.57958984375, (2154.7292, 1.8535411, 967.86115, 0.13585256)
   validation loss 1655.5147705078125, (1319.7202, 0.42466167, 335.234, 0.13585256)
decoder loss ratio: 51128.252258, decoder SINDy loss  ratio: 0.723650
--- 0.1865684986114502 seconds for one epoch ---
--- 1.542461633682251 seconds for one epoch ---
--- 0.30454182624816895 seconds for one epoch ---
--- 1.5244858264923096 seconds for one epoch ---
--- 0.2923130989074707 seconds for one epoch ---
--- 1.521827220916748 seconds for one epoch ---
--- 0.2995481491088867 seconds for one epoch ---
--- 1.4691951274871826 seconds for one epoch ---
--- 0.30107903480529785 seconds for one epoch ---
--- 1.536820650100708 seconds for one epoch ---
--- 0.2768862247467041 seconds for one epoch ---
--- 1.5359714031219482 seconds for one epoch ---
--- 0.29557371139526367 seconds for one epoch ---
--- 1.5272512435913086 seconds for one epoch ---
--- 0.17458033561706543 seconds for one epoch ---
--- 1.5356252193450928 seconds for one epoch ---
--- 0.2903306484222412 seconds for one epoch ---
--- 1.5243096351623535 seconds for one epoch ---
--- 0.2934730052947998 seconds for one epoch ---
--- 1.535109043121338 seconds for one epoch ---
--- 0.2942805290222168 seconds for one epoch ---
--- 1.5432212352752686 seconds for one epoch ---
--- 0.2954885959625244 seconds for one epoch ---
--- 1.5326132774353027 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17470062]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.936405]
 [ -0.      ]]
--- 0.29296135902404785 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4327.49169921875, (2188.1587, 11.982444, 2127.2146, 0.13614206)
   validation loss 784.01025390625, (507.33554, 0.45630565, 276.08224, 0.13614206)
decoder loss ratio: 19655.059623, decoder SINDy loss  ratio: 0.595962
--- 0.266402006149292 seconds for one epoch ---
--- 0.2824735641479492 seconds for one epoch ---
--- 1.5491507053375244 seconds for one epoch ---
--- 0.286787748336792 seconds for one epoch ---
--- 1.5412521362304688 seconds for one epoch ---
--- 0.298370361328125 seconds for one epoch ---
--- 1.5468931198120117 seconds for one epoch ---
--- 0.2929558753967285 seconds for one epoch ---
--- 1.5428833961486816 seconds for one epoch ---
--- 0.30078554153442383 seconds for one epoch ---
--- 1.5444178581237793 seconds for one epoch ---
--- 0.296384334564209 seconds for one epoch ---
--- 1.5423517227172852 seconds for one epoch ---
--- 0.29063844680786133 seconds for one epoch ---
--- 1.4103686809539795 seconds for one epoch ---
--- 0.2603428363800049 seconds for one epoch ---
--- 1.517871618270874 seconds for one epoch ---
--- 0.2749478816986084 seconds for one epoch ---
--- 1.540113925933838 seconds for one epoch ---
--- 0.2995321750640869 seconds for one epoch ---
--- 1.5511887073516846 seconds for one epoch ---
--- 0.3042123317718506 seconds for one epoch ---
--- 1.6169614791870117 seconds for one epoch ---
--- 0.29202795028686523 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17321604]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.013292]
 [  0.      ]]
--- 0.25234270095825195 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3024.1982421875, (1424.1968, 0.4261321, 1599.4388, 0.13645062)
   validation loss 950.39208984375, (652.0468, 0.540862, 297.668, 0.13645062)
decoder loss ratio: 25261.425576, decoder SINDy loss  ratio: 0.642558
--- 0.30682921409606934 seconds for one epoch ---
--- 1.55399751663208 seconds for one epoch ---
--- 0.29949474334716797 seconds for one epoch ---
--- 1.5290546417236328 seconds for one epoch ---
--- 0.3038904666900635 seconds for one epoch ---
--- 1.544694423675537 seconds for one epoch ---
--- 0.3047475814819336 seconds for one epoch ---
--- 1.478564739227295 seconds for one epoch ---
--- 0.16587495803833008 seconds for one epoch ---
--- 1.5672509670257568 seconds for one epoch ---
--- 0.295499324798584 seconds for one epoch ---
--- 1.5471832752227783 seconds for one epoch ---
--- 0.3116114139556885 seconds for one epoch ---
--- 1.5503849983215332 seconds for one epoch ---
--- 0.3082575798034668 seconds for one epoch ---
--- 1.5581316947937012 seconds for one epoch ---
--- 0.30191612243652344 seconds for one epoch ---
--- 1.5329205989837646 seconds for one epoch ---
--- 0.28639984130859375 seconds for one epoch ---
--- 1.5479929447174072 seconds for one epoch ---
--- 0.266587495803833 seconds for one epoch ---
--- 1.5392301082611084 seconds for one epoch ---
--- 0.2927589416503906 seconds for one epoch ---
--- 1.5711660385131836 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17172751]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.089174]
 [  0.      ]]
--- 0.2929098606109619 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2466.81640625, (1571.5137, 2.0390682, 893.127, 0.13674346)
   validation loss 1055.860595703125, (740.0641, 0.56111926, 315.09872, 0.13674346)
decoder loss ratio: 28671.367535, decoder SINDy loss  ratio: 0.680185
--- 0.20499968528747559 seconds for one epoch ---
--- 0.29782843589782715 seconds for one epoch ---
--- 1.5432124137878418 seconds for one epoch ---
--- 0.30805301666259766 seconds for one epoch ---
--- 1.5658063888549805 seconds for one epoch ---
--- 0.29441094398498535 seconds for one epoch ---
--- 1.5634264945983887 seconds for one epoch ---
--- 0.2954280376434326 seconds for one epoch ---
--- 1.5752081871032715 seconds for one epoch ---
--- 0.28734612464904785 seconds for one epoch ---
--- 1.5759878158569336 seconds for one epoch ---
--- 0.3054842948913574 seconds for one epoch ---
--- 1.5866947174072266 seconds for one epoch ---
--- 0.3051450252532959 seconds for one epoch ---
--- 1.4895555973052979 seconds for one epoch ---
--- 0.25659608840942383 seconds for one epoch ---
--- 1.5703425407409668 seconds for one epoch ---
--- 0.2960543632507324 seconds for one epoch ---
--- 1.5546798706054688 seconds for one epoch ---
--- 0.2920691967010498 seconds for one epoch ---
--- 1.573709487915039 seconds for one epoch ---
--- 0.2937192916870117 seconds for one epoch ---
--- 1.642263650894165 seconds for one epoch ---
--- 0.3082242012023926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17057069]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.147377]
 [ -0.      ]]
--- 0.2812645435333252 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2032.129150390625, (1140.9054, 1.6571548, 889.42975, 0.13697991)
   validation loss 886.284912109375, (600.48157, 0.40533587, 285.26105, 0.13697991)
decoder loss ratio: 23263.698402, decoder SINDy loss  ratio: 0.615776
--- 0.3001222610473633 seconds for one epoch ---
--- 1.5935137271881104 seconds for one epoch ---
--- 0.31902241706848145 seconds for one epoch ---
--- 1.5675938129425049 seconds for one epoch ---
--- 0.29603004455566406 seconds for one epoch ---
--- 1.5865349769592285 seconds for one epoch ---
--- 0.23231744766235352 seconds for one epoch ---
--- 1.6004793643951416 seconds for one epoch ---
--- 0.29522204399108887 seconds for one epoch ---
--- 1.5605483055114746 seconds for one epoch ---
--- 0.29929113388061523 seconds for one epoch ---
--- 1.553009033203125 seconds for one epoch ---
--- 0.30526304244995117 seconds for one epoch ---
--- 1.4894206523895264 seconds for one epoch ---
--- 0.2579538822174072 seconds for one epoch ---
--- 1.5597684383392334 seconds for one epoch ---
--- 0.294081449508667 seconds for one epoch ---
--- 1.5727651119232178 seconds for one epoch ---
--- 0.2999880313873291 seconds for one epoch ---
--- 1.5906732082366943 seconds for one epoch ---
--- 0.29480624198913574 seconds for one epoch ---
--- 1.6244616508483887 seconds for one epoch ---
--- 0.29645204544067383 seconds for one epoch ---
--- 1.5718557834625244 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1691295]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.218997]
 [ -0.      ]]
--- 0.2982809543609619 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2552.453125, (925.96674, 0.3371544, 1626.0121, 0.1372415)
   validation loss 791.8211669921875, (497.69388, 0.51736456, 293.47266, 0.1372415)
decoder loss ratio: 19281.524875, decoder SINDy loss  ratio: 0.633502
--- 0.26836705207824707 seconds for one epoch ---
--- 0.3068695068359375 seconds for one epoch ---
--- 1.6098427772521973 seconds for one epoch ---
--- 0.2928652763366699 seconds for one epoch ---
--- 1.599205732345581 seconds for one epoch ---
--- 0.1839902400970459 seconds for one epoch ---
--- 1.5575201511383057 seconds for one epoch ---
--- 0.2951698303222656 seconds for one epoch ---
--- 1.5799167156219482 seconds for one epoch ---
--- 0.30782318115234375 seconds for one epoch ---
--- 1.5686671733856201 seconds for one epoch ---
--- 0.29315710067749023 seconds for one epoch ---
--- 1.604609489440918 seconds for one epoch ---
--- 0.3037075996398926 seconds for one epoch ---
--- 1.5974175930023193 seconds for one epoch ---
--- 0.30699825286865234 seconds for one epoch ---
--- 1.6223583221435547 seconds for one epoch ---
--- 0.3004758358001709 seconds for one epoch ---
--- 1.6059751510620117 seconds for one epoch ---
--- 0.2999532222747803 seconds for one epoch ---
--- 1.6461057662963867 seconds for one epoch ---
--- 0.30104780197143555 seconds for one epoch ---
--- 1.5914273262023926 seconds for one epoch ---
--- 0.3024251461029053 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16753824]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.297008]
 [  0.      ]]
--- 0.2649695873260498 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3215.4365234375, (997.71106, 3.8423831, 2213.7456, 0.13750885)
   validation loss 822.4153442382812, (519.95807, 0.5491849, 301.77057, 0.13750885)
decoder loss ratio: 20144.078274, decoder SINDy loss  ratio: 0.651414
--- 0.3029775619506836 seconds for one epoch ---
--- 1.6735479831695557 seconds for one epoch ---
--- 0.2979612350463867 seconds for one epoch ---
--- 1.599778652191162 seconds for one epoch ---
--- 0.295881986618042 seconds for one epoch ---
--- 1.5955297946929932 seconds for one epoch ---
--- 0.2924802303314209 seconds for one epoch ---
--- 1.5239324569702148 seconds for one epoch ---
--- 0.30530595779418945 seconds for one epoch ---
--- 1.6113007068634033 seconds for one epoch ---
--- 0.3138234615325928 seconds for one epoch ---
--- 1.6109564304351807 seconds for one epoch ---
--- 0.31270384788513184 seconds for one epoch ---
--- 1.598355770111084 seconds for one epoch ---
--- 0.2964186668395996 seconds for one epoch ---
--- 1.67763352394104 seconds for one epoch ---
--- 0.28914594650268555 seconds for one epoch ---
--- 1.5941197872161865 seconds for one epoch ---
--- 0.2941305637359619 seconds for one epoch ---
--- 1.5919749736785889 seconds for one epoch ---
--- 0.29964709281921387 seconds for one epoch ---
--- 1.4874107837677002 seconds for one epoch ---
--- 0.18507051467895508 seconds for one epoch ---
--- 1.576298713684082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16599263]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.371776]
 [ -0.      ]]
--- 0.298048734664917 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2316.898681640625, (1028.615, 0.89213866, 1287.2539, 0.13777697)
   validation loss 844.4461059570312, (545.1549, 0.48020643, 298.6732, 0.13777697)
decoder loss ratio: 21120.247536, decoder SINDy loss  ratio: 0.644728
--- 0.26265811920166016 seconds for one epoch ---
--- 0.3085637092590332 seconds for one epoch ---
--- 1.5957434177398682 seconds for one epoch ---
--- 0.2949814796447754 seconds for one epoch ---
--- 1.6091217994689941 seconds for one epoch ---
--- 0.28327250480651855 seconds for one epoch ---
--- 1.611943006515503 seconds for one epoch ---
--- 0.3109891414642334 seconds for one epoch ---
--- 1.6192741394042969 seconds for one epoch ---
--- 0.3032851219177246 seconds for one epoch ---
--- 1.6351029872894287 seconds for one epoch ---
--- 0.2962162494659424 seconds for one epoch ---
--- 1.6236224174499512 seconds for one epoch ---
--- 0.298445463180542 seconds for one epoch ---
--- 1.6260275840759277 seconds for one epoch ---
--- 0.28896665573120117 seconds for one epoch ---
--- 1.6307802200317383 seconds for one epoch ---
--- 0.29984116554260254 seconds for one epoch ---
--- 1.5978217124938965 seconds for one epoch ---
--- 0.29450201988220215 seconds for one epoch ---
--- 1.6030726432800293 seconds for one epoch ---
--- 0.29317164421081543 seconds for one epoch ---
--- 1.6165692806243896 seconds for one epoch ---
--- 0.30094194412231445 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1648061]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.428549]
 [  0.      ]]
--- 0.2614436149597168 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2575.108154296875, (1035.0208, 0.60525566, 1539.3441, 0.13798138)
   validation loss 916.6868286132812, (605.2192, 0.4714335, 310.8582, 0.13798138)
decoder loss ratio: 23447.241633, decoder SINDy loss  ratio: 0.671031
--- 0.29079246520996094 seconds for one epoch ---
--- 1.6315281391143799 seconds for one epoch ---
--- 0.3012416362762451 seconds for one epoch ---
--- 1.624366044998169 seconds for one epoch ---
--- 0.2983996868133545 seconds for one epoch ---
--- 1.5448074340820312 seconds for one epoch ---
--- 0.2360694408416748 seconds for one epoch ---
--- 1.6358489990234375 seconds for one epoch ---
--- 0.30101871490478516 seconds for one epoch ---
--- 1.6726787090301514 seconds for one epoch ---
--- 0.2974972724914551 seconds for one epoch ---
--- 1.6294889450073242 seconds for one epoch ---
--- 0.32854247093200684 seconds for one epoch ---
--- 1.6500282287597656 seconds for one epoch ---
--- 0.27572202682495117 seconds for one epoch ---
--- 1.6060104370117188 seconds for one epoch ---
--- 0.2965092658996582 seconds for one epoch ---
--- 1.6190159320831299 seconds for one epoch ---
--- 0.29508042335510254 seconds for one epoch ---
--- 1.6301090717315674 seconds for one epoch ---
--- 0.2914130687713623 seconds for one epoch ---
--- 1.6330938339233398 seconds for one epoch ---
--- 0.3106963634490967 seconds for one epoch ---
--- 1.6350748538970947 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1634804]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.491381]
 [  0.      ]]
--- 0.29857802391052246 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2023.7412109375, (1052.2417, 0.7339556, 970.62726, 0.13819417)
   validation loss 890.1112060546875, (606.29, 0.50732726, 283.17575, 0.13819417)
decoder loss ratio: 23488.726314, decoder SINDy loss  ratio: 0.611275
--- 0.267791748046875 seconds for one epoch ---
--- 0.3026556968688965 seconds for one epoch ---
--- 1.6284136772155762 seconds for one epoch ---
--- 0.30190134048461914 seconds for one epoch ---
--- 1.6320617198944092 seconds for one epoch ---
--- 0.3132760524749756 seconds for one epoch ---
--- 1.6440775394439697 seconds for one epoch ---
--- 0.2970268726348877 seconds for one epoch ---
--- 1.5550851821899414 seconds for one epoch ---
--- 0.287935733795166 seconds for one epoch ---
--- 1.6225934028625488 seconds for one epoch ---
--- 0.29470086097717285 seconds for one epoch ---
--- 1.6331214904785156 seconds for one epoch ---
--- 0.3007676601409912 seconds for one epoch ---
--- 1.6238484382629395 seconds for one epoch ---
--- 0.2712404727935791 seconds for one epoch ---
--- 1.6646687984466553 seconds for one epoch ---
--- 0.30355072021484375 seconds for one epoch ---
--- 1.6269376277923584 seconds for one epoch ---
--- 0.272247314453125 seconds for one epoch ---
--- 1.6536335945129395 seconds for one epoch ---
--- 0.3064737319946289 seconds for one epoch ---
--- 1.643348217010498 seconds for one epoch ---
--- 0.2936849594116211 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16212317]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-13.55508]
 [ -0.     ]]
--- 0.2631645202636719 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4472.71337890625, (1480.2592, 7.137533, 2985.1782, 0.13840172)
   validation loss 1003.866943359375, (730.1771, 0.45185995, 273.09955, 0.13840172)
decoder loss ratio: 28288.329428, decoder SINDy loss  ratio: 0.589524
--- 0.30317258834838867 seconds for one epoch ---
--- 1.6383721828460693 seconds for one epoch ---
--- 0.2795119285583496 seconds for one epoch ---
--- 1.638458490371704 seconds for one epoch ---
--- 0.29828310012817383 seconds for one epoch ---
--- 1.6933262348175049 seconds for one epoch ---
--- 0.31051087379455566 seconds for one epoch ---
--- 1.659362554550171 seconds for one epoch ---
--- 0.2950739860534668 seconds for one epoch ---
--- 1.6828360557556152 seconds for one epoch ---
--- 0.28541994094848633 seconds for one epoch ---
--- 1.666640043258667 seconds for one epoch ---
--- 0.29587602615356445 seconds for one epoch ---
--- 1.6643662452697754 seconds for one epoch ---
--- 0.30089712142944336 seconds for one epoch ---
--- 1.6517724990844727 seconds for one epoch ---
--- 0.2890748977661133 seconds for one epoch ---
--- 1.6843008995056152 seconds for one epoch ---
--- 0.3156254291534424 seconds for one epoch ---
--- 1.6378695964813232 seconds for one epoch ---
--- 0.31572747230529785 seconds for one epoch ---
--- 1.652036190032959 seconds for one epoch ---
--- 0.2899057865142822 seconds for one epoch ---
--- 1.6564137935638428 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16077554]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.617749]
 [ -0.      ]]
--- 0.2984936237335205 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2343.576171875, (1328.8857, 1.0541065, 1013.4977, 0.13861172)
   validation loss 843.9697875976562, (539.2082, 0.47601536, 304.14694, 0.13861172)
decoder loss ratio: 20889.861423, decoder SINDy loss  ratio: 0.656544
--- 0.2679874897003174 seconds for one epoch ---
--- 0.2899928092956543 seconds for one epoch ---
--- 1.6775813102722168 seconds for one epoch ---
--- 0.29759907722473145 seconds for one epoch ---
--- 1.6587040424346924 seconds for one epoch ---
--- 0.2991456985473633 seconds for one epoch ---
--- 1.706453800201416 seconds for one epoch ---
--- 0.3031587600708008 seconds for one epoch ---
--- 1.6609816551208496 seconds for one epoch ---
--- 0.2978503704071045 seconds for one epoch ---
--- 1.6520884037017822 seconds for one epoch ---
--- 0.30052876472473145 seconds for one epoch ---
--- 1.657043218612671 seconds for one epoch ---
--- 0.30733609199523926 seconds for one epoch ---
--- 1.6380455493927002 seconds for one epoch ---
--- 0.29403042793273926 seconds for one epoch ---
--- 1.680361270904541 seconds for one epoch ---
--- 0.29680800437927246 seconds for one epoch ---
--- 1.6753480434417725 seconds for one epoch ---
--- 0.18506193161010742 seconds for one epoch ---
--- 1.6514091491699219 seconds for one epoch ---
--- 0.31148266792297363 seconds for one epoch ---
--- 1.7803637981414795 seconds for one epoch ---
--- 0.3049159049987793 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15940562]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.680895]
 [  0.      ]]
--- 0.24146413803100586 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2414.342529296875, (1084.9126, 0.39466304, 1328.8964, 0.13881774)
   validation loss 801.48486328125, (522.34827, 0.47097617, 278.52682, 0.13881774)
decoder loss ratio: 20236.678685, decoder SINDy loss  ratio: 0.601239
--- 0.2979717254638672 seconds for one epoch ---
--- 1.6775133609771729 seconds for one epoch ---
--- 0.3082101345062256 seconds for one epoch ---
--- 1.6736810207366943 seconds for one epoch ---
--- 0.2912130355834961 seconds for one epoch ---
--- 1.6758391857147217 seconds for one epoch ---
--- 0.30983996391296387 seconds for one epoch ---
--- 1.5794239044189453 seconds for one epoch ---
--- 0.3043961524963379 seconds for one epoch ---
--- 1.6870827674865723 seconds for one epoch ---
--- 0.30750131607055664 seconds for one epoch ---
--- 1.697396993637085 seconds for one epoch ---
--- 0.29982662200927734 seconds for one epoch ---
--- 1.7025537490844727 seconds for one epoch ---
--- 0.3072824478149414 seconds for one epoch ---
--- 1.72841477394104 seconds for one epoch ---
--- 0.3023536205291748 seconds for one epoch ---
--- 1.696857213973999 seconds for one epoch ---
--- 0.5880460739135742 seconds for one epoch ---
--- 1.7806377410888672 seconds for one epoch ---
--- 0.30263590812683105 seconds for one epoch ---
--- 1.713602066040039 seconds for one epoch ---
--- 0.3008430004119873 seconds for one epoch ---
--- 1.710944414138794 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15772764]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.757509]
 [ -0.      ]]
--- 0.29383015632629395 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2222.745849609375, (898.02594, 3.053832, 1321.527, 0.13904946)
   validation loss 826.2274169921875, (554.89935, 0.3709493, 270.81808, 0.13904946)
decoder loss ratio: 21497.764284, decoder SINDy loss  ratio: 0.584599
--- 0.270322322845459 seconds for one epoch ---
--- 0.3073394298553467 seconds for one epoch ---
--- 1.7083745002746582 seconds for one epoch ---
--- 0.2972524166107178 seconds for one epoch ---
--- 1.6991078853607178 seconds for one epoch ---
--- 0.29944825172424316 seconds for one epoch ---
--- 1.6983304023742676 seconds for one epoch ---
--- 0.3035299777984619 seconds for one epoch ---
--- 1.7479612827301025 seconds for one epoch ---
--- 0.28827452659606934 seconds for one epoch ---
--- 1.6514830589294434 seconds for one epoch ---
--- 0.2939333915710449 seconds for one epoch ---
--- 1.6494956016540527 seconds for one epoch ---
--- 0.29102301597595215 seconds for one epoch ---
--- 1.6956322193145752 seconds for one epoch ---
--- 0.25418949127197266 seconds for one epoch ---
--- 1.7026488780975342 seconds for one epoch ---
--- 0.2884683609008789 seconds for one epoch ---
--- 1.6799514293670654 seconds for one epoch ---
--- 0.3014068603515625 seconds for one epoch ---
--- 1.6780717372894287 seconds for one epoch ---
--- 0.2752044200897217 seconds for one epoch ---
--- 1.7384285926818848 seconds for one epoch ---
--- 0.28774142265319824 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15644766]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.815441]
 [  0.      ]]
--- 0.2619802951812744 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3613.681640625, (1789.5597, 1.4016616, 1822.5812, 0.13923453)
   validation loss 642.2258911132812, (360.852, 0.5808759, 280.65384, 0.13923453)
decoder loss ratio: 13980.032549, decoder SINDy loss  ratio: 0.605831
--- 0.30345726013183594 seconds for one epoch ---
--- 1.7090322971343994 seconds for one epoch ---
--- 0.305649995803833 seconds for one epoch ---
--- 1.703256368637085 seconds for one epoch ---
--- 0.31263089179992676 seconds for one epoch ---
--- 1.6864569187164307 seconds for one epoch ---
--- 0.31799840927124023 seconds for one epoch ---
--- 1.6822681427001953 seconds for one epoch ---
--- 0.30161237716674805 seconds for one epoch ---
--- 1.6798853874206543 seconds for one epoch ---
--- 0.17052817344665527 seconds for one epoch ---
--- 1.6777784824371338 seconds for one epoch ---
--- 0.28241562843322754 seconds for one epoch ---
--- 1.727445125579834 seconds for one epoch ---
--- 0.3066248893737793 seconds for one epoch ---
--- 1.7058801651000977 seconds for one epoch ---
--- 0.2757580280303955 seconds for one epoch ---
--- 1.7133204936981201 seconds for one epoch ---
--- 0.2995173931121826 seconds for one epoch ---
--- 1.6992604732513428 seconds for one epoch ---
--- 0.29507875442504883 seconds for one epoch ---
--- 1.6994073390960693 seconds for one epoch ---
--- 0.28392767906188965 seconds for one epoch ---
--- 1.7297775745391846 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15487805]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.885942]
 [  0.      ]]
--- 0.3007931709289551 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3567.048095703125, (1358.6993, 4.2617674, 2203.9475, 0.13942252)
   validation loss 802.7705688476562, (528.5004, 0.43379164, 273.69696, 0.13942252)
decoder loss ratio: 20475.024069, decoder SINDy loss  ratio: 0.590813
THRESHOLDING: 1 active coefficients
--- 0.269528865814209 seconds for one epoch ---
--- 0.3052794933319092 seconds for one epoch ---
--- 1.713613748550415 seconds for one epoch ---
--- 0.3038496971130371 seconds for one epoch ---
--- 1.704801082611084 seconds for one epoch ---
--- 0.30131101608276367 seconds for one epoch ---
--- 1.7013792991638184 seconds for one epoch ---
--- 0.3028523921966553 seconds for one epoch ---
--- 1.73879075050354 seconds for one epoch ---
--- 0.2998008728027344 seconds for one epoch ---
--- 1.6051983833312988 seconds for one epoch ---
--- 0.29629039764404297 seconds for one epoch ---
--- 1.7236838340759277 seconds for one epoch ---
--- 0.28697776794433594 seconds for one epoch ---
--- 1.7102136611938477 seconds for one epoch ---
--- 0.30440306663513184 seconds for one epoch ---
--- 1.7319421768188477 seconds for one epoch ---
--- 0.3225688934326172 seconds for one epoch ---
--- 1.7430016994476318 seconds for one epoch ---
--- 0.32346558570861816 seconds for one epoch ---
--- 1.7322304248809814 seconds for one epoch ---
--- 0.3076634407043457 seconds for one epoch ---
--- 1.7271249294281006 seconds for one epoch ---
--- 0.30123162269592285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15384278]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.932128]
 [ -0.      ]]
--- 0.26064586639404297 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5674.56396484375, (1636.5548, 3.077183, 4034.7922, 0.13957453)
   validation loss 729.6298828125, (459.00745, 0.45636553, 270.0265, 0.13957453)
decoder loss ratio: 17782.745341, decoder SINDy loss  ratio: 0.582890
--- 0.3145420551300049 seconds for one epoch ---
--- 1.6978282928466797 seconds for one epoch ---
--- 0.3143327236175537 seconds for one epoch ---
--- 1.7162203788757324 seconds for one epoch ---
--- 0.30645108222961426 seconds for one epoch ---
--- 1.7281017303466797 seconds for one epoch ---
--- 0.304384708404541 seconds for one epoch ---
--- 1.731264352798462 seconds for one epoch ---
--- 0.305675745010376 seconds for one epoch ---
--- 1.730658769607544 seconds for one epoch ---
--- 0.3048865795135498 seconds for one epoch ---
--- 1.7475998401641846 seconds for one epoch ---
--- 0.3270084857940674 seconds for one epoch ---
--- 1.700871229171753 seconds for one epoch ---
--- 0.2944514751434326 seconds for one epoch ---
--- 1.7141618728637695 seconds for one epoch ---
--- 0.29381728172302246 seconds for one epoch ---
--- 1.7190465927124023 seconds for one epoch ---
--- 0.3025553226470947 seconds for one epoch ---
--- 1.7224481105804443 seconds for one epoch ---
--- 0.3100154399871826 seconds for one epoch ---
--- 1.7302727699279785 seconds for one epoch ---
--- 0.29656171798706055 seconds for one epoch ---
--- 1.71730637550354 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15248576]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.992285]
 [ -0.      ]]
--- 0.2962021827697754 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2632.7568359375, (1092.985, 1.3483987, 1538.2837, 0.13973485)
   validation loss 842.2437133789062, (566.2218, 0.4673719, 275.4149, 0.13973485)
decoder loss ratio: 21936.415604, decoder SINDy loss  ratio: 0.594522
--- 0.2573673725128174 seconds for one epoch ---
--- 0.3151736259460449 seconds for one epoch ---
--- 1.7477576732635498 seconds for one epoch ---
--- 0.27962374687194824 seconds for one epoch ---
--- 1.757223129272461 seconds for one epoch ---
--- 0.3131859302520752 seconds for one epoch ---
--- 1.7309601306915283 seconds for one epoch ---
--- 0.3028981685638428 seconds for one epoch ---
--- 1.7413082122802734 seconds for one epoch ---
--- 0.3100302219390869 seconds for one epoch ---
--- 1.7276418209075928 seconds for one epoch ---
--- 0.15190863609313965 seconds for one epoch ---
--- 1.7466356754302979 seconds for one epoch ---
--- 0.2967808246612549 seconds for one epoch ---
--- 1.7668566703796387 seconds for one epoch ---
--- 0.30913496017456055 seconds for one epoch ---
--- 1.7505078315734863 seconds for one epoch ---
--- 0.31118345260620117 seconds for one epoch ---
--- 1.796064853668213 seconds for one epoch ---
--- 0.30532336235046387 seconds for one epoch ---
--- 1.7435243129730225 seconds for one epoch ---
--- 0.27840495109558105 seconds for one epoch ---
--- 1.747736930847168 seconds for one epoch ---
--- 0.30061960220336914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15116432]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.050518]
 [  0.      ]]
--- 0.2573239803314209 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2741.372314453125, (1347.9926, 1.7933689, 1391.4465, 0.13991119)
   validation loss 1805.6981201171875, (1492.3381, 0.43533036, 312.7848, 0.13991119)
decoder loss ratio: 57815.770154, decoder SINDy loss  ratio: 0.675190
--- 0.3100314140319824 seconds for one epoch ---
--- 1.762171745300293 seconds for one epoch ---
--- 0.30393099784851074 seconds for one epoch ---
--- 1.646721601486206 seconds for one epoch ---
--- 0.3042337894439697 seconds for one epoch ---
--- 1.758669376373291 seconds for one epoch ---
--- 0.278958797454834 seconds for one epoch ---
--- 1.7489185333251953 seconds for one epoch ---
--- 0.2990396022796631 seconds for one epoch ---
--- 1.7493243217468262 seconds for one epoch ---
--- 0.22997117042541504 seconds for one epoch ---
--- 1.729731798171997 seconds for one epoch ---
--- 0.29612255096435547 seconds for one epoch ---
--- 1.7371549606323242 seconds for one epoch ---
--- 0.29606127738952637 seconds for one epoch ---
--- 1.7311697006225586 seconds for one epoch ---
--- 0.30167055130004883 seconds for one epoch ---
--- 1.7828271389007568 seconds for one epoch ---
--- 0.2929699420928955 seconds for one epoch ---
--- 1.7908408641815186 seconds for one epoch ---
--- 0.30440211296081543 seconds for one epoch ---
--- 1.7562446594238281 seconds for one epoch ---
--- 0.30664920806884766 seconds for one epoch ---
--- 1.8370451927185059 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1499127]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.105341]
 [ -0.      ]]
--- 0.29103541374206543 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4143.4208984375, (1533.104, 0.57606065, 2609.6006, 0.14005089)
   validation loss 751.298828125, (474.34323, 0.4579939, 276.3575, 0.14005089)
decoder loss ratio: 18376.880273, decoder SINDy loss  ratio: 0.596557
--- 0.2631990909576416 seconds for one epoch ---
--- 0.3031754493713379 seconds for one epoch ---
--- 1.8033897876739502 seconds for one epoch ---
--- 0.30209922790527344 seconds for one epoch ---
--- 1.778688907623291 seconds for one epoch ---
--- 0.3092224597930908 seconds for one epoch ---
--- 1.7596924304962158 seconds for one epoch ---
--- 0.2963242530822754 seconds for one epoch ---
--- 1.771355152130127 seconds for one epoch ---
--- 0.3044252395629883 seconds for one epoch ---
--- 1.7611675262451172 seconds for one epoch ---
--- 0.3080019950866699 seconds for one epoch ---
--- 1.7383549213409424 seconds for one epoch ---
--- 0.32724642753601074 seconds for one epoch ---
--- 1.6488430500030518 seconds for one epoch ---
--- 0.3035919666290283 seconds for one epoch ---
--- 1.732698917388916 seconds for one epoch ---
--- 0.2909843921661377 seconds for one epoch ---
--- 1.759977102279663 seconds for one epoch ---
--- 0.30072832107543945 seconds for one epoch ---
--- 1.7513582706451416 seconds for one epoch ---
--- 0.19639921188354492 seconds for one epoch ---
--- 1.7801783084869385 seconds for one epoch ---
--- 0.29334425926208496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14870243]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.158103]
 [  0.      ]]
--- 0.2685971260070801 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2477.446533203125, (852.30145, 1.5355535, 1623.4694, 0.1401987)
   validation loss 965.6267700195312, (671.3951, 0.4675525, 293.62393, 0.1401987)
decoder loss ratio: 26011.011014, decoder SINDy loss  ratio: 0.633829
--- 0.28835344314575195 seconds for one epoch ---
--- 1.7881767749786377 seconds for one epoch ---
--- 0.2923777103424072 seconds for one epoch ---
--- 1.7552475929260254 seconds for one epoch ---
--- 0.29325246810913086 seconds for one epoch ---
--- 1.7697880268096924 seconds for one epoch ---
--- 0.2915680408477783 seconds for one epoch ---
--- 1.7919526100158691 seconds for one epoch ---
--- 0.3145120143890381 seconds for one epoch ---
--- 1.7798388004302979 seconds for one epoch ---
--- 0.30698323249816895 seconds for one epoch ---
--- 1.7849314212799072 seconds for one epoch ---
--- 0.3025176525115967 seconds for one epoch ---
--- 1.8088200092315674 seconds for one epoch ---
--- 0.3016800880432129 seconds for one epoch ---
--- 1.7848944664001465 seconds for one epoch ---
--- 0.2963836193084717 seconds for one epoch ---
--- 1.777026891708374 seconds for one epoch ---
--- 0.2953505516052246 seconds for one epoch ---
--- 1.7963764667510986 seconds for one epoch ---
--- 0.29753971099853516 seconds for one epoch ---
--- 1.7995846271514893 seconds for one epoch ---
--- 0.3044097423553467 seconds for one epoch ---
--- 1.759592056274414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14776134]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.198935]
 [  0.      ]]
--- 0.1942739486694336 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1857.810791015625, (1118.0344, 2.5655658, 737.07056, 0.14029305)
   validation loss 929.524658203125, (635.62103, 0.48789722, 293.2754, 0.14029305)
decoder loss ratio: 24625.062294, decoder SINDy loss  ratio: 0.633076
--- 0.27367663383483887 seconds for one epoch ---
--- 0.2999453544616699 seconds for one epoch ---
--- 1.7751491069793701 seconds for one epoch ---
--- 0.2928743362426758 seconds for one epoch ---
--- 1.7949445247650146 seconds for one epoch ---
--- 0.29341745376586914 seconds for one epoch ---
--- 1.8022289276123047 seconds for one epoch ---
--- 0.2999608516693115 seconds for one epoch ---
--- 1.7927756309509277 seconds for one epoch ---
--- 0.2885723114013672 seconds for one epoch ---
--- 1.6694655418395996 seconds for one epoch ---
--- 0.24156928062438965 seconds for one epoch ---
--- 1.7922132015228271 seconds for one epoch ---
--- 0.3082585334777832 seconds for one epoch ---
--- 1.799574851989746 seconds for one epoch ---
--- 0.28388428688049316 seconds for one epoch ---
--- 1.8034121990203857 seconds for one epoch ---
--- 0.3018972873687744 seconds for one epoch ---
--- 1.776606798171997 seconds for one epoch ---
--- 0.28964877128601074 seconds for one epoch ---
--- 1.7653465270996094 seconds for one epoch ---
--- 0.3047332763671875 seconds for one epoch ---
--- 1.7732226848602295 seconds for one epoch ---
--- 0.21675467491149902 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14666206]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.246437]
 [ -0.      ]]
--- 0.2657172679901123 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2569.44091796875, (1066.3271, 1.0748731, 1501.8986, 0.1404209)
   validation loss 1108.2855224609375, (803.2179, 0.4647503, 304.46255, 0.1404209)
decoder loss ratio: 31118.055720, decoder SINDy loss  ratio: 0.657225
--- 0.30396127700805664 seconds for one epoch ---
--- 1.7866284847259521 seconds for one epoch ---
--- 0.29004406929016113 seconds for one epoch ---
--- 1.8091347217559814 seconds for one epoch ---
--- 0.29531335830688477 seconds for one epoch ---
--- 1.7948877811431885 seconds for one epoch ---
--- 0.3033480644226074 seconds for one epoch ---
--- 1.792353630065918 seconds for one epoch ---
--- 0.3053584098815918 seconds for one epoch ---
--- 1.8499646186828613 seconds for one epoch ---
--- 0.3141820430755615 seconds for one epoch ---
--- 1.8109140396118164 seconds for one epoch ---
--- 0.3038671016693115 seconds for one epoch ---
--- 1.7969107627868652 seconds for one epoch ---
--- 0.2524886131286621 seconds for one epoch ---
--- 1.8332173824310303 seconds for one epoch ---
--- 0.2891225814819336 seconds for one epoch ---
--- 1.8192567825317383 seconds for one epoch ---
--- 0.3120386600494385 seconds for one epoch ---
--- 1.9047532081604004 seconds for one epoch ---
--- 0.3029294013977051 seconds for one epoch ---
--- 1.784731149673462 seconds for one epoch ---
--- 0.29190921783447266 seconds for one epoch ---
--- 1.8169479370117188 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14554064]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.294719]
 [ -0.      ]]
--- 0.29415345191955566 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3815.1298828125, (1279.1907, 1.3657539, 2534.4329, 0.14053929)
   validation loss 943.8465576171875, (666.0494, 0.50863254, 277.148, 0.14053929)
decoder loss ratio: 25803.909195, decoder SINDy loss  ratio: 0.598263
--- 0.28434300422668457 seconds for one epoch ---
--- 0.3002316951751709 seconds for one epoch ---
--- 1.7674615383148193 seconds for one epoch ---
--- 0.29834723472595215 seconds for one epoch ---
--- 1.7780277729034424 seconds for one epoch ---
--- 0.16801095008850098 seconds for one epoch ---
--- 1.8036525249481201 seconds for one epoch ---
--- 0.2841765880584717 seconds for one epoch ---
--- 1.809572458267212 seconds for one epoch ---
--- 0.2943089008331299 seconds for one epoch ---
--- 1.8838751316070557 seconds for one epoch ---
--- 0.29297900199890137 seconds for one epoch ---
--- 1.7997934818267822 seconds for one epoch ---
--- 0.31069111824035645 seconds for one epoch ---
--- 1.7854704856872559 seconds for one epoch ---
--- 0.27544260025024414 seconds for one epoch ---
--- 1.8381657600402832 seconds for one epoch ---
--- 0.30309534072875977 seconds for one epoch ---
--- 1.8137269020080566 seconds for one epoch ---
--- 0.2930879592895508 seconds for one epoch ---
--- 1.8413686752319336 seconds for one epoch ---
--- 0.2979462146759033 seconds for one epoch ---
--- 1.8592259883880615 seconds for one epoch ---
--- 0.3023195266723633 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14450803]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.339001]
 [  0.      ]]
--- 0.23821353912353516 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2385.729248046875, (1171.3654, 1.6115557, 1212.6117, 0.14065015)
   validation loss 794.151611328125, (518.26654, 0.47095737, 275.2735, 0.14065015)
decoder loss ratio: 20078.545530, decoder SINDy loss  ratio: 0.594217
--- 0.2881503105163574 seconds for one epoch ---
--- 1.819514513015747 seconds for one epoch ---
--- 0.3058784008026123 seconds for one epoch ---
--- 1.8205878734588623 seconds for one epoch ---
--- 0.2852010726928711 seconds for one epoch ---
--- 1.7390780448913574 seconds for one epoch ---
--- 0.244384765625 seconds for one epoch ---
--- 1.8360815048217773 seconds for one epoch ---
--- 0.2891559600830078 seconds for one epoch ---
--- 1.825758695602417 seconds for one epoch ---
--- 0.288266658782959 seconds for one epoch ---
--- 1.8049659729003906 seconds for one epoch ---
--- 0.28717494010925293 seconds for one epoch ---
--- 1.8115081787109375 seconds for one epoch ---
--- 0.29583048820495605 seconds for one epoch ---
--- 1.8109705448150635 seconds for one epoch ---
--- 0.2974569797515869 seconds for one epoch ---
--- 1.8607642650604248 seconds for one epoch ---
--- 0.30754613876342773 seconds for one epoch ---
--- 1.803797721862793 seconds for one epoch ---
--- 0.28125691413879395 seconds for one epoch ---
--- 1.8244147300720215 seconds for one epoch ---
--- 0.29915785789489746 seconds for one epoch ---
--- 1.8635287284851074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14349838]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.382159]
 [ -0.      ]]
--- 0.3024721145629883 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3959.137451171875, (983.8448, 1.6500468, 2973.5017, 0.14075394)
   validation loss 1037.7574462890625, (766.3122, 0.5072903, 270.7972, 0.14075394)
decoder loss ratio: 29688.264804, decoder SINDy loss  ratio: 0.584554
--- 0.26377320289611816 seconds for one epoch ---
--- 0.3052678108215332 seconds for one epoch ---
--- 1.8626134395599365 seconds for one epoch ---
--- 0.30014467239379883 seconds for one epoch ---
--- 1.7987782955169678 seconds for one epoch ---
--- 0.30066633224487305 seconds for one epoch ---
--- 1.8306934833526611 seconds for one epoch ---
--- 0.2732398509979248 seconds for one epoch ---
--- 1.8646142482757568 seconds for one epoch ---
--- 0.30880212783813477 seconds for one epoch ---
--- 1.8983094692230225 seconds for one epoch ---
--- 0.28260016441345215 seconds for one epoch ---
--- 1.8358607292175293 seconds for one epoch ---
--- 0.3021976947784424 seconds for one epoch ---
--- 1.863133430480957 seconds for one epoch ---
--- 0.31246328353881836 seconds for one epoch ---
--- 1.825343132019043 seconds for one epoch ---
--- 0.2967948913574219 seconds for one epoch ---
--- 1.8073337078094482 seconds for one epoch ---
--- 0.29140806198120117 seconds for one epoch ---
--- 1.861248254776001 seconds for one epoch ---
--- 0.2901930809020996 seconds for one epoch ---
--- 1.8661634922027588 seconds for one epoch ---
--- 0.29350829124450684 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14253324]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.423284]
 [  0.      ]]
--- 0.26281118392944336 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2147.415771484375, (905.4376, 0.7246256, 1241.1127, 0.14086054)
   validation loss 1160.422119140625, (861.1414, 0.5137789, 298.62604, 0.14086054)
decoder loss ratio: 33362.113558, decoder SINDy loss  ratio: 0.644626
--- 0.2918097972869873 seconds for one epoch ---
--- 1.9283418655395508 seconds for one epoch ---
--- 0.298112154006958 seconds for one epoch ---
--- 1.8664829730987549 seconds for one epoch ---
--- 0.2986907958984375 seconds for one epoch ---
--- 1.8319754600524902 seconds for one epoch ---
--- 0.27767157554626465 seconds for one epoch ---
--- 1.8209176063537598 seconds for one epoch ---
--- 0.31308698654174805 seconds for one epoch ---
--- 1.865830898284912 seconds for one epoch ---
--- 0.2922234535217285 seconds for one epoch ---
--- 1.9017415046691895 seconds for one epoch ---
--- 0.306720495223999 seconds for one epoch ---
--- 1.8273646831512451 seconds for one epoch ---
--- 0.29706764221191406 seconds for one epoch ---
--- 1.8910107612609863 seconds for one epoch ---
--- 0.30362653732299805 seconds for one epoch ---
--- 1.8337278366088867 seconds for one epoch ---
--- 0.29393839836120605 seconds for one epoch ---
--- 1.8386094570159912 seconds for one epoch ---
--- 0.30608415603637695 seconds for one epoch ---
--- 1.8624534606933594 seconds for one epoch ---
--- 0.29985880851745605 seconds for one epoch ---
--- 1.838986873626709 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1415868]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.463487]
 [  0.      ]]
--- 0.2917013168334961 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1976.7176513671875, (1039.9552, 1.0351775, 935.58636, 0.14095262)
   validation loss 850.0006713867188, (573.1431, 0.62059003, 276.09598, 0.14095262)
decoder loss ratio: 22204.559777, decoder SINDy loss  ratio: 0.595992
--- 0.27141642570495605 seconds for one epoch ---
--- 0.28772783279418945 seconds for one epoch ---
--- 1.818220615386963 seconds for one epoch ---
--- 0.29485416412353516 seconds for one epoch ---
--- 1.7752528190612793 seconds for one epoch ---
--- 0.17353248596191406 seconds for one epoch ---
--- 1.8662734031677246 seconds for one epoch ---
--- 0.29491710662841797 seconds for one epoch ---
--- 1.839879035949707 seconds for one epoch ---
--- 0.3070497512817383 seconds for one epoch ---
--- 1.8203113079071045 seconds for one epoch ---
--- 0.17201638221740723 seconds for one epoch ---
--- 1.8695180416107178 seconds for one epoch ---
--- 0.2989070415496826 seconds for one epoch ---
--- 1.8527207374572754 seconds for one epoch ---
--- 0.306624174118042 seconds for one epoch ---
--- 1.8548996448516846 seconds for one epoch ---
--- 0.28835058212280273 seconds for one epoch ---
--- 1.8662090301513672 seconds for one epoch ---
--- 0.28910088539123535 seconds for one epoch ---
--- 1.8531785011291504 seconds for one epoch ---
--- 0.3000764846801758 seconds for one epoch ---
--- 1.8589715957641602 seconds for one epoch ---
--- 0.29900503158569336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14059025]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.505706]
 [ -0.      ]]
--- 0.24852824211120605 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3669.06298828125, (1825.1056, 1.6638025, 1842.1526, 0.14105554)
   validation loss 765.7994995117188, (497.7404, 0.5348923, 267.38315, 0.14105554)
decoder loss ratio: 19283.326706, decoder SINDy loss  ratio: 0.577184
--- 0.3000223636627197 seconds for one epoch ---
--- 1.8671674728393555 seconds for one epoch ---
--- 0.2887125015258789 seconds for one epoch ---
--- 1.8727822303771973 seconds for one epoch ---
--- 0.2735483646392822 seconds for one epoch ---
--- 1.8506348133087158 seconds for one epoch ---
--- 0.2909886837005615 seconds for one epoch ---
--- 1.8731577396392822 seconds for one epoch ---
--- 0.3027632236480713 seconds for one epoch ---
--- 1.8575165271759033 seconds for one epoch ---
--- 0.29865026473999023 seconds for one epoch ---
--- 1.8551032543182373 seconds for one epoch ---
--- 0.304563045501709 seconds for one epoch ---
--- 1.8504295349121094 seconds for one epoch ---
--- 0.3071763515472412 seconds for one epoch ---
--- 1.910188913345337 seconds for one epoch ---
--- 0.2898256778717041 seconds for one epoch ---
--- 1.874342918395996 seconds for one epoch ---
--- 0.28992366790771484 seconds for one epoch ---
--- 1.897819995880127 seconds for one epoch ---
--- 0.3084290027618408 seconds for one epoch ---
--- 1.8686180114746094 seconds for one epoch ---
--- 0.28582096099853516 seconds for one epoch ---
--- 1.8748033046722412 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13950351]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.551625]
 [ -0.      ]]
--- 0.2943899631500244 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3500.910400390625, (1331.8865, 0.9880166, 2167.8948, 0.14116062)
   validation loss 854.8391723632812, (580.10474, 0.4885767, 274.10464, 0.14116062)
decoder loss ratio: 22474.264591, decoder SINDy loss  ratio: 0.591693
--- 0.25293707847595215 seconds for one epoch ---
--- 0.28244662284851074 seconds for one epoch ---
--- 1.8402025699615479 seconds for one epoch ---
--- 0.15673470497131348 seconds for one epoch ---
--- 1.8309175968170166 seconds for one epoch ---
--- 0.2891108989715576 seconds for one epoch ---
--- 1.864717721939087 seconds for one epoch ---
--- 0.2992429733276367 seconds for one epoch ---
--- 1.8773107528686523 seconds for one epoch ---
--- 0.30145263671875 seconds for one epoch ---
--- 1.9095396995544434 seconds for one epoch ---
--- 0.29119372367858887 seconds for one epoch ---
--- 1.8631327152252197 seconds for one epoch ---
--- 0.3016202449798584 seconds for one epoch ---
--- 1.7786614894866943 seconds for one epoch ---
--- 0.29753994941711426 seconds for one epoch ---
--- 1.886836051940918 seconds for one epoch ---
--- 0.2758970260620117 seconds for one epoch ---
--- 1.884948492050171 seconds for one epoch ---
--- 0.29813647270202637 seconds for one epoch ---
--- 1.9089252948760986 seconds for one epoch ---
--- 0.29178571701049805 seconds for one epoch ---
--- 1.8548805713653564 seconds for one epoch ---
--- 0.29099249839782715 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13834031]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.600627]
 [  0.      ]]
--- 0.26929354667663574 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2187.587158203125, (1056.032, 1.1567008, 1130.2572, 0.14127374)
   validation loss 765.5380859375, (482.29153, 0.54153174, 282.56372, 0.14127374)
decoder loss ratio: 18684.811339, decoder SINDy loss  ratio: 0.609954
--- 0.2965354919433594 seconds for one epoch ---
--- 1.9155099391937256 seconds for one epoch ---
--- 0.30678343772888184 seconds for one epoch ---
--- 1.8884918689727783 seconds for one epoch ---
--- 0.3036763668060303 seconds for one epoch ---
--- 1.886504888534546 seconds for one epoch ---
--- 0.3010103702545166 seconds for one epoch ---
--- 1.8657140731811523 seconds for one epoch ---
--- 0.28534412384033203 seconds for one epoch ---
--- 1.8886702060699463 seconds for one epoch ---
--- 0.29537367820739746 seconds for one epoch ---
--- 1.8586063385009766 seconds for one epoch ---
--- 0.3025026321411133 seconds for one epoch ---
--- 1.8940327167510986 seconds for one epoch ---
--- 0.3005819320678711 seconds for one epoch ---
--- 1.9371721744537354 seconds for one epoch ---
--- 0.3060743808746338 seconds for one epoch ---
--- 1.9073786735534668 seconds for one epoch ---
--- 0.2898557186126709 seconds for one epoch ---
--- 1.8596653938293457 seconds for one epoch ---
--- 0.30147361755371094 seconds for one epoch ---
--- 1.9256842136383057 seconds for one epoch ---
--- 0.29697728157043457 seconds for one epoch ---
--- 1.8929593563079834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13726483]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.645822]
 [ -0.      ]]
--- 0.2935211658477783 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3707.529541015625, (1803.1296, 1.4440082, 1902.8146, 0.14136945)
   validation loss 740.4600219726562, (479.5091, 0.5181931, 260.29138, 0.14136945)
decoder loss ratio: 18577.014775, decoder SINDy loss  ratio: 0.561876
--- 0.26192235946655273 seconds for one epoch ---
--- 0.3039534091949463 seconds for one epoch ---
--- 1.9070560932159424 seconds for one epoch ---
--- 0.305464506149292 seconds for one epoch ---
--- 1.9286644458770752 seconds for one epoch ---
--- 0.2969965934753418 seconds for one epoch ---
--- 1.9506046772003174 seconds for one epoch ---
--- 0.2953827381134033 seconds for one epoch ---
--- 1.9169285297393799 seconds for one epoch ---
--- 0.3056221008300781 seconds for one epoch ---
--- 1.8908143043518066 seconds for one epoch ---
--- 0.32106494903564453 seconds for one epoch ---
--- 1.8496356010437012 seconds for one epoch ---
--- 0.2982649803161621 seconds for one epoch ---
--- 1.9469923973083496 seconds for one epoch ---
--- 0.29592156410217285 seconds for one epoch ---
--- 1.9991998672485352 seconds for one epoch ---
--- 0.28473877906799316 seconds for one epoch ---
--- 1.8847205638885498 seconds for one epoch ---
--- 0.29195404052734375 seconds for one epoch ---
--- 1.902705430984497 seconds for one epoch ---
--- 0.27353930473327637 seconds for one epoch ---
--- 1.8977086544036865 seconds for one epoch ---
--- 0.3001739978790283 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13597216]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.699989]
 [  0.      ]]
--- 0.26409268379211426 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3632.18115234375, (1784.7855, 3.1287396, 1844.1254, 0.14147966)
   validation loss 798.7033081054688, (532.5585, 0.47302347, 265.53033, 0.14147966)
decoder loss ratio: 20632.239755, decoder SINDy loss  ratio: 0.573185
--- 0.28870439529418945 seconds for one epoch ---
--- 1.901561975479126 seconds for one epoch ---
--- 0.2981889247894287 seconds for one epoch ---
--- 1.898984432220459 seconds for one epoch ---
--- 0.28085947036743164 seconds for one epoch ---
--- 1.8689100742340088 seconds for one epoch ---
--- 0.3015718460083008 seconds for one epoch ---
--- 1.8984990119934082 seconds for one epoch ---
--- 0.2978219985961914 seconds for one epoch ---
--- 1.9086236953735352 seconds for one epoch ---
--- 0.28791332244873047 seconds for one epoch ---
--- 1.9082438945770264 seconds for one epoch ---
--- 0.31165528297424316 seconds for one epoch ---
--- 1.9038629531860352 seconds for one epoch ---
--- 0.30317139625549316 seconds for one epoch ---
--- 1.908473014831543 seconds for one epoch ---
--- 0.29152917861938477 seconds for one epoch ---
--- 1.9170434474945068 seconds for one epoch ---
--- 0.2970445156097412 seconds for one epoch ---
--- 1.912961721420288 seconds for one epoch ---
--- 0.29919004440307617 seconds for one epoch ---
--- 1.9172308444976807 seconds for one epoch ---
--- 0.3065207004547119 seconds for one epoch ---
--- 1.9204604625701904 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13498716]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.74117]
 [  0.     ]]
--- 0.31264758110046387 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2957.461669921875, (1152.8986, 2.1667774, 1802.2548, 0.14157636)
   validation loss 781.0225830078125, (505.26477, 0.48359206, 275.13266, 0.14157636)
decoder loss ratio: 19574.834388, decoder SINDy loss  ratio: 0.593913
--- 0.27116942405700684 seconds for one epoch ---
--- 0.2912924289703369 seconds for one epoch ---
--- 1.8611865043640137 seconds for one epoch ---
--- 0.22428488731384277 seconds for one epoch ---
--- 1.9268198013305664 seconds for one epoch ---
--- 0.30683422088623047 seconds for one epoch ---
--- 1.9253816604614258 seconds for one epoch ---
--- 0.3012228012084961 seconds for one epoch ---
--- 1.9123175144195557 seconds for one epoch ---
--- 0.1522047519683838 seconds for one epoch ---
--- 1.9330933094024658 seconds for one epoch ---
--- 0.3032822608947754 seconds for one epoch ---
--- 1.938777208328247 seconds for one epoch ---
--- 0.30840229988098145 seconds for one epoch ---
--- 1.7936558723449707 seconds for one epoch ---
--- 0.20568132400512695 seconds for one epoch ---
--- 1.9587397575378418 seconds for one epoch ---
--- 0.2961463928222656 seconds for one epoch ---
--- 1.9156768321990967 seconds for one epoch ---
--- 0.30435633659362793 seconds for one epoch ---
--- 1.7978715896606445 seconds for one epoch ---
--- 0.2560558319091797 seconds for one epoch ---
--- 1.910670280456543 seconds for one epoch ---
--- 0.3009185791015625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13382126]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.789824]
 [ -0.      ]]
--- 0.253101110458374 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3154.9140625, (1273.0074, 3.4012678, 1878.3638, 0.14167863)
   validation loss 829.1471557617188, (547.9306, 0.4890331, 280.58588, 0.14167863)
decoder loss ratio: 21227.782811, decoder SINDy loss  ratio: 0.605684
--- 0.30130696296691895 seconds for one epoch ---
--- 1.9588305950164795 seconds for one epoch ---
--- 0.27378106117248535 seconds for one epoch ---
--- 2.0661699771881104 seconds for one epoch ---
--- 0.30362629890441895 seconds for one epoch ---
--- 1.9581215381622314 seconds for one epoch ---
--- 0.3026123046875 seconds for one epoch ---
--- 2.018639087677002 seconds for one epoch ---
--- 0.29764533042907715 seconds for one epoch ---
--- 1.9717280864715576 seconds for one epoch ---
--- 0.3052990436553955 seconds for one epoch ---
--- 1.9261419773101807 seconds for one epoch ---
--- 0.29143643379211426 seconds for one epoch ---
--- 1.9252679347991943 seconds for one epoch ---
--- 0.20519518852233887 seconds for one epoch ---
--- 1.9156968593597412 seconds for one epoch ---
--- 0.2980372905731201 seconds for one epoch ---
--- 1.9368982315063477 seconds for one epoch ---
--- 0.3047003746032715 seconds for one epoch ---
--- 1.9585669040679932 seconds for one epoch ---
--- 0.30761289596557617 seconds for one epoch ---
--- 1.9330763816833496 seconds for one epoch ---
--- 0.2991209030151367 seconds for one epoch ---
--- 1.9387829303741455 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13294724]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.82622]
 [ -0.     ]]
--- 0.29869985580444336 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1818.2191162109375, (962.8526, 1.1108644, 854.1139, 0.14174666)
   validation loss 742.3475341796875, (480.0574, 0.49481228, 261.6536, 0.14174666)
decoder loss ratio: 18598.257230, decoder SINDy loss  ratio: 0.564816
THRESHOLDING: 1 active coefficients
--- 1.9218432903289795 seconds for one epoch ---
--- 0.3057103157043457 seconds for one epoch ---
--- 1.983595609664917 seconds for one epoch ---
--- 0.2989370822906494 seconds for one epoch ---
--- 1.9264373779296875 seconds for one epoch ---
--- 0.3001832962036133 seconds for one epoch ---
--- 1.9386167526245117 seconds for one epoch ---
--- 0.3068366050720215 seconds for one epoch ---
--- 1.9491395950317383 seconds for one epoch ---
--- 0.29615211486816406 seconds for one epoch ---
--- 1.939115047454834 seconds for one epoch ---
--- 0.3131446838378906 seconds for one epoch ---
--- 1.9408445358276367 seconds for one epoch ---
--- 0.30265355110168457 seconds for one epoch ---
--- 1.996842384338379 seconds for one epoch ---
--- 0.30089497566223145 seconds for one epoch ---
--- 1.948028564453125 seconds for one epoch ---
--- 0.3026425838470459 seconds for one epoch ---
--- 1.9396557807922363 seconds for one epoch ---
--- 0.30133700370788574 seconds for one epoch ---
--- 1.979860544204712 seconds for one epoch ---
--- 0.2948000431060791 seconds for one epoch ---
--- 1.9722082614898682 seconds for one epoch ---
--- 0.301680326461792 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13202387]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.864624]
 [  0.      ]]
--- 0.25328731536865234 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5460.6279296875, (2726.7495, 8.661911, 2725.0752, 0.1418284)
   validation loss 733.4095458984375, (456.54285, 0.61296403, 276.11188, 0.1418284)
decoder loss ratio: 17687.262474, decoder SINDy loss  ratio: 0.596026
--- 0.27794981002807617 seconds for one epoch ---
--- 1.9606051445007324 seconds for one epoch ---
--- 0.3070704936981201 seconds for one epoch ---
--- 1.9543440341949463 seconds for one epoch ---
--- 0.31359338760375977 seconds for one epoch ---
--- 2.004612922668457 seconds for one epoch ---
--- 0.29525279998779297 seconds for one epoch ---
--- 2.1115145683288574 seconds for one epoch ---
--- 0.29419922828674316 seconds for one epoch ---
--- 2.0120770931243896 seconds for one epoch ---
--- 0.2985827922821045 seconds for one epoch ---
--- 2.0002026557922363 seconds for one epoch ---
--- 0.30573034286499023 seconds for one epoch ---
--- 1.9910554885864258 seconds for one epoch ---
--- 0.2959895133972168 seconds for one epoch ---
--- 1.9867491722106934 seconds for one epoch ---
--- 0.29720020294189453 seconds for one epoch ---
--- 1.9896867275238037 seconds for one epoch ---
--- 0.29575228691101074 seconds for one epoch ---
--- 1.9714488983154297 seconds for one epoch ---
--- 0.3023416996002197 seconds for one epoch ---
--- 1.9814667701721191 seconds for one epoch ---
--- 0.20756149291992188 seconds for one epoch ---
--- 1.9816887378692627 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13102624]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.906059]
 [ -0.      ]]
--- 0.2890627384185791 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2461.663818359375, (1051.3446, 7.240997, 1402.9365, 0.14190911)
   validation loss 811.2892456054688, (535.58044, 0.5493408, 275.01755, 0.14190911)
decoder loss ratio: 20749.316222, decoder SINDy loss  ratio: 0.593664
--- 0.27499914169311523 seconds for one epoch ---
--- 0.3047752380371094 seconds for one epoch ---
--- 2.0028514862060547 seconds for one epoch ---
--- 0.3036978244781494 seconds for one epoch ---
--- 1.9864764213562012 seconds for one epoch ---
--- 0.29322052001953125 seconds for one epoch ---
--- 1.9883990287780762 seconds for one epoch ---
--- 0.3090231418609619 seconds for one epoch ---
--- 1.9996542930603027 seconds for one epoch ---
--- 0.3145585060119629 seconds for one epoch ---
--- 1.987858772277832 seconds for one epoch ---
--- 0.30093932151794434 seconds for one epoch ---
--- 1.9744129180908203 seconds for one epoch ---
--- 0.3021683692932129 seconds for one epoch ---
--- 2.0101711750030518 seconds for one epoch ---
--- 0.3071739673614502 seconds for one epoch ---
--- 1.9749360084533691 seconds for one epoch ---
--- 0.2926912307739258 seconds for one epoch ---
--- 2.03147029876709 seconds for one epoch ---
--- 0.30789923667907715 seconds for one epoch ---
--- 2.0132124423980713 seconds for one epoch ---
--- 0.3027794361114502 seconds for one epoch ---
--- 2.0205562114715576 seconds for one epoch ---
--- 0.3039896488189697 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1300344]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.947194]
 [  0.      ]]
--- 0.2698783874511719 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2783.8916015625, (1339.7311, 1.9411753, 1442.0773, 0.14199288)
   validation loss 761.4752197265625, (492.4975, 0.6110687, 268.2247, 0.14199288)
decoder loss ratio: 19080.208069, decoder SINDy loss  ratio: 0.579001
--- 0.3019835948944092 seconds for one epoch ---
--- 1.976536512374878 seconds for one epoch ---
--- 0.2956259250640869 seconds for one epoch ---
--- 1.985419511795044 seconds for one epoch ---
--- 0.17142248153686523 seconds for one epoch ---
--- 2.0137810707092285 seconds for one epoch ---
--- 0.2755882740020752 seconds for one epoch ---
--- 2.1065452098846436 seconds for one epoch ---
--- 0.31237196922302246 seconds for one epoch ---
--- 1.951465129852295 seconds for one epoch ---
--- 0.1723165512084961 seconds for one epoch ---
--- 1.9918670654296875 seconds for one epoch ---
--- 0.2988545894622803 seconds for one epoch ---
--- 2.005741596221924 seconds for one epoch ---
--- 0.29717254638671875 seconds for one epoch ---
--- 2.022118091583252 seconds for one epoch ---
--- 0.3130974769592285 seconds for one epoch ---
--- 2.0275559425354004 seconds for one epoch ---
--- 0.28855252265930176 seconds for one epoch ---
--- 2.0302956104278564 seconds for one epoch ---
--- 0.18539118766784668 seconds for one epoch ---
--- 2.024773120880127 seconds for one epoch ---
--- 0.31008267402648926 seconds for one epoch ---
--- 2.030630588531494 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.129192]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.982092]
 [  0.      ]]
--- 0.29956674575805664 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2898.1298828125, (1493.5051, 1.972741, 1402.51, 0.14206088)
   validation loss 784.8214111328125, (516.47046, 0.58801466, 267.62088, 0.14206088)
decoder loss ratio: 20008.962213, decoder SINDy loss  ratio: 0.577697
--- 0.26082921028137207 seconds for one epoch ---
--- 0.30252623558044434 seconds for one epoch ---
--- 2.006213665008545 seconds for one epoch ---
--- 0.2936997413635254 seconds for one epoch ---
--- 2.0365397930145264 seconds for one epoch ---
--- 0.2967801094055176 seconds for one epoch ---
--- 1.9922118186950684 seconds for one epoch ---
--- 0.29777073860168457 seconds for one epoch ---
--- 2.0049374103546143 seconds for one epoch ---
--- 0.30084753036499023 seconds for one epoch ---
--- 2.0167739391326904 seconds for one epoch ---
--- 0.30718183517456055 seconds for one epoch ---
--- 2.012873411178589 seconds for one epoch ---
--- 0.30548882484436035 seconds for one epoch ---
--- 2.028519868850708 seconds for one epoch ---
--- 0.30094289779663086 seconds for one epoch ---
--- 1.998741865158081 seconds for one epoch ---
--- 0.29711365699768066 seconds for one epoch ---
--- 2.0345382690429688 seconds for one epoch ---
--- 0.18031764030456543 seconds for one epoch ---
--- 2.0305638313293457 seconds for one epoch ---
--- 0.2982039451599121 seconds for one epoch ---
--- 2.0182688236236572 seconds for one epoch ---
--- 0.2882058620452881 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12833643]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.017496]
 [ -0.      ]]
--- 0.25775647163391113 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2909.639404296875, (1479.4048, 7.286503, 1422.806, 0.14212562)
   validation loss 795.8400268554688, (526.08984, 0.63704294, 268.971, 0.14212562)
decoder loss ratio: 20381.633879, decoder SINDy loss  ratio: 0.580612
--- 0.30328845977783203 seconds for one epoch ---
--- 2.0062668323516846 seconds for one epoch ---
--- 0.29865550994873047 seconds for one epoch ---
--- 2.0231096744537354 seconds for one epoch ---
--- 0.29326820373535156 seconds for one epoch ---
--- 2.0445518493652344 seconds for one epoch ---
--- 0.29507875442504883 seconds for one epoch ---
--- 2.0097930431365967 seconds for one epoch ---
--- 0.2593555450439453 seconds for one epoch ---
--- 2.0232605934143066 seconds for one epoch ---
--- 0.29579710960388184 seconds for one epoch ---
--- 2.056580066680908 seconds for one epoch ---
--- 0.2878537178039551 seconds for one epoch ---
--- 2.0238263607025146 seconds for one epoch ---
--- 0.2910764217376709 seconds for one epoch ---
--- 2.038907289505005 seconds for one epoch ---
--- 0.294971227645874 seconds for one epoch ---
--- 2.0551435947418213 seconds for one epoch ---
--- 0.28592824935913086 seconds for one epoch ---
--- 2.049126625061035 seconds for one epoch ---
--- 0.30711913108825684 seconds for one epoch ---
--- 2.0516533851623535 seconds for one epoch ---
--- 0.30568671226501465 seconds for one epoch ---
--- 1.9404449462890625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12747763]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.0530205]
 [ -0.       ]]
--- 0.299069881439209 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2870.77490234375, (1626.752, 1.7409176, 1242.1398, 0.14219926)
   validation loss 967.3873291015625, (653.7334, 0.5540103, 312.9577, 0.14219926)
decoder loss ratio: 25326.766787, decoder SINDy loss  ratio: 0.675563
--- 0.26318907737731934 seconds for one epoch ---
--- 0.3053734302520752 seconds for one epoch ---
--- 2.0689449310302734 seconds for one epoch ---
--- 0.3093249797821045 seconds for one epoch ---
--- 2.0501885414123535 seconds for one epoch ---
--- 0.29689478874206543 seconds for one epoch ---
--- 2.055327892303467 seconds for one epoch ---
--- 0.2359158992767334 seconds for one epoch ---
--- 2.080188274383545 seconds for one epoch ---
--- 0.3016347885131836 seconds for one epoch ---
--- 2.0720903873443604 seconds for one epoch ---
--- 0.30571413040161133 seconds for one epoch ---
--- 2.0396728515625 seconds for one epoch ---
--- 0.3053164482116699 seconds for one epoch ---
--- 2.053013324737549 seconds for one epoch ---
--- 0.2977619171142578 seconds for one epoch ---
--- 2.058175563812256 seconds for one epoch ---
--- 0.3078420162200928 seconds for one epoch ---
--- 2.100914716720581 seconds for one epoch ---
--- 0.3114943504333496 seconds for one epoch ---
--- 2.0444114208221436 seconds for one epoch ---
--- 0.29229259490966797 seconds for one epoch ---
--- 2.0535049438476562 seconds for one epoch ---
--- 0.29864978790283203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12653078]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.092133]
 [  0.      ]]
--- 0.28508853912353516 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5006.49365234375, (948.4, 3.821759, 4054.13, 0.14227223)
   validation loss 691.9710083007812, (403.81436, 0.5856224, 287.42877, 0.14227223)
decoder loss ratio: 15644.469420, decoder SINDy loss  ratio: 0.620455
--- 0.29346132278442383 seconds for one epoch ---
--- 2.0309503078460693 seconds for one epoch ---
--- 0.29173946380615234 seconds for one epoch ---
--- 2.0393035411834717 seconds for one epoch ---
--- 0.29494500160217285 seconds for one epoch ---
--- 2.0496163368225098 seconds for one epoch ---
--- 0.2889440059661865 seconds for one epoch ---
--- 2.0449845790863037 seconds for one epoch ---
--- 0.2927894592285156 seconds for one epoch ---
--- 2.0288684368133545 seconds for one epoch ---
--- 0.30402398109436035 seconds for one epoch ---
--- 2.0784993171691895 seconds for one epoch ---
--- 0.29964303970336914 seconds for one epoch ---
--- 2.021678924560547 seconds for one epoch ---
--- 0.2966330051422119 seconds for one epoch ---
--- 2.0476744174957275 seconds for one epoch ---
--- 0.2831900119781494 seconds for one epoch ---
--- 2.1139373779296875 seconds for one epoch ---
--- 0.30296921730041504 seconds for one epoch ---
--- 2.0753731727600098 seconds for one epoch ---
--- 0.3035306930541992 seconds for one epoch ---
--- 2.045192003250122 seconds for one epoch ---
--- 0.3236396312713623 seconds for one epoch ---
--- 2.0672755241394043 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12559332]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.130849]
 [ -0.      ]]
--- 0.30292367935180664 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2176.69091796875, (762.7007, 12.037524, 1401.8103, 0.14234239)
   validation loss 800.5902099609375, (520.8613, 0.5903449, 278.99625, 0.14234239)
decoder loss ratio: 20179.072107, decoder SINDy loss  ratio: 0.602253
--- 0.26340222358703613 seconds for one epoch ---
--- 0.297210693359375 seconds for one epoch ---
--- 2.0689945220947266 seconds for one epoch ---
--- 0.30878281593322754 seconds for one epoch ---
--- 2.053060531616211 seconds for one epoch ---
--- 0.3067300319671631 seconds for one epoch ---
--- 2.0848207473754883 seconds for one epoch ---
--- 0.3065359592437744 seconds for one epoch ---
--- 2.0623717308044434 seconds for one epoch ---
--- 0.30254578590393066 seconds for one epoch ---
--- 1.9560472965240479 seconds for one epoch ---
--- 0.2928791046142578 seconds for one epoch ---
--- 2.0580708980560303 seconds for one epoch ---
--- 0.2851431369781494 seconds for one epoch ---
--- 2.0381674766540527 seconds for one epoch ---
--- 0.3074026107788086 seconds for one epoch ---
--- 2.094071626663208 seconds for one epoch ---
--- 0.28034019470214844 seconds for one epoch ---
--- 2.0730414390563965 seconds for one epoch ---
--- 0.3020014762878418 seconds for one epoch ---
--- 2.054095506668091 seconds for one epoch ---
--- 0.20336294174194336 seconds for one epoch ---
--- 2.0708770751953125 seconds for one epoch ---
--- 0.30142712593078613 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12482291]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.162628]
 [  0.      ]]
--- 0.25954389572143555 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2911.164794921875, (1336.181, 3.5547366, 1571.2866, 0.14239898)
   validation loss 768.8107299804688, (490.27496, 0.5854944, 277.8079, 0.14239898)
decoder loss ratio: 18994.103236, decoder SINDy loss  ratio: 0.599687
--- 0.3033633232116699 seconds for one epoch ---
--- 2.091029167175293 seconds for one epoch ---
--- 0.30181097984313965 seconds for one epoch ---
--- 2.070174217224121 seconds for one epoch ---
--- 0.30024290084838867 seconds for one epoch ---
--- 2.116356372833252 seconds for one epoch ---
--- 0.29456257820129395 seconds for one epoch ---
--- 2.079030752182007 seconds for one epoch ---
--- 0.3093571662902832 seconds for one epoch ---
--- 2.105464220046997 seconds for one epoch ---
--- 0.29915571212768555 seconds for one epoch ---
--- 2.107271194458008 seconds for one epoch ---
--- 0.29657411575317383 seconds for one epoch ---
--- 2.12176513671875 seconds for one epoch ---
--- 0.30605483055114746 seconds for one epoch ---
--- 2.1497697830200195 seconds for one epoch ---
--- 0.3001136779785156 seconds for one epoch ---
--- 2.0918450355529785 seconds for one epoch ---
--- 0.29161810874938965 seconds for one epoch ---
--- 1.9867873191833496 seconds for one epoch ---
--- 0.2944519519805908 seconds for one epoch ---
--- 2.0979514122009277 seconds for one epoch ---
--- 0.2901124954223633 seconds for one epoch ---
--- 2.112403631210327 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12427919]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.185056]
 [  0.      ]]
--- 0.29149913787841797 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2651.900146484375, (1023.1261, 8.287767, 1620.3441, 0.14243919)
   validation loss 898.009765625, (631.4355, 0.6226758, 265.80914, 0.14243919)
decoder loss ratio: 24462.906942, decoder SINDy loss  ratio: 0.573786
--- 0.2627246379852295 seconds for one epoch ---
--- 0.2957322597503662 seconds for one epoch ---
--- 2.122103691101074 seconds for one epoch ---
--- 0.3012402057647705 seconds for one epoch ---
--- 2.106674909591675 seconds for one epoch ---
--- 0.30670928955078125 seconds for one epoch ---
--- 2.0963945388793945 seconds for one epoch ---
--- 0.29313135147094727 seconds for one epoch ---
--- 2.169301986694336 seconds for one epoch ---
--- 0.2957456111907959 seconds for one epoch ---
--- 2.115288496017456 seconds for one epoch ---
--- 0.30895256996154785 seconds for one epoch ---
--- 2.1581919193267822 seconds for one epoch ---
--- 0.28958892822265625 seconds for one epoch ---
--- 2.115657329559326 seconds for one epoch ---
--- 0.2931697368621826 seconds for one epoch ---
--- 2.0875627994537354 seconds for one epoch ---
--- 0.3031589984893799 seconds for one epoch ---
--- 2.109182596206665 seconds for one epoch ---
--- 0.29459595680236816 seconds for one epoch ---
--- 2.0962095260620117 seconds for one epoch ---
--- 0.30159878730773926 seconds for one epoch ---
--- 2.1409149169921875 seconds for one epoch ---
--- 0.30664706230163574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12334173]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.223713]
 [ -0.      ]]
--- 0.2656383514404297 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2715.324951171875, (1318.6697, 3.0467987, 1393.466, 0.14250872)
   validation loss 777.9642944335938, (498.4429, 0.6965361, 278.6823, 0.14250872)
decoder loss ratio: 19310.543343, decoder SINDy loss  ratio: 0.601575
--- 0.24214434623718262 seconds for one epoch ---
--- 2.097365379333496 seconds for one epoch ---
--- 0.2967994213104248 seconds for one epoch ---
--- 2.106243133544922 seconds for one epoch ---
--- 0.29854822158813477 seconds for one epoch ---
--- 2.1601643562316895 seconds for one epoch ---
--- 0.29396915435791016 seconds for one epoch ---
--- 2.1034603118896484 seconds for one epoch ---
--- 0.3002316951751709 seconds for one epoch ---
--- 2.1002326011657715 seconds for one epoch ---
--- 0.23784327507019043 seconds for one epoch ---
--- 2.1135761737823486 seconds for one epoch ---
--- 0.2940070629119873 seconds for one epoch ---
--- 2.099994421005249 seconds for one epoch ---
--- 0.29982495307922363 seconds for one epoch ---
--- 2.1306068897247314 seconds for one epoch ---
--- 0.3091011047363281 seconds for one epoch ---
--- 2.101505756378174 seconds for one epoch ---
--- 0.2975647449493408 seconds for one epoch ---
--- 2.1043896675109863 seconds for one epoch ---
--- 0.2797882556915283 seconds for one epoch ---
--- 2.1423685550689697 seconds for one epoch ---
--- 0.6646430492401123 seconds for one epoch ---
--- 2.119920492172241 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12250692]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.258121]
 [ -0.      ]]
--- 0.2940082550048828 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2819.972412109375, (1172.1808, 1.454953, 1646.1941, 0.14256446)
   validation loss 812.4795532226562, (539.09064, 0.5698983, 272.67645, 0.14256446)
decoder loss ratio: 20885.307188, decoder SINDy loss  ratio: 0.588610
--- 0.2673351764678955 seconds for one epoch ---
--- 0.3013758659362793 seconds for one epoch ---
--- 2.0952956676483154 seconds for one epoch ---
--- 0.28796815872192383 seconds for one epoch ---
--- 2.1056618690490723 seconds for one epoch ---
--- 0.2977445125579834 seconds for one epoch ---
--- 2.0832996368408203 seconds for one epoch ---
--- 0.3017270565032959 seconds for one epoch ---
--- 2.1031272411346436 seconds for one epoch ---
--- 0.30295896530151367 seconds for one epoch ---
--- 2.0915212631225586 seconds for one epoch ---
--- 0.3008918762207031 seconds for one epoch ---
--- 2.0029892921447754 seconds for one epoch ---
--- 0.29599428176879883 seconds for one epoch ---
--- 2.119321584701538 seconds for one epoch ---
--- 0.29085326194763184 seconds for one epoch ---
--- 2.1475298404693604 seconds for one epoch ---
--- 0.3067359924316406 seconds for one epoch ---
--- 2.169151544570923 seconds for one epoch ---
--- 0.30617737770080566 seconds for one epoch ---
--- 2.13240122795105 seconds for one epoch ---
--- 0.3081059455871582 seconds for one epoch ---
--- 2.038627862930298 seconds for one epoch ---
--- 0.28676629066467285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12175094]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.289276]
 [  0.      ]]
--- 0.25793981552124023 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2906.4853515625, (1220.7592, 3.1918993, 1682.3916, 0.14262213)
   validation loss 947.7221069335938, (672.6108, 0.6035928, 274.36508, 0.14262213)
decoder loss ratio: 26058.109275, decoder SINDy loss  ratio: 0.592256
--- 0.30498600006103516 seconds for one epoch ---
--- 2.1497886180877686 seconds for one epoch ---
--- 0.29516172409057617 seconds for one epoch ---
--- 2.1378538608551025 seconds for one epoch ---
--- 0.3015925884246826 seconds for one epoch ---
--- 2.165919780731201 seconds for one epoch ---
--- 0.3062305450439453 seconds for one epoch ---
--- 2.14607310295105 seconds for one epoch ---
--- 0.29181885719299316 seconds for one epoch ---
--- 2.1523399353027344 seconds for one epoch ---
--- 0.3144700527191162 seconds for one epoch ---
--- 2.1101841926574707 seconds for one epoch ---
--- 0.308138370513916 seconds for one epoch ---
--- 2.0951573848724365 seconds for one epoch ---
--- 0.2973134517669678 seconds for one epoch ---
--- 2.1343753337860107 seconds for one epoch ---
--- 0.3058664798736572 seconds for one epoch ---
--- 2.1535732746124268 seconds for one epoch ---
--- 0.3049600124359131 seconds for one epoch ---
--- 2.153944492340088 seconds for one epoch ---
--- 0.30281567573547363 seconds for one epoch ---
--- 2.103233814239502 seconds for one epoch ---
--- 0.298297643661499 seconds for one epoch ---
--- 2.1299965381622314 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12088099]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.325125]
 [ -0.      ]]
--- 0.2931241989135742 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2765.0341796875, (1430.0352, 3.1287606, 1331.7278, 0.1426823)
   validation loss 816.0128173828125, (545.154, 0.59187716, 270.12424, 0.1426823)
decoder loss ratio: 21120.212067, decoder SINDy loss  ratio: 0.583101
--- 0.27184391021728516 seconds for one epoch ---
--- 0.31018567085266113 seconds for one epoch ---
--- 2.2090015411376953 seconds for one epoch ---
--- 0.2999300956726074 seconds for one epoch ---
--- 2.192079782485962 seconds for one epoch ---
--- 0.3183598518371582 seconds for one epoch ---
--- 2.163902759552002 seconds for one epoch ---
--- 0.2939748764038086 seconds for one epoch ---
--- 2.1951122283935547 seconds for one epoch ---
--- 0.2937307357788086 seconds for one epoch ---
--- 2.179955244064331 seconds for one epoch ---
--- 0.30571556091308594 seconds for one epoch ---
--- 2.151625871658325 seconds for one epoch ---
--- 0.31018710136413574 seconds for one epoch ---
--- 2.158085346221924 seconds for one epoch ---
--- 0.17661809921264648 seconds for one epoch ---
--- 2.1307077407836914 seconds for one epoch ---
--- 0.2982945442199707 seconds for one epoch ---
--- 2.135071277618408 seconds for one epoch ---
--- 0.2899355888366699 seconds for one epoch ---
--- 2.200157880783081 seconds for one epoch ---
--- 0.305633544921875 seconds for one epoch ---
--- 2.181119918823242 seconds for one epoch ---
--- 0.3107278347015381 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11987044]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.36676]
 [  0.     ]]
--- 0.2583913803100586 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3449.976318359375, (1510.1533, 0.98700017, 1938.6931, 0.14275384)
   validation loss 748.5731811523438, (487.0074, 0.6534619, 260.76956, 0.14275384)
decoder loss ratio: 18867.511587, decoder SINDy loss  ratio: 0.562908
--- 0.3020467758178711 seconds for one epoch ---
--- 2.1530535221099854 seconds for one epoch ---
--- 0.2784144878387451 seconds for one epoch ---
--- 2.196824789047241 seconds for one epoch ---
--- 0.2998325824737549 seconds for one epoch ---
--- 2.108726739883423 seconds for one epoch ---
--- 0.2799549102783203 seconds for one epoch ---
--- 2.1389319896698 seconds for one epoch ---
--- 0.29995083808898926 seconds for one epoch ---
--- 2.1388449668884277 seconds for one epoch ---
--- 0.29208827018737793 seconds for one epoch ---
--- 2.174147844314575 seconds for one epoch ---
--- 0.3162415027618408 seconds for one epoch ---
--- 2.1572749614715576 seconds for one epoch ---
--- 0.29144859313964844 seconds for one epoch ---
--- 2.0909202098846436 seconds for one epoch ---
--- 0.2484753131866455 seconds for one epoch ---
--- 2.150541067123413 seconds for one epoch ---
--- 0.2912914752960205 seconds for one epoch ---
--- 2.1584150791168213 seconds for one epoch ---
--- 0.2883310317993164 seconds for one epoch ---
--- 2.204491138458252 seconds for one epoch ---
--- 0.30385708808898926 seconds for one epoch ---
--- 2.185389995574951 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11908686]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.399043]
 [  0.      ]]
--- 0.29727935791015625 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2025.7705078125, (895.27167, 0.68946826, 1129.6665, 0.14280753)
   validation loss 672.711669921875, (416.34485, 0.62491274, 255.5991, 0.14280753)
decoder loss ratio: 16129.922242, decoder SINDy loss  ratio: 0.551747
--- 0.9916059970855713 seconds for one epoch ---
--- 0.18908166885375977 seconds for one epoch ---
--- 2.1514687538146973 seconds for one epoch ---
--- 0.2989072799682617 seconds for one epoch ---
--- 2.1586501598358154 seconds for one epoch ---
--- 0.29921436309814453 seconds for one epoch ---
--- 2.1634531021118164 seconds for one epoch ---
--- 0.2965831756591797 seconds for one epoch ---
--- 2.1615262031555176 seconds for one epoch ---
--- 0.2901592254638672 seconds for one epoch ---
--- 2.163362979888916 seconds for one epoch ---
--- 0.23857378959655762 seconds for one epoch ---
--- 2.182657241821289 seconds for one epoch ---
--- 0.2974967956542969 seconds for one epoch ---
--- 2.1642472743988037 seconds for one epoch ---
--- 0.2943103313446045 seconds for one epoch ---
--- 2.059621572494507 seconds for one epoch ---
--- 0.29124927520751953 seconds for one epoch ---
--- 2.174776792526245 seconds for one epoch ---
--- 0.29972028732299805 seconds for one epoch ---
--- 2.1556525230407715 seconds for one epoch ---
--- 0.29925107955932617 seconds for one epoch ---
--- 2.1694633960723877 seconds for one epoch ---
--- 0.2900855541229248 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1182926]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.431774]
 [ -0.      ]]
--- 0.26146960258483887 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1479.610595703125, (561.8091, 1.2697388, 916.38904, 0.14286208)
   validation loss 750.9799194335938, (478.5759, 0.6094933, 271.65167, 0.14286208)
decoder loss ratio: 18540.861102, decoder SINDy loss  ratio: 0.586398
--- 0.3047370910644531 seconds for one epoch ---
--- 2.1610918045043945 seconds for one epoch ---
--- 0.2989380359649658 seconds for one epoch ---
--- 2.1651806831359863 seconds for one epoch ---
--- 0.2943453788757324 seconds for one epoch ---
--- 2.1597743034362793 seconds for one epoch ---
--- 0.29456233978271484 seconds for one epoch ---
--- 2.1618645191192627 seconds for one epoch ---
--- 0.26013755798339844 seconds for one epoch ---
--- 2.1977782249450684 seconds for one epoch ---
--- 0.30110740661621094 seconds for one epoch ---
--- 2.1752829551696777 seconds for one epoch ---
--- 0.2907590866088867 seconds for one epoch ---
--- 2.1865627765655518 seconds for one epoch ---
--- 0.3013181686401367 seconds for one epoch ---
--- 2.166003942489624 seconds for one epoch ---
--- 0.2899489402770996 seconds for one epoch ---
--- 2.178269386291504 seconds for one epoch ---
--- 0.23615074157714844 seconds for one epoch ---
--- 2.226839542388916 seconds for one epoch ---
--- 0.29932212829589844 seconds for one epoch ---
--- 2.1614930629730225 seconds for one epoch ---
--- 0.2963223457336426 seconds for one epoch ---
--- 2.1798973083496094 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11752336]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.463474]
 [ -0.      ]]
--- 0.16119837760925293 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2050.989013671875, (1278.3909, 0.30476296, 772.15063, 0.14291331)
   validation loss 812.2111206054688, (523.8559, 0.5284764, 287.68387, 0.14291331)
decoder loss ratio: 20295.086865, decoder SINDy loss  ratio: 0.621006
--- 0.28902745246887207 seconds for one epoch ---
--- 0.28548693656921387 seconds for one epoch ---
--- 2.172905921936035 seconds for one epoch ---
--- 0.30295300483703613 seconds for one epoch ---
--- 2.23884654045105 seconds for one epoch ---
--- 0.2983372211456299 seconds for one epoch ---
--- 2.209306478500366 seconds for one epoch ---
--- 0.3014225959777832 seconds for one epoch ---
--- 2.062479019165039 seconds for one epoch ---
--- 0.28143811225891113 seconds for one epoch ---
--- 2.193643093109131 seconds for one epoch ---
--- 0.28316378593444824 seconds for one epoch ---
--- 2.171135425567627 seconds for one epoch ---
--- 0.2913393974304199 seconds for one epoch ---
--- 2.2047972679138184 seconds for one epoch ---
--- 0.2907979488372803 seconds for one epoch ---
--- 2.1943318843841553 seconds for one epoch ---
--- 0.3083820343017578 seconds for one epoch ---
--- 2.179473400115967 seconds for one epoch ---
--- 0.29745960235595703 seconds for one epoch ---
--- 2.205500602722168 seconds for one epoch ---
--- 0.2991824150085449 seconds for one epoch ---
--- 2.2137718200683594 seconds for one epoch ---
--- 0.2987067699432373 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.116885]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.489792]
 [  0.      ]]
--- 0.27059507369995117 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2631.340576171875, (991.6047, 2.5810728, 1637.0117, 0.14296171)
   validation loss 746.6212768554688, (468.2196, 0.6296248, 277.6291, 0.14296171)
decoder loss ratio: 18139.640343, decoder SINDy loss  ratio: 0.599301
--- 0.2978219985961914 seconds for one epoch ---
--- 2.2020514011383057 seconds for one epoch ---
--- 0.29467177391052246 seconds for one epoch ---
--- 2.1246144771575928 seconds for one epoch ---
--- 0.2061316967010498 seconds for one epoch ---
--- 2.187594175338745 seconds for one epoch ---
--- 0.29630541801452637 seconds for one epoch ---
--- 2.1881744861602783 seconds for one epoch ---
--- 0.2936432361602783 seconds for one epoch ---
--- 2.2109718322753906 seconds for one epoch ---
--- 0.3038480281829834 seconds for one epoch ---
--- 2.2027180194854736 seconds for one epoch ---
--- 0.2979238033294678 seconds for one epoch ---
--- 2.125157117843628 seconds for one epoch ---
--- 0.29478883743286133 seconds for one epoch ---
--- 2.2319388389587402 seconds for one epoch ---
--- 0.2967722415924072 seconds for one epoch ---
--- 2.191720485687256 seconds for one epoch ---
--- 0.30219483375549316 seconds for one epoch ---
--- 2.2009401321411133 seconds for one epoch ---
--- 0.3163180351257324 seconds for one epoch ---
--- 2.243572235107422 seconds for one epoch ---
--- 0.3012542724609375 seconds for one epoch ---
--- 2.2097270488739014 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11623016]
 [0.        ]]
[[ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-15.5168]
 [ -0.    ]]
--- 0.3050670623779297 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2821.89501953125, (1461.849, 3.3246758, 1356.5782, 0.14299929)
   validation loss 784.7086181640625, (507.07394, 0.6415039, 276.85016, 0.14299929)
decoder loss ratio: 19644.924913, decoder SINDy loss  ratio: 0.597620
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11622927]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.516833]
 [  0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 982.738037109375, (483.02246, 0.22934052, 499.48627, 0.14300142)
   validation loss 687.57421875, (424.61456, 0.435706, 262.52396, 0.14300142)
decoder loss ratio: 16450.305333, decoder SINDy loss  ratio: 0.566695
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11479417]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.571819]
 [ -0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.8310546875, (399.21118, 0.33595616, 478.2839, 0.14309321)
   validation loss 554.4705810546875, (325.09753, 0.17768352, 229.1954, 0.14309321)
decoder loss ratio: 12594.842868, decoder SINDy loss  ratio: 0.494751
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11543845]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.571554]
 [ -0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.390869140625, (257.76813, 0.30181867, 451.32095, 0.143049)
   validation loss 442.4388427734375, (216.35606, 0.13142797, 225.95135, 0.143049)
decoder loss ratio: 8382.009524, decoder SINDy loss  ratio: 0.487748
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11659982]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.473097]
 [  0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.6908569335938, (252.73117, 0.27729762, 443.6824, 0.14297147)
   validation loss 431.8868408203125, (207.77621, 0.108959846, 224.00165, 0.14297147)
decoder loss ratio: 8049.611269, decoder SINDy loss  ratio: 0.483539
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11785342]
 [0.        ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-15.4469385]
 [  0.       ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.788818359375, (299.9775, 0.26186693, 435.54947, 0.14288735)
   validation loss 476.7467346191406, (250.78046, 0.10178657, 225.86449, 0.14288735)
decoder loss ratio: 9715.670260, decoder SINDy loss  ratio: 0.487560
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11919692]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.45171]
 [  0.     ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2430.331787109375, (1963.1307, 0.25870287, 466.94232, 0.1427977)
   validation loss 2107.989501953125, (1818.702, 0.09404279, 289.19342, 0.1427977)
decoder loss ratio: 70459.673907, decoder SINDy loss  ratio: 0.624265
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.120491]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.386639]
 [ -0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2597.278076171875, (2135.014, 0.25458765, 462.00958, 0.14270823)
   validation loss 2245.3515625, (1956.9213, 0.090770304, 288.3394, 0.14270823)
decoder loss ratio: 75814.527157, decoder SINDy loss  ratio: 0.622421
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12166471]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.23902]
 [ -0.     ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.1542358398438, (371.48135, 0.256022, 428.41687, 0.1426221)
   validation loss 522.5870971679688, (296.91693, 0.082661055, 225.58748, 0.1426221)
decoder loss ratio: 11503.077383, decoder SINDy loss  ratio: 0.486962
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12279222]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.204556]
 [  0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.029296875, (301.0182, 0.23327531, 426.77786, 0.14254197)
   validation loss 458.15704345703125, (235.54626, 0.078951836, 222.53181, 0.14254197)
decoder loss ratio: 9125.471219, decoder SINDy loss  ratio: 0.480366
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12380457]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.249563]
 [  0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.4650268554688, (338.4884, 0.22865263, 423.748, 0.14246784)
   validation loss 489.2208251953125, (265.824, 0.07579703, 223.32101, 0.14246784)
decoder loss ratio: 10298.483449, decoder SINDy loss  ratio: 0.482070
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12467788]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.184181]
 [ -0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.1107788085938, (282.03818, 0.2335267, 423.83908, 0.14240268)
   validation loss 435.94659423828125, (216.36754, 0.07425434, 219.5048, 0.14240268)
decoder loss ratio: 8382.454070, decoder SINDy loss  ratio: 0.473832
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1254078]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.188951]
 [  0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.4722290039062, (227.82092, 0.24703486, 430.40427, 0.14234947)
   validation loss 397.81365966796875, (182.39507, 0.06930393, 215.34927, 0.14234947)
decoder loss ratio: 7066.301482, decoder SINDy loss  ratio: 0.464862
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12613696]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.103745]
 [ -0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3392.0234375, (2907.6614, 0.2394189, 484.12268, 0.14229889)
   validation loss 2882.038818359375, (2570.032, 0.07972347, 311.9269, 0.14229889)
decoder loss ratio: 99567.500771, decoder SINDy loss  ratio: 0.673338
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1267022]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.054641]
 [  0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.0381469726562, (292.2652, 0.22029486, 424.55264, 0.14225204)
   validation loss 464.54656982421875, (251.04285, 0.071766146, 213.43196, 0.14225204)
decoder loss ratio: 9725.835710, decoder SINDy loss  ratio: 0.460723
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12714331]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.041513]
 [ -0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.156982421875, (303.56305, 0.2335494, 420.36035, 0.14221735)
   validation loss 455.5443115234375, (236.1005, 0.06806585, 219.37576, 0.14221735)
decoder loss ratio: 9146.943041, decoder SINDy loss  ratio: 0.473553
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12758574]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.01995]
 [ -0.     ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 919.8824462890625, (499.7973, 0.22107206, 419.86407, 0.14218412)
   validation loss 626.63427734375, (398.40936, 0.06796504, 228.15692, 0.14218412)
decoder loss ratio: 15435.070384, decoder SINDy loss  ratio: 0.492509
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12793122]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.078962]
 [ -0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.16748046875, (292.08423, 0.21426916, 417.86896, 0.14215629)
   validation loss 443.5743408203125, (224.08904, 0.065221645, 219.42007, 0.14215629)
decoder loss ratio: 8681.598253, decoder SINDy loss  ratio: 0.473649
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12820558]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.045312]
 [ -0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.8841552734375, (319.5775, 0.22432318, 417.08228, 0.14213489)
   validation loss 465.3577880859375, (245.89316, 0.06491382, 219.39973, 0.14213489)
decoder loss ratio: 9526.327829, decoder SINDy loss  ratio: 0.473605
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12842903]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.025636]
 [ -0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 789.525634765625, (373.39706, 0.21380976, 415.91476, 0.14211698)
   validation loss 516.21435546875, (293.21545, 0.06327248, 222.93562, 0.14211698)
decoder loss ratio: 11359.675736, decoder SINDy loss  ratio: 0.481238
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12854847]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.005981]
 [ -0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 831.3344116210938, (415.29785, 0.20875129, 415.82782, 0.14210777)
   validation loss 557.5228881835938, (330.49124, 0.06279491, 226.96886, 0.14210777)
decoder loss ratio: 12803.804452, decoder SINDy loss  ratio: 0.489944
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12858275]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.936313]
 [ -0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 946.5870361328125, (529.46466, 0.21144892, 416.91095, 0.14210601)
   validation loss 668.7569580078125, (435.50327, 0.062723406, 233.191, 0.14210601)
decoder loss ratio: 16872.152568, decoder SINDy loss  ratio: 0.503376
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12856144]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.054696]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.5006103515625, (303.73813, 0.22416952, 415.53827, 0.14210795)
   validation loss 458.7825927734375, (239.13728, 0.061451256, 219.58385, 0.14210795)
decoder loss ratio: 9264.593517, decoder SINDy loss  ratio: 0.474003
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.128492]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.996919]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.755615234375, (306.1718, 0.2386856, 447.3451, 0.14211415)
   validation loss 490.06097412109375, (274.26944, 0.05753925, 215.734, 0.14211415)
decoder loss ratio: 10625.674247, decoder SINDy loss  ratio: 0.465692
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12846303]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.019552]
 [ -0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1130.8585205078125, (647.2498, 0.23652895, 483.37216, 0.14211884)
   validation loss 842.0364990234375, (614.33075, 0.056313798, 227.64938, 0.14211884)
decoder loss ratio: 23800.239761, decoder SINDy loss  ratio: 0.491413
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1283938]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.060619]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3225.34130859375, (2734.9646, 0.22050388, 490.15622, 0.14212511)
   validation loss 2750.15087890625, (2430.5818, 0.061646264, 319.50726, 0.14212511)
decoder loss ratio: 94164.958108, decoder SINDy loss  ratio: 0.689701
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12819666]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.078242]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1796.1502685546875, (1280.1361, 0.21990669, 515.7943, 0.1421343)
   validation loss 1499.8111572265625, (1255.7986, 0.05207525, 243.9604, 0.1421343)
decoder loss ratio: 48651.817306, decoder SINDy loss  ratio: 0.526623
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12808341]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.031735]
 [ -0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.4906616210938, (425.93484, 0.22018017, 415.33563, 0.14214778)
   validation loss 564.5347290039062, (346.84085, 0.060773358, 217.63312, 0.14214778)
decoder loss ratio: 13437.216703, decoder SINDy loss  ratio: 0.469792
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12790881]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.026932]
 [ -0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2640.582763671875, (2162.8489, 0.21171321, 477.52216, 0.14216171)
   validation loss 2219.5146484375, (1912.5222, 0.058586966, 306.93378, 0.14216171)
decoder loss ratio: 74094.430963, decoder SINDy loss  ratio: 0.662560
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12772699]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.992192]
 [ -0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.1937255859375, (218.89928, 0.213116, 420.08133, 0.14217372)
   validation loss 383.79937744140625, (170.83162, 0.053945225, 212.91382, 0.14217372)
decoder loss ratio: 6618.313507, decoder SINDy loss  ratio: 0.459604
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1274748]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.066448]
 [ -0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.9615478515625, (267.27264, 0.21143076, 411.47745, 0.14219442)
   validation loss 426.4783935546875, (211.80087, 0.060213536, 214.61732, 0.14219442)
decoder loss ratio: 8205.533515, decoder SINDy loss  ratio: 0.463282
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1272053]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.038953]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.656494140625, (217.60452, 0.22571918, 419.82623, 0.14221428)
   validation loss 386.2276916503906, (173.01338, 0.05700957, 213.1573, 0.14221428)
decoder loss ratio: 6702.838781, decoder SINDy loss  ratio: 0.460130
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12697719]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.027094]
 [ -0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.1612548828125, (222.00655, 0.2197915, 421.9349, 0.14223303)
   validation loss 387.2806701660156, (174.26376, 0.05544636, 212.96146, 0.14223303)
decoder loss ratio: 6751.280730, decoder SINDy loss  ratio: 0.459707
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12668602]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.039629]
 [  0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.3279418945312, (222.22525, 0.23723567, 425.86545, 0.142255)
   validation loss 392.77935791015625, (180.55002, 0.05647307, 212.17288, 0.142255)
decoder loss ratio: 6994.821158, decoder SINDy loss  ratio: 0.458005
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12643291]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.077928]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1119.324951171875, (642.4035, 0.22501677, 476.6964, 0.14227177)
   validation loss 834.19921875, (608.6998, 0.050807502, 225.44864, 0.14227177)
decoder loss ratio: 23582.088129, decoder SINDy loss  ratio: 0.486663
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12615764]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.094271]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2229.406005859375, (1657.4207, 0.23223434, 571.7531, 0.14229192)
   validation loss 1819.84130859375, (1557.2521, 0.05147805, 262.53775, 0.14229192)
decoder loss ratio: 60330.648902, decoder SINDy loss  ratio: 0.566725
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12595819]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.077684]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.26708984375, (284.89124, 0.21573114, 431.16016, 0.1423099)
   validation loss 471.4927062988281, (259.3416, 0.051373113, 212.09973, 0.1423099)
decoder loss ratio: 10047.344354, decoder SINDy loss  ratio: 0.457847
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1257096]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.10692]
 [  0.     ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.2523193359375, (222.30573, 0.2162133, 424.73038, 0.14232929)
   validation loss 387.50604248046875, (176.3533, 0.053577274, 211.09915, 0.14232929)
decoder loss ratio: 6832.233082, decoder SINDy loss  ratio: 0.455687
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12537088]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.135677]
 [  0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1043.943359375, (574.1627, 0.21238886, 469.5682, 0.1423523)
   validation loss 758.60595703125, (538.03723, 0.052778617, 220.51595, 0.1423523)
decoder loss ratio: 20844.496420, decoder SINDy loss  ratio: 0.476015
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12510453]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.149019]
 [ -0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.9832763671875, (335.7115, 0.21463802, 441.0572, 0.14237235)
   validation loss 511.73553466796875, (299.1009, 0.05411555, 212.58052, 0.14237235)
decoder loss ratio: 11587.687784, decoder SINDy loss  ratio: 0.458885
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12485672]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.126826]
 [  0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.4513549804688, (222.06636, 0.21979238, 424.16522, 0.14239351)
   validation loss 388.5888977050781, (176.75366, 0.05535338, 211.77988, 0.14239351)
decoder loss ratio: 6847.743728, decoder SINDy loss  ratio: 0.457157
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12457664]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.065053]
 [ -0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.4037475585938, (213.07135, 0.23217824, 424.10022, 0.14241438)
   validation loss 382.0851745605469, (171.02498, 0.056420073, 211.00377, 0.14241438)
decoder loss ratio: 6625.804585, decoder SINDy loss  ratio: 0.455481
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12433954]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.1867695]
 [ -0.       ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.9873657226562, (219.90382, 0.2167077, 419.86682, 0.14243235)
   validation loss 382.74261474609375, (171.02364, 0.055394482, 211.66357, 0.14243235)
decoder loss ratio: 6625.752563, decoder SINDy loss  ratio: 0.456906
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12409338]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.14164]
 [ -0.     ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 629.9440307617188, (210.47983, 0.22579885, 419.2384, 0.1424494)
   validation loss 377.17840576171875, (166.39873, 0.056513067, 210.72314, 0.1424494)
decoder loss ratio: 6446.575581, decoder SINDy loss  ratio: 0.454876
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12386139]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.205106]
 [  0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.924072265625, (231.53427, 0.22695005, 415.16284, 0.14246733)
   validation loss 386.77239990234375, (175.51962, 0.057007518, 211.19579, 0.14246733)
decoder loss ratio: 6799.934903, decoder SINDy loss  ratio: 0.455896
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12361918]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.202834]
 [ -0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 636.2403564453125, (218.66882, 0.23104306, 417.3405, 0.14248423)
   validation loss 378.88739013671875, (168.66675, 0.057109278, 210.16354, 0.14248423)
decoder loss ratio: 6534.442638, decoder SINDy loss  ratio: 0.453668
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12339619]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.237878]
 [ -0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 633.9292602539062, (213.73293, 0.23142946, 419.9649, 0.14250086)
   validation loss 377.8443603515625, (167.7675, 0.057237003, 210.0196, 0.14250086)
decoder loss ratio: 6499.604278, decoder SINDy loss  ratio: 0.453357
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12316407]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.312454]
 [  0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.770751953125, (253.00366, 0.23412448, 437.533, 0.14251897)
   validation loss 437.5284118652344, (226.1931, 0.054756176, 211.28055, 0.14251897)
decoder loss ratio: 8763.113382, decoder SINDy loss  ratio: 0.456079
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12293662]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.281385]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.672119140625, (321.65985, 0.24015227, 448.7721, 0.14253643)
   validation loss 508.9853515625, (295.8644, 0.053098302, 213.06783, 0.14253643)
decoder loss ratio: 11462.300902, decoder SINDy loss  ratio: 0.459937
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12273014]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.298868]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.2301025390625, (351.1017, 0.21424086, 445.91415, 0.14254926)
   validation loss 544.5177001953125, (331.43634, 0.052785974, 213.02856, 0.14254926)
decoder loss ratio: 12840.419223, decoder SINDy loss  ratio: 0.459852
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12252484]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.267484]
 [ -0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1127.422607421875, (643.6116, 0.21271636, 483.59833, 0.14256446)
   validation loss 833.4086303710938, (605.2377, 0.053711984, 228.11726, 0.14256446)
decoder loss ratio: 23447.958109, decoder SINDy loss  ratio: 0.492423
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12223172]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.283119]
 [ -0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.734619140625, (404.8058, 0.20245257, 446.7264, 0.14258279)
   validation loss 596.070068359375, (382.47748, 0.052876465, 213.53973, 0.14258279)
decoder loss ratio: 14817.841509, decoder SINDy loss  ratio: 0.460956
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1219701]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.238817]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.7791748046875, (399.58713, 0.23152143, 456.96057, 0.14260624)
   validation loss 584.718994140625, (369.19376, 0.05183286, 215.47339, 0.14260624)
decoder loss ratio: 14303.207060, decoder SINDy loss  ratio: 0.465130
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1217031]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.249848]
 [  0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.8255004882812, (329.96375, 0.21066897, 408.6511, 0.14262506)
   validation loss 465.50701904296875, (253.35574, 0.05477785, 212.09651, 0.14262506)
decoder loss ratio: 9815.441345, decoder SINDy loss  ratio: 0.457840
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12142851]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.319467]
 [ -0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.5134887695312, (213.82788, 0.22319335, 416.4624, 0.14264272)
   validation loss 375.943359375, (166.84688, 0.05607258, 209.0404, 0.14264272)
decoder loss ratio: 6463.937715, decoder SINDy loss  ratio: 0.451243
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12118342]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.279821]
 [ -0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 972.7308349609375, (561.8557, 0.20519802, 410.6699, 0.14266098)
   validation loss 667.1806640625, (443.55634, 0.057138957, 223.5672, 0.14266098)
decoder loss ratio: 17184.142483, decoder SINDy loss  ratio: 0.482601
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12092003]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.297573]
 [ -0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.3815307617188, (207.5656, 0.21985495, 416.59607, 0.14267889)
   validation loss 374.79095458984375, (166.16287, 0.05522721, 208.57288, 0.14267889)
decoder loss ratio: 6437.438145, decoder SINDy loss  ratio: 0.450234
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12066595]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.391835]
 [ -0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 638.0433349609375, (224.52095, 0.20522021, 413.3172, 0.14269733)
   validation loss 379.57489013671875, (169.96724, 0.052790202, 209.55486, 0.14269733)
decoder loss ratio: 6584.825930, decoder SINDy loss  ratio: 0.452354
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12037604]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.3475065]
 [ -0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.81201171875, (208.17598, 0.21508725, 416.42093, 0.14271693)
   validation loss 374.5662841796875, (165.87886, 0.05464332, 208.63277, 0.14271693)
decoder loss ratio: 6426.435033, decoder SINDy loss  ratio: 0.450363
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12009776]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.338508]
 [ -0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.9627685546875, (318.72495, 0.19717878, 408.04065, 0.142737)
   validation loss 455.59600830078125, (241.16992, 0.05369806, 214.3724, 0.142737)
decoder loss ratio: 9343.341463, decoder SINDy loss  ratio: 0.462753
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11981986]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.286656]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.0807495117188, (210.77707, 0.19560012, 414.1081, 0.1427559)
   validation loss 374.10650634765625, (165.0209, 0.0519934, 209.03363, 0.1427559)
decoder loss ratio: 6393.196331, decoder SINDy loss  ratio: 0.451228
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11952466]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.408188]
 [ -0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.5413208007812, (232.34152, 0.20631076, 410.99347, 0.14277676)
   validation loss 385.81414794921875, (176.00876, 0.05343673, 209.75197, 0.14277676)
decoder loss ratio: 6818.884871, decoder SINDy loss  ratio: 0.452779
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11919363]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.384025]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.4237060546875, (332.5499, 0.20533429, 407.66846, 0.14279948)
   validation loss 464.370361328125, (250.19759, 0.05519939, 214.11758, 0.14279948)
decoder loss ratio: 9693.088846, decoder SINDy loss  ratio: 0.462203
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11888199]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.392001]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.2581787109375, (344.8189, 0.22394124, 448.21533, 0.14282297)
   validation loss 531.6653442382812, (318.57654, 0.05101891, 213.03777, 0.14282297)
decoder loss ratio: 12342.208159, decoder SINDy loss  ratio: 0.459872
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1186294]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.397564]
 [ -0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.7276000976562, (235.7293, 0.19952913, 411.79877, 0.14284061)
   validation loss 392.04351806640625, (181.822, 0.051614728, 210.16989, 0.14284061)
decoder loss ratio: 7044.100178, decoder SINDy loss  ratio: 0.453681
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11832319]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.39322]
 [ -0.     ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.0853271484375, (274.66943, 0.19378802, 407.22208, 0.14285883)
   validation loss 418.0833740234375, (205.70538, 0.05261422, 212.32536, 0.14285883)
decoder loss ratio: 7969.383669, decoder SINDy loss  ratio: 0.458334
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11800639]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.416587]
 [ -0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 897.9534912109375, (437.19113, 0.22216591, 460.54022, 0.14288305)
   validation loss 623.1085205078125, (405.97964, 0.04911963, 217.07971, 0.14288305)
decoder loss ratio: 15728.356250, decoder SINDy loss  ratio: 0.468597
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1177557]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.398856]
 [  0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2248.155517578125, (1821.6433, 0.20761101, 426.30457, 0.14290135)
   validation loss 1894.816162109375, (1635.439, 0.0626598, 259.3145, 0.14290135)
decoder loss ratio: 63359.744745, decoder SINDy loss  ratio: 0.559767
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1174845]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.448943]
 [ -0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.091552734375, (267.27567, 0.19606328, 408.6198, 0.14291601)
   validation loss 406.3510437011719, (193.66731, 0.04902889, 212.6347, 0.14291601)
decoder loss ratio: 7503.007912, decoder SINDy loss  ratio: 0.459002
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11726874]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.455465]
 [  0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.9979858398438, (415.25787, 0.18228613, 406.55783, 0.14293143)
   validation loss 547.40380859375, (326.75436, 0.052313793, 220.59715, 0.14293143)
decoder loss ratio: 12659.031332, decoder SINDy loss  ratio: 0.476190
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11700589]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.419469]
 [  0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.6649169921875, (286.29968, 0.18426749, 406.18097, 0.14294894)
   validation loss 433.758056640625, (218.5563, 0.05088656, 215.15085, 0.14294894)
decoder loss ratio: 8467.250683, decoder SINDy loss  ratio: 0.464433
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11668341]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.563686]
 [  0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.5269775390625, (233.1555, 0.19278006, 408.1787, 0.14296953)
   validation loss 386.4528503417969, (175.38707, 0.051205795, 211.01457, 0.14296953)
decoder loss ratio: 6794.799566, decoder SINDy loss  ratio: 0.455505
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11637577]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.529441]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.301025390625, (213.02008, 0.20661908, 413.07434, 0.14299071)
   validation loss 376.3836364746094, (167.70268, 0.052387863, 208.62857, 0.14299071)
decoder loss ratio: 6497.093065, decoder SINDy loss  ratio: 0.450354
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11606888]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.526499]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.456298828125, (223.49138, 0.20464979, 413.76028, 0.14301133)
   validation loss 378.3310852050781, (169.2307, 0.050976194, 209.04941, 0.14301133)
decoder loss ratio: 6556.291024, decoder SINDy loss  ratio: 0.451263
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11583589]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.552904]
 [  0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1282.624755859375, (866.0033, 0.19125259, 416.4302, 0.1430271)
   validation loss 965.7791748046875, (728.0494, 0.053492185, 237.6763, 0.1430271)
decoder loss ratio: 28205.896831, decoder SINDy loss  ratio: 0.513058
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11568482]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.482825]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.751708984375, (288.18372, 0.17953324, 428.38846, 0.14303531)
   validation loss 462.555908203125, (251.90115, 0.04945725, 210.60532, 0.14303531)
decoder loss ratio: 9759.088009, decoder SINDy loss  ratio: 0.454621
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11541596]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.514901]
 [  0.      ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.6988525390625, (212.13882, 0.18426427, 413.3758, 0.14305428)
   validation loss 373.067138671875, (162.16914, 0.04861897, 210.8494, 0.14305428)
decoder loss ratio: 6282.714164, decoder SINDy loss  ratio: 0.455148
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.115098]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.541278]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.632568359375, (231.6989, 0.19289945, 407.74078, 0.14307438)
   validation loss 384.8367004394531, (174.47318, 0.050409082, 210.31311, 0.14307438)
decoder loss ratio: 6759.393700, decoder SINDy loss  ratio: 0.453990
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11478536]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.586136]
 [ -0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.080078125, (367.16016, 0.18722391, 405.7327, 0.14309594)
   validation loss 500.2227478027344, (283.2846, 0.052041467, 216.88611, 0.14309594)
decoder loss ratio: 10974.937476, decoder SINDy loss  ratio: 0.468179
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1144577]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.548368]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.927978515625, (231.14426, 0.18951498, 408.59418, 0.14311658)
   validation loss 383.6071472167969, (173.08232, 0.051475976, 210.47334, 0.14311658)
decoder loss ratio: 6705.509606, decoder SINDy loss  ratio: 0.454336
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1141438]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.541496]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.8055419921875, (362.79135, 0.18344128, 405.83075, 0.14313696)
   validation loss 495.097900390625, (277.63464, 0.051724967, 217.41153, 0.14313696)
decoder loss ratio: 10756.048086, decoder SINDy loss  ratio: 0.469313
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11390708]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.599869]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.689453125, (221.62991, 0.1921014, 408.86746, 0.14315215)
   validation loss 375.5014953613281, (166.03642, 0.05093309, 209.41414, 0.14315215)
decoder loss ratio: 6432.539268, decoder SINDy loss  ratio: 0.452050
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1136376]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.549228]
 [  0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.3276977539062, (270.04544, 0.18804109, 406.0942, 0.1431688)
   validation loss 413.10321044921875, (201.20204, 0.051839482, 211.84932, 0.1431688)
decoder loss ratio: 7794.916395, decoder SINDy loss  ratio: 0.457307
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11341944]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.66473]
 [  0.     ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.1012573242188, (221.23761, 0.19674608, 409.6669, 0.1431834)
   validation loss 375.3346252441406, (166.68799, 0.051957548, 208.59468, 0.1431834)
decoder loss ratio: 6457.782049, decoder SINDy loss  ratio: 0.450281
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11315571]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.676987]
 [  0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.34716796875, (208.85188, 0.20514444, 416.29013, 0.14319989)
   validation loss 376.42779541015625, (169.22765, 0.052636746, 207.14749, 0.14319989)
decoder loss ratio: 6556.172793, decoder SINDy loss  ratio: 0.447157
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11294071]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.599921]
 [ -0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.4564208984375, (221.01495, 0.21102601, 421.2304, 0.14321423)
   validation loss 387.46600341796875, (179.9943, 0.05345852, 207.41826, 0.14321423)
decoder loss ratio: 6973.291403, decoder SINDy loss  ratio: 0.447741
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11286565]
 [0.        ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.6084585]
 [ -0.       ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1024.2637939453125, (560.09607, 0.22508195, 463.94266, 0.14322166)
   validation loss 748.067626953125, (528.1165, 0.045845777, 219.90529, 0.14322166)
decoder loss ratio: 20460.150685, decoder SINDy loss  ratio: 0.474696
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11276116]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.6500635]
 [ -0.       ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 968.1702880859375, (513.89026, 0.20706184, 454.0729, 0.14322942)
   validation loss 717.3890380859375, (500.57114, 0.04706278, 216.77081, 0.14322942)
decoder loss ratio: 19392.994857, decoder SINDy loss  ratio: 0.467930
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11258774]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.689035]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.8055419921875, (347.83398, 0.19051902, 417.78104, 0.14323714)
   validation loss 476.9869689941406, (266.95294, 0.05382749, 209.9802, 0.14323714)
decoder loss ratio: 10342.220420, decoder SINDy loss  ratio: 0.453272
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11250749]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.711725]
 [ -0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.187255859375, (222.00856, 0.18544066, 408.9933, 0.14324227)
   validation loss 375.0937805175781, (167.35696, 0.047061633, 207.68976, 0.14324227)
decoder loss ratio: 6483.699334, decoder SINDy loss  ratio: 0.448328
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11234143]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.642594]
 [  0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.1927490234375, (220.75436, 0.18210779, 410.2563, 0.14325221)
   validation loss 371.29193115234375, (164.03589, 0.05016838, 207.20586, 0.14325221)
decoder loss ratio: 6355.035106, decoder SINDy loss  ratio: 0.447283
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11224153]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.69534]
 [ -0.     ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.1878662109375, (234.22939, 0.17991371, 406.77856, 0.1432585)
   validation loss 381.00048828125, (172.68816, 0.049615227, 208.2627, 0.1432585)
decoder loss ratio: 6690.238968, decoder SINDy loss  ratio: 0.449564
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11208171]
 [0.        ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.6980915]
 [ -0.       ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.2849731445312, (212.24785, 0.17622073, 409.8609, 0.14326817)
   validation loss 366.6101379394531, (158.9913, 0.04970204, 207.56914, 0.14326817)
decoder loss ratio: 6159.599080, decoder SINDy loss  ratio: 0.448067
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11195429]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.749027]
 [ -0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.4158935546875, (256.0892, 0.17956948, 405.1471, 0.14327724)
   validation loss 397.5655517578125, (188.28029, 0.049959715, 209.23532, 0.14327724)
decoder loss ratio: 7294.305253, decoder SINDy loss  ratio: 0.451664
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11178336]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.745945]
 [  0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.0379638671875, (211.91628, 0.17583491, 407.94583, 0.14328673)
   validation loss 366.5103454589844, (159.2017, 0.049400903, 207.25923, 0.14328673)
decoder loss ratio: 6167.750474, decoder SINDy loss  ratio: 0.447398
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11159418]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.796869]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.1348266601562, (218.17857, 0.1860757, 407.77017, 0.14329901)
   validation loss 371.9718017578125, (165.26866, 0.05189216, 206.65125, 0.14329901)
decoder loss ratio: 6402.794865, decoder SINDy loss  ratio: 0.446086
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11144588]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.762198]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.6077270507812, (219.12941, 0.17200352, 406.3063, 0.14330772)
   validation loss 371.2469787597656, (163.62115, 0.05019655, 207.57562, 0.14330772)
decoder loss ratio: 6338.967595, decoder SINDy loss  ratio: 0.448081
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11130748]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.71878]
 [ -0.     ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.6263427734375, (312.47504, 0.17529397, 402.976, 0.14331768)
   validation loss 445.28167724609375, (233.73486, 0.051522013, 211.4953, 0.14331768)
decoder loss ratio: 9055.294385, decoder SINDy loss  ratio: 0.456542
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1111343]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.691412]
 [ -0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.1580810546875, (224.94333, 0.17027456, 405.04446, 0.14332771)
   validation loss 375.46026611328125, (167.05515, 0.04945903, 208.35565, 0.14332771)
decoder loss ratio: 6472.006348, decoder SINDy loss  ratio: 0.449765
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11096051]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.705172]
 [ -0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.0784301757812, (491.2135, 0.16918926, 404.69574, 0.1433394)
   validation loss 607.351318359375, (386.12186, 0.051105466, 221.17836, 0.1433394)
decoder loss ratio: 14959.031065, decoder SINDy loss  ratio: 0.477445
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11091615]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.766195]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.6961669921875, (342.108, 0.16545606, 431.42267, 0.14334162)
   validation loss 514.8093872070312, (303.63235, 0.047523208, 211.12952, 0.14334162)
decoder loss ratio: 11763.244551, decoder SINDy loss  ratio: 0.455753
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11064543]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.734647]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.0255126953125, (290.16785, 0.17343183, 402.6842, 0.14335863)
   validation loss 430.4627380371094, (218.53995, 0.0487852, 211.87401, 0.14335863)
decoder loss ratio: 8466.616969, decoder SINDy loss  ratio: 0.457360
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11046104]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.733022]
 [  0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.1075439453125, (215.71762, 0.17476875, 406.21512, 0.14337014)
   validation loss 370.78118896484375, (163.22867, 0.0485017, 207.50401, 0.14337014)
decoder loss ratio: 6323.761984, decoder SINDy loss  ratio: 0.447927
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11026765]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.70091]
 [ -0.     ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.0027465820312, (297.2382, 0.16811448, 401.59644, 0.14338174)
   validation loss 436.606201171875, (224.2633, 0.04986887, 212.29303, 0.14338174)
decoder loss ratio: 8688.349800, decoder SINDy loss  ratio: 0.458264
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11009471]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-15.73224]
 [ -0.     ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.59521484375, (253.63112, 0.17107108, 402.79303, 0.1433923)
   validation loss 396.5670166015625, (187.37755, 0.05060439, 209.13889, 0.1433923)
decoder loss ratio: 7259.331520, decoder SINDy loss  ratio: 0.451456
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1098676]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.733483]
 [ -0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 859.050048828125, (455.80594, 0.16708119, 403.07706, 0.1434055)
   validation loss 570.2353515625, (351.439, 0.052826367, 218.74352, 0.1434055)
decoder loss ratio: 13615.356805, decoder SINDy loss  ratio: 0.472189
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10977843]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.749725]
 [ -0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1773.4730224609375, (1257.2323, 0.19350724, 516.04724, 0.14341441)
   validation loss 1457.1619873046875, (1210.3625, 0.04448121, 246.75504, 0.14341441)
decoder loss ratio: 46891.546423, decoder SINDy loss  ratio: 0.532655
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10954104]
 [0.        ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.7337265]
 [  0.       ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.4937133789062, (311.1823, 0.17107852, 402.14032, 0.14342724)
   validation loss 448.7979736328125, (237.12962, 0.048921667, 211.61943, 0.14342724)
decoder loss ratio: 9186.813286, decoder SINDy loss  ratio: 0.456810
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10935547]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.783452]
 [  0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.1405029296875, (341.38962, 0.17303684, 401.57788, 0.14343901)
   validation loss 468.93511962890625, (256.46692, 0.049685236, 212.41853, 0.14343901)
decoder loss ratio: 9935.973686, decoder SINDy loss  ratio: 0.458535
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10918054]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.772394]
 [ -0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.6129150390625, (412.09738, 0.16244589, 402.35306, 0.14344873)
   validation loss 529.6392211914062, (312.9495, 0.051637217, 216.63808, 0.14344873)
decoder loss ratio: 12124.206679, decoder SINDy loss  ratio: 0.467644
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10910836]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.876661]
 [ -0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1273.7545166015625, (788.1672, 0.18561184, 485.4017, 0.14345515)
   validation loss 967.073974609375, (738.5154, 0.045914214, 228.5127, 0.14345515)
decoder loss ratio: 28611.367974, decoder SINDy loss  ratio: 0.493277
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1088801]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.761571]
 [ -0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.8346557617188, (250.74843, 0.1698855, 401.91632, 0.14346726)
   validation loss 390.53900146484375, (180.636, 0.047437195, 209.85556, 0.14346726)
decoder loss ratio: 6998.152299, decoder SINDy loss  ratio: 0.453003
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10869028]
 [0.        ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.8081665]
 [ -0.       ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1006.96923828125, (600.70715, 0.17091808, 406.09122, 0.14347963)
   validation loss 701.8972778320312, (478.2909, 0.051303983, 223.55508, 0.14347963)
decoder loss ratio: 18529.819566, decoder SINDy loss  ratio: 0.482575
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10854907]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.85903]
 [  0.     ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.1200561523438, (246.94049, 0.16706985, 416.01248, 0.14348821)
   validation loss 421.4682922363281, (215.10912, 0.04766973, 206.31151, 0.14348821)
decoder loss ratio: 8333.700584, decoder SINDy loss  ratio: 0.445352
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10841616]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.796131]
 [ -0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 836.4986572265625, (434.8791, 0.15792534, 401.46164, 0.1434956)
   validation loss 555.1693725585938, (337.41428, 0.0509657, 217.70415, 0.1434956)
decoder loss ratio: 13072.014834, decoder SINDy loss  ratio: 0.469945
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10820501]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.839644]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 614.44140625, (205.8284, 0.17468034, 408.43835, 0.14350855)
   validation loss 370.60247802734375, (165.31975, 0.05238899, 205.23033, 0.14350855)
decoder loss ratio: 6404.774042, decoder SINDy loss  ratio: 0.443019
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10806003]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.805819]
 [  0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.986328125, (362.053, 0.16549583, 428.76785, 0.1435166)
   validation loss 551.5802001953125, (342.7422, 0.04770814, 208.79031, 0.1435166)
decoder loss ratio: 13278.427370, decoder SINDy loss  ratio: 0.450703
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10791348]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.815794]
 [  0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.65478515625, (250.81152, 0.16261071, 401.68063, 0.14352639)
   validation loss 391.96771240234375, (183.51886, 0.048319183, 208.40051, 0.14352639)
decoder loss ratio: 7109.839234, decoder SINDy loss  ratio: 0.449862
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10775325]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.838215]
 [  0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 616.7421875, (210.5288, 0.15774246, 406.05566, 0.14353645)
   validation loss 365.473876953125, (159.5132, 0.049612414, 205.91107, 0.14353645)
decoder loss ratio: 6179.818251, decoder SINDy loss  ratio: 0.444488
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10766004]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.86537]
 [  0.     ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.9550170898438, (418.74527, 0.15364988, 401.0561, 0.14354132)
   validation loss 540.2400512695312, (322.64618, 0.0510616, 217.54282, 0.14354132)
decoder loss ratio: 12499.873121, decoder SINDy loss  ratio: 0.469597
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10753648]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.872248]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.6561889648438, (263.08276, 0.14947672, 399.42395, 0.14354949)
   validation loss 408.13970947265625, (197.33464, 0.050074507, 210.755, 0.14354949)
decoder loss ratio: 7645.086561, decoder SINDy loss  ratio: 0.454944
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1073626]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.943578]
 [ -0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.573974609375, (268.3065, 0.1560784, 399.11142, 0.1435602)
   validation loss 413.6986083984375, (202.88493, 0.04951567, 210.76418, 0.1435602)
decoder loss ratio: 7860.114546, decoder SINDy loss  ratio: 0.454964
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10710253]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.904472]
 [ -0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.524169921875, (208.19226, 0.17070769, 407.16122, 0.14357524)
   validation loss 371.5106506347656, (165.92421, 0.052748755, 205.53369, 0.14357524)
decoder loss ratio: 6428.191937, decoder SINDy loss  ratio: 0.443673
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10692636]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.915579]
 [ -0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.3544921875, (266.35104, 0.15815188, 399.8453, 0.14358565)
   validation loss 405.78472900390625, (195.62668, 0.049908195, 210.10815, 0.14358565)
decoder loss ratio: 7578.917147, decoder SINDy loss  ratio: 0.453548
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1067751]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.920063]
 [  0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.566162109375, (287.76636, 0.15035924, 398.64948, 0.14359409)
   validation loss 428.17047119140625, (215.79778, 0.051444065, 212.32126, 0.14359409)
decoder loss ratio: 8360.380455, decoder SINDy loss  ratio: 0.458325
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10655715]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.898227]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 965.3150634765625, (566.11316, 0.15683009, 399.045, 0.14360896)
   validation loss 690.6776733398438, (470.55273, 0.05214257, 220.07277, 0.14360896)
decoder loss ratio: 18230.029845, decoder SINDy loss  ratio: 0.475058
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10639241]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.96959]
 [ -0.     ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 636.3961181640625, (236.89484, 0.14685114, 399.35443, 0.14361738)
   validation loss 386.7315979003906, (178.04631, 0.05105212, 208.63423, 0.14361738)
decoder loss ratio: 6897.823168, decoder SINDy loss  ratio: 0.450366
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10620405]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.880003]
 [  0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.6513671875, (211.60707, 0.163708, 406.8806, 0.14362934)
   validation loss 375.50103759765625, (170.14763, 0.05163513, 205.30176, 0.14362934)
decoder loss ratio: 6591.814528, decoder SINDy loss  ratio: 0.443173
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10599288]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.894207]
 [ -0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 633.519287109375, (226.94856, 0.14979918, 406.42096, 0.14363952)
   validation loss 395.00775146484375, (190.19394, 0.05046172, 204.76335, 0.14363952)
decoder loss ratio: 7368.443396, decoder SINDy loss  ratio: 0.442010
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.105933]
 [0.      ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.98897]
 [  0.     ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.3417358398438, (393.66318, 0.15622729, 402.52234, 0.14364731)
   validation loss 512.9530029296875, (295.5754, 0.04886955, 217.32877, 0.14364731)
decoder loss ratio: 11451.104484, decoder SINDy loss  ratio: 0.469135
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10567897]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.001661]
 [  0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.1812744140625, (215.69308, 0.15307513, 406.33514, 0.14366)
   validation loss 376.47039794921875, (171.1037, 0.05009238, 205.31662, 0.14366)
decoder loss ratio: 6628.854338, decoder SINDy loss  ratio: 0.443205
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10551074]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.890845]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 614.1975708007812, (212.81627, 0.14812893, 401.23315, 0.14367072)
   validation loss 366.80718994140625, (159.97122, 0.047703836, 206.78828, 0.14367072)
decoder loss ratio: 6197.562860, decoder SINDy loss  ratio: 0.446382
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10529857]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.953264]
 [  0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.287353515625, (212.61743, 0.15174615, 402.5182, 0.14368346)
   validation loss 366.8900146484375, (161.23888, 0.051054556, 205.6001, 0.14368346)
decoder loss ratio: 6246.673993, decoder SINDy loss  ratio: 0.443817
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10513726]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.924477]
 [  0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.9515991210938, (389.1462, 0.14660642, 397.65878, 0.1436929)
   validation loss 517.057373046875, (301.9523, 0.051034577, 215.05405, 0.1436929)
decoder loss ratio: 11698.156354, decoder SINDy loss  ratio: 0.464224
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10499212]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.022972]
 [ -0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.351806640625, (213.33081, 0.1478486, 401.87314, 0.14370112)
   validation loss 366.9236755371094, (161.35982, 0.051014174, 205.51285, 0.14370112)
decoder loss ratio: 6251.359463, decoder SINDy loss  ratio: 0.443628
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10482319]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.990865]
 [ -0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.8746337890625, (502.53033, 0.14638202, 398.1979, 0.14371324)
   validation loss 629.2315673828125, (410.1509, 0.050408583, 219.03026, 0.14371324)
decoder loss ratio: 15889.958284, decoder SINDy loss  ratio: 0.472808
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10473064]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.05562]
 [ -0.     ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.8609619140625, (272.57697, 0.14449319, 398.13953, 0.14371862)
   validation loss 417.62646484375, (206.89003, 0.048906684, 210.68755, 0.14371862)
decoder loss ratio: 8015.278935, decoder SINDy loss  ratio: 0.454799
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10466062]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.977808]
 [  0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.7748413085938, (283.74362, 0.15399489, 406.87723, 0.14372075)
   validation loss 453.79656982421875, (247.03815, 0.044458732, 206.71397, 0.14372075)
decoder loss ratio: 9570.686691, decoder SINDy loss  ratio: 0.446221
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10435413]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.939851]
 [ -0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.7589111328125, (246.5562, 0.15066788, 411.05203, 0.14373925)
   validation loss 415.23779296875, (210.1554, 0.049495716, 205.0329, 0.14373925)
decoder loss ratio: 8141.784868, decoder SINDy loss  ratio: 0.442592
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10417621]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.986521]
 [ -0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1754.5791015625, (1237.882, 0.1576962, 516.5395, 0.1437515)
   validation loss 1428.0018310546875, (1182.7773, 0.046892032, 245.17757, 0.1437515)
decoder loss ratio: 45822.847689, decoder SINDy loss  ratio: 0.529250
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10397151]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.090187]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 957.022216796875, (551.6311, 0.15553308, 405.2356, 0.14376199)
   validation loss 645.993896484375, (423.34866, 0.050605997, 222.59467, 0.14376199)
decoder loss ratio: 16401.262183, decoder SINDy loss  ratio: 0.480502
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10388881]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.049929]
 [  0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.6473388671875, (288.39032, 0.14042981, 396.11655, 0.14376733)
   validation loss 425.73126220703125, (216.3529, 0.0517422, 209.32661, 0.14376733)
decoder loss ratio: 8381.887155, decoder SINDy loss  ratio: 0.451861
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10379878]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.015944]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.4366455078125, (316.0625, 0.13692112, 396.2372, 0.14377247)
   validation loss 452.9203796386719, (239.96916, 0.049142625, 212.90207, 0.14377247)
decoder loss ratio: 9296.821940, decoder SINDy loss  ratio: 0.459579
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10365062]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.036425]
 [ -0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.8045654296875, (261.05893, 0.13458037, 395.61108, 0.1437807)
   validation loss 405.0879211425781, (195.45201, 0.050782636, 209.58513, 0.1437807)
decoder loss ratio: 7572.150230, decoder SINDy loss  ratio: 0.452419
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10347659]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.068932]
 [ -0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 634.4491577148438, (237.18, 0.14720283, 397.12195, 0.14379098)
   validation loss 383.7474365234375, (176.71362, 0.051108472, 206.9827, 0.14379098)
decoder loss ratio: 6846.192545, decoder SINDy loss  ratio: 0.446801
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10325643]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.015907]
 [  0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.4061889648438, (224.85538, 0.14510337, 398.4057, 0.14380372)
   validation loss 374.485107421875, (168.66507, 0.052456036, 205.76756, 0.14380372)
decoder loss ratio: 6534.377611, decoder SINDy loss  ratio: 0.444178
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10305585]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.051825]
 [ -0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 633.0216674804688, (226.27727, 0.16022912, 406.58417, 0.14381647)
   validation loss 387.414794921875, (183.93483, 0.054756876, 203.42519, 0.14381647)
decoder loss ratio: 7125.954628, decoder SINDy loss  ratio: 0.439122
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10293254]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.023102]
 [  0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 616.505126953125, (212.31947, 0.14359923, 404.04202, 0.14382362)
   validation loss 367.32696533203125, (162.3587, 0.04800985, 204.92026, 0.14382362)
decoder loss ratio: 6290.058045, decoder SINDy loss  ratio: 0.442349
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10278368]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.010096]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.912841796875, (236.2031, 0.14125484, 408.5685, 0.14383161)
   validation loss 403.4691162109375, (199.23775, 0.05039258, 204.18095, 0.14383161)
decoder loss ratio: 7718.816218, decoder SINDy loss  ratio: 0.440753
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10265521]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.102205]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.587646484375, (269.54013, 0.14260486, 395.90488, 0.14383934)
   validation loss 403.24822998046875, (196.30272, 0.05273297, 206.89276, 0.14383934)
decoder loss ratio: 7605.108135, decoder SINDy loss  ratio: 0.446607
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1025323]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.14276]
 [  0.     ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.397705078125, (250.47649, 0.13399407, 395.78726, 0.14384621)
   validation loss 389.5726318359375, (182.72905, 0.05257609, 206.791, 0.14384621)
decoder loss ratio: 7079.240616, decoder SINDy loss  ratio: 0.446387
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10243692]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.098167]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.4177856445312, (209.51215, 0.14081919, 400.7648, 0.14385137)
   validation loss 366.3420104980469, (162.84486, 0.054144617, 203.44301, 0.14385137)
decoder loss ratio: 6308.892738, decoder SINDy loss  ratio: 0.439160
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10226631]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.159208]
 [ -0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 611.0206298828125, (211.13033, 0.15049678, 399.73984, 0.14386176)
   validation loss 364.9381103515625, (162.03488, 0.056673344, 202.84654, 0.14386176)
decoder loss ratio: 6277.512618, decoder SINDy loss  ratio: 0.437873
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10222242]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.098871]
 [ -0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1281.4306640625, (812.96625, 0.1533426, 468.31104, 0.14386539)
   validation loss 1019.8358154296875, (796.9572, 0.052483905, 222.82614, 0.14386539)
decoder loss ratio: 30875.506063, decoder SINDy loss  ratio: 0.481002
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10210676]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.12018]
 [  0.     ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.5591430664062, (225.60268, 0.13928744, 397.8172, 0.14387117)
   validation loss 371.181884765625, (166.5792, 0.049389496, 204.55331, 0.14387117)
decoder loss ratio: 6453.567135, decoder SINDy loss  ratio: 0.441557
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10203847]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.03748]
 [  0.     ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.4979248046875, (238.86021, 0.13008058, 409.50763, 0.14387499)
   validation loss 401.8865661621094, (197.74922, 0.05227906, 204.08507, 0.14387499)
decoder loss ratio: 7661.148160, decoder SINDy loss  ratio: 0.440546
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10186909]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.044374]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.3997802734375, (290.97372, 0.13815275, 394.28793, 0.14388566)
   validation loss 417.60540771484375, (210.63304, 0.053609375, 206.91878, 0.14388566)
decoder loss ratio: 8160.289698, decoder SINDy loss  ratio: 0.446663
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10180591]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.089785]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 609.8555297851562, (211.5114, 0.13915652, 398.20496, 0.14388858)
   validation loss 364.3525695800781, (161.75598, 0.055978667, 202.5406, 0.14388858)
decoder loss ratio: 6266.707542, decoder SINDy loss  ratio: 0.437212
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10170811]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.10835]
 [  0.     ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 612.3640747070312, (213.3392, 0.146602, 398.87827, 0.14389347)
   validation loss 366.272705078125, (163.93338, 0.058493823, 202.28082, 0.14389347)
decoder loss ratio: 6351.063747, decoder SINDy loss  ratio: 0.436652
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10165122]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.157696]
 [ -0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 995.1790161132812, (580.16956, 0.15066071, 414.85883, 0.14389451)
   validation loss 808.5984497070312, (604.6202, 0.045892794, 203.93239, 0.14389451)
decoder loss ratio: 23424.035371, decoder SINDy loss  ratio: 0.440217
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10170887]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.143915]
 [ -0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.5311889648438, (226.59734, 0.1240301, 396.80984, 0.14389412)
   validation loss 373.3939208984375, (169.71654, 0.055406723, 203.62196, 0.14389412)
decoder loss ratio: 6575.113303, decoder SINDy loss  ratio: 0.439547
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10157382]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.073683]
 [ -0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 612.7442626953125, (216.52368, 0.13235751, 396.08826, 0.14390169)
   validation loss 363.85369873046875, (160.59598, 0.05438419, 203.20332, 0.14390169)
decoder loss ratio: 6221.766986, decoder SINDy loss  ratio: 0.438643
params['save_name']
pendulum_2023_11_11_19_27_05_785152
