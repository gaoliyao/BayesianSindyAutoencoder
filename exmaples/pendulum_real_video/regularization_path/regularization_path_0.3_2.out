nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-11-09 04:00:57.213592: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-11-09 04:00:57.221117: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-11-09 04:00:57.222839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557b0005750 executing computations on platform Host. Devices:
2023-11-09 04:00:57.222878: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-11-09 04:00:57.224761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-11-09 04:00:57.357749: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557b00ccd70 executing computations on platform CUDA. Devices:
2023-11-09 04:00:57.357808: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-11-09 04:00:57.358794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-11-09 04:00:57.359373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-09 04:00:57.363993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-11-09 04:00:57.367596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-11-09 04:00:57.368133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-11-09 04:00:57.371310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-11-09 04:00:57.373116: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-11-09 04:00:57.378915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-11-09 04:00:57.379732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-11-09 04:00:57.379782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-09 04:00:57.380236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-11-09 04:00:57.380249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-11-09 04:00:57.380257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-11-09 04:00:57.381035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-11-09 04:00:58.575958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.3, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8680598735809326 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 109847.265625, (107245.15, 0.0064096847, 2585.1458, 2.5317788)
   validation loss 98052.71875, (96835.0, 0.003170234, 1200.7545, 2.5317788)
decoder loss ratio: 3751556.012953, decoder SINDy loss  ratio: 2.591998
--- 0.2547590732574463 seconds for one epoch ---
--- 0.3193039894104004 seconds for one epoch ---
--- 0.32761454582214355 seconds for one epoch ---
--- 0.31028223037719727 seconds for one epoch ---
--- 0.2974417209625244 seconds for one epoch ---
--- 0.28911256790161133 seconds for one epoch ---
--- 0.3115525245666504 seconds for one epoch ---
--- 0.31278085708618164 seconds for one epoch ---
--- 0.3479788303375244 seconds for one epoch ---
--- 0.32748961448669434 seconds for one epoch ---
--- 0.35391664505004883 seconds for one epoch ---
--- 0.30359816551208496 seconds for one epoch ---
--- 0.33397960662841797 seconds for one epoch ---
--- 0.30261826515197754 seconds for one epoch ---
--- 0.3537333011627197 seconds for one epoch ---
--- 0.3276994228363037 seconds for one epoch ---
--- 0.33432435989379883 seconds for one epoch ---
--- 0.3459932804107666 seconds for one epoch ---
--- 0.3541254997253418 seconds for one epoch ---
--- 0.3443260192871094 seconds for one epoch ---
--- 0.33556222915649414 seconds for one epoch ---
--- 0.329226016998291 seconds for one epoch ---
--- 0.32416844367980957 seconds for one epoch ---
--- 0.3280344009399414 seconds for one epoch ---
=========================
[[0.7808559 ]
 [0.77729505]
 [0.7850444 ]
 [0.7767081 ]
 [0.7728973 ]
 [0.78774154]
 [0.78287834]
 [0.7727033 ]
 [0.7723687 ]
 [0.871141  ]
 [0.7745738 ]]
[[ 0.66662496]
 [ 0.52178085]
 [-0.78198797]
 [-0.490143  ]
 [-0.1240962 ]
 [-0.83991754]
 [ 0.7272355 ]
 [-0.08619197]
 [ 0.00711717]
 [-1.5400411 ]
 [ 0.3376694 ]]
--- 0.25893640518188477 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 66429.4453125, (64053.246, 9.309596, 2330.5615, 2.531736)
   validation loss 47934.10546875, (46593.87, 16.288702, 1287.6161, 2.531736)
decoder loss ratio: 1805127.456689, decoder SINDy loss  ratio: 2.779500
--- 0.3327174186706543 seconds for one epoch ---
--- 0.3285810947418213 seconds for one epoch ---
--- 0.320723295211792 seconds for one epoch ---
--- 0.3505570888519287 seconds for one epoch ---
--- 0.3146209716796875 seconds for one epoch ---
--- 0.3445158004760742 seconds for one epoch ---
--- 0.30315709114074707 seconds for one epoch ---
--- 0.35025954246520996 seconds for one epoch ---
--- 0.31109166145324707 seconds for one epoch ---
--- 0.32080602645874023 seconds for one epoch ---
--- 0.30796241760253906 seconds for one epoch ---
--- 0.34418606758117676 seconds for one epoch ---
--- 0.31059741973876953 seconds for one epoch ---
--- 0.36369943618774414 seconds for one epoch ---
--- 0.3026285171508789 seconds for one epoch ---
--- 0.3405930995941162 seconds for one epoch ---
--- 0.3158881664276123 seconds for one epoch ---
--- 0.3414168357849121 seconds for one epoch ---
--- 0.32053542137145996 seconds for one epoch ---
--- 0.33661556243896484 seconds for one epoch ---
--- 0.33588552474975586 seconds for one epoch ---
--- 0.33404541015625 seconds for one epoch ---
--- 0.3016014099121094 seconds for one epoch ---
--- 0.3271055221557617 seconds for one epoch ---
=========================
[[0.7200341 ]
 [0.6138874 ]
 [0.6191956 ]
 [0.61180496]
 [0.6106882 ]
 [0.6913942 ]
 [0.6206167 ]
 [0.61171716]
 [0.6105465 ]
 [0.6202231 ]
 [0.61380893]]
[[ 1.3364133 ]
 [ 0.31260148]
 [-0.5278543 ]
 [-0.1584356 ]
 [ 0.02625555]
 [-1.2161819 ]
 [ 0.56716084]
 [ 0.14986838]
 [ 0.00449432]
 [-0.5567454 ]
 [ 0.3079794 ]]
--- 0.30852508544921875 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 52810.2734375, (47981.477, 10.193246, 4766.678, 2.5317218)
   validation loss 36434.55859375, (35220.695, 3.526377, 1158.4103, 2.5317218)
decoder loss ratio: 1364510.882222, decoder SINDy loss  ratio: 2.500592
--- 0.2531144618988037 seconds for one epoch ---
--- 0.2978787422180176 seconds for one epoch ---
--- 0.3567330837249756 seconds for one epoch ---
--- 0.3223152160644531 seconds for one epoch ---
--- 0.35375142097473145 seconds for one epoch ---
--- 0.30742335319519043 seconds for one epoch ---
--- 0.352524995803833 seconds for one epoch ---
--- 0.30480504035949707 seconds for one epoch ---
--- 0.3519132137298584 seconds for one epoch ---
--- 0.29989123344421387 seconds for one epoch ---
--- 0.3452420234680176 seconds for one epoch ---
--- 0.3076810836791992 seconds for one epoch ---
--- 0.35861873626708984 seconds for one epoch ---
--- 0.29662442207336426 seconds for one epoch ---
--- 0.31776881217956543 seconds for one epoch ---
--- 0.40300679206848145 seconds for one epoch ---
--- 0.3470187187194824 seconds for one epoch ---
--- 0.3117334842681885 seconds for one epoch ---
--- 0.3639945983886719 seconds for one epoch ---
--- 0.30553722381591797 seconds for one epoch ---
--- 0.35970616340637207 seconds for one epoch ---
--- 0.32527923583984375 seconds for one epoch ---
--- 0.3488883972167969 seconds for one epoch ---
--- 0.32226133346557617 seconds for one epoch ---
=========================
[[0.67494357]
 [0.4770823 ]
 [0.4796015 ]
 [0.47554103]
 [0.4750363 ]
 [0.7623391 ]
 [0.4840845 ]
 [0.47754186]
 [0.47498205]
 [0.475268  ]
 [0.4789174 ]]
[[ 1.4732320e+00]
 [ 1.8404157e-01]
 [-3.1632549e-01]
 [-6.1356019e-02]
 [ 7.4577103e-03]
 [-1.6787040e+00]
 [ 4.6573246e-01]
 [ 2.1277545e-01]
 [ 1.0382129e-03]
 [-3.3399656e-02]
 [ 2.8562143e-01]]
--- 0.2826073169708252 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 29570.048828125, (23838.525, 6.134362, 5656.073, 2.5317273)
   validation loss 13950.4189453125, (12841.719, 1.0262064, 1038.3584, 2.5317273)
decoder loss ratio: 497510.478579, decoder SINDy loss  ratio: 2.241443
--- 0.29955101013183594 seconds for one epoch ---
--- 0.34200239181518555 seconds for one epoch ---
--- 0.32878780364990234 seconds for one epoch ---
--- 0.3407421112060547 seconds for one epoch ---
--- 0.3113067150115967 seconds for one epoch ---
--- 0.3417999744415283 seconds for one epoch ---
--- 0.3265650272369385 seconds for one epoch ---
--- 0.3504822254180908 seconds for one epoch ---
--- 0.30152368545532227 seconds for one epoch ---
--- 0.35683751106262207 seconds for one epoch ---
--- 0.30448365211486816 seconds for one epoch ---
--- 0.3569364547729492 seconds for one epoch ---
--- 0.3108644485473633 seconds for one epoch ---
--- 0.3728139400482178 seconds for one epoch ---
--- 0.3096327781677246 seconds for one epoch ---
--- 0.3550899028778076 seconds for one epoch ---
--- 0.3186054229736328 seconds for one epoch ---
--- 0.3602933883666992 seconds for one epoch ---
--- 0.2968015670776367 seconds for one epoch ---
--- 0.3472590446472168 seconds for one epoch ---
--- 0.3199484348297119 seconds for one epoch ---
--- 0.3497741222381592 seconds for one epoch ---
--- 0.32339954376220703 seconds for one epoch ---
--- 0.35723209381103516 seconds for one epoch ---
=========================
[[0.49931866]
 [0.37928188]
 [0.37839544]
 [0.3781228 ]
 [0.3780873 ]
 [0.9086563 ]
 [0.3853649 ]
 [0.38160244]
 [0.37805337]
 [0.3780845 ]
 [0.38446462]]
[[ 1.1926932 ]
 [ 0.10603213]
 [ 0.0351202 ]
 [-0.0094982 ]
 [-0.00598869]
 [-2.1597025 ]
 [ 0.37692863]
 [ 0.2385213 ]
 [-0.00264189]
 [-0.00573516]
 [ 0.348987  ]]
--- 0.296522855758667 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 25474.439453125, (14014.555, 37.920048, 11338.374, 2.5317342)
   validation loss 8557.1943359375, (7537.089, 0.5551979, 935.95966, 2.5317342)
decoder loss ratio: 291999.907677, decoder SINDy loss  ratio: 2.020401
--- 0.27117085456848145 seconds for one epoch ---
--- 0.3017463684082031 seconds for one epoch ---
--- 0.34342503547668457 seconds for one epoch ---
--- 0.3072981834411621 seconds for one epoch ---
--- 0.3539559841156006 seconds for one epoch ---
--- 0.3164184093475342 seconds for one epoch ---
--- 0.34663844108581543 seconds for one epoch ---
--- 0.3186628818511963 seconds for one epoch ---
--- 0.3647744655609131 seconds for one epoch ---
--- 0.29886674880981445 seconds for one epoch ---
--- 0.3646426200866699 seconds for one epoch ---
--- 0.2943897247314453 seconds for one epoch ---
--- 0.3688619136810303 seconds for one epoch ---
--- 0.29788994789123535 seconds for one epoch ---
--- 0.3635714054107666 seconds for one epoch ---
--- 0.3029215335845947 seconds for one epoch ---
--- 0.36955857276916504 seconds for one epoch ---
--- 0.32741832733154297 seconds for one epoch ---
--- 0.3724794387817383 seconds for one epoch ---
--- 0.32394909858703613 seconds for one epoch ---
--- 0.368624210357666 seconds for one epoch ---
--- 0.2998480796813965 seconds for one epoch ---
--- 0.37078213691711426 seconds for one epoch ---
--- 0.2989535331726074 seconds for one epoch ---
=========================
[[0.33234233]
 [0.29681873]
 [0.30186886]
 [0.29661804]
 [0.2965262 ]
 [0.97512823]
 [0.30337554]
 [0.3002779 ]
 [0.29636234]
 [0.30121255]
 [0.30610546]]
[[ 0.7565155 ]
 [ 0.04073143]
 [ 0.29436675]
 [ 0.02465593]
 [-0.01698105]
 [-2.6374087 ]
 [ 0.34206817]
 [ 0.23449007]
 [-0.0027984 ]
 [-0.27105328]
 [ 0.41338947]]
--- 0.27965474128723145 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 17296.4921875, (9404.075, 0.6396052, 7794.47, 2.5317543)
   validation loss 6241.8076171875, (5306.2314, 0.24016215, 838.0288, 2.5317543)
decoder loss ratio: 205572.618214, decoder SINDy loss  ratio: 1.809003
--- 0.30582642555236816 seconds for one epoch ---
--- 0.3861379623413086 seconds for one epoch ---
--- 0.2916450500488281 seconds for one epoch ---
--- 0.34380292892456055 seconds for one epoch ---
--- 0.3274829387664795 seconds for one epoch ---
--- 0.38826584815979004 seconds for one epoch ---
--- 0.3215451240539551 seconds for one epoch ---
--- 0.3594834804534912 seconds for one epoch ---
--- 0.34293651580810547 seconds for one epoch ---
--- 0.3634064197540283 seconds for one epoch ---
--- 0.3133704662322998 seconds for one epoch ---
--- 0.3672041893005371 seconds for one epoch ---
--- 0.3170969486236572 seconds for one epoch ---
--- 0.37752294540405273 seconds for one epoch ---
--- 0.3069112300872803 seconds for one epoch ---
--- 0.3945121765136719 seconds for one epoch ---
--- 0.30333709716796875 seconds for one epoch ---
--- 0.38738536834716797 seconds for one epoch ---
--- 0.3053760528564453 seconds for one epoch ---
--- 0.3778250217437744 seconds for one epoch ---
--- 0.309051513671875 seconds for one epoch ---
--- 0.3642146587371826 seconds for one epoch ---
--- 0.2949039936065674 seconds for one epoch ---
--- 0.3585329055786133 seconds for one epoch ---
=========================
[[0.24971932]
 [0.23794581]
 [0.25526232]
 [0.23859473]
 [0.23807374]
 [0.9901751 ]
 [0.24300489]
 [0.24265546]
 [0.237559  ]
 [0.2531918 ]
 [0.25058955]]
[[ 4.4579235e-01]
 [-3.1306867e-02]
 [ 5.3864205e-01]
 [ 7.6146856e-02]
 [-4.0692098e-02]
 [-2.9577453e+00]
 [ 2.7677187e-01]
 [ 2.6486382e-01]
 [ 1.0580355e-03]
 [-5.0703973e-01]
 [ 4.6228251e-01]]
--- 0.2796323299407959 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13657.1611328125, (8303.065, 0.7326052, 5244.649, 2.5317762)
   validation loss 4092.494140625, (3214.4194, 0.25888225, 769.10254, 2.5317762)
decoder loss ratio: 124532.189335, decoder SINDy loss  ratio: 1.660216
--- 0.265064001083374 seconds for one epoch ---
--- 0.30097436904907227 seconds for one epoch ---
--- 0.4071474075317383 seconds for one epoch ---
--- 0.29460692405700684 seconds for one epoch ---
--- 0.34255409240722656 seconds for one epoch ---
--- 0.30083441734313965 seconds for one epoch ---
--- 0.3816957473754883 seconds for one epoch ---
--- 0.3189549446105957 seconds for one epoch ---
--- 0.3846564292907715 seconds for one epoch ---
--- 0.3121206760406494 seconds for one epoch ---
--- 0.3822612762451172 seconds for one epoch ---
--- 0.30068302154541016 seconds for one epoch ---
--- 0.4047057628631592 seconds for one epoch ---
--- 0.3102281093597412 seconds for one epoch ---
--- 0.3909177780151367 seconds for one epoch ---
--- 0.32607197761535645 seconds for one epoch ---
--- 0.4096863269805908 seconds for one epoch ---
--- 0.32010507583618164 seconds for one epoch ---
--- 0.39737439155578613 seconds for one epoch ---
--- 0.3086521625518799 seconds for one epoch ---
--- 0.4188246726989746 seconds for one epoch ---
--- 0.27251362800598145 seconds for one epoch ---
--- 0.3898766040802002 seconds for one epoch ---
--- 0.2953376770019531 seconds for one epoch ---
=========================
[[0.19120066]
 [0.18961857]
 [0.2347288 ]
 [0.18940653]
 [0.18790369]
 [0.9961557 ]
 [0.19251183]
 [0.19391038]
 [0.18778543]
 [0.22122192]
 [0.2035067 ]]
[[ 0.19336754]
 [-0.12025693]
 [ 0.79291207]
 [ 0.1089749 ]
 [-0.01432695]
 [-3.2724855 ]
 [ 0.24304906]
 [ 0.28847834]
 [-0.0054471 ]
 [-0.6942864 ]
 [ 0.49356583]]
--- 0.25896477699279785 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12208.2890625, (7396.061, 35.569073, 4657.89, 2.5318036)
   validation loss 3497.539794921875, (2674.6777, 0.17350376, 703.9198, 2.5318036)
decoder loss ratio: 103621.658874, decoder SINDy loss  ratio: 1.519510
--- 0.33437609672546387 seconds for one epoch ---
--- 0.3967013359069824 seconds for one epoch ---
--- 0.30548548698425293 seconds for one epoch ---
--- 0.37573671340942383 seconds for one epoch ---
--- 0.2870802879333496 seconds for one epoch ---
--- 0.3909034729003906 seconds for one epoch ---
--- 0.28975892066955566 seconds for one epoch ---
--- 0.3858520984649658 seconds for one epoch ---
--- 0.31890439987182617 seconds for one epoch ---
--- 0.39681315422058105 seconds for one epoch ---
--- 0.32683300971984863 seconds for one epoch ---
--- 0.37377238273620605 seconds for one epoch ---
--- 0.3123586177825928 seconds for one epoch ---
--- 0.3883659839630127 seconds for one epoch ---
--- 0.32405996322631836 seconds for one epoch ---
--- 0.3956313133239746 seconds for one epoch ---
--- 0.3194403648376465 seconds for one epoch ---
--- 0.39905810356140137 seconds for one epoch ---
--- 0.30991101264953613 seconds for one epoch ---
--- 0.3981475830078125 seconds for one epoch ---
--- 0.30185508728027344 seconds for one epoch ---
--- 0.38940858840942383 seconds for one epoch ---
--- 0.30450010299682617 seconds for one epoch ---
--- 0.40070223808288574 seconds for one epoch ---
=========================
[[0.15235618]
 [0.15534908]
 [0.23278463]
 [0.15507504]
 [0.15172926]
 [0.9980424 ]
 [0.15581647]
 [0.15833531]
 [0.15171775]
 [0.2240874 ]
 [0.17315428]]
[[-0.04853574]
 [-0.19578627]
 [ 0.9482861 ]
 [ 0.18488495]
 [-0.00609779]
 [-3.4978695 ]
 [ 0.2135139 ]
 [ 0.2947197 ]
 [-0.0052436 ]
 [-0.9122016 ]
 [ 0.5612816 ]]
--- 0.2986137866973877 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9218.6669921875, (3992.9617, 3.3125896, 5094.8633, 2.5318286)
   validation loss 2194.111328125, (1581.3734, 0.124698974, 485.08414, 2.5318286)
decoder loss ratio: 61265.151408, decoder SINDy loss  ratio: 1.047122
--- 0.2869851589202881 seconds for one epoch ---
--- 0.3096776008605957 seconds for one epoch ---
--- 0.4070000648498535 seconds for one epoch ---
--- 0.31862592697143555 seconds for one epoch ---
--- 0.3809165954589844 seconds for one epoch ---
--- 0.334334135055542 seconds for one epoch ---
--- 0.38097071647644043 seconds for one epoch ---
--- 0.27578163146972656 seconds for one epoch ---
--- 0.39910078048706055 seconds for one epoch ---
--- 0.2828848361968994 seconds for one epoch ---
--- 0.39049839973449707 seconds for one epoch ---
--- 0.31977200508117676 seconds for one epoch ---
--- 0.42177891731262207 seconds for one epoch ---
--- 0.30832386016845703 seconds for one epoch ---
--- 0.4183473587036133 seconds for one epoch ---
--- 0.43706250190734863 seconds for one epoch ---
--- 0.41274452209472656 seconds for one epoch ---
--- 0.33233642578125 seconds for one epoch ---
--- 0.3975231647491455 seconds for one epoch ---
--- 0.323258638381958 seconds for one epoch ---
--- 0.4100167751312256 seconds for one epoch ---
--- 0.3081705570220947 seconds for one epoch ---
--- 0.41586971282958984 seconds for one epoch ---
--- 0.3091316223144531 seconds for one epoch ---
=========================
[[0.12545376]
 [0.1264542 ]
 [0.25676143]
 [0.12479962]
 [0.1209418 ]
 [0.9986486 ]
 [0.12474916]
 [0.12755798]
 [0.12094903]
 [0.24846295]
 [0.1466154 ]]
[[-2.2185712e-01]
 [-2.5468883e-01]
 [ 1.1089430e+00]
 [ 1.9831429e-01]
 [-3.3150113e-03]
 [-3.6253593e+00]
 [ 1.9643134e-01]
 [ 2.8727880e-01]
 [-3.8295179e-03]
 [-1.0870023e+00]
 [ 5.9929246e-01]]
--- 0.2546060085296631 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6157.3681640625, (2987.064, 0.59468454, 3035.0325, 2.5318508)
   validation loss 1772.1285400390625, (1147.7585, 0.095342994, 489.59784, 2.5318508)
decoder loss ratio: 44466.158627, decoder SINDy loss  ratio: 1.056866
--- 0.3112211227416992 seconds for one epoch ---
--- 0.4127519130706787 seconds for one epoch ---
--- 0.2880868911743164 seconds for one epoch ---
--- 0.4079911708831787 seconds for one epoch ---
--- 0.29923009872436523 seconds for one epoch ---
--- 0.4255390167236328 seconds for one epoch ---
--- 0.3016982078552246 seconds for one epoch ---
--- 0.438368558883667 seconds for one epoch ---
--- 0.29755210876464844 seconds for one epoch ---
--- 0.41705322265625 seconds for one epoch ---
--- 0.29491686820983887 seconds for one epoch ---
--- 0.40123748779296875 seconds for one epoch ---
--- 0.27887773513793945 seconds for one epoch ---
--- 0.4300706386566162 seconds for one epoch ---
--- 0.3051631450653076 seconds for one epoch ---
--- 0.4189596176147461 seconds for one epoch ---
--- 0.2954983711242676 seconds for one epoch ---
--- 0.4364891052246094 seconds for one epoch ---
--- 0.2942206859588623 seconds for one epoch ---
--- 0.41071271896362305 seconds for one epoch ---
--- 0.2925593852996826 seconds for one epoch ---
--- 0.4322025775909424 seconds for one epoch ---
--- 0.33542490005493164 seconds for one epoch ---
--- 0.41982126235961914 seconds for one epoch ---
=========================
[[0.10899829]
 [0.10473132]
 [0.29566565]
 [0.10198553]
 [0.09873196]
 [0.998852  ]
 [0.10206049]
 [0.10525648]
 [0.09854478]
 [0.3083107 ]
 [0.13138698]]
[[-3.7391078e-01]
 [-2.7012438e-01]
 [ 1.2358969e+00]
 [ 1.7843701e-01]
 [-1.5132184e-02]
 [-3.6844673e+00]
 [ 1.8134187e-01]
 [ 2.8493336e-01]
 [-2.4460279e-03]
 [-1.2599530e+00]
 [ 6.5962273e-01]]
--- 0.2945394515991211 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8877.0263671875, (4127.941, 1.4913957, 4605.967, 2.5318677)
   validation loss 2405.34619140625, (1827.5442, 0.061098814, 436.1137, 2.5318677)
decoder loss ratio: 70802.234656, decoder SINDy loss  ratio: 0.941413
--- 0.2639608383178711 seconds for one epoch ---
--- 0.33350157737731934 seconds for one epoch ---
--- 0.4084970951080322 seconds for one epoch ---
--- 0.3278505802154541 seconds for one epoch ---
--- 0.4126698970794678 seconds for one epoch ---
--- 0.30237460136413574 seconds for one epoch ---
--- 0.4127471446990967 seconds for one epoch ---
--- 0.3170435428619385 seconds for one epoch ---
--- 0.4388720989227295 seconds for one epoch ---
--- 0.332813024520874 seconds for one epoch ---
--- 0.42467689514160156 seconds for one epoch ---
--- 0.30858850479125977 seconds for one epoch ---
--- 0.42899298667907715 seconds for one epoch ---
--- 0.2937006950378418 seconds for one epoch ---
--- 0.41725873947143555 seconds for one epoch ---
--- 0.29481935501098633 seconds for one epoch ---
--- 0.4251410961151123 seconds for one epoch ---
--- 0.30298829078674316 seconds for one epoch ---
--- 0.4516279697418213 seconds for one epoch ---
--- 0.30321168899536133 seconds for one epoch ---
--- 0.44921278953552246 seconds for one epoch ---
--- 0.31357860565185547 seconds for one epoch ---
--- 0.4102764129638672 seconds for one epoch ---
--- 0.28847169876098633 seconds for one epoch ---
=========================
[[0.09793343]
 [0.08703183]
 [0.33599856]
 [0.08285496]
 [0.07954093]
 [0.99880767]
 [0.08296927]
 [0.08655707]
 [0.07935636]
 [0.39817187]
 [0.11217686]]
[[-5.0335360e-01]
 [-3.0641320e-01]
 [ 1.3328450e+00]
 [ 1.7800952e-01]
 [-1.4967314e-02]
 [-3.6790485e+00]
 [ 1.8233962e-01]
 [ 2.9423407e-01]
 [-2.7260883e-03]
 [-1.4279943e+00]
 [ 6.5361863e-01]]
--- 0.24093198776245117 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7690.46630859375, (2894.8845, 4.013201, 4643.5864, 2.5318787)
   validation loss 2434.776611328125, (1888.4424, 0.05118881, 398.30084, 2.5318787)
decoder loss ratio: 73161.536390, decoder SINDy loss  ratio: 0.859788
--- 0.31717824935913086 seconds for one epoch ---
--- 0.43048572540283203 seconds for one epoch ---
--- 0.297119140625 seconds for one epoch ---
--- 0.4160323143005371 seconds for one epoch ---
--- 0.34341859817504883 seconds for one epoch ---
--- 0.43052172660827637 seconds for one epoch ---
--- 0.3069462776184082 seconds for one epoch ---
--- 0.42148685455322266 seconds for one epoch ---
--- 0.32700109481811523 seconds for one epoch ---
--- 0.4172689914703369 seconds for one epoch ---
--- 0.32114410400390625 seconds for one epoch ---
--- 0.44219970703125 seconds for one epoch ---
--- 0.3001675605773926 seconds for one epoch ---
--- 0.4452357292175293 seconds for one epoch ---
--- 0.3139369487762451 seconds for one epoch ---
--- 0.40024662017822266 seconds for one epoch ---
--- 0.29863834381103516 seconds for one epoch ---
--- 0.4307565689086914 seconds for one epoch ---
--- 0.2876460552215576 seconds for one epoch ---
--- 0.41490650177001953 seconds for one epoch ---
--- 0.2936580181121826 seconds for one epoch ---
--- 0.43961238861083984 seconds for one epoch ---
--- 0.3020286560058594 seconds for one epoch ---
--- 0.43438720703125 seconds for one epoch ---
=========================
[[0.09316363]
 [0.07316633]
 [0.37369618]
 [0.06988972]
 [0.06564389]
 [0.99857163]
 [0.0688792 ]
 [0.07178418]
 [0.06528471]
 [0.50035846]
 [0.10389374]]
[[-6.0464793e-01]
 [-3.0806565e-01]
 [ 1.4058892e+00]
 [ 2.1447879e-01]
 [-2.4410000e-02]
 [-3.6272476e+00]
 [ 1.7877102e-01]
 [ 2.7197620e-01]
 [-1.2457138e-03]
 [-1.5787337e+00]
 [ 6.9479334e-01]]
--- 0.2961394786834717 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3786.012451171875, (2501.2207, 3.4361877, 1127.9773, 2.5318856)
   validation loss 2551.009521484375, (1991.127, 0.045974914, 406.45828, 2.5318856)
decoder loss ratio: 77139.714912, decoder SINDy loss  ratio: 0.877397
--- 0.2824552059173584 seconds for one epoch ---
--- 0.3166806697845459 seconds for one epoch ---
--- 0.4409213066101074 seconds for one epoch ---
--- 0.3019542694091797 seconds for one epoch ---
--- 0.4529380798339844 seconds for one epoch ---
--- 0.3004899024963379 seconds for one epoch ---
--- 0.452512264251709 seconds for one epoch ---
--- 0.3132660388946533 seconds for one epoch ---
--- 0.44389963150024414 seconds for one epoch ---
--- 0.32147812843322754 seconds for one epoch ---
--- 0.4535946846008301 seconds for one epoch ---
--- 0.30438733100891113 seconds for one epoch ---
--- 0.45944643020629883 seconds for one epoch ---
--- 0.32146263122558594 seconds for one epoch ---
--- 0.4611246585845947 seconds for one epoch ---
--- 0.32172274589538574 seconds for one epoch ---
--- 0.4312913417816162 seconds for one epoch ---
--- 0.3162524700164795 seconds for one epoch ---
--- 0.4492669105529785 seconds for one epoch ---
--- 0.2937586307525635 seconds for one epoch ---
--- 0.4740321636199951 seconds for one epoch ---
--- 0.2981431484222412 seconds for one epoch ---
--- 0.4324634075164795 seconds for one epoch ---
--- 0.3004450798034668 seconds for one epoch ---
=========================
[[0.0884802 ]
 [0.06040879]
 [0.41991714]
 [0.05799879]
 [0.05361516]
 [0.9980567 ]
 [0.05776081]
 [0.05988181]
 [0.05322007]
 [0.5812603 ]
 [0.09252302]]
[[-0.66598016]
 [-0.28933212]
 [ 1.481529  ]
 [ 0.21976934]
 [-0.02921807]
 [-3.5345898 ]
 [ 0.21196519]
 [ 0.2754002 ]
 [-0.00439527]
 [-1.6915557 ]
 [ 0.69654155]]
--- 0.26705098152160645 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7677.78759765625, (2318.7273, 0.90100586, 5199.6597, 2.5318875)
   validation loss 1350.1002197265625, (822.5513, 0.06138142, 368.9879, 2.5318875)
decoder loss ratio: 31867.064193, decoder SINDy loss  ratio: 0.796512
--- 0.31975507736206055 seconds for one epoch ---
--- 0.46275997161865234 seconds for one epoch ---
--- 0.3381533622741699 seconds for one epoch ---
--- 0.4320356845855713 seconds for one epoch ---
--- 0.3231475353240967 seconds for one epoch ---
--- 0.468951940536499 seconds for one epoch ---
--- 0.3048434257507324 seconds for one epoch ---
--- 0.4477059841156006 seconds for one epoch ---
--- 0.31760239601135254 seconds for one epoch ---
--- 0.4623086452484131 seconds for one epoch ---
--- 0.30524730682373047 seconds for one epoch ---
--- 0.4652392864227295 seconds for one epoch ---
--- 0.3045976161956787 seconds for one epoch ---
--- 0.4463489055633545 seconds for one epoch ---
--- 0.2930490970611572 seconds for one epoch ---
--- 0.4426271915435791 seconds for one epoch ---
--- 0.31064510345458984 seconds for one epoch ---
--- 0.4732785224914551 seconds for one epoch ---
--- 0.31730008125305176 seconds for one epoch ---
--- 0.461733341217041 seconds for one epoch ---
--- 0.3073594570159912 seconds for one epoch ---
--- 0.46210408210754395 seconds for one epoch ---
--- 0.3121376037597656 seconds for one epoch ---
--- 0.46555137634277344 seconds for one epoch ---
=========================
[[0.09406842]
 [0.05361479]
 [0.4906473 ]
 [0.04892068]
 [0.04468595]
 [0.9974152 ]
 [0.0481317 ]
 [0.05102402]
 [0.04424775]
 [0.69803697]
 [0.08723529]]
[[-7.6196945e-01]
 [-3.3789578e-01]
 [ 1.5806887e+00]
 [ 2.1301052e-01]
 [-2.8130990e-02]
 [-3.4480162e+00]
 [ 1.8599077e-01]
 [ 2.7524662e-01]
 [-6.3643180e-04]
 [-1.8567336e+00]
 [ 7.1907479e-01]]
--- 0.2967712879180908 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3741.075439453125, (1908.4363, 1.5280756, 1668.3394, 2.5318947)
   validation loss 1989.3380126953125, (1405.4265, 0.053598363, 421.08627, 2.5318947)
decoder loss ratio: 54448.663067, decoder SINDy loss  ratio: 0.908974
--- 0.26212644577026367 seconds for one epoch ---
--- 0.3072535991668701 seconds for one epoch ---
--- 0.46881723403930664 seconds for one epoch ---
--- 0.3131275177001953 seconds for one epoch ---
--- 0.4612612724304199 seconds for one epoch ---
--- 0.29360103607177734 seconds for one epoch ---
--- 0.45894455909729004 seconds for one epoch ---
--- 0.31323790550231934 seconds for one epoch ---
--- 0.44313931465148926 seconds for one epoch ---
--- 0.3193395137786865 seconds for one epoch ---
--- 0.46970534324645996 seconds for one epoch ---
--- 0.31787753105163574 seconds for one epoch ---
--- 0.46899938583374023 seconds for one epoch ---
--- 0.3175654411315918 seconds for one epoch ---
--- 0.48598408699035645 seconds for one epoch ---
--- 0.33434033393859863 seconds for one epoch ---
--- 0.4637463092803955 seconds for one epoch ---
--- 0.29793572425842285 seconds for one epoch ---
--- 0.4673442840576172 seconds for one epoch ---
--- 0.30707478523254395 seconds for one epoch ---
--- 0.4628283977508545 seconds for one epoch ---
--- 0.30346179008483887 seconds for one epoch ---
--- 0.47070837020874023 seconds for one epoch ---
--- 0.291226863861084 seconds for one epoch ---
=========================
[[0.10943151]
 [0.04705968]
 [0.55463   ]
 [0.04109318]
 [0.03690385]
 [0.9967871 ]
 [0.03950095]
 [0.04348067]
 [0.03659762]
 [0.80222124]
 [0.08345424]]
[[-0.87446755]
 [-0.36084622]
 [ 1.6669301 ]
 [ 0.20848663]
 [-0.02462929]
 [-3.3823593 ]
 [ 0.15085278]
 [ 0.2786553 ]
 [-0.0056104 ]
 [-2.0349526 ]
 [ 0.74215657]]
--- 0.26079487800598145 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4535.36083984375, (2237.5894, 0.26842627, 2131.032, 2.531905)
   validation loss 2232.45361328125, (1662.9977, 0.046398114, 402.93777, 2.531905)
decoder loss ratio: 64427.417240, decoder SINDy loss  ratio: 0.869798
--- 0.29912519454956055 seconds for one epoch ---
--- 0.460712194442749 seconds for one epoch ---
--- 0.3065180778503418 seconds for one epoch ---
--- 0.48500823974609375 seconds for one epoch ---
--- 0.3223898410797119 seconds for one epoch ---
--- 0.4845864772796631 seconds for one epoch ---
--- 0.3266723155975342 seconds for one epoch ---
--- 0.4737107753753662 seconds for one epoch ---
--- 0.30420470237731934 seconds for one epoch ---
--- 0.4758467674255371 seconds for one epoch ---
--- 0.31871867179870605 seconds for one epoch ---
--- 0.4711012840270996 seconds for one epoch ---
--- 0.30631279945373535 seconds for one epoch ---
--- 0.4794769287109375 seconds for one epoch ---
--- 0.3036806583404541 seconds for one epoch ---
--- 0.48186612129211426 seconds for one epoch ---
--- 0.30766797065734863 seconds for one epoch ---
--- 0.4748237133026123 seconds for one epoch ---
--- 0.2913219928741455 seconds for one epoch ---
--- 0.48421788215637207 seconds for one epoch ---
--- 0.29994940757751465 seconds for one epoch ---
--- 0.49480724334716797 seconds for one epoch ---
--- 0.31514978408813477 seconds for one epoch ---
--- 0.4869651794433594 seconds for one epoch ---
=========================
[[0.1337949 ]
 [0.04302737]
 [0.6168292 ]
 [0.03572049]
 [0.03137574]
 [0.996076  ]
 [0.03376407]
 [0.03760016]
 [0.03091799]
 [0.8755689 ]
 [0.08812627]]
[[-0.98241717]
 [-0.39181966]
 [ 1.7504288 ]
 [ 0.21874048]
 [-0.03563347]
 [-3.3214226 ]
 [ 0.14938876]
 [ 0.2732736 ]
 [-0.00799282]
 [-2.2076905 ]
 [ 0.7994248 ]]
--- 0.4284374713897705 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6764.8505859375, (2260.9429, 1.1965051, 4332.77, 2.5319166)
   validation loss 1316.64111328125, (795.8743, 0.043622077, 350.78183, 2.5319166)
decoder loss ratio: 30833.553189, decoder SINDy loss  ratio: 0.757212
--- 0.2710843086242676 seconds for one epoch ---
--- 0.30188512802124023 seconds for one epoch ---
--- 0.4666318893432617 seconds for one epoch ---
--- 0.2848978042602539 seconds for one epoch ---
--- 0.469210147857666 seconds for one epoch ---
--- 0.29515743255615234 seconds for one epoch ---
--- 0.4839601516723633 seconds for one epoch ---
--- 0.2990269660949707 seconds for one epoch ---
--- 0.4857749938964844 seconds for one epoch ---
--- 0.29263734817504883 seconds for one epoch ---
--- 0.4886763095855713 seconds for one epoch ---
--- 0.30675673484802246 seconds for one epoch ---
--- 0.4966251850128174 seconds for one epoch ---
--- 0.2985103130340576 seconds for one epoch ---
--- 0.4815812110900879 seconds for one epoch ---
--- 0.2719078063964844 seconds for one epoch ---
--- 0.49500513076782227 seconds for one epoch ---
--- 0.31260037422180176 seconds for one epoch ---
--- 0.516066312789917 seconds for one epoch ---
--- 0.30812525749206543 seconds for one epoch ---
--- 0.48894667625427246 seconds for one epoch ---
--- 0.33277273178100586 seconds for one epoch ---
--- 0.49637436866760254 seconds for one epoch ---
--- 0.31893277168273926 seconds for one epoch ---
=========================
[[0.1527991 ]
 [0.03888794]
 [0.6715814 ]
 [0.03041736]
 [0.02685446]
 [0.9948205 ]
 [0.02878094]
 [0.03185935]
 [0.02587488]
 [0.9147112 ]
 [0.08715618]]
[[-1.0503025 ]
 [-0.4056015 ]
 [ 1.8272474 ]
 [ 0.20759289]
 [-0.06082725]
 [-3.2359476 ]
 [ 0.14872473]
 [ 0.25151247]
 [ 0.00406076]
 [-2.339808  ]
 [ 0.8182114 ]]
--- 0.25136709213256836 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5220.568359375, (2966.1934, 2.728176, 2079.1628, 2.5319228)
   validation loss 1905.644775390625, (1361.9065, 0.049673308, 371.20425, 2.5319228)
decoder loss ratio: 52762.621957, decoder SINDy loss  ratio: 0.801297
--- 0.31487488746643066 seconds for one epoch ---
--- 0.49608397483825684 seconds for one epoch ---
--- 0.2980082035064697 seconds for one epoch ---
--- 0.4855058193206787 seconds for one epoch ---
--- 0.3135502338409424 seconds for one epoch ---
--- 0.492142915725708 seconds for one epoch ---
--- 0.3120701313018799 seconds for one epoch ---
--- 0.5189900398254395 seconds for one epoch ---
--- 0.29726076126098633 seconds for one epoch ---
--- 0.48088836669921875 seconds for one epoch ---
--- 0.2870917320251465 seconds for one epoch ---
--- 0.4938509464263916 seconds for one epoch ---
--- 0.2959709167480469 seconds for one epoch ---
--- 0.5162186622619629 seconds for one epoch ---
--- 0.2967488765716553 seconds for one epoch ---
--- 0.5093774795532227 seconds for one epoch ---
--- 0.29233789443969727 seconds for one epoch ---
--- 0.49928998947143555 seconds for one epoch ---
--- 0.30838537216186523 seconds for one epoch ---
--- 0.4771919250488281 seconds for one epoch ---
--- 0.3053724765777588 seconds for one epoch ---
--- 0.5232927799224854 seconds for one epoch ---
--- 0.3265342712402344 seconds for one epoch ---
--- 0.4878549575805664 seconds for one epoch ---
=========================
[[0.19228551]
 [0.03718736]
 [0.7051077 ]
 [0.02667726]
 [0.02292538]
 [0.99411047]
 [0.02415943]
 [0.02854313]
 [0.02212914]
 [0.94593394]
 [0.09018719]]
[[-1.15109980e+00]
 [-4.37613130e-01]
 [ 1.87737167e+00]
 [ 2.05880627e-01]
 [-4.85891998e-02]
 [-3.19682384e+00]
 [ 1.09697685e-01]
 [ 2.61695623e-01]
 [-1.46650581e-03]
 [-2.49249935e+00]
 [ 8.48738015e-01]]
--- 0.30550670623779297 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4832.984375, (2057.0586, 0.44116098, 2599.7542, 2.5319345)
   validation loss 1370.92578125, (819.6715, 0.047724403, 375.47577, 2.5319345)
decoder loss ratio: 31755.497263, decoder SINDy loss  ratio: 0.810517
--- 0.2583656311035156 seconds for one epoch ---
--- 0.3096895217895508 seconds for one epoch ---
--- 0.4970712661743164 seconds for one epoch ---
--- 0.29875731468200684 seconds for one epoch ---
--- 0.5041627883911133 seconds for one epoch ---
--- 0.29625797271728516 seconds for one epoch ---
--- 0.5458660125732422 seconds for one epoch ---
--- 0.3033585548400879 seconds for one epoch ---
--- 0.5049631595611572 seconds for one epoch ---
--- 0.29309916496276855 seconds for one epoch ---
--- 0.4994642734527588 seconds for one epoch ---
--- 0.29212212562561035 seconds for one epoch ---
--- 0.5066840648651123 seconds for one epoch ---
--- 0.30266833305358887 seconds for one epoch ---
--- 0.5214815139770508 seconds for one epoch ---
--- 0.2939138412475586 seconds for one epoch ---
--- 0.5125155448913574 seconds for one epoch ---
--- 0.29596781730651855 seconds for one epoch ---
--- 0.503380537033081 seconds for one epoch ---
--- 0.2997007369995117 seconds for one epoch ---
--- 0.517359733581543 seconds for one epoch ---
--- 0.30049562454223633 seconds for one epoch ---
--- 0.5004780292510986 seconds for one epoch ---
--- 0.3076286315917969 seconds for one epoch ---
=========================
[[0.22205496]
 [0.03635319]
 [0.73804075]
 [0.02343245]
 [0.01968795]
 [0.99226713]
 [0.02151232]
 [0.02499458]
 [0.01894129]
 [0.9634142 ]
 [0.0906093 ]]
[[-1.2151805 ]
 [-0.47227097]
 [ 1.9294758 ]
 [ 0.20538068]
 [-0.04883909]
 [-3.112381  ]
 [ 0.13504371]
 [ 0.25269723]
 [-0.00506822]
 [-2.6202059 ]
 [ 0.86384225]]
--- 0.2626667022705078 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3688.476806640625, (1787.6132, 0.7337525, 1721.7283, 2.5319412)
   validation loss 2107.875244140625, (1490.0262, 0.06044525, 439.38684, 2.5319412)
decoder loss ratio: 57726.203535, decoder SINDy loss  ratio: 0.948478
--- 0.29607653617858887 seconds for one epoch ---
--- 0.5289380550384521 seconds for one epoch ---
--- 0.297382116317749 seconds for one epoch ---
--- 0.5205116271972656 seconds for one epoch ---
--- 0.298565149307251 seconds for one epoch ---
--- 0.5106995105743408 seconds for one epoch ---
--- 0.2967851161956787 seconds for one epoch ---
--- 0.5068254470825195 seconds for one epoch ---
--- 0.2990443706512451 seconds for one epoch ---
--- 0.5052976608276367 seconds for one epoch ---
--- 0.32222461700439453 seconds for one epoch ---
--- 0.5299694538116455 seconds for one epoch ---
--- 0.3138120174407959 seconds for one epoch ---
--- 0.5122401714324951 seconds for one epoch ---
--- 0.31466174125671387 seconds for one epoch ---
--- 0.544952392578125 seconds for one epoch ---
--- 0.33034563064575195 seconds for one epoch ---
--- 0.5231409072875977 seconds for one epoch ---
--- 0.33089280128479004 seconds for one epoch ---
--- 0.5356996059417725 seconds for one epoch ---
--- 0.295457124710083 seconds for one epoch ---
--- 0.5095500946044922 seconds for one epoch ---
--- 0.29910874366760254 seconds for one epoch ---
--- 0.5153703689575195 seconds for one epoch ---
=========================
[[0.25842792]
 [0.03582478]
 [0.75827855]
 [0.02098185]
 [0.01728408]
 [0.989877  ]
 [0.01887101]
 [0.02276879]
 [0.01647001]
 [0.9757681 ]
 [0.1006184 ]]
[[-1.2818931e+00]
 [-4.9700248e-01]
 [ 1.9636470e+00]
 [ 2.0419253e-01]
 [-4.9909424e-02]
 [-3.0284901e+00]
 [ 1.2577631e-01]
 [ 2.5782627e-01]
 [-2.1692244e-03]
 [-2.7527115e+00]
 [ 9.1293567e-01]]
--- 0.297562837600708 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6386.72900390625, (2345.7454, 0.52017033, 3859.2698, 2.5319483)
   validation loss 1725.445556640625, (1169.9318, 0.047574572, 374.2721, 2.5319483)
decoder loss ratio: 45325.187578, decoder SINDy loss  ratio: 0.807919
THRESHOLDING: 5 active coefficients
--- 0.51529860496521 seconds for one epoch ---
--- 0.299422025680542 seconds for one epoch ---
--- 0.5260934829711914 seconds for one epoch ---
--- 0.3069331645965576 seconds for one epoch ---
--- 0.5324957370758057 seconds for one epoch ---
--- 0.3075437545776367 seconds for one epoch ---
--- 0.5272939205169678 seconds for one epoch ---
--- 0.3136727809906006 seconds for one epoch ---
--- 0.5155160427093506 seconds for one epoch ---
--- 0.3283076286315918 seconds for one epoch ---
--- 0.5280425548553467 seconds for one epoch ---
--- 0.3338453769683838 seconds for one epoch ---
--- 0.5230758190155029 seconds for one epoch ---
--- 0.3243529796600342 seconds for one epoch ---
--- 0.5171303749084473 seconds for one epoch ---
--- 0.30837225914001465 seconds for one epoch ---
--- 0.5397930145263672 seconds for one epoch ---
--- 0.3067595958709717 seconds for one epoch ---
--- 0.5537114143371582 seconds for one epoch ---
--- 0.2961115837097168 seconds for one epoch ---
--- 0.5226848125457764 seconds for one epoch ---
--- 0.29421496391296387 seconds for one epoch ---
--- 0.5268793106079102 seconds for one epoch ---
--- 0.31804394721984863 seconds for one epoch ---
=========================
[[0.04903927]
 [0.        ]
 [0.68323237]
 [0.        ]
 [0.        ]
 [0.81152314]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9286008 ]
 [0.11033947]]
[[-0.65010184]
 [-0.        ]
 [ 1.8490855 ]
 [ 0.        ]
 [-0.        ]
 [-2.062141  ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.4033713 ]
 [ 0.9542469 ]]
--- 0.25831127166748047 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4869.40283203125, (1715.343, 0.6530753, 3152.641, 0.76560974)
   validation loss 2135.012939453125, (1725.104, 0.08069658, 409.06253, 0.76560974)
decoder loss ratio: 66833.524024, decoder SINDy loss  ratio: 0.883019
--- 0.3153502941131592 seconds for one epoch ---
--- 0.5256152153015137 seconds for one epoch ---
--- 0.3163914680480957 seconds for one epoch ---
--- 0.5368251800537109 seconds for one epoch ---
--- 0.3159675598144531 seconds for one epoch ---
--- 0.5419321060180664 seconds for one epoch ---
--- 0.3077967166900635 seconds for one epoch ---
--- 0.5628359317779541 seconds for one epoch ---
--- 0.30927157402038574 seconds for one epoch ---
--- 0.5060837268829346 seconds for one epoch ---
--- 0.3066904544830322 seconds for one epoch ---
--- 0.5459456443786621 seconds for one epoch ---
--- 0.30076169967651367 seconds for one epoch ---
--- 0.5297064781188965 seconds for one epoch ---
--- 0.29569149017333984 seconds for one epoch ---
--- 0.56058669090271 seconds for one epoch ---
--- 0.28843164443969727 seconds for one epoch ---
--- 0.5164079666137695 seconds for one epoch ---
--- 0.3070197105407715 seconds for one epoch ---
--- 0.5148086547851562 seconds for one epoch ---
--- 0.30666375160217285 seconds for one epoch ---
--- 0.5623712539672852 seconds for one epoch ---
--- 0.2876455783843994 seconds for one epoch ---
--- 0.530799150466919 seconds for one epoch ---
=========================
[[0.02689854]
 [0.        ]
 [0.56954944]
 [0.        ]
 [0.        ]
 [0.5458248 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9051011 ]
 [0.11437288]]
[[-0.4213907 ]
 [-0.        ]
 [ 1.6993103 ]
 [ 0.        ]
 [-0.        ]
 [-1.6696669 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.3080873 ]
 [ 0.97216934]]
--- 0.2956216335296631 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3297.021728515625, (1938.9993, 0.9628989, 1356.3735, 0.68603605)
   validation loss 1654.3270263671875, (1302.4004, 0.06231294, 351.17838, 0.68603605)
decoder loss ratio: 50457.252199, decoder SINDy loss  ratio: 0.758068
--- 0.2706747055053711 seconds for one epoch ---
--- 0.285599946975708 seconds for one epoch ---
--- 0.5327112674713135 seconds for one epoch ---
--- 0.28691792488098145 seconds for one epoch ---
--- 0.5337638854980469 seconds for one epoch ---
--- 0.29892539978027344 seconds for one epoch ---
--- 0.5371923446655273 seconds for one epoch ---
--- 0.2956843376159668 seconds for one epoch ---
--- 0.5523903369903564 seconds for one epoch ---
--- 0.30877089500427246 seconds for one epoch ---
--- 0.5633533000946045 seconds for one epoch ---
--- 0.31430935859680176 seconds for one epoch ---
--- 0.5388259887695312 seconds for one epoch ---
--- 0.32289838790893555 seconds for one epoch ---
--- 0.5727875232696533 seconds for one epoch ---
--- 0.32136034965515137 seconds for one epoch ---
--- 0.5456621646881104 seconds for one epoch ---
--- 0.3063011169433594 seconds for one epoch ---
--- 0.5407900810241699 seconds for one epoch ---
--- 0.2993347644805908 seconds for one epoch ---
--- 0.5369303226470947 seconds for one epoch ---
--- 0.2937953472137451 seconds for one epoch ---
--- 0.5212001800537109 seconds for one epoch ---
--- 0.30055856704711914 seconds for one epoch ---
=========================
[[0.02154282]
 [0.        ]
 [0.4497398 ]
 [0.        ]
 [0.        ]
 [0.40818062]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9024006 ]
 [0.12791546]]
[[-0.34959716]
 [-0.        ]
 [ 1.5517416 ]
 [ 0.        ]
 [-0.        ]
 [-1.4994018 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.2989936 ]
 [ 1.0168079 ]]
--- 0.27660107612609863 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3904.20654296875, (2442.0815, 0.6578527, 1460.8287, 0.6381203)
   validation loss 2000.0008544921875, (1710.8892, 0.09884455, 288.37476, 0.6381203)
decoder loss ratio: 66282.816299, decoder SINDy loss  ratio: 0.622497
--- 0.314589262008667 seconds for one epoch ---
--- 0.5623137950897217 seconds for one epoch ---
--- 0.32083988189697266 seconds for one epoch ---
--- 0.5812053680419922 seconds for one epoch ---
--- 0.32962632179260254 seconds for one epoch ---
--- 0.5759372711181641 seconds for one epoch ---
--- 0.31914758682250977 seconds for one epoch ---
--- 0.5680012702941895 seconds for one epoch ---
--- 0.32225680351257324 seconds for one epoch ---
--- 0.5579783916473389 seconds for one epoch ---
--- 0.3045947551727295 seconds for one epoch ---
--- 0.5634090900421143 seconds for one epoch ---
--- 0.3291010856628418 seconds for one epoch ---
--- 0.5588951110839844 seconds for one epoch ---
--- 0.3180553913116455 seconds for one epoch ---
--- 0.5595970153808594 seconds for one epoch ---
--- 0.3052361011505127 seconds for one epoch ---
--- 0.5893349647521973 seconds for one epoch ---
--- 0.29661107063293457 seconds for one epoch ---
--- 0.5667088031768799 seconds for one epoch ---
--- 0.29766345024108887 seconds for one epoch ---
--- 0.5279548168182373 seconds for one epoch ---
--- 0.2769443988800049 seconds for one epoch ---
--- 0.570920467376709 seconds for one epoch ---
=========================
[[0.02062903]
 [0.        ]
 [0.29151204]
 [0.        ]
 [0.        ]
 [0.32965338]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91598505]
 [0.12686329]]
[[-0.3525487]
 [-0.       ]
 [ 1.3409008]
 [ 0.       ]
 [-0.       ]
 [-1.395957 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3502557]
 [ 1.0165006]]
--- 0.30519819259643555 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3566.58349609375, (1920.7562, 0.66885865, 1644.5616, 0.5966503)
   validation loss 1935.8204345703125, (1554.4124, 0.057241425, 380.75415, 0.5966503)
decoder loss ratio: 60220.633154, decoder SINDy loss  ratio: 0.821911
--- 0.2651078701019287 seconds for one epoch ---
--- 0.31070828437805176 seconds for one epoch ---
--- 0.5558898448944092 seconds for one epoch ---
--- 0.3162195682525635 seconds for one epoch ---
--- 0.5503325462341309 seconds for one epoch ---
--- 0.30569887161254883 seconds for one epoch ---
--- 0.5665736198425293 seconds for one epoch ---
--- 0.2975344657897949 seconds for one epoch ---
--- 0.5583477020263672 seconds for one epoch ---
--- 0.31209564208984375 seconds for one epoch ---
--- 0.5663747787475586 seconds for one epoch ---
--- 0.3015866279602051 seconds for one epoch ---
--- 0.5749964714050293 seconds for one epoch ---
--- 0.30141520500183105 seconds for one epoch ---
--- 0.5808546543121338 seconds for one epoch ---
--- 0.30569005012512207 seconds for one epoch ---
--- 0.5672588348388672 seconds for one epoch ---
--- 0.3110237121582031 seconds for one epoch ---
--- 0.5564987659454346 seconds for one epoch ---
--- 0.28571224212646484 seconds for one epoch ---
--- 0.5905210971832275 seconds for one epoch ---
--- 0.2751193046569824 seconds for one epoch ---
--- 0.5868566036224365 seconds for one epoch ---
--- 0.295196533203125 seconds for one epoch ---
=========================
[[0.02141364]
 [0.        ]
 [0.21998122]
 [0.        ]
 [0.        ]
 [0.28593105]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9330259 ]
 [0.16468324]]
[[-0.38552862]
 [-0.        ]
 [ 1.225267  ]
 [ 0.        ]
 [-0.        ]
 [-1.3335384 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.4263134 ]
 [ 1.1141889 ]]
--- 0.24849414825439453 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4557.767578125, (2470.9639, 0.37566853, 2085.8418, 0.5860542)
   validation loss 2704.955078125, (2324.0215, 0.11644923, 380.2313, 0.5860542)
decoder loss ratio: 90036.626983, decoder SINDy loss  ratio: 0.820783
--- 0.32128071784973145 seconds for one epoch ---
--- 0.583270788192749 seconds for one epoch ---
--- 0.4610025882720947 seconds for one epoch ---
--- 0.5683412551879883 seconds for one epoch ---
--- 0.30016064643859863 seconds for one epoch ---
--- 0.5752828121185303 seconds for one epoch ---
--- 0.32169008255004883 seconds for one epoch ---
--- 0.5716981887817383 seconds for one epoch ---
--- 0.2982203960418701 seconds for one epoch ---
--- 0.603736162185669 seconds for one epoch ---
--- 0.3047311305999756 seconds for one epoch ---
--- 0.5853118896484375 seconds for one epoch ---
--- 0.3047630786895752 seconds for one epoch ---
--- 0.5967776775360107 seconds for one epoch ---
--- 0.29868364334106445 seconds for one epoch ---
--- 0.5686531066894531 seconds for one epoch ---
--- 0.28939223289489746 seconds for one epoch ---
--- 0.5885863304138184 seconds for one epoch ---
--- 0.3061363697052002 seconds for one epoch ---
--- 0.5924527645111084 seconds for one epoch ---
--- 0.28751397132873535 seconds for one epoch ---
--- 0.6157124042510986 seconds for one epoch ---
--- 0.2954137325286865 seconds for one epoch ---
--- 0.6100261211395264 seconds for one epoch ---
=========================
[[0.02420046]
 [0.        ]
 [0.14906603]
 [0.        ]
 [0.        ]
 [0.28519222]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9446564 ]
 [0.16593574]]
[[-0.44329637]
 [-0.        ]
 [ 1.0788912 ]
 [ 0.        ]
 [-0.        ]
 [-1.3332075 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.489362  ]
 [ 1.1183759 ]]
--- 0.28685855865478516 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6412.8486328125, (2340.1094, 1.2840292, 4070.8792, 0.5762014)
   validation loss 1784.64697265625, (1389.2063, 0.101620145, 394.763, 0.5762014)
decoder loss ratio: 53820.263785, decoder SINDy loss  ratio: 0.852151
--- 0.2723660469055176 seconds for one epoch ---
--- 0.31728196144104004 seconds for one epoch ---
--- 0.5801262855529785 seconds for one epoch ---
--- 0.31186437606811523 seconds for one epoch ---
--- 0.5921943187713623 seconds for one epoch ---
--- 0.3232700824737549 seconds for one epoch ---
--- 0.6048917770385742 seconds for one epoch ---
--- 0.306821346282959 seconds for one epoch ---
--- 0.5847809314727783 seconds for one epoch ---
--- 0.2889833450317383 seconds for one epoch ---
--- 0.605654239654541 seconds for one epoch ---
--- 0.3051109313964844 seconds for one epoch ---
--- 0.5991456508636475 seconds for one epoch ---
--- 0.29829931259155273 seconds for one epoch ---
--- 0.5907487869262695 seconds for one epoch ---
--- 0.2956087589263916 seconds for one epoch ---
--- 0.5832645893096924 seconds for one epoch ---
--- 0.2929096221923828 seconds for one epoch ---
--- 0.6230263710021973 seconds for one epoch ---
--- 0.30519652366638184 seconds for one epoch ---
--- 0.6037213802337646 seconds for one epoch ---
--- 0.2992830276489258 seconds for one epoch ---
--- 0.6274566650390625 seconds for one epoch ---
--- 0.3173387050628662 seconds for one epoch ---
=========================
[[0.02545047]
 [0.        ]
 [0.12122872]
 [0.        ]
 [0.        ]
 [0.25062078]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9529901 ]
 [0.20120907]]
[[-0.47048527]
 [-0.        ]
 [ 1.006159  ]
 [ 0.        ]
 [-0.        ]
 [-1.2796602 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.5427866 ]
 [ 1.1923952 ]]
--- 0.2552824020385742 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3038.044677734375, (1499.8754, 0.5632776, 1537.0353, 0.5708418)
   validation loss 1174.983154296875, (803.5553, 0.063512, 370.79355, 0.5708418)
decoder loss ratio: 31131.127272, decoder SINDy loss  ratio: 0.800410
--- 0.2973053455352783 seconds for one epoch ---
--- 0.5980606079101562 seconds for one epoch ---
--- 0.308746337890625 seconds for one epoch ---
--- 0.6149113178253174 seconds for one epoch ---
--- 0.3115081787109375 seconds for one epoch ---
--- 0.60329270362854 seconds for one epoch ---
--- 0.3234696388244629 seconds for one epoch ---
--- 0.607154369354248 seconds for one epoch ---
--- 0.3096494674682617 seconds for one epoch ---
--- 0.613609790802002 seconds for one epoch ---
--- 0.3217906951904297 seconds for one epoch ---
--- 0.6044735908508301 seconds for one epoch ---
--- 0.29699134826660156 seconds for one epoch ---
--- 0.6170074939727783 seconds for one epoch ---
--- 0.29192614555358887 seconds for one epoch ---
--- 0.6079578399658203 seconds for one epoch ---
--- 0.2923297882080078 seconds for one epoch ---
--- 0.6164782047271729 seconds for one epoch ---
--- 0.28743410110473633 seconds for one epoch ---
--- 0.621502161026001 seconds for one epoch ---
--- 0.26453137397766113 seconds for one epoch ---
--- 0.6669797897338867 seconds for one epoch ---
--- 0.30153703689575195 seconds for one epoch ---
--- 0.6202459335327148 seconds for one epoch ---
=========================
[[0.02931483]
 [0.        ]
 [0.0923119 ]
 [0.        ]
 [0.        ]
 [0.24527742]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9620361 ]
 [0.20212176]]
[[-0.52552086]
 [-0.        ]
 [ 0.912765  ]
 [ 0.        ]
 [-0.        ]
 [-1.2714651 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6120431 ]
 [ 1.1948951 ]]
--- 0.2897512912750244 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1990.673095703125, (1387.8638, 0.28438336, 601.9602, 0.56472486)
   validation loss 1111.385009765625, (761.75977, 0.08501629, 348.97546, 0.56472486)
decoder loss ratio: 29511.895793, decoder SINDy loss  ratio: 0.753313
--- 0.25596189498901367 seconds for one epoch ---
--- 0.29354071617126465 seconds for one epoch ---
--- 0.6120238304138184 seconds for one epoch ---
--- 0.2834346294403076 seconds for one epoch ---
--- 0.5961604118347168 seconds for one epoch ---
--- 0.3021676540374756 seconds for one epoch ---
--- 0.6208031177520752 seconds for one epoch ---
--- 0.30541014671325684 seconds for one epoch ---
--- 0.606806755065918 seconds for one epoch ---
--- 0.31235766410827637 seconds for one epoch ---
--- 0.6229972839355469 seconds for one epoch ---
--- 0.2902228832244873 seconds for one epoch ---
--- 0.6270287036895752 seconds for one epoch ---
--- 0.29305052757263184 seconds for one epoch ---
--- 0.6459541320800781 seconds for one epoch ---
--- 0.29366230964660645 seconds for one epoch ---
--- 0.6084380149841309 seconds for one epoch ---
--- 0.2915618419647217 seconds for one epoch ---
--- 0.6355698108673096 seconds for one epoch ---
--- 0.2963278293609619 seconds for one epoch ---
--- 0.6203951835632324 seconds for one epoch ---
--- 0.3049352169036865 seconds for one epoch ---
--- 0.6422631740570068 seconds for one epoch ---
--- 0.2960071563720703 seconds for one epoch ---
=========================
[[0.03179237]
 [0.        ]
 [0.07391726]
 [0.        ]
 [0.        ]
 [0.21290347]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9692969 ]
 [0.17860611]]
[[-0.55766004]
 [-0.        ]
 [ 0.8389463 ]
 [ 0.        ]
 [-0.        ]
 [-1.2156994 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.6802893 ]
 [ 1.1486531 ]]
--- 0.26592445373535156 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3020.529296875, (1538.0459, 0.8089217, 1481.1249, 0.54963917)
   validation loss 1259.8824462890625, (962.4075, 0.092316195, 296.83292, 0.54963917)
decoder loss ratio: 37285.336228, decoder SINDy loss  ratio: 0.640756
--- 0.2969534397125244 seconds for one epoch ---
--- 0.6202898025512695 seconds for one epoch ---
--- 0.29195094108581543 seconds for one epoch ---
--- 0.6031780242919922 seconds for one epoch ---
--- 0.2872793674468994 seconds for one epoch ---
--- 0.6200289726257324 seconds for one epoch ---
--- 0.2889101505279541 seconds for one epoch ---
--- 0.6122021675109863 seconds for one epoch ---
--- 0.28524041175842285 seconds for one epoch ---
--- 0.6331701278686523 seconds for one epoch ---
--- 0.289048433303833 seconds for one epoch ---
--- 0.6172008514404297 seconds for one epoch ---
--- 0.29421401023864746 seconds for one epoch ---
--- 0.6293106079101562 seconds for one epoch ---
--- 0.3030083179473877 seconds for one epoch ---
--- 0.6360030174255371 seconds for one epoch ---
--- 0.30895423889160156 seconds for one epoch ---
--- 0.635939359664917 seconds for one epoch ---
--- 0.3108694553375244 seconds for one epoch ---
--- 0.6615035533905029 seconds for one epoch ---
--- 0.3072512149810791 seconds for one epoch ---
--- 0.6722047328948975 seconds for one epoch ---
--- 0.32511210441589355 seconds for one epoch ---
--- 0.6460292339324951 seconds for one epoch ---
=========================
[[0.0372135 ]
 [0.        ]
 [0.06419785]
 [0.        ]
 [0.        ]
 [0.20024359]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97611797]
 [0.1623418 ]]
[[-0.6130885]
 [-0.       ]
 [ 0.7933074]
 [ 0.       ]
 [-0.       ]
 [-1.1924995]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7604945]
 [ 1.1139127]]
--- 0.3120238780975342 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5866.20751953125, (1749.4264, 2.2894695, 4113.9497, 0.5418214)
   validation loss 1732.373779296875, (1350.4272, 0.11088995, 381.29382, 0.5418214)
decoder loss ratio: 52317.895958, decoder SINDy loss  ratio: 0.823076
--- 0.25618720054626465 seconds for one epoch ---
--- 0.3301105499267578 seconds for one epoch ---
--- 0.619483232498169 seconds for one epoch ---
--- 0.30501556396484375 seconds for one epoch ---
--- 0.616713285446167 seconds for one epoch ---
--- 0.2929997444152832 seconds for one epoch ---
--- 0.6301660537719727 seconds for one epoch ---
--- 0.29357194900512695 seconds for one epoch ---
--- 0.6206815242767334 seconds for one epoch ---
--- 0.28911685943603516 seconds for one epoch ---
--- 0.6495406627655029 seconds for one epoch ---
--- 0.31404829025268555 seconds for one epoch ---
--- 0.6675679683685303 seconds for one epoch ---
--- 0.3128938674926758 seconds for one epoch ---
--- 0.6523687839508057 seconds for one epoch ---
--- 0.3135867118835449 seconds for one epoch ---
--- 0.6479024887084961 seconds for one epoch ---
--- 0.3116421699523926 seconds for one epoch ---
--- 0.6684181690216064 seconds for one epoch ---
--- 0.3137495517730713 seconds for one epoch ---
--- 0.6564056873321533 seconds for one epoch ---
--- 0.31009459495544434 seconds for one epoch ---
--- 0.6422581672668457 seconds for one epoch ---
--- 0.3340322971343994 seconds for one epoch ---
=========================
[[0.04532487]
 [0.        ]
 [0.05467369]
 [0.        ]
 [0.        ]
 [0.20582604]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9807275 ]
 [0.14954907]]
[[-0.68021715]
 [-0.        ]
 [ 0.74177617]
 [ 0.        ]
 [-0.        ]
 [-1.2035328 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.8286216 ]
 [ 1.084676  ]]
--- 0.253387451171875 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4895.58447265625, (3586.7595, 1.7460246, 1306.5382, 0.5403658)
   validation loss 1542.792236328125, (1108.3789, 0.100486495, 433.7725, 0.5403658)
decoder loss ratio: 42940.523059, decoder SINDy loss  ratio: 0.936359
--- 0.3220798969268799 seconds for one epoch ---
--- 0.6589450836181641 seconds for one epoch ---
--- 0.3225891590118408 seconds for one epoch ---
--- 0.6466026306152344 seconds for one epoch ---
--- 0.29979801177978516 seconds for one epoch ---
--- 0.6470222473144531 seconds for one epoch ---
--- 0.2866232395172119 seconds for one epoch ---
--- 0.6373398303985596 seconds for one epoch ---
--- 0.28603339195251465 seconds for one epoch ---
--- 0.6407744884490967 seconds for one epoch ---
--- 0.2911229133605957 seconds for one epoch ---
--- 0.6283175945281982 seconds for one epoch ---
--- 0.2994861602783203 seconds for one epoch ---
--- 0.6560883522033691 seconds for one epoch ---
--- 0.3133430480957031 seconds for one epoch ---
--- 0.6646425724029541 seconds for one epoch ---
--- 0.31222105026245117 seconds for one epoch ---
--- 0.6445882320404053 seconds for one epoch ---
--- 0.3106708526611328 seconds for one epoch ---
--- 0.6485762596130371 seconds for one epoch ---
--- 0.31520509719848633 seconds for one epoch ---
--- 0.6647379398345947 seconds for one epoch ---
--- 0.2888925075531006 seconds for one epoch ---
--- 0.6873900890350342 seconds for one epoch ---
=========================
[[0.04844577]
 [0.        ]
 [0.0491353 ]
 [0.        ]
 [0.        ]
 [0.18208955]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98300946]
 [0.12211157]]
[[-0.7035521]
 [-0.       ]
 [ 0.708167 ]
 [ 0.       ]
 [-0.       ]
 [-1.1573739]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8685653]
 [ 1.0133151]]
--- 0.29947972297668457 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4425.52294921875, (2245.6318, 0.5337716, 2178.8308, 0.52669734)
   validation loss 1366.0419921875, (1023.15924, 0.12403463, 342.23203, 0.52669734)
decoder loss ratio: 39638.965268, decoder SINDy loss  ratio: 0.738756
--- 0.2600581645965576 seconds for one epoch ---
--- 0.32820630073547363 seconds for one epoch ---
--- 0.676461935043335 seconds for one epoch ---
--- 0.3202073574066162 seconds for one epoch ---
--- 0.6736156940460205 seconds for one epoch ---
--- 0.3051338195800781 seconds for one epoch ---
--- 0.6547319889068604 seconds for one epoch ---
--- 0.29592204093933105 seconds for one epoch ---
--- 0.6781129837036133 seconds for one epoch ---
--- 0.2890815734863281 seconds for one epoch ---
--- 0.6643638610839844 seconds for one epoch ---
--- 0.2860603332519531 seconds for one epoch ---
--- 0.6788396835327148 seconds for one epoch ---
--- 0.282623291015625 seconds for one epoch ---
--- 0.6775729656219482 seconds for one epoch ---
--- 0.3097560405731201 seconds for one epoch ---
--- 0.6993141174316406 seconds for one epoch ---
--- 0.3226187229156494 seconds for one epoch ---
--- 0.6619117259979248 seconds for one epoch ---
--- 0.3259005546569824 seconds for one epoch ---
--- 0.692143440246582 seconds for one epoch ---
--- 0.3185155391693115 seconds for one epoch ---
--- 0.6582694053649902 seconds for one epoch ---
--- 0.2916862964630127 seconds for one epoch ---
=========================
[[0.05762256]
 [0.        ]
 [0.04143753]
 [0.        ]
 [0.        ]
 [0.18599036]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98533684]
 [0.12644936]]
[[-0.7614773 ]
 [-0.        ]
 [ 0.65421855]
 [ 0.        ]
 [-0.        ]
 [-1.1656727 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.9151535 ]
 [ 1.0260489 ]]
--- 0.256213903427124 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6514.7958984375, (2200.977, 1.2620265, 4312.0234, 0.53336364)
   validation loss 1497.1519775390625, (1194.5605, 0.08813036, 301.96994, 0.53336364)
decoder loss ratio: 46279.349434, decoder SINDy loss  ratio: 0.651845
--- 0.3188614845275879 seconds for one epoch ---
--- 0.6748471260070801 seconds for one epoch ---
--- 0.32300567626953125 seconds for one epoch ---
--- 0.6780886650085449 seconds for one epoch ---
--- 0.31069397926330566 seconds for one epoch ---
--- 0.6781971454620361 seconds for one epoch ---
--- 0.31923437118530273 seconds for one epoch ---
--- 0.6660511493682861 seconds for one epoch ---
--- 0.30208802223205566 seconds for one epoch ---
--- 0.7052819728851318 seconds for one epoch ---
--- 0.2939639091491699 seconds for one epoch ---
--- 0.6569585800170898 seconds for one epoch ---
--- 0.2966597080230713 seconds for one epoch ---
--- 0.6876199245452881 seconds for one epoch ---
--- 0.2904214859008789 seconds for one epoch ---
--- 0.6496627330780029 seconds for one epoch ---
--- 0.2658238410949707 seconds for one epoch ---
--- 0.6726665496826172 seconds for one epoch ---
--- 0.32009124755859375 seconds for one epoch ---
--- 0.6706151962280273 seconds for one epoch ---
--- 0.3024466037750244 seconds for one epoch ---
--- 0.6771049499511719 seconds for one epoch ---
--- 0.3050973415374756 seconds for one epoch ---
--- 0.68747878074646 seconds for one epoch ---
=========================
[[0.069327  ]
 [0.        ]
 [0.03856297]
 [0.        ]
 [0.        ]
 [0.17742682]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98830146]
 [0.11990511]]
[[-0.82300293]
 [-0.        ]
 [ 0.6322697 ]
 [ 0.        ]
 [-0.        ]
 [-1.1483418 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-2.986394  ]
 [ 1.0079132 ]]
--- 0.3135848045349121 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3677.354736328125, (1687.0958, 0.86506075, 1988.8641, 0.52966046)
   validation loss 1680.3499755859375, (1306.1261, 0.05738022, 373.63684, 0.52966046)
decoder loss ratio: 50601.592596, decoder SINDy loss  ratio: 0.806548
--- 0.24541807174682617 seconds for one epoch ---
--- 0.3350095748901367 seconds for one epoch ---
--- 0.6865134239196777 seconds for one epoch ---
--- 0.31836485862731934 seconds for one epoch ---
--- 0.6847620010375977 seconds for one epoch ---
--- 0.32590460777282715 seconds for one epoch ---
--- 0.680084228515625 seconds for one epoch ---
--- 0.296083927154541 seconds for one epoch ---
--- 0.6787281036376953 seconds for one epoch ---
--- 0.2960031032562256 seconds for one epoch ---
--- 0.683293342590332 seconds for one epoch ---
--- 0.2871732711791992 seconds for one epoch ---
--- 0.6979532241821289 seconds for one epoch ---
--- 0.2928931713104248 seconds for one epoch ---
--- 0.6751337051391602 seconds for one epoch ---
--- 0.26854443550109863 seconds for one epoch ---
--- 0.6769616603851318 seconds for one epoch ---
--- 0.28962111473083496 seconds for one epoch ---
--- 0.6746940612792969 seconds for one epoch ---
--- 0.296069860458374 seconds for one epoch ---
--- 0.693359375 seconds for one epoch ---
--- 0.30271053314208984 seconds for one epoch ---
--- 0.7210628986358643 seconds for one epoch ---
--- 0.30207061767578125 seconds for one epoch ---
=========================
[[0.0813683 ]
 [0.        ]
 [0.03566605]
 [0.        ]
 [0.        ]
 [0.17666157]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98976374]
 [0.11392111]]
[[-0.87667245]
 [-0.        ]
 [ 0.60842407]
 [ 0.        ]
 [-0.        ]
 [-1.1469938 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0284522 ]
 [ 0.9905818 ]]
--- 0.26584792137145996 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3605.49658203125, (1361.7704, 0.55887115, 2242.636, 0.5312007)
   validation loss 1049.914794921875, (759.1587, 0.07480532, 290.15005, 0.5312007)
decoder loss ratio: 29411.125663, decoder SINDy loss  ratio: 0.626330
--- 0.32335543632507324 seconds for one epoch ---
--- 0.6760916709899902 seconds for one epoch ---
--- 0.31248998641967773 seconds for one epoch ---
--- 0.6985926628112793 seconds for one epoch ---
--- 0.30720949172973633 seconds for one epoch ---
--- 0.6716396808624268 seconds for one epoch ---
--- 0.3109855651855469 seconds for one epoch ---
--- 0.6953780651092529 seconds for one epoch ---
--- 0.31652259826660156 seconds for one epoch ---
--- 0.7058420181274414 seconds for one epoch ---
--- 0.3035109043121338 seconds for one epoch ---
--- 0.688758373260498 seconds for one epoch ---
--- 0.29741477966308594 seconds for one epoch ---
--- 0.7061350345611572 seconds for one epoch ---
--- 0.29301905632019043 seconds for one epoch ---
--- 0.6980788707733154 seconds for one epoch ---
--- 0.2981574535369873 seconds for one epoch ---
--- 0.6930074691772461 seconds for one epoch ---
--- 0.2994065284729004 seconds for one epoch ---
--- 0.7000937461853027 seconds for one epoch ---
--- 0.2949690818786621 seconds for one epoch ---
--- 0.7000808715820312 seconds for one epoch ---
--- 0.33741164207458496 seconds for one epoch ---
--- 0.7166314125061035 seconds for one epoch ---
=========================
[[0.09487443]
 [0.        ]
 [0.0354421 ]
 [0.        ]
 [0.        ]
 [0.16750334]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99143994]
 [0.10100799]]
[[-0.9285401 ]
 [-0.        ]
 [ 0.6074082 ]
 [ 0.        ]
 [-0.        ]
 [-1.1275722 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.0846887 ]
 [ 0.94974566]]
--- 0.3017995357513428 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2986.296142578125, (1510.5017, 0.36125112, 1474.9031, 0.5300983)
   validation loss 1066.955078125, (750.48956, 0.116002046, 315.81934, 0.5300983)
decoder loss ratio: 29075.268577, decoder SINDy loss  ratio: 0.681740
--- 0.2971837520599365 seconds for one epoch ---
--- 0.3147318363189697 seconds for one epoch ---
--- 0.7108471393585205 seconds for one epoch ---
--- 0.3151986598968506 seconds for one epoch ---
--- 0.6909518241882324 seconds for one epoch ---
--- 0.31206297874450684 seconds for one epoch ---
--- 0.7022266387939453 seconds for one epoch ---
--- 0.32034802436828613 seconds for one epoch ---
--- 0.7121670246124268 seconds for one epoch ---
--- 0.333843469619751 seconds for one epoch ---
--- 0.7295801639556885 seconds for one epoch ---
--- 0.3305094242095947 seconds for one epoch ---
--- 0.7135181427001953 seconds for one epoch ---
--- 0.4835014343261719 seconds for one epoch ---
--- 0.7087867259979248 seconds for one epoch ---
--- 0.2995274066925049 seconds for one epoch ---
--- 0.7280447483062744 seconds for one epoch ---
--- 0.3019990921020508 seconds for one epoch ---
--- 0.7075293064117432 seconds for one epoch ---
--- 0.2879478931427002 seconds for one epoch ---
--- 0.70583176612854 seconds for one epoch ---
--- 0.3065488338470459 seconds for one epoch ---
--- 0.7244083881378174 seconds for one epoch ---
--- 0.3115816116333008 seconds for one epoch ---
=========================
[[0.10736685]
 [0.        ]
 [0.03260527]
 [0.        ]
 [0.        ]
 [0.15489541]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.992842  ]
 [0.08732402]]
[[-0.97085047]
 [-0.        ]
 [ 0.5817829 ]
 [ 0.        ]
 [-0.        ]
 [-1.0993125 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.1409252 ]
 [ 0.901041  ]]
--- 0.25061607360839844 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2816.394287109375, (1041.1298, 0.46656153, 1774.2738, 0.5240509)
   validation loss 1226.2659912109375, (890.54205, 0.13629888, 335.06354, 0.5240509)
decoder loss ratio: 34501.145191, decoder SINDy loss  ratio: 0.723282
--- 0.2868618965148926 seconds for one epoch ---
--- 0.7270846366882324 seconds for one epoch ---
--- 0.2961149215698242 seconds for one epoch ---
--- 0.7084822654724121 seconds for one epoch ---
--- 0.3096940517425537 seconds for one epoch ---
--- 0.7121462821960449 seconds for one epoch ---
--- 0.28491997718811035 seconds for one epoch ---
--- 0.7107501029968262 seconds for one epoch ---
--- 0.29257702827453613 seconds for one epoch ---
--- 0.7155125141143799 seconds for one epoch ---
--- 0.29115891456604004 seconds for one epoch ---
--- 0.7172837257385254 seconds for one epoch ---
--- 0.2932908535003662 seconds for one epoch ---
--- 0.7355544567108154 seconds for one epoch ---
--- 0.3120560646057129 seconds for one epoch ---
--- 0.7271108627319336 seconds for one epoch ---
--- 0.3138883113861084 seconds for one epoch ---
--- 0.7149062156677246 seconds for one epoch ---
--- 0.3027818202972412 seconds for one epoch ---
--- 0.731243371963501 seconds for one epoch ---
--- 0.30032920837402344 seconds for one epoch ---
--- 0.710862398147583 seconds for one epoch ---
--- 0.30258655548095703 seconds for one epoch ---
--- 0.739142894744873 seconds for one epoch ---
=========================
[[0.11880959]
 [0.        ]
 [0.02875823]
 [0.        ]
 [0.        ]
 [0.14032084]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9940286 ]
 [0.07085591]]
[[-1.0058826]
 [-0.       ]
 [ 0.5428003]
 [ 0.       ]
 [-0.       ]
 [-1.0641377]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.1978467]
 [ 0.8321455]]
--- 0.3086669445037842 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5051.90283203125, (1802.4967, 3.4595706, 3245.4307, 0.5162265)
   validation loss 899.6742553710938, (603.9883, 0.13680106, 295.03296, 0.5162265)
decoder loss ratio: 23399.554585, decoder SINDy loss  ratio: 0.636870
--- 0.2737288475036621 seconds for one epoch ---
--- 0.30417943000793457 seconds for one epoch ---
--- 0.7309541702270508 seconds for one epoch ---
--- 0.31700825691223145 seconds for one epoch ---
--- 0.727902889251709 seconds for one epoch ---
--- 0.31177234649658203 seconds for one epoch ---
--- 0.757922887802124 seconds for one epoch ---
--- 0.3181462287902832 seconds for one epoch ---
--- 0.7238783836364746 seconds for one epoch ---
--- 0.3282592296600342 seconds for one epoch ---
--- 0.7576303482055664 seconds for one epoch ---
--- 0.34018373489379883 seconds for one epoch ---
--- 0.7306482791900635 seconds for one epoch ---
--- 0.336198091506958 seconds for one epoch ---
--- 0.7138588428497314 seconds for one epoch ---
--- 0.3211500644683838 seconds for one epoch ---
--- 0.762397050857544 seconds for one epoch ---
--- 0.31477904319763184 seconds for one epoch ---
--- 0.7392599582672119 seconds for one epoch ---
--- 0.3194451332092285 seconds for one epoch ---
--- 0.7241158485412598 seconds for one epoch ---
--- 0.32102489471435547 seconds for one epoch ---
--- 0.7442445755004883 seconds for one epoch ---
--- 0.30295586585998535 seconds for one epoch ---
=========================
[[0.14516045]
 [0.        ]
 [0.03003198]
 [0.        ]
 [0.        ]
 [0.1362134 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.995528  ]
 [0.07867433]]
[[-1.0763519]
 [-0.       ]
 [ 0.5572747]
 [ 0.       ]
 [-0.       ]
 [-1.0537966]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2885869]
 [ 0.8669347]]
--- 0.24601387977600098 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5787.392578125, (1791.673, 2.0859551, 3993.1062, 0.52729076)
   validation loss 1632.629638671875, (1269.5188, 0.07121994, 362.51227, 0.52729076)
decoder loss ratio: 49183.362248, decoder SINDy loss  ratio: 0.782534
--- 0.29258179664611816 seconds for one epoch ---
--- 0.737567663192749 seconds for one epoch ---
--- 0.28915929794311523 seconds for one epoch ---
--- 0.7372527122497559 seconds for one epoch ---
--- 0.2938804626464844 seconds for one epoch ---
--- 0.7189614772796631 seconds for one epoch ---
--- 0.28367185592651367 seconds for one epoch ---
--- 0.7199740409851074 seconds for one epoch ---
--- 0.30849552154541016 seconds for one epoch ---
--- 0.7382252216339111 seconds for one epoch ---
--- 0.29503655433654785 seconds for one epoch ---
--- 0.7208468914031982 seconds for one epoch ---
--- 0.3020467758178711 seconds for one epoch ---
--- 0.7289695739746094 seconds for one epoch ---
--- 0.3060462474822998 seconds for one epoch ---
--- 0.7614195346832275 seconds for one epoch ---
--- 0.292849063873291 seconds for one epoch ---
--- 0.7390158176422119 seconds for one epoch ---
--- 0.32532620429992676 seconds for one epoch ---
--- 0.7439215183258057 seconds for one epoch ---
--- 0.2868039608001709 seconds for one epoch ---
--- 0.7466762065887451 seconds for one epoch ---
--- 0.31171751022338867 seconds for one epoch ---
--- 0.7668898105621338 seconds for one epoch ---
=========================
[[0.17694703]
 [0.        ]
 [0.03000272]
 [0.        ]
 [0.        ]
 [0.13437532]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9965162 ]
 [0.07076366]]
[[-1.148342  ]
 [-0.        ]
 [ 0.55756253]
 [ 0.        ]
 [-0.        ]
 [-1.0491424 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.366964  ]
 [ 0.832291  ]]
--- 0.2980008125305176 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4389.32861328125, (1644.8575, 1.2668372, 2742.6726, 0.5318486)
   validation loss 1558.0020751953125, (1206.1875, 0.10922579, 351.1735, 0.5318486)
decoder loss ratio: 46729.797784, decoder SINDy loss  ratio: 0.758057
THRESHOLDING: 3 active coefficients
--- 0.7415704727172852 seconds for one epoch ---
--- 0.2949047088623047 seconds for one epoch ---
--- 0.7523362636566162 seconds for one epoch ---
--- 0.2803664207458496 seconds for one epoch ---
--- 0.736731767654419 seconds for one epoch ---
--- 0.3091139793395996 seconds for one epoch ---
--- 0.753201961517334 seconds for one epoch ---
--- 0.33266186714172363 seconds for one epoch ---
--- 0.7479898929595947 seconds for one epoch ---
--- 0.3317098617553711 seconds for one epoch ---
--- 0.7659265995025635 seconds for one epoch ---
--- 0.3171803951263428 seconds for one epoch ---
--- 0.7644143104553223 seconds for one epoch ---
--- 0.31113243103027344 seconds for one epoch ---
--- 0.7423853874206543 seconds for one epoch ---
--- 0.32605457305908203 seconds for one epoch ---
--- 0.7368314266204834 seconds for one epoch ---
--- 0.31694459915161133 seconds for one epoch ---
--- 0.7598190307617188 seconds for one epoch ---
--- 0.30098533630371094 seconds for one epoch ---
--- 0.7403733730316162 seconds for one epoch ---
--- 0.29976439476013184 seconds for one epoch ---
--- 0.7505745887756348 seconds for one epoch ---
--- 0.27481508255004883 seconds for one epoch ---
=========================
[[0.20475748]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.127895  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99724275]
 [0.        ]]
[[-1.2033873]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0319463]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.440374 ]
 [ 0.       ]]
--- 0.23607301712036133 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2713.66748046875, (1960.7999, 1.8899229, 750.5279, 0.44966003)
   validation loss 1074.9510498046875, (763.2031, 0.10376931, 311.19446, 0.44966003)
decoder loss ratio: 29567.814041, decoder SINDy loss  ratio: 0.671757
--- 0.2947711944580078 seconds for one epoch ---
--- 0.7453899383544922 seconds for one epoch ---
--- 0.28910040855407715 seconds for one epoch ---
--- 0.7598607540130615 seconds for one epoch ---
--- 0.28472423553466797 seconds for one epoch ---
--- 0.7864804267883301 seconds for one epoch ---
--- 0.29707908630371094 seconds for one epoch ---
--- 0.7707188129425049 seconds for one epoch ---
--- 0.2863621711730957 seconds for one epoch ---
--- 0.7761831283569336 seconds for one epoch ---
--- 0.2983067035675049 seconds for one epoch ---
--- 0.7882773876190186 seconds for one epoch ---
--- 0.30371856689453125 seconds for one epoch ---
--- 0.7501723766326904 seconds for one epoch ---
--- 0.3248422145843506 seconds for one epoch ---
--- 0.7778804302215576 seconds for one epoch ---
--- 0.3331286907196045 seconds for one epoch ---
--- 0.780249834060669 seconds for one epoch ---
--- 0.32073044776916504 seconds for one epoch ---
--- 0.7714157104492188 seconds for one epoch ---
--- 0.32192492485046387 seconds for one epoch ---
--- 0.7653045654296875 seconds for one epoch ---
--- 0.30749034881591797 seconds for one epoch ---
--- 0.7892379760742188 seconds for one epoch ---
=========================
[[0.2402218 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12065518]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9979273 ]
 [0.        ]]
[[-1.2660435]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0117975]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5300405]
 [ 0.       ]]
--- 0.30262279510498047 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2775.100830078125, (1425.0261, 0.80796856, 1348.8104, 0.45629)
   validation loss 1243.479248046875, (889.2399, 0.20150103, 353.58157, 0.45629)
decoder loss ratio: 34450.698646, decoder SINDy loss  ratio: 0.763256
--- 0.2570626735687256 seconds for one epoch ---
--- 0.30080366134643555 seconds for one epoch ---
--- 0.7675397396087646 seconds for one epoch ---
--- 0.2895989418029785 seconds for one epoch ---
--- 0.7553150653839111 seconds for one epoch ---
--- 0.31255602836608887 seconds for one epoch ---
--- 0.7581498622894287 seconds for one epoch ---
--- 0.3044779300689697 seconds for one epoch ---
--- 0.7671735286712646 seconds for one epoch ---
--- 0.2970733642578125 seconds for one epoch ---
--- 0.7651000022888184 seconds for one epoch ---
--- 0.2987997531890869 seconds for one epoch ---
--- 0.7847628593444824 seconds for one epoch ---
--- 0.29769039154052734 seconds for one epoch ---
--- 0.7885808944702148 seconds for one epoch ---
--- 0.29537487030029297 seconds for one epoch ---
--- 0.7713005542755127 seconds for one epoch ---
--- 0.27333521842956543 seconds for one epoch ---
--- 0.7904398441314697 seconds for one epoch ---
--- 0.2943909168243408 seconds for one epoch ---
--- 0.7886769771575928 seconds for one epoch ---
--- 0.3061802387237549 seconds for one epoch ---
--- 0.7876572608947754 seconds for one epoch ---
--- 0.2913990020751953 seconds for one epoch ---
=========================
[[0.28237373]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12066887]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9983661 ]
 [0.        ]]
[[-1.3328003]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0119345]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.604696 ]
 [ 0.       ]]
--- 0.2600831985473633 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2639.60791015625, (1565.1101, 1.280528, 1072.7534, 0.46384197)
   validation loss 768.10986328125, (501.39594, 0.1371927, 266.11288, 0.46384197)
decoder loss ratio: 19424.948986, decoder SINDy loss  ratio: 0.574442
--- 0.31345343589782715 seconds for one epoch ---
--- 0.7917423248291016 seconds for one epoch ---
--- 0.3312373161315918 seconds for one epoch ---
--- 0.7886388301849365 seconds for one epoch ---
--- 0.3275470733642578 seconds for one epoch ---
--- 0.7866010665893555 seconds for one epoch ---
--- 0.323225736618042 seconds for one epoch ---
--- 0.7883055210113525 seconds for one epoch ---
--- 0.327831506729126 seconds for one epoch ---
--- 0.7857105731964111 seconds for one epoch ---
--- 0.3166229724884033 seconds for one epoch ---
--- 0.7643561363220215 seconds for one epoch ---
--- 0.3169722557067871 seconds for one epoch ---
--- 0.7997050285339355 seconds for one epoch ---
--- 0.31795740127563477 seconds for one epoch ---
--- 0.8121163845062256 seconds for one epoch ---
--- 0.327178955078125 seconds for one epoch ---
--- 0.7904589176177979 seconds for one epoch ---
--- 0.3090384006500244 seconds for one epoch ---
--- 0.796515941619873 seconds for one epoch ---
--- 0.31064391136169434 seconds for one epoch ---
--- 0.786778450012207 seconds for one epoch ---
--- 0.3021857738494873 seconds for one epoch ---
--- 0.7925379276275635 seconds for one epoch ---
=========================
[[0.3158741 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11439571]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99866617]
 [0.        ]]
[[-1.3816271]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.993614 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.6685312]
 [ 0.       ]]
--- 0.2981100082397461 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3287.821533203125, (1759.7878, 1.1665435, 1526.3969, 0.4705479)
   validation loss 1312.564697265625, (995.3337, 0.08611548, 316.6743, 0.4705479)
decoder loss ratio: 38560.954707, decoder SINDy loss  ratio: 0.683586
--- 0.25694847106933594 seconds for one epoch ---
--- 0.28949689865112305 seconds for one epoch ---
--- 0.7949881553649902 seconds for one epoch ---
--- 0.290252685546875 seconds for one epoch ---
--- 0.7959680557250977 seconds for one epoch ---
--- 0.29946160316467285 seconds for one epoch ---
--- 0.8006281852722168 seconds for one epoch ---
--- 0.28982973098754883 seconds for one epoch ---
--- 0.780120849609375 seconds for one epoch ---
--- 0.29419922828674316 seconds for one epoch ---
--- 0.8035390377044678 seconds for one epoch ---
--- 0.28887081146240234 seconds for one epoch ---
--- 0.7950706481933594 seconds for one epoch ---
--- 0.29072141647338867 seconds for one epoch ---
--- 0.8337278366088867 seconds for one epoch ---
--- 0.29843783378601074 seconds for one epoch ---
--- 0.8199629783630371 seconds for one epoch ---
--- 0.2882211208343506 seconds for one epoch ---
--- 0.8172163963317871 seconds for one epoch ---
--- 0.28602147102355957 seconds for one epoch ---
--- 0.813077449798584 seconds for one epoch ---
--- 0.2973453998565674 seconds for one epoch ---
--- 0.8215863704681396 seconds for one epoch ---
--- 0.3051300048828125 seconds for one epoch ---
=========================
[[0.3502914 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.109565  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99889475]
 [0.        ]]
[[-1.428981 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9789183]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7276008]
 [ 0.       ]]
--- 0.2656898498535156 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2969.04345703125, (1439.2268, 2.122838, 1527.2174, 0.4766676)
   validation loss 866.6795654296875, (583.329, 0.1922602, 282.6816, 0.4766676)
decoder loss ratio: 22599.177369, decoder SINDy loss  ratio: 0.610208
--- 0.2787024974822998 seconds for one epoch ---
--- 0.7779645919799805 seconds for one epoch ---
--- 0.3187403678894043 seconds for one epoch ---
--- 0.8441677093505859 seconds for one epoch ---
--- 0.3157532215118408 seconds for one epoch ---
--- 0.7950351238250732 seconds for one epoch ---
--- 0.310230016708374 seconds for one epoch ---
--- 0.785508394241333 seconds for one epoch ---
--- 0.3303351402282715 seconds for one epoch ---
--- 0.7920398712158203 seconds for one epoch ---
--- 0.3158905506134033 seconds for one epoch ---
--- 0.8234541416168213 seconds for one epoch ---
--- 0.3188643455505371 seconds for one epoch ---
--- 0.8085410594940186 seconds for one epoch ---
--- 0.3135814666748047 seconds for one epoch ---
--- 0.81396484375 seconds for one epoch ---
--- 0.30581092834472656 seconds for one epoch ---
--- 0.8080806732177734 seconds for one epoch ---
--- 0.31029796600341797 seconds for one epoch ---
--- 0.8189408779144287 seconds for one epoch ---
--- 0.3090047836303711 seconds for one epoch ---
--- 0.8131856918334961 seconds for one epoch ---
--- 0.2967867851257324 seconds for one epoch ---
--- 0.8114056587219238 seconds for one epoch ---
=========================
[[0.3758849 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10248313]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99902964]
 [0.        ]]
[[-1.4628078]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9562649]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7684767]
 [ 0.       ]]
--- 0.2897775173187256 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2403.135498046875, (1262.9216, 1.5817423, 1138.1528, 0.4793589)
   validation loss 1199.063720703125, (912.8078, 0.108902454, 285.66766, 0.4793589)
decoder loss ratio: 35363.758887, decoder SINDy loss  ratio: 0.616654
--- 0.2584841251373291 seconds for one epoch ---
--- 0.2868802547454834 seconds for one epoch ---
--- 0.8089015483856201 seconds for one epoch ---
--- 0.29422521591186523 seconds for one epoch ---
--- 0.802309513092041 seconds for one epoch ---
--- 0.3249330520629883 seconds for one epoch ---
--- 0.828559398651123 seconds for one epoch ---
--- 0.32505226135253906 seconds for one epoch ---
--- 0.8115313053131104 seconds for one epoch ---
--- 0.31758999824523926 seconds for one epoch ---
--- 0.8316671848297119 seconds for one epoch ---
--- 0.33040809631347656 seconds for one epoch ---
--- 0.8348112106323242 seconds for one epoch ---
--- 0.3299062252044678 seconds for one epoch ---
--- 0.8360161781311035 seconds for one epoch ---
--- 0.3158836364746094 seconds for one epoch ---
--- 0.8149354457855225 seconds for one epoch ---
--- 0.3099853992462158 seconds for one epoch ---
--- 0.8036720752716064 seconds for one epoch ---
--- 0.31689929962158203 seconds for one epoch ---
--- 0.8332674503326416 seconds for one epoch ---
--- 0.31396055221557617 seconds for one epoch ---
--- 0.8197348117828369 seconds for one epoch ---
--- 0.3239591121673584 seconds for one epoch ---
=========================
[[0.4273754 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10193369]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9992311 ]
 [0.        ]]
[[-1.5283586]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9545073]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.8416913]
 [ 0.       ]]
--- 0.25890660285949707 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3427.281005859375, (1625.9484, 0.8002342, 1800.0424, 0.49009228)
   validation loss 929.1795043945312, (633.02484, 0.11437253, 295.55017, 0.49009228)
decoder loss ratio: 24524.481332, decoder SINDy loss  ratio: 0.637987
--- 0.28418612480163574 seconds for one epoch ---
--- 0.8115499019622803 seconds for one epoch ---
--- 0.2912008762359619 seconds for one epoch ---
--- 0.7697563171386719 seconds for one epoch ---
--- 0.29553771018981934 seconds for one epoch ---
--- 0.8370528221130371 seconds for one epoch ---
--- 0.28040194511413574 seconds for one epoch ---
--- 0.8347539901733398 seconds for one epoch ---
--- 0.3072240352630615 seconds for one epoch ---
--- 0.8471417427062988 seconds for one epoch ---
--- 0.30815815925598145 seconds for one epoch ---
--- 0.8528034687042236 seconds for one epoch ---
--- 0.3019545078277588 seconds for one epoch ---
--- 0.8468174934387207 seconds for one epoch ---
--- 0.31580352783203125 seconds for one epoch ---
--- 0.8650262355804443 seconds for one epoch ---
--- 0.3300633430480957 seconds for one epoch ---
--- 0.8618371486663818 seconds for one epoch ---
--- 0.3341655731201172 seconds for one epoch ---
--- 0.864802360534668 seconds for one epoch ---
--- 0.321946382522583 seconds for one epoch ---
--- 0.833566427230835 seconds for one epoch ---
--- 0.3340470790863037 seconds for one epoch ---
--- 0.8395388126373291 seconds for one epoch ---
=========================
[[0.47260267]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10038349]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99936557]
 [0.        ]]
[[-1.5842829]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9493773]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.9022312]
 [ 0.       ]]
--- 0.2942686080932617 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2993.8193359375, (2077.7654, 0.6558376, 914.9004, 0.497917)
   validation loss 1241.7244873046875, (890.5157, 0.14156963, 350.56934, 0.497917)
decoder loss ratio: 34500.123680, decoder SINDy loss  ratio: 0.756753
--- 0.2539091110229492 seconds for one epoch ---
--- 0.2899925708770752 seconds for one epoch ---
--- 0.8590645790100098 seconds for one epoch ---
--- 0.295351505279541 seconds for one epoch ---
--- 0.8193979263305664 seconds for one epoch ---
--- 0.29067349433898926 seconds for one epoch ---
--- 0.831932544708252 seconds for one epoch ---
--- 0.3182566165924072 seconds for one epoch ---
--- 0.8465631008148193 seconds for one epoch ---
--- 0.3110837936401367 seconds for one epoch ---
--- 0.8492412567138672 seconds for one epoch ---
--- 0.30247950553894043 seconds for one epoch ---
--- 0.831608772277832 seconds for one epoch ---
--- 0.3016493320465088 seconds for one epoch ---
--- 0.8403842449188232 seconds for one epoch ---
--- 0.2978055477142334 seconds for one epoch ---
--- 0.8528618812561035 seconds for one epoch ---
--- 0.29985666275024414 seconds for one epoch ---
--- 0.8472249507904053 seconds for one epoch ---
--- 0.2987704277038574 seconds for one epoch ---
--- 0.8290636539459229 seconds for one epoch ---
--- 0.28604984283447266 seconds for one epoch ---
--- 0.8399977684020996 seconds for one epoch ---
--- 0.2931673526763916 seconds for one epoch ---
=========================
[[0.511509  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09587134]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9994635 ]
 [0.        ]]
[[-1.6319399 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.93393654]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-3.955148  ]
 [ 0.        ]]
--- 0.25218963623046875 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3329.400634765625, (1587.6207, 1.676439, 1739.5986, 0.5047836)
   validation loss 990.0592041015625, (726.0207, 0.16398251, 263.36972, 0.5047836)
decoder loss ratio: 28127.301994, decoder SINDy loss  ratio: 0.568521
--- 0.2847590446472168 seconds for one epoch ---
--- 0.8333101272583008 seconds for one epoch ---
--- 0.2999715805053711 seconds for one epoch ---
--- 0.8444023132324219 seconds for one epoch ---
--- 0.294816255569458 seconds for one epoch ---
--- 0.7968916893005371 seconds for one epoch ---
--- 0.29444217681884766 seconds for one epoch ---
--- 0.8197529315948486 seconds for one epoch ---
--- 0.3258051872253418 seconds for one epoch ---
--- 0.8756704330444336 seconds for one epoch ---
--- 0.326967716217041 seconds for one epoch ---
--- 0.88584303855896 seconds for one epoch ---
--- 0.32563304901123047 seconds for one epoch ---
--- 0.8607807159423828 seconds for one epoch ---
--- 0.3287208080291748 seconds for one epoch ---
--- 0.8623635768890381 seconds for one epoch ---
--- 0.32132720947265625 seconds for one epoch ---
--- 0.8478262424468994 seconds for one epoch ---
--- 0.3294670581817627 seconds for one epoch ---
--- 0.8517229557037354 seconds for one epoch ---
--- 0.32480645179748535 seconds for one epoch ---
--- 0.8525485992431641 seconds for one epoch ---
--- 0.32463598251342773 seconds for one epoch ---
--- 0.8622491359710693 seconds for one epoch ---
=========================
[[0.5625022 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09840319]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9995579 ]
 [0.        ]]
[[-1.6947904 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.94274193]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.0163665 ]
 [ 0.        ]]
--- 0.29824209213256836 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3068.943359375, (1404.6259, 1.922514, 1661.8811, 0.5140027)
   validation loss 1036.6568603515625, (755.5228, 0.18422738, 280.4358, 0.5140027)
decoder loss ratio: 29270.265969, decoder SINDy loss  ratio: 0.605360
--- 0.2523477077484131 seconds for one epoch ---
--- 0.2929859161376953 seconds for one epoch ---
--- 0.8579530715942383 seconds for one epoch ---
--- 0.2868204116821289 seconds for one epoch ---
--- 0.845452070236206 seconds for one epoch ---
--- 0.2935354709625244 seconds for one epoch ---
--- 0.8313331604003906 seconds for one epoch ---
--- 0.2982182502746582 seconds for one epoch ---
--- 0.8666772842407227 seconds for one epoch ---
--- 0.2974355220794678 seconds for one epoch ---
--- 0.8500320911407471 seconds for one epoch ---
--- 0.295055627822876 seconds for one epoch ---
--- 0.8712432384490967 seconds for one epoch ---
--- 0.2733488082885742 seconds for one epoch ---
--- 0.8618769645690918 seconds for one epoch ---
--- 0.29070043563842773 seconds for one epoch ---
--- 0.8823673725128174 seconds for one epoch ---
--- 0.45116734504699707 seconds for one epoch ---
--- 0.8674259185791016 seconds for one epoch ---
--- 0.2926175594329834 seconds for one epoch ---
--- 0.8713085651397705 seconds for one epoch ---
--- 0.2940027713775635 seconds for one epoch ---
--- 0.871065616607666 seconds for one epoch ---
--- 0.29120969772338867 seconds for one epoch ---
=========================
[[0.6132498]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0988113]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9996517]
 [0.       ]]
[[-1.7590319 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.94417155]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.09181   ]
 [ 0.        ]]
--- 0.25536322593688965 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4689.4501953125, (1661.2131, 1.8003322, 3025.9155, 0.5214639)
   validation loss 1491.4849853515625, (1156.6062, 0.29195935, 334.06528, 0.5214639)
decoder loss ratio: 44808.932190, decoder SINDy loss  ratio: 0.721127
--- 0.29262328147888184 seconds for one epoch ---
--- 0.8624532222747803 seconds for one epoch ---
--- 0.29600000381469727 seconds for one epoch ---
--- 0.8741192817687988 seconds for one epoch ---
--- 0.2987055778503418 seconds for one epoch ---
--- 0.8863089084625244 seconds for one epoch ---
--- 0.2917752265930176 seconds for one epoch ---
--- 0.8372397422790527 seconds for one epoch ---
--- 0.2792677879333496 seconds for one epoch ---
--- 0.8994960784912109 seconds for one epoch ---
--- 0.3361954689025879 seconds for one epoch ---
--- 0.8862097263336182 seconds for one epoch ---
--- 0.3270564079284668 seconds for one epoch ---
--- 0.8739540576934814 seconds for one epoch ---
--- 0.3195512294769287 seconds for one epoch ---
--- 0.900810718536377 seconds for one epoch ---
--- 0.3262169361114502 seconds for one epoch ---
--- 0.8796467781066895 seconds for one epoch ---
--- 0.33342671394348145 seconds for one epoch ---
--- 0.8871815204620361 seconds for one epoch ---
--- 0.3067591190338135 seconds for one epoch ---
--- 0.8827822208404541 seconds for one epoch ---
--- 0.3125293254852295 seconds for one epoch ---
--- 0.8774247169494629 seconds for one epoch ---
=========================
[[0.6497069 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0950501 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99971294]
 [0.        ]]
[[-1.8070942]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.9311526]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.152981 ]
 [ 0.       ]]
--- 0.2834348678588867 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4396.8349609375, (1790.4014, 1.9220332, 2603.9849, 0.5266854)
   validation loss 1844.359375, (1542.0818, 0.19185078, 301.55893, 0.5266854)
decoder loss ratio: 59742.925604, decoder SINDy loss  ratio: 0.650957
--- 0.25464749336242676 seconds for one epoch ---
--- 0.2970418930053711 seconds for one epoch ---
--- 0.8586909770965576 seconds for one epoch ---
--- 0.2903428077697754 seconds for one epoch ---
--- 0.8560914993286133 seconds for one epoch ---
--- 0.28147125244140625 seconds for one epoch ---
--- 0.8740839958190918 seconds for one epoch ---
--- 0.29030489921569824 seconds for one epoch ---
--- 0.8539087772369385 seconds for one epoch ---
--- 0.3025393486022949 seconds for one epoch ---
--- 0.8824787139892578 seconds for one epoch ---
--- 0.2878129482269287 seconds for one epoch ---
--- 0.8903429508209229 seconds for one epoch ---
--- 0.2911405563354492 seconds for one epoch ---
--- 0.9117002487182617 seconds for one epoch ---
--- 0.3006734848022461 seconds for one epoch ---
--- 0.9095463752746582 seconds for one epoch ---
--- 0.29702329635620117 seconds for one epoch ---
--- 0.9118554592132568 seconds for one epoch ---
--- 0.29722142219543457 seconds for one epoch ---
--- 0.9038307666778564 seconds for one epoch ---
--- 0.29792213439941406 seconds for one epoch ---
--- 0.9186739921569824 seconds for one epoch ---
--- 0.2975120544433594 seconds for one epoch ---
=========================
[[0.67949986]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09099068]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9997541 ]
 [0.        ]]
[[-1.8481154 ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.91657275]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [-4.201637  ]
 [ 0.        ]]
--- 0.24037551879882812 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3232.502197265625, (1718.5979, 1.0271846, 1512.347, 0.5300693)
   validation loss 1320.3060302734375, (1007.1207, 0.3448868, 312.31036, 0.5300693)
decoder loss ratio: 39017.605423, decoder SINDy loss  ratio: 0.674166
--- 0.31368279457092285 seconds for one epoch ---
--- 0.8757607936859131 seconds for one epoch ---
--- 0.30347490310668945 seconds for one epoch ---
--- 0.8693020343780518 seconds for one epoch ---
--- 0.2688131332397461 seconds for one epoch ---
--- 0.8732025623321533 seconds for one epoch ---
--- 0.30436253547668457 seconds for one epoch ---
--- 0.89512038230896 seconds for one epoch ---
--- 0.2837800979614258 seconds for one epoch ---
--- 0.8845028877258301 seconds for one epoch ---
--- 0.29308390617370605 seconds for one epoch ---
--- 0.8875367641448975 seconds for one epoch ---
--- 0.2985987663269043 seconds for one epoch ---
--- 0.9019436836242676 seconds for one epoch ---
--- 0.2886347770690918 seconds for one epoch ---
--- 0.8965909481048584 seconds for one epoch ---
--- 0.28556227684020996 seconds for one epoch ---
--- 0.9340190887451172 seconds for one epoch ---
--- 0.29614686965942383 seconds for one epoch ---
--- 0.8789582252502441 seconds for one epoch ---
--- 0.29029369354248047 seconds for one epoch ---
--- 0.912982702255249 seconds for one epoch ---
--- 0.30663156509399414 seconds for one epoch ---
--- 0.9009037017822266 seconds for one epoch ---
=========================
[[0.7120576]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0889485]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.999792 ]
 [0.       ]]
[[-1.8953581]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9090257]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.255381 ]
 [ 0.       ]]
--- 0.2913670539855957 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3602.767333984375, (1679.194, 1.7269725, 1921.3132, 0.5332102)
   validation loss 1179.432861328125, (903.58795, 0.39143035, 274.92026, 0.5332102)
decoder loss ratio: 35006.565945, decoder SINDy loss  ratio: 0.593454
--- 0.25693345069885254 seconds for one epoch ---
--- 0.29659152030944824 seconds for one epoch ---
--- 0.888592004776001 seconds for one epoch ---
--- 0.2937331199645996 seconds for one epoch ---
--- 0.8944427967071533 seconds for one epoch ---
--- 0.29526710510253906 seconds for one epoch ---
--- 0.8936557769775391 seconds for one epoch ---
--- 0.2857799530029297 seconds for one epoch ---
--- 0.9227120876312256 seconds for one epoch ---
--- 0.2952454090118408 seconds for one epoch ---
--- 0.8865616321563721 seconds for one epoch ---
--- 0.2910182476043701 seconds for one epoch ---
--- 0.9391095638275146 seconds for one epoch ---
--- 0.29370808601379395 seconds for one epoch ---
--- 0.9239239692687988 seconds for one epoch ---
--- 0.30164217948913574 seconds for one epoch ---
--- 0.9248316287994385 seconds for one epoch ---
--- 0.32119107246398926 seconds for one epoch ---
--- 0.9176182746887207 seconds for one epoch ---
--- 0.32042813301086426 seconds for one epoch ---
--- 0.9400944709777832 seconds for one epoch ---
--- 0.3205268383026123 seconds for one epoch ---
--- 0.9410831928253174 seconds for one epoch ---
--- 0.3289933204650879 seconds for one epoch ---
=========================
[[0.7426925 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08738236]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998243 ]
 [0.        ]]
[[-1.9428385 ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.90313625]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.309009  ]
 [ 0.        ]]
--- 0.26761364936828613 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4327.82763671875, (2226.7957, 0.3806436, 2100.1135, 0.5377869)
   validation loss 1154.14599609375, (855.1214, 0.26602218, 298.22067, 0.5377869)
decoder loss ratio: 33128.887550, decoder SINDy loss  ratio: 0.643751
--- 0.3301811218261719 seconds for one epoch ---
--- 0.9417421817779541 seconds for one epoch ---
--- 0.3384740352630615 seconds for one epoch ---
--- 0.9237592220306396 seconds for one epoch ---
--- 0.3031439781188965 seconds for one epoch ---
--- 0.9325582981109619 seconds for one epoch ---
--- 0.2966592311859131 seconds for one epoch ---
--- 0.9055638313293457 seconds for one epoch ---
--- 0.2917211055755615 seconds for one epoch ---
--- 0.9299790859222412 seconds for one epoch ---
--- 0.2814910411834717 seconds for one epoch ---
--- 0.9143362045288086 seconds for one epoch ---
--- 0.2738187313079834 seconds for one epoch ---
--- 0.9023230075836182 seconds for one epoch ---
--- 0.2914309501647949 seconds for one epoch ---
--- 0.9499049186706543 seconds for one epoch ---
--- 0.30789732933044434 seconds for one epoch ---
--- 0.9268825054168701 seconds for one epoch ---
--- 0.30201268196105957 seconds for one epoch ---
--- 0.9583132266998291 seconds for one epoch ---
--- 0.3013298511505127 seconds for one epoch ---
--- 0.9294118881225586 seconds for one epoch ---
--- 0.2832667827606201 seconds for one epoch ---
--- 0.9356930255889893 seconds for one epoch ---
=========================
[[0.7704505 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08820218]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998502 ]
 [0.        ]]
[[-1.9891891]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9062603]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.358757 ]
 [ 0.       ]]
--- 0.28372836112976074 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2277.9765625, (1027.3423, 0.78136665, 1249.3108, 0.54208785)
   validation loss 884.9112548828125, (588.19946, 0.20092545, 295.96878, 0.54208785)
decoder loss ratio: 22787.868352, decoder SINDy loss  ratio: 0.638890
--- 0.2632923126220703 seconds for one epoch ---
--- 0.2850339412689209 seconds for one epoch ---
--- 0.9314579963684082 seconds for one epoch ---
--- 0.2895984649658203 seconds for one epoch ---
--- 0.9264400005340576 seconds for one epoch ---
--- 0.2966017723083496 seconds for one epoch ---
--- 0.92582106590271 seconds for one epoch ---
--- 0.2919294834136963 seconds for one epoch ---
--- 0.9377231597900391 seconds for one epoch ---
--- 0.274616003036499 seconds for one epoch ---
--- 0.9437465667724609 seconds for one epoch ---
--- 0.29779505729675293 seconds for one epoch ---
--- 0.887232780456543 seconds for one epoch ---
--- 0.28394603729248047 seconds for one epoch ---
--- 0.9324445724487305 seconds for one epoch ---
--- 0.3070566654205322 seconds for one epoch ---
--- 0.9498884677886963 seconds for one epoch ---
--- 0.3159949779510498 seconds for one epoch ---
--- 0.9739634990692139 seconds for one epoch ---
--- 0.32314252853393555 seconds for one epoch ---
--- 0.9598479270935059 seconds for one epoch ---
--- 0.308687686920166 seconds for one epoch ---
--- 0.9514040946960449 seconds for one epoch ---
--- 0.32417988777160645 seconds for one epoch ---
=========================
[[0.79482937]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08302522]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99987656]
 [0.        ]]
[[-2.0332856]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.8862088]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.421233 ]
 [ 0.       ]]
--- 0.2622811794281006 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2446.187744140625, (1511.6417, 0.4912843, 933.51196, 0.54283994)
   validation loss 968.5542602539062, (684.5351, 0.15577358, 283.32056, 0.54283994)
decoder loss ratio: 26520.077994, decoder SINDy loss  ratio: 0.611587
--- 0.32738804817199707 seconds for one epoch ---
--- 0.9287683963775635 seconds for one epoch ---
--- 0.3262064456939697 seconds for one epoch ---
--- 0.9402813911437988 seconds for one epoch ---
--- 0.2986927032470703 seconds for one epoch ---
--- 0.9368107318878174 seconds for one epoch ---
--- 0.29253697395324707 seconds for one epoch ---
--- 0.9424099922180176 seconds for one epoch ---
--- 0.2834141254425049 seconds for one epoch ---
--- 0.9321813583374023 seconds for one epoch ---
--- 0.2955183982849121 seconds for one epoch ---
--- 0.948157548904419 seconds for one epoch ---
--- 0.30315446853637695 seconds for one epoch ---
--- 0.9395289421081543 seconds for one epoch ---
--- 0.2988617420196533 seconds for one epoch ---
--- 0.9256637096405029 seconds for one epoch ---
--- 0.2897837162017822 seconds for one epoch ---
--- 0.954331636428833 seconds for one epoch ---
--- 0.29251956939697266 seconds for one epoch ---
--- 0.9573991298675537 seconds for one epoch ---
--- 0.28978848457336426 seconds for one epoch ---
--- 0.9554064273834229 seconds for one epoch ---
--- 0.304793119430542 seconds for one epoch ---
--- 0.957395076751709 seconds for one epoch ---
=========================
[[0.80992115]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0807219 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998864 ]
 [0.        ]]
[[-2.0625687 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.87692875]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-4.448154  ]
 [ 0.        ]]
--- 0.2981376647949219 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4907.94482421875, (2576.8867, 2.0906775, 2328.424, 0.54333866)
   validation loss 1431.8887939453125, (1126.1932, 0.27257457, 304.87958, 0.54333866)
decoder loss ratio: 43630.681171, decoder SINDy loss  ratio: 0.658125
--- 0.25223755836486816 seconds for one epoch ---
--- 0.3029906749725342 seconds for one epoch ---
--- 0.9527032375335693 seconds for one epoch ---
--- 0.289691686630249 seconds for one epoch ---
--- 0.9426813125610352 seconds for one epoch ---
--- 0.2961125373840332 seconds for one epoch ---
--- 0.9631998538970947 seconds for one epoch ---
--- 0.2928471565246582 seconds for one epoch ---
--- 0.9491770267486572 seconds for one epoch ---
--- 0.2734208106994629 seconds for one epoch ---
--- 0.941443920135498 seconds for one epoch ---
--- 0.28787660598754883 seconds for one epoch ---
--- 0.9415862560272217 seconds for one epoch ---
--- 0.2980058193206787 seconds for one epoch ---
--- 0.9397008419036865 seconds for one epoch ---
--- 0.2834815979003906 seconds for one epoch ---
--- 0.9643816947937012 seconds for one epoch ---
--- 0.2769005298614502 seconds for one epoch ---
--- 0.9570009708404541 seconds for one epoch ---
--- 0.2827010154724121 seconds for one epoch ---
--- 0.9837169647216797 seconds for one epoch ---
--- 0.28636860847473145 seconds for one epoch ---
--- 0.9463951587677002 seconds for one epoch ---
--- 0.2750129699707031 seconds for one epoch ---
=========================
[[0.82941467]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08060676]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9998994 ]
 [0.        ]]
[[-2.1031823 ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.87647194]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-4.488281  ]
 [ 0.        ]]
--- 0.25217485427856445 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3382.72607421875, (1972.3694, 1.3792951, 1408.4341, 0.543538)
   validation loss 866.3882446289062, (590.4579, 0.28733295, 275.0995, 0.543538)
decoder loss ratio: 22875.363574, decoder SINDy loss  ratio: 0.593841
--- 0.3065016269683838 seconds for one epoch ---
--- 0.9438984394073486 seconds for one epoch ---
--- 0.3102445602416992 seconds for one epoch ---
--- 0.9632573127746582 seconds for one epoch ---
--- 0.3051779270172119 seconds for one epoch ---
--- 0.9516615867614746 seconds for one epoch ---
--- 0.29658031463623047 seconds for one epoch ---
--- 0.9791696071624756 seconds for one epoch ---
--- 0.29668569564819336 seconds for one epoch ---
--- 0.9557945728302002 seconds for one epoch ---
--- 0.2960171699523926 seconds for one epoch ---
--- 0.936354398727417 seconds for one epoch ---
--- 0.296614408493042 seconds for one epoch ---
--- 0.9827923774719238 seconds for one epoch ---
--- 0.28711485862731934 seconds for one epoch ---
--- 0.9631791114807129 seconds for one epoch ---
--- 0.29508423805236816 seconds for one epoch ---
--- 0.9725310802459717 seconds for one epoch ---
--- 0.29444050788879395 seconds for one epoch ---
--- 0.9701204299926758 seconds for one epoch ---
--- 0.2948265075683594 seconds for one epoch ---
--- 0.9762203693389893 seconds for one epoch ---
--- 0.30570507049560547 seconds for one epoch ---
--- 0.9680991172790527 seconds for one epoch ---
=========================
[[0.83547705]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07551916]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99990547]
 [0.        ]]
[[-2.1165626]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.85504  ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5032263]
 [ 0.       ]]
--- 0.29418468475341797 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2367.1376953125, (1100.2135, 0.8181563, 1265.566, 0.53992635)
   validation loss 884.2044677734375, (606.8127, 0.1447021, 276.70715, 0.53992635)
decoder loss ratio: 23508.976817, decoder SINDy loss  ratio: 0.597311
THRESHOLDING: 2 active coefficients
--- 0.26459527015686035 seconds for one epoch ---
--- 0.32038307189941406 seconds for one epoch ---
--- 0.9519248008728027 seconds for one epoch ---
--- 0.3249526023864746 seconds for one epoch ---
--- 0.9786155223846436 seconds for one epoch ---
--- 0.3138906955718994 seconds for one epoch ---
--- 0.9764058589935303 seconds for one epoch ---
--- 0.3126180171966553 seconds for one epoch ---
--- 0.9771490097045898 seconds for one epoch ---
--- 0.3210446834564209 seconds for one epoch ---
--- 0.9681167602539062 seconds for one epoch ---
--- 0.3177480697631836 seconds for one epoch ---
--- 0.9788899421691895 seconds for one epoch ---
--- 0.3082764148712158 seconds for one epoch ---
--- 0.9903366565704346 seconds for one epoch ---
--- 0.3032114505767822 seconds for one epoch ---
--- 1.005544662475586 seconds for one epoch ---
--- 0.2988300323486328 seconds for one epoch ---
--- 0.9991135597229004 seconds for one epoch ---
--- 0.30527377128601074 seconds for one epoch ---
--- 0.985670804977417 seconds for one epoch ---
--- 0.30123353004455566 seconds for one epoch ---
--- 0.9894046783447266 seconds for one epoch ---
--- 0.3095419406890869 seconds for one epoch ---
=========================
[[0.97732556]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999553 ]
 [0.        ]]
[[-2.777558]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.735125]
 [ 0.      ]]
--- 0.256763219833374 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2888.415283203125, (1338.9208, 1.117306, 1547.879, 0.49833727)
   validation loss 1230.72265625, (949.7434, 0.28618515, 280.19476, 0.49833727)
decoder loss ratio: 36794.708461, decoder SINDy loss  ratio: 0.604840
--- 0.328458309173584 seconds for one epoch ---
--- 0.9601964950561523 seconds for one epoch ---
--- 0.3219883441925049 seconds for one epoch ---
--- 0.9762265682220459 seconds for one epoch ---
--- 0.3232421875 seconds for one epoch ---
--- 0.9800403118133545 seconds for one epoch ---
--- 0.3168163299560547 seconds for one epoch ---
--- 0.9822723865509033 seconds for one epoch ---
--- 0.30861473083496094 seconds for one epoch ---
--- 1.008044958114624 seconds for one epoch ---
--- 0.30167555809020996 seconds for one epoch ---
--- 1.017629861831665 seconds for one epoch ---
--- 0.27727365493774414 seconds for one epoch ---
--- 0.9759836196899414 seconds for one epoch ---
--- 0.28935909271240234 seconds for one epoch ---
--- 0.9872636795043945 seconds for one epoch ---
--- 0.2951366901397705 seconds for one epoch ---
--- 0.9985318183898926 seconds for one epoch ---
--- 0.2904777526855469 seconds for one epoch ---
--- 0.9514205455780029 seconds for one epoch ---
--- 0.2971360683441162 seconds for one epoch ---
--- 0.9942600727081299 seconds for one epoch ---
--- 0.31481075286865234 seconds for one epoch ---
--- 1.0171597003936768 seconds for one epoch ---
=========================
[[0.99596995]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999692 ]
 [0.        ]]
[[-3.321302 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.9102564]
 [ 0.       ]]
--- 0.2914156913757324 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4071.66455078125, (1673.602, 0.7512147, 2396.808, 0.5032209)
   validation loss 977.7054443359375, (684.4802, 0.245805, 292.4762, 0.5032209)
decoder loss ratio: 26517.952211, decoder SINDy loss  ratio: 0.631351
--- 0.2434239387512207 seconds for one epoch ---
--- 0.2945892810821533 seconds for one epoch ---
--- 0.9804162979125977 seconds for one epoch ---
--- 0.28209924697875977 seconds for one epoch ---
--- 0.9762520790100098 seconds for one epoch ---
--- 0.2921626567840576 seconds for one epoch ---
--- 0.9790441989898682 seconds for one epoch ---
--- 0.2938838005065918 seconds for one epoch ---
--- 0.9920198917388916 seconds for one epoch ---
--- 0.29230833053588867 seconds for one epoch ---
--- 0.9978883266448975 seconds for one epoch ---
--- 0.3031172752380371 seconds for one epoch ---
--- 0.9845249652862549 seconds for one epoch ---
--- 0.29372644424438477 seconds for one epoch ---
--- 1.003368854522705 seconds for one epoch ---
--- 0.29650402069091797 seconds for one epoch ---
--- 0.9829754829406738 seconds for one epoch ---
--- 0.2905881404876709 seconds for one epoch ---
--- 1.010298728942871 seconds for one epoch ---
--- 0.30765604972839355 seconds for one epoch ---
--- 0.965285062789917 seconds for one epoch ---
--- 0.2925598621368408 seconds for one epoch ---
--- 1.0359349250793457 seconds for one epoch ---
--- 0.2915072441101074 seconds for one epoch ---
=========================
[[0.99910057]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999804 ]
 [0.        ]]
[[-3.792314]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-5.049172]
 [ 0.      ]]
--- 0.2683584690093994 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2590.3369140625, (1563.3523, 0.5412724, 1025.9365, 0.50680566)
   validation loss 734.6580810546875, (446.36557, 0.28940493, 287.49625, 0.50680566)
decoder loss ratio: 17292.977109, decoder SINDy loss  ratio: 0.620601
--- 0.3325471878051758 seconds for one epoch ---
--- 0.9944519996643066 seconds for one epoch ---
--- 0.3474867343902588 seconds for one epoch ---
--- 1.0328080654144287 seconds for one epoch ---
--- 0.3294868469238281 seconds for one epoch ---
--- 1.01686692237854 seconds for one epoch ---
--- 0.3065664768218994 seconds for one epoch ---
--- 1.0023033618927002 seconds for one epoch ---
--- 0.3260042667388916 seconds for one epoch ---
--- 1.0205659866333008 seconds for one epoch ---
--- 0.31027817726135254 seconds for one epoch ---
--- 1.0278205871582031 seconds for one epoch ---
--- 0.2970852851867676 seconds for one epoch ---
--- 1.0312087535858154 seconds for one epoch ---
--- 0.28705668449401855 seconds for one epoch ---
--- 1.012657642364502 seconds for one epoch ---
--- 0.2806413173675537 seconds for one epoch ---
--- 1.008059024810791 seconds for one epoch ---
--- 0.2911365032196045 seconds for one epoch ---
--- 1.0335056781768799 seconds for one epoch ---
--- 0.2847025394439697 seconds for one epoch ---
--- 0.979388952255249 seconds for one epoch ---
--- 0.2945990562438965 seconds for one epoch ---
--- 1.0331809520721436 seconds for one epoch ---
=========================
[[0.9997529]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.999982 ]
 [0.       ]]
[[-4.199947 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.1342635]
 [ 0.       ]]
--- 0.2698230743408203 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3839.719970703125, (2446.887, 1.0138314, 1391.3093, 0.50978804)
   validation loss 856.9487915039062, (589.4934, 0.24093942, 266.70465, 0.50978804)
decoder loss ratio: 22837.998039, decoder SINDy loss  ratio: 0.575720
--- 0.2543375492095947 seconds for one epoch ---
--- 0.28945255279541016 seconds for one epoch ---
--- 1.013800859451294 seconds for one epoch ---
--- 0.2960793972015381 seconds for one epoch ---
--- 1.026473045349121 seconds for one epoch ---
--- 0.2978498935699463 seconds for one epoch ---
--- 1.0073986053466797 seconds for one epoch ---
--- 0.2903740406036377 seconds for one epoch ---
--- 1.0354712009429932 seconds for one epoch ---
--- 0.29131555557250977 seconds for one epoch ---
--- 1.0128066539764404 seconds for one epoch ---
--- 0.2944016456604004 seconds for one epoch ---
--- 1.029348611831665 seconds for one epoch ---
--- 0.29001736640930176 seconds for one epoch ---
--- 1.030177116394043 seconds for one epoch ---
--- 0.2965245246887207 seconds for one epoch ---
--- 1.0199942588806152 seconds for one epoch ---
--- 0.2928895950317383 seconds for one epoch ---
--- 1.024446964263916 seconds for one epoch ---
--- 0.29393696784973145 seconds for one epoch ---
--- 1.006972312927246 seconds for one epoch ---
--- 0.28679800033569336 seconds for one epoch ---
--- 0.9924194812774658 seconds for one epoch ---
--- 0.2931995391845703 seconds for one epoch ---
=========================
[[0.99992645]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998665]
 [0.        ]]
[[-4.584618]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-5.190301]
 [ 0.      ]]
--- 0.2569289207458496 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2333.84130859375, (978.9394, 0.9555359, 1353.4338, 0.5126526)
   validation loss 751.0147094726562, (475.50684, 0.2936044, 274.70163, 0.5126526)
decoder loss ratio: 18421.960340, decoder SINDy loss  ratio: 0.592982
--- 0.2890326976776123 seconds for one epoch ---
--- 1.0570778846740723 seconds for one epoch ---
--- 0.3014085292816162 seconds for one epoch ---
--- 1.0484733581542969 seconds for one epoch ---
--- 0.3040292263031006 seconds for one epoch ---
--- 1.0476500988006592 seconds for one epoch ---
--- 0.31020259857177734 seconds for one epoch ---
--- 1.0249316692352295 seconds for one epoch ---
--- 0.306804895401001 seconds for one epoch ---
--- 1.0663230419158936 seconds for one epoch ---
--- 0.3100557327270508 seconds for one epoch ---
--- 1.0535969734191895 seconds for one epoch ---
--- 0.30602025985717773 seconds for one epoch ---
--- 1.020871877670288 seconds for one epoch ---
--- 0.29929208755493164 seconds for one epoch ---
--- 1.032639741897583 seconds for one epoch ---
--- 0.2930300235748291 seconds for one epoch ---
--- 1.0465896129608154 seconds for one epoch ---
--- 0.3058309555053711 seconds for one epoch ---
--- 1.0380609035491943 seconds for one epoch ---
--- 0.28688955307006836 seconds for one epoch ---
--- 1.0452136993408203 seconds for one epoch ---
--- 0.28034424781799316 seconds for one epoch ---
--- 1.0148489475250244 seconds for one epoch ---
=========================
[[0.9999746]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999927]
 [0.       ]]
[[-4.9412584]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.232185 ]
 [-0.       ]]
--- 0.2922475337982178 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5488.31005859375, (1904.776, 2.4195683, 3580.599, 0.5153634)
   validation loss 937.42919921875, (646.5981, 0.29270247, 290.023, 0.5153634)
decoder loss ratio: 25050.332298, decoder SINDy loss  ratio: 0.626055
--- 0.26247501373291016 seconds for one epoch ---
--- 0.2816481590270996 seconds for one epoch ---
--- 1.0322911739349365 seconds for one epoch ---
--- 0.2993335723876953 seconds for one epoch ---
--- 1.0355525016784668 seconds for one epoch ---
--- 0.28814220428466797 seconds for one epoch ---
--- 1.0118281841278076 seconds for one epoch ---
--- 0.2895057201385498 seconds for one epoch ---
--- 1.0471484661102295 seconds for one epoch ---
--- 0.29149580001831055 seconds for one epoch ---
--- 1.0288362503051758 seconds for one epoch ---
--- 0.29758644104003906 seconds for one epoch ---
--- 1.0434880256652832 seconds for one epoch ---
--- 0.293060302734375 seconds for one epoch ---
--- 1.054006814956665 seconds for one epoch ---
--- 0.28430604934692383 seconds for one epoch ---
--- 1.0415527820587158 seconds for one epoch ---
--- 0.2932267189025879 seconds for one epoch ---
--- 1.0284364223480225 seconds for one epoch ---
--- 0.29224181175231934 seconds for one epoch ---
--- 1.0493543148040771 seconds for one epoch ---
--- 0.2893702983856201 seconds for one epoch ---
--- 1.0505778789520264 seconds for one epoch ---
--- 0.29009413719177246 seconds for one epoch ---
=========================
[[0.9999931]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999931]
 [0.       ]]
[[-5.257253]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-5.24595 ]
 [ 0.      ]]
--- 0.2603580951690674 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3167.336181640625, (1707.168, 4.709137, 1454.9413, 0.51786417)
   validation loss 830.8224487304688, (539.046, 0.2838518, 290.9747, 0.51786417)
decoder loss ratio: 20883.578660, decoder SINDy loss  ratio: 0.628110
--- 0.3192586898803711 seconds for one epoch ---
--- 1.0320348739624023 seconds for one epoch ---
--- 0.3400001525878906 seconds for one epoch ---
--- 1.0319504737854004 seconds for one epoch ---
--- 0.28409719467163086 seconds for one epoch ---
--- 1.0542774200439453 seconds for one epoch ---
--- 0.297487735748291 seconds for one epoch ---
--- 1.0480616092681885 seconds for one epoch ---
--- 0.301044225692749 seconds for one epoch ---
--- 1.0549566745758057 seconds for one epoch ---
--- 0.28578853607177734 seconds for one epoch ---
--- 1.0719261169433594 seconds for one epoch ---
--- 0.29704999923706055 seconds for one epoch ---
--- 1.0589163303375244 seconds for one epoch ---
--- 0.30243420600891113 seconds for one epoch ---
--- 1.0693414211273193 seconds for one epoch ---
--- 0.2791299819946289 seconds for one epoch ---
--- 1.0447728633880615 seconds for one epoch ---
--- 0.29770708084106445 seconds for one epoch ---
--- 1.068965196609497 seconds for one epoch ---
--- 0.28740930557250977 seconds for one epoch ---
--- 1.0586552619934082 seconds for one epoch ---
--- 0.29627084732055664 seconds for one epoch ---
--- 1.075404405593872 seconds for one epoch ---
=========================
[[0.999993]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999993]
 [0.      ]]
[[-5.5426316]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.2292986]
 [ 0.       ]]
--- 0.28804874420166016 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2532.571044921875, (1535.655, 0.8094634, 995.58655, 0.51994866)
   validation loss 1514.33251953125, (1197.6713, 0.30005503, 315.84128, 0.51994866)
decoder loss ratio: 46399.864041, decoder SINDy loss  ratio: 0.681788
--- 0.258575439453125 seconds for one epoch ---
--- 0.29920291900634766 seconds for one epoch ---
--- 1.0568594932556152 seconds for one epoch ---
--- 0.2865169048309326 seconds for one epoch ---
--- 1.0936956405639648 seconds for one epoch ---
--- 0.30776214599609375 seconds for one epoch ---
--- 1.0615649223327637 seconds for one epoch ---
--- 0.32059741020202637 seconds for one epoch ---
--- 1.0857586860656738 seconds for one epoch ---
--- 0.32189273834228516 seconds for one epoch ---
--- 1.0866806507110596 seconds for one epoch ---
--- 0.5364766120910645 seconds for one epoch ---
--- 1.0865859985351562 seconds for one epoch ---
--- 0.29114627838134766 seconds for one epoch ---
--- 1.0905990600585938 seconds for one epoch ---
--- 0.3083384037017822 seconds for one epoch ---
--- 1.0728130340576172 seconds for one epoch ---
--- 0.30067920684814453 seconds for one epoch ---
--- 1.0823967456817627 seconds for one epoch ---
--- 0.3011941909790039 seconds for one epoch ---
--- 1.090811014175415 seconds for one epoch ---
--- 0.3008859157562256 seconds for one epoch ---
--- 1.1086010932922363 seconds for one epoch ---
--- 0.30015110969543457 seconds for one epoch ---
=========================
[[0.999993 ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999912]
 [0.       ]]
[[-5.8168535]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.2118344]
 [ 0.       ]]
--- 0.25507211685180664 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1983.2412109375, (1015.84814, 0.90737987, 965.9637, 0.52202904)
   validation loss 854.8756713867188, (561.65393, 0.28301486, 292.41672, 0.52202904)
decoder loss ratio: 21759.448348, decoder SINDy loss  ratio: 0.631223
--- 0.32215046882629395 seconds for one epoch ---
--- 1.0831925868988037 seconds for one epoch ---
--- 0.32433009147644043 seconds for one epoch ---
--- 1.0613977909088135 seconds for one epoch ---
--- 0.326688289642334 seconds for one epoch ---
--- 1.0866367816925049 seconds for one epoch ---
--- 0.31393909454345703 seconds for one epoch ---
--- 1.0576536655426025 seconds for one epoch ---
--- 0.29926395416259766 seconds for one epoch ---
--- 1.0961267948150635 seconds for one epoch ---
--- 0.32151126861572266 seconds for one epoch ---
--- 1.11358642578125 seconds for one epoch ---
--- 0.3152191638946533 seconds for one epoch ---
--- 1.0907323360443115 seconds for one epoch ---
--- 0.2975800037384033 seconds for one epoch ---
--- 1.1121559143066406 seconds for one epoch ---
--- 0.300076961517334 seconds for one epoch ---
--- 1.1077196598052979 seconds for one epoch ---
--- 0.2993910312652588 seconds for one epoch ---
--- 1.1128709316253662 seconds for one epoch ---
--- 0.291778564453125 seconds for one epoch ---
--- 1.118861436843872 seconds for one epoch ---
--- 0.2982757091522217 seconds for one epoch ---
--- 1.1043143272399902 seconds for one epoch ---
=========================
[[0.9999931]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999889]
 [0.       ]]
[[-6.0766683]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.1879635]
 [-0.       ]]
--- 0.2897155284881592 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3853.16845703125, (1590.0614, 4.083888, 2258.4993, 0.5240379)
   validation loss 1131.2535400390625, (826.3128, 0.31794783, 304.09882, 0.5240379)
decoder loss ratio: 32012.792615, decoder SINDy loss  ratio: 0.656440
--- 0.2520482540130615 seconds for one epoch ---
--- 0.29183220863342285 seconds for one epoch ---
--- 1.0879771709442139 seconds for one epoch ---
--- 0.28615593910217285 seconds for one epoch ---
--- 1.078352451324463 seconds for one epoch ---
--- 0.2882270812988281 seconds for one epoch ---
--- 1.0832738876342773 seconds for one epoch ---
--- 0.2884514331817627 seconds for one epoch ---
--- 1.0779526233673096 seconds for one epoch ---
--- 0.2710556983947754 seconds for one epoch ---
--- 1.0936319828033447 seconds for one epoch ---
--- 0.2923445701599121 seconds for one epoch ---
--- 1.1247906684875488 seconds for one epoch ---
--- 0.29483485221862793 seconds for one epoch ---
--- 1.0916812419891357 seconds for one epoch ---
--- 0.2971067428588867 seconds for one epoch ---
--- 1.1179397106170654 seconds for one epoch ---
--- 0.2911717891693115 seconds for one epoch ---
--- 1.1056501865386963 seconds for one epoch ---
--- 0.2921640872955322 seconds for one epoch ---
--- 1.1206533908843994 seconds for one epoch ---
--- 0.2863154411315918 seconds for one epoch ---
--- 1.0944266319274902 seconds for one epoch ---
--- 0.3086378574371338 seconds for one epoch ---
=========================
[[0.9999964 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998295]
 [0.        ]]
[[-6.282729]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-5.136691]
 [-0.      ]]
--- 0.24307537078857422 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2898.071044921875, (1074.4081, 1.1796899, 1821.9576, 0.5255588)
   validation loss 1106.180419921875, (828.2248, 0.34194273, 277.08823, 0.5255588)
decoder loss ratio: 32086.866322, decoder SINDy loss  ratio: 0.598134
--- 0.2832663059234619 seconds for one epoch ---
--- 1.0855000019073486 seconds for one epoch ---
--- 0.28507256507873535 seconds for one epoch ---
--- 1.1015138626098633 seconds for one epoch ---
--- 0.29518938064575195 seconds for one epoch ---
--- 1.0884695053100586 seconds for one epoch ---
--- 0.272810697555542 seconds for one epoch ---
--- 1.109649896621704 seconds for one epoch ---
--- 0.29113030433654785 seconds for one epoch ---
--- 1.1069116592407227 seconds for one epoch ---
--- 0.2975282669067383 seconds for one epoch ---
--- 1.1341307163238525 seconds for one epoch ---
--- 0.30299925804138184 seconds for one epoch ---
--- 1.1302695274353027 seconds for one epoch ---
--- 0.296703577041626 seconds for one epoch ---
--- 1.133655071258545 seconds for one epoch ---
--- 0.273190975189209 seconds for one epoch ---
--- 1.124284029006958 seconds for one epoch ---
--- 0.2989177703857422 seconds for one epoch ---
--- 1.1111454963684082 seconds for one epoch ---
--- 0.2973165512084961 seconds for one epoch ---
--- 1.1121530532836914 seconds for one epoch ---
--- 0.29199790954589844 seconds for one epoch ---
--- 1.1218955516815186 seconds for one epoch ---
=========================
[[0.99999845]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999789 ]
 [0.        ]]
[[-6.4668856]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.071065 ]
 [ 0.       ]]
--- 0.3008456230163574 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4491.50341796875, (2302.655, 8.978957, 2179.3428, 0.5268194)
   validation loss 805.3687744140625, (539.4567, 0.30839747, 265.07684, 0.5268194)
decoder loss ratio: 20899.490106, decoder SINDy loss  ratio: 0.572206
--- 0.28142237663269043 seconds for one epoch ---
--- 0.3196370601654053 seconds for one epoch ---
--- 1.1214697360992432 seconds for one epoch ---
--- 0.3334188461303711 seconds for one epoch ---
--- 1.1206879615783691 seconds for one epoch ---
--- 0.31842708587646484 seconds for one epoch ---
--- 1.1275792121887207 seconds for one epoch ---
--- 0.33989977836608887 seconds for one epoch ---
--- 1.1293847560882568 seconds for one epoch ---
--- 0.3276054859161377 seconds for one epoch ---
--- 1.135044813156128 seconds for one epoch ---
--- 0.32418155670166016 seconds for one epoch ---
--- 1.124591588973999 seconds for one epoch ---
--- 0.3272736072540283 seconds for one epoch ---
--- 1.1255066394805908 seconds for one epoch ---
--- 0.33524417877197266 seconds for one epoch ---
--- 1.144202470779419 seconds for one epoch ---
--- 0.3269684314727783 seconds for one epoch ---
--- 1.1616339683532715 seconds for one epoch ---
--- 0.32318711280822754 seconds for one epoch ---
--- 1.1210455894470215 seconds for one epoch ---
--- 0.26734089851379395 seconds for one epoch ---
--- 1.1260805130004883 seconds for one epoch ---
--- 0.2799062728881836 seconds for one epoch ---
=========================
[[0.9999995 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997777]
 [0.        ]]
[[-6.63922  ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.0070047]
 [ 0.       ]]
--- 0.25071001052856445 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3540.150146484375, (1361.1505, 0.73974854, 2177.7317, 0.52798575)
   validation loss 882.9956665039062, (610.4839, 0.26516876, 271.71854, 0.52798575)
decoder loss ratio: 23651.205618, decoder SINDy loss  ratio: 0.586543
--- 0.2942326068878174 seconds for one epoch ---
--- 1.0986261367797852 seconds for one epoch ---
--- 0.3051295280456543 seconds for one epoch ---
--- 1.1328353881835938 seconds for one epoch ---
--- 0.28040218353271484 seconds for one epoch ---
--- 1.1457929611206055 seconds for one epoch ---
--- 0.2912461757659912 seconds for one epoch ---
--- 1.1458091735839844 seconds for one epoch ---
--- 0.29482126235961914 seconds for one epoch ---
--- 1.1475131511688232 seconds for one epoch ---
--- 0.3009922504425049 seconds for one epoch ---
--- 1.1328697204589844 seconds for one epoch ---
--- 0.287020206451416 seconds for one epoch ---
--- 1.132305383682251 seconds for one epoch ---
--- 0.2940177917480469 seconds for one epoch ---
--- 1.1362535953521729 seconds for one epoch ---
--- 0.2943997383117676 seconds for one epoch ---
--- 1.131589651107788 seconds for one epoch ---
--- 0.28805017471313477 seconds for one epoch ---
--- 1.1187951564788818 seconds for one epoch ---
--- 0.281388521194458 seconds for one epoch ---
--- 1.1558408737182617 seconds for one epoch ---
--- 0.29541015625 seconds for one epoch ---
--- 1.147001028060913 seconds for one epoch ---
=========================
[[0.9999995]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999752]
 [0.       ]]
[[-6.781929]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-4.923211]
 [-0.      ]]
--- 0.30553722381591797 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3285.34521484375, (1501.2914, 0.26317236, 1783.2618, 0.52870154)
   validation loss 959.89990234375, (668.8677, 0.3310502, 290.17252, 0.52870154)
decoder loss ratio: 25913.094965, decoder SINDy loss  ratio: 0.626378
--- 0.2738938331604004 seconds for one epoch ---
--- 0.319720983505249 seconds for one epoch ---
--- 1.1542978286743164 seconds for one epoch ---
--- 0.2984437942504883 seconds for one epoch ---
--- 1.1530160903930664 seconds for one epoch ---
--- 0.30588293075561523 seconds for one epoch ---
--- 1.1418383121490479 seconds for one epoch ---
--- 0.334430456161499 seconds for one epoch ---
--- 1.139211654663086 seconds for one epoch ---
--- 0.317795991897583 seconds for one epoch ---
--- 1.1657805442810059 seconds for one epoch ---
--- 0.3287928104400635 seconds for one epoch ---
--- 1.1722078323364258 seconds for one epoch ---
--- 0.33995556831359863 seconds for one epoch ---
--- 1.140350341796875 seconds for one epoch ---
--- 0.3344590663909912 seconds for one epoch ---
--- 1.1509075164794922 seconds for one epoch ---
--- 0.33835673332214355 seconds for one epoch ---
--- 1.1631639003753662 seconds for one epoch ---
--- 0.3244295120239258 seconds for one epoch ---
--- 1.1679158210754395 seconds for one epoch ---
--- 0.2963540554046631 seconds for one epoch ---
--- 1.1543033123016357 seconds for one epoch ---
--- 0.29082632064819336 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99996233]
 [0.        ]]
[[-6.913009]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.833052]
 [-0.      ]]
--- 0.24974799156188965 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2363.275390625, (901.3152, 9.057977, 1452.3729, 0.5293231)
   validation loss 772.0932006835938, (506.44516, 0.34692654, 264.77182, 0.5293231)
decoder loss ratio: 19620.564722, decoder SINDy loss  ratio: 0.571547
--- 0.28914666175842285 seconds for one epoch ---
--- 1.1226606369018555 seconds for one epoch ---
--- 0.2784874439239502 seconds for one epoch ---
--- 1.1546573638916016 seconds for one epoch ---
--- 0.27863645553588867 seconds for one epoch ---
--- 1.134519338607788 seconds for one epoch ---
--- 0.29530954360961914 seconds for one epoch ---
--- 1.1515843868255615 seconds for one epoch ---
--- 0.2802543640136719 seconds for one epoch ---
--- 1.1559429168701172 seconds for one epoch ---
--- 0.30190277099609375 seconds for one epoch ---
--- 1.169755220413208 seconds for one epoch ---
--- 0.30384182929992676 seconds for one epoch ---
--- 1.1870818138122559 seconds for one epoch ---
--- 0.2955019474029541 seconds for one epoch ---
--- 1.15513014793396 seconds for one epoch ---
--- 0.29407238960266113 seconds for one epoch ---
--- 1.1796252727508545 seconds for one epoch ---
--- 0.2939183712005615 seconds for one epoch ---
--- 1.1635534763336182 seconds for one epoch ---
--- 0.29584217071533203 seconds for one epoch ---
--- 1.1425068378448486 seconds for one epoch ---
--- 0.2795126438140869 seconds for one epoch ---
--- 1.1878314018249512 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995345]
 [0.        ]]
[[-7.0388503]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.7504454]
 [ 0.       ]]
--- 0.2922852039337158 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3641.014404296875, (1391.943, 0.4604451, 2248.081, 0.5299839)
   validation loss 946.0457763671875, (667.3106, 0.4008496, 277.80432, 0.5299839)
decoder loss ratio: 25852.771453, decoder SINDy loss  ratio: 0.599680
--- 0.25921130180358887 seconds for one epoch ---
--- 0.2906620502471924 seconds for one epoch ---
--- 1.1561896800994873 seconds for one epoch ---
--- 0.3075747489929199 seconds for one epoch ---
--- 1.1468517780303955 seconds for one epoch ---
--- 0.283766508102417 seconds for one epoch ---
--- 1.1693401336669922 seconds for one epoch ---
--- 0.28867411613464355 seconds for one epoch ---
--- 1.1776957511901855 seconds for one epoch ---
--- 0.28400301933288574 seconds for one epoch ---
--- 1.1774704456329346 seconds for one epoch ---
--- 0.2865266799926758 seconds for one epoch ---
--- 1.1852681636810303 seconds for one epoch ---
--- 0.29723215103149414 seconds for one epoch ---
--- 1.1594035625457764 seconds for one epoch ---
--- 0.29471325874328613 seconds for one epoch ---
--- 1.175929307937622 seconds for one epoch ---
--- 0.2995293140411377 seconds for one epoch ---
--- 1.1776294708251953 seconds for one epoch ---
--- 0.29216980934143066 seconds for one epoch ---
--- 1.156916856765747 seconds for one epoch ---
--- 0.2841513156890869 seconds for one epoch ---
--- 1.1693968772888184 seconds for one epoch ---
--- 0.29760289192199707 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999411]
 [0.       ]]
[[-7.1613197]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.662225 ]
 [ 0.       ]]
--- 0.2546713352203369 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4188.4130859375, (2131.3162, 2.1976483, 2054.3684, 0.5305714)
   validation loss 3005.583984375, (2581.6726, 0.29893997, 423.08197, 0.5305714)
decoder loss ratio: 100018.478792, decoder SINDy loss  ratio: 0.913282
--- 0.2922656536102295 seconds for one epoch ---
--- 1.1576578617095947 seconds for one epoch ---
--- 0.2898402214050293 seconds for one epoch ---
--- 1.1642298698425293 seconds for one epoch ---
--- 0.28522777557373047 seconds for one epoch ---
--- 1.1534063816070557 seconds for one epoch ---
--- 0.2925596237182617 seconds for one epoch ---
--- 1.1789817810058594 seconds for one epoch ---
--- 0.29003071784973145 seconds for one epoch ---
--- 1.1756093502044678 seconds for one epoch ---
--- 0.29798054695129395 seconds for one epoch ---
--- 1.169161081314087 seconds for one epoch ---
--- 0.3058500289916992 seconds for one epoch ---
--- 1.1952497959136963 seconds for one epoch ---
--- 0.313493013381958 seconds for one epoch ---
--- 1.1751837730407715 seconds for one epoch ---
--- 0.2902858257293701 seconds for one epoch ---
--- 1.2101187705993652 seconds for one epoch ---
--- 0.32356786727905273 seconds for one epoch ---
--- 1.196350336074829 seconds for one epoch ---
--- 0.318464994430542 seconds for one epoch ---
--- 1.1780810356140137 seconds for one epoch ---
--- 0.32799839973449707 seconds for one epoch ---
--- 1.2081472873687744 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99992394]
 [0.        ]]
[[-7.273093 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.5792794]
 [-0.       ]]
--- 0.30730319023132324 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3180.966552734375, (1665.4775, 0.44570184, 1514.5123, 0.5310493)
   validation loss 1308.874267578125, (997.52826, 0.30161023, 310.51334, 0.5310493)
decoder loss ratio: 38645.976550, decoder SINDy loss  ratio: 0.670287
--- 0.27876758575439453 seconds for one epoch ---
--- 0.30648350715637207 seconds for one epoch ---
--- 1.2016754150390625 seconds for one epoch ---
--- 0.30716490745544434 seconds for one epoch ---
--- 1.1794211864471436 seconds for one epoch ---
--- 0.32145214080810547 seconds for one epoch ---
--- 1.1932010650634766 seconds for one epoch ---
--- 0.3227198123931885 seconds for one epoch ---
--- 1.1697254180908203 seconds for one epoch ---
--- 0.3342723846435547 seconds for one epoch ---
--- 1.1980764865875244 seconds for one epoch ---
--- 0.32314348220825195 seconds for one epoch ---
--- 1.2007300853729248 seconds for one epoch ---
--- 0.3237156867980957 seconds for one epoch ---
--- 1.180403709411621 seconds for one epoch ---
--- 0.31755828857421875 seconds for one epoch ---
--- 1.200725793838501 seconds for one epoch ---
--- 0.32698678970336914 seconds for one epoch ---
--- 1.2204523086547852 seconds for one epoch ---
--- 0.3287041187286377 seconds for one epoch ---
--- 1.1784029006958008 seconds for one epoch ---
--- 0.3267357349395752 seconds for one epoch ---
--- 1.2155590057373047 seconds for one epoch ---
--- 0.3218977451324463 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999018]
 [0.       ]]
[[-7.3725758]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.498529 ]
 [-0.       ]]
--- 0.25556302070617676 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2720.344482421875, (1092.1653, 0.82018805, 1626.8274, 0.5314813)
   validation loss 828.7015380859375, (566.2377, 0.38103387, 261.5513, 0.5314813)
decoder loss ratio: 21937.030402, decoder SINDy loss  ratio: 0.564595
--- 0.2892770767211914 seconds for one epoch ---
--- 1.2150707244873047 seconds for one epoch ---
--- 0.299497127532959 seconds for one epoch ---
--- 1.192131757736206 seconds for one epoch ---
--- 0.296128511428833 seconds for one epoch ---
--- 1.1934762001037598 seconds for one epoch ---
--- 0.2931396961212158 seconds for one epoch ---
--- 1.203942060470581 seconds for one epoch ---
--- 0.2963440418243408 seconds for one epoch ---
--- 1.2005805969238281 seconds for one epoch ---
--- 0.300368070602417 seconds for one epoch ---
--- 1.1643311977386475 seconds for one epoch ---
--- 0.29032254219055176 seconds for one epoch ---
--- 1.2236201763153076 seconds for one epoch ---
--- 0.3297555446624756 seconds for one epoch ---
--- 1.1861474514007568 seconds for one epoch ---
--- 0.32251787185668945 seconds for one epoch ---
--- 1.2103478908538818 seconds for one epoch ---
--- 0.33030128479003906 seconds for one epoch ---
--- 1.2155718803405762 seconds for one epoch ---
--- 0.3122737407684326 seconds for one epoch ---
--- 1.1887109279632568 seconds for one epoch ---
--- 0.32164931297302246 seconds for one epoch ---
--- 1.2474122047424316 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99987745]
 [0.        ]]
[[-7.4574986]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.421053 ]
 [ 0.       ]]
--- 0.295727014541626 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3103.780517578125, (956.4563, 2.1833584, 2144.6094, 0.5315806)
   validation loss 901.1244506835938, (626.6199, 0.55119306, 273.42178, 0.5315806)
decoder loss ratio: 24276.341742, decoder SINDy loss  ratio: 0.590219
THRESHOLDING: 2 active coefficients
--- 1.1864275932312012 seconds for one epoch ---
--- 0.29840755462646484 seconds for one epoch ---
--- 1.2067124843597412 seconds for one epoch ---
--- 0.286998987197876 seconds for one epoch ---
--- 1.1974232196807861 seconds for one epoch ---
--- 0.2999837398529053 seconds for one epoch ---
--- 1.2178549766540527 seconds for one epoch ---
--- 0.27910661697387695 seconds for one epoch ---
--- 1.2048048973083496 seconds for one epoch ---
--- 0.2953059673309326 seconds for one epoch ---
--- 1.2157437801361084 seconds for one epoch ---
--- 0.3000171184539795 seconds for one epoch ---
--- 1.211369514465332 seconds for one epoch ---
--- 0.29378390312194824 seconds for one epoch ---
--- 1.1922545433044434 seconds for one epoch ---
--- 0.29015254974365234 seconds for one epoch ---
--- 1.1753559112548828 seconds for one epoch ---
--- 0.2973301410675049 seconds for one epoch ---
--- 1.2039484977722168 seconds for one epoch ---
--- 0.3006291389465332 seconds for one epoch ---
--- 1.2284927368164062 seconds for one epoch ---
--- 0.29369664192199707 seconds for one epoch ---
--- 1.2225210666656494 seconds for one epoch ---
--- 0.2774841785430908 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99983656]
 [0.        ]]
[[-7.5392685]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.332953 ]
 [ 0.       ]]
--- 0.26364731788635254 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2569.414794921875, (1093.2914, 0.50474596, 1475.1033, 0.5153552)
   validation loss 1396.16748046875, (1093.0719, 0.47498968, 302.10516, 0.5153552)
decoder loss ratio: 42347.503040, decoder SINDy loss  ratio: 0.652136
--- 0.29199814796447754 seconds for one epoch ---
--- 1.2362136840820312 seconds for one epoch ---
--- 0.3017253875732422 seconds for one epoch ---
--- 1.2367873191833496 seconds for one epoch ---
--- 0.2931549549102783 seconds for one epoch ---
--- 1.2540802955627441 seconds for one epoch ---
--- 0.29613184928894043 seconds for one epoch ---
--- 1.2171175479888916 seconds for one epoch ---
--- 0.31053805351257324 seconds for one epoch ---
--- 1.2275416851043701 seconds for one epoch ---
--- 0.3020284175872803 seconds for one epoch ---
--- 1.2372033596038818 seconds for one epoch ---
--- 0.3265194892883301 seconds for one epoch ---
--- 1.2612087726593018 seconds for one epoch ---
--- 0.3260371685028076 seconds for one epoch ---
--- 1.261728048324585 seconds for one epoch ---
--- 0.3243875503540039 seconds for one epoch ---
--- 1.2668719291687012 seconds for one epoch ---
--- 0.3414454460144043 seconds for one epoch ---
--- 1.2524046897888184 seconds for one epoch ---
--- 0.3372023105621338 seconds for one epoch ---
--- 1.244342565536499 seconds for one epoch ---
--- 0.32651257514953613 seconds for one epoch ---
--- 1.2198894023895264 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99979323]
 [0.        ]]
[[-7.6176963]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.2554083]
 [-0.       ]]
--- 0.297015905380249 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3296.33154296875, (1565.0719, 1.1107028, 1729.6334, 0.5156738)
   validation loss 888.7943115234375, (621.20056, 0.42698768, 266.65106, 0.5156738)
decoder loss ratio: 24066.388205, decoder SINDy loss  ratio: 0.575604
--- 0.2592966556549072 seconds for one epoch ---
--- 0.3348267078399658 seconds for one epoch ---
--- 1.2603650093078613 seconds for one epoch ---
--- 0.3429720401763916 seconds for one epoch ---
--- 1.2668652534484863 seconds for one epoch ---
--- 0.34067368507385254 seconds for one epoch ---
--- 1.232597827911377 seconds for one epoch ---
--- 0.32378363609313965 seconds for one epoch ---
--- 1.2263765335083008 seconds for one epoch ---
--- 0.3314683437347412 seconds for one epoch ---
--- 1.2222323417663574 seconds for one epoch ---
--- 0.3272888660430908 seconds for one epoch ---
--- 1.2464301586151123 seconds for one epoch ---
--- 0.31385302543640137 seconds for one epoch ---
--- 1.247692346572876 seconds for one epoch ---
--- 0.3177347183227539 seconds for one epoch ---
--- 1.275352954864502 seconds for one epoch ---
--- 0.3188440799713135 seconds for one epoch ---
--- 1.253124713897705 seconds for one epoch ---
--- 0.3148612976074219 seconds for one epoch ---
--- 1.260498046875 seconds for one epoch ---
--- 0.3253962993621826 seconds for one epoch ---
--- 1.2286770343780518 seconds for one epoch ---
--- 0.29874587059020996 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99971604]
 [0.        ]]
[[-7.680199 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.1567664]
 [-0.       ]]
--- 0.24922561645507812 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2819.24853515625, (1214.181, 1.5236765, 1603.0283, 0.51574)
   validation loss 741.9376220703125, (474.8975, 0.42761713, 266.0968, 0.51574)
decoder loss ratio: 18398.353277, decoder SINDy loss  ratio: 0.574407
--- 0.2875051498413086 seconds for one epoch ---
--- 1.2329516410827637 seconds for one epoch ---
--- 0.31139707565307617 seconds for one epoch ---
--- 1.244095802307129 seconds for one epoch ---
--- 0.3032345771789551 seconds for one epoch ---
--- 1.2471208572387695 seconds for one epoch ---
--- 0.31546950340270996 seconds for one epoch ---
--- 1.238935947418213 seconds for one epoch ---
--- 0.3100547790527344 seconds for one epoch ---
--- 1.2487294673919678 seconds for one epoch ---
--- 0.28746795654296875 seconds for one epoch ---
--- 1.2649462223052979 seconds for one epoch ---
--- 0.30129504203796387 seconds for one epoch ---
--- 1.2385046482086182 seconds for one epoch ---
--- 0.2935450077056885 seconds for one epoch ---
--- 1.2697136402130127 seconds for one epoch ---
--- 0.2825756072998047 seconds for one epoch ---
--- 1.2553319931030273 seconds for one epoch ---
--- 0.29582738876342773 seconds for one epoch ---
--- 1.2760989665985107 seconds for one epoch ---
--- 0.2767043113708496 seconds for one epoch ---
--- 1.2338762283325195 seconds for one epoch ---
--- 0.30095410346984863 seconds for one epoch ---
--- 1.2413513660430908 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99962085]
 [0.        ]]
[[-7.740531 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0641446]
 [ 0.       ]]
--- 0.2857625484466553 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3258.261474609375, (1178.53, 1.6649975, 2077.5505, 0.5158194)
   validation loss 1263.636474609375, (969.53656, 0.46268925, 293.1214, 0.5158194)
decoder loss ratio: 37561.529526, decoder SINDy loss  ratio: 0.632744
--- 0.25238585472106934 seconds for one epoch ---
--- 0.2901725769042969 seconds for one epoch ---
--- 1.2613534927368164 seconds for one epoch ---
--- 0.29596805572509766 seconds for one epoch ---
--- 1.276012659072876 seconds for one epoch ---
--- 0.29488158226013184 seconds for one epoch ---
--- 1.2457361221313477 seconds for one epoch ---
--- 0.29876160621643066 seconds for one epoch ---
--- 1.2786822319030762 seconds for one epoch ---
--- 0.29487109184265137 seconds for one epoch ---
--- 1.2975351810455322 seconds for one epoch ---
--- 0.293010950088501 seconds for one epoch ---
--- 1.2868156433105469 seconds for one epoch ---
--- 0.2693462371826172 seconds for one epoch ---
--- 1.2811017036437988 seconds for one epoch ---
--- 0.29878783226013184 seconds for one epoch ---
--- 1.2824666500091553 seconds for one epoch ---
--- 0.2989804744720459 seconds for one epoch ---
--- 1.281583309173584 seconds for one epoch ---
--- 0.29715657234191895 seconds for one epoch ---
--- 1.2516798973083496 seconds for one epoch ---
--- 0.29831790924072266 seconds for one epoch ---
--- 1.2975904941558838 seconds for one epoch ---
--- 0.318850040435791 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949515]
 [0.        ]]
[[-7.8050923]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.9746518]
 [ 0.       ]]
--- 0.2572503089904785 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2110.22900390625, (1198.0736, 0.45382392, 911.1855, 0.5160969)
   validation loss 700.27197265625, (439.04126, 0.43353915, 260.28107, 0.5160969)
decoder loss ratio: 17009.220612, decoder SINDy loss  ratio: 0.561853
--- 0.29933929443359375 seconds for one epoch ---
--- 1.2744231224060059 seconds for one epoch ---
--- 0.30877184867858887 seconds for one epoch ---
--- 1.253713846206665 seconds for one epoch ---
--- 0.31312060356140137 seconds for one epoch ---
--- 1.2772393226623535 seconds for one epoch ---
--- 0.32316088676452637 seconds for one epoch ---
--- 1.2643425464630127 seconds for one epoch ---
--- 0.3084547519683838 seconds for one epoch ---
--- 1.3066606521606445 seconds for one epoch ---
--- 0.2965071201324463 seconds for one epoch ---
--- 1.2581086158752441 seconds for one epoch ---
--- 0.2999391555786133 seconds for one epoch ---
--- 1.2630839347839355 seconds for one epoch ---
--- 0.3079969882965088 seconds for one epoch ---
--- 1.2745509147644043 seconds for one epoch ---
--- 0.3014986515045166 seconds for one epoch ---
--- 1.2735176086425781 seconds for one epoch ---
--- 0.28641414642333984 seconds for one epoch ---
--- 1.2831141948699951 seconds for one epoch ---
--- 0.2910892963409424 seconds for one epoch ---
--- 1.2800593376159668 seconds for one epoch ---
--- 0.29999542236328125 seconds for one epoch ---
--- 1.281585931777954 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993235]
 [0.       ]]
[[-7.869561 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.8822498]
 [-0.       ]]
--- 0.29296040534973145 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2333.220703125, (1272.7555, 0.34650782, 1059.6023, 0.51626974)
   validation loss 912.5376586914062, (632.8127, 0.341254, 278.86746, 0.51626974)
decoder loss ratio: 24516.261955, decoder SINDy loss  ratio: 0.601975
--- 0.2411808967590332 seconds for one epoch ---
--- 0.2897329330444336 seconds for one epoch ---
--- 1.2758853435516357 seconds for one epoch ---
--- 0.2888813018798828 seconds for one epoch ---
--- 1.2809484004974365 seconds for one epoch ---
--- 0.28549790382385254 seconds for one epoch ---
--- 1.3008053302764893 seconds for one epoch ---
--- 0.3008859157562256 seconds for one epoch ---
--- 1.2888669967651367 seconds for one epoch ---
--- 0.28940629959106445 seconds for one epoch ---
--- 1.2972075939178467 seconds for one epoch ---
--- 0.29062700271606445 seconds for one epoch ---
--- 1.3021464347839355 seconds for one epoch ---
--- 0.2874782085418701 seconds for one epoch ---
--- 1.2723119258880615 seconds for one epoch ---
--- 0.27610349655151367 seconds for one epoch ---
--- 1.3210952281951904 seconds for one epoch ---
--- 0.2899799346923828 seconds for one epoch ---
--- 1.3021390438079834 seconds for one epoch ---
--- 0.31085968017578125 seconds for one epoch ---
--- 1.3063361644744873 seconds for one epoch ---
--- 0.28859853744506836 seconds for one epoch ---
--- 1.3518750667572021 seconds for one epoch ---
--- 0.2910022735595703 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990994]
 [0.       ]]
[[-7.9146943]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.7919562]
 [-0.       ]]
--- 0.24281597137451172 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2676.724609375, (1177.9893, 2.352735, 1495.8662, 0.51628846)
   validation loss 836.5367431640625, (554.502, 0.501303, 281.01715, 0.51628846)
decoder loss ratio: 21482.370686, decoder SINDy loss  ratio: 0.606615
--- 0.27740025520324707 seconds for one epoch ---
--- 1.322664499282837 seconds for one epoch ---
--- 0.30486631393432617 seconds for one epoch ---
--- 1.2664334774017334 seconds for one epoch ---
--- 0.28865981101989746 seconds for one epoch ---
--- 1.3221120834350586 seconds for one epoch ---
--- 0.294389009475708 seconds for one epoch ---
--- 1.3189585208892822 seconds for one epoch ---
--- 0.30138707160949707 seconds for one epoch ---
--- 1.3464431762695312 seconds for one epoch ---
--- 0.2808072566986084 seconds for one epoch ---
--- 1.3331236839294434 seconds for one epoch ---
--- 0.29543328285217285 seconds for one epoch ---
--- 1.3358049392700195 seconds for one epoch ---
--- 0.2953510284423828 seconds for one epoch ---
--- 1.3087308406829834 seconds for one epoch ---
--- 0.29370760917663574 seconds for one epoch ---
--- 1.3209834098815918 seconds for one epoch ---
--- 0.28209996223449707 seconds for one epoch ---
--- 1.328582525253296 seconds for one epoch ---
--- 0.30074238777160645 seconds for one epoch ---
--- 1.3381226062774658 seconds for one epoch ---
--- 0.2949700355529785 seconds for one epoch ---
--- 1.3356478214263916 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988218]
 [0.       ]]
[[-7.9740996]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7075663]
 [ 0.       ]]
--- 0.2968308925628662 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3934.2958984375, (1075.3953, 2.758442, 2855.6257, 0.5165175)
   validation loss 1024.44970703125, (713.9646, 0.5407624, 309.4278, 0.5165175)
decoder loss ratio: 27660.228086, decoder SINDy loss  ratio: 0.667943
--- 0.2569589614868164 seconds for one epoch ---
--- 0.2935478687286377 seconds for one epoch ---
--- 1.232818603515625 seconds for one epoch ---
--- 0.3037142753601074 seconds for one epoch ---
--- 1.2931430339813232 seconds for one epoch ---
--- 0.3164985179901123 seconds for one epoch ---
--- 1.3096179962158203 seconds for one epoch ---
--- 0.3041815757751465 seconds for one epoch ---
--- 1.3269400596618652 seconds for one epoch ---
--- 0.3266324996948242 seconds for one epoch ---
--- 1.3242809772491455 seconds for one epoch ---
--- 0.3115699291229248 seconds for one epoch ---
--- 1.3418078422546387 seconds for one epoch ---
--- 0.3257870674133301 seconds for one epoch ---
--- 1.3529391288757324 seconds for one epoch ---
--- 0.3112328052520752 seconds for one epoch ---
--- 1.3324594497680664 seconds for one epoch ---
--- 0.3191080093383789 seconds for one epoch ---
--- 1.32700514793396 seconds for one epoch ---
--- 0.31347203254699707 seconds for one epoch ---
--- 1.3194143772125244 seconds for one epoch ---
--- 0.2947957515716553 seconds for one epoch ---
--- 1.3088531494140625 seconds for one epoch ---
--- 0.2996518611907959 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9984464]
 [0.       ]]
[[-8.019641 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.6204786]
 [ 0.       ]]
--- 0.25663280487060547 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3607.61083984375, (1846.4962, 5.1910114, 1755.4069, 0.5165412)
   validation loss 768.4745483398438, (498.13568, 0.4434892, 269.37885, 0.5165412)
decoder loss ratio: 19298.641089, decoder SINDy loss  ratio: 0.581492
--- 0.290956974029541 seconds for one epoch ---
--- 1.2571985721588135 seconds for one epoch ---
--- 0.3012981414794922 seconds for one epoch ---
--- 1.3103432655334473 seconds for one epoch ---
--- 0.2978379726409912 seconds for one epoch ---
--- 1.3017821311950684 seconds for one epoch ---
--- 0.2894105911254883 seconds for one epoch ---
--- 1.3330085277557373 seconds for one epoch ---
--- 0.28339552879333496 seconds for one epoch ---
--- 1.2936360836029053 seconds for one epoch ---
--- 0.2915918827056885 seconds for one epoch ---
--- 1.3402819633483887 seconds for one epoch ---
--- 0.3002943992614746 seconds for one epoch ---
--- 1.3411827087402344 seconds for one epoch ---
--- 0.2914447784423828 seconds for one epoch ---
--- 1.3229594230651855 seconds for one epoch ---
--- 0.2971625328063965 seconds for one epoch ---
--- 1.312774896621704 seconds for one epoch ---
--- 0.29673004150390625 seconds for one epoch ---
--- 1.3463687896728516 seconds for one epoch ---
--- 0.2931942939758301 seconds for one epoch ---
--- 1.32057523727417 seconds for one epoch ---
--- 0.2819368839263916 seconds for one epoch ---
--- 1.323317289352417 seconds for one epoch ---
=========================
[[1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.997941]
 [0.      ]]
[[-8.0815935]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5321383]
 [-0.       ]]
--- 0.29550838470458984 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3391.196044921875, (1349.5038, 1.9517732, 2039.2236, 0.5168477)
   validation loss 953.8070068359375, (659.86456, 0.5865666, 292.83902, 0.5168477)
decoder loss ratio: 25564.298745, decoder SINDy loss  ratio: 0.632134
--- 0.2656724452972412 seconds for one epoch ---
--- 0.2911808490753174 seconds for one epoch ---
--- 1.313016414642334 seconds for one epoch ---
--- 0.2919430732727051 seconds for one epoch ---
--- 1.321748971939087 seconds for one epoch ---
--- 0.2997114658355713 seconds for one epoch ---
--- 1.332493543624878 seconds for one epoch ---
--- 0.29302334785461426 seconds for one epoch ---
--- 1.3428921699523926 seconds for one epoch ---
--- 0.5431027412414551 seconds for one epoch ---
--- 1.3262157440185547 seconds for one epoch ---
--- 0.28040170669555664 seconds for one epoch ---
--- 1.2971937656402588 seconds for one epoch ---
--- 0.28307080268859863 seconds for one epoch ---
--- 1.3144903182983398 seconds for one epoch ---
--- 0.29799461364746094 seconds for one epoch ---
--- 1.3457272052764893 seconds for one epoch ---
--- 0.2887876033782959 seconds for one epoch ---
--- 1.3396151065826416 seconds for one epoch ---
--- 0.2896153926849365 seconds for one epoch ---
--- 1.3211052417755127 seconds for one epoch ---
--- 0.28528904914855957 seconds for one epoch ---
--- 1.3250041007995605 seconds for one epoch ---
--- 0.29227566719055176 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9973798]
 [0.       ]]
[[-8.134074 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.4564762]
 [-0.       ]]
--- 0.24668216705322266 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7834.1572265625, (1671.215, 4.8901224, 6157.535, 0.51703334)
   validation loss 1496.6549072265625, (1149.2897, 0.46982738, 346.37833, 0.51703334)
decoder loss ratio: 44525.477181, decoder SINDy loss  ratio: 0.747706
--- 0.2910737991333008 seconds for one epoch ---
--- 1.2947967052459717 seconds for one epoch ---
--- 0.29712557792663574 seconds for one epoch ---
--- 1.2953226566314697 seconds for one epoch ---
--- 0.30144333839416504 seconds for one epoch ---
--- 1.366269826889038 seconds for one epoch ---
--- 0.30048584938049316 seconds for one epoch ---
--- 1.3771519660949707 seconds for one epoch ---
--- 0.2953824996948242 seconds for one epoch ---
--- 1.3539202213287354 seconds for one epoch ---
--- 0.297696590423584 seconds for one epoch ---
--- 1.3652377128601074 seconds for one epoch ---
--- 0.2966301441192627 seconds for one epoch ---
--- 1.3686695098876953 seconds for one epoch ---
--- 0.3277883529663086 seconds for one epoch ---
--- 1.3762800693511963 seconds for one epoch ---
--- 0.32868266105651855 seconds for one epoch ---
--- 1.3473730087280273 seconds for one epoch ---
--- 0.3257880210876465 seconds for one epoch ---
--- 1.3954572677612305 seconds for one epoch ---
--- 0.32510972023010254 seconds for one epoch ---
--- 1.3516998291015625 seconds for one epoch ---
--- 0.3283059597015381 seconds for one epoch ---
--- 1.347902774810791 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99657035]
 [0.        ]]
[[-8.173203 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-3.3719597]
 [ 0.       ]]
--- 0.3002433776855469 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4831.35302734375, (1794.3003, 1.6724616, 3034.863, 0.5170378)
   validation loss 1014.3585205078125, (742.8305, 0.40444648, 270.60657, 0.5170378)
decoder loss ratio: 28778.543389, decoder SINDy loss  ratio: 0.584142
--- 0.25488734245300293 seconds for one epoch ---
--- 0.31165409088134766 seconds for one epoch ---
--- 1.3192429542541504 seconds for one epoch ---
--- 0.2890493869781494 seconds for one epoch ---
--- 1.2957062721252441 seconds for one epoch ---
--- 0.292982816696167 seconds for one epoch ---
--- 1.351557970046997 seconds for one epoch ---
--- 0.29775309562683105 seconds for one epoch ---
--- 1.3474066257476807 seconds for one epoch ---
--- 0.29276251792907715 seconds for one epoch ---
--- 1.3497934341430664 seconds for one epoch ---
--- 0.2914924621582031 seconds for one epoch ---
--- 1.3531837463378906 seconds for one epoch ---
--- 0.2984504699707031 seconds for one epoch ---
--- 1.3598482608795166 seconds for one epoch ---
--- 0.2943699359893799 seconds for one epoch ---
--- 1.366621732711792 seconds for one epoch ---
--- 0.2922937870025635 seconds for one epoch ---
--- 1.371211290359497 seconds for one epoch ---
--- 0.2879064083099365 seconds for one epoch ---
--- 1.3705692291259766 seconds for one epoch ---
--- 0.28292226791381836 seconds for one epoch ---
--- 1.374225378036499 seconds for one epoch ---
--- 0.29518914222717285 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9954276]
 [0.       ]]
[[-8.214047]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-3.281794]
 [ 0.      ]]
--- 0.2530405521392822 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3101.87109375, (1152.7192, 9.753452, 1938.8813, 0.51699704)
   validation loss 1367.623046875, (1019.9525, 0.63267285, 346.52084, 0.51699704)
decoder loss ratio: 39514.731133, decoder SINDy loss  ratio: 0.748014
--- 0.29392266273498535 seconds for one epoch ---
--- 1.353804111480713 seconds for one epoch ---
--- 0.2936527729034424 seconds for one epoch ---
--- 1.334573745727539 seconds for one epoch ---
--- 0.29622912406921387 seconds for one epoch ---
--- 1.36264967918396 seconds for one epoch ---
--- 0.2928290367126465 seconds for one epoch ---
--- 1.362410068511963 seconds for one epoch ---
--- 0.29299497604370117 seconds for one epoch ---
--- 1.385791540145874 seconds for one epoch ---
--- 0.3122730255126953 seconds for one epoch ---
--- 1.37382173538208 seconds for one epoch ---
--- 0.29271626472473145 seconds for one epoch ---
--- 1.3704020977020264 seconds for one epoch ---
--- 0.28931331634521484 seconds for one epoch ---
--- 1.386277198791504 seconds for one epoch ---
--- 0.3003971576690674 seconds for one epoch ---
--- 1.3977088928222656 seconds for one epoch ---
--- 0.2825310230255127 seconds for one epoch ---
--- 1.3758046627044678 seconds for one epoch ---
--- 0.29419493675231934 seconds for one epoch ---
--- 1.3596289157867432 seconds for one epoch ---
--- 0.2966752052307129 seconds for one epoch ---
--- 1.3925247192382812 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9943907]
 [0.       ]]
[[-8.263363 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-3.2176144]
 [-0.       ]]
--- 0.2965049743652344 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3004.239990234375, (1155.4447, 3.0782297, 1845.1997, 0.51723015)
   validation loss 894.2235107421875, (605.7328, 0.38413355, 287.58932, 0.51723015)
decoder loss ratio: 23467.139809, decoder SINDy loss  ratio: 0.620802
--- 0.26177453994750977 seconds for one epoch ---
--- 0.30687499046325684 seconds for one epoch ---
--- 1.3584623336791992 seconds for one epoch ---
--- 0.2922534942626953 seconds for one epoch ---
--- 1.3268976211547852 seconds for one epoch ---
--- 0.28118896484375 seconds for one epoch ---
--- 1.3321020603179932 seconds for one epoch ---
--- 0.2967493534088135 seconds for one epoch ---
--- 1.40799880027771 seconds for one epoch ---
--- 0.31727051734924316 seconds for one epoch ---
--- 1.3899204730987549 seconds for one epoch ---
--- 0.33687925338745117 seconds for one epoch ---
--- 1.3968429565429688 seconds for one epoch ---
--- 0.32600831985473633 seconds for one epoch ---
--- 1.3907415866851807 seconds for one epoch ---
--- 0.34838199615478516 seconds for one epoch ---
--- 1.3966352939605713 seconds for one epoch ---
--- 0.3374457359313965 seconds for one epoch ---
--- 1.394188642501831 seconds for one epoch ---
--- 0.33135485649108887 seconds for one epoch ---
--- 1.4034173488616943 seconds for one epoch ---
--- 0.3348257541656494 seconds for one epoch ---
--- 1.384963035583496 seconds for one epoch ---
--- 0.3223133087158203 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9928361]
 [0.       ]]
[[-8.308839 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.1408625]
 [-0.       ]]
--- 0.2585029602050781 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2225.338623046875, (1127.8617, 0.27447388, 1096.6852, 0.5173516)
   validation loss 776.7685546875, (505.4506, 0.45660928, 270.344, 0.5173516)
decoder loss ratio: 19582.033436, decoder SINDy loss  ratio: 0.583576
--- 0.2944343090057373 seconds for one epoch ---
--- 1.4002089500427246 seconds for one epoch ---
--- 0.28779029846191406 seconds for one epoch ---
--- 1.3671162128448486 seconds for one epoch ---
--- 0.29056596755981445 seconds for one epoch ---
--- 1.3626105785369873 seconds for one epoch ---
--- 0.2814195156097412 seconds for one epoch ---
--- 1.402820110321045 seconds for one epoch ---
--- 0.31049537658691406 seconds for one epoch ---
--- 1.3961517810821533 seconds for one epoch ---
--- 0.32659292221069336 seconds for one epoch ---
--- 1.3992481231689453 seconds for one epoch ---
--- 0.33254265785217285 seconds for one epoch ---
--- 1.3786840438842773 seconds for one epoch ---
--- 0.3274693489074707 seconds for one epoch ---
--- 1.4020841121673584 seconds for one epoch ---
--- 0.31031131744384766 seconds for one epoch ---
--- 1.3876235485076904 seconds for one epoch ---
--- 0.3141775131225586 seconds for one epoch ---
--- 1.4233441352844238 seconds for one epoch ---
--- 0.3233211040496826 seconds for one epoch ---
--- 1.3812932968139648 seconds for one epoch ---
--- 0.3002510070800781 seconds for one epoch ---
--- 1.423438310623169 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99124885]
 [0.        ]]
[[-8.356775 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0779712]
 [ 0.       ]]
--- 0.28804922103881836 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3844.030029296875, (1239.9414, 6.8054185, 2596.7656, 0.51749927)
   validation loss 853.353759765625, (575.62146, 0.5372849, 276.6775, 0.51749927)
decoder loss ratio: 22300.574682, decoder SINDy loss  ratio: 0.597247
--- 0.2577683925628662 seconds for one epoch ---
--- 0.29477882385253906 seconds for one epoch ---
--- 1.4070146083831787 seconds for one epoch ---
--- 0.3046126365661621 seconds for one epoch ---
--- 1.3462083339691162 seconds for one epoch ---
--- 0.29254150390625 seconds for one epoch ---
--- 1.3549611568450928 seconds for one epoch ---
--- 0.28117942810058594 seconds for one epoch ---
--- 1.3647561073303223 seconds for one epoch ---
--- 0.2951526641845703 seconds for one epoch ---
--- 1.400777816772461 seconds for one epoch ---
--- 0.2881600856781006 seconds for one epoch ---
--- 1.4034526348114014 seconds for one epoch ---
--- 0.29863786697387695 seconds for one epoch ---
--- 1.4417293071746826 seconds for one epoch ---
--- 0.290102481842041 seconds for one epoch ---
--- 1.3914999961853027 seconds for one epoch ---
--- 0.3019545078277588 seconds for one epoch ---
--- 1.4320850372314453 seconds for one epoch ---
--- 0.2919011116027832 seconds for one epoch ---
--- 1.4374396800994873 seconds for one epoch ---
--- 0.29377245903015137 seconds for one epoch ---
--- 1.4314134120941162 seconds for one epoch ---
--- 0.2893640995025635 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9885527]
 [0.       ]]
[[-8.386945]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-2.993516]
 [ 0.      ]]
--- 0.24953794479370117 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2468.237548828125, (1114.5065, 2.2474053, 1350.9664, 0.51735765)
   validation loss 1232.928955078125, (914.29974, 0.45150048, 317.66046, 0.51735765)
decoder loss ratio: 35421.559363, decoder SINDy loss  ratio: 0.685715
--- 0.28946375846862793 seconds for one epoch ---
--- 1.4099278450012207 seconds for one epoch ---
--- 0.3026008605957031 seconds for one epoch ---
--- 1.3972361087799072 seconds for one epoch ---
--- 0.29192304611206055 seconds for one epoch ---
--- 1.3694374561309814 seconds for one epoch ---
--- 0.29819536209106445 seconds for one epoch ---
--- 1.4009745121002197 seconds for one epoch ---
--- 0.29708385467529297 seconds for one epoch ---
--- 1.4190325736999512 seconds for one epoch ---
--- 0.28034043312072754 seconds for one epoch ---
--- 1.414196491241455 seconds for one epoch ---
--- 0.29424357414245605 seconds for one epoch ---
--- 1.4218707084655762 seconds for one epoch ---
--- 0.2844054698944092 seconds for one epoch ---
--- 1.425097942352295 seconds for one epoch ---
--- 0.29002904891967773 seconds for one epoch ---
--- 1.4403631687164307 seconds for one epoch ---
--- 0.29247498512268066 seconds for one epoch ---
--- 1.435460090637207 seconds for one epoch ---
--- 0.28037190437316895 seconds for one epoch ---
--- 1.4303147792816162 seconds for one epoch ---
--- 0.29081106185913086 seconds for one epoch ---
--- 1.4314534664154053 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98519707]
 [0.        ]]
[[-8.412743 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.9124982]
 [-0.       ]]
--- 0.2887403964996338 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1914.8875732421875, (1022.83417, 1.896088, 889.6403, 0.5170111)
   validation loss 977.5253295898438, (646.48535, 0.40626788, 330.1167, 0.5170111)
decoder loss ratio: 25045.964867, decoder SINDy loss  ratio: 0.712603
--- 0.24899649620056152 seconds for one epoch ---
--- 0.30124807357788086 seconds for one epoch ---
--- 1.5010459423065186 seconds for one epoch ---
--- 0.27619242668151855 seconds for one epoch ---
--- 1.470841646194458 seconds for one epoch ---
--- 0.17209362983703613 seconds for one epoch ---
--- 1.7117187976837158 seconds for one epoch ---
--- 0.14854717254638672 seconds for one epoch ---
--- 1.7329926490783691 seconds for one epoch ---
--- 0.15549468994140625 seconds for one epoch ---
--- 1.432750940322876 seconds for one epoch ---
--- 0.17751812934875488 seconds for one epoch ---
--- 1.6706697940826416 seconds for one epoch ---
--- 0.15198206901550293 seconds for one epoch ---
--- 1.4606776237487793 seconds for one epoch ---
--- 0.15457987785339355 seconds for one epoch ---
--- 1.6340546607971191 seconds for one epoch ---
--- 0.14910888671875 seconds for one epoch ---
--- 1.5612454414367676 seconds for one epoch ---
--- 0.14924335479736328 seconds for one epoch ---
--- 1.7771143913269043 seconds for one epoch ---
--- 0.15499305725097656 seconds for one epoch ---
--- 1.5113797187805176 seconds for one epoch ---
--- 0.16136384010314941 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98073304]
 [0.        ]]
[[-8.444387]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-2.829205]
 [-0.      ]]
--- 0.14412879943847656 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2426.30224609375, (1233.6804, 0.95595175, 1191.149, 0.516737)
   validation loss 1286.01416015625, (941.6852, 0.5570989, 343.25516, 0.516737)
decoder loss ratio: 36482.518736, decoder SINDy loss  ratio: 0.740965
--- 0.15975570678710938 seconds for one epoch ---
--- 1.3774943351745605 seconds for one epoch ---
--- 0.15034914016723633 seconds for one epoch ---
--- 1.6911695003509521 seconds for one epoch ---
--- 0.2061018943786621 seconds for one epoch ---
--- 1.3860933780670166 seconds for one epoch ---
--- 0.17062854766845703 seconds for one epoch ---
--- 1.6293737888336182 seconds for one epoch ---
--- 0.1497795581817627 seconds for one epoch ---
--- 1.6433076858520508 seconds for one epoch ---
--- 0.15981674194335938 seconds for one epoch ---
--- 1.3937301635742188 seconds for one epoch ---
--- 0.1565852165222168 seconds for one epoch ---
--- 1.5145819187164307 seconds for one epoch ---
--- 0.15861153602600098 seconds for one epoch ---
--- 1.3749797344207764 seconds for one epoch ---
--- 0.18684005737304688 seconds for one epoch ---
--- 1.7351281642913818 seconds for one epoch ---
--- 0.1696174144744873 seconds for one epoch ---
--- 1.4024956226348877 seconds for one epoch ---
--- 0.1817615032196045 seconds for one epoch ---
--- 1.4176301956176758 seconds for one epoch ---
--- 0.19666647911071777 seconds for one epoch ---
--- 1.4421541690826416 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97498375]
 [0.        ]]
[[-8.466875 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.7463248]
 [ 0.       ]]
--- 0.17940688133239746 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4732.61767578125, (1743.443, 0.5284784, 2988.1304, 0.51620686)
   validation loss 772.38818359375, (482.35107, 0.49304676, 289.02786, 0.51620686)
decoder loss ratio: 18687.118014, decoder SINDy loss  ratio: 0.623907
THRESHOLDING: 2 active coefficients
--- 1.3696072101593018 seconds for one epoch ---
--- 0.16698336601257324 seconds for one epoch ---
--- 1.7012479305267334 seconds for one epoch ---
--- 0.17648839950561523 seconds for one epoch ---
--- 1.5218009948730469 seconds for one epoch ---
--- 0.20387649536132812 seconds for one epoch ---
--- 1.4170384407043457 seconds for one epoch ---
--- 0.17124485969543457 seconds for one epoch ---
--- 1.716036081314087 seconds for one epoch ---
--- 0.1516714096069336 seconds for one epoch ---
--- 1.6753790378570557 seconds for one epoch ---
--- 0.1717844009399414 seconds for one epoch ---
--- 1.4052116870880127 seconds for one epoch ---
--- 0.1880810260772705 seconds for one epoch ---
--- 1.512681245803833 seconds for one epoch ---
--- 0.1489405632019043 seconds for one epoch ---
--- 1.6111540794372559 seconds for one epoch ---
--- 0.168853759765625 seconds for one epoch ---
--- 1.401557207107544 seconds for one epoch ---
--- 0.17598581314086914 seconds for one epoch ---
--- 1.4670066833496094 seconds for one epoch ---
--- 0.17426323890686035 seconds for one epoch ---
--- 1.4622247219085693 seconds for one epoch ---
--- 0.1968235969543457 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97027504]
 [0.        ]]
[[-8.492056 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.6913486]
 [ 0.       ]]
--- 0.1757209300994873 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6576.48046875, (1299.1311, 1.4933189, 5275.3403, 0.51578486)
   validation loss 806.3263549804688, (524.6264, 0.5530287, 280.63113, 0.51578486)
decoder loss ratio: 20324.937675, decoder SINDy loss  ratio: 0.605782
--- 0.15308022499084473 seconds for one epoch ---
--- 1.386457920074463 seconds for one epoch ---
--- 0.1978776454925537 seconds for one epoch ---
--- 1.5068371295928955 seconds for one epoch ---
--- 0.1590871810913086 seconds for one epoch ---
--- 1.559133529663086 seconds for one epoch ---
--- 0.18790245056152344 seconds for one epoch ---
--- 1.4288079738616943 seconds for one epoch ---
--- 0.20818567276000977 seconds for one epoch ---
--- 1.3994803428649902 seconds for one epoch ---
--- 0.18100357055664062 seconds for one epoch ---
--- 1.4501380920410156 seconds for one epoch ---
--- 0.16192412376403809 seconds for one epoch ---
--- 1.4312913417816162 seconds for one epoch ---
--- 0.180877685546875 seconds for one epoch ---
--- 1.6827912330627441 seconds for one epoch ---
--- 0.17019891738891602 seconds for one epoch ---
--- 1.5571398735046387 seconds for one epoch ---
--- 0.18609237670898438 seconds for one epoch ---
--- 1.5336601734161377 seconds for one epoch ---
--- 0.21022701263427734 seconds for one epoch ---
--- 1.526080846786499 seconds for one epoch ---
--- 0.18059825897216797 seconds for one epoch ---
--- 1.4752767086029053 seconds for one epoch ---
=========================
[[1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.960695]
 [0.      ]]
[[-8.5063715]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.601715 ]
 [-0.       ]]
--- 0.18479371070861816 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2477.314697265625, (1089.9043, 2.6767673, 1384.219, 0.5147558)
   validation loss 723.5528564453125, (447.05698, 0.5353018, 275.44583, 0.5147558)
decoder loss ratio: 17319.763388, decoder SINDy loss  ratio: 0.594589
--- 0.13965630531311035 seconds for one epoch ---
--- 0.19604039192199707 seconds for one epoch ---
--- 1.4276323318481445 seconds for one epoch ---
--- 0.20417451858520508 seconds for one epoch ---
--- 1.6459524631500244 seconds for one epoch ---
--- 0.15343046188354492 seconds for one epoch ---
--- 1.5331408977508545 seconds for one epoch ---
--- 0.1880021095275879 seconds for one epoch ---
--- 1.4886441230773926 seconds for one epoch ---
--- 0.2126941680908203 seconds for one epoch ---
--- 1.6585721969604492 seconds for one epoch ---
--- 0.1921243667602539 seconds for one epoch ---
--- 1.6978318691253662 seconds for one epoch ---
--- 0.20058155059814453 seconds for one epoch ---
--- 1.477402687072754 seconds for one epoch ---
--- 0.17060303688049316 seconds for one epoch ---
--- 1.4808580875396729 seconds for one epoch ---
--- 0.22344088554382324 seconds for one epoch ---
--- 1.5418446063995361 seconds for one epoch ---
--- 0.20070099830627441 seconds for one epoch ---
--- 1.5260777473449707 seconds for one epoch ---
--- 0.15694785118103027 seconds for one epoch ---
--- 1.5175371170043945 seconds for one epoch ---
--- 0.22530508041381836 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95439696]
 [0.        ]]
[[-8.549008 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.5536652]
 [-0.       ]]
--- 0.17153596878051758 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3662.62841796875, (1360.8348, 2.7934268, 2298.4856, 0.5145485)
   validation loss 898.85791015625, (608.3649, 0.5961406, 289.38235, 0.5145485)
decoder loss ratio: 23569.113525, decoder SINDy loss  ratio: 0.624673
--- 0.17609095573425293 seconds for one epoch ---
--- 1.445016860961914 seconds for one epoch ---
--- 0.19628429412841797 seconds for one epoch ---
--- 1.4863572120666504 seconds for one epoch ---
--- 0.21949529647827148 seconds for one epoch ---
--- 1.4373610019683838 seconds for one epoch ---
--- 0.18458032608032227 seconds for one epoch ---
--- 1.8154261112213135 seconds for one epoch ---
--- 0.1752490997314453 seconds for one epoch ---
--- 1.4459257125854492 seconds for one epoch ---
--- 0.20193982124328613 seconds for one epoch ---
--- 1.542146921157837 seconds for one epoch ---
--- 0.23194551467895508 seconds for one epoch ---
--- 1.4466967582702637 seconds for one epoch ---
--- 0.15319561958312988 seconds for one epoch ---
--- 1.5627024173736572 seconds for one epoch ---
--- 0.21514201164245605 seconds for one epoch ---
--- 1.4533941745758057 seconds for one epoch ---
--- 0.1818103790283203 seconds for one epoch ---
--- 1.6327908039093018 seconds for one epoch ---
--- 0.1852095127105713 seconds for one epoch ---
--- 1.4884800910949707 seconds for one epoch ---
--- 0.212188720703125 seconds for one epoch ---
--- 1.5075972080230713 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9420447]
 [0.       ]]
[[-8.573425 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4754896]
 [ 0.       ]]
--- 0.22957968711853027 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3864.009765625, (1355.815, 5.999419, 2501.6824, 0.51326686)
   validation loss 994.2335815429688, (697.5776, 0.43621072, 295.70657, 0.51326686)
decoder loss ratio: 27025.366330, decoder SINDy loss  ratio: 0.638324
--- 0.18301987648010254 seconds for one epoch ---
--- 0.23393559455871582 seconds for one epoch ---
--- 1.6274926662445068 seconds for one epoch ---
--- 0.2126474380493164 seconds for one epoch ---
--- 1.665151596069336 seconds for one epoch ---
--- 0.1984548568725586 seconds for one epoch ---
--- 1.6131935119628906 seconds for one epoch ---
--- 0.15206193923950195 seconds for one epoch ---
--- 1.4773228168487549 seconds for one epoch ---
--- 0.19559001922607422 seconds for one epoch ---
--- 1.4180715084075928 seconds for one epoch ---
--- 0.19566869735717773 seconds for one epoch ---
--- 1.504913330078125 seconds for one epoch ---
--- 0.20870304107666016 seconds for one epoch ---
--- 1.4364748001098633 seconds for one epoch ---
--- 0.21309471130371094 seconds for one epoch ---
--- 1.5746030807495117 seconds for one epoch ---
--- 0.20413851737976074 seconds for one epoch ---
--- 1.555467128753662 seconds for one epoch ---
--- 0.21360564231872559 seconds for one epoch ---
--- 1.5599589347839355 seconds for one epoch ---
--- 0.20865345001220703 seconds for one epoch ---
--- 1.6189007759094238 seconds for one epoch ---
--- 0.1883084774017334 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9293717]
 [0.       ]]
[[-8.594769 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4101844]
 [ 0.       ]]
--- 0.1497974395751953 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2278.851806640625, (955.3225, 2.6537447, 1320.3635, 0.5119507)
   validation loss 1065.3731689453125, (765.5113, 0.6425163, 298.70737, 0.5119507)
decoder loss ratio: 29657.236419, decoder SINDy loss  ratio: 0.644802
--- 0.16552233695983887 seconds for one epoch ---
--- 1.5517172813415527 seconds for one epoch ---
--- 0.15443944931030273 seconds for one epoch ---
--- 1.4839837551116943 seconds for one epoch ---
--- 0.15346479415893555 seconds for one epoch ---
--- 1.4497501850128174 seconds for one epoch ---
--- 0.24836063385009766 seconds for one epoch ---
--- 1.465139389038086 seconds for one epoch ---
--- 0.22783637046813965 seconds for one epoch ---
--- 1.4992759227752686 seconds for one epoch ---
--- 0.22002530097961426 seconds for one epoch ---
--- 1.4869494438171387 seconds for one epoch ---
--- 0.21084141731262207 seconds for one epoch ---
--- 1.511594533920288 seconds for one epoch ---
--- 0.17542695999145508 seconds for one epoch ---
--- 1.5110602378845215 seconds for one epoch ---
--- 0.21303200721740723 seconds for one epoch ---
--- 1.6558635234832764 seconds for one epoch ---
--- 0.15097975730895996 seconds for one epoch ---
--- 1.634113073348999 seconds for one epoch ---
--- 0.1855030059814453 seconds for one epoch ---
--- 1.6432602405548096 seconds for one epoch ---
--- 0.14878249168395996 seconds for one epoch ---
--- 1.674170732498169 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91576755]
 [0.        ]]
[[-8.619145 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3512325]
 [-0.       ]]
--- 0.20363306999206543 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2814.869384765625, (1479.1847, 1.7241683, 1333.4502, 0.51044947)
   validation loss 888.9224243164062, (595.2844, 0.44293347, 292.68466, 0.51044947)
decoder loss ratio: 23062.352038, decoder SINDy loss  ratio: 0.631801
--- 0.16807985305786133 seconds for one epoch ---
--- 0.1962418556213379 seconds for one epoch ---
--- 1.5175111293792725 seconds for one epoch ---
--- 0.1866588592529297 seconds for one epoch ---
--- 1.4947876930236816 seconds for one epoch ---
--- 0.1490943431854248 seconds for one epoch ---
--- 1.5379343032836914 seconds for one epoch ---
--- 0.20067954063415527 seconds for one epoch ---
--- 1.4839086532592773 seconds for one epoch ---
--- 0.22341346740722656 seconds for one epoch ---
--- 1.6166822910308838 seconds for one epoch ---
--- 0.1573948860168457 seconds for one epoch ---
--- 1.6820569038391113 seconds for one epoch ---
--- 0.1481461524963379 seconds for one epoch ---
--- 1.6281166076660156 seconds for one epoch ---
--- 0.15238404273986816 seconds for one epoch ---
--- 1.5943958759307861 seconds for one epoch ---
--- 0.1710507869720459 seconds for one epoch ---
--- 1.567007064819336 seconds for one epoch ---
--- 0.16473388671875 seconds for one epoch ---
--- 1.5037178993225098 seconds for one epoch ---
--- 0.19851899147033691 seconds for one epoch ---
--- 1.6614391803741455 seconds for one epoch ---
--- 0.17334508895874023 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.89625096]
 [0.        ]]
[[-8.639347 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.2802773]
 [-0.       ]]
--- 0.17808246612548828 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2611.3662109375, (1181.0336, 1.0323812, 1428.7921, 0.5082557)
   validation loss 1139.0992431640625, (835.63605, 0.63113433, 302.3237, 0.5082557)
decoder loss ratio: 32373.991203, decoder SINDy loss  ratio: 0.652608
--- 0.20915532112121582 seconds for one epoch ---
--- 1.5671322345733643 seconds for one epoch ---
--- 0.20116090774536133 seconds for one epoch ---
--- 1.6060171127319336 seconds for one epoch ---
--- 0.18583893775939941 seconds for one epoch ---
--- 1.5503273010253906 seconds for one epoch ---
--- 0.22728180885314941 seconds for one epoch ---
--- 1.6413779258728027 seconds for one epoch ---
--- 0.16738343238830566 seconds for one epoch ---
--- 1.666614055633545 seconds for one epoch ---
--- 0.1504979133605957 seconds for one epoch ---
--- 1.4586224555969238 seconds for one epoch ---
--- 0.22008657455444336 seconds for one epoch ---
--- 1.6186671257019043 seconds for one epoch ---
--- 0.19724249839782715 seconds for one epoch ---
--- 1.6497793197631836 seconds for one epoch ---
--- 0.16930389404296875 seconds for one epoch ---
--- 1.6372597217559814 seconds for one epoch ---
--- 0.14609360694885254 seconds for one epoch ---
--- 1.6163525581359863 seconds for one epoch ---
--- 0.1454474925994873 seconds for one epoch ---
--- 1.638453483581543 seconds for one epoch ---
--- 0.15169882774353027 seconds for one epoch ---
--- 1.724367618560791 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8809507]
 [0.       ]]
[[-8.668934 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.2325528]
 [ 0.       ]]
--- 0.22531461715698242 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2294.863037109375, (1256.1655, 0.83819205, 1037.3529, 0.50671095)
   validation loss 719.605224609375, (422.1349, 0.6746868, 296.28897, 0.50671095)
decoder loss ratio: 16354.238408, decoder SINDy loss  ratio: 0.639581
--- 0.15142345428466797 seconds for one epoch ---
--- 0.23309016227722168 seconds for one epoch ---
--- 1.6361541748046875 seconds for one epoch ---
--- 0.22217035293579102 seconds for one epoch ---
--- 1.5271751880645752 seconds for one epoch ---
--- 0.14616703987121582 seconds for one epoch ---
--- 1.5853314399719238 seconds for one epoch ---
--- 0.19168949127197266 seconds for one epoch ---
--- 1.5547873973846436 seconds for one epoch ---
--- 0.22555780410766602 seconds for one epoch ---
--- 1.5337889194488525 seconds for one epoch ---
--- 0.20940613746643066 seconds for one epoch ---
--- 1.4981951713562012 seconds for one epoch ---
--- 0.20169734954833984 seconds for one epoch ---
--- 1.4984426498413086 seconds for one epoch ---
--- 0.1927628517150879 seconds for one epoch ---
--- 1.6267085075378418 seconds for one epoch ---
--- 0.14986371994018555 seconds for one epoch ---
--- 1.545607089996338 seconds for one epoch ---
--- 0.21769356727600098 seconds for one epoch ---
--- 1.5770847797393799 seconds for one epoch ---
--- 0.20033669471740723 seconds for one epoch ---
--- 1.5461301803588867 seconds for one epoch ---
--- 0.19454264640808105 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85679233]
 [0.        ]]
[[-8.690147 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.1670535]
 [ 0.       ]]
--- 0.1591167449951172 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2114.017578125, (1120.4694, 2.557395, 990.4868, 0.50386846)
   validation loss 738.3867797851562, (461.06845, 0.6414526, 276.17307, 0.50386846)
decoder loss ratio: 17862.592239, decoder SINDy loss  ratio: 0.596158
--- 0.2003159523010254 seconds for one epoch ---
--- 1.6359508037567139 seconds for one epoch ---
--- 0.15309929847717285 seconds for one epoch ---
--- 1.4708001613616943 seconds for one epoch ---
--- 0.21056747436523438 seconds for one epoch ---
--- 1.6496853828430176 seconds for one epoch ---
--- 0.21280217170715332 seconds for one epoch ---
--- 1.579986810684204 seconds for one epoch ---
--- 0.16518640518188477 seconds for one epoch ---
--- 1.6066102981567383 seconds for one epoch ---
--- 0.20447254180908203 seconds for one epoch ---
--- 1.5657212734222412 seconds for one epoch ---
--- 0.16514945030212402 seconds for one epoch ---
--- 1.5562820434570312 seconds for one epoch ---
--- 0.2257068157196045 seconds for one epoch ---
--- 1.6255383491516113 seconds for one epoch ---
--- 0.14751672744750977 seconds for one epoch ---
--- 1.4934701919555664 seconds for one epoch ---
--- 0.19223499298095703 seconds for one epoch ---
--- 1.6846437454223633 seconds for one epoch ---
--- 0.21084213256835938 seconds for one epoch ---
--- 1.6149110794067383 seconds for one epoch ---
--- 0.15587735176086426 seconds for one epoch ---
--- 1.5520057678222656 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8392857]
 [0.       ]]
[[-8.716889 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-2.1251814]
 [-0.       ]]
--- 0.23576879501342773 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4449.6611328125, (1433.5721, 1.344071, 3014.2427, 0.5018997)
   validation loss 1145.5255126953125, (843.8353, 0.6574112, 300.5308, 0.5018997)
decoder loss ratio: 32691.645536, decoder SINDy loss  ratio: 0.648738
--- 0.21031689643859863 seconds for one epoch ---
--- 0.18245744705200195 seconds for one epoch ---
--- 1.6433329582214355 seconds for one epoch ---
--- 0.1959216594696045 seconds for one epoch ---
--- 1.6449837684631348 seconds for one epoch ---
--- 0.2012166976928711 seconds for one epoch ---
--- 1.4820358753204346 seconds for one epoch ---
--- 0.21427297592163086 seconds for one epoch ---
--- 1.6636888980865479 seconds for one epoch ---
--- 0.22716283798217773 seconds for one epoch ---
--- 1.6476075649261475 seconds for one epoch ---
--- 0.14313912391662598 seconds for one epoch ---
--- 1.575876235961914 seconds for one epoch ---
--- 0.22150254249572754 seconds for one epoch ---
--- 1.6775126457214355 seconds for one epoch ---
--- 0.2314448356628418 seconds for one epoch ---
--- 1.508803129196167 seconds for one epoch ---
--- 0.1855158805847168 seconds for one epoch ---
--- 1.5659160614013672 seconds for one epoch ---
--- 0.16368389129638672 seconds for one epoch ---
--- 1.5538573265075684 seconds for one epoch ---
--- 0.21497035026550293 seconds for one epoch ---
--- 1.6022870540618896 seconds for one epoch ---
--- 0.1710653305053711 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8145767]
 [0.       ]]
[[-8.728589 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.0719724]
 [-0.       ]]
--- 0.15705323219299316 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2328.496826171875, (1039.8905, 1.0403674, 1287.0671, 0.49884635)
   validation loss 721.7835083007812, (438.47552, 0.68202806, 282.12714, 0.49884635)
decoder loss ratio: 16987.303062, decoder SINDy loss  ratio: 0.609011
--- 0.22329187393188477 seconds for one epoch ---
--- 1.6670453548431396 seconds for one epoch ---
--- 0.18897151947021484 seconds for one epoch ---
--- 1.7064931392669678 seconds for one epoch ---
--- 0.16449522972106934 seconds for one epoch ---
--- 1.621809482574463 seconds for one epoch ---
--- 0.23320388793945312 seconds for one epoch ---
--- 1.5322461128234863 seconds for one epoch ---
--- 0.216294527053833 seconds for one epoch ---
--- 1.5343594551086426 seconds for one epoch ---
--- 0.19524240493774414 seconds for one epoch ---
--- 1.6025078296661377 seconds for one epoch ---
--- 0.17231535911560059 seconds for one epoch ---
--- 1.5784649848937988 seconds for one epoch ---
--- 0.23623991012573242 seconds for one epoch ---
--- 1.723804235458374 seconds for one epoch ---
--- 0.18620800971984863 seconds for one epoch ---
--- 1.6794555187225342 seconds for one epoch ---
--- 0.22542333602905273 seconds for one epoch ---
--- 1.6156764030456543 seconds for one epoch ---
--- 0.1719989776611328 seconds for one epoch ---
--- 1.6211140155792236 seconds for one epoch ---
--- 0.23209381103515625 seconds for one epoch ---
--- 1.5584547519683838 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.79421026]
 [0.        ]]
[[-8.756091]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-2.032132]
 [ 0.      ]]
--- 0.23679423332214355 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3235.6103515625, (1506.8279, 2.901201, 1725.3851, 0.49614665)
   validation loss 1425.609130859375, (1065.7054, 0.7468675, 358.6607, 0.49614665)
decoder loss ratio: 41287.279060, decoder SINDy loss  ratio: 0.774220
--- 0.17950224876403809 seconds for one epoch ---
--- 0.21232104301452637 seconds for one epoch ---
--- 1.5227077007293701 seconds for one epoch ---
--- 0.2074117660522461 seconds for one epoch ---
--- 1.5354773998260498 seconds for one epoch ---
--- 0.20365166664123535 seconds for one epoch ---
--- 1.6541624069213867 seconds for one epoch ---
--- 0.1864480972290039 seconds for one epoch ---
--- 1.6431841850280762 seconds for one epoch ---
--- 0.22518467903137207 seconds for one epoch ---
--- 1.5252580642700195 seconds for one epoch ---
--- 0.24863100051879883 seconds for one epoch ---
--- 1.6652021408081055 seconds for one epoch ---
--- 0.16562318801879883 seconds for one epoch ---
--- 1.6028468608856201 seconds for one epoch ---
--- 0.19647932052612305 seconds for one epoch ---
--- 1.7651660442352295 seconds for one epoch ---
--- 0.14648890495300293 seconds for one epoch ---
--- 1.6008806228637695 seconds for one epoch ---
--- 0.1906132698059082 seconds for one epoch ---
--- 1.5458474159240723 seconds for one epoch ---
--- 0.22654271125793457 seconds for one epoch ---
--- 1.654127597808838 seconds for one epoch ---
--- 0.2195298671722412 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.75941765]
 [0.        ]]
[[-8.766061]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-1.970347]
 [ 0.      ]]
--- 0.14631009101867676 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4585.5380859375, (1015.06616, 2.5011556, 3567.4792, 0.4914685)
   validation loss 849.49755859375, (554.95233, 0.68619883, 293.36758, 0.4914685)
decoder loss ratio: 21499.816764, decoder SINDy loss  ratio: 0.633275
--- 0.24071931838989258 seconds for one epoch ---
--- 1.6839606761932373 seconds for one epoch ---
--- 0.21801185607910156 seconds for one epoch ---
--- 1.8134870529174805 seconds for one epoch ---
--- 0.15825104713439941 seconds for one epoch ---
--- 1.6917259693145752 seconds for one epoch ---
--- 0.16034555435180664 seconds for one epoch ---
--- 1.7272403240203857 seconds for one epoch ---
--- 0.211867094039917 seconds for one epoch ---
--- 1.6389541625976562 seconds for one epoch ---
--- 0.2331080436706543 seconds for one epoch ---
--- 1.6568198204040527 seconds for one epoch ---
--- 0.1899890899658203 seconds for one epoch ---
--- 1.742924690246582 seconds for one epoch ---
--- 0.23318839073181152 seconds for one epoch ---
--- 1.5728633403778076 seconds for one epoch ---
--- 0.23436617851257324 seconds for one epoch ---
--- 1.577671766281128 seconds for one epoch ---
--- 0.2552516460418701 seconds for one epoch ---
--- 1.6677381992340088 seconds for one epoch ---
--- 0.17981600761413574 seconds for one epoch ---
--- 1.6018717288970947 seconds for one epoch ---
--- 0.20551609992980957 seconds for one epoch ---
--- 1.6022298336029053 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7267976]
 [0.       ]]
[[-8.783517 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.9178061]
 [-0.       ]]
--- 0.178863525390625 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2389.95263671875, (1007.6623, 0.6937668, 1381.1099, 0.4867382)
   validation loss 750.5446166992188, (449.87775, 0.61071783, 299.56937, 0.4867382)
decoder loss ratio: 17429.044925, decoder SINDy loss  ratio: 0.646663
--- 0.15748906135559082 seconds for one epoch ---
--- 0.22743630409240723 seconds for one epoch ---
--- 1.5732145309448242 seconds for one epoch ---
--- 0.20566010475158691 seconds for one epoch ---
--- 1.6265389919281006 seconds for one epoch ---
--- 0.2031993865966797 seconds for one epoch ---
--- 1.6830353736877441 seconds for one epoch ---
--- 0.23207831382751465 seconds for one epoch ---
--- 1.7809088230133057 seconds for one epoch ---
--- 0.14703798294067383 seconds for one epoch ---
--- 1.693662166595459 seconds for one epoch ---
--- 0.2280881404876709 seconds for one epoch ---
--- 1.592123031616211 seconds for one epoch ---
--- 0.23246431350708008 seconds for one epoch ---
--- 1.7093837261199951 seconds for one epoch ---
--- 0.23391032218933105 seconds for one epoch ---
--- 1.5947515964508057 seconds for one epoch ---
--- 0.25029945373535156 seconds for one epoch ---
--- 1.5521938800811768 seconds for one epoch ---
--- 0.22774124145507812 seconds for one epoch ---
--- 1.671266794204712 seconds for one epoch ---
--- 0.21040749549865723 seconds for one epoch ---
--- 1.6699399948120117 seconds for one epoch ---
--- 0.2026660442352295 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6960314]
 [0.       ]]
[[-8.807179 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.8717684]
 [-0.       ]]
--- 0.17502641677856445 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4904.0390625, (1874.749, 1.5451951, 3027.2627, 0.48252255)
   validation loss 872.3970947265625, (575.53076, 0.5227947, 295.86102, 0.48252255)
decoder loss ratio: 22297.060874, decoder SINDy loss  ratio: 0.638658
--- 0.2263660430908203 seconds for one epoch ---
--- 1.789043664932251 seconds for one epoch ---
--- 0.15307998657226562 seconds for one epoch ---
--- 1.748685359954834 seconds for one epoch ---
--- 0.1783149242401123 seconds for one epoch ---
--- 1.6502747535705566 seconds for one epoch ---
--- 0.17626214027404785 seconds for one epoch ---
--- 1.6765201091766357 seconds for one epoch ---
--- 0.1900484561920166 seconds for one epoch ---
--- 1.660325050354004 seconds for one epoch ---
--- 0.26786279678344727 seconds for one epoch ---
--- 1.5993518829345703 seconds for one epoch ---
--- 0.2051224708557129 seconds for one epoch ---
--- 1.6631972789764404 seconds for one epoch ---
--- 0.21464920043945312 seconds for one epoch ---
--- 1.6075730323791504 seconds for one epoch ---
--- 0.240861177444458 seconds for one epoch ---
--- 1.6091010570526123 seconds for one epoch ---
--- 0.21611332893371582 seconds for one epoch ---
--- 1.5843956470489502 seconds for one epoch ---
--- 0.16787481307983398 seconds for one epoch ---
--- 1.7658495903015137 seconds for one epoch ---
--- 0.18622946739196777 seconds for one epoch ---
--- 1.6523547172546387 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.65675485]
 [0.        ]]
[[-8.824873 ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.8166676]
 [ 0.       ]]
--- 0.22751951217651367 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6045.740234375, (1772.7275, 2.1892395, 4270.346, 0.47739077)
   validation loss 750.595947265625, (451.3558, 0.60323, 298.15952, 0.47739077)
decoder loss ratio: 17486.307452, decoder SINDy loss  ratio: 0.643619
--- 0.18342161178588867 seconds for one epoch ---
--- 0.2734806537628174 seconds for one epoch ---
--- 1.8418495655059814 seconds for one epoch ---
--- 0.15958809852600098 seconds for one epoch ---
--- 1.7532556056976318 seconds for one epoch ---
--- 0.21152305603027344 seconds for one epoch ---
--- 1.6385536193847656 seconds for one epoch ---
--- 0.2447524070739746 seconds for one epoch ---
--- 1.6706788539886475 seconds for one epoch ---
--- 0.1484222412109375 seconds for one epoch ---
--- 1.6718544960021973 seconds for one epoch ---
--- 0.19452118873596191 seconds for one epoch ---
--- 1.691943883895874 seconds for one epoch ---
--- 0.19806170463562012 seconds for one epoch ---
--- 1.6582155227661133 seconds for one epoch ---
--- 0.1997830867767334 seconds for one epoch ---
--- 1.644517183303833 seconds for one epoch ---
--- 0.21195411682128906 seconds for one epoch ---
--- 1.5559625625610352 seconds for one epoch ---
--- 0.24054813385009766 seconds for one epoch ---
--- 1.6982998847961426 seconds for one epoch ---
--- 0.2387526035308838 seconds for one epoch ---
--- 1.6759061813354492 seconds for one epoch ---
--- 0.24684500694274902 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.62273026]
 [0.        ]]
[[-8.849617 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.7713788]
 [ 0.       ]]
--- 0.21264863014221191 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3528.467529296875, (1064.8911, 6.732057, 2456.3726, 0.47185156)
   validation loss 985.0730590820312, (671.2461, 0.69334173, 312.66177, 0.47185156)
decoder loss ratio: 26005.239006, decoder SINDy loss  ratio: 0.674924
--- 0.25559115409851074 seconds for one epoch ---
--- 1.625443458557129 seconds for one epoch ---
--- 0.24283504486083984 seconds for one epoch ---
--- 1.6725730895996094 seconds for one epoch ---
--- 0.23691439628601074 seconds for one epoch ---
--- 1.7255003452301025 seconds for one epoch ---
--- 0.17111992835998535 seconds for one epoch ---
--- 1.8007843494415283 seconds for one epoch ---
--- 0.1689283847808838 seconds for one epoch ---
--- 1.7118799686431885 seconds for one epoch ---
--- 0.1505119800567627 seconds for one epoch ---
--- 1.7580962181091309 seconds for one epoch ---
--- 0.1492140293121338 seconds for one epoch ---
--- 1.6677088737487793 seconds for one epoch ---
--- 0.24060487747192383 seconds for one epoch ---
--- 1.6332805156707764 seconds for one epoch ---
--- 0.2694106101989746 seconds for one epoch ---
--- 1.6743478775024414 seconds for one epoch ---
--- 0.5584607124328613 seconds for one epoch ---
--- 1.6929726600646973 seconds for one epoch ---
--- 0.2037520408630371 seconds for one epoch ---
--- 1.623081922531128 seconds for one epoch ---
--- 0.18231892585754395 seconds for one epoch ---
--- 1.703564167022705 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5838015]
 [0.       ]]
[[-8.8639765]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.7215078]
 [-0.       ]]
--- 0.18395686149597168 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2475.3408203125, (1765.6262, 2.6905336, 706.5583, 0.4658948)
   validation loss 960.9573364257812, (676.3277, 0.60457796, 283.55923, 0.4658948)
decoder loss ratio: 26202.109168, decoder SINDy loss  ratio: 0.612102
--- 0.2219841480255127 seconds for one epoch ---
--- 0.15058660507202148 seconds for one epoch ---
--- 1.7655255794525146 seconds for one epoch ---
--- 0.1622323989868164 seconds for one epoch ---
--- 1.6683542728424072 seconds for one epoch ---
--- 0.24870610237121582 seconds for one epoch ---
--- 1.7533040046691895 seconds for one epoch ---
--- 0.24354791641235352 seconds for one epoch ---
--- 1.779388666152954 seconds for one epoch ---
--- 0.18313813209533691 seconds for one epoch ---
--- 1.6529383659362793 seconds for one epoch ---
--- 0.2573094367980957 seconds for one epoch ---
--- 1.6448571681976318 seconds for one epoch ---
--- 0.2687077522277832 seconds for one epoch ---
--- 1.6960747241973877 seconds for one epoch ---
--- 0.18755149841308594 seconds for one epoch ---
--- 1.7285754680633545 seconds for one epoch ---
--- 0.17484545707702637 seconds for one epoch ---
--- 1.7913587093353271 seconds for one epoch ---
--- 0.1444857120513916 seconds for one epoch ---
--- 1.7518043518066406 seconds for one epoch ---
--- 0.15941524505615234 seconds for one epoch ---
--- 1.730956792831421 seconds for one epoch ---
--- 0.1517345905303955 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5429961]
 [0.       ]]
[[-8.880708 ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.6706758]
 [-0.       ]]
--- 0.24301576614379883 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2218.491455078125, (1069.6106, 0.16239007, 1148.2589, 0.45968208)
   validation loss 1409.82568359375, (1038.6953, 0.60976154, 370.06088, 0.45968208)
decoder loss ratio: 40240.859661, decoder SINDy loss  ratio: 0.798828
--- 0.26611852645874023 seconds for one epoch ---
--- 1.7437412738800049 seconds for one epoch ---
--- 0.2272500991821289 seconds for one epoch ---
--- 1.8010411262512207 seconds for one epoch ---
--- 0.15096664428710938 seconds for one epoch ---
--- 1.7153732776641846 seconds for one epoch ---
--- 0.17160511016845703 seconds for one epoch ---
--- 1.7408928871154785 seconds for one epoch ---
--- 0.22092533111572266 seconds for one epoch ---
--- 1.5991876125335693 seconds for one epoch ---
--- 0.21817803382873535 seconds for one epoch ---
--- 1.6862409114837646 seconds for one epoch ---
--- 0.1909780502319336 seconds for one epoch ---
--- 1.8136494159698486 seconds for one epoch ---
--- 0.1841869354248047 seconds for one epoch ---
--- 1.7215662002563477 seconds for one epoch ---
--- 0.1650078296661377 seconds for one epoch ---
--- 1.5776219367980957 seconds for one epoch ---
--- 0.25385522842407227 seconds for one epoch ---
--- 1.8440735340118408 seconds for one epoch ---
--- 0.21973204612731934 seconds for one epoch ---
--- 1.8635008335113525 seconds for one epoch ---
--- 0.14884233474731445 seconds for one epoch ---
--- 1.6393253803253174 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.50244546]
 [0.        ]]
[[-8.885199 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.6209048]
 [ 0.       ]]
--- 0.24062657356262207 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2529.73095703125, (989.89734, 3.6042132, 1535.7764, 0.45311242)
   validation loss 808.279296875, (502.8831, 0.6115122, 304.3316, 0.45311242)
decoder loss ratio: 19482.563840, decoder SINDy loss  ratio: 0.656943
THRESHOLDING: 2 active coefficients
--- 0.1833021640777588 seconds for one epoch ---
--- 0.23394989967346191 seconds for one epoch ---
--- 1.7291464805603027 seconds for one epoch ---
--- 0.16238999366760254 seconds for one epoch ---
--- 1.618333101272583 seconds for one epoch ---
--- 0.2501027584075928 seconds for one epoch ---
--- 1.8314085006713867 seconds for one epoch ---
--- 0.21988797187805176 seconds for one epoch ---
--- 1.6762175559997559 seconds for one epoch ---
--- 0.18287301063537598 seconds for one epoch ---
--- 1.8189442157745361 seconds for one epoch ---
--- 0.17728090286254883 seconds for one epoch ---
--- 1.6432831287384033 seconds for one epoch ---
--- 0.22939705848693848 seconds for one epoch ---
--- 1.7505438327789307 seconds for one epoch ---
--- 0.16446852684020996 seconds for one epoch ---
--- 1.6578073501586914 seconds for one epoch ---
--- 0.26378631591796875 seconds for one epoch ---
--- 1.7199442386627197 seconds for one epoch ---
--- 0.25548481941223145 seconds for one epoch ---
--- 1.730226993560791 seconds for one epoch ---
--- 0.23082423210144043 seconds for one epoch ---
--- 1.671919822692871 seconds for one epoch ---
--- 0.16573882102966309 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.47866982]
 [0.        ]]
[[-8.91259  ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.5917974]
 [ 0.       ]]
--- 0.22257208824157715 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3381.889404296875, (1365.2167, 3.0925956, 2013.1313, 0.44864616)
   validation loss 754.5977172851562, (455.1024, 0.60378873, 298.4429, 0.44864616)
decoder loss ratio: 17631.456545, decoder SINDy loss  ratio: 0.644231
--- 0.2199094295501709 seconds for one epoch ---
--- 1.6902782917022705 seconds for one epoch ---
--- 0.2183995246887207 seconds for one epoch ---
--- 1.8421268463134766 seconds for one epoch ---
--- 0.2344684600830078 seconds for one epoch ---
--- 1.6586887836456299 seconds for one epoch ---
--- 0.21550345420837402 seconds for one epoch ---
--- 1.6561861038208008 seconds for one epoch ---
--- 0.2508666515350342 seconds for one epoch ---
--- 1.775242805480957 seconds for one epoch ---
--- 0.19511795043945312 seconds for one epoch ---
--- 1.7776775360107422 seconds for one epoch ---
--- 0.19881153106689453 seconds for one epoch ---
--- 1.713510274887085 seconds for one epoch ---
--- 0.2563769817352295 seconds for one epoch ---
--- 1.723374366760254 seconds for one epoch ---
--- 0.20122885704040527 seconds for one epoch ---
--- 1.669809341430664 seconds for one epoch ---
--- 0.25376176834106445 seconds for one epoch ---
--- 1.7556426525115967 seconds for one epoch ---
--- 0.20880460739135742 seconds for one epoch ---
--- 1.7138912677764893 seconds for one epoch ---
--- 0.2241501808166504 seconds for one epoch ---
--- 1.669022560119629 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.44953722]
 [0.        ]]
[[-8.929752 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5559703]
 [-0.       ]]
--- 0.20591521263122559 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2127.05322265625, (1226.3241, 1.3847281, 898.9002, 0.44403377)
   validation loss 864.7531127929688, (565.9665, 0.6518087, 297.69083, 0.44403377)
decoder loss ratio: 21926.524449, decoder SINDy loss  ratio: 0.642608
--- 0.22017526626586914 seconds for one epoch ---
--- 0.2274322509765625 seconds for one epoch ---
--- 1.7148640155792236 seconds for one epoch ---
--- 0.19195914268493652 seconds for one epoch ---
--- 1.7542202472686768 seconds for one epoch ---
--- 0.2367699146270752 seconds for one epoch ---
--- 1.6762874126434326 seconds for one epoch ---
--- 0.19982314109802246 seconds for one epoch ---
--- 1.779876708984375 seconds for one epoch ---
--- 0.19440674781799316 seconds for one epoch ---
--- 1.738779067993164 seconds for one epoch ---
--- 0.1555016040802002 seconds for one epoch ---
--- 1.6899816989898682 seconds for one epoch ---
--- 0.22561216354370117 seconds for one epoch ---
--- 1.8292770385742188 seconds for one epoch ---
--- 0.1748340129852295 seconds for one epoch ---
--- 1.6999387741088867 seconds for one epoch ---
--- 0.2650141716003418 seconds for one epoch ---
--- 1.7172963619232178 seconds for one epoch ---
--- 0.19237351417541504 seconds for one epoch ---
--- 1.7181830406188965 seconds for one epoch ---
--- 0.24538683891296387 seconds for one epoch ---
--- 1.6917870044708252 seconds for one epoch ---
--- 0.15892887115478516 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41578856]
 [0.        ]]
[[-8.938929 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5139322]
 [-0.       ]]
--- 0.21021389961242676 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1912.158447265625, (939.7627, 0.6761876, 971.28143, 0.4380912)
   validation loss 924.279296875, (628.49963, 0.62969285, 294.71188, 0.4380912)
decoder loss ratio: 24349.166936, decoder SINDy loss  ratio: 0.636177
--- 0.2778756618499756 seconds for one epoch ---
--- 1.7992708683013916 seconds for one epoch ---
--- 0.18814635276794434 seconds for one epoch ---
--- 1.823319911956787 seconds for one epoch ---
--- 0.20718002319335938 seconds for one epoch ---
--- 1.741891622543335 seconds for one epoch ---
--- 0.2757539749145508 seconds for one epoch ---
--- 1.8193295001983643 seconds for one epoch ---
--- 0.1468062400817871 seconds for one epoch ---
--- 1.6573338508605957 seconds for one epoch ---
--- 0.26101088523864746 seconds for one epoch ---
--- 1.8098812103271484 seconds for one epoch ---
--- 0.14753413200378418 seconds for one epoch ---
--- 1.7006471157073975 seconds for one epoch ---
--- 0.25667285919189453 seconds for one epoch ---
--- 1.8240845203399658 seconds for one epoch ---
--- 0.15249919891357422 seconds for one epoch ---
--- 1.7062668800354004 seconds for one epoch ---
--- 0.2528958320617676 seconds for one epoch ---
--- 1.7424373626708984 seconds for one epoch ---
--- 0.18850421905517578 seconds for one epoch ---
--- 1.6960515975952148 seconds for one epoch ---
--- 0.24979948997497559 seconds for one epoch ---
--- 1.7458422183990479 seconds for one epoch ---
=========================
[[1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.393157]
 [0.      ]]
[[-8.954621 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4852232]
 [ 0.       ]]
--- 0.23233318328857422 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1656.4285888671875, (915.1216, 0.88979393, 739.9833, 0.43398818)
   validation loss 736.4098510742188, (433.9971, 0.65946627, 301.31934, 0.43398818)
decoder loss ratio: 16813.801138, decoder SINDy loss  ratio: 0.650440
--- 0.24723267555236816 seconds for one epoch ---
--- 0.15256834030151367 seconds for one epoch ---
--- 1.7469356060028076 seconds for one epoch ---
--- 0.19711756706237793 seconds for one epoch ---
--- 1.678842544555664 seconds for one epoch ---
--- 0.27815771102905273 seconds for one epoch ---
--- 1.774083137512207 seconds for one epoch ---
--- 0.14284539222717285 seconds for one epoch ---
--- 1.666675090789795 seconds for one epoch ---
--- 0.20856189727783203 seconds for one epoch ---
--- 1.7214438915252686 seconds for one epoch ---
--- 0.231581449508667 seconds for one epoch ---
--- 1.7835962772369385 seconds for one epoch ---
--- 0.16397571563720703 seconds for one epoch ---
--- 1.6873445510864258 seconds for one epoch ---
--- 0.19802117347717285 seconds for one epoch ---
--- 1.822777271270752 seconds for one epoch ---
--- 0.2084980010986328 seconds for one epoch ---
--- 1.7253880500793457 seconds for one epoch ---
--- 0.15500640869140625 seconds for one epoch ---
--- 1.7722859382629395 seconds for one epoch ---
--- 0.24683141708374023 seconds for one epoch ---
--- 1.7831711769104004 seconds for one epoch ---
--- 0.234727144241333 seconds for one epoch ---
=========================
[[1.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.355541]
 [0.      ]]
[[-8.962271]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-1.43615 ]
 [ 0.      ]]
--- 0.14372658729553223 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2334.87646484375, (780.97424, 3.7252839, 1549.7501, 0.42683306)
   validation loss 816.6652221679688, (532.60004, 0.6727112, 282.9656, 0.42683306)
decoder loss ratio: 20633.850053, decoder SINDy loss  ratio: 0.610821
--- 0.21914911270141602 seconds for one epoch ---
--- 1.776123046875 seconds for one epoch ---
--- 0.18160080909729004 seconds for one epoch ---
--- 1.7701902389526367 seconds for one epoch ---
--- 0.2216968536376953 seconds for one epoch ---
--- 1.848461627960205 seconds for one epoch ---
--- 0.21177196502685547 seconds for one epoch ---
--- 1.774087905883789 seconds for one epoch ---
--- 0.20228195190429688 seconds for one epoch ---
--- 1.6839642524719238 seconds for one epoch ---
--- 0.2718164920806885 seconds for one epoch ---
--- 1.7648718357086182 seconds for one epoch ---
--- 0.1921086311340332 seconds for one epoch ---
--- 1.7055580615997314 seconds for one epoch ---
--- 0.18484020233154297 seconds for one epoch ---
--- 1.7953784465789795 seconds for one epoch ---
--- 0.2801663875579834 seconds for one epoch ---
--- 1.7767488956451416 seconds for one epoch ---
--- 0.21513986587524414 seconds for one epoch ---
--- 1.7127923965454102 seconds for one epoch ---
--- 0.27849841117858887 seconds for one epoch ---
--- 1.794316053390503 seconds for one epoch ---
--- 0.17479443550109863 seconds for one epoch ---
--- 1.7177643775939941 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32715642]
 [0.        ]]
[[-8.979495 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3976032]
 [-0.       ]]
--- 0.18512821197509766 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2960.566650390625, (1255.5074, 2.5504975, 1702.0873, 0.42138657)
   validation loss 1188.340087890625, (865.62573, 0.6892679, 321.60376, 0.42138657)
decoder loss ratio: 33535.843666, decoder SINDy loss  ratio: 0.694227
--- 0.18608689308166504 seconds for one epoch ---
--- 0.2648625373840332 seconds for one epoch ---
--- 1.8108124732971191 seconds for one epoch ---
--- 0.1730823516845703 seconds for one epoch ---
--- 1.917548656463623 seconds for one epoch ---
--- 0.2711367607116699 seconds for one epoch ---
--- 1.7811284065246582 seconds for one epoch ---
--- 0.20808887481689453 seconds for one epoch ---
--- 1.7423722743988037 seconds for one epoch ---
--- 0.24114704132080078 seconds for one epoch ---
--- 1.782754898071289 seconds for one epoch ---
--- 0.21542596817016602 seconds for one epoch ---
--- 1.768700122833252 seconds for one epoch ---
--- 0.1807706356048584 seconds for one epoch ---
--- 1.7169663906097412 seconds for one epoch ---
--- 0.264967679977417 seconds for one epoch ---
--- 1.829275131225586 seconds for one epoch ---
--- 0.20414423942565918 seconds for one epoch ---
--- 1.8647582530975342 seconds for one epoch ---
--- 0.16605925559997559 seconds for one epoch ---
--- 1.7609241008758545 seconds for one epoch ---
--- 0.23396658897399902 seconds for one epoch ---
--- 1.7453422546386719 seconds for one epoch ---
--- 0.23267436027526855 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2988468]
 [0.       ]]
[[-8.996779 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.3574238]
 [-0.       ]]
--- 0.24314522743225098 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2966.2255859375, (1474.4286, 0.83075154, 1490.5503, 0.41599724)
   validation loss 887.010009765625, (587.2438, 0.80422, 298.54605, 0.41599724)
decoder loss ratio: 22750.843321, decoder SINDy loss  ratio: 0.644454
--- 0.26212596893310547 seconds for one epoch ---
--- 1.9102203845977783 seconds for one epoch ---
--- 0.16210150718688965 seconds for one epoch ---
--- 1.8224241733551025 seconds for one epoch ---
--- 0.1911773681640625 seconds for one epoch ---
--- 1.7647120952606201 seconds for one epoch ---
--- 0.30072546005249023 seconds for one epoch ---
--- 1.8011846542358398 seconds for one epoch ---
--- 0.23293399810791016 seconds for one epoch ---
--- 1.8209397792816162 seconds for one epoch ---
--- 0.18277859687805176 seconds for one epoch ---
--- 1.8659989833831787 seconds for one epoch ---
--- 0.2645437717437744 seconds for one epoch ---
--- 1.885251760482788 seconds for one epoch ---
--- 0.17084217071533203 seconds for one epoch ---
--- 1.768862009048462 seconds for one epoch ---
--- 0.292431116104126 seconds for one epoch ---
--- 1.8547618389129639 seconds for one epoch ---
--- 0.16565537452697754 seconds for one epoch ---
--- 1.764134407043457 seconds for one epoch ---
--- 0.17500996589660645 seconds for one epoch ---
--- 1.7634215354919434 seconds for one epoch ---
--- 0.26764845848083496 seconds for one epoch ---
--- 1.7129578590393066 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28087586]
 [0.        ]]
[[-9.01195 ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-1.330796]
 [ 0.      ]]
--- 0.24851226806640625 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2961.95556640625, (1064.2258, 0.53201807, 1896.7854, 0.41225553)
   validation loss 898.1644287109375, (570.4694, 0.63910943, 326.64365, 0.41225553)
decoder loss ratio: 22100.975763, decoder SINDy loss  ratio: 0.705106
--- 0.1916654109954834 seconds for one epoch ---
--- 0.1697089672088623 seconds for one epoch ---
--- 1.9236986637115479 seconds for one epoch ---
--- 0.267009973526001 seconds for one epoch ---
--- 1.841270923614502 seconds for one epoch ---
--- 0.18756389617919922 seconds for one epoch ---
--- 1.8180267810821533 seconds for one epoch ---
--- 0.24641919136047363 seconds for one epoch ---
--- 1.741483449935913 seconds for one epoch ---
--- 0.2781379222869873 seconds for one epoch ---
--- 1.8543272018432617 seconds for one epoch ---
--- 0.21704721450805664 seconds for one epoch ---
--- 1.8156609535217285 seconds for one epoch ---
--- 0.16473174095153809 seconds for one epoch ---
--- 1.8305044174194336 seconds for one epoch ---
--- 0.261488676071167 seconds for one epoch ---
--- 1.8740100860595703 seconds for one epoch ---
--- 0.24515557289123535 seconds for one epoch ---
--- 1.8214006423950195 seconds for one epoch ---
--- 0.2041769027709961 seconds for one epoch ---
--- 1.6873953342437744 seconds for one epoch ---
--- 0.25080108642578125 seconds for one epoch ---
--- 1.6810595989227295 seconds for one epoch ---
--- 0.2205948829650879 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2564575]
 [0.       ]]
[[-9.02524  ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2928977]
 [ 0.       ]]
--- 0.1882612705230713 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2352.2060546875, (977.60486, 2.5681856, 1371.6262, 0.40670797)
   validation loss 764.4893188476562, (473.4983, 0.6872767, 289.897, 0.40670797)
decoder loss ratio: 18344.145823, decoder SINDy loss  ratio: 0.625783
--- 0.26699233055114746 seconds for one epoch ---
--- 1.8760054111480713 seconds for one epoch ---
--- 0.1851496696472168 seconds for one epoch ---
--- 1.8297119140625 seconds for one epoch ---
--- 0.1949021816253662 seconds for one epoch ---
--- 1.7886734008789062 seconds for one epoch ---
--- 0.22650671005249023 seconds for one epoch ---
--- 1.7857136726379395 seconds for one epoch ---
--- 0.2818474769592285 seconds for one epoch ---
--- 1.812378168106079 seconds for one epoch ---
--- 0.1883547306060791 seconds for one epoch ---
--- 1.8314378261566162 seconds for one epoch ---
--- 0.15406513214111328 seconds for one epoch ---
--- 1.860957384109497 seconds for one epoch ---
--- 0.15634393692016602 seconds for one epoch ---
--- 1.7838752269744873 seconds for one epoch ---
--- 0.2601804733276367 seconds for one epoch ---
--- 1.8401703834533691 seconds for one epoch ---
--- 0.2401137351989746 seconds for one epoch ---
--- 1.818281888961792 seconds for one epoch ---
--- 0.1791985034942627 seconds for one epoch ---
--- 1.7822716236114502 seconds for one epoch ---
--- 0.17108535766601562 seconds for one epoch ---
--- 1.743683099746704 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24285387]
 [0.        ]]
[[-9.045253 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2707659]
 [-0.       ]]
--- 0.2924971580505371 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5544.89208984375, (799.70325, 12.790831, 4731.994, 0.4040439)
   validation loss 909.3833618164062, (619.95807, 0.71828556, 288.30298, 0.4040439)
decoder loss ratio: 24018.251882, decoder SINDy loss  ratio: 0.622343
--- 0.2572166919708252 seconds for one epoch ---
--- 0.2933626174926758 seconds for one epoch ---
--- 1.7951750755310059 seconds for one epoch ---
--- 0.3037986755371094 seconds for one epoch ---
--- 1.7917675971984863 seconds for one epoch ---
--- 0.28479552268981934 seconds for one epoch ---
--- 1.8639037609100342 seconds for one epoch ---
--- 0.29425978660583496 seconds for one epoch ---
--- 1.7761025428771973 seconds for one epoch ---
--- 0.19844841957092285 seconds for one epoch ---
--- 2.318225383758545 seconds for one epoch ---
--- 0.14852666854858398 seconds for one epoch ---
--- 1.830960750579834 seconds for one epoch ---
--- 0.1821916103363037 seconds for one epoch ---
--- 1.9005036354064941 seconds for one epoch ---
--- 0.1472463607788086 seconds for one epoch ---
--- 2.3843495845794678 seconds for one epoch ---
--- 0.1741034984588623 seconds for one epoch ---
--- 2.2950870990753174 seconds for one epoch ---
--- 0.15817689895629883 seconds for one epoch ---
--- 1.8047845363616943 seconds for one epoch ---
--- 0.15500378608703613 seconds for one epoch ---
--- 1.7577481269836426 seconds for one epoch ---
--- 0.1477518081665039 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22049902]
 [0.        ]]
[[-9.0576935]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2324927]
 [-0.       ]]
--- 0.14223790168762207 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3887.250732421875, (1875.7257, 2.8209646, 2008.3053, 0.39878628)
   validation loss 907.075927734375, (600.4087, 0.6375528, 305.63086, 0.39878628)
decoder loss ratio: 23260.875060, decoder SINDy loss  ratio: 0.659747
--- 0.1568460464477539 seconds for one epoch ---
--- 1.9802908897399902 seconds for one epoch ---
--- 0.16873669624328613 seconds for one epoch ---
--- 2.245992422103882 seconds for one epoch ---
--- 0.1570143699645996 seconds for one epoch ---
--- 2.051128625869751 seconds for one epoch ---
--- 0.18654727935791016 seconds for one epoch ---
--- 1.7799866199493408 seconds for one epoch ---
--- 0.17151856422424316 seconds for one epoch ---
--- 1.9303016662597656 seconds for one epoch ---
--- 0.19336295127868652 seconds for one epoch ---
--- 1.7756638526916504 seconds for one epoch ---
--- 0.20245766639709473 seconds for one epoch ---
--- 2.1162731647491455 seconds for one epoch ---
--- 0.1619563102722168 seconds for one epoch ---
--- 2.188751697540283 seconds for one epoch ---
--- 0.16013884544372559 seconds for one epoch ---
--- 1.8041911125183105 seconds for one epoch ---
--- 0.14914751052856445 seconds for one epoch ---
--- 1.8098416328430176 seconds for one epoch ---
--- 0.1493208408355713 seconds for one epoch ---
--- 2.041863441467285 seconds for one epoch ---
--- 0.17161250114440918 seconds for one epoch ---
--- 1.812551736831665 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19730394]
 [0.        ]]
[[-9.059329 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1897302]
 [ 0.       ]]
--- 0.17458462715148926 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4034.66015625, (1363.3926, 2.558776, 2668.3157, 0.39313576)
   validation loss 896.2236938476562, (596.4109, 0.6463536, 298.77335, 0.39313576)
decoder loss ratio: 23105.993242, decoder SINDy loss  ratio: 0.644944
--- 0.14639639854431152 seconds for one epoch ---
--- 0.1494457721710205 seconds for one epoch ---
--- 1.9545698165893555 seconds for one epoch ---
--- 0.17663049697875977 seconds for one epoch ---
--- 1.8164923191070557 seconds for one epoch ---
--- 0.21956610679626465 seconds for one epoch ---
--- 1.9723763465881348 seconds for one epoch ---
--- 0.14742231369018555 seconds for one epoch ---
--- 1.7933430671691895 seconds for one epoch ---
--- 0.17896175384521484 seconds for one epoch ---
--- 1.8550159931182861 seconds for one epoch ---
--- 0.15060806274414062 seconds for one epoch ---
--- 1.850762128829956 seconds for one epoch ---
--- 0.17258048057556152 seconds for one epoch ---
--- 1.7876663208007812 seconds for one epoch ---
--- 0.16934657096862793 seconds for one epoch ---
--- 1.8901147842407227 seconds for one epoch ---
--- 0.167952299118042 seconds for one epoch ---
--- 1.8847427368164062 seconds for one epoch ---
--- 0.17202258110046387 seconds for one epoch ---
--- 1.8331279754638672 seconds for one epoch ---
--- 0.20270371437072754 seconds for one epoch ---
--- 1.8236362934112549 seconds for one epoch ---
--- 0.18172669410705566 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18014339]
 [0.        ]]
[[-9.063477 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1556059]
 [ 0.       ]]
--- 0.16459441184997559 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2800.770751953125, (1004.2772, 1.130429, 1794.9739, 0.3890439)
   validation loss 1147.6290283203125, (829.9832, 0.6424995, 316.61432, 0.3890439)
decoder loss ratio: 32154.990676, decoder SINDy loss  ratio: 0.683457
--- 0.15463733673095703 seconds for one epoch ---
--- 1.8518280982971191 seconds for one epoch ---
--- 0.18201327323913574 seconds for one epoch ---
--- 2.020418167114258 seconds for one epoch ---
--- 0.17121624946594238 seconds for one epoch ---
--- 1.913956642150879 seconds for one epoch ---
--- 0.20410585403442383 seconds for one epoch ---
--- 1.8495025634765625 seconds for one epoch ---
--- 0.1867523193359375 seconds for one epoch ---
--- 1.89542555809021 seconds for one epoch ---
--- 0.18274950981140137 seconds for one epoch ---
--- 1.8223323822021484 seconds for one epoch ---
--- 0.19036269187927246 seconds for one epoch ---
--- 1.816469430923462 seconds for one epoch ---
--- 0.17197608947753906 seconds for one epoch ---
--- 2.006427764892578 seconds for one epoch ---
--- 0.15991759300231934 seconds for one epoch ---
--- 1.852834701538086 seconds for one epoch ---
--- 0.1671600341796875 seconds for one epoch ---
--- 1.902416706085205 seconds for one epoch ---
--- 0.14992785453796387 seconds for one epoch ---
--- 2.16550874710083 seconds for one epoch ---
--- 0.19302582740783691 seconds for one epoch ---
--- 1.8608770370483398 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16378394]
 [0.        ]]
[[-9.071581 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1206397]
 [-0.       ]]
--- 0.2032763957977295 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5742.27099609375, (2045.3821, 7.218168, 3689.2861, 0.3844156)
   validation loss 1265.1488037109375, (953.83, 0.69869703, 310.23578, 0.3844156)
decoder loss ratio: 36953.030784, decoder SINDy loss  ratio: 0.669688
--- 0.16557049751281738 seconds for one epoch ---
--- 0.19684219360351562 seconds for one epoch ---
--- 1.8426687717437744 seconds for one epoch ---
--- 0.2206566333770752 seconds for one epoch ---
--- 1.9961767196655273 seconds for one epoch ---
--- 0.18457460403442383 seconds for one epoch ---
--- 1.8797345161437988 seconds for one epoch ---
--- 0.1934821605682373 seconds for one epoch ---
--- 1.8831491470336914 seconds for one epoch ---
--- 0.19359183311462402 seconds for one epoch ---
--- 1.8718972206115723 seconds for one epoch ---
--- 0.18629741668701172 seconds for one epoch ---
--- 1.9710822105407715 seconds for one epoch ---
--- 0.1563129425048828 seconds for one epoch ---
--- 1.8308959007263184 seconds for one epoch ---
--- 0.1587967872619629 seconds for one epoch ---
--- 2.003720998764038 seconds for one epoch ---
--- 0.21334314346313477 seconds for one epoch ---
--- 1.9662086963653564 seconds for one epoch ---
--- 0.2009410858154297 seconds for one epoch ---
--- 2.149963855743408 seconds for one epoch ---
--- 0.1969616413116455 seconds for one epoch ---
--- 1.9921855926513672 seconds for one epoch ---
--- 0.14996719360351562 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14823984]
 [0.        ]]
[[-9.078262 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0847248]
 [-0.       ]]
--- 0.1790456771850586 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3063.880859375, (1359.3209, 1.7142966, 1702.4652, 0.380465)
   validation loss 891.21875, (567.64355, 0.6019385, 322.59277, 0.380465)
decoder loss ratio: 21991.496781, decoder SINDy loss  ratio: 0.696362
--- 0.1861560344696045 seconds for one epoch ---
--- 1.995877742767334 seconds for one epoch ---
--- 0.18118762969970703 seconds for one epoch ---
--- 2.058696985244751 seconds for one epoch ---
--- 0.1692805290222168 seconds for one epoch ---
--- 1.9901924133300781 seconds for one epoch ---
--- 0.1905064582824707 seconds for one epoch ---
--- 1.9462430477142334 seconds for one epoch ---
--- 0.2171938419342041 seconds for one epoch ---
--- 1.8846516609191895 seconds for one epoch ---
--- 0.17339777946472168 seconds for one epoch ---
--- 1.8908610343933105 seconds for one epoch ---
--- 0.20017147064208984 seconds for one epoch ---
--- 1.8409383296966553 seconds for one epoch ---
--- 0.1899583339691162 seconds for one epoch ---
--- 2.083071708679199 seconds for one epoch ---
--- 0.18980646133422852 seconds for one epoch ---
--- 2.0336408615112305 seconds for one epoch ---
--- 0.20248770713806152 seconds for one epoch ---
--- 1.9645764827728271 seconds for one epoch ---
--- 0.20968246459960938 seconds for one epoch ---
--- 2.001643180847168 seconds for one epoch ---
--- 0.1878948211669922 seconds for one epoch ---
--- 2.099330186843872 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1357246]
 [0.       ]]
[[-9.088313 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0534865]
 [ 0.       ]]
--- 0.17386603355407715 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1876.1788330078125, (749.4367, 2.884337, 1123.4813, 0.37649617)
   validation loss 780.7542114257812, (483.21854, 0.7250447, 296.43414, 0.37649617)
decoder loss ratio: 18720.725004, decoder SINDy loss  ratio: 0.639895
--- 0.18179965019226074 seconds for one epoch ---
--- 0.1703488826751709 seconds for one epoch ---
--- 1.8998923301696777 seconds for one epoch ---
--- 0.17005157470703125 seconds for one epoch ---
--- 2.087798595428467 seconds for one epoch ---
--- 0.15905451774597168 seconds for one epoch ---
--- 1.9556143283843994 seconds for one epoch ---
--- 0.15498900413513184 seconds for one epoch ---
--- 1.8972625732421875 seconds for one epoch ---
--- 0.21909737586975098 seconds for one epoch ---
--- 2.063098907470703 seconds for one epoch ---
--- 0.22109651565551758 seconds for one epoch ---
--- 1.9534876346588135 seconds for one epoch ---
--- 0.24052762985229492 seconds for one epoch ---
--- 2.104257106781006 seconds for one epoch ---
--- 0.20349860191345215 seconds for one epoch ---
--- 1.8785784244537354 seconds for one epoch ---
--- 0.21035122871398926 seconds for one epoch ---
--- 1.9235286712646484 seconds for one epoch ---
--- 0.21177458763122559 seconds for one epoch ---
--- 2.0569956302642822 seconds for one epoch ---
--- 0.23182344436645508 seconds for one epoch ---
--- 1.836622953414917 seconds for one epoch ---
--- 0.1975243091583252 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12577514]
 [0.        ]]
[[-9.102302 ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0268801]
 [ 0.       ]]
--- 0.1778571605682373 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3193.806884765625, (1714.5671, 0.6439261, 1478.2227, 0.3734122)
   validation loss 907.3834228515625, (597.75366, 0.6634412, 308.59286, 0.3734122)
decoder loss ratio: 23158.014616, decoder SINDy loss  ratio: 0.666141
--- 0.20589041709899902 seconds for one epoch ---
--- 1.9230437278747559 seconds for one epoch ---
--- 0.17686057090759277 seconds for one epoch ---
--- 1.8867907524108887 seconds for one epoch ---
--- 0.18264436721801758 seconds for one epoch ---
--- 1.8847575187683105 seconds for one epoch ---
--- 0.14793920516967773 seconds for one epoch ---
--- 1.9378278255462646 seconds for one epoch ---
--- 0.23580455780029297 seconds for one epoch ---
--- 1.896017074584961 seconds for one epoch ---
--- 0.20578551292419434 seconds for one epoch ---
--- 1.9402084350585938 seconds for one epoch ---
--- 0.18979358673095703 seconds for one epoch ---
--- 1.9551732540130615 seconds for one epoch ---
--- 0.19476056098937988 seconds for one epoch ---
--- 1.8572251796722412 seconds for one epoch ---
--- 0.22258806228637695 seconds for one epoch ---
--- 1.9721243381500244 seconds for one epoch ---
--- 0.20300650596618652 seconds for one epoch ---
--- 1.936532735824585 seconds for one epoch ---
--- 0.2027437686920166 seconds for one epoch ---
--- 1.974658727645874 seconds for one epoch ---
--- 0.20220375061035156 seconds for one epoch ---
--- 1.9357752799987793 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11649683]
 [0.        ]]
[[-9.113141 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.0004017]
 [-0.       ]]
--- 0.17746829986572266 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1608.21728515625, (937.9176, 1.9231848, 668.00586, 0.3705803)
   validation loss 942.0320434570312, (648.0431, 0.691123, 292.92725, 0.3705803)
decoder loss ratio: 25106.314391, decoder SINDy loss  ratio: 0.632325
--- 0.173170804977417 seconds for one epoch ---
--- 0.18665266036987305 seconds for one epoch ---
--- 1.9488468170166016 seconds for one epoch ---
--- 0.2220470905303955 seconds for one epoch ---
--- 1.895770788192749 seconds for one epoch ---
--- 0.2355053424835205 seconds for one epoch ---
--- 1.9026694297790527 seconds for one epoch ---
--- 0.212019681930542 seconds for one epoch ---
--- 1.9425384998321533 seconds for one epoch ---
--- 0.16264081001281738 seconds for one epoch ---
--- 1.9352991580963135 seconds for one epoch ---
--- 0.1634540557861328 seconds for one epoch ---
--- 1.8333585262298584 seconds for one epoch ---
--- 0.2372293472290039 seconds for one epoch ---
--- 1.8803160190582275 seconds for one epoch ---
--- 0.2429337501525879 seconds for one epoch ---
--- 1.9699859619140625 seconds for one epoch ---
--- 0.1732926368713379 seconds for one epoch ---
--- 2.057755470275879 seconds for one epoch ---
--- 0.22832703590393066 seconds for one epoch ---
--- 1.9181020259857178 seconds for one epoch ---
--- 0.20476913452148438 seconds for one epoch ---
--- 1.886721134185791 seconds for one epoch ---
--- 0.21272778511047363 seconds for one epoch ---
=========================
[[1.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10745606]
 [0.        ]]
[[-9.120312  ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.97278565]
 [-0.        ]]
--- 0.15389704704284668 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1869.9365234375, (925.2502, 2.0636117, 942.2549, 0.36786634)
   validation loss 822.2335205078125, (521.4033, 0.7688862, 299.69348, 0.36786634)
decoder loss ratio: 20200.069825, decoder SINDy loss  ratio: 0.646931
--- 0.18429970741271973 seconds for one epoch ---
--- 1.932769536972046 seconds for one epoch ---
--- 0.202728271484375 seconds for one epoch ---
--- 1.9799246788024902 seconds for one epoch ---
--- 0.19930171966552734 seconds for one epoch ---
--- 1.916511058807373 seconds for one epoch ---
--- 0.21439433097839355 seconds for one epoch ---
--- 1.9889628887176514 seconds for one epoch ---
--- 0.15433096885681152 seconds for one epoch ---
--- 1.89412522315979 seconds for one epoch ---
--- 0.23340749740600586 seconds for one epoch ---
--- 2.1940805912017822 seconds for one epoch ---
--- 0.22617340087890625 seconds for one epoch ---
--- 1.9258575439453125 seconds for one epoch ---
--- 0.16491222381591797 seconds for one epoch ---
--- 2.0660653114318848 seconds for one epoch ---
--- 0.17536163330078125 seconds for one epoch ---
--- 2.0717482566833496 seconds for one epoch ---
--- 0.1692948341369629 seconds for one epoch ---
--- 2.071922540664673 seconds for one epoch ---
--- 0.17485904693603516 seconds for one epoch ---
--- 2.0269813537597656 seconds for one epoch ---
--- 0.18159008026123047 seconds for one epoch ---
--- 1.858886957168579 seconds for one epoch ---
=========================
[[1.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1009661]
 [0.       ]]
[[-9.139262  ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.95167994]
 [ 0.        ]]
--- 0.19990038871765137 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1868.04443359375, (1015.0154, 0.32280076, 852.34064, 0.36560827)
   validation loss 779.7466430664062, (486.58466, 0.7068036, 292.08957, 0.36560827)
decoder loss ratio: 18851.134312, decoder SINDy loss  ratio: 0.630516
THRESHOLDING: 1 active coefficients
--- 1.880875587463379 seconds for one epoch ---
--- 0.2377469539642334 seconds for one epoch ---
--- 2.0091962814331055 seconds for one epoch ---
--- 0.2247602939605713 seconds for one epoch ---
--- 1.990783452987671 seconds for one epoch ---
--- 0.17001795768737793 seconds for one epoch ---
--- 1.9583804607391357 seconds for one epoch ---
--- 0.1719357967376709 seconds for one epoch ---
--- 1.88641357421875 seconds for one epoch ---
--- 0.2645301818847656 seconds for one epoch ---
--- 1.908813238143921 seconds for one epoch ---
--- 0.19867873191833496 seconds for one epoch ---
--- 2.12432599067688 seconds for one epoch ---
--- 0.2039966583251953 seconds for one epoch ---
--- 2.0153138637542725 seconds for one epoch ---
--- 0.20238471031188965 seconds for one epoch ---
--- 1.9334073066711426 seconds for one epoch ---
--- 0.14507842063903809 seconds for one epoch ---
--- 1.8850517272949219 seconds for one epoch ---
--- 0.23662996292114258 seconds for one epoch ---
--- 1.9916951656341553 seconds for one epoch ---
--- 0.15345358848571777 seconds for one epoch ---
--- 1.9318459033966064 seconds for one epoch ---
--- 0.16756558418273926 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.156728]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.18292498588562012 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2718.690673828125, (1060.7919, 0.67111, 1656.9136, 0.31409037)
   validation loss 789.91748046875, (480.84143, 0.7835579, 307.97836, 0.31409037)
decoder loss ratio: 18628.631801, decoder SINDy loss  ratio: 0.664815
--- 0.22683191299438477 seconds for one epoch ---
--- 1.9512913227081299 seconds for one epoch ---
--- 0.25645899772644043 seconds for one epoch ---
--- 2.034003973007202 seconds for one epoch ---
--- 0.17569255828857422 seconds for one epoch ---
--- 1.976672887802124 seconds for one epoch ---
--- 0.19963908195495605 seconds for one epoch ---
--- 1.944136381149292 seconds for one epoch ---
--- 0.2344963550567627 seconds for one epoch ---
--- 2.1351969242095947 seconds for one epoch ---
--- 0.1600813865661621 seconds for one epoch ---
--- 2.0123374462127686 seconds for one epoch ---
--- 0.23055171966552734 seconds for one epoch ---
--- 2.1080970764160156 seconds for one epoch ---
--- 0.1438765525817871 seconds for one epoch ---
--- 2.0017685890197754 seconds for one epoch ---
--- 0.24066877365112305 seconds for one epoch ---
--- 2.1517577171325684 seconds for one epoch ---
--- 0.1676313877105713 seconds for one epoch ---
--- 1.9926927089691162 seconds for one epoch ---
--- 0.15301966667175293 seconds for one epoch ---
--- 1.9642298221588135 seconds for one epoch ---
--- 0.20259952545166016 seconds for one epoch ---
--- 2.010420560836792 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.19104]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]]
--- 0.2717933654785156 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3810.0966796875, (1810.0548, 0.30256465, 1999.4249, 0.3145295)
   validation loss 747.4202270507812, (466.50397, 0.70089155, 279.90088, 0.3145295)
decoder loss ratio: 18073.173579, decoder SINDy loss  ratio: 0.604205
--- 0.18843507766723633 seconds for one epoch ---
--- 0.2118685245513916 seconds for one epoch ---
--- 1.9556488990783691 seconds for one epoch ---
--- 0.21941804885864258 seconds for one epoch ---
--- 2.0132930278778076 seconds for one epoch ---
--- 0.1572587490081787 seconds for one epoch ---
--- 2.0011379718780518 seconds for one epoch ---
--- 0.21454858779907227 seconds for one epoch ---
--- 2.00026535987854 seconds for one epoch ---
--- 0.21668672561645508 seconds for one epoch ---
--- 2.2135424613952637 seconds for one epoch ---
--- 0.16497254371643066 seconds for one epoch ---
--- 1.9806406497955322 seconds for one epoch ---
--- 0.20038843154907227 seconds for one epoch ---
--- 2.097141742706299 seconds for one epoch ---
--- 0.14316487312316895 seconds for one epoch ---
--- 2.0223677158355713 seconds for one epoch ---
--- 0.19456100463867188 seconds for one epoch ---
--- 2.002000093460083 seconds for one epoch ---
--- 0.20498991012573242 seconds for one epoch ---
--- 2.2051303386688232 seconds for one epoch ---
--- 0.23112082481384277 seconds for one epoch ---
--- 2.0912325382232666 seconds for one epoch ---
--- 0.17109227180480957 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.211389]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.17775177955627441 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1737.0020751953125, (736.8145, 0.6238402, 999.2489, 0.3147931)
   validation loss 771.66015625, (480.96622, 0.72950506, 289.64963, 0.3147931)
decoder loss ratio: 18633.466242, decoder SINDy loss  ratio: 0.625249
--- 0.21639800071716309 seconds for one epoch ---
--- 1.9696085453033447 seconds for one epoch ---
--- 0.22278857231140137 seconds for one epoch ---
--- 2.1368472576141357 seconds for one epoch ---
--- 0.18249988555908203 seconds for one epoch ---
--- 2.012131452560425 seconds for one epoch ---
--- 0.21035456657409668 seconds for one epoch ---
--- 2.03071928024292 seconds for one epoch ---
--- 0.21373534202575684 seconds for one epoch ---
--- 1.9923317432403564 seconds for one epoch ---
--- 0.21070051193237305 seconds for one epoch ---
--- 2.158320188522339 seconds for one epoch ---
--- 0.2104790210723877 seconds for one epoch ---
--- 2.201143980026245 seconds for one epoch ---
--- 0.1652829647064209 seconds for one epoch ---
--- 2.194490909576416 seconds for one epoch ---
--- 0.21680617332458496 seconds for one epoch ---
--- 2.030172824859619 seconds for one epoch ---
--- 0.1939244270324707 seconds for one epoch ---
--- 1.9972033500671387 seconds for one epoch ---
--- 0.1537175178527832 seconds for one epoch ---
--- 1.9270997047424316 seconds for one epoch ---
--- 0.22209930419921875 seconds for one epoch ---
--- 1.9230320453643799 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.236704]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.2361135482788086 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2796.089111328125, (1259.3685, 3.5704215, 1532.8351, 0.3151008)
   validation loss 1175.78369140625, (856.2431, 0.8201491, 318.40536, 0.3151008)
decoder loss ratio: 33172.344315, decoder SINDy loss  ratio: 0.687323
--- 0.17127680778503418 seconds for one epoch ---
--- 0.27036380767822266 seconds for one epoch ---
--- 1.9751322269439697 seconds for one epoch ---
--- 0.23007798194885254 seconds for one epoch ---
--- 2.0810534954071045 seconds for one epoch ---
--- 0.1537177562713623 seconds for one epoch ---
--- 2.1593172550201416 seconds for one epoch ---
--- 0.15958476066589355 seconds for one epoch ---
--- 2.1526451110839844 seconds for one epoch ---
--- 0.23674368858337402 seconds for one epoch ---
--- 2.0403528213500977 seconds for one epoch ---
--- 0.24581384658813477 seconds for one epoch ---
--- 2.0302820205688477 seconds for one epoch ---
--- 0.2640254497528076 seconds for one epoch ---
--- 1.9985928535461426 seconds for one epoch ---
--- 0.268190860748291 seconds for one epoch ---
--- 2.0333051681518555 seconds for one epoch ---
--- 0.2540414333343506 seconds for one epoch ---
--- 2.0164289474487305 seconds for one epoch ---
--- 0.265794038772583 seconds for one epoch ---
--- 2.0013797283172607 seconds for one epoch ---
--- 0.26144933700561523 seconds for one epoch ---
--- 2.0627622604370117 seconds for one epoch ---
--- 0.15953421592712402 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.254951]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.16847705841064453 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2533.048828125, (1259.443, 0.48212668, 1272.8082, 0.31537977)
   validation loss 819.861083984375, (536.1877, 0.7013118, 282.65674, 0.31537977)
decoder loss ratio: 20772.841706, decoder SINDy loss  ratio: 0.610154
--- 0.202193021774292 seconds for one epoch ---
--- 1.9736216068267822 seconds for one epoch ---
--- 0.21745944023132324 seconds for one epoch ---
--- 2.1092658042907715 seconds for one epoch ---
--- 0.15483689308166504 seconds for one epoch ---
--- 2.0206167697906494 seconds for one epoch ---
--- 0.22530269622802734 seconds for one epoch ---
--- 2.216115951538086 seconds for one epoch ---
--- 0.19982409477233887 seconds for one epoch ---
--- 2.024768590927124 seconds for one epoch ---
--- 0.2161421775817871 seconds for one epoch ---
--- 2.0810632705688477 seconds for one epoch ---
--- 0.20103073120117188 seconds for one epoch ---
--- 2.16610050201416 seconds for one epoch ---
--- 0.2474532127380371 seconds for one epoch ---
--- 2.0498225688934326 seconds for one epoch ---
--- 0.2066662311553955 seconds for one epoch ---
--- 2.020723819732666 seconds for one epoch ---
--- 0.21736764907836914 seconds for one epoch ---
--- 1.9907855987548828 seconds for one epoch ---
--- 0.24587488174438477 seconds for one epoch ---
--- 1.9783039093017578 seconds for one epoch ---
--- 0.1474928855895996 seconds for one epoch ---
--- 2.044070243835449 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.266888]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.2542562484741211 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6124.51806640625, (1520.6886, 3.6671855, 4599.8467, 0.31551585)
   validation loss 995.8314208984375, (697.0569, 0.7283321, 297.7307, 0.31551585)
decoder loss ratio: 27005.193860, decoder SINDy loss  ratio: 0.642694
--- 0.18852996826171875 seconds for one epoch ---
--- 0.23962831497192383 seconds for one epoch ---
--- 1.984100103378296 seconds for one epoch ---
--- 0.2172856330871582 seconds for one epoch ---
--- 2.1581473350524902 seconds for one epoch ---
--- 0.20818567276000977 seconds for one epoch ---
--- 2.1485509872436523 seconds for one epoch ---
--- 0.1867678165435791 seconds for one epoch ---
--- 2.108248472213745 seconds for one epoch ---
--- 0.19834589958190918 seconds for one epoch ---
--- 2.0451691150665283 seconds for one epoch ---
--- 0.25005197525024414 seconds for one epoch ---
--- 2.0748753547668457 seconds for one epoch ---
--- 0.18434977531433105 seconds for one epoch ---
--- 2.147656202316284 seconds for one epoch ---
--- 0.17350029945373535 seconds for one epoch ---
--- 1.982396125793457 seconds for one epoch ---
--- 0.2657933235168457 seconds for one epoch ---
--- 2.1913211345672607 seconds for one epoch ---
--- 0.26627302169799805 seconds for one epoch ---
--- 1.9943382740020752 seconds for one epoch ---
--- 0.17121529579162598 seconds for one epoch ---
--- 2.012697458267212 seconds for one epoch ---
--- 0.23412656784057617 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.283242]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.19283246994018555 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3194.85791015625, (1672.2057, 1.31951, 1521.0171, 0.31574997)
   validation loss 684.5946655273438, (407.2717, 0.7198934, 276.28732, 0.31574997)
decoder loss ratio: 15778.412635, decoder SINDy loss  ratio: 0.596405
--- 0.2508997917175293 seconds for one epoch ---
--- 2.0785017013549805 seconds for one epoch ---
--- 0.21808266639709473 seconds for one epoch ---
--- 2.0656275749206543 seconds for one epoch ---
--- 0.19447088241577148 seconds for one epoch ---
--- 2.0377402305603027 seconds for one epoch ---
--- 0.14114022254943848 seconds for one epoch ---
--- 2.08371901512146 seconds for one epoch ---
--- 0.25504302978515625 seconds for one epoch ---
--- 2.0554068088531494 seconds for one epoch ---
--- 0.2095491886138916 seconds for one epoch ---
--- 2.010270833969116 seconds for one epoch ---
--- 0.23448681831359863 seconds for one epoch ---
--- 2.0389771461486816 seconds for one epoch ---
--- 0.228759765625 seconds for one epoch ---
--- 1.9460322856903076 seconds for one epoch ---
--- 0.2751898765563965 seconds for one epoch ---
--- 2.1558310985565186 seconds for one epoch ---
--- 0.24199247360229492 seconds for one epoch ---
--- 2.082425117492676 seconds for one epoch ---
--- 0.17931818962097168 seconds for one epoch ---
--- 2.0865910053253174 seconds for one epoch ---
--- 0.23589730262756348 seconds for one epoch ---
--- 2.051053285598755 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.302887]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.2120523452758789 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3361.42138671875, (1642.7147, 1.7899406, 1716.6007, 0.31602284)
   validation loss 708.98583984375, (437.80133, 0.7288851, 270.13956, 0.31602284)
decoder loss ratio: 16961.183603, decoder SINDy loss  ratio: 0.583134
--- 0.214341402053833 seconds for one epoch ---
--- 0.22802233695983887 seconds for one epoch ---
--- 1.995100736618042 seconds for one epoch ---
--- 0.21591854095458984 seconds for one epoch ---
--- 2.083893299102783 seconds for one epoch ---
--- 0.2517986297607422 seconds for one epoch ---
--- 2.1455013751983643 seconds for one epoch ---
--- 0.2692885398864746 seconds for one epoch ---
--- 2.0951666831970215 seconds for one epoch ---
--- 0.16071510314941406 seconds for one epoch ---
--- 2.0433201789855957 seconds for one epoch ---
--- 0.25839734077453613 seconds for one epoch ---
--- 2.085402011871338 seconds for one epoch ---
--- 0.1641249656677246 seconds for one epoch ---
--- 2.0750319957733154 seconds for one epoch ---
--- 0.15752840042114258 seconds for one epoch ---
--- 2.3328630924224854 seconds for one epoch ---
--- 0.17313718795776367 seconds for one epoch ---
--- 2.0459401607513428 seconds for one epoch ---
--- 0.17855262756347656 seconds for one epoch ---
--- 2.1757452487945557 seconds for one epoch ---
--- 0.19182729721069336 seconds for one epoch ---
--- 2.020120859146118 seconds for one epoch ---
--- 0.22270917892456055 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.319982]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.18688082695007324 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2374.601318359375, (1120.791, 0.24109809, 1253.2529, 0.3162282)
   validation loss 1065.2181396484375, (758.5091, 0.75094765, 305.64178, 0.3162282)
decoder loss ratio: 29385.959140, decoder SINDy loss  ratio: 0.659771
--- 0.2658224105834961 seconds for one epoch ---
--- 2.1366846561431885 seconds for one epoch ---
--- 0.16141915321350098 seconds for one epoch ---
--- 2.055481433868408 seconds for one epoch ---
--- 0.28543806076049805 seconds for one epoch ---
--- 2.1306955814361572 seconds for one epoch ---
--- 0.16308808326721191 seconds for one epoch ---
--- 2.272392749786377 seconds for one epoch ---
--- 0.22548341751098633 seconds for one epoch ---
--- 2.2802250385284424 seconds for one epoch ---
--- 0.21266412734985352 seconds for one epoch ---
--- 2.0872764587402344 seconds for one epoch ---
--- 0.1737346649169922 seconds for one epoch ---
--- 2.1004528999328613 seconds for one epoch ---
--- 0.1966090202331543 seconds for one epoch ---
--- 2.0382466316223145 seconds for one epoch ---
--- 0.2834737300872803 seconds for one epoch ---
--- 2.1833858489990234 seconds for one epoch ---
--- 0.17096543312072754 seconds for one epoch ---
--- 2.011884927749634 seconds for one epoch ---
--- 0.20242547988891602 seconds for one epoch ---
--- 2.1160812377929688 seconds for one epoch ---
--- 0.24616765975952148 seconds for one epoch ---
--- 2.2538411617279053 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.331949]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.19176363945007324 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2395.25341796875, (1293.5032, 0.25396317, 1101.1798, 0.31638813)
   validation loss 843.6846313476562, (538.0888, 0.7641917, 304.5152, 0.31638813)
decoder loss ratio: 20846.494514, decoder SINDy loss  ratio: 0.657339
--- 0.18883848190307617 seconds for one epoch ---
--- 0.27276062965393066 seconds for one epoch ---
--- 2.086778163909912 seconds for one epoch ---
--- 0.20228338241577148 seconds for one epoch ---
--- 2.136820077896118 seconds for one epoch ---
--- 0.14722776412963867 seconds for one epoch ---
--- 2.038264751434326 seconds for one epoch ---
--- 0.21626901626586914 seconds for one epoch ---
--- 2.1785900592803955 seconds for one epoch ---
--- 0.20083141326904297 seconds for one epoch ---
--- 2.1119093894958496 seconds for one epoch ---
--- 0.18292999267578125 seconds for one epoch ---
--- 2.045513868331909 seconds for one epoch ---
--- 0.23306846618652344 seconds for one epoch ---
--- 2.089465618133545 seconds for one epoch ---
--- 0.27669620513916016 seconds for one epoch ---
--- 2.1282763481140137 seconds for one epoch ---
--- 0.15462613105773926 seconds for one epoch ---
--- 2.053365468978882 seconds for one epoch ---
--- 0.2091212272644043 seconds for one epoch ---
--- 2.0148770809173584 seconds for one epoch ---
--- 0.28237271308898926 seconds for one epoch ---
--- 2.0995826721191406 seconds for one epoch ---
--- 0.20554161071777344 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.347697]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.2606995105743408 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4015.555419921875, (1439.3114, 0.5165246, 2575.411, 0.3165607)
   validation loss 863.170166015625, (577.56805, 0.8718054, 284.4137, 0.3165607)
decoder loss ratio: 22375.989122, decoder SINDy loss  ratio: 0.613947
--- 0.2821695804595947 seconds for one epoch ---
--- 2.1775312423706055 seconds for one epoch ---
--- 0.21495914459228516 seconds for one epoch ---
--- 2.1544313430786133 seconds for one epoch ---
--- 0.14941978454589844 seconds for one epoch ---
--- 2.1728432178497314 seconds for one epoch ---
--- 0.21207666397094727 seconds for one epoch ---
--- 2.036479949951172 seconds for one epoch ---
--- 0.22829103469848633 seconds for one epoch ---
--- 2.0481393337249756 seconds for one epoch ---
--- 0.288102388381958 seconds for one epoch ---
--- 2.298447608947754 seconds for one epoch ---
--- 0.14993524551391602 seconds for one epoch ---
--- 2.0923733711242676 seconds for one epoch ---
--- 0.18915796279907227 seconds for one epoch ---
--- 2.0765607357025146 seconds for one epoch ---
--- 0.2338542938232422 seconds for one epoch ---
--- 2.077702522277832 seconds for one epoch ---
--- 0.2790491580963135 seconds for one epoch ---
--- 2.256638765335083 seconds for one epoch ---
--- 0.1758871078491211 seconds for one epoch ---
--- 2.109339475631714 seconds for one epoch ---
--- 0.6680617332458496 seconds for one epoch ---
--- 2.0613136291503906 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.360774]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.29581403732299805 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4204.6748046875, (1928.1486, 5.1021757, 2271.1072, 0.31670797)
   validation loss 934.7525024414062, (645.85126, 0.7504835, 287.83405, 0.31670797)
decoder loss ratio: 25021.398956, decoder SINDy loss  ratio: 0.621330
--- 0.20397543907165527 seconds for one epoch ---
--- 0.2163867950439453 seconds for one epoch ---
--- 2.0946950912475586 seconds for one epoch ---
--- 0.23460793495178223 seconds for one epoch ---
--- 2.227654457092285 seconds for one epoch ---
--- 0.23579168319702148 seconds for one epoch ---
--- 2.2733380794525146 seconds for one epoch ---
--- 0.16701459884643555 seconds for one epoch ---
--- 2.19167423248291 seconds for one epoch ---
--- 0.21703815460205078 seconds for one epoch ---
--- 2.1129846572875977 seconds for one epoch ---
--- 0.24870562553405762 seconds for one epoch ---
--- 2.3089489936828613 seconds for one epoch ---
--- 0.2024211883544922 seconds for one epoch ---
--- 2.149451494216919 seconds for one epoch ---
--- 0.1721205711364746 seconds for one epoch ---
--- 2.202597141265869 seconds for one epoch ---
--- 0.25229883193969727 seconds for one epoch ---
--- 2.077460289001465 seconds for one epoch ---
--- 0.2401599884033203 seconds for one epoch ---
--- 2.071638584136963 seconds for one epoch ---
--- 0.2891700267791748 seconds for one epoch ---
--- 2.1390817165374756 seconds for one epoch ---
--- 0.2275385856628418 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.370474]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.13043880462646484 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4012.233642578125, (1513.9493, 4.0024066, 2493.965, 0.31675193)
   validation loss 893.6634521484375, (601.5184, 0.8967061, 290.93158, 0.31675193)
decoder loss ratio: 23303.865997, decoder SINDy loss  ratio: 0.628017
--- 0.2537851333618164 seconds for one epoch ---
--- 2.2769906520843506 seconds for one epoch ---
--- 0.1453549861907959 seconds for one epoch ---
--- 2.1970553398132324 seconds for one epoch ---
--- 0.16213393211364746 seconds for one epoch ---
--- 2.176374673843384 seconds for one epoch ---
--- 0.20525813102722168 seconds for one epoch ---
--- 2.1207499504089355 seconds for one epoch ---
--- 0.17157649993896484 seconds for one epoch ---
--- 2.1961660385131836 seconds for one epoch ---
--- 0.14323759078979492 seconds for one epoch ---
--- 2.172342300415039 seconds for one epoch ---
--- 0.18617630004882812 seconds for one epoch ---
--- 2.132634162902832 seconds for one epoch ---
--- 0.17585420608520508 seconds for one epoch ---
--- 2.1636674404144287 seconds for one epoch ---
--- 0.29601597785949707 seconds for one epoch ---
--- 2.153881311416626 seconds for one epoch ---
--- 0.271115779876709 seconds for one epoch ---
--- 2.073059320449829 seconds for one epoch ---
--- 0.27947378158569336 seconds for one epoch ---
--- 2.048152208328247 seconds for one epoch ---
--- 0.2592780590057373 seconds for one epoch ---
--- 2.1082024574279785 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.3855]
 [ 0.    ]
 [ 0.    ]
 [ 0.    ]
 [-0.    ]
 [-0.    ]
 [ 0.    ]
 [-0.    ]
 [-0.    ]
 [-0.    ]
 [-0.    ]]
--- 0.2166156768798828 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1693.0897216796875, (1194.8978, 0.34328902, 497.53174, 0.31685594)
   validation loss 1111.53564453125, (819.2981, 0.8493735, 291.07123, 0.31685594)
decoder loss ratio: 31741.030592, decoder SINDy loss  ratio: 0.628318
--- 0.23810601234436035 seconds for one epoch ---
--- 0.17691779136657715 seconds for one epoch ---
--- 2.324398994445801 seconds for one epoch ---
--- 0.14847326278686523 seconds for one epoch ---
--- 2.157257318496704 seconds for one epoch ---
--- 0.2019028663635254 seconds for one epoch ---
--- 2.1816632747650146 seconds for one epoch ---
--- 0.1607532501220703 seconds for one epoch ---
--- 2.1808485984802246 seconds for one epoch ---
--- 0.20537519454956055 seconds for one epoch ---
--- 2.145009756088257 seconds for one epoch ---
--- 0.19951081275939941 seconds for one epoch ---
--- 2.193772315979004 seconds for one epoch ---
--- 0.20744729042053223 seconds for one epoch ---
--- 2.21933650970459 seconds for one epoch ---
--- 0.16531586647033691 seconds for one epoch ---
--- 2.172055244445801 seconds for one epoch ---
--- 0.18414521217346191 seconds for one epoch ---
--- 2.223209857940674 seconds for one epoch ---
--- 0.1596081256866455 seconds for one epoch ---
--- 2.1593806743621826 seconds for one epoch ---
--- 0.1694788932800293 seconds for one epoch ---
--- 2.228543996810913 seconds for one epoch ---
--- 0.15623164176940918 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.393413]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.18672418594360352 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2542.44775390625, (1168.4675, 2.282273, 1371.3811, 0.31677425)
   validation loss 1040.5621337890625, (756.73926, 0.81386715, 282.6923, 0.31677425)
decoder loss ratio: 29317.392605, decoder SINDy loss  ratio: 0.610231
--- 0.2781667709350586 seconds for one epoch ---
--- 2.2367897033691406 seconds for one epoch ---
--- 0.23734021186828613 seconds for one epoch ---
--- 2.237973690032959 seconds for one epoch ---
--- 0.2517533302307129 seconds for one epoch ---
--- 2.2516002655029297 seconds for one epoch ---
--- 0.22482919692993164 seconds for one epoch ---
--- 2.183988094329834 seconds for one epoch ---
--- 0.2341604232788086 seconds for one epoch ---
--- 2.2829749584198 seconds for one epoch ---
--- 0.16258811950683594 seconds for one epoch ---
--- 2.1973767280578613 seconds for one epoch ---
--- 0.20228981971740723 seconds for one epoch ---
--- 2.191479444503784 seconds for one epoch ---
--- 0.20192813873291016 seconds for one epoch ---
--- 2.180696487426758 seconds for one epoch ---
--- 0.2029571533203125 seconds for one epoch ---
--- 2.1923370361328125 seconds for one epoch ---
--- 0.2577979564666748 seconds for one epoch ---
--- 2.2881240844726562 seconds for one epoch ---
--- 0.19219255447387695 seconds for one epoch ---
--- 2.1442675590515137 seconds for one epoch ---
--- 0.2685551643371582 seconds for one epoch ---
--- 2.160452365875244 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.403007]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.24069976806640625 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2966.054931640625, (1535.7435, 1.8127993, 1428.182, 0.3166173)
   validation loss 885.3366088867188, (604.5246, 0.80352217, 279.6919, 0.3166173)
decoder loss ratio: 23420.332395, decoder SINDy loss  ratio: 0.603754
--- 0.889014482498169 seconds for one epoch ---
--- 0.22623443603515625 seconds for one epoch ---
--- 2.0314574241638184 seconds for one epoch ---
--- 0.2536299228668213 seconds for one epoch ---
--- 2.1779158115386963 seconds for one epoch ---
--- 0.23117566108703613 seconds for one epoch ---
--- 2.186675786972046 seconds for one epoch ---
--- 0.15094876289367676 seconds for one epoch ---
--- 2.2275450229644775 seconds for one epoch ---
--- 0.19046235084533691 seconds for one epoch ---
--- 2.1551096439361572 seconds for one epoch ---
--- 0.2688608169555664 seconds for one epoch ---
--- 2.131730079650879 seconds for one epoch ---
--- 0.25224971771240234 seconds for one epoch ---
--- 2.0717103481292725 seconds for one epoch ---
--- 0.27585887908935547 seconds for one epoch ---
--- 2.3735530376434326 seconds for one epoch ---
--- 0.21167850494384766 seconds for one epoch ---
--- 2.3448126316070557 seconds for one epoch ---
--- 0.1474897861480713 seconds for one epoch ---
--- 2.323343276977539 seconds for one epoch ---
--- 0.2040722370147705 seconds for one epoch ---
--- 2.258789539337158 seconds for one epoch ---
--- 0.2347278594970703 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.4132395]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.23006796836853027 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3021.9736328125, (990.4467, 1.0292822, 2030.1812, 0.31631428)
   validation loss 742.9937744140625, (460.06885, 0.7595591, 281.84912, 0.31631428)
decoder loss ratio: 17823.865873, decoder SINDy loss  ratio: 0.608411
--- 0.27693963050842285 seconds for one epoch ---
--- 2.2349462509155273 seconds for one epoch ---
--- 0.17528915405273438 seconds for one epoch ---
--- 2.216526746749878 seconds for one epoch ---
--- 0.19296002388000488 seconds for one epoch ---
--- 2.234990119934082 seconds for one epoch ---
--- 0.2520442008972168 seconds for one epoch ---
--- 2.1882712841033936 seconds for one epoch ---
--- 0.27767300605773926 seconds for one epoch ---
--- 2.14280366897583 seconds for one epoch ---
--- 0.2746243476867676 seconds for one epoch ---
--- 2.1752541065216064 seconds for one epoch ---
--- 0.22852659225463867 seconds for one epoch ---
--- 2.192095994949341 seconds for one epoch ---
--- 0.24616718292236328 seconds for one epoch ---
--- 2.2047111988067627 seconds for one epoch ---
--- 0.17073297500610352 seconds for one epoch ---
--- 2.2423367500305176 seconds for one epoch ---
--- 0.17990899085998535 seconds for one epoch ---
--- 2.149423360824585 seconds for one epoch ---
--- 0.2435305118560791 seconds for one epoch ---
--- 2.0712342262268066 seconds for one epoch ---
--- 0.2537875175476074 seconds for one epoch ---
--- 2.32991886138916 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.430642]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.27583837509155273 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2241.939208984375, (856.9177, 0.5422144, 1384.1633, 0.3158739)
   validation loss 766.8473510742188, (485.83167, 0.79724663, 279.9026, 0.3158739)
decoder loss ratio: 18821.962144, decoder SINDy loss  ratio: 0.604209
--- 0.1454768180847168 seconds for one epoch ---
--- 0.21944689750671387 seconds for one epoch ---
--- 2.2318179607391357 seconds for one epoch ---
--- 0.19169116020202637 seconds for one epoch ---
--- 2.2273008823394775 seconds for one epoch ---
--- 0.1545414924621582 seconds for one epoch ---
--- 2.186335325241089 seconds for one epoch ---
--- 0.2617025375366211 seconds for one epoch ---
--- 2.120830535888672 seconds for one epoch ---
--- 0.29520702362060547 seconds for one epoch ---
--- 2.1544816493988037 seconds for one epoch ---
--- 0.22323393821716309 seconds for one epoch ---
--- 2.183932304382324 seconds for one epoch ---
--- 0.1652066707611084 seconds for one epoch ---
--- 2.1737608909606934 seconds for one epoch ---
--- 0.25188302993774414 seconds for one epoch ---
--- 2.1360228061676025 seconds for one epoch ---
--- 0.2791016101837158 seconds for one epoch ---
--- 2.116874933242798 seconds for one epoch ---
--- 0.23970961570739746 seconds for one epoch ---
--- 2.311370372772217 seconds for one epoch ---
--- 0.22971320152282715 seconds for one epoch ---
--- 2.212068796157837 seconds for one epoch ---
--- 0.19582080841064453 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.450519]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
--- 0.2365269660949707 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3232.525146484375, (1259.8734, 1.6007158, 1970.7358, 0.31510663)
   validation loss 939.5199584960938, (668.8902, 0.76468825, 269.5499, 0.31510663)
decoder loss ratio: 25913.967505, decoder SINDy loss  ratio: 0.581861
--- 0.24150681495666504 seconds for one epoch ---
--- 2.3003313541412354 seconds for one epoch ---
--- 0.238358736038208 seconds for one epoch ---
--- 2.2459020614624023 seconds for one epoch ---
--- 0.15665459632873535 seconds for one epoch ---
--- 2.4071614742279053 seconds for one epoch ---
--- 0.2025747299194336 seconds for one epoch ---
--- 2.1812596321105957 seconds for one epoch ---
--- 0.2615385055541992 seconds for one epoch ---
--- 2.1757631301879883 seconds for one epoch ---
--- 0.27629947662353516 seconds for one epoch ---
--- 2.2065324783325195 seconds for one epoch ---
--- 0.20627856254577637 seconds for one epoch ---
--- 2.233205795288086 seconds for one epoch ---
--- 0.19684219360351562 seconds for one epoch ---
--- 2.150047540664673 seconds for one epoch ---
--- 0.29344725608825684 seconds for one epoch ---
--- 2.162813663482666 seconds for one epoch ---
--- 0.25609922409057617 seconds for one epoch ---
--- 2.282620429992676 seconds for one epoch ---
--- 0.14469575881958008 seconds for one epoch ---
--- 2.1417324542999268 seconds for one epoch ---
--- 0.2826499938964844 seconds for one epoch ---
--- 2.160583734512329 seconds for one epoch ---
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.464848]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.23013520240783691 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4192.7822265625, (969.4799, 1.5727539, 3221.4158, 0.31379423)
   validation loss 862.2022094726562, (571.6865, 0.6990889, 289.5028, 0.31379423)
decoder loss ratio: 22148.128409, decoder SINDy loss  ratio: 0.624933
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.46577]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1250.241943359375, (679.4188, 0.53054744, 570.29266, 0.29532516)
   validation loss 799.49560546875, (527.22565, 0.57716715, 271.69284, 0.29532516)
decoder loss ratio: 20425.636868, decoder SINDy loss  ratio: 0.586487
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.417596]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.609130859375, (417.92273, 0.5229137, 524.16345, 0.29517537)
   validation loss 542.9282836914062, (324.1192, 0.20917939, 218.59991, 0.29517537)
decoder loss ratio: 12556.940568, decoder SINDy loss  ratio: 0.471879
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.408591]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.1954956054688, (296.66605, 0.43301055, 503.09644, 0.29357946)
   validation loss 445.9331970214844, (232.49686, 0.14179122, 213.29456, 0.29357946)
decoder loss ratio: 9007.331860, decoder SINDy loss  ratio: 0.460426
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.126478]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.9654541015625, (356.19928, 0.40007898, 493.36612, 0.2917473)
   validation loss 515.0534057617188, (296.3096, 0.11772191, 218.62607, 0.2917473)
decoder loss ratio: 11479.548352, decoder SINDy loss  ratio: 0.471935
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-9.102108]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.1175537109375, (364.69418, 0.3819344, 491.0414, 0.29006582)
   validation loss 519.9620971679688, (301.20862, 0.1082686, 218.6452, 0.29006582)
decoder loss ratio: 11669.344789, decoder SINDy loss  ratio: 0.471976
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.964603]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.96630859375, (271.6512, 0.37207776, 491.943, 0.2886301)
   validation loss 423.0627136230469, (211.91891, 0.110008664, 211.03378, 0.2886301)
decoder loss ratio: 8210.106667, decoder SINDy loss  ratio: 0.455546
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.944383]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.572509765625, (276.32462, 0.3614648, 487.88647, 0.2874633)
   validation loss 428.8042907714844, (215.29877, 0.10047926, 213.40504, 0.2874633)
decoder loss ratio: 8341.048012, decoder SINDy loss  ratio: 0.460665
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.728812]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.2935180664062, (280.4062, 0.33671653, 485.5506, 0.28634363)
   validation loss 429.0059814453125, (215.91177, 0.09777375, 212.99641, 0.28634363)
decoder loss ratio: 8364.796952, decoder SINDy loss  ratio: 0.459783
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.723371]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 810.0487060546875, (326.9165, 0.33659104, 482.7956, 0.28562352)
   validation loss 472.47265625, (255.90224, 0.09865361, 216.47179, 0.28562352)
decoder loss ratio: 9914.096925, decoder SINDy loss  ratio: 0.467285
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.694665]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 855.0177612304688, (366.2349, 0.41254163, 488.37033, 0.28497976)
   validation loss 489.8480224609375, (278.22238, 0.09390856, 211.53175, 0.28497976)
decoder loss ratio: 10778.818078, decoder SINDy loss  ratio: 0.456621
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.64969]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 832.4985961914062, (331.34238, 0.31284836, 500.84338, 0.28439492)
   validation loss 461.8589782714844, (251.26907, 0.09868392, 210.49123, 0.28439492)
decoder loss ratio: 9734.600129, decoder SINDy loss  ratio: 0.454375
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.666363]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.6719970703125, (269.60248, 0.31632224, 480.7532, 0.28404093)
   validation loss 420.4556884765625, (207.18431, 0.10320009, 213.1682, 0.28404093)
decoder loss ratio: 8026.679893, decoder SINDy loss  ratio: 0.460154
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.551746]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2016.1201171875, (1501.589, 0.300135, 514.23096, 0.28365287)
   validation loss 1637.6651611328125, (1369.2307, 0.10456617, 268.32983, 0.28365287)
decoder loss ratio: 53046.374906, decoder SINDy loss  ratio: 0.579228
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.497762]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.8550415039062, (326.4538, 0.27597913, 477.12527, 0.2834379)
   validation loss 477.72418212890625, (259.30325, 0.10335124, 218.31757, 0.2834379)
decoder loss ratio: 10045.858198, decoder SINDy loss  ratio: 0.471269
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.570239]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 973.3256225585938, (495.1916, 0.28243995, 477.8516, 0.28337097)
   validation loss 647.46142578125, (420.51096, 0.10850225, 226.84198, 0.28337097)
decoder loss ratio: 16291.324467, decoder SINDy loss  ratio: 0.489670
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.587034]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.9326171875, (366.0775, 0.30627173, 473.54883, 0.28327417)
   validation loss 511.25189208984375, (291.78625, 0.10605381, 219.35957, 0.28327417)
decoder loss ratio: 11304.306077, decoder SINDy loss  ratio: 0.473518
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.559754]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1680.107421875, (1093.6567, 0.31713426, 586.13354, 0.28319773)
   validation loss 1147.4876708984375, (910.3541, 0.09590098, 237.0377, 0.28319773)
decoder loss ratio: 35268.699285, decoder SINDy loss  ratio: 0.511679
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.454742]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.7037353515625, (276.96896, 0.27998105, 473.45477, 0.28316304)
   validation loss 430.5715637207031, (213.90642, 0.113920234, 216.55122, 0.28316304)
decoder loss ratio: 8287.105985, decoder SINDy loss  ratio: 0.467456
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.559521]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.94091796875, (261.21158, 0.28330117, 475.446, 0.28318763)
   validation loss 410.2125244140625, (195.74353, 0.11709155, 214.35188, 0.28318763)
decoder loss ratio: 7583.444189, decoder SINDy loss  ratio: 0.462709
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.603866]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.4981689453125, (304.10086, 0.2943537, 472.103, 0.2831853)
   validation loss 443.34649658203125, (228.4452, 0.119020276, 214.78226, 0.2831853)
decoder loss ratio: 8850.363867, decoder SINDy loss  ratio: 0.463638
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.557123]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 864.8432006835938, (396.1014, 0.27746895, 468.46432, 0.28328124)
   validation loss 545.122802734375, (322.29172, 0.1239594, 222.70712, 0.28328124)
decoder loss ratio: 12486.140660, decoder SINDy loss  ratio: 0.480745
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.544585]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.5817260742188, (277.34262, 0.28795826, 467.95114, 0.28335273)
   validation loss 426.6712341308594, (210.3768, 0.12733819, 216.1671, 0.28335273)
decoder loss ratio: 8150.362483, decoder SINDy loss  ratio: 0.466627
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.554922]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2210.26318359375, (1586.009, 0.35955548, 623.8946, 0.28338242)
   validation loss 1653.20654296875, (1397.7784, 0.10692412, 255.32118, 0.28338242)
decoder loss ratio: 54152.363508, decoder SINDy loss  ratio: 0.551147
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.518953]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.64599609375, (436.71957, 0.26776963, 465.65863, 0.28337374)
   validation loss 586.5348510742188, (361.97598, 0.13060269, 224.42825, 0.28337374)
decoder loss ratio: 14023.577986, decoder SINDy loss  ratio: 0.484460
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.484914]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.6214599609375, (261.7016, 0.27153474, 467.6483, 0.28347462)
   validation loss 410.81463623046875, (195.1617, 0.13423547, 215.51872, 0.28347462)
decoder loss ratio: 7560.902972, decoder SINDy loss  ratio: 0.465227
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.615415]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.6787109375, (346.3648, 0.31474182, 462.9992, 0.28360328)
   validation loss 487.2192077636719, (269.39835, 0.13361165, 217.68726, 0.28360328)
decoder loss ratio: 10436.959618, decoder SINDy loss  ratio: 0.469909
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.509633]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.5953369140625, (262.1664, 0.2655006, 472.1634, 0.2835332)
   validation loss 405.2159118652344, (191.0439, 0.13407, 214.03795, 0.2835332)
decoder loss ratio: 7401.372335, decoder SINDy loss  ratio: 0.462031
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.538395]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.72216796875, (255.9121, 0.25734398, 468.55276, 0.28362766)
   validation loss 404.84918212890625, (189.67601, 0.1381693, 215.03502, 0.28362766)
decoder loss ratio: 7348.377925, decoder SINDy loss  ratio: 0.464183
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.601036]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 868.7933959960938, (405.6652, 0.2579855, 462.8702, 0.2837583)
   validation loss 544.8675537109375, (321.52875, 0.14018115, 223.19867, 0.2837583)
decoder loss ratio: 12456.581879, decoder SINDy loss  ratio: 0.481806
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.571201]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.707763671875, (312.33197, 0.30653813, 467.06927, 0.28382427)
   validation loss 465.1401062011719, (249.41513, 0.122697264, 215.60228, 0.28382427)
decoder loss ratio: 9662.775164, decoder SINDy loss  ratio: 0.465408
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.593009]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1086.13623046875, (625.7912, 0.2525211, 460.09253, 0.28384683)
   validation loss 772.1600952148438, (544.1934, 0.14839055, 227.8183, 0.28384683)
decoder loss ratio: 21082.997868, decoder SINDy loss  ratio: 0.491778
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.579349]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 875.2427978515625, (414.38544, 0.2601799, 460.5972, 0.28393015)
   validation loss 562.6771850585938, (338.6299, 0.14615887, 223.90114, 0.28393015)
decoder loss ratio: 13119.110730, decoder SINDy loss  ratio: 0.483322
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.636797]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 724.606201171875, (255.54073, 0.25152862, 468.81396, 0.2839925)
   validation loss 403.3775634765625, (188.5108, 0.1449257, 214.72185, 0.2839925)
decoder loss ratio: 7303.235786, decoder SINDy loss  ratio: 0.463507
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.66265]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.6168212890625, (257.30206, 0.262219, 461.05252, 0.28412503)
   validation loss 408.71142578125, (192.63707, 0.14912179, 215.92523, 0.28412503)
decoder loss ratio: 7463.094513, decoder SINDy loss  ratio: 0.466105
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.693626]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1072.9915771484375, (608.7687, 0.24930924, 463.97357, 0.28422913)
   validation loss 730.099853515625, (498.9785, 0.14766596, 230.97368, 0.28422913)
decoder loss ratio: 19331.292778, decoder SINDy loss  ratio: 0.498589
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.608653]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.5125732421875, (310.64767, 0.29135284, 458.57352, 0.2843658)
   validation loss 453.94183349609375, (237.80263, 0.14496708, 215.99423, 0.2843658)
decoder loss ratio: 9212.886635, decoder SINDy loss  ratio: 0.466254
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.657184]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1125.490966796875, (607.79944, 0.25826946, 517.4332, 0.28427503)
   validation loss 736.982421875, (512.98224, 0.15303749, 223.84714, 0.28427503)
decoder loss ratio: 19873.822506, decoder SINDy loss  ratio: 0.483206
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.675651]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1595.4166259765625, (1115.8857, 0.24562036, 479.28528, 0.2843829)
   validation loss 1229.913818359375, (978.2699, 0.14885905, 251.49501, 0.2843829)
decoder loss ratio: 37899.874179, decoder SINDy loss  ratio: 0.542887
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.6616]
 [ 0.    ]
 [ 0.    ]
 [-0.    ]
 [-0.    ]
 [ 0.    ]
 [ 0.    ]
 [-0.    ]
 [ 0.    ]
 [-0.    ]
 [ 0.    ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.4876098632812, (259.50705, 0.23969196, 459.74088, 0.28446728)
   validation loss 408.384765625, (191.54942, 0.1499311, 216.68541, 0.28446728)
decoder loss ratio: 7420.957200, decoder SINDy loss  ratio: 0.467746
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.6835785]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.4976806640625, (266.03598, 0.2501142, 457.21158, 0.28450948)
   validation loss 413.5555114746094, (196.66943, 0.1537403, 216.73233, 0.28450948)
decoder loss ratio: 7619.315291, decoder SINDy loss  ratio: 0.467847
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.624057]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.0906372070312, (250.75757, 0.27052742, 458.06253, 0.2846461)
   validation loss 400.370849609375, (185.0427, 0.1549221, 215.17323, 0.2846461)
decoder loss ratio: 7168.875217, decoder SINDy loss  ratio: 0.464482
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.645891]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.5709228515625, (297.49454, 0.31716913, 455.75922, 0.28472525)
   validation loss 443.81842041015625, (227.97293, 0.14737542, 215.69812, 0.28472525)
decoder loss ratio: 8832.067122, decoder SINDy loss  ratio: 0.465615
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.707533]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.72021484375, (330.66565, 0.31017286, 467.7444, 0.28468677)
   validation loss 491.71490478515625, (274.17923, 0.14103451, 217.39464, 0.28468677)
decoder loss ratio: 10622.179356, decoder SINDy loss  ratio: 0.469277
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.70876]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.6395263671875, (249.01271, 0.2571926, 461.36966, 0.28484643)
   validation loss 398.68951416015625, (184.30438, 0.15776528, 214.22736, 0.28484643)
decoder loss ratio: 7140.271738, decoder SINDy loss  ratio: 0.462440
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.676473]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 791.4583740234375, (337.9488, 0.25133494, 453.25827, 0.28487173)
   validation loss 471.20904541015625, (252.08983, 0.15497966, 218.96423, 0.28487173)
decoder loss ratio: 9766.397603, decoder SINDy loss  ratio: 0.472665
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.5628195]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.03857421875, (274.92404, 0.2576715, 453.85684, 0.28490606)
   validation loss 415.69677734375, (199.65625, 0.15473081, 215.88579, 0.28490606)
decoder loss ratio: 7735.029743, decoder SINDy loss  ratio: 0.466020
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.716207]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.1973876953125, (255.3629, 0.26585945, 455.56866, 0.28494877)
   validation loss 403.7006530761719, (189.228, 0.15589286, 214.31676, 0.28494877)
decoder loss ratio: 7331.021111, decoder SINDy loss  ratio: 0.462633
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.704171]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1127.45849609375, (675.2045, 0.24310915, 452.0109, 0.28486827)
   validation loss 808.2546997070312, (581.3966, 0.16025767, 226.69783, 0.28486827)
decoder loss ratio: 22524.313883, decoder SINDy loss  ratio: 0.489359
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.700598]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.440673828125, (313.78885, 0.24821061, 453.4036, 0.28489366)
   validation loss 457.7714538574219, (239.09805, 0.15644825, 218.51695, 0.28489366)
decoder loss ratio: 9263.073665, decoder SINDy loss  ratio: 0.471700
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.678645]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.957275390625, (256.4497, 0.2360552, 460.2715, 0.28491578)
   validation loss 404.48468017578125, (190.28679, 0.15227114, 214.04562, 0.28491578)
decoder loss ratio: 7372.040556, decoder SINDy loss  ratio: 0.462048
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.761513]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.2909545898438, (257.38443, 0.23851152, 453.668, 0.2849842)
   validation loss 406.2427062988281, (190.45699, 0.15327021, 215.63245, 0.2849842)
decoder loss ratio: 7378.634265, decoder SINDy loss  ratio: 0.465473
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.649494]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.24267578125, (256.95874, 0.26125297, 453.02264, 0.28504202)
   validation loss 404.2362060546875, (189.34933, 0.15368581, 214.7332, 0.28504202)
decoder loss ratio: 7335.721952, decoder SINDy loss  ratio: 0.463532
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.712808]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1179.39453125, (720.06085, 0.24899292, 459.08472, 0.2849621)
   validation loss 818.8609008789062, (583.7235, 0.15673885, 234.98064, 0.2849621)
decoder loss ratio: 22614.462195, decoder SINDy loss  ratio: 0.507239
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.68984]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.476806640625, (294.87598, 0.24116862, 468.35965, 0.2850063)
   validation loss 446.0870361328125, (231.32922, 0.15367165, 214.60416, 0.2850063)
decoder loss ratio: 8962.095729, decoder SINDy loss  ratio: 0.463253
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.666667]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 847.0072021484375, (395.912, 0.22332048, 450.8719, 0.2850351)
   validation loss 525.9498291015625, (303.32794, 0.14848924, 222.47336, 0.2850351)
decoder loss ratio: 11751.451069, decoder SINDy loss  ratio: 0.480240
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.656477]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.3948364257812, (249.43217, 0.23135434, 454.73132, 0.28509504)
   validation loss 402.08740234375, (185.74356, 0.1457914, 216.19806, 0.28509504)
decoder loss ratio: 7196.028010, decoder SINDy loss  ratio: 0.466694
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.727266]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.146484375, (314.18826, 0.25754407, 448.70065, 0.28520805)
   validation loss 454.58953857421875, (236.74957, 0.15569502, 217.68427, 0.28520805)
decoder loss ratio: 9172.089464, decoder SINDy loss  ratio: 0.469902
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.7190275]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.5302734375, (291.81247, 0.28175488, 449.43604, 0.2852462)
   validation loss 432.1109313964844, (217.13042, 0.14894827, 214.83157, 0.2852462)
decoder loss ratio: 8412.009305, decoder SINDy loss  ratio: 0.463744
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.684714]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1929.198486328125, (1465.3269, 0.23372868, 463.63788, 0.28522182)
   validation loss 1560.9267578125, (1308.9482, 0.15096007, 251.82758, 0.28522182)
decoder loss ratio: 50710.927336, decoder SINDy loss  ratio: 0.543605
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.748208]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.8408813476562, (251.72716, 0.24078715, 454.87292, 0.28526875)
   validation loss 398.2413330078125, (183.73189, 0.1528393, 214.3566, 0.28526875)
decoder loss ratio: 7118.092307, decoder SINDy loss  ratio: 0.462719
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.743103]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.36083984375, (330.72998, 0.24202485, 448.38882, 0.2853673)
   validation loss 467.06524658203125, (247.45667, 0.1512518, 219.45734, 0.2853673)
decoder loss ratio: 9586.900807, decoder SINDy loss  ratio: 0.473730
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.632904]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.6817626953125, (310.4899, 0.23404753, 447.95782, 0.28543726)
   validation loss 448.4844970703125, (229.8695, 0.15074673, 218.46423, 0.28543726)
decoder loss ratio: 8905.543766, decoder SINDy loss  ratio: 0.471586
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.707543]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.7738647460938, (248.99724, 0.23409553, 451.5425, 0.28546923)
   validation loss 396.86163330078125, (182.00406, 0.15098912, 214.70659, 0.28546923)
decoder loss ratio: 7051.153212, decoder SINDy loss  ratio: 0.463474
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.776245]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.2120361328125, (243.30074, 0.24417938, 450.66714, 0.28551242)
   validation loss 394.8529052734375, (179.65392, 0.15057795, 215.04843, 0.28551242)
decoder loss ratio: 6960.104576, decoder SINDy loss  ratio: 0.464212
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.691776]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.812255859375, (274.7982, 0.3322972, 462.68176, 0.2856041)
   validation loss 423.666015625, (210.46236, 0.15104814, 213.0526, 0.2856041)
decoder loss ratio: 8153.677072, decoder SINDy loss  ratio: 0.459904
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.8518505]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1638.146484375, (1101.973, 0.2810358, 535.8925, 0.2855205)
   validation loss 1298.6806640625, (1062.2875, 0.15980376, 236.23341, 0.2855205)
decoder loss ratio: 41154.861016, decoder SINDy loss  ratio: 0.509943
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.674535]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.8866577148438, (268.4313, 0.24138823, 449.21396, 0.28555334)
   validation loss 417.6595458984375, (199.7861, 0.14981756, 217.72365, 0.28555334)
decoder loss ratio: 7740.060447, decoder SINDy loss  ratio: 0.469987
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.736333]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.0413818359375, (259.10678, 0.22586554, 447.7087, 0.28561267)
   validation loss 406.74969482421875, (189.94081, 0.14535213, 216.66354, 0.28561267)
decoder loss ratio: 7358.636776, decoder SINDy loss  ratio: 0.467699
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.718047]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.3419189453125, (237.19289, 0.24754743, 450.90152, 0.28563458)
   validation loss 392.34393310546875, (177.37663, 0.14917862, 214.8181, 0.28563458)
decoder loss ratio: 6871.878690, decoder SINDy loss  ratio: 0.463715
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.722879]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.2806396484375, (300.3518, 0.28618395, 445.6426, 0.28571317)
   validation loss 437.40625, (222.34872, 0.15012124, 214.90741, 0.28571317)
decoder loss ratio: 8614.175596, decoder SINDy loss  ratio: 0.463908
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.731366]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1570.515380859375, (1097.875, 0.23372202, 472.40665, 0.2856201)
   validation loss 1151.9189453125, (902.1255, 0.14948712, 249.64395, 0.2856201)
decoder loss ratio: 34949.907575, decoder SINDy loss  ratio: 0.538892
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.723705]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 837.7027587890625, (390.04675, 0.23823804, 447.4178, 0.28566292)
   validation loss 521.4669189453125, (298.59723, 0.14333484, 222.72635, 0.28566292)
decoder loss ratio: 11568.175039, decoder SINDy loss  ratio: 0.480786
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.762829]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.797119140625, (342.7353, 0.23310107, 445.82877, 0.28574732)
   validation loss 475.9664306640625, (255.40796, 0.1449666, 220.41348, 0.28574732)
decoder loss ratio: 9894.947739, decoder SINDy loss  ratio: 0.475794
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.787416]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.869384765625, (239.22469, 0.24574414, 449.39896, 0.28583705)
   validation loss 392.07843017578125, (177.28004, 0.14929715, 214.64911, 0.28583705)
decoder loss ratio: 6868.136698, decoder SINDy loss  ratio: 0.463350
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.789644]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.9234008789062, (253.80707, 0.26779976, 448.8485, 0.28589758)
   validation loss 406.29571533203125, (192.88918, 0.14679411, 213.25975, 0.28589758)
decoder loss ratio: 7472.861526, decoder SINDy loss  ratio: 0.460351
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.728652]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1622.5655517578125, (1072.0604, 0.3404444, 550.1647, 0.2858563)
   validation loss 1217.929443359375, (979.9508, 0.14818692, 237.83038, 0.2858563)
decoder loss ratio: 37964.995481, decoder SINDy loss  ratio: 0.513390
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.65952]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.0513916015625, (268.89362, 0.25325155, 463.9045, 0.28583112)
   validation loss 427.4493408203125, (211.16338, 0.14690053, 216.13908, 0.28583112)
decoder loss ratio: 8180.835776, decoder SINDy loss  ratio: 0.466567
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.77649]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.3161010742188, (252.28816, 0.23806714, 452.78986, 0.28587484)
   validation loss 408.239990234375, (194.36601, 0.14682753, 213.72714, 0.28587484)
decoder loss ratio: 7530.076761, decoder SINDy loss  ratio: 0.461360
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.73765]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.91650390625, (405.50095, 0.23155038, 444.18405, 0.28590852)
   validation loss 530.2232666015625, (308.4941, 0.1425872, 221.58661, 0.28590852)
decoder loss ratio: 11951.597395, decoder SINDy loss  ratio: 0.478326
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.796161]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.7286987304688, (263.48502, 0.22709014, 445.0166, 0.28591654)
   validation loss 407.4266357421875, (191.18008, 0.14265583, 216.10391, 0.28591654)
decoder loss ratio: 7406.648366, decoder SINDy loss  ratio: 0.466491
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.731096]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.6113891601562, (247.95195, 0.22540641, 449.43405, 0.2859673)
   validation loss 398.9278564453125, (184.76466, 0.14174284, 214.02147, 0.2859673)
decoder loss ratio: 7158.103837, decoder SINDy loss  ratio: 0.461995
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.7932825]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.19677734375, (310.94724, 0.23048972, 443.01907, 0.28604102)
   validation loss 439.2906799316406, (221.84749, 0.14093736, 217.30226, 0.28604102)
decoder loss ratio: 8594.756845, decoder SINDy loss  ratio: 0.469077
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.687763]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.8258056640625, (242.42032, 0.23231013, 446.1732, 0.286063)
   validation loss 391.64935302734375, (177.14746, 0.14146174, 214.36044, 0.286063)
decoder loss ratio: 6863.000178, decoder SINDy loss  ratio: 0.462727
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.800738]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2159.190673828125, (1678.5486, 0.22188422, 480.4202, 0.28601497)
   validation loss 1724.0284423828125, (1460.3383, 0.14335659, 263.54684, 0.28601497)
decoder loss ratio: 56576.039329, decoder SINDy loss  ratio: 0.568903
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.792032]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1064.9833984375, (563.0023, 0.30538288, 501.67578, 0.2861106)
   validation loss 725.5817260742188, (502.98386, 0.15179782, 222.44608, 0.2861106)
decoder loss ratio: 19486.467808, decoder SINDy loss  ratio: 0.480181
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.763846]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2050.236328125, (1573.502, 0.21962278, 476.51477, 0.2860658)
   validation loss 1607.44873046875, (1347.5261, 0.1349207, 259.78778, 0.2860658)
decoder loss ratio: 52205.501415, decoder SINDy loss  ratio: 0.560788
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.752176]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.3970947265625, (257.54373, 0.2219436, 443.63138, 0.28592634)
   validation loss 402.0332336425781, (186.05919, 0.1387413, 215.8353, 0.28592634)
decoder loss ratio: 7208.255989, decoder SINDy loss  ratio: 0.465911
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.74195]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.2587280273438, (259.55487, 0.24495432, 453.4589, 0.28605017)
   validation loss 420.71966552734375, (205.605, 0.13680196, 214.97789, 0.28605017)
decoder loss ratio: 7965.494480, decoder SINDy loss  ratio: 0.464060
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.800861]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1913.670654296875, (1376.4368, 0.33763096, 536.8962, 0.2859334)
   validation loss 1615.7738037109375, (1374.0226, 0.1391439, 241.6121, 0.2859334)
decoder loss ratio: 53232.020274, decoder SINDy loss  ratio: 0.521554
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.758158]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.3077392578125, (362.95007, 0.2399242, 475.11774, 0.2860368)
   validation loss 506.40557861328125, (288.327, 0.13550542, 217.94307, 0.2860368)
decoder loss ratio: 11170.288377, decoder SINDy loss  ratio: 0.470461
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.835203]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.930419921875, (274.95557, 0.23450427, 454.74033, 0.28605962)
   validation loss 432.8299560546875, (218.55742, 0.13902223, 214.13351, 0.28605962)
decoder loss ratio: 8467.293838, decoder SINDy loss  ratio: 0.462237
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.718875]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.927734375, (421.06305, 0.22887944, 441.63577, 0.28614536)
   validation loss 543.8544921875, (321.52377, 0.13688464, 222.19383, 0.28614536)
decoder loss ratio: 12456.389163, decoder SINDy loss  ratio: 0.479637
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.790996]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.919189453125, (322.89453, 0.22743723, 440.7972, 0.28617427)
   validation loss 452.976318359375, (234.45561, 0.13505806, 218.38564, 0.28617427)
decoder loss ratio: 9083.217449, decoder SINDy loss  ratio: 0.471416
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.795206]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.4454345703125, (309.00403, 0.2065998, 440.2348, 0.2861225)
   validation loss 441.4500732421875, (222.94843, 0.13135518, 218.37029, 0.2861225)
decoder loss ratio: 8637.409051, decoder SINDy loss  ratio: 0.471383
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.766577]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1480.9326171875, (1011.8189, 0.19807914, 468.91565, 0.28605852)
   validation loss 1041.3018798828125, (794.7192, 0.122599654, 246.46011, 0.28605852)
decoder loss ratio: 30788.800620, decoder SINDy loss  ratio: 0.532019
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.737365]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 893.3335571289062, (410.3598, 0.24893479, 482.72482, 0.28603905)
   validation loss 569.4507446289062, (347.8199, 0.13040166, 221.50044, 0.28603905)
decoder loss ratio: 13475.146197, decoder SINDy loss  ratio: 0.478140
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.809676]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1591.3271484375, (1126.6484, 0.22313043, 464.45557, 0.28613073)
   validation loss 1190.6309814453125, (941.65204, 0.13350174, 248.8455, 0.28613073)
decoder loss ratio: 36481.234754, decoder SINDy loss  ratio: 0.537168
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.818806]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.27587890625, (393.8199, 0.23169313, 439.22427, 0.2861698)
   validation loss 524.0068359375, (302.9594, 0.13415325, 220.91328, 0.2861698)
decoder loss ratio: 11737.173567, decoder SINDy loss  ratio: 0.476872
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.742291]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 815.531494140625, (374.53305, 0.23275146, 440.76572, 0.28627667)
   validation loss 497.25177001953125, (276.46527, 0.13352236, 220.65298, 0.28627667)
decoder loss ratio: 10710.744563, decoder SINDy loss  ratio: 0.476311
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.809038]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.887451171875, (359.6278, 0.20812692, 439.0515, 0.28623077)
   validation loss 483.7749328613281, (263.15762, 0.12865722, 220.48865, 0.28623077)
decoder loss ratio: 10195.183188, decoder SINDy loss  ratio: 0.475956
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.816703]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.366455078125, (271.2625, 0.24597888, 441.85797, 0.2863073)
   validation loss 421.86785888671875, (206.38586, 0.13403066, 215.34798, 0.2863073)
decoder loss ratio: 7995.746683, decoder SINDy loss  ratio: 0.464859
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.730544]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1727.986083984375, (1200.8486, 0.2991232, 526.83844, 0.28622317)
   validation loss 1420.47216796875, (1183.4762, 0.13625024, 236.85971, 0.28622317)
decoder loss ratio: 45849.922449, decoder SINDy loss  ratio: 0.511295
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.769022]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1020.7738037109375, (576.1011, 0.21866743, 444.45407, 0.28629848)
   validation loss 660.2378540039062, (432.31, 0.13477163, 227.7931, 0.28629848)
decoder loss ratio: 16748.439829, decoder SINDy loss  ratio: 0.491723
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.757888]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.156494140625, (419.75064, 0.23957115, 442.16632, 0.2863124)
   validation loss 541.7645263671875, (317.76935, 0.13268554, 223.86247, 0.2863124)
decoder loss ratio: 12310.936219, decoder SINDy loss  ratio: 0.483239
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.826031]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.344970703125, (246.90341, 0.23998347, 443.20154, 0.28639084)
   validation loss 398.31536865234375, (182.26454, 0.13168354, 215.91913, 0.28639084)
decoder loss ratio: 7061.244768, decoder SINDy loss  ratio: 0.466092
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.875809]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.0438232421875, (291.8329, 0.21545258, 437.9955, 0.2863403)
   validation loss 427.0950927734375, (209.45885, 0.12813787, 217.5081, 0.2863403)
decoder loss ratio: 8114.799371, decoder SINDy loss  ratio: 0.469522
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.809804]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 853.9093017578125, (388.97928, 0.22146532, 464.7086, 0.2862764)
   validation loss 565.6393432617188, (348.86993, 0.12563129, 216.64375, 0.2862764)
decoder loss ratio: 13515.826911, decoder SINDy loss  ratio: 0.467656
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.794463]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.64111328125, (265.0038, 0.22633363, 438.41092, 0.28635272)
   validation loss 404.7241516113281, (188.68779, 0.12910344, 215.90726, 0.28635272)
decoder loss ratio: 7310.092558, decoder SINDy loss  ratio: 0.466066
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.76496]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.8955078125, (239.67975, 0.23221274, 443.98358, 0.28639057)
   validation loss 392.4779052734375, (178.20718, 0.12891, 214.14182, 0.28639057)
decoder loss ratio: 6904.055683, decoder SINDy loss  ratio: 0.462255
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.739033]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.4357299804688, (398.8379, 0.22970593, 439.36813, 0.28645465)
   validation loss 519.1962280273438, (297.03064, 0.1288721, 222.03671, 0.28645465)
decoder loss ratio: 11507.482648, decoder SINDy loss  ratio: 0.479297
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.7839]
 [ 0.    ]
 [-0.    ]
 [ 0.    ]
 [-0.    ]
 [-0.    ]
 [-0.    ]
 [ 0.    ]
 [-0.    ]
 [-0.    ]
 [ 0.    ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.248291015625, (240.43039, 0.23309897, 444.58478, 0.28652573)
   validation loss 394.4751281738281, (180.43158, 0.12934296, 213.9142, 0.28652573)
decoder loss ratio: 6990.232636, decoder SINDy loss  ratio: 0.461764
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.786525]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.7488403320312, (260.07336, 0.22750427, 438.44797, 0.28652936)
   validation loss 401.364501953125, (185.58336, 0.12754543, 215.65361, 0.28652936)
decoder loss ratio: 7189.821505, decoder SINDy loss  ratio: 0.465519
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.849761]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.9287109375, (285.42264, 0.2293996, 438.27664, 0.2865784)
   validation loss 418.1278076171875, (201.12592, 0.12876542, 216.87312, 0.2865784)
decoder loss ratio: 7791.967137, decoder SINDy loss  ratio: 0.468151
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.775293]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.3604736328125, (366.7586, 0.20812511, 437.3937, 0.2864734)
   validation loss 487.87530517578125, (267.16272, 0.12271679, 220.58986, 0.2864734)
decoder loss ratio: 10350.347577, decoder SINDy loss  ratio: 0.476174
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.803984]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.582763671875, (411.10876, 0.2532018, 440.22083, 0.2863418)
   validation loss 537.745361328125, (314.0527, 0.13765496, 223.55501, 0.2863418)
decoder loss ratio: 12166.946967, decoder SINDy loss  ratio: 0.482575
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.784308]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.6295776367188, (261.18668, 0.22338091, 437.2195, 0.28646672)
   validation loss 400.884521484375, (184.96292, 0.12422072, 215.79736, 0.28646672)
decoder loss ratio: 7165.784675, decoder SINDy loss  ratio: 0.465829
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.753022]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.301513671875, (394.86462, 0.23172058, 438.20514, 0.28648764)
   validation loss 517.3758544921875, (295.46582, 0.12638776, 221.78369, 0.28648764)
decoder loss ratio: 11446.858830, decoder SINDy loss  ratio: 0.478751
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.828491]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.8380737304688, (240.66716, 0.22831137, 440.9426, 0.2865245)
   validation loss 388.59002685546875, (174.4073, 0.12566799, 214.05704, 0.2865245)
decoder loss ratio: 6756.841697, decoder SINDy loss  ratio: 0.462072
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.813943]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.8857421875, (265.66333, 0.23124038, 437.9912, 0.286566)
   validation loss 403.25726318359375, (187.10016, 0.12806164, 216.02905, 0.286566)
decoder loss ratio: 7248.584968, decoder SINDy loss  ratio: 0.466329
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.778883]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.6399536132812, (235.73535, 0.23056464, 440.67404, 0.28657237)
   validation loss 387.2397155761719, (173.10258, 0.12731013, 214.00983, 0.28657237)
decoder loss ratio: 6706.294656, decoder SINDy loss  ratio: 0.461970
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.8068495]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 936.9827880859375, (496.88678, 0.21273625, 439.88327, 0.28650266)
   validation loss 588.29150390625, (363.857, 0.11821428, 224.31627, 0.28650266)
decoder loss ratio: 14096.451655, decoder SINDy loss  ratio: 0.484218
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.753512]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.828125, (275.9362, 0.24083966, 446.65106, 0.28655684)
   validation loss 442.24578857421875, (228.58218, 0.12201643, 213.54158, 0.28655684)
decoder loss ratio: 8855.670638, decoder SINDy loss  ratio: 0.460960
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.759414]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.386474609375, (341.07855, 0.2576135, 455.05032, 0.2864496)
   validation loss 530.1254272460938, (315.45282, 0.12046757, 214.55214, 0.2864496)
decoder loss ratio: 12221.189890, decoder SINDy loss  ratio: 0.463141
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.836954]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.764892578125, (266.01526, 0.23339064, 449.51627, 0.28653833)
   validation loss 414.94964599609375, (201.12491, 0.11978486, 213.70497, 0.28653833)
decoder loss ratio: 7791.928121, decoder SINDy loss  ratio: 0.461312
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.806094]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.4913330078125, (251.4246, 0.25339848, 447.8133, 0.28661993)
   validation loss 428.61260986328125, (214.34402, 0.1203615, 214.14821, 0.28661993)
decoder loss ratio: 8304.059633, decoder SINDy loss  ratio: 0.462269
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.782722]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.9854736328125, (262.95926, 0.22290824, 435.80328, 0.28649077)
   validation loss 404.8177185058594, (189.35928, 0.119951025, 215.33849, 0.28649077)
decoder loss ratio: 7336.107383, decoder SINDy loss  ratio: 0.464838
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.77608]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.2281494140625, (265.71948, 0.22328527, 438.28534, 0.28655052)
   validation loss 411.0419921875, (193.56381, 0.12277731, 217.35542, 0.28655052)
decoder loss ratio: 7498.998128, decoder SINDy loss  ratio: 0.469192
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.823263]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.5438232421875, (238.65103, 0.24000879, 437.65277, 0.28658554)
   validation loss 385.865478515625, (171.46843, 0.12380616, 214.27325, 0.28658554)
decoder loss ratio: 6642.984644, decoder SINDy loss  ratio: 0.462539
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.797222]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.3046264648438, (232.59348, 0.23991533, 439.47122, 0.28665802)
   validation loss 384.0543518066406, (170.00336, 0.12358208, 213.92741, 0.28665802)
decoder loss ratio: 6586.225186, decoder SINDy loss  ratio: 0.461792
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.833164]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.460205078125, (248.55054, 0.23340304, 436.67624, 0.28671747)
   validation loss 391.4089660644531, (177.03012, 0.121727094, 214.25711, 0.28671747)
decoder loss ratio: 6858.454220, decoder SINDy loss  ratio: 0.462504
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.855615]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.7893676757812, (307.91238, 0.21538322, 435.6616, 0.28661573)
   validation loss 436.0269470214844, (217.42677, 0.11881953, 218.48135, 0.28661573)
decoder loss ratio: 8423.490658, decoder SINDy loss  ratio: 0.471623
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.88079]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.482421875, (279.25766, 0.24415573, 437.9806, 0.28670904)
   validation loss 427.1282958984375, (212.32085, 0.12613714, 214.68132, 0.28670904)
decoder loss ratio: 8225.678201, decoder SINDy loss  ratio: 0.463420
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.85688]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 986.3265380859375, (518.11505, 0.26700377, 467.94446, 0.28658858)
   validation loss 718.9011840820312, (501.54352, 0.116470896, 217.24117, 0.28658858)
decoder loss ratio: 19430.666608, decoder SINDy loss  ratio: 0.468946
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.875591]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.415771484375, (239.9308, 0.2598345, 444.2251, 0.2865835)
   validation loss 406.52117919921875, (191.65753, 0.12246838, 214.7412, 0.2865835)
decoder loss ratio: 7425.145512, decoder SINDy loss  ratio: 0.463549
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.83649]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.1724243164062, (246.55807, 0.23127927, 440.38306, 0.28666693)
   validation loss 393.7196960449219, (180.2881, 0.11880035, 213.31279, 0.28666693)
decoder loss ratio: 6984.674034, decoder SINDy loss  ratio: 0.460466
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.793722]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 832.442626953125, (396.92676, 0.22869875, 435.2872, 0.28667304)
   validation loss 514.7964477539062, (293.62778, 0.1219036, 221.04674, 0.28667304)
decoder loss ratio: 11375.649845, decoder SINDy loss  ratio: 0.477160
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.766165]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.5618286132812, (462.68143, 0.20747587, 433.6729, 0.28663358)
   validation loss 566.5856323242188, (343.75494, 0.11392715, 222.71677, 0.28663358)
decoder loss ratio: 13317.663309, decoder SINDy loss  ratio: 0.480765
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.830288]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.3980102539062, (241.79715, 0.23344247, 441.36743, 0.28674087)
   validation loss 394.357666015625, (180.53905, 0.119630285, 213.69897, 0.28674087)
decoder loss ratio: 6994.396120, decoder SINDy loss  ratio: 0.461299
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.88685]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.7095947265625, (353.64447, 0.21440712, 433.8507, 0.28662902)
   validation loss 475.67333984375, (255.40208, 0.11721781, 220.15402, 0.28662902)
decoder loss ratio: 9894.720145, decoder SINDy loss  ratio: 0.475233
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.812774]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.7816162109375, (250.32616, 0.26667202, 439.18878, 0.28647754)
   validation loss 402.1128845214844, (185.25558, 0.12934487, 216.72795, 0.28647754)
decoder loss ratio: 7177.122970, decoder SINDy loss  ratio: 0.467838
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.814142]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.46484375, (350.13126, 0.22826862, 434.1053, 0.2865642)
   validation loss 477.0867919921875, (256.2273, 0.11694128, 220.74257, 0.2865642)
decoder loss ratio: 9926.690235, decoder SINDy loss  ratio: 0.476504
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.810673]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.7398681640625, (294.46173, 0.23133162, 433.04684, 0.28667378)
   validation loss 428.6279602050781, (211.81328, 0.11981995, 216.69485, 0.28667378)
decoder loss ratio: 8206.014121, decoder SINDy loss  ratio: 0.467766
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.827732]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.839599609375, (248.01494, 0.24099152, 443.58368, 0.28674805)
   validation loss 404.67974853515625, (190.83582, 0.12184484, 213.72208, 0.28674805)
decoder loss ratio: 7393.310795, decoder SINDy loss  ratio: 0.461349
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.804151]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.23974609375, (396.1772, 0.21398278, 433.84857, 0.2866808)
   validation loss 509.22064208984375, (287.85825, 0.11492555, 221.24745, 0.2866808)
decoder loss ratio: 11152.128188, decoder SINDy loss  ratio: 0.477594
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.824253]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.9451293945312, (231.97389, 0.23605065, 439.7352, 0.28675878)
   validation loss 386.65899658203125, (172.63089, 0.12008947, 213.908, 0.28675878)
decoder loss ratio: 6688.020375, decoder SINDy loss  ratio: 0.461751
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.899061]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.608642578125, (331.38925, 0.22567107, 432.99368, 0.28670162)
   validation loss 460.76336669921875, (241.73372, 0.11653388, 218.91313, 0.28670162)
decoder loss ratio: 9365.183937, decoder SINDy loss  ratio: 0.472555
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.799359]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 910.9561767578125, (473.0613, 0.19916362, 437.6957, 0.2865809)
   validation loss 573.243408203125, (346.85165, 0.11451202, 226.27728, 0.2865809)
decoder loss ratio: 13437.635239, decoder SINDy loss  ratio: 0.488451
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.88585]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.335693359375, (373.79855, 0.24131691, 435.29584, 0.28673297)
   validation loss 501.66632080078125, (279.63614, 0.11862977, 221.91154, 0.28673297)
decoder loss ratio: 10833.589491, decoder SINDy loss  ratio: 0.479027
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.863097]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 834.0943603515625, (374.42206, 0.2667334, 459.40555, 0.28680417)
   validation loss 560.305419921875, (343.5757, 0.12506081, 216.60461, 0.28680417)
decoder loss ratio: 13310.719638, decoder SINDy loss  ratio: 0.467572
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.748901]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.3607788085938, (233.1189, 0.24156108, 438.0003, 0.28676578)
   validation loss 391.4632263183594, (175.91257, 0.116536446, 215.43413, 0.28676578)
decoder loss ratio: 6815.158249, decoder SINDy loss  ratio: 0.465045
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.876534]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.9600830078125, (238.2641, 0.23723365, 435.45877, 0.28683084)
   validation loss 385.4034118652344, (170.56114, 0.11770275, 214.72456, 0.28683084)
decoder loss ratio: 6607.834747, decoder SINDy loss  ratio: 0.463513
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.818074]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.56005859375, (341.95224, 0.21985759, 432.38797, 0.28669038)
   validation loss 468.39202880859375, (248.46783, 0.11523591, 219.80898, 0.28669038)
decoder loss ratio: 9626.075267, decoder SINDy loss  ratio: 0.474489
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.8072815]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1189.9207763671875, (699.40924, 0.2721448, 490.23935, 0.2865694)
   validation loss 893.7001953125, (668.2113, 0.1066289, 225.3823, 0.2865694)
decoder loss ratio: 25887.665972, decoder SINDy loss  ratio: 0.486519
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.878854]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.186279296875, (260.99606, 0.23161875, 432.95862, 0.2866733)
   validation loss 401.5921936035156, (186.19696, 0.11312358, 215.2821, 0.2866733)
decoder loss ratio: 7213.593500, decoder SINDy loss  ratio: 0.464717
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.809012]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.1558837890625, (237.42236, 0.24207382, 439.49142, 0.28678194)
   validation loss 391.95928955078125, (178.3415, 0.11860412, 213.49916, 0.28678194)
decoder loss ratio: 6909.259594, decoder SINDy loss  ratio: 0.460868
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.856032]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.8462524414062, (323.30328, 0.23125376, 432.3117, 0.28682518)
   validation loss 450.34478759765625, (232.28455, 0.11723139, 217.94301, 0.28682518)
decoder loss ratio: 8999.106572, decoder SINDy loss  ratio: 0.470461
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.803085]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.7141723632812, (240.38692, 0.22066599, 434.1066, 0.2867395)
   validation loss 387.9205017089844, (173.8659, 0.11277424, 213.94182, 0.2867395)
decoder loss ratio: 6735.867034, decoder SINDy loss  ratio: 0.461824
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.782845]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.3858642578125, (283.6851, 0.23493549, 433.46588, 0.2868499)
   validation loss 418.37896728515625, (201.27481, 0.11748086, 216.98666, 0.2868499)
decoder loss ratio: 7797.735598, decoder SINDy loss  ratio: 0.468396
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.8267355]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.9178466796875, (252.4249, 0.22249629, 432.27045, 0.2867531)
   validation loss 395.28155517578125, (180.3601, 0.11309855, 214.80836, 0.2867531)
decoder loss ratio: 6987.463680, decoder SINDy loss  ratio: 0.463694
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.750827]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.1961669921875, (297.82617, 0.21673091, 433.15326, 0.28673515)
   validation loss 424.30535888671875, (206.04022, 0.116136156, 218.149, 0.28673515)
decoder loss ratio: 7982.355908, decoder SINDy loss  ratio: 0.470905
=========================
[[1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[-8.850506]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.0701904296875, (300.54492, 0.23769931, 432.28754, 0.28680825)
   validation loss 434.9651184082031, (216.81711, 0.11606342, 218.03195, 0.28680825)
decoder loss ratio: 8399.871181, decoder SINDy loss  ratio: 0.470653
params['save_name']
pendulum_2023_11_09_04_00_55_161866
