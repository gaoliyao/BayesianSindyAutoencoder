nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 09:38:52.615981: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 09:38:52.623499: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 09:38:52.625473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f2fd9efb40 executing computations on platform Host. Devices:
2023-10-25 09:38:52.625538: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 09:38:52.631301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 09:38:52.778433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f2fdb6aff0 executing computations on platform CUDA. Devices:
2023-10-25 09:38:52.778497: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 09:38:52.779502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2023-10-25 09:38:52.780113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 09:38:52.784988: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 09:38:52.788848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 09:38:52.789639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 09:38:52.794492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 09:38:52.797186: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 09:38:52.803780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 09:38:52.804824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 09:38:52.804888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 09:38:52.805509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 09:38:52.805526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 09:38:52.805537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 09:38:52.806626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2023-10-25 09:38:53.942012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.6, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8526153564453125 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 106035.8203125, (101438.984, 0.0009908744, 4579.6665, 2.531781)
   validation loss 88457.8203125, (87239.89, 0.0034338827, 1200.7552, 2.531781)
decoder loss ratio: 3379824.817923, decoder SINDy loss  ratio: 2.591999
--- 0.2784545421600342 seconds for one epoch ---
--- 0.33080458641052246 seconds for one epoch ---
--- 0.3374776840209961 seconds for one epoch ---
--- 0.32301831245422363 seconds for one epoch ---
--- 0.3268108367919922 seconds for one epoch ---
--- 0.3309638500213623 seconds for one epoch ---
--- 0.33145594596862793 seconds for one epoch ---
--- 0.32657909393310547 seconds for one epoch ---
--- 0.3264796733856201 seconds for one epoch ---
--- 0.32213664054870605 seconds for one epoch ---
--- 0.3305339813232422 seconds for one epoch ---
--- 0.3316073417663574 seconds for one epoch ---
--- 0.35231518745422363 seconds for one epoch ---
--- 0.3266899585723877 seconds for one epoch ---
--- 0.35544466972351074 seconds for one epoch ---
--- 0.32657504081726074 seconds for one epoch ---
--- 0.33151674270629883 seconds for one epoch ---
--- 0.3156626224517822 seconds for one epoch ---
--- 0.3221452236175537 seconds for one epoch ---
--- 0.3175382614135742 seconds for one epoch ---
--- 0.34360408782958984 seconds for one epoch ---
--- 0.3235971927642822 seconds for one epoch ---
--- 0.345264196395874 seconds for one epoch ---
--- 0.3158450126647949 seconds for one epoch ---
=========================
[[0.7756199 ]
 [0.77807283]
 [0.7792624 ]
 [0.7769411 ]
 [0.77370924]
 [0.7821548 ]
 [0.7832417 ]
 [0.7738951 ]
 [0.7734606 ]
 [0.80818474]
 [0.7754287 ]]
[[ 0.4273256 ]
 [ 0.7051174 ]
 [-0.80661196]
 [-0.59142387]
 [-0.07494973]
 [-1.00376   ]
 [ 1.0653216 ]
 [-0.11935903]
 [ 0.01028646]
 [-1.8407255 ]
 [ 0.39971256]]
--- 0.27077317237854004 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 68035.0, (65586.38, 19.969542, 2391.0266, 2.5317636)
   validation loss 54866.9375, (53545.613, 10.126331, 1273.5698, 2.5317636)
decoder loss ratio: 2074450.017788, decoder SINDy loss  ratio: 2.749180
--- 0.3247058391571045 seconds for one epoch ---
--- 0.3434181213378906 seconds for one epoch ---
--- 0.32394886016845703 seconds for one epoch ---
--- 0.34077906608581543 seconds for one epoch ---
--- 0.3141753673553467 seconds for one epoch ---
--- 0.349198579788208 seconds for one epoch ---
--- 0.32662463188171387 seconds for one epoch ---
--- 0.34861016273498535 seconds for one epoch ---
--- 0.3320934772491455 seconds for one epoch ---
--- 0.3373677730560303 seconds for one epoch ---
--- 0.3203890323638916 seconds for one epoch ---
--- 0.36426711082458496 seconds for one epoch ---
--- 0.32544469833374023 seconds for one epoch ---
--- 0.34087371826171875 seconds for one epoch ---
--- 0.32686424255371094 seconds for one epoch ---
--- 0.346203088760376 seconds for one epoch ---
--- 0.3323550224304199 seconds for one epoch ---
--- 0.3494141101837158 seconds for one epoch ---
--- 0.3278310298919678 seconds for one epoch ---
--- 0.36837196350097656 seconds for one epoch ---
--- 0.3250885009765625 seconds for one epoch ---
--- 0.3389763832092285 seconds for one epoch ---
--- 0.31393980979919434 seconds for one epoch ---
--- 0.34679508209228516 seconds for one epoch ---
=========================
[[0.6318803 ]
 [0.6171854 ]
 [0.61558795]
 [0.61558616]
 [0.6123848 ]
 [0.6379531 ]
 [0.62492734]
 [0.61354816]
 [0.6124092 ]
 [0.6225666 ]
 [0.6154379 ]]
[[ 1.1464758 ]
 [ 0.5095229 ]
 [-0.3812712 ]
 [-0.38113493]
 [ 0.00285597]
 [-1.3003277 ]
 [ 0.91612256]
 [ 0.16776596]
 [ 0.00682599]
 [-0.8162572 ]
 [ 0.3678372 ]]
--- 0.31631922721862793 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 41598.45703125, (37105.797, 5.707716, 4431.808, 2.5317361)
   validation loss 40529.56640625, (39301.19, 6.066855, 1167.1643, 2.5317361)
decoder loss ratio: 1522596.384947, decoder SINDy loss  ratio: 2.519488
--- 0.28662919998168945 seconds for one epoch ---
--- 0.33073949813842773 seconds for one epoch ---
--- 0.3399488925933838 seconds for one epoch ---
--- 0.3243706226348877 seconds for one epoch ---
--- 0.37273263931274414 seconds for one epoch ---
--- 0.32682251930236816 seconds for one epoch ---
--- 0.35558295249938965 seconds for one epoch ---
--- 0.3234438896179199 seconds for one epoch ---
--- 0.3529317378997803 seconds for one epoch ---
--- 0.3223857879638672 seconds for one epoch ---
--- 0.3677198886871338 seconds for one epoch ---
--- 0.3204472064971924 seconds for one epoch ---
--- 0.35242557525634766 seconds for one epoch ---
--- 0.3254060745239258 seconds for one epoch ---
--- 0.37753844261169434 seconds for one epoch ---
--- 0.4082374572753906 seconds for one epoch ---
--- 0.3332254886627197 seconds for one epoch ---
--- 0.3229987621307373 seconds for one epoch ---
--- 0.3474094867706299 seconds for one epoch ---
--- 0.3258626461029053 seconds for one epoch ---
--- 0.34989237785339355 seconds for one epoch ---
--- 0.331035852432251 seconds for one epoch ---
--- 0.35280680656433105 seconds for one epoch ---
--- 0.3152766227722168 seconds for one epoch ---
=========================
[[0.5116841 ]
 [0.4796799 ]
 [0.47919893]
 [0.4816633 ]
 [0.47784558]
 [0.5456497 ]
 [0.48690146]
 [0.48010138]
 [0.47749338]
 [0.4815978 ]
 [0.48092183]]
[[ 1.2957219 ]
 [ 0.2228218 ]
 [-0.18069108]
 [-0.37172404]
 [-0.04434889]
 [-1.7289317 ]
 [ 0.65152067]
 [ 0.25751266]
 [ 0.00335487]
 [-0.3673262 ]
 [ 0.32006496]]
--- 0.26726222038269043 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 32801.48046875, (24597.969, 3.62923, 8130.6216, 2.531735)
   validation loss 18531.962890625, (17396.54, 1.1906353, 1064.9689, 2.531735)
decoder loss ratio: 673972.125001, decoder SINDy loss  ratio: 2.298885
--- 0.3210146427154541 seconds for one epoch ---
--- 0.3623836040496826 seconds for one epoch ---
--- 0.32609987258911133 seconds for one epoch ---
--- 0.3575711250305176 seconds for one epoch ---
--- 0.3165428638458252 seconds for one epoch ---
--- 0.35080838203430176 seconds for one epoch ---
--- 0.3198075294494629 seconds for one epoch ---
--- 0.361954927444458 seconds for one epoch ---
--- 0.3322939872741699 seconds for one epoch ---
--- 0.3381791114807129 seconds for one epoch ---
--- 0.3236396312713623 seconds for one epoch ---
--- 0.3704385757446289 seconds for one epoch ---
--- 0.3355119228363037 seconds for one epoch ---
--- 0.3694298267364502 seconds for one epoch ---
--- 0.3211495876312256 seconds for one epoch ---
--- 0.3764786720275879 seconds for one epoch ---
--- 0.3308529853820801 seconds for one epoch ---
--- 0.37790608406066895 seconds for one epoch ---
--- 0.33086562156677246 seconds for one epoch ---
--- 0.3713545799255371 seconds for one epoch ---
--- 0.32700324058532715 seconds for one epoch ---
--- 0.3828258514404297 seconds for one epoch ---
--- 0.3340275287628174 seconds for one epoch ---
--- 0.37497448921203613 seconds for one epoch ---
=========================
[[0.409496  ]
 [0.381738  ]
 [0.38137093]
 [0.3853017 ]
 [0.3815983 ]
 [0.5359484 ]
 [0.38896784]
 [0.38507238]
 [0.3810331 ]
 [0.38525015]
 [0.38428506]]
[[ 1.0981063 ]
 [ 0.07294295]
 [ 0.03870318]
 [-0.33387122]
 [-0.06013443]
 [-2.2117033 ]
 [ 0.52277064]
 [ 0.319956  ]
 [ 0.00540068]
 [-0.33076373]
 [ 0.26976964]]
--- 0.30108189582824707 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 23455.0078125, (19857.209, 29.069466, 3483.6936, 2.5317442)
   validation loss 10914.21875, (9876.464, 0.61124265, 952.107, 2.5317442)
decoder loss ratio: 382631.356510, decoder SINDy loss  ratio: 2.055257
--- 0.27199244499206543 seconds for one epoch ---
--- 0.3304135799407959 seconds for one epoch ---
--- 0.37358975410461426 seconds for one epoch ---
--- 0.32533836364746094 seconds for one epoch ---
--- 0.38154006004333496 seconds for one epoch ---
--- 0.3100109100341797 seconds for one epoch ---
--- 0.35652875900268555 seconds for one epoch ---
--- 0.31847262382507324 seconds for one epoch ---
--- 0.3543214797973633 seconds for one epoch ---
--- 0.29518699645996094 seconds for one epoch ---
--- 0.36591601371765137 seconds for one epoch ---
--- 0.2980518341064453 seconds for one epoch ---
--- 0.3666505813598633 seconds for one epoch ---
--- 0.3251354694366455 seconds for one epoch ---
--- 0.3630549907684326 seconds for one epoch ---
--- 0.3164050579071045 seconds for one epoch ---
--- 0.3878471851348877 seconds for one epoch ---
--- 0.32081031799316406 seconds for one epoch ---
--- 0.37156176567077637 seconds for one epoch ---
--- 0.3190343379974365 seconds for one epoch ---
--- 0.36600637435913086 seconds for one epoch ---
--- 0.3169112205505371 seconds for one epoch ---
--- 0.38144612312316895 seconds for one epoch ---
--- 0.31931447982788086 seconds for one epoch ---
=========================
[[0.3116982 ]
 [0.30028555]
 [0.30317673]
 [0.3031755 ]
 [0.300359  ]
 [0.6040441 ]
 [0.30672088]
 [0.3044722 ]
 [0.29974735]
 [0.31225684]
 [0.30315235]]
[[ 0.631159  ]
 [-0.05309716]
 [ 0.25588256]
 [-0.25582492]
 [-0.05916331]
 [-2.7334433 ]
 [ 0.4391481 ]
 [ 0.32915065]
 [-0.00684138]
 [-0.6495431 ]
 [ 0.25442833]]
--- 0.2714691162109375 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 15047.923828125, (11025.067, 2.2893634, 3922.0806, 2.531767)
   validation loss 7347.9775390625, (6412.1396, 0.34106785, 837.0112, 2.531767)
decoder loss ratio: 248417.421944, decoder SINDy loss  ratio: 1.806806
--- 0.3126707077026367 seconds for one epoch ---
--- 0.36847352981567383 seconds for one epoch ---
--- 0.3249073028564453 seconds for one epoch ---
--- 0.39109063148498535 seconds for one epoch ---
--- 0.3119664192199707 seconds for one epoch ---
--- 0.3614978790283203 seconds for one epoch ---
--- 0.32690000534057617 seconds for one epoch ---
--- 0.36673545837402344 seconds for one epoch ---
--- 0.32355451583862305 seconds for one epoch ---
--- 0.38400888442993164 seconds for one epoch ---
--- 0.32280564308166504 seconds for one epoch ---
--- 0.3725602626800537 seconds for one epoch ---
--- 0.3245840072631836 seconds for one epoch ---
--- 0.3673560619354248 seconds for one epoch ---
--- 0.3208904266357422 seconds for one epoch ---
--- 0.40358614921569824 seconds for one epoch ---
--- 0.31799912452697754 seconds for one epoch ---
--- 0.38071107864379883 seconds for one epoch ---
--- 0.32991456985473633 seconds for one epoch ---
--- 0.36780428886413574 seconds for one epoch ---
--- 0.32993197441101074 seconds for one epoch ---
--- 0.3725748062133789 seconds for one epoch ---
--- 0.32230520248413086 seconds for one epoch ---
--- 0.3730354309082031 seconds for one epoch ---
=========================
[[0.243896  ]
 [0.24332593]
 [0.25007877]
 [0.24322152]
 [0.24166253]
 [0.6986157 ]
 [0.2476457 ]
 [0.24603994]
 [0.24118687]
 [0.2705331 ]
 [0.24472533]]
[[ 1.9385706e-01]
 [-1.5806825e-01]
 [ 4.8995048e-01]
 [-1.5124981e-01]
 [-4.0078729e-02]
 [-3.1688595e+00]
 [ 3.8921797e-01]
 [ 3.1280428e-01]
 [-1.8154170e-03]
 [-1.0059891e+00]
 [ 2.4257171e-01]]
--- 0.3033316135406494 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 16203.9248046875, (10066.923, 10.946817, 6014.9395, 2.5317972)
   validation loss 5161.70068359375, (4291.0854, 0.15422426, 759.34674, 2.5317972)
decoder loss ratio: 166244.099955, decoder SINDy loss  ratio: 1.639157
--- 0.27321887016296387 seconds for one epoch ---
--- 0.3193507194519043 seconds for one epoch ---
--- 0.3800065517425537 seconds for one epoch ---
--- 0.3278310298919678 seconds for one epoch ---
--- 0.37490081787109375 seconds for one epoch ---
--- 0.3240931034088135 seconds for one epoch ---
--- 0.39314699172973633 seconds for one epoch ---
--- 0.329071044921875 seconds for one epoch ---
--- 0.40635251998901367 seconds for one epoch ---
--- 0.31949853897094727 seconds for one epoch ---
--- 0.37996840476989746 seconds for one epoch ---
--- 0.3076212406158447 seconds for one epoch ---
--- 0.38230323791503906 seconds for one epoch ---
--- 0.3281214237213135 seconds for one epoch ---
--- 0.37872982025146484 seconds for one epoch ---
--- 0.32739710807800293 seconds for one epoch ---
--- 0.4006054401397705 seconds for one epoch ---
--- 0.3215219974517822 seconds for one epoch ---
--- 0.3813157081604004 seconds for one epoch ---
--- 0.3235297203063965 seconds for one epoch ---
--- 0.38961267471313477 seconds for one epoch ---
--- 0.31035804748535156 seconds for one epoch ---
--- 0.3872056007385254 seconds for one epoch ---
--- 0.3182539939880371 seconds for one epoch ---
=========================
[[0.19347288]
 [0.1955831 ]
 [0.20796329]
 [0.19273181]
 [0.19201776]
 [0.77169114]
 [0.19762477]
 [0.19712055]
 [0.19161777]
 [0.24448958]
 [0.1961649 ]]
[[-0.13336949]
 [-0.25413513]
 [ 0.7000078 ]
 [-0.08475424]
 [-0.03403227]
 [-3.503286  ]
 [ 0.35241526]
 [ 0.32953337]
 [-0.00367823]
 [-1.2954811 ]
 [ 0.2837321 ]]
--- 0.2691671848297119 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10220.9716796875, (4864.7554, 0.9185126, 5234.386, 2.5318344)
   validation loss 3272.529296875, (2493.5122, 0.11653539, 657.99054, 2.5318344)
decoder loss ratio: 96602.991828, decoder SINDy loss  ratio: 1.420365
--- 0.3266160488128662 seconds for one epoch ---
--- 0.38776135444641113 seconds for one epoch ---
--- 0.3227970600128174 seconds for one epoch ---
--- 0.3833169937133789 seconds for one epoch ---
--- 0.3243441581726074 seconds for one epoch ---
--- 0.3985481262207031 seconds for one epoch ---
--- 0.3272078037261963 seconds for one epoch ---
--- 0.4088921546936035 seconds for one epoch ---
--- 0.34287190437316895 seconds for one epoch ---
--- 0.3976132869720459 seconds for one epoch ---
--- 0.3216543197631836 seconds for one epoch ---
--- 0.40982866287231445 seconds for one epoch ---
--- 0.319976806640625 seconds for one epoch ---
--- 0.4166147708892822 seconds for one epoch ---
--- 0.3280191421508789 seconds for one epoch ---
--- 0.4020419120788574 seconds for one epoch ---
--- 0.3272581100463867 seconds for one epoch ---
--- 0.3955342769622803 seconds for one epoch ---
--- 0.34030747413635254 seconds for one epoch ---
--- 0.4043745994567871 seconds for one epoch ---
--- 0.3316042423248291 seconds for one epoch ---
--- 0.3910787105560303 seconds for one epoch ---
--- 0.33255624771118164 seconds for one epoch ---
--- 0.41509294509887695 seconds for one epoch ---
=========================
[[0.16308881]
 [0.16119038]
 [0.18007909]
 [0.15650927]
 [0.15615086]
 [0.82655746]
 [0.16179964]
 [0.16144831]
 [0.15569635]
 [0.23783642]
 [0.1623121 ]]
[[-3.9741361e-01]
 [-3.1701532e-01]
 [ 8.6060309e-01]
 [-5.9597071e-02]
 [-3.4738775e-02]
 [-3.7787142e+00]
 [ 3.4393895e-01]
 [ 3.2855323e-01]
 [ 1.6895297e-03]
 [-1.5367565e+00]
 [ 3.6574283e-01]]
--- 0.3049650192260742 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9248.912109375, (5485.2236, 2.9498854, 3630.9941, 2.531872)
   validation loss 3102.132568359375, (2319.7764, 0.10295541, 652.5095, 2.531872)
decoder loss ratio: 89872.163774, decoder SINDy loss  ratio: 1.408534
--- 0.2697563171386719 seconds for one epoch ---
--- 0.33271288871765137 seconds for one epoch ---
--- 0.4150238037109375 seconds for one epoch ---
--- 0.3293337821960449 seconds for one epoch ---
--- 0.39670252799987793 seconds for one epoch ---
--- 0.32155275344848633 seconds for one epoch ---
--- 0.4225285053253174 seconds for one epoch ---
--- 0.3267793655395508 seconds for one epoch ---
--- 0.4284346103668213 seconds for one epoch ---
--- 0.32317566871643066 seconds for one epoch ---
--- 0.3938159942626953 seconds for one epoch ---
--- 0.32525205612182617 seconds for one epoch ---
--- 0.3933711051940918 seconds for one epoch ---
--- 0.31723713874816895 seconds for one epoch ---
--- 0.416109561920166 seconds for one epoch ---
--- 0.42338013648986816 seconds for one epoch ---
--- 0.38416314125061035 seconds for one epoch ---
--- 0.3242950439453125 seconds for one epoch ---
--- 0.41330885887145996 seconds for one epoch ---
--- 0.3176844120025635 seconds for one epoch ---
--- 0.40034914016723633 seconds for one epoch ---
--- 0.324660062789917 seconds for one epoch ---
--- 0.43029236793518066 seconds for one epoch ---
--- 0.32932019233703613 seconds for one epoch ---
=========================
[[0.137741  ]
 [0.13184153]
 [0.16193955]
 [0.1254872 ]
 [0.12535506]
 [0.85278153]
 [0.13034438]
 [0.1308839 ]
 [0.12517846]
 [0.23413554]
 [0.13236012]]
[[-0.5650191 ]
 [-0.36144817]
 [ 1.050538  ]
 [-0.02954729]
 [-0.02037956]
 [-3.940524  ]
 [ 0.29751736]
 [ 0.32130495]
 [-0.00791173]
 [-1.6981522 ]
 [ 0.38217425]]
--- 0.27026915550231934 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9336.58984375, (5857.786, 0.7531661, 3340.7803, 2.5318987)
   validation loss 2328.025634765625, (1677.1288, 0.09673983, 513.5301, 2.5318987)
decoder loss ratio: 64974.880723, decoder SINDy loss  ratio: 1.108527
--- 0.32302093505859375 seconds for one epoch ---
--- 0.4082016944885254 seconds for one epoch ---
--- 0.3181147575378418 seconds for one epoch ---
--- 0.4092082977294922 seconds for one epoch ---
--- 0.31848597526550293 seconds for one epoch ---
--- 0.4173398017883301 seconds for one epoch ---
--- 0.31744956970214844 seconds for one epoch ---
--- 0.4010343551635742 seconds for one epoch ---
--- 0.321246862411499 seconds for one epoch ---
--- 0.4122285842895508 seconds for one epoch ---
--- 0.31803107261657715 seconds for one epoch ---
--- 0.4354519844055176 seconds for one epoch ---
--- 0.3155629634857178 seconds for one epoch ---
--- 0.4090251922607422 seconds for one epoch ---
--- 0.3337862491607666 seconds for one epoch ---
--- 0.4416530132293701 seconds for one epoch ---
--- 0.32594823837280273 seconds for one epoch ---
--- 0.43153977394104004 seconds for one epoch ---
--- 0.3162531852722168 seconds for one epoch ---
--- 0.42915892601013184 seconds for one epoch ---
--- 0.3179030418395996 seconds for one epoch ---
--- 0.4102931022644043 seconds for one epoch ---
--- 0.33632659912109375 seconds for one epoch ---
--- 0.4089229106903076 seconds for one epoch ---
=========================
[[0.12027512]
 [0.11087377]
 [0.1525099 ]
 [0.10307472]
 [0.10309351]
 [0.8631885 ]
 [0.10816026]
 [0.10865801]
 [0.102855  ]
 [0.23690023]
 [0.11192104]]
[[-0.68319976]
 [-0.40504706]
 [ 1.2000123 ]
 [ 0.01980499]
 [-0.02108061]
 [-4.0181623 ]
 [ 0.29579708]
 [ 0.3172883 ]
 [-0.00463877]
 [-1.822439  ]
 [ 0.44265416]]
--- 0.3184926509857178 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5562.28759765625, (2795.6184, 0.4503998, 2622.154, 2.5319176)
   validation loss 1992.7579345703125, (1375.5366, 0.08289861, 473.07352, 2.5319176)
decoder loss ratio: 53290.676738, decoder SINDy loss  ratio: 1.021196
--- 0.27309370040893555 seconds for one epoch ---
--- 0.3198566436767578 seconds for one epoch ---
--- 0.41530418395996094 seconds for one epoch ---
--- 0.32259654998779297 seconds for one epoch ---
--- 0.40801477432250977 seconds for one epoch ---
--- 0.3092458248138428 seconds for one epoch ---
--- 0.43445920944213867 seconds for one epoch ---
--- 0.3293874263763428 seconds for one epoch ---
--- 0.4098069667816162 seconds for one epoch ---
--- 0.3118720054626465 seconds for one epoch ---
--- 0.4063384532928467 seconds for one epoch ---
--- 0.3191351890563965 seconds for one epoch ---
--- 0.4188661575317383 seconds for one epoch ---
--- 0.31658411026000977 seconds for one epoch ---
--- 0.41922712326049805 seconds for one epoch ---
--- 0.3287491798400879 seconds for one epoch ---
--- 0.4412870407104492 seconds for one epoch ---
--- 0.3386392593383789 seconds for one epoch ---
--- 0.4383254051208496 seconds for one epoch ---
--- 0.33058929443359375 seconds for one epoch ---
--- 0.4190380573272705 seconds for one epoch ---
--- 0.32533836364746094 seconds for one epoch ---
--- 0.43782854080200195 seconds for one epoch ---
--- 0.3263976573944092 seconds for one epoch ---
=========================
[[0.10501319]
 [0.09333746]
 [0.15188257]
 [0.08553873]
 [0.08371064]
 [0.85884756]
 [0.08902536]
 [0.08998924]
 [0.08375432]
 [0.24192064]
 [0.09385145]]
[[-7.6027697e-01]
 [-4.5363694e-01]
 [ 1.3713994e+00]
 [ 1.1616888e-01]
 [-1.6457443e-03]
 [-4.0102029e+00]
 [ 2.8944069e-01]
 [ 3.2999462e-01]
 [-4.6434151e-03]
 [-1.9253943e+00]
 [ 4.7066984e-01]]
--- 0.2705049514770508 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6497.19384765625, (3128.3184, 25.3047, 3194.686, 2.5319314)
   validation loss 1801.909423828125, (1155.0879, 0.08242455, 497.8541, 2.5319314)
decoder loss ratio: 44750.110204, decoder SINDy loss  ratio: 1.074688
--- 0.29227709770202637 seconds for one epoch ---
--- 0.4186263084411621 seconds for one epoch ---
--- 0.30974698066711426 seconds for one epoch ---
--- 0.41239285469055176 seconds for one epoch ---
--- 0.3014955520629883 seconds for one epoch ---
--- 0.43076133728027344 seconds for one epoch ---
--- 0.3032662868499756 seconds for one epoch ---
--- 0.44835352897644043 seconds for one epoch ---
--- 0.3081939220428467 seconds for one epoch ---
--- 0.4479069709777832 seconds for one epoch ---
--- 0.3008601665496826 seconds for one epoch ---
--- 0.4281473159790039 seconds for one epoch ---
--- 0.29367804527282715 seconds for one epoch ---
--- 0.46781229972839355 seconds for one epoch ---
--- 0.32869458198547363 seconds for one epoch ---
--- 0.4463682174682617 seconds for one epoch ---
--- 0.31427550315856934 seconds for one epoch ---
--- 0.4259982109069824 seconds for one epoch ---
--- 0.3184635639190674 seconds for one epoch ---
--- 0.4409146308898926 seconds for one epoch ---
--- 0.32768678665161133 seconds for one epoch ---
--- 0.4387247562408447 seconds for one epoch ---
--- 0.3275034427642822 seconds for one epoch ---
--- 0.4432830810546875 seconds for one epoch ---
=========================
[[0.09548351]
 [0.07935088]
 [0.15718053]
 [0.07243801]
 [0.06991684]
 [0.8543409 ]
 [0.07470276]
 [0.07601951]
 [0.06971193]
 [0.25581372]
 [0.08122163]]
[[-8.40554118e-01]
 [-4.48642164e-01]
 [ 1.51508474e+00]
 [ 1.62570745e-01]
 [-1.43264225e-02]
 [-3.99742961e+00]
 [ 2.71175027e-01]
 [ 3.26676100e-01]
 [-5.81940403e-04]
 [-2.03471351e+00]
 [ 5.08150756e-01]]
--- 0.3230092525482178 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9311.4287109375, (4414.1694, 3.8671312, 4739.524, 2.531943)
   validation loss 1780.183837890625, (1170.2651, 0.065969326, 455.98465, 2.531943)
decoder loss ratio: 45338.103066, decoder SINDy loss  ratio: 0.984307
--- 0.26694726943969727 seconds for one epoch ---
--- 0.3107876777648926 seconds for one epoch ---
--- 0.43933653831481934 seconds for one epoch ---
--- 0.2915968894958496 seconds for one epoch ---
--- 0.443911075592041 seconds for one epoch ---
--- 0.30856800079345703 seconds for one epoch ---
--- 0.4551050662994385 seconds for one epoch ---
--- 0.31096673011779785 seconds for one epoch ---
--- 0.4546232223510742 seconds for one epoch ---
--- 0.32027482986450195 seconds for one epoch ---
--- 0.4493286609649658 seconds for one epoch ---
--- 0.31974267959594727 seconds for one epoch ---
--- 0.4736928939819336 seconds for one epoch ---
--- 0.3197610378265381 seconds for one epoch ---
--- 0.48230409622192383 seconds for one epoch ---
--- 0.31580615043640137 seconds for one epoch ---
--- 0.4545729160308838 seconds for one epoch ---
--- 0.31691718101501465 seconds for one epoch ---
--- 0.45804452896118164 seconds for one epoch ---
--- 0.3237483501434326 seconds for one epoch ---
--- 0.4581735134124756 seconds for one epoch ---
--- 0.31412792205810547 seconds for one epoch ---
--- 0.44649624824523926 seconds for one epoch ---
--- 0.3236806392669678 seconds for one epoch ---
=========================
[[0.09024506]
 [0.0684353 ]
 [0.15913254]
 [0.06192509]
 [0.05773177]
 [0.85605717]
 [0.06238025]
 [0.0644618 ]
 [0.05767469]
 [0.28159246]
 [0.07133307]]
[[-9.4870234e-01]
 [-4.8118901e-01]
 [ 1.6017525e+00]
 [ 2.3597775e-01]
 [-5.5807019e-03]
 [-4.0168133e+00]
 [ 2.5656819e-01]
 [ 3.4301805e-01]
 [ 1.7780701e-03]
 [-2.1693380e+00]
 [ 5.6599873e-01]]
--- 0.2561779022216797 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4568.52587890625, (2422.3345, 2.069207, 1985.0378, 2.5319595)
   validation loss 1332.960693359375, (791.05255, 0.06517188, 382.75854, 2.5319595)
decoder loss ratio: 30646.749164, decoder SINDy loss  ratio: 0.826238
--- 0.3125722408294678 seconds for one epoch ---
--- 0.46397995948791504 seconds for one epoch ---
--- 0.3188192844390869 seconds for one epoch ---
--- 0.4441864490509033 seconds for one epoch ---
--- 0.3229527473449707 seconds for one epoch ---
--- 0.4479787349700928 seconds for one epoch ---
--- 0.32317662239074707 seconds for one epoch ---
--- 0.49018073081970215 seconds for one epoch ---
--- 0.2978081703186035 seconds for one epoch ---
--- 0.4559030532836914 seconds for one epoch ---
--- 0.33115482330322266 seconds for one epoch ---
--- 0.4589400291442871 seconds for one epoch ---
--- 0.315152645111084 seconds for one epoch ---
--- 0.4489729404449463 seconds for one epoch ---
--- 0.3072514533996582 seconds for one epoch ---
--- 0.458904504776001 seconds for one epoch ---
--- 0.3273274898529053 seconds for one epoch ---
--- 0.48180389404296875 seconds for one epoch ---
--- 0.3315279483795166 seconds for one epoch ---
--- 0.4745948314666748 seconds for one epoch ---
--- 0.3166356086730957 seconds for one epoch ---
--- 0.46836233139038086 seconds for one epoch ---
--- 0.3357980251312256 seconds for one epoch ---
--- 0.4765317440032959 seconds for one epoch ---
=========================
[[0.08876884]
 [0.06021203]
 [0.16474868]
 [0.05296453]
 [0.04900485]
 [0.85677946]
 [0.05283429]
 [0.05573103]
 [0.04884414]
 [0.31288412]
 [0.06329179]]
[[-1.0493126 ]
 [-0.49795544]
 [ 1.6833134 ]
 [ 0.23012966]
 [-0.01507394]
 [-4.0280685 ]
 [ 0.22411618]
 [ 0.346017  ]
 [ 0.00456464]
 [-2.298607  ]
 [ 0.5848228 ]]
--- 0.3107786178588867 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9852.966796875, (2590.1794, 3.3797905, 7095.0386, 2.531973)
   validation loss 1183.7984619140625, (650.0717, 0.068735644, 369.28955, 2.531973)
decoder loss ratio: 25184.906864, decoder SINDy loss  ratio: 0.797163
--- 0.27835536003112793 seconds for one epoch ---
--- 0.29485249519348145 seconds for one epoch ---
--- 0.4730098247528076 seconds for one epoch ---
--- 0.3133070468902588 seconds for one epoch ---
--- 0.4521162509918213 seconds for one epoch ---
--- 0.3170170783996582 seconds for one epoch ---
--- 0.47879791259765625 seconds for one epoch ---
--- 0.31449437141418457 seconds for one epoch ---
--- 0.4942939281463623 seconds for one epoch ---
--- 0.306119441986084 seconds for one epoch ---
--- 0.4775066375732422 seconds for one epoch ---
--- 0.295029878616333 seconds for one epoch ---
--- 0.4428386688232422 seconds for one epoch ---
--- 0.30861330032348633 seconds for one epoch ---
--- 0.454880952835083 seconds for one epoch ---
--- 0.30479979515075684 seconds for one epoch ---
--- 0.49407076835632324 seconds for one epoch ---
--- 0.3246731758117676 seconds for one epoch ---
--- 0.4499776363372803 seconds for one epoch ---
--- 0.3026001453399658 seconds for one epoch ---
--- 0.4832041263580322 seconds for one epoch ---
--- 0.31265997886657715 seconds for one epoch ---
--- 0.46915626525878906 seconds for one epoch ---
--- 0.3340799808502197 seconds for one epoch ---
=========================
[[0.08876938]
 [0.05368531]
 [0.17539373]
 [0.04602787]
 [0.0414917 ]
 [0.85149235]
 [0.0443185 ]
 [0.04803811]
 [0.04122682]
 [0.34934902]
 [0.0575194 ]]
[[-1.1397613 ]
 [-0.52926624]
 [ 1.7772883 ]
 [ 0.26214054]
 [-0.02626311]
 [-4.006008  ]
 [ 0.18330534]
 [ 0.34378853]
 [-0.00929813]
 [-2.4287283 ]
 [ 0.63035095]]
--- 0.2582883834838867 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3740.77587890625, (1932.8076, 0.1249841, 1639.175, 2.5319855)
   validation loss 1305.7640380859375, (803.78644, 0.06985443, 333.23962, 2.5319855)
decoder loss ratio: 31140.082042, decoder SINDy loss  ratio: 0.719345
--- 0.3227052688598633 seconds for one epoch ---
--- 0.4844505786895752 seconds for one epoch ---
--- 0.3110659122467041 seconds for one epoch ---
--- 0.4915344715118408 seconds for one epoch ---
--- 0.3099205493927002 seconds for one epoch ---
--- 0.47974228858947754 seconds for one epoch ---
--- 0.3141152858734131 seconds for one epoch ---
--- 0.4984405040740967 seconds for one epoch ---
--- 0.3081841468811035 seconds for one epoch ---
--- 0.45742177963256836 seconds for one epoch ---
--- 0.30466318130493164 seconds for one epoch ---
--- 0.48728084564208984 seconds for one epoch ---
--- 0.31940579414367676 seconds for one epoch ---
--- 0.48107123374938965 seconds for one epoch ---
--- 0.3021969795227051 seconds for one epoch ---
--- 0.48297572135925293 seconds for one epoch ---
--- 0.3165452480316162 seconds for one epoch ---
--- 0.5043699741363525 seconds for one epoch ---
--- 0.3173995018005371 seconds for one epoch ---
--- 0.49277472496032715 seconds for one epoch ---
--- 0.33013224601745605 seconds for one epoch ---
--- 0.5098397731781006 seconds for one epoch ---
--- 0.3097097873687744 seconds for one epoch ---
--- 0.4960441589355469 seconds for one epoch ---
=========================
[[0.09238525]
 [0.04839164]
 [0.18372193]
 [0.04021998]
 [0.03566159]
 [0.8478134 ]
 [0.03890769]
 [0.04223933]
 [0.03544189]
 [0.392409  ]
 [0.05243839]]
[[-1.2363186e+00]
 [-5.3833944e-01]
 [ 1.8423378e+00]
 [ 2.5579086e-01]
 [-1.7284416e-02]
 [-3.9914374e+00]
 [ 1.9590864e-01]
 [ 3.3809939e-01]
 [ 3.1234408e-03]
 [-2.5637019e+00]
 [ 6.4266348e-01]]
--- 0.4051179885864258 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5291.91796875, (1972.5852, 1.8237201, 3145.2864, 2.5319977)
   validation loss 1721.5914306640625, (1235.6405, 0.0853714, 313.643, 2.5319977)
decoder loss ratio: 47870.858250, decoder SINDy loss  ratio: 0.677043
--- 0.26941347122192383 seconds for one epoch ---
--- 0.297684907913208 seconds for one epoch ---
--- 0.5064783096313477 seconds for one epoch ---
--- 0.31191062927246094 seconds for one epoch ---
--- 0.49042272567749023 seconds for one epoch ---
--- 0.33202672004699707 seconds for one epoch ---
--- 0.48723268508911133 seconds for one epoch ---
--- 0.3120541572570801 seconds for one epoch ---
--- 0.4979362487792969 seconds for one epoch ---
--- 0.31057262420654297 seconds for one epoch ---
--- 0.5012781620025635 seconds for one epoch ---
--- 0.34157824516296387 seconds for one epoch ---
--- 0.5086767673492432 seconds for one epoch ---
--- 0.3415713310241699 seconds for one epoch ---
--- 0.5030069351196289 seconds for one epoch ---
--- 0.33689236640930176 seconds for one epoch ---
--- 0.5021321773529053 seconds for one epoch ---
--- 0.29886770248413086 seconds for one epoch ---
--- 0.5047459602355957 seconds for one epoch ---
--- 0.3153254985809326 seconds for one epoch ---
--- 0.4994351863861084 seconds for one epoch ---
--- 0.3049614429473877 seconds for one epoch ---
--- 0.5074970722198486 seconds for one epoch ---
--- 0.32658815383911133 seconds for one epoch ---
=========================
[[0.09647873]
 [0.04435431]
 [0.19414781]
 [0.03544015]
 [0.03060967]
 [0.8428309 ]
 [0.03351407]
 [0.03771112]
 [0.03055122]
 [0.43317744]
 [0.04959487]]
[[-1.31879   ]
 [-0.56167   ]
 [ 1.9091136 ]
 [ 0.26239637]
 [-0.0112104 ]
 [-3.970087  ]
 [ 0.17391992]
 [ 0.35293028]
 [ 0.00745834]
 [-2.683581  ]
 [ 0.6890235 ]]
--- 0.26891016960144043 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5903.18212890625, (2411.1753, 1.681409, 3313.5105, 2.5320094)
   validation loss 1239.0341796875, (735.674, 0.074216194, 326.47147, 2.5320094)
decoder loss ratio: 28501.288381, decoder SINDy loss  ratio: 0.704735
--- 0.32089734077453613 seconds for one epoch ---
--- 0.5034730434417725 seconds for one epoch ---
--- 0.30334997177124023 seconds for one epoch ---
--- 0.48316383361816406 seconds for one epoch ---
--- 0.30825018882751465 seconds for one epoch ---
--- 0.5120971202850342 seconds for one epoch ---
--- 0.3265495300292969 seconds for one epoch ---
--- 0.4882478713989258 seconds for one epoch ---
--- 0.3185579776763916 seconds for one epoch ---
--- 0.5135138034820557 seconds for one epoch ---
--- 0.3226127624511719 seconds for one epoch ---
--- 0.5046653747558594 seconds for one epoch ---
--- 0.31979942321777344 seconds for one epoch ---
--- 0.49675846099853516 seconds for one epoch ---
--- 0.3071413040161133 seconds for one epoch ---
--- 0.4952542781829834 seconds for one epoch ---
--- 0.30827832221984863 seconds for one epoch ---
--- 0.5066587924957275 seconds for one epoch ---
--- 0.3066129684448242 seconds for one epoch ---
--- 0.47331738471984863 seconds for one epoch ---
--- 0.2871429920196533 seconds for one epoch ---
--- 0.4911825656890869 seconds for one epoch ---
--- 0.3368716239929199 seconds for one epoch ---
--- 0.5233039855957031 seconds for one epoch ---
=========================
[[0.10171866]
 [0.04172619]
 [0.20632288]
 [0.03172039]
 [0.02710617]
 [0.8353425 ]
 [0.0293615 ]
 [0.03376003]
 [0.02675409]
 [0.47352797]
 [0.04814195]]
[[-1.3921124e+00]
 [-5.8804154e-01]
 [ 1.9740206e+00]
 [ 2.6021013e-01]
 [-2.2805326e-02]
 [-3.9361894e+00]
 [ 1.5004998e-01]
 [ 3.4206501e-01]
 [-3.7078350e-04]
 [-2.7962739e+00]
 [ 7.3495126e-01]]
--- 0.3115358352661133 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5599.28857421875, (1643.2933, 74.105095, 3701.7693, 2.5320206)
   validation loss 2742.93896484375, (2138.4844, 0.06912274, 424.2653, 2.5320206)
decoder loss ratio: 82848.597260, decoder SINDy loss  ratio: 0.915836
--- 0.2663304805755615 seconds for one epoch ---
--- 0.31741976737976074 seconds for one epoch ---
--- 0.4818558692932129 seconds for one epoch ---
--- 0.3292407989501953 seconds for one epoch ---
--- 0.5012693405151367 seconds for one epoch ---
--- 0.32346177101135254 seconds for one epoch ---
--- 0.5026297569274902 seconds for one epoch ---
--- 0.32643699645996094 seconds for one epoch ---
--- 0.5293700695037842 seconds for one epoch ---
--- 0.3061497211456299 seconds for one epoch ---
--- 0.5100975036621094 seconds for one epoch ---
--- 0.3055894374847412 seconds for one epoch ---
--- 0.5653696060180664 seconds for one epoch ---
--- 0.29714322090148926 seconds for one epoch ---
--- 0.5019693374633789 seconds for one epoch ---
--- 0.3150334358215332 seconds for one epoch ---
--- 0.517484188079834 seconds for one epoch ---
--- 0.314908504486084 seconds for one epoch ---
--- 0.5160830020904541 seconds for one epoch ---
--- 0.32660794258117676 seconds for one epoch ---
--- 0.5417520999908447 seconds for one epoch ---
--- 0.3176567554473877 seconds for one epoch ---
--- 0.5199649333953857 seconds for one epoch ---
--- 0.3174312114715576 seconds for one epoch ---
=========================
[[0.10814387]
 [0.03899257]
 [0.22013687]
 [0.02792832]
 [0.02408627]
 [0.82400393]
 [0.02608722]
 [0.03034467]
 [0.02353015]
 [0.516868  ]
 [0.0455824 ]]
[[-1.4641443e+00]
 [-5.9935462e-01]
 [ 2.0396352e+00]
 [ 2.3498021e-01]
 [-3.5664387e-02]
 [-3.8855214e+00]
 [ 1.4731625e-01]
 [ 3.3416146e-01]
 [ 7.1525481e-04]
 [-2.9142718e+00]
 [ 7.4708569e-01]]
--- 0.26371288299560547 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3464.103271484375, (1955.9104, 0.76600564, 1325.136, 2.532029)
   validation loss 1206.0389404296875, (682.6296, 0.07656614, 341.04202, 2.532029)
decoder loss ratio: 26446.254935, decoder SINDy loss  ratio: 0.736187
--- 0.31663942337036133 seconds for one epoch ---
--- 0.5029809474945068 seconds for one epoch ---
--- 0.3261096477508545 seconds for one epoch ---
--- 0.5543012619018555 seconds for one epoch ---
--- 0.31290578842163086 seconds for one epoch ---
--- 0.5257117748260498 seconds for one epoch ---
--- 0.3191080093383789 seconds for one epoch ---
--- 0.5016989707946777 seconds for one epoch ---
--- 0.29645514488220215 seconds for one epoch ---
--- 0.5363850593566895 seconds for one epoch ---
--- 0.29468846321105957 seconds for one epoch ---
--- 0.5462594032287598 seconds for one epoch ---
--- 0.30273938179016113 seconds for one epoch ---
--- 0.5261220932006836 seconds for one epoch ---
--- 0.3159768581390381 seconds for one epoch ---
--- 0.5284209251403809 seconds for one epoch ---
--- 0.32564520835876465 seconds for one epoch ---
--- 0.5253584384918213 seconds for one epoch ---
--- 0.31862473487854004 seconds for one epoch ---
--- 0.5363459587097168 seconds for one epoch ---
--- 0.3204514980316162 seconds for one epoch ---
--- 0.5338015556335449 seconds for one epoch ---
--- 0.3014857769012451 seconds for one epoch ---
--- 0.515678882598877 seconds for one epoch ---
=========================
[[0.11707076]
 [0.03644495]
 [0.229154  ]
 [0.0254232 ]
 [0.02134636]
 [0.81709534]
 [0.02330596]
 [0.02837651]
 [0.02121385]
 [0.56057584]
 [0.04400039]]
[[-1.5414551 ]
 [-0.5950312 ]
 [ 2.081136  ]
 [ 0.23044266]
 [-0.01538885]
 [-3.8563893 ]
 [ 0.12798062]
 [ 0.35021865]
 [ 0.00698657]
 [-3.032282  ]
 [ 0.76248235]]
--- 0.3129606246948242 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2596.20166015625, (1496.2546, 0.53776157, 914.4892, 2.5320394)
   validation loss 1555.22021484375, (1031.6575, 0.095599666, 338.54712, 2.5320394)
decoder loss ratio: 39968.201451, decoder SINDy loss  ratio: 0.730802
THRESHOLDING: 4 active coefficients
--- 0.53389573097229 seconds for one epoch ---
--- 0.3137624263763428 seconds for one epoch ---
--- 0.5492970943450928 seconds for one epoch ---
--- 0.30885744094848633 seconds for one epoch ---
--- 0.5457804203033447 seconds for one epoch ---
--- 0.3162350654602051 seconds for one epoch ---
--- 0.5156357288360596 seconds for one epoch ---
--- 0.32564544677734375 seconds for one epoch ---
--- 0.526289701461792 seconds for one epoch ---
--- 0.31590986251831055 seconds for one epoch ---
--- 0.5248391628265381 seconds for one epoch ---
--- 0.3279438018798828 seconds for one epoch ---
--- 0.5539019107818604 seconds for one epoch ---
--- 0.321077823638916 seconds for one epoch ---
--- 0.536308765411377 seconds for one epoch ---
--- 0.31113457679748535 seconds for one epoch ---
--- 0.5243990421295166 seconds for one epoch ---
--- 0.32439589500427246 seconds for one epoch ---
--- 0.5250115394592285 seconds for one epoch ---
--- 0.3078157901763916 seconds for one epoch ---
--- 0.5528476238250732 seconds for one epoch ---
--- 0.31066179275512695 seconds for one epoch ---
--- 0.5437395572662354 seconds for one epoch ---
--- 0.31170129776000977 seconds for one epoch ---
=========================
[[0.04294404]
 [0.        ]
 [0.294075  ]
 [0.        ]
 [0.        ]
 [0.4506471 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37264207]
 [0.        ]]
[[-0.78208303]
 [-0.        ]
 [ 2.307128  ]
 [ 0.        ]
 [-0.        ]
 [-2.7473788 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5376384 ]
 [ 0.        ]]
--- 0.2763864994049072 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3423.8359375, (1483.9978, 0.53881174, 1938.8412, 0.45811358)
   validation loss 1222.5440673828125, (898.3536, 0.07689418, 323.65543, 0.45811358)
decoder loss ratio: 34803.777170, decoder SINDy loss  ratio: 0.698656
--- 0.3052215576171875 seconds for one epoch ---
--- 0.5491423606872559 seconds for one epoch ---
--- 0.31917309761047363 seconds for one epoch ---
--- 0.5265424251556396 seconds for one epoch ---
--- 0.33627867698669434 seconds for one epoch ---
--- 0.5407819747924805 seconds for one epoch ---
--- 0.31906867027282715 seconds for one epoch ---
--- 0.5354652404785156 seconds for one epoch ---
--- 0.3140218257904053 seconds for one epoch ---
--- 0.5255930423736572 seconds for one epoch ---
--- 0.32097792625427246 seconds for one epoch ---
--- 0.5380561351776123 seconds for one epoch ---
--- 0.29041242599487305 seconds for one epoch ---
--- 0.5447773933410645 seconds for one epoch ---
--- 0.3397867679595947 seconds for one epoch ---
--- 0.5456218719482422 seconds for one epoch ---
--- 0.32330942153930664 seconds for one epoch ---
--- 0.5384249687194824 seconds for one epoch ---
--- 0.30257630348205566 seconds for one epoch ---
--- 0.5357222557067871 seconds for one epoch ---
--- 0.31473636627197266 seconds for one epoch ---
--- 0.5323059558868408 seconds for one epoch ---
--- 0.3101475238800049 seconds for one epoch ---
--- 0.5442461967468262 seconds for one epoch ---
=========================
[[0.02701715]
 [0.        ]
 [0.31305334]
 [0.        ]
 [0.        ]
 [0.26401016]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30117264]
 [0.        ]]
[[-0.43080977]
 [-0.        ]
 [ 2.3688674 ]
 [ 0.        ]
 [-0.        ]
 [-2.2138162 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3327065 ]
 [ 0.        ]]
--- 0.3044564723968506 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2856.194091796875, (1272.1038, 1.613989, 1582.0817, 0.3948543)
   validation loss 2138.278564453125, (1735.0023, 0.084801495, 402.79657, 0.3948543)
decoder loss ratio: 67217.001948, decoder SINDy loss  ratio: 0.869493
--- 0.27106571197509766 seconds for one epoch ---
--- 0.2925455570220947 seconds for one epoch ---
--- 0.5287883281707764 seconds for one epoch ---
--- 0.31824827194213867 seconds for one epoch ---
--- 0.5583157539367676 seconds for one epoch ---
--- 0.3029155731201172 seconds for one epoch ---
--- 0.5583491325378418 seconds for one epoch ---
--- 0.30025458335876465 seconds for one epoch ---
--- 0.5636928081512451 seconds for one epoch ---
--- 0.2898242473602295 seconds for one epoch ---
--- 0.5566911697387695 seconds for one epoch ---
--- 0.31335020065307617 seconds for one epoch ---
--- 0.5617043972015381 seconds for one epoch ---
--- 0.31168484687805176 seconds for one epoch ---
--- 0.5478556156158447 seconds for one epoch ---
--- 0.31234025955200195 seconds for one epoch ---
--- 0.5668208599090576 seconds for one epoch ---
--- 0.32883429527282715 seconds for one epoch ---
--- 0.5386264324188232 seconds for one epoch ---
--- 0.33908510208129883 seconds for one epoch ---
--- 0.5638697147369385 seconds for one epoch ---
--- 0.32030224800109863 seconds for one epoch ---
--- 0.5778286457061768 seconds for one epoch ---
--- 0.31137871742248535 seconds for one epoch ---
=========================
[[0.02089679]
 [0.        ]
 [0.2895839 ]
 [0.        ]
 [0.        ]
 [0.18878971]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27019277]
 [0.        ]]
[[-0.25581792]
 [-0.        ]
 [ 2.2998443 ]
 [ 0.        ]
 [-0.        ]
 [-1.9376867 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2377222 ]
 [ 0.        ]]
--- 0.27463650703430176 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5660.7021484375, (1940.2795, 0.76562, 3719.298, 0.3590573)
   validation loss 1168.1026611328125, (844.7438, 0.08122841, 322.91864, 0.3590573)
decoder loss ratio: 32726.840360, decoder SINDy loss  ratio: 0.697065
--- 0.32503390312194824 seconds for one epoch ---
--- 0.5442769527435303 seconds for one epoch ---
--- 0.29853010177612305 seconds for one epoch ---
--- 0.5584011077880859 seconds for one epoch ---
--- 0.31642746925354004 seconds for one epoch ---
--- 0.5699377059936523 seconds for one epoch ---
--- 0.3135030269622803 seconds for one epoch ---
--- 0.5746841430664062 seconds for one epoch ---
--- 0.341353178024292 seconds for one epoch ---
--- 0.5912661552429199 seconds for one epoch ---
--- 0.3231208324432373 seconds for one epoch ---
--- 0.5940876007080078 seconds for one epoch ---
--- 0.29631948471069336 seconds for one epoch ---
--- 0.5521628856658936 seconds for one epoch ---
--- 0.30512261390686035 seconds for one epoch ---
--- 0.6125364303588867 seconds for one epoch ---
--- 0.32819294929504395 seconds for one epoch ---
--- 0.5915162563323975 seconds for one epoch ---
--- 0.31401777267456055 seconds for one epoch ---
--- 0.5930662155151367 seconds for one epoch ---
--- 0.32106757164001465 seconds for one epoch ---
--- 0.601891279220581 seconds for one epoch ---
--- 0.32123470306396484 seconds for one epoch ---
--- 0.5957543849945068 seconds for one epoch ---
=========================
[[0.01833476]
 [0.        ]
 [0.2527016 ]
 [0.        ]
 [0.        ]
 [0.15693478]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.26415727]
 [0.        ]]
[[-0.18830827]
 [-0.        ]
 [ 2.1819851 ]
 [ 0.        ]
 [-0.        ]
 [-1.7972904 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2204626 ]
 [ 0.        ]]
--- 0.31679534912109375 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4327.89794921875, (1414.8093, 1.0561697, 2911.693, 0.33935085)
   validation loss 960.0498046875, (685.5482, 0.06328523, 274.0989, 0.33935085)
decoder loss ratio: 26559.328121, decoder SINDy loss  ratio: 0.591681
--- 0.25835442543029785 seconds for one epoch ---
--- 0.3132166862487793 seconds for one epoch ---
--- 0.5857987403869629 seconds for one epoch ---
--- 0.3237946033477783 seconds for one epoch ---
--- 0.6017153263092041 seconds for one epoch ---
--- 0.3209257125854492 seconds for one epoch ---
--- 0.6101789474487305 seconds for one epoch ---
--- 0.3190956115722656 seconds for one epoch ---
--- 0.5943613052368164 seconds for one epoch ---
--- 0.3180699348449707 seconds for one epoch ---
--- 0.5663895606994629 seconds for one epoch ---
--- 0.295299768447876 seconds for one epoch ---
--- 0.5664114952087402 seconds for one epoch ---
--- 0.31162476539611816 seconds for one epoch ---
--- 0.571540355682373 seconds for one epoch ---
--- 0.31617069244384766 seconds for one epoch ---
--- 0.5808782577514648 seconds for one epoch ---
--- 0.32653164863586426 seconds for one epoch ---
--- 0.5765507221221924 seconds for one epoch ---
--- 0.32059359550476074 seconds for one epoch ---
--- 0.5728428363800049 seconds for one epoch ---
--- 0.29901647567749023 seconds for one epoch ---
--- 0.562725305557251 seconds for one epoch ---
--- 0.3014256954193115 seconds for one epoch ---
=========================
[[0.01651785]
 [0.        ]
 [0.2255752 ]
 [0.        ]
 [0.        ]
 [0.14127927]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.25764915]
 [0.        ]]
[[-0.14546664]
 [-0.        ]
 [ 2.088678  ]
 [ 0.        ]
 [-0.        ]
 [-1.7218124 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2011352 ]
 [ 0.        ]]
--- 0.26828789710998535 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4122.2919921875, (1982.7662, 0.5553314, 2138.6465, 0.32428798)
   validation loss 1639.52978515625, (1300.6802, 0.079810485, 338.44547, 0.32428798)
decoder loss ratio: 50390.608090, decoder SINDy loss  ratio: 0.730582
--- 0.3028838634490967 seconds for one epoch ---
--- 0.5713567733764648 seconds for one epoch ---
--- 0.45674586296081543 seconds for one epoch ---
--- 0.588050127029419 seconds for one epoch ---
--- 0.32730722427368164 seconds for one epoch ---
--- 0.6215457916259766 seconds for one epoch ---
--- 0.3171095848083496 seconds for one epoch ---
--- 0.6008219718933105 seconds for one epoch ---
--- 0.31057000160217285 seconds for one epoch ---
--- 0.5939550399780273 seconds for one epoch ---
--- 0.30809688568115234 seconds for one epoch ---
--- 0.5938153266906738 seconds for one epoch ---
--- 0.2970895767211914 seconds for one epoch ---
--- 0.5773019790649414 seconds for one epoch ---
--- 0.31842827796936035 seconds for one epoch ---
--- 0.6025021076202393 seconds for one epoch ---
--- 0.3116154670715332 seconds for one epoch ---
--- 0.5939452648162842 seconds for one epoch ---
--- 0.3015105724334717 seconds for one epoch ---
--- 0.5684764385223389 seconds for one epoch ---
--- 0.3292832374572754 seconds for one epoch ---
--- 0.5908594131469727 seconds for one epoch ---
--- 0.3348681926727295 seconds for one epoch ---
--- 0.609351396560669 seconds for one epoch ---
=========================
[[0.01569527]
 [0.        ]
 [0.20361404]
 [0.        ]
 [0.        ]
 [0.1349234 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2596867 ]
 [0.        ]]
[[-0.14004105]
 [-0.        ]
 [ 2.007303  ]
 [ 0.        ]
 [-0.        ]
 [-1.6908954 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2097528 ]
 [ 0.        ]]
--- 0.2983675003051758 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4089.6064453125, (1852.8501, 0.34359252, 2236.0942, 0.31838894)
   validation loss 1157.8489990234375, (846.5203, 0.10042767, 310.90994, 0.31838894)
decoder loss ratio: 32795.667003, decoder SINDy loss  ratio: 0.671143
--- 0.27875304222106934 seconds for one epoch ---
--- 0.3013887405395508 seconds for one epoch ---
--- 0.5771946907043457 seconds for one epoch ---
--- 0.29959607124328613 seconds for one epoch ---
--- 0.6060948371887207 seconds for one epoch ---
--- 0.31872081756591797 seconds for one epoch ---
--- 0.6009657382965088 seconds for one epoch ---
--- 0.33134961128234863 seconds for one epoch ---
--- 0.5912988185882568 seconds for one epoch ---
--- 0.3210155963897705 seconds for one epoch ---
--- 0.6163654327392578 seconds for one epoch ---
--- 0.30646705627441406 seconds for one epoch ---
--- 0.6166946887969971 seconds for one epoch ---
--- 0.29021644592285156 seconds for one epoch ---
--- 0.6159548759460449 seconds for one epoch ---
--- 0.31310319900512695 seconds for one epoch ---
--- 0.6240153312683105 seconds for one epoch ---
--- 0.3084280490875244 seconds for one epoch ---
--- 0.5967094898223877 seconds for one epoch ---
--- 0.3087456226348877 seconds for one epoch ---
--- 0.6283564567565918 seconds for one epoch ---
--- 0.3390774726867676 seconds for one epoch ---
--- 0.6086552143096924 seconds for one epoch ---
--- 0.3361937999725342 seconds for one epoch ---
=========================
[[0.01535233]
 [0.        ]
 [0.18437117]
 [0.        ]
 [0.        ]
 [0.12603252]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27165508]
 [0.        ]]
[[-0.15500629]
 [-0.        ]
 [ 1.9307534 ]
 [ 0.        ]
 [-0.        ]
 [-1.6439242 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2505906 ]
 [ 0.        ]]
--- 0.273592472076416 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3488.995849609375, (1678.7985, 0.9947322, 1808.8883, 0.31427208)
   validation loss 1109.5947265625, (790.2187, 0.07096544, 318.99072, 0.31427208)
decoder loss ratio: 30614.443890, decoder SINDy loss  ratio: 0.688586
--- 0.33500242233276367 seconds for one epoch ---
--- 0.6261343955993652 seconds for one epoch ---
--- 0.30368685722351074 seconds for one epoch ---
--- 0.6275453567504883 seconds for one epoch ---
--- 0.2950608730316162 seconds for one epoch ---
--- 0.6173908710479736 seconds for one epoch ---
--- 0.2829864025115967 seconds for one epoch ---
--- 0.6158854961395264 seconds for one epoch ---
--- 0.29346156120300293 seconds for one epoch ---
--- 0.6250588893890381 seconds for one epoch ---
--- 0.31549882888793945 seconds for one epoch ---
--- 0.6147420406341553 seconds for one epoch ---
--- 0.31146240234375 seconds for one epoch ---
--- 0.616180419921875 seconds for one epoch ---
--- 0.3085341453552246 seconds for one epoch ---
--- 0.6053669452667236 seconds for one epoch ---
--- 0.311720609664917 seconds for one epoch ---
--- 0.6170058250427246 seconds for one epoch ---
--- 0.33062243461608887 seconds for one epoch ---
--- 0.619880199432373 seconds for one epoch ---
--- 0.3253138065338135 seconds for one epoch ---
--- 0.6345582008361816 seconds for one epoch ---
--- 0.3198862075805664 seconds for one epoch ---
--- 0.6252491474151611 seconds for one epoch ---
=========================
[[0.01483724]
 [0.        ]
 [0.1682038 ]
 [0.        ]
 [0.        ]
 [0.119887  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27536052]
 [0.        ]]
[[-0.15359524]
 [-0.        ]
 [ 1.8615518 ]
 [ 0.        ]
 [-0.        ]
 [-1.6101483 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.263667  ]
 [ 0.        ]]
--- 0.2858295440673828 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4875.12353515625, (1574.7932, 1.1662416, 3298.8552, 0.30889413)
   validation loss 954.780517578125, (645.7588, 0.08807066, 308.62476, 0.30889413)
decoder loss ratio: 25017.816575, decoder SINDy loss  ratio: 0.666210
--- 0.26128506660461426 seconds for one epoch ---
--- 0.3177673816680908 seconds for one epoch ---
--- 0.6101136207580566 seconds for one epoch ---
--- 0.32313036918640137 seconds for one epoch ---
--- 0.5946786403656006 seconds for one epoch ---
--- 0.29918956756591797 seconds for one epoch ---
--- 0.6295959949493408 seconds for one epoch ---
--- 0.30562400817871094 seconds for one epoch ---
--- 0.6031861305236816 seconds for one epoch ---
--- 0.30664658546447754 seconds for one epoch ---
--- 0.6443939208984375 seconds for one epoch ---
--- 0.2864413261413574 seconds for one epoch ---
--- 0.6234092712402344 seconds for one epoch ---
--- 0.27752161026000977 seconds for one epoch ---
--- 0.5974481105804443 seconds for one epoch ---
--- 0.29552555084228516 seconds for one epoch ---
--- 0.6265382766723633 seconds for one epoch ---
--- 0.31502270698547363 seconds for one epoch ---
--- 0.6335427761077881 seconds for one epoch ---
--- 0.32604002952575684 seconds for one epoch ---
--- 0.6468515396118164 seconds for one epoch ---
--- 0.2995309829711914 seconds for one epoch ---
--- 0.6253001689910889 seconds for one epoch ---
--- 0.3019750118255615 seconds for one epoch ---
=========================
[[0.01439102]
 [0.        ]
 [0.151995  ]
 [0.        ]
 [0.        ]
 [0.11319718]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28019628]
 [0.        ]]
[[-0.15310986]
 [-0.        ]
 [ 1.7866455 ]
 [ 0.        ]
 [-0.        ]
 [-1.5712628 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.28008   ]
 [ 0.        ]]
--- 0.26467132568359375 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4611.6064453125, (2961.9285, 0.83116364, 1648.5426, 0.30416742)
   validation loss 1487.95166015625, (1066.1223, 0.097843, 421.42725, 0.30416742)
decoder loss ratio: 41303.429332, decoder SINDy loss  ratio: 0.909710
--- 0.3208174705505371 seconds for one epoch ---
--- 0.6355478763580322 seconds for one epoch ---
--- 0.3256649971008301 seconds for one epoch ---
--- 0.6344618797302246 seconds for one epoch ---
--- 0.3243582248687744 seconds for one epoch ---
--- 0.6246275901794434 seconds for one epoch ---
--- 0.30500268936157227 seconds for one epoch ---
--- 0.6223247051239014 seconds for one epoch ---
--- 0.29639267921447754 seconds for one epoch ---
--- 0.6354720592498779 seconds for one epoch ---
--- 0.3223237991333008 seconds for one epoch ---
--- 0.6246058940887451 seconds for one epoch ---
--- 0.29749131202697754 seconds for one epoch ---
--- 0.6472864151000977 seconds for one epoch ---
--- 0.3016231060028076 seconds for one epoch ---
--- 0.6248223781585693 seconds for one epoch ---
--- 0.28966188430786133 seconds for one epoch ---
--- 0.637526273727417 seconds for one epoch ---
--- 0.30209803581237793 seconds for one epoch ---
--- 0.6202361583709717 seconds for one epoch ---
--- 0.32023024559020996 seconds for one epoch ---
--- 0.6253628730773926 seconds for one epoch ---
--- 0.3292415142059326 seconds for one epoch ---
--- 0.6525290012359619 seconds for one epoch ---
=========================
[[0.01488126]
 [0.        ]
 [0.13537368]
 [0.        ]
 [0.        ]
 [0.11182342]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2969348 ]
 [0.        ]]
[[-0.19303039]
 [-0.        ]
 [ 1.7024249 ]
 [ 0.        ]
 [-0.        ]
 [-1.5644534 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3328903 ]
 [ 0.        ]]
--- 0.3054237365722656 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4293.78369140625, (1686.3636, 1.3794142, 2605.7378, 0.30263492)
   validation loss 1572.4791259765625, (1160.4371, 0.06694099, 411.6725, 0.30263492)
decoder loss ratio: 44957.349170, decoder SINDy loss  ratio: 0.888653
--- 0.2681310176849365 seconds for one epoch ---
--- 0.2964742183685303 seconds for one epoch ---
--- 0.6264173984527588 seconds for one epoch ---
--- 0.3077733516693115 seconds for one epoch ---
--- 0.6247057914733887 seconds for one epoch ---
--- 0.3008544445037842 seconds for one epoch ---
--- 0.6476092338562012 seconds for one epoch ---
--- 0.3041341304779053 seconds for one epoch ---
--- 0.6479580402374268 seconds for one epoch ---
--- 0.30437636375427246 seconds for one epoch ---
--- 0.6274139881134033 seconds for one epoch ---
--- 0.3124823570251465 seconds for one epoch ---
--- 0.6251323223114014 seconds for one epoch ---
--- 0.3173544406890869 seconds for one epoch ---
--- 0.683333158493042 seconds for one epoch ---
--- 0.3215370178222656 seconds for one epoch ---
--- 0.6455075740814209 seconds for one epoch ---
--- 0.3253941535949707 seconds for one epoch ---
--- 0.6447899341583252 seconds for one epoch ---
--- 0.3201143741607666 seconds for one epoch ---
--- 0.6646425724029541 seconds for one epoch ---
--- 0.32269787788391113 seconds for one epoch ---
--- 0.6456758975982666 seconds for one epoch ---
--- 0.3038651943206787 seconds for one epoch ---
=========================
[[0.01524688]
 [0.        ]
 [0.11844694]
 [0.        ]
 [0.        ]
 [0.10663079]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31594363]
 [0.        ]]
[[-0.22352861]
 [-0.        ]
 [ 1.6072334 ]
 [ 0.        ]
 [-0.        ]
 [-1.5324838 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3906505 ]
 [ 0.        ]]
--- 0.2613639831542969 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4109.7333984375, (1958.0314, 1.110665, 2150.2896, 0.3018162)
   validation loss 1121.0654296875, (796.6864, 0.09704799, 323.9802, 0.3018162)
decoder loss ratio: 30865.014297, decoder SINDy loss  ratio: 0.699357
--- 0.2931351661682129 seconds for one epoch ---
--- 0.6471116542816162 seconds for one epoch ---
--- 0.3049144744873047 seconds for one epoch ---
--- 0.6411027908325195 seconds for one epoch ---
--- 0.29797840118408203 seconds for one epoch ---
--- 0.6633572578430176 seconds for one epoch ---
--- 0.3035409450531006 seconds for one epoch ---
--- 0.659609317779541 seconds for one epoch ---
--- 0.313723087310791 seconds for one epoch ---
--- 0.6610805988311768 seconds for one epoch ---
--- 0.3303520679473877 seconds for one epoch ---
--- 0.6802504062652588 seconds for one epoch ---
--- 0.3411369323730469 seconds for one epoch ---
--- 0.6775200366973877 seconds for one epoch ---
--- 0.3216440677642822 seconds for one epoch ---
--- 0.6900861263275146 seconds for one epoch ---
--- 0.3126332759857178 seconds for one epoch ---
--- 0.6720316410064697 seconds for one epoch ---
--- 0.3079714775085449 seconds for one epoch ---
--- 0.6579749584197998 seconds for one epoch ---
--- 0.29772210121154785 seconds for one epoch ---
--- 0.6597347259521484 seconds for one epoch ---
--- 0.29532599449157715 seconds for one epoch ---
--- 0.6522216796875 seconds for one epoch ---
=========================
[[0.01622192]
 [0.        ]
 [0.11112024]
 [0.        ]
 [0.        ]
 [0.10585651]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33793262]
 [0.        ]]
[[-0.27522692]
 [-0.        ]
 [ 1.563026  ]
 [ 0.        ]
 [-0.        ]
 [-1.5287337 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.4549747 ]
 [ 0.        ]]
--- 0.2939121723175049 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2836.676025390625, (1248.0183, 0.32878843, 1588.0234, 0.30541283)
   validation loss 1792.6954345703125, (1435.9348, 0.13750991, 356.31778, 0.30541283)
decoder loss ratio: 55630.607604, decoder SINDy loss  ratio: 0.769162
--- 0.25998663902282715 seconds for one epoch ---
--- 0.3028724193572998 seconds for one epoch ---
--- 0.6805131435394287 seconds for one epoch ---
--- 0.321582555770874 seconds for one epoch ---
--- 0.6438171863555908 seconds for one epoch ---
--- 0.3126335144042969 seconds for one epoch ---
--- 0.652829647064209 seconds for one epoch ---
--- 0.3319571018218994 seconds for one epoch ---
--- 0.6781671047210693 seconds for one epoch ---
--- 0.32949304580688477 seconds for one epoch ---
--- 0.6879935264587402 seconds for one epoch ---
--- 0.3312647342681885 seconds for one epoch ---
--- 0.6958856582641602 seconds for one epoch ---
--- 0.3152914047241211 seconds for one epoch ---
--- 0.6773409843444824 seconds for one epoch ---
--- 0.31601476669311523 seconds for one epoch ---
--- 0.6710004806518555 seconds for one epoch ---
--- 0.3232109546661377 seconds for one epoch ---
--- 0.6893124580383301 seconds for one epoch ---
--- 0.3026871681213379 seconds for one epoch ---
--- 0.6773815155029297 seconds for one epoch ---
--- 0.303149938583374 seconds for one epoch ---
--- 0.7019307613372803 seconds for one epoch ---
--- 0.3011317253112793 seconds for one epoch ---
=========================
[[0.01658916]
 [0.        ]
 [0.1005584 ]
 [0.        ]
 [0.        ]
 [0.1012537 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.351513  ]
 [0.        ]]
[[-0.29848847]
 [-0.        ]
 [ 1.4939988 ]
 [ 0.        ]
 [-0.        ]
 [-1.4988164 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.4938114 ]
 [ 0.        ]]
--- 0.26946449279785156 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3131.139892578125, (1400.5262, 0.63520056, 1729.6752, 0.3032886)
   validation loss 4397.81494140625, (3962.0046, 0.113974534, 435.39325, 0.3032886)
decoder loss ratio: 153494.938045, decoder SINDy loss  ratio: 0.939858
--- 0.30061841011047363 seconds for one epoch ---
--- 0.6589362621307373 seconds for one epoch ---
--- 0.32002973556518555 seconds for one epoch ---
--- 0.6888260841369629 seconds for one epoch ---
--- 0.3152623176574707 seconds for one epoch ---
--- 0.685215950012207 seconds for one epoch ---
--- 0.32737088203430176 seconds for one epoch ---
--- 0.7033758163452148 seconds for one epoch ---
--- 0.31789612770080566 seconds for one epoch ---
--- 0.6990058422088623 seconds for one epoch ---
--- 0.3202509880065918 seconds for one epoch ---
--- 0.6907474994659424 seconds for one epoch ---
--- 0.30417776107788086 seconds for one epoch ---
--- 0.694960355758667 seconds for one epoch ---
--- 0.3105616569519043 seconds for one epoch ---
--- 0.6836161613464355 seconds for one epoch ---
--- 0.3072507381439209 seconds for one epoch ---
--- 0.6836574077606201 seconds for one epoch ---
--- 0.30431318283081055 seconds for one epoch ---
--- 0.7018578052520752 seconds for one epoch ---
--- 0.28860974311828613 seconds for one epoch ---
--- 0.6854324340820312 seconds for one epoch ---
--- 0.32320237159729004 seconds for one epoch ---
--- 0.6843101978302002 seconds for one epoch ---
=========================
[[0.01679349]
 [0.        ]
 [0.09269334]
 [0.        ]
 [0.        ]
 [0.09603111]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.36326984]
 [0.        ]]
[[-0.31280875]
 [-0.        ]
 [ 1.4384537 ]
 [ 0.        ]
 [-0.        ]
 [-1.4629595 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5268505 ]
 [ 0.        ]]
--- 0.2922971248626709 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3293.03857421875, (1933.8591, 0.19846162, 1358.6783, 0.3027738)
   validation loss 1307.9305419921875, (975.28156, 0.1270981, 332.21918, 0.3027738)
decoder loss ratio: 37784.100611, decoder SINDy loss  ratio: 0.717142
--- 0.2656550407409668 seconds for one epoch ---
--- 0.3014681339263916 seconds for one epoch ---
--- 0.6704554557800293 seconds for one epoch ---
--- 0.33068275451660156 seconds for one epoch ---
--- 0.6815211772918701 seconds for one epoch ---
--- 0.34241271018981934 seconds for one epoch ---
--- 0.6840333938598633 seconds for one epoch ---
--- 0.32816028594970703 seconds for one epoch ---
--- 0.7106223106384277 seconds for one epoch ---
--- 0.3189713954925537 seconds for one epoch ---
--- 0.707038402557373 seconds for one epoch ---
--- 0.30126380920410156 seconds for one epoch ---
--- 0.6843228340148926 seconds for one epoch ---
--- 0.30477094650268555 seconds for one epoch ---
--- 0.6879746913909912 seconds for one epoch ---
--- 0.29839038848876953 seconds for one epoch ---
--- 0.7043650150299072 seconds for one epoch ---
--- 0.3030261993408203 seconds for one epoch ---
--- 0.6951534748077393 seconds for one epoch ---
--- 0.3105432987213135 seconds for one epoch ---
--- 0.681708812713623 seconds for one epoch ---
--- 0.30777502059936523 seconds for one epoch ---
--- 0.6971089839935303 seconds for one epoch ---
--- 0.31806015968322754 seconds for one epoch ---
=========================
[[0.01764914]
 [0.        ]
 [0.09056856]
 [0.        ]
 [0.        ]
 [0.09238388]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.38278198]
 [0.        ]]
[[-0.35050228]
 [-0.        ]
 [ 1.4234686 ]
 [ 0.        ]
 [-0.        ]
 [-1.4371496 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5805206 ]
 [ 0.        ]]
--- 0.25225043296813965 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2069.776123046875, (1277.8759, 0.47308633, 791.1211, 0.30579755)
   validation loss 1159.3236083984375, (858.3584, 0.10331537, 300.55615, 0.30579755)
decoder loss ratio: 33254.294531, decoder SINDy loss  ratio: 0.648793
--- 0.3015711307525635 seconds for one epoch ---
--- 0.6787686347961426 seconds for one epoch ---
--- 0.32535624504089355 seconds for one epoch ---
--- 0.683112621307373 seconds for one epoch ---
--- 0.3166630268096924 seconds for one epoch ---
--- 0.6871778964996338 seconds for one epoch ---
--- 0.3294706344604492 seconds for one epoch ---
--- 0.701493501663208 seconds for one epoch ---
--- 0.32152462005615234 seconds for one epoch ---
--- 0.7134878635406494 seconds for one epoch ---
--- 0.2863948345184326 seconds for one epoch ---
--- 0.6989462375640869 seconds for one epoch ---
--- 0.2933478355407715 seconds for one epoch ---
--- 0.7080726623535156 seconds for one epoch ---
--- 0.3061826229095459 seconds for one epoch ---
--- 0.6968138217926025 seconds for one epoch ---
--- 0.30728936195373535 seconds for one epoch ---
--- 0.6984307765960693 seconds for one epoch ---
--- 0.3179500102996826 seconds for one epoch ---
--- 0.6958887577056885 seconds for one epoch ---
--- 0.30423712730407715 seconds for one epoch ---
--- 0.6966640949249268 seconds for one epoch ---
--- 0.30077266693115234 seconds for one epoch ---
--- 0.7316997051239014 seconds for one epoch ---
=========================
[[0.01872291]
 [0.        ]
 [0.08389022]
 [0.        ]
 [0.        ]
 [0.09068576]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40217203]
 [0.        ]]
[[-0.39244455]
 [-0.        ]
 [ 1.3717884 ]
 [ 0.        ]
 [-0.        ]
 [-1.4251534 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6328244 ]
 [ 0.        ]]
--- 0.29346203804016113 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3380.002197265625, (1346.0135, 4.0892973, 2029.5906, 0.30872366)
   validation loss 2662.171630859375, (2304.0588, 0.12892571, 357.67508, 0.30872366)
decoder loss ratio: 89263.239402, decoder SINDy loss  ratio: 0.772092
--- 0.26645922660827637 seconds for one epoch ---
--- 0.3132927417755127 seconds for one epoch ---
--- 0.7336814403533936 seconds for one epoch ---
--- 0.33770108222961426 seconds for one epoch ---
--- 0.7289483547210693 seconds for one epoch ---
--- 0.3133399486541748 seconds for one epoch ---
--- 0.7047741413116455 seconds for one epoch ---
--- 0.2978477478027344 seconds for one epoch ---
--- 0.7053210735321045 seconds for one epoch ---
--- 0.2896449565887451 seconds for one epoch ---
--- 0.6933643817901611 seconds for one epoch ---
--- 0.3202993869781494 seconds for one epoch ---
--- 0.7236161231994629 seconds for one epoch ---
--- 0.45963168144226074 seconds for one epoch ---
--- 0.7103626728057861 seconds for one epoch ---
--- 0.30020928382873535 seconds for one epoch ---
--- 0.7317631244659424 seconds for one epoch ---
--- 0.3001129627227783 seconds for one epoch ---
--- 0.7646694183349609 seconds for one epoch ---
--- 0.3058648109436035 seconds for one epoch ---
--- 0.7137308120727539 seconds for one epoch ---
--- 0.30265331268310547 seconds for one epoch ---
--- 0.7185418605804443 seconds for one epoch ---
--- 0.3123598098754883 seconds for one epoch ---
=========================
[[0.02064713]
 [0.        ]
 [0.08159311]
 [0.        ]
 [0.        ]
 [0.08702832]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4387198 ]
 [0.        ]]
[[-0.45826468]
 [-0.        ]
 [ 1.3536725 ]
 [ 0.        ]
 [-0.        ]
 [-1.3976486 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7293005 ]
 [ 0.        ]]
--- 0.2684931755065918 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8464.6064453125, (1862.6942, 2.5039523, 6599.0923, 0.31615645)
   validation loss 817.689453125, (533.8148, 0.18328574, 283.37515, 0.31615645)
decoder loss ratio: 20680.912844, decoder SINDy loss  ratio: 0.611705
--- 0.2983360290527344 seconds for one epoch ---
--- 0.7225644588470459 seconds for one epoch ---
--- 0.3039247989654541 seconds for one epoch ---
--- 0.7174291610717773 seconds for one epoch ---
--- 0.2934727668762207 seconds for one epoch ---
--- 0.715484619140625 seconds for one epoch ---
--- 0.2766385078430176 seconds for one epoch ---
--- 0.7470076084136963 seconds for one epoch ---
--- 0.31798458099365234 seconds for one epoch ---
--- 0.7579760551452637 seconds for one epoch ---
--- 0.3096787929534912 seconds for one epoch ---
--- 0.725811243057251 seconds for one epoch ---
--- 0.30222296714782715 seconds for one epoch ---
--- 0.7205934524536133 seconds for one epoch ---
--- 0.3028566837310791 seconds for one epoch ---
--- 0.7297754287719727 seconds for one epoch ---
--- 0.29967331886291504 seconds for one epoch ---
--- 0.7238893508911133 seconds for one epoch ---
--- 0.3144690990447998 seconds for one epoch ---
--- 0.7260262966156006 seconds for one epoch ---
--- 0.3050370216369629 seconds for one epoch ---
--- 0.7329154014587402 seconds for one epoch ---
--- 0.30993175506591797 seconds for one epoch ---
--- 0.727747917175293 seconds for one epoch ---
=========================
[[0.02206064]
 [0.        ]
 [0.07741055]
 [0.        ]
 [0.        ]
 [0.08477522]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.46151385]
 [0.        ]]
[[-0.50276715]
 [-0.        ]
 [ 1.3186538 ]
 [ 0.        ]
 [-0.        ]
 [-1.3803276 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.788641  ]
 [ 0.        ]]
--- 0.29227161407470703 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2761.4619140625, (1603.8588, 0.50741374, 1156.776, 0.31970704)
   validation loss 1004.9739990234375, (701.32874, 0.18188499, 303.14365, 0.31970704)
decoder loss ratio: 27170.692768, decoder SINDy loss  ratio: 0.654378
--- 0.2701272964477539 seconds for one epoch ---
--- 0.29681825637817383 seconds for one epoch ---
--- 0.7086727619171143 seconds for one epoch ---
--- 0.30240440368652344 seconds for one epoch ---
--- 0.7413265705108643 seconds for one epoch ---
--- 0.3322134017944336 seconds for one epoch ---
--- 0.709458589553833 seconds for one epoch ---
--- 0.30516982078552246 seconds for one epoch ---
--- 0.7290618419647217 seconds for one epoch ---
--- 0.3218958377838135 seconds for one epoch ---
--- 0.7467474937438965 seconds for one epoch ---
--- 0.34215354919433594 seconds for one epoch ---
--- 0.7367801666259766 seconds for one epoch ---
--- 0.3194267749786377 seconds for one epoch ---
--- 0.7441399097442627 seconds for one epoch ---
--- 0.3260800838470459 seconds for one epoch ---
--- 0.7610008716583252 seconds for one epoch ---
--- 0.30141258239746094 seconds for one epoch ---
--- 0.7317135334014893 seconds for one epoch ---
--- 0.3019678592681885 seconds for one epoch ---
--- 0.7626831531524658 seconds for one epoch ---
--- 0.31077146530151367 seconds for one epoch ---
--- 0.7223048210144043 seconds for one epoch ---
--- 0.2996785640716553 seconds for one epoch ---
=========================
[[0.0234199 ]
 [0.        ]
 [0.07502127]
 [0.        ]
 [0.        ]
 [0.08091561]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.48506072]
 [0.        ]]
[[-0.5427401]
 [-0.       ]
 [ 1.2981228]
 [ 0.       ]
 [-0.       ]
 [-1.3492128]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8495724]
 [ 0.       ]]
--- 0.27460336685180664 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2661.071044921875, (1382.6046, 1.3482245, 1276.7954, 0.3226669)
   validation loss 1131.3948974609375, (816.4939, 0.16842334, 314.4099, 0.3226669)
decoder loss ratio: 31632.391046, decoder SINDy loss  ratio: 0.678698
--- 0.3091738224029541 seconds for one epoch ---
--- 0.7331511974334717 seconds for one epoch ---
--- 0.32035040855407715 seconds for one epoch ---
--- 0.747927188873291 seconds for one epoch ---
--- 0.3099493980407715 seconds for one epoch ---
--- 0.7466690540313721 seconds for one epoch ---
--- 0.3036155700683594 seconds for one epoch ---
--- 0.7329857349395752 seconds for one epoch ---
--- 0.29377150535583496 seconds for one epoch ---
--- 0.7543730735778809 seconds for one epoch ---
--- 0.3177626132965088 seconds for one epoch ---
--- 0.7479166984558105 seconds for one epoch ---
--- 0.302462100982666 seconds for one epoch ---
--- 0.7479970455169678 seconds for one epoch ---
--- 0.3059718608856201 seconds for one epoch ---
--- 0.7561831474304199 seconds for one epoch ---
--- 0.3338449001312256 seconds for one epoch ---
--- 0.7639703750610352 seconds for one epoch ---
--- 0.33206748962402344 seconds for one epoch ---
--- 0.7604629993438721 seconds for one epoch ---
--- 0.34042930603027344 seconds for one epoch ---
--- 0.7727820873260498 seconds for one epoch ---
--- 0.32617926597595215 seconds for one epoch ---
--- 0.7623789310455322 seconds for one epoch ---
=========================
[[0.02561048]
 [0.        ]
 [0.07563806]
 [0.        ]
 [0.        ]
 [0.07937794]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5132438 ]
 [0.        ]]
[[-0.6008753]
 [-0.       ]
 [ 1.3041161]
 [ 0.       ]
 [-0.       ]
 [-1.336675 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9223695]
 [ 0.       ]]
--- 0.316925048828125 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3148.8095703125, (1394.7191, 2.570397, 1751.1908, 0.32906613)
   validation loss 951.0223999023438, (660.0566, 0.25180864, 290.38495, 0.32906613)
decoder loss ratio: 25571.737802, decoder SINDy loss  ratio: 0.626837
THRESHOLDING: 1 active coefficients
--- 0.7508218288421631 seconds for one epoch ---
--- 0.3270697593688965 seconds for one epoch ---
--- 0.7610752582550049 seconds for one epoch ---
--- 0.3246314525604248 seconds for one epoch ---
--- 0.7541611194610596 seconds for one epoch ---
--- 0.32129812240600586 seconds for one epoch ---
--- 0.7815747261047363 seconds for one epoch ---
--- 0.3017761707305908 seconds for one epoch ---
--- 0.7611572742462158 seconds for one epoch ---
--- 0.3085482120513916 seconds for one epoch ---
--- 0.7785460948944092 seconds for one epoch ---
--- 0.2986938953399658 seconds for one epoch ---
--- 0.7510743141174316 seconds for one epoch ---
--- 0.2990412712097168 seconds for one epoch ---
--- 0.7548098564147949 seconds for one epoch ---
--- 0.30713701248168945 seconds for one epoch ---
--- 0.7434220314025879 seconds for one epoch ---
--- 0.2953338623046875 seconds for one epoch ---
--- 0.743924617767334 seconds for one epoch ---
--- 0.29781055450439453 seconds for one epoch ---
--- 0.7609031200408936 seconds for one epoch ---
--- 0.31469106674194336 seconds for one epoch ---
--- 0.7954795360565186 seconds for one epoch ---
--- 0.3158073425292969 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6768404]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-3.367935]
 [ 0.      ]]
--- 0.2587757110595703 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2238.44970703125, (1099.1051, 0.6474395, 1138.4607, 0.23630865)
   validation loss 1555.58056640625, (1154.9071, 0.17897114, 400.2582, 0.23630865)
decoder loss ratio: 44743.106235, decoder SINDy loss  ratio: 0.864014
--- 0.29654502868652344 seconds for one epoch ---
--- 0.7569012641906738 seconds for one epoch ---
--- 0.30222392082214355 seconds for one epoch ---
--- 0.7603113651275635 seconds for one epoch ---
--- 0.2972991466522217 seconds for one epoch ---
--- 0.7418439388275146 seconds for one epoch ---
--- 0.31044983863830566 seconds for one epoch ---
--- 0.7639150619506836 seconds for one epoch ---
--- 0.3271787166595459 seconds for one epoch ---
--- 0.7945361137390137 seconds for one epoch ---
--- 0.3231372833251953 seconds for one epoch ---
--- 0.7798380851745605 seconds for one epoch ---
--- 0.315645694732666 seconds for one epoch ---
--- 0.7656726837158203 seconds for one epoch ---
--- 0.3065011501312256 seconds for one epoch ---
--- 0.764333963394165 seconds for one epoch ---
--- 0.2911078929901123 seconds for one epoch ---
--- 0.7490131855010986 seconds for one epoch ---
--- 0.3038792610168457 seconds for one epoch ---
--- 0.7548537254333496 seconds for one epoch ---
--- 0.30779051780700684 seconds for one epoch ---
--- 0.7893140316009521 seconds for one epoch ---
--- 0.3035862445831299 seconds for one epoch ---
--- 0.7653820514678955 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.80290365]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.8047616]
 [ 0.       ]]
--- 0.28981518745422363 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5753.63427734375, (2301.8508, 1.2339175, 3450.2917, 0.2579462)
   validation loss 933.2857666015625, (629.4189, 0.26993388, 303.33896, 0.2579462)
decoder loss ratio: 24384.780296, decoder SINDy loss  ratio: 0.654800
--- 0.26073169708251953 seconds for one epoch ---
--- 0.2965857982635498 seconds for one epoch ---
--- 0.7474029064178467 seconds for one epoch ---
--- 0.29636216163635254 seconds for one epoch ---
--- 0.7872536182403564 seconds for one epoch ---
--- 0.29686570167541504 seconds for one epoch ---
--- 0.775355339050293 seconds for one epoch ---
--- 0.29822278022766113 seconds for one epoch ---
--- 0.7893509864807129 seconds for one epoch ---
--- 0.2982950210571289 seconds for one epoch ---
--- 0.7820315361022949 seconds for one epoch ---
--- 0.312868595123291 seconds for one epoch ---
--- 0.8093123435974121 seconds for one epoch ---
--- 0.3178727626800537 seconds for one epoch ---
--- 0.7997410297393799 seconds for one epoch ---
--- 0.3228464126586914 seconds for one epoch ---
--- 0.7808699607849121 seconds for one epoch ---
--- 0.2986302375793457 seconds for one epoch ---
--- 0.7903387546539307 seconds for one epoch ---
--- 0.3367655277252197 seconds for one epoch ---
--- 0.7892718315124512 seconds for one epoch ---
--- 0.3261730670928955 seconds for one epoch ---
--- 0.8147342205047607 seconds for one epoch ---
--- 0.32520508766174316 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.884977]
 [0.      ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.2270393]
 [ 0.       ]]
--- 0.25885725021362305 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2045.1766357421875, (1216.301, 0.6148226, 827.9891, 0.2716578)
   validation loss 912.8244018554688, (605.6122, 0.26051557, 306.68002, 0.2716578)
decoder loss ratio: 23462.467344, decoder SINDy loss  ratio: 0.662012
--- 0.3082404136657715 seconds for one epoch ---
--- 0.7578623294830322 seconds for one epoch ---
--- 0.3203771114349365 seconds for one epoch ---
--- 0.797466516494751 seconds for one epoch ---
--- 0.3242473602294922 seconds for one epoch ---
--- 0.7863445281982422 seconds for one epoch ---
--- 0.3376927375793457 seconds for one epoch ---
--- 0.7872345447540283 seconds for one epoch ---
--- 0.31450915336608887 seconds for one epoch ---
--- 0.8358352184295654 seconds for one epoch ---
--- 0.3220198154449463 seconds for one epoch ---
--- 0.8035123348236084 seconds for one epoch ---
--- 0.32259583473205566 seconds for one epoch ---
--- 0.8023543357849121 seconds for one epoch ---
--- 0.321591854095459 seconds for one epoch ---
--- 0.8012471199035645 seconds for one epoch ---
--- 0.30341339111328125 seconds for one epoch ---
--- 0.7997074127197266 seconds for one epoch ---
--- 0.30208897590637207 seconds for one epoch ---
--- 0.8050718307495117 seconds for one epoch ---
--- 0.2928142547607422 seconds for one epoch ---
--- 0.8009650707244873 seconds for one epoch ---
--- 0.2892789840698242 seconds for one epoch ---
--- 0.7871816158294678 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93246776]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6196194]
 [ 0.       ]]
--- 0.296917200088501 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2218.237060546875, (943.3383, 1.569932, 1273.0486, 0.28021333)
   validation loss 981.0729370117188, (664.18884, 0.28245994, 316.32138, 0.28021333)
decoder loss ratio: 25731.828852, decoder SINDy loss  ratio: 0.682824
--- 0.2653822898864746 seconds for one epoch ---
--- 0.3008553981781006 seconds for one epoch ---
--- 0.8199887275695801 seconds for one epoch ---
--- 0.29375219345092773 seconds for one epoch ---
--- 0.7945919036865234 seconds for one epoch ---
--- 0.29917359352111816 seconds for one epoch ---
--- 0.7972688674926758 seconds for one epoch ---
--- 0.3036808967590332 seconds for one epoch ---
--- 0.8116095066070557 seconds for one epoch ---
--- 0.3006627559661865 seconds for one epoch ---
--- 0.7859804630279541 seconds for one epoch ---
--- 0.30935168266296387 seconds for one epoch ---
--- 0.7908096313476562 seconds for one epoch ---
--- 0.2971036434173584 seconds for one epoch ---
--- 0.8156285285949707 seconds for one epoch ---
--- 0.3079352378845215 seconds for one epoch ---
--- 0.8215577602386475 seconds for one epoch ---
--- 0.32390332221984863 seconds for one epoch ---
--- 0.8265795707702637 seconds for one epoch ---
--- 0.3270585536956787 seconds for one epoch ---
--- 0.8307466506958008 seconds for one epoch ---
--- 0.3035585880279541 seconds for one epoch ---
--- 0.8065104484558105 seconds for one epoch ---
--- 0.30465054512023926 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9600603]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.9956765]
 [-0.       ]]
--- 0.26894187927246094 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3628.45556640625, (1314.1526, 1.2952992, 2312.7217, 0.28612384)
   validation loss 1914.9866943359375, (1515.9214, 0.35029802, 398.42883, 0.28612384)
decoder loss ratio: 58729.426277, decoder SINDy loss  ratio: 0.860065
--- 0.3083207607269287 seconds for one epoch ---
--- 0.7991533279418945 seconds for one epoch ---
--- 0.28647398948669434 seconds for one epoch ---
--- 0.807884931564331 seconds for one epoch ---
--- 0.31505727767944336 seconds for one epoch ---
--- 0.8380289077758789 seconds for one epoch ---
--- 0.3114345073699951 seconds for one epoch ---
--- 0.8144207000732422 seconds for one epoch ---
--- 0.3067007064819336 seconds for one epoch ---
--- 0.8296678066253662 seconds for one epoch ---
--- 0.2945365905761719 seconds for one epoch ---
--- 0.8178532123565674 seconds for one epoch ---
--- 0.3039062023162842 seconds for one epoch ---
--- 0.81669020652771 seconds for one epoch ---
--- 0.28917860984802246 seconds for one epoch ---
--- 0.7995638847351074 seconds for one epoch ---
--- 0.3044850826263428 seconds for one epoch ---
--- 0.8000092506408691 seconds for one epoch ---
--- 0.3067774772644043 seconds for one epoch ---
--- 0.8166725635528564 seconds for one epoch ---
--- 0.30556797981262207 seconds for one epoch ---
--- 0.8080408573150635 seconds for one epoch ---
--- 0.30647873878479004 seconds for one epoch ---
--- 0.8193809986114502 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9761711]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.3609443]
 [-0.       ]]
--- 0.29090094566345215 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3247.7265625, (1388.5103, 0.849668, 1858.0762, 0.29060808)
   validation loss 1033.447998046875, (699.70166, 0.50210154, 332.95358, 0.29060808)
decoder loss ratio: 27107.657050, decoder SINDy loss  ratio: 0.718727
--- 0.2657790184020996 seconds for one epoch ---
--- 0.29172348976135254 seconds for one epoch ---
--- 0.8084652423858643 seconds for one epoch ---
--- 0.3018162250518799 seconds for one epoch ---
--- 0.7996511459350586 seconds for one epoch ---
--- 0.31344127655029297 seconds for one epoch ---
--- 0.8173563480377197 seconds for one epoch ---
--- 0.287264347076416 seconds for one epoch ---
--- 0.8240456581115723 seconds for one epoch ---
--- 0.30667614936828613 seconds for one epoch ---
--- 0.8298358917236328 seconds for one epoch ---
--- 0.2925539016723633 seconds for one epoch ---
--- 0.8215513229370117 seconds for one epoch ---
--- 0.3098151683807373 seconds for one epoch ---
--- 0.8411428928375244 seconds for one epoch ---
--- 0.301785945892334 seconds for one epoch ---
--- 0.8140003681182861 seconds for one epoch ---
--- 0.30902862548828125 seconds for one epoch ---
--- 0.8250672817230225 seconds for one epoch ---
--- 0.3051178455352783 seconds for one epoch ---
--- 0.8216590881347656 seconds for one epoch ---
--- 0.3143484592437744 seconds for one epoch ---
--- 0.833716869354248 seconds for one epoch ---
--- 0.30620813369750977 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9860119]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-5.736645]
 [-0.      ]]
--- 0.26210856437683105 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3920.245849609375, (2005.6608, 0.31698483, 1913.9735, 0.29467297)
   validation loss 866.667724609375, (566.32306, 0.29962128, 299.75034, 0.29467297)
decoder loss ratio: 21940.338489, decoder SINDy loss  ratio: 0.647053
--- 0.29827094078063965 seconds for one epoch ---
--- 0.8261232376098633 seconds for one epoch ---
--- 0.2924206256866455 seconds for one epoch ---
--- 0.8282763957977295 seconds for one epoch ---
--- 0.30037498474121094 seconds for one epoch ---
--- 0.7663984298706055 seconds for one epoch ---
--- 0.28086090087890625 seconds for one epoch ---
--- 0.8276009559631348 seconds for one epoch ---
--- 0.29315853118896484 seconds for one epoch ---
--- 0.840015172958374 seconds for one epoch ---
--- 0.2994205951690674 seconds for one epoch ---
--- 0.8292927742004395 seconds for one epoch ---
--- 0.3158848285675049 seconds for one epoch ---
--- 0.8376615047454834 seconds for one epoch ---
--- 0.3095533847808838 seconds for one epoch ---
--- 0.841944694519043 seconds for one epoch ---
--- 0.335618257522583 seconds for one epoch ---
--- 0.8469009399414062 seconds for one epoch ---
--- 0.32915639877319336 seconds for one epoch ---
--- 0.8531622886657715 seconds for one epoch ---
--- 0.32547664642333984 seconds for one epoch ---
--- 0.8551416397094727 seconds for one epoch ---
--- 0.32309937477111816 seconds for one epoch ---
--- 0.8701071739196777 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99110305]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.0565076]
 [-0.       ]]
--- 0.2921481132507324 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4211.326171875, (1348.087, 0.80777144, 2862.1335, 0.29775342)
   validation loss 1317.4114990234375, (939.5732, 0.28498966, 377.2556, 0.29775342)
decoder loss ratio: 36400.696209, decoder SINDy loss  ratio: 0.814359
--- 0.26722192764282227 seconds for one epoch ---
--- 0.295712947845459 seconds for one epoch ---
--- 0.8474924564361572 seconds for one epoch ---
--- 0.3147273063659668 seconds for one epoch ---
--- 0.835468053817749 seconds for one epoch ---
--- 0.323347806930542 seconds for one epoch ---
--- 0.8547053337097168 seconds for one epoch ---
--- 0.31671619415283203 seconds for one epoch ---
--- 0.8634018898010254 seconds for one epoch ---
--- 0.31287717819213867 seconds for one epoch ---
--- 0.8516139984130859 seconds for one epoch ---
--- 0.2926170825958252 seconds for one epoch ---
--- 0.8618021011352539 seconds for one epoch ---
--- 0.31353092193603516 seconds for one epoch ---
--- 0.8610794544219971 seconds for one epoch ---
--- 0.28746867179870605 seconds for one epoch ---
--- 0.8199582099914551 seconds for one epoch ---
--- 0.2903294563293457 seconds for one epoch ---
--- 0.8549442291259766 seconds for one epoch ---
--- 0.2983968257904053 seconds for one epoch ---
--- 0.8574731349945068 seconds for one epoch ---
--- 0.3018651008605957 seconds for one epoch ---
--- 0.8591241836547852 seconds for one epoch ---
--- 0.2971680164337158 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99423444]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.3646264]
 [-0.       ]]
--- 0.2601010799407959 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3770.837158203125, (2049.7488, 1.071041, 1719.7166, 0.300838)
   validation loss 994.9862670898438, (692.48376, 0.32377577, 301.87784, 0.300838)
decoder loss ratio: 26828.023247, decoder SINDy loss  ratio: 0.651646
--- 0.29182934761047363 seconds for one epoch ---
--- 0.8329343795776367 seconds for one epoch ---
--- 0.3003847599029541 seconds for one epoch ---
--- 0.8624911308288574 seconds for one epoch ---
--- 0.30391621589660645 seconds for one epoch ---
--- 0.8604657649993896 seconds for one epoch ---
--- 0.30388545989990234 seconds for one epoch ---
--- 0.8303306102752686 seconds for one epoch ---
--- 0.2906382083892822 seconds for one epoch ---
--- 0.8659358024597168 seconds for one epoch ---
--- 0.2971065044403076 seconds for one epoch ---
--- 0.8648695945739746 seconds for one epoch ---
--- 0.29032135009765625 seconds for one epoch ---
--- 0.8456549644470215 seconds for one epoch ---
--- 0.30280280113220215 seconds for one epoch ---
--- 0.8385598659515381 seconds for one epoch ---
--- 0.2969698905944824 seconds for one epoch ---
--- 0.8551383018493652 seconds for one epoch ---
--- 0.3095102310180664 seconds for one epoch ---
--- 0.8563082218170166 seconds for one epoch ---
--- 0.3163943290710449 seconds for one epoch ---
--- 0.9074592590332031 seconds for one epoch ---
--- 0.3147406578063965 seconds for one epoch ---
--- 0.8777735233306885 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99625415]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.672765]
 [-0.      ]]
--- 0.2966580390930176 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2788.501708984375, (1342.0199, 0.85192096, 1445.3258, 0.30386597)
   validation loss 1106.697998046875, (780.7541, 0.2433446, 325.39676, 0.30386597)
decoder loss ratio: 30247.768870, decoder SINDy loss  ratio: 0.702415
--- 0.26831984519958496 seconds for one epoch ---
--- 0.31447434425354004 seconds for one epoch ---
--- 0.8530056476593018 seconds for one epoch ---
--- 0.31273579597473145 seconds for one epoch ---
--- 0.8639392852783203 seconds for one epoch ---
--- 0.33298587799072266 seconds for one epoch ---
--- 0.8777961730957031 seconds for one epoch ---
--- 0.31409788131713867 seconds for one epoch ---
--- 0.8661391735076904 seconds for one epoch ---
--- 0.3432490825653076 seconds for one epoch ---
--- 0.8826284408569336 seconds for one epoch ---
--- 0.3243401050567627 seconds for one epoch ---
--- 0.8907029628753662 seconds for one epoch ---
--- 0.32436347007751465 seconds for one epoch ---
--- 0.8971042633056641 seconds for one epoch ---
--- 0.30558323860168457 seconds for one epoch ---
--- 0.9112505912780762 seconds for one epoch ---
--- 0.48174262046813965 seconds for one epoch ---
--- 0.8521270751953125 seconds for one epoch ---
--- 0.2981266975402832 seconds for one epoch ---
--- 0.8659226894378662 seconds for one epoch ---
--- 0.2899315357208252 seconds for one epoch ---
--- 0.8806037902832031 seconds for one epoch ---
--- 0.29160165786743164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99756587]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-6.983137]
 [-0.      ]]
--- 0.2753262519836426 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4878.6396484375, (2494.6287, 0.9903289, 2382.7136, 0.30699143)
   validation loss 867.4519653320312, (567.49805, 0.24675225, 299.40015, 0.30699143)
decoder loss ratio: 21985.859556, decoder SINDy loss  ratio: 0.646297
--- 0.31771063804626465 seconds for one epoch ---
--- 0.894052267074585 seconds for one epoch ---
--- 0.32197093963623047 seconds for one epoch ---
--- 0.8666589260101318 seconds for one epoch ---
--- 0.288541316986084 seconds for one epoch ---
--- 0.863955020904541 seconds for one epoch ---
--- 0.29564380645751953 seconds for one epoch ---
--- 0.8763086795806885 seconds for one epoch ---
--- 0.30077123641967773 seconds for one epoch ---
--- 0.874875545501709 seconds for one epoch ---
--- 0.2975640296936035 seconds for one epoch ---
--- 0.8885467052459717 seconds for one epoch ---
--- 0.2774851322174072 seconds for one epoch ---
--- 0.8738689422607422 seconds for one epoch ---
--- 0.3029153347015381 seconds for one epoch ---
--- 0.8857793807983398 seconds for one epoch ---
--- 0.2916600704193115 seconds for one epoch ---
--- 0.8731241226196289 seconds for one epoch ---
--- 0.2987496852874756 seconds for one epoch ---
--- 0.8759510517120361 seconds for one epoch ---
--- 0.3021109104156494 seconds for one epoch ---
--- 0.8899626731872559 seconds for one epoch ---
--- 0.2952115535736084 seconds for one epoch ---
--- 0.8807010650634766 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9983281]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.2555246]
 [-0.       ]]
--- 0.296306848526001 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2487.968994140625, (1494.684, 0.31290078, 992.6624, 0.30982634)
   validation loss 1009.7425537109375, (697.47125, 0.26075587, 311.7007, 0.30982634)
decoder loss ratio: 27021.247183, decoder SINDy loss  ratio: 0.672850
--- 0.2515242099761963 seconds for one epoch ---
--- 0.29686570167541504 seconds for one epoch ---
--- 0.8759660720825195 seconds for one epoch ---
--- 0.30170440673828125 seconds for one epoch ---
--- 0.8786652088165283 seconds for one epoch ---
--- 0.29392385482788086 seconds for one epoch ---
--- 0.8936033248901367 seconds for one epoch ---
--- 0.3021390438079834 seconds for one epoch ---
--- 0.8867623805999756 seconds for one epoch ---
--- 0.3095073699951172 seconds for one epoch ---
--- 0.908907413482666 seconds for one epoch ---
--- 0.3157997131347656 seconds for one epoch ---
--- 0.8932106494903564 seconds for one epoch ---
--- 0.3214244842529297 seconds for one epoch ---
--- 0.8857002258300781 seconds for one epoch ---
--- 0.3287985324859619 seconds for one epoch ---
--- 0.8946840763092041 seconds for one epoch ---
--- 0.3073270320892334 seconds for one epoch ---
--- 0.8945329189300537 seconds for one epoch ---
--- 0.3083789348602295 seconds for one epoch ---
--- 0.8774783611297607 seconds for one epoch ---
--- 0.3009476661682129 seconds for one epoch ---
--- 0.8883781433105469 seconds for one epoch ---
--- 0.29536962509155273 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988656]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-7.538801]
 [-0.      ]]
--- 0.26847052574157715 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4100.93212890625, (1960.2601, 0.55460614, 2139.8047, 0.3128436)
   validation loss 782.6019287109375, (488.0052, 0.3023212, 293.98157, 0.3128436)
decoder loss ratio: 18906.168197, decoder SINDy loss  ratio: 0.634601
--- 0.3101658821105957 seconds for one epoch ---
--- 0.8796613216400146 seconds for one epoch ---
--- 0.30626535415649414 seconds for one epoch ---
--- 0.9017374515533447 seconds for one epoch ---
--- 0.3223762512207031 seconds for one epoch ---
--- 0.895618200302124 seconds for one epoch ---
--- 0.3326432704925537 seconds for one epoch ---
--- 0.8918073177337646 seconds for one epoch ---
--- 0.3258836269378662 seconds for one epoch ---
--- 0.8982062339782715 seconds for one epoch ---
--- 0.3346710205078125 seconds for one epoch ---
--- 0.9043424129486084 seconds for one epoch ---
--- 0.3294336795806885 seconds for one epoch ---
--- 0.9346516132354736 seconds for one epoch ---
--- 0.338939905166626 seconds for one epoch ---
--- 0.9097075462341309 seconds for one epoch ---
--- 0.3078274726867676 seconds for one epoch ---
--- 0.9108471870422363 seconds for one epoch ---
--- 0.30562329292297363 seconds for one epoch ---
--- 0.9033527374267578 seconds for one epoch ---
--- 0.2948317527770996 seconds for one epoch ---
--- 0.9276523590087891 seconds for one epoch ---
--- 0.31179118156433105 seconds for one epoch ---
--- 0.9137775897979736 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99921536]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.8106675]
 [-0.       ]]
--- 0.31380438804626465 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3574.604248046875, (1540.1311, 1.1631984, 2032.9944, 0.31579435)
   validation loss 1291.4825439453125, (948.46466, 0.2254456, 342.4766, 0.31579435)
decoder loss ratio: 36745.167560, decoder SINDy loss  ratio: 0.739284
--- 0.2537264823913574 seconds for one epoch ---
--- 0.3141655921936035 seconds for one epoch ---
--- 0.9291539192199707 seconds for one epoch ---
--- 0.33027052879333496 seconds for one epoch ---
--- 0.9173383712768555 seconds for one epoch ---
--- 0.3303670883178711 seconds for one epoch ---
--- 0.9166676998138428 seconds for one epoch ---
--- 0.32706427574157715 seconds for one epoch ---
--- 0.929326057434082 seconds for one epoch ---
--- 0.3189539909362793 seconds for one epoch ---
--- 0.9583356380462646 seconds for one epoch ---
--- 0.30535006523132324 seconds for one epoch ---
--- 0.9212319850921631 seconds for one epoch ---
--- 0.30167245864868164 seconds for one epoch ---
--- 0.9344122409820557 seconds for one epoch ---
--- 0.30974793434143066 seconds for one epoch ---
--- 0.935722827911377 seconds for one epoch ---
--- 0.2994372844696045 seconds for one epoch ---
--- 0.9496049880981445 seconds for one epoch ---
--- 0.299227237701416 seconds for one epoch ---
--- 0.956836462020874 seconds for one epoch ---
--- 0.30432963371276855 seconds for one epoch ---
--- 0.9465336799621582 seconds for one epoch ---
--- 0.3266589641571045 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99944246]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.064064]
 [-0.      ]]
--- 0.26929807662963867 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2355.815673828125, (1010.63324, 1.4447888, 1343.4192, 0.318583)
   validation loss 1342.8779296875, (995.53394, 0.29629952, 346.72906, 0.318583)
decoder loss ratio: 38568.712986, decoder SINDy loss  ratio: 0.748463
--- 0.29235267639160156 seconds for one epoch ---
--- 0.9334876537322998 seconds for one epoch ---
--- 0.302034854888916 seconds for one epoch ---
--- 0.8935019969940186 seconds for one epoch ---
--- 0.29805517196655273 seconds for one epoch ---
--- 0.9104053974151611 seconds for one epoch ---
--- 0.30304622650146484 seconds for one epoch ---
--- 0.9246768951416016 seconds for one epoch ---
--- 0.29409146308898926 seconds for one epoch ---
--- 0.9620335102081299 seconds for one epoch ---
--- 0.30239415168762207 seconds for one epoch ---
--- 0.9353599548339844 seconds for one epoch ---
--- 0.29990124702453613 seconds for one epoch ---
--- 0.9045190811157227 seconds for one epoch ---
--- 0.3010990619659424 seconds for one epoch ---
--- 0.929879903793335 seconds for one epoch ---
--- 0.2990543842315674 seconds for one epoch ---
--- 0.9368631839752197 seconds for one epoch ---
--- 0.29845333099365234 seconds for one epoch ---
--- 0.9269328117370605 seconds for one epoch ---
--- 0.3349730968475342 seconds for one epoch ---
--- 0.9283719062805176 seconds for one epoch ---
--- 0.31618213653564453 seconds for one epoch ---
--- 0.9310381412506104 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99960315]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.318739]
 [-0.      ]]
--- 0.30307579040527344 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4366.7548828125, (2609.0525, 1.462923, 1755.9183, 0.32137865)
   validation loss 1110.9013671875, (756.58716, 0.2698207, 353.72293, 0.32137865)
decoder loss ratio: 29311.500002, decoder SINDy loss  ratio: 0.763561
--- 0.2889392375946045 seconds for one epoch ---
--- 0.2933223247528076 seconds for one epoch ---
--- 0.9377479553222656 seconds for one epoch ---
--- 0.2918891906738281 seconds for one epoch ---
--- 0.9512557983398438 seconds for one epoch ---
--- 0.28076982498168945 seconds for one epoch ---
--- 0.9286799430847168 seconds for one epoch ---
--- 0.30117034912109375 seconds for one epoch ---
--- 0.9213285446166992 seconds for one epoch ---
--- 0.3036670684814453 seconds for one epoch ---
--- 0.9381134510040283 seconds for one epoch ---
--- 0.2956862449645996 seconds for one epoch ---
--- 0.9243159294128418 seconds for one epoch ---
--- 0.30730605125427246 seconds for one epoch ---
--- 0.9154422283172607 seconds for one epoch ---
--- 0.292797327041626 seconds for one epoch ---
--- 0.9296793937683105 seconds for one epoch ---
--- 0.3203880786895752 seconds for one epoch ---
--- 0.9387600421905518 seconds for one epoch ---
--- 0.3285253047943115 seconds for one epoch ---
--- 0.9334750175476074 seconds for one epoch ---
--- 0.3320467472076416 seconds for one epoch ---
--- 0.9642746448516846 seconds for one epoch ---
--- 0.33136773109436035 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997051]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.542812]
 [-0.      ]]
--- 0.25319361686706543 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4005.142578125, (1101.2783, 1.247681, 2902.2927, 0.32383254)
   validation loss 876.2080078125, (596.8323, 0.39272276, 278.6592, 0.32383254)
decoder loss ratio: 23122.318495, decoder SINDy loss  ratio: 0.601525
--- 0.2931234836578369 seconds for one epoch ---
--- 0.9152355194091797 seconds for one epoch ---
--- 0.2949488162994385 seconds for one epoch ---
--- 0.9577414989471436 seconds for one epoch ---
--- 0.3100104331970215 seconds for one epoch ---
--- 0.9594395160675049 seconds for one epoch ---
--- 0.29886817932128906 seconds for one epoch ---
--- 0.9530339241027832 seconds for one epoch ---
--- 0.2925987243652344 seconds for one epoch ---
--- 0.9485857486724854 seconds for one epoch ---
--- 0.30322933197021484 seconds for one epoch ---
--- 0.9538049697875977 seconds for one epoch ---
--- 0.302584171295166 seconds for one epoch ---
--- 0.9002223014831543 seconds for one epoch ---
--- 0.2927837371826172 seconds for one epoch ---
--- 0.9645764827728271 seconds for one epoch ---
--- 0.3016510009765625 seconds for one epoch ---
--- 0.9818832874298096 seconds for one epoch ---
--- 0.291015625 seconds for one epoch ---
--- 0.9485206604003906 seconds for one epoch ---
--- 0.2986867427825928 seconds for one epoch ---
--- 0.9638950824737549 seconds for one epoch ---
--- 0.2912318706512451 seconds for one epoch ---
--- 0.951207160949707 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997803]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.766737]
 [-0.      ]]
--- 0.30146217346191406 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3686.67822265625, (1547.7893, 1.2554055, 2137.3074, 0.32613975)
   validation loss 1503.517578125, (1192.8221, 0.3417496, 310.02753, 0.32613975)
decoder loss ratio: 46212.000672, decoder SINDy loss  ratio: 0.669238
--- 0.2665126323699951 seconds for one epoch ---
--- 0.33222317695617676 seconds for one epoch ---
--- 0.9838080406188965 seconds for one epoch ---
--- 0.2998366355895996 seconds for one epoch ---
--- 0.9589252471923828 seconds for one epoch ---
--- 0.3018484115600586 seconds for one epoch ---
--- 0.9595677852630615 seconds for one epoch ---
--- 0.29677534103393555 seconds for one epoch ---
--- 0.944939374923706 seconds for one epoch ---
--- 0.2988419532775879 seconds for one epoch ---
--- 0.9195587635040283 seconds for one epoch ---
--- 0.2949836254119873 seconds for one epoch ---
--- 0.9509897232055664 seconds for one epoch ---
--- 0.29543519020080566 seconds for one epoch ---
--- 0.9797894954681396 seconds for one epoch ---
--- 0.30768370628356934 seconds for one epoch ---
--- 0.9592537879943848 seconds for one epoch ---
--- 0.30083370208740234 seconds for one epoch ---
--- 0.9854695796966553 seconds for one epoch ---
--- 0.29547810554504395 seconds for one epoch ---
--- 0.9767637252807617 seconds for one epoch ---
--- 0.29960083961486816 seconds for one epoch ---
--- 0.946014404296875 seconds for one epoch ---
--- 0.28951072692871094 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998387]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.005819]
 [-0.      ]]
--- 0.2712278366088867 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3318.565185546875, (1414.3507, 0.94600713, 1902.9398, 0.3285366)
   validation loss 1171.166748046875, (866.3993, 0.3903324, 304.04865, 0.3285366)
decoder loss ratio: 33565.812707, decoder SINDy loss  ratio: 0.656332
--- 0.30236315727233887 seconds for one epoch ---
--- 0.952756404876709 seconds for one epoch ---
--- 0.30121469497680664 seconds for one epoch ---
--- 0.9485082626342773 seconds for one epoch ---
--- 0.2969241142272949 seconds for one epoch ---
--- 0.965888500213623 seconds for one epoch ---
--- 0.29844164848327637 seconds for one epoch ---
--- 0.967242956161499 seconds for one epoch ---
--- 0.300203800201416 seconds for one epoch ---
--- 0.9614989757537842 seconds for one epoch ---
--- 0.3001711368560791 seconds for one epoch ---
--- 0.9844586849212646 seconds for one epoch ---
--- 0.30076003074645996 seconds for one epoch ---
--- 0.9844777584075928 seconds for one epoch ---
--- 0.296842098236084 seconds for one epoch ---
--- 0.9636991024017334 seconds for one epoch ---
--- 0.2941875457763672 seconds for one epoch ---
--- 0.9702787399291992 seconds for one epoch ---
--- 0.30535292625427246 seconds for one epoch ---
--- 0.981755256652832 seconds for one epoch ---
--- 0.302814245223999 seconds for one epoch ---
--- 1.006443977355957 seconds for one epoch ---
--- 0.305696964263916 seconds for one epoch ---
--- 0.989861011505127 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998817]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.243139]
 [-0.      ]]
--- 0.2942469120025635 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2238.08544921875, (825.4662, 0.54369396, 1411.7451, 0.33045658)
   validation loss 837.3579711914062, (555.2938, 0.3139833, 281.41974, 0.33045658)
decoder loss ratio: 21513.046745, decoder SINDy loss  ratio: 0.607484
THRESHOLDING: 1 active coefficients
--- 0.25484228134155273 seconds for one epoch ---
--- 0.3238708972930908 seconds for one epoch ---
--- 0.9963064193725586 seconds for one epoch ---
--- 0.32007551193237305 seconds for one epoch ---
--- 1.0143842697143555 seconds for one epoch ---
--- 0.33328795433044434 seconds for one epoch ---
--- 0.9897572994232178 seconds for one epoch ---
--- 0.33835506439208984 seconds for one epoch ---
--- 0.9892983436584473 seconds for one epoch ---
--- 0.32845306396484375 seconds for one epoch ---
--- 0.9797627925872803 seconds for one epoch ---
--- 0.327312707901001 seconds for one epoch ---
--- 1.0083885192871094 seconds for one epoch ---
--- 0.3080484867095947 seconds for one epoch ---
--- 1.0012860298156738 seconds for one epoch ---
--- 0.29595088958740234 seconds for one epoch ---
--- 1.0055668354034424 seconds for one epoch ---
--- 0.3001973628997803 seconds for one epoch ---
--- 0.9954779148101807 seconds for one epoch ---
--- 0.305863618850708 seconds for one epoch ---
--- 0.9816458225250244 seconds for one epoch ---
--- 0.2950472831726074 seconds for one epoch ---
--- 1.0133416652679443 seconds for one epoch ---
--- 0.29207420349121094 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999083]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.4456215]
 [-0.       ]]
--- 0.26406240463256836 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2390.004150390625, (1089.5844, 2.015661, 1298.1091, 0.29515067)
   validation loss 1178.699951171875, (877.0616, 0.33384207, 301.00934, 0.29515067)
decoder loss ratio: 33978.888428, decoder SINDy loss  ratio: 0.649771
--- 0.2950441837310791 seconds for one epoch ---
--- 0.9765915870666504 seconds for one epoch ---
--- 0.2979259490966797 seconds for one epoch ---
--- 0.9685227870941162 seconds for one epoch ---
--- 0.29746508598327637 seconds for one epoch ---
--- 0.9964044094085693 seconds for one epoch ---
--- 0.29534268379211426 seconds for one epoch ---
--- 0.9763109683990479 seconds for one epoch ---
--- 0.29305076599121094 seconds for one epoch ---
--- 0.9853508472442627 seconds for one epoch ---
--- 0.297792911529541 seconds for one epoch ---
--- 1.0111472606658936 seconds for one epoch ---
--- 0.29592275619506836 seconds for one epoch ---
--- 0.9751100540161133 seconds for one epoch ---
--- 0.2996833324432373 seconds for one epoch ---
--- 0.9578454494476318 seconds for one epoch ---
--- 0.3010213375091553 seconds for one epoch ---
--- 1.001417875289917 seconds for one epoch ---
--- 0.28760600090026855 seconds for one epoch ---
--- 0.9870233535766602 seconds for one epoch ---
--- 0.29361414909362793 seconds for one epoch ---
--- 1.0356712341308594 seconds for one epoch ---
--- 0.3135802745819092 seconds for one epoch ---
--- 1.029017686843872 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99992895]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.637277]
 [-0.      ]]
--- 0.29964280128479004 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3212.729248046875, (1476.1019, 2.8913984, 1733.4384, 0.29768726)
   validation loss 1336.336181640625, (1038.132, 0.3194028, 297.58707, 0.29768726)
decoder loss ratio: 40219.034330, decoder SINDy loss  ratio: 0.642384
--- 0.269153356552124 seconds for one epoch ---
--- 0.30681705474853516 seconds for one epoch ---
--- 0.9680566787719727 seconds for one epoch ---
--- 0.2929806709289551 seconds for one epoch ---
--- 0.9961717128753662 seconds for one epoch ---
--- 0.3111448287963867 seconds for one epoch ---
--- 0.9767196178436279 seconds for one epoch ---
--- 0.2986013889312744 seconds for one epoch ---
--- 0.9897658824920654 seconds for one epoch ---
--- 0.30598902702331543 seconds for one epoch ---
--- 1.0026445388793945 seconds for one epoch ---
--- 0.2956862449645996 seconds for one epoch ---
--- 0.9944820404052734 seconds for one epoch ---
--- 0.3076462745666504 seconds for one epoch ---
--- 0.9994378089904785 seconds for one epoch ---
--- 0.3121614456176758 seconds for one epoch ---
--- 0.9975376129150391 seconds for one epoch ---
--- 0.29192304611206055 seconds for one epoch ---
--- 1.0087604522705078 seconds for one epoch ---
--- 0.3015763759613037 seconds for one epoch ---
--- 1.0003149509429932 seconds for one epoch ---
--- 0.2951626777648926 seconds for one epoch ---
--- 1.0120651721954346 seconds for one epoch ---
--- 0.2953624725341797 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999429]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.836512]
 [-0.      ]]
--- 0.25708436965942383 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2835.4091796875, (1377.4275, 1.7834795, 1455.8977, 0.3006131)
   validation loss 969.176025390625, (649.5035, 0.36120012, 319.01074, 0.3006131)
decoder loss ratio: 25162.892364, decoder SINDy loss  ratio: 0.688630
--- 0.31261730194091797 seconds for one epoch ---
--- 1.0147931575775146 seconds for one epoch ---
--- 0.301912784576416 seconds for one epoch ---
--- 1.019775152206421 seconds for one epoch ---
--- 0.293931245803833 seconds for one epoch ---
--- 1.0183956623077393 seconds for one epoch ---
--- 0.28707242012023926 seconds for one epoch ---
--- 1.020240068435669 seconds for one epoch ---
--- 0.29552292823791504 seconds for one epoch ---
--- 0.9845790863037109 seconds for one epoch ---
--- 0.3026463985443115 seconds for one epoch ---
--- 1.035118579864502 seconds for one epoch ---
--- 0.29502201080322266 seconds for one epoch ---
--- 1.0170307159423828 seconds for one epoch ---
--- 0.29648280143737793 seconds for one epoch ---
--- 1.0342133045196533 seconds for one epoch ---
--- 0.2984921932220459 seconds for one epoch ---
--- 1.0125088691711426 seconds for one epoch ---
--- 0.30556368827819824 seconds for one epoch ---
--- 1.0348684787750244 seconds for one epoch ---
--- 0.2947251796722412 seconds for one epoch ---
--- 0.9727013111114502 seconds for one epoch ---
--- 0.29386162757873535 seconds for one epoch ---
--- 1.025815486907959 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995404]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.027339]
 [ -0.      ]]
--- 0.3007638454437256 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4742.00341796875, (2481.4114, 1.4917847, 2258.797, 0.30333418)
   validation loss 1712.778076171875, (1357.5741, 0.22486797, 354.67578, 0.30333418)
decoder loss ratio: 52594.777358, decoder SINDy loss  ratio: 0.765618
--- 0.27573108673095703 seconds for one epoch ---
--- 0.2952151298522949 seconds for one epoch ---
--- 1.03593111038208 seconds for one epoch ---
--- 0.3232407569885254 seconds for one epoch ---
--- 1.0120878219604492 seconds for one epoch ---
--- 0.291886568069458 seconds for one epoch ---
--- 1.0133697986602783 seconds for one epoch ---
--- 0.3092668056488037 seconds for one epoch ---
--- 1.0243184566497803 seconds for one epoch ---
--- 0.29288482666015625 seconds for one epoch ---
--- 1.0410377979278564 seconds for one epoch ---
--- 0.3027205467224121 seconds for one epoch ---
--- 1.0215225219726562 seconds for one epoch ---
--- 0.28735923767089844 seconds for one epoch ---
--- 1.023148775100708 seconds for one epoch ---
--- 0.2988600730895996 seconds for one epoch ---
--- 1.0424582958221436 seconds for one epoch ---
--- 0.2993326187133789 seconds for one epoch ---
--- 0.9893114566802979 seconds for one epoch ---
--- 0.2951939105987549 seconds for one epoch ---
--- 1.011432409286499 seconds for one epoch ---
--- 0.29131126403808594 seconds for one epoch ---
--- 1.0309529304504395 seconds for one epoch ---
--- 0.28875279426574707 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999658]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.197845]
 [ -0.      ]]
--- 0.27387475967407227 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2385.2255859375, (1218.3699, 3.5940285, 1162.9558, 0.305882)
   validation loss 954.04736328125, (676.1644, 0.29730532, 277.27975, 0.305882)
decoder loss ratio: 26195.783841, decoder SINDy loss  ratio: 0.598547
--- 0.3271949291229248 seconds for one epoch ---
--- 1.050325632095337 seconds for one epoch ---
--- 0.3281211853027344 seconds for one epoch ---
--- 1.036724328994751 seconds for one epoch ---
--- 0.3275601863861084 seconds for one epoch ---
--- 1.0245771408081055 seconds for one epoch ---
--- 0.3175206184387207 seconds for one epoch ---
--- 1.0415422916412354 seconds for one epoch ---
--- 0.32307863235473633 seconds for one epoch ---
--- 1.043107271194458 seconds for one epoch ---
--- 0.32123446464538574 seconds for one epoch ---
--- 1.0466864109039307 seconds for one epoch ---
--- 0.30713701248168945 seconds for one epoch ---
--- 1.0517184734344482 seconds for one epoch ---
--- 0.2995467185974121 seconds for one epoch ---
--- 1.0613324642181396 seconds for one epoch ---
--- 0.29402804374694824 seconds for one epoch ---
--- 1.0689666271209717 seconds for one epoch ---
--- 0.2987668514251709 seconds for one epoch ---
--- 1.0568451881408691 seconds for one epoch ---
--- 0.30005311965942383 seconds for one epoch ---
--- 1.045724868774414 seconds for one epoch ---
--- 0.30385875701904297 seconds for one epoch ---
--- 1.0703446865081787 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999689]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-10.39848]
 [ -0.     ]]
--- 0.31085753440856934 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5352.17236328125, (2145.1494, 4.2629504, 3202.4507, 0.30893344)
   validation loss 1202.308837890625, (920.7057, 0.36588597, 280.92828, 0.30893344)
decoder loss ratio: 35669.736787, decoder SINDy loss  ratio: 0.606423
--- 0.2678558826446533 seconds for one epoch ---
--- 0.32140636444091797 seconds for one epoch ---
--- 1.0399692058563232 seconds for one epoch ---
--- 0.30033111572265625 seconds for one epoch ---
--- 1.0560011863708496 seconds for one epoch ---
--- 0.304516077041626 seconds for one epoch ---
--- 1.0514893531799316 seconds for one epoch ---
--- 0.3018639087677002 seconds for one epoch ---
--- 1.0539381504058838 seconds for one epoch ---
--- 0.30719828605651855 seconds for one epoch ---
--- 1.068134069442749 seconds for one epoch ---
--- 0.29709959030151367 seconds for one epoch ---
--- 1.0973281860351562 seconds for one epoch ---
--- 0.29764652252197266 seconds for one epoch ---
--- 1.0797009468078613 seconds for one epoch ---
--- 0.300062894821167 seconds for one epoch ---
--- 1.0524487495422363 seconds for one epoch ---
--- 0.29618287086486816 seconds for one epoch ---
--- 1.0626904964447021 seconds for one epoch ---
--- 0.3021116256713867 seconds for one epoch ---
--- 1.0691993236541748 seconds for one epoch ---
--- 0.3013322353363037 seconds for one epoch ---
--- 1.0666406154632568 seconds for one epoch ---
--- 0.2957601547241211 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999793]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.565455]
 [ -0.      ]]
--- 0.2779121398925781 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6142.0556640625, (2247.1814, 1.8535464, 3892.709, 0.31141615)
   validation loss 784.998291015625, (504.5717, 0.31097767, 279.8042, 0.31141615)
decoder loss ratio: 19547.983083, decoder SINDy loss  ratio: 0.603997
--- 0.30411291122436523 seconds for one epoch ---
--- 1.0495498180389404 seconds for one epoch ---
--- 0.30414342880249023 seconds for one epoch ---
--- 1.0456984043121338 seconds for one epoch ---
--- 0.29871177673339844 seconds for one epoch ---
--- 1.0530164241790771 seconds for one epoch ---
--- 0.3025083541870117 seconds for one epoch ---
--- 1.021075963973999 seconds for one epoch ---
--- 0.301776647567749 seconds for one epoch ---
--- 1.049459457397461 seconds for one epoch ---
--- 0.29848647117614746 seconds for one epoch ---
--- 1.055410385131836 seconds for one epoch ---
--- 0.3025851249694824 seconds for one epoch ---
--- 1.0709807872772217 seconds for one epoch ---
--- 0.29933786392211914 seconds for one epoch ---
--- 1.0584959983825684 seconds for one epoch ---
--- 0.29068851470947266 seconds for one epoch ---
--- 1.0830445289611816 seconds for one epoch ---
--- 0.3092987537384033 seconds for one epoch ---
--- 1.057509422302246 seconds for one epoch ---
--- 0.3106410503387451 seconds for one epoch ---
--- 1.0477268695831299 seconds for one epoch ---
--- 0.31420326232910156 seconds for one epoch ---
--- 1.0746324062347412 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999792]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.730027]
 [ -0.      ]]
--- 0.30925822257995605 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2451.00634765625, (929.68604, 2.4426794, 1518.5636, 0.31396475)
   validation loss 1301.8377685546875, (940.1176, 0.296033, 361.11017, 0.31396475)
decoder loss ratio: 36421.788511, decoder SINDy loss  ratio: 0.779507
--- 0.2708747386932373 seconds for one epoch ---
--- 0.3244955539703369 seconds for one epoch ---
--- 1.0760812759399414 seconds for one epoch ---
--- 0.3088994026184082 seconds for one epoch ---
--- 1.106985092163086 seconds for one epoch ---
--- 0.30119752883911133 seconds for one epoch ---
--- 1.074821949005127 seconds for one epoch ---
--- 0.28689122200012207 seconds for one epoch ---
--- 1.1027162075042725 seconds for one epoch ---
--- 0.3016781806945801 seconds for one epoch ---
--- 1.1244301795959473 seconds for one epoch ---
--- 0.49439144134521484 seconds for one epoch ---
--- 1.0803825855255127 seconds for one epoch ---
--- 0.29819512367248535 seconds for one epoch ---
--- 1.091841220855713 seconds for one epoch ---
--- 0.29700422286987305 seconds for one epoch ---
--- 1.1048684120178223 seconds for one epoch ---
--- 0.3076930046081543 seconds for one epoch ---
--- 1.103684663772583 seconds for one epoch ---
--- 0.29763031005859375 seconds for one epoch ---
--- 1.0795321464538574 seconds for one epoch ---
--- 0.29919934272766113 seconds for one epoch ---
--- 1.0977466106414795 seconds for one epoch ---
--- 0.2897310256958008 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997985]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.878428]
 [ -0.      ]]
--- 0.2586548328399658 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1842.398681640625, (1064.3303, 1.6713865, 776.0807, 0.31631815)
   validation loss 1722.1988525390625, (1379.8453, 0.21222675, 341.825, 0.31631815)
decoder loss ratio: 53457.603869, decoder SINDy loss  ratio: 0.737877
--- 0.3003089427947998 seconds for one epoch ---
--- 1.0603952407836914 seconds for one epoch ---
--- 0.30466437339782715 seconds for one epoch ---
--- 1.1027822494506836 seconds for one epoch ---
--- 0.30507493019104004 seconds for one epoch ---
--- 1.0782039165496826 seconds for one epoch ---
--- 0.2935209274291992 seconds for one epoch ---
--- 1.0684442520141602 seconds for one epoch ---
--- 0.29578638076782227 seconds for one epoch ---
--- 1.0836002826690674 seconds for one epoch ---
--- 0.3013029098510742 seconds for one epoch ---
--- 1.0759751796722412 seconds for one epoch ---
--- 0.29559803009033203 seconds for one epoch ---
--- 1.0868728160858154 seconds for one epoch ---
--- 0.3098893165588379 seconds for one epoch ---
--- 1.0971028804779053 seconds for one epoch ---
--- 0.2992382049560547 seconds for one epoch ---
--- 1.0888702869415283 seconds for one epoch ---
--- 0.29752516746520996 seconds for one epoch ---
--- 1.110083818435669 seconds for one epoch ---
--- 0.2990090847015381 seconds for one epoch ---
--- 1.0848767757415771 seconds for one epoch ---
--- 0.2889597415924072 seconds for one epoch ---
--- 1.1056554317474365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99998534]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.034268]
 [ -0.      ]]
--- 0.28913331031799316 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3968.148193359375, (1726.8944, 3.2353654, 2237.6997, 0.31872)
   validation loss 1427.0013427734375, (1113.8174, 0.29485258, 312.57047, 0.31872)
decoder loss ratio: 43151.219082, decoder SINDy loss  ratio: 0.674727
--- 0.25977635383605957 seconds for one epoch ---
--- 0.3039119243621826 seconds for one epoch ---
--- 1.0369148254394531 seconds for one epoch ---
--- 0.27866673469543457 seconds for one epoch ---
--- 1.0839040279388428 seconds for one epoch ---
--- 0.2926290035247803 seconds for one epoch ---
--- 1.0980224609375 seconds for one epoch ---
--- 0.3107109069824219 seconds for one epoch ---
--- 1.1115317344665527 seconds for one epoch ---
--- 0.3116445541381836 seconds for one epoch ---
--- 1.0918939113616943 seconds for one epoch ---
--- 0.29781508445739746 seconds for one epoch ---
--- 1.1244404315948486 seconds for one epoch ---
--- 0.3040482997894287 seconds for one epoch ---
--- 1.091325283050537 seconds for one epoch ---
--- 0.3008112907409668 seconds for one epoch ---
--- 1.105158805847168 seconds for one epoch ---
--- 0.2962632179260254 seconds for one epoch ---
--- 1.0940790176391602 seconds for one epoch ---
--- 0.294161319732666 seconds for one epoch ---
--- 1.078343391418457 seconds for one epoch ---
--- 0.29714345932006836 seconds for one epoch ---
--- 1.1399636268615723 seconds for one epoch ---
--- 0.310319185256958 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999928]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-11.19881]
 [ -0.     ]]
--- 0.26110029220581055 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3262.06103515625, (2111.7224, 3.4709127, 1146.5461, 0.3214459)
   validation loss 998.7938842773438, (723.17633, 0.38043588, 274.91565, 0.3214459)
decoder loss ratio: 28017.106535, decoder SINDy loss  ratio: 0.593444
--- 0.28752732276916504 seconds for one epoch ---
--- 1.095146656036377 seconds for one epoch ---
--- 0.3100557327270508 seconds for one epoch ---
--- 1.0765180587768555 seconds for one epoch ---
--- 0.29923176765441895 seconds for one epoch ---
--- 1.121877670288086 seconds for one epoch ---
--- 0.3057212829589844 seconds for one epoch ---
--- 1.103114366531372 seconds for one epoch ---
--- 0.32291316986083984 seconds for one epoch ---
--- 1.1244163513183594 seconds for one epoch ---
--- 0.30515217781066895 seconds for one epoch ---
--- 1.0818357467651367 seconds for one epoch ---
--- 0.29961252212524414 seconds for one epoch ---
--- 1.0940005779266357 seconds for one epoch ---
--- 0.2922804355621338 seconds for one epoch ---
--- 1.111602544784546 seconds for one epoch ---
--- 0.3043398857116699 seconds for one epoch ---
--- 1.0741908550262451 seconds for one epoch ---
--- 0.30240821838378906 seconds for one epoch ---
--- 1.0896382331848145 seconds for one epoch ---
--- 0.29271817207336426 seconds for one epoch ---
--- 1.1407504081726074 seconds for one epoch ---
--- 0.33927297592163086 seconds for one epoch ---
--- 1.1335976123809814 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999267]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.352771]
 [ -0.      ]]
--- 0.31377363204956055 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5412.791015625, (1968.5842, 2.2080736, 3441.6743, 0.3240107)
   validation loss 839.2440185546875, (553.9435, 0.33625135, 284.64026, 0.3240107)
decoder loss ratio: 21460.732159, decoder SINDy loss  ratio: 0.614436
--- 0.2863445281982422 seconds for one epoch ---
--- 0.2972846031188965 seconds for one epoch ---
--- 1.137465000152588 seconds for one epoch ---
--- 0.31145596504211426 seconds for one epoch ---
--- 1.1390650272369385 seconds for one epoch ---
--- 0.29544854164123535 seconds for one epoch ---
--- 1.1082768440246582 seconds for one epoch ---
--- 0.3057997226715088 seconds for one epoch ---
--- 1.1261677742004395 seconds for one epoch ---
--- 0.3047468662261963 seconds for one epoch ---
--- 1.1400315761566162 seconds for one epoch ---
--- 0.288820743560791 seconds for one epoch ---
--- 1.1177175045013428 seconds for one epoch ---
--- 0.3014347553253174 seconds for one epoch ---
--- 1.1447136402130127 seconds for one epoch ---
--- 0.31251955032348633 seconds for one epoch ---
--- 1.1002957820892334 seconds for one epoch ---
--- 0.2944011688232422 seconds for one epoch ---
--- 1.1445376873016357 seconds for one epoch ---
--- 0.3009331226348877 seconds for one epoch ---
--- 1.1423683166503906 seconds for one epoch ---
--- 0.28861117362976074 seconds for one epoch ---
--- 1.1496670246124268 seconds for one epoch ---
--- 0.30876994132995605 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999926]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.492824]
 [ -0.      ]]
--- 0.25617456436157227 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3142.797119140625, (1504.7502, 0.8059069, 1636.9148, 0.32627583)
   validation loss 899.2596435546875, (625.80585, 0.30288464, 272.82465, 0.32627583)
decoder loss ratio: 24244.804966, decoder SINDy loss  ratio: 0.588930
--- 0.2860562801361084 seconds for one epoch ---
--- 1.1380808353424072 seconds for one epoch ---
--- 0.2999129295349121 seconds for one epoch ---
--- 1.1414744853973389 seconds for one epoch ---
--- 0.29734110832214355 seconds for one epoch ---
--- 1.1532056331634521 seconds for one epoch ---
--- 0.2929413318634033 seconds for one epoch ---
--- 1.155085802078247 seconds for one epoch ---
--- 0.30170583724975586 seconds for one epoch ---
--- 1.1238481998443604 seconds for one epoch ---
--- 0.288116455078125 seconds for one epoch ---
--- 1.1562268733978271 seconds for one epoch ---
--- 0.29880523681640625 seconds for one epoch ---
--- 1.1196990013122559 seconds for one epoch ---
--- 0.2962164878845215 seconds for one epoch ---
--- 1.1485393047332764 seconds for one epoch ---
--- 0.3000462055206299 seconds for one epoch ---
--- 1.1262948513031006 seconds for one epoch ---
--- 0.2947123050689697 seconds for one epoch ---
--- 1.149825096130371 seconds for one epoch ---
--- 0.309887170791626 seconds for one epoch ---
--- 1.1365056037902832 seconds for one epoch ---
--- 0.33051085472106934 seconds for one epoch ---
--- 1.1537466049194336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999255]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.644008]
 [ -0.      ]]
--- 0.29688143730163574 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3318.814208984375, (1130.7368, 2.147118, 2185.6013, 0.32876754)
   validation loss 1063.81005859375, (818.42444, 0.3101444, 244.74678, 0.32876754)
decoder loss ratio: 31707.183594, decoder SINDy loss  ratio: 0.528320
--- 0.2640039920806885 seconds for one epoch ---
--- 0.2958536148071289 seconds for one epoch ---
--- 1.1967337131500244 seconds for one epoch ---
--- 0.29836440086364746 seconds for one epoch ---
--- 1.1409943103790283 seconds for one epoch ---
--- 0.29884862899780273 seconds for one epoch ---
--- 1.13153076171875 seconds for one epoch ---
--- 0.30107593536376953 seconds for one epoch ---
--- 1.1304023265838623 seconds for one epoch ---
--- 0.30130863189697266 seconds for one epoch ---
--- 1.1534972190856934 seconds for one epoch ---
--- 0.31079745292663574 seconds for one epoch ---
--- 1.1166398525238037 seconds for one epoch ---
--- 0.2745378017425537 seconds for one epoch ---
--- 1.1532411575317383 seconds for one epoch ---
--- 0.3058583736419678 seconds for one epoch ---
--- 1.193413496017456 seconds for one epoch ---
--- 0.2995262145996094 seconds for one epoch ---
--- 1.1349608898162842 seconds for one epoch ---
--- 0.297910213470459 seconds for one epoch ---
--- 1.1697070598602295 seconds for one epoch ---
--- 0.3097875118255615 seconds for one epoch ---
--- 1.1676771640777588 seconds for one epoch ---
--- 0.3010716438293457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999243]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.775889]
 [ -0.      ]]
--- 0.25089359283447266 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3713.32958984375, (1643.8112, 0.49828187, 2068.6892, 0.33104745)
   validation loss 1065.05908203125, (783.76086, 0.3174022, 280.6498, 0.33104745)
decoder loss ratio: 30364.256550, decoder SINDy loss  ratio: 0.605822
--- 0.3009788990020752 seconds for one epoch ---
--- 1.1391820907592773 seconds for one epoch ---
--- 0.30913209915161133 seconds for one epoch ---
--- 1.1550889015197754 seconds for one epoch ---
--- 0.29105710983276367 seconds for one epoch ---
--- 1.1183967590332031 seconds for one epoch ---
--- 0.2881438732147217 seconds for one epoch ---
--- 1.1581778526306152 seconds for one epoch ---
--- 0.3028564453125 seconds for one epoch ---
--- 1.1383459568023682 seconds for one epoch ---
--- 0.2834603786468506 seconds for one epoch ---
--- 1.1282804012298584 seconds for one epoch ---
--- 0.29611849784851074 seconds for one epoch ---
--- 1.1908371448516846 seconds for one epoch ---
--- 0.2993631362915039 seconds for one epoch ---
--- 1.161318302154541 seconds for one epoch ---
--- 0.2991185188293457 seconds for one epoch ---
--- 1.1525554656982422 seconds for one epoch ---
--- 0.2959439754486084 seconds for one epoch ---
--- 1.146878719329834 seconds for one epoch ---
--- 0.2936549186706543 seconds for one epoch ---
--- 1.1422455310821533 seconds for one epoch ---
--- 0.2925105094909668 seconds for one epoch ---
--- 1.1430425643920898 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999924]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.923162]
 [ -0.      ]]
--- 0.2932310104370117 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2642.828125, (1639.5101, 4.4748764, 998.50946, 0.3336327)
   validation loss 751.53857421875, (480.94458, 0.3844744, 269.8759, 0.3336327)
decoder loss ratio: 18632.627989, decoder SINDy loss  ratio: 0.582565
--- 0.25080323219299316 seconds for one epoch ---
--- 0.2991204261779785 seconds for one epoch ---
--- 1.1645269393920898 seconds for one epoch ---
--- 0.3029515743255615 seconds for one epoch ---
--- 1.1652414798736572 seconds for one epoch ---
--- 0.3025233745574951 seconds for one epoch ---
--- 1.170309066772461 seconds for one epoch ---
--- 0.3002798557281494 seconds for one epoch ---
--- 1.17921781539917 seconds for one epoch ---
--- 0.29590702056884766 seconds for one epoch ---
--- 1.1461153030395508 seconds for one epoch ---
--- 0.2984743118286133 seconds for one epoch ---
--- 1.1718053817749023 seconds for one epoch ---
--- 0.30704736709594727 seconds for one epoch ---
--- 1.1810719966888428 seconds for one epoch ---
--- 0.30300164222717285 seconds for one epoch ---
--- 1.1680312156677246 seconds for one epoch ---
--- 0.2962982654571533 seconds for one epoch ---
--- 1.1760077476501465 seconds for one epoch ---
--- 0.2991340160369873 seconds for one epoch ---
--- 1.1898243427276611 seconds for one epoch ---
--- 0.30411624908447266 seconds for one epoch ---
--- 1.191779613494873 seconds for one epoch ---
--- 0.3129565715789795 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999225]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.063085]
 [ -0.      ]]
--- 0.24868083000183105 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2040.0899658203125, (861.3709, 2.3187356, 1176.0642, 0.3360744)
   validation loss 864.4656982421875, (590.5878, 0.37226573, 273.1696, 0.3360744)
decoder loss ratio: 22880.397824, decoder SINDy loss  ratio: 0.589675
--- 0.29020237922668457 seconds for one epoch ---
--- 1.1502509117126465 seconds for one epoch ---
--- 0.29506587982177734 seconds for one epoch ---
--- 1.1561555862426758 seconds for one epoch ---
--- 0.3004577159881592 seconds for one epoch ---
--- 1.1725819110870361 seconds for one epoch ---
--- 0.30080175399780273 seconds for one epoch ---
--- 1.1448094844818115 seconds for one epoch ---
--- 0.2952399253845215 seconds for one epoch ---
--- 1.1496062278747559 seconds for one epoch ---
--- 0.29836392402648926 seconds for one epoch ---
--- 1.1632647514343262 seconds for one epoch ---
--- 0.2964768409729004 seconds for one epoch ---
--- 1.1667265892028809 seconds for one epoch ---
--- 0.27269625663757324 seconds for one epoch ---
--- 1.1749637126922607 seconds for one epoch ---
--- 0.29173874855041504 seconds for one epoch ---
--- 1.1826393604278564 seconds for one epoch ---
--- 0.3016791343688965 seconds for one epoch ---
--- 1.1652822494506836 seconds for one epoch ---
--- 0.308809757232666 seconds for one epoch ---
--- 1.1872365474700928 seconds for one epoch ---
--- 0.29808902740478516 seconds for one epoch ---
--- 1.1811578273773193 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999213]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.198164]
 [ -0.      ]]
--- 0.29451966285705566 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2514.93994140625, (1003.7419, 1.7481583, 1509.1116, 0.33841643)
   validation loss 923.6381225585938, (634.29504, 0.32748917, 288.67712, 0.33841643)
decoder loss ratio: 24573.691187, decoder SINDy loss  ratio: 0.623150
--- 0.26201963424682617 seconds for one epoch ---
--- 0.2982361316680908 seconds for one epoch ---
--- 1.1929924488067627 seconds for one epoch ---
--- 0.29852294921875 seconds for one epoch ---
--- 1.2091832160949707 seconds for one epoch ---
--- 0.30881714820861816 seconds for one epoch ---
--- 1.139345407485962 seconds for one epoch ---
--- 0.2986564636230469 seconds for one epoch ---
--- 1.1799325942993164 seconds for one epoch ---
--- 0.2955465316772461 seconds for one epoch ---
--- 1.1852538585662842 seconds for one epoch ---
--- 0.29341697692871094 seconds for one epoch ---
--- 1.1991236209869385 seconds for one epoch ---
--- 0.28351354598999023 seconds for one epoch ---
--- 1.203129768371582 seconds for one epoch ---
--- 0.2984955310821533 seconds for one epoch ---
--- 1.196826696395874 seconds for one epoch ---
--- 0.30271005630493164 seconds for one epoch ---
--- 1.203200340270996 seconds for one epoch ---
--- 0.3017761707305908 seconds for one epoch ---
--- 1.2087724208831787 seconds for one epoch ---
--- 0.29482555389404297 seconds for one epoch ---
--- 1.2200095653533936 seconds for one epoch ---
--- 0.30080723762512207 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999921]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.323357]
 [ -0.      ]]
--- 0.26471590995788574 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2889.218505859375, (1142.5212, 2.2803671, 1744.0763, 0.34057418)
   validation loss 888.7142944335938, (627.4654, 0.33167028, 260.57666, 0.34057418)
decoder loss ratio: 24309.098655, decoder SINDy loss  ratio: 0.562491
--- 0.31391429901123047 seconds for one epoch ---
--- 1.1929433345794678 seconds for one epoch ---
--- 0.3038036823272705 seconds for one epoch ---
--- 1.1786444187164307 seconds for one epoch ---
--- 0.2980954647064209 seconds for one epoch ---
--- 1.1537463665008545 seconds for one epoch ---
--- 0.3025398254394531 seconds for one epoch ---
--- 1.1870720386505127 seconds for one epoch ---
--- 0.2941577434539795 seconds for one epoch ---
--- 1.200279951095581 seconds for one epoch ---
--- 0.2969684600830078 seconds for one epoch ---
--- 1.175741195678711 seconds for one epoch ---
--- 0.30034708976745605 seconds for one epoch ---
--- 1.1887197494506836 seconds for one epoch ---
--- 0.2978360652923584 seconds for one epoch ---
--- 1.2103595733642578 seconds for one epoch ---
--- 0.29444122314453125 seconds for one epoch ---
--- 1.1933910846710205 seconds for one epoch ---
--- 0.3003087043762207 seconds for one epoch ---
--- 1.2009038925170898 seconds for one epoch ---
--- 0.29891371726989746 seconds for one epoch ---
--- 1.1910710334777832 seconds for one epoch ---
--- 0.2995898723602295 seconds for one epoch ---
--- 1.2098288536071777 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999919]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.441046]
 [ -0.      ]]
--- 0.28714752197265625 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3161.5068359375, (1074.6365, 0.4579321, 2086.0696, 0.34276772)
   validation loss 1001.3556518554688, (731.9031, 0.31111887, 268.7987, 0.34276772)
decoder loss ratio: 28355.195811, decoder SINDy loss  ratio: 0.580240
THRESHOLDING: 1 active coefficients
--- 1.2096500396728516 seconds for one epoch ---
--- 0.3001708984375 seconds for one epoch ---
--- 1.2305150032043457 seconds for one epoch ---
--- 0.2994868755340576 seconds for one epoch ---
--- 1.2354671955108643 seconds for one epoch ---
--- 0.2962219715118408 seconds for one epoch ---
--- 1.209183931350708 seconds for one epoch ---
--- 0.279512882232666 seconds for one epoch ---
--- 1.2198102474212646 seconds for one epoch ---
--- 0.29499125480651855 seconds for one epoch ---
--- 1.2233455181121826 seconds for one epoch ---
--- 0.2861289978027344 seconds for one epoch ---
--- 1.2066688537597656 seconds for one epoch ---
--- 0.29813194274902344 seconds for one epoch ---
--- 1.2082428932189941 seconds for one epoch ---
--- 0.2986135482788086 seconds for one epoch ---
--- 1.2227964401245117 seconds for one epoch ---
--- 0.29421067237854004 seconds for one epoch ---
--- 1.2204015254974365 seconds for one epoch ---
--- 0.2842726707458496 seconds for one epoch ---
--- 1.220573902130127 seconds for one epoch ---
--- 0.3003711700439453 seconds for one epoch ---
--- 1.2225425243377686 seconds for one epoch ---
--- 0.3001229763031006 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999918]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.572395]
 [ -0.      ]]
--- 0.2634413242340088 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4074.609375, (1534.7803, 0.6172768, 2538.8665, 0.34526038)
   validation loss 987.065185546875, (722.7538, 0.29269913, 263.6734, 0.34526038)
decoder loss ratio: 28000.736355, decoder SINDy loss  ratio: 0.569176
--- 0.29935264587402344 seconds for one epoch ---
--- 1.209245204925537 seconds for one epoch ---
--- 0.30396366119384766 seconds for one epoch ---
--- 1.214482307434082 seconds for one epoch ---
--- 0.29117536544799805 seconds for one epoch ---
--- 1.2196111679077148 seconds for one epoch ---
--- 0.3056168556213379 seconds for one epoch ---
--- 1.244333028793335 seconds for one epoch ---
--- 0.29305267333984375 seconds for one epoch ---
--- 1.1680498123168945 seconds for one epoch ---
--- 0.29369688034057617 seconds for one epoch ---
--- 1.2226417064666748 seconds for one epoch ---
--- 0.2912778854370117 seconds for one epoch ---
--- 1.2278754711151123 seconds for one epoch ---
--- 0.295795202255249 seconds for one epoch ---
--- 1.2379674911499023 seconds for one epoch ---
--- 0.30290818214416504 seconds for one epoch ---
--- 1.23856520652771 seconds for one epoch ---
--- 0.28727126121520996 seconds for one epoch ---
--- 1.2341384887695312 seconds for one epoch ---
--- 0.28725361824035645 seconds for one epoch ---
--- 1.234454870223999 seconds for one epoch ---
--- 0.3038291931152344 seconds for one epoch ---
--- 1.204179048538208 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999183]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-12.6891985]
 [ -0.       ]]
--- 0.30151963233947754 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3539.22265625, (1235.5895, 2.7987063, 2300.487, 0.34738746)
   validation loss 888.7491455078125, (593.8137, 0.37296474, 294.21503, 0.34738746)
decoder loss ratio: 23005.374446, decoder SINDy loss  ratio: 0.635105
--- 0.2683424949645996 seconds for one epoch ---
--- 0.2978675365447998 seconds for one epoch ---
--- 1.2355732917785645 seconds for one epoch ---
--- 0.3004417419433594 seconds for one epoch ---
--- 1.230182409286499 seconds for one epoch ---
--- 0.3067774772644043 seconds for one epoch ---
--- 1.209761142730713 seconds for one epoch ---
--- 0.2965855598449707 seconds for one epoch ---
--- 1.1858892440795898 seconds for one epoch ---
--- 0.29955172538757324 seconds for one epoch ---
--- 1.250464677810669 seconds for one epoch ---
--- 0.3110771179199219 seconds for one epoch ---
--- 1.24908447265625 seconds for one epoch ---
--- 0.305147647857666 seconds for one epoch ---
--- 1.239750862121582 seconds for one epoch ---
--- 0.30333924293518066 seconds for one epoch ---
--- 1.258399486541748 seconds for one epoch ---
--- 0.30774545669555664 seconds for one epoch ---
--- 1.249941110610962 seconds for one epoch ---
--- 0.30954909324645996 seconds for one epoch ---
--- 1.2799582481384277 seconds for one epoch ---
--- 0.3058311939239502 seconds for one epoch ---
--- 1.214148998260498 seconds for one epoch ---
--- 0.29924511909484863 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.799518]
 [ -0.      ]]
--- 0.2722928524017334 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5674.505859375, (1638.4933, 0.975372, 4034.6875, 0.34938183)
   validation loss 945.3961181640625, (630.6042, 0.3797145, 314.0629, 0.34938183)
decoder loss ratio: 24430.700982, decoder SINDy loss  ratio: 0.677949
--- 0.2953372001647949 seconds for one epoch ---
--- 1.25173020362854 seconds for one epoch ---
--- 0.303056001663208 seconds for one epoch ---
--- 1.2129604816436768 seconds for one epoch ---
--- 0.2983534336090088 seconds for one epoch ---
--- 1.2276747226715088 seconds for one epoch ---
--- 0.3007819652557373 seconds for one epoch ---
--- 1.2454423904418945 seconds for one epoch ---
--- 0.3011772632598877 seconds for one epoch ---
--- 1.2547552585601807 seconds for one epoch ---
--- 0.2960636615753174 seconds for one epoch ---
--- 1.2630751132965088 seconds for one epoch ---
--- 0.3040921688079834 seconds for one epoch ---
--- 1.2276225090026855 seconds for one epoch ---
--- 0.2911043167114258 seconds for one epoch ---
--- 1.2432260513305664 seconds for one epoch ---
--- 0.30584025382995605 seconds for one epoch ---
--- 1.2746787071228027 seconds for one epoch ---
--- 0.29170870780944824 seconds for one epoch ---
--- 1.2213983535766602 seconds for one epoch ---
--- 0.29592204093933105 seconds for one epoch ---
--- 1.257096767425537 seconds for one epoch ---
--- 0.3069319725036621 seconds for one epoch ---
--- 1.2419238090515137 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999166]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.921348]
 [ -0.      ]]
--- 0.2865426540374756 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4283.3330078125, (1994.7832, 0.81610924, 2287.3823, 0.35166603)
   validation loss 722.1993408203125, (439.6193, 0.29225373, 281.93607, 0.35166603)
decoder loss ratio: 17031.614632, decoder SINDy loss  ratio: 0.608599
--- 0.2623171806335449 seconds for one epoch ---
--- 0.29735732078552246 seconds for one epoch ---
--- 1.2606639862060547 seconds for one epoch ---
--- 0.30137205123901367 seconds for one epoch ---
--- 1.2569687366485596 seconds for one epoch ---
--- 0.3132479190826416 seconds for one epoch ---
--- 1.2604591846466064 seconds for one epoch ---
--- 0.29795193672180176 seconds for one epoch ---
--- 1.2859292030334473 seconds for one epoch ---
--- 0.3075218200683594 seconds for one epoch ---
--- 1.2689788341522217 seconds for one epoch ---
--- 0.31215763092041016 seconds for one epoch ---
--- 1.279388666152954 seconds for one epoch ---
--- 0.3266165256500244 seconds for one epoch ---
--- 1.2839996814727783 seconds for one epoch ---
--- 0.33582520484924316 seconds for one epoch ---
--- 1.258094310760498 seconds for one epoch ---
--- 0.3324615955352783 seconds for one epoch ---
--- 1.2773735523223877 seconds for one epoch ---
--- 0.3390793800354004 seconds for one epoch ---
--- 1.2899460792541504 seconds for one epoch ---
--- 0.3497331142425537 seconds for one epoch ---
--- 1.2748420238494873 seconds for one epoch ---
--- 0.34204697608947754 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999917]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.029627]
 [ -0.      ]]
--- 0.2600071430206299 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4149.31201171875, (1548.3425, 1.3951892, 2599.221, 0.35369354)
   validation loss 1036.6431884765625, (767.4381, 0.32757184, 268.5239, 0.35369354)
decoder loss ratio: 29731.884726, decoder SINDy loss  ratio: 0.579647
--- 0.2979419231414795 seconds for one epoch ---
--- 1.2675373554229736 seconds for one epoch ---
--- 0.3034639358520508 seconds for one epoch ---
--- 1.2648711204528809 seconds for one epoch ---
--- 0.30444979667663574 seconds for one epoch ---
--- 1.2748396396636963 seconds for one epoch ---
--- 0.3065834045410156 seconds for one epoch ---
--- 1.2680139541625977 seconds for one epoch ---
--- 0.3060901165008545 seconds for one epoch ---
--- 1.2756562232971191 seconds for one epoch ---
--- 0.30931830406188965 seconds for one epoch ---
--- 1.2878377437591553 seconds for one epoch ---
--- 0.30298805236816406 seconds for one epoch ---
--- 1.3046672344207764 seconds for one epoch ---
--- 0.3290224075317383 seconds for one epoch ---
--- 1.2867765426635742 seconds for one epoch ---
--- 0.32192540168762207 seconds for one epoch ---
--- 1.272676706314087 seconds for one epoch ---
--- 0.33788228034973145 seconds for one epoch ---
--- 1.2672369480133057 seconds for one epoch ---
--- 0.33652400970458984 seconds for one epoch ---
--- 1.2797634601593018 seconds for one epoch ---
--- 0.3274204730987549 seconds for one epoch ---
--- 1.2716619968414307 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999919]
 [0.       ]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-13.1525345]
 [ -0.       ]]
--- 0.30497169494628906 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2740.773681640625, (1549.6537, 4.0062337, 1186.7578, 0.35597703)
   validation loss 737.122802734375, (477.34332, 0.23555735, 259.18796, 0.35597703)
decoder loss ratio: 18493.109028, decoder SINDy loss  ratio: 0.559494
--- 0.283214807510376 seconds for one epoch ---
--- 0.30614447593688965 seconds for one epoch ---
--- 1.2937226295471191 seconds for one epoch ---
--- 0.30610203742980957 seconds for one epoch ---
--- 1.3039507865905762 seconds for one epoch ---
--- 0.2943122386932373 seconds for one epoch ---
--- 1.2860031127929688 seconds for one epoch ---
--- 0.2881302833557129 seconds for one epoch ---
--- 1.297182321548462 seconds for one epoch ---
--- 0.302748441696167 seconds for one epoch ---
--- 1.2998273372650146 seconds for one epoch ---
--- 0.30507349967956543 seconds for one epoch ---
--- 1.3288323879241943 seconds for one epoch ---
--- 0.30643272399902344 seconds for one epoch ---
--- 1.2974059581756592 seconds for one epoch ---
--- 0.3071784973144531 seconds for one epoch ---
--- 1.300175428390503 seconds for one epoch ---
--- 0.30152273178100586 seconds for one epoch ---
--- 1.2849624156951904 seconds for one epoch ---
--- 0.310258150100708 seconds for one epoch ---
--- 1.290733814239502 seconds for one epoch ---
--- 0.2978518009185791 seconds for one epoch ---
--- 1.2996494770050049 seconds for one epoch ---
--- 0.2961158752441406 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999213]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.256081]
 [ -0.      ]]
--- 0.2423861026763916 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3761.09765625, (1470.7511, 2.9098842, 2287.0786, 0.35795066)
   validation loss 874.3677368164062, (614.05695, 0.33672154, 259.61606, 0.35795066)
decoder loss ratio: 23789.632130, decoder SINDy loss  ratio: 0.560418
--- 0.3185720443725586 seconds for one epoch ---
--- 1.30027174949646 seconds for one epoch ---
--- 0.3013319969177246 seconds for one epoch ---
--- 1.291980504989624 seconds for one epoch ---
--- 0.3066573143005371 seconds for one epoch ---
--- 1.2916159629821777 seconds for one epoch ---
--- 0.3297574520111084 seconds for one epoch ---
--- 1.305199384689331 seconds for one epoch ---
--- 0.31792545318603516 seconds for one epoch ---
--- 1.3119392395019531 seconds for one epoch ---
--- 0.35776495933532715 seconds for one epoch ---
--- 1.297440528869629 seconds for one epoch ---
--- 0.3298628330230713 seconds for one epoch ---
--- 1.3088533878326416 seconds for one epoch ---
--- 0.3350706100463867 seconds for one epoch ---
--- 1.299809217453003 seconds for one epoch ---
--- 0.32680535316467285 seconds for one epoch ---
--- 1.3235509395599365 seconds for one epoch ---
--- 0.35137343406677246 seconds for one epoch ---
--- 1.3097267150878906 seconds for one epoch ---
--- 0.3427135944366455 seconds for one epoch ---
--- 1.3021304607391357 seconds for one epoch ---
--- 0.3127751350402832 seconds for one epoch ---
--- 1.3014464378356934 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999992]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.366073]
 [ -0.      ]]
--- 0.31040430068969727 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3152.35888671875, (1517.1431, 2.4322877, 1632.4235, 0.3601757)
   validation loss 845.4258422851562, (597.204, 0.34017286, 247.52156, 0.3601757)
decoder loss ratio: 23136.718957, decoder SINDy loss  ratio: 0.534310
--- 0.2638072967529297 seconds for one epoch ---
--- 0.29457521438598633 seconds for one epoch ---
--- 1.3313241004943848 seconds for one epoch ---
--- 0.2962064743041992 seconds for one epoch ---
--- 1.2966346740722656 seconds for one epoch ---
--- 0.3061985969543457 seconds for one epoch ---
--- 1.3064906597137451 seconds for one epoch ---
--- 0.29689979553222656 seconds for one epoch ---
--- 1.3103735446929932 seconds for one epoch ---
--- 0.30005407333374023 seconds for one epoch ---
--- 1.3202738761901855 seconds for one epoch ---
--- 0.3068554401397705 seconds for one epoch ---
--- 1.3092260360717773 seconds for one epoch ---
--- 0.30358290672302246 seconds for one epoch ---
--- 1.310007095336914 seconds for one epoch ---
--- 0.30336952209472656 seconds for one epoch ---
--- 1.3135106563568115 seconds for one epoch ---
--- 0.3035848140716553 seconds for one epoch ---
--- 1.3054850101470947 seconds for one epoch ---
--- 0.29372334480285645 seconds for one epoch ---
--- 1.3219020366668701 seconds for one epoch ---
--- 0.30917930603027344 seconds for one epoch ---
--- 1.3256127834320068 seconds for one epoch ---
--- 0.3101081848144531 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999225]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.472143]
 [ -0.      ]]
--- 0.2706582546234131 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1875.025146484375, (877.0264, 1.4100847, 996.22626, 0.36225745)
   validation loss 732.2137451171875, (479.68204, 0.24771762, 251.92177, 0.36225745)
decoder loss ratio: 18583.714892, decoder SINDy loss  ratio: 0.543809
--- 0.2997736930847168 seconds for one epoch ---
--- 1.3189303874969482 seconds for one epoch ---
--- 0.3024733066558838 seconds for one epoch ---
--- 1.304255485534668 seconds for one epoch ---
--- 0.29567718505859375 seconds for one epoch ---
--- 1.3134610652923584 seconds for one epoch ---
--- 0.3092031478881836 seconds for one epoch ---
--- 1.3254833221435547 seconds for one epoch ---
--- 0.2951395511627197 seconds for one epoch ---
--- 1.299825668334961 seconds for one epoch ---
--- 0.3012843132019043 seconds for one epoch ---
--- 1.3253684043884277 seconds for one epoch ---
--- 0.30314159393310547 seconds for one epoch ---
--- 1.3624577522277832 seconds for one epoch ---
--- 0.30891895294189453 seconds for one epoch ---
--- 1.3464024066925049 seconds for one epoch ---
--- 0.31034231185913086 seconds for one epoch ---
--- 1.360583782196045 seconds for one epoch ---
--- 0.3261072635650635 seconds for one epoch ---
--- 1.3353395462036133 seconds for one epoch ---
--- 0.3016035556793213 seconds for one epoch ---
--- 1.3195574283599854 seconds for one epoch ---
--- 0.2996799945831299 seconds for one epoch ---
--- 1.336122751235962 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999927]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.569977]
 [ -0.      ]]
--- 0.30552124977111816 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2041.174072265625, (1053.6636, 0.8706358, 986.2757, 0.36424342)
   validation loss 768.9451293945312, (506.4249, 0.26175916, 261.89423, 0.36424342)
decoder loss ratio: 19619.779673, decoder SINDy loss  ratio: 0.565336
--- 0.2861771583557129 seconds for one epoch ---
--- 0.2908344268798828 seconds for one epoch ---
--- 1.3375976085662842 seconds for one epoch ---
--- 0.2870807647705078 seconds for one epoch ---
--- 1.3654134273529053 seconds for one epoch ---
--- 0.2946813106536865 seconds for one epoch ---
--- 1.3381295204162598 seconds for one epoch ---
--- 0.3020603656768799 seconds for one epoch ---
--- 1.3435935974121094 seconds for one epoch ---
--- 0.546044111251831 seconds for one epoch ---
--- 1.3354942798614502 seconds for one epoch ---
--- 0.29244041442871094 seconds for one epoch ---
--- 1.324474811553955 seconds for one epoch ---
--- 0.300004243850708 seconds for one epoch ---
--- 1.3269622325897217 seconds for one epoch ---
--- 0.2991015911102295 seconds for one epoch ---
--- 1.3272018432617188 seconds for one epoch ---
--- 0.29337048530578613 seconds for one epoch ---
--- 1.3288054466247559 seconds for one epoch ---
--- 0.2943744659423828 seconds for one epoch ---
--- 1.3458104133605957 seconds for one epoch ---
--- 0.2913506031036377 seconds for one epoch ---
--- 1.3476054668426514 seconds for one epoch ---
--- 0.29966211318969727 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999926]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.692349]
 [ -0.      ]]
--- 0.279726505279541 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3749.48095703125, (1974.6222, 1.4786623, 1773.0133, 0.36661068)
   validation loss 891.0112915039062, (569.95917, 0.28504634, 320.40045, 0.36661068)
decoder loss ratio: 22081.207641, decoder SINDy loss  ratio: 0.691629
--- 0.3156301975250244 seconds for one epoch ---
--- 1.3609089851379395 seconds for one epoch ---
--- 0.3194422721862793 seconds for one epoch ---
--- 1.359140157699585 seconds for one epoch ---
--- 0.3181285858154297 seconds for one epoch ---
--- 1.3416426181793213 seconds for one epoch ---
--- 0.30639123916625977 seconds for one epoch ---
--- 1.3545622825622559 seconds for one epoch ---
--- 0.30996060371398926 seconds for one epoch ---
--- 1.3548171520233154 seconds for one epoch ---
--- 0.30152225494384766 seconds for one epoch ---
--- 1.3678021430969238 seconds for one epoch ---
--- 0.30031728744506836 seconds for one epoch ---
--- 1.355945348739624 seconds for one epoch ---
--- 0.2968575954437256 seconds for one epoch ---
--- 1.3678462505340576 seconds for one epoch ---
--- 0.2947347164154053 seconds for one epoch ---
--- 1.358546257019043 seconds for one epoch ---
--- 0.3018476963043213 seconds for one epoch ---
--- 1.3571908473968506 seconds for one epoch ---
--- 0.3073854446411133 seconds for one epoch ---
--- 1.3440577983856201 seconds for one epoch ---
--- 0.31368374824523926 seconds for one epoch ---
--- 1.3731842041015625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999404]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.781201]
 [ -0.      ]]
--- 0.30510544776916504 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2858.348388671875, (1509.2633, 1.3554951, 1347.3611, 0.36839953)
   validation loss 1189.369873046875, (893.31494, 0.32778567, 295.3587, 0.36839953)
decoder loss ratio: 34608.571693, decoder SINDy loss  ratio: 0.637573
--- 0.26519155502319336 seconds for one epoch ---
--- 0.29415416717529297 seconds for one epoch ---
--- 1.3627948760986328 seconds for one epoch ---
--- 0.3041963577270508 seconds for one epoch ---
--- 1.3566920757293701 seconds for one epoch ---
--- 0.2939310073852539 seconds for one epoch ---
--- 1.3642559051513672 seconds for one epoch ---
--- 0.3052821159362793 seconds for one epoch ---
--- 1.3423645496368408 seconds for one epoch ---
--- 0.3059244155883789 seconds for one epoch ---
--- 1.3496806621551514 seconds for one epoch ---
--- 0.291806697845459 seconds for one epoch ---
--- 1.3502283096313477 seconds for one epoch ---
--- 0.3015453815460205 seconds for one epoch ---
--- 1.3577373027801514 seconds for one epoch ---
--- 0.294536828994751 seconds for one epoch ---
--- 1.3677449226379395 seconds for one epoch ---
--- 0.2987985610961914 seconds for one epoch ---
--- 1.3809261322021484 seconds for one epoch ---
--- 0.3133525848388672 seconds for one epoch ---
--- 1.3808822631835938 seconds for one epoch ---
--- 0.3055264949798584 seconds for one epoch ---
--- 1.3946874141693115 seconds for one epoch ---
--- 0.304659366607666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999404]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.877314]
 [ -0.      ]]
--- 0.2607882022857666 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2480.500244140625, (1294.6189, 7.207413, 1178.3038, 0.370231)
   validation loss 755.7593994140625, (480.86047, 0.2679689, 274.2607, 0.370231)
decoder loss ratio: 18629.369559, decoder SINDy loss  ratio: 0.592030
--- 0.3009796142578125 seconds for one epoch ---
--- 1.362417459487915 seconds for one epoch ---
--- 0.2927868366241455 seconds for one epoch ---
--- 1.3848679065704346 seconds for one epoch ---
--- 0.29714155197143555 seconds for one epoch ---
--- 1.4217886924743652 seconds for one epoch ---
--- 0.3020622730255127 seconds for one epoch ---
--- 1.4209740161895752 seconds for one epoch ---
--- 0.28644704818725586 seconds for one epoch ---
--- 1.3752708435058594 seconds for one epoch ---
--- 0.2880871295928955 seconds for one epoch ---
--- 1.424349308013916 seconds for one epoch ---
--- 0.2935049533843994 seconds for one epoch ---
--- 1.4234344959259033 seconds for one epoch ---
--- 0.2981128692626953 seconds for one epoch ---
--- 1.3806016445159912 seconds for one epoch ---
--- 0.28972887992858887 seconds for one epoch ---
--- 1.364194631576538 seconds for one epoch ---
--- 0.2959425449371338 seconds for one epoch ---
--- 1.379504680633545 seconds for one epoch ---
--- 0.2985248565673828 seconds for one epoch ---
--- 1.390876293182373 seconds for one epoch ---
--- 0.30069637298583984 seconds for one epoch ---
--- 1.3928780555725098 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999963]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.959835]
 [ -0.      ]]
--- 0.3020668029785156 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3613.51220703125, (1008.8141, 4.3590784, 2599.9673, 0.37186176)
   validation loss 1026.0184326171875, (751.9366, 0.29587987, 273.4141, 0.37186176)
decoder loss ratio: 29131.328702, decoder SINDy loss  ratio: 0.590203
--- 0.2840394973754883 seconds for one epoch ---
--- 0.2866396903991699 seconds for one epoch ---
--- 1.387052297592163 seconds for one epoch ---
--- 0.3059062957763672 seconds for one epoch ---
--- 1.4041824340820312 seconds for one epoch ---
--- 0.3020460605621338 seconds for one epoch ---
--- 1.3731606006622314 seconds for one epoch ---
--- 0.304154634475708 seconds for one epoch ---
--- 1.3878087997436523 seconds for one epoch ---
--- 0.30155444145202637 seconds for one epoch ---
--- 1.3848156929016113 seconds for one epoch ---
--- 0.2945988178253174 seconds for one epoch ---
--- 1.386518955230713 seconds for one epoch ---
--- 0.2955434322357178 seconds for one epoch ---
--- 1.3739862442016602 seconds for one epoch ---
--- 0.29849863052368164 seconds for one epoch ---
--- 1.385164737701416 seconds for one epoch ---
--- 0.30340003967285156 seconds for one epoch ---
--- 1.3811874389648438 seconds for one epoch ---
--- 0.296947717666626 seconds for one epoch ---
--- 1.3866875171661377 seconds for one epoch ---
--- 0.2998466491699219 seconds for one epoch ---
--- 1.3600304126739502 seconds for one epoch ---
--- 0.29474329948425293 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999963]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.032157]
 [ -0.      ]]
--- 0.2538115978240967 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2571.88916015625, (1125.188, 0.806702, 1445.5209, 0.37344107)
   validation loss 701.9871215820312, (428.88086, 0.33180878, 272.40103, 0.37344107)
decoder loss ratio: 16615.589062, decoder SINDy loss  ratio: 0.588016
--- 0.2991609573364258 seconds for one epoch ---
--- 1.3768048286437988 seconds for one epoch ---
--- 0.3059389591217041 seconds for one epoch ---
--- 1.3826804161071777 seconds for one epoch ---
--- 0.30376315116882324 seconds for one epoch ---
--- 1.4004945755004883 seconds for one epoch ---
--- 0.29944944381713867 seconds for one epoch ---
--- 1.3872160911560059 seconds for one epoch ---
--- 0.29192638397216797 seconds for one epoch ---
--- 1.4016942977905273 seconds for one epoch ---
--- 0.2906227111816406 seconds for one epoch ---
--- 1.4076759815216064 seconds for one epoch ---
--- 0.3008553981781006 seconds for one epoch ---
--- 1.419159173965454 seconds for one epoch ---
--- 0.29315996170043945 seconds for one epoch ---
--- 1.410691499710083 seconds for one epoch ---
--- 0.3011922836303711 seconds for one epoch ---
--- 1.3892264366149902 seconds for one epoch ---
--- 0.29351353645324707 seconds for one epoch ---
--- 1.396040916442871 seconds for one epoch ---
--- 0.2920238971710205 seconds for one epoch ---
--- 1.4096276760101318 seconds for one epoch ---
--- 0.2995326519012451 seconds for one epoch ---
--- 1.3565094470977783 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999963]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.115677]
 [ -0.      ]]
--- 0.295060396194458 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2434.099853515625, (1032.878, 0.43160546, 1400.4148, 0.37513357)
   validation loss 730.0773315429688, (478.57184, 0.28957894, 250.84077, 0.37513357)
decoder loss ratio: 18540.703856, decoder SINDy loss  ratio: 0.541475
--- 0.2639801502227783 seconds for one epoch ---
--- 0.3118705749511719 seconds for one epoch ---
--- 1.3940553665161133 seconds for one epoch ---
--- 0.2983253002166748 seconds for one epoch ---
--- 1.4116873741149902 seconds for one epoch ---
--- 0.29312825202941895 seconds for one epoch ---
--- 1.3987321853637695 seconds for one epoch ---
--- 0.2986111640930176 seconds for one epoch ---
--- 1.3845007419586182 seconds for one epoch ---
--- 0.29720091819763184 seconds for one epoch ---
--- 1.4085502624511719 seconds for one epoch ---
--- 0.30158114433288574 seconds for one epoch ---
--- 1.3983385562896729 seconds for one epoch ---
--- 0.3015141487121582 seconds for one epoch ---
--- 1.3866088390350342 seconds for one epoch ---
--- 0.2919962406158447 seconds for one epoch ---
--- 1.3740668296813965 seconds for one epoch ---
--- 0.291532039642334 seconds for one epoch ---
--- 1.4121603965759277 seconds for one epoch ---
--- 0.3142130374908447 seconds for one epoch ---
--- 1.3674609661102295 seconds for one epoch ---
--- 0.29356980323791504 seconds for one epoch ---
--- 1.377387523651123 seconds for one epoch ---
--- 0.30171895027160645 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999963]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.193316]
 [ -0.      ]]
--- 0.24590754508972168 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2778.748779296875, (1509.7451, 2.553766, 1266.0734, 0.37671897)
   validation loss 1008.6641845703125, (767.3227, 0.33025783, 240.63454, 0.37671897)
decoder loss ratio: 29727.413253, decoder SINDy loss  ratio: 0.519443
--- 0.3258085250854492 seconds for one epoch ---
--- 1.422217845916748 seconds for one epoch ---
--- 0.3300302028656006 seconds for one epoch ---
--- 1.4570674896240234 seconds for one epoch ---
--- 0.33888840675354004 seconds for one epoch ---
--- 1.4420630931854248 seconds for one epoch ---
--- 0.325775146484375 seconds for one epoch ---
--- 1.4202461242675781 seconds for one epoch ---
--- 0.3138880729675293 seconds for one epoch ---
--- 1.4045960903167725 seconds for one epoch ---
--- 0.3116118907928467 seconds for one epoch ---
--- 1.4091908931732178 seconds for one epoch ---
--- 0.3121769428253174 seconds for one epoch ---
--- 1.4290826320648193 seconds for one epoch ---
--- 0.30030322074890137 seconds for one epoch ---
--- 1.422694206237793 seconds for one epoch ---
--- 0.29740142822265625 seconds for one epoch ---
--- 1.428406000137329 seconds for one epoch ---
--- 0.2955441474914551 seconds for one epoch ---
--- 1.3910202980041504 seconds for one epoch ---
--- 0.29492735862731934 seconds for one epoch ---
--- 1.384699821472168 seconds for one epoch ---
--- 0.30162787437438965 seconds for one epoch ---
--- 1.420950174331665 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.262747]
 [ -0.      ]]
--- 0.2903628349304199 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2902.335693359375, (1137.3562, 3.4851573, 1761.1163, 0.3781374)
   validation loss 710.2926635742188, (445.22803, 0.30638993, 264.38013, 0.3781374)
decoder loss ratio: 17248.906729, decoder SINDy loss  ratio: 0.570702
--- 0.2678337097167969 seconds for one epoch ---
--- 0.3029496669769287 seconds for one epoch ---
--- 1.4060988426208496 seconds for one epoch ---
--- 0.2857015132904053 seconds for one epoch ---
--- 1.4223518371582031 seconds for one epoch ---
--- 0.30558252334594727 seconds for one epoch ---
--- 1.4135468006134033 seconds for one epoch ---
--- 0.2957475185394287 seconds for one epoch ---
--- 1.4295241832733154 seconds for one epoch ---
--- 0.3053576946258545 seconds for one epoch ---
--- 1.4264698028564453 seconds for one epoch ---
--- 0.2919044494628906 seconds for one epoch ---
--- 1.416548728942871 seconds for one epoch ---
--- 0.3021063804626465 seconds for one epoch ---
--- 1.4267079830169678 seconds for one epoch ---
--- 0.3031587600708008 seconds for one epoch ---
--- 1.436372995376587 seconds for one epoch ---
--- 0.3026297092437744 seconds for one epoch ---
--- 1.3890681266784668 seconds for one epoch ---
--- 0.30183863639831543 seconds for one epoch ---
--- 1.4071764945983887 seconds for one epoch ---
--- 0.2979106903076172 seconds for one epoch ---
--- 1.4286880493164062 seconds for one epoch ---
--- 0.3043999671936035 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.330571]
 [ -0.      ]]
--- 0.27109313011169434 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3255.4306640625, (1427.3077, 0.88482654, 1826.8589, 0.37951365)
   validation loss 1108.219482421875, (824.4325, 0.31411138, 283.09335, 0.37951365)
decoder loss ratio: 31939.946139, decoder SINDy loss  ratio: 0.611097
--- 0.3002781867980957 seconds for one epoch ---
--- 1.4458551406860352 seconds for one epoch ---
--- 0.2966117858886719 seconds for one epoch ---
--- 1.4582059383392334 seconds for one epoch ---
--- 0.30191731452941895 seconds for one epoch ---
--- 1.4434514045715332 seconds for one epoch ---
--- 0.30589771270751953 seconds for one epoch ---
--- 1.4075555801391602 seconds for one epoch ---
--- 0.3020038604736328 seconds for one epoch ---
--- 1.4400913715362549 seconds for one epoch ---
--- 0.3149380683898926 seconds for one epoch ---
--- 1.4175498485565186 seconds for one epoch ---
--- 0.294971227645874 seconds for one epoch ---
--- 1.428177833557129 seconds for one epoch ---
--- 0.3104712963104248 seconds for one epoch ---
--- 1.4369962215423584 seconds for one epoch ---
--- 0.29968881607055664 seconds for one epoch ---
--- 1.4194507598876953 seconds for one epoch ---
--- 0.2974979877471924 seconds for one epoch ---
--- 1.4038453102111816 seconds for one epoch ---
--- 0.29930663108825684 seconds for one epoch ---
--- 1.4142820835113525 seconds for one epoch ---
--- 0.29270458221435547 seconds for one epoch ---
--- 1.466543197631836 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.416476]
 [ -0.      ]]
--- 0.3108482360839844 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3983.21630859375, (1645.8099, 5.5418873, 2331.4832, 0.3813724)
   validation loss 1099.6474609375, (824.77246, 0.40570414, 274.0879, 0.3813724)
decoder loss ratio: 31953.117005, decoder SINDy loss  ratio: 0.591657
THRESHOLDING: 1 active coefficients
--- 1.4084482192993164 seconds for one epoch ---
--- 0.2981407642364502 seconds for one epoch ---
--- 1.4326071739196777 seconds for one epoch ---
--- 0.30950069427490234 seconds for one epoch ---
--- 1.4470772743225098 seconds for one epoch ---
--- 0.2983121871948242 seconds for one epoch ---
--- 1.4512436389923096 seconds for one epoch ---
--- 0.30202150344848633 seconds for one epoch ---
--- 1.4675195217132568 seconds for one epoch ---
--- 0.30296826362609863 seconds for one epoch ---
--- 1.4783709049224854 seconds for one epoch ---
--- 0.3111557960510254 seconds for one epoch ---
--- 1.4463987350463867 seconds for one epoch ---
--- 0.2940065860748291 seconds for one epoch ---
--- 1.464311122894287 seconds for one epoch ---
--- 0.30082178115844727 seconds for one epoch ---
--- 1.456181526184082 seconds for one epoch ---
--- 0.3000783920288086 seconds for one epoch ---
--- 1.4683618545532227 seconds for one epoch ---
--- 0.3119537830352783 seconds for one epoch ---
--- 1.485194444656372 seconds for one epoch ---
--- 0.29807424545288086 seconds for one epoch ---
--- 1.4615042209625244 seconds for one epoch ---
--- 0.29152870178222656 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999982]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.472268]
 [ -0.      ]]
--- 0.25986266136169434 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2097.321533203125, (944.116, 0.6827447, 1152.1403, 0.38254195)
   validation loss 871.4093627929688, (595.87665, 0.34899476, 274.80115, 0.38254195)
decoder loss ratio: 23085.295829, decoder SINDy loss  ratio: 0.593197
--- 0.2900733947753906 seconds for one epoch ---
--- 1.43880033493042 seconds for one epoch ---
--- 0.3009648323059082 seconds for one epoch ---
--- 1.4422924518585205 seconds for one epoch ---
--- 0.2922670841217041 seconds for one epoch ---
--- 1.4390592575073242 seconds for one epoch ---
--- 0.28402161598205566 seconds for one epoch ---
--- 1.4708964824676514 seconds for one epoch ---
--- 0.3153660297393799 seconds for one epoch ---
--- 1.4442086219787598 seconds for one epoch ---
--- 0.3034360408782959 seconds for one epoch ---
--- 1.4675886631011963 seconds for one epoch ---
--- 0.30063462257385254 seconds for one epoch ---
--- 1.4551527500152588 seconds for one epoch ---
--- 0.31150388717651367 seconds for one epoch ---
--- 1.4694271087646484 seconds for one epoch ---
--- 0.3118932247161865 seconds for one epoch ---
--- 1.4515712261199951 seconds for one epoch ---
--- 0.3169362545013428 seconds for one epoch ---
--- 1.430452585220337 seconds for one epoch ---
--- 0.29892802238464355 seconds for one epoch ---
--- 1.4446721076965332 seconds for one epoch ---
--- 0.29515528678894043 seconds for one epoch ---
--- 1.4659843444824219 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999981]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.542862]
 [ -0.      ]]
--- 0.31905150413513184 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2639.861328125, (1314.0321, 1.8697349, 1323.5754, 0.38406605)
   validation loss 878.518310546875, (584.5487, 0.44560233, 293.1399, 0.38406605)
decoder loss ratio: 22646.431694, decoder SINDy loss  ratio: 0.632784
--- 0.2679448127746582 seconds for one epoch ---
--- 0.2961604595184326 seconds for one epoch ---
--- 1.4794940948486328 seconds for one epoch ---
--- 0.30303096771240234 seconds for one epoch ---
--- 1.4757730960845947 seconds for one epoch ---
--- 0.2992422580718994 seconds for one epoch ---
--- 1.482940435409546 seconds for one epoch ---
--- 0.29235196113586426 seconds for one epoch ---
--- 1.4631612300872803 seconds for one epoch ---
--- 0.3092784881591797 seconds for one epoch ---
--- 1.4708003997802734 seconds for one epoch ---
--- 0.2994687557220459 seconds for one epoch ---
--- 1.484032154083252 seconds for one epoch ---
--- 0.2968437671661377 seconds for one epoch ---
--- 1.4799997806549072 seconds for one epoch ---
--- 0.2988722324371338 seconds for one epoch ---
--- 1.486246109008789 seconds for one epoch ---
--- 0.2990853786468506 seconds for one epoch ---
--- 1.4977903366088867 seconds for one epoch ---
--- 0.2988917827606201 seconds for one epoch ---
--- 1.486217975616455 seconds for one epoch ---
--- 0.30557703971862793 seconds for one epoch ---
--- 1.492126226425171 seconds for one epoch ---
--- 0.29868364334106445 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999981]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.607843]
 [ -0.      ]]
--- 0.274263858795166 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3510.492431640625, (1489.5192, 0.5961475, 2019.9916, 0.38539267)
   validation loss 671.142578125, (406.2962, 0.3561684, 264.10486, 0.38539267)
decoder loss ratio: 15740.620289, decoder SINDy loss  ratio: 0.570107
--- 0.3110675811767578 seconds for one epoch ---
--- 1.461683988571167 seconds for one epoch ---
--- 0.3058328628540039 seconds for one epoch ---
--- 1.4685962200164795 seconds for one epoch ---
--- 0.30873847007751465 seconds for one epoch ---
--- 1.4758808612823486 seconds for one epoch ---
--- 0.2981083393096924 seconds for one epoch ---
--- 1.4689886569976807 seconds for one epoch ---
--- 0.2975471019744873 seconds for one epoch ---
--- 1.4910619258880615 seconds for one epoch ---
--- 0.30658435821533203 seconds for one epoch ---
--- 1.5063650608062744 seconds for one epoch ---
--- 0.3101048469543457 seconds for one epoch ---
--- 1.4411089420318604 seconds for one epoch ---
--- 0.2946662902832031 seconds for one epoch ---
--- 1.4289376735687256 seconds for one epoch ---
--- 0.2943432331085205 seconds for one epoch ---
--- 1.4417753219604492 seconds for one epoch ---
--- 0.28791332244873047 seconds for one epoch ---
--- 1.4853029251098633 seconds for one epoch ---
--- 0.31417346000671387 seconds for one epoch ---
--- 1.4771101474761963 seconds for one epoch ---
--- 0.31870317459106445 seconds for one epoch ---
--- 1.508314847946167 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999998]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.690666]
 [ -0.      ]]
--- 0.29749321937561035 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2759.579833984375, (1163.6249, 2.6236622, 1592.9441, 0.3872151)
   validation loss 925.435791015625, (667.78174, 0.3246433, 256.94217, 0.3872151)
decoder loss ratio: 25871.023861, decoder SINDy loss  ratio: 0.554646
--- 0.27103090286254883 seconds for one epoch ---
--- 0.296921968460083 seconds for one epoch ---
--- 1.5137815475463867 seconds for one epoch ---
--- 0.2986292839050293 seconds for one epoch ---
--- 1.499995470046997 seconds for one epoch ---
--- 0.30099010467529297 seconds for one epoch ---
--- 1.5163679122924805 seconds for one epoch ---
--- 0.30317115783691406 seconds for one epoch ---
--- 1.5328173637390137 seconds for one epoch ---
--- 0.308579683303833 seconds for one epoch ---
--- 1.4674429893493652 seconds for one epoch ---
--- 0.30123114585876465 seconds for one epoch ---
--- 1.4701216220855713 seconds for one epoch ---
--- 0.29651665687561035 seconds for one epoch ---
--- 1.4969711303710938 seconds for one epoch ---
--- 0.30260634422302246 seconds for one epoch ---
--- 1.5163118839263916 seconds for one epoch ---
--- 0.3011484146118164 seconds for one epoch ---
--- 1.4874253273010254 seconds for one epoch ---
--- 0.30138158798217773 seconds for one epoch ---
--- 1.4976646900177002 seconds for one epoch ---
--- 0.29467129707336426 seconds for one epoch ---
--- 1.4915382862091064 seconds for one epoch ---
--- 0.30971598625183105 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.754771]
 [ -0.      ]]
--- 0.26167941093444824 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2142.244873046875, (736.1256, 1.6848718, 1404.0459, 0.38852248)
   validation loss 851.0924682617188, (593.23456, 0.40994003, 257.05945, 0.38852248)
decoder loss ratio: 22982.936681, decoder SINDy loss  ratio: 0.554899
--- 0.30301451683044434 seconds for one epoch ---
--- 1.522704839706421 seconds for one epoch ---
--- 0.2946176528930664 seconds for one epoch ---
--- 1.5003256797790527 seconds for one epoch ---
--- 0.30567383766174316 seconds for one epoch ---
--- 1.5228724479675293 seconds for one epoch ---
--- 0.29478001594543457 seconds for one epoch ---
--- 1.5325491428375244 seconds for one epoch ---
--- 0.3066568374633789 seconds for one epoch ---
--- 1.4979848861694336 seconds for one epoch ---
--- 0.29739856719970703 seconds for one epoch ---
--- 1.4860379695892334 seconds for one epoch ---
--- 0.2875971794128418 seconds for one epoch ---
--- 1.4807441234588623 seconds for one epoch ---
--- 0.2939443588256836 seconds for one epoch ---
--- 1.5092358589172363 seconds for one epoch ---
--- 0.33336472511291504 seconds for one epoch ---
--- 1.5475010871887207 seconds for one epoch ---
--- 0.3366577625274658 seconds for one epoch ---
--- 1.5401511192321777 seconds for one epoch ---
--- 0.3201918601989746 seconds for one epoch ---
--- 1.5480265617370605 seconds for one epoch ---
--- 0.31470632553100586 seconds for one epoch ---
--- 1.5400333404541016 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.812528]
 [ -0.      ]]
--- 0.3156261444091797 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1954.2601318359375, (791.84875, 2.3358054, 1159.6858, 0.38977194)
   validation loss 1319.086669921875, (1026.3849, 0.30606094, 292.006, 0.38977194)
decoder loss ratio: 39763.932432, decoder SINDy loss  ratio: 0.630336
--- 0.2694113254547119 seconds for one epoch ---
--- 0.30515098571777344 seconds for one epoch ---
--- 1.5288505554199219 seconds for one epoch ---
--- 0.3060643672943115 seconds for one epoch ---
--- 1.5227994918823242 seconds for one epoch ---
--- 0.3024930953979492 seconds for one epoch ---
--- 1.5319163799285889 seconds for one epoch ---
--- 0.3014333248138428 seconds for one epoch ---
--- 1.4736926555633545 seconds for one epoch ---
--- 0.30184221267700195 seconds for one epoch ---
--- 1.4858908653259277 seconds for one epoch ---
--- 0.3020639419555664 seconds for one epoch ---
--- 1.49344801902771 seconds for one epoch ---
--- 0.29378509521484375 seconds for one epoch ---
--- 1.5205597877502441 seconds for one epoch ---
--- 0.30225610733032227 seconds for one epoch ---
--- 1.5396091938018799 seconds for one epoch ---
--- 0.30039072036743164 seconds for one epoch ---
--- 1.5007436275482178 seconds for one epoch ---
--- 0.30086731910705566 seconds for one epoch ---
--- 1.5304670333862305 seconds for one epoch ---
--- 0.30213451385498047 seconds for one epoch ---
--- 1.5410480499267578 seconds for one epoch ---
--- 0.3030354976654053 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.858244]
 [ -0.      ]]
--- 0.2600376605987549 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2422.49951171875, (1186.7723, 1.7403984, 1233.5961, 0.39073572)
   validation loss 727.911865234375, (459.64633, 0.26414338, 267.61066, 0.39073572)
decoder loss ratio: 17807.496875, decoder SINDy loss  ratio: 0.577675
--- 0.28707027435302734 seconds for one epoch ---
--- 1.5252926349639893 seconds for one epoch ---
--- 0.29705047607421875 seconds for one epoch ---
--- 1.5447652339935303 seconds for one epoch ---
--- 0.30286717414855957 seconds for one epoch ---
--- 1.570899248123169 seconds for one epoch ---
--- 0.30896735191345215 seconds for one epoch ---
--- 1.5114266872406006 seconds for one epoch ---
--- 0.2970442771911621 seconds for one epoch ---
--- 1.5073728561401367 seconds for one epoch ---
--- 0.3059976100921631 seconds for one epoch ---
--- 1.5063674449920654 seconds for one epoch ---
--- 0.3126664161682129 seconds for one epoch ---
--- 1.5550217628479004 seconds for one epoch ---
--- 0.2984325885772705 seconds for one epoch ---
--- 1.5503909587860107 seconds for one epoch ---
--- 0.29203081130981445 seconds for one epoch ---
--- 1.5373506546020508 seconds for one epoch ---
--- 0.2982907295227051 seconds for one epoch ---
--- 1.5415170192718506 seconds for one epoch ---
--- 0.29641270637512207 seconds for one epoch ---
--- 1.5551395416259766 seconds for one epoch ---
--- 0.2943706512451172 seconds for one epoch ---
--- 1.5704419612884521 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.925196]
 [ -0.      ]]
--- 0.29288482666015625 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3371.8369140625, (976.28925, 3.3131785, 2391.8425, 0.39216152)
   validation loss 821.4690551757812, (561.6551, 0.371047, 259.05075, 0.39216152)
decoder loss ratio: 21759.493276, decoder SINDy loss  ratio: 0.559197
--- 0.26656508445739746 seconds for one epoch ---
--- 0.298994779586792 seconds for one epoch ---
--- 1.5538523197174072 seconds for one epoch ---
--- 0.30860352516174316 seconds for one epoch ---
--- 1.5433597564697266 seconds for one epoch ---
--- 0.3084721565246582 seconds for one epoch ---
--- 1.5196895599365234 seconds for one epoch ---
--- 0.3015146255493164 seconds for one epoch ---
--- 1.5008187294006348 seconds for one epoch ---
--- 0.2791464328765869 seconds for one epoch ---
--- 1.5531971454620361 seconds for one epoch ---
--- 0.3148922920227051 seconds for one epoch ---
--- 1.5679936408996582 seconds for one epoch ---
--- 0.33475685119628906 seconds for one epoch ---
--- 1.5844178199768066 seconds for one epoch ---
--- 0.34092283248901367 seconds for one epoch ---
--- 1.5775938034057617 seconds for one epoch ---
--- 0.31963491439819336 seconds for one epoch ---
--- 1.5562283992767334 seconds for one epoch ---
--- 0.312239408493042 seconds for one epoch ---
--- 1.550175428390503 seconds for one epoch ---
--- 0.3024258613586426 seconds for one epoch ---
--- 1.5434863567352295 seconds for one epoch ---
--- 0.3160562515258789 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-14.9769335]
 [ -0.       ]]
--- 0.25941920280456543 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4027.602294921875, (1867.1823, 1.098613, 2158.9282, 0.39330506)
   validation loss 727.145263671875, (446.07782, 0.32969695, 280.3444, 0.39330506)
decoder loss ratio: 17281.829165, decoder SINDy loss  ratio: 0.605163
--- 0.29687047004699707 seconds for one epoch ---
--- 1.5121896266937256 seconds for one epoch ---
--- 0.2887859344482422 seconds for one epoch ---
--- 1.5483427047729492 seconds for one epoch ---
--- 0.30089330673217773 seconds for one epoch ---
--- 1.510511875152588 seconds for one epoch ---
--- 0.2895989418029785 seconds for one epoch ---
--- 1.5160236358642578 seconds for one epoch ---
--- 0.29615163803100586 seconds for one epoch ---
--- 1.5347578525543213 seconds for one epoch ---
--- 0.30086851119995117 seconds for one epoch ---
--- 1.5818145275115967 seconds for one epoch ---
--- 0.32782888412475586 seconds for one epoch ---
--- 1.5488111972808838 seconds for one epoch ---
--- 0.3229963779449463 seconds for one epoch ---
--- 1.5573468208312988 seconds for one epoch ---
--- 0.32404136657714844 seconds for one epoch ---
--- 1.5642271041870117 seconds for one epoch ---
--- 0.3084688186645508 seconds for one epoch ---
--- 1.5720384120941162 seconds for one epoch ---
--- 0.31191349029541016 seconds for one epoch ---
--- 1.553065538406372 seconds for one epoch ---
--- 0.2990550994873047 seconds for one epoch ---
--- 1.6105663776397705 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.034539]
 [ -0.      ]]
--- 0.2882676124572754 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2689.03125, (951.3671, 2.2610705, 1735.0085, 0.3945693)
   validation loss 907.45751953125, (632.8449, 0.3844699, 273.83356, 0.3945693)
decoder loss ratio: 24517.510468, decoder SINDy loss  ratio: 0.591108
--- 0.27327513694763184 seconds for one epoch ---
--- 0.3012263774871826 seconds for one epoch ---
--- 1.552659273147583 seconds for one epoch ---
--- 0.29299378395080566 seconds for one epoch ---
--- 1.5172228813171387 seconds for one epoch ---
--- 0.29381370544433594 seconds for one epoch ---
--- 1.5155186653137207 seconds for one epoch ---
--- 0.28418445587158203 seconds for one epoch ---
--- 1.5279078483581543 seconds for one epoch ---
--- 0.29485440254211426 seconds for one epoch ---
--- 1.552990436553955 seconds for one epoch ---
--- 0.29268360137939453 seconds for one epoch ---
--- 1.5732221603393555 seconds for one epoch ---
--- 0.301375150680542 seconds for one epoch ---
--- 1.5816113948822021 seconds for one epoch ---
--- 0.28784632682800293 seconds for one epoch ---
--- 1.5752906799316406 seconds for one epoch ---
--- 0.29736900329589844 seconds for one epoch ---
--- 1.5990757942199707 seconds for one epoch ---
--- 0.2927515506744385 seconds for one epoch ---
--- 1.5776088237762451 seconds for one epoch ---
--- 0.3042778968811035 seconds for one epoch ---
--- 1.5983669757843018 seconds for one epoch ---
--- 0.29706311225891113 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.078486]
 [ -0.      ]]
--- 0.25309062004089355 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2183.24462890625, (932.7388, 0.80195546, 1249.3085, 0.39550477)
   validation loss 926.1360473632812, (669.72925, 0.3326361, 255.67867, 0.39550477)
decoder loss ratio: 25946.473770, decoder SINDy loss  ratio: 0.551918
--- 0.2983896732330322 seconds for one epoch ---
--- 1.591454267501831 seconds for one epoch ---
--- 0.29605889320373535 seconds for one epoch ---
--- 1.5724694728851318 seconds for one epoch ---
--- 0.30179357528686523 seconds for one epoch ---
--- 1.5500285625457764 seconds for one epoch ---
--- 0.3002634048461914 seconds for one epoch ---
--- 1.5215351581573486 seconds for one epoch ---
--- 0.29947447776794434 seconds for one epoch ---
--- 1.569744348526001 seconds for one epoch ---
--- 0.3094601631164551 seconds for one epoch ---
--- 1.5444748401641846 seconds for one epoch ---
--- 0.30764245986938477 seconds for one epoch ---
--- 1.555084466934204 seconds for one epoch ---
--- 0.3080289363861084 seconds for one epoch ---
--- 1.572368860244751 seconds for one epoch ---
--- 0.30049586296081543 seconds for one epoch ---
--- 1.6034009456634521 seconds for one epoch ---
--- 0.30006933212280273 seconds for one epoch ---
--- 1.5959060192108154 seconds for one epoch ---
--- 0.30991387367248535 seconds for one epoch ---
--- 1.6022489070892334 seconds for one epoch ---
--- 0.3059525489807129 seconds for one epoch ---
--- 1.6000773906707764 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.131071]
 [ -0.      ]]
--- 0.299851655960083 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3144.896728515625, (1314.308, 0.6189449, 1829.5731, 0.39671594)
   validation loss 699.89599609375, (441.14325, 0.35572493, 258.00027, 0.39671594)
decoder loss ratio: 17090.655344, decoder SINDy loss  ratio: 0.556930
--- 0.2612946033477783 seconds for one epoch ---
--- 0.3031151294708252 seconds for one epoch ---
--- 1.5708577632904053 seconds for one epoch ---
--- 0.2893104553222656 seconds for one epoch ---
--- 1.554321050643921 seconds for one epoch ---
--- 0.29553842544555664 seconds for one epoch ---
--- 1.600116491317749 seconds for one epoch ---
--- 0.29647374153137207 seconds for one epoch ---
--- 1.5996203422546387 seconds for one epoch ---
--- 0.3047056198120117 seconds for one epoch ---
--- 1.6036241054534912 seconds for one epoch ---
--- 0.3054533004760742 seconds for one epoch ---
--- 1.6058998107910156 seconds for one epoch ---
--- 0.289722204208374 seconds for one epoch ---
--- 1.6156864166259766 seconds for one epoch ---
--- 0.28752827644348145 seconds for one epoch ---
--- 1.5906710624694824 seconds for one epoch ---
--- 0.2954280376434326 seconds for one epoch ---
--- 1.5752403736114502 seconds for one epoch ---
--- 0.28925323486328125 seconds for one epoch ---
--- 1.568188190460205 seconds for one epoch ---
--- 0.2901146411895752 seconds for one epoch ---
--- 1.611511468887329 seconds for one epoch ---
--- 0.3021559715270996 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.165082]
 [ -0.      ]]
--- 0.26146531105041504 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3629.26806640625, (1631.4049, 0.7195035, 1996.7461, 0.39740285)
   validation loss 813.38720703125, (554.41187, 0.38651478, 258.1914, 0.39740285)
decoder loss ratio: 21478.878161, decoder SINDy loss  ratio: 0.557342
--- 0.3094625473022461 seconds for one epoch ---
--- 1.563202142715454 seconds for one epoch ---
--- 0.3110954761505127 seconds for one epoch ---
--- 1.5453310012817383 seconds for one epoch ---
--- 0.30486083030700684 seconds for one epoch ---
--- 1.5681450366973877 seconds for one epoch ---
--- 0.2956967353820801 seconds for one epoch ---
--- 1.5638682842254639 seconds for one epoch ---
--- 0.3034703731536865 seconds for one epoch ---
--- 1.5715100765228271 seconds for one epoch ---
--- 0.29430508613586426 seconds for one epoch ---
--- 1.591291904449463 seconds for one epoch ---
--- 0.32575559616088867 seconds for one epoch ---
--- 1.615126609802246 seconds for one epoch ---
--- 0.30069494247436523 seconds for one epoch ---
--- 1.6044306755065918 seconds for one epoch ---
--- 0.2931253910064697 seconds for one epoch ---
--- 1.6097209453582764 seconds for one epoch ---
--- 0.30158567428588867 seconds for one epoch ---
--- 1.609426736831665 seconds for one epoch ---
--- 0.2876133918762207 seconds for one epoch ---
--- 1.6121723651885986 seconds for one epoch ---
--- 0.2967967987060547 seconds for one epoch ---
--- 1.606163740158081 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.2186575]
 [ -0.       ]]
--- 0.2995479106903076 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1936.1571044921875, (907.8053, 4.897107, 1023.0562, 0.3986024)
   validation loss 847.9694213867188, (568.48737, 0.31829795, 278.76514, 0.3986024)
decoder loss ratio: 22024.187486, decoder SINDy loss  ratio: 0.601754
--- 0.2656877040863037 seconds for one epoch ---
--- 0.29860758781433105 seconds for one epoch ---
--- 1.559135913848877 seconds for one epoch ---
--- 0.28940558433532715 seconds for one epoch ---
--- 1.554488182067871 seconds for one epoch ---
--- 0.28823375701904297 seconds for one epoch ---
--- 1.6155967712402344 seconds for one epoch ---
--- 0.3022956848144531 seconds for one epoch ---
--- 1.6169915199279785 seconds for one epoch ---
--- 0.3029971122741699 seconds for one epoch ---
--- 1.6089286804199219 seconds for one epoch ---
--- 0.31035327911376953 seconds for one epoch ---
--- 1.6072614192962646 seconds for one epoch ---
--- 0.3162198066711426 seconds for one epoch ---
--- 1.6400420665740967 seconds for one epoch ---
--- 0.32480335235595703 seconds for one epoch ---
--- 1.634458065032959 seconds for one epoch ---
--- 0.32163476943969727 seconds for one epoch ---
--- 1.6533660888671875 seconds for one epoch ---
--- 0.32957887649536133 seconds for one epoch ---
--- 1.6737852096557617 seconds for one epoch ---
--- 0.3210792541503906 seconds for one epoch ---
--- 1.6842436790466309 seconds for one epoch ---
--- 0.3214077949523926 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.265989]
 [ -0.      ]]
--- 0.26412367820739746 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3210.089111328125, (1162.6985, 1.1634381, 2045.8274, 0.39971492)
   validation loss 799.5973510742188, (529.16614, 0.31009963, 269.72137, 0.39971492)
decoder loss ratio: 20500.814847, decoder SINDy loss  ratio: 0.582232
--- 0.29639339447021484 seconds for one epoch ---
--- 1.5890355110168457 seconds for one epoch ---
--- 0.2887411117553711 seconds for one epoch ---
--- 1.587181568145752 seconds for one epoch ---
--- 0.29713964462280273 seconds for one epoch ---
--- 1.6112959384918213 seconds for one epoch ---
--- 0.3152647018432617 seconds for one epoch ---
--- 1.653050422668457 seconds for one epoch ---
--- 0.2978341579437256 seconds for one epoch ---
--- 1.6465072631835938 seconds for one epoch ---
--- 0.3290064334869385 seconds for one epoch ---
--- 1.6159403324127197 seconds for one epoch ---
--- 0.32552647590637207 seconds for one epoch ---
--- 1.6586413383483887 seconds for one epoch ---
--- 0.33172011375427246 seconds for one epoch ---
--- 1.6423425674438477 seconds for one epoch ---
--- 0.33773326873779297 seconds for one epoch ---
--- 1.6318154335021973 seconds for one epoch ---
--- 0.33020544052124023 seconds for one epoch ---
--- 1.6698684692382812 seconds for one epoch ---
--- 0.3351781368255615 seconds for one epoch ---
--- 1.6780269145965576 seconds for one epoch ---
--- 0.3387770652770996 seconds for one epoch ---
--- 1.6519355773925781 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.321245]
 [ -0.      ]]
--- 0.29537153244018555 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3517.6689453125, (1348.2292, 4.7997704, 2164.239, 0.40088612)
   validation loss 830.9597778320312, (543.4269, 0.31525448, 286.81677, 0.40088612)
decoder loss ratio: 21053.300757, decoder SINDy loss  ratio: 0.619134
--- 0.2647252082824707 seconds for one epoch ---
--- 0.29275035858154297 seconds for one epoch ---
--- 1.6488761901855469 seconds for one epoch ---
--- 0.30530524253845215 seconds for one epoch ---
--- 1.645125389099121 seconds for one epoch ---
--- 0.28284478187561035 seconds for one epoch ---
--- 1.6445741653442383 seconds for one epoch ---
--- 0.3070356845855713 seconds for one epoch ---
--- 1.6216139793395996 seconds for one epoch ---
--- 0.29524850845336914 seconds for one epoch ---
--- 1.675661563873291 seconds for one epoch ---
--- 0.30148935317993164 seconds for one epoch ---
--- 1.6459851264953613 seconds for one epoch ---
--- 0.2942206859588623 seconds for one epoch ---
--- 1.649310827255249 seconds for one epoch ---
--- 0.30092811584472656 seconds for one epoch ---
--- 1.6402685642242432 seconds for one epoch ---
--- 0.301816463470459 seconds for one epoch ---
--- 1.6037392616271973 seconds for one epoch ---
--- 0.3000462055206299 seconds for one epoch ---
--- 1.605506420135498 seconds for one epoch ---
--- 0.2864818572998047 seconds for one epoch ---
--- 1.6345398426055908 seconds for one epoch ---
--- 0.2993626594543457 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.3713665]
 [ -0.       ]]
--- 0.24457502365112305 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3752.54052734375, (1973.2856, 0.98251396, 1777.8702, 0.4020444)
   validation loss 780.4488525390625, (501.42282, 0.35976243, 278.26422, 0.4020444)
decoder loss ratio: 19425.990596, decoder SINDy loss  ratio: 0.600672
--- 0.29329419136047363 seconds for one epoch ---
--- 1.601501703262329 seconds for one epoch ---
--- 0.2885420322418213 seconds for one epoch ---
--- 1.6612505912780762 seconds for one epoch ---
--- 0.3046150207519531 seconds for one epoch ---
--- 1.6786212921142578 seconds for one epoch ---
--- 0.30528759956359863 seconds for one epoch ---
--- 1.6691267490386963 seconds for one epoch ---
--- 0.30344128608703613 seconds for one epoch ---
--- 1.6735656261444092 seconds for one epoch ---
--- 0.3005492687225342 seconds for one epoch ---
--- 1.6596972942352295 seconds for one epoch ---
--- 0.3138582706451416 seconds for one epoch ---
--- 1.6792488098144531 seconds for one epoch ---
--- 0.3111567497253418 seconds for one epoch ---
--- 1.6766297817230225 seconds for one epoch ---
--- 0.308826208114624 seconds for one epoch ---
--- 1.676978349685669 seconds for one epoch ---
--- 0.6363465785980225 seconds for one epoch ---
--- 1.6722168922424316 seconds for one epoch ---
--- 0.3176236152648926 seconds for one epoch ---
--- 1.6787395477294922 seconds for one epoch ---
--- 0.32755398750305176 seconds for one epoch ---
--- 1.6995303630828857 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.408757]
 [ -0.      ]]
--- 0.2878429889678955 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3303.80859375, (1138.8622, 2.2196167, 2162.324, 0.40284473)
   validation loss 1164.5513916015625, (834.1815, 0.34730387, 329.61975, 0.40284473)
decoder loss ratio: 32317.640232, decoder SINDy loss  ratio: 0.711531
--- 0.2657294273376465 seconds for one epoch ---
--- 0.30314159393310547 seconds for one epoch ---
--- 1.6463966369628906 seconds for one epoch ---
--- 0.29692745208740234 seconds for one epoch ---
--- 1.6720280647277832 seconds for one epoch ---
--- 0.2987823486328125 seconds for one epoch ---
--- 1.6595418453216553 seconds for one epoch ---
--- 0.3013017177581787 seconds for one epoch ---
--- 1.6820039749145508 seconds for one epoch ---
--- 0.30210137367248535 seconds for one epoch ---
--- 1.662461757659912 seconds for one epoch ---
--- 0.30406737327575684 seconds for one epoch ---
--- 1.6869862079620361 seconds for one epoch ---
--- 0.30851173400878906 seconds for one epoch ---
--- 1.6821911334991455 seconds for one epoch ---
--- 0.304884672164917 seconds for one epoch ---
--- 1.65903639793396 seconds for one epoch ---
--- 0.30527424812316895 seconds for one epoch ---
--- 1.7058625221252441 seconds for one epoch ---
--- 0.3105282783508301 seconds for one epoch ---
--- 1.7005064487457275 seconds for one epoch ---
--- 0.3328709602355957 seconds for one epoch ---
--- 1.6626348495483398 seconds for one epoch ---
--- 0.33107447624206543 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.458491]
 [ -0.      ]]
--- 0.25608348846435547 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2305.768798828125, (1165.5044, 3.200046, 1136.6603, 0.40393114)
   validation loss 727.2296142578125, (456.58224, 0.34035498, 269.90308, 0.40393114)
decoder loss ratio: 17688.788828, decoder SINDy loss  ratio: 0.582624
--- 0.2983095645904541 seconds for one epoch ---
--- 1.6916122436523438 seconds for one epoch ---
--- 0.2920498847961426 seconds for one epoch ---
--- 1.7026703357696533 seconds for one epoch ---
--- 0.293565034866333 seconds for one epoch ---
--- 1.7077770233154297 seconds for one epoch ---
--- 0.2948293685913086 seconds for one epoch ---
--- 1.6548471450805664 seconds for one epoch ---
--- 0.2954719066619873 seconds for one epoch ---
--- 1.6628434658050537 seconds for one epoch ---
--- 0.3100619316101074 seconds for one epoch ---
--- 1.6643917560577393 seconds for one epoch ---
--- 0.2894289493560791 seconds for one epoch ---
--- 1.6628143787384033 seconds for one epoch ---
--- 0.30237913131713867 seconds for one epoch ---
--- 1.6948127746582031 seconds for one epoch ---
--- 0.29734063148498535 seconds for one epoch ---
--- 1.6773173809051514 seconds for one epoch ---
--- 0.2953007221221924 seconds for one epoch ---
--- 1.6907925605773926 seconds for one epoch ---
--- 0.2907228469848633 seconds for one epoch ---
--- 1.6748073101043701 seconds for one epoch ---
--- 0.301239013671875 seconds for one epoch ---
--- 1.6684141159057617 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.488817]
 [ -0.      ]]
--- 0.27782511711120605 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2731.95654296875, (1162.8873, 0.86404014, 1567.8003, 0.40469295)
   validation loss 802.3682861328125, (529.24603, 0.35488048, 272.36273, 0.40469295)
decoder loss ratio: 20503.910119, decoder SINDy loss  ratio: 0.587933
THRESHOLDING: 1 active coefficients
--- 0.25861525535583496 seconds for one epoch ---
--- 0.3290228843688965 seconds for one epoch ---
--- 1.693319320678711 seconds for one epoch ---
--- 0.3394777774810791 seconds for one epoch ---
--- 1.7155303955078125 seconds for one epoch ---
--- 0.3341243267059326 seconds for one epoch ---
--- 1.6691725254058838 seconds for one epoch ---
--- 0.30779194831848145 seconds for one epoch ---
--- 1.6997957229614258 seconds for one epoch ---
--- 0.31261706352233887 seconds for one epoch ---
--- 1.681049108505249 seconds for one epoch ---
--- 0.3094179630279541 seconds for one epoch ---
--- 1.6684706211090088 seconds for one epoch ---
--- 0.2944803237915039 seconds for one epoch ---
--- 1.6919174194335938 seconds for one epoch ---
--- 0.29534435272216797 seconds for one epoch ---
--- 1.6861512660980225 seconds for one epoch ---
--- 0.30243682861328125 seconds for one epoch ---
--- 1.6215829849243164 seconds for one epoch ---
--- 0.2987029552459717 seconds for one epoch ---
--- 1.6339361667633057 seconds for one epoch ---
--- 0.2973790168762207 seconds for one epoch ---
--- 1.6294705867767334 seconds for one epoch ---
--- 0.2921485900878906 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.530293]
 [ -0.      ]]
--- 0.2714991569519043 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4220.02734375, (1315.8984, 0.4429954, 2903.28, 0.40558472)
   validation loss 841.490966796875, (570.80054, 0.41775092, 269.86713, 0.40558472)
decoder loss ratio: 22113.803761, decoder SINDy loss  ratio: 0.582546
--- 0.2981252670288086 seconds for one epoch ---
--- 1.6882402896881104 seconds for one epoch ---
--- 0.30358219146728516 seconds for one epoch ---
--- 1.6946327686309814 seconds for one epoch ---
--- 0.3042573928833008 seconds for one epoch ---
--- 1.6690261363983154 seconds for one epoch ---
--- 0.3032209873199463 seconds for one epoch ---
--- 1.68404221534729 seconds for one epoch ---
--- 0.30603742599487305 seconds for one epoch ---
--- 1.7031922340393066 seconds for one epoch ---
--- 0.3017706871032715 seconds for one epoch ---
--- 1.6875014305114746 seconds for one epoch ---
--- 0.2984285354614258 seconds for one epoch ---
--- 1.6674745082855225 seconds for one epoch ---
--- 0.28713059425354004 seconds for one epoch ---
--- 1.6481964588165283 seconds for one epoch ---
--- 0.29741978645324707 seconds for one epoch ---
--- 1.6578800678253174 seconds for one epoch ---
--- 0.3078346252441406 seconds for one epoch ---
--- 1.7307274341583252 seconds for one epoch ---
--- 0.29413437843322754 seconds for one epoch ---
--- 1.730668544769287 seconds for one epoch ---
--- 0.2912633419036865 seconds for one epoch ---
--- 1.7042663097381592 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.570459]
 [ -0.      ]]
--- 0.2961406707763672 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2533.06201171875, (979.0021, 0.915578, 1552.7378, 0.40655103)
   validation loss 818.5297241210938, (546.2706, 0.33116174, 271.52136, 0.40655103)
decoder loss ratio: 21163.472569, decoder SINDy loss  ratio: 0.586117
--- 0.26923561096191406 seconds for one epoch ---
--- 0.2943148612976074 seconds for one epoch ---
--- 1.701512336730957 seconds for one epoch ---
--- 0.30024051666259766 seconds for one epoch ---
--- 1.697655439376831 seconds for one epoch ---
--- 0.31031012535095215 seconds for one epoch ---
--- 1.7197554111480713 seconds for one epoch ---
--- 0.3035249710083008 seconds for one epoch ---
--- 1.7386858463287354 seconds for one epoch ---
--- 0.30596041679382324 seconds for one epoch ---
--- 1.6624836921691895 seconds for one epoch ---
--- 0.308666467666626 seconds for one epoch ---
--- 1.6722099781036377 seconds for one epoch ---
--- 0.30150580406188965 seconds for one epoch ---
--- 1.6815149784088135 seconds for one epoch ---
--- 0.30228614807128906 seconds for one epoch ---
--- 1.7226004600524902 seconds for one epoch ---
--- 0.3205695152282715 seconds for one epoch ---
--- 1.7416434288024902 seconds for one epoch ---
--- 0.29148006439208984 seconds for one epoch ---
--- 1.721653699874878 seconds for one epoch ---
--- 0.29721713066101074 seconds for one epoch ---
--- 1.7290167808532715 seconds for one epoch ---
--- 0.30057430267333984 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.607245]
 [ -0.      ]]
--- 0.2644221782684326 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4235.60498046875, (2307.6707, 0.6397026, 1926.8876, 0.40737325)
   validation loss 905.3690795898438, (629.0524, 0.3920079, 275.51727, 0.40737325)
decoder loss ratio: 24370.583190, decoder SINDy loss  ratio: 0.594743
--- 0.29141902923583984 seconds for one epoch ---
--- 1.7302639484405518 seconds for one epoch ---
--- 0.3004276752471924 seconds for one epoch ---
--- 1.747046709060669 seconds for one epoch ---
--- 0.31718993186950684 seconds for one epoch ---
--- 1.7078826427459717 seconds for one epoch ---
--- 0.31733083724975586 seconds for one epoch ---
--- 1.7158150672912598 seconds for one epoch ---
--- 0.3369472026824951 seconds for one epoch ---
--- 1.7197751998901367 seconds for one epoch ---
--- 0.3080410957336426 seconds for one epoch ---
--- 1.7291638851165771 seconds for one epoch ---
--- 0.3241755962371826 seconds for one epoch ---
--- 1.7411043643951416 seconds for one epoch ---
--- 0.33399367332458496 seconds for one epoch ---
--- 1.7271099090576172 seconds for one epoch ---
--- 0.3420376777648926 seconds for one epoch ---
--- 1.7682836055755615 seconds for one epoch ---
--- 0.329967737197876 seconds for one epoch ---
--- 1.7208070755004883 seconds for one epoch ---
--- 0.31851696968078613 seconds for one epoch ---
--- 1.7621347904205322 seconds for one epoch ---
--- 0.30052638053894043 seconds for one epoch ---
--- 1.7500419616699219 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.639992]
 [ -0.      ]]
--- 0.30211448669433594 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3624.196533203125, (1587.7218, 4.9894676, 2031.0771, 0.4080356)
   validation loss 747.8563842773438, (463.7319, 0.38127187, 283.33517, 0.4080356)
decoder loss ratio: 17965.778999, decoder SINDy loss  ratio: 0.611619
--- 0.26807403564453125 seconds for one epoch ---
--- 0.2823011875152588 seconds for one epoch ---
--- 1.7209692001342773 seconds for one epoch ---
--- 0.29816484451293945 seconds for one epoch ---
--- 1.7269237041473389 seconds for one epoch ---
--- 0.28922367095947266 seconds for one epoch ---
--- 1.727482557296753 seconds for one epoch ---
--- 0.30359649658203125 seconds for one epoch ---
--- 1.7402172088623047 seconds for one epoch ---
--- 0.29514312744140625 seconds for one epoch ---
--- 1.7254245281219482 seconds for one epoch ---
--- 0.3073146343231201 seconds for one epoch ---
--- 1.735210657119751 seconds for one epoch ---
--- 0.30501699447631836 seconds for one epoch ---
--- 1.7206928730010986 seconds for one epoch ---
--- 0.29714536666870117 seconds for one epoch ---
--- 1.7322311401367188 seconds for one epoch ---
--- 0.30220699310302734 seconds for one epoch ---
--- 1.7369270324707031 seconds for one epoch ---
--- 0.2980983257293701 seconds for one epoch ---
--- 1.7460577487945557 seconds for one epoch ---
--- 0.30510520935058594 seconds for one epoch ---
--- 1.753587245941162 seconds for one epoch ---
--- 0.30227112770080566 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.68617]
 [ -0.     ]]
--- 0.2609224319458008 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2978.8125, (1431.5345, 1.2392553, 1545.6295, 0.40920553)
   validation loss 1051.4500732421875, (742.61615, 0.2935428, 308.13126, 0.40920553)
decoder loss ratio: 28770.238886, decoder SINDy loss  ratio: 0.665145
--- 0.30690526962280273 seconds for one epoch ---
--- 1.7492146492004395 seconds for one epoch ---
--- 0.2992241382598877 seconds for one epoch ---
--- 1.7544898986816406 seconds for one epoch ---
--- 0.29964327812194824 seconds for one epoch ---
--- 1.7289996147155762 seconds for one epoch ---
--- 0.2865622043609619 seconds for one epoch ---
--- 1.7606830596923828 seconds for one epoch ---
--- 0.3034353256225586 seconds for one epoch ---
--- 1.7361822128295898 seconds for one epoch ---
--- 0.30182528495788574 seconds for one epoch ---
--- 1.7780721187591553 seconds for one epoch ---
--- 0.2915468215942383 seconds for one epoch ---
--- 1.7533323764801025 seconds for one epoch ---
--- 0.3098323345184326 seconds for one epoch ---
--- 1.7467916011810303 seconds for one epoch ---
--- 0.30022096633911133 seconds for one epoch ---
--- 1.7625007629394531 seconds for one epoch ---
--- 0.2985193729400635 seconds for one epoch ---
--- 1.764510154724121 seconds for one epoch ---
--- 0.3087582588195801 seconds for one epoch ---
--- 1.7624030113220215 seconds for one epoch ---
--- 0.3113210201263428 seconds for one epoch ---
--- 1.765773057937622 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-15.72099]
 [ -0.     ]]
--- 0.28443408012390137 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2902.642578125, (1492.2235, 0.7526105, 1409.2566, 0.4099474)
   validation loss 869.4431762695312, (585.1852, 0.30316663, 283.54483, 0.4099474)
decoder loss ratio: 22671.089825, decoder SINDy loss  ratio: 0.612071
--- 0.25644922256469727 seconds for one epoch ---
--- 0.30205750465393066 seconds for one epoch ---
--- 1.7786026000976562 seconds for one epoch ---
--- 0.3013167381286621 seconds for one epoch ---
--- 1.7696797847747803 seconds for one epoch ---
--- 0.30152249336242676 seconds for one epoch ---
--- 1.756392478942871 seconds for one epoch ---
--- 0.302689790725708 seconds for one epoch ---
--- 1.758530616760254 seconds for one epoch ---
--- 0.2876420021057129 seconds for one epoch ---
--- 1.7795310020446777 seconds for one epoch ---
--- 0.3066396713256836 seconds for one epoch ---
--- 1.75874662399292 seconds for one epoch ---
--- 0.28879237174987793 seconds for one epoch ---
--- 1.769690752029419 seconds for one epoch ---
--- 0.30484986305236816 seconds for one epoch ---
--- 1.7354395389556885 seconds for one epoch ---
--- 0.2964940071105957 seconds for one epoch ---
--- 1.782435417175293 seconds for one epoch ---
--- 0.301159143447876 seconds for one epoch ---
--- 1.766247034072876 seconds for one epoch ---
--- 0.3010730743408203 seconds for one epoch ---
--- 1.7700669765472412 seconds for one epoch ---
--- 0.3000020980834961 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.745267]
 [ -0.      ]]
--- 0.2645256519317627 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3767.27197265625, (1846.5789, 1.8728298, 1918.4099, 0.41045138)
   validation loss 922.660888671875, (650.34845, 0.39120874, 271.51074, 0.41045138)
decoder loss ratio: 25195.627996, decoder SINDy loss  ratio: 0.586094
--- 0.33104658126831055 seconds for one epoch ---
--- 1.7692022323608398 seconds for one epoch ---
--- 0.32515573501586914 seconds for one epoch ---
--- 1.7425317764282227 seconds for one epoch ---
--- 0.3346436023712158 seconds for one epoch ---
--- 1.7862892150878906 seconds for one epoch ---
--- 0.3206353187561035 seconds for one epoch ---
--- 1.752429485321045 seconds for one epoch ---
--- 0.33718204498291016 seconds for one epoch ---
--- 1.7864313125610352 seconds for one epoch ---
--- 0.3355264663696289 seconds for one epoch ---
--- 1.779773473739624 seconds for one epoch ---
--- 0.34957432746887207 seconds for one epoch ---
--- 1.7708568572998047 seconds for one epoch ---
--- 0.3250429630279541 seconds for one epoch ---
--- 1.7930214405059814 seconds for one epoch ---
--- 0.3056356906890869 seconds for one epoch ---
--- 1.7724223136901855 seconds for one epoch ---
--- 0.3042786121368408 seconds for one epoch ---
--- 1.7748684883117676 seconds for one epoch ---
--- 0.31713390350341797 seconds for one epoch ---
--- 1.7713680267333984 seconds for one epoch ---
--- 0.2964479923248291 seconds for one epoch ---
--- 1.7572593688964844 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.780603]
 [ -0.      ]]
--- 0.3069314956665039 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2760.69384765625, (1009.48694, 2.5023458, 1748.2932, 0.41131863)
   validation loss 841.6577758789062, (557.86896, 0.3871128, 282.9904, 0.41131863)
decoder loss ratio: 21612.811917, decoder SINDy loss  ratio: 0.610875
--- 0.27683353424072266 seconds for one epoch ---
--- 0.3303654193878174 seconds for one epoch ---
--- 1.7991979122161865 seconds for one epoch ---
--- 0.32195472717285156 seconds for one epoch ---
--- 1.7676923274993896 seconds for one epoch ---
--- 0.33580660820007324 seconds for one epoch ---
--- 1.7446532249450684 seconds for one epoch ---
--- 0.3444960117340088 seconds for one epoch ---
--- 1.775726556777954 seconds for one epoch ---
--- 0.34302735328674316 seconds for one epoch ---
--- 1.799748420715332 seconds for one epoch ---
--- 0.3474915027618408 seconds for one epoch ---
--- 1.7687475681304932 seconds for one epoch ---
--- 0.35094761848449707 seconds for one epoch ---
--- 1.7747230529785156 seconds for one epoch ---
--- 0.3361847400665283 seconds for one epoch ---
--- 1.775083303451538 seconds for one epoch ---
--- 0.302717924118042 seconds for one epoch ---
--- 1.778273105621338 seconds for one epoch ---
--- 0.29583072662353516 seconds for one epoch ---
--- 1.778038501739502 seconds for one epoch ---
--- 0.29851508140563965 seconds for one epoch ---
--- 1.7748923301696777 seconds for one epoch ---
--- 0.30539917945861816 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.819783]
 [ -0.      ]]
--- 0.2576425075531006 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1947.157470703125, (863.8575, 6.8994694, 1075.9883, 0.41218773)
   validation loss 778.6371459960938, (500.92917, 0.37112674, 276.92465, 0.41218773)
decoder loss ratio: 19406.865647, decoder SINDy loss  ratio: 0.597781
--- 0.30037736892700195 seconds for one epoch ---
--- 1.7894294261932373 seconds for one epoch ---
--- 0.3152048587799072 seconds for one epoch ---
--- 1.8110342025756836 seconds for one epoch ---
--- 0.3110945224761963 seconds for one epoch ---
--- 1.785846471786499 seconds for one epoch ---
--- 0.3013732433319092 seconds for one epoch ---
--- 1.7661080360412598 seconds for one epoch ---
--- 0.2938103675842285 seconds for one epoch ---
--- 1.7959632873535156 seconds for one epoch ---
--- 0.3123316764831543 seconds for one epoch ---
--- 1.78444504737854 seconds for one epoch ---
--- 0.31021976470947266 seconds for one epoch ---
--- 1.7907142639160156 seconds for one epoch ---
--- 0.3029792308807373 seconds for one epoch ---
--- 1.8156731128692627 seconds for one epoch ---
--- 0.3065371513366699 seconds for one epoch ---
--- 1.8006794452667236 seconds for one epoch ---
--- 0.2956717014312744 seconds for one epoch ---
--- 1.8020811080932617 seconds for one epoch ---
--- 0.3044590950012207 seconds for one epoch ---
--- 1.7949378490447998 seconds for one epoch ---
--- 0.300708532333374 seconds for one epoch ---
--- 1.7968239784240723 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.857223]
 [ -0.      ]]
--- 0.29421162605285645 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2379.38232421875, (984.30347, 1.5820428, 1393.0836, 0.41304174)
   validation loss 1023.5110473632812, (718.238, 0.37076983, 304.48923, 0.41304174)
decoder loss ratio: 27825.786109, decoder SINDy loss  ratio: 0.657283
--- 0.26166391372680664 seconds for one epoch ---
--- 0.2908008098602295 seconds for one epoch ---
--- 1.8118784427642822 seconds for one epoch ---
--- 0.3031332492828369 seconds for one epoch ---
--- 1.7937824726104736 seconds for one epoch ---
--- 0.30872154235839844 seconds for one epoch ---
--- 1.8403408527374268 seconds for one epoch ---
--- 0.31569743156433105 seconds for one epoch ---
--- 1.7988841533660889 seconds for one epoch ---
--- 0.3142683506011963 seconds for one epoch ---
--- 1.8313374519348145 seconds for one epoch ---
--- 0.3123347759246826 seconds for one epoch ---
--- 1.7864651679992676 seconds for one epoch ---
--- 0.321990966796875 seconds for one epoch ---
--- 1.7843372821807861 seconds for one epoch ---
--- 0.3238682746887207 seconds for one epoch ---
--- 1.7947399616241455 seconds for one epoch ---
--- 0.29303979873657227 seconds for one epoch ---
--- 1.8069915771484375 seconds for one epoch ---
--- 0.29694437980651855 seconds for one epoch ---
--- 1.8064663410186768 seconds for one epoch ---
--- 0.30879783630371094 seconds for one epoch ---
--- 1.8057925701141357 seconds for one epoch ---
--- 0.30564260482788086 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.8770275]
 [ -0.       ]]
--- 0.26026415824890137 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6780.33642578125, (1691.729, 0.49576023, 5087.698, 0.41348672)
   validation loss 749.4983520507812, (478.52023, 0.36053684, 270.20407, 0.41348672)
decoder loss ratio: 18538.704580, decoder SINDy loss  ratio: 0.583273
--- 0.29679036140441895 seconds for one epoch ---
--- 1.8051319122314453 seconds for one epoch ---
--- 0.3003222942352295 seconds for one epoch ---
--- 1.832533597946167 seconds for one epoch ---
--- 0.2885253429412842 seconds for one epoch ---
--- 1.8054234981536865 seconds for one epoch ---
--- 0.2821345329284668 seconds for one epoch ---
--- 1.83577561378479 seconds for one epoch ---
--- 0.3083515167236328 seconds for one epoch ---
--- 1.8206639289855957 seconds for one epoch ---
--- 0.31070780754089355 seconds for one epoch ---
--- 1.8112199306488037 seconds for one epoch ---
--- 0.3145174980163574 seconds for one epoch ---
--- 1.8268966674804688 seconds for one epoch ---
--- 0.30250024795532227 seconds for one epoch ---
--- 1.8230409622192383 seconds for one epoch ---
--- 0.3208181858062744 seconds for one epoch ---
--- 1.8177416324615479 seconds for one epoch ---
--- 0.3008115291595459 seconds for one epoch ---
--- 1.81205415725708 seconds for one epoch ---
--- 0.2910795211791992 seconds for one epoch ---
--- 1.8014380931854248 seconds for one epoch ---
--- 0.2801859378814697 seconds for one epoch ---
--- 1.8003933429718018 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.909358]
 [ -0.      ]]
--- 0.29469799995422363 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2835.161865234375, (1213.6198, 0.6869334, 1620.441, 0.4142495)
   validation loss 769.91650390625, (506.61874, 0.35891235, 262.5246, 0.4142495)
decoder loss ratio: 19627.289667, decoder SINDy loss  ratio: 0.566696
--- 0.26289916038513184 seconds for one epoch ---
--- 0.3040964603424072 seconds for one epoch ---
--- 1.8049185276031494 seconds for one epoch ---
--- 0.3038492202758789 seconds for one epoch ---
--- 1.8455827236175537 seconds for one epoch ---
--- 0.2858407497406006 seconds for one epoch ---
--- 1.8126423358917236 seconds for one epoch ---
--- 0.3007664680480957 seconds for one epoch ---
--- 1.8262338638305664 seconds for one epoch ---
--- 0.30049657821655273 seconds for one epoch ---
--- 1.8275468349456787 seconds for one epoch ---
--- 0.30721497535705566 seconds for one epoch ---
--- 1.8379971981048584 seconds for one epoch ---
--- 0.29772448539733887 seconds for one epoch ---
--- 1.8499398231506348 seconds for one epoch ---
--- 0.3069167137145996 seconds for one epoch ---
--- 1.880617380142212 seconds for one epoch ---
--- 0.301804780960083 seconds for one epoch ---
--- 1.8175888061523438 seconds for one epoch ---
--- 0.29923248291015625 seconds for one epoch ---
--- 1.8314564228057861 seconds for one epoch ---
--- 0.298720121383667 seconds for one epoch ---
--- 1.8283793926239014 seconds for one epoch ---
--- 0.2927968502044678 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.947623]
 [ -0.      ]]
--- 0.26360368728637695 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2286.371826171875, (991.34576, 2.5599475, 1292.051, 0.41515064)
   validation loss 763.12451171875, (484.96848, 0.33408526, 277.4068, 0.41515064)
decoder loss ratio: 18788.520677, decoder SINDy loss  ratio: 0.598822
--- 0.30912280082702637 seconds for one epoch ---
--- 1.8463144302368164 seconds for one epoch ---
--- 0.3056163787841797 seconds for one epoch ---
--- 1.8656036853790283 seconds for one epoch ---
--- 0.28417158126831055 seconds for one epoch ---
--- 1.8778085708618164 seconds for one epoch ---
--- 0.3042433261871338 seconds for one epoch ---
--- 1.8608424663543701 seconds for one epoch ---
--- 0.3041074275970459 seconds for one epoch ---
--- 1.8604731559753418 seconds for one epoch ---
--- 0.3098316192626953 seconds for one epoch ---
--- 1.8472974300384521 seconds for one epoch ---
--- 0.3078577518463135 seconds for one epoch ---
--- 1.8432202339172363 seconds for one epoch ---
--- 0.32401156425476074 seconds for one epoch ---
--- 1.8517546653747559 seconds for one epoch ---
--- 0.31897664070129395 seconds for one epoch ---
--- 1.8248767852783203 seconds for one epoch ---
--- 0.298306941986084 seconds for one epoch ---
--- 1.8439412117004395 seconds for one epoch ---
--- 0.30072736740112305 seconds for one epoch ---
--- 1.8463735580444336 seconds for one epoch ---
--- 0.2984600067138672 seconds for one epoch ---
--- 1.819256067276001 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.977775]
 [ -0.      ]]
--- 0.2983520030975342 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2976.334228515625, (1222.1799, 2.43506, 1751.3036, 0.41583395)
   validation loss 805.3265991210938, (516.67474, 0.3893034, 287.84677, 0.41583395)
decoder loss ratio: 20016.876556, decoder SINDy loss  ratio: 0.621358
--- 0.2641727924346924 seconds for one epoch ---
--- 0.3006594181060791 seconds for one epoch ---
--- 1.8517823219299316 seconds for one epoch ---
--- 0.2937636375427246 seconds for one epoch ---
--- 1.8503046035766602 seconds for one epoch ---
--- 0.3019592761993408 seconds for one epoch ---
--- 1.8663005828857422 seconds for one epoch ---
--- 0.30910277366638184 seconds for one epoch ---
--- 1.8207917213439941 seconds for one epoch ---
--- 0.31043529510498047 seconds for one epoch ---
--- 1.8633272647857666 seconds for one epoch ---
--- 0.30442309379577637 seconds for one epoch ---
--- 1.8683698177337646 seconds for one epoch ---
--- 0.3088061809539795 seconds for one epoch ---
--- 1.8697314262390137 seconds for one epoch ---
--- 0.3098878860473633 seconds for one epoch ---
--- 1.8543319702148438 seconds for one epoch ---
--- 0.30404019355773926 seconds for one epoch ---
--- 1.877553939819336 seconds for one epoch ---
--- 0.30590343475341797 seconds for one epoch ---
--- 1.8346121311187744 seconds for one epoch ---
--- 0.29975414276123047 seconds for one epoch ---
--- 1.8434362411499023 seconds for one epoch ---
--- 0.29979801177978516 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.01101]
 [ -0.     ]]
--- 0.26488399505615234 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3559.88134765625, (1354.9526, 1.6670213, 2202.845, 0.41665173)
   validation loss 734.0360107421875, (449.29333, 0.2971115, 284.02893, 0.41665173)
decoder loss ratio: 17406.403804, decoder SINDy loss  ratio: 0.613116
--- 0.29955625534057617 seconds for one epoch ---
--- 1.8599908351898193 seconds for one epoch ---
--- 0.2938990592956543 seconds for one epoch ---
--- 1.8646996021270752 seconds for one epoch ---
--- 0.2865486145019531 seconds for one epoch ---
--- 1.8454914093017578 seconds for one epoch ---
--- 0.30943942070007324 seconds for one epoch ---
--- 1.8468561172485352 seconds for one epoch ---
--- 0.30496644973754883 seconds for one epoch ---
--- 1.835752010345459 seconds for one epoch ---
--- 0.30118775367736816 seconds for one epoch ---
--- 1.8470337390899658 seconds for one epoch ---
--- 0.30001068115234375 seconds for one epoch ---
--- 1.8891713619232178 seconds for one epoch ---
--- 0.3044703006744385 seconds for one epoch ---
--- 1.863346815109253 seconds for one epoch ---
--- 0.3001227378845215 seconds for one epoch ---
--- 1.8974320888519287 seconds for one epoch ---
--- 0.30295705795288086 seconds for one epoch ---
--- 1.9119668006896973 seconds for one epoch ---
--- 0.3034977912902832 seconds for one epoch ---
--- 1.8898015022277832 seconds for one epoch ---
--- 0.3107128143310547 seconds for one epoch ---
--- 1.8688466548919678 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.042068]
 [ -0.      ]]
--- 0.2940664291381836 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1982.569580078125, (1536.8943, 0.38250127, 444.87564, 0.41728956)
   validation loss 790.427978515625, (497.68622, 0.30524102, 292.01923, 0.41728956)
decoder loss ratio: 19281.228117, decoder SINDy loss  ratio: 0.630365
--- 0.26809239387512207 seconds for one epoch ---
--- 0.30741047859191895 seconds for one epoch ---
--- 1.8540973663330078 seconds for one epoch ---
--- 0.29099512100219727 seconds for one epoch ---
--- 1.8666954040527344 seconds for one epoch ---
--- 0.30272579193115234 seconds for one epoch ---
--- 1.8649146556854248 seconds for one epoch ---
--- 0.2991142272949219 seconds for one epoch ---
--- 1.8436737060546875 seconds for one epoch ---
--- 0.30397629737854004 seconds for one epoch ---
--- 1.874243974685669 seconds for one epoch ---
--- 0.3089566230773926 seconds for one epoch ---
--- 1.866039752960205 seconds for one epoch ---
--- 0.30137038230895996 seconds for one epoch ---
--- 1.8735525608062744 seconds for one epoch ---
--- 0.3009178638458252 seconds for one epoch ---
--- 1.9007940292358398 seconds for one epoch ---
--- 0.303633451461792 seconds for one epoch ---
--- 1.877044677734375 seconds for one epoch ---
--- 0.3059244155883789 seconds for one epoch ---
--- 1.8920938968658447 seconds for one epoch ---
--- 0.30698657035827637 seconds for one epoch ---
--- 1.8958981037139893 seconds for one epoch ---
--- 0.30559754371643066 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.066278]
 [ -0.      ]]
--- 0.2810404300689697 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2089.54638671875, (910.74536, 1.8665982, 1176.5164, 0.4178836)
   validation loss 737.8756103515625, (472.43134, 0.38029426, 264.6461, 0.4178836)
decoder loss ratio: 18302.810112, decoder SINDy loss  ratio: 0.571276
--- 0.310375452041626 seconds for one epoch ---
--- 1.894129991531372 seconds for one epoch ---
--- 0.3055891990661621 seconds for one epoch ---
--- 1.908689260482788 seconds for one epoch ---
--- 0.30455923080444336 seconds for one epoch ---
--- 1.9229588508605957 seconds for one epoch ---
--- 0.30452656745910645 seconds for one epoch ---
--- 1.8954408168792725 seconds for one epoch ---
--- 0.2984583377838135 seconds for one epoch ---
--- 1.8839538097381592 seconds for one epoch ---
--- 0.3028535842895508 seconds for one epoch ---
--- 1.8911981582641602 seconds for one epoch ---
--- 0.29986572265625 seconds for one epoch ---
--- 1.8679850101470947 seconds for one epoch ---
--- 0.30873894691467285 seconds for one epoch ---
--- 1.8627946376800537 seconds for one epoch ---
--- 0.30426692962646484 seconds for one epoch ---
--- 1.8783249855041504 seconds for one epoch ---
--- 0.2933924198150635 seconds for one epoch ---
--- 1.885024070739746 seconds for one epoch ---
--- 0.29797863960266113 seconds for one epoch ---
--- 1.8693928718566895 seconds for one epoch ---
--- 0.3008124828338623 seconds for one epoch ---
--- 1.9048535823822021 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.08723]
 [ -0.     ]]
--- 0.3262603282928467 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4408.81103515625, (2221.1763, 2.373795, 2184.8428, 0.41838652)
   validation loss 886.5588989257812, (576.0178, 0.38507435, 309.7376, 0.41838652)
decoder loss ratio: 22315.930445, decoder SINDy loss  ratio: 0.668612
--- 0.29457902908325195 seconds for one epoch ---
--- 0.3337256908416748 seconds for one epoch ---
--- 1.8681104183197021 seconds for one epoch ---
--- 0.3315918445587158 seconds for one epoch ---
--- 1.9163484573364258 seconds for one epoch ---
--- 0.3352053165435791 seconds for one epoch ---
--- 1.9063396453857422 seconds for one epoch ---
--- 0.3126068115234375 seconds for one epoch ---
--- 1.9037370681762695 seconds for one epoch ---
--- 0.3334782123565674 seconds for one epoch ---
--- 1.9389808177947998 seconds for one epoch ---
--- 0.3186173439025879 seconds for one epoch ---
--- 1.9311058521270752 seconds for one epoch ---
--- 0.3237028121948242 seconds for one epoch ---
--- 1.8924806118011475 seconds for one epoch ---
--- 0.28797316551208496 seconds for one epoch ---
--- 1.8935260772705078 seconds for one epoch ---
--- 0.30016422271728516 seconds for one epoch ---
--- 1.888990879058838 seconds for one epoch ---
--- 0.3061373233795166 seconds for one epoch ---
--- 1.8961529731750488 seconds for one epoch ---
--- 0.3013174533843994 seconds for one epoch ---
--- 1.8976507186889648 seconds for one epoch ---
--- 0.29818010330200195 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.105814]
 [ -0.      ]]
--- 0.2667524814605713 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2371.981689453125, (1768.7488, 0.4205785, 602.3937, 0.41881552)
   validation loss 780.1858520507812, (490.75305, 0.35705978, 288.65692, 0.41881552)
decoder loss ratio: 19012.625210, decoder SINDy loss  ratio: 0.623107
--- 0.3306424617767334 seconds for one epoch ---
--- 1.9164397716522217 seconds for one epoch ---
--- 0.32274293899536133 seconds for one epoch ---
--- 1.9029600620269775 seconds for one epoch ---
--- 0.33048367500305176 seconds for one epoch ---
--- 1.879854440689087 seconds for one epoch ---
--- 0.314119815826416 seconds for one epoch ---
--- 1.941269874572754 seconds for one epoch ---
--- 0.3336677551269531 seconds for one epoch ---
--- 1.887331485748291 seconds for one epoch ---
--- 0.33037805557250977 seconds for one epoch ---
--- 1.8929352760314941 seconds for one epoch ---
--- 0.3223273754119873 seconds for one epoch ---
--- 1.8859589099884033 seconds for one epoch ---
--- 0.32720279693603516 seconds for one epoch ---
--- 1.9420523643493652 seconds for one epoch ---
--- 0.2963125705718994 seconds for one epoch ---
--- 1.9271206855773926 seconds for one epoch ---
--- 0.29805421829223633 seconds for one epoch ---
--- 1.9258532524108887 seconds for one epoch ---
--- 0.30945587158203125 seconds for one epoch ---
--- 1.9362983703613281 seconds for one epoch ---
--- 0.2986593246459961 seconds for one epoch ---
--- 1.971482276916504 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.127893]
 [ -0.      ]]
--- 0.28604984283447266 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2084.56884765625, (856.22003, 2.2296607, 1225.6998, 0.4193829)
   validation loss 811.029052734375, (533.6444, 0.40313247, 276.56213, 0.4193829)
decoder loss ratio: 20674.310859, decoder SINDy loss  ratio: 0.596998
THRESHOLDING: 1 active coefficients
--- 1.9063196182250977 seconds for one epoch ---
--- 0.30506062507629395 seconds for one epoch ---
--- 1.951716423034668 seconds for one epoch ---
--- 0.30114293098449707 seconds for one epoch ---
--- 1.8952240943908691 seconds for one epoch ---
--- 0.29872584342956543 seconds for one epoch ---
--- 1.885193109512329 seconds for one epoch ---
--- 0.304459810256958 seconds for one epoch ---
--- 1.883448839187622 seconds for one epoch ---
--- 0.3092522621154785 seconds for one epoch ---
--- 1.9289414882659912 seconds for one epoch ---
--- 0.3065319061279297 seconds for one epoch ---
--- 1.9259312152862549 seconds for one epoch ---
--- 0.31656455993652344 seconds for one epoch ---
--- 1.9565308094024658 seconds for one epoch ---
--- 0.3312711715698242 seconds for one epoch ---
--- 1.935283899307251 seconds for one epoch ---
--- 0.31113743782043457 seconds for one epoch ---
--- 1.9149303436279297 seconds for one epoch ---
--- 0.3102295398712158 seconds for one epoch ---
--- 1.9346113204956055 seconds for one epoch ---
--- 0.30933117866516113 seconds for one epoch ---
--- 1.943598985671997 seconds for one epoch ---
--- 0.31331610679626465 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.148632]
 [ -0.      ]]
--- 0.2555360794067383 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3294.51171875, (1392.087, 0.5840109, 1901.4207, 0.41983494)
   validation loss 725.2427368164062, (438.15082, 0.32823786, 286.3438, 0.41983494)
decoder loss ratio: 16974.723348, decoder SINDy loss  ratio: 0.618113
--- 0.29843592643737793 seconds for one epoch ---
--- 1.9109034538269043 seconds for one epoch ---
--- 0.29697394371032715 seconds for one epoch ---
--- 1.9252126216888428 seconds for one epoch ---
--- 0.30224061012268066 seconds for one epoch ---
--- 1.9444408416748047 seconds for one epoch ---
--- 0.3064742088317871 seconds for one epoch ---
--- 1.9371380805969238 seconds for one epoch ---
--- 0.298001766204834 seconds for one epoch ---
--- 1.988312005996704 seconds for one epoch ---
--- 0.2974710464477539 seconds for one epoch ---
--- 1.9636149406433105 seconds for one epoch ---
--- 0.2834928035736084 seconds for one epoch ---
--- 1.9446702003479004 seconds for one epoch ---
--- 0.29605865478515625 seconds for one epoch ---
--- 1.9675920009613037 seconds for one epoch ---
--- 0.2932858467102051 seconds for one epoch ---
--- 1.9692871570587158 seconds for one epoch ---
--- 0.3047518730163574 seconds for one epoch ---
--- 1.94162917137146 seconds for one epoch ---
--- 0.3114290237426758 seconds for one epoch ---
--- 1.9792819023132324 seconds for one epoch ---
--- 0.3197312355041504 seconds for one epoch ---
--- 1.941969871520996 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.180202]
 [ -0.      ]]
--- 0.3015291690826416 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2415.598388671875, (1162.5936, 4.183871, 1248.4003, 0.42058015)
   validation loss 990.2973022460938, (672.7736, 0.33935878, 316.7637, 0.42058015)
decoder loss ratio: 26064.418049, decoder SINDy loss  ratio: 0.683779
--- 0.26462483406066895 seconds for one epoch ---
--- 0.30011558532714844 seconds for one epoch ---
--- 1.9489986896514893 seconds for one epoch ---
--- 0.32040953636169434 seconds for one epoch ---
--- 1.9765353202819824 seconds for one epoch ---
--- 0.31114673614501953 seconds for one epoch ---
--- 1.9764652252197266 seconds for one epoch ---
--- 0.3012278079986572 seconds for one epoch ---
--- 1.9801130294799805 seconds for one epoch ---
--- 0.2980842590332031 seconds for one epoch ---
--- 1.9720370769500732 seconds for one epoch ---
--- 0.3119065761566162 seconds for one epoch ---
--- 1.9752192497253418 seconds for one epoch ---
--- 0.3094346523284912 seconds for one epoch ---
--- 1.9926087856292725 seconds for one epoch ---
--- 0.30937838554382324 seconds for one epoch ---
--- 2.0053517818450928 seconds for one epoch ---
--- 0.29878735542297363 seconds for one epoch ---
--- 1.983020544052124 seconds for one epoch ---
--- 0.29236340522766113 seconds for one epoch ---
--- 1.983943223953247 seconds for one epoch ---
--- 0.2866530418395996 seconds for one epoch ---
--- 1.9368066787719727 seconds for one epoch ---
--- 0.30745482444763184 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.20976]
 [ -0.     ]]
--- 0.26953840255737305 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3523.302001953125, (2098.241, 0.876199, 1423.7637, 0.42125636)
   validation loss 824.35400390625, (506.16913, 0.37576672, 317.38782, 0.42125636)
decoder loss ratio: 19609.870783, decoder SINDy loss  ratio: 0.685126
--- 0.3191640377044678 seconds for one epoch ---
--- 2.00846791267395 seconds for one epoch ---
--- 0.3304619789123535 seconds for one epoch ---
--- 2.0326831340789795 seconds for one epoch ---
--- 0.34180283546447754 seconds for one epoch ---
--- 1.9921419620513916 seconds for one epoch ---
--- 0.33563876152038574 seconds for one epoch ---
--- 2.0156166553497314 seconds for one epoch ---
--- 0.2999687194824219 seconds for one epoch ---
--- 2.0252647399902344 seconds for one epoch ---
--- 0.29836440086364746 seconds for one epoch ---
--- 1.9946637153625488 seconds for one epoch ---
--- 0.30156922340393066 seconds for one epoch ---
--- 1.9774456024169922 seconds for one epoch ---
--- 0.3055989742279053 seconds for one epoch ---
--- 1.998824119567871 seconds for one epoch ---
--- 0.29653239250183105 seconds for one epoch ---
--- 2.0152041912078857 seconds for one epoch ---
--- 0.30045509338378906 seconds for one epoch ---
--- 1.9889004230499268 seconds for one epoch ---
--- 0.2883789539337158 seconds for one epoch ---
--- 1.9481701850891113 seconds for one epoch ---
--- 0.30553269386291504 seconds for one epoch ---
--- 1.966909646987915 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.231308]
 [ -0.      ]]
--- 0.3059525489807129 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3758.1064453125, (1394.1173, 0.65967405, 2362.9075, 0.42178082)
   validation loss 810.1998291015625, (518.9054, 0.32956785, 290.54306, 0.42178082)
decoder loss ratio: 20103.295881, decoder SINDy loss  ratio: 0.627178
--- 0.2727549076080322 seconds for one epoch ---
--- 0.30450940132141113 seconds for one epoch ---
--- 1.9735329151153564 seconds for one epoch ---
--- 0.3034365177154541 seconds for one epoch ---
--- 2.001776933670044 seconds for one epoch ---
--- 0.3004612922668457 seconds for one epoch ---
--- 1.9845459461212158 seconds for one epoch ---
--- 0.30019664764404297 seconds for one epoch ---
--- 1.9917497634887695 seconds for one epoch ---
--- 0.3072538375854492 seconds for one epoch ---
--- 2.0148367881774902 seconds for one epoch ---
--- 0.30151987075805664 seconds for one epoch ---
--- 1.995713472366333 seconds for one epoch ---
--- 0.2977256774902344 seconds for one epoch ---
--- 2.006171464920044 seconds for one epoch ---
--- 0.3038022518157959 seconds for one epoch ---
--- 2.023702383041382 seconds for one epoch ---
--- 0.310366153717041 seconds for one epoch ---
--- 2.0015995502471924 seconds for one epoch ---
--- 0.30071425437927246 seconds for one epoch ---
--- 1.9648497104644775 seconds for one epoch ---
--- 0.30338406562805176 seconds for one epoch ---
--- 1.9742686748504639 seconds for one epoch ---
--- 0.29792261123657227 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.254898]
 [ -0.      ]]
--- 0.25819993019104004 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6072.45751953125, (2029.3147, 2.1548321, 4040.5657, 0.42230645)
   validation loss 706.1459350585938, (430.53223, 0.3076576, 274.88376, 0.42230645)
decoder loss ratio: 16679.565894, decoder SINDy loss  ratio: 0.593375
--- 0.2949247360229492 seconds for one epoch ---
--- 2.016592502593994 seconds for one epoch ---
--- 0.3026554584503174 seconds for one epoch ---
--- 1.9993159770965576 seconds for one epoch ---
--- 0.30254316329956055 seconds for one epoch ---
--- 2.0050718784332275 seconds for one epoch ---
--- 0.30333447456359863 seconds for one epoch ---
--- 2.0104689598083496 seconds for one epoch ---
--- 0.29953861236572266 seconds for one epoch ---
--- 2.036360740661621 seconds for one epoch ---
--- 0.29843950271606445 seconds for one epoch ---
--- 2.0054397583007812 seconds for one epoch ---
--- 0.30815744400024414 seconds for one epoch ---
--- 2.0415568351745605 seconds for one epoch ---
--- 0.31308579444885254 seconds for one epoch ---
--- 2.0406885147094727 seconds for one epoch ---
--- 0.30305051803588867 seconds for one epoch ---
--- 1.9640209674835205 seconds for one epoch ---
--- 0.3021712303161621 seconds for one epoch ---
--- 1.9964895248413086 seconds for one epoch ---
--- 0.29120922088623047 seconds for one epoch ---
--- 1.9767074584960938 seconds for one epoch ---
--- 0.3032107353210449 seconds for one epoch ---
--- 1.9811651706695557 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.276253]
 [ -0.      ]]
--- 0.30456089973449707 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3599.077392578125, (1645.4955, 0.50889176, 1952.6501, 0.42285034)
   validation loss 746.6654663085938, (472.59457, 0.289328, 273.3587, 0.42285034)
decoder loss ratio: 18309.134256, decoder SINDy loss  ratio: 0.590083
--- 0.2758805751800537 seconds for one epoch ---
--- 0.30024003982543945 seconds for one epoch ---
--- 1.9834916591644287 seconds for one epoch ---
--- 0.3023974895477295 seconds for one epoch ---
--- 2.0008745193481445 seconds for one epoch ---
--- 0.2975304126739502 seconds for one epoch ---
--- 1.986914873123169 seconds for one epoch ---
--- 0.2964191436767578 seconds for one epoch ---
--- 1.9762868881225586 seconds for one epoch ---
--- 0.2896602153778076 seconds for one epoch ---
--- 1.9910318851470947 seconds for one epoch ---
--- 0.30016112327575684 seconds for one epoch ---
--- 2.013759136199951 seconds for one epoch ---
--- 0.29993462562561035 seconds for one epoch ---
--- 2.009394645690918 seconds for one epoch ---
--- 0.3016660213470459 seconds for one epoch ---
--- 1.9582839012145996 seconds for one epoch ---
--- 0.2948172092437744 seconds for one epoch ---
--- 1.94893217086792 seconds for one epoch ---
--- 0.30206775665283203 seconds for one epoch ---
--- 1.9660212993621826 seconds for one epoch ---
--- 0.30844926834106445 seconds for one epoch ---
--- 1.955110788345337 seconds for one epoch ---
--- 0.3039398193359375 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.297287]
 [ -0.      ]]
--- 0.2648751735687256 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4875.04931640625, (2130.0754, 2.351301, 2742.1995, 0.4232737)
   validation loss 796.010986328125, (520.76715, 0.33033463, 274.49023, 0.4232737)
decoder loss ratio: 20175.423517, decoder SINDy loss  ratio: 0.592526
--- 0.2959434986114502 seconds for one epoch ---
--- 1.9978723526000977 seconds for one epoch ---
--- 0.29844141006469727 seconds for one epoch ---
--- 2.0328688621520996 seconds for one epoch ---
--- 0.2983410358428955 seconds for one epoch ---
--- 2.0190248489379883 seconds for one epoch ---
--- 0.2998964786529541 seconds for one epoch ---
--- 2.0160348415374756 seconds for one epoch ---
--- 0.2958099842071533 seconds for one epoch ---
--- 1.994143009185791 seconds for one epoch ---
--- 0.2992384433746338 seconds for one epoch ---
--- 2.025632381439209 seconds for one epoch ---
--- 0.2999000549316406 seconds for one epoch ---
--- 2.0091958045959473 seconds for one epoch ---
--- 0.298290491104126 seconds for one epoch ---
--- 1.971168041229248 seconds for one epoch ---
--- 0.29714417457580566 seconds for one epoch ---
--- 1.9760000705718994 seconds for one epoch ---
--- 0.29883432388305664 seconds for one epoch ---
--- 1.995288610458374 seconds for one epoch ---
--- 0.30455732345581055 seconds for one epoch ---
--- 1.9822866916656494 seconds for one epoch ---
--- 0.29895853996276855 seconds for one epoch ---
--- 2.030291795730591 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.317017]
 [ -0.      ]]
--- 0.292888879776001 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4247.2880859375, (1268.747, 3.1644495, 2974.9531, 0.4237445)
   validation loss 667.2421875, (399.48615, 0.3050933, 267.0272, 0.4237445)
decoder loss ratio: 15476.786797, decoder SINDy loss  ratio: 0.576416
--- 0.2648305892944336 seconds for one epoch ---
--- 0.3087890148162842 seconds for one epoch ---
--- 2.029329538345337 seconds for one epoch ---
--- 0.3004617691040039 seconds for one epoch ---
--- 2.0276236534118652 seconds for one epoch ---
--- 0.29694080352783203 seconds for one epoch ---
--- 2.022254705429077 seconds for one epoch ---
--- 0.29878950119018555 seconds for one epoch ---
--- 2.025176763534546 seconds for one epoch ---
--- 0.29857373237609863 seconds for one epoch ---
--- 2.0013818740844727 seconds for one epoch ---
--- 0.2929697036743164 seconds for one epoch ---
--- 2.0531489849090576 seconds for one epoch ---
--- 0.3018033504486084 seconds for one epoch ---
--- 2.0575265884399414 seconds for one epoch ---
--- 0.30847764015197754 seconds for one epoch ---
--- 1.9902312755584717 seconds for one epoch ---
--- 0.30260610580444336 seconds for one epoch ---
--- 2.0094635486602783 seconds for one epoch ---
--- 0.30083179473876953 seconds for one epoch ---
--- 1.9817883968353271 seconds for one epoch ---
--- 0.29352450370788574 seconds for one epoch ---
--- 1.9838593006134033 seconds for one epoch ---
--- 0.2904071807861328 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.340715]
 [ -0.      ]]
--- 0.2590334415435791 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2979.51904296875, (1073.0234, 2.8476608, 1903.2236, 0.4243674)
   validation loss 846.6229858398438, (546.95074, 0.38749307, 298.86032, 0.4243674)
decoder loss ratio: 21189.821395, decoder SINDy loss  ratio: 0.645132
--- 0.28556156158447266 seconds for one epoch ---
--- 2.0603220462799072 seconds for one epoch ---
--- 0.3004567623138428 seconds for one epoch ---
--- 2.0824222564697266 seconds for one epoch ---
--- 0.2925286293029785 seconds for one epoch ---
--- 2.076420783996582 seconds for one epoch ---
--- 0.3004288673400879 seconds for one epoch ---
--- 2.0929365158081055 seconds for one epoch ---
--- 0.3018147945404053 seconds for one epoch ---
--- 2.075728416442871 seconds for one epoch ---
--- 0.29987549781799316 seconds for one epoch ---
--- 2.0984714031219482 seconds for one epoch ---
--- 0.3065989017486572 seconds for one epoch ---
--- 2.114665985107422 seconds for one epoch ---
--- 0.2950904369354248 seconds for one epoch ---
--- 2.0431747436523438 seconds for one epoch ---
--- 0.30410099029541016 seconds for one epoch ---
--- 2.0381357669830322 seconds for one epoch ---
--- 0.29195189476013184 seconds for one epoch ---
--- 2.0496976375579834 seconds for one epoch ---
--- 0.29806017875671387 seconds for one epoch ---
--- 2.048844575881958 seconds for one epoch ---
--- 0.3012995719909668 seconds for one epoch ---
--- 2.0496115684509277 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.35847]
 [ -0.     ]]
--- 0.29042744636535645 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3135.77099609375, (1746.2969, 1.8098247, 1387.2396, 0.4248124)
   validation loss 1263.482666015625, (931.9474, 0.33642328, 330.774, 0.4248124)
decoder loss ratio: 36105.259731, decoder SINDy loss  ratio: 0.714022
--- 0.26642680168151855 seconds for one epoch ---
--- 0.297452449798584 seconds for one epoch ---
--- 2.0966522693634033 seconds for one epoch ---
--- 0.2974221706390381 seconds for one epoch ---
--- 2.0930984020233154 seconds for one epoch ---
--- 0.300060510635376 seconds for one epoch ---
--- 2.092585802078247 seconds for one epoch ---
--- 0.2929549217224121 seconds for one epoch ---
--- 2.06290864944458 seconds for one epoch ---
--- 0.3012564182281494 seconds for one epoch ---
--- 2.071502685546875 seconds for one epoch ---
--- 0.29978489875793457 seconds for one epoch ---
--- 2.079744577407837 seconds for one epoch ---
--- 0.3024892807006836 seconds for one epoch ---
--- 2.090532064437866 seconds for one epoch ---
--- 0.30242466926574707 seconds for one epoch ---
--- 2.042182207107544 seconds for one epoch ---
--- 0.29717063903808594 seconds for one epoch ---
--- 2.054683208465576 seconds for one epoch ---
--- 0.30645060539245605 seconds for one epoch ---
--- 2.030604839324951 seconds for one epoch ---
--- 0.2893946170806885 seconds for one epoch ---
--- 2.025190830230713 seconds for one epoch ---
--- 0.29784488677978516 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.37198]
 [ -0.     ]]
--- 0.27205562591552734 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2944.6962890625, (1404.3744, 1.3292421, 1538.5676, 0.42510563)
   validation loss 843.4895629882812, (570.58386, 0.31642395, 272.1642, 0.42510563)
decoder loss ratio: 22105.409403, decoder SINDy loss  ratio: 0.587505
--- 0.2805190086364746 seconds for one epoch ---
--- 2.075556516647339 seconds for one epoch ---
--- 0.2998342514038086 seconds for one epoch ---
--- 2.088592052459717 seconds for one epoch ---
--- 0.29805827140808105 seconds for one epoch ---
--- 2.0424139499664307 seconds for one epoch ---
--- 0.3020668029785156 seconds for one epoch ---
--- 2.033828020095825 seconds for one epoch ---
--- 0.2970874309539795 seconds for one epoch ---
--- 2.0532193183898926 seconds for one epoch ---
--- 0.30309033393859863 seconds for one epoch ---
--- 2.082716226577759 seconds for one epoch ---
--- 0.3044393062591553 seconds for one epoch ---
--- 2.0824289321899414 seconds for one epoch ---
--- 0.2957010269165039 seconds for one epoch ---
--- 2.0258708000183105 seconds for one epoch ---
--- 0.29886960983276367 seconds for one epoch ---
--- 2.033977746963501 seconds for one epoch ---
--- 0.2973802089691162 seconds for one epoch ---
--- 2.0492730140686035 seconds for one epoch ---
--- 0.29204726219177246 seconds for one epoch ---
--- 2.024256706237793 seconds for one epoch ---
--- 0.6629247665405273 seconds for one epoch ---
--- 2.065293788909912 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.404202]
 [ -0.      ]]
--- 0.3073234558105469 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4632.82763671875, (1737.4755, 1.1633393, 2893.7632, 0.42575455)
   validation loss 820.3082275390625, (535.6339, 0.37511033, 283.87344, 0.42575455)
decoder loss ratio: 20751.387619, decoder SINDy loss  ratio: 0.612781
--- 0.28104209899902344 seconds for one epoch ---
--- 0.32625389099121094 seconds for one epoch ---
--- 2.106266498565674 seconds for one epoch ---
--- 0.31049156188964844 seconds for one epoch ---
--- 2.104032039642334 seconds for one epoch ---
--- 0.30671072006225586 seconds for one epoch ---
--- 2.081178903579712 seconds for one epoch ---
--- 0.3165626525878906 seconds for one epoch ---
--- 2.0955076217651367 seconds for one epoch ---
--- 0.29889726638793945 seconds for one epoch ---
--- 2.096073627471924 seconds for one epoch ---
--- 0.30419135093688965 seconds for one epoch ---
--- 2.1462955474853516 seconds for one epoch ---
--- 0.3085358142852783 seconds for one epoch ---
--- 2.0831544399261475 seconds for one epoch ---
--- 0.2992568016052246 seconds for one epoch ---
--- 2.0894854068756104 seconds for one epoch ---
--- 0.3009941577911377 seconds for one epoch ---
--- 2.0751261711120605 seconds for one epoch ---
--- 0.30066800117492676 seconds for one epoch ---
--- 2.0779666900634766 seconds for one epoch ---
--- 0.28969860076904297 seconds for one epoch ---
--- 2.0730791091918945 seconds for one epoch ---
--- 0.3034019470214844 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.428038]
 [ -0.      ]]
--- 0.2469778060913086 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3363.626220703125, (1925.7903, 1.7747706, 1435.6346, 0.4264083)
   validation loss 796.0303955078125, (493.62396, 0.37365368, 301.60638, 0.4264083)
decoder loss ratio: 19123.849272, decoder SINDy loss  ratio: 0.651060
--- 0.29194211959838867 seconds for one epoch ---
--- 2.135364294052124 seconds for one epoch ---
--- 0.3101019859313965 seconds for one epoch ---
--- 2.1089041233062744 seconds for one epoch ---
--- 0.30415821075439453 seconds for one epoch ---
--- 2.115633726119995 seconds for one epoch ---
--- 0.3085949420928955 seconds for one epoch ---
--- 2.116154432296753 seconds for one epoch ---
--- 0.29900169372558594 seconds for one epoch ---
--- 2.147827625274658 seconds for one epoch ---
--- 0.3043515682220459 seconds for one epoch ---
--- 2.1345841884613037 seconds for one epoch ---
--- 0.2944984436035156 seconds for one epoch ---
--- 2.06233286857605 seconds for one epoch ---
--- 0.3005807399749756 seconds for one epoch ---
--- 2.093937397003174 seconds for one epoch ---
--- 0.30182957649230957 seconds for one epoch ---
--- 2.091583490371704 seconds for one epoch ---
--- 0.2993912696838379 seconds for one epoch ---
--- 2.0673816204071045 seconds for one epoch ---
--- 0.29828739166259766 seconds for one epoch ---
--- 2.0919344425201416 seconds for one epoch ---
--- 0.2955195903778076 seconds for one epoch ---
--- 2.1180124282836914 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.437597]
 [ -0.      ]]
--- 0.2864189147949219 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3356.41796875, (1409.2699, 0.8366283, 1945.8846, 0.42665216)
   validation loss 753.1277465820312, (480.2343, 0.33172572, 272.13507, 0.42665216)
decoder loss ratio: 18605.111046, decoder SINDy loss  ratio: 0.587442
--- 0.26471686363220215 seconds for one epoch ---
--- 0.30996274948120117 seconds for one epoch ---
--- 2.0955491065979004 seconds for one epoch ---
--- 0.30080628395080566 seconds for one epoch ---
--- 2.098876714706421 seconds for one epoch ---
--- 0.3011138439178467 seconds for one epoch ---
--- 2.0856120586395264 seconds for one epoch ---
--- 0.2988295555114746 seconds for one epoch ---
--- 2.1230196952819824 seconds for one epoch ---
--- 0.29550719261169434 seconds for one epoch ---
--- 2.13529109954834 seconds for one epoch ---
--- 0.29952454566955566 seconds for one epoch ---
--- 2.066303014755249 seconds for one epoch ---
--- 0.2942626476287842 seconds for one epoch ---
--- 2.068732738494873 seconds for one epoch ---
--- 0.29665040969848633 seconds for one epoch ---
--- 2.071929931640625 seconds for one epoch ---
--- 0.293651819229126 seconds for one epoch ---
--- 2.077826499938965 seconds for one epoch ---
--- 0.29993200302124023 seconds for one epoch ---
--- 2.0812127590179443 seconds for one epoch ---
--- 0.2884817123413086 seconds for one epoch ---
--- 2.1199803352355957 seconds for one epoch ---
--- 0.3041846752166748 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.453993]
 [ -0.      ]]
--- 0.2640509605407715 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2497.853271484375, (1103.1747, 0.94260895, 1393.3088, 0.42707187)
   validation loss 720.0825805664062, (440.2203, 0.35058, 279.08463, 0.42707187)
decoder loss ratio: 17054.898926, decoder SINDy loss  ratio: 0.602443
--- 0.2904641628265381 seconds for one epoch ---
--- 2.1414082050323486 seconds for one epoch ---
--- 0.30428051948547363 seconds for one epoch ---
--- 2.1186320781707764 seconds for one epoch ---
--- 0.3080315589904785 seconds for one epoch ---
--- 2.136765241622925 seconds for one epoch ---
--- 0.29705142974853516 seconds for one epoch ---
--- 2.148521661758423 seconds for one epoch ---
--- 0.31104183197021484 seconds for one epoch ---
--- 2.15972900390625 seconds for one epoch ---
--- 0.2972133159637451 seconds for one epoch ---
--- 2.0928375720977783 seconds for one epoch ---
--- 0.29610300064086914 seconds for one epoch ---
--- 2.120426893234253 seconds for one epoch ---
--- 0.2976350784301758 seconds for one epoch ---
--- 2.103875160217285 seconds for one epoch ---
--- 0.3012971878051758 seconds for one epoch ---
--- 2.115213394165039 seconds for one epoch ---
--- 0.3047351837158203 seconds for one epoch ---
--- 2.1341090202331543 seconds for one epoch ---
--- 0.30477285385131836 seconds for one epoch ---
--- 2.159132242202759 seconds for one epoch ---
--- 0.2908914089202881 seconds for one epoch ---
--- 2.149855613708496 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.47513]
 [ -0.     ]]
--- 0.2946617603302002 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3813.197021484375, (1534.6492, 1.7931561, 2276.3271, 0.42757183)
   validation loss 749.1395874023438, (456.17014, 0.3214747, 292.22046, 0.42757183)
decoder loss ratio: 17672.822995, decoder SINDy loss  ratio: 0.630799
--- 0.972557783126831 seconds for one epoch ---
--- 0.29427313804626465 seconds for one epoch ---
--- 2.1071903705596924 seconds for one epoch ---
--- 0.29912519454956055 seconds for one epoch ---
--- 2.1133501529693604 seconds for one epoch ---
--- 0.3014545440673828 seconds for one epoch ---
--- 2.1548831462860107 seconds for one epoch ---
--- 0.31118345260620117 seconds for one epoch ---
--- 2.156259059906006 seconds for one epoch ---
--- 0.29784178733825684 seconds for one epoch ---
--- 2.099022388458252 seconds for one epoch ---
--- 0.3023097515106201 seconds for one epoch ---
--- 2.0773115158081055 seconds for one epoch ---
--- 0.3013491630554199 seconds for one epoch ---
--- 2.1133949756622314 seconds for one epoch ---
--- 0.28553199768066406 seconds for one epoch ---
--- 2.1010513305664062 seconds for one epoch ---
--- 0.30020570755004883 seconds for one epoch ---
--- 2.1043927669525146 seconds for one epoch ---
--- 0.30969905853271484 seconds for one epoch ---
--- 2.1769769191741943 seconds for one epoch ---
--- 0.32439541816711426 seconds for one epoch ---
--- 2.1817948818206787 seconds for one epoch ---
--- 0.3144221305847168 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.493715]
 [ -0.      ]]
--- 0.2672295570373535 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2852.044677734375, (1397.6265, 1.515436, 1452.475, 0.4280448)
   validation loss 823.2384643554688, (516.1494, 0.3435927, 306.31744, 0.4280448)
decoder loss ratio: 19996.524376, decoder SINDy loss  ratio: 0.661229
--- 0.30081605911254883 seconds for one epoch ---
--- 2.168308734893799 seconds for one epoch ---
--- 0.2955050468444824 seconds for one epoch ---
--- 2.168865919113159 seconds for one epoch ---
--- 0.29132723808288574 seconds for one epoch ---
--- 2.174248695373535 seconds for one epoch ---
--- 0.2969639301300049 seconds for one epoch ---
--- 2.196377992630005 seconds for one epoch ---
--- 0.2855992317199707 seconds for one epoch ---
--- 2.11961030960083 seconds for one epoch ---
--- 0.3045940399169922 seconds for one epoch ---
--- 2.1379334926605225 seconds for one epoch ---
--- 0.29512739181518555 seconds for one epoch ---
--- 2.14255952835083 seconds for one epoch ---
--- 0.29696059226989746 seconds for one epoch ---
--- 2.129983425140381 seconds for one epoch ---
--- 0.300858736038208 seconds for one epoch ---
--- 2.1579737663269043 seconds for one epoch ---
--- 0.2918105125427246 seconds for one epoch ---
--- 2.1671595573425293 seconds for one epoch ---
--- 0.30150413513183594 seconds for one epoch ---
--- 2.1879446506500244 seconds for one epoch ---
--- 0.29955363273620605 seconds for one epoch ---
--- 2.1291723251342773 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.508362]
 [ -0.      ]]
--- 0.29610252380371094 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4024.211181640625, (1833.9211, 5.71974, 2184.1418, 0.4283618)
   validation loss 689.2422485351562, (404.13574, 0.36625323, 284.31192, 0.4283618)
decoder loss ratio: 15656.920263, decoder SINDy loss  ratio: 0.613727
--- 0.26964688301086426 seconds for one epoch ---
--- 0.31231212615966797 seconds for one epoch ---
--- 2.153372049331665 seconds for one epoch ---
--- 0.30249738693237305 seconds for one epoch ---
--- 2.174049139022827 seconds for one epoch ---
--- 0.2914872169494629 seconds for one epoch ---
--- 2.214172840118408 seconds for one epoch ---
--- 0.30131006240844727 seconds for one epoch ---
--- 2.157270669937134 seconds for one epoch ---
--- 0.29920530319213867 seconds for one epoch ---
--- 2.1464812755584717 seconds for one epoch ---
--- 0.3026301860809326 seconds for one epoch ---
--- 2.129815101623535 seconds for one epoch ---
--- 0.3019599914550781 seconds for one epoch ---
--- 2.1434834003448486 seconds for one epoch ---
--- 0.27997303009033203 seconds for one epoch ---
--- 2.129512071609497 seconds for one epoch ---
--- 0.2853710651397705 seconds for one epoch ---
--- 2.171213388442993 seconds for one epoch ---
--- 0.30128002166748047 seconds for one epoch ---
--- 2.1342837810516357 seconds for one epoch ---
--- 0.30881261825561523 seconds for one epoch ---
--- 2.143141508102417 seconds for one epoch ---
--- 0.30280470848083496 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.535013]
 [ -0.      ]]
--- 0.25401997566223145 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6943.70263671875, (2090.9521, 3.1518922, 4849.1694, 0.4289895)
   validation loss 1110.483642578125, (814.8952, 0.37055418, 294.789, 0.4289895)
decoder loss ratio: 31570.454870, decoder SINDy loss  ratio: 0.636344
--- 0.30602025985717773 seconds for one epoch ---
--- 2.175837993621826 seconds for one epoch ---
--- 0.3012714385986328 seconds for one epoch ---
--- 2.141394853591919 seconds for one epoch ---
--- 0.29969024658203125 seconds for one epoch ---
--- 2.1686224937438965 seconds for one epoch ---
--- 0.2914702892303467 seconds for one epoch ---
--- 2.177459955215454 seconds for one epoch ---
--- 0.29964351654052734 seconds for one epoch ---
--- 2.1226394176483154 seconds for one epoch ---
--- 0.2845418453216553 seconds for one epoch ---
--- 2.115349531173706 seconds for one epoch ---
--- 0.303394079208374 seconds for one epoch ---
--- 2.1345667839050293 seconds for one epoch ---
--- 0.2985529899597168 seconds for one epoch ---
--- 2.1458468437194824 seconds for one epoch ---
--- 0.3023045063018799 seconds for one epoch ---
--- 2.2069785594940186 seconds for one epoch ---
--- 0.30225157737731934 seconds for one epoch ---
--- 2.1985342502593994 seconds for one epoch ---
--- 0.30615806579589844 seconds for one epoch ---
--- 2.1927833557128906 seconds for one epoch ---
--- 0.2998616695404053 seconds for one epoch ---
--- 2.19907546043396 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.559748]
 [ -0.      ]]
--- 0.29476356506347656 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2740.4912109375, (1648.4672, 2.2660155, 1089.3282, 0.42962238)
   validation loss 712.9131469726562, (423.71756, 0.32171762, 288.4442, 0.42962238)
decoder loss ratio: 16415.553873, decoder SINDy loss  ratio: 0.622647
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.561338]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1160.207275390625, (590.9759, 0.9065948, 568.3247, 0.42959294)
   validation loss 664.6182250976562, (415.18915, 0.2623414, 249.16676, 0.42959294)
decoder loss ratio: 16085.148392, decoder SINDy loss  ratio: 0.537862
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.582355]
 [  0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.387939453125, (338.79022, 0.42977157, 499.16797, 0.43001872)
   validation loss 483.56951904296875, (255.74118, 0.14660703, 227.68175, 0.43001872)
decoder loss ratio: 9907.857316, decoder SINDy loss  ratio: 0.491483
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.517273]
 [  0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.7921142578125, (297.08878, 0.29640755, 481.40695, 0.42831603)
   validation loss 464.93463134765625, (239.05669, 0.08586563, 225.79207, 0.42831603)
decoder loss ratio: 9261.471052, decoder SINDy loss  ratio: 0.487404
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.462986]
 [  0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.3709106445312, (296.0225, 0.25334698, 482.09506, 0.4260571)
   validation loss 457.97552490234375, (237.88399, 0.06697606, 220.02457, 0.4260571)
decoder loss ratio: 9216.038658, decoder SINDy loss  ratio: 0.474954
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.359804]
 [  0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.529052734375, (258.64993, 0.24323513, 473.63586, 0.42365915)
   validation loss 414.00299072265625, (195.5436, 0.057657946, 218.40173, 0.42365915)
decoder loss ratio: 7575.698324, decoder SINDy loss  ratio: 0.471451
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.208635]
 [  0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.388671875, (261.1931, 0.22585243, 467.9697, 0.42126322)
   validation loss 413.9826965332031, (195.45169, 0.053318907, 218.47769, 0.42126322)
decoder loss ratio: 7572.137816, decoder SINDy loss  ratio: 0.471615
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.06376]
 [  0.     ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 808.9200439453125, (322.70013, 0.23993537, 485.98, 0.41902757)
   validation loss 464.26593017578125, (248.36966, 0.05381383, 215.84244, 0.41902757)
decoder loss ratio: 9622.271795, decoder SINDy loss  ratio: 0.465926
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.060427]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.195556640625, (312.5962, 0.22782238, 461.37152, 0.41696247)
   validation loss 455.81182861328125, (235.20523, 0.053813964, 220.55276, 0.41696247)
decoder loss ratio: 9112.258972, decoder SINDy loss  ratio: 0.476094
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.934897]
 [  0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.0748901367188, (246.87201, 0.21801166, 466.98486, 0.41497087)
   validation loss 396.8372802734375, (182.04848, 0.059786938, 214.729, 0.41497087)
decoder loss ratio: 7052.874056, decoder SINDy loss  ratio: 0.463523
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.837375]
 [ -0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.00390625, (247.35287, 0.22811505, 464.42294, 0.41320154)
   validation loss 393.11358642578125, (178.32463, 0.0645511, 214.72441, 0.41320154)
decoder loss ratio: 6908.605780, decoder SINDy loss  ratio: 0.463513
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.778651]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2318.41015625, (1731.0931, 0.21111225, 587.1061, 0.4114731)
   validation loss 1883.2030029296875, (1629.1698, 0.07037443, 253.96277, 0.4114731)
decoder loss ratio: 63116.866408, decoder SINDy loss  ratio: 0.548214
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.756943]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.7221069335938, (327.5427, 0.19893791, 456.98047, 0.41025668)
   validation loss 470.27667236328125, (250.19974, 0.06522289, 220.01173, 0.41025668)
decoder loss ratio: 9693.172198, decoder SINDy loss  ratio: 0.474926
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.621405]
 [ -0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 921.0936889648438, (432.24854, 0.19060706, 488.65454, 0.4090105)
   validation loss 583.3251342773438, (366.24985, 0.07424786, 217.00104, 0.4090105)
decoder loss ratio: 14189.154926, decoder SINDy loss  ratio: 0.468427
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.611256]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.1476440429688, (255.65707, 0.19320774, 457.29736, 0.40795118)
   validation loss 398.64996337890625, (183.9368, 0.07076869, 214.64238, 0.40795118)
decoder loss ratio: 7126.030887, decoder SINDy loss  ratio: 0.463336
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.692851]
 [ -0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.502685546875, (417.06754, 0.18556118, 486.24957, 0.4069406)
   validation loss 565.4501953125, (348.7467, 0.07674301, 216.62672, 0.4069406)
decoder loss ratio: 13511.052768, decoder SINDy loss  ratio: 0.467619
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.592782]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.6837158203125, (263.1369, 0.19025314, 453.35657, 0.4061156)
   validation loss 410.19708251953125, (193.79222, 0.07724911, 216.3276, 0.4061156)
decoder loss ratio: 7507.847082, decoder SINDy loss  ratio: 0.466974
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.518719]
 [  0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1050.99658203125, (553.13763, 0.20087196, 497.65814, 0.4053091)
   validation loss 696.5823974609375, (478.10995, 0.074349366, 218.39809, 0.4053091)
decoder loss ratio: 18522.809686, decoder SINDy loss  ratio: 0.471443
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.47588]
 [ -0.     ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 908.3006591796875, (453.21924, 0.17458235, 454.90683, 0.40468565)
   validation loss 586.6077880859375, (361.37152, 0.08299705, 225.15323, 0.40468565)
decoder loss ratio: 14000.160092, decoder SINDy loss  ratio: 0.486025
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.470636]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.523193359375, (233.06775, 0.17398287, 455.28146, 0.40415832)
   validation loss 389.0439453125, (175.91936, 0.08337913, 213.04123, 0.40415832)
decoder loss ratio: 6815.421311, decoder SINDy loss  ratio: 0.459879
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.537611]
 [ -0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.598876953125, (271.67084, 0.2045672, 467.7235, 0.40371385)
   validation loss 425.2919921875, (211.63075, 0.08437255, 213.57689, 0.40371385)
decoder loss ratio: 8198.942761, decoder SINDy loss  ratio: 0.461036
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.391987]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.9117431640625, (240.33112, 0.17276998, 455.40787, 0.40329406)
   validation loss 396.53363037109375, (183.99829, 0.08485493, 212.45047, 0.40329406)
decoder loss ratio: 7128.413229, decoder SINDy loss  ratio: 0.458604
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.46538]
 [  0.     ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.3817138671875, (269.91727, 0.1738237, 451.2906, 0.40292874)
   validation loss 402.11480712890625, (186.33302, 0.09136093, 215.69041, 0.40292874)
decoder loss ratio: 7218.864802, decoder SINDy loss  ratio: 0.465598
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.386141]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 771.1430053710938, (322.2763, 0.16637486, 448.70032, 0.40266624)
   validation loss 462.97857666015625, (243.89561, 0.09209638, 218.99086, 0.40266624)
decoder loss ratio: 9448.939532, decoder SINDy loss  ratio: 0.472723
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.4016695]
 [  0.       ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.0206298828125, (273.31998, 0.16537008, 460.53528, 0.40249506)
   validation loss 424.50823974609375, (210.94945, 0.0910801, 213.4677, 0.40249506)
decoder loss ratio: 8172.547826, decoder SINDy loss  ratio: 0.460800
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.422027]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 879.08984375, (428.68848, 0.1583881, 450.24295, 0.40241224)
   validation loss 561.6326904296875, (337.35544, 0.09284146, 224.1844, 0.40241224)
decoder loss ratio: 13069.735352, decoder SINDy loss  ratio: 0.483934
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.342704]
 [ -0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.7803955078125, (228.61604, 0.16380426, 449.00058, 0.4023922)
   validation loss 384.1510009765625, (169.89017, 0.09535098, 214.1655, 0.4023922)
decoder loss ratio: 6581.840021, decoder SINDy loss  ratio: 0.462306
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.356692]
 [  0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.4843139648438, (240.79427, 0.15969275, 452.53033, 0.40237838)
   validation loss 398.84619140625, (185.86885, 0.09166409, 212.8857, 0.40237838)
decoder loss ratio: 7200.881959, decoder SINDy loss  ratio: 0.459544
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.404631]
 [  0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.7872314453125, (415.36954, 0.17400247, 447.2437, 0.40249082)
   validation loss 550.4287109375, (327.7856, 0.09315446, 222.54993, 0.40249082)
decoder loss ratio: 12698.983748, decoder SINDy loss  ratio: 0.480405
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.445192]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.4100341796875, (248.24995, 0.1969824, 445.9631, 0.4026439)
   validation loss 392.6228332519531, (178.05493, 0.09562351, 214.47227, 0.4026439)
decoder loss ratio: 6898.157169, decoder SINDy loss  ratio: 0.462969
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.384497]
 [  0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1460.864990234375, (931.9877, 0.17715147, 528.70013, 0.40263802)
   validation loss 1066.979736328125, (832.05664, 0.098724164, 234.82439, 0.40263802)
decoder loss ratio: 32235.318772, decoder SINDy loss  ratio: 0.506901
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.461132]
 [ -0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 864.6500244140625, (418.5704, 0.17353687, 445.9061, 0.40284568)
   validation loss 552.7366333007812, (329.86972, 0.094647124, 222.77226, 0.40284568)
decoder loss ratio: 12779.725650, decoder SINDy loss  ratio: 0.480885
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.410617]
 [ -0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.5677490234375, (236.32632, 0.18639402, 446.05505, 0.40305114)
   validation loss 386.70849609375, (172.75508, 0.09629265, 213.8571, 0.40305114)
decoder loss ratio: 6692.831761, decoder SINDy loss  ratio: 0.461641
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.404354]
 [  0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.0711059570312, (247.40726, 0.1668581, 443.49698, 0.4032259)
   validation loss 394.8434143066406, (179.62071, 0.09384273, 215.12886, 0.4032259)
decoder loss ratio: 6958.818229, decoder SINDy loss  ratio: 0.464386
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.449912]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1200.3477783203125, (740.85736, 0.15576454, 459.3347, 0.40355068)
   validation loss 851.117919921875, (612.0831, 0.098601125, 238.93625, 0.40355068)
decoder loss ratio: 23713.163075, decoder SINDy loss  ratio: 0.515778
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.443058]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 905.0927734375, (457.65567, 0.16455112, 447.27258, 0.40391898)
   validation loss 582.38671875, (356.86136, 0.100788966, 225.42459, 0.40391898)
decoder loss ratio: 13825.428572, decoder SINDy loss  ratio: 0.486611
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-15.43143]
 [ -0.     ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.401123046875, (374.271, 0.16741258, 443.9627, 0.40423545)
   validation loss 508.379638671875, (286.03763, 0.09852635, 222.24348, 0.40423545)
decoder loss ratio: 11081.594299, decoder SINDy loss  ratio: 0.479744
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.48216]
 [  0.     ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 992.774169921875, (542.7791, 0.1591031, 449.83597, 0.40459552)
   validation loss 662.9478759765625, (432.8957, 0.09872734, 229.95345, 0.40459552)
decoder loss ratio: 16771.130606, decoder SINDy loss  ratio: 0.496387
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-15.5165]
 [  0.    ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.08544921875, (237.23857, 0.16363668, 441.68326, 0.40497014)
   validation loss 390.73193359375, (175.05424, 0.09706792, 215.58064, 0.40497014)
decoder loss ratio: 6781.905359, decoder SINDy loss  ratio: 0.465361
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.476904]
 [  0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.11767578125, (224.17517, 0.16556291, 442.77695, 0.40533915)
   validation loss 382.22998046875, (167.50252, 0.09843779, 214.62901, 0.40533915)
decoder loss ratio: 6489.338333, decoder SINDy loss  ratio: 0.463307
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.515693]
 [  0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 859.6439208984375, (416.33124, 0.16262117, 443.15002, 0.40574512)
   validation loss 556.5873413085938, (331.98593, 0.09942645, 224.50197, 0.40574512)
decoder loss ratio: 12861.711335, decoder SINDy loss  ratio: 0.484619
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.491144]
 [ -0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.3953857421875, (242.02556, 0.17094173, 448.19888, 0.40613744)
   validation loss 402.22515869140625, (187.64668, 0.098606884, 214.47986, 0.40613744)
decoder loss ratio: 7269.758258, decoder SINDy loss  ratio: 0.462985
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.642749]
 [  0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.640869140625, (271.4031, 0.17635669, 440.0614, 0.4065628)
   validation loss 417.3006896972656, (199.49928, 0.09688581, 217.70451, 0.4065628)
decoder loss ratio: 7728.948563, decoder SINDy loss  ratio: 0.469946
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.611418]
 [ -0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.2315063476562, (226.30293, 0.1742824, 440.75427, 0.4069911)
   validation loss 380.79815673828125, (165.4663, 0.09849324, 215.23335, 0.4069911)
decoder loss ratio: 6410.451466, decoder SINDy loss  ratio: 0.464611
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.699244]
 [ -0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.2669677734375, (259.5952, 0.17504211, 438.49667, 0.40743157)
   validation loss 409.9178466796875, (193.41916, 0.09978981, 216.39891, 0.40743157)
decoder loss ratio: 7493.394008, decoder SINDy loss  ratio: 0.467127
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.672474]
 [ -0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.0318603515625, (323.3382, 0.18507305, 460.50864, 0.4078692)
   validation loss 472.79217529296875, (255.74869, 0.09705049, 216.94644, 0.4078692)
decoder loss ratio: 9908.148162, decoder SINDy loss  ratio: 0.468309
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.710307]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.1947021484375, (255.43303, 0.18544139, 440.5762, 0.40840396)
   validation loss 401.8480224609375, (184.8563, 0.09694527, 216.89479, 0.40840396)
decoder loss ratio: 7161.653705, decoder SINDy loss  ratio: 0.468198
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.670765]
 [  0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.001220703125, (235.59996, 0.1811248, 444.22015, 0.40885887)
   validation loss 382.08984375, (166.61275, 0.097991645, 215.37912, 0.40885887)
decoder loss ratio: 6454.867079, decoder SINDy loss  ratio: 0.464926
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.677511]
 [  0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.0823364257812, (229.59412, 0.18349715, 442.30472, 0.40937606)
   validation loss 382.6875, (168.02109, 0.09529044, 214.57114, 0.40937606)
decoder loss ratio: 6509.428633, decoder SINDy loss  ratio: 0.463182
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.67593]
 [ -0.     ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.4423828125, (241.34889, 0.1967051, 438.89676, 0.40993243)
   validation loss 388.1463623046875, (172.80403, 0.0992754, 215.24304, 0.40993243)
decoder loss ratio: 6694.728176, decoder SINDy loss  ratio: 0.464632
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999993]
 [0.       ]]
[[  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-15.6968]
 [  0.    ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 808.5787963867188, (367.46777, 0.20285721, 440.90817, 0.41042373)
   validation loss 491.36456298828125, (271.47144, 0.09314857, 219.79997, 0.41042373)
decoder loss ratio: 10517.274708, decoder SINDy loss  ratio: 0.474469
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.745187]
 [  0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.9063110351562, (224.2145, 0.200428, 439.4914, 0.41087818)
   validation loss 380.91064453125, (166.81401, 0.09429469, 214.00232, 0.41087818)
decoder loss ratio: 6462.664373, decoder SINDy loss  ratio: 0.461954
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.778865]
 [ -0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 820.9597778320312, (368.00735, 0.21782361, 452.7346, 0.4113187)
   validation loss 530.0926513671875, (316.77747, 0.090105705, 213.2251, 0.4113187)
decoder loss ratio: 12272.508976, decoder SINDy loss  ratio: 0.460276
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.743925]
 [  0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.2994384765625, (259.77124, 0.19158956, 446.33658, 0.4118522)
   validation loss 419.9510498046875, (206.01944, 0.09214955, 213.83945, 0.4118522)
decoder loss ratio: 7981.550759, decoder SINDy loss  ratio: 0.461603
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.848059]
 [  0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1228.9970703125, (730.4901, 0.20502448, 498.30197, 0.41235015)
   validation loss 873.3623657226562, (645.7867, 0.08722718, 227.48845, 0.41235015)
decoder loss ratio: 25018.897201, decoder SINDy loss  ratio: 0.491066
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.914781]
 [ -0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.0126953125, (231.10023, 0.2044808, 441.70795, 0.41286817)
   validation loss 391.99505615234375, (178.45119, 0.09259438, 213.45126, 0.41286817)
decoder loss ratio: 6913.508794, decoder SINDy loss  ratio: 0.460765
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.823337]
 [  0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.792724609375, (233.06877, 0.22760099, 439.49634, 0.41334945)
   validation loss 382.8123779296875, (169.88623, 0.09101661, 212.83511, 0.41334945)
decoder loss ratio: 6581.687504, decoder SINDy loss  ratio: 0.459435
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.906501]
 [ -0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.941650390625, (241.9965, 0.1951097, 435.75003, 0.413794)
   validation loss 390.7630310058594, (175.65079, 0.09117417, 215.02107, 0.413794)
decoder loss ratio: 6805.016445, decoder SINDy loss  ratio: 0.464153
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.012684]
 [ -0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 837.3345336914062, (398.3587, 0.183378, 438.79245, 0.41423866)
   validation loss 530.6196899414062, (307.15524, 0.09261478, 223.37183, 0.41423866)
decoder loss ratio: 11899.727356, decoder SINDy loss  ratio: 0.482180
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.897898]
 [ -0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.1951904296875, (229.54202, 0.18864243, 435.4645, 0.4146723)
   validation loss 383.5140380859375, (168.18178, 0.089743495, 215.24254, 0.4146723)
decoder loss ratio: 6515.654054, decoder SINDy loss  ratio: 0.464631
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.960064]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 843.4512329101562, (404.93817, 0.18492872, 438.32812, 0.41511258)
   validation loss 538.53173828125, (314.84802, 0.09106727, 223.59267, 0.41511258)
decoder loss ratio: 12197.758990, decoder SINDy loss  ratio: 0.482656
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.031317]
 [  0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1024.719970703125, (576.7665, 0.18425477, 447.76923, 0.41554195)
   validation loss 697.5458984375, (464.47263, 0.091682345, 232.9816, 0.41554195)
decoder loss ratio: 17994.475881, decoder SINDy loss  ratio: 0.502924
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.015192]
 [ -0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.2406005859375, (320.42538, 0.18088923, 434.63434, 0.41597852)
   validation loss 463.16888427734375, (243.61923, 0.08768098, 219.46196, 0.41597852)
decoder loss ratio: 9438.231996, decoder SINDy loss  ratio: 0.473740
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.992392]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.8427734375, (313.44806, 0.18029891, 434.21445, 0.4163774)
   validation loss 459.7215270996094, (239.64008, 0.086713426, 219.99474, 0.4163774)
decoder loss ratio: 9284.072565, decoder SINDy loss  ratio: 0.474890
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.027668]
 [ -0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1152.68115234375, (654.42194, 0.2395835, 498.01965, 0.41684452)
   validation loss 782.128173828125, (557.6298, 0.088571884, 224.40977, 0.41684452)
decoder loss ratio: 21603.547384, decoder SINDy loss  ratio: 0.484420
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.958561]
 [  0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.9950561523438, (265.45233, 0.20026267, 447.34247, 0.41718718)
   validation loss 399.7850646972656, (183.6647, 0.08591234, 216.03445, 0.41718718)
decoder loss ratio: 7115.489464, decoder SINDy loss  ratio: 0.466341
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.084778]
 [  0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.6014404296875, (247.29733, 0.19815749, 440.10593, 0.41760668)
   validation loss 410.9013366699219, (198.77734, 0.08329386, 212.0407, 0.41760668)
decoder loss ratio: 7700.979390, decoder SINDy loss  ratio: 0.457720
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-16.0782]
 [ -0.    ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1090.690673828125, (646.0215, 0.17934857, 444.4899, 0.41804892)
   validation loss 772.8553466796875, (538.0569, 0.087021224, 234.71141, 0.41804892)
decoder loss ratio: 20845.257824, decoder SINDy loss  ratio: 0.506658
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.101608]
 [  0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.8203125, (241.21475, 0.1810343, 432.42453, 0.41847286)
   validation loss 393.38116455078125, (177.88765, 0.0810466, 215.41248, 0.41847286)
decoder loss ratio: 6891.676370, decoder SINDy loss  ratio: 0.464998
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.10556]
 [  0.     ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1014.5150146484375, (568.7278, 0.18189313, 445.60532, 0.41887355)
   validation loss 683.7114868164062, (452.1113, 0.085983604, 231.5142, 0.41887355)
decoder loss ratio: 17515.576569, decoder SINDy loss  ratio: 0.499756
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.138494]
 [ -0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1294.4915771484375, (837.9802, 0.17439692, 456.337, 0.4192904)
   validation loss 942.131103515625, (697.492, 0.08344839, 244.55568, 0.4192904)
decoder loss ratio: 27022.051150, decoder SINDy loss  ratio: 0.527908
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.20222]
 [ -0.     ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.5025634765625, (384.06302, 0.18506259, 435.2545, 0.4196983)
   validation loss 519.6375732421875, (297.21515, 0.08318335, 222.33923, 0.4196983)
decoder loss ratio: 11514.630858, decoder SINDy loss  ratio: 0.479951
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.104235]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.139892578125, (242.46567, 0.20040518, 437.4738, 0.42005968)
   validation loss 402.68084716796875, (191.13766, 0.07871959, 211.46445, 0.42005968)
decoder loss ratio: 7405.004964, decoder SINDy loss  ratio: 0.456476
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.223999]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1099.6868896484375, (652.7216, 0.17174295, 446.79352, 0.42049375)
   validation loss 761.8800048828125, (526.5505, 0.083894424, 235.2456, 0.42049375)
decoder loss ratio: 20399.479575, decoder SINDy loss  ratio: 0.507811
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.164593]
 [  0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.952880859375, (235.71913, 0.18996076, 438.0438, 0.4208397)
   validation loss 394.08453369140625, (181.78409, 0.07647658, 212.22398, 0.4208397)
decoder loss ratio: 7042.631165, decoder SINDy loss  ratio: 0.458115
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.220901]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 853.1876220703125, (416.27557, 0.18670857, 436.72537, 0.42123458)
   validation loss 542.5498046875, (318.79074, 0.08162465, 223.67743, 0.42123458)
decoder loss ratio: 12350.506750, decoder SINDy loss  ratio: 0.482839
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.193224]
 [  0.      ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.2459716796875, (320.46384, 0.18202788, 430.6001, 0.4215888)
   validation loss 466.08856201171875, (246.79288, 0.079423256, 219.21626, 0.4215888)
decoder loss ratio: 9561.184514, decoder SINDy loss  ratio: 0.473209
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.277437]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1014.4891357421875, (541.73627, 0.22954573, 472.52335, 0.4219818)
   validation loss 701.2647705078125, (481.4837, 0.07303762, 219.70804, 0.4219818)
decoder loss ratio: 18653.514570, decoder SINDy loss  ratio: 0.474271
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.325956]
 [ -0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.04833984375, (301.08258, 0.20016876, 442.7656, 0.4222919)
   validation loss 470.8942565917969, (259.95096, 0.07422606, 210.86908, 0.4222919)
decoder loss ratio: 10070.951417, decoder SINDy loss  ratio: 0.455191
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.238522]
 [  0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.5068359375, (376.7228, 0.18976545, 432.59427, 0.42269468)
   validation loss 504.7377014160156, (284.08966, 0.08087311, 220.56717, 0.42269468)
decoder loss ratio: 11006.126655, decoder SINDy loss  ratio: 0.476125
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.291998]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.6847534179688, (330.6606, 0.20024645, 447.82388, 0.42301318)
   validation loss 501.26751708984375, (289.19693, 0.07381548, 211.99677, 0.42301318)
decoder loss ratio: 11203.991134, decoder SINDy loss  ratio: 0.457625
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.303915]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.629638671875, (315.8206, 0.18243518, 430.62662, 0.42335916)
   validation loss 455.7321472167969, (237.44249, 0.076624274, 218.21303, 0.42335916)
decoder loss ratio: 9198.934266, decoder SINDy loss  ratio: 0.471044
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.34482]
 [  0.     ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.786376953125, (260.25284, 0.1972332, 440.33627, 0.4236795)
   validation loss 426.8939514160156, (215.87485, 0.07552248, 210.94359, 0.4236795)
decoder loss ratio: 8363.366364, decoder SINDy loss  ratio: 0.455351
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.287048]
 [  0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.8375854492188, (292.9887, 0.18978803, 430.6591, 0.4240459)
   validation loss 430.1688232421875, (213.84807, 0.075661846, 216.2451, 0.4240459)
decoder loss ratio: 8284.845420, decoder SINDy loss  ratio: 0.466795
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.395971]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.8717041015625, (232.57428, 0.1816497, 428.11578, 0.42436916)
   validation loss 382.97601318359375, (170.2671, 0.07555661, 212.63333, 0.42436916)
decoder loss ratio: 6596.443248, decoder SINDy loss  ratio: 0.458999
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.38818]
 [  0.     ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.0349731445312, (282.46075, 0.18848188, 428.38574, 0.4246872)
   validation loss 421.97003173828125, (206.65616, 0.076855555, 215.23701, 0.4246872)
decoder loss ratio: 8006.218349, decoder SINDy loss  ratio: 0.464619
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.315266]
 [ -0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.69970703125, (219.80852, 0.18262893, 429.7086, 0.4249826)
   validation loss 372.8287353515625, (161.19258, 0.07322795, 211.56291, 0.4249826)
decoder loss ratio: 6244.880437, decoder SINDy loss  ratio: 0.456688
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.412235]
 [  0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.7557983398438, (239.5971, 0.18399812, 427.97467, 0.42527905)
   validation loss 385.16766357421875, (172.66125, 0.07341668, 212.43301, 0.42527905)
decoder loss ratio: 6689.196767, decoder SINDy loss  ratio: 0.458567
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.366379]
 [  0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.1171264648438, (217.04466, 0.19742532, 428.87503, 0.42562586)
   validation loss 370.29888916015625, (159.51506, 0.076238774, 210.70758, 0.42562586)
decoder loss ratio: 6179.890371, decoder SINDy loss  ratio: 0.454842
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.502874]
 [  0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.253173828125, (226.90276, 0.1770419, 427.1734, 0.42587516)
   validation loss 378.0531921386719, (166.66876, 0.07217759, 211.31226, 0.42587516)
decoder loss ratio: 6457.037198, decoder SINDy loss  ratio: 0.456147
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.464079]
 [  0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.0684814453125, (236.10591, 0.2244415, 430.73816, 0.42622095)
   validation loss 384.37884521484375, (175.56862, 0.07315846, 208.73706, 0.42622095)
decoder loss ratio: 6801.833092, decoder SINDy loss  ratio: 0.450588
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.451311]
 [ -0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1455.4176025390625, (967.0404, 0.2275484, 488.14966, 0.4263806)
   validation loss 1147.1512451171875, (923.1247, 0.06200397, 223.96454, 0.4263806)
decoder loss ratio: 35763.453292, decoder SINDy loss  ratio: 0.483459
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.46296]
 [ -0.     ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.9503173828125, (249.10657, 0.20656061, 435.6372, 0.4267481)
   validation loss 404.21868896484375, (194.4833, 0.06992652, 209.66544, 0.4267481)
decoder loss ratio: 7534.620947, decoder SINDy loss  ratio: 0.452592
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.361555]
 [  0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.839599609375, (267.83215, 0.19656332, 426.8109, 0.42703825)
   validation loss 409.7021484375, (195.64763, 0.07788232, 213.97664, 0.42703825)
decoder loss ratio: 7579.728798, decoder SINDy loss  ratio: 0.461899
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.39239]
 [  0.     ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.2471313476562, (238.81456, 0.18774603, 427.24484, 0.42724606)
   validation loss 383.6679382324219, (172.42891, 0.0704507, 211.16858, 0.42724606)
decoder loss ratio: 6680.195296, decoder SINDy loss  ratio: 0.455837
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.471273]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.27197265625, (278.35406, 0.1904854, 439.7274, 0.4274766)
   validation loss 443.4058532714844, (233.66821, 0.06831955, 209.66933, 0.4274766)
decoder loss ratio: 9052.712233, decoder SINDy loss  ratio: 0.452601
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.468027]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.2578125, (257.538, 0.18746652, 436.53232, 0.4277238)
   validation loss 424.2779541015625, (215.15013, 0.068502955, 209.05933, 0.4277238)
decoder loss ratio: 8335.289601, decoder SINDy loss  ratio: 0.451284
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.513819]
 [ -0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.506591796875, (318.14362, 0.1776895, 426.18527, 0.42797884)
   validation loss 451.7420654296875, (235.41118, 0.07163212, 216.25926, 0.42797884)
decoder loss ratio: 9120.237750, decoder SINDy loss  ratio: 0.466826
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.45142]
 [  0.     ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.47119140625, (217.10875, 0.18265803, 426.1798, 0.42819571)
   validation loss 369.5020751953125, (159.52592, 0.0703792, 209.90579, 0.42819571)
decoder loss ratio: 6180.311271, decoder SINDy loss  ratio: 0.453111
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.490221]
 [ -0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 950.70263671875, (517.0604, 0.17177944, 433.47046, 0.42838606)
   validation loss 634.6592407226562, (408.06927, 0.072156884, 226.5178, 0.42838606)
decoder loss ratio: 15809.312149, decoder SINDy loss  ratio: 0.488971
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.626328]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.1181640625, (357.0587, 0.17434302, 426.8851, 0.42862198)
   validation loss 481.4835205078125, (263.39517, 0.07130758, 218.01704, 0.42862198)
decoder loss ratio: 10204.386242, decoder SINDy loss  ratio: 0.470620
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.51744]
 [  0.     ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.1547241210938, (219.73875, 0.19389151, 425.22208, 0.4288884)
   validation loss 370.4857177734375, (160.97386, 0.0707885, 209.44107, 0.4288884)
decoder loss ratio: 6236.406865, decoder SINDy loss  ratio: 0.452108
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.5543]
 [ -0.    ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.89111328125, (247.39305, 0.2157422, 437.28232, 0.42912704)
   validation loss 403.49053955078125, (194.72308, 0.07237876, 208.6951, 0.42912704)
decoder loss ratio: 7543.910309, decoder SINDy loss  ratio: 0.450498
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.580608]
 [ -0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.3912353515625, (394.7502, 0.1825833, 443.4584, 0.42919207)
   validation loss 569.96923828125, (360.94058, 0.061553057, 208.9671, 0.42919207)
decoder loss ratio: 13983.464778, decoder SINDy loss  ratio: 0.451085
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.609991]
 [  0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.906494140625, (351.7429, 0.15789594, 426.00568, 0.42941114)
   validation loss 483.1298522949219, (264.13254, 0.06612797, 218.93118, 0.42941114)
decoder loss ratio: 10232.953070, decoder SINDy loss  ratio: 0.472594
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.622625]
 [  0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 914.3015747070312, (483.22647, 0.16166194, 430.91345, 0.42955938)
   validation loss 607.422119140625, (380.97147, 0.064043835, 226.38661, 0.42955938)
decoder loss ratio: 14759.495991, decoder SINDy loss  ratio: 0.488687
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.561712]
 [ -0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1182.42041015625, (741.88904, 0.1522176, 440.37915, 0.42970297)
   validation loss 854.2185668945312, (615.2686, 0.06567171, 238.88426, 0.42970297)
decoder loss ratio: 23836.574326, decoder SINDy loss  ratio: 0.515665
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.496328]
 [ -0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1174.473876953125, (688.833, 0.19663395, 485.44424, 0.42987925)
   validation loss 825.5759887695312, (602.416, 0.054976195, 223.10498, 0.42987925)
decoder loss ratio: 23338.642286, decoder SINDy loss  ratio: 0.481603
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.649948]
 [  0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1072.339111328125, (637.4986, 0.16434118, 434.6761, 0.4301587)
   validation loss 749.6057739257812, (517.46704, 0.06741253, 232.07135, 0.4301587)
decoder loss ratio: 20047.571531, decoder SINDy loss  ratio: 0.500959
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.577606]
 [ -0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1132.927978515625, (647.8368, 0.22082922, 484.87042, 0.4303939)
   validation loss 790.9412841796875, (570.55634, 0.05641517, 220.32858, 0.4303939)
decoder loss ratio: 22104.342965, decoder SINDy loss  ratio: 0.475610
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.58599]
 [  0.     ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 906.7066040039062, (474.97168, 0.17403932, 431.56088, 0.43058452)
   validation loss 588.1727905273438, (363.01016, 0.06564913, 225.09698, 0.43058452)
decoder loss ratio: 14063.643903, decoder SINDy loss  ratio: 0.485904
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.570395]
 [ -0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.1783447265625, (234.00938, 0.17871924, 428.99026, 0.43081856)
   validation loss 393.42449951171875, (185.5924, 0.059444174, 207.77266, 0.43081856)
decoder loss ratio: 7190.172059, decoder SINDy loss  ratio: 0.448507
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.65568]
 [ -0.     ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 792.741455078125, (368.61633, 0.1716011, 423.9535, 0.4310514)
   validation loss 494.26788330078125, (275.8592, 0.06395316, 218.34473, 0.4310514)
decoder loss ratio: 10687.264007, decoder SINDy loss  ratio: 0.471328
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.609243]
 [  0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.6650390625, (238.9823, 0.1745236, 420.50818, 0.43129826)
   validation loss 385.82952880859375, (175.10205, 0.061667785, 210.6658, 0.43129826)
decoder loss ratio: 6783.757438, decoder SINDy loss  ratio: 0.454752
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.572645]
 [  0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.1026611328125, (246.2625, 0.1775134, 429.66266, 0.43148097)
   validation loss 406.9922180175781, (199.7557, 0.057023767, 207.17949, 0.43148097)
decoder loss ratio: 7738.882872, decoder SINDy loss  ratio: 0.447226
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.65562]
 [ -0.     ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1420.0294189453125, (969.8947, 0.15716074, 449.97757, 0.4316516)
   validation loss 1067.5267333984375, (818.08344, 0.061575137, 249.3817, 0.4316516)
decoder loss ratio: 31693.972529, decoder SINDy loss  ratio: 0.538325
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.691061]
 [  0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.0169677734375, (270.94434, 0.17038433, 419.90228, 0.4318532)
   validation loss 410.4377746582031, (197.56496, 0.06037359, 212.81244, 0.4318532)
decoder loss ratio: 7654.009409, decoder SINDy loss  ratio: 0.459386
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.69538]
 [  0.     ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.4500122070312, (391.18192, 0.17201442, 427.09607, 0.4320278)
   validation loss 510.28851318359375, (289.29547, 0.05949835, 220.93352, 0.4320278)
decoder loss ratio: 11207.808793, decoder SINDy loss  ratio: 0.476916
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.694267]
 [ -0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.4834594726562, (252.12991, 0.17554225, 430.178, 0.43226653)
   validation loss 414.3680419921875, (207.06497, 0.05515015, 207.24791, 0.43226653)
decoder loss ratio: 8022.056493, decoder SINDy loss  ratio: 0.447374
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.650455]
 [ -0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.4551391601562, (392.49075, 0.16230653, 421.8021, 0.4324647)
   validation loss 525.94140625, (306.00308, 0.058982443, 219.87936, 0.4324647)
decoder loss ratio: 11855.090652, decoder SINDy loss  ratio: 0.474641
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.646267]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.39208984375, (228.10582, 0.15629144, 418.12994, 0.4326403)
   validation loss 380.3955383300781, (169.77246, 0.052993633, 210.57008, 0.4326403)
decoder loss ratio: 6577.279875, decoder SINDy loss  ratio: 0.454545
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.685043]
 [  0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.65478515625, (255.12148, 0.17509373, 418.35825, 0.43287864)
   validation loss 395.76568603515625, (184.08734, 0.057460632, 211.6209, 0.43287864)
decoder loss ratio: 7131.863192, decoder SINDy loss  ratio: 0.456813
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.72684]
 [  0.     ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 650.31884765625, (230.01627, 0.18022203, 420.12238, 0.4331251)
   validation loss 375.5401306152344, (166.55255, 0.057545703, 208.93004, 0.4331251)
decoder loss ratio: 6452.534984, decoder SINDy loss  ratio: 0.451005
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.732548]
 [ -0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1982.1351318359375, (1509.5709, 0.15317647, 472.411, 0.43328124)
   validation loss 1582.73779296875, (1309.929, 0.059547693, 272.74927, 0.43328124)
decoder loss ratio: 50748.921856, decoder SINDy loss  ratio: 0.588768
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.704296]
 [  0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.352294921875, (292.09955, 0.1646703, 417.0881, 0.43347293)
   validation loss 432.47137451171875, (219.37895, 0.05648694, 213.03593, 0.43347293)
decoder loss ratio: 8499.121460, decoder SINDy loss  ratio: 0.459868
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.707869]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 786.021240234375, (352.13028, 0.16352028, 433.72745, 0.43360803)
   validation loss 523.1617431640625, (316.77966, 0.047186337, 206.33487, 0.43360803)
decoder loss ratio: 12272.594102, decoder SINDy loss  ratio: 0.445403
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.637545]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.5130004882812, (280.2138, 0.19150044, 429.1077, 0.4339137)
   validation loss 436.5986328125, (229.57071, 0.05361623, 206.97432, 0.4339137)
decoder loss ratio: 8893.967828, decoder SINDy loss  ratio: 0.446783
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.745134]
 [  0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 994.5427856445312, (566.15234, 0.15869085, 428.23175, 0.4340313)
   validation loss 686.8580932617188, (457.10486, 0.05129848, 229.70195, 0.4340313)
decoder loss ratio: 17709.035783, decoder SINDy loss  ratio: 0.495844
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.79512]
 [ -0.     ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.849609375, (211.53252, 0.19573992, 420.12137, 0.4342167)
   validation loss 370.7837219238281, (165.11807, 0.054274023, 205.61137, 0.4342167)
decoder loss ratio: 6396.960787, decoder SINDy loss  ratio: 0.443841
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.751572]
 [  0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1031.3291015625, (601.62177, 0.15917754, 429.5482, 0.4343973)
   validation loss 713.306884765625, (483.0913, 0.05326394, 230.16231, 0.4343973)
decoder loss ratio: 18715.795978, decoder SINDy loss  ratio: 0.496838
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.768633]
 [ -0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.0606079101562, (320.6263, 0.15128517, 416.28302, 0.4345201)
   validation loss 462.110595703125, (245.91176, 0.0496832, 216.14917, 0.4345201)
decoder loss ratio: 9527.048443, decoder SINDy loss  ratio: 0.466588
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.793789]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.001708984375, (218.4664, 0.18340981, 420.35187, 0.43473265)
   validation loss 376.5157775878906, (170.87039, 0.052187297, 205.5932, 0.43473265)
decoder loss ratio: 6619.815624, decoder SINDy loss  ratio: 0.443802
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.762814]
 [ -0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 966.5659790039062, (513.83325, 0.17659271, 452.55615, 0.43491966)
   validation loss 680.19287109375, (468.81625, 0.046851896, 211.32979, 0.43491966)
decoder loss ratio: 18162.755568, decoder SINDy loss  ratio: 0.456185
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.793379]
 [  0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 710.8519897460938, (292.95038, 0.17538933, 417.72623, 0.43512088)
   validation loss 431.36761474609375, (218.2195, 0.04804666, 213.10007, 0.43512088)
decoder loss ratio: 8454.202186, decoder SINDy loss  ratio: 0.460006
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.768534]
 [  0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.482666015625, (316.6663, 0.17074603, 415.64563, 0.4353512)
   validation loss 447.7767333984375, (234.24408, 0.051912572, 213.48073, 0.4353512)
decoder loss ratio: 9075.022309, decoder SINDy loss  ratio: 0.460828
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.736025]
 [ -0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 826.1472778320312, (392.10785, 0.16797192, 433.87146, 0.43542743)
   validation loss 567.54541015625, (361.63153, 0.044218656, 205.86969, 0.43542743)
decoder loss ratio: 14010.233322, decoder SINDy loss  ratio: 0.444399
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.748745]
 [ -0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.6212158203125, (360.56418, 0.15088834, 413.90616, 0.43551227)
   validation loss 501.5408020019531, (284.80453, 0.048666712, 216.68759, 0.43551227)
decoder loss ratio: 11033.822125, decoder SINDy loss  ratio: 0.467751
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.769249]
 [  0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.6754150390625, (222.23267, 0.16633257, 418.27643, 0.43573853)
   validation loss 382.5364685058594, (178.05156, 0.045878, 204.43903, 0.43573853)
decoder loss ratio: 6898.026524, decoder SINDy loss  ratio: 0.441310
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.860714]
 [  0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 650.207763671875, (237.02739, 0.17759643, 413.00278, 0.43599278)
   validation loss 379.63812255859375, (171.74602, 0.050841685, 207.84126, 0.43599278)
decoder loss ratio: 6653.738880, decoder SINDy loss  ratio: 0.448655
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.882187]
 [ -0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 628.3894653320312, (211.324, 0.18940602, 416.87607, 0.43616563)
   validation loss 367.7502136230469, (163.79298, 0.050933175, 203.9063, 0.43616563)
decoder loss ratio: 6345.624558, decoder SINDy loss  ratio: 0.440160
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.844242]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 901.1761474609375, (449.0846, 0.21862705, 451.8729, 0.436318)
   validation loss 609.4427490234375, (400.44598, 0.049988896, 208.94681, 0.436318)
decoder loss ratio: 15513.972621, decoder SINDy loss  ratio: 0.451041
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.788744]
 [  0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1245.6934814453125, (770.35425, 0.17232619, 475.1669, 0.43634844)
   validation loss 943.0928344726562, (725.4524, 0.046884816, 217.59355, 0.43634844)
decoder loss ratio: 28105.285129, decoder SINDy loss  ratio: 0.469706
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.838005]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.581298828125, (233.29631, 0.16587536, 421.11914, 0.43650532)
   validation loss 390.03997802734375, (186.24951, 0.045403793, 203.74504, 0.43650532)
decoder loss ratio: 7215.629427, decoder SINDy loss  ratio: 0.439812
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.784231]
 [  0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.1508178710938, (337.2752, 0.15936509, 412.71625, 0.43664303)
   validation loss 465.81494140625, (252.85602, 0.048228845, 212.91069, 0.43664303)
decoder loss ratio: 9796.081117, decoder SINDy loss  ratio: 0.459598
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.901005]
 [  0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.20654296875, (207.00494, 0.21295266, 414.98862, 0.4368434)
   validation loss 359.51385498046875, (156.42874, 0.056681786, 203.02841, 0.4368434)
decoder loss ratio: 6060.321016, decoder SINDy loss  ratio: 0.438265
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.839346]
 [  0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.6427612304688, (305.2527, 0.1830933, 429.20697, 0.4368711)
   validation loss 462.5622253417969, (258.50986, 0.045783225, 204.00659, 0.4368711)
decoder loss ratio: 10015.120660, decoder SINDy loss  ratio: 0.440377
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.813824]
 [  0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.980712890625, (207.70677, 0.14896846, 412.12494, 0.43678156)
   validation loss 360.8650207519531, (156.39723, 0.042520326, 204.42526, 0.43678156)
decoder loss ratio: 6059.100287, decoder SINDy loss  ratio: 0.441281
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.823639]
 [  0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.7228393554688, (225.79333, 0.17757998, 416.75192, 0.43697187)
   validation loss 387.42254638671875, (184.78387, 0.04653325, 202.59213, 0.43697187)
decoder loss ratio: 7158.848097, decoder SINDy loss  ratio: 0.437324
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.901834]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1667.3736572265625, (1228.7488, 0.15954672, 438.46536, 0.4370125)
   validation loss 1343.22607421875, (1090.351, 0.04921453, 252.82599, 0.4370125)
decoder loss ratio: 42242.088819, decoder SINDy loss  ratio: 0.545760
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.894222]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.7039184570312, (370.12833, 0.1636816, 436.4119, 0.4371237)
   validation loss 528.1144409179688, (322.5009, 0.04327203, 205.57027, 0.4371237)
decoder loss ratio: 12494.244171, decoder SINDy loss  ratio: 0.443752
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.77015]
 [  0.     ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1149.7025146484375, (725.0083, 0.14224482, 424.55194, 0.43717352)
   validation loss 838.833251953125, (604.6989, 0.043640044, 234.09067, 0.43717352)
decoder loss ratio: 23427.085715, decoder SINDy loss  ratio: 0.505318
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.859947]
 [ -0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.0740966796875, (283.35028, 0.13785109, 407.58597, 0.43716547)
   validation loss 424.84014892578125, (213.50226, 0.040553708, 211.29733, 0.43716547)
decoder loss ratio: 8271.448143, decoder SINDy loss  ratio: 0.456115
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.811853]
 [ -0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.7952880859375, (374.76147, 0.15251435, 410.88126, 0.43734542)
   validation loss 498.583251953125, (283.30975, 0.042827994, 215.2307, 0.43734542)
decoder loss ratio: 10975.911695, decoder SINDy loss  ratio: 0.464606
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.844025]
 [ -0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.534912109375, (223.02669, 0.16239709, 407.3458, 0.43751732)
   validation loss 367.2182922363281, (162.28955, 0.044204596, 204.88454, 0.43751732)
decoder loss ratio: 6287.378944, decoder SINDy loss  ratio: 0.442272
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.90395]
 [ -0.     ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 638.66162109375, (231.44489, 0.17290066, 407.04385, 0.4376722)
   validation loss 372.967529296875, (168.23396, 0.046404548, 204.68716, 0.4376722)
decoder loss ratio: 6517.675794, decoder SINDy loss  ratio: 0.441846
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.912045]
 [ -0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.410400390625, (296.92426, 0.13873897, 406.34738, 0.43771735)
   validation loss 431.39013671875, (220.68222, 0.04339802, 210.66454, 0.43771735)
decoder loss ratio: 8549.612342, decoder SINDy loss  ratio: 0.454749
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.871319]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1956.1534423828125, (1491.383, 0.14161088, 464.62878, 0.4377865)
   validation loss 1538.850341796875, (1267.6179, 0.04342966, 271.18896, 0.4377865)
decoder loss ratio: 49109.718899, decoder SINDy loss  ratio: 0.585400
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.859798]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.57470703125, (270.15125, 0.14665915, 405.27682, 0.4378186)
   validation loss 407.66693115234375, (198.49663, 0.04039243, 209.1299, 0.4378186)
decoder loss ratio: 7690.103967, decoder SINDy loss  ratio: 0.451436
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.011847]
 [  0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 932.5848388671875, (520.3381, 0.13308845, 412.11365, 0.43786803)
   validation loss 643.374267578125, (419.83185, 0.039470427, 223.50296, 0.43786803)
decoder loss ratio: 16265.014657, decoder SINDy loss  ratio: 0.482463
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.852022]
 [ -0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.5368041992188, (241.5402, 0.14623788, 410.85037, 0.43787202)
   validation loss 402.5702819824219, (201.3996, 0.035653025, 201.13503, 0.43787202)
decoder loss ratio: 7802.570039, decoder SINDy loss  ratio: 0.434178
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.856327]
 [  0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.5206298828125, (281.0869, 0.17952178, 418.2542, 0.4380876)
   validation loss 442.34320068359375, (241.15216, 0.0406346, 201.15039, 0.4380876)
decoder loss ratio: 9342.653362, decoder SINDy loss  ratio: 0.434211
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.91852]
 [  0.     ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.9623413085938, (280.34943, 0.17762573, 421.4353, 0.4382902)
   validation loss 434.444580078125, (232.4503, 0.041613963, 201.95265, 0.4382902)
decoder loss ratio: 9005.528256, decoder SINDy loss  ratio: 0.435943
params['save_name']
pendulum_2023_10_25_09_38_50_650324
