nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 16:37:42.247982: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 16:37:42.258632: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 16:37:42.259796: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591c3f35180 executing computations on platform Host. Devices:
2023-10-25 16:37:42.259832: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 16:37:42.261732: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 16:37:42.363823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591c40a8810 executing computations on platform CUDA. Devices:
2023-10-25 16:37:42.363861: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 16:37:42.364350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-25 16:37:42.364618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 16:37:42.366556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 16:37:42.368120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 16:37:42.368421: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 16:37:42.370141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 16:37:42.371054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 16:37:42.374543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 16:37:42.375210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 16:37:42.375252: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 16:37:42.375610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 16:37:42.375619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 16:37:42.375625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 16:37:42.376218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-25 16:37:43.861004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 1.5, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.9545736312866211 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 112800.359375, (102712.91, 0.03518714, 10068.633, 2.5317805)
   validation loss 80793.4375, (79573.88, 0.015802192, 1200.7559, 2.5317805)
decoder loss ratio: 3082830.366492, decoder SINDy loss  ratio: 2.592000
--- 0.2136547565460205 seconds for one epoch ---
--- 0.19268536567687988 seconds for one epoch ---
--- 0.2207784652709961 seconds for one epoch ---
--- 0.2225661277770996 seconds for one epoch ---
--- 0.21960902214050293 seconds for one epoch ---
--- 0.18122029304504395 seconds for one epoch ---
--- 0.21228313446044922 seconds for one epoch ---
--- 0.20237469673156738 seconds for one epoch ---
--- 0.208848237991333 seconds for one epoch ---
--- 0.171769380569458 seconds for one epoch ---
--- 0.24060583114624023 seconds for one epoch ---
--- 0.23148393630981445 seconds for one epoch ---
--- 0.22919774055480957 seconds for one epoch ---
--- 0.21674323081970215 seconds for one epoch ---
--- 0.24156999588012695 seconds for one epoch ---
--- 0.22052431106567383 seconds for one epoch ---
--- 0.24189209938049316 seconds for one epoch ---
--- 0.1844630241394043 seconds for one epoch ---
--- 0.23889756202697754 seconds for one epoch ---
--- 0.21920013427734375 seconds for one epoch ---
--- 0.23082542419433594 seconds for one epoch ---
--- 0.2438216209411621 seconds for one epoch ---
--- 0.2482750415802002 seconds for one epoch ---
--- 0.20366597175598145 seconds for one epoch ---
=========================
[[0.7779896 ]
 [0.779299  ]
 [0.78116846]
 [0.7792952 ]
 [0.776925  ]
 [0.7825608 ]
 [0.78059286]
 [0.77676713]
 [0.77662873]
 [0.78710556]
 [0.77748233]]
[[ 0.35826004]
 [ 0.6420613 ]
 [-0.9848643 ]
 [-0.64128864]
 [-0.08954022]
 [-1.2060392 ]
 [ 0.88565993]
 [-0.04605862]
 [ 0.00690611]
 [-1.7977387 ]
 [ 0.2352361 ]]
--- 0.18476200103759766 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 56260.15234375, (49613.97, 4.2518673, 6597.825, 2.5317628)
   validation loss 52285.9453125, (50938.81, 11.855108, 1291.1713, 2.5317628)
decoder loss ratio: 1973457.878583, decoder SINDy loss  ratio: 2.787175
--- 0.1801471710205078 seconds for one epoch ---
--- 0.26200199127197266 seconds for one epoch ---
--- 0.2059462070465088 seconds for one epoch ---
--- 0.2889130115509033 seconds for one epoch ---
--- 0.19952034950256348 seconds for one epoch ---
--- 0.27979493141174316 seconds for one epoch ---
--- 0.19071364402770996 seconds for one epoch ---
--- 0.27344536781311035 seconds for one epoch ---
--- 0.20012831687927246 seconds for one epoch ---
--- 0.24687910079956055 seconds for one epoch ---
--- 0.20838570594787598 seconds for one epoch ---
--- 0.25856661796569824 seconds for one epoch ---
--- 0.22379112243652344 seconds for one epoch ---
--- 0.2645258903503418 seconds for one epoch ---
--- 0.2142951488494873 seconds for one epoch ---
--- 0.2696676254272461 seconds for one epoch ---
--- 0.2300736904144287 seconds for one epoch ---
--- 0.2460770606994629 seconds for one epoch ---
--- 0.19919061660766602 seconds for one epoch ---
--- 0.23446083068847656 seconds for one epoch ---
--- 0.21288824081420898 seconds for one epoch ---
--- 0.25153160095214844 seconds for one epoch ---
--- 0.21979570388793945 seconds for one epoch ---
--- 0.2449636459350586 seconds for one epoch ---
=========================
[[0.6242639 ]
 [0.6202151 ]
 [0.6245245 ]
 [0.61962754]
 [0.6178193 ]
 [0.63267404]
 [0.6217541 ]
 [0.6187675 ]
 [0.6178722 ]
 [0.6257599 ]
 [0.61964816]]
[[ 8.47166061e-01]
 [ 3.63195330e-01]
 [-8.74421895e-01]
 [-2.81061143e-01]
 [-1.54231838e-03]
 [-1.58096290e+00]
 [ 5.62232912e-01]
 [ 1.53577968e-01]
 [ 1.03827575e-02]
 [-9.98780072e-01]
 [ 2.84014791e-01]]
--- 0.21503543853759766 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 57141.625, (51397.547, 32.630653, 5647.827, 2.531739)
   validation loss 43883.53515625, (42583.707, 6.8207016, 1229.3883, 2.531739)
decoder loss ratio: 1649766.738957, decoder SINDy loss  ratio: 2.653808
--- 0.19211578369140625 seconds for one epoch ---
--- 0.18465876579284668 seconds for one epoch ---
--- 0.22983932495117188 seconds for one epoch ---
--- 0.25203561782836914 seconds for one epoch ---
--- 0.3181600570678711 seconds for one epoch ---
--- 0.27373552322387695 seconds for one epoch ---
--- 0.24362468719482422 seconds for one epoch ---
--- 0.17852139472961426 seconds for one epoch ---
--- 0.3044881820678711 seconds for one epoch ---
--- 0.21028590202331543 seconds for one epoch ---
--- 0.2405552864074707 seconds for one epoch ---
--- 0.205460786819458 seconds for one epoch ---
--- 0.23120379447937012 seconds for one epoch ---
--- 0.20662903785705566 seconds for one epoch ---
--- 0.23290181159973145 seconds for one epoch ---
--- 0.29938244819641113 seconds for one epoch ---
--- 0.26716160774230957 seconds for one epoch ---
--- 0.19383597373962402 seconds for one epoch ---
--- 0.26999616622924805 seconds for one epoch ---
--- 0.21609759330749512 seconds for one epoch ---
--- 0.26402878761291504 seconds for one epoch ---
--- 0.20867228507995605 seconds for one epoch ---
--- 0.25638365745544434 seconds for one epoch ---
--- 0.17514944076538086 seconds for one epoch ---
=========================
[[0.49632832]
 [0.48579416]
 [0.49269754]
 [0.48585388]
 [0.48504752]
 [0.512906  ]
 [0.48807472]
 [0.48701715]
 [0.48482233]
 [0.48873702]
 [0.48683438]]
[[ 1.0564805 ]
 [ 0.11918513]
 [-0.7831388 ]
 [-0.12614548]
 [-0.03018206]
 [-1.9821173 ]
 [ 0.36622378]
 [ 0.25590208]
 [-0.00244514]
 [-0.4320522 ]
 [ 0.23611964]]
--- 0.1674480438232422 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 29385.67578125, (20354.162, 22.400366, 8926.136, 2.5317395)
   validation loss 16983.74609375, (15817.409, 0.5154411, 1082.845, 2.5317395)
decoder loss ratio: 612793.891851, decoder SINDy loss  ratio: 2.337473
--- 0.17637848854064941 seconds for one epoch ---
--- 0.286454439163208 seconds for one epoch ---
--- 0.23092007637023926 seconds for one epoch ---
--- 0.24086260795593262 seconds for one epoch ---
--- 0.1842360496520996 seconds for one epoch ---
--- 0.24512434005737305 seconds for one epoch ---
--- 0.18250417709350586 seconds for one epoch ---
--- 0.29482126235961914 seconds for one epoch ---
--- 0.20339298248291016 seconds for one epoch ---
--- 0.2814769744873047 seconds for one epoch ---
--- 0.22643017768859863 seconds for one epoch ---
--- 0.26447176933288574 seconds for one epoch ---
--- 0.21116089820861816 seconds for one epoch ---
--- 0.25480008125305176 seconds for one epoch ---
--- 0.19032859802246094 seconds for one epoch ---
--- 0.29337453842163086 seconds for one epoch ---
--- 0.20690560340881348 seconds for one epoch ---
--- 0.2776975631713867 seconds for one epoch ---
--- 0.22524380683898926 seconds for one epoch ---
--- 0.2564408779144287 seconds for one epoch ---
--- 0.1913433074951172 seconds for one epoch ---
--- 0.32861995697021484 seconds for one epoch ---
--- 0.24161577224731445 seconds for one epoch ---
--- 0.29517197608947754 seconds for one epoch ---
=========================
[[0.3991685 ]
 [0.39021587]
 [0.39490712]
 [0.39010304]
 [0.3897772 ]
 [0.4385636 ]
 [0.39301154]
 [0.39261892]
 [0.3896883 ]
 [0.39318424]
 [0.39156502]]
[[ 7.9296076e-01]
 [ 5.6200389e-02]
 [-4.7879085e-01]
 [-4.4702966e-02]
 [ 1.1063928e-02]
 [-2.5183537e+00]
 [ 3.1981671e-01]
 [ 2.8508118e-01]
 [-1.7450191e-03]
 [-3.3490008e-01]
 [ 1.8833877e-01]]
--- 0.21584105491638184 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 30297.5625, (23812.418, 4.713598, 6379.9565, 2.5317495)
   validation loss 9487.751953125, (8459.359, 0.3493246, 927.5673, 2.5317495)
decoder loss ratio: 327730.268281, decoder SINDy loss  ratio: 2.002285
--- 0.16157007217407227 seconds for one epoch ---
--- 0.21701478958129883 seconds for one epoch ---
--- 0.27301526069641113 seconds for one epoch ---
--- 0.1795341968536377 seconds for one epoch ---
--- 0.3069000244140625 seconds for one epoch ---
--- 0.251922607421875 seconds for one epoch ---
--- 0.26442408561706543 seconds for one epoch ---
--- 0.19566559791564941 seconds for one epoch ---
--- 0.2750980854034424 seconds for one epoch ---
--- 0.18940973281860352 seconds for one epoch ---
--- 0.30151891708374023 seconds for one epoch ---
--- 0.20654702186584473 seconds for one epoch ---
--- 0.26618385314941406 seconds for one epoch ---
--- 0.24505066871643066 seconds for one epoch ---
--- 0.3029968738555908 seconds for one epoch ---
--- 0.18507122993469238 seconds for one epoch ---
--- 0.28692030906677246 seconds for one epoch ---
--- 0.22781062126159668 seconds for one epoch ---
--- 0.3612797260284424 seconds for one epoch ---
--- 0.2097320556640625 seconds for one epoch ---
--- 0.27257823944091797 seconds for one epoch ---
--- 0.20302033424377441 seconds for one epoch ---
--- 0.3144097328186035 seconds for one epoch ---
--- 0.2059464454650879 seconds for one epoch ---
=========================
[[0.31463808]
 [0.30960536]
 [0.3126544 ]
 [0.30972594]
 [0.30957663]
 [0.38289997]
 [0.3126937 ]
 [0.3127298 ]
 [0.30950615]
 [0.31607544]
 [0.31154013]]
[[ 4.21867967e-01]
 [ 9.30132996e-03]
 [-2.70420432e-01]
 [ 2.04138160e-02]
 [ 6.63918117e-03]
 [-2.97327447e+00]
 [ 2.73531526e-01]
 [ 2.76434809e-01]
 [-1.15282324e-04]
 [-5.24192929e-01]
 [ 1.79402947e-01]]
--- 0.1553974151611328 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 15986.5458984375, (9888.976, 1.5983098, 5982.514, 2.5317667)
   validation loss 10012.8046875, (9162.342, 0.18794252, 736.81714, 2.5317667)
decoder loss ratio: 354965.027736, decoder SINDy loss  ratio: 1.590523
--- 0.1744844913482666 seconds for one epoch ---
--- 0.26045727729797363 seconds for one epoch ---
--- 0.20186066627502441 seconds for one epoch ---
--- 0.2860603332519531 seconds for one epoch ---
--- 0.21055245399475098 seconds for one epoch ---
--- 0.2735733985900879 seconds for one epoch ---
--- 0.18847894668579102 seconds for one epoch ---
--- 0.26433897018432617 seconds for one epoch ---
--- 0.2023611068725586 seconds for one epoch ---
--- 0.3386514186859131 seconds for one epoch ---
--- 0.22203350067138672 seconds for one epoch ---
--- 0.3353769779205322 seconds for one epoch ---
--- 0.20163631439208984 seconds for one epoch ---
--- 0.3154919147491455 seconds for one epoch ---
--- 0.19055724143981934 seconds for one epoch ---
--- 0.3030579090118408 seconds for one epoch ---
--- 0.19443106651306152 seconds for one epoch ---
--- 0.29355406761169434 seconds for one epoch ---
--- 0.2179548740386963 seconds for one epoch ---
--- 0.33595967292785645 seconds for one epoch ---
--- 0.21280431747436523 seconds for one epoch ---
--- 0.2977259159088135 seconds for one epoch ---
--- 0.19406652450561523 seconds for one epoch ---
--- 0.29680705070495605 seconds for one epoch ---
=========================
[[0.25330007]
 [0.2526836 ]
 [0.25225827]
 [0.25277892]
 [0.25211447]
 [0.34691393]
 [0.25469825]
 [0.2555779 ]
 [0.25183964]
 [0.26276523]
 [0.2541433 ]]
[[ 1.2237093e-01]
 [-7.2426334e-02]
 [-3.7120733e-02]
 [ 8.0255076e-02]
 [ 2.5007796e-02]
 [-3.2905107e+00]
 [ 2.3068628e-01]
 [ 2.9560935e-01]
 [-1.6523430e-03]
 [-7.5393862e-01]
 [ 1.8847989e-01]]
--- 0.2073824405670166 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10797.005859375, (6304.0093, 2.0404537, 4364.179, 2.5317867)
   validation loss 5018.49072265625, (4224.0303, 0.11874254, 667.5644, 2.5317867)
decoder loss ratio: 163646.266032, decoder SINDy loss  ratio: 1.441032
--- 0.17358160018920898 seconds for one epoch ---
--- 0.2100222110748291 seconds for one epoch ---
--- 0.27942967414855957 seconds for one epoch ---
--- 0.20151972770690918 seconds for one epoch ---
--- 0.29421377182006836 seconds for one epoch ---
--- 0.18780231475830078 seconds for one epoch ---
--- 0.32564234733581543 seconds for one epoch ---
--- 0.22808408737182617 seconds for one epoch ---
--- 0.2957627773284912 seconds for one epoch ---
--- 0.2057933807373047 seconds for one epoch ---
--- 0.3002488613128662 seconds for one epoch ---
--- 0.24096465110778809 seconds for one epoch ---
--- 0.28551650047302246 seconds for one epoch ---
--- 0.19780182838439941 seconds for one epoch ---
--- 0.27193117141723633 seconds for one epoch ---
--- 0.19258832931518555 seconds for one epoch ---
--- 0.3106527328491211 seconds for one epoch ---
--- 0.20670557022094727 seconds for one epoch ---
--- 0.2916131019592285 seconds for one epoch ---
--- 0.2211911678314209 seconds for one epoch ---
--- 0.32622265815734863 seconds for one epoch ---
--- 0.25649476051330566 seconds for one epoch ---
--- 0.3291289806365967 seconds for one epoch ---
--- 0.2015380859375 seconds for one epoch ---
=========================
[[0.20481978]
 [0.20504816]
 [0.20363376]
 [0.20437449]
 [0.2029875 ]
 [0.31934828]
 [0.20565982]
 [0.20704475]
 [0.20293057]
 [0.21918406]
 [0.20595519]]
[[-1.4634024e-01]
 [-1.6315697e-01]
 [ 5.6345195e-02]
 [ 1.1308698e-01]
 [ 5.2891215e-03]
 [-3.5552475e+00]
 [ 2.0740938e-01]
 [ 3.0372313e-01]
 [-7.0499058e-04]
 [-9.8389703e-01]
 [ 2.2839008e-01]]
--- 0.16231799125671387 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9468.3671875, (4560.546, 0.91041255, 4769.4683, 2.531814)
   validation loss 5713.81640625, (4975.0386, 0.10704966, 601.2289, 2.531814)
decoder loss ratio: 192741.631412, decoder SINDy loss  ratio: 1.297837
--- 0.2151036262512207 seconds for one epoch ---
--- 0.3156135082244873 seconds for one epoch ---
--- 0.19768977165222168 seconds for one epoch ---
--- 0.2872045040130615 seconds for one epoch ---
--- 0.18193912506103516 seconds for one epoch ---
--- 0.28783726692199707 seconds for one epoch ---
--- 0.1822984218597412 seconds for one epoch ---
--- 0.36658191680908203 seconds for one epoch ---
--- 0.31624484062194824 seconds for one epoch ---
--- 0.3748311996459961 seconds for one epoch ---
--- 0.22475886344909668 seconds for one epoch ---
--- 0.3364698886871338 seconds for one epoch ---
--- 0.2028059959411621 seconds for one epoch ---
--- 0.2988004684448242 seconds for one epoch ---
--- 0.18563008308410645 seconds for one epoch ---
--- 0.306093692779541 seconds for one epoch ---
--- 0.19443774223327637 seconds for one epoch ---
--- 0.3158857822418213 seconds for one epoch ---
--- 0.21125102043151855 seconds for one epoch ---
--- 0.3616831302642822 seconds for one epoch ---
--- 0.2101917266845703 seconds for one epoch ---
--- 0.33524632453918457 seconds for one epoch ---
--- 0.18894219398498535 seconds for one epoch ---
--- 0.3486974239349365 seconds for one epoch ---
=========================
[[0.17274646]
 [0.17138444]
 [0.16937613]
 [0.1695152 ]
 [0.16757402]
 [0.2988727 ]
 [0.16984871]
 [0.17168261]
 [0.16756992]
 [0.18935843]
 [0.17187406]]
[[-3.6186001e-01]
 [-2.7426103e-01]
 [ 1.3672973e-01]
 [ 1.4660391e-01]
 [ 3.4651160e-03]
 [-3.7094634e+00]
 [ 1.7005453e-01]
 [ 2.9382297e-01]
 [-3.1447099e-03]
 [-1.1912584e+00]
 [ 3.0626133e-01]]
--- 0.22247695922851562 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9173.7705078125, (4450.0, 1.5860939, 4576.0977, 2.531837)
   validation loss 2214.32080078125, (1526.7194, 0.066548765, 541.4485, 2.531837)
decoder loss ratio: 59147.758521, decoder SINDy loss  ratio: 1.168793
--- 0.1710655689239502 seconds for one epoch ---
--- 0.19938278198242188 seconds for one epoch ---
--- 0.3504452705383301 seconds for one epoch ---
--- 0.2111220359802246 seconds for one epoch ---
--- 0.32471728324890137 seconds for one epoch ---
--- 0.2462174892425537 seconds for one epoch ---
--- 0.3339526653289795 seconds for one epoch ---
--- 0.20510149002075195 seconds for one epoch ---
--- 0.32512760162353516 seconds for one epoch ---
--- 0.18691778182983398 seconds for one epoch ---
--- 0.36041259765625 seconds for one epoch ---
--- 0.1974184513092041 seconds for one epoch ---
--- 0.33446335792541504 seconds for one epoch ---
--- 0.18672466278076172 seconds for one epoch ---
--- 0.30655741691589355 seconds for one epoch ---
--- 0.32989025115966797 seconds for one epoch ---
--- 0.3289530277252197 seconds for one epoch ---
--- 0.17484688758850098 seconds for one epoch ---
--- 0.36086463928222656 seconds for one epoch ---
--- 0.2381601333618164 seconds for one epoch ---
--- 0.32108330726623535 seconds for one epoch ---
--- 0.20907354354858398 seconds for one epoch ---
--- 0.3253061771392822 seconds for one epoch ---
--- 0.18820643424987793 seconds for one epoch ---
=========================
[[0.14459257]
 [0.14236198]
 [0.14001115]
 [0.13998903]
 [0.13748978]
 [0.27162012]
 [0.13900189]
 [0.14172502]
 [0.13745272]
 [0.16385077]
 [0.14282985]]
[[-0.4696398 ]
 [-0.3375891 ]
 [ 0.1871095 ]
 [ 0.1856255 ]
 [ 0.01010308]
 [-3.6818638 ]
 [ 0.1183762 ]
 [ 0.29805204]
 [-0.00736527]
 [-1.3379672 ]
 [ 0.36609796]]
--- 0.19359707832336426 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8020.8896484375, (3658.6309, 0.4877768, 4208.085, 2.5318437)
   validation loss 2203.45654296875, (1580.3716, 0.07132739, 469.3274, 2.5318437)
decoder loss ratio: 61226.338734, decoder SINDy loss  ratio: 1.013109
--- 0.23962903022766113 seconds for one epoch ---
--- 0.31952428817749023 seconds for one epoch ---
--- 0.2194826602935791 seconds for one epoch ---
--- 0.3149123191833496 seconds for one epoch ---
--- 0.18329286575317383 seconds for one epoch ---
--- 0.3586089611053467 seconds for one epoch ---
--- 0.18002748489379883 seconds for one epoch ---
--- 0.36687135696411133 seconds for one epoch ---
--- 0.19373083114624023 seconds for one epoch ---
--- 0.3896143436431885 seconds for one epoch ---
--- 0.18122220039367676 seconds for one epoch ---
--- 0.321425199508667 seconds for one epoch ---
--- 0.21962928771972656 seconds for one epoch ---
--- 0.32265162467956543 seconds for one epoch ---
--- 0.19565725326538086 seconds for one epoch ---
--- 0.3733391761779785 seconds for one epoch ---
--- 0.20099449157714844 seconds for one epoch ---
--- 0.390300989151001 seconds for one epoch ---
--- 0.20852231979370117 seconds for one epoch ---
--- 0.32929182052612305 seconds for one epoch ---
--- 0.22646665573120117 seconds for one epoch ---
--- 0.34433960914611816 seconds for one epoch ---
--- 0.18442463874816895 seconds for one epoch ---
--- 0.31598639488220215 seconds for one epoch ---
=========================
[[0.12431655]
 [0.12157816]
 [0.11897349]
 [0.11860845]
 [0.11548008]
 [0.25013018]
 [0.11737096]
 [0.11980046]
 [0.11540789]
 [0.14614812]
 [0.12197877]]
[[-5.5164671e-01]
 [-3.9968818e-01]
 [ 2.4231470e-01]
 [ 2.1912867e-01]
 [-6.7284158e-03]
 [-3.6383758e+00]
 [ 1.3813834e-01]
 [ 2.9379505e-01]
 [-1.5173672e-03]
 [-1.4620428e+00]
 [ 4.2272878e-01]]
--- 0.2766575813293457 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8666.06640625, (5473.4707, 2.6154041, 3029.6836, 2.5318487)
   validation loss 2909.341552734375, (2340.2964, 0.06557329, 408.68362, 2.5318487)
decoder loss ratio: 90667.144955, decoder SINDy loss  ratio: 0.882201
--- 0.20110344886779785 seconds for one epoch ---
--- 0.21433329582214355 seconds for one epoch ---
--- 0.3588383197784424 seconds for one epoch ---
--- 0.20050358772277832 seconds for one epoch ---
--- 0.3556966781616211 seconds for one epoch ---
--- 0.21748948097229004 seconds for one epoch ---
--- 0.3211836814880371 seconds for one epoch ---
--- 0.18724274635314941 seconds for one epoch ---
--- 0.3197364807128906 seconds for one epoch ---
--- 0.20036530494689941 seconds for one epoch ---
--- 0.3574645519256592 seconds for one epoch ---
--- 0.23234152793884277 seconds for one epoch ---
--- 0.37334394454956055 seconds for one epoch ---
--- 0.1890709400177002 seconds for one epoch ---
--- 0.42385196685791016 seconds for one epoch ---
--- 0.22748565673828125 seconds for one epoch ---
--- 0.35209059715270996 seconds for one epoch ---
--- 0.17180943489074707 seconds for one epoch ---
--- 0.38417768478393555 seconds for one epoch ---
--- 0.1991891860961914 seconds for one epoch ---
--- 0.36265993118286133 seconds for one epoch ---
--- 0.2053689956665039 seconds for one epoch ---
--- 0.3577253818511963 seconds for one epoch ---
--- 0.1815342903137207 seconds for one epoch ---
=========================
[[0.10871267]
 [0.10371707]
 [0.10058361]
 [0.09997863]
 [0.09683966]
 [0.23383293]
 [0.09891587]
 [0.10130381]
 [0.09662881]
 [0.13427953]
 [0.10414645]]
[[-0.7038153 ]
 [-0.4467294 ]
 [ 0.26491663]
 [ 0.22759342]
 [ 0.02021365]
 [-3.6335404 ]
 [ 0.16007547]
 [ 0.30834627]
 [-0.00536432]
 [-1.6600288 ]
 [ 0.47028238]]
--- 0.158219575881958 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4857.6962890625, (3588.0608, 2.6863177, 1100.0295, 2.5318618)
   validation loss 2485.854248046875, (1957.3589, 0.067921, 361.5073, 2.5318618)
decoder loss ratio: 75831.481396, decoder SINDy loss  ratio: 0.780364
--- 0.1974802017211914 seconds for one epoch ---
--- 0.4049499034881592 seconds for one epoch ---
--- 0.20876550674438477 seconds for one epoch ---
--- 0.40050578117370605 seconds for one epoch ---
--- 0.22607684135437012 seconds for one epoch ---
--- 0.35233426094055176 seconds for one epoch ---
--- 0.22979497909545898 seconds for one epoch ---
--- 0.3303399085998535 seconds for one epoch ---
--- 0.21979618072509766 seconds for one epoch ---
--- 0.385608434677124 seconds for one epoch ---
--- 0.21622514724731445 seconds for one epoch ---
--- 0.383709192276001 seconds for one epoch ---
--- 0.21283769607543945 seconds for one epoch ---
--- 0.35927391052246094 seconds for one epoch ---
--- 0.20628881454467773 seconds for one epoch ---
--- 0.3837885856628418 seconds for one epoch ---
--- 0.18659257888793945 seconds for one epoch ---
--- 0.3435494899749756 seconds for one epoch ---
--- 0.2195146083831787 seconds for one epoch ---
--- 0.3449742794036865 seconds for one epoch ---
--- 0.19874858856201172 seconds for one epoch ---
--- 0.37514328956604004 seconds for one epoch ---
--- 0.18796467781066895 seconds for one epoch ---
--- 0.3535611629486084 seconds for one epoch ---
=========================
[[0.09751687]
 [0.09082287]
 [0.08737525]
 [0.08619522]
 [0.08291823]
 [0.21994008]
 [0.08590712]
 [0.087712  ]
 [0.08279582]
 [0.12645721]
 [0.09110315]]
[[-8.1446075e-01]
 [-4.8884919e-01]
 [ 2.9575041e-01]
 [ 2.2460373e-01]
 [ 1.0607276e-02]
 [-3.6018162e+00]
 [ 2.0679770e-01]
 [ 3.1554216e-01]
 [-2.0819216e-03]
 [-1.8137062e+00]
 [ 5.0368941e-01]]
--- 0.16485309600830078 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5314.10693359375, (3278.02, 0.760533, 1861.6669, 2.5318706)
   validation loss 3709.6875, (3048.225, 0.047083214, 487.75528, 2.5318706)
decoder loss ratio: 118093.532235, decoder SINDy loss  ratio: 1.052888
--- 0.16565632820129395 seconds for one epoch ---
--- 0.19878578186035156 seconds for one epoch ---
--- 0.4374430179595947 seconds for one epoch ---
--- 0.20520591735839844 seconds for one epoch ---
--- 0.3482480049133301 seconds for one epoch ---
--- 0.2080850601196289 seconds for one epoch ---
--- 0.3683767318725586 seconds for one epoch ---
--- 0.2190542221069336 seconds for one epoch ---
--- 0.37466979026794434 seconds for one epoch ---
--- 0.18823504447937012 seconds for one epoch ---
--- 0.38980984687805176 seconds for one epoch ---
--- 0.19676494598388672 seconds for one epoch ---
--- 0.42857980728149414 seconds for one epoch ---
--- 0.19314861297607422 seconds for one epoch ---
--- 0.37507033348083496 seconds for one epoch ---
--- 0.20708298683166504 seconds for one epoch ---
--- 0.39841341972351074 seconds for one epoch ---
--- 0.20283770561218262 seconds for one epoch ---
--- 0.3586575984954834 seconds for one epoch ---
--- 0.20835590362548828 seconds for one epoch ---
--- 0.43799543380737305 seconds for one epoch ---
--- 0.3053412437438965 seconds for one epoch ---
--- 0.36281919479370117 seconds for one epoch ---
--- 0.17849493026733398 seconds for one epoch ---
=========================
[[0.08851298]
 [0.07940087]
 [0.07572627]
 [0.07402916]
 [0.07100181]
 [0.20577826]
 [0.07420079]
 [0.07562184]
 [0.07091558]
 [0.12164079]
 [0.08106914]]
[[-9.2965269e-01]
 [-5.0762391e-01]
 [ 3.0606350e-01]
 [ 2.0478979e-01]
 [ 8.3853733e-03]
 [-3.5434313e+00]
 [ 2.1529853e-01]
 [ 2.9999688e-01]
 [-2.4477202e-03]
 [-1.9840951e+00]
 [ 5.9229064e-01]]
--- 0.19205164909362793 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4167.5283203125, (2660.98, 0.05340512, 1327.7241, 2.5318787)
   validation loss 3721.738037109375, (3125.7217, 0.048798926, 417.19678, 2.5318787)
decoder loss ratio: 121095.884363, decoder SINDy loss  ratio: 0.900578
--- 0.2049546241760254 seconds for one epoch ---
--- 0.34573960304260254 seconds for one epoch ---
--- 0.19355368614196777 seconds for one epoch ---
--- 0.37410688400268555 seconds for one epoch ---
--- 0.19622564315795898 seconds for one epoch ---
--- 0.4139237403869629 seconds for one epoch ---
--- 0.21672582626342773 seconds for one epoch ---
--- 0.3807404041290283 seconds for one epoch ---
--- 0.17284917831420898 seconds for one epoch ---
--- 0.39375877380371094 seconds for one epoch ---
--- 0.19057440757751465 seconds for one epoch ---
--- 0.39633750915527344 seconds for one epoch ---
--- 0.2225348949432373 seconds for one epoch ---
--- 0.4224250316619873 seconds for one epoch ---
--- 0.22501611709594727 seconds for one epoch ---
--- 0.4017186164855957 seconds for one epoch ---
--- 0.22210288047790527 seconds for one epoch ---
--- 0.3866868019104004 seconds for one epoch ---
--- 0.2389070987701416 seconds for one epoch ---
--- 0.3686361312866211 seconds for one epoch ---
--- 0.18342185020446777 seconds for one epoch ---
--- 0.40126490592956543 seconds for one epoch ---
--- 0.16614198684692383 seconds for one epoch ---
--- 0.4197359085083008 seconds for one epoch ---
=========================
[[0.08197965]
 [0.07116318]
 [0.06713699]
 [0.06569888]
 [0.06247063]
 [0.19225313]
 [0.06548053]
 [0.06677137]
 [0.06216596]
 [0.11902979]
 [0.07378796]]
[[-1.0122495e+00]
 [-5.2963930e-01]
 [ 3.1257698e-01]
 [ 2.2826329e-01]
 [ 2.3021283e-02]
 [-3.4553773e+00]
 [ 2.1511032e-01]
 [ 2.9151806e-01]
 [-2.3470388e-03]
 [-2.1215980e+00]
 [ 6.5851152e-01]]
--- 0.22221755981445312 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6337.205078125, (2844.036, 0.71573585, 3309.2637, 2.5318832)
   validation loss 3081.338134765625, (2522.7964, 0.03984043, 375.31238, 2.5318832)
decoder loss ratio: 97737.511789, decoder SINDy loss  ratio: 0.810165
--- 0.16000032424926758 seconds for one epoch ---
--- 0.16333246231079102 seconds for one epoch ---
--- 0.366870641708374 seconds for one epoch ---
--- 0.2291707992553711 seconds for one epoch ---
--- 0.42438554763793945 seconds for one epoch ---
--- 0.17869305610656738 seconds for one epoch ---
--- 0.39990854263305664 seconds for one epoch ---
--- 0.15326380729675293 seconds for one epoch ---
--- 0.42284607887268066 seconds for one epoch ---
--- 0.1827104091644287 seconds for one epoch ---
--- 0.4005157947540283 seconds for one epoch ---
--- 0.20184588432312012 seconds for one epoch ---
--- 0.36635375022888184 seconds for one epoch ---
--- 0.22539567947387695 seconds for one epoch ---
--- 0.39013147354125977 seconds for one epoch ---
--- 0.19151639938354492 seconds for one epoch ---
--- 0.49970149993896484 seconds for one epoch ---
--- 0.17375397682189941 seconds for one epoch ---
--- 0.4321012496948242 seconds for one epoch ---
--- 0.2041792869567871 seconds for one epoch ---
--- 0.3932018280029297 seconds for one epoch ---
--- 0.23004889488220215 seconds for one epoch ---
--- 0.48389744758605957 seconds for one epoch ---
--- 0.191056489944458 seconds for one epoch ---
=========================
[[0.07617701]
 [0.06485864]
 [0.05939153]
 [0.05775215]
 [0.05456672]
 [0.17841987]
 [0.05811061]
 [0.0590663 ]
 [0.05459797]
 [0.11716995]
 [0.06793148]]
[[-1.0746659e+00]
 [-5.8943546e-01]
 [ 3.0098215e-01]
 [ 2.0470858e-01]
 [ 1.1959763e-03]
 [-3.3468926e+00]
 [ 2.2620687e-01]
 [ 2.8229129e-01]
 [-3.3161631e-03]
 [-2.2417953e+00]
 [ 7.3378688e-01]]
--- 0.17358732223510742 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5818.32373046875, (2368.3962, 1.449662, 3260.2205, 2.5318847)
   validation loss 1242.940673828125, (762.22766, 0.050425597, 292.405, 2.5318847)
decoder loss ratio: 29530.022878, decoder SINDy loss  ratio: 0.631197
--- 0.1866319179534912 seconds for one epoch ---
--- 0.41281604766845703 seconds for one epoch ---
--- 0.18507122993469238 seconds for one epoch ---
--- 0.41614866256713867 seconds for one epoch ---
--- 0.20705199241638184 seconds for one epoch ---
--- 0.39914655685424805 seconds for one epoch ---
--- 0.19478964805603027 seconds for one epoch ---
--- 0.4225480556488037 seconds for one epoch ---
--- 0.19389677047729492 seconds for one epoch ---
--- 0.4598851203918457 seconds for one epoch ---
--- 0.22507047653198242 seconds for one epoch ---
--- 0.4321119785308838 seconds for one epoch ---
--- 0.18916726112365723 seconds for one epoch ---
--- 0.45744752883911133 seconds for one epoch ---
--- 0.2010490894317627 seconds for one epoch ---
--- 0.39406275749206543 seconds for one epoch ---
--- 0.21366262435913086 seconds for one epoch ---
--- 0.42354822158813477 seconds for one epoch ---
--- 0.17922115325927734 seconds for one epoch ---
--- 0.4004695415496826 seconds for one epoch ---
--- 0.2202441692352295 seconds for one epoch ---
--- 0.4270749092102051 seconds for one epoch ---
--- 0.25164318084716797 seconds for one epoch ---
--- 0.41463780403137207 seconds for one epoch ---
=========================
[[0.07299349]
 [0.06014881]
 [0.05414132]
 [0.0527023 ]
 [0.04895353]
 [0.16889082]
 [0.05245388]
 [0.05334876]
 [0.04898921]
 [0.11817078]
 [0.0636566 ]]
[[-1.1595489e+00]
 [-6.2975901e-01]
 [ 3.1974068e-01]
 [ 2.3691514e-01]
 [ 1.0228221e-03]
 [-3.2763290e+00]
 [ 2.2221985e-01]
 [ 2.7459741e-01]
 [-3.4252401e-03]
 [-2.3763390e+00]
 [ 7.8944385e-01]]
--- 0.31118273735046387 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11723.9619140625, (4936.8813, 3.183637, 6592.231, 2.531892)
   validation loss 1568.783203125, (1080.5173, 0.042432074, 296.5573, 2.531892)
decoder loss ratio: 41861.117379, decoder SINDy loss  ratio: 0.640161
--- 0.2614293098449707 seconds for one epoch ---
--- 0.29456591606140137 seconds for one epoch ---
--- 0.42513346672058105 seconds for one epoch ---
--- 0.2023329734802246 seconds for one epoch ---
--- 0.42676711082458496 seconds for one epoch ---
--- 0.21586227416992188 seconds for one epoch ---
--- 0.3892333507537842 seconds for one epoch ---
--- 0.16935014724731445 seconds for one epoch ---
--- 0.46511268615722656 seconds for one epoch ---
--- 0.19239187240600586 seconds for one epoch ---
--- 0.4346578121185303 seconds for one epoch ---
--- 0.18546533584594727 seconds for one epoch ---
--- 0.4360494613647461 seconds for one epoch ---
--- 0.19762372970581055 seconds for one epoch ---
--- 0.4106123447418213 seconds for one epoch ---
--- 0.19725298881530762 seconds for one epoch ---
--- 0.4401822090148926 seconds for one epoch ---
--- 0.20035505294799805 seconds for one epoch ---
--- 0.39820170402526855 seconds for one epoch ---
--- 0.1752474308013916 seconds for one epoch ---
--- 0.4728856086730957 seconds for one epoch ---
--- 0.26822972297668457 seconds for one epoch ---
--- 0.47615790367126465 seconds for one epoch ---
--- 0.2073957920074463 seconds for one epoch ---
=========================
[[0.07013107]
 [0.05520932]
 [0.04955361]
 [0.04778861]
 [0.04443328]
 [0.158834  ]
 [0.04746015]
 [0.04856898]
 [0.04410645]
 [0.11956408]
 [0.05972181]]
[[-1.2268391 ]
 [-0.62461054]
 [ 0.33500618]
 [ 0.23429772]
 [ 0.02551052]
 [-3.1869032 ]
 [ 0.21491027]
 [ 0.27952307]
 [-0.00378502]
 [-2.4972205 ]
 [ 0.82720774]]
--- 0.1646747589111328 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3166.80029296875, (2064.4275, 2.4989624, 904.75055, 2.531895)
   validation loss 1525.1153564453125, (985.77783, 0.0814047, 344.13306, 2.531895)
decoder loss ratio: 38190.744598, decoder SINDy loss  ratio: 0.742860
--- 0.1954822540283203 seconds for one epoch ---
--- 0.42574262619018555 seconds for one epoch ---
--- 0.18198466300964355 seconds for one epoch ---
--- 0.4048008918762207 seconds for one epoch ---
--- 0.20036816596984863 seconds for one epoch ---
--- 0.41971921920776367 seconds for one epoch ---
--- 0.21665310859680176 seconds for one epoch ---
--- 0.40066027641296387 seconds for one epoch ---
--- 0.18090152740478516 seconds for one epoch ---
--- 0.41754913330078125 seconds for one epoch ---
--- 0.14772868156433105 seconds for one epoch ---
--- 0.40810132026672363 seconds for one epoch ---
--- 0.2048511505126953 seconds for one epoch ---
--- 0.43094944953918457 seconds for one epoch ---
--- 0.21185994148254395 seconds for one epoch ---
--- 0.43535447120666504 seconds for one epoch ---
--- 0.20248174667358398 seconds for one epoch ---
--- 0.45353269577026367 seconds for one epoch ---
--- 0.20023751258850098 seconds for one epoch ---
--- 0.43885183334350586 seconds for one epoch ---
--- 0.1940295696258545 seconds for one epoch ---
--- 0.44232964515686035 seconds for one epoch ---
--- 0.1936054229736328 seconds for one epoch ---
--- 0.46358203887939453 seconds for one epoch ---
=========================
[[0.06836577]
 [0.0517891 ]
 [0.04566085]
 [0.04417083]
 [0.04058934]
 [0.14901753]
 [0.04344453]
 [0.04471184]
 [0.0404707 ]
 [0.12252365]
 [0.05696593]]
[[-1.2873363 ]
 [-0.6327749 ]
 [ 0.3195844 ]
 [ 0.23452213]
 [ 0.01166652]
 [-3.0818486 ]
 [ 0.19154987]
 [ 0.2658773 ]
 [-0.00377822]
 [-2.6195934 ]
 [ 0.8617037 ]]
--- 0.2067413330078125 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5699.466796875, (2687.2368, 3.030459, 2812.1077, 2.5318975)
   validation loss 2674.62060546875, (2182.192, 0.07435272, 295.26227, 2.5318975)
decoder loss ratio: 84541.902446, decoder SINDy loss  ratio: 0.637365
--- 0.14949250221252441 seconds for one epoch ---
--- 0.18626046180725098 seconds for one epoch ---
--- 0.4421253204345703 seconds for one epoch ---
--- 0.17787718772888184 seconds for one epoch ---
--- 0.4598863124847412 seconds for one epoch ---
--- 0.1999051570892334 seconds for one epoch ---
--- 0.4482877254486084 seconds for one epoch ---
--- 0.22969675064086914 seconds for one epoch ---
--- 0.43852686882019043 seconds for one epoch ---
--- 0.16436290740966797 seconds for one epoch ---
--- 0.42053842544555664 seconds for one epoch ---
--- 0.18718457221984863 seconds for one epoch ---
--- 0.4799187183380127 seconds for one epoch ---
--- 0.18180155754089355 seconds for one epoch ---
--- 0.45386195182800293 seconds for one epoch ---
--- 0.24341797828674316 seconds for one epoch ---
--- 0.4127166271209717 seconds for one epoch ---
--- 0.22054743766784668 seconds for one epoch ---
--- 0.49638915061950684 seconds for one epoch ---
--- 0.20644307136535645 seconds for one epoch ---
--- 0.46275806427001953 seconds for one epoch ---
--- 0.1859588623046875 seconds for one epoch ---
--- 0.4409499168395996 seconds for one epoch ---
--- 0.204603910446167 seconds for one epoch ---
=========================
[[0.06690746]
 [0.04933491]
 [0.04219288]
 [0.04150017]
 [0.03747028]
 [0.14116631]
 [0.04017604]
 [0.04139883]
 [0.03725652]
 [0.12501493]
 [0.05461868]]
[[-1.3413901e+00]
 [-6.6492212e-01]
 [ 3.0275688e-01]
 [ 2.6347208e-01]
 [ 1.5917225e-02]
 [-2.9998477e+00]
 [ 1.8589166e-01]
 [ 2.5765511e-01]
 [ 1.7570045e-03]
 [-2.7198331e+00]
 [ 8.9391041e-01]]
--- 0.1632387638092041 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3451.205810546875, (1535.127, 2.713542, 1713.4766, 2.531901)
   validation loss 1878.4876708984375, (1382.5529, 0.07331202, 295.97263, 2.531901)
decoder loss ratio: 53562.497876, decoder SINDy loss  ratio: 0.638899
--- 0.18898725509643555 seconds for one epoch ---
--- 0.48245763778686523 seconds for one epoch ---
--- 0.21205711364746094 seconds for one epoch ---
--- 0.5001013278961182 seconds for one epoch ---
--- 0.2331986427307129 seconds for one epoch ---
--- 0.46480393409729004 seconds for one epoch ---
--- 0.22881150245666504 seconds for one epoch ---
--- 0.498704195022583 seconds for one epoch ---
--- 0.22541308403015137 seconds for one epoch ---
--- 0.47581982612609863 seconds for one epoch ---
--- 0.18421697616577148 seconds for one epoch ---
--- 0.4364314079284668 seconds for one epoch ---
--- 0.19297075271606445 seconds for one epoch ---
--- 0.48433780670166016 seconds for one epoch ---
--- 0.18049979209899902 seconds for one epoch ---
--- 0.4862039089202881 seconds for one epoch ---
--- 0.21922826766967773 seconds for one epoch ---
--- 0.4699535369873047 seconds for one epoch ---
--- 0.21419954299926758 seconds for one epoch ---
--- 0.5068879127502441 seconds for one epoch ---
--- 0.282865047454834 seconds for one epoch ---
--- 0.45432186126708984 seconds for one epoch ---
--- 0.21442937850952148 seconds for one epoch ---
--- 0.49258923530578613 seconds for one epoch ---
=========================
[[0.066718  ]
 [0.04751384]
 [0.03931579]
 [0.03920592]
 [0.03489   ]
 [0.1343237 ]
 [0.03778055]
 [0.03912346]
 [0.03486038]
 [0.1294816 ]
 [0.05404577]]
[[-1.4092818e+00]
 [-6.8907815e-01]
 [ 2.7403593e-01]
 [ 2.6778182e-01]
 [ 2.6605837e-03]
 [-2.9209824e+00]
 [ 1.8454187e-01]
 [ 2.6306799e-01]
 [ 6.9344649e-04]
 [-2.8377998e+00]
 [ 9.6451151e-01]]
--- 0.21063804626464844 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3406.029296875, (1668.2999, 0.7571142, 1534.718, 2.531908)
   validation loss 1297.1983642578125, (786.51495, 0.092296675, 308.33698, 2.531908)
decoder loss ratio: 30470.954753, decoder SINDy loss  ratio: 0.665589
THRESHOLDING: 2 active coefficients
--- 0.5019843578338623 seconds for one epoch ---
--- 0.1961960792541504 seconds for one epoch ---
--- 0.5006670951843262 seconds for one epoch ---
--- 0.17668414115905762 seconds for one epoch ---
--- 0.4977433681488037 seconds for one epoch ---
--- 0.20992708206176758 seconds for one epoch ---
--- 0.5775580406188965 seconds for one epoch ---
--- 0.23392939567565918 seconds for one epoch ---
--- 0.45311784744262695 seconds for one epoch ---
--- 0.20694851875305176 seconds for one epoch ---
--- 0.43386244773864746 seconds for one epoch ---
--- 0.18378496170043945 seconds for one epoch ---
--- 0.4720785617828369 seconds for one epoch ---
--- 0.2002274990081787 seconds for one epoch ---
--- 0.48542308807373047 seconds for one epoch ---
--- 0.18194913864135742 seconds for one epoch ---
--- 0.5030577182769775 seconds for one epoch ---
--- 0.1868739128112793 seconds for one epoch ---
--- 0.48677897453308105 seconds for one epoch ---
--- 0.17570233345031738 seconds for one epoch ---
--- 0.4790184497833252 seconds for one epoch ---
--- 0.1961348056793213 seconds for one epoch ---
--- 0.4583742618560791 seconds for one epoch ---
--- 0.20373821258544922 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08346665]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10877646]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.9317839]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.4896224]
 [ 0.       ]]
--- 0.18104171752929688 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3712.37890625, (2234.0303, 2.0366654, 1476.1354, 0.17686139)
   validation loss 1805.2554931640625, (1479.909, 0.13721293, 325.0324, 0.17686139)
decoder loss ratio: 57334.246127, decoder SINDy loss  ratio: 0.701628
--- 0.19368219375610352 seconds for one epoch ---
--- 0.48668456077575684 seconds for one epoch ---
--- 0.2162761688232422 seconds for one epoch ---
--- 0.4567112922668457 seconds for one epoch ---
--- 0.19861555099487305 seconds for one epoch ---
--- 0.48378539085388184 seconds for one epoch ---
--- 0.18227267265319824 seconds for one epoch ---
--- 0.4668235778808594 seconds for one epoch ---
--- 0.17287564277648926 seconds for one epoch ---
--- 0.5042595863342285 seconds for one epoch ---
--- 0.1836857795715332 seconds for one epoch ---
--- 0.539574146270752 seconds for one epoch ---
--- 0.17420244216918945 seconds for one epoch ---
--- 0.48569560050964355 seconds for one epoch ---
--- 0.20004963874816895 seconds for one epoch ---
--- 0.4846029281616211 seconds for one epoch ---
--- 0.19460654258728027 seconds for one epoch ---
--- 0.5081455707550049 seconds for one epoch ---
--- 0.17743515968322754 seconds for one epoch ---
--- 0.47775816917419434 seconds for one epoch ---
--- 0.20415115356445312 seconds for one epoch ---
--- 0.5645129680633545 seconds for one epoch ---
--- 0.2955961227416992 seconds for one epoch ---
--- 0.5327284336090088 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06747138]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10119437]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.5403026]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3657563]
 [ 0.       ]]
--- 0.17862153053283691 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3982.652587890625, (1462.5339, 0.8517198, 2519.0994, 0.16775246)
   validation loss 903.238525390625, (622.8366, 0.09678408, 280.1374, 0.16775246)
decoder loss ratio: 24129.771520, decoder SINDy loss  ratio: 0.604716
--- 0.145249605178833 seconds for one epoch ---
--- 0.21814179420471191 seconds for one epoch ---
--- 0.5022222995758057 seconds for one epoch ---
--- 0.22555017471313477 seconds for one epoch ---
--- 0.4910438060760498 seconds for one epoch ---
--- 0.19220614433288574 seconds for one epoch ---
--- 0.44251084327697754 seconds for one epoch ---
--- 0.20064616203308105 seconds for one epoch ---
--- 0.4923110008239746 seconds for one epoch ---
--- 0.1771383285522461 seconds for one epoch ---
--- 0.5236129760742188 seconds for one epoch ---
--- 0.22728204727172852 seconds for one epoch ---
--- 0.559532642364502 seconds for one epoch ---
--- 0.2319185733795166 seconds for one epoch ---
--- 0.5091898441314697 seconds for one epoch ---
--- 0.17820358276367188 seconds for one epoch ---
--- 0.5088050365447998 seconds for one epoch ---
--- 0.20488405227661133 seconds for one epoch ---
--- 0.4748103618621826 seconds for one epoch ---
--- 0.16428017616271973 seconds for one epoch ---
--- 0.6170608997344971 seconds for one epoch ---
--- 0.19901633262634277 seconds for one epoch ---
--- 0.48607850074768066 seconds for one epoch ---
--- 0.19454193115234375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06165049]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09832101]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.4037905]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3328438]
 [ 0.       ]]
--- 0.16515183448791504 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5417.7900390625, (3060.5208, 0.69252074, 2356.4116, 0.16514497)
   validation loss 2095.5205078125, (1728.6987, 0.14498393, 366.51172, 0.16514497)
decoder loss ratio: 66972.789971, decoder SINDy loss  ratio: 0.791167
--- 0.18877935409545898 seconds for one epoch ---
--- 0.5546317100524902 seconds for one epoch ---
--- 0.1932985782623291 seconds for one epoch ---
--- 0.5778934955596924 seconds for one epoch ---
--- 0.18862199783325195 seconds for one epoch ---
--- 0.5164880752563477 seconds for one epoch ---
--- 0.21487689018249512 seconds for one epoch ---
--- 0.4828057289123535 seconds for one epoch ---
--- 0.20906352996826172 seconds for one epoch ---
--- 0.5423076152801514 seconds for one epoch ---
--- 0.24308347702026367 seconds for one epoch ---
--- 0.50113844871521 seconds for one epoch ---
--- 0.19040393829345703 seconds for one epoch ---
--- 0.5143051147460938 seconds for one epoch ---
--- 0.2062091827392578 seconds for one epoch ---
--- 0.5150723457336426 seconds for one epoch ---
--- 0.2097630500793457 seconds for one epoch ---
--- 0.5058465003967285 seconds for one epoch ---
--- 0.2199714183807373 seconds for one epoch ---
--- 0.5593287944793701 seconds for one epoch ---
--- 0.21164321899414062 seconds for one epoch ---
--- 0.5389533042907715 seconds for one epoch ---
--- 0.20602679252624512 seconds for one epoch ---
--- 0.5356266498565674 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05909884]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09736985]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3549523]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3333676]
 [ 0.       ]]
--- 0.17682456970214844 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3938.896484375, (1968.5118, 2.028684, 1968.1917, 0.16419578)
   validation loss 1621.5518798828125, (1231.6332, 0.10743065, 389.6471, 0.16419578)
decoder loss ratio: 47715.607552, decoder SINDy loss  ratio: 0.841108
--- 0.17483830451965332 seconds for one epoch ---
--- 0.21587324142456055 seconds for one epoch ---
--- 0.4881479740142822 seconds for one epoch ---
--- 0.23287439346313477 seconds for one epoch ---
--- 0.532578706741333 seconds for one epoch ---
--- 0.21042847633361816 seconds for one epoch ---
--- 0.5200660228729248 seconds for one epoch ---
--- 0.20140910148620605 seconds for one epoch ---
--- 0.516643762588501 seconds for one epoch ---
--- 0.22603154182434082 seconds for one epoch ---
--- 0.5484335422515869 seconds for one epoch ---
--- 0.17738127708435059 seconds for one epoch ---
--- 0.6282525062561035 seconds for one epoch ---
--- 0.29804182052612305 seconds for one epoch ---
--- 0.5466361045837402 seconds for one epoch ---
--- 0.19707131385803223 seconds for one epoch ---
--- 0.5113518238067627 seconds for one epoch ---
--- 0.1490473747253418 seconds for one epoch ---
--- 0.5338113307952881 seconds for one epoch ---
--- 0.20025062561035156 seconds for one epoch ---
--- 0.5497667789459229 seconds for one epoch ---
--- 0.19632339477539062 seconds for one epoch ---
--- 0.5305376052856445 seconds for one epoch ---
--- 0.18888330459594727 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05762457]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09643115]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3365446]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3318765]
 [ 0.       ]]
--- 0.17710041999816895 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4478.21240234375, (1737.6171, 0.726668, 2739.705, 0.16380616)
   validation loss 1527.769775390625, (1164.8397, 0.078909576, 362.68732, 0.16380616)
decoder loss ratio: 45127.913069, decoder SINDy loss  ratio: 0.782912
--- 0.1868910789489746 seconds for one epoch ---
--- 0.5000450611114502 seconds for one epoch ---
--- 0.3239600658416748 seconds for one epoch ---
--- 0.5075292587280273 seconds for one epoch ---
--- 0.1866147518157959 seconds for one epoch ---
--- 0.5634298324584961 seconds for one epoch ---
--- 0.18732428550720215 seconds for one epoch ---
--- 0.5359585285186768 seconds for one epoch ---
--- 0.18381595611572266 seconds for one epoch ---
--- 0.4864363670349121 seconds for one epoch ---
--- 0.20340275764465332 seconds for one epoch ---
--- 0.5581600666046143 seconds for one epoch ---
--- 0.19002962112426758 seconds for one epoch ---
--- 0.5629632472991943 seconds for one epoch ---
--- 0.18857264518737793 seconds for one epoch ---
--- 0.5798182487487793 seconds for one epoch ---
--- 0.2314774990081787 seconds for one epoch ---
--- 0.5818049907684326 seconds for one epoch ---
--- 0.1861891746520996 seconds for one epoch ---
--- 0.567617654800415 seconds for one epoch ---
--- 0.21779417991638184 seconds for one epoch ---
--- 0.5119941234588623 seconds for one epoch ---
--- 0.17253947257995605 seconds for one epoch ---
--- 0.5361247062683105 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05646146]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09592265]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.3210258]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.3349938]
 [ 0.       ]]
--- 0.19876408576965332 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1835.8154296875, (1018.9843, 0.46744666, 816.1999, 0.16386335)
   validation loss 1539.63720703125, (1171.5723, 0.07711912, 367.82397, 0.16386335)
decoder loss ratio: 45388.743509, decoder SINDy loss  ratio: 0.794000
--- 0.14779448509216309 seconds for one epoch ---
--- 0.18285322189331055 seconds for one epoch ---
--- 0.5225403308868408 seconds for one epoch ---
--- 0.2213423252105713 seconds for one epoch ---
--- 0.5741767883300781 seconds for one epoch ---
--- 0.2069551944732666 seconds for one epoch ---
--- 0.5398538112640381 seconds for one epoch ---
--- 0.20487666130065918 seconds for one epoch ---
--- 0.5542564392089844 seconds for one epoch ---
--- 0.17342257499694824 seconds for one epoch ---
--- 0.5055944919586182 seconds for one epoch ---
--- 0.18271708488464355 seconds for one epoch ---
--- 0.5657863616943359 seconds for one epoch ---
--- 0.20411038398742676 seconds for one epoch ---
--- 0.5192205905914307 seconds for one epoch ---
--- 0.1951141357421875 seconds for one epoch ---
--- 0.6172962188720703 seconds for one epoch ---
--- 0.1970686912536621 seconds for one epoch ---
--- 0.5545933246612549 seconds for one epoch ---
--- 0.16311931610107422 seconds for one epoch ---
--- 0.5680789947509766 seconds for one epoch ---
--- 0.20621013641357422 seconds for one epoch ---
--- 0.5675520896911621 seconds for one epoch ---
--- 0.2309277057647705 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05489304]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09755224]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2896023]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.380791 ]
 [ 0.       ]]
--- 0.1741321086883545 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2930.484375, (1475.5387, 1.8446462, 1452.937, 0.16396978)
   validation loss 939.3723754882812, (647.68896, 0.1393731, 291.38013, 0.16396978)
decoder loss ratio: 25092.594936, decoder SINDy loss  ratio: 0.628985
--- 0.17234182357788086 seconds for one epoch ---
--- 0.5275356769561768 seconds for one epoch ---
--- 0.20680880546569824 seconds for one epoch ---
--- 0.537222146987915 seconds for one epoch ---
--- 0.1965498924255371 seconds for one epoch ---
--- 0.5381953716278076 seconds for one epoch ---
--- 0.18079900741577148 seconds for one epoch ---
--- 0.5967483520507812 seconds for one epoch ---
--- 0.18905425071716309 seconds for one epoch ---
--- 0.6205453872680664 seconds for one epoch ---
--- 0.18839812278747559 seconds for one epoch ---
--- 0.5830557346343994 seconds for one epoch ---
--- 0.20574474334716797 seconds for one epoch ---
--- 0.6596918106079102 seconds for one epoch ---
--- 0.14972829818725586 seconds for one epoch ---
--- 0.5533759593963623 seconds for one epoch ---
--- 0.1641998291015625 seconds for one epoch ---
--- 0.5410737991333008 seconds for one epoch ---
--- 0.1831512451171875 seconds for one epoch ---
--- 0.5955243110656738 seconds for one epoch ---
--- 0.29144287109375 seconds for one epoch ---
--- 0.5206282138824463 seconds for one epoch ---
--- 0.20056819915771484 seconds for one epoch ---
--- 0.5812182426452637 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05417927]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09931516]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.281422 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.4256024]
 [ 0.       ]]
--- 0.1880478858947754 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2272.34423828125, (1437.6611, 0.22353059, 834.2948, 0.16484407)
   validation loss 1507.328125, (1116.0822, 0.09467357, 390.9865, 0.16484407)
decoder loss ratio: 43238.960223, decoder SINDy loss  ratio: 0.843999
--- 0.15483999252319336 seconds for one epoch ---
--- 0.20511102676391602 seconds for one epoch ---
--- 0.5835626125335693 seconds for one epoch ---
--- 0.21211838722229004 seconds for one epoch ---
--- 0.603057861328125 seconds for one epoch ---
--- 0.18782591819763184 seconds for one epoch ---
--- 0.5783934593200684 seconds for one epoch ---
--- 0.1860799789428711 seconds for one epoch ---
--- 0.5959818363189697 seconds for one epoch ---
--- 0.20558905601501465 seconds for one epoch ---
--- 0.5840733051300049 seconds for one epoch ---
--- 0.19388818740844727 seconds for one epoch ---
--- 0.5323638916015625 seconds for one epoch ---
--- 0.19444870948791504 seconds for one epoch ---
--- 0.5530416965484619 seconds for one epoch ---
--- 0.1711575984954834 seconds for one epoch ---
--- 0.5739297866821289 seconds for one epoch ---
--- 0.17383837699890137 seconds for one epoch ---
--- 0.5850167274475098 seconds for one epoch ---
--- 0.2096843719482422 seconds for one epoch ---
--- 0.5999999046325684 seconds for one epoch ---
--- 0.2537956237792969 seconds for one epoch ---
--- 0.5472698211669922 seconds for one epoch ---
--- 0.1726982593536377 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05427693]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1012172 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2985251]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.471445 ]
 [ 0.       ]]
--- 0.18707680702209473 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2635.489990234375, (1577.863, 0.8612073, 1056.5997, 0.1659149)
   validation loss 2604.408447265625, (2289.5073, 0.14850888, 314.58676, 0.1659149)
decoder loss ratio: 88699.488500, decoder SINDy loss  ratio: 0.679080
--- 0.20735931396484375 seconds for one epoch ---
--- 0.5622048377990723 seconds for one epoch ---
--- 0.20479917526245117 seconds for one epoch ---
--- 0.600933313369751 seconds for one epoch ---
--- 0.19425725936889648 seconds for one epoch ---
--- 0.5637679100036621 seconds for one epoch ---
--- 0.17769193649291992 seconds for one epoch ---
--- 0.6187245845794678 seconds for one epoch ---
--- 0.19837689399719238 seconds for one epoch ---
--- 0.587019681930542 seconds for one epoch ---
--- 0.18193888664245605 seconds for one epoch ---
--- 0.6373133659362793 seconds for one epoch ---
--- 0.21682429313659668 seconds for one epoch ---
--- 0.6568441390991211 seconds for one epoch ---
--- 0.19796371459960938 seconds for one epoch ---
--- 0.5701563358306885 seconds for one epoch ---
--- 0.23635053634643555 seconds for one epoch ---
--- 0.6787440776824951 seconds for one epoch ---
--- 0.21039438247680664 seconds for one epoch ---
--- 0.5453956127166748 seconds for one epoch ---
--- 0.16143417358398438 seconds for one epoch ---
--- 0.5770900249481201 seconds for one epoch ---
--- 0.21200990676879883 seconds for one epoch ---
--- 0.6183922290802002 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05294468]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1021725 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2649164]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.4961972]
 [ 0.       ]]
--- 0.21056175231933594 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5051.576171875, (1874.9415, 3.192069, 3173.2766, 0.16594182)
   validation loss 1935.8187255859375, (1569.0299, 0.15728025, 366.46564, 0.16594182)
decoder loss ratio: 60786.942562, decoder SINDy loss  ratio: 0.791068
--- 0.16542744636535645 seconds for one epoch ---
--- 0.19594883918762207 seconds for one epoch ---
--- 0.573570728302002 seconds for one epoch ---
--- 0.22249960899353027 seconds for one epoch ---
--- 0.6023280620574951 seconds for one epoch ---
--- 0.17274856567382812 seconds for one epoch ---
--- 0.6031348705291748 seconds for one epoch ---
--- 0.22638916969299316 seconds for one epoch ---
--- 0.632972240447998 seconds for one epoch ---
--- 0.1892561912536621 seconds for one epoch ---
--- 0.6788740158081055 seconds for one epoch ---
--- 0.19966459274291992 seconds for one epoch ---
--- 0.723259687423706 seconds for one epoch ---
--- 0.2202298641204834 seconds for one epoch ---
--- 0.5881366729736328 seconds for one epoch ---
--- 0.21799230575561523 seconds for one epoch ---
--- 0.589261531829834 seconds for one epoch ---
--- 0.20336151123046875 seconds for one epoch ---
--- 0.6184380054473877 seconds for one epoch ---
--- 0.17821073532104492 seconds for one epoch ---
--- 0.6095185279846191 seconds for one epoch ---
--- 0.1920299530029297 seconds for one epoch ---
--- 0.6229760646820068 seconds for one epoch ---
--- 0.20872879028320312 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05222534]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10741014]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2504568]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.6017935]
 [ 0.       ]]
--- 0.18204712867736816 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2419.236083984375, (1046.7324, 0.7872123, 1371.5486, 0.16775064)
   validation loss 1158.5960693359375, (892.33746, 0.17065866, 265.9202, 0.16775064)
decoder loss ratio: 34570.702497, decoder SINDy loss  ratio: 0.574026
--- 0.20674967765808105 seconds for one epoch ---
--- 0.6754601001739502 seconds for one epoch ---
--- 0.179642915725708 seconds for one epoch ---
--- 0.5644030570983887 seconds for one epoch ---
--- 0.1813056468963623 seconds for one epoch ---
--- 0.6221849918365479 seconds for one epoch ---
--- 0.21843433380126953 seconds for one epoch ---
--- 0.5937709808349609 seconds for one epoch ---
--- 0.19778203964233398 seconds for one epoch ---
--- 0.6368808746337891 seconds for one epoch ---
--- 0.2065882682800293 seconds for one epoch ---
--- 0.6301512718200684 seconds for one epoch ---
--- 0.18544697761535645 seconds for one epoch ---
--- 0.6341574192047119 seconds for one epoch ---
--- 0.1930398941040039 seconds for one epoch ---
--- 0.7105095386505127 seconds for one epoch ---
--- 0.17887663841247559 seconds for one epoch ---
--- 0.6133670806884766 seconds for one epoch ---
--- 0.18709230422973633 seconds for one epoch ---
--- 0.6220929622650146 seconds for one epoch ---
--- 0.19942879676818848 seconds for one epoch ---
--- 0.6193046569824219 seconds for one epoch ---
--- 0.20224475860595703 seconds for one epoch ---
--- 0.5824527740478516 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05314182]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11331614]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2884876]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7142706]
 [ 0.       ]]
--- 0.20006823539733887 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2976.139404296875, (2191.9895, 0.43681297, 783.54224, 0.17099829)
   validation loss 1173.9365234375, (909.5949, 0.18152694, 263.98904, 0.17099829)
decoder loss ratio: 35239.285927, decoder SINDy loss  ratio: 0.569857
--- 0.17325401306152344 seconds for one epoch ---
--- 0.19249558448791504 seconds for one epoch ---
--- 0.6570272445678711 seconds for one epoch ---
--- 0.2043933868408203 seconds for one epoch ---
--- 0.6704394817352295 seconds for one epoch ---
--- 0.29343104362487793 seconds for one epoch ---
--- 0.6170458793640137 seconds for one epoch ---
--- 0.18494534492492676 seconds for one epoch ---
--- 0.6251485347747803 seconds for one epoch ---
--- 0.19997692108154297 seconds for one epoch ---
--- 0.6129050254821777 seconds for one epoch ---
--- 0.18004536628723145 seconds for one epoch ---
--- 0.6780788898468018 seconds for one epoch ---
--- 0.2138211727142334 seconds for one epoch ---
--- 0.6207904815673828 seconds for one epoch ---
--- 0.17159748077392578 seconds for one epoch ---
--- 0.6949374675750732 seconds for one epoch ---
--- 0.2109227180480957 seconds for one epoch ---
--- 0.6429338455200195 seconds for one epoch ---
--- 0.1606764793395996 seconds for one epoch ---
--- 0.7064580917358398 seconds for one epoch ---
--- 0.18941259384155273 seconds for one epoch ---
--- 0.5976145267486572 seconds for one epoch ---
--- 0.18268680572509766 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05161869]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1189162 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2442626]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.816651 ]
 [ 0.       ]]
--- 0.2036430835723877 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3692.3935546875, (1972.658, 0.21119985, 1719.352, 0.17229071)
   validation loss 1718.2989501953125, (1451.2512, 0.17851225, 266.69696, 0.17229071)
decoder loss ratio: 56223.991773, decoder SINDy loss  ratio: 0.575703
--- 0.18081140518188477 seconds for one epoch ---
--- 0.6511430740356445 seconds for one epoch ---
--- 0.2103273868560791 seconds for one epoch ---
--- 0.5851750373840332 seconds for one epoch ---
--- 0.1829848289489746 seconds for one epoch ---
--- 0.5902862548828125 seconds for one epoch ---
--- 0.214263916015625 seconds for one epoch ---
--- 0.5765748023986816 seconds for one epoch ---
--- 0.20438623428344727 seconds for one epoch ---
--- 0.6183085441589355 seconds for one epoch ---
--- 0.19616222381591797 seconds for one epoch ---
--- 0.7112991809844971 seconds for one epoch ---
--- 0.2886831760406494 seconds for one epoch ---
--- 0.617276668548584 seconds for one epoch ---
--- 0.18700909614562988 seconds for one epoch ---
--- 0.6546075344085693 seconds for one epoch ---
--- 0.20375370979309082 seconds for one epoch ---
--- 0.6158957481384277 seconds for one epoch ---
--- 0.20882892608642578 seconds for one epoch ---
--- 0.5991911888122559 seconds for one epoch ---
--- 0.1711258888244629 seconds for one epoch ---
--- 0.6128575801849365 seconds for one epoch ---
--- 0.1678769588470459 seconds for one epoch ---
--- 0.6118254661560059 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05133461]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12444536]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.239898 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9135375]
 [ 0.       ]]
--- 0.1922142505645752 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3452.083251953125, (1803.449, 2.1723924, 1646.2876, 0.17426889)
   validation loss 1222.1383056640625, (908.0037, 0.15125893, 313.80902, 0.17426889)
decoder loss ratio: 35177.640598, decoder SINDy loss  ratio: 0.677401
--- 0.20389795303344727 seconds for one epoch ---
--- 0.19563508033752441 seconds for one epoch ---
--- 0.6686601638793945 seconds for one epoch ---
--- 0.22534632682800293 seconds for one epoch ---
--- 0.630882740020752 seconds for one epoch ---
--- 0.17260313034057617 seconds for one epoch ---
--- 0.6431746482849121 seconds for one epoch ---
--- 0.1955242156982422 seconds for one epoch ---
--- 0.660520076751709 seconds for one epoch ---
--- 0.23203587532043457 seconds for one epoch ---
--- 0.6210176944732666 seconds for one epoch ---
--- 0.16084551811218262 seconds for one epoch ---
--- 0.6581401824951172 seconds for one epoch ---
--- 0.21406292915344238 seconds for one epoch ---
--- 0.6873161792755127 seconds for one epoch ---
--- 0.19432544708251953 seconds for one epoch ---
--- 0.7007098197937012 seconds for one epoch ---
--- 0.17684173583984375 seconds for one epoch ---
--- 0.6835336685180664 seconds for one epoch ---
--- 0.20736980438232422 seconds for one epoch ---
--- 0.6252875328063965 seconds for one epoch ---
--- 0.18181133270263672 seconds for one epoch ---
--- 0.6452748775482178 seconds for one epoch ---
--- 0.16931772232055664 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05079903]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1303946 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2264879]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.0139072]
 [ 0.       ]]
--- 0.15904474258422852 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2908.18994140625, (1427.4741, 0.78612226, 1479.7535, 0.17619064)
   validation loss 1880.9031982421875, (1600.2006, 0.19753698, 280.32895, 0.17619064)
decoder loss ratio: 61994.547824, decoder SINDy loss  ratio: 0.605129
--- 0.16881155967712402 seconds for one epoch ---
--- 0.710254430770874 seconds for one epoch ---
--- 0.2864203453063965 seconds for one epoch ---
--- 0.6517913341522217 seconds for one epoch ---
--- 0.20433783531188965 seconds for one epoch ---
--- 0.6307182312011719 seconds for one epoch ---
--- 0.1996171474456787 seconds for one epoch ---
--- 0.6209447383880615 seconds for one epoch ---
--- 0.17180848121643066 seconds for one epoch ---
--- 0.6374127864837646 seconds for one epoch ---
--- 0.18526291847229004 seconds for one epoch ---
--- 0.7060377597808838 seconds for one epoch ---
--- 0.2140505313873291 seconds for one epoch ---
--- 0.6651909351348877 seconds for one epoch ---
--- 0.19512152671813965 seconds for one epoch ---
--- 0.6674766540527344 seconds for one epoch ---
--- 0.1773700714111328 seconds for one epoch ---
--- 0.6774523258209229 seconds for one epoch ---
--- 0.22824645042419434 seconds for one epoch ---
--- 0.6624517440795898 seconds for one epoch ---
--- 0.19686675071716309 seconds for one epoch ---
--- 0.6743435859680176 seconds for one epoch ---
--- 0.20708417892456055 seconds for one epoch ---
--- 0.7293500900268555 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05095417]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13676399]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2354798]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.117166 ]
 [ 0.       ]]
--- 0.18338704109191895 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4013.9501953125, (1466.2858, 0.28602704, 2547.2002, 0.17822811)
   validation loss 1599.888427734375, (1208.222, 0.308875, 391.17932, 0.17822811)
decoder loss ratio: 46808.619624, decoder SINDy loss  ratio: 0.844416
--- 0.16621637344360352 seconds for one epoch ---
--- 0.17857670783996582 seconds for one epoch ---
--- 0.6615900993347168 seconds for one epoch ---
--- 0.18915295600891113 seconds for one epoch ---
--- 0.7424602508544922 seconds for one epoch ---
--- 0.19932889938354492 seconds for one epoch ---
--- 0.6732456684112549 seconds for one epoch ---
--- 0.1808476448059082 seconds for one epoch ---
--- 0.6833393573760986 seconds for one epoch ---
--- 0.2236781120300293 seconds for one epoch ---
--- 0.6797122955322266 seconds for one epoch ---
--- 0.20891547203063965 seconds for one epoch ---
--- 0.6459887027740479 seconds for one epoch ---
--- 0.3339347839355469 seconds for one epoch ---
--- 0.6965587139129639 seconds for one epoch ---
--- 0.1907954216003418 seconds for one epoch ---
--- 0.6669561862945557 seconds for one epoch ---
--- 0.18877935409545898 seconds for one epoch ---
--- 0.7076506614685059 seconds for one epoch ---
--- 0.19220590591430664 seconds for one epoch ---
--- 0.698756217956543 seconds for one epoch ---
--- 0.19315075874328613 seconds for one epoch ---
--- 0.6853225231170654 seconds for one epoch ---
--- 0.22728729248046875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04994903]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14289702]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2045162]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2133605]
 [ 0.       ]]
--- 0.15046167373657227 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5509.12353515625, (1780.4468, 2.5779026, 3725.9192, 0.17961285)
   validation loss 896.0720825195312, (638.7793, 0.21037851, 256.9028, 0.17961285)
decoder loss ratio: 24747.418931, decoder SINDy loss  ratio: 0.554561
--- 0.17597627639770508 seconds for one epoch ---
--- 0.724494218826294 seconds for one epoch ---
--- 0.2846689224243164 seconds for one epoch ---
--- 0.6941778659820557 seconds for one epoch ---
--- 0.21855592727661133 seconds for one epoch ---
--- 0.7018647193908691 seconds for one epoch ---
--- 0.21310949325561523 seconds for one epoch ---
--- 0.6982882022857666 seconds for one epoch ---
--- 0.22057604789733887 seconds for one epoch ---
--- 0.7709600925445557 seconds for one epoch ---
--- 0.16834688186645508 seconds for one epoch ---
--- 0.6467347145080566 seconds for one epoch ---
--- 0.21862268447875977 seconds for one epoch ---
--- 0.6375472545623779 seconds for one epoch ---
--- 0.15523648262023926 seconds for one epoch ---
--- 0.696155309677124 seconds for one epoch ---
--- 0.17614316940307617 seconds for one epoch ---
--- 0.6748917102813721 seconds for one epoch ---
--- 0.19642233848571777 seconds for one epoch ---
--- 0.6969754695892334 seconds for one epoch ---
--- 0.18264055252075195 seconds for one epoch ---
--- 0.6957731246948242 seconds for one epoch ---
--- 0.17136430740356445 seconds for one epoch ---
--- 0.7267529964447021 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04985422]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14950919]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-1.203922]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-3.313535]
 [ 0.      ]]
--- 0.20579004287719727 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3018.84228515625, (1120.4941, 3.2574425, 1894.909, 0.18172958)
   validation loss 1354.6817626953125, (1085.8817, 0.3543699, 268.2639, 0.18172958)
decoder loss ratio: 42068.942769, decoder SINDy loss  ratio: 0.579085
--- 0.17166399955749512 seconds for one epoch ---
--- 0.2463085651397705 seconds for one epoch ---
--- 0.6529989242553711 seconds for one epoch ---
--- 0.20306134223937988 seconds for one epoch ---
--- 0.6803216934204102 seconds for one epoch ---
--- 0.2105731964111328 seconds for one epoch ---
--- 0.7013833522796631 seconds for one epoch ---
--- 0.20520615577697754 seconds for one epoch ---
--- 0.6674890518188477 seconds for one epoch ---
--- 0.21162676811218262 seconds for one epoch ---
--- 0.6943073272705078 seconds for one epoch ---
--- 0.1860487461090088 seconds for one epoch ---
--- 0.6976346969604492 seconds for one epoch ---
--- 0.21357226371765137 seconds for one epoch ---
--- 0.7354669570922852 seconds for one epoch ---
--- 0.18277788162231445 seconds for one epoch ---
--- 0.6854684352874756 seconds for one epoch ---
--- 0.22982239723205566 seconds for one epoch ---
--- 0.763704776763916 seconds for one epoch ---
--- 0.1744985580444336 seconds for one epoch ---
--- 0.7879490852355957 seconds for one epoch ---
--- 0.19984841346740723 seconds for one epoch ---
--- 0.6750540733337402 seconds for one epoch ---
--- 0.1990664005279541 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04955911]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15684618]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.196185 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4210734]
 [ 0.       ]]
--- 0.15981149673461914 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4792.31787109375, (2143.2886, 2.934858, 2645.9114, 0.18322042)
   validation loss 1062.5137939453125, (785.5068, 0.20066315, 276.6231, 0.18322042)
decoder loss ratio: 30431.896159, decoder SINDy loss  ratio: 0.597130
--- 0.18546533584594727 seconds for one epoch ---
--- 0.7457015514373779 seconds for one epoch ---
--- 0.27655839920043945 seconds for one epoch ---
--- 0.7287425994873047 seconds for one epoch ---
--- 0.2151796817779541 seconds for one epoch ---
--- 0.7713115215301514 seconds for one epoch ---
--- 0.19910359382629395 seconds for one epoch ---
--- 0.7438857555389404 seconds for one epoch ---
--- 0.1651477813720703 seconds for one epoch ---
--- 0.8025205135345459 seconds for one epoch ---
--- 0.2223670482635498 seconds for one epoch ---
--- 0.7333343029022217 seconds for one epoch ---
--- 0.20493102073669434 seconds for one epoch ---
--- 0.6863341331481934 seconds for one epoch ---
--- 0.2561030387878418 seconds for one epoch ---
--- 0.6506485939025879 seconds for one epoch ---
--- 0.1674354076385498 seconds for one epoch ---
--- 0.7095334529876709 seconds for one epoch ---
--- 0.21570777893066406 seconds for one epoch ---
--- 0.6956968307495117 seconds for one epoch ---
--- 0.1823713779449463 seconds for one epoch ---
--- 0.7197308540344238 seconds for one epoch ---
--- 0.21297550201416016 seconds for one epoch ---
--- 0.7107889652252197 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04943419]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1637847 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.193781 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.5196314]
 [ 0.       ]]
--- 0.18126535415649414 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6216.677734375, (2663.7544, 7.1352544, 3545.6038, 0.18477039)
   validation loss 781.3604736328125, (522.6887, 0.18211067, 258.30487, 0.18477039)
decoder loss ratio: 20249.868468, decoder SINDy loss  ratio: 0.557587
THRESHOLDING: 1 active coefficients
--- 0.7103517055511475 seconds for one epoch ---
--- 0.1927652359008789 seconds for one epoch ---
--- 0.7434675693511963 seconds for one epoch ---
--- 0.18044614791870117 seconds for one epoch ---
--- 0.7352354526519775 seconds for one epoch ---
--- 0.19674205780029297 seconds for one epoch ---
--- 0.7461402416229248 seconds for one epoch ---
--- 0.17561817169189453 seconds for one epoch ---
--- 0.8035297393798828 seconds for one epoch ---
--- 0.2107234001159668 seconds for one epoch ---
--- 0.6924905776977539 seconds for one epoch ---
--- 0.2140333652496338 seconds for one epoch ---
--- 0.7074384689331055 seconds for one epoch ---
--- 0.21386981010437012 seconds for one epoch ---
--- 0.6998617649078369 seconds for one epoch ---
--- 0.17704153060913086 seconds for one epoch ---
--- 0.7257633209228516 seconds for one epoch ---
--- 0.16044974327087402 seconds for one epoch ---
--- 0.7416369915008545 seconds for one epoch ---
--- 0.21051788330078125 seconds for one epoch ---
--- 0.7519903182983398 seconds for one epoch ---
--- 0.23243284225463867 seconds for one epoch ---
--- 0.8094558715820312 seconds for one epoch ---
--- 0.29486584663391113 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19884884]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.9792826]
 [ 0.       ]]
--- 0.17485737800598145 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2945.6962890625, (1359.2563, 1.8806272, 1584.4612, 0.09819051)
   validation loss 1432.205322265625, (1045.964, 0.2629422, 385.8802, 0.09819051)
decoder loss ratio: 40522.460817, decoder SINDy loss  ratio: 0.832977
--- 0.17213988304138184 seconds for one epoch ---
--- 0.7608575820922852 seconds for one epoch ---
--- 0.22437715530395508 seconds for one epoch ---
--- 0.6804256439208984 seconds for one epoch ---
--- 0.16340184211730957 seconds for one epoch ---
--- 0.7588646411895752 seconds for one epoch ---
--- 0.19234538078308105 seconds for one epoch ---
--- 0.7595245838165283 seconds for one epoch ---
--- 0.18025970458984375 seconds for one epoch ---
--- 0.7093601226806641 seconds for one epoch ---
--- 0.17943978309631348 seconds for one epoch ---
--- 0.8170342445373535 seconds for one epoch ---
--- 0.222365140914917 seconds for one epoch ---
--- 0.7555642127990723 seconds for one epoch ---
--- 0.19956254959106445 seconds for one epoch ---
--- 0.7107334136962891 seconds for one epoch ---
--- 0.18788456916809082 seconds for one epoch ---
--- 0.7257373332977295 seconds for one epoch ---
--- 0.2030658721923828 seconds for one epoch ---
--- 0.7351782321929932 seconds for one epoch ---
--- 0.19002389907836914 seconds for one epoch ---
--- 0.7590816020965576 seconds for one epoch ---
--- 0.19097113609313965 seconds for one epoch ---
--- 0.7499446868896484 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.23775633]
 [0.        ]]
[[-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-4.43868]
 [ 0.     ]]
--- 0.18151354789733887 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2908.560546875, (1455.1666, 0.66641134, 1452.6171, 0.110460185)
   validation loss 931.08740234375, (636.41907, 0.13928911, 294.41858, 0.110460185)
decoder loss ratio: 24655.979542, decoder SINDy loss  ratio: 0.635544
--- 0.1533210277557373 seconds for one epoch ---
--- 0.21608710289001465 seconds for one epoch ---
--- 0.7310879230499268 seconds for one epoch ---
--- 0.1684730052947998 seconds for one epoch ---
--- 0.8086516857147217 seconds for one epoch ---
--- 0.30023646354675293 seconds for one epoch ---
--- 0.6685280799865723 seconds for one epoch ---
--- 0.1962587833404541 seconds for one epoch ---
--- 0.7807633876800537 seconds for one epoch ---
--- 0.23231148719787598 seconds for one epoch ---
--- 0.7461166381835938 seconds for one epoch ---
--- 0.19626307487487793 seconds for one epoch ---
--- 0.8051583766937256 seconds for one epoch ---
--- 0.17451214790344238 seconds for one epoch ---
--- 0.7591769695281982 seconds for one epoch ---
--- 0.2134084701538086 seconds for one epoch ---
--- 0.7487185001373291 seconds for one epoch ---
--- 0.20613694190979004 seconds for one epoch ---
--- 0.7694399356842041 seconds for one epoch ---
--- 0.19816970825195312 seconds for one epoch ---
--- 0.835456371307373 seconds for one epoch ---
--- 0.22803235054016113 seconds for one epoch ---
--- 0.8073577880859375 seconds for one epoch ---
--- 0.21013998985290527 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27568784]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.853308]
 [ 0.      ]]
--- 0.16771960258483887 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3659.30615234375, (1915.699, 1.1662117, 1742.3184, 0.1225152)
   validation loss 1016.3565673828125, (714.94666, 0.19076154, 301.09668, 0.1225152)
decoder loss ratio: 27698.274627, decoder SINDy loss  ratio: 0.649960
--- 0.15860271453857422 seconds for one epoch ---
--- 0.7538788318634033 seconds for one epoch ---
--- 0.19391107559204102 seconds for one epoch ---
--- 0.7578396797180176 seconds for one epoch ---
--- 0.20739269256591797 seconds for one epoch ---
--- 0.7286167144775391 seconds for one epoch ---
--- 0.18619632720947266 seconds for one epoch ---
--- 0.7775347232818604 seconds for one epoch ---
--- 0.18066191673278809 seconds for one epoch ---
--- 0.7565972805023193 seconds for one epoch ---
--- 0.21598029136657715 seconds for one epoch ---
--- 0.7187869548797607 seconds for one epoch ---
--- 0.17936038970947266 seconds for one epoch ---
--- 0.7524416446685791 seconds for one epoch ---
--- 0.20392847061157227 seconds for one epoch ---
--- 0.7465448379516602 seconds for one epoch ---
--- 0.19168949127197266 seconds for one epoch ---
--- 0.8397998809814453 seconds for one epoch ---
--- 0.30846619606018066 seconds for one epoch ---
--- 0.7445826530456543 seconds for one epoch ---
--- 0.20030570030212402 seconds for one epoch ---
--- 0.7566545009613037 seconds for one epoch ---
--- 0.21353769302368164 seconds for one epoch ---
--- 0.7799551486968994 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3156441]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-5.267515]
 [ 0.      ]]
--- 0.17686676979064941 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2431.948974609375, (1439.2048, 0.6028269, 992.0072, 0.13407663)
   validation loss 1051.359619140625, (743.31964, 0.15397285, 307.7519, 0.13407663)
decoder loss ratio: 28797.493356, decoder SINDy loss  ratio: 0.664326
--- 0.13605713844299316 seconds for one epoch ---
--- 0.1892375946044922 seconds for one epoch ---
--- 0.7624328136444092 seconds for one epoch ---
--- 0.17415213584899902 seconds for one epoch ---
--- 0.744035005569458 seconds for one epoch ---
--- 0.20408415794372559 seconds for one epoch ---
--- 0.7285420894622803 seconds for one epoch ---
--- 0.17026638984680176 seconds for one epoch ---
--- 0.7662484645843506 seconds for one epoch ---
--- 0.1880662441253662 seconds for one epoch ---
--- 0.7834582328796387 seconds for one epoch ---
--- 0.2025470733642578 seconds for one epoch ---
--- 0.7807199954986572 seconds for one epoch ---
--- 0.1959230899810791 seconds for one epoch ---
--- 0.7213046550750732 seconds for one epoch ---
--- 0.17151546478271484 seconds for one epoch ---
--- 0.7695953845977783 seconds for one epoch ---
--- 0.22321724891662598 seconds for one epoch ---
--- 0.8451611995697021 seconds for one epoch ---
--- 0.28191208839416504 seconds for one epoch ---
--- 0.7733860015869141 seconds for one epoch ---
--- 0.2196788787841797 seconds for one epoch ---
--- 0.7742974758148193 seconds for one epoch ---
--- 0.2551572322845459 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35237497]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.6362133]
 [-0.       ]]
--- 0.1859722137451172 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3213.424560546875, (1754.8235, 1.7637496, 1456.6926, 0.1448179)
   validation loss 2155.753173828125, (1793.0421, 0.1286678, 362.4377, 0.1448179)
decoder loss ratio: 69465.564364, decoder SINDy loss  ratio: 0.782373
--- 0.22510147094726562 seconds for one epoch ---
--- 0.7518939971923828 seconds for one epoch ---
--- 0.2462902069091797 seconds for one epoch ---
--- 0.7831649780273438 seconds for one epoch ---
--- 0.1962137222290039 seconds for one epoch ---
--- 0.8143374919891357 seconds for one epoch ---
--- 0.2015848159790039 seconds for one epoch ---
--- 0.7980818748474121 seconds for one epoch ---
--- 0.17474126815795898 seconds for one epoch ---
--- 0.7432057857513428 seconds for one epoch ---
--- 0.21028590202331543 seconds for one epoch ---
--- 0.7699997425079346 seconds for one epoch ---
--- 0.16648340225219727 seconds for one epoch ---
--- 0.7733774185180664 seconds for one epoch ---
--- 0.20858359336853027 seconds for one epoch ---
--- 0.7630388736724854 seconds for one epoch ---
--- 0.2050306797027588 seconds for one epoch ---
--- 0.7720434665679932 seconds for one epoch ---
--- 0.2156691551208496 seconds for one epoch ---
--- 0.7932958602905273 seconds for one epoch ---
--- 0.20440030097961426 seconds for one epoch ---
--- 0.9125759601593018 seconds for one epoch ---
--- 0.22434258460998535 seconds for one epoch ---
--- 0.7931416034698486 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39263293]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.034277]
 [-0.      ]]
--- 0.18382930755615234 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2864.5263671875, (1459.2251, 1.0157493, 1404.129, 0.15655605)
   validation loss 1097.79296875, (768.2947, 0.13080107, 329.21085, 0.15655605)
decoder loss ratio: 29765.069634, decoder SINDy loss  ratio: 0.710648
--- 0.17789554595947266 seconds for one epoch ---
--- 0.25312185287475586 seconds for one epoch ---
--- 0.7721226215362549 seconds for one epoch ---
--- 0.22194576263427734 seconds for one epoch ---
--- 0.7506685256958008 seconds for one epoch ---
--- 0.2420952320098877 seconds for one epoch ---
--- 0.8100030422210693 seconds for one epoch ---
--- 0.2070751190185547 seconds for one epoch ---
--- 0.8062894344329834 seconds for one epoch ---
--- 0.17052364349365234 seconds for one epoch ---
--- 0.7814867496490479 seconds for one epoch ---
--- 0.22328400611877441 seconds for one epoch ---
--- 0.8332061767578125 seconds for one epoch ---
--- 0.1885817050933838 seconds for one epoch ---
--- 0.8366134166717529 seconds for one epoch ---
--- 0.19055891036987305 seconds for one epoch ---
--- 0.7843677997589111 seconds for one epoch ---
--- 0.1850426197052002 seconds for one epoch ---
--- 0.8546111583709717 seconds for one epoch ---
--- 0.20054101943969727 seconds for one epoch ---
--- 0.8069286346435547 seconds for one epoch ---
--- 0.19061064720153809 seconds for one epoch ---
--- 0.7957417964935303 seconds for one epoch ---
--- 0.22957324981689453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.42912796]
 [0.        ]]
[[ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [-6.39529]
 [-0.     ]]
--- 0.17931294441223145 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3350.030029296875, (1819.8007, 0.8478113, 1529.2146, 0.16710973)
   validation loss 1263.034423828125, (961.90515, 0.1534612, 300.80872, 0.16710973)
decoder loss ratio: 37265.875505, decoder SINDy loss  ratio: 0.649338
--- 0.20851564407348633 seconds for one epoch ---
--- 0.8428676128387451 seconds for one epoch ---
--- 0.21506500244140625 seconds for one epoch ---
--- 0.7757642269134521 seconds for one epoch ---
--- 0.20009922981262207 seconds for one epoch ---
--- 0.7918860912322998 seconds for one epoch ---
--- 0.24422597885131836 seconds for one epoch ---
--- 0.8416225910186768 seconds for one epoch ---
--- 0.20368385314941406 seconds for one epoch ---
--- 0.8824663162231445 seconds for one epoch ---
--- 0.1929478645324707 seconds for one epoch ---
--- 0.8695247173309326 seconds for one epoch ---
--- 0.216461181640625 seconds for one epoch ---
--- 0.7983989715576172 seconds for one epoch ---
--- 0.18968868255615234 seconds for one epoch ---
--- 0.7702639102935791 seconds for one epoch ---
--- 0.18194794654846191 seconds for one epoch ---
--- 0.8004751205444336 seconds for one epoch ---
--- 0.21449708938598633 seconds for one epoch ---
--- 0.7992782592773438 seconds for one epoch ---
--- 0.21185994148254395 seconds for one epoch ---
--- 0.8330104351043701 seconds for one epoch ---
--- 0.21419596672058105 seconds for one epoch ---
--- 0.8411014080047607 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4633117]
 [0.       ]]
[[-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-6.73799]
 [-0.     ]]
--- 0.1832866668701172 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2803.119873046875, (1077.2327, 0.72409403, 1724.9862, 0.17710334)
   validation loss 1324.6656494140625, (986.05725, 0.14463036, 338.28668, 0.17710334)
decoder loss ratio: 38201.569774, decoder SINDy loss  ratio: 0.730239
--- 0.17700982093811035 seconds for one epoch ---
--- 0.17519903182983398 seconds for one epoch ---
--- 0.8381376266479492 seconds for one epoch ---
--- 0.18663907051086426 seconds for one epoch ---
--- 0.8233544826507568 seconds for one epoch ---
--- 0.20419526100158691 seconds for one epoch ---
--- 0.793466329574585 seconds for one epoch ---
--- 0.23815011978149414 seconds for one epoch ---
--- 0.8424780368804932 seconds for one epoch ---
--- 0.2974257469177246 seconds for one epoch ---
--- 0.8942127227783203 seconds for one epoch ---
--- 0.31337690353393555 seconds for one epoch ---
--- 0.8599720001220703 seconds for one epoch ---
--- 0.29465508460998535 seconds for one epoch ---
--- 0.8847904205322266 seconds for one epoch ---
--- 0.30153775215148926 seconds for one epoch ---
--- 0.8928670883178711 seconds for one epoch ---
--- 0.3042631149291992 seconds for one epoch ---
--- 0.8594331741333008 seconds for one epoch ---
--- 0.29899072647094727 seconds for one epoch ---
--- 0.8228271007537842 seconds for one epoch ---
--- 0.2924022674560547 seconds for one epoch ---
--- 0.8330848217010498 seconds for one epoch ---
--- 0.30066823959350586 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4979088]
 [0.       ]]
[[ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.0936017]
 [-0.       ]]
--- 0.2541804313659668 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3457.964111328125, (1984.318, 0.76520157, 1472.6935, 0.18726711)
   validation loss 1801.1439208984375, (1403.2783, 0.13826846, 397.54007, 0.18726711)
decoder loss ratio: 54365.438327, decoder SINDy loss  ratio: 0.858146
--- 0.3154268264770508 seconds for one epoch ---
--- 0.8651361465454102 seconds for one epoch ---
--- 0.32198381423950195 seconds for one epoch ---
--- 0.8377954959869385 seconds for one epoch ---
--- 0.319472074508667 seconds for one epoch ---
--- 0.8478238582611084 seconds for one epoch ---
--- 0.29576873779296875 seconds for one epoch ---
--- 0.8379132747650146 seconds for one epoch ---
--- 0.31226491928100586 seconds for one epoch ---
--- 0.853147029876709 seconds for one epoch ---
--- 0.2876551151275635 seconds for one epoch ---
--- 0.8392221927642822 seconds for one epoch ---
--- 0.30226945877075195 seconds for one epoch ---
--- 0.849639892578125 seconds for one epoch ---
--- 0.29262447357177734 seconds for one epoch ---
--- 0.8600025177001953 seconds for one epoch ---
--- 0.29619669914245605 seconds for one epoch ---
--- 0.8709709644317627 seconds for one epoch ---
--- 0.30498695373535156 seconds for one epoch ---
--- 0.8621575832366943 seconds for one epoch ---
--- 0.29947471618652344 seconds for one epoch ---
--- 0.8442761898040771 seconds for one epoch ---
--- 0.3061544895172119 seconds for one epoch ---
--- 0.8634374141693115 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5307839]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.443922]
 [-0.      ]]
--- 0.2979001998901367 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3696.906982421875, (1724.3135, 1.0325068, 1971.3641, 0.19705951)
   validation loss 785.5180053710938, (488.55505, 0.28606346, 296.47983, 0.19705951)
decoder loss ratio: 18927.470950, decoder SINDy loss  ratio: 0.639993
--- 0.2634720802307129 seconds for one epoch ---
--- 0.29264211654663086 seconds for one epoch ---
--- 0.852400541305542 seconds for one epoch ---
--- 0.3122375011444092 seconds for one epoch ---
--- 0.8497684001922607 seconds for one epoch ---
--- 0.3003256320953369 seconds for one epoch ---
--- 0.8701448440551758 seconds for one epoch ---
--- 0.2968904972076416 seconds for one epoch ---
--- 0.8532319068908691 seconds for one epoch ---
--- 0.31321001052856445 seconds for one epoch ---
--- 0.8816111087799072 seconds for one epoch ---
--- 0.31348490715026855 seconds for one epoch ---
--- 0.8846035003662109 seconds for one epoch ---
--- 0.34319210052490234 seconds for one epoch ---
--- 0.8598101139068604 seconds for one epoch ---
--- 0.33196544647216797 seconds for one epoch ---
--- 0.8746590614318848 seconds for one epoch ---
--- 0.5155949592590332 seconds for one epoch ---
--- 0.8735795021057129 seconds for one epoch ---
--- 0.3293783664703369 seconds for one epoch ---
--- 0.8690831661224365 seconds for one epoch ---
--- 0.33235597610473633 seconds for one epoch ---
--- 0.8752498626708984 seconds for one epoch ---
--- 0.32027697563171387 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5614072]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.7853193]
 [-0.       ]]
--- 0.27065181732177734 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4192.662109375, (2027.1735, 2.2821834, 2162.9998, 0.20648871)
   validation loss 815.0958251953125, (544.23926, 0.2654765, 270.38458, 0.20648871)
decoder loss ratio: 21084.773689, decoder SINDy loss  ratio: 0.583663
--- 0.28742384910583496 seconds for one epoch ---
--- 0.8899290561676025 seconds for one epoch ---
--- 0.32285118103027344 seconds for one epoch ---
--- 0.862332820892334 seconds for one epoch ---
--- 0.3225550651550293 seconds for one epoch ---
--- 0.8940303325653076 seconds for one epoch ---
--- 0.33148765563964844 seconds for one epoch ---
--- 0.8645610809326172 seconds for one epoch ---
--- 0.3330814838409424 seconds for one epoch ---
--- 0.8989624977111816 seconds for one epoch ---
--- 0.32530784606933594 seconds for one epoch ---
--- 0.8660809993743896 seconds for one epoch ---
--- 0.30979251861572266 seconds for one epoch ---
--- 0.8897843360900879 seconds for one epoch ---
--- 0.3257615566253662 seconds for one epoch ---
--- 0.8803534507751465 seconds for one epoch ---
--- 0.31124019622802734 seconds for one epoch ---
--- 0.8760159015655518 seconds for one epoch ---
--- 0.31199169158935547 seconds for one epoch ---
--- 0.8889369964599609 seconds for one epoch ---
--- 0.3081345558166504 seconds for one epoch ---
--- 0.8790583610534668 seconds for one epoch ---
--- 0.29636263847351074 seconds for one epoch ---
--- 0.8718235492706299 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.5868722]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.083627]
 [-0.      ]]
--- 0.2982163429260254 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2019.8994140625, (839.46155, 1.2244006, 1178.9988, 0.214576)
   validation loss 1052.139404296875, (753.75507, 0.21613024, 297.95358, 0.214576)
decoder loss ratio: 29201.779830, decoder SINDy loss  ratio: 0.643175
--- 0.24994301795959473 seconds for one epoch ---
--- 0.2926630973815918 seconds for one epoch ---
--- 0.8732080459594727 seconds for one epoch ---
--- 0.3196132183074951 seconds for one epoch ---
--- 0.879169225692749 seconds for one epoch ---
--- 0.30232787132263184 seconds for one epoch ---
--- 0.8865416049957275 seconds for one epoch ---
--- 0.3203003406524658 seconds for one epoch ---
--- 0.8883891105651855 seconds for one epoch ---
--- 0.29611706733703613 seconds for one epoch ---
--- 0.9013376235961914 seconds for one epoch ---
--- 0.2934226989746094 seconds for one epoch ---
--- 0.8791556358337402 seconds for one epoch ---
--- 0.3024270534515381 seconds for one epoch ---
--- 0.8885900974273682 seconds for one epoch ---
--- 0.2989373207092285 seconds for one epoch ---
--- 0.9069411754608154 seconds for one epoch ---
--- 0.31183409690856934 seconds for one epoch ---
--- 0.9138562679290771 seconds for one epoch ---
--- 0.29696106910705566 seconds for one epoch ---
--- 0.894850492477417 seconds for one epoch ---
--- 0.30912089347839355 seconds for one epoch ---
--- 0.8976213932037354 seconds for one epoch ---
--- 0.29500651359558105 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6117301]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.390766]
 [-0.      ]]
--- 0.2547190189361572 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3980.427978515625, (1722.435, 1.7184081, 2256.0518, 0.2229108)
   validation loss 1277.3089599609375, (915.12646, 0.41175634, 361.54785, 0.2229108)
decoder loss ratio: 35453.587977, decoder SINDy loss  ratio: 0.780452
--- 0.28026390075683594 seconds for one epoch ---
--- 0.88702392578125 seconds for one epoch ---
--- 0.2954864501953125 seconds for one epoch ---
--- 0.8981385231018066 seconds for one epoch ---
--- 0.30326080322265625 seconds for one epoch ---
--- 0.870018482208252 seconds for one epoch ---
--- 0.3179035186767578 seconds for one epoch ---
--- 0.9005246162414551 seconds for one epoch ---
--- 0.30312204360961914 seconds for one epoch ---
--- 0.9044640064239502 seconds for one epoch ---
--- 0.2983360290527344 seconds for one epoch ---
--- 0.8905086517333984 seconds for one epoch ---
--- 0.2978546619415283 seconds for one epoch ---
--- 0.9218025207519531 seconds for one epoch ---
--- 0.30418848991394043 seconds for one epoch ---
--- 0.9100613594055176 seconds for one epoch ---
--- 0.2989785671234131 seconds for one epoch ---
--- 0.9120969772338867 seconds for one epoch ---
--- 0.29051709175109863 seconds for one epoch ---
--- 0.9125022888183594 seconds for one epoch ---
--- 0.28548336029052734 seconds for one epoch ---
--- 0.9190709590911865 seconds for one epoch ---
--- 0.305678129196167 seconds for one epoch ---
--- 0.9330461025238037 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6343237]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.686759]
 [-0.      ]]
--- 0.28219127655029297 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2170.626220703125, (974.4744, 0.6217382, 1195.2999, 0.23033953)
   validation loss 848.7535400390625, (587.9416, 0.26914144, 260.31247, 0.23033953)
decoder loss ratio: 22777.877883, decoder SINDy loss  ratio: 0.561921
--- 0.26677441596984863 seconds for one epoch ---
--- 0.30264830589294434 seconds for one epoch ---
--- 0.9007184505462646 seconds for one epoch ---
--- 0.3099994659423828 seconds for one epoch ---
--- 0.9034478664398193 seconds for one epoch ---
--- 0.3015446662902832 seconds for one epoch ---
--- 0.8879148960113525 seconds for one epoch ---
--- 0.2837564945220947 seconds for one epoch ---
--- 0.9202420711517334 seconds for one epoch ---
--- 0.29948902130126953 seconds for one epoch ---
--- 0.9110467433929443 seconds for one epoch ---
--- 0.29447007179260254 seconds for one epoch ---
--- 0.9173746109008789 seconds for one epoch ---
--- 0.3189833164215088 seconds for one epoch ---
--- 0.9493651390075684 seconds for one epoch ---
--- 0.3249824047088623 seconds for one epoch ---
--- 0.9378523826599121 seconds for one epoch ---
--- 0.33695363998413086 seconds for one epoch ---
--- 0.9149854183197021 seconds for one epoch ---
--- 0.31447839736938477 seconds for one epoch ---
--- 0.9222140312194824 seconds for one epoch ---
--- 0.32523250579833984 seconds for one epoch ---
--- 0.9356553554534912 seconds for one epoch ---
--- 0.30633974075317383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.65336007]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-8.951311]
 [-0.      ]]
--- 0.25568318367004395 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4651.42529296875, (1294.8389, 2.9936495, 3353.3555, 0.23710476)
   validation loss 1219.6597900390625, (900.0486, 0.15913674, 319.21503, 0.23710476)
decoder loss ratio: 34869.444697, decoder SINDy loss  ratio: 0.689071
--- 0.31046533584594727 seconds for one epoch ---
--- 0.9253013134002686 seconds for one epoch ---
--- 0.29549241065979004 seconds for one epoch ---
--- 0.9244580268859863 seconds for one epoch ---
--- 0.2833900451660156 seconds for one epoch ---
--- 0.9010498523712158 seconds for one epoch ---
--- 0.30004239082336426 seconds for one epoch ---
--- 0.8857908248901367 seconds for one epoch ---
--- 0.2881593704223633 seconds for one epoch ---
--- 0.9168314933776855 seconds for one epoch ---
--- 0.31880736351013184 seconds for one epoch ---
--- 0.9087021350860596 seconds for one epoch ---
--- 0.301713228225708 seconds for one epoch ---
--- 0.9346888065338135 seconds for one epoch ---
--- 0.3040804862976074 seconds for one epoch ---
--- 0.9436748027801514 seconds for one epoch ---
--- 0.2939441204071045 seconds for one epoch ---
--- 0.9522182941436768 seconds for one epoch ---
--- 0.3197774887084961 seconds for one epoch ---
--- 0.953740119934082 seconds for one epoch ---
--- 0.2993285655975342 seconds for one epoch ---
--- 0.9293768405914307 seconds for one epoch ---
--- 0.30472564697265625 seconds for one epoch ---
--- 0.945094108581543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.67076063]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.207649]
 [-0.      ]]
--- 0.29019951820373535 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2128.870361328125, (1253.1421, 1.0256586, 874.45935, 0.24351454)
   validation loss 915.0489501953125, (603.2496, 0.18026261, 311.37564, 0.24351454)
decoder loss ratio: 23370.935736, decoder SINDy loss  ratio: 0.672148
--- 0.2531774044036865 seconds for one epoch ---
--- 0.2884056568145752 seconds for one epoch ---
--- 0.9285449981689453 seconds for one epoch ---
--- 0.30230116844177246 seconds for one epoch ---
--- 0.9371318817138672 seconds for one epoch ---
--- 0.2979850769042969 seconds for one epoch ---
--- 0.9132890701293945 seconds for one epoch ---
--- 0.2887856960296631 seconds for one epoch ---
--- 0.9353311061859131 seconds for one epoch ---
--- 0.3144495487213135 seconds for one epoch ---
--- 0.9466655254364014 seconds for one epoch ---
--- 0.3109304904937744 seconds for one epoch ---
--- 0.9291698932647705 seconds for one epoch ---
--- 0.3003504276275635 seconds for one epoch ---
--- 0.9478189945220947 seconds for one epoch ---
--- 0.31359386444091797 seconds for one epoch ---
--- 0.9448442459106445 seconds for one epoch ---
--- 0.29726600646972656 seconds for one epoch ---
--- 0.9531700611114502 seconds for one epoch ---
--- 0.30013108253479004 seconds for one epoch ---
--- 0.9233734607696533 seconds for one epoch ---
--- 0.3003242015838623 seconds for one epoch ---
--- 0.9297497272491455 seconds for one epoch ---
--- 0.3045046329498291 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6901957]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.513617]
 [-0.      ]]
--- 0.25316882133483887 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2487.134765625, (1275.5507, 1.0150673, 1210.3181, 0.25106332)
   validation loss 1099.1201171875, (799.6038, 0.19719307, 299.06802, 0.25106332)
decoder loss ratio: 30978.040191, decoder SINDy loss  ratio: 0.645580
--- 0.28930020332336426 seconds for one epoch ---
--- 0.9354443550109863 seconds for one epoch ---
--- 0.29903340339660645 seconds for one epoch ---
--- 0.9250316619873047 seconds for one epoch ---
--- 0.3053700923919678 seconds for one epoch ---
--- 0.9473059177398682 seconds for one epoch ---
--- 0.31128931045532227 seconds for one epoch ---
--- 0.965519905090332 seconds for one epoch ---
--- 0.29854583740234375 seconds for one epoch ---
--- 0.960399866104126 seconds for one epoch ---
--- 0.3047926425933838 seconds for one epoch ---
--- 0.9568080902099609 seconds for one epoch ---
--- 0.298250675201416 seconds for one epoch ---
--- 0.9693193435668945 seconds for one epoch ---
--- 0.30437135696411133 seconds for one epoch ---
--- 1.0148687362670898 seconds for one epoch ---
--- 0.27987051010131836 seconds for one epoch ---
--- 0.9531683921813965 seconds for one epoch ---
--- 0.3035898208618164 seconds for one epoch ---
--- 0.9912517070770264 seconds for one epoch ---
--- 0.29834961891174316 seconds for one epoch ---
--- 0.9473867416381836 seconds for one epoch ---
--- 0.3091099262237549 seconds for one epoch ---
--- 0.9527335166931152 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7049831]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.763003]
 [-0.      ]]
--- 0.30359506607055664 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2138.593505859375, (1099.8606, 6.123991, 1032.3517, 0.25703257)
   validation loss 1672.9976806640625, (1332.2336, 0.21745795, 340.28952, 0.25703257)
decoder loss ratio: 51613.044173, decoder SINDy loss  ratio: 0.734563
--- 0.2622530460357666 seconds for one epoch ---
--- 0.3053872585296631 seconds for one epoch ---
--- 0.9042718410491943 seconds for one epoch ---
--- 0.2806525230407715 seconds for one epoch ---
--- 0.9602808952331543 seconds for one epoch ---
--- 0.32729434967041016 seconds for one epoch ---
--- 0.9656422138214111 seconds for one epoch ---
--- 0.3387875556945801 seconds for one epoch ---
--- 0.9779572486877441 seconds for one epoch ---
--- 0.32306361198425293 seconds for one epoch ---
--- 0.974860668182373 seconds for one epoch ---
--- 0.3379495143890381 seconds for one epoch ---
--- 0.9679121971130371 seconds for one epoch ---
--- 0.33134007453918457 seconds for one epoch ---
--- 0.9943325519561768 seconds for one epoch ---
--- 0.3450753688812256 seconds for one epoch ---
--- 0.972456693649292 seconds for one epoch ---
--- 0.2880551815032959 seconds for one epoch ---
--- 0.9475383758544922 seconds for one epoch ---
--- 0.32305145263671875 seconds for one epoch ---
--- 0.9621427059173584 seconds for one epoch ---
--- 0.2724301815032959 seconds for one epoch ---
--- 0.9630293846130371 seconds for one epoch ---
--- 0.2973759174346924 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7192309]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.019499]
 [ -0.      ]]
--- 0.25726866722106934 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3337.713623046875, (1949.6451, 0.8223113, 1386.9834, 0.26297814)
   validation loss 1434.971435546875, (1077.4901, 0.24742667, 356.971, 0.26297814)
decoder loss ratio: 41743.837556, decoder SINDy loss  ratio: 0.770572
--- 0.2991182804107666 seconds for one epoch ---
--- 0.9482972621917725 seconds for one epoch ---
--- 0.29450440406799316 seconds for one epoch ---
--- 0.9719164371490479 seconds for one epoch ---
--- 0.2921462059020996 seconds for one epoch ---
--- 0.913017749786377 seconds for one epoch ---
--- 0.30367326736450195 seconds for one epoch ---
--- 0.9436497688293457 seconds for one epoch ---
--- 0.34433698654174805 seconds for one epoch ---
--- 0.9612033367156982 seconds for one epoch ---
--- 0.33069849014282227 seconds for one epoch ---
--- 0.9939620494842529 seconds for one epoch ---
--- 0.3287694454193115 seconds for one epoch ---
--- 0.9753773212432861 seconds for one epoch ---
--- 0.33097147941589355 seconds for one epoch ---
--- 0.9789285659790039 seconds for one epoch ---
--- 0.32684779167175293 seconds for one epoch ---
--- 0.9786224365234375 seconds for one epoch ---
--- 0.33911991119384766 seconds for one epoch ---
--- 0.9717273712158203 seconds for one epoch ---
--- 0.3283376693725586 seconds for one epoch ---
--- 0.9925410747528076 seconds for one epoch ---
--- 0.3313295841217041 seconds for one epoch ---
--- 0.9990549087524414 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7318829]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.262975]
 [ -0.      ]]
--- 0.301619291305542 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2150.08154296875, (919.03064, 0.9006734, 1229.8817, 0.26852155)
   validation loss 893.8496704101562, (618.72845, 0.31471488, 274.53802, 0.26852155)
decoder loss ratio: 23970.614491, decoder SINDy loss  ratio: 0.592629
THRESHOLDING: 1 active coefficients
--- 0.26361656188964844 seconds for one epoch ---
--- 0.2980928421020508 seconds for one epoch ---
--- 0.9735162258148193 seconds for one epoch ---
--- 0.3008873462677002 seconds for one epoch ---
--- 1.009220838546753 seconds for one epoch ---
--- 0.2992110252380371 seconds for one epoch ---
--- 0.9984445571899414 seconds for one epoch ---
--- 0.3059678077697754 seconds for one epoch ---
--- 0.9989025592803955 seconds for one epoch ---
--- 0.3181140422821045 seconds for one epoch ---
--- 0.9939253330230713 seconds for one epoch ---
--- 0.3334038257598877 seconds for one epoch ---
--- 1.0084326267242432 seconds for one epoch ---
--- 0.33915209770202637 seconds for one epoch ---
--- 1.0232245922088623 seconds for one epoch ---
--- 0.3284308910369873 seconds for one epoch ---
--- 0.979381799697876 seconds for one epoch ---
--- 0.3271498680114746 seconds for one epoch ---
--- 0.9902403354644775 seconds for one epoch ---
--- 0.34580516815185547 seconds for one epoch ---
--- 0.9968166351318359 seconds for one epoch ---
--- 0.3413546085357666 seconds for one epoch ---
--- 0.9849152565002441 seconds for one epoch ---
--- 0.3255934715270996 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7422361]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.475085]
 [ -0.      ]]
--- 0.2399001121520996 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2636.986572265625, (1378.129, 1.5348774, 1257.0596, 0.26289186)
   validation loss 714.6580200195312, (444.6239, 0.31839782, 269.45285, 0.26289186)
decoder loss ratio: 17225.501840, decoder SINDy loss  ratio: 0.581652
--- 0.3361353874206543 seconds for one epoch ---
--- 0.9907500743865967 seconds for one epoch ---
--- 0.31569790840148926 seconds for one epoch ---
--- 0.995807409286499 seconds for one epoch ---
--- 0.3219645023345947 seconds for one epoch ---
--- 0.9821426868438721 seconds for one epoch ---
--- 0.31687021255493164 seconds for one epoch ---
--- 1.0171387195587158 seconds for one epoch ---
--- 0.2994234561920166 seconds for one epoch ---
--- 1.0022413730621338 seconds for one epoch ---
--- 0.302609920501709 seconds for one epoch ---
--- 0.9836335182189941 seconds for one epoch ---
--- 0.3035714626312256 seconds for one epoch ---
--- 0.9854059219360352 seconds for one epoch ---
--- 0.3068380355834961 seconds for one epoch ---
--- 0.9786946773529053 seconds for one epoch ---
--- 0.3083772659301758 seconds for one epoch ---
--- 0.9808938503265381 seconds for one epoch ---
--- 0.29657673835754395 seconds for one epoch ---
--- 0.9989476203918457 seconds for one epoch ---
--- 0.31053638458251953 seconds for one epoch ---
--- 0.9822814464569092 seconds for one epoch ---
--- 0.2995796203613281 seconds for one epoch ---
--- 0.978736400604248 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.75227463]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.693584]
 [ -0.      ]]
--- 0.30463576316833496 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3419.4345703125, (1800.283, 1.3611242, 1617.5223, 0.26798782)
   validation loss 1506.0128173828125, (1175.7609, 0.22176804, 329.76227, 0.26798782)
decoder loss ratio: 45551.017092, decoder SINDy loss  ratio: 0.711838
--- 0.2704761028289795 seconds for one epoch ---
--- 0.315354585647583 seconds for one epoch ---
--- 0.9831993579864502 seconds for one epoch ---
--- 0.3038444519042969 seconds for one epoch ---
--- 0.9757540225982666 seconds for one epoch ---
--- 0.2741727828979492 seconds for one epoch ---
--- 0.967998743057251 seconds for one epoch ---
--- 0.30026698112487793 seconds for one epoch ---
--- 0.9932911396026611 seconds for one epoch ---
--- 0.3089561462402344 seconds for one epoch ---
--- 1.0126137733459473 seconds for one epoch ---
--- 0.30523252487182617 seconds for one epoch ---
--- 1.0161149501800537 seconds for one epoch ---
--- 0.29993700981140137 seconds for one epoch ---
--- 0.9949259757995605 seconds for one epoch ---
--- 0.3005077838897705 seconds for one epoch ---
--- 0.9914720058441162 seconds for one epoch ---
--- 0.29233360290527344 seconds for one epoch ---
--- 1.003230094909668 seconds for one epoch ---
--- 0.29590868949890137 seconds for one epoch ---
--- 0.982487678527832 seconds for one epoch ---
--- 0.3011746406555176 seconds for one epoch ---
--- 1.032923698425293 seconds for one epoch ---
--- 0.29638123512268066 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7622807]
 [0.       ]]
[[  0.   ]
 [ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [  0.   ]
 [ -0.   ]
 [ -0.   ]
 [  0.   ]
 [  0.   ]
 [-10.926]
 [ -0.   ]]
--- 0.2623138427734375 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3048.68603515625, (1411.9877, 2.966836, 1633.4584, 0.2732865)
   validation loss 1172.9066162109375, (865.32556, 0.24949682, 307.0582, 0.2732865)
decoder loss ratio: 33524.214525, decoder SINDy loss  ratio: 0.662828
--- 0.3076760768890381 seconds for one epoch ---
--- 1.016676902770996 seconds for one epoch ---
--- 0.3109264373779297 seconds for one epoch ---
--- 1.0077927112579346 seconds for one epoch ---
--- 0.29152512550354004 seconds for one epoch ---
--- 1.0230751037597656 seconds for one epoch ---
--- 0.2877984046936035 seconds for one epoch ---
--- 1.0313477516174316 seconds for one epoch ---
--- 0.29575157165527344 seconds for one epoch ---
--- 1.0370714664459229 seconds for one epoch ---
--- 0.27350473403930664 seconds for one epoch ---
--- 1.0246667861938477 seconds for one epoch ---
--- 0.3044474124908447 seconds for one epoch ---
--- 1.0098822116851807 seconds for one epoch ---
--- 0.29775071144104004 seconds for one epoch ---
--- 1.0369822978973389 seconds for one epoch ---
--- 0.2905750274658203 seconds for one epoch ---
--- 1.0301179885864258 seconds for one epoch ---
--- 0.2967531681060791 seconds for one epoch ---
--- 1.0273947715759277 seconds for one epoch ---
--- 0.2994239330291748 seconds for one epoch ---
--- 1.0185284614562988 seconds for one epoch ---
--- 0.2930030822753906 seconds for one epoch ---
--- 1.0384047031402588 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.77175486]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.161769]
 [ -0.      ]]
--- 0.3151834011077881 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4739.123046875, (2483.4385, 2.9181619, 2252.4883, 0.27852425)
   validation loss 843.2434692382812, (574.83563, 0.25760898, 267.8717, 0.27852425)
decoder loss ratio: 22270.130355, decoder SINDy loss  ratio: 0.578239
--- 0.25501465797424316 seconds for one epoch ---
--- 0.3384544849395752 seconds for one epoch ---
--- 1.0201983451843262 seconds for one epoch ---
--- 0.33203792572021484 seconds for one epoch ---
--- 1.0336229801177979 seconds for one epoch ---
--- 0.30997300148010254 seconds for one epoch ---
--- 1.0270271301269531 seconds for one epoch ---
--- 0.30723071098327637 seconds for one epoch ---
--- 1.028954267501831 seconds for one epoch ---
--- 0.29566359519958496 seconds for one epoch ---
--- 1.0330913066864014 seconds for one epoch ---
--- 0.2975285053253174 seconds for one epoch ---
--- 1.0273447036743164 seconds for one epoch ---
--- 0.2906944751739502 seconds for one epoch ---
--- 1.0099096298217773 seconds for one epoch ---
--- 0.297879695892334 seconds for one epoch ---
--- 1.0163683891296387 seconds for one epoch ---
--- 0.30907487869262695 seconds for one epoch ---
--- 1.0496327877044678 seconds for one epoch ---
--- 0.3023364543914795 seconds for one epoch ---
--- 1.0310766696929932 seconds for one epoch ---
--- 0.3073735237121582 seconds for one epoch ---
--- 1.0465545654296875 seconds for one epoch ---
--- 0.30156469345092773 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.77946883]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.366908]
 [ -0.      ]]
--- 0.26547741889953613 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3577.52001953125, (1355.4896, 0.784789, 2220.9626, 0.283079)
   validation loss 1042.2838134765625, (751.2126, 0.23493442, 290.55328, 0.283079)
decoder loss ratio: 29103.279723, decoder SINDy loss  ratio: 0.627200
--- 0.3350181579589844 seconds for one epoch ---
--- 1.0208418369293213 seconds for one epoch ---
--- 0.32277464866638184 seconds for one epoch ---
--- 1.0221672058105469 seconds for one epoch ---
--- 0.3095376491546631 seconds for one epoch ---
--- 1.033540964126587 seconds for one epoch ---
--- 0.3102414608001709 seconds for one epoch ---
--- 1.0316462516784668 seconds for one epoch ---
--- 0.29904818534851074 seconds for one epoch ---
--- 1.0328569412231445 seconds for one epoch ---
--- 0.29781436920166016 seconds for one epoch ---
--- 1.0431671142578125 seconds for one epoch ---
--- 0.2942373752593994 seconds for one epoch ---
--- 1.0316946506500244 seconds for one epoch ---
--- 0.3056979179382324 seconds for one epoch ---
--- 1.04256272315979 seconds for one epoch ---
--- 0.29866647720336914 seconds for one epoch ---
--- 1.0484800338745117 seconds for one epoch ---
--- 0.29019689559936523 seconds for one epoch ---
--- 1.0346143245697021 seconds for one epoch ---
--- 0.29028797149658203 seconds for one epoch ---
--- 1.040989875793457 seconds for one epoch ---
--- 0.3123805522918701 seconds for one epoch ---
--- 1.0496292114257812 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7861136]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.554577]
 [ -0.      ]]
--- 0.3128342628479004 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3632.025634765625, (1516.5979, 2.8136384, 2112.327, 0.28738013)
   validation loss 881.5216064453125, (597.76483, 0.29394042, 283.1755, 0.28738013)
decoder loss ratio: 23158.447339, decoder SINDy loss  ratio: 0.611274
--- 0.2717123031616211 seconds for one epoch ---
--- 0.3341059684753418 seconds for one epoch ---
--- 1.0386579036712646 seconds for one epoch ---
--- 0.32788968086242676 seconds for one epoch ---
--- 1.0887439250946045 seconds for one epoch ---
--- 0.32513904571533203 seconds for one epoch ---
--- 1.041576623916626 seconds for one epoch ---
--- 0.33486127853393555 seconds for one epoch ---
--- 1.0598018169403076 seconds for one epoch ---
--- 0.3068251609802246 seconds for one epoch ---
--- 1.0428061485290527 seconds for one epoch ---
--- 0.2950439453125 seconds for one epoch ---
--- 1.0663814544677734 seconds for one epoch ---
--- 0.29491209983825684 seconds for one epoch ---
--- 1.0892930030822754 seconds for one epoch ---
--- 0.3021361827850342 seconds for one epoch ---
--- 1.0805480480194092 seconds for one epoch ---
--- 0.2899010181427002 seconds for one epoch ---
--- 1.0863018035888672 seconds for one epoch ---
--- 0.2868022918701172 seconds for one epoch ---
--- 1.112441062927246 seconds for one epoch ---
--- 0.30768561363220215 seconds for one epoch ---
--- 1.0886752605438232 seconds for one epoch ---
--- 0.30075502395629883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.79246426]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.744892]
 [ -0.      ]]
--- 0.2702810764312744 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2430.236572265625, (1484.9829, 0.96249324, 943.9996, 0.2915709)
   validation loss 1053.3582763671875, (758.31445, 0.32750028, 294.42474, 0.2915709)
decoder loss ratio: 29378.418406, decoder SINDy loss  ratio: 0.635557
--- 0.3043782711029053 seconds for one epoch ---
--- 1.0508887767791748 seconds for one epoch ---
--- 0.3135082721710205 seconds for one epoch ---
--- 1.054962396621704 seconds for one epoch ---
--- 0.31197547912597656 seconds for one epoch ---
--- 1.064450740814209 seconds for one epoch ---
--- 0.33441829681396484 seconds for one epoch ---
--- 1.076263666152954 seconds for one epoch ---
--- 0.3318023681640625 seconds for one epoch ---
--- 1.0816619396209717 seconds for one epoch ---
--- 0.3373687267303467 seconds for one epoch ---
--- 1.0480313301086426 seconds for one epoch ---
--- 0.33221936225891113 seconds for one epoch ---
--- 1.0647857189178467 seconds for one epoch ---
--- 0.3300786018371582 seconds for one epoch ---
--- 1.0744521617889404 seconds for one epoch ---
--- 0.3227512836456299 seconds for one epoch ---
--- 1.0491456985473633 seconds for one epoch ---
--- 0.3182191848754883 seconds for one epoch ---
--- 1.0702176094055176 seconds for one epoch ---
--- 0.30590105056762695 seconds for one epoch ---
--- 1.0678107738494873 seconds for one epoch ---
--- 0.3072655200958252 seconds for one epoch ---
--- 1.087127923965454 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7981485]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.925572]
 [ -0.      ]]
--- 0.2944021224975586 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3260.96240234375, (1361.0636, 0.7277974, 1898.8754, 0.29563674)
   validation loss 1091.9697265625, (800.3305, 0.255119, 291.08847, 0.29563674)
decoder loss ratio: 31006.193213, decoder SINDy loss  ratio: 0.628355
--- 0.2801661491394043 seconds for one epoch ---
--- 0.325319766998291 seconds for one epoch ---
--- 1.0605242252349854 seconds for one epoch ---
--- 0.3289632797241211 seconds for one epoch ---
--- 1.0617790222167969 seconds for one epoch ---
--- 0.3262672424316406 seconds for one epoch ---
--- 1.0712363719940186 seconds for one epoch ---
--- 0.32355284690856934 seconds for one epoch ---
--- 1.0883584022521973 seconds for one epoch ---
--- 0.3064084053039551 seconds for one epoch ---
--- 1.106698751449585 seconds for one epoch ---
--- 0.5445113182067871 seconds for one epoch ---
--- 1.0620720386505127 seconds for one epoch ---
--- 0.33566808700561523 seconds for one epoch ---
--- 1.099308729171753 seconds for one epoch ---
--- 0.3250846862792969 seconds for one epoch ---
--- 1.0791127681732178 seconds for one epoch ---
--- 0.3387184143066406 seconds for one epoch ---
--- 1.1195404529571533 seconds for one epoch ---
--- 0.2964305877685547 seconds for one epoch ---
--- 1.0867187976837158 seconds for one epoch ---
--- 0.3047199249267578 seconds for one epoch ---
--- 1.0949509143829346 seconds for one epoch ---
--- 0.3149411678314209 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.80400544]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.123537]
 [ -0.      ]]
--- 0.2620260715484619 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3290.960693359375, (2030.664, 1.3406489, 1258.6562, 0.29992104)
   validation loss 1764.2222900390625, (1419.9889, 0.30572435, 343.62778, 0.29992104)
decoder loss ratio: 55012.834870, decoder SINDy loss  ratio: 0.741769
--- 0.29368042945861816 seconds for one epoch ---
--- 1.021803617477417 seconds for one epoch ---
--- 0.28494906425476074 seconds for one epoch ---
--- 1.055908441543579 seconds for one epoch ---
--- 0.34642720222473145 seconds for one epoch ---
--- 1.0886850357055664 seconds for one epoch ---
--- 0.3135354518890381 seconds for one epoch ---
--- 1.082685947418213 seconds for one epoch ---
--- 0.2919652462005615 seconds for one epoch ---
--- 1.0823681354522705 seconds for one epoch ---
--- 0.30422329902648926 seconds for one epoch ---
--- 1.0999562740325928 seconds for one epoch ---
--- 0.2992410659790039 seconds for one epoch ---
--- 1.0938987731933594 seconds for one epoch ---
--- 0.2974240779876709 seconds for one epoch ---
--- 1.082672119140625 seconds for one epoch ---
--- 0.3025665283203125 seconds for one epoch ---
--- 1.1120884418487549 seconds for one epoch ---
--- 0.2960548400878906 seconds for one epoch ---
--- 1.118800163269043 seconds for one epoch ---
--- 0.2983393669128418 seconds for one epoch ---
--- 1.1080641746520996 seconds for one epoch ---
--- 0.3006434440612793 seconds for one epoch ---
--- 1.121474266052246 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.809203]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.310776]
 [ -0.      ]]
--- 0.29958653450012207 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2688.865966796875, (1346.4381, 2.1285508, 1339.9954, 0.30400887)
   validation loss 1012.4716186523438, (724.5352, 0.33704442, 287.29535, 0.30400887)
decoder loss ratio: 28069.752166, decoder SINDy loss  ratio: 0.620167
--- 0.27188801765441895 seconds for one epoch ---
--- 0.2953176498413086 seconds for one epoch ---
--- 1.0482580661773682 seconds for one epoch ---
--- 0.3055412769317627 seconds for one epoch ---
--- 1.0774221420288086 seconds for one epoch ---
--- 0.2893061637878418 seconds for one epoch ---
--- 1.0940296649932861 seconds for one epoch ---
--- 0.2789630889892578 seconds for one epoch ---
--- 1.1080989837646484 seconds for one epoch ---
--- 0.29754114151000977 seconds for one epoch ---
--- 1.1168782711029053 seconds for one epoch ---
--- 0.3036072254180908 seconds for one epoch ---
--- 1.1092541217803955 seconds for one epoch ---
--- 0.3040640354156494 seconds for one epoch ---
--- 1.122678518295288 seconds for one epoch ---
--- 0.29718923568725586 seconds for one epoch ---
--- 1.1234924793243408 seconds for one epoch ---
--- 0.3044154644012451 seconds for one epoch ---
--- 1.1292359828948975 seconds for one epoch ---
--- 0.30005669593811035 seconds for one epoch ---
--- 1.1172003746032715 seconds for one epoch ---
--- 0.3010077476501465 seconds for one epoch ---
--- 1.1161119937896729 seconds for one epoch ---
--- 0.29358386993408203 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8132459]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.465017]
 [ -0.      ]]
--- 0.2600724697113037 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2089.5390625, (1185.025, 1.2822477, 902.9245, 0.307354)
   validation loss 816.1199951171875, (549.66797, 0.34123167, 265.80344, 0.307354)
decoder loss ratio: 21295.091375, decoder SINDy loss  ratio: 0.573774
--- 0.2977316379547119 seconds for one epoch ---
--- 1.106048345565796 seconds for one epoch ---
--- 0.29379940032958984 seconds for one epoch ---
--- 1.0926642417907715 seconds for one epoch ---
--- 0.2866184711456299 seconds for one epoch ---
--- 1.0755441188812256 seconds for one epoch ---
--- 0.29019999504089355 seconds for one epoch ---
--- 1.1164541244506836 seconds for one epoch ---
--- 0.3191068172454834 seconds for one epoch ---
--- 1.1165072917938232 seconds for one epoch ---
--- 0.33972859382629395 seconds for one epoch ---
--- 1.1396362781524658 seconds for one epoch ---
--- 0.3315742015838623 seconds for one epoch ---
--- 1.1362106800079346 seconds for one epoch ---
--- 0.3376500606536865 seconds for one epoch ---
--- 1.1577630043029785 seconds for one epoch ---
--- 0.337705135345459 seconds for one epoch ---
--- 1.1230583190917969 seconds for one epoch ---
--- 0.3380317687988281 seconds for one epoch ---
--- 1.1267609596252441 seconds for one epoch ---
--- 0.3237013816833496 seconds for one epoch ---
--- 1.1240317821502686 seconds for one epoch ---
--- 0.3237450122833252 seconds for one epoch ---
--- 1.1484732627868652 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.81713456]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.621531]
 [ -0.      ]]
--- 0.3045523166656494 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3873.85888671875, (1163.9526, 7.340127, 2702.2554, 0.31080168)
   validation loss 1454.162841796875, (1178.1974, 0.43208233, 275.2226, 0.31080168)
decoder loss ratio: 45645.412240, decoder SINDy loss  ratio: 0.594107
--- 0.253831148147583 seconds for one epoch ---
--- 0.2917630672454834 seconds for one epoch ---
--- 1.0869829654693604 seconds for one epoch ---
--- 0.3002784252166748 seconds for one epoch ---
--- 1.1124804019927979 seconds for one epoch ---
--- 0.29493212699890137 seconds for one epoch ---
--- 1.073453664779663 seconds for one epoch ---
--- 0.2950162887573242 seconds for one epoch ---
--- 1.1251246929168701 seconds for one epoch ---
--- 0.3490290641784668 seconds for one epoch ---
--- 1.138810634613037 seconds for one epoch ---
--- 0.326505184173584 seconds for one epoch ---
--- 1.1327357292175293 seconds for one epoch ---
--- 0.3440237045288086 seconds for one epoch ---
--- 1.1098146438598633 seconds for one epoch ---
--- 0.31968116760253906 seconds for one epoch ---
--- 1.1378424167633057 seconds for one epoch ---
--- 0.30191564559936523 seconds for one epoch ---
--- 1.139155387878418 seconds for one epoch ---
--- 0.3229825496673584 seconds for one epoch ---
--- 1.145838975906372 seconds for one epoch ---
--- 0.31116271018981934 seconds for one epoch ---
--- 1.113171100616455 seconds for one epoch ---
--- 0.3059976100921631 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8208821]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.780916]
 [ -0.      ]]
--- 0.2593567371368408 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4855.19189453125, (1776.9062, 1.1272742, 3076.8438, 0.31425276)
   validation loss 973.3543701171875, (693.92255, 0.3794294, 278.7381, 0.31425276)
decoder loss ratio: 26883.764150, decoder SINDy loss  ratio: 0.601695
--- 0.3111281394958496 seconds for one epoch ---
--- 1.1136431694030762 seconds for one epoch ---
--- 0.30379366874694824 seconds for one epoch ---
--- 1.1469752788543701 seconds for one epoch ---
--- 0.3090379238128662 seconds for one epoch ---
--- 1.1582508087158203 seconds for one epoch ---
--- 0.3003544807434082 seconds for one epoch ---
--- 1.1267123222351074 seconds for one epoch ---
--- 0.29722023010253906 seconds for one epoch ---
--- 1.0961077213287354 seconds for one epoch ---
--- 0.3016986846923828 seconds for one epoch ---
--- 1.177431583404541 seconds for one epoch ---
--- 0.3337531089782715 seconds for one epoch ---
--- 1.133441686630249 seconds for one epoch ---
--- 0.32343149185180664 seconds for one epoch ---
--- 1.1576168537139893 seconds for one epoch ---
--- 0.3206925392150879 seconds for one epoch ---
--- 1.1660592555999756 seconds for one epoch ---
--- 0.32981085777282715 seconds for one epoch ---
--- 1.179539442062378 seconds for one epoch ---
--- 0.3348691463470459 seconds for one epoch ---
--- 1.1495747566223145 seconds for one epoch ---
--- 0.3123338222503662 seconds for one epoch ---
--- 1.1702513694763184 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8244869]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.943326]
 [ -0.      ]]
--- 0.29207277297973633 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2921.1904296875, (1233.4194, 0.20977175, 1687.2433, 0.31785664)
   validation loss 964.6717529296875, (642.362, 0.53025997, 321.46164, 0.31785664)
decoder loss ratio: 24886.219051, decoder SINDy loss  ratio: 0.693920
--- 0.21839499473571777 seconds for one epoch ---
--- 0.2904205322265625 seconds for one epoch ---
--- 1.1528944969177246 seconds for one epoch ---
--- 0.2944459915161133 seconds for one epoch ---
--- 1.1178627014160156 seconds for one epoch ---
--- 0.2896859645843506 seconds for one epoch ---
--- 1.139937162399292 seconds for one epoch ---
--- 0.29385924339294434 seconds for one epoch ---
--- 1.1281092166900635 seconds for one epoch ---
--- 0.29595232009887695 seconds for one epoch ---
--- 1.113948106765747 seconds for one epoch ---
--- 0.28220415115356445 seconds for one epoch ---
--- 1.1530230045318604 seconds for one epoch ---
--- 0.31073951721191406 seconds for one epoch ---
--- 1.1765835285186768 seconds for one epoch ---
--- 0.3039219379425049 seconds for one epoch ---
--- 1.1937603950500488 seconds for one epoch ---
--- 0.3311347961425781 seconds for one epoch ---
--- 1.169755458831787 seconds for one epoch ---
--- 0.3547549247741699 seconds for one epoch ---
--- 1.1543042659759521 seconds for one epoch ---
--- 0.34551024436950684 seconds for one epoch ---
--- 1.1618075370788574 seconds for one epoch ---
--- 0.3380005359649658 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.82800907]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.111883]
 [ -0.      ]]
--- 0.2511160373687744 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3394.745361328125, (1292.1984, 2.6855013, 2099.5398, 0.3215579)
   validation loss 1065.6434326171875, (796.6999, 0.49927977, 268.1227, 0.3215579)
decoder loss ratio: 30865.536876, decoder SINDy loss  ratio: 0.578781
--- 0.3313741683959961 seconds for one epoch ---
--- 1.1328108310699463 seconds for one epoch ---
--- 0.31078267097473145 seconds for one epoch ---
--- 1.1311383247375488 seconds for one epoch ---
--- 0.29613208770751953 seconds for one epoch ---
--- 1.1437535285949707 seconds for one epoch ---
--- 0.3194103240966797 seconds for one epoch ---
--- 1.1320815086364746 seconds for one epoch ---
--- 0.28948402404785156 seconds for one epoch ---
--- 1.1489722728729248 seconds for one epoch ---
--- 0.2899818420410156 seconds for one epoch ---
--- 1.1362879276275635 seconds for one epoch ---
--- 0.2982611656188965 seconds for one epoch ---
--- 1.1246192455291748 seconds for one epoch ---
--- 0.30849528312683105 seconds for one epoch ---
--- 1.19136643409729 seconds for one epoch ---
--- 0.33580875396728516 seconds for one epoch ---
--- 1.1593272686004639 seconds for one epoch ---
--- 0.32285141944885254 seconds for one epoch ---
--- 1.1765129566192627 seconds for one epoch ---
--- 0.3195953369140625 seconds for one epoch ---
--- 1.1823947429656982 seconds for one epoch ---
--- 0.32666563987731934 seconds for one epoch ---
--- 1.1776111125946045 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8307333]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.249953]
 [ -0.      ]]
--- 0.31255364418029785 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2173.410400390625, (1129.7931, 0.5538747, 1042.7389, 0.32448778)
   validation loss 985.5330810546875, (693.06946, 0.45077518, 291.68832, 0.32448778)
decoder loss ratio: 26850.714025, decoder SINDy loss  ratio: 0.629650
--- 0.2880992889404297 seconds for one epoch ---
--- 0.32367634773254395 seconds for one epoch ---
--- 1.2088572978973389 seconds for one epoch ---
--- 0.29441404342651367 seconds for one epoch ---
--- 1.1536338329315186 seconds for one epoch ---
--- 0.3048868179321289 seconds for one epoch ---
--- 1.1586480140686035 seconds for one epoch ---
--- 0.2956209182739258 seconds for one epoch ---
--- 1.1733646392822266 seconds for one epoch ---
--- 0.3077855110168457 seconds for one epoch ---
--- 1.1597316265106201 seconds for one epoch ---
--- 0.3111991882324219 seconds for one epoch ---
--- 1.1586084365844727 seconds for one epoch ---
--- 0.29752159118652344 seconds for one epoch ---
--- 1.135648488998413 seconds for one epoch ---
--- 0.29921579360961914 seconds for one epoch ---
--- 1.2015166282653809 seconds for one epoch ---
--- 0.3142979145050049 seconds for one epoch ---
--- 1.1903254985809326 seconds for one epoch ---
--- 0.3108687400817871 seconds for one epoch ---
--- 1.1875019073486328 seconds for one epoch ---
--- 0.29762768745422363 seconds for one epoch ---
--- 1.189913034439087 seconds for one epoch ---
--- 0.2957265377044678 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8334214]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-13.3937235]
 [ -0.       ]]
--- 0.2592582702636719 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4729.71728515625, (1199.7867, 7.6146836, 3521.988, 0.3276437)
   validation loss 1245.5902099609375, (929.12836, 0.50229734, 315.63193, 0.3276437)
decoder loss ratio: 35996.045585, decoder SINDy loss  ratio: 0.681336
--- 0.29321765899658203 seconds for one epoch ---
--- 1.1412534713745117 seconds for one epoch ---
--- 0.2899169921875 seconds for one epoch ---
--- 1.1873078346252441 seconds for one epoch ---
--- 0.29598021507263184 seconds for one epoch ---
--- 1.2724289894104004 seconds for one epoch ---
--- 0.32809901237487793 seconds for one epoch ---
--- 1.2472765445709229 seconds for one epoch ---
--- 0.25722289085388184 seconds for one epoch ---
--- 1.2208459377288818 seconds for one epoch ---
--- 0.29756736755371094 seconds for one epoch ---
--- 1.2480213642120361 seconds for one epoch ---
--- 0.2851831912994385 seconds for one epoch ---
--- 1.1718826293945312 seconds for one epoch ---
--- 0.1991560459136963 seconds for one epoch ---
--- 1.186213493347168 seconds for one epoch ---
--- 0.1972215175628662 seconds for one epoch ---
--- 1.2784428596496582 seconds for one epoch ---
--- 0.21368646621704102 seconds for one epoch ---
--- 1.2472350597381592 seconds for one epoch ---
--- 0.18805742263793945 seconds for one epoch ---
--- 1.263704538345337 seconds for one epoch ---
--- 0.20801639556884766 seconds for one epoch ---
--- 1.189547061920166 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8357846]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.527193]
 [ -0.      ]]
--- 0.22951483726501465 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1936.8504638671875, (1005.27716, 0.31685644, 930.9261, 0.3304895)
   validation loss 1061.3006591796875, (739.58716, 0.5790524, 320.80396, 0.3304895)
decoder loss ratio: 28652.890489, decoder SINDy loss  ratio: 0.692500
--- 0.17281723022460938 seconds for one epoch ---
--- 0.1906299591064453 seconds for one epoch ---
--- 1.2010867595672607 seconds for one epoch ---
--- 0.23110127449035645 seconds for one epoch ---
--- 1.207047939300537 seconds for one epoch ---
--- 0.19617366790771484 seconds for one epoch ---
--- 1.1844878196716309 seconds for one epoch ---
--- 0.19447851181030273 seconds for one epoch ---
--- 1.2002289295196533 seconds for one epoch ---
--- 0.15989017486572266 seconds for one epoch ---
--- 1.2143113613128662 seconds for one epoch ---
--- 0.18926501274108887 seconds for one epoch ---
--- 1.2838788032531738 seconds for one epoch ---
--- 0.18481898307800293 seconds for one epoch ---
--- 1.133484125137329 seconds for one epoch ---
--- 0.20108580589294434 seconds for one epoch ---
--- 1.1812100410461426 seconds for one epoch ---
--- 0.1610124111175537 seconds for one epoch ---
--- 1.2442944049835205 seconds for one epoch ---
--- 0.20119643211364746 seconds for one epoch ---
--- 1.3459930419921875 seconds for one epoch ---
--- 0.22696876525878906 seconds for one epoch ---
--- 1.212827205657959 seconds for one epoch ---
--- 0.19226932525634766 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83780706]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.647501]
 [ -0.      ]]
--- 0.17137980461120605 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1464.469970703125, (849.4861, 0.60333204, 614.04736, 0.33319613)
   validation loss 795.2846069335938, (505.13016, 0.5337937, 289.2875, 0.33319613)
decoder loss ratio: 19569.619245, decoder SINDy loss  ratio: 0.624468
--- 0.20800375938415527 seconds for one epoch ---
--- 1.1820483207702637 seconds for one epoch ---
--- 0.21837925910949707 seconds for one epoch ---
--- 1.1948673725128174 seconds for one epoch ---
--- 0.21847772598266602 seconds for one epoch ---
--- 1.1851658821105957 seconds for one epoch ---
--- 0.2001361846923828 seconds for one epoch ---
--- 1.1574985980987549 seconds for one epoch ---
--- 0.1950516700744629 seconds for one epoch ---
--- 1.2047662734985352 seconds for one epoch ---
--- 0.19312548637390137 seconds for one epoch ---
--- 1.2523858547210693 seconds for one epoch ---
--- 0.19945001602172852 seconds for one epoch ---
--- 1.1605069637298584 seconds for one epoch ---
--- 0.17340826988220215 seconds for one epoch ---
--- 1.2367572784423828 seconds for one epoch ---
--- 0.21613001823425293 seconds for one epoch ---
--- 1.1916193962097168 seconds for one epoch ---
--- 0.18230199813842773 seconds for one epoch ---
--- 1.3596532344818115 seconds for one epoch ---
--- 0.1743791103363037 seconds for one epoch ---
--- 1.2451367378234863 seconds for one epoch ---
--- 0.18285155296325684 seconds for one epoch ---
--- 1.2221405506134033 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83982575]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.773759]
 [ -0.      ]]
--- 0.1848890781402588 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3305.623779296875, (1229.9669, 3.9156895, 2071.4053, 0.33591273)
   validation loss 1161.6129150390625, (859.5316, 0.40995336, 301.33536, 0.33591273)
decoder loss ratio: 33299.747025, decoder SINDy loss  ratio: 0.650475
THRESHOLDING: 1 active coefficients
--- 1.1695959568023682 seconds for one epoch ---
--- 0.16821742057800293 seconds for one epoch ---
--- 1.19917893409729 seconds for one epoch ---
--- 0.2055974006652832 seconds for one epoch ---
--- 1.2706949710845947 seconds for one epoch ---
--- 0.17982077598571777 seconds for one epoch ---
--- 1.1952402591705322 seconds for one epoch ---
--- 0.16248512268066406 seconds for one epoch ---
--- 1.21956205368042 seconds for one epoch ---
--- 0.19590997695922852 seconds for one epoch ---
--- 1.2485682964324951 seconds for one epoch ---
--- 0.21840214729309082 seconds for one epoch ---
--- 1.247007131576538 seconds for one epoch ---
--- 0.20178008079528809 seconds for one epoch ---
--- 1.1851658821105957 seconds for one epoch ---
--- 0.19629430770874023 seconds for one epoch ---
--- 1.260603904724121 seconds for one epoch ---
--- 0.1928701400756836 seconds for one epoch ---
--- 1.26955246925354 seconds for one epoch ---
--- 0.17890548706054688 seconds for one epoch ---
--- 1.2745649814605713 seconds for one epoch ---
--- 0.2347245216369629 seconds for one epoch ---
--- 1.2371933460235596 seconds for one epoch ---
--- 0.18886327743530273 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84137976]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.875773]
 [ -0.      ]]
--- 0.1618785858154297 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2861.51513671875, (1373.8337, 1.089216, 1486.254, 0.33815017)
   validation loss 751.6836547851562, (485.614, 0.37172523, 265.35977, 0.33815017)
decoder loss ratio: 18813.529953, decoder SINDy loss  ratio: 0.572816
--- 0.20184588432312012 seconds for one epoch ---
--- 1.2068932056427002 seconds for one epoch ---
--- 0.20560979843139648 seconds for one epoch ---
--- 1.3410022258758545 seconds for one epoch ---
--- 0.21146368980407715 seconds for one epoch ---
--- 1.2260539531707764 seconds for one epoch ---
--- 0.22876667976379395 seconds for one epoch ---
--- 1.2983663082122803 seconds for one epoch ---
--- 0.20261335372924805 seconds for one epoch ---
--- 1.2642567157745361 seconds for one epoch ---
--- 0.2029590606689453 seconds for one epoch ---
--- 1.2862870693206787 seconds for one epoch ---
--- 0.19512104988098145 seconds for one epoch ---
--- 1.1859731674194336 seconds for one epoch ---
--- 0.1851339340209961 seconds for one epoch ---
--- 1.2175211906433105 seconds for one epoch ---
--- 0.21016168594360352 seconds for one epoch ---
--- 1.2634913921356201 seconds for one epoch ---
--- 0.18235087394714355 seconds for one epoch ---
--- 1.2517387866973877 seconds for one epoch ---
--- 0.20955681800842285 seconds for one epoch ---
--- 1.24399733543396 seconds for one epoch ---
--- 0.19248270988464355 seconds for one epoch ---
--- 1.2322258949279785 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8429092]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.980814]
 [ -0.      ]]
--- 0.19933748245239258 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2936.508056640625, (1535.7118, 0.78815454, 1399.6674, 0.34052867)
   validation loss 914.817138671875, (637.1596, 0.38687918, 276.9301, 0.34052867)
decoder loss ratio: 24684.669330, decoder SINDy loss  ratio: 0.597793
--- 0.15093111991882324 seconds for one epoch ---
--- 0.198228120803833 seconds for one epoch ---
--- 1.1828913688659668 seconds for one epoch ---
--- 0.1868915557861328 seconds for one epoch ---
--- 1.2414164543151855 seconds for one epoch ---
--- 0.18389129638671875 seconds for one epoch ---
--- 1.245819330215454 seconds for one epoch ---
--- 0.22040557861328125 seconds for one epoch ---
--- 1.2557179927825928 seconds for one epoch ---
--- 0.21493148803710938 seconds for one epoch ---
--- 1.2471215724945068 seconds for one epoch ---
--- 0.2035069465637207 seconds for one epoch ---
--- 1.2905669212341309 seconds for one epoch ---
--- 0.2024831771850586 seconds for one epoch ---
--- 1.2075304985046387 seconds for one epoch ---
--- 0.21185016632080078 seconds for one epoch ---
--- 1.2315256595611572 seconds for one epoch ---
--- 0.1538410186767578 seconds for one epoch ---
--- 1.2191393375396729 seconds for one epoch ---
--- 0.1676194667816162 seconds for one epoch ---
--- 1.3320772647857666 seconds for one epoch ---
--- 0.20267224311828613 seconds for one epoch ---
--- 1.3366966247558594 seconds for one epoch ---
--- 0.19265270233154297 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84436524]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.085595]
 [ -0.      ]]
--- 0.1679222583770752 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3264.955078125, (1390.6193, 6.3052363, 1867.688, 0.34280965)
   validation loss 920.2946166992188, (638.62585, 0.35917965, 280.96677, 0.34280965)
decoder loss ratio: 24741.474306, decoder SINDy loss  ratio: 0.606506
--- 0.17844200134277344 seconds for one epoch ---
--- 1.2853689193725586 seconds for one epoch ---
--- 0.2460777759552002 seconds for one epoch ---
--- 1.3371965885162354 seconds for one epoch ---
--- 0.22842907905578613 seconds for one epoch ---
--- 1.265791893005371 seconds for one epoch ---
--- 0.2087397575378418 seconds for one epoch ---
--- 1.31675386428833 seconds for one epoch ---
--- 0.1989288330078125 seconds for one epoch ---
--- 1.3100831508636475 seconds for one epoch ---
--- 0.23030924797058105 seconds for one epoch ---
--- 1.220973253250122 seconds for one epoch ---
--- 0.19332265853881836 seconds for one epoch ---
--- 1.2208926677703857 seconds for one epoch ---
--- 0.17949390411376953 seconds for one epoch ---
--- 1.247962236404419 seconds for one epoch ---
--- 0.17005419731140137 seconds for one epoch ---
--- 1.2698867321014404 seconds for one epoch ---
--- 0.219834566116333 seconds for one epoch ---
--- 1.2425084114074707 seconds for one epoch ---
--- 0.2417762279510498 seconds for one epoch ---
--- 1.3790791034698486 seconds for one epoch ---
--- 0.20833659172058105 seconds for one epoch ---
--- 1.2368204593658447 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84600097]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.209706]
 [ -0.      ]]
--- 0.209975004196167 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3326.8115234375, (1232.201, 1.0750297, 2093.19, 0.34556276)
   validation loss 758.8763427734375, (491.8887, 0.37803861, 266.26398, 0.34556276)
decoder loss ratio: 19056.622287, decoder SINDy loss  ratio: 0.574768
--- 0.13624238967895508 seconds for one epoch ---
--- 0.19021105766296387 seconds for one epoch ---
--- 1.2569844722747803 seconds for one epoch ---
--- 0.2266538143157959 seconds for one epoch ---
--- 1.2474501132965088 seconds for one epoch ---
--- 0.2200164794921875 seconds for one epoch ---
--- 1.2514221668243408 seconds for one epoch ---
--- 0.21631407737731934 seconds for one epoch ---
--- 1.2870357036590576 seconds for one epoch ---
--- 0.1811048984527588 seconds for one epoch ---
--- 1.2592437267303467 seconds for one epoch ---
--- 0.17380118370056152 seconds for one epoch ---
--- 1.2974762916564941 seconds for one epoch ---
--- 0.23207616806030273 seconds for one epoch ---
--- 1.2607743740081787 seconds for one epoch ---
--- 0.19261407852172852 seconds for one epoch ---
--- 1.2749297618865967 seconds for one epoch ---
--- 0.18673372268676758 seconds for one epoch ---
--- 1.3288016319274902 seconds for one epoch ---
--- 0.2171187400817871 seconds for one epoch ---
--- 1.3581674098968506 seconds for one epoch ---
--- 0.1858375072479248 seconds for one epoch ---
--- 1.3240201473236084 seconds for one epoch ---
--- 0.19570016860961914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.84735936]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.318647]
 [ -0.      ]]
--- 0.15576624870300293 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3547.508544921875, (1774.6637, 1.536269, 1770.9606, 0.34781638)
   validation loss 822.6538696289062, (556.7173, 0.39771616, 265.191, 0.34781638)
decoder loss ratio: 21568.194131, decoder SINDy loss  ratio: 0.572452
--- 0.19295120239257812 seconds for one epoch ---
--- 1.2789115905761719 seconds for one epoch ---
--- 0.1968517303466797 seconds for one epoch ---
--- 1.302741289138794 seconds for one epoch ---
--- 0.18995189666748047 seconds for one epoch ---
--- 1.3035950660705566 seconds for one epoch ---
--- 0.188140869140625 seconds for one epoch ---
--- 1.3060648441314697 seconds for one epoch ---
--- 0.2101452350616455 seconds for one epoch ---
--- 1.276017665863037 seconds for one epoch ---
--- 0.17574501037597656 seconds for one epoch ---
--- 1.3630590438842773 seconds for one epoch ---
--- 0.2182912826538086 seconds for one epoch ---
--- 1.337864875793457 seconds for one epoch ---
--- 0.18887042999267578 seconds for one epoch ---
--- 1.2939388751983643 seconds for one epoch ---
--- 0.1975724697113037 seconds for one epoch ---
--- 1.265026569366455 seconds for one epoch ---
--- 0.20111680030822754 seconds for one epoch ---
--- 1.2489705085754395 seconds for one epoch ---
--- 0.17269325256347656 seconds for one epoch ---
--- 1.3667066097259521 seconds for one epoch ---
--- 0.19186711311340332 seconds for one epoch ---
--- 1.2980396747589111 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8485941]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.422901]
 [ -0.      ]]
--- 0.2005295753479004 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4054.5361328125, (1400.0825, 1.905172, 2652.1982, 0.3501931)
   validation loss 908.8478393554688, (631.9491, 0.43022534, 276.1183, 0.3501931)
decoder loss ratio: 24482.805117, decoder SINDy loss  ratio: 0.596040
--- 0.161834716796875 seconds for one epoch ---
--- 0.19780468940734863 seconds for one epoch ---
--- 1.2960009574890137 seconds for one epoch ---
--- 0.20677757263183594 seconds for one epoch ---
--- 1.2651472091674805 seconds for one epoch ---
--- 0.17799162864685059 seconds for one epoch ---
--- 1.3176920413970947 seconds for one epoch ---
--- 0.19365644454956055 seconds for one epoch ---
--- 1.3339130878448486 seconds for one epoch ---
--- 0.19997620582580566 seconds for one epoch ---
--- 1.304253101348877 seconds for one epoch ---
--- 0.18952655792236328 seconds for one epoch ---
--- 1.3254225254058838 seconds for one epoch ---
--- 0.18390297889709473 seconds for one epoch ---
--- 1.3226783275604248 seconds for one epoch ---
--- 0.20631980895996094 seconds for one epoch ---
--- 1.3052265644073486 seconds for one epoch ---
--- 0.19913625717163086 seconds for one epoch ---
--- 1.3170819282531738 seconds for one epoch ---
--- 0.2029571533203125 seconds for one epoch ---
--- 1.2923686504364014 seconds for one epoch ---
--- 0.19611406326293945 seconds for one epoch ---
--- 1.2929143905639648 seconds for one epoch ---
--- 0.16836166381835938 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8496266]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-14.5145855]
 [ -0.       ]]
--- 0.16296625137329102 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3864.906982421875, (1400.5735, 8.02182, 2455.9595, 0.35220525)
   validation loss 696.0089111328125, (439.58194, 0.52728415, 255.54745, 0.35220525)
decoder loss ratio: 17030.167492, decoder SINDy loss  ratio: 0.551635
--- 0.18480443954467773 seconds for one epoch ---
--- 1.2351343631744385 seconds for one epoch ---
--- 0.19249892234802246 seconds for one epoch ---
--- 1.3381178379058838 seconds for one epoch ---
--- 0.16748690605163574 seconds for one epoch ---
--- 1.2980461120605469 seconds for one epoch ---
--- 0.1971299648284912 seconds for one epoch ---
--- 1.2971103191375732 seconds for one epoch ---
--- 0.1980118751525879 seconds for one epoch ---
--- 1.2708301544189453 seconds for one epoch ---
--- 0.20109820365905762 seconds for one epoch ---
--- 1.3427674770355225 seconds for one epoch ---
--- 0.18251895904541016 seconds for one epoch ---
--- 1.2649426460266113 seconds for one epoch ---
--- 0.17342281341552734 seconds for one epoch ---
--- 1.311720371246338 seconds for one epoch ---
--- 0.1928086280822754 seconds for one epoch ---
--- 1.2940659523010254 seconds for one epoch ---
--- 0.18692922592163086 seconds for one epoch ---
--- 1.2991001605987549 seconds for one epoch ---
--- 0.17769312858581543 seconds for one epoch ---
--- 1.2895100116729736 seconds for one epoch ---
--- 0.198822021484375 seconds for one epoch ---
--- 1.3085575103759766 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8506291]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.608011]
 [ -0.      ]]
--- 0.1868596076965332 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2822.3837890625, (1233.6729, 1.7054898, 1586.6512, 0.35426754)
   validation loss 748.5123291015625, (496.71362, 0.50130683, 250.94313, 0.35426754)
decoder loss ratio: 19243.548090, decoder SINDy loss  ratio: 0.541696
--- 0.1881401538848877 seconds for one epoch ---
--- 0.22859835624694824 seconds for one epoch ---
--- 1.4677314758300781 seconds for one epoch ---
--- 0.20584654808044434 seconds for one epoch ---
--- 1.356783151626587 seconds for one epoch ---
--- 0.20409321784973145 seconds for one epoch ---
--- 1.2901270389556885 seconds for one epoch ---
--- 0.17873573303222656 seconds for one epoch ---
--- 1.3141729831695557 seconds for one epoch ---
--- 0.21727991104125977 seconds for one epoch ---
--- 1.2853288650512695 seconds for one epoch ---
--- 0.21784353256225586 seconds for one epoch ---
--- 1.3719003200531006 seconds for one epoch ---
--- 0.19592523574829102 seconds for one epoch ---
--- 1.334831714630127 seconds for one epoch ---
--- 0.19824719429016113 seconds for one epoch ---
--- 1.3033206462860107 seconds for one epoch ---
--- 0.18634462356567383 seconds for one epoch ---
--- 1.3881537914276123 seconds for one epoch ---
--- 0.19735455513000488 seconds for one epoch ---
--- 1.3316469192504883 seconds for one epoch ---
--- 0.18382930755615234 seconds for one epoch ---
--- 1.428469181060791 seconds for one epoch ---
--- 0.15726423263549805 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8515932]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.702536]
 [ -0.      ]]
--- 0.16250872611999512 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3323.354248046875, (1667.4338, 1.38195, 1654.182, 0.35640004)
   validation loss 713.947998046875, (463.53204, 0.4965418, 249.563, 0.35640004)
decoder loss ratio: 17958.036091, decoder SINDy loss  ratio: 0.538717
--- 0.17916560173034668 seconds for one epoch ---
--- 1.3746387958526611 seconds for one epoch ---
--- 0.18427014350891113 seconds for one epoch ---
--- 1.3323757648468018 seconds for one epoch ---
--- 0.18678951263427734 seconds for one epoch ---
--- 1.3592989444732666 seconds for one epoch ---
--- 0.2001485824584961 seconds for one epoch ---
--- 1.3700056076049805 seconds for one epoch ---
--- 0.22837209701538086 seconds for one epoch ---
--- 1.3626551628112793 seconds for one epoch ---
--- 0.20225071907043457 seconds for one epoch ---
--- 1.3984870910644531 seconds for one epoch ---
--- 0.18846702575683594 seconds for one epoch ---
--- 1.4449818134307861 seconds for one epoch ---
--- 0.20177030563354492 seconds for one epoch ---
--- 1.4190740585327148 seconds for one epoch ---
--- 0.1897287368774414 seconds for one epoch ---
--- 1.4038734436035156 seconds for one epoch ---
--- 0.20883727073669434 seconds for one epoch ---
--- 1.4246060848236084 seconds for one epoch ---
--- 0.17223644256591797 seconds for one epoch ---
--- 1.4127013683319092 seconds for one epoch ---
--- 0.2855033874511719 seconds for one epoch ---
--- 1.4554624557495117 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8524654]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.792611]
 [ -0.      ]]
--- 0.2036294937133789 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1759.8201904296875, (622.37274, 1.6476173, 1135.4414, 0.35838005)
   validation loss 782.8939208984375, (524.82965, 0.4848705, 257.22104, 0.35838005)
decoder loss ratio: 20332.811819, decoder SINDy loss  ratio: 0.555248
--- 0.17678380012512207 seconds for one epoch ---
--- 0.18048906326293945 seconds for one epoch ---
--- 1.3496356010437012 seconds for one epoch ---
--- 0.17754840850830078 seconds for one epoch ---
--- 1.4097981452941895 seconds for one epoch ---
--- 0.19552159309387207 seconds for one epoch ---
--- 1.3115975856781006 seconds for one epoch ---
--- 0.19829058647155762 seconds for one epoch ---
--- 1.3208982944488525 seconds for one epoch ---
--- 0.4602203369140625 seconds for one epoch ---
--- 1.3745677471160889 seconds for one epoch ---
--- 0.2558271884918213 seconds for one epoch ---
--- 1.3113832473754883 seconds for one epoch ---
--- 0.2145535945892334 seconds for one epoch ---
--- 1.4509971141815186 seconds for one epoch ---
--- 0.20310449600219727 seconds for one epoch ---
--- 1.3399951457977295 seconds for one epoch ---
--- 0.1942763328552246 seconds for one epoch ---
--- 1.3560760021209717 seconds for one epoch ---
--- 0.18454241752624512 seconds for one epoch ---
--- 1.3348190784454346 seconds for one epoch ---
--- 0.21947050094604492 seconds for one epoch ---
--- 1.3352198600769043 seconds for one epoch ---
--- 0.16734623908996582 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85326374]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.879531]
 [ -0.      ]]
--- 0.1472158432006836 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2742.991943359375, (1209.9847, 0.45222065, 1532.1946, 0.36034247)
   validation loss 677.5971069335938, (416.8601, 0.51602197, 259.86063, 0.36034247)
decoder loss ratio: 16149.884262, decoder SINDy loss  ratio: 0.560946
--- 0.20927643775939941 seconds for one epoch ---
--- 1.3435468673706055 seconds for one epoch ---
--- 0.21659541130065918 seconds for one epoch ---
--- 1.3681910037994385 seconds for one epoch ---
--- 0.2271425724029541 seconds for one epoch ---
--- 1.3465337753295898 seconds for one epoch ---
--- 0.20796895027160645 seconds for one epoch ---
--- 1.5512957572937012 seconds for one epoch ---
--- 0.2110593318939209 seconds for one epoch ---
--- 1.390547275543213 seconds for one epoch ---
--- 0.18234539031982422 seconds for one epoch ---
--- 1.5242137908935547 seconds for one epoch ---
--- 0.1812751293182373 seconds for one epoch ---
--- 1.3382923603057861 seconds for one epoch ---
--- 0.21433615684509277 seconds for one epoch ---
--- 1.5560791492462158 seconds for one epoch ---
--- 0.22411060333251953 seconds for one epoch ---
--- 1.4944837093353271 seconds for one epoch ---
--- 0.1992955207824707 seconds for one epoch ---
--- 1.3862638473510742 seconds for one epoch ---
--- 0.16350531578063965 seconds for one epoch ---
--- 1.452204704284668 seconds for one epoch ---
--- 0.20801782608032227 seconds for one epoch ---
--- 1.4142134189605713 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85395026]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.958165]
 [ -0.      ]]
--- 0.18576979637145996 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3326.047607421875, (1217.4814, 1.1222123, 2107.082, 0.36205134)
   validation loss 811.5662841796875, (563.15686, 0.50139093, 247.54599, 0.36205134)
decoder loss ratio: 21817.674453, decoder SINDy loss  ratio: 0.534363
--- 0.16146206855773926 seconds for one epoch ---
--- 0.22672581672668457 seconds for one epoch ---
--- 1.3707644939422607 seconds for one epoch ---
--- 0.21864938735961914 seconds for one epoch ---
--- 1.4029905796051025 seconds for one epoch ---
--- 0.18625450134277344 seconds for one epoch ---
--- 1.4015257358551025 seconds for one epoch ---
--- 0.21707892417907715 seconds for one epoch ---
--- 1.5826451778411865 seconds for one epoch ---
--- 0.20030426979064941 seconds for one epoch ---
--- 1.370286226272583 seconds for one epoch ---
--- 0.20794272422790527 seconds for one epoch ---
--- 1.383594036102295 seconds for one epoch ---
--- 0.19669747352600098 seconds for one epoch ---
--- 1.451749563217163 seconds for one epoch ---
--- 0.22159719467163086 seconds for one epoch ---
--- 1.4879858493804932 seconds for one epoch ---
--- 0.188706636428833 seconds for one epoch ---
--- 1.426516056060791 seconds for one epoch ---
--- 0.20193099975585938 seconds for one epoch ---
--- 1.4526216983795166 seconds for one epoch ---
--- 0.18036508560180664 seconds for one epoch ---
--- 1.3550448417663574 seconds for one epoch ---
--- 0.2022233009338379 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8546319]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.040162]
 [ -0.      ]]
--- 0.17944025993347168 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2829.047607421875, (1214.0769, 3.2232363, 1611.3837, 0.3638478)
   validation loss 755.1354370117188, (486.41907, 0.49552107, 267.85703, 0.3638478)
decoder loss ratio: 18844.719131, decoder SINDy loss  ratio: 0.578207
--- 0.2166283130645752 seconds for one epoch ---
--- 1.4287023544311523 seconds for one epoch ---
--- 0.2238311767578125 seconds for one epoch ---
--- 1.5054888725280762 seconds for one epoch ---
--- 0.2020118236541748 seconds for one epoch ---
--- 1.6454875469207764 seconds for one epoch ---
--- 0.20687150955200195 seconds for one epoch ---
--- 1.4721782207489014 seconds for one epoch ---
--- 0.31794095039367676 seconds for one epoch ---
--- 1.4566781520843506 seconds for one epoch ---
--- 0.19751453399658203 seconds for one epoch ---
--- 1.4065918922424316 seconds for one epoch ---
--- 0.20288991928100586 seconds for one epoch ---
--- 1.457315444946289 seconds for one epoch ---
--- 0.2078104019165039 seconds for one epoch ---
--- 1.3880729675292969 seconds for one epoch ---
--- 0.198380708694458 seconds for one epoch ---
--- 1.523097038269043 seconds for one epoch ---
--- 0.21205925941467285 seconds for one epoch ---
--- 1.3881874084472656 seconds for one epoch ---
--- 0.19426703453063965 seconds for one epoch ---
--- 1.3918304443359375 seconds for one epoch ---
--- 0.1865677833557129 seconds for one epoch ---
--- 1.4197466373443604 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8552668]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.120947]
 [ -0.      ]]
--- 0.1942594051361084 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3142.9638671875, (1653.6177, 0.7596992, 1488.2211, 0.36556855)
   validation loss 1030.90380859375, (704.02686, 0.5200123, 325.9913, 0.36556855)
decoder loss ratio: 27275.222625, decoder SINDy loss  ratio: 0.703698
--- 0.15755581855773926 seconds for one epoch ---
--- 0.19169831275939941 seconds for one epoch ---
--- 1.3684234619140625 seconds for one epoch ---
--- 0.1970503330230713 seconds for one epoch ---
--- 1.6950914859771729 seconds for one epoch ---
--- 0.2776651382446289 seconds for one epoch ---
--- 1.3652679920196533 seconds for one epoch ---
--- 0.21123051643371582 seconds for one epoch ---
--- 1.4405417442321777 seconds for one epoch ---
--- 0.19330954551696777 seconds for one epoch ---
--- 1.3784563541412354 seconds for one epoch ---
--- 0.2201402187347412 seconds for one epoch ---
--- 1.3788771629333496 seconds for one epoch ---
--- 0.18323087692260742 seconds for one epoch ---
--- 1.421410322189331 seconds for one epoch ---
--- 0.2179732322692871 seconds for one epoch ---
--- 1.454935073852539 seconds for one epoch ---
--- 0.16689276695251465 seconds for one epoch ---
--- 1.4809889793395996 seconds for one epoch ---
--- 0.19184660911560059 seconds for one epoch ---
--- 1.435697078704834 seconds for one epoch ---
--- 0.19533443450927734 seconds for one epoch ---
--- 1.386784553527832 seconds for one epoch ---
--- 0.18764853477478027 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8557897]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.190905]
 [ -0.      ]]
--- 0.1765894889831543 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2114.61083984375, (1147.8707, 0.17457852, 966.1985, 0.3672393)
   validation loss 1113.814208984375, (816.5068, 0.68510103, 296.25513, 0.3672393)
decoder loss ratio: 31632.889978, decoder SINDy loss  ratio: 0.639508
--- 0.2157268524169922 seconds for one epoch ---
--- 1.4856855869293213 seconds for one epoch ---
--- 0.2016432285308838 seconds for one epoch ---
--- 1.4692137241363525 seconds for one epoch ---
--- 0.21518397331237793 seconds for one epoch ---
--- 1.529691219329834 seconds for one epoch ---
--- 0.21172428131103516 seconds for one epoch ---
--- 1.4406836032867432 seconds for one epoch ---
--- 0.19720458984375 seconds for one epoch ---
--- 1.5452470779418945 seconds for one epoch ---
--- 0.15518665313720703 seconds for one epoch ---
--- 1.4996578693389893 seconds for one epoch ---
--- 0.19081902503967285 seconds for one epoch ---
--- 1.4656152725219727 seconds for one epoch ---
--- 0.18771886825561523 seconds for one epoch ---
--- 1.4898669719696045 seconds for one epoch ---
--- 0.18849658966064453 seconds for one epoch ---
--- 1.4560766220092773 seconds for one epoch ---
--- 0.1939868927001953 seconds for one epoch ---
--- 1.4486405849456787 seconds for one epoch ---
--- 0.17389178276062012 seconds for one epoch ---
--- 1.435715913772583 seconds for one epoch ---
--- 0.21534323692321777 seconds for one epoch ---
--- 1.4969379901885986 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85630196]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.263008]
 [ -0.      ]]
--- 0.1862642765045166 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2602.623291015625, (1177.1672, 0.24895488, 1424.8383, 0.36886317)
   validation loss 855.5697631835938, (550.8601, 0.57545006, 303.76538, 0.36886317)
decoder loss ratio: 21341.276897, decoder SINDy loss  ratio: 0.655720
--- 0.15398597717285156 seconds for one epoch ---
--- 0.17221903800964355 seconds for one epoch ---
--- 1.3926165103912354 seconds for one epoch ---
--- 0.18903589248657227 seconds for one epoch ---
--- 1.371356725692749 seconds for one epoch ---
--- 0.191009521484375 seconds for one epoch ---
--- 1.472203016281128 seconds for one epoch ---
--- 0.20423030853271484 seconds for one epoch ---
--- 1.4639513492584229 seconds for one epoch ---
--- 0.2959756851196289 seconds for one epoch ---
--- 1.4558346271514893 seconds for one epoch ---
--- 0.200547456741333 seconds for one epoch ---
--- 1.4388985633850098 seconds for one epoch ---
--- 0.20412015914916992 seconds for one epoch ---
--- 1.4231641292572021 seconds for one epoch ---
--- 0.1930832862854004 seconds for one epoch ---
--- 1.436335563659668 seconds for one epoch ---
--- 0.18024897575378418 seconds for one epoch ---
--- 1.4216609001159668 seconds for one epoch ---
--- 0.21506357192993164 seconds for one epoch ---
--- 1.5967991352081299 seconds for one epoch ---
--- 0.27940797805786133 seconds for one epoch ---
--- 1.495936393737793 seconds for one epoch ---
--- 0.22403883934020996 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85681593]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.339598]
 [ -0.      ]]
--- 0.15333199501037598 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2374.317138671875, (1253.1285, 1.0840324, 1119.7344, 0.37044737)
   validation loss 830.3175659179688, (540.6973, 0.75305194, 288.49673, 0.37044737)
decoder loss ratio: 20947.553127, decoder SINDy loss  ratio: 0.622761
--- 0.2105729579925537 seconds for one epoch ---
--- 1.371800422668457 seconds for one epoch ---
--- 0.16521310806274414 seconds for one epoch ---
--- 1.442319631576538 seconds for one epoch ---
--- 0.16965508460998535 seconds for one epoch ---
--- 1.445744514465332 seconds for one epoch ---
--- 0.2044382095336914 seconds for one epoch ---
--- 1.4288239479064941 seconds for one epoch ---
--- 0.19312429428100586 seconds for one epoch ---
--- 1.4668426513671875 seconds for one epoch ---
--- 0.18074321746826172 seconds for one epoch ---
--- 1.4366295337677002 seconds for one epoch ---
--- 0.20277070999145508 seconds for one epoch ---
--- 1.476219892501831 seconds for one epoch ---
--- 0.18834185600280762 seconds for one epoch ---
--- 1.396467685699463 seconds for one epoch ---
--- 0.21116352081298828 seconds for one epoch ---
--- 1.4010779857635498 seconds for one epoch ---
--- 0.19695186614990234 seconds for one epoch ---
--- 1.5243256092071533 seconds for one epoch ---
--- 0.17920494079589844 seconds for one epoch ---
--- 1.462343692779541 seconds for one epoch ---
--- 0.18296289443969727 seconds for one epoch ---
--- 1.3791069984436035 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8573197]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.419511]
 [ -0.      ]]
--- 0.19688081741333008 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2052.114501953125, (917.73376, 1.0169814, 1132.9913, 0.37225217)
   validation loss 745.3253784179688, (473.50333, 0.6838777, 270.7659, 0.37225217)
decoder loss ratio: 18344.340903, decoder SINDy loss  ratio: 0.584486
--- 0.14640331268310547 seconds for one epoch ---
--- 0.2086501121520996 seconds for one epoch ---
--- 1.4989099502563477 seconds for one epoch ---
--- 0.18050789833068848 seconds for one epoch ---
--- 1.4846012592315674 seconds for one epoch ---
--- 0.1827259063720703 seconds for one epoch ---
--- 1.4962158203125 seconds for one epoch ---
--- 0.17325186729431152 seconds for one epoch ---
--- 1.5749554634094238 seconds for one epoch ---
--- 0.22593235969543457 seconds for one epoch ---
--- 1.4910085201263428 seconds for one epoch ---
--- 0.17275500297546387 seconds for one epoch ---
--- 1.406473159790039 seconds for one epoch ---
--- 0.18273162841796875 seconds for one epoch ---
--- 1.4088134765625 seconds for one epoch ---
--- 0.16963529586791992 seconds for one epoch ---
--- 1.4936935901641846 seconds for one epoch ---
--- 0.19455838203430176 seconds for one epoch ---
--- 1.5014777183532715 seconds for one epoch ---
--- 0.2150278091430664 seconds for one epoch ---
--- 1.536902904510498 seconds for one epoch ---
--- 0.19633221626281738 seconds for one epoch ---
--- 1.4756524562835693 seconds for one epoch ---
--- 0.1900479793548584 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8577502]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.492433]
 [ -0.      ]]
--- 0.152083158493042 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3590.482177734375, (2093.1445, 0.75854605, 1496.2051, 0.37391397)
   validation loss 1240.1156005859375, (920.9011, 0.64304364, 318.19748, 0.37391397)
decoder loss ratio: 35677.308261, decoder SINDy loss  ratio: 0.686874
--- 0.17698907852172852 seconds for one epoch ---
--- 1.4703361988067627 seconds for one epoch ---
--- 0.2140638828277588 seconds for one epoch ---
--- 1.5008769035339355 seconds for one epoch ---
--- 0.1850130558013916 seconds for one epoch ---
--- 1.4009501934051514 seconds for one epoch ---
--- 0.1775658130645752 seconds for one epoch ---
--- 1.43404221534729 seconds for one epoch ---
--- 0.19689345359802246 seconds for one epoch ---
--- 1.4725544452667236 seconds for one epoch ---
--- 0.29842138290405273 seconds for one epoch ---
--- 1.4597363471984863 seconds for one epoch ---
--- 0.2131497859954834 seconds for one epoch ---
--- 1.450031042098999 seconds for one epoch ---
--- 0.23106622695922852 seconds for one epoch ---
--- 1.4440593719482422 seconds for one epoch ---
--- 0.2110593318939209 seconds for one epoch ---
--- 1.5335032939910889 seconds for one epoch ---
--- 0.19926667213439941 seconds for one epoch ---
--- 1.4716815948486328 seconds for one epoch ---
--- 0.19811010360717773 seconds for one epoch ---
--- 1.490790605545044 seconds for one epoch ---
--- 0.20407700538635254 seconds for one epoch ---
--- 1.497344732284546 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8580961]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.554236]
 [ -0.      ]]
--- 0.18784117698669434 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2406.80078125, (880.3661, 0.64570457, 1525.4137, 0.37531376)
   validation loss 1115.021484375, (820.5266, 0.6710968, 293.44846, 0.37531376)
decoder loss ratio: 31788.625420, decoder SINDy loss  ratio: 0.633450
THRESHOLDING: 1 active coefficients
--- 1.460007905960083 seconds for one epoch ---
--- 0.20703649520874023 seconds for one epoch ---
--- 1.4792745113372803 seconds for one epoch ---
--- 0.18104243278503418 seconds for one epoch ---
--- 1.4657201766967773 seconds for one epoch ---
--- 0.19555902481079102 seconds for one epoch ---
--- 1.6019482612609863 seconds for one epoch ---
--- 0.2279834747314453 seconds for one epoch ---
--- 1.4731526374816895 seconds for one epoch ---
--- 0.19637250900268555 seconds for one epoch ---
--- 1.4769434928894043 seconds for one epoch ---
--- 0.17711758613586426 seconds for one epoch ---
--- 1.456510066986084 seconds for one epoch ---
--- 0.17395782470703125 seconds for one epoch ---
--- 1.4462800025939941 seconds for one epoch ---
--- 0.21520185470581055 seconds for one epoch ---
--- 1.4934935569763184 seconds for one epoch ---
--- 0.18745660781860352 seconds for one epoch ---
--- 1.5469207763671875 seconds for one epoch ---
--- 0.18615984916687012 seconds for one epoch ---
--- 1.7055714130401611 seconds for one epoch ---
--- 0.30140113830566406 seconds for one epoch ---
--- 1.4229364395141602 seconds for one epoch ---
--- 0.21028661727905273 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8584355]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.619125]
 [ -0.      ]]
--- 0.1795945167541504 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1671.850341796875, (841.71643, 0.9608484, 828.7963, 0.37671667)
   validation loss 897.6116333007812, (620.49445, 0.6396098, 276.1009, 0.37671667)
decoder loss ratio: 24039.032056, decoder SINDy loss  ratio: 0.596003
--- 0.21553850173950195 seconds for one epoch ---
--- 1.5094873905181885 seconds for one epoch ---
--- 0.19516587257385254 seconds for one epoch ---
--- 1.4686331748962402 seconds for one epoch ---
--- 0.20693039894104004 seconds for one epoch ---
--- 1.4544565677642822 seconds for one epoch ---
--- 0.21303224563598633 seconds for one epoch ---
--- 1.4486136436462402 seconds for one epoch ---
--- 0.1915757656097412 seconds for one epoch ---
--- 1.5213053226470947 seconds for one epoch ---
--- 0.1703023910522461 seconds for one epoch ---
--- 1.5349390506744385 seconds for one epoch ---
--- 0.21044135093688965 seconds for one epoch ---
--- 1.5090460777282715 seconds for one epoch ---
--- 0.21362829208374023 seconds for one epoch ---
--- 1.509345531463623 seconds for one epoch ---
--- 0.20127344131469727 seconds for one epoch ---
--- 1.4900505542755127 seconds for one epoch ---
--- 0.20432376861572266 seconds for one epoch ---
--- 1.5059127807617188 seconds for one epoch ---
--- 0.20237398147583008 seconds for one epoch ---
--- 1.779822826385498 seconds for one epoch ---
--- 0.21367692947387695 seconds for one epoch ---
--- 1.4790582656860352 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8587457]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.681932]
 [ -0.      ]]
--- 0.17787647247314453 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1831.9052734375, (694.5549, 1.2507575, 1135.7216, 0.37814817)
   validation loss 824.6092529296875, (557.36975, 0.66265625, 266.1987, 0.37814817)
decoder loss ratio: 21593.471789, decoder SINDy loss  ratio: 0.574627
--- 0.1500399112701416 seconds for one epoch ---
--- 0.17810964584350586 seconds for one epoch ---
--- 1.543651819229126 seconds for one epoch ---
--- 0.2784695625305176 seconds for one epoch ---
--- 1.53285813331604 seconds for one epoch ---
--- 0.20215487480163574 seconds for one epoch ---
--- 1.501452922821045 seconds for one epoch ---
--- 0.1991443634033203 seconds for one epoch ---
--- 1.483832597732544 seconds for one epoch ---
--- 0.21831822395324707 seconds for one epoch ---
--- 1.4900321960449219 seconds for one epoch ---
--- 0.18338966369628906 seconds for one epoch ---
--- 1.4948463439941406 seconds for one epoch ---
--- 0.1978743076324463 seconds for one epoch ---
--- 1.5538320541381836 seconds for one epoch ---
--- 0.20800280570983887 seconds for one epoch ---
--- 1.537693977355957 seconds for one epoch ---
--- 0.21107172966003418 seconds for one epoch ---
--- 1.529813528060913 seconds for one epoch ---
--- 0.21061325073242188 seconds for one epoch ---
--- 1.5184996128082275 seconds for one epoch ---
--- 0.21299314498901367 seconds for one epoch ---
--- 1.509547472000122 seconds for one epoch ---
--- 0.21128392219543457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85903007]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.74343]
 [ -0.     ]]
--- 0.13892793655395508 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2654.305908203125, (1720.2979, 2.1120386, 931.51666, 0.37949234)
   validation loss 1101.6348876953125, (800.2765, 0.7167362, 300.2622, 0.37949234)
decoder loss ratio: 31004.100535, decoder SINDy loss  ratio: 0.648158
--- 0.17346644401550293 seconds for one epoch ---
--- 1.5918755531311035 seconds for one epoch ---
--- 0.28971266746520996 seconds for one epoch ---
--- 1.5964138507843018 seconds for one epoch ---
--- 0.20534515380859375 seconds for one epoch ---
--- 1.4880304336547852 seconds for one epoch ---
--- 0.1962287425994873 seconds for one epoch ---
--- 1.4857711791992188 seconds for one epoch ---
--- 0.20742535591125488 seconds for one epoch ---
--- 1.5125839710235596 seconds for one epoch ---
--- 0.18432950973510742 seconds for one epoch ---
--- 1.5245740413665771 seconds for one epoch ---
--- 0.1900038719177246 seconds for one epoch ---
--- 1.6287224292755127 seconds for one epoch ---
--- 0.19637441635131836 seconds for one epoch ---
--- 1.6107425689697266 seconds for one epoch ---
--- 0.20672225952148438 seconds for one epoch ---
--- 1.5254511833190918 seconds for one epoch ---
--- 0.21498799324035645 seconds for one epoch ---
--- 1.6642489433288574 seconds for one epoch ---
--- 0.21059083938598633 seconds for one epoch ---
--- 1.5820379257202148 seconds for one epoch ---
--- 0.1980435848236084 seconds for one epoch ---
--- 1.5892393589019775 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85932374]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.811871]
 [ -0.      ]]
--- 0.1773207187652588 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3078.873291015625, (1643.987, 1.5910535, 1432.9141, 0.38101903)
   validation loss 1493.146728515625, (1146.3588, 0.8744655, 345.5325, 0.38101903)
decoder loss ratio: 44411.928709, decoder SINDy loss  ratio: 0.745881
--- 0.16158795356750488 seconds for one epoch ---
--- 0.21483373641967773 seconds for one epoch ---
--- 1.4934048652648926 seconds for one epoch ---
--- 0.19320058822631836 seconds for one epoch ---
--- 1.4903905391693115 seconds for one epoch ---
--- 0.23253417015075684 seconds for one epoch ---
--- 1.4933605194091797 seconds for one epoch ---
--- 0.2187666893005371 seconds for one epoch ---
--- 1.6634156703948975 seconds for one epoch ---
--- 0.29673123359680176 seconds for one epoch ---
--- 1.4756340980529785 seconds for one epoch ---
--- 0.2274789810180664 seconds for one epoch ---
--- 1.5657804012298584 seconds for one epoch ---
--- 0.18919897079467773 seconds for one epoch ---
--- 1.5109667778015137 seconds for one epoch ---
--- 0.2009141445159912 seconds for one epoch ---
--- 1.5242724418640137 seconds for one epoch ---
--- 0.20047974586486816 seconds for one epoch ---
--- 1.512157678604126 seconds for one epoch ---
--- 0.1885545253753662 seconds for one epoch ---
--- 1.5057690143585205 seconds for one epoch ---
--- 0.18628859519958496 seconds for one epoch ---
--- 1.5269508361816406 seconds for one epoch ---
--- 0.23070764541625977 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8595557]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.869896]
 [ -0.      ]]
--- 0.1414322853088379 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2670.078369140625, (1515.5267, 0.124398656, 1154.0449, 0.38229257)
   validation loss 843.681884765625, (578.1614, 0.71695036, 264.42126, 0.38229257)
decoder loss ratio: 22398.975475, decoder SINDy loss  ratio: 0.570790
--- 0.1697368621826172 seconds for one epoch ---
--- 1.5946142673492432 seconds for one epoch ---
--- 0.18236565589904785 seconds for one epoch ---
--- 1.5559461116790771 seconds for one epoch ---
--- 0.19859623908996582 seconds for one epoch ---
--- 1.7310609817504883 seconds for one epoch ---
--- 0.17911815643310547 seconds for one epoch ---
--- 1.5014796257019043 seconds for one epoch ---
--- 0.20578432083129883 seconds for one epoch ---
--- 1.5623464584350586 seconds for one epoch ---
--- 0.19189095497131348 seconds for one epoch ---
--- 1.5750017166137695 seconds for one epoch ---
--- 0.20057249069213867 seconds for one epoch ---
--- 1.6010396480560303 seconds for one epoch ---
--- 0.20610260963439941 seconds for one epoch ---
--- 1.5021843910217285 seconds for one epoch ---
--- 0.15165424346923828 seconds for one epoch ---
--- 1.5959734916687012 seconds for one epoch ---
--- 0.20755887031555176 seconds for one epoch ---
--- 1.6517963409423828 seconds for one epoch ---
--- 0.20052838325500488 seconds for one epoch ---
--- 1.6621339321136475 seconds for one epoch ---
--- 0.18134522438049316 seconds for one epoch ---
--- 1.6188340187072754 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8597747]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.928723]
 [ -0.      ]]
--- 0.1977689266204834 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3307.8388671875, (1338.1688, 3.390464, 1965.896, 0.38365075)
   validation loss 1116.383056640625, (839.2357, 0.6857872, 276.0779, 0.38365075)
decoder loss ratio: 32513.448684, decoder SINDy loss  ratio: 0.595953
--- 0.16532611846923828 seconds for one epoch ---
--- 0.19192218780517578 seconds for one epoch ---
--- 1.491461992263794 seconds for one epoch ---
--- 0.16486907005310059 seconds for one epoch ---
--- 1.5463459491729736 seconds for one epoch ---
--- 0.1844494342803955 seconds for one epoch ---
--- 1.5536537170410156 seconds for one epoch ---
--- 0.16448330879211426 seconds for one epoch ---
--- 1.5246968269348145 seconds for one epoch ---
--- 0.19219684600830078 seconds for one epoch ---
--- 1.5321784019470215 seconds for one epoch ---
--- 0.17020153999328613 seconds for one epoch ---
--- 1.571568250656128 seconds for one epoch ---
--- 0.2441093921661377 seconds for one epoch ---
--- 1.5572807788848877 seconds for one epoch ---
--- 0.17854046821594238 seconds for one epoch ---
--- 1.5925533771514893 seconds for one epoch ---
--- 0.20871305465698242 seconds for one epoch ---
--- 1.5510704517364502 seconds for one epoch ---
--- 0.2190701961517334 seconds for one epoch ---
--- 1.559093952178955 seconds for one epoch ---
--- 0.18715739250183105 seconds for one epoch ---
--- 1.533759593963623 seconds for one epoch ---
--- 0.22962117195129395 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85995156]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.980202]
 [ -0.      ]]
--- 0.13013362884521484 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3374.8876953125, (1539.2437, 5.822068, 1829.4371, 0.3847272)
   validation loss 936.6299438476562, (677.7055, 0.7068567, 257.83286, 0.3847272)
decoder loss ratio: 26255.487827, decoder SINDy loss  ratio: 0.556568
--- 0.2207050323486328 seconds for one epoch ---
--- 1.6014420986175537 seconds for one epoch ---
--- 0.18475770950317383 seconds for one epoch ---
--- 1.5322034358978271 seconds for one epoch ---
--- 0.18378210067749023 seconds for one epoch ---
--- 1.5285098552703857 seconds for one epoch ---
--- 0.20983505249023438 seconds for one epoch ---
--- 1.7360508441925049 seconds for one epoch ---
--- 0.23330354690551758 seconds for one epoch ---
--- 1.501563549041748 seconds for one epoch ---
--- 0.19280600547790527 seconds for one epoch ---
--- 1.682502031326294 seconds for one epoch ---
--- 0.27419209480285645 seconds for one epoch ---
--- 1.5336811542510986 seconds for one epoch ---
--- 0.18501067161560059 seconds for one epoch ---
--- 1.592045783996582 seconds for one epoch ---
--- 0.21910953521728516 seconds for one epoch ---
--- 1.5571370124816895 seconds for one epoch ---
--- 0.17250418663024902 seconds for one epoch ---
--- 1.645021915435791 seconds for one epoch ---
--- 0.1853327751159668 seconds for one epoch ---
--- 1.6102993488311768 seconds for one epoch ---
--- 0.18792247772216797 seconds for one epoch ---
--- 1.6344106197357178 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8601315]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.037016]
 [ -0.      ]]
--- 0.17310404777526855 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2919.447265625, (1371.7137, 1.7355248, 1545.612, 0.38603494)
   validation loss 1655.3271484375, (1344.4154, 0.7850571, 309.74075, 0.38603494)
decoder loss ratio: 52084.986808, decoder SINDy loss  ratio: 0.668619
--- 0.1767728328704834 seconds for one epoch ---
--- 0.2139592170715332 seconds for one epoch ---
--- 1.7830326557159424 seconds for one epoch ---
--- 0.3004748821258545 seconds for one epoch ---
--- 1.7062311172485352 seconds for one epoch ---
--- 0.19515204429626465 seconds for one epoch ---
--- 1.5576581954956055 seconds for one epoch ---
--- 0.18144536018371582 seconds for one epoch ---
--- 1.5978896617889404 seconds for one epoch ---
--- 0.19201040267944336 seconds for one epoch ---
--- 1.5535056591033936 seconds for one epoch ---
--- 0.2096116542816162 seconds for one epoch ---
--- 1.5609710216522217 seconds for one epoch ---
--- 0.19415712356567383 seconds for one epoch ---
--- 1.8184130191802979 seconds for one epoch ---
--- 0.29462575912475586 seconds for one epoch ---
--- 1.5559711456298828 seconds for one epoch ---
--- 0.23820853233337402 seconds for one epoch ---
--- 1.800943374633789 seconds for one epoch ---
--- 0.18697023391723633 seconds for one epoch ---
--- 1.6087849140167236 seconds for one epoch ---
--- 0.17923998832702637 seconds for one epoch ---
--- 1.6413416862487793 seconds for one epoch ---
--- 0.21537518501281738 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86025745]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.080389]
 [ -0.      ]]
--- 0.187089204788208 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1955.4700927734375, (1003.86847, 2.8636081, 948.3509, 0.38703716)
   validation loss 873.8193359375, (597.91693, 0.6757375, 274.83966, 0.38703716)
decoder loss ratio: 23164.339942, decoder SINDy loss  ratio: 0.593280
--- 0.20248031616210938 seconds for one epoch ---
--- 1.6523799896240234 seconds for one epoch ---
--- 0.20352840423583984 seconds for one epoch ---
--- 1.5167186260223389 seconds for one epoch ---
--- 0.16206836700439453 seconds for one epoch ---
--- 1.7059557437896729 seconds for one epoch ---
--- 0.19303154945373535 seconds for one epoch ---
--- 1.6354992389678955 seconds for one epoch ---
--- 0.16552734375 seconds for one epoch ---
--- 1.6137101650238037 seconds for one epoch ---
--- 0.192152738571167 seconds for one epoch ---
--- 1.5629773139953613 seconds for one epoch ---
--- 0.18413209915161133 seconds for one epoch ---
--- 1.5631413459777832 seconds for one epoch ---
--- 0.1831352710723877 seconds for one epoch ---
--- 1.600534439086914 seconds for one epoch ---
--- 0.1915726661682129 seconds for one epoch ---
--- 1.6552021503448486 seconds for one epoch ---
--- 0.20701909065246582 seconds for one epoch ---
--- 1.662316083908081 seconds for one epoch ---
--- 0.22605347633361816 seconds for one epoch ---
--- 1.7563371658325195 seconds for one epoch ---
--- 0.19692683219909668 seconds for one epoch ---
--- 1.6337916851043701 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86037326]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.122833]
 [ -0.      ]]
--- 0.17804980278015137 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4723.771484375, (1469.7584, 3.3018541, 3250.323, 0.3879503)
   validation loss 1189.8974609375, (890.6974, 0.64632493, 298.1659, 0.3879503)
decoder loss ratio: 34507.163118, decoder SINDy loss  ratio: 0.643633
--- 0.17783856391906738 seconds for one epoch ---
--- 0.1710348129272461 seconds for one epoch ---
--- 1.629906177520752 seconds for one epoch ---
--- 0.19452524185180664 seconds for one epoch ---
--- 1.5499858856201172 seconds for one epoch ---
--- 0.20795249938964844 seconds for one epoch ---
--- 1.673919439315796 seconds for one epoch ---
--- 0.18884754180908203 seconds for one epoch ---
--- 1.6119465827941895 seconds for one epoch ---
--- 0.20048999786376953 seconds for one epoch ---
--- 1.642000675201416 seconds for one epoch ---
--- 0.21889376640319824 seconds for one epoch ---
--- 1.5717535018920898 seconds for one epoch ---
--- 0.1760871410369873 seconds for one epoch ---
--- 1.8355700969696045 seconds for one epoch ---
--- 0.3047466278076172 seconds for one epoch ---
--- 1.5136065483093262 seconds for one epoch ---
--- 0.20018577575683594 seconds for one epoch ---
--- 1.6151816844940186 seconds for one epoch ---
--- 0.18616557121276855 seconds for one epoch ---
--- 1.6924962997436523 seconds for one epoch ---
--- 0.2206435203552246 seconds for one epoch ---
--- 1.6228115558624268 seconds for one epoch ---
--- 0.19363689422607422 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8604832]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.167114]
 [ -0.      ]]
--- 0.17752528190612793 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3043.27001953125, (1190.6605, 1.8560611, 1850.3644, 0.3890407)
   validation loss 871.569580078125, (552.5694, 0.87221396, 317.73895, 0.3890407)
decoder loss ratio: 21407.497741, decoder SINDy loss  ratio: 0.685884
--- 0.2022695541381836 seconds for one epoch ---
--- 1.6493277549743652 seconds for one epoch ---
--- 0.19873261451721191 seconds for one epoch ---
--- 1.6516790390014648 seconds for one epoch ---
--- 0.18057990074157715 seconds for one epoch ---
--- 1.6215076446533203 seconds for one epoch ---
--- 0.17227387428283691 seconds for one epoch ---
--- 1.8286805152893066 seconds for one epoch ---
--- 0.17843985557556152 seconds for one epoch ---
--- 1.626176118850708 seconds for one epoch ---
--- 0.1835470199584961 seconds for one epoch ---
--- 1.6567537784576416 seconds for one epoch ---
--- 0.19369077682495117 seconds for one epoch ---
--- 1.5619580745697021 seconds for one epoch ---
--- 0.18394947052001953 seconds for one epoch ---
--- 1.6277105808258057 seconds for one epoch ---
--- 0.21306991577148438 seconds for one epoch ---
--- 1.6326985359191895 seconds for one epoch ---
--- 0.16363239288330078 seconds for one epoch ---
--- 1.651951789855957 seconds for one epoch ---
--- 0.19057250022888184 seconds for one epoch ---
--- 1.650019884109497 seconds for one epoch ---
--- 0.2248830795288086 seconds for one epoch ---
--- 1.6851325035095215 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8605883]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.212921]
 [ -0.      ]]
--- 0.21026921272277832 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2596.54052734375, (968.9052, 3.3279698, 1623.9175, 0.3899698)
   validation loss 935.9154663085938, (661.9493, 0.784759, 272.79153, 0.3899698)
decoder loss ratio: 25645.064293, decoder SINDy loss  ratio: 0.588859
--- 0.14862370491027832 seconds for one epoch ---
--- 0.22525382041931152 seconds for one epoch ---
--- 1.6168913841247559 seconds for one epoch ---
--- 0.18216824531555176 seconds for one epoch ---
--- 1.6101298332214355 seconds for one epoch ---
--- 0.1803264617919922 seconds for one epoch ---
--- 1.6383275985717773 seconds for one epoch ---
--- 0.20019173622131348 seconds for one epoch ---
--- 1.5819170475006104 seconds for one epoch ---
--- 0.20968866348266602 seconds for one epoch ---
--- 1.6905970573425293 seconds for one epoch ---
--- 0.16649150848388672 seconds for one epoch ---
--- 1.6077837944030762 seconds for one epoch ---
--- 0.19673991203308105 seconds for one epoch ---
--- 1.5808250904083252 seconds for one epoch ---
--- 0.20220112800598145 seconds for one epoch ---
--- 1.643937110900879 seconds for one epoch ---
--- 0.20504999160766602 seconds for one epoch ---
--- 1.5863008499145508 seconds for one epoch ---
--- 0.1918652057647705 seconds for one epoch ---
--- 1.6182758808135986 seconds for one epoch ---
--- 0.1754004955291748 seconds for one epoch ---
--- 1.7127580642700195 seconds for one epoch ---
--- 0.18831610679626465 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8606942]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.263666]
 [ -0.      ]]
--- 0.14467215538024902 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2643.73388671875, (1482.9064, 1.6114109, 1158.8251, 0.3911593)
   validation loss 908.1773071289062, (647.73694, 0.7381205, 259.31113, 0.3911593)
decoder loss ratio: 25094.453517, decoder SINDy loss  ratio: 0.559760
--- 0.18335437774658203 seconds for one epoch ---
--- 1.6440093517303467 seconds for one epoch ---
--- 0.18714022636413574 seconds for one epoch ---
--- 1.6921534538269043 seconds for one epoch ---
--- 0.18294286727905273 seconds for one epoch ---
--- 1.9033029079437256 seconds for one epoch ---
--- 0.20649003982543945 seconds for one epoch ---
--- 1.6720342636108398 seconds for one epoch ---
--- 0.24070048332214355 seconds for one epoch ---
--- 1.6639752388000488 seconds for one epoch ---
--- 0.22250747680664062 seconds for one epoch ---
--- 1.7157471179962158 seconds for one epoch ---
--- 0.2556188106536865 seconds for one epoch ---
--- 1.6396422386169434 seconds for one epoch ---
--- 0.184464693069458 seconds for one epoch ---
--- 1.6740801334381104 seconds for one epoch ---
--- 0.1978154182434082 seconds for one epoch ---
--- 1.624993085861206 seconds for one epoch ---
--- 0.22257018089294434 seconds for one epoch ---
--- 1.6062467098236084 seconds for one epoch ---
--- 0.21814441680908203 seconds for one epoch ---
--- 1.627906322479248 seconds for one epoch ---
--- 0.19309711456298828 seconds for one epoch ---
--- 1.6430473327636719 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607613]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.300539]
 [ -0.      ]]
--- 0.22236967086791992 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4135.27099609375, (1218.3428, 1.4472468, 2915.0886, 0.392011)
   validation loss 782.0944213867188, (499.57465, 0.87123513, 281.2565, 0.392011)
decoder loss ratio: 19354.389086, decoder SINDy loss  ratio: 0.607132
--- 0.1642458438873291 seconds for one epoch ---
--- 0.17726516723632812 seconds for one epoch ---
--- 1.6726479530334473 seconds for one epoch ---
--- 0.18076348304748535 seconds for one epoch ---
--- 1.6542658805847168 seconds for one epoch ---
--- 0.20384693145751953 seconds for one epoch ---
--- 1.946427583694458 seconds for one epoch ---
--- 0.20154523849487305 seconds for one epoch ---
--- 1.6446266174316406 seconds for one epoch ---
--- 0.18870306015014648 seconds for one epoch ---
--- 1.7291457653045654 seconds for one epoch ---
--- 0.2707967758178711 seconds for one epoch ---
--- 1.737119197845459 seconds for one epoch ---
--- 0.21784305572509766 seconds for one epoch ---
--- 2.1044371128082275 seconds for one epoch ---
--- 0.22556090354919434 seconds for one epoch ---
--- 1.8721668720245361 seconds for one epoch ---
--- 0.18675947189331055 seconds for one epoch ---
--- 1.6518158912658691 seconds for one epoch ---
--- 0.17765426635742188 seconds for one epoch ---
--- 1.6316475868225098 seconds for one epoch ---
--- 0.19827699661254883 seconds for one epoch ---
--- 1.6390924453735352 seconds for one epoch ---
--- 0.24465179443359375 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608558]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.359142]
 [ -0.      ]]
--- 0.15346002578735352 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3643.16943359375, (1316.3699, 2.7566352, 2323.6497, 0.39331225)
   validation loss 762.2473754882812, (501.9405, 0.7182364, 259.19534, 0.39331225)
decoder loss ratio: 19446.046018, decoder SINDy loss  ratio: 0.559510
--- 0.2031559944152832 seconds for one epoch ---
--- 1.683668851852417 seconds for one epoch ---
--- 0.17298102378845215 seconds for one epoch ---
--- 1.7891061305999756 seconds for one epoch ---
--- 0.215010404586792 seconds for one epoch ---
--- 1.7741539478302002 seconds for one epoch ---
--- 0.23400545120239258 seconds for one epoch ---
--- 1.6944372653961182 seconds for one epoch ---
--- 0.2142808437347412 seconds for one epoch ---
--- 1.6729724407196045 seconds for one epoch ---
--- 0.1698596477508545 seconds for one epoch ---
--- 1.6900074481964111 seconds for one epoch ---
--- 0.18956327438354492 seconds for one epoch ---
--- 1.687567949295044 seconds for one epoch ---
--- 0.17720365524291992 seconds for one epoch ---
--- 1.6779308319091797 seconds for one epoch ---
--- 0.21233892440795898 seconds for one epoch ---
--- 1.661139965057373 seconds for one epoch ---
--- 0.22639060020446777 seconds for one epoch ---
--- 1.680098295211792 seconds for one epoch ---
--- 0.16960453987121582 seconds for one epoch ---
--- 1.7831048965454102 seconds for one epoch ---
--- 0.21992278099060059 seconds for one epoch ---
--- 1.6744577884674072 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86092234]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.408487]
 [ -0.      ]]
--- 0.17335128784179688 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2504.3662109375, (1030.5538, 0.41259897, 1473.0051, 0.39441985)
   validation loss 967.6566162109375, (661.49365, 0.80927205, 304.9593, 0.39441985)
decoder loss ratio: 25627.412495, decoder SINDy loss  ratio: 0.658298
--- 0.18139886856079102 seconds for one epoch ---
--- 0.20567989349365234 seconds for one epoch ---
--- 1.740997552871704 seconds for one epoch ---
--- 0.19688749313354492 seconds for one epoch ---
--- 1.768744707107544 seconds for one epoch ---
--- 0.17023587226867676 seconds for one epoch ---
--- 1.6171941757202148 seconds for one epoch ---
--- 0.2560243606567383 seconds for one epoch ---
--- 1.6399328708648682 seconds for one epoch ---
--- 0.197706937789917 seconds for one epoch ---
--- 1.62424635887146 seconds for one epoch ---
--- 0.18771147727966309 seconds for one epoch ---
--- 1.672860860824585 seconds for one epoch ---
--- 0.18477559089660645 seconds for one epoch ---
--- 1.7489705085754395 seconds for one epoch ---
--- 0.17251110076904297 seconds for one epoch ---
--- 1.6621880531311035 seconds for one epoch ---
--- 0.18734169006347656 seconds for one epoch ---
--- 1.7106521129608154 seconds for one epoch ---
--- 0.19506621360778809 seconds for one epoch ---
--- 1.6406397819519043 seconds for one epoch ---
--- 0.2226107120513916 seconds for one epoch ---
--- 1.7113697528839111 seconds for one epoch ---
--- 0.18741559982299805 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609785]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.458326]
 [ -0.      ]]
--- 0.1538705825805664 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2416.5751953125, (1734.1418, 1.5958292, 680.4419, 0.39555326)
   validation loss 812.6107788085938, (555.1893, 0.7182649, 256.3077, 0.39555326)
decoder loss ratio: 21508.996172, decoder SINDy loss  ratio: 0.553276
--- 0.2158806324005127 seconds for one epoch ---
--- 1.7518854141235352 seconds for one epoch ---
--- 0.1848888397216797 seconds for one epoch ---
--- 1.72282075881958 seconds for one epoch ---
--- 0.2971031665802002 seconds for one epoch ---
--- 1.7015142440795898 seconds for one epoch ---
--- 0.219390869140625 seconds for one epoch ---
--- 1.7411844730377197 seconds for one epoch ---
--- 0.21351408958435059 seconds for one epoch ---
--- 1.7245571613311768 seconds for one epoch ---
--- 0.18282842636108398 seconds for one epoch ---
--- 1.6969363689422607 seconds for one epoch ---
--- 0.20318222045898438 seconds for one epoch ---
--- 1.7319450378417969 seconds for one epoch ---
--- 0.18778467178344727 seconds for one epoch ---
--- 1.677058219909668 seconds for one epoch ---
--- 0.1761624813079834 seconds for one epoch ---
--- 1.8037631511688232 seconds for one epoch ---
--- 0.48444509506225586 seconds for one epoch ---
--- 1.7627804279327393 seconds for one epoch ---
--- 0.18485498428344727 seconds for one epoch ---
--- 1.6661748886108398 seconds for one epoch ---
--- 0.1784195899963379 seconds for one epoch ---
--- 1.7382867336273193 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102235]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.507658]
 [ -0.      ]]
--- 0.18932008743286133 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3828.384521484375, (1220.4485, 10.62074, 2596.9185, 0.39664972)
   validation loss 1391.663818359375, (1099.8656, 0.7951667, 290.6064, 0.39664972)
decoder loss ratio: 42610.702817, decoder SINDy loss  ratio: 0.627315
--- 0.18736791610717773 seconds for one epoch ---
--- 0.19221949577331543 seconds for one epoch ---
--- 1.6424129009246826 seconds for one epoch ---
--- 0.19830942153930664 seconds for one epoch ---
--- 1.7488088607788086 seconds for one epoch ---
--- 0.1984424591064453 seconds for one epoch ---
--- 1.7600245475769043 seconds for one epoch ---
--- 0.19767522811889648 seconds for one epoch ---
--- 1.7692224979400635 seconds for one epoch ---
--- 0.1860978603363037 seconds for one epoch ---
--- 1.7623045444488525 seconds for one epoch ---
--- 0.1850447654724121 seconds for one epoch ---
--- 1.7532460689544678 seconds for one epoch ---
--- 0.21159672737121582 seconds for one epoch ---
--- 1.7819766998291016 seconds for one epoch ---
--- 0.18184518814086914 seconds for one epoch ---
--- 1.7515676021575928 seconds for one epoch ---
--- 0.19052910804748535 seconds for one epoch ---
--- 1.7558298110961914 seconds for one epoch ---
--- 0.16200852394104004 seconds for one epoch ---
--- 1.7252023220062256 seconds for one epoch ---
--- 0.1748642921447754 seconds for one epoch ---
--- 1.776871919631958 seconds for one epoch ---
--- 0.18401479721069336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86104476]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.540228]
 [ -0.      ]]
--- 0.17645788192749023 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2786.947021484375, (1022.3708, 1.7092409, 1762.4695, 0.39734828)
   validation loss 858.585205078125, (568.3716, 0.68522596, 289.131, 0.39734828)
decoder loss ratio: 22019.701824, decoder SINDy loss  ratio: 0.624130
--- 0.1919994354248047 seconds for one epoch ---
--- 1.7008655071258545 seconds for one epoch ---
--- 0.18347406387329102 seconds for one epoch ---
--- 1.7421925067901611 seconds for one epoch ---
--- 0.19364714622497559 seconds for one epoch ---
--- 1.770596981048584 seconds for one epoch ---
--- 0.1955397129058838 seconds for one epoch ---
--- 1.6810595989227295 seconds for one epoch ---
--- 0.1817004680633545 seconds for one epoch ---
--- 1.8360207080841064 seconds for one epoch ---
--- 0.16446614265441895 seconds for one epoch ---
--- 1.7734980583190918 seconds for one epoch ---
--- 0.22636127471923828 seconds for one epoch ---
--- 1.6679439544677734 seconds for one epoch ---
--- 0.19986438751220703 seconds for one epoch ---
--- 1.6937081813812256 seconds for one epoch ---
--- 0.19324564933776855 seconds for one epoch ---
--- 1.7110495567321777 seconds for one epoch ---
--- 0.22951936721801758 seconds for one epoch ---
--- 1.8572745323181152 seconds for one epoch ---
--- 0.3067319393157959 seconds for one epoch ---
--- 1.7675201892852783 seconds for one epoch ---
--- 0.17708587646484375 seconds for one epoch ---
--- 1.7548925876617432 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610656]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.583834]
 [ -0.      ]]
--- 0.17600369453430176 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2530.320556640625, (1352.2681, 3.2913408, 1174.3627, 0.39837152)
   validation loss 731.3516235351562, (465.80823, 0.683837, 264.46115, 0.39837152)
decoder loss ratio: 18046.219414, decoder SINDy loss  ratio: 0.570877
THRESHOLDING: 1 active coefficients
--- 0.16006970405578613 seconds for one epoch ---
--- 0.21329998970031738 seconds for one epoch ---
--- 1.742823839187622 seconds for one epoch ---
--- 0.1694948673248291 seconds for one epoch ---
--- 1.665605068206787 seconds for one epoch ---
--- 0.16518068313598633 seconds for one epoch ---
--- 1.677269697189331 seconds for one epoch ---
--- 0.1696033477783203 seconds for one epoch ---
--- 1.664294958114624 seconds for one epoch ---
--- 0.2176036834716797 seconds for one epoch ---
--- 1.7275233268737793 seconds for one epoch ---
--- 0.19391679763793945 seconds for one epoch ---
--- 1.7218029499053955 seconds for one epoch ---
--- 0.19495344161987305 seconds for one epoch ---
--- 1.8570117950439453 seconds for one epoch ---
--- 0.2069389820098877 seconds for one epoch ---
--- 1.7736835479736328 seconds for one epoch ---
--- 0.18182015419006348 seconds for one epoch ---
--- 1.9348516464233398 seconds for one epoch ---
--- 0.2161426544189453 seconds for one epoch ---
--- 1.806682825088501 seconds for one epoch ---
--- 0.1789250373840332 seconds for one epoch ---
--- 1.6932694911956787 seconds for one epoch ---
--- 0.19875478744506836 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610786]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.62449]
 [ -0.     ]]
--- 0.17050504684448242 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2738.26318359375, (1240.2084, 0.495005, 1497.1606, 0.39925334)
   validation loss 744.2330932617188, (473.14862, 0.7790044, 269.90625, 0.39925334)
decoder loss ratio: 18330.598984, decoder SINDy loss  ratio: 0.582631
--- 0.17857861518859863 seconds for one epoch ---
--- 1.7754089832305908 seconds for one epoch ---
--- 0.20777106285095215 seconds for one epoch ---
--- 1.8235719203948975 seconds for one epoch ---
--- 0.19778156280517578 seconds for one epoch ---
--- 1.7766191959381104 seconds for one epoch ---
--- 0.20758438110351562 seconds for one epoch ---
--- 1.8082304000854492 seconds for one epoch ---
--- 0.2909400463104248 seconds for one epoch ---
--- 1.8097186088562012 seconds for one epoch ---
--- 0.15967535972595215 seconds for one epoch ---
--- 1.773592233657837 seconds for one epoch ---
--- 0.21605443954467773 seconds for one epoch ---
--- 1.7268962860107422 seconds for one epoch ---
--- 0.1752316951751709 seconds for one epoch ---
--- 1.7864296436309814 seconds for one epoch ---
--- 0.17925453186035156 seconds for one epoch ---
--- 1.7350397109985352 seconds for one epoch ---
--- 0.17076659202575684 seconds for one epoch ---
--- 1.784956932067871 seconds for one epoch ---
--- 0.20325851440429688 seconds for one epoch ---
--- 1.7289152145385742 seconds for one epoch ---
--- 0.1905837059020996 seconds for one epoch ---
--- 1.808894395828247 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86108184]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.655993]
 [ -0.      ]]
--- 0.205061674118042 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3144.99755859375, (1326.3865, 0.6753292, 1817.5359, 0.39998052)
   validation loss 690.3582763671875, (415.3802, 0.8254866, 273.75262, 0.39998052)
decoder loss ratio: 16092.549614, decoder SINDy loss  ratio: 0.590934
--- 0.17641091346740723 seconds for one epoch ---
--- 0.19720983505249023 seconds for one epoch ---
--- 1.9383060932159424 seconds for one epoch ---
--- 0.17029690742492676 seconds for one epoch ---
--- 1.8275516033172607 seconds for one epoch ---
--- 0.17937922477722168 seconds for one epoch ---
--- 1.7831428050994873 seconds for one epoch ---
--- 0.20368599891662598 seconds for one epoch ---
--- 1.8577487468719482 seconds for one epoch ---
--- 0.16948246955871582 seconds for one epoch ---
--- 1.7133045196533203 seconds for one epoch ---
--- 0.22926878929138184 seconds for one epoch ---
--- 1.7844650745391846 seconds for one epoch ---
--- 0.20316147804260254 seconds for one epoch ---
--- 1.8112974166870117 seconds for one epoch ---
--- 0.18215513229370117 seconds for one epoch ---
--- 1.7704715728759766 seconds for one epoch ---
--- 0.19849133491516113 seconds for one epoch ---
--- 1.7885794639587402 seconds for one epoch ---
--- 0.17284059524536133 seconds for one epoch ---
--- 1.740997076034546 seconds for one epoch ---
--- 0.18838214874267578 seconds for one epoch ---
--- 1.7762112617492676 seconds for one epoch ---
--- 0.22369623184204102 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610795]
 [0.       ]]
[[  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-16.6986]
 [ -0.    ]]
--- 0.1911153793334961 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5749.81298828125, (1902.3804, 8.222681, 3838.8093, 0.40090942)
   validation loss 1133.5750732421875, (843.7369, 0.79262733, 288.64474, 0.40090942)
decoder loss ratio: 32687.831424, decoder SINDy loss  ratio: 0.623080
--- 0.216827392578125 seconds for one epoch ---
--- 1.747077226638794 seconds for one epoch ---
--- 0.1997978687286377 seconds for one epoch ---
--- 1.774521827697754 seconds for one epoch ---
--- 0.2164466381072998 seconds for one epoch ---
--- 1.8608410358428955 seconds for one epoch ---
--- 0.2670753002166748 seconds for one epoch ---
--- 1.723097324371338 seconds for one epoch ---
--- 0.21876001358032227 seconds for one epoch ---
--- 1.8415241241455078 seconds for one epoch ---
--- 0.1695997714996338 seconds for one epoch ---
--- 1.7600831985473633 seconds for one epoch ---
--- 0.18002080917358398 seconds for one epoch ---
--- 1.8714625835418701 seconds for one epoch ---
--- 0.1779482364654541 seconds for one epoch ---
--- 1.8750813007354736 seconds for one epoch ---
--- 0.2015368938446045 seconds for one epoch ---
--- 1.7899894714355469 seconds for one epoch ---
--- 0.22187590599060059 seconds for one epoch ---
--- 1.765289545059204 seconds for one epoch ---
--- 0.20624303817749023 seconds for one epoch ---
--- 1.8146891593933105 seconds for one epoch ---
--- 0.2086019515991211 seconds for one epoch ---
--- 1.814568281173706 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610705]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.737724]
 [ -0.      ]]
--- 0.1795201301574707 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3088.4658203125, (1434.2738, 2.181976, 1651.608, 0.40187335)
   validation loss 777.4264526367188, (471.09094, 0.9261825, 305.00748, 0.40187335)
decoder loss ratio: 18250.880958, decoder SINDy loss  ratio: 0.658402
--- 0.15616154670715332 seconds for one epoch ---
--- 0.20409941673278809 seconds for one epoch ---
--- 1.7656917572021484 seconds for one epoch ---
--- 0.18445563316345215 seconds for one epoch ---
--- 1.8987491130828857 seconds for one epoch ---
--- 0.1696326732635498 seconds for one epoch ---
--- 1.8888084888458252 seconds for one epoch ---
--- 0.19348835945129395 seconds for one epoch ---
--- 2.0030343532562256 seconds for one epoch ---
--- 0.3034067153930664 seconds for one epoch ---
--- 1.8480567932128906 seconds for one epoch ---
--- 0.21644973754882812 seconds for one epoch ---
--- 1.812446117401123 seconds for one epoch ---
--- 0.172438383102417 seconds for one epoch ---
--- 1.8282279968261719 seconds for one epoch ---
--- 0.1797008514404297 seconds for one epoch ---
--- 1.733097791671753 seconds for one epoch ---
--- 0.18008828163146973 seconds for one epoch ---
--- 1.8403503894805908 seconds for one epoch ---
--- 0.21059322357177734 seconds for one epoch ---
--- 1.818850040435791 seconds for one epoch ---
--- 0.20416712760925293 seconds for one epoch ---
--- 1.7602088451385498 seconds for one epoch ---
--- 0.17911028861999512 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86104953]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.78548]
 [ -0.     ]]
--- 0.18461132049560547 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2788.5849609375, (1693.1138, 4.091235, 1090.977, 0.4028534)
   validation loss 938.8529052734375, (668.212, 0.8077647, 269.4304, 0.4028534)
decoder loss ratio: 25887.691982, decoder SINDy loss  ratio: 0.581603
--- 0.20050358772277832 seconds for one epoch ---
--- 1.7965755462646484 seconds for one epoch ---
--- 0.17130804061889648 seconds for one epoch ---
--- 1.7967946529388428 seconds for one epoch ---
--- 0.16947245597839355 seconds for one epoch ---
--- 1.7995421886444092 seconds for one epoch ---
--- 0.20383048057556152 seconds for one epoch ---
--- 1.80436372756958 seconds for one epoch ---
--- 0.16896796226501465 seconds for one epoch ---
--- 1.754634141921997 seconds for one epoch ---
--- 0.22442078590393066 seconds for one epoch ---
--- 1.8878772258758545 seconds for one epoch ---
--- 0.2557249069213867 seconds for one epoch ---
--- 1.7602739334106445 seconds for one epoch ---
--- 0.21825218200683594 seconds for one epoch ---
--- 1.8209326267242432 seconds for one epoch ---
--- 0.19286012649536133 seconds for one epoch ---
--- 1.8542242050170898 seconds for one epoch ---
--- 0.23223447799682617 seconds for one epoch ---
--- 1.8414685726165771 seconds for one epoch ---
--- 0.17915964126586914 seconds for one epoch ---
--- 1.8096339702606201 seconds for one epoch ---
--- 0.1782236099243164 seconds for one epoch ---
--- 1.8293042182922363 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102355]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.822525]
 [ -0.      ]]
--- 0.20203638076782227 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2719.422119140625, (1015.5258, 2.194562, 1701.2979, 0.4037662)
   validation loss 1010.054443359375, (678.5965, 0.9011728, 330.153, 0.4037662)
decoder loss ratio: 26290.006373, decoder SINDy loss  ratio: 0.712682
--- 0.16451525688171387 seconds for one epoch ---
--- 0.17635488510131836 seconds for one epoch ---
--- 1.8935799598693848 seconds for one epoch ---
--- 0.19904732704162598 seconds for one epoch ---
--- 1.7941601276397705 seconds for one epoch ---
--- 0.19239163398742676 seconds for one epoch ---
--- 1.8994500637054443 seconds for one epoch ---
--- 0.24791264533996582 seconds for one epoch ---
--- 1.8721911907196045 seconds for one epoch ---
--- 0.19577527046203613 seconds for one epoch ---
--- 1.905308723449707 seconds for one epoch ---
--- 0.20070457458496094 seconds for one epoch ---
--- 1.8279478549957275 seconds for one epoch ---
--- 0.17507028579711914 seconds for one epoch ---
--- 1.857696771621704 seconds for one epoch ---
--- 0.18719029426574707 seconds for one epoch ---
--- 1.8148081302642822 seconds for one epoch ---
--- 0.18354320526123047 seconds for one epoch ---
--- 1.8463475704193115 seconds for one epoch ---
--- 0.18066024780273438 seconds for one epoch ---
--- 1.8096818923950195 seconds for one epoch ---
--- 0.2077648639678955 seconds for one epoch ---
--- 1.761178731918335 seconds for one epoch ---
--- 0.21166563034057617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86099267]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.860378]
 [ -0.      ]]
--- 0.15166831016540527 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3659.4072265625, (1550.0575, 1.9610386, 2106.9841, 0.40462494)
   validation loss 788.3546752929688, (529.84045, 0.8615371, 257.24814, 0.40462494)
decoder loss ratio: 20526.939035, decoder SINDy loss  ratio: 0.555306
--- 0.18248534202575684 seconds for one epoch ---
--- 1.8464884757995605 seconds for one epoch ---
--- 0.2224442958831787 seconds for one epoch ---
--- 1.7879278659820557 seconds for one epoch ---
--- 0.16427254676818848 seconds for one epoch ---
--- 1.8536810874938965 seconds for one epoch ---
--- 0.2140514850616455 seconds for one epoch ---
--- 1.8446102142333984 seconds for one epoch ---
--- 0.21608901023864746 seconds for one epoch ---
--- 1.8794808387756348 seconds for one epoch ---
--- 0.21149682998657227 seconds for one epoch ---
--- 1.8933343887329102 seconds for one epoch ---
--- 0.18597769737243652 seconds for one epoch ---
--- 1.9320802688598633 seconds for one epoch ---
--- 0.16515278816223145 seconds for one epoch ---
--- 1.8835608959197998 seconds for one epoch ---
--- 0.18623971939086914 seconds for one epoch ---
--- 1.975029468536377 seconds for one epoch ---
--- 0.19243860244750977 seconds for one epoch ---
--- 1.9150116443634033 seconds for one epoch ---
--- 0.1895599365234375 seconds for one epoch ---
--- 1.8174588680267334 seconds for one epoch ---
--- 0.18093466758728027 seconds for one epoch ---
--- 1.845571756362915 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.860948]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.902897]
 [ -0.      ]]
--- 0.24282193183898926 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1699.7896728515625, (1026.6427, 1.6390436, 671.1024, 0.40552446)
   validation loss 1128.5850830078125, (807.2425, 1.0354772, 319.90158, 0.40552446)
decoder loss ratio: 31273.975601, decoder SINDy loss  ratio: 0.690553
--- 0.2119903564453125 seconds for one epoch ---
--- 0.17621660232543945 seconds for one epoch ---
--- 2.290313720703125 seconds for one epoch ---
--- 0.20529985427856445 seconds for one epoch ---
--- 2.330811023712158 seconds for one epoch ---
--- 0.2423388957977295 seconds for one epoch ---
--- 2.286581516265869 seconds for one epoch ---
--- 0.24615693092346191 seconds for one epoch ---
--- 2.1887426376342773 seconds for one epoch ---
--- 0.22187423706054688 seconds for one epoch ---
--- 2.0551466941833496 seconds for one epoch ---
--- 0.25499582290649414 seconds for one epoch ---
--- 2.0364861488342285 seconds for one epoch ---
--- 0.22332215309143066 seconds for one epoch ---
--- 2.0387260913848877 seconds for one epoch ---
--- 0.2153332233428955 seconds for one epoch ---
--- 2.2213079929351807 seconds for one epoch ---
--- 0.19113421440124512 seconds for one epoch ---
--- 2.1501214504241943 seconds for one epoch ---
--- 0.20516324043273926 seconds for one epoch ---
--- 2.123046875 seconds for one epoch ---
--- 0.21382880210876465 seconds for one epoch ---
--- 1.9782931804656982 seconds for one epoch ---
--- 0.17244720458984375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86090255]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.940567]
 [ -0.      ]]
--- 0.18193435668945312 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4248.24755859375, (1625.3109, 2.357918, 2620.1726, 0.4063863)
   validation loss 1040.6551513671875, (746.8705, 0.99614334, 292.38214, 0.4063863)
decoder loss ratio: 28935.059151, decoder SINDy loss  ratio: 0.631148
--- 0.21718358993530273 seconds for one epoch ---
--- 2.085803985595703 seconds for one epoch ---
--- 0.224609375 seconds for one epoch ---
--- 2.1944639682769775 seconds for one epoch ---
--- 0.197587251663208 seconds for one epoch ---
--- 2.101451873779297 seconds for one epoch ---
--- 0.19175171852111816 seconds for one epoch ---
--- 2.2235608100891113 seconds for one epoch ---
--- 0.2273857593536377 seconds for one epoch ---
--- 2.0591745376586914 seconds for one epoch ---
--- 0.22376704216003418 seconds for one epoch ---
--- 2.234846591949463 seconds for one epoch ---
--- 0.183380126953125 seconds for one epoch ---
--- 2.049358606338501 seconds for one epoch ---
--- 0.18875432014465332 seconds for one epoch ---
--- 2.1260271072387695 seconds for one epoch ---
--- 0.19415688514709473 seconds for one epoch ---
--- 2.2109718322753906 seconds for one epoch ---
--- 0.19612646102905273 seconds for one epoch ---
--- 2.118433713912964 seconds for one epoch ---
--- 0.21100926399230957 seconds for one epoch ---
--- 2.4362168312072754 seconds for one epoch ---
--- 0.16119146347045898 seconds for one epoch ---
--- 2.0694899559020996 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86084735]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.979582]
 [ -0.      ]]
--- 0.18145966529846191 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2697.267578125, (1190.959, 3.843495, 1502.058, 0.40728292)
   validation loss 916.1126708984375, (622.7339, 0.9950169, 291.9765, 0.40728292)
decoder loss ratio: 24125.791885, decoder SINDy loss  ratio: 0.630272
--- 0.1491711139678955 seconds for one epoch ---
--- 0.18510794639587402 seconds for one epoch ---
--- 1.8513004779815674 seconds for one epoch ---
--- 0.19403576850891113 seconds for one epoch ---
--- 1.8916070461273193 seconds for one epoch ---
--- 0.18681049346923828 seconds for one epoch ---
--- 1.9152848720550537 seconds for one epoch ---
--- 0.16043686866760254 seconds for one epoch ---
--- 1.8673100471496582 seconds for one epoch ---
--- 0.21988153457641602 seconds for one epoch ---
--- 1.8788206577301025 seconds for one epoch ---
--- 0.20280742645263672 seconds for one epoch ---
--- 1.922053337097168 seconds for one epoch ---
--- 0.1910114288330078 seconds for one epoch ---
--- 1.9164354801177979 seconds for one epoch ---
--- 0.20433902740478516 seconds for one epoch ---
--- 1.979320764541626 seconds for one epoch ---
--- 0.21283793449401855 seconds for one epoch ---
--- 1.9253027439117432 seconds for one epoch ---
--- 0.20236468315124512 seconds for one epoch ---
--- 1.9356861114501953 seconds for one epoch ---
--- 0.1967325210571289 seconds for one epoch ---
--- 2.090148448944092 seconds for one epoch ---
--- 0.17327141761779785 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608047]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.007015]
 [ -0.      ]]
--- 0.16210484504699707 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3410.501708984375, (1247.1711, 2.3730996, 2160.5496, 0.40792236)
   validation loss 742.1906127929688, (476.29965, 0.8823692, 264.60074, 0.40792236)
decoder loss ratio: 18452.675415, decoder SINDy loss  ratio: 0.571178
--- 0.25040555000305176 seconds for one epoch ---
--- 2.254617929458618 seconds for one epoch ---
--- 0.19776415824890137 seconds for one epoch ---
--- 2.2642822265625 seconds for one epoch ---
--- 0.21407532691955566 seconds for one epoch ---
--- 2.2193241119384766 seconds for one epoch ---
--- 0.1911606788635254 seconds for one epoch ---
--- 2.040740728378296 seconds for one epoch ---
--- 0.19278216361999512 seconds for one epoch ---
--- 2.2233903408050537 seconds for one epoch ---
--- 0.2833857536315918 seconds for one epoch ---
--- 2.221405506134033 seconds for one epoch ---
--- 0.17725062370300293 seconds for one epoch ---
--- 2.0995237827301025 seconds for one epoch ---
--- 0.18991303443908691 seconds for one epoch ---
--- 2.0484249591827393 seconds for one epoch ---
--- 0.20247364044189453 seconds for one epoch ---
--- 2.1096062660217285 seconds for one epoch ---
--- 0.1976168155670166 seconds for one epoch ---
--- 2.051856517791748 seconds for one epoch ---
--- 0.2005784511566162 seconds for one epoch ---
--- 2.073423147201538 seconds for one epoch ---
--- 0.1935575008392334 seconds for one epoch ---
--- 1.9203705787658691 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607327]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.048542]
 [ -0.      ]]
--- 0.17402076721191406 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2033.779541015625, (948.8769, 2.378174, 1082.1156, 0.4088783)
   validation loss 1530.010498046875, (1207.5685, 0.97772115, 321.05542, 0.4088783)
decoder loss ratio: 46783.299402, decoder SINDy loss  ratio: 0.693043
--- 0.14142155647277832 seconds for one epoch ---
--- 0.18503618240356445 seconds for one epoch ---
--- 1.865492582321167 seconds for one epoch ---
--- 0.20957374572753906 seconds for one epoch ---
--- 1.9557161331176758 seconds for one epoch ---
--- 0.19028496742248535 seconds for one epoch ---
--- 1.9584457874298096 seconds for one epoch ---
--- 0.21143865585327148 seconds for one epoch ---
--- 1.9407610893249512 seconds for one epoch ---
--- 0.21035003662109375 seconds for one epoch ---
--- 1.889540672302246 seconds for one epoch ---
--- 0.19145774841308594 seconds for one epoch ---
--- 1.9347963333129883 seconds for one epoch ---
--- 0.23255419731140137 seconds for one epoch ---
--- 1.87674880027771 seconds for one epoch ---
--- 0.1813499927520752 seconds for one epoch ---
--- 1.9495604038238525 seconds for one epoch ---
--- 0.18509936332702637 seconds for one epoch ---
--- 1.969797134399414 seconds for one epoch ---
--- 0.18030619621276855 seconds for one epoch ---
--- 1.9343321323394775 seconds for one epoch ---
--- 0.21417927742004395 seconds for one epoch ---
--- 1.9138667583465576 seconds for one epoch ---
--- 0.20116686820983887 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86068314]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.074757]
 [ -0.      ]]
--- 0.16119003295898438 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3804.715576171875, (1585.052, 3.624524, 2215.6296, 0.40941745)
   validation loss 817.44873046875, (552.7401, 0.9465724, 263.35257, 0.40941745)
decoder loss ratio: 21414.111550, decoder SINDy loss  ratio: 0.568484
--- 0.23444175720214844 seconds for one epoch ---
--- 1.9163918495178223 seconds for one epoch ---
--- 0.25432443618774414 seconds for one epoch ---
--- 1.9272689819335938 seconds for one epoch ---
--- 0.21196436882019043 seconds for one epoch ---
--- 1.91269850730896 seconds for one epoch ---
--- 0.19081544876098633 seconds for one epoch ---
--- 1.9383447170257568 seconds for one epoch ---
--- 0.2304248809814453 seconds for one epoch ---
--- 2.0179967880249023 seconds for one epoch ---
--- 0.22963881492614746 seconds for one epoch ---
--- 1.9606404304504395 seconds for one epoch ---
--- 0.18719983100891113 seconds for one epoch ---
--- 1.8997104167938232 seconds for one epoch ---
--- 0.20567727088928223 seconds for one epoch ---
--- 1.9527099132537842 seconds for one epoch ---
--- 0.19584012031555176 seconds for one epoch ---
--- 1.9734382629394531 seconds for one epoch ---
--- 0.22277379035949707 seconds for one epoch ---
--- 1.902543306350708 seconds for one epoch ---
--- 0.2261061668395996 seconds for one epoch ---
--- 1.9031391143798828 seconds for one epoch ---
--- 0.17666053771972656 seconds for one epoch ---
--- 1.9414007663726807 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.860631]
 [0.      ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-17.1007]
 [ -0.    ]]
--- 0.1820065975189209 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3423.75927734375, (865.3693, 3.581532, 2554.3984, 0.4100226)
   validation loss 785.5309448242188, (523.6827, 0.87655205, 260.5617, 0.4100226)
decoder loss ratio: 20288.376107, decoder SINDy loss  ratio: 0.562459
--- 0.18500518798828125 seconds for one epoch ---
--- 0.20456790924072266 seconds for one epoch ---
--- 1.8463208675384521 seconds for one epoch ---
--- 0.1889033317565918 seconds for one epoch ---
--- 1.9003288745880127 seconds for one epoch ---
--- 0.2136385440826416 seconds for one epoch ---
--- 1.9447252750396729 seconds for one epoch ---
--- 0.20339393615722656 seconds for one epoch ---
--- 1.9478554725646973 seconds for one epoch ---
--- 0.19712519645690918 seconds for one epoch ---
--- 1.9853198528289795 seconds for one epoch ---
--- 0.21255803108215332 seconds for one epoch ---
--- 1.9739775657653809 seconds for one epoch ---
--- 0.19446349143981934 seconds for one epoch ---
--- 1.9282805919647217 seconds for one epoch ---
--- 0.21717572212219238 seconds for one epoch ---
--- 1.9431633949279785 seconds for one epoch ---
--- 0.19396305084228516 seconds for one epoch ---
--- 1.9953389167785645 seconds for one epoch ---
--- 0.17786836624145508 seconds for one epoch ---
--- 1.9565331935882568 seconds for one epoch ---
--- 0.2096691131591797 seconds for one epoch ---
--- 1.8630421161651611 seconds for one epoch ---
--- 0.19778084754943848 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86056054]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.132877]
 [ -0.      ]]
--- 0.1544647216796875 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1836.2001953125, (974.56964, 2.121991, 859.0978, 0.41073313)
   validation loss 884.1423950195312, (615.7025, 0.9112696, 267.11795, 0.41073313)
decoder loss ratio: 23853.384324, decoder SINDy loss  ratio: 0.576612
--- 0.1969006061553955 seconds for one epoch ---
--- 2.003028154373169 seconds for one epoch ---
--- 0.18585753440856934 seconds for one epoch ---
--- 1.8856594562530518 seconds for one epoch ---
--- 0.19559693336486816 seconds for one epoch ---
--- 1.9137699604034424 seconds for one epoch ---
--- 0.21509480476379395 seconds for one epoch ---
--- 1.9304773807525635 seconds for one epoch ---
--- 0.1763744354248047 seconds for one epoch ---
--- 1.952944040298462 seconds for one epoch ---
--- 0.20714020729064941 seconds for one epoch ---
--- 1.8924946784973145 seconds for one epoch ---
--- 0.17580127716064453 seconds for one epoch ---
--- 1.942145586013794 seconds for one epoch ---
--- 0.17232537269592285 seconds for one epoch ---
--- 1.9082062244415283 seconds for one epoch ---
--- 0.17447185516357422 seconds for one epoch ---
--- 1.9227654933929443 seconds for one epoch ---
--- 0.20089221000671387 seconds for one epoch ---
--- 1.942948818206787 seconds for one epoch ---
--- 0.18848490715026855 seconds for one epoch ---
--- 2.0839288234710693 seconds for one epoch ---
--- 0.1982269287109375 seconds for one epoch ---
--- 1.914625644683838 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86047935]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.168276]
 [ -0.      ]]
--- 0.18642520904541016 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3695.1455078125, (1544.0249, 2.1005354, 2148.6084, 0.41153532)
   validation loss 893.2216796875, (620.77765, 1.0097318, 271.02277, 0.41153532)
decoder loss ratio: 24050.003837, decoder SINDy loss  ratio: 0.585041
--- 0.154127836227417 seconds for one epoch ---
--- 0.17360806465148926 seconds for one epoch ---
--- 1.976510763168335 seconds for one epoch ---
--- 0.1810598373413086 seconds for one epoch ---
--- 1.9705758094787598 seconds for one epoch ---
--- 0.17045354843139648 seconds for one epoch ---
--- 2.025723695755005 seconds for one epoch ---
--- 0.23609328269958496 seconds for one epoch ---
--- 2.0344276428222656 seconds for one epoch ---
--- 0.2914602756500244 seconds for one epoch ---
--- 2.083230495452881 seconds for one epoch ---
--- 0.16699790954589844 seconds for one epoch ---
--- 2.2441940307617188 seconds for one epoch ---
--- 0.17630600929260254 seconds for one epoch ---
--- 2.156841993331909 seconds for one epoch ---
--- 0.24465370178222656 seconds for one epoch ---
--- 2.1839447021484375 seconds for one epoch ---
--- 0.2651076316833496 seconds for one epoch ---
--- 2.1803536415100098 seconds for one epoch ---
--- 0.1715390682220459 seconds for one epoch ---
--- 2.1884522438049316 seconds for one epoch ---
--- 0.20145273208618164 seconds for one epoch ---
--- 2.2495994567871094 seconds for one epoch ---
--- 0.16366243362426758 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8603962]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.20138]
 [ -0.     ]]
--- 0.16096210479736328 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2965.02587890625, (1356.7697, 2.170663, 1605.6732, 0.41231704)
   validation loss 821.1375122070312, (559.1598, 0.9986348, 260.5668, 0.41231704)
decoder loss ratio: 21662.821010, decoder SINDy loss  ratio: 0.562470
--- 0.20449113845825195 seconds for one epoch ---
--- 2.2396767139434814 seconds for one epoch ---
--- 0.18500161170959473 seconds for one epoch ---
--- 2.337967872619629 seconds for one epoch ---
--- 0.1944575309753418 seconds for one epoch ---
--- 1.988678216934204 seconds for one epoch ---
--- 0.19252800941467285 seconds for one epoch ---
--- 1.994680643081665 seconds for one epoch ---
--- 0.18117165565490723 seconds for one epoch ---
--- 1.9863169193267822 seconds for one epoch ---
--- 0.1744527816772461 seconds for one epoch ---
--- 2.0191283226013184 seconds for one epoch ---
--- 0.1922152042388916 seconds for one epoch ---
--- 2.0778956413269043 seconds for one epoch ---
--- 0.17438101768493652 seconds for one epoch ---
--- 2.004596710205078 seconds for one epoch ---
--- 0.17373919486999512 seconds for one epoch ---
--- 1.9566497802734375 seconds for one epoch ---
--- 0.17877793312072754 seconds for one epoch ---
--- 1.881065845489502 seconds for one epoch ---
--- 0.17945456504821777 seconds for one epoch ---
--- 1.9662103652954102 seconds for one epoch ---
--- 0.18095707893371582 seconds for one epoch ---
--- 2.0872550010681152 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8602988]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.238466]
 [ -0.      ]]
--- 0.21585988998413086 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2053.82275390625, (1177.2661, 3.0229661, 873.12067, 0.41309068)
   validation loss 944.2606201171875, (653.9718, 1.0829045, 288.79288, 0.41309068)
decoder loss ratio: 25336.002945, decoder SINDy loss  ratio: 0.623400
--- 0.15721678733825684 seconds for one epoch ---
--- 0.2067873477935791 seconds for one epoch ---
--- 1.9322497844696045 seconds for one epoch ---
--- 0.16547298431396484 seconds for one epoch ---
--- 2.0255351066589355 seconds for one epoch ---
--- 0.2061934471130371 seconds for one epoch ---
--- 1.928421974182129 seconds for one epoch ---
--- 0.20894432067871094 seconds for one epoch ---
--- 2.0983755588531494 seconds for one epoch ---
--- 0.20582103729248047 seconds for one epoch ---
--- 1.9404191970825195 seconds for one epoch ---
--- 0.1771693229675293 seconds for one epoch ---
--- 1.965296745300293 seconds for one epoch ---
--- 0.20140814781188965 seconds for one epoch ---
--- 1.9175782203674316 seconds for one epoch ---
--- 0.1744844913482666 seconds for one epoch ---
--- 1.9204645156860352 seconds for one epoch ---
--- 0.18340468406677246 seconds for one epoch ---
--- 1.9225671291351318 seconds for one epoch ---
--- 0.1811985969543457 seconds for one epoch ---
--- 2.3273799419403076 seconds for one epoch ---
--- 0.19496798515319824 seconds for one epoch ---
--- 2.4522624015808105 seconds for one epoch ---
--- 0.2044072151184082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86020666]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.270668]
 [ -0.      ]]
--- 0.20093965530395508 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2501.256103515625, (1036.2191, 0.25172433, 1464.3716, 0.41389653)
   validation loss 763.4255981445312, (459.83273, 1.0860376, 302.09296, 0.41389653)
decoder loss ratio: 17814.718387, decoder SINDy loss  ratio: 0.652110
--- 0.23944687843322754 seconds for one epoch ---
--- 2.3476452827453613 seconds for one epoch ---
--- 0.17897653579711914 seconds for one epoch ---
--- 2.124023914337158 seconds for one epoch ---
--- 0.17769885063171387 seconds for one epoch ---
--- 2.2534420490264893 seconds for one epoch ---
--- 0.23011517524719238 seconds for one epoch ---
--- 2.2705860137939453 seconds for one epoch ---
--- 0.21011972427368164 seconds for one epoch ---
--- 2.30812668800354 seconds for one epoch ---
--- 0.22385549545288086 seconds for one epoch ---
--- 2.1924545764923096 seconds for one epoch ---
--- 0.2096261978149414 seconds for one epoch ---
--- 2.1016685962677 seconds for one epoch ---
--- 0.1892702579498291 seconds for one epoch ---
--- 2.1931228637695312 seconds for one epoch ---
--- 0.17947983741760254 seconds for one epoch ---
--- 2.3873026371002197 seconds for one epoch ---
--- 0.16458821296691895 seconds for one epoch ---
--- 2.223968744277954 seconds for one epoch ---
--- 0.17599892616271973 seconds for one epoch ---
--- 2.394030809402466 seconds for one epoch ---
--- 0.2096390724182129 seconds for one epoch ---
--- 2.4301018714904785 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8601167]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.300869]
 [ -0.      ]]
--- 0.18230652809143066 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3253.578369140625, (1106.4172, 3.3716195, 2143.375, 0.4144911)
   validation loss 1009.7823486328125, (709.9566, 1.1109123, 298.30035, 0.4144911)
decoder loss ratio: 27504.951378, decoder SINDy loss  ratio: 0.643923
THRESHOLDING: 1 active coefficients
--- 1.9952397346496582 seconds for one epoch ---
--- 0.2466132640838623 seconds for one epoch ---
--- 2.033909797668457 seconds for one epoch ---
--- 0.2123415470123291 seconds for one epoch ---
--- 2.0143957138061523 seconds for one epoch ---
--- 0.18216729164123535 seconds for one epoch ---
--- 2.063960313796997 seconds for one epoch ---
--- 0.21698498725891113 seconds for one epoch ---
--- 1.9517207145690918 seconds for one epoch ---
--- 0.18321704864501953 seconds for one epoch ---
--- 2.0504117012023926 seconds for one epoch ---
--- 0.1897904872894287 seconds for one epoch ---
--- 2.017298936843872 seconds for one epoch ---
--- 0.24186038970947266 seconds for one epoch ---
--- 2.0018727779388428 seconds for one epoch ---
--- 0.17317676544189453 seconds for one epoch ---
--- 2.127551794052124 seconds for one epoch ---
--- 0.18534064292907715 seconds for one epoch ---
--- 1.9463939666748047 seconds for one epoch ---
--- 0.17081618309020996 seconds for one epoch ---
--- 2.0053205490112305 seconds for one epoch ---
--- 0.22995257377624512 seconds for one epoch ---
--- 1.950028896331787 seconds for one epoch ---
--- 0.21202421188354492 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8600074]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.335476]
 [ -0.      ]]
--- 0.17900419235229492 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3459.832763671875, (1312.9576, 1.9012467, 2144.5586, 0.41538596)
   validation loss 846.9395751953125, (529.31616, 1.1443715, 316.0637, 0.41538596)
decoder loss ratio: 20506.627053, decoder SINDy loss  ratio: 0.682268
--- 0.16623830795288086 seconds for one epoch ---
--- 2.268113374710083 seconds for one epoch ---
--- 0.31198692321777344 seconds for one epoch ---
--- 2.2337327003479004 seconds for one epoch ---
--- 0.17344307899475098 seconds for one epoch ---
--- 2.328237771987915 seconds for one epoch ---
--- 0.2134091854095459 seconds for one epoch ---
--- 2.237764835357666 seconds for one epoch ---
--- 0.1749250888824463 seconds for one epoch ---
--- 2.179961919784546 seconds for one epoch ---
--- 0.157698392868042 seconds for one epoch ---
--- 2.1275224685668945 seconds for one epoch ---
--- 0.2048015594482422 seconds for one epoch ---
--- 2.0153093338012695 seconds for one epoch ---
--- 0.2008495330810547 seconds for one epoch ---
--- 2.1233131885528564 seconds for one epoch ---
--- 0.19669175148010254 seconds for one epoch ---
--- 2.0700747966766357 seconds for one epoch ---
--- 0.2070331573486328 seconds for one epoch ---
--- 2.1055564880371094 seconds for one epoch ---
--- 0.18308043479919434 seconds for one epoch ---
--- 2.1395156383514404 seconds for one epoch ---
--- 0.3124845027923584 seconds for one epoch ---
--- 2.125293731689453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85990757]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.365852]
 [ -0.      ]]
--- 0.196929931640625 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3457.03857421875, (1729.1431, 0.5378593, 1726.9415, 0.41601405)
   validation loss 790.5152587890625, (514.87994, 1.0569282, 274.16232, 0.41601405)
decoder loss ratio: 19947.342896, decoder SINDy loss  ratio: 0.591818
--- 0.17917323112487793 seconds for one epoch ---
--- 0.1854536533355713 seconds for one epoch ---
--- 2.363650321960449 seconds for one epoch ---
--- 0.26293110847473145 seconds for one epoch ---
--- 2.426382541656494 seconds for one epoch ---
--- 0.20026040077209473 seconds for one epoch ---
--- 2.220402240753174 seconds for one epoch ---
--- 0.23832154273986816 seconds for one epoch ---
--- 2.312875747680664 seconds for one epoch ---
--- 0.20946979522705078 seconds for one epoch ---
--- 2.3840277194976807 seconds for one epoch ---
--- 0.2763044834136963 seconds for one epoch ---
--- 2.2387149333953857 seconds for one epoch ---
--- 0.24683451652526855 seconds for one epoch ---
--- 2.440833568572998 seconds for one epoch ---
--- 0.23299384117126465 seconds for one epoch ---
--- 2.3070828914642334 seconds for one epoch ---
--- 0.20616555213928223 seconds for one epoch ---
--- 2.378197193145752 seconds for one epoch ---
--- 0.21323657035827637 seconds for one epoch ---
--- 2.2376577854156494 seconds for one epoch ---
--- 0.19925975799560547 seconds for one epoch ---
--- 2.371277093887329 seconds for one epoch ---
--- 0.1884593963623047 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85979956]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.397165]
 [ -0.      ]]
--- 0.15522336959838867 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3663.83349609375, (1499.004, 1.8939128, 2162.5188, 0.41674042)
   validation loss 880.330078125, (594.8853, 1.0167967, 284.0112, 0.41674042)
decoder loss ratio: 23046.889867, decoder SINDy loss  ratio: 0.613078
--- 0.16716599464416504 seconds for one epoch ---
--- 2.0705349445343018 seconds for one epoch ---
--- 0.18497610092163086 seconds for one epoch ---
--- 2.184095859527588 seconds for one epoch ---
--- 0.2159278392791748 seconds for one epoch ---
--- 2.08713436126709 seconds for one epoch ---
--- 0.1988375186920166 seconds for one epoch ---
--- 1.9481236934661865 seconds for one epoch ---
--- 0.20635032653808594 seconds for one epoch ---
--- 2.0488128662109375 seconds for one epoch ---
--- 0.21645212173461914 seconds for one epoch ---
--- 2.0212106704711914 seconds for one epoch ---
--- 0.2530944347381592 seconds for one epoch ---
--- 2.019166946411133 seconds for one epoch ---
--- 0.20910072326660156 seconds for one epoch ---
--- 2.233100652694702 seconds for one epoch ---
--- 0.209975004196167 seconds for one epoch ---
--- 2.1154472827911377 seconds for one epoch ---
--- 0.21421241760253906 seconds for one epoch ---
--- 2.0254125595092773 seconds for one epoch ---
--- 0.19156241416931152 seconds for one epoch ---
--- 2.0747177600860596 seconds for one epoch ---
--- 0.19069695472717285 seconds for one epoch ---
--- 2.049611806869507 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8596856]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.42889]
 [ -0.     ]]
--- 0.20375394821166992 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2521.834228515625, (1042.832, 2.496065, 1476.0886, 0.41741157)
   validation loss 1023.729248046875, (731.3712, 1.1243479, 290.81628, 0.41741157)
decoder loss ratio: 28334.590617, decoder SINDy loss  ratio: 0.627768
--- 0.14404988288879395 seconds for one epoch ---
--- 0.16422438621520996 seconds for one epoch ---
--- 2.0165293216705322 seconds for one epoch ---
--- 0.19622039794921875 seconds for one epoch ---
--- 2.022151470184326 seconds for one epoch ---
--- 0.1844022274017334 seconds for one epoch ---
--- 2.0771329402923584 seconds for one epoch ---
--- 0.19983553886413574 seconds for one epoch ---
--- 2.1120712757110596 seconds for one epoch ---
--- 0.2980501651763916 seconds for one epoch ---
--- 2.1162827014923096 seconds for one epoch ---
--- 0.16416239738464355 seconds for one epoch ---
--- 2.1504526138305664 seconds for one epoch ---
--- 0.18950438499450684 seconds for one epoch ---
--- 2.142164707183838 seconds for one epoch ---
--- 0.21415472030639648 seconds for one epoch ---
--- 2.080798864364624 seconds for one epoch ---
--- 0.20104241371154785 seconds for one epoch ---
--- 2.131474018096924 seconds for one epoch ---
--- 0.17897534370422363 seconds for one epoch ---
--- 2.09657621383667 seconds for one epoch ---
--- 0.22240924835205078 seconds for one epoch ---
--- 2.119027853012085 seconds for one epoch ---
--- 0.1984713077545166 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85958964]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.45483]
 [ -0.     ]]
--- 0.2126767635345459 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2337.1669921875, (1464.3993, 1.393978, 870.9559, 0.41801053)
   validation loss 926.6901245117188, (651.7012, 1.1036412, 273.46725, 0.41801053)
decoder loss ratio: 25248.034801, decoder SINDy loss  ratio: 0.590318
--- 0.17352843284606934 seconds for one epoch ---
--- 2.486370325088501 seconds for one epoch ---
--- 0.20340490341186523 seconds for one epoch ---
--- 2.256085157394409 seconds for one epoch ---
--- 0.2255096435546875 seconds for one epoch ---
--- 2.561453342437744 seconds for one epoch ---
--- 0.18828606605529785 seconds for one epoch ---
--- 2.3608386516571045 seconds for one epoch ---
--- 0.20682668685913086 seconds for one epoch ---
--- 2.4198849201202393 seconds for one epoch ---
--- 0.26323580741882324 seconds for one epoch ---
--- 2.248837471008301 seconds for one epoch ---
--- 0.2072744369506836 seconds for one epoch ---
--- 2.409395217895508 seconds for one epoch ---
--- 0.20125246047973633 seconds for one epoch ---
--- 2.3020193576812744 seconds for one epoch ---
--- 0.24103689193725586 seconds for one epoch ---
--- 2.425711154937744 seconds for one epoch ---
--- 0.2116718292236328 seconds for one epoch ---
--- 2.348398447036743 seconds for one epoch ---
--- 0.21473383903503418 seconds for one epoch ---
--- 2.361438035964966 seconds for one epoch ---
--- 0.2216336727142334 seconds for one epoch ---
--- 2.0811691284179688 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8594836]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.48223]
 [ -0.     ]]
--- 0.1840665340423584 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5403.73583984375, (2875.013, 0.9790229, 2527.3252, 0.418598)
   validation loss 760.0560302734375, (490.0867, 1.1451693, 268.40558, 0.418598)
decoder loss ratio: 18986.809603, decoder SINDy loss  ratio: 0.579391
--- 0.15329647064208984 seconds for one epoch ---
--- 0.212022066116333 seconds for one epoch ---
--- 2.300358772277832 seconds for one epoch ---
--- 0.19308829307556152 seconds for one epoch ---
--- 2.120635747909546 seconds for one epoch ---
--- 0.16894268989562988 seconds for one epoch ---
--- 2.1248788833618164 seconds for one epoch ---
--- 0.19159507751464844 seconds for one epoch ---
--- 2.1208765506744385 seconds for one epoch ---
--- 0.2163681983947754 seconds for one epoch ---
--- 2.150045871734619 seconds for one epoch ---
--- 0.21940898895263672 seconds for one epoch ---
--- 2.165288209915161 seconds for one epoch ---
--- 0.1842517852783203 seconds for one epoch ---
--- 2.1236331462860107 seconds for one epoch ---
--- 0.20519375801086426 seconds for one epoch ---
--- 2.1082136631011963 seconds for one epoch ---
--- 0.2044081687927246 seconds for one epoch ---
--- 2.205202341079712 seconds for one epoch ---
--- 0.18607544898986816 seconds for one epoch ---
--- 2.1438119411468506 seconds for one epoch ---
--- 0.23258042335510254 seconds for one epoch ---
--- 2.211839437484741 seconds for one epoch ---
--- 0.1914823055267334 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85939074]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.505455]
 [ -0.      ]]
--- 0.15164518356323242 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2213.07080078125, (912.2035, 0.6972417, 1299.7509, 0.4191992)
   validation loss 842.5421142578125, (548.69073, 1.1637912, 292.26834, 0.4191992)
decoder loss ratio: 21257.231638, decoder SINDy loss  ratio: 0.630902
--- 0.23332929611206055 seconds for one epoch ---
--- 2.4720077514648438 seconds for one epoch ---
--- 0.19080686569213867 seconds for one epoch ---
--- 2.415376663208008 seconds for one epoch ---
--- 0.19977188110351562 seconds for one epoch ---
--- 2.486924409866333 seconds for one epoch ---
--- 0.16221308708190918 seconds for one epoch ---
--- 2.303081750869751 seconds for one epoch ---
--- 0.23673605918884277 seconds for one epoch ---
--- 2.4571478366851807 seconds for one epoch ---
--- 0.20703506469726562 seconds for one epoch ---
--- 2.4355380535125732 seconds for one epoch ---
--- 0.1963210105895996 seconds for one epoch ---
--- 2.53787899017334 seconds for one epoch ---
--- 0.267681360244751 seconds for one epoch ---
--- 2.466686725616455 seconds for one epoch ---
--- 0.2094740867614746 seconds for one epoch ---
--- 2.480422258377075 seconds for one epoch ---
--- 0.15932512283325195 seconds for one epoch ---
--- 2.35624361038208 seconds for one epoch ---
--- 0.18326115608215332 seconds for one epoch ---
--- 2.3912744522094727 seconds for one epoch ---
--- 0.20183444023132324 seconds for one epoch ---
--- 2.206913471221924 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8592857]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.531109]
 [ -0.      ]]
--- 0.16919589042663574 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3580.601806640625, (1376.3756, 0.8171583, 2202.9895, 0.41976053)
   validation loss 866.4389038085938, (609.1167, 1.0747652, 255.8277, 0.41976053)
decoder loss ratio: 23598.238401, decoder SINDy loss  ratio: 0.552240
--- 0.18694615364074707 seconds for one epoch ---
--- 0.20466160774230957 seconds for one epoch ---
--- 2.432600736618042 seconds for one epoch ---
--- 0.24100542068481445 seconds for one epoch ---
--- 2.4755911827087402 seconds for one epoch ---
--- 0.19835400581359863 seconds for one epoch ---
--- 2.266315460205078 seconds for one epoch ---
--- 0.2326509952545166 seconds for one epoch ---
--- 2.2503774166107178 seconds for one epoch ---
--- 0.2421555519104004 seconds for one epoch ---
--- 2.3413727283477783 seconds for one epoch ---
--- 0.17739415168762207 seconds for one epoch ---
--- 2.5506956577301025 seconds for one epoch ---
--- 0.18059992790222168 seconds for one epoch ---
--- 2.5249528884887695 seconds for one epoch ---
--- 0.18808984756469727 seconds for one epoch ---
--- 2.435560464859009 seconds for one epoch ---
--- 0.1660449504852295 seconds for one epoch ---
--- 2.2971482276916504 seconds for one epoch ---
--- 0.18141746520996094 seconds for one epoch ---
--- 2.5412745475769043 seconds for one epoch ---
--- 0.17838358879089355 seconds for one epoch ---
--- 2.3409488201141357 seconds for one epoch ---
--- 0.23348474502563477 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8591826]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.555368]
 [ -0.      ]]
--- 0.1790623664855957 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3407.85546875, (1470.3424, 2.6254141, 1934.4673, 0.42030683)
   validation loss 785.3118896484375, (522.1733, 0.98466444, 261.7336, 0.42030683)
decoder loss ratio: 20229.899354, decoder SINDy loss  ratio: 0.564989
--- 0.1725010871887207 seconds for one epoch ---
--- 2.0994436740875244 seconds for one epoch ---
--- 0.17941784858703613 seconds for one epoch ---
--- 2.2331559658050537 seconds for one epoch ---
--- 0.18254351615905762 seconds for one epoch ---
--- 2.180136203765869 seconds for one epoch ---
--- 0.18215298652648926 seconds for one epoch ---
--- 2.1483476161956787 seconds for one epoch ---
--- 0.17341256141662598 seconds for one epoch ---
--- 2.2022058963775635 seconds for one epoch ---
--- 0.20114946365356445 seconds for one epoch ---
--- 2.126861095428467 seconds for one epoch ---
--- 0.2085738182067871 seconds for one epoch ---
--- 2.186342239379883 seconds for one epoch ---
--- 0.19021964073181152 seconds for one epoch ---
--- 2.280461549758911 seconds for one epoch ---
--- 0.19627714157104492 seconds for one epoch ---
--- 2.1923038959503174 seconds for one epoch ---
--- 0.19375324249267578 seconds for one epoch ---
--- 2.202446460723877 seconds for one epoch ---
--- 0.1791548728942871 seconds for one epoch ---
--- 2.1922802925109863 seconds for one epoch ---
--- 0.215712308883667 seconds for one epoch ---
--- 2.3752589225769043 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8590334]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.589281]
 [ -0.      ]]
--- 0.17035484313964844 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2769.72705078125, (1117.8932, 2.1390805, 1649.2737, 0.4210701)
   validation loss 737.091064453125, (475.30698, 1.0031945, 260.3598, 0.4210701)
decoder loss ratio: 18414.217432, decoder SINDy loss  ratio: 0.562023
--- 0.2588367462158203 seconds for one epoch ---
--- 0.19589853286743164 seconds for one epoch ---
--- 2.6937642097473145 seconds for one epoch ---
--- 0.19474411010742188 seconds for one epoch ---
--- 2.663015842437744 seconds for one epoch ---
--- 0.21282100677490234 seconds for one epoch ---
--- 2.467693328857422 seconds for one epoch ---
--- 0.18924784660339355 seconds for one epoch ---
--- 2.5185441970825195 seconds for one epoch ---
--- 0.2572009563446045 seconds for one epoch ---
--- 2.7348811626434326 seconds for one epoch ---
--- 0.1766054630279541 seconds for one epoch ---
--- 2.752359628677368 seconds for one epoch ---
--- 0.21267080307006836 seconds for one epoch ---
--- 2.4174678325653076 seconds for one epoch ---
--- 0.18830037117004395 seconds for one epoch ---
--- 2.5734541416168213 seconds for one epoch ---
--- 0.1936030387878418 seconds for one epoch ---
--- 2.492866039276123 seconds for one epoch ---
--- 0.24953460693359375 seconds for one epoch ---
--- 2.5189998149871826 seconds for one epoch ---
--- 0.21039223670959473 seconds for one epoch ---
--- 2.3671514987945557 seconds for one epoch ---
--- 0.2280416488647461 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8589456]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.60857]
 [ -0.     ]]
--- 0.16983819007873535 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5284.64306640625, (1888.3527, 2.9666529, 3392.9023, 0.42157087)
   validation loss 924.5265502929688, (620.96216, 0.95997226, 302.1829, 0.42157087)
decoder loss ratio: 24057.152047, decoder SINDy loss  ratio: 0.652304
--- 0.19303035736083984 seconds for one epoch ---
--- 2.129045009613037 seconds for one epoch ---
--- 0.1926267147064209 seconds for one epoch ---
--- 2.196467399597168 seconds for one epoch ---
--- 0.15800690650939941 seconds for one epoch ---
--- 2.185162305831909 seconds for one epoch ---
--- 0.18741726875305176 seconds for one epoch ---
--- 2.179736375808716 seconds for one epoch ---
--- 0.2171792984008789 seconds for one epoch ---
--- 2.151312828063965 seconds for one epoch ---
--- 0.19417095184326172 seconds for one epoch ---
--- 2.323849678039551 seconds for one epoch ---
--- 0.2151029109954834 seconds for one epoch ---
--- 2.1709399223327637 seconds for one epoch ---
--- 0.21258783340454102 seconds for one epoch ---
--- 2.1863033771514893 seconds for one epoch ---
--- 0.20521068572998047 seconds for one epoch ---
--- 2.1714344024658203 seconds for one epoch ---
--- 0.21087193489074707 seconds for one epoch ---
--- 2.1648812294006348 seconds for one epoch ---
--- 0.1969447135925293 seconds for one epoch ---
--- 2.231492280960083 seconds for one epoch ---
--- 0.6156904697418213 seconds for one epoch ---
--- 2.213092565536499 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85881877]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.635838]
 [ -0.      ]]
--- 0.1837172508239746 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5068.9443359375, (1843.2632, 3.317548, 3221.9414, 0.42213845)
   validation loss 725.62646484375, (452.48474, 1.0384625, 271.68118, 0.42213845)
decoder loss ratio: 17530.044423, decoder SINDy loss  ratio: 0.586462
--- 0.18997955322265625 seconds for one epoch ---
--- 0.18944215774536133 seconds for one epoch ---
--- 2.1416680812835693 seconds for one epoch ---
--- 0.21565842628479004 seconds for one epoch ---
--- 2.1725597381591797 seconds for one epoch ---
--- 0.15779662132263184 seconds for one epoch ---
--- 2.257896661758423 seconds for one epoch ---
--- 0.16723871231079102 seconds for one epoch ---
--- 2.285126209259033 seconds for one epoch ---
--- 0.18970084190368652 seconds for one epoch ---
--- 2.1972970962524414 seconds for one epoch ---
--- 0.2148289680480957 seconds for one epoch ---
--- 2.2008090019226074 seconds for one epoch ---
--- 0.1985151767730713 seconds for one epoch ---
--- 2.2858476638793945 seconds for one epoch ---
--- 0.18648004531860352 seconds for one epoch ---
--- 2.2426319122314453 seconds for one epoch ---
--- 0.20326876640319824 seconds for one epoch ---
--- 2.4451863765716553 seconds for one epoch ---
--- 0.18816280364990234 seconds for one epoch ---
--- 2.559551239013672 seconds for one epoch ---
--- 0.20335912704467773 seconds for one epoch ---
--- 2.722365379333496 seconds for one epoch ---
--- 0.29842114448547363 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8587027]
 [0.       ]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-17.6602]
 [ -0.    ]]
--- 0.2687361240386963 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2595.394775390625, (950.24255, 5.1003146, 1639.6293, 0.42270216)
   validation loss 856.553955078125, (557.7505, 1.0306453, 297.35013, 0.42270216)
decoder loss ratio: 21608.222213, decoder SINDy loss  ratio: 0.641872
--- 0.2974567413330078 seconds for one epoch ---
--- 2.641033411026001 seconds for one epoch ---
--- 0.21973490715026855 seconds for one epoch ---
--- 2.5301663875579834 seconds for one epoch ---
--- 0.1916217803955078 seconds for one epoch ---
--- 2.5276503562927246 seconds for one epoch ---
--- 0.21300029754638672 seconds for one epoch ---
--- 2.492940664291382 seconds for one epoch ---
--- 0.17234039306640625 seconds for one epoch ---
--- 2.828406572341919 seconds for one epoch ---
--- 0.196183443069458 seconds for one epoch ---
--- 2.5445258617401123 seconds for one epoch ---
--- 0.2060694694519043 seconds for one epoch ---
--- 2.231414794921875 seconds for one epoch ---
--- 0.22348856925964355 seconds for one epoch ---
--- 2.281024217605591 seconds for one epoch ---
--- 0.1740553379058838 seconds for one epoch ---
--- 2.304064989089966 seconds for one epoch ---
--- 0.17917943000793457 seconds for one epoch ---
--- 2.275413990020752 seconds for one epoch ---
--- 0.2004683017730713 seconds for one epoch ---
--- 2.2321224212646484 seconds for one epoch ---
--- 0.21230435371398926 seconds for one epoch ---
--- 2.1900885105133057 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85859466]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.682285]
 [ -0.      ]]
--- 0.2199079990386963 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3546.85986328125, (1473.7024, 2.7258484, 2070.0085, 0.42318988)
   validation loss 862.0040283203125, (572.57184, 0.9841574, 288.02487, 0.42318988)
decoder loss ratio: 22182.427047, decoder SINDy loss  ratio: 0.621742
--- 0.23378658294677734 seconds for one epoch ---
--- 0.1678314208984375 seconds for one epoch ---
--- 2.4797592163085938 seconds for one epoch ---
--- 0.24701333045959473 seconds for one epoch ---
--- 2.601200580596924 seconds for one epoch ---
--- 0.2077798843383789 seconds for one epoch ---
--- 2.491382122039795 seconds for one epoch ---
--- 0.18627476692199707 seconds for one epoch ---
--- 2.5095863342285156 seconds for one epoch ---
--- 0.21292901039123535 seconds for one epoch ---
--- 2.5019867420196533 seconds for one epoch ---
--- 0.251910924911499 seconds for one epoch ---
--- 2.3787736892700195 seconds for one epoch ---
--- 0.18619394302368164 seconds for one epoch ---
--- 2.557920455932617 seconds for one epoch ---
--- 0.17847180366516113 seconds for one epoch ---
--- 2.673845052719116 seconds for one epoch ---
--- 0.21567130088806152 seconds for one epoch ---
--- 2.640636682510376 seconds for one epoch ---
--- 0.22340655326843262 seconds for one epoch ---
--- 2.4610188007354736 seconds for one epoch ---
--- 0.21593379974365234 seconds for one epoch ---
--- 2.540093183517456 seconds for one epoch ---
--- 0.18055438995361328 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8584913]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.703163]
 [ -0.      ]]
--- 0.16364145278930664 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2831.642822265625, (995.01245, 0.7148197, 1835.492, 0.42364788)
   validation loss 727.0963134765625, (461.76425, 1.0046784, 263.90375, 0.42364788)
decoder loss ratio: 17889.548769, decoder SINDy loss  ratio: 0.569673
--- 0.2208702564239502 seconds for one epoch ---
--- 2.1683719158172607 seconds for one epoch ---
--- 0.18690013885498047 seconds for one epoch ---
--- 2.23917818069458 seconds for one epoch ---
--- 0.23235774040222168 seconds for one epoch ---
--- 2.2049763202667236 seconds for one epoch ---
--- 0.1914222240447998 seconds for one epoch ---
--- 2.2085044384002686 seconds for one epoch ---
--- 0.23564887046813965 seconds for one epoch ---
--- 2.277740716934204 seconds for one epoch ---
--- 0.22667336463928223 seconds for one epoch ---
--- 2.3108291625976562 seconds for one epoch ---
--- 0.25579190254211426 seconds for one epoch ---
--- 2.2789251804351807 seconds for one epoch ---
--- 0.20183897018432617 seconds for one epoch ---
--- 2.428209066390991 seconds for one epoch ---
--- 0.18770408630371094 seconds for one epoch ---
--- 2.2561893463134766 seconds for one epoch ---
--- 0.18380475044250488 seconds for one epoch ---
--- 2.2140114307403564 seconds for one epoch ---
--- 0.17956066131591797 seconds for one epoch ---
--- 2.28558087348938 seconds for one epoch ---
--- 0.18903326988220215 seconds for one epoch ---
--- 2.348296880722046 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.858343]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.732296]
 [ -0.      ]]
--- 0.17972850799560547 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3291.05859375, (1650.9338, 0.7691884, 1638.9313, 0.42429516)
   validation loss 848.7821044921875, (533.5107, 1.158215, 313.68893, 0.42429516)
decoder loss ratio: 20669.130003, decoder SINDy loss  ratio: 0.677142
--- 1.0826911926269531 seconds for one epoch ---
--- 0.20931434631347656 seconds for one epoch ---
--- 2.6192798614501953 seconds for one epoch ---
--- 0.19833588600158691 seconds for one epoch ---
--- 2.648557424545288 seconds for one epoch ---
--- 0.21899175643920898 seconds for one epoch ---
--- 2.472771167755127 seconds for one epoch ---
--- 0.20601367950439453 seconds for one epoch ---
--- 2.543705701828003 seconds for one epoch ---
--- 0.2737603187561035 seconds for one epoch ---
--- 2.5638978481292725 seconds for one epoch ---
--- 0.2639658451080322 seconds for one epoch ---
--- 2.5581791400909424 seconds for one epoch ---
--- 0.19240283966064453 seconds for one epoch ---
--- 2.5783884525299072 seconds for one epoch ---
--- 0.28301334381103516 seconds for one epoch ---
--- 2.574420213699341 seconds for one epoch ---
--- 0.1781468391418457 seconds for one epoch ---
--- 2.4774937629699707 seconds for one epoch ---
--- 0.17988324165344238 seconds for one epoch ---
--- 2.729292392730713 seconds for one epoch ---
--- 0.22753477096557617 seconds for one epoch ---
--- 2.449018716812134 seconds for one epoch ---
--- 0.24162673950195312 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8582022]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.75916]
 [ -0.     ]]
--- 0.16381216049194336 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3682.143798828125, (1588.1868, 1.6020539, 2091.93, 0.42493495)
   validation loss 804.1300659179688, (520.42505, 0.913367, 282.3667, 0.42493495)
decoder loss ratio: 20162.169889, decoder SINDy loss  ratio: 0.609528
--- 0.17467045783996582 seconds for one epoch ---
--- 2.28796124458313 seconds for one epoch ---
--- 0.20239019393920898 seconds for one epoch ---
--- 2.183966875076294 seconds for one epoch ---
--- 0.20159339904785156 seconds for one epoch ---
--- 2.2349212169647217 seconds for one epoch ---
--- 0.20185089111328125 seconds for one epoch ---
--- 2.3135509490966797 seconds for one epoch ---
--- 0.18715953826904297 seconds for one epoch ---
--- 2.2272703647613525 seconds for one epoch ---
--- 0.19124317169189453 seconds for one epoch ---
--- 2.2812633514404297 seconds for one epoch ---
--- 0.23118019104003906 seconds for one epoch ---
--- 2.236638307571411 seconds for one epoch ---
--- 0.2050614356994629 seconds for one epoch ---
--- 2.253638505935669 seconds for one epoch ---
--- 0.17700505256652832 seconds for one epoch ---
--- 2.220928907394409 seconds for one epoch ---
--- 0.2202763557434082 seconds for one epoch ---
--- 2.2097971439361572 seconds for one epoch ---
--- 0.18153882026672363 seconds for one epoch ---
--- 2.2186899185180664 seconds for one epoch ---
--- 0.18325328826904297 seconds for one epoch ---
--- 2.193148136138916 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.858058]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.785934]
 [ -0.      ]]
--- 0.1797943115234375 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2366.011962890625, (1219.6115, 2.2050586, 1143.77, 0.42549935)
   validation loss 759.08349609375, (469.43915, 1.0577968, 288.16107, 0.42549935)
decoder loss ratio: 18186.887574, decoder SINDy loss  ratio: 0.622036
--- 0.1972205638885498 seconds for one epoch ---
--- 0.20948052406311035 seconds for one epoch ---
--- 2.2457003593444824 seconds for one epoch ---
--- 0.20552492141723633 seconds for one epoch ---
--- 2.2877140045166016 seconds for one epoch ---
--- 0.26817941665649414 seconds for one epoch ---
--- 2.2267301082611084 seconds for one epoch ---
--- 0.1718132495880127 seconds for one epoch ---
--- 2.3673579692840576 seconds for one epoch ---
--- 0.17776179313659668 seconds for one epoch ---
--- 2.2159576416015625 seconds for one epoch ---
--- 0.21103477478027344 seconds for one epoch ---
--- 2.5397555828094482 seconds for one epoch ---
--- 0.17866206169128418 seconds for one epoch ---
--- 2.7224860191345215 seconds for one epoch ---
--- 0.21362042427062988 seconds for one epoch ---
--- 2.4951894283294678 seconds for one epoch ---
--- 0.2000713348388672 seconds for one epoch ---
--- 2.7204582691192627 seconds for one epoch ---
--- 0.2210087776184082 seconds for one epoch ---
--- 2.531981945037842 seconds for one epoch ---
--- 0.2764606475830078 seconds for one epoch ---
--- 2.683990716934204 seconds for one epoch ---
--- 0.21268200874328613 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8579748]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.80104]
 [ -0.     ]]
--- 0.16389083862304688 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1822.8109130859375, (993.714, 0.23062265, 828.4404, 0.4258732)
   validation loss 889.5446166992188, (613.40564, 1.0414144, 274.67163, 0.4258732)
decoder loss ratio: 23764.399399, decoder SINDy loss  ratio: 0.592917
--- 0.18601703643798828 seconds for one epoch ---
--- 2.5707340240478516 seconds for one epoch ---
--- 0.21434259414672852 seconds for one epoch ---
--- 2.6286611557006836 seconds for one epoch ---
--- 0.16780686378479004 seconds for one epoch ---
--- 2.3351290225982666 seconds for one epoch ---
--- 0.21124982833862305 seconds for one epoch ---
--- 2.348630905151367 seconds for one epoch ---
--- 0.19246840476989746 seconds for one epoch ---
--- 2.3285698890686035 seconds for one epoch ---
--- 0.20192742347717285 seconds for one epoch ---
--- 2.3896753787994385 seconds for one epoch ---
--- 0.16535019874572754 seconds for one epoch ---
--- 2.1896660327911377 seconds for one epoch ---
--- 0.2113327980041504 seconds for one epoch ---
--- 2.250868320465088 seconds for one epoch ---
--- 0.22763681411743164 seconds for one epoch ---
--- 2.481109857559204 seconds for one epoch ---
--- 0.21220874786376953 seconds for one epoch ---
--- 2.3775644302368164 seconds for one epoch ---
--- 0.20393681526184082 seconds for one epoch ---
--- 2.2235779762268066 seconds for one epoch ---
--- 0.23168063163757324 seconds for one epoch ---
--- 2.291038990020752 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.857805]
 [0.      ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [-17.8314]
 [ -0.    ]]
--- 0.23049712181091309 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4010.848388671875, (1081.4042, 3.7168539, 2925.301, 0.42655745)
   validation loss 1036.991943359375, (735.8731, 1.0625627, 299.62982, 0.42655745)
decoder loss ratio: 28509.001732, decoder SINDy loss  ratio: 0.646793
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8577937]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.83321]
 [  0.     ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1059.54541015625, (564.31854, 0.34640098, 494.8805, 0.4265957)
   validation loss 705.7586669921875, (450.94046, 0.70472324, 254.11353, 0.4265957)
decoder loss ratio: 17470.216295, decoder SINDy loss  ratio: 0.548540
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85756385]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.76255]
 [  0.     ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.4686889648438, (371.84573, 0.7984347, 423.82452, 0.4274527)
   validation loss 489.48284912109375, (271.96997, 0.15783665, 217.35504, 0.4274527)
decoder loss ratio: 10536.588826, decoder SINDy loss  ratio: 0.469191
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85795575]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.80212]
 [ -0.     ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.0145263671875, (358.47336, 0.61767745, 395.92346, 0.42580482)
   validation loss 507.2635498046875, (299.5281, 0.12471022, 207.61073, 0.42580482)
decoder loss ratio: 11604.238857, decoder SINDy loss  ratio: 0.448157
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8585267]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.730127]
 [ -0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.6194458007812, (286.80344, 0.4894636, 379.32654, 0.42337838)
   validation loss 458.7882995605469, (244.9391, 0.08322345, 213.76598, 0.42337838)
decoder loss ratio: 9489.366051, decoder SINDy loss  ratio: 0.461444
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8590731]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.54679]
 [  0.     ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1157.4710693359375, (779.0948, 0.42567846, 377.9506, 0.42075253)
   validation loss 998.168212890625, (754.52606, 0.072476745, 243.56972, 0.42075253)
decoder loss ratio: 29231.649557, decoder SINDy loss  ratio: 0.525779
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8595567]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.486279]
 [ -0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.0140380859375, (263.28326, 0.36365774, 362.3671, 0.41808096)
   validation loss 433.87249755859375, (222.80228, 0.061087687, 211.00916, 0.41808096)
decoder loss ratio: 8631.746998, decoder SINDy loss  ratio: 0.455493
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.85994923]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.345634]
 [  0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 600.770263671875, (239.00395, 0.35923406, 361.40707, 0.4156126)
   validation loss 387.58404541015625, (188.61693, 0.059783515, 198.90735, 0.4156126)
decoder loss ratio: 7307.347248, decoder SINDy loss  ratio: 0.429369
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86026967]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.223087]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.2333984375, (359.2477, 0.32983413, 356.65582, 0.41324958)
   validation loss 528.95703125, (316.34323, 0.049219623, 212.56459, 0.41324958)
decoder loss ratio: 12255.685973, decoder SINDy loss  ratio: 0.458851
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86051625]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.094643]
 [ -0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.0211181640625, (537.92834, 0.2990268, 361.79376, 0.4111053)
   validation loss 718.38818359375, (491.8552, 0.047219947, 226.4858, 0.4111053)
decoder loss ratio: 19055.324117, decoder SINDy loss  ratio: 0.488901
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.860702]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.038109]
 [ -0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.10498046875, (260.9809, 0.2778265, 357.84625, 0.4091231)
   validation loss 420.37939453125, (213.00964, 0.04291948, 207.32683, 0.4091231)
decoder loss ratio: 8252.363392, decoder SINDy loss  ratio: 0.447544
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86083394]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.056969]
 [ -0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 597.6482543945312, (235.1587, 0.2779474, 362.2116, 0.40737435)
   validation loss 378.008544921875, (181.0766, 0.0445455, 196.88742, 0.40737435)
decoder loss ratio: 7015.221813, decoder SINDy loss  ratio: 0.425009
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86093533]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.906332]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 603.0734252929688, (249.4761, 0.28976423, 353.30756, 0.4057479)
   validation loss 401.4681396484375, (201.02635, 0.043884497, 200.39789, 0.4057479)
decoder loss ratio: 7788.109871, decoder SINDy loss  ratio: 0.432587
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609994]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.842691]
 [ -0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.1168823242188, (390.25592, 0.27282768, 382.58813, 0.40434486)
   validation loss 525.4710693359375, (328.5468, 0.042401865, 196.88188, 0.40434486)
decoder loss ratio: 12728.473955, decoder SINDy loss  ratio: 0.424997
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86104083]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.795153]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 904.181640625, (495.7311, 0.27712074, 408.17337, 0.4031252)
   validation loss 595.1875, (397.69376, 0.0452062, 197.44858, 0.4031252)
decoder loss ratio: 15407.346538, decoder SINDy loss  ratio: 0.426221
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610668]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.802027]
 [ -0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 593.581787109375, (237.35481, 0.2658131, 355.96115, 0.40197918)
   validation loss 371.57281494140625, (180.00713, 0.045727685, 191.51994, 0.40197918)
decoder loss ratio: 6973.788562, decoder SINDy loss  ratio: 0.413423
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86107856]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.624578]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.259765625, (413.42444, 0.24911271, 347.5862, 0.40101996)
   validation loss 564.4500732421875, (356.68182, 0.04328586, 207.72498, 0.40101996)
decoder loss ratio: 13818.473078, decoder SINDy loss  ratio: 0.448404
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86108094]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.674604]
 [  0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 591.0284423828125, (233.13776, 0.25278458, 357.6379, 0.40010795)
   validation loss 370.50103759765625, (179.50894, 0.043549966, 190.94856, 0.40010795)
decoder loss ratio: 6954.488041, decoder SINDy loss  ratio: 0.412189
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610792]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.592783]
 [  0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 968.584716796875, (614.81903, 0.23601061, 353.52963, 0.39946947)
   validation loss 761.9110107421875, (541.77924, 0.042493653, 220.08931, 0.39946947)
decoder loss ratio: 20989.468167, decoder SINDy loss  ratio: 0.475094
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86107385]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.606667]
 [ -0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 592.8082885742188, (232.56157, 0.25925362, 359.9875, 0.39879686)
   validation loss 372.1712646484375, (181.60364, 0.04357132, 190.52406, 0.39879686)
decoder loss ratio: 7035.640202, decoder SINDy loss  ratio: 0.411273
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610646]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.570173]
 [  0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1712.860107421875, (1296.7299, 0.22395845, 415.9062, 0.3982788)
   validation loss 1368.8773193359375, (1100.5205, 0.039617155, 268.31714, 0.3982788)
decoder loss ratio: 42636.075060, decoder SINDy loss  ratio: 0.579200
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86105424]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.562305]
 [ -0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 628.27978515625, (264.71268, 0.24857739, 363.31854, 0.39777136)
   validation loss 393.7982482910156, (205.7456, 0.04381666, 188.00882, 0.39777136)
decoder loss ratio: 7970.941946, decoder SINDy loss  ratio: 0.405843
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86104524]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.544306]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 641.42431640625, (294.1707, 0.23552129, 347.01813, 0.39742216)
   validation loss 430.691650390625, (233.00786, 0.04254966, 197.64124, 0.39742216)
decoder loss ratio: 9027.128949, decoder SINDy loss  ratio: 0.426636
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610393]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.543844]
 [  0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 573.1962890625, (219.71832, 0.24553964, 353.2324, 0.3971471)
   validation loss 357.84332275390625, (168.34637, 0.043453954, 189.45348, 0.3971471)
decoder loss ratio: 6522.030811, decoder SINDy loss  ratio: 0.408962
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.861031]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.453287]
 [  0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 594.6948852539062, (242.33292, 0.2313221, 352.13065, 0.39696473)
   validation loss 381.6587219238281, (187.21869, 0.040271096, 194.39977, 0.39696473)
decoder loss ratio: 7253.177036, decoder SINDy loss  ratio: 0.419639
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102617]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.473122]
 [  0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.1873168945312, (392.04852, 0.23960312, 377.8992, 0.3967235)
   validation loss 530.7174682617188, (341.7564, 0.04174208, 188.91931, 0.3967235)
decoder loss ratio: 13240.236588, decoder SINDy loss  ratio: 0.407809
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610202]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.42789]
 [ -0.     ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.3485107421875, (348.10687, 0.22635627, 346.0153, 0.3965821)
   validation loss 476.51885986328125, (277.66092, 0.042314354, 198.81563, 0.3965821)
decoder loss ratio: 10757.066050, decoder SINDy loss  ratio: 0.429171
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610196]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.501122]
 [ -0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 581.8951416015625, (234.28058, 0.22923957, 347.3853, 0.39655405)
   validation loss 367.02880859375, (177.63542, 0.04309078, 189.35031, 0.39655405)
decoder loss ratio: 6881.904627, decoder SINDy loss  ratio: 0.408739
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86101806]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.557507]
 [  0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 566.2113037109375, (212.83224, 0.23708546, 353.142, 0.39652714)
   validation loss 358.17657470703125, (170.09503, 0.042558182, 188.039, 0.39652714)
decoder loss ratio: 6589.776828, decoder SINDy loss  ratio: 0.405909
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610182]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.483952]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.6117553710938, (249.67645, 0.2238557, 355.71143, 0.39651403)
   validation loss 389.91748046875, (204.22942, 0.041687407, 185.64636, 0.39651403)
decoder loss ratio: 7912.202130, decoder SINDy loss  ratio: 0.400744
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102146]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.50212]
 [ -0.     ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 573.0508422851562, (218.07066, 0.23073234, 354.74945, 0.39661315)
   validation loss 361.200439453125, (172.6022, 0.041893296, 188.55634, 0.39661315)
decoder loss ratio: 6686.909009, decoder SINDy loss  ratio: 0.407025
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102146]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.517302]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 585.6572265625, (230.25009, 0.22248921, 355.18463, 0.39662296)
   validation loss 359.44921875, (173.64717, 0.04238045, 185.75967, 0.39662296)
decoder loss ratio: 6727.392870, decoder SINDy loss  ratio: 0.400988
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102635]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.505169]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.671875, (363.2782, 0.20551991, 346.18814, 0.3967699)
   validation loss 489.3341064453125, (288.43127, 0.042128086, 200.8607, 0.3967699)
decoder loss ratio: 11174.328310, decoder SINDy loss  ratio: 0.433586
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610311]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.639473]
 [  0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 580.81689453125, (234.03728, 0.20704892, 346.5726, 0.39692092)
   validation loss 367.01397705078125, (175.99825, 0.041774128, 190.97395, 0.39692092)
decoder loss ratio: 6818.477567, decoder SINDy loss  ratio: 0.412244
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86103827]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.556555]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 580.656005859375, (225.94556, 0.21780139, 354.49268, 0.39712426)
   validation loss 364.9022521972656, (175.62555, 0.04064041, 189.23607, 0.39712426)
decoder loss ratio: 6804.038680, decoder SINDy loss  ratio: 0.408493
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610399]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.541447]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.7731323242188, (387.90244, 0.20432235, 367.66638, 0.39724407)
   validation loss 543.5130615234375, (356.77835, 0.03849933, 186.69617, 0.39724407)
decoder loss ratio: 13822.212706, decoder SINDy loss  ratio: 0.403010
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610447]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.538366]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.8718872070312, (279.07144, 0.20218737, 345.59827, 0.39743534)
   validation loss 407.46661376953125, (213.06764, 0.041731186, 194.35725, 0.39743534)
decoder loss ratio: 8254.610361, decoder SINDy loss  ratio: 0.419547
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.861049]
 [0.      ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.57788]
 [  0.     ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 565.311767578125, (215.67645, 0.21028969, 349.425, 0.39759886)
   validation loss 350.06402587890625, (162.53972, 0.041833673, 187.48245, 0.39759886)
decoder loss ratio: 6297.070881, decoder SINDy loss  ratio: 0.404707
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610567]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.548992]
 [  0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 597.4248657226562, (240.0961, 0.21055034, 357.11823, 0.39785716)
   validation loss 366.9581298828125, (182.5311, 0.042783678, 184.38423, 0.39785716)
decoder loss ratio: 7071.571602, decoder SINDy loss  ratio: 0.398019
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610604]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.65222]
 [ -0.     ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.1337890625, (243.12076, 0.22028962, 361.79272, 0.39810243)
   validation loss 392.588134765625, (207.39748, 0.041140176, 185.14952, 0.39810243)
decoder loss ratio: 8034.938286, decoder SINDy loss  ratio: 0.399671
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86106557]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.703787]
 [ -0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1072.55419921875, (716.7763, 0.19547161, 355.5824, 0.39831468)
   validation loss 818.717529296875, (600.3007, 0.043535125, 218.37332, 0.39831468)
decoder loss ratio: 23256.692069, decoder SINDy loss  ratio: 0.471390
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610712]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.628273]
 [  0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 565.4818115234375, (212.08551, 0.20502445, 353.1913, 0.39864397)
   validation loss 353.59246826171875, (166.73996, 0.04089751, 186.8116, 0.39864397)
decoder loss ratio: 6459.795513, decoder SINDy loss  ratio: 0.403259
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610741]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.604925]
 [ -0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1270.1300048828125, (887.082, 0.18150596, 382.86655, 0.3989049)
   validation loss 932.8245849609375, (695.52075, 0.04187511, 237.26195, 0.3989049)
decoder loss ratio: 26945.681408, decoder SINDy loss  ratio: 0.512163
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610779]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.640392]
 [  0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 593.0997924804688, (232.83961, 0.19903576, 360.06116, 0.3992798)
   validation loss 367.4035949707031, (179.58812, 0.039792143, 187.77568, 0.3992798)
decoder loss ratio: 6957.555528, decoder SINDy loss  ratio: 0.405340
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610792]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.607159]
 [  0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.2349243164062, (343.42642, 0.19834115, 346.61017, 0.39948255)
   validation loss 465.62261962890625, (267.8473, 0.042759094, 197.73257, 0.39948255)
decoder loss ratio: 10376.869019, decoder SINDy loss  ratio: 0.426834
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610802]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.637335]
 [  0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 572.76123046875, (218.22998, 0.19911888, 354.33215, 0.39977056)
   validation loss 353.4619140625, (168.32628, 0.0403373, 185.09529, 0.39977056)
decoder loss ratio: 6521.252264, decoder SINDy loss  ratio: 0.399554
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86108094]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.634811]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.8056030273438, (357.78827, 0.19088581, 345.82645, 0.4000702)
   validation loss 478.8125, (279.41092, 0.04161898, 199.35997, 0.4000702)
decoder loss ratio: 10824.864088, decoder SINDy loss  ratio: 0.430347
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86108094]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.675285]
 [ -0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.687255859375, (274.55865, 0.19601576, 368.93256, 0.40033817)
   validation loss 421.723388671875, (235.49533, 0.038542617, 186.1895, 0.40033817)
decoder loss ratio: 9123.497953, decoder SINDy loss  ratio: 0.401916
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610805]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.659409]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 884.109130859375, (483.52005, 0.20835373, 400.38074, 0.40061092)
   validation loss 630.7803344726562, (439.8316, 0.036778286, 190.91197, 0.40061092)
decoder loss ratio: 17039.839920, decoder SINDy loss  ratio: 0.412110
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86107963]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.690712]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 602.7693481445312, (256.8791, 0.19816394, 345.6921, 0.40081406)
   validation loss 382.445068359375, (193.02902, 0.040361274, 189.37569, 0.40081406)
decoder loss ratio: 7478.279434, decoder SINDy loss  ratio: 0.408794
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86107856]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.750343]
 [  0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 862.9684448242188, (510.0434, 0.18797141, 352.7371, 0.40106526)
   validation loss 611.8853759765625, (402.16013, 0.041325066, 209.68393, 0.40106526)
decoder loss ratio: 15580.381452, decoder SINDy loss  ratio: 0.452632
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86107683]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.77713]
 [ -0.     ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.9601440429688, (250.08524, 0.19856167, 360.67633, 0.40131268)
   validation loss 389.1561279296875, (205.76309, 0.03812282, 183.3549, 0.40131268)
decoder loss ratio: 7971.619406, decoder SINDy loss  ratio: 0.395797
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86107385]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.695807]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 601.5484008789062, (252.93372, 0.19712313, 348.41754, 0.40160185)
   validation loss 379.62554931640625, (189.10977, 0.040104467, 190.47568, 0.40160185)
decoder loss ratio: 7326.440866, decoder SINDy loss  ratio: 0.411169
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610698]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.74553]
 [ -0.     ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.3731689453125, (433.50812, 0.21463488, 387.65042, 0.40180883)
   validation loss 591.86669921875, (404.94757, 0.038164884, 186.88094, 0.40180883)
decoder loss ratio: 15688.371913, decoder SINDy loss  ratio: 0.403409
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610663]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.805809]
 [  0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 575.6641845703125, (222.75581, 0.21271567, 352.69562, 0.40206066)
   validation loss 352.8056640625, (167.78731, 0.040237512, 184.97813, 0.40206066)
decoder loss ratio: 6500.371593, decoder SINDy loss  ratio: 0.399301
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610596]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.827177]
 [ -0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.6395263671875, (377.89703, 0.20496768, 377.5375, 0.40233073)
   validation loss 536.2852783203125, (351.9049, 0.03586806, 184.34454, 0.40233073)
decoder loss ratio: 13633.407040, decoder SINDy loss  ratio: 0.397934
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.861057]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.732777]
 [ -0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 589.39306640625, (228.63544, 0.20795085, 360.5497, 0.4025198)
   validation loss 372.28594970703125, (189.31392, 0.03800764, 182.93404, 0.4025198)
decoder loss ratio: 7334.349888, decoder SINDy loss  ratio: 0.394889
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610506]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.73419]
 [ -0.     ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.4905395507812, (399.16388, 0.21122085, 383.11545, 0.4027834)
   validation loss 562.4127197265625, (376.12415, 0.036319498, 186.25223, 0.4027834)
decoder loss ratio: 14571.702377, decoder SINDy loss  ratio: 0.402052
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.861045]
 [0.      ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.86558]
 [ -0.     ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.138427734375, (250.69878, 0.2193957, 367.22028, 0.4029821)
   validation loss 395.8956604003906, (213.45956, 0.0390384, 182.39706, 0.4029821)
decoder loss ratio: 8269.794100, decoder SINDy loss  ratio: 0.393730
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610413]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.792986]
 [ -0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.6817626953125, (293.1915, 0.21609578, 369.2742, 0.403117)
   validation loss 451.8725280761719, (269.94135, 0.036995, 181.8942, 0.403117)
decoder loss ratio: 10457.996352, decoder SINDy loss  ratio: 0.392644
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86103857]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.80955]
 [ -0.     ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 570.6677856445312, (218.25737, 0.20690559, 352.2035, 0.403261)
   validation loss 347.51739501953125, (163.58505, 0.03767527, 183.89465, 0.403261)
decoder loss ratio: 6337.568930, decoder SINDy loss  ratio: 0.396962
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610337]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.836025]
 [ -0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 569.7296142578125, (214.40396, 0.20891823, 355.11676, 0.40338698)
   validation loss 357.41943359375, (175.64568, 0.03717008, 181.73657, 0.40338698)
decoder loss ratio: 6804.818409, decoder SINDy loss  ratio: 0.392304
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.861031]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.846209]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1431.61474609375, (1066.8279, 0.1916713, 364.5952, 0.403496)
   validation loss 1141.6439208984375, (913.463, 0.04239906, 228.13844, 0.403496)
decoder loss ratio: 35389.142953, decoder SINDy loss  ratio: 0.492469
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86102545]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.810896]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 567.06396484375, (215.5234, 0.19486955, 351.34567, 0.403646)
   validation loss 346.9515380859375, (165.23636, 0.0362626, 181.6789, 0.403646)
decoder loss ratio: 6401.543397, decoder SINDy loss  ratio: 0.392179
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86101854]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.77609]
 [  0.     ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.7303466796875, (402.55106, 0.21066488, 391.96866, 0.40387127)
   validation loss 550.4227294921875, (364.1192, 0.034505256, 186.26901, 0.40387127)
decoder loss ratio: 14106.610011, decoder SINDy loss  ratio: 0.402088
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610164]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.870129]
 [  0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 592.593994140625, (234.9126, 0.20305263, 357.47833, 0.40392074)
   validation loss 366.78057861328125, (185.82079, 0.036031917, 180.92375, 0.40392074)
decoder loss ratio: 7199.019830, decoder SINDy loss  ratio: 0.390549
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610109]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.847696]
 [ -0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.184814453125, (462.21353, 0.19058968, 346.78067, 0.40409026)
   validation loss 563.8140869140625, (363.7932, 0.039047547, 199.98178, 0.40409026)
decoder loss ratio: 14093.980640, decoder SINDy loss  ratio: 0.431689
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8610054]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.875072]
 [  0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 560.0924072265625, (211.83691, 0.19017462, 348.0653, 0.40422007)
   validation loss 344.3158264160156, (159.78273, 0.036625836, 184.49648, 0.40422007)
decoder loss ratio: 6190.260359, decoder SINDy loss  ratio: 0.398262
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86099946]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.85451]
 [ -0.     ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1286.3875732421875, (922.79047, 0.17528073, 363.42184, 0.40442774)
   validation loss 991.5448608398438, (766.33997, 0.03997521, 225.16492, 0.40442774)
decoder loss ratio: 29689.340701, decoder SINDy loss  ratio: 0.486050
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609942]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.808409]
 [  0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 609.083251953125, (265.18637, 0.18546511, 343.71146, 0.40456247)
   validation loss 382.79046630859375, (194.1005, 0.036426343, 188.65356, 0.40456247)
decoder loss ratio: 7519.790126, decoder SINDy loss  ratio: 0.407235
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609841]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.864067]
 [ -0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 594.1983642578125, (245.83241, 0.18788126, 348.17807, 0.40475512)
   validation loss 368.3020935058594, (177.86203, 0.038823865, 190.40125, 0.40475512)
decoder loss ratio: 6890.683825, decoder SINDy loss  ratio: 0.411008
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86097634]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.814724]
 [ -0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 561.6396484375, (212.35228, 0.192837, 349.0945, 0.40493318)
   validation loss 342.4146728515625, (158.62088, 0.037612695, 183.75618, 0.40493318)
decoder loss ratio: 6145.248274, decoder SINDy loss  ratio: 0.396664
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609693]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.874977]
 [  0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.46875, (280.09277, 0.20130827, 366.17465, 0.4050601)
   validation loss 409.8365478515625, (228.91438, 0.037296057, 180.88487, 0.4050601)
decoder loss ratio: 8868.540608, decoder SINDy loss  ratio: 0.390465
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609607]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.844534]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 579.5506591796875, (232.79442, 0.19120708, 346.565, 0.40527478)
   validation loss 355.57537841796875, (170.20732, 0.037423257, 185.33063, 0.40527478)
decoder loss ratio: 6594.127115, decoder SINDy loss  ratio: 0.400062
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.860954]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.842762]
 [  0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 599.166015625, (253.27164, 0.19031751, 345.70407, 0.40541482)
   validation loss 373.91015625, (185.18034, 0.038497955, 188.6913, 0.40541482)
decoder loss ratio: 7174.207999, decoder SINDy loss  ratio: 0.407317
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86094546]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.869917]
 [  0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1222.274169921875, (797.81506, 0.20824507, 424.25082, 0.40550166)
   validation loss 940.147216796875, (744.47546, 0.034017656, 195.63776, 0.40550166)
decoder loss ratio: 28842.271936, decoder SINDy loss  ratio: 0.422312
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609404]
 [0.       ]]
[[  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.8329]
 [  0.    ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.6729736328125, (411.34326, 0.18772675, 352.14203, 0.40568596)
   validation loss 509.33245849609375, (306.75296, 0.040397845, 202.53911, 0.40568596)
decoder loss ratio: 11884.142225, decoder SINDy loss  ratio: 0.437209
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86092746]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.00845]
 [ -0.     ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 590.159423828125, (244.35066, 0.18596677, 345.62277, 0.40592813)
   validation loss 366.271240234375, (177.78223, 0.038079724, 188.45093, 0.40592813)
decoder loss ratio: 6887.592101, decoder SINDy loss  ratio: 0.406798
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609159]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.983929]
 [  0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 580.0560913085938, (224.48119, 0.19531931, 355.37958, 0.40614277)
   validation loss 357.32415771484375, (172.69437, 0.036791027, 184.59302, 0.40614277)
decoder loss ratio: 6690.479567, decoder SINDy loss  ratio: 0.398470
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8609117]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.937233]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1065.778076171875, (715.7228, 0.18474069, 349.8705, 0.40627098)
   validation loss 807.6668701171875, (596.4119, 0.04016674, 211.21477, 0.40627098)
decoder loss ratio: 23106.033440, decoder SINDy loss  ratio: 0.455937
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86090446]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.926006]
 [ -0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1121.627197265625, (761.43097, 0.18044816, 360.01587, 0.4063371)
   validation loss 838.6729125976562, (617.01904, 0.040235404, 221.61365, 0.4063371)
decoder loss ratio: 23904.388917, decoder SINDy loss  ratio: 0.478384
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608911]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.941652]
 [  0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.074462890625, (302.63144, 0.17746958, 342.26553, 0.40657645)
   validation loss 415.2266845703125, (222.70242, 0.037590183, 192.48668, 0.40657645)
decoder loss ratio: 8627.878499, decoder SINDy loss  ratio: 0.415510
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608867]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.998756]
 [ -0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 959.3568725585938, (619.429, 0.19119129, 339.7367, 0.40672112)
   validation loss 720.436767578125, (520.9597, 0.042004596, 199.43507, 0.40672112)
decoder loss ratio: 20182.883855, decoder SINDy loss  ratio: 0.430509
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608786]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.965548]
 [  0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 606.0033569335938, (245.15947, 0.20113239, 360.64276, 0.4067598)
   validation loss 372.42181396484375, (191.48506, 0.036791213, 180.89996, 0.4067598)
decoder loss ratio: 7418.463721, decoder SINDy loss  ratio: 0.390498
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608719]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.974388]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.91845703125, (412.2993, 0.18508294, 345.43408, 0.40688944)
   validation loss 517.4451904296875, (318.0171, 0.039210502, 199.38885, 0.40688944)
decoder loss ratio: 12320.534162, decoder SINDy loss  ratio: 0.430409
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86086047]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.002087]
 [ -0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 996.6815185546875, (597.8445, 0.19716181, 398.6399, 0.40701756)
   validation loss 739.2105712890625, (551.3197, 0.033993144, 187.85689, 0.40701756)
decoder loss ratio: 21359.082394, decoder SINDy loss  ratio: 0.405516
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608572]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.985785]
 [ -0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 594.2727661132812, (233.45638, 0.20101644, 360.61536, 0.4070959)
   validation loss 357.514892578125, (175.15463, 0.037908807, 182.32236, 0.4070959)
decoder loss ratio: 6785.794548, decoder SINDy loss  ratio: 0.393568
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86084867]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.008469]
 [ -0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 598.3463745117188, (240.49933, 0.198217, 357.64883, 0.40723768)
   validation loss 373.67034912109375, (193.13792, 0.0356165, 180.4968, 0.40723768)
decoder loss ratio: 7482.498485, decoder SINDy loss  ratio: 0.389628
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608333]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.015978]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.0687866210938, (338.5045, 0.18634263, 347.37796, 0.40748292)
   validation loss 451.0040588378906, (255.06958, 0.037916917, 195.89656, 0.40748292)
decoder loss ratio: 9881.838352, decoder SINDy loss  ratio: 0.422870
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608263]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.023457]
 [  0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.743408203125, (293.3417, 0.20215108, 369.19952, 0.40755406)
   validation loss 440.41973876953125, (259.07178, 0.035222128, 181.31276, 0.40755406)
decoder loss ratio: 10036.890423, decoder SINDy loss  ratio: 0.391389
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608209]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.967201]
 [ -0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 913.01171875, (560.9213, 0.20040455, 351.89005, 0.40767175)
   validation loss 644.8737182617188, (440.77295, 0.039432324, 204.06133, 0.40767175)
decoder loss ratio: 17076.309268, decoder SINDy loss  ratio: 0.440495
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86081344]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.986969]
 [  0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 569.0988159179688, (217.41121, 0.19921887, 351.4884, 0.40773508)
   validation loss 346.28424072265625, (166.11661, 0.0352362, 180.13242, 0.40773508)
decoder loss ratio: 6435.645772, decoder SINDy loss  ratio: 0.388841
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608085]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.970432]
 [  0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 598.0745239257812, (233.96843, 0.2047435, 363.90137, 0.40785757)
   validation loss 384.1854553222656, (201.25739, 0.035080228, 182.89299, 0.40785757)
decoder loss ratio: 7797.060503, decoder SINDy loss  ratio: 0.394800
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86080337]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.060215]
 [  0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 602.404296875, (245.79099, 0.20411684, 356.4092, 0.4078754)
   validation loss 380.82635498046875, (201.70763, 0.03428885, 179.08443, 0.4078754)
decoder loss ratio: 7814.503624, decoder SINDy loss  ratio: 0.386579
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608006]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.006138]
 [  0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 938.1417846679688, (586.94916, 0.19725993, 350.99536, 0.40794393)
   validation loss 670.6309204101562, (465.9566, 0.038388163, 204.63594, 0.40794393)
decoder loss ratio: 18051.967775, decoder SINDy loss  ratio: 0.441735
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86079687]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.979347]
 [  0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 589.234619140625, (228.60577, 0.21267441, 360.4162, 0.40797076)
   validation loss 376.447509765625, (196.47571, 0.035409745, 179.93639, 0.40797076)
decoder loss ratio: 7611.810025, decoder SINDy loss  ratio: 0.388418
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607987]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.972742]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1583.4693603515625, (1193.7542, 0.18326207, 389.53195, 0.40796348)
   validation loss 1206.757568359375, (962.0444, 0.03807045, 244.67513, 0.40796348)
decoder loss ratio: 37271.269175, decoder SINDy loss  ratio: 0.528166
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86079687]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.969362]
 [  0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 565.2833862304688, (216.81996, 0.19835779, 348.26508, 0.4079662)
   validation loss 341.2268981933594, (158.78351, 0.0354696, 182.40791, 0.4079662)
decoder loss ratio: 6151.548772, decoder SINDy loss  ratio: 0.393753
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86079305]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.000874]
 [  0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.9981689453125, (276.57428, 0.18787602, 345.236, 0.40802965)
   validation loss 389.41033935546875, (199.92876, 0.036160994, 189.44542, 0.40802965)
decoder loss ratio: 7745.587127, decoder SINDy loss  ratio: 0.408945
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607917]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.005215]
 [ -0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 573.3668823242188, (216.5997, 0.2091187, 356.55804, 0.40804204)
   validation loss 354.8233642578125, (175.00377, 0.035583194, 179.78401, 0.40804204)
decoder loss ratio: 6779.949828, decoder SINDy loss  ratio: 0.388089
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607944]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.968842]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 934.6084594726562, (530.1136, 0.21500438, 404.27985, 0.4079654)
   validation loss 676.144775390625, (488.03394, 0.033963606, 188.07684, 0.4079654)
decoder loss ratio: 18907.281927, decoder SINDy loss  ratio: 0.405990
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.86079]
 [0.     ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.000542]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.645263671875, (293.12045, 0.20242082, 365.32236, 0.4080421)
   validation loss 434.6954650878906, (255.15431, 0.03335552, 179.5078, 0.4080421)
decoder loss ratio: 9885.121019, decoder SINDy loss  ratio: 0.387493
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078584]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.012833]
 [ -0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 561.1404418945312, (206.76347, 0.20908687, 354.16788, 0.40812048)
   validation loss 350.611083984375, (169.95314, 0.035009686, 180.62294, 0.40812048)
decoder loss ratio: 6584.279705, decoder SINDy loss  ratio: 0.389900
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078864]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.063086]
 [ -0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 589.3382568359375, (246.5671, 0.19759518, 342.57358, 0.40809733)
   validation loss 358.58197021484375, (175.59161, 0.03647951, 182.95386, 0.40809733)
decoder loss ratio: 6802.723958, decoder SINDy loss  ratio: 0.394932
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078304]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.96792]
 [  0.     ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 612.873046875, (266.55115, 0.18937376, 346.1325, 0.40817505)
   validation loss 383.3968505859375, (193.86682, 0.035821196, 189.49419, 0.40817505)
decoder loss ratio: 7510.737224, decoder SINDy loss  ratio: 0.409050
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86077905]
 [0.        ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-17.0582]
 [  0.    ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.88916015625, (365.48483, 0.19833696, 377.20602, 0.40818056)
   validation loss 513.21533203125, (331.28442, 0.033443578, 181.89746, 0.40818056)
decoder loss ratio: 12834.533714, decoder SINDy loss  ratio: 0.392651
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86077535]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.046577]
 [  0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.7330932617188, (336.13504, 0.18585832, 346.4122, 0.40829572)
   validation loss 443.00177001953125, (247.42294, 0.03524484, 195.54358, 0.40829572)
decoder loss ratio: 9585.594361, decoder SINDy loss  ratio: 0.422108
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.860767]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.047754]
 [ -0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 607.9269409179688, (247.62616, 0.19410123, 360.1067, 0.4083531)
   validation loss 383.29986572265625, (202.55376, 0.034031764, 180.71208, 0.4083531)
decoder loss ratio: 7847.284184, decoder SINDy loss  ratio: 0.390092
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86076635]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.060553]
 [ -0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.756103515625, (273.76, 0.19303107, 345.80307, 0.4083913)
   validation loss 389.87786865234375, (199.9517, 0.036185227, 189.89, 0.4083913)
decoder loss ratio: 7746.476219, decoder SINDy loss  ratio: 0.409904
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607652]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.989807]
 [  0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 563.4047241210938, (216.36833, 0.1910156, 346.84537, 0.4084172)
   validation loss 341.1639099121094, (158.55928, 0.03578686, 182.56885, 0.4084172)
decoder loss ratio: 6142.861794, decoder SINDy loss  ratio: 0.394101
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607614]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.101597]
 [  0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.887939453125, (440.16003, 0.1930502, 347.53488, 0.40847737)
   validation loss 539.2735595703125, (339.53412, 0.037182994, 199.7023, 0.40847737)
decoder loss ratio: 13154.141214, decoder SINDy loss  ratio: 0.431086
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607534]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.041803]
 [ -0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.533203125, (330.776, 0.18382561, 344.57336, 0.40856528)
   validation loss 438.58111572265625, (242.96765, 0.03587202, 195.57759, 0.40856528)
decoder loss ratio: 9412.988624, decoder SINDy loss  ratio: 0.422182
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86075014]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.065783]
 [ -0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 563.590576171875, (214.38516, 0.19577411, 349.00967, 0.40859085)
   validation loss 342.5928039550781, (157.54271, 0.035599057, 185.0145, 0.40859085)
decoder loss ratio: 6103.478066, decoder SINDy loss  ratio: 0.399380
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607534]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.985182]
 [  0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 597.3709716796875, (254.43571, 0.19315225, 342.7421, 0.40856907)
   validation loss 370.167236328125, (185.25891, 0.03702718, 184.8713, 0.40856907)
decoder loss ratio: 7177.251841, decoder SINDy loss  ratio: 0.399071
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607507]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.111986]
 [ -0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.9365844726562, (262.72815, 0.19688469, 348.01154, 0.40860358)
   validation loss 383.0505065917969, (193.96431, 0.036081016, 189.05011, 0.40860358)
decoder loss ratio: 7514.514094, decoder SINDy loss  ratio: 0.408091
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86075085]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.989157]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.14306640625, (341.8448, 0.19127125, 343.10696, 0.4085915)
   validation loss 450.97222900390625, (258.3649, 0.036602855, 192.57072, 0.4085915)
decoder loss ratio: 10009.504716, decoder SINDy loss  ratio: 0.415691
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86074996]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.03476]
 [  0.     ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.1471557617188, (334.34613, 0.20392829, 347.5971, 0.40861183)
   validation loss 441.0980224609375, (249.28978, 0.03507729, 191.77316, 0.40861183)
decoder loss ratio: 9657.918850, decoder SINDy loss  ratio: 0.413969
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607419]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.07882]
 [ -0.     ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 561.576171875, (213.9636, 0.19114701, 347.42142, 0.40868112)
   validation loss 338.839111328125, (156.1914, 0.034240935, 182.61345, 0.40868112)
decoder loss ratio: 6051.126238, decoder SINDy loss  ratio: 0.394197
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86073625]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.988085]
 [  0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.30908203125, (377.24643, 0.1923523, 347.87027, 0.4087777)
   validation loss 480.0270080566406, (283.90656, 0.03599495, 196.08447, 0.4087777)
decoder loss ratio: 10999.032831, decoder SINDy loss  ratio: 0.423276
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86073923]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.065153]
 [ -0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 585.2166137695312, (225.94911, 0.21717261, 359.05032, 0.40870625)
   validation loss 377.4559326171875, (198.74521, 0.033278976, 178.67744, 0.40870625)
decoder loss ratio: 7699.734423, decoder SINDy loss  ratio: 0.385700
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.860747]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.057978]
 [  0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1091.099853515625, (734.6188, 0.19379762, 356.28735, 0.40863204)
   validation loss 797.9532470703125, (583.9256, 0.036568284, 213.9911, 0.40863204)
decoder loss ratio: 22622.291412, decoder SINDy loss  ratio: 0.461930
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86074716]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.026232]
 [  0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.060546875, (310.9973, 0.20874181, 368.85452, 0.40860325)
   validation loss 458.642578125, (279.46133, 0.031833027, 179.14943, 0.40860325)
decoder loss ratio: 10826.817254, decoder SINDy loss  ratio: 0.386719
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607441]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.126238]
 [  0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 881.341552734375, (536.4087, 0.18565518, 344.74722, 0.4086795)
   validation loss 620.1925048828125, (419.3299, 0.037294272, 200.82529, 0.4086795)
decoder loss ratio: 16245.568122, decoder SINDy loss  ratio: 0.433510
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86075085]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.00144]
 [  0.     ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 572.000732421875, (221.7116, 0.19852959, 350.09064, 0.4085648)
   validation loss 345.1291809082031, (166.1493, 0.03333955, 178.94653, 0.4085648)
decoder loss ratio: 6436.912611, decoder SINDy loss  ratio: 0.386281
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86075366]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.027159]
 [  0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 599.650634765625, (237.84882, 0.21927473, 361.58252, 0.40854755)
   validation loss 377.96533203125, (198.24463, 0.031471808, 179.68924, 0.40854755)
decoder loss ratio: 7680.341092, decoder SINDy loss  ratio: 0.387884
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607652]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.022375]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 578.4668579101562, (229.35507, 0.201283, 348.91052, 0.40842763)
   validation loss 346.7024841308594, (163.18192, 0.032239445, 183.48833, 0.40842763)
decoder loss ratio: 6321.950694, decoder SINDy loss  ratio: 0.396085
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86076796]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.087517]
 [  0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 558.2540283203125, (207.23587, 0.20164964, 350.81653, 0.4083664)
   validation loss 340.9256591796875, (159.04102, 0.032862626, 181.85179, 0.4083664)
decoder loss ratio: 6161.525053, decoder SINDy loss  ratio: 0.392553
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86077416]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.109303]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.234375, (341.46606, 0.2102652, 374.55807, 0.40827796)
   validation loss 474.4344482421875, (294.69675, 0.03369171, 179.70401, 0.40827796)
decoder loss ratio: 11417.063588, decoder SINDy loss  ratio: 0.387916
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86077464]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.99189]
 [ -0.     ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 600.033203125, (251.96999, 0.19558838, 347.86765, 0.40828642)
   validation loss 367.159912109375, (180.52954, 0.03396507, 186.59639, 0.40828642)
decoder loss ratio: 6994.027832, decoder SINDy loss  ratio: 0.402795
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607744]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.07385]
 [ -0.     ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 565.4319458007812, (212.02629, 0.19844858, 353.2072, 0.40827808)
   validation loss 342.64923095703125, (162.63147, 0.03303036, 179.98473, 0.40827808)
decoder loss ratio: 6300.625478, decoder SINDy loss  ratio: 0.388522
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607784]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.076025]
 [  0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 600.2650146484375, (235.99127, 0.20413569, 364.0696, 0.40824133)
   validation loss 386.51812744140625, (205.24802, 0.030664947, 181.23943, 0.40824133)
decoder loss ratio: 7951.664480, decoder SINDy loss  ratio: 0.391231
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86077976]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.97242]
 [  0.     ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.5316162109375, (267.2015, 0.20358832, 363.12653, 0.40827227)
   validation loss 409.5733642578125, (230.05215, 0.03000576, 179.4912, 0.40827227)
decoder loss ratio: 8912.619855, decoder SINDy loss  ratio: 0.387457
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078346]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.11939]
 [  0.     ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.3883056640625, (251.04826, 0.20280057, 359.13727, 0.40817818)
   validation loss 385.1332702636719, (199.05247, 0.03091687, 186.04988, 0.40817818)
decoder loss ratio: 7711.638451, decoder SINDy loss  ratio: 0.401615
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607788]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.020529]
 [  0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 580.00732421875, (223.48213, 0.1991738, 356.32605, 0.40820137)
   validation loss 355.07513427734375, (175.33784, 0.032198224, 179.70508, 0.40820137)
decoder loss ratio: 6792.892509, decoder SINDy loss  ratio: 0.387919
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078304]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.985092]
 [ -0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 578.3626098632812, (228.9525, 0.20841286, 349.2017, 0.40817147)
   validation loss 351.15625, (168.40106, 0.03318976, 182.72202, 0.40817147)
decoder loss ratio: 6524.149499, decoder SINDy loss  ratio: 0.394431
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078954]
 [0.        ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [-16.9732]
 [ -0.    ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 596.208984375, (248.3849, 0.19398013, 347.63013, 0.40810347)
   validation loss 358.3947448730469, (171.31332, 0.032730963, 187.04869, 0.40810347)
decoder loss ratio: 6636.975584, decoder SINDy loss  ratio: 0.403771
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078525]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.026388]
 [ -0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 980.4700927734375, (632.0778, 0.18171477, 348.2106, 0.4081479)
   validation loss 710.4692993164062, (502.77078, 0.037003282, 207.66151, 0.4081479)
decoder loss ratio: 19478.212961, decoder SINDy loss  ratio: 0.448267
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078614]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.014647]
 [ -0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.346923828125, (369.17728, 0.20278305, 379.96683, 0.40810212)
   validation loss 513.9376831054688, (332.18774, 0.031092873, 181.71886, 0.40810212)
decoder loss ratio: 12869.529911, decoder SINDy loss  ratio: 0.392266
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078614]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.025696]
 [  0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.864501953125, (304.90448, 0.19021837, 346.76978, 0.40813994)
   validation loss 414.40380859375, (221.9156, 0.033082545, 192.45514, 0.40813994)
decoder loss ratio: 8597.395747, decoder SINDy loss  ratio: 0.415441
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86078525]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.06116]
 [ -0.     ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.6063232421875, (276.70657, 0.18731341, 345.7124, 0.4081451)
   validation loss 390.47943115234375, (199.61859, 0.03281933, 190.828, 0.4081451)
decoder loss ratio: 7733.570780, decoder SINDy loss  ratio: 0.411929
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607928]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.009735]
 [  0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 926.6522216796875, (563.67664, 0.18684337, 362.7888, 0.40805793)
   validation loss 635.98193359375, (420.06592, 0.031670135, 215.88431, 0.40805793)
decoder loss ratio: 16274.082929, decoder SINDy loss  ratio: 0.466017
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607944]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.980743]
 [ -0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 567.691650390625, (216.73506, 0.19731458, 350.75928, 0.40799323)
   validation loss 343.2626953125, (163.44292, 0.032877397, 179.7869, 0.40799323)
decoder loss ratio: 6332.062349, decoder SINDy loss  ratio: 0.388095
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607973]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.01272]
 [  0.     ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.7559814453125, (291.63, 0.19533168, 347.9306, 0.40798578)
   validation loss 403.3204650878906, (212.08113, 0.03250252, 191.20683, 0.40798578)
decoder loss ratio: 8216.391203, decoder SINDy loss  ratio: 0.412747
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8607962]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.94488]
 [ -0.     ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.18310546875, (383.8539, 0.19935603, 376.12988, 0.407932)
   validation loss 529.339111328125, (348.47827, 0.030829987, 180.83, 0.407932)
decoder loss ratio: 13500.653222, decoder SINDy loss  ratio: 0.390347
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608048]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.991825]
 [  0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 854.513427734375, (496.27246, 0.18978086, 358.05118, 0.407893)
   validation loss 572.052001953125, (363.05777, 0.030685661, 208.96352, 0.407893)
decoder loss ratio: 14065.488297, decoder SINDy loss  ratio: 0.451077
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608099]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.978748]
 [ -0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 614.6068115234375, (251.85612, 0.2075766, 362.54312, 0.4078071)
   validation loss 393.211181640625, (214.01767, 0.030603271, 179.16292, 0.4078071)
decoder loss ratio: 8291.416074, decoder SINDy loss  ratio: 0.386748
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86081374]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.06703]
 [  0.     ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 872.7430419921875, (524.27563, 0.19364987, 348.2737, 0.4077618)
   validation loss 608.073486328125, (406.18976, 0.03412141, 201.84958, 0.4077618)
decoder loss ratio: 15736.496413, decoder SINDy loss  ratio: 0.435721
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608181]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.998863]
 [  0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 602.886962890625, (239.93333, 0.21115844, 362.7425, 0.40766793)
   validation loss 386.467529296875, (207.09471, 0.030299617, 179.34253, 0.40766793)
decoder loss ratio: 8023.208648, decoder SINDy loss  ratio: 0.387136
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86082757]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.045149]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 928.9390258789062, (579.8705, 0.19446321, 348.87408, 0.40754437)
   validation loss 663.2776489257812, (458.54193, 0.033873033, 204.70184, 0.40754437)
decoder loss ratio: 17764.710477, decoder SINDy loss  ratio: 0.441878
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86083126]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.021505]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 617.33837890625, (256.6045, 0.2027669, 360.53116, 0.40746447)
   validation loss 396.8832092285156, (218.88313, 0.030893553, 177.96918, 0.40746447)
decoder loss ratio: 8479.912568, decoder SINDy loss  ratio: 0.384172
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86083114]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.012686]
 [ -0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 571.597412109375, (217.42845, 0.20644829, 353.96252, 0.40749112)
   validation loss 347.15838623046875, (165.76122, 0.030268516, 181.3669, 0.40749112)
decoder loss ratio: 6421.877251, decoder SINDy loss  ratio: 0.391506
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.86084]
 [0.     ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.000923]
 [ -0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.694580078125, (353.75272, 0.20862311, 378.73328, 0.40733033)
   validation loss 501.6107177734375, (320.74542, 0.02932918, 180.83595, 0.40733033)
decoder loss ratio: 12426.234501, decoder SINDy loss  ratio: 0.390360
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608459]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.969053]
 [  0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 579.8426513671875, (231.17358, 0.20571421, 348.46332, 0.4072871)
   validation loss 350.988037109375, (168.2002, 0.030624224, 182.75723, 0.4072871)
decoder loss ratio: 6516.367575, decoder SINDy loss  ratio: 0.394507
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608552]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.077919]
 [  0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 600.9878540039062, (240.06512, 0.20509492, 360.71762, 0.40714088)
   validation loss 371.0446472167969, (192.59807, 0.03044599, 178.41614, 0.40714088)
decoder loss ratio: 7461.583528, decoder SINDy loss  ratio: 0.385136
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86085665]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.997723]
 [ -0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.2003173828125, (272.5473, 0.19147366, 345.46158, 0.407123)
   validation loss 381.9024658203125, (194.18913, 0.030699857, 187.68263, 0.407123)
decoder loss ratio: 7523.224128, decoder SINDy loss  ratio: 0.405139
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608615]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.961916]
 [  0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 600.831787109375, (239.05092, 0.20078813, 361.58008, 0.40702516)
   validation loss 373.92108154296875, (194.5456, 0.029897362, 179.34558, 0.40702516)
decoder loss ratio: 7537.034029, decoder SINDy loss  ratio: 0.387143
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608663]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.892082]
 [ -0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 564.1171875, (215.19064, 0.19951192, 348.72702, 0.40695697)
   validation loss 337.730712890625, (155.89432, 0.030684667, 181.80573, 0.40695697)
decoder loss ratio: 6039.616509, decoder SINDy loss  ratio: 0.392453
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86087465]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.93449]
 [ -0.     ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 576.1063232421875, (218.13506, 0.20926079, 357.762, 0.406844)
   validation loss 360.83770751953125, (179.08005, 0.028205663, 181.72945, 0.406844)
decoder loss ratio: 6937.871941, decoder SINDy loss  ratio: 0.392289
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608744]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.979141]
 [ -0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1524.0693359375, (1156.4736, 0.17590365, 367.41977, 0.40686235)
   validation loss 1197.578125, (963.4348, 0.038723454, 234.1046, 0.40686235)
decoder loss ratio: 37325.137308, decoder SINDy loss  ratio: 0.505348
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608728]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.977245]
 [  0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 560.1934204101562, (210.21944, 0.19369707, 349.78027, 0.40686828)
   validation loss 334.68670654296875, (152.74031, 0.030855443, 181.91554, 0.40686828)
decoder loss ratio: 5917.424804, decoder SINDy loss  ratio: 0.392690
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8608731]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.003078]
 [ -0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 591.6121826171875, (243.4063, 0.19041583, 348.0155, 0.4068635)
   validation loss 362.0050964355469, (172.28242, 0.029256033, 189.69342, 0.4068635)
decoder loss ratio: 6674.520237, decoder SINDy loss  ratio: 0.409480
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86087036]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.895075]
 [ -0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 586.5135498046875, (226.53539, 0.20155326, 359.77658, 0.40690413)
   validation loss 367.34503173828125, (186.83734, 0.02946036, 180.47823, 0.40690413)
decoder loss ratio: 7238.402966, decoder SINDy loss  ratio: 0.389588
params['save_name']
pendulum_2023_10_25_16_37_40_004806
