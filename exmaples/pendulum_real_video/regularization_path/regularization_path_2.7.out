nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-26 04:58:26.073831: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-26 04:58:26.094570: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-26 04:58:26.097476: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556188c81d90 executing computations on platform Host. Devices:
2023-10-26 04:58:26.097535: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-26 04:58:26.102319: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-26 04:58:26.238451: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556188d92900 executing computations on platform CUDA. Devices:
2023-10-26 04:58:26.238519: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-26 04:58:26.239512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2023-10-26 04:58:26.240089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-26 04:58:26.243030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-26 04:58:26.244544: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-26 04:58:26.244832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-26 04:58:26.246532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-26 04:58:26.247406: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-26 04:58:26.250727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-26 04:58:26.251382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-26 04:58:26.251422: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-26 04:58:26.251771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-26 04:58:26.251780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-26 04:58:26.251786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-26 04:58:26.252361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2023-10-26 04:58:27.445153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 2.7, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.9285867214202881 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 108906.7421875, (98809.57, 0.006857246, 10078.669, 2.531781)
   validation loss 86631.4453125, (85412.19, 0.01074045, 1200.7548, 2.531781)
decoder loss ratio: 3309016.425828, decoder SINDy loss  ratio: 2.591998
--- 0.2812798023223877 seconds for one epoch ---
--- 0.31261110305786133 seconds for one epoch ---
--- 0.30890631675720215 seconds for one epoch ---
--- 0.33576536178588867 seconds for one epoch ---
--- 0.33445239067077637 seconds for one epoch ---
--- 0.323411226272583 seconds for one epoch ---
--- 0.32138919830322266 seconds for one epoch ---
--- 0.31796932220458984 seconds for one epoch ---
--- 0.33870577812194824 seconds for one epoch ---
--- 0.33132004737854004 seconds for one epoch ---
--- 0.3288872241973877 seconds for one epoch ---
--- 0.3257327079772949 seconds for one epoch ---
--- 0.3688664436340332 seconds for one epoch ---
--- 0.31142234802246094 seconds for one epoch ---
--- 0.3179206848144531 seconds for one epoch ---
--- 0.3267538547515869 seconds for one epoch ---
--- 0.3491816520690918 seconds for one epoch ---
--- 0.3150629997253418 seconds for one epoch ---
--- 0.35811877250671387 seconds for one epoch ---
--- 0.3182520866394043 seconds for one epoch ---
--- 0.3369159698486328 seconds for one epoch ---
--- 0.31152939796447754 seconds for one epoch ---
--- 0.3511943817138672 seconds for one epoch ---
--- 0.31804513931274414 seconds for one epoch ---
=========================
[[0.78202766]
 [0.78283256]
 [0.78285563]
 [0.7850037 ]
 [0.7810614 ]
 [0.78475064]
 [0.78358555]
 [0.7810417 ]
 [0.7807667 ]
 [0.788553  ]
 [0.7820878 ]]
[[ 0.37595603]
 [ 0.59170985]
 [-0.5977858 ]
 [-1.1332474 ]
 [-0.10333049]
 [-1.0727116 ]
 [ 0.7854412 ]
 [-0.09750316]
 [ 0.01671016]
 [-1.9298546 ]
 [ 0.3924083 ]]
--- 0.2672281265258789 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 74048.40625, (66934.39, 11.041997, 7063.3516, 2.5317676)
   validation loss 53431.08984375, (52142.17, 9.445392, 1239.8533, 2.5317676)
decoder loss ratio: 2020078.261229, decoder SINDy loss  ratio: 2.676398
--- 0.3027644157409668 seconds for one epoch ---
--- 0.34187746047973633 seconds for one epoch ---
--- 0.32971978187561035 seconds for one epoch ---
--- 0.3364710807800293 seconds for one epoch ---
--- 0.3013334274291992 seconds for one epoch ---
--- 0.32441043853759766 seconds for one epoch ---
--- 0.31621503829956055 seconds for one epoch ---
--- 0.33487486839294434 seconds for one epoch ---
--- 0.3196284770965576 seconds for one epoch ---
--- 0.35033249855041504 seconds for one epoch ---
--- 0.31349730491638184 seconds for one epoch ---
--- 0.35323500633239746 seconds for one epoch ---
--- 0.3257722854614258 seconds for one epoch ---
--- 0.3539998531341553 seconds for one epoch ---
--- 0.3223752975463867 seconds for one epoch ---
--- 0.3361489772796631 seconds for one epoch ---
--- 0.32468724250793457 seconds for one epoch ---
--- 0.35114574432373047 seconds for one epoch ---
--- 0.3287990093231201 seconds for one epoch ---
--- 0.3507423400878906 seconds for one epoch ---
--- 0.320293664932251 seconds for one epoch ---
--- 0.3631584644317627 seconds for one epoch ---
--- 0.3002598285675049 seconds for one epoch ---
--- 0.3569610118865967 seconds for one epoch ---
=========================
[[0.63157576]
 [0.6267319 ]
 [0.6267916 ]
 [0.632142  ]
 [0.6253261 ]
 [0.63396406]
 [0.6283001 ]
 [0.6256885 ]
 [0.62488014]
 [0.63076437]
 [0.6268291 ]]
[[ 1.0487202 ]
 [ 0.31861725]
 [-0.3282974 ]
 [-1.128099  ]
 [-0.08486968]
 [-1.3768167 ]
 [ 0.5664128 ]
 [ 0.14626984]
 [ 0.00804721]
 [-0.9331118 ]
 [ 0.3343495 ]]
--- 0.31542253494262695 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 48755.05078125, (41905.86, 6.054535, 6783.009, 2.531744)
   validation loss 41615.6953125, (40377.016, 6.4791284, 1172.0687, 2.531744)
decoder loss ratio: 1564275.682894, decoder SINDy loss  ratio: 2.530075
--- 0.2722923755645752 seconds for one epoch ---
--- 0.3146250247955322 seconds for one epoch ---
--- 0.33727598190307617 seconds for one epoch ---
--- 0.3428506851196289 seconds for one epoch ---
--- 0.3557918071746826 seconds for one epoch ---
--- 0.2802305221557617 seconds for one epoch ---
--- 0.3734452724456787 seconds for one epoch ---
--- 0.31325340270996094 seconds for one epoch ---
--- 0.34731340408325195 seconds for one epoch ---
--- 0.30660247802734375 seconds for one epoch ---
--- 0.3439474105834961 seconds for one epoch ---
--- 0.31438231468200684 seconds for one epoch ---
--- 0.34517979621887207 seconds for one epoch ---
--- 0.3239457607269287 seconds for one epoch ---
--- 0.3476073741912842 seconds for one epoch ---
--- 0.40114617347717285 seconds for one epoch ---
--- 0.3648548126220703 seconds for one epoch ---
--- 0.31896185874938965 seconds for one epoch ---
--- 0.3422222137451172 seconds for one epoch ---
--- 0.3206765651702881 seconds for one epoch ---
--- 0.3471367359161377 seconds for one epoch ---
--- 0.32472801208496094 seconds for one epoch ---
--- 0.35613465309143066 seconds for one epoch ---
--- 0.30913615226745605 seconds for one epoch ---
=========================
[[0.5050686 ]
 [0.49504438]
 [0.497643  ]
 [0.50514054]
 [0.49501428]
 [0.51012194]
 [0.49775937]
 [0.49625665]
 [0.49430817]
 [0.4976605 ]
 [0.49622592]]
[[ 1.2250291 ]
 [ 0.09879991]
 [-0.41548485]
 [-1.2323631 ]
 [-0.09489708]
 [-1.7205484 ]
 [ 0.42915836]
 [ 0.249244  ]
 [ 0.00483831]
 [-0.41756213]
 [ 0.24547689]]
--- 0.2705695629119873 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 37250.6953125, (29535.764, 380.9941, 7255.966, 2.5317504)
   validation loss 21539.4765625, (20400.021, 1.0153902, 1060.467, 2.5317504)
decoder loss ratio: 790332.248299, decoder SINDy loss  ratio: 2.289167
--- 0.2985498905181885 seconds for one epoch ---
--- 0.36197638511657715 seconds for one epoch ---
--- 0.3049027919769287 seconds for one epoch ---
--- 0.36803245544433594 seconds for one epoch ---
--- 0.30902552604675293 seconds for one epoch ---
--- 0.3329744338989258 seconds for one epoch ---
--- 0.28681039810180664 seconds for one epoch ---
--- 0.35945916175842285 seconds for one epoch ---
--- 0.28342485427856445 seconds for one epoch ---
--- 0.3690481185913086 seconds for one epoch ---
--- 0.3070056438446045 seconds for one epoch ---
--- 0.38043856620788574 seconds for one epoch ---
--- 0.30974483489990234 seconds for one epoch ---
--- 0.37718796730041504 seconds for one epoch ---
--- 0.3142740726470947 seconds for one epoch ---
--- 0.3747706413269043 seconds for one epoch ---
--- 0.31064748764038086 seconds for one epoch ---
--- 0.3853724002838135 seconds for one epoch ---
--- 0.2971358299255371 seconds for one epoch ---
--- 0.3470325469970703 seconds for one epoch ---
--- 0.2844424247741699 seconds for one epoch ---
--- 0.3694794178009033 seconds for one epoch ---
--- 0.32077741622924805 seconds for one epoch ---
--- 0.3597702980041504 seconds for one epoch ---
=========================
[[0.41112825]
 [0.40107194]
 [0.40760666]
 [0.4127718 ]
 [0.4016489 ]
 [0.42503875]
 [0.40442732]
 [0.40340742]
 [0.40090418]
 [0.40418762]
 [0.40218833]]
[[ 1.0020121e+00]
 [-1.9995453e-02]
 [-6.7936075e-01]
 [-1.1466072e+00]
 [-8.2158238e-02]
 [-2.1401024e+00]
 [ 3.6995840e-01]
 [ 2.6639244e-01]
 [ 1.7805559e-03]
 [-3.4585580e-01]
 [ 1.3947247e-01]]
--- 0.3243381977081299 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 23711.005859375, (17402.064, 44.95755, 6171.5073, 2.5317614)
   validation loss 11017.7890625, (10061.187, 0.6109806, 863.51355, 2.5317614)
decoder loss ratio: 389787.832906, decoder SINDy loss  ratio: 1.864015
--- 0.2700979709625244 seconds for one epoch ---
--- 0.3116295337677002 seconds for one epoch ---
--- 0.3564317226409912 seconds for one epoch ---
--- 0.33007287979125977 seconds for one epoch ---
--- 0.3821392059326172 seconds for one epoch ---
--- 0.3191356658935547 seconds for one epoch ---
--- 0.39487123489379883 seconds for one epoch ---
--- 0.30808115005493164 seconds for one epoch ---
--- 0.3478364944458008 seconds for one epoch ---
--- 0.3216521739959717 seconds for one epoch ---
--- 0.38254356384277344 seconds for one epoch ---
--- 0.3332827091217041 seconds for one epoch ---
--- 0.3718268871307373 seconds for one epoch ---
--- 0.32030367851257324 seconds for one epoch ---
--- 0.36771416664123535 seconds for one epoch ---
--- 0.326305627822876 seconds for one epoch ---
--- 0.3902244567871094 seconds for one epoch ---
--- 0.32259225845336914 seconds for one epoch ---
--- 0.3666675090789795 seconds for one epoch ---
--- 0.31629085540771484 seconds for one epoch ---
--- 0.4039137363433838 seconds for one epoch ---
--- 0.3217775821685791 seconds for one epoch ---
--- 0.369382381439209 seconds for one epoch ---
--- 0.32246971130371094 seconds for one epoch ---
=========================
[[0.32988673]
 [0.323648  ]
 [0.33289266]
 [0.3339327 ]
 [0.32326192]
 [0.35482898]
 [0.32586524]
 [0.3252588 ]
 [0.32220665]
 [0.32766387]
 [0.32280213]]
[[ 6.8696302e-01]
 [-1.3781990e-01]
 [-9.3178952e-01]
 [-1.0140656e+00]
 [-1.0166609e-01]
 [-2.4928441e+00]
 [ 3.4025624e-01]
 [ 2.8576747e-01]
 [-1.1810586e-03]
 [-4.9831241e-01]
 [ 5.8153674e-02]]
--- 0.2726094722747803 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18033.720703125, (10066.752, 37.96842, 7824.1816, 2.5317767)
   validation loss 12006.5341796875, (11180.467, 0.5991557, 720.64874, 2.5317767)
decoder loss ratio: 433150.693855, decoder SINDy loss  ratio: 1.555622
--- 0.3006594181060791 seconds for one epoch ---
--- 0.36139774322509766 seconds for one epoch ---
--- 0.3215763568878174 seconds for one epoch ---
--- 0.36733388900756836 seconds for one epoch ---
--- 0.32114577293395996 seconds for one epoch ---
--- 0.3718447685241699 seconds for one epoch ---
--- 0.32920026779174805 seconds for one epoch ---
--- 0.39109182357788086 seconds for one epoch ---
--- 0.30520176887512207 seconds for one epoch ---
--- 0.3782663345336914 seconds for one epoch ---
--- 0.30574679374694824 seconds for one epoch ---
--- 0.3874080181121826 seconds for one epoch ---
--- 0.3204493522644043 seconds for one epoch ---
--- 0.3805828094482422 seconds for one epoch ---
--- 0.32623982429504395 seconds for one epoch ---
--- 0.381622314453125 seconds for one epoch ---
--- 0.32439470291137695 seconds for one epoch ---
--- 0.3886590003967285 seconds for one epoch ---
--- 0.3205692768096924 seconds for one epoch ---
--- 0.36900997161865234 seconds for one epoch ---
--- 0.3364877700805664 seconds for one epoch ---
--- 0.37555909156799316 seconds for one epoch ---
--- 0.3397223949432373 seconds for one epoch ---
--- 0.376720666885376 seconds for one epoch ---
=========================
[[0.26980808]
 [0.26844415]
 [0.27831426]
 [0.2750941 ]
 [0.26643583]
 [0.30566052]
 [0.269614  ]
 [0.26889253]
 [0.26559502]
 [0.27494538]
 [0.2664739 ]]
[[ 3.6169901e-01]
 [-2.4839579e-01]
 [-1.0159169e+00]
 [-7.7761942e-01]
 [-7.6289348e-02]
 [-2.7757242e+00]
 [ 3.4574071e-01]
 [ 2.8596795e-01]
 [-2.2235592e-03]
 [-7.6636946e-01]
 [ 7.9642132e-02]]
--- 0.3197472095489502 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13835.783203125, (6539.2197, 5.043716, 7173.8604, 2.5317903)
   validation loss 4040.531005859375, (3267.7644, 0.21799697, 654.8899, 2.5317903)
decoder loss ratio: 126598.866111, decoder SINDy loss  ratio: 1.413672
--- 0.26309943199157715 seconds for one epoch ---
--- 0.29694175720214844 seconds for one epoch ---
--- 0.3871781826019287 seconds for one epoch ---
--- 0.30433154106140137 seconds for one epoch ---
--- 0.3832411766052246 seconds for one epoch ---
--- 0.3284933567047119 seconds for one epoch ---
--- 0.384657621383667 seconds for one epoch ---
--- 0.31090426445007324 seconds for one epoch ---
--- 0.37990617752075195 seconds for one epoch ---
--- 0.3251798152923584 seconds for one epoch ---
--- 0.3829457759857178 seconds for one epoch ---
--- 0.2863795757293701 seconds for one epoch ---
--- 0.38414883613586426 seconds for one epoch ---
--- 0.3311440944671631 seconds for one epoch ---
--- 0.3797163963317871 seconds for one epoch ---
--- 0.32210206985473633 seconds for one epoch ---
--- 0.3831181526184082 seconds for one epoch ---
--- 0.3289670944213867 seconds for one epoch ---
--- 0.38959193229675293 seconds for one epoch ---
--- 0.3562767505645752 seconds for one epoch ---
--- 0.40630006790161133 seconds for one epoch ---
--- 0.3362889289855957 seconds for one epoch ---
--- 0.37659573554992676 seconds for one epoch ---
--- 0.3262813091278076 seconds for one epoch ---
=========================
[[0.21875519]
 [0.22170681]
 [0.23077221]
 [0.22594339]
 [0.21828578]
 [0.26368266]
 [0.2222714 ]
 [0.22140089]
 [0.21767938]
 [0.23122898]
 [0.21800096]]
[[ 0.09778529]
 [-0.3324769 ]
 [-0.9903409 ]
 [-0.65028495]
 [-0.05932733]
 [-2.9640872 ]
 [ 0.37603527]
 [ 0.30869707]
 [-0.0091195 ]
 [-1.021463  ]
 [ 0.0358172 ]]
--- 0.2602531909942627 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11647.78125, (8312.663, 6.78285, 3201.1252, 2.531802)
   validation loss 3471.1728515625, (2833.2546, 0.22341686, 510.48508, 2.531802)
decoder loss ratio: 109765.203449, decoder SINDy loss  ratio: 1.101954
--- 0.2965583801269531 seconds for one epoch ---
--- 0.3770406246185303 seconds for one epoch ---
--- 0.31673622131347656 seconds for one epoch ---
--- 0.3932321071624756 seconds for one epoch ---
--- 0.31187987327575684 seconds for one epoch ---
--- 0.41190576553344727 seconds for one epoch ---
--- 0.3220221996307373 seconds for one epoch ---
--- 0.3948178291320801 seconds for one epoch ---
--- 0.2993595600128174 seconds for one epoch ---
--- 0.3899674415588379 seconds for one epoch ---
--- 0.311847448348999 seconds for one epoch ---
--- 0.4047281742095947 seconds for one epoch ---
--- 0.296738862991333 seconds for one epoch ---
--- 0.4038207530975342 seconds for one epoch ---
--- 0.29134654998779297 seconds for one epoch ---
--- 0.40750646591186523 seconds for one epoch ---
--- 0.310549259185791 seconds for one epoch ---
--- 0.4017767906188965 seconds for one epoch ---
--- 0.31806087493896484 seconds for one epoch ---
--- 0.3953225612640381 seconds for one epoch ---
--- 0.32091617584228516 seconds for one epoch ---
--- 0.40700721740722656 seconds for one epoch ---
--- 0.3262791633605957 seconds for one epoch ---
--- 0.4149606227874756 seconds for one epoch ---
=========================
[[0.18486516]
 [0.18778948]
 [0.19513512]
 [0.18940783]
 [0.18320896]
 [0.23372556]
 [0.18821986]
 [0.18689272]
 [0.18284906]
 [0.20135884]
 [0.1834432 ]]
[[-1.5984586e-01]
 [-3.7983289e-01]
 [-8.9262682e-01]
 [-4.9732393e-01]
 [-3.0344432e-02]
 [-3.1081510e+00]
 [ 4.1134682e-01]
 [ 3.1347740e-01]
 [ 1.6910157e-03]
 [-1.2929083e+00]
 [ 4.8912074e-02]]
--- 0.3150827884674072 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8522.48828125, (5683.9414, 6.783968, 2695.9043, 2.531816)
   validation loss 2518.883544921875, (1856.9426, 0.22168745, 525.8612, 2.531816)
decoder loss ratio: 71941.181162, decoder SINDy loss  ratio: 1.135145
--- 0.26720356941223145 seconds for one epoch ---
--- 0.3252999782562256 seconds for one epoch ---
--- 0.3968026638031006 seconds for one epoch ---
--- 0.3255743980407715 seconds for one epoch ---
--- 0.3990490436553955 seconds for one epoch ---
--- 0.3243069648742676 seconds for one epoch ---
--- 0.40543675422668457 seconds for one epoch ---
--- 0.3253331184387207 seconds for one epoch ---
--- 0.39496469497680664 seconds for one epoch ---
--- 0.3318328857421875 seconds for one epoch ---
--- 0.4004685878753662 seconds for one epoch ---
--- 0.3073418140411377 seconds for one epoch ---
--- 0.3960566520690918 seconds for one epoch ---
--- 0.2990293502807617 seconds for one epoch ---
--- 0.3809242248535156 seconds for one epoch ---
--- 0.3850409984588623 seconds for one epoch ---
--- 0.41250109672546387 seconds for one epoch ---
--- 0.309246301651001 seconds for one epoch ---
--- 0.4042661190032959 seconds for one epoch ---
--- 0.3108961582183838 seconds for one epoch ---
--- 0.411175012588501 seconds for one epoch ---
--- 0.32320666313171387 seconds for one epoch ---
--- 0.4223811626434326 seconds for one epoch ---
--- 0.32213878631591797 seconds for one epoch ---
=========================
[[0.1581201 ]
 [0.1592398 ]
 [0.16431004]
 [0.15933624]
 [0.15363447]
 [0.20700793]
 [0.15814435]
 [0.15716454]
 [0.15324648]
 [0.17665473]
 [0.15402262]]
[[-3.6361557e-01]
 [-4.4262978e-01]
 [-7.8562587e-01]
 [-4.4939211e-01]
 [-3.2854047e-02]
 [-3.1617081e+00]
 [ 3.6534050e-01]
 [ 2.9513982e-01]
 [-3.0562219e-03]
 [-1.5433713e+00]
 [ 6.2458746e-02]]
--- 0.2839064598083496 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5424.732421875, (3351.4648, 0.35735205, 1928.9845, 2.5318282)
   validation loss 1924.6826171875, (1314.313, 0.15095808, 466.29282, 2.5318282)
decoder loss ratio: 50918.766914, decoder SINDy loss  ratio: 1.006559
--- 0.30237245559692383 seconds for one epoch ---
--- 0.40603184700012207 seconds for one epoch ---
--- 0.3053007125854492 seconds for one epoch ---
--- 0.4138448238372803 seconds for one epoch ---
--- 0.33240556716918945 seconds for one epoch ---
--- 0.43673110008239746 seconds for one epoch ---
--- 0.32780027389526367 seconds for one epoch ---
--- 0.4243004322052002 seconds for one epoch ---
--- 0.31818199157714844 seconds for one epoch ---
--- 0.4224679470062256 seconds for one epoch ---
--- 0.32697629928588867 seconds for one epoch ---
--- 0.4145052433013916 seconds for one epoch ---
--- 0.3360466957092285 seconds for one epoch ---
--- 0.43612051010131836 seconds for one epoch ---
--- 0.3114633560180664 seconds for one epoch ---
--- 0.40821099281311035 seconds for one epoch ---
--- 0.2979457378387451 seconds for one epoch ---
--- 0.4334220886230469 seconds for one epoch ---
--- 0.31250929832458496 seconds for one epoch ---
--- 0.40811991691589355 seconds for one epoch ---
--- 0.30581140518188477 seconds for one epoch ---
--- 0.42269396781921387 seconds for one epoch ---
--- 0.303067684173584 seconds for one epoch ---
--- 0.42256975173950195 seconds for one epoch ---
=========================
[[0.13875699]
 [0.13833198]
 [0.14106476]
 [0.137087  ]
 [0.13177353]
 [0.1868968 ]
 [0.13652131]
 [0.1355389 ]
 [0.13178773]
 [0.15918319]
 [0.13356349]]
[[-0.50546557]
 [-0.4767382 ]
 [-0.65864724]
 [-0.39160198]
 [-0.00972664]
 [-3.1657271 ]
 [ 0.35241553]
 [ 0.28358683]
 [-0.01078803]
 [-1.7383077 ]
 [ 0.14200382]]
--- 0.2948751449584961 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6451.66650390625, (4136.332, 0.3910246, 2163.8525, 2.531834)
   validation loss 2153.611328125, (1566.617, 0.16211975, 435.74127, 2.531834)
decoder loss ratio: 60693.460152, decoder SINDy loss  ratio: 0.940609
--- 0.27480411529541016 seconds for one epoch ---
--- 0.31981706619262695 seconds for one epoch ---
--- 0.3986175060272217 seconds for one epoch ---
--- 0.3115513324737549 seconds for one epoch ---
--- 0.4149167537689209 seconds for one epoch ---
--- 0.30637669563293457 seconds for one epoch ---
--- 0.41401100158691406 seconds for one epoch ---
--- 0.3203604221343994 seconds for one epoch ---
--- 0.4467010498046875 seconds for one epoch ---
--- 0.3114197254180908 seconds for one epoch ---
--- 0.4328172206878662 seconds for one epoch ---
--- 0.3166632652282715 seconds for one epoch ---
--- 0.4196927547454834 seconds for one epoch ---
--- 0.30985498428344727 seconds for one epoch ---
--- 0.4196922779083252 seconds for one epoch ---
--- 0.3333871364593506 seconds for one epoch ---
--- 0.4305613040924072 seconds for one epoch ---
--- 0.30330657958984375 seconds for one epoch ---
--- 0.4127185344696045 seconds for one epoch ---
--- 0.29934263229370117 seconds for one epoch ---
--- 0.4368143081665039 seconds for one epoch ---
--- 0.3025474548339844 seconds for one epoch ---
--- 0.42322492599487305 seconds for one epoch ---
--- 0.304034948348999 seconds for one epoch ---
=========================
[[0.12216626]
 [0.12024744]
 [0.12112256]
 [0.11876211]
 [0.11329027]
 [0.16850273]
 [0.11755349]
 [0.11733162]
 [0.1132881 ]
 [0.14473946]
 [0.11632289]]
[[-0.61936384]
 [-0.49401873]
 [-0.5515653 ]
 [-0.39478892]
 [-0.00986365]
 [-3.1134324 ]
 [ 0.31248584]
 [ 0.2972274 ]
 [-0.00968991]
 [-1.9227843 ]
 [ 0.22718725]]
--- 0.2597172260284424 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7339.96337890625, (3814.251, 5.4895186, 3363.6663, 2.5318408)
   validation loss 2973.44970703125, (2368.5544, 0.15206753, 448.18622, 2.5318408)
decoder loss ratio: 91761.911127, decoder SINDy loss  ratio: 0.967473
--- 0.31156039237976074 seconds for one epoch ---
--- 0.4342186450958252 seconds for one epoch ---
--- 0.3026418685913086 seconds for one epoch ---
--- 0.44295310974121094 seconds for one epoch ---
--- 0.30402207374572754 seconds for one epoch ---
--- 0.44666218757629395 seconds for one epoch ---
--- 0.2941601276397705 seconds for one epoch ---
--- 0.4461698532104492 seconds for one epoch ---
--- 0.3214848041534424 seconds for one epoch ---
--- 0.43301963806152344 seconds for one epoch ---
--- 0.29213857650756836 seconds for one epoch ---
--- 0.4304964542388916 seconds for one epoch ---
--- 0.29524827003479004 seconds for one epoch ---
--- 0.4188346862792969 seconds for one epoch ---
--- 0.320526123046875 seconds for one epoch ---
--- 0.450056791305542 seconds for one epoch ---
--- 0.31957197189331055 seconds for one epoch ---
--- 0.44253993034362793 seconds for one epoch ---
--- 0.30028772354125977 seconds for one epoch ---
--- 0.44822192192077637 seconds for one epoch ---
--- 0.2951784133911133 seconds for one epoch ---
--- 0.4200446605682373 seconds for one epoch ---
--- 0.3017580509185791 seconds for one epoch ---
--- 0.4672555923461914 seconds for one epoch ---
=========================
[[0.11117565]
 [0.10705991]
 [0.10642233]
 [0.10516648]
 [0.09964607]
 [0.15517648]
 [0.10337428]
 [0.103761  ]
 [0.09969745]
 [0.1359705 ]
 [0.10407624]]
[[-7.7003694e-01]
 [-5.0949848e-01]
 [-4.6792018e-01]
 [-3.8497013e-01]
 [-1.7037111e-03]
 [-3.0830641e+00]
 [ 2.6402190e-01]
 [ 2.9038954e-01]
 [-5.4246173e-03]
 [-2.1427946e+00]
 [ 3.1176770e-01]]
--- 0.30899882316589355 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8578.037109375, (5332.0825, 4.4466424, 3080.2295, 2.5318508)
   validation loss 1507.6002197265625, (955.82336, 0.15790227, 390.34082, 2.5318508)
decoder loss ratio: 37030.256514, decoder SINDy loss  ratio: 0.842606
--- 0.2678353786468506 seconds for one epoch ---
--- 0.3106269836425781 seconds for one epoch ---
--- 0.42451977729797363 seconds for one epoch ---
--- 0.33188462257385254 seconds for one epoch ---
--- 0.43627452850341797 seconds for one epoch ---
--- 0.31532907485961914 seconds for one epoch ---
--- 0.42300963401794434 seconds for one epoch ---
--- 0.3360123634338379 seconds for one epoch ---
--- 0.454573392868042 seconds for one epoch ---
--- 0.32016468048095703 seconds for one epoch ---
--- 0.45705080032348633 seconds for one epoch ---
--- 0.3114337921142578 seconds for one epoch ---
--- 0.44377970695495605 seconds for one epoch ---
--- 0.3082587718963623 seconds for one epoch ---
--- 0.43682360649108887 seconds for one epoch ---
--- 0.3132345676422119 seconds for one epoch ---
--- 0.44927334785461426 seconds for one epoch ---
--- 0.3100612163543701 seconds for one epoch ---
--- 0.446422815322876 seconds for one epoch ---
--- 0.30155158042907715 seconds for one epoch ---
--- 0.45551037788391113 seconds for one epoch ---
--- 0.2991914749145508 seconds for one epoch ---
--- 0.44842982292175293 seconds for one epoch ---
--- 0.3467097282409668 seconds for one epoch ---
=========================
[[0.10121518]
 [0.09575942]
 [0.09340643]
 [0.09343743]
 [0.08815328]
 [0.14259382]
 [0.0919019 ]
 [0.09232697]
 [0.08815107]
 [0.12814245]
 [0.09296946]]
[[-0.8641641 ]
 [-0.52682555]
 [-0.3741471 ]
 [-0.37618285]
 [-0.01417321]
 [-3.0060084 ]
 [ 0.27390328]
 [ 0.302439  ]
 [-0.01400837]
 [-2.3103495 ]
 [ 0.34524745]]
--- 0.280440092086792 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4969.005859375, (1845.8159, 0.73145545, 2955.4375, 2.5318568)
   validation loss 1880.5810546875, (1353.1519, 0.12948246, 360.27838, 2.5318568)
decoder loss ratio: 52423.452056, decoder SINDy loss  ratio: 0.777712
--- 0.3124656677246094 seconds for one epoch ---
--- 0.43997693061828613 seconds for one epoch ---
--- 0.31150364875793457 seconds for one epoch ---
--- 0.46050071716308594 seconds for one epoch ---
--- 0.3219592571258545 seconds for one epoch ---
--- 0.46744489669799805 seconds for one epoch ---
--- 0.3032712936401367 seconds for one epoch ---
--- 0.4615910053253174 seconds for one epoch ---
--- 0.3074531555175781 seconds for one epoch ---
--- 0.46236133575439453 seconds for one epoch ---
--- 0.31848764419555664 seconds for one epoch ---
--- 0.4602634906768799 seconds for one epoch ---
--- 0.32958126068115234 seconds for one epoch ---
--- 0.49631643295288086 seconds for one epoch ---
--- 0.33519673347473145 seconds for one epoch ---
--- 0.46036601066589355 seconds for one epoch ---
--- 0.3197810649871826 seconds for one epoch ---
--- 0.4555356502532959 seconds for one epoch ---
--- 0.3259103298187256 seconds for one epoch ---
--- 0.4527778625488281 seconds for one epoch ---
--- 0.31177830696105957 seconds for one epoch ---
--- 0.44999265670776367 seconds for one epoch ---
--- 0.29361581802368164 seconds for one epoch ---
--- 0.46187376976013184 seconds for one epoch ---
=========================
[[0.09514444]
 [0.08732447]
 [0.08345374]
 [0.08435027]
 [0.07972361]
 [0.13360831]
 [0.08333423]
 [0.08354893]
 [0.07942747]
 [0.12439569]
 [0.08588628]]
[[-1.0044352 ]
 [-0.531843  ]
 [-0.28072646]
 [-0.34006768]
 [-0.02519357]
 [-2.9633007 ]
 [ 0.27276   ]
 [ 0.2870644 ]
 [-0.00426017]
 [-2.5266445 ]
 [ 0.44005117]]
--- 0.2855825424194336 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5203.29541015625, (2104.903, 2.2262778, 2924.0024, 2.5318677)
   validation loss 1469.482666015625, (926.00507, 0.1267618, 371.18713, 2.5318677)
decoder loss ratio: 35875.043869, decoder SINDy loss  ratio: 0.801260
--- 0.26665520668029785 seconds for one epoch ---
--- 0.3096034526824951 seconds for one epoch ---
--- 0.459118127822876 seconds for one epoch ---
--- 0.31940317153930664 seconds for one epoch ---
--- 0.4705638885498047 seconds for one epoch ---
--- 0.3077244758605957 seconds for one epoch ---
--- 0.48142480850219727 seconds for one epoch ---
--- 0.31133127212524414 seconds for one epoch ---
--- 0.48009181022644043 seconds for one epoch ---
--- 0.31296515464782715 seconds for one epoch ---
--- 0.45914387702941895 seconds for one epoch ---
--- 0.3179171085357666 seconds for one epoch ---
--- 0.47179293632507324 seconds for one epoch ---
--- 0.28155946731567383 seconds for one epoch ---
--- 0.4750361442565918 seconds for one epoch ---
--- 0.312389612197876 seconds for one epoch ---
--- 0.48087334632873535 seconds for one epoch ---
--- 0.3142688274383545 seconds for one epoch ---
--- 0.4749581813812256 seconds for one epoch ---
--- 0.32122278213500977 seconds for one epoch ---
--- 0.471820592880249 seconds for one epoch ---
--- 0.30855321884155273 seconds for one epoch ---
--- 0.4642786979675293 seconds for one epoch ---
--- 0.29723596572875977 seconds for one epoch ---
=========================
[[0.08966267]
 [0.08028758]
 [0.07457653]
 [0.07720152]
 [0.07214024]
 [0.1252553 ]
 [0.07545914]
 [0.07605641]
 [0.07198043]
 [0.12110304]
 [0.07964119]]
[[-1.1088874 ]
 [-0.553245  ]
 [-0.1827445 ]
 [-0.35662907]
 [-0.0151799 ]
 [-2.9005592 ]
 [ 0.24194902]
 [ 0.2815768 ]
 [-0.0039593 ]
 [-2.7060518 ]
 [ 0.5127088 ]]
--- 0.2584209442138672 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5888.02880859375, (1931.9624, 2.50761, 3776.5352, 2.5318773)
   validation loss 3674.47802734375, (3103.1287, 0.13798569, 394.18732, 2.5318773)
decoder loss ratio: 120220.591638, decoder SINDy loss  ratio: 0.850909
--- 0.306307315826416 seconds for one epoch ---
--- 0.49729347229003906 seconds for one epoch ---
--- 0.30497002601623535 seconds for one epoch ---
--- 0.4672839641571045 seconds for one epoch ---
--- 0.32126474380493164 seconds for one epoch ---
--- 0.47496533393859863 seconds for one epoch ---
--- 0.29613566398620605 seconds for one epoch ---
--- 0.4614253044128418 seconds for one epoch ---
--- 0.3128843307495117 seconds for one epoch ---
--- 0.4794917106628418 seconds for one epoch ---
--- 0.305819034576416 seconds for one epoch ---
--- 0.4769022464752197 seconds for one epoch ---
--- 0.29703807830810547 seconds for one epoch ---
--- 0.4857008457183838 seconds for one epoch ---
--- 0.3064568042755127 seconds for one epoch ---
--- 0.4897804260253906 seconds for one epoch ---
--- 0.3009645938873291 seconds for one epoch ---
--- 0.4781937599182129 seconds for one epoch ---
--- 0.2900254726409912 seconds for one epoch ---
--- 0.4857919216156006 seconds for one epoch ---
--- 0.2938671112060547 seconds for one epoch ---
--- 0.48717594146728516 seconds for one epoch ---
--- 0.3145945072174072 seconds for one epoch ---
--- 0.48599982261657715 seconds for one epoch ---
=========================
[[0.085944  ]
 [0.07471922]
 [0.06779789]
 [0.07178612]
 [0.06655981]
 [0.11855299]
 [0.06938443]
 [0.07046276]
 [0.06645524]
 [0.1194316 ]
 [0.07544096]]
[[-1.2026739e+00]
 [-5.4638082e-01]
 [-9.5556468e-02]
 [-3.6056146e-01]
 [-1.0001755e-02]
 [-2.8304136e+00]
 [ 2.0281851e-01]
 [ 2.7430078e-01]
 [-2.7027568e-03]
 [-2.8712206e+00]
 [ 5.9105605e-01]]
--- 0.40452122688293457 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5476.71533203125, (2187.7317, 2.7437422, 3105.5647, 2.5318856)
   validation loss 1305.09814453125, (753.752, 0.107933685, 370.5629, 2.5318856)
decoder loss ratio: 29201.661600, decoder SINDy loss  ratio: 0.799912
--- 0.265214204788208 seconds for one epoch ---
--- 0.33098769187927246 seconds for one epoch ---
--- 0.504399299621582 seconds for one epoch ---
--- 0.3273134231567383 seconds for one epoch ---
--- 0.5041875839233398 seconds for one epoch ---
--- 0.32921791076660156 seconds for one epoch ---
--- 0.4851498603820801 seconds for one epoch ---
--- 0.32285189628601074 seconds for one epoch ---
--- 0.48630189895629883 seconds for one epoch ---
--- 0.33623504638671875 seconds for one epoch ---
--- 0.48825740814208984 seconds for one epoch ---
--- 0.32424044609069824 seconds for one epoch ---
--- 0.4786508083343506 seconds for one epoch ---
--- 0.3209092617034912 seconds for one epoch ---
--- 0.5001299381256104 seconds for one epoch ---
--- 0.31102561950683594 seconds for one epoch ---
--- 0.4743483066558838 seconds for one epoch ---
--- 0.31803035736083984 seconds for one epoch ---
--- 0.4887714385986328 seconds for one epoch ---
--- 0.3231053352355957 seconds for one epoch ---
--- 0.48909735679626465 seconds for one epoch ---
--- 0.3158395290374756 seconds for one epoch ---
--- 0.5012228488922119 seconds for one epoch ---
--- 0.3127877712249756 seconds for one epoch ---
=========================
[[0.08344762]
 [0.07062762]
 [0.06187937]
 [0.06708577]
 [0.06162827]
 [0.11292392]
 [0.06431884]
 [0.06543211]
 [0.06181369]
 [0.11912987]
 [0.07191738]]
[[-1.3226572e+00]
 [-5.8730388e-01]
 [-1.8144000e-02]
 [-3.6508769e-01]
 [ 7.1192038e-04]
 [-2.7795346e+00]
 [ 1.8401632e-01]
 [ 2.5772643e-01]
 [-1.3590803e-02]
 [-3.0653603e+00]
 [ 6.6584063e-01]]
--- 0.25358104705810547 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4761.5244140625, (1925.7114, 1.6618892, 2649.9646, 2.5319002)
   validation loss 1721.2279052734375, (1175.5992, 0.1395378, 361.30228, 2.5319002)
decoder loss ratio: 45544.755610, decoder SINDy loss  ratio: 0.779922
--- 0.29922008514404297 seconds for one epoch ---
--- 0.48357534408569336 seconds for one epoch ---
--- 0.301098108291626 seconds for one epoch ---
--- 0.49746036529541016 seconds for one epoch ---
--- 0.3092348575592041 seconds for one epoch ---
--- 0.49784255027770996 seconds for one epoch ---
--- 0.30505847930908203 seconds for one epoch ---
--- 0.4894578456878662 seconds for one epoch ---
--- 0.32242918014526367 seconds for one epoch ---
--- 0.5256271362304688 seconds for one epoch ---
--- 0.32363438606262207 seconds for one epoch ---
--- 0.4970996379852295 seconds for one epoch ---
--- 0.32208824157714844 seconds for one epoch ---
--- 0.5033631324768066 seconds for one epoch ---
--- 0.32195448875427246 seconds for one epoch ---
--- 0.5196170806884766 seconds for one epoch ---
--- 0.33829832077026367 seconds for one epoch ---
--- 0.5150914192199707 seconds for one epoch ---
--- 0.3178977966308594 seconds for one epoch ---
--- 0.5299732685089111 seconds for one epoch ---
--- 0.33002543449401855 seconds for one epoch ---
--- 0.5097370147705078 seconds for one epoch ---
--- 0.3325662612915039 seconds for one epoch ---
--- 0.5197808742523193 seconds for one epoch ---
=========================
[[0.08148824]
 [0.06668626]
 [0.05857658]
 [0.06288011]
 [0.0582237 ]
 [0.10874747]
 [0.0605553 ]
 [0.06198958]
 [0.05810624]
 [0.11874373]
 [0.06941859]]
[[-1.4042779 ]
 [-0.562396  ]
 [ 0.03642158]
 [-0.32286677]
 [-0.01209703]
 [-2.7424123 ]
 [ 0.17038347]
 [ 0.2650513 ]
 [ 0.00397005]
 [-3.2002225 ]
 [ 0.7275532 ]]
--- 0.29887962341308594 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5257.126953125, (1938.5588, 1.271282, 3129.5781, 2.5319092)
   validation loss 1541.1214599609375, (1011.1937, 0.15472531, 342.0542, 2.5319092)
decoder loss ratio: 39175.400439, decoder SINDy loss  ratio: 0.738372
--- 0.24414682388305664 seconds for one epoch ---
--- 0.29217529296875 seconds for one epoch ---
--- 0.49837684631347656 seconds for one epoch ---
--- 0.3049466609954834 seconds for one epoch ---
--- 0.48097658157348633 seconds for one epoch ---
--- 0.28905463218688965 seconds for one epoch ---
--- 0.48772168159484863 seconds for one epoch ---
--- 0.31036901473999023 seconds for one epoch ---
--- 0.49867892265319824 seconds for one epoch ---
--- 0.3039829730987549 seconds for one epoch ---
--- 0.5214028358459473 seconds for one epoch ---
--- 0.3075873851776123 seconds for one epoch ---
--- 0.5168812274932861 seconds for one epoch ---
--- 0.30532026290893555 seconds for one epoch ---
--- 0.5130841732025146 seconds for one epoch ---
--- 0.30349183082580566 seconds for one epoch ---
--- 0.5110495090484619 seconds for one epoch ---
--- 0.3172938823699951 seconds for one epoch ---
--- 0.5056755542755127 seconds for one epoch ---
--- 0.30379700660705566 seconds for one epoch ---
--- 0.5111033916473389 seconds for one epoch ---
--- 0.30679893493652344 seconds for one epoch ---
--- 0.5268590450286865 seconds for one epoch ---
--- 0.3016982078552246 seconds for one epoch ---
=========================
[[0.08022113]
 [0.0636992 ]
 [0.05630995]
 [0.05966071]
 [0.0550813 ]
 [0.10502167]
 [0.05714652]
 [0.05887185]
 [0.05499157]
 [0.11916785]
 [0.06695285]]
[[-1.4979526 ]
 [-0.5691107 ]
 [ 0.09475287]
 [-0.31578752]
 [-0.01088949]
 [-2.7068992 ]
 [ 0.15095468]
 [ 0.2647016 ]
 [-0.00470027]
 [-3.3514667 ]
 [ 0.7643131 ]]
--- 0.26561784744262695 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3569.64306640625, (2183.6992, 1.2724164, 1195.0293, 2.5319226)
   validation loss 1782.36328125, (1232.9167, 0.094744176, 359.70984, 2.5319226)
decoder loss ratio: 47765.335257, decoder SINDy loss  ratio: 0.776484
--- 0.3124809265136719 seconds for one epoch ---
--- 0.5010221004486084 seconds for one epoch ---
--- 0.30187392234802246 seconds for one epoch ---
--- 0.5098755359649658 seconds for one epoch ---
--- 0.2985422611236572 seconds for one epoch ---
--- 0.49665069580078125 seconds for one epoch ---
--- 0.2979152202606201 seconds for one epoch ---
--- 0.5198206901550293 seconds for one epoch ---
--- 0.29624080657958984 seconds for one epoch ---
--- 0.5156257152557373 seconds for one epoch ---
--- 0.2928273677825928 seconds for one epoch ---
--- 0.515887975692749 seconds for one epoch ---
--- 0.29317212104797363 seconds for one epoch ---
--- 0.5134966373443604 seconds for one epoch ---
--- 0.3112905025482178 seconds for one epoch ---
--- 0.5484778881072998 seconds for one epoch ---
--- 0.3016331195831299 seconds for one epoch ---
--- 0.5414552688598633 seconds for one epoch ---
--- 0.31227612495422363 seconds for one epoch ---
--- 0.5372076034545898 seconds for one epoch ---
--- 0.30649757385253906 seconds for one epoch ---
--- 0.5203638076782227 seconds for one epoch ---
--- 0.328474760055542 seconds for one epoch ---
--- 0.5524454116821289 seconds for one epoch ---
=========================
[[0.07942838]
 [0.06143269]
 [0.05480665]
 [0.05673358]
 [0.05276806]
 [0.10206755]
 [0.0549563 ]
 [0.05649998]
 [0.05261771]
 [0.1196963 ]
 [0.06566919]]
[[-1.5747569e+00]
 [-5.7205218e-01]
 [ 1.5035935e-01]
 [-2.7692217e-01]
 [-1.2454636e-02]
 [-2.6726456e+00]
 [ 1.6031723e-01]
 [ 2.6176557e-01]
 [-2.1086135e-03]
 [-3.4731123e+00]
 [ 8.2408631e-01]]
--- 0.3057260513305664 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4271.8544921875, (1375.3182, 1.8070008, 2702.4553, 2.531934)
   validation loss 1261.4986572265625, (735.7664, 0.103012815, 333.3552, 2.531934)
decoder loss ratio: 28504.868398, decoder SINDy loss  ratio: 0.719594
THRESHOLDING: 2 active coefficients
--- 0.5223429203033447 seconds for one epoch ---
--- 0.31729841232299805 seconds for one epoch ---
--- 0.5266530513763428 seconds for one epoch ---
--- 0.3086228370666504 seconds for one epoch ---
--- 0.5381207466125488 seconds for one epoch ---
--- 0.295668363571167 seconds for one epoch ---
--- 0.5158901214599609 seconds for one epoch ---
--- 0.2946040630340576 seconds for one epoch ---
--- 0.5176622867584229 seconds for one epoch ---
--- 0.2998545169830322 seconds for one epoch ---
--- 0.5256638526916504 seconds for one epoch ---
--- 0.3084404468536377 seconds for one epoch ---
--- 0.5537638664245605 seconds for one epoch ---
--- 0.30291080474853516 seconds for one epoch ---
--- 0.53045654296875 seconds for one epoch ---
--- 0.29544734954833984 seconds for one epoch ---
--- 0.5419890880584717 seconds for one epoch ---
--- 0.3006727695465088 seconds for one epoch ---
--- 0.5287377834320068 seconds for one epoch ---
--- 0.311290979385376 seconds for one epoch ---
--- 0.5349140167236328 seconds for one epoch ---
--- 0.2984933853149414 seconds for one epoch ---
--- 0.5303549766540527 seconds for one epoch ---
--- 0.30051708221435547 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08069913]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11141467]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.7411706]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1869123]
 [ 0.       ]]
--- 0.26201653480529785 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5673.888671875, (2546.3604, 0.7388326, 3126.5952, 0.19440722)
   validation loss 1638.2003173828125, (1283.6232, 0.11981389, 354.2628, 0.19440722)
decoder loss ratio: 49729.790033, decoder SINDy loss  ratio: 0.764726
--- 0.29808855056762695 seconds for one epoch ---
--- 0.5183022022247314 seconds for one epoch ---
--- 0.30877113342285156 seconds for one epoch ---
--- 0.5291140079498291 seconds for one epoch ---
--- 0.29262781143188477 seconds for one epoch ---
--- 0.530339241027832 seconds for one epoch ---
--- 0.33421802520751953 seconds for one epoch ---
--- 0.5408599376678467 seconds for one epoch ---
--- 0.3394043445587158 seconds for one epoch ---
--- 0.5466525554656982 seconds for one epoch ---
--- 0.31696152687072754 seconds for one epoch ---
--- 0.5594272613525391 seconds for one epoch ---
--- 0.3106391429901123 seconds for one epoch ---
--- 0.5496499538421631 seconds for one epoch ---
--- 0.3322877883911133 seconds for one epoch ---
--- 0.5371017456054688 seconds for one epoch ---
--- 0.3262455463409424 seconds for one epoch ---
--- 0.5551493167877197 seconds for one epoch ---
--- 0.3373885154724121 seconds for one epoch ---
--- 0.5477452278137207 seconds for one epoch ---
--- 0.32309961318969727 seconds for one epoch ---
--- 0.5452487468719482 seconds for one epoch ---
--- 0.3338923454284668 seconds for one epoch ---
--- 0.537473201751709 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07203159]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10901579]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.3716011]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.144003 ]
 [ 0.       ]]
--- 0.29049181938171387 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3788.397216796875, (1660.9595, 2.0556784, 2125.1917, 0.19054838)
   validation loss 2082.22705078125, (1664.8827, 0.19727226, 416.9567, 0.19054838)
decoder loss ratio: 64500.445791, decoder SINDy loss  ratio: 0.900060
--- 0.2528879642486572 seconds for one epoch ---
--- 0.2955758571624756 seconds for one epoch ---
--- 0.5322072505950928 seconds for one epoch ---
--- 0.29727673530578613 seconds for one epoch ---
--- 0.5345172882080078 seconds for one epoch ---
--- 0.2942829132080078 seconds for one epoch ---
--- 0.5375823974609375 seconds for one epoch ---
--- 0.302875280380249 seconds for one epoch ---
--- 0.540740966796875 seconds for one epoch ---
--- 0.30061841011047363 seconds for one epoch ---
--- 0.5342569351196289 seconds for one epoch ---
--- 0.30586743354797363 seconds for one epoch ---
--- 0.5539581775665283 seconds for one epoch ---
--- 0.29524660110473633 seconds for one epoch ---
--- 0.5631062984466553 seconds for one epoch ---
--- 0.3112969398498535 seconds for one epoch ---
--- 0.5377142429351807 seconds for one epoch ---
--- 0.28597283363342285 seconds for one epoch ---
--- 0.5451431274414062 seconds for one epoch ---
--- 0.3047597408294678 seconds for one epoch ---
--- 0.5512757301330566 seconds for one epoch ---
--- 0.30345940589904785 seconds for one epoch ---
--- 0.565962553024292 seconds for one epoch ---
--- 0.3137247562408447 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06802719]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10832584]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2289852]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1705225]
 [ 0.       ]]
--- 0.273165225982666 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3180.73388671875, (1610.9054, 0.49181253, 1569.1473, 0.1894782)
   validation loss 1552.6607666015625, (1226.2194, 0.16493139, 326.08707, 0.1894782)
decoder loss ratio: 47505.866830, decoder SINDy loss  ratio: 0.703905
--- 0.30667853355407715 seconds for one epoch ---
--- 0.5586590766906738 seconds for one epoch ---
--- 0.3017563819885254 seconds for one epoch ---
--- 0.5508530139923096 seconds for one epoch ---
--- 0.3012702465057373 seconds for one epoch ---
--- 0.5595064163208008 seconds for one epoch ---
--- 0.2992703914642334 seconds for one epoch ---
--- 0.6000080108642578 seconds for one epoch ---
--- 0.33794236183166504 seconds for one epoch ---
--- 0.5513134002685547 seconds for one epoch ---
--- 0.3479795455932617 seconds for one epoch ---
--- 0.5623292922973633 seconds for one epoch ---
--- 0.3189809322357178 seconds for one epoch ---
--- 0.5573139190673828 seconds for one epoch ---
--- 0.3289835453033447 seconds for one epoch ---
--- 0.5445578098297119 seconds for one epoch ---
--- 0.3192918300628662 seconds for one epoch ---
--- 0.5490138530731201 seconds for one epoch ---
--- 0.3150770664215088 seconds for one epoch ---
--- 0.570563793182373 seconds for one epoch ---
--- 0.31978750228881836 seconds for one epoch ---
--- 0.5485491752624512 seconds for one epoch ---
--- 0.3105497360229492 seconds for one epoch ---
--- 0.5868840217590332 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06568521]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10874218]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1567063]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2325044]
 [ 0.       ]]
--- 0.2980620861053467 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3481.078125, (1738.1814, 0.740041, 1741.9674, 0.18943702)
   validation loss 2026.4652099609375, (1700.9862, 0.13024509, 325.15927, 0.18943702)
decoder loss ratio: 65899.158664, decoder SINDy loss  ratio: 0.701902
--- 0.2831094264984131 seconds for one epoch ---
--- 0.3239145278930664 seconds for one epoch ---
--- 0.584662675857544 seconds for one epoch ---
--- 0.3175678253173828 seconds for one epoch ---
--- 0.5651824474334717 seconds for one epoch ---
--- 0.30629992485046387 seconds for one epoch ---
--- 0.5694406032562256 seconds for one epoch ---
--- 0.2976553440093994 seconds for one epoch ---
--- 0.5896322727203369 seconds for one epoch ---
--- 0.3040626049041748 seconds for one epoch ---
--- 0.5920536518096924 seconds for one epoch ---
--- 0.3051025867462158 seconds for one epoch ---
--- 0.6134295463562012 seconds for one epoch ---
--- 0.3097226619720459 seconds for one epoch ---
--- 0.5719480514526367 seconds for one epoch ---
--- 0.30055999755859375 seconds for one epoch ---
--- 0.5823595523834229 seconds for one epoch ---
--- 0.30481863021850586 seconds for one epoch ---
--- 0.582557201385498 seconds for one epoch ---
--- 0.30872654914855957 seconds for one epoch ---
--- 0.5927503108978271 seconds for one epoch ---
--- 0.3152046203613281 seconds for one epoch ---
--- 0.5928452014923096 seconds for one epoch ---
--- 0.3263256549835205 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06400211]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10949669]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1137695]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3045762]
 [ 0.       ]]
--- 0.2648041248321533 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4083.04443359375, (2425.1946, 0.7233054, 1656.9365, 0.18985403)
   validation loss 1166.6190185546875, (828.79407, 0.16733545, 337.46774, 0.18985403)
decoder loss ratio: 32108.921020, decoder SINDy loss  ratio: 0.728472
--- 0.334209680557251 seconds for one epoch ---
--- 0.5878267288208008 seconds for one epoch ---
--- 0.44458937644958496 seconds for one epoch ---
--- 0.5638198852539062 seconds for one epoch ---
--- 0.30464744567871094 seconds for one epoch ---
--- 0.5954461097717285 seconds for one epoch ---
--- 0.2903616428375244 seconds for one epoch ---
--- 0.5781826972961426 seconds for one epoch ---
--- 0.2865259647369385 seconds for one epoch ---
--- 0.5783953666687012 seconds for one epoch ---
--- 0.3028740882873535 seconds for one epoch ---
--- 0.5863008499145508 seconds for one epoch ---
--- 0.327880859375 seconds for one epoch ---
--- 0.5885708332061768 seconds for one epoch ---
--- 0.32192182540893555 seconds for one epoch ---
--- 0.588688850402832 seconds for one epoch ---
--- 0.3175318241119385 seconds for one epoch ---
--- 0.5808713436126709 seconds for one epoch ---
--- 0.3071906566619873 seconds for one epoch ---
--- 0.6112921237945557 seconds for one epoch ---
--- 0.3198280334472656 seconds for one epoch ---
--- 0.5900158882141113 seconds for one epoch ---
--- 0.31587719917297363 seconds for one epoch ---
--- 0.5793344974517822 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06327451]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11007709]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.1112413]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.359437 ]
 [ 0.       ]]
--- 0.2976360321044922 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4444.7080078125, (1858.5122, 1.3327671, 2584.6726, 0.190365)
   validation loss 2048.470703125, (1620.4224, 0.2015241, 427.65634, 0.190365)
decoder loss ratio: 62777.975530, decoder SINDy loss  ratio: 0.923156
--- 0.2823200225830078 seconds for one epoch ---
--- 0.2975614070892334 seconds for one epoch ---
--- 0.5876321792602539 seconds for one epoch ---
--- 0.3033266067504883 seconds for one epoch ---
--- 0.5811870098114014 seconds for one epoch ---
--- 0.2993783950805664 seconds for one epoch ---
--- 0.595484733581543 seconds for one epoch ---
--- 0.29529738426208496 seconds for one epoch ---
--- 0.5936629772186279 seconds for one epoch ---
--- 0.29857754707336426 seconds for one epoch ---
--- 0.587801456451416 seconds for one epoch ---
--- 0.289975643157959 seconds for one epoch ---
--- 0.6329288482666016 seconds for one epoch ---
--- 0.31029200553894043 seconds for one epoch ---
--- 0.6240170001983643 seconds for one epoch ---
--- 0.30593013763427734 seconds for one epoch ---
--- 0.6034801006317139 seconds for one epoch ---
--- 0.3092830181121826 seconds for one epoch ---
--- 0.6209027767181396 seconds for one epoch ---
--- 0.3029189109802246 seconds for one epoch ---
--- 0.6271235942840576 seconds for one epoch ---
--- 0.3068115711212158 seconds for one epoch ---
--- 0.6103694438934326 seconds for one epoch ---
--- 0.3110198974609375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06216278]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11105753]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0835829]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4289007]
 [ 0.       ]]
--- 0.28163957595825195 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3419.83544921875, (1722.1097, 1.67925, 1695.8555, 0.19093472)
   validation loss 1307.6353759765625, (948.8203, 0.1255867, 358.4985, 0.19093472)
decoder loss ratio: 36758.946131, decoder SINDy loss  ratio: 0.773869
--- 0.320127010345459 seconds for one epoch ---
--- 0.6112170219421387 seconds for one epoch ---
--- 0.317812442779541 seconds for one epoch ---
--- 0.6385748386383057 seconds for one epoch ---
--- 0.31031107902526855 seconds for one epoch ---
--- 0.605919599533081 seconds for one epoch ---
--- 0.30144453048706055 seconds for one epoch ---
--- 0.5789487361907959 seconds for one epoch ---
--- 0.30170416831970215 seconds for one epoch ---
--- 0.6084825992584229 seconds for one epoch ---
--- 0.28145360946655273 seconds for one epoch ---
--- 0.5986800193786621 seconds for one epoch ---
--- 0.32751941680908203 seconds for one epoch ---
--- 0.6200084686279297 seconds for one epoch ---
--- 0.3186168670654297 seconds for one epoch ---
--- 0.6160149574279785 seconds for one epoch ---
--- 0.3217768669128418 seconds for one epoch ---
--- 0.601872444152832 seconds for one epoch ---
--- 0.2978627681732178 seconds for one epoch ---
--- 0.6345160007476807 seconds for one epoch ---
--- 0.32227110862731934 seconds for one epoch ---
--- 0.6051332950592041 seconds for one epoch ---
--- 0.32518935203552246 seconds for one epoch ---
--- 0.6196424961090088 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06185539]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11212344]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0921788]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4959278]
 [ 0.       ]]
--- 0.2953476905822754 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3162.609130859375, (1310.2919, 1.1478245, 1850.9778, 0.19172037)
   validation loss 963.5609130859375, (652.54474, 0.1685145, 310.65594, 0.19172037)
decoder loss ratio: 25280.716047, decoder SINDy loss  ratio: 0.670595
--- 0.2551889419555664 seconds for one epoch ---
--- 0.3224203586578369 seconds for one epoch ---
--- 0.622161865234375 seconds for one epoch ---
--- 0.31810617446899414 seconds for one epoch ---
--- 0.6114938259124756 seconds for one epoch ---
--- 0.3067014217376709 seconds for one epoch ---
--- 0.618391752243042 seconds for one epoch ---
--- 0.29439401626586914 seconds for one epoch ---
--- 0.6092934608459473 seconds for one epoch ---
--- 0.30011510848999023 seconds for one epoch ---
--- 0.6325740814208984 seconds for one epoch ---
--- 0.2951974868774414 seconds for one epoch ---
--- 0.6239163875579834 seconds for one epoch ---
--- 0.29895877838134766 seconds for one epoch ---
--- 0.6276962757110596 seconds for one epoch ---
--- 0.28397440910339355 seconds for one epoch ---
--- 0.6204016208648682 seconds for one epoch ---
--- 0.2987692356109619 seconds for one epoch ---
--- 0.6322307586669922 seconds for one epoch ---
--- 0.29550600051879883 seconds for one epoch ---
--- 0.6271076202392578 seconds for one epoch ---
--- 0.3059391975402832 seconds for one epoch ---
--- 0.6310057640075684 seconds for one epoch ---
--- 0.30042243003845215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06145515]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11388019]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-1.093024]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-3.591561]
 [ 0.      ]]
--- 0.25823020935058594 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3167.4228515625, (1440.6891, 0.88490444, 1725.6562, 0.19262406)
   validation loss 1255.54345703125, (939.16595, 0.21331957, 315.9716, 0.19262406)
decoder loss ratio: 36384.919545, decoder SINDy loss  ratio: 0.682069
--- 0.30000758171081543 seconds for one epoch ---
--- 0.6143462657928467 seconds for one epoch ---
--- 0.31921982765197754 seconds for one epoch ---
--- 0.6390373706817627 seconds for one epoch ---
--- 0.305619478225708 seconds for one epoch ---
--- 0.6489615440368652 seconds for one epoch ---
--- 0.3179628849029541 seconds for one epoch ---
--- 0.6246180534362793 seconds for one epoch ---
--- 0.2913079261779785 seconds for one epoch ---
--- 0.6144669055938721 seconds for one epoch ---
--- 0.29607605934143066 seconds for one epoch ---
--- 0.61759352684021 seconds for one epoch ---
--- 0.2917976379394531 seconds for one epoch ---
--- 0.6423661708831787 seconds for one epoch ---
--- 0.33203768730163574 seconds for one epoch ---
--- 0.6459274291992188 seconds for one epoch ---
--- 0.3293581008911133 seconds for one epoch ---
--- 0.6240487098693848 seconds for one epoch ---
--- 0.3177304267883301 seconds for one epoch ---
--- 0.611414909362793 seconds for one epoch ---
--- 0.31998610496520996 seconds for one epoch ---
--- 0.6350035667419434 seconds for one epoch ---
--- 0.3071901798248291 seconds for one epoch ---
--- 0.6294097900390625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06066677]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11497989]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0671471]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.6538079]
 [ 0.       ]]
--- 0.32134008407592773 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4118.07568359375, (2127.7454, 2.8621569, 1987.2748, 0.19312845)
   validation loss 989.1358642578125, (664.2133, 0.27186292, 324.45758, 0.19312845)
decoder loss ratio: 25732.777059, decoder SINDy loss  ratio: 0.700387
--- 0.2767677307128906 seconds for one epoch ---
--- 0.3324451446533203 seconds for one epoch ---
--- 0.6221880912780762 seconds for one epoch ---
--- 0.31579017639160156 seconds for one epoch ---
--- 0.6248781681060791 seconds for one epoch ---
--- 0.3209514617919922 seconds for one epoch ---
--- 0.6177153587341309 seconds for one epoch ---
--- 0.3112449645996094 seconds for one epoch ---
--- 0.6335580348968506 seconds for one epoch ---
--- 0.29311609268188477 seconds for one epoch ---
--- 0.6448981761932373 seconds for one epoch ---
--- 0.2842733860015869 seconds for one epoch ---
--- 0.63700270652771 seconds for one epoch ---
--- 0.28285956382751465 seconds for one epoch ---
--- 0.6466989517211914 seconds for one epoch ---
--- 0.3037099838256836 seconds for one epoch ---
--- 0.6540954113006592 seconds for one epoch ---
--- 0.3063206672668457 seconds for one epoch ---
--- 0.648334264755249 seconds for one epoch ---
--- 0.3085033893585205 seconds for one epoch ---
--- 0.6675119400024414 seconds for one epoch ---
--- 0.30472230911254883 seconds for one epoch ---
--- 0.6635172367095947 seconds for one epoch ---
--- 0.3207418918609619 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05991784]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11726288]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.041603 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7673526]
 [ 0.       ]]
--- 0.26842260360717773 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5862.9462890625, (1647.3986, 1.7082556, 4213.645, 0.19418174)
   validation loss 1080.0301513671875, (750.91327, 0.19718657, 328.7254, 0.19418174)
decoder loss ratio: 29091.683685, decoder SINDy loss  ratio: 0.709600
--- 0.30576157569885254 seconds for one epoch ---
--- 0.6455674171447754 seconds for one epoch ---
--- 0.29323577880859375 seconds for one epoch ---
--- 0.6528995037078857 seconds for one epoch ---
--- 0.3003959655761719 seconds for one epoch ---
--- 0.6620564460754395 seconds for one epoch ---
--- 0.2987642288208008 seconds for one epoch ---
--- 0.6817939281463623 seconds for one epoch ---
--- 0.3002908229827881 seconds for one epoch ---
--- 0.6716136932373047 seconds for one epoch ---
--- 0.299072265625 seconds for one epoch ---
--- 0.6644408702850342 seconds for one epoch ---
--- 0.29120397567749023 seconds for one epoch ---
--- 0.6557862758636475 seconds for one epoch ---
--- 0.2921915054321289 seconds for one epoch ---
--- 0.658137321472168 seconds for one epoch ---
--- 0.3292195796966553 seconds for one epoch ---
--- 0.6504108905792236 seconds for one epoch ---
--- 0.33904314041137695 seconds for one epoch ---
--- 0.6781513690948486 seconds for one epoch ---
--- 0.3118877410888672 seconds for one epoch ---
--- 0.6647722721099854 seconds for one epoch ---
--- 0.3298335075378418 seconds for one epoch ---
--- 0.6798303127288818 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06002752]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11956862]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0598472]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.8792412]
 [ 0.       ]]
--- 0.2992103099822998 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5597.3798828125, (2496.8435, 1.0847137, 3099.256, 0.1954307)
   validation loss 1074.4906005859375, (730.30505, 0.24639419, 343.74377, 0.1954307)
decoder loss ratio: 28293.285646, decoder SINDy loss  ratio: 0.742019
--- 0.2730851173400879 seconds for one epoch ---
--- 0.29840850830078125 seconds for one epoch ---
--- 0.6592063903808594 seconds for one epoch ---
--- 0.30150604248046875 seconds for one epoch ---
--- 0.6767220497131348 seconds for one epoch ---
--- 0.3032348155975342 seconds for one epoch ---
--- 0.6623878479003906 seconds for one epoch ---
--- 0.3201484680175781 seconds for one epoch ---
--- 0.660224199295044 seconds for one epoch ---
--- 0.29367852210998535 seconds for one epoch ---
--- 0.6585779190063477 seconds for one epoch ---
--- 0.29506468772888184 seconds for one epoch ---
--- 0.6646523475646973 seconds for one epoch ---
--- 0.2976109981536865 seconds for one epoch ---
--- 0.6623163223266602 seconds for one epoch ---
--- 0.3045191764831543 seconds for one epoch ---
--- 0.6585350036621094 seconds for one epoch ---
--- 0.28459668159484863 seconds for one epoch ---
--- 0.658764123916626 seconds for one epoch ---
--- 0.288618803024292 seconds for one epoch ---
--- 0.6748461723327637 seconds for one epoch ---
--- 0.29917025566101074 seconds for one epoch ---
--- 0.693845272064209 seconds for one epoch ---
--- 0.28812623023986816 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05903396]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12119611]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0158589]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.9601686]
 [ 0.       ]]
--- 0.25712060928344727 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3192.931884765625, (2090.889, 0.93600214, 1100.911, 0.19594698)
   validation loss 1148.5062255859375, (834.7528, 0.19717586, 313.36035, 0.19594698)
decoder loss ratio: 32339.772962, decoder SINDy loss  ratio: 0.676432
--- 0.30748724937438965 seconds for one epoch ---
--- 0.6590297222137451 seconds for one epoch ---
--- 0.31853508949279785 seconds for one epoch ---
--- 0.674501895904541 seconds for one epoch ---
--- 0.3099679946899414 seconds for one epoch ---
--- 0.6674518585205078 seconds for one epoch ---
--- 0.29484987258911133 seconds for one epoch ---
--- 0.6764812469482422 seconds for one epoch ---
--- 0.2954285144805908 seconds for one epoch ---
--- 0.6835176944732666 seconds for one epoch ---
--- 0.29340600967407227 seconds for one epoch ---
--- 0.6848495006561279 seconds for one epoch ---
--- 0.2996945381164551 seconds for one epoch ---
--- 0.6947808265686035 seconds for one epoch ---
--- 0.29912614822387695 seconds for one epoch ---
--- 0.6750614643096924 seconds for one epoch ---
--- 0.27976179122924805 seconds for one epoch ---
--- 0.6736307144165039 seconds for one epoch ---
--- 0.32950639724731445 seconds for one epoch ---
--- 0.6988654136657715 seconds for one epoch ---
--- 0.3322780132293701 seconds for one epoch ---
--- 0.6933879852294922 seconds for one epoch ---
--- 0.3204069137573242 seconds for one epoch ---
--- 0.7088377475738525 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05891893]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1236775 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0180193]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0775933]
 [ 0.       ]]
--- 0.2896111011505127 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4353.615234375, (1868.972, 0.52725863, 2483.919, 0.19718677)
   validation loss 1582.5372314453125, (1220.7208, 0.2382008, 361.38107, 0.19718677)
decoder loss ratio: 47292.844033, decoder SINDy loss  ratio: 0.780092
--- 0.2666616439819336 seconds for one epoch ---
--- 0.29592204093933105 seconds for one epoch ---
--- 0.6875312328338623 seconds for one epoch ---
--- 0.30451488494873047 seconds for one epoch ---
--- 0.698040246963501 seconds for one epoch ---
--- 0.29491734504699707 seconds for one epoch ---
--- 0.6985399723052979 seconds for one epoch ---
--- 0.28490138053894043 seconds for one epoch ---
--- 0.7136631011962891 seconds for one epoch ---
--- 0.2826676368713379 seconds for one epoch ---
--- 0.6889972686767578 seconds for one epoch ---
--- 0.29378747940063477 seconds for one epoch ---
--- 0.6784083843231201 seconds for one epoch ---
--- 0.29178524017333984 seconds for one epoch ---
--- 0.680809736251831 seconds for one epoch ---
--- 0.2998046875 seconds for one epoch ---
--- 0.6676681041717529 seconds for one epoch ---
--- 0.2887277603149414 seconds for one epoch ---
--- 0.6836097240447998 seconds for one epoch ---
--- 0.2893490791320801 seconds for one epoch ---
--- 0.7054286003112793 seconds for one epoch ---
--- 0.29295921325683594 seconds for one epoch ---
--- 0.6916828155517578 seconds for one epoch ---
--- 0.30313873291015625 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05873789]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.126465  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0157261]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.2086854]
 [ 0.       ]]
--- 0.2465054988861084 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2626.375244140625, (1278.4835, 1.2637111, 1346.4297, 0.19859505)
   validation loss 1285.1361083984375, (933.21814, 0.38367587, 351.33566, 0.19859505)
decoder loss ratio: 36154.490868, decoder SINDy loss  ratio: 0.758407
--- 0.33505678176879883 seconds for one epoch ---
--- 0.6797919273376465 seconds for one epoch ---
--- 0.30937695503234863 seconds for one epoch ---
--- 0.7035555839538574 seconds for one epoch ---
--- 0.30358195304870605 seconds for one epoch ---
--- 0.6781883239746094 seconds for one epoch ---
--- 0.3000061511993408 seconds for one epoch ---
--- 0.6822848320007324 seconds for one epoch ---
--- 0.29938602447509766 seconds for one epoch ---
--- 0.6897895336151123 seconds for one epoch ---
--- 0.3005635738372803 seconds for one epoch ---
--- 0.695380449295044 seconds for one epoch ---
--- 0.3088264465332031 seconds for one epoch ---
--- 0.6923742294311523 seconds for one epoch ---
--- 0.2983872890472412 seconds for one epoch ---
--- 0.6948418617248535 seconds for one epoch ---
--- 0.2973611354827881 seconds for one epoch ---
--- 0.7088415622711182 seconds for one epoch ---
--- 0.29369425773620605 seconds for one epoch ---
--- 0.6958713531494141 seconds for one epoch ---
--- 0.32738161087036133 seconds for one epoch ---
--- 0.7204878330230713 seconds for one epoch ---
--- 0.32550978660583496 seconds for one epoch ---
--- 0.7219750881195068 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05858384]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12909904]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0131856]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.332262 ]
 [ 0.       ]]
--- 0.2983553409576416 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3623.1201171875, (1209.132, 0.398869, 2413.3896, 0.19960241)
   validation loss 1290.7320556640625, (909.34955, 0.30806237, 380.87482, 0.19960241)
decoder loss ratio: 35229.780203, decoder SINDy loss  ratio: 0.822172
--- 0.2699129581451416 seconds for one epoch ---
--- 0.2900419235229492 seconds for one epoch ---
--- 0.7136280536651611 seconds for one epoch ---
--- 0.29065656661987305 seconds for one epoch ---
--- 0.7025105953216553 seconds for one epoch ---
--- 0.3078920841217041 seconds for one epoch ---
--- 0.7114448547363281 seconds for one epoch ---
--- 0.29304933547973633 seconds for one epoch ---
--- 0.7167208194732666 seconds for one epoch ---
--- 0.29485321044921875 seconds for one epoch ---
--- 0.7174508571624756 seconds for one epoch ---
--- 0.3010098934173584 seconds for one epoch ---
--- 0.7086362838745117 seconds for one epoch ---
--- 0.44670987129211426 seconds for one epoch ---
--- 0.7223503589630127 seconds for one epoch ---
--- 0.2936532497406006 seconds for one epoch ---
--- 0.716843843460083 seconds for one epoch ---
--- 0.29997873306274414 seconds for one epoch ---
--- 0.7130651473999023 seconds for one epoch ---
--- 0.28683948516845703 seconds for one epoch ---
--- 0.713810920715332 seconds for one epoch ---
--- 0.30329251289367676 seconds for one epoch ---
--- 0.7078828811645508 seconds for one epoch ---
--- 0.303372859954834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05846988]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.131651  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0123432]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.4525256]
 [ 0.       ]]
--- 0.2747035026550293 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4121.32568359375, (1530.4034, 2.7786748, 2587.9426, 0.200768)
   validation loss 919.4125366210938, (624.70483, 0.23075576, 294.27618, 0.200768)
decoder loss ratio: 24202.149804, decoder SINDy loss  ratio: 0.635237
--- 0.31612372398376465 seconds for one epoch ---
--- 0.712303876876831 seconds for one epoch ---
--- 0.32114601135253906 seconds for one epoch ---
--- 0.7258169651031494 seconds for one epoch ---
--- 0.31730031967163086 seconds for one epoch ---
--- 0.7304477691650391 seconds for one epoch ---
--- 0.315838098526001 seconds for one epoch ---
--- 0.7328653335571289 seconds for one epoch ---
--- 0.34575557708740234 seconds for one epoch ---
--- 0.7377176284790039 seconds for one epoch ---
--- 0.3420674800872803 seconds for one epoch ---
--- 0.7242968082427979 seconds for one epoch ---
--- 0.3264646530151367 seconds for one epoch ---
--- 0.7287425994873047 seconds for one epoch ---
--- 0.2950623035430908 seconds for one epoch ---
--- 0.7036750316619873 seconds for one epoch ---
--- 0.296337366104126 seconds for one epoch ---
--- 0.7269124984741211 seconds for one epoch ---
--- 0.3028569221496582 seconds for one epoch ---
--- 0.7024955749511719 seconds for one epoch ---
--- 0.3025791645050049 seconds for one epoch ---
--- 0.7345712184906006 seconds for one epoch ---
--- 0.3197662830352783 seconds for one epoch ---
--- 0.7401659488677979 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05833597]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13415654]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-1.0091709]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.570674 ]
 [ 0.       ]]
--- 0.3120577335357666 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2233.2841796875, (1301.9302, 0.35704082, 930.795, 0.20178726)
   validation loss 1009.574462890625, (644.1598, 0.19850385, 365.0144, 0.20178726)
decoder loss ratio: 24955.868577, decoder SINDy loss  ratio: 0.787935
--- 0.26476216316223145 seconds for one epoch ---
--- 0.3112924098968506 seconds for one epoch ---
--- 0.7202744483947754 seconds for one epoch ---
--- 0.31249570846557617 seconds for one epoch ---
--- 0.7097334861755371 seconds for one epoch ---
--- 0.31424379348754883 seconds for one epoch ---
--- 0.7278625965118408 seconds for one epoch ---
--- 0.31064391136169434 seconds for one epoch ---
--- 0.723102331161499 seconds for one epoch ---
--- 0.2962944507598877 seconds for one epoch ---
--- 0.7210805416107178 seconds for one epoch ---
--- 0.3082091808319092 seconds for one epoch ---
--- 0.7409818172454834 seconds for one epoch ---
--- 0.3035397529602051 seconds for one epoch ---
--- 0.7496612071990967 seconds for one epoch ---
--- 0.3004035949707031 seconds for one epoch ---
--- 0.7356960773468018 seconds for one epoch ---
--- 0.2954084873199463 seconds for one epoch ---
--- 0.7267906665802002 seconds for one epoch ---
--- 0.30062127113342285 seconds for one epoch ---
--- 0.7196168899536133 seconds for one epoch ---
--- 0.29551148414611816 seconds for one epoch ---
--- 0.7240891456604004 seconds for one epoch ---
--- 0.29906296730041504 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0577154 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13627279]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9784959]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.671508 ]
 [ 0.       ]]
--- 0.26104283332824707 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3127.36083984375, (1792.7473, 0.37006608, 1334.0413, 0.20220609)
   validation loss 1751.015380859375, (1405.349, 0.18894343, 345.27533, 0.20220609)
decoder loss ratio: 54445.660015, decoder SINDy loss  ratio: 0.745325
--- 0.2909514904022217 seconds for one epoch ---
--- 0.7272698879241943 seconds for one epoch ---
--- 0.2915384769439697 seconds for one epoch ---
--- 0.7754373550415039 seconds for one epoch ---
--- 0.2937757968902588 seconds for one epoch ---
--- 0.7842679023742676 seconds for one epoch ---
--- 0.31429195404052734 seconds for one epoch ---
--- 0.7276999950408936 seconds for one epoch ---
--- 0.2976534366607666 seconds for one epoch ---
--- 0.7953453063964844 seconds for one epoch ---
--- 0.3190474510192871 seconds for one epoch ---
--- 0.78141188621521 seconds for one epoch ---
--- 0.32483482360839844 seconds for one epoch ---
--- 0.7483406066894531 seconds for one epoch ---
--- 0.3053889274597168 seconds for one epoch ---
--- 0.7548835277557373 seconds for one epoch ---
--- 0.3087024688720703 seconds for one epoch ---
--- 0.7470099925994873 seconds for one epoch ---
--- 0.31864428520202637 seconds for one epoch ---
--- 0.7557103633880615 seconds for one epoch ---
--- 0.3176255226135254 seconds for one epoch ---
--- 0.7497119903564453 seconds for one epoch ---
--- 0.2989978790283203 seconds for one epoch ---
--- 0.7652251720428467 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05767887]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13843343]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.9795253]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.7746015]
 [ 0.       ]]
--- 0.2983570098876953 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3495.18798828125, (1238.8461, 0.5675954, 2255.5715, 0.20259355)
   validation loss 905.2710571289062, (595.6007, 0.27929744, 309.18848, 0.20259355)
decoder loss ratio: 23074.605437, decoder SINDy loss  ratio: 0.667427
THRESHOLDING: 1 active coefficients
--- 0.7171251773834229 seconds for one epoch ---
--- 0.30306482315063477 seconds for one epoch ---
--- 0.7675702571868896 seconds for one epoch ---
--- 0.3417549133300781 seconds for one epoch ---
--- 0.7633414268493652 seconds for one epoch ---
--- 0.32063722610473633 seconds for one epoch ---
--- 0.7515673637390137 seconds for one epoch ---
--- 0.32492756843566895 seconds for one epoch ---
--- 0.7861208915710449 seconds for one epoch ---
--- 0.32755398750305176 seconds for one epoch ---
--- 0.7612123489379883 seconds for one epoch ---
--- 0.32238316535949707 seconds for one epoch ---
--- 0.7664225101470947 seconds for one epoch ---
--- 0.3227219581604004 seconds for one epoch ---
--- 0.7750325202941895 seconds for one epoch ---
--- 0.323822021484375 seconds for one epoch ---
--- 0.7865211963653564 seconds for one epoch ---
--- 0.3365633487701416 seconds for one epoch ---
--- 0.7403497695922852 seconds for one epoch ---
--- 0.32767367362976074 seconds for one epoch ---
--- 0.7605698108673096 seconds for one epoch ---
--- 0.32862401008605957 seconds for one epoch ---
--- 0.7737247943878174 seconds for one epoch ---
--- 0.3315403461456299 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14548206]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.1127815]
 [ 0.       ]]
--- 0.26093268394470215 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3837.840087890625, (1454.7344, 1.5780122, 2381.4487, 0.07880328)
   validation loss 1164.568115234375, (806.5821, 0.29894224, 357.60815, 0.07880328)
decoder loss ratio: 31248.390543, decoder SINDy loss  ratio: 0.771948
--- 0.2943861484527588 seconds for one epoch ---
--- 0.7460851669311523 seconds for one epoch ---
--- 0.2988317012786865 seconds for one epoch ---
--- 0.7684919834136963 seconds for one epoch ---
--- 0.29751157760620117 seconds for one epoch ---
--- 0.7632825374603271 seconds for one epoch ---
--- 0.29357075691223145 seconds for one epoch ---
--- 0.7872064113616943 seconds for one epoch ---
--- 0.3012199401855469 seconds for one epoch ---
--- 0.7759072780609131 seconds for one epoch ---
--- 0.3005659580230713 seconds for one epoch ---
--- 0.7856044769287109 seconds for one epoch ---
--- 0.3060779571533203 seconds for one epoch ---
--- 0.7782258987426758 seconds for one epoch ---
--- 0.2947707176208496 seconds for one epoch ---
--- 0.7850031852722168 seconds for one epoch ---
--- 0.296844482421875 seconds for one epoch ---
--- 0.7544808387756348 seconds for one epoch ---
--- 0.29878783226013184 seconds for one epoch ---
--- 0.7606043815612793 seconds for one epoch ---
--- 0.2934303283691406 seconds for one epoch ---
--- 0.775707483291626 seconds for one epoch ---
--- 0.3012394905090332 seconds for one epoch ---
--- 0.7702758312225342 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15196016]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-5.436174]
 [ 0.      ]]
--- 0.3193378448486328 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5385.94189453125, (2277.7192, 0.6854205, 3107.4546, 0.08237817)
   validation loss 1443.0316162109375, (1081.9514, 0.29179662, 360.70602, 0.08237817)
decoder loss ratio: 41916.676207, decoder SINDy loss  ratio: 0.778635
--- 0.25841593742370605 seconds for one epoch ---
--- 0.33322787284851074 seconds for one epoch ---
--- 0.7675764560699463 seconds for one epoch ---
--- 0.32972002029418945 seconds for one epoch ---
--- 0.7894124984741211 seconds for one epoch ---
--- 0.32921457290649414 seconds for one epoch ---
--- 0.7780611515045166 seconds for one epoch ---
--- 0.32111668586730957 seconds for one epoch ---
--- 0.7799043655395508 seconds for one epoch ---
--- 0.31971049308776855 seconds for one epoch ---
--- 0.8055486679077148 seconds for one epoch ---
--- 0.33530735969543457 seconds for one epoch ---
--- 0.769157886505127 seconds for one epoch ---
--- 0.33203911781311035 seconds for one epoch ---
--- 0.7824404239654541 seconds for one epoch ---
--- 0.3043639659881592 seconds for one epoch ---
--- 0.7732620239257812 seconds for one epoch ---
--- 0.29465770721435547 seconds for one epoch ---
--- 0.7685773372650146 seconds for one epoch ---
--- 0.29227399826049805 seconds for one epoch ---
--- 0.7763681411743164 seconds for one epoch ---
--- 0.2927432060241699 seconds for one epoch ---
--- 0.7339329719543457 seconds for one epoch ---
--- 0.2954690456390381 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15719227]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.7097993]
 [ 0.       ]]
--- 0.2517426013946533 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4120.21337890625, (2092.2002, 0.557607, 2027.3699, 0.08540129)
   validation loss 1345.740966796875, (1015.1296, 0.36712217, 330.15887, 0.08540129)
decoder loss ratio: 39327.882180, decoder SINDy loss  ratio: 0.712694
--- 0.29386162757873535 seconds for one epoch ---
--- 0.7857739925384521 seconds for one epoch ---
--- 0.294497013092041 seconds for one epoch ---
--- 0.7901351451873779 seconds for one epoch ---
--- 0.2946970462799072 seconds for one epoch ---
--- 0.7768619060516357 seconds for one epoch ---
--- 0.2853586673736572 seconds for one epoch ---
--- 0.7739846706390381 seconds for one epoch ---
--- 0.30226755142211914 seconds for one epoch ---
--- 0.7966811656951904 seconds for one epoch ---
--- 0.2970600128173828 seconds for one epoch ---
--- 0.7765953540802002 seconds for one epoch ---
--- 0.2978212833404541 seconds for one epoch ---
--- 0.8018877506256104 seconds for one epoch ---
--- 0.29639720916748047 seconds for one epoch ---
--- 0.772496223449707 seconds for one epoch ---
--- 0.2968888282775879 seconds for one epoch ---
--- 0.7867231369018555 seconds for one epoch ---
--- 0.31060338020324707 seconds for one epoch ---
--- 0.7863309383392334 seconds for one epoch ---
--- 0.29564976692199707 seconds for one epoch ---
--- 0.7881734371185303 seconds for one epoch ---
--- 0.29741811752319336 seconds for one epoch ---
--- 0.7744920253753662 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16274755]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.015881]
 [ 0.      ]]
--- 0.28377246856689453 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3032.908203125, (1238.1597, 1.5030899, 1793.1567, 0.08876268)
   validation loss 1003.1939697265625, (644.0607, 0.30477127, 358.73972, 0.08876268)
decoder loss ratio: 24952.030818, decoder SINDy loss  ratio: 0.774390
--- 0.27155399322509766 seconds for one epoch ---
--- 0.3127624988555908 seconds for one epoch ---
--- 0.7958705425262451 seconds for one epoch ---
--- 0.2982289791107178 seconds for one epoch ---
--- 0.7854359149932861 seconds for one epoch ---
--- 0.296142578125 seconds for one epoch ---
--- 0.7842929363250732 seconds for one epoch ---
--- 0.3083302974700928 seconds for one epoch ---
--- 0.7949292659759521 seconds for one epoch ---
--- 0.2997744083404541 seconds for one epoch ---
--- 0.8089263439178467 seconds for one epoch ---
--- 0.30287647247314453 seconds for one epoch ---
--- 0.8152120113372803 seconds for one epoch ---
--- 0.30075693130493164 seconds for one epoch ---
--- 0.8235878944396973 seconds for one epoch ---
--- 0.2890918254852295 seconds for one epoch ---
--- 0.7834665775299072 seconds for one epoch ---
--- 0.3035585880279541 seconds for one epoch ---
--- 0.8232238292694092 seconds for one epoch ---
--- 0.29200077056884766 seconds for one epoch ---
--- 0.813298225402832 seconds for one epoch ---
--- 0.30164575576782227 seconds for one epoch ---
--- 0.8100512027740479 seconds for one epoch ---
--- 0.29498720169067383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16745429]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.2924495]
 [ 0.       ]]
--- 0.26406073570251465 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3288.33642578125, (2041.8396, 1.2001104, 1245.2048, 0.09172262)
   validation loss 1015.4375, (683.3098, 0.3078474, 331.7281, 0.09172262)
decoder loss ratio: 26472.608490, decoder SINDy loss  ratio: 0.716082
--- 0.2964754104614258 seconds for one epoch ---
--- 0.8132889270782471 seconds for one epoch ---
--- 0.29992055892944336 seconds for one epoch ---
--- 0.8085393905639648 seconds for one epoch ---
--- 0.3138723373413086 seconds for one epoch ---
--- 0.7985498905181885 seconds for one epoch ---
--- 0.3210880756378174 seconds for one epoch ---
--- 0.7980039119720459 seconds for one epoch ---
--- 0.3017446994781494 seconds for one epoch ---
--- 0.8095707893371582 seconds for one epoch ---
--- 0.2816028594970703 seconds for one epoch ---
--- 0.8000173568725586 seconds for one epoch ---
--- 0.2934122085571289 seconds for one epoch ---
--- 0.8318605422973633 seconds for one epoch ---
--- 0.29817795753479004 seconds for one epoch ---
--- 0.8106505870819092 seconds for one epoch ---
--- 0.3180811405181885 seconds for one epoch ---
--- 0.8019537925720215 seconds for one epoch ---
--- 0.2941017150878906 seconds for one epoch ---
--- 0.8092696666717529 seconds for one epoch ---
--- 0.29361438751220703 seconds for one epoch ---
--- 0.8013155460357666 seconds for one epoch ---
--- 0.30046892166137695 seconds for one epoch ---
--- 0.809840202331543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17189881]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.572886]
 [ 0.      ]]
--- 0.3162093162536621 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3209.757568359375, (1440.5082, 2.1328354, 1767.0219, 0.09470443)
   validation loss 1328.8416748046875, (928.67804, 0.395772, 399.6732, 0.09470443)
decoder loss ratio: 35978.599508, decoder SINDy loss  ratio: 0.862751
--- 0.2589302062988281 seconds for one epoch ---
--- 0.3375234603881836 seconds for one epoch ---
--- 0.8361825942993164 seconds for one epoch ---
--- 0.32566118240356445 seconds for one epoch ---
--- 0.8441026210784912 seconds for one epoch ---
--- 0.32923269271850586 seconds for one epoch ---
--- 0.8327798843383789 seconds for one epoch ---
--- 0.3264482021331787 seconds for one epoch ---
--- 0.8331961631774902 seconds for one epoch ---
--- 0.31143641471862793 seconds for one epoch ---
--- 0.8465127944946289 seconds for one epoch ---
--- 0.33319544792175293 seconds for one epoch ---
--- 0.8235905170440674 seconds for one epoch ---
--- 0.33266282081604004 seconds for one epoch ---
--- 0.8703811168670654 seconds for one epoch ---
--- 0.3316683769226074 seconds for one epoch ---
--- 0.8326151371002197 seconds for one epoch ---
--- 0.29731249809265137 seconds for one epoch ---
--- 0.8387875556945801 seconds for one epoch ---
--- 0.3034336566925049 seconds for one epoch ---
--- 0.8280797004699707 seconds for one epoch ---
--- 0.29810023307800293 seconds for one epoch ---
--- 0.8214702606201172 seconds for one epoch ---
--- 0.27076244354248047 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17511176]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.791541]
 [-0.      ]]
--- 0.2574739456176758 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5607.86962890625, (1391.9161, 2.25895, 4213.5977, 0.0969952)
   validation loss 1164.5841064453125, (755.4009, 0.322659, 408.76352, 0.0969952)
decoder loss ratio: 29265.541482, decoder SINDy loss  ratio: 0.882374
--- 0.2824537754058838 seconds for one epoch ---
--- 0.8056850433349609 seconds for one epoch ---
--- 0.3146202564239502 seconds for one epoch ---
--- 0.8117058277130127 seconds for one epoch ---
--- 0.30064964294433594 seconds for one epoch ---
--- 0.8293850421905518 seconds for one epoch ---
--- 0.2978084087371826 seconds for one epoch ---
--- 0.838789701461792 seconds for one epoch ---
--- 0.2958991527557373 seconds for one epoch ---
--- 0.8678610324859619 seconds for one epoch ---
--- 0.3015737533569336 seconds for one epoch ---
--- 0.871272087097168 seconds for one epoch ---
--- 0.2891669273376465 seconds for one epoch ---
--- 0.8192963600158691 seconds for one epoch ---
--- 0.3122866153717041 seconds for one epoch ---
--- 0.8192195892333984 seconds for one epoch ---
--- 0.2974860668182373 seconds for one epoch ---
--- 0.8291316032409668 seconds for one epoch ---
--- 0.2930123805999756 seconds for one epoch ---
--- 0.8378591537475586 seconds for one epoch ---
--- 0.2997257709503174 seconds for one epoch ---
--- 0.8364403247833252 seconds for one epoch ---
--- 0.2941138744354248 seconds for one epoch ---
--- 0.8235321044921875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17849466]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.0406666]
 [ 0.       ]]
--- 0.29657673835754395 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3139.692138671875, (1497.5659, 2.9521759, 1639.0748, 0.09948655)
   validation loss 1687.892822265625, (1356.5137, 0.34166592, 330.93802, 0.09948655)
decoder loss ratio: 52553.694660, decoder SINDy loss  ratio: 0.714376
--- 0.26195740699768066 seconds for one epoch ---
--- 0.291914701461792 seconds for one epoch ---
--- 0.8764746189117432 seconds for one epoch ---
--- 0.3092679977416992 seconds for one epoch ---
--- 0.8309719562530518 seconds for one epoch ---
--- 0.2946619987487793 seconds for one epoch ---
--- 0.819939136505127 seconds for one epoch ---
--- 0.295473575592041 seconds for one epoch ---
--- 0.8528528213500977 seconds for one epoch ---
--- 0.2911677360534668 seconds for one epoch ---
--- 0.8785562515258789 seconds for one epoch ---
--- 0.2948732376098633 seconds for one epoch ---
--- 0.8855123519897461 seconds for one epoch ---
--- 0.30797886848449707 seconds for one epoch ---
--- 0.8823151588439941 seconds for one epoch ---
--- 0.24928736686706543 seconds for one epoch ---
--- 0.842628002166748 seconds for one epoch ---
--- 0.2764768600463867 seconds for one epoch ---
--- 0.8502559661865234 seconds for one epoch ---
--- 0.29941701889038086 seconds for one epoch ---
--- 0.8479433059692383 seconds for one epoch ---
--- 0.2955472469329834 seconds for one epoch ---
--- 0.842803955078125 seconds for one epoch ---
--- 0.29358553886413574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18113603]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.2537913]
 [ 0.       ]]
--- 0.25849437713623047 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2819.79638671875, (1431.0887, 1.7833586, 1386.8226, 0.10168121)
   validation loss 1143.5306396484375, (780.3804, 0.3098644, 362.73865, 0.10168121)
decoder loss ratio: 30233.290376, decoder SINDy loss  ratio: 0.783022
--- 0.297443151473999 seconds for one epoch ---
--- 0.8175451755523682 seconds for one epoch ---
--- 0.28369688987731934 seconds for one epoch ---
--- 0.8316004276275635 seconds for one epoch ---
--- 0.2973592281341553 seconds for one epoch ---
--- 0.8370931148529053 seconds for one epoch ---
--- 0.29840731620788574 seconds for one epoch ---
--- 0.8263046741485596 seconds for one epoch ---
--- 0.28969717025756836 seconds for one epoch ---
--- 0.8276546001434326 seconds for one epoch ---
--- 0.2966902256011963 seconds for one epoch ---
--- 0.8547887802124023 seconds for one epoch ---
--- 0.3061830997467041 seconds for one epoch ---
--- 0.8482766151428223 seconds for one epoch ---
--- 0.29813146591186523 seconds for one epoch ---
--- 0.8774690628051758 seconds for one epoch ---
--- 0.3083620071411133 seconds for one epoch ---
--- 0.8602094650268555 seconds for one epoch ---
--- 0.296278715133667 seconds for one epoch ---
--- 0.8632702827453613 seconds for one epoch ---
--- 0.299868106842041 seconds for one epoch ---
--- 0.8748035430908203 seconds for one epoch ---
--- 0.29674601554870605 seconds for one epoch ---
--- 0.8605406284332275 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18358459]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.4712152]
 [-0.       ]]
--- 0.2777228355407715 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3757.178466796875, (1259.6483, 1.183791, 2496.2427, 0.10385273)
   validation loss 2174.697509765625, (1757.4692, 0.3390266, 416.78543, 0.10385273)
decoder loss ratio: 68087.409392, decoder SINDy loss  ratio: 0.899690
--- 0.27924013137817383 seconds for one epoch ---
--- 0.29434895515441895 seconds for one epoch ---
--- 0.8765459060668945 seconds for one epoch ---
--- 0.3185572624206543 seconds for one epoch ---
--- 0.8744876384735107 seconds for one epoch ---
--- 0.30061888694763184 seconds for one epoch ---
--- 0.8632478713989258 seconds for one epoch ---
--- 0.3024425506591797 seconds for one epoch ---
--- 0.911252498626709 seconds for one epoch ---
--- 0.29839515686035156 seconds for one epoch ---
--- 0.8679399490356445 seconds for one epoch ---
--- 0.30698299407958984 seconds for one epoch ---
--- 0.8795750141143799 seconds for one epoch ---
--- 0.3102869987487793 seconds for one epoch ---
--- 0.884352445602417 seconds for one epoch ---
--- 0.30502748489379883 seconds for one epoch ---
--- 0.8730688095092773 seconds for one epoch ---
--- 0.49208641052246094 seconds for one epoch ---
--- 0.8431980609893799 seconds for one epoch ---
--- 0.2994987964630127 seconds for one epoch ---
--- 0.8500595092773438 seconds for one epoch ---
--- 0.2780342102050781 seconds for one epoch ---
--- 0.8707237243652344 seconds for one epoch ---
--- 0.2963113784790039 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18581627]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.6931424]
 [-0.       ]]
--- 0.2553539276123047 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4042.150390625, (1957.5616, 0.39789492, 2084.085, 0.10606165)
   validation loss 1194.160400390625, (819.3004, 0.4076627, 374.34628, 0.10606165)
decoder loss ratio: 31741.120447, decoder SINDy loss  ratio: 0.808079
--- 0.30760741233825684 seconds for one epoch ---
--- 0.8788411617279053 seconds for one epoch ---
--- 0.3269388675689697 seconds for one epoch ---
--- 0.8587319850921631 seconds for one epoch ---
--- 0.3257765769958496 seconds for one epoch ---
--- 0.8732824325561523 seconds for one epoch ---
--- 0.32291316986083984 seconds for one epoch ---
--- 0.8932459354400635 seconds for one epoch ---
--- 0.33706235885620117 seconds for one epoch ---
--- 0.8851518630981445 seconds for one epoch ---
--- 0.3212728500366211 seconds for one epoch ---
--- 0.8756117820739746 seconds for one epoch ---
--- 0.3343634605407715 seconds for one epoch ---
--- 0.8899927139282227 seconds for one epoch ---
--- 0.32228589057922363 seconds for one epoch ---
--- 0.883244514465332 seconds for one epoch ---
--- 0.3265039920806885 seconds for one epoch ---
--- 0.8620879650115967 seconds for one epoch ---
--- 0.320786714553833 seconds for one epoch ---
--- 0.8812024593353271 seconds for one epoch ---
--- 0.30069947242736816 seconds for one epoch ---
--- 0.8745975494384766 seconds for one epoch ---
--- 0.29851460456848145 seconds for one epoch ---
--- 0.8714253902435303 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18760721]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.8952837]
 [ 0.       ]]
--- 0.29011082649230957 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2991.16552734375, (1127.3558, 2.1076038, 1861.5942, 0.10793775)
   validation loss 1073.462646484375, (729.1052, 0.40816697, 343.8414, 0.10793775)
decoder loss ratio: 28246.802184, decoder SINDy loss  ratio: 0.742230
--- 0.2582206726074219 seconds for one epoch ---
--- 0.29881763458251953 seconds for one epoch ---
--- 0.8716659545898438 seconds for one epoch ---
--- 0.31350159645080566 seconds for one epoch ---
--- 0.8623456954956055 seconds for one epoch ---
--- 0.31793904304504395 seconds for one epoch ---
--- 0.8995180130004883 seconds for one epoch ---
--- 0.3082270622253418 seconds for one epoch ---
--- 0.9034905433654785 seconds for one epoch ---
--- 0.3033630847930908 seconds for one epoch ---
--- 0.8892452716827393 seconds for one epoch ---
--- 0.2961738109588623 seconds for one epoch ---
--- 0.8863120079040527 seconds for one epoch ---
--- 0.31058335304260254 seconds for one epoch ---
--- 0.9045143127441406 seconds for one epoch ---
--- 0.29900622367858887 seconds for one epoch ---
--- 0.8913419246673584 seconds for one epoch ---
--- 0.3002665042877197 seconds for one epoch ---
--- 0.8778162002563477 seconds for one epoch ---
--- 0.3157041072845459 seconds for one epoch ---
--- 0.8868248462677002 seconds for one epoch ---
--- 0.2995727062225342 seconds for one epoch ---
--- 0.8796124458312988 seconds for one epoch ---
--- 0.29680919647216797 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18928438]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.114843]
 [ 0.      ]]
--- 0.24634909629821777 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2546.3779296875, (1490.5519, 1.4955082, 1054.2208, 0.109928206)
   validation loss 904.0265502929688, (558.96783, 0.48751506, 344.46127, 0.109928206)
decoder loss ratio: 21655.384318, decoder SINDy loss  ratio: 0.743568
--- 0.30092453956604004 seconds for one epoch ---
--- 0.8795459270477295 seconds for one epoch ---
--- 0.28922224044799805 seconds for one epoch ---
--- 0.8758940696716309 seconds for one epoch ---
--- 0.3030712604522705 seconds for one epoch ---
--- 0.9057960510253906 seconds for one epoch ---
--- 0.3080885410308838 seconds for one epoch ---
--- 0.8888421058654785 seconds for one epoch ---
--- 0.29254841804504395 seconds for one epoch ---
--- 0.9066252708435059 seconds for one epoch ---
--- 0.2992680072784424 seconds for one epoch ---
--- 0.9077394008636475 seconds for one epoch ---
--- 0.29790687561035156 seconds for one epoch ---
--- 0.9187979698181152 seconds for one epoch ---
--- 0.30832910537719727 seconds for one epoch ---
--- 0.903677225112915 seconds for one epoch ---
--- 0.30746936798095703 seconds for one epoch ---
--- 0.914980411529541 seconds for one epoch ---
--- 0.29302144050598145 seconds for one epoch ---
--- 0.8815410137176514 seconds for one epoch ---
--- 0.29859399795532227 seconds for one epoch ---
--- 0.9272029399871826 seconds for one epoch ---
--- 0.2878763675689697 seconds for one epoch ---
--- 0.9124875068664551 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19044966]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.295427]
 [-0.      ]]
--- 0.2912156581878662 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2719.589111328125, (1102.1063, 4.9290657, 1612.442, 0.11159058)
   validation loss 943.94091796875, (603.1927, 0.3298791, 340.30676, 0.11159058)
decoder loss ratio: 23368.731921, decoder SINDy loss  ratio: 0.734600
--- 0.25260210037231445 seconds for one epoch ---
--- 0.2877073287963867 seconds for one epoch ---
--- 0.8716182708740234 seconds for one epoch ---
--- 0.2859055995941162 seconds for one epoch ---
--- 0.906144380569458 seconds for one epoch ---
--- 0.2883901596069336 seconds for one epoch ---
--- 0.8940324783325195 seconds for one epoch ---
--- 0.28346943855285645 seconds for one epoch ---
--- 0.9210278987884521 seconds for one epoch ---
--- 0.2908191680908203 seconds for one epoch ---
--- 0.9246194362640381 seconds for one epoch ---
--- 0.2934739589691162 seconds for one epoch ---
--- 0.9022235870361328 seconds for one epoch ---
--- 0.3038291931152344 seconds for one epoch ---
--- 0.9097297191619873 seconds for one epoch ---
--- 0.29882097244262695 seconds for one epoch ---
--- 0.9233050346374512 seconds for one epoch ---
--- 0.27686285972595215 seconds for one epoch ---
--- 0.8966779708862305 seconds for one epoch ---
--- 0.2982020378112793 seconds for one epoch ---
--- 0.923551082611084 seconds for one epoch ---
--- 0.2908306121826172 seconds for one epoch ---
--- 0.9200365543365479 seconds for one epoch ---
--- 0.29475831985473633 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19147396]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.487438]
 [-0.      ]]
--- 0.2831542491912842 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4584.57080078125, (1563.5066, 0.82363504, 3020.1272, 0.113313675)
   validation loss 1403.612060546875, (1086.3999, 0.35586873, 316.74298, 0.113313675)
decoder loss ratio: 42089.018290, decoder SINDy loss  ratio: 0.683734
--- 0.29816174507141113 seconds for one epoch ---
--- 0.9267654418945312 seconds for one epoch ---
--- 0.2965812683105469 seconds for one epoch ---
--- 0.9314477443695068 seconds for one epoch ---
--- 0.2912130355834961 seconds for one epoch ---
--- 0.9128808975219727 seconds for one epoch ---
--- 0.29842567443847656 seconds for one epoch ---
--- 0.9109129905700684 seconds for one epoch ---
--- 0.29024767875671387 seconds for one epoch ---
--- 0.9425303936004639 seconds for one epoch ---
--- 0.3004434108734131 seconds for one epoch ---
--- 0.9342570304870605 seconds for one epoch ---
--- 0.30925440788269043 seconds for one epoch ---
--- 0.9536290168762207 seconds for one epoch ---
--- 0.30378055572509766 seconds for one epoch ---
--- 0.9393551349639893 seconds for one epoch ---
--- 0.30582547187805176 seconds for one epoch ---
--- 0.9462010860443115 seconds for one epoch ---
--- 0.3036525249481201 seconds for one epoch ---
--- 0.9174621105194092 seconds for one epoch ---
--- 0.31468653678894043 seconds for one epoch ---
--- 0.9259545803070068 seconds for one epoch ---
--- 0.2936718463897705 seconds for one epoch ---
--- 0.9245209693908691 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19222009]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.664542]
 [ 0.      ]]
--- 0.3090817928314209 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3632.407470703125, (1291.409, 1.5888196, 2339.2944, 0.114941)
   validation loss 1204.6221923828125, (811.6448, 0.481328, 392.38107, 0.114941)
decoder loss ratio: 31444.527676, decoder SINDy loss  ratio: 0.847010
--- 0.2913694381713867 seconds for one epoch ---
--- 0.3181943893432617 seconds for one epoch ---
--- 0.9165935516357422 seconds for one epoch ---
--- 0.3134727478027344 seconds for one epoch ---
--- 0.9244174957275391 seconds for one epoch ---
--- 0.32912135124206543 seconds for one epoch ---
--- 0.9351885318756104 seconds for one epoch ---
--- 0.3351414203643799 seconds for one epoch ---
--- 0.9479987621307373 seconds for one epoch ---
--- 0.3405423164367676 seconds for one epoch ---
--- 0.9515054225921631 seconds for one epoch ---
--- 0.3285653591156006 seconds for one epoch ---
--- 0.9485652446746826 seconds for one epoch ---
--- 0.33335089683532715 seconds for one epoch ---
--- 0.925532341003418 seconds for one epoch ---
--- 0.3232712745666504 seconds for one epoch ---
--- 0.9578311443328857 seconds for one epoch ---
--- 0.3130013942718506 seconds for one epoch ---
--- 0.93166184425354 seconds for one epoch ---
--- 0.31131625175476074 seconds for one epoch ---
--- 0.9445376396179199 seconds for one epoch ---
--- 0.3137655258178711 seconds for one epoch ---
--- 0.9419081211090088 seconds for one epoch ---
--- 0.3026556968688965 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.192747]
 [0.      ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.831599]
 [ 0.      ]]
--- 0.26111316680908203 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6164.9296875, (1399.4773, 2.4641647, 4762.872, 0.11634512)
   validation loss 1367.7523193359375, (1023.24567, 0.48339227, 343.90686, 0.11634512)
decoder loss ratio: 39642.313553, decoder SINDy loss  ratio: 0.742371
--- 0.30716872215270996 seconds for one epoch ---
--- 0.932098388671875 seconds for one epoch ---
--- 0.3121485710144043 seconds for one epoch ---
--- 0.9375545978546143 seconds for one epoch ---
--- 0.29169273376464844 seconds for one epoch ---
--- 0.9355459213256836 seconds for one epoch ---
--- 0.30711984634399414 seconds for one epoch ---
--- 0.9359622001647949 seconds for one epoch ---
--- 0.2887091636657715 seconds for one epoch ---
--- 0.9364748001098633 seconds for one epoch ---
--- 0.296567440032959 seconds for one epoch ---
--- 0.9371991157531738 seconds for one epoch ---
--- 0.29770350456237793 seconds for one epoch ---
--- 0.9250407218933105 seconds for one epoch ---
--- 0.2968437671661377 seconds for one epoch ---
--- 0.9554500579833984 seconds for one epoch ---
--- 0.2951653003692627 seconds for one epoch ---
--- 0.9546000957489014 seconds for one epoch ---
--- 0.29872941970825195 seconds for one epoch ---
--- 0.9667432308197021 seconds for one epoch ---
--- 0.3041505813598633 seconds for one epoch ---
--- 0.9362728595733643 seconds for one epoch ---
--- 0.2922017574310303 seconds for one epoch ---
--- 0.9441099166870117 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19312796]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.015325]
 [-0.      ]]
--- 0.2922217845916748 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3077.9609375, (1511.0264, 0.663008, 1566.1537, 0.117867164)
   validation loss 1033.6978759765625, (699.5127, 0.36664355, 333.70065, 0.117867164)
decoder loss ratio: 27100.336224, decoder SINDy loss  ratio: 0.720340
--- 0.2889547348022461 seconds for one epoch ---
--- 0.31387877464294434 seconds for one epoch ---
--- 0.9615917205810547 seconds for one epoch ---
--- 0.3037526607513428 seconds for one epoch ---
--- 0.9673054218292236 seconds for one epoch ---
--- 0.3116319179534912 seconds for one epoch ---
--- 0.9498617649078369 seconds for one epoch ---
--- 0.3105480670928955 seconds for one epoch ---
--- 0.966465950012207 seconds for one epoch ---
--- 0.31087517738342285 seconds for one epoch ---
--- 0.9750616550445557 seconds for one epoch ---
--- 0.29895544052124023 seconds for one epoch ---
--- 0.9710421562194824 seconds for one epoch ---
--- 0.3096294403076172 seconds for one epoch ---
--- 0.9767317771911621 seconds for one epoch ---
--- 0.3167095184326172 seconds for one epoch ---
--- 0.9863193035125732 seconds for one epoch ---
--- 0.3190164566040039 seconds for one epoch ---
--- 0.9772014617919922 seconds for one epoch ---
--- 0.3087584972381592 seconds for one epoch ---
--- 0.9790112972259521 seconds for one epoch ---
--- 0.3169667720794678 seconds for one epoch ---
--- 1.0042955875396729 seconds for one epoch ---
--- 0.2949976921081543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19328912]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.176615]
 [-0.      ]]
--- 0.25703859329223633 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2969.65478515625, (1723.8667, 2.3463583, 1243.3228, 0.11917322)
   validation loss 1204.0638427734375, (822.08813, 0.46461943, 381.392, 0.11917322)
decoder loss ratio: 31849.121549, decoder SINDy loss  ratio: 0.823288
--- 0.2952461242675781 seconds for one epoch ---
--- 0.9635989665985107 seconds for one epoch ---
--- 0.3003685474395752 seconds for one epoch ---
--- 0.9688990116119385 seconds for one epoch ---
--- 0.30088162422180176 seconds for one epoch ---
--- 0.9383025169372559 seconds for one epoch ---
--- 0.30144405364990234 seconds for one epoch ---
--- 0.9404823780059814 seconds for one epoch ---
--- 0.3146028518676758 seconds for one epoch ---
--- 0.9624943733215332 seconds for one epoch ---
--- 0.2870051860809326 seconds for one epoch ---
--- 0.9792385101318359 seconds for one epoch ---
--- 0.31398749351501465 seconds for one epoch ---
--- 0.9778516292572021 seconds for one epoch ---
--- 0.29987406730651855 seconds for one epoch ---
--- 0.9651474952697754 seconds for one epoch ---
--- 0.307476282119751 seconds for one epoch ---
--- 0.9937870502471924 seconds for one epoch ---
--- 0.29741430282592773 seconds for one epoch ---
--- 0.9799501895904541 seconds for one epoch ---
--- 0.3090705871582031 seconds for one epoch ---
--- 0.9712545871734619 seconds for one epoch ---
--- 0.3034071922302246 seconds for one epoch ---
--- 0.9827189445495605 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19329536]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.323176]
 [ 0.      ]]
--- 0.28854942321777344 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3616.692138671875, (1686.4806, 0.97357535, 1929.1176, 0.12027957)
   validation loss 914.3140258789062, (540.1993, 0.5630264, 373.4314, 0.12027957)
decoder loss ratio: 20928.257926, decoder SINDy loss  ratio: 0.806104
THRESHOLDING: 1 active coefficients
--- 0.2507503032684326 seconds for one epoch ---
--- 0.2800638675689697 seconds for one epoch ---
--- 0.9602432250976562 seconds for one epoch ---
--- 0.2939765453338623 seconds for one epoch ---
--- 0.964630126953125 seconds for one epoch ---
--- 0.2998075485229492 seconds for one epoch ---
--- 0.9737644195556641 seconds for one epoch ---
--- 0.30408406257629395 seconds for one epoch ---
--- 0.9884099960327148 seconds for one epoch ---
--- 0.29732775688171387 seconds for one epoch ---
--- 0.9699971675872803 seconds for one epoch ---
--- 0.2849006652832031 seconds for one epoch ---
--- 0.9336748123168945 seconds for one epoch ---
--- 0.2824056148529053 seconds for one epoch ---
--- 0.9692046642303467 seconds for one epoch ---
--- 0.280714750289917 seconds for one epoch ---
--- 0.9637665748596191 seconds for one epoch ---
--- 0.29975438117980957 seconds for one epoch ---
--- 0.9653496742248535 seconds for one epoch ---
--- 0.2970125675201416 seconds for one epoch ---
--- 0.9739944934844971 seconds for one epoch ---
--- 0.2985115051269531 seconds for one epoch ---
--- 0.9888346195220947 seconds for one epoch ---
--- 0.2975935935974121 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1931581]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.476934]
 [ 0.      ]]
--- 0.25538015365600586 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3847.33154296875, (1624.1107, 1.1600779, 2221.9521, 0.10857662)
   validation loss 1138.17138671875, (740.847, 0.56926113, 396.64664, 0.10857662)
decoder loss ratio: 28701.698361, decoder SINDy loss  ratio: 0.856218
--- 0.3056302070617676 seconds for one epoch ---
--- 0.954658031463623 seconds for one epoch ---
--- 0.31253957748413086 seconds for one epoch ---
--- 1.0000927448272705 seconds for one epoch ---
--- 0.3105313777923584 seconds for one epoch ---
--- 1.0119380950927734 seconds for one epoch ---
--- 0.32259511947631836 seconds for one epoch ---
--- 0.9952080249786377 seconds for one epoch ---
--- 0.32035040855407715 seconds for one epoch ---
--- 0.9657657146453857 seconds for one epoch ---
--- 0.3174748420715332 seconds for one epoch ---
--- 0.9827272891998291 seconds for one epoch ---
--- 0.31511425971984863 seconds for one epoch ---
--- 0.9974205493927002 seconds for one epoch ---
--- 0.31920504570007324 seconds for one epoch ---
--- 1.0052211284637451 seconds for one epoch ---
--- 0.31322216987609863 seconds for one epoch ---
--- 0.998483419418335 seconds for one epoch ---
--- 0.30263614654541016 seconds for one epoch ---
--- 1.0130319595336914 seconds for one epoch ---
--- 0.3014650344848633 seconds for one epoch ---
--- 0.9885659217834473 seconds for one epoch ---
--- 0.3027348518371582 seconds for one epoch ---
--- 0.9889647960662842 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19294259]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.599799]
 [-0.      ]]
--- 0.29569387435913086 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3427.098388671875, (1389.4933, 2.1728308, 2035.3226, 0.109521925)
   validation loss 1788.8314208984375, (1446.2897, 0.5507127, 341.8816, 0.109521925)
decoder loss ratio: 56031.772796, decoder SINDy loss  ratio: 0.738000
--- 0.2639157772064209 seconds for one epoch ---
--- 0.28517866134643555 seconds for one epoch ---
--- 0.9698264598846436 seconds for one epoch ---
--- 0.28711915016174316 seconds for one epoch ---
--- 0.9731969833374023 seconds for one epoch ---
--- 0.30531835556030273 seconds for one epoch ---
--- 0.9934186935424805 seconds for one epoch ---
--- 0.29628944396972656 seconds for one epoch ---
--- 1.0008063316345215 seconds for one epoch ---
--- 0.2924234867095947 seconds for one epoch ---
--- 0.9823215007781982 seconds for one epoch ---
--- 0.2941732406616211 seconds for one epoch ---
--- 1.0001587867736816 seconds for one epoch ---
--- 0.30089282989501953 seconds for one epoch ---
--- 1.0104167461395264 seconds for one epoch ---
--- 0.301741361618042 seconds for one epoch ---
--- 1.0066986083984375 seconds for one epoch ---
--- 0.29985928535461426 seconds for one epoch ---
--- 1.026726484298706 seconds for one epoch ---
--- 0.30356931686401367 seconds for one epoch ---
--- 1.018343210220337 seconds for one epoch ---
--- 0.29947423934936523 seconds for one epoch ---
--- 1.0043315887451172 seconds for one epoch ---
--- 0.303086519241333 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19258785]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-9.738162]
 [-0.      ]]
--- 0.2798943519592285 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4671.42724609375, (2030.5433, 3.383063, 2637.3906, 0.11054819)
   validation loss 1126.1910400390625, (766.0766, 0.46772236, 359.5361, 0.11054819)
decoder loss ratio: 29679.137417, decoder SINDy loss  ratio: 0.776109
--- 0.3040769100189209 seconds for one epoch ---
--- 1.0151920318603516 seconds for one epoch ---
--- 0.3020029067993164 seconds for one epoch ---
--- 1.0097651481628418 seconds for one epoch ---
--- 0.2952394485473633 seconds for one epoch ---
--- 1.0398776531219482 seconds for one epoch ---
--- 0.31492018699645996 seconds for one epoch ---
--- 0.9801371097564697 seconds for one epoch ---
--- 0.31385159492492676 seconds for one epoch ---
--- 1.0426990985870361 seconds for one epoch ---
--- 0.31705594062805176 seconds for one epoch ---
--- 1.0347046852111816 seconds for one epoch ---
--- 0.3246431350708008 seconds for one epoch ---
--- 1.0315451622009277 seconds for one epoch ---
--- 0.3144693374633789 seconds for one epoch ---
--- 1.0177247524261475 seconds for one epoch ---
--- 0.32280755043029785 seconds for one epoch ---
--- 1.0237932205200195 seconds for one epoch ---
--- 0.32042479515075684 seconds for one epoch ---
--- 1.0338168144226074 seconds for one epoch ---
--- 0.3108103275299072 seconds for one epoch ---
--- 1.0450377464294434 seconds for one epoch ---
--- 0.3106846809387207 seconds for one epoch ---
--- 1.0500891208648682 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19203866]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.896245]
 [ 0.      ]]
--- 0.2862997055053711 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3746.98046875, (1921.9382, 3.1319394, 1821.7983, 0.11172807)
   validation loss 1176.345458984375, (830.47974, 0.5788241, 345.17523, 0.11172807)
decoder loss ratio: 32174.226762, decoder SINDy loss  ratio: 0.745109
--- 0.2719309329986572 seconds for one epoch ---
--- 0.31618309020996094 seconds for one epoch ---
--- 1.0415887832641602 seconds for one epoch ---
--- 0.32335829734802246 seconds for one epoch ---
--- 1.0321331024169922 seconds for one epoch ---
--- 0.34371352195739746 seconds for one epoch ---
--- 1.017942190170288 seconds for one epoch ---
--- 0.3363659381866455 seconds for one epoch ---
--- 1.0320537090301514 seconds for one epoch ---
--- 0.33756327629089355 seconds for one epoch ---
--- 1.0241777896881104 seconds for one epoch ---
--- 0.3412761688232422 seconds for one epoch ---
--- 1.0462760925292969 seconds for one epoch ---
--- 0.3356325626373291 seconds for one epoch ---
--- 1.0581188201904297 seconds for one epoch ---
--- 0.3311300277709961 seconds for one epoch ---
--- 1.035360336303711 seconds for one epoch ---
--- 0.32707953453063965 seconds for one epoch ---
--- 1.0503482818603516 seconds for one epoch ---
--- 0.3325333595275879 seconds for one epoch ---
--- 1.0699563026428223 seconds for one epoch ---
--- 0.3427753448486328 seconds for one epoch ---
--- 1.0427966117858887 seconds for one epoch ---
--- 0.3362998962402344 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19136615]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.048092]
 [  0.      ]]
--- 0.2639591693878174 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3381.614013671875, (1019.8702, 3.6679308, 2357.9631, 0.11282833)
   validation loss 978.8943481445312, (621.27875, 0.5359298, 356.96683, 0.11282833)
decoder loss ratio: 24069.417268, decoder SINDy loss  ratio: 0.770563
--- 0.2896308898925781 seconds for one epoch ---
--- 1.00111985206604 seconds for one epoch ---
--- 0.30294203758239746 seconds for one epoch ---
--- 1.012305736541748 seconds for one epoch ---
--- 0.28864526748657227 seconds for one epoch ---
--- 0.9991757869720459 seconds for one epoch ---
--- 0.29854679107666016 seconds for one epoch ---
--- 1.018117904663086 seconds for one epoch ---
--- 0.29509902000427246 seconds for one epoch ---
--- 1.0361266136169434 seconds for one epoch ---
--- 0.28921961784362793 seconds for one epoch ---
--- 1.0314488410949707 seconds for one epoch ---
--- 0.3049745559692383 seconds for one epoch ---
--- 1.0175039768218994 seconds for one epoch ---
--- 0.30820322036743164 seconds for one epoch ---
--- 1.0391018390655518 seconds for one epoch ---
--- 0.2930750846862793 seconds for one epoch ---
--- 1.0305562019348145 seconds for one epoch ---
--- 0.3007664680480957 seconds for one epoch ---
--- 1.041057825088501 seconds for one epoch ---
--- 0.29842138290405273 seconds for one epoch ---
--- 1.044454574584961 seconds for one epoch ---
--- 0.3017463684082031 seconds for one epoch ---
--- 1.048206090927124 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19071446]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.171832]
 [ -0.      ]]
--- 0.29045534133911133 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1957.30810546875, (1172.5441, 2.515264, 782.13513, 0.11369177)
   validation loss 1220.8416748046875, (858.8157, 0.5892465, 361.32312, 0.11369177)
decoder loss ratio: 33272.010174, decoder SINDy loss  ratio: 0.779967
--- 0.2567436695098877 seconds for one epoch ---
--- 0.31949520111083984 seconds for one epoch ---
--- 1.0361080169677734 seconds for one epoch ---
--- 0.3046417236328125 seconds for one epoch ---
--- 1.0018951892852783 seconds for one epoch ---
--- 0.2962770462036133 seconds for one epoch ---
--- 1.034837245941162 seconds for one epoch ---
--- 0.3002340793609619 seconds for one epoch ---
--- 1.0457355976104736 seconds for one epoch ---
--- 0.295926570892334 seconds for one epoch ---
--- 1.0514194965362549 seconds for one epoch ---
--- 0.2996852397918701 seconds for one epoch ---
--- 1.0397684574127197 seconds for one epoch ---
--- 0.2933204174041748 seconds for one epoch ---
--- 1.0495624542236328 seconds for one epoch ---
--- 0.27382874488830566 seconds for one epoch ---
--- 1.0387892723083496 seconds for one epoch ---
--- 0.30509161949157715 seconds for one epoch ---
--- 1.0423579216003418 seconds for one epoch ---
--- 0.28958678245544434 seconds for one epoch ---
--- 1.0701415538787842 seconds for one epoch ---
--- 0.2960343360900879 seconds for one epoch ---
--- 1.0511937141418457 seconds for one epoch ---
--- 0.2988004684448242 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18998608]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.293068]
 [ -0.      ]]
--- 0.26200270652770996 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3038.113525390625, (1260.2139, 2.2633073, 1775.5217, 0.11452208)
   validation loss 991.51318359375, (628.0513, 0.69333076, 362.65405, 0.11452208)
decoder loss ratio: 24331.796527, decoder SINDy loss  ratio: 0.782840
--- 0.30443525314331055 seconds for one epoch ---
--- 1.0422964096069336 seconds for one epoch ---
--- 0.308915376663208 seconds for one epoch ---
--- 1.019181489944458 seconds for one epoch ---
--- 0.2917349338531494 seconds for one epoch ---
--- 1.027442455291748 seconds for one epoch ---
--- 0.28856515884399414 seconds for one epoch ---
--- 1.0418322086334229 seconds for one epoch ---
--- 0.29596590995788574 seconds for one epoch ---
--- 1.0786337852478027 seconds for one epoch ---
--- 0.3007931709289551 seconds for one epoch ---
--- 1.0463800430297852 seconds for one epoch ---
--- 0.2929074764251709 seconds for one epoch ---
--- 1.0660107135772705 seconds for one epoch ---
--- 0.30248045921325684 seconds for one epoch ---
--- 1.0521965026855469 seconds for one epoch ---
--- 0.2983705997467041 seconds for one epoch ---
--- 1.0611534118652344 seconds for one epoch ---
--- 0.30979466438293457 seconds for one epoch ---
--- 1.0573158264160156 seconds for one epoch ---
--- 0.29807114601135254 seconds for one epoch ---
--- 1.064957857131958 seconds for one epoch ---
--- 0.3002283573150635 seconds for one epoch ---
--- 1.0766880512237549 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18911833]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.421546]
 [  0.      ]]
--- 0.28756093978881836 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4104.8291015625, (1384.07, 2.4651144, 2718.1787, 0.11538935)
   validation loss 1340.935791015625, (975.55927, 0.47482973, 364.78632, 0.11538935)
decoder loss ratio: 37794.859577, decoder SINDy loss  ratio: 0.787443
--- 0.25848984718322754 seconds for one epoch ---
--- 0.2971930503845215 seconds for one epoch ---
--- 1.071296215057373 seconds for one epoch ---
--- 0.2963273525238037 seconds for one epoch ---
--- 1.0474848747253418 seconds for one epoch ---
--- 0.29717206954956055 seconds for one epoch ---
--- 1.0515422821044922 seconds for one epoch ---
--- 0.29155731201171875 seconds for one epoch ---
--- 1.0747730731964111 seconds for one epoch ---
--- 0.28792619705200195 seconds for one epoch ---
--- 1.319021224975586 seconds for one epoch ---
--- 0.5044822692871094 seconds for one epoch ---
--- 1.0600101947784424 seconds for one epoch ---
--- 0.3068091869354248 seconds for one epoch ---
--- 1.0943663120269775 seconds for one epoch ---
--- 0.29350996017456055 seconds for one epoch ---
--- 1.1013221740722656 seconds for one epoch ---
--- 0.2872183322906494 seconds for one epoch ---
--- 1.0683207511901855 seconds for one epoch ---
--- 0.29337644577026367 seconds for one epoch ---
--- 1.0669476985931396 seconds for one epoch ---
--- 0.2969515323638916 seconds for one epoch ---
--- 1.0957403182983398 seconds for one epoch ---
--- 0.29329705238342285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18808503]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-10.55859]
 [  0.     ]]
--- 0.25353217124938965 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3562.99169921875, (1251.4001, 1.4637256, 2310.0117, 0.11625879)
   validation loss 1073.82861328125, (750.7477, 0.6179221, 322.34683, 0.11625879)
decoder loss ratio: 29085.268504, decoder SINDy loss  ratio: 0.695831
--- 0.28473353385925293 seconds for one epoch ---
--- 1.081587553024292 seconds for one epoch ---
--- 0.2925398349761963 seconds for one epoch ---
--- 1.070615530014038 seconds for one epoch ---
--- 0.2850203514099121 seconds for one epoch ---
--- 1.0873026847839355 seconds for one epoch ---
--- 0.28003621101379395 seconds for one epoch ---
--- 1.103834629058838 seconds for one epoch ---
--- 0.2961618900299072 seconds for one epoch ---
--- 1.0928359031677246 seconds for one epoch ---
--- 0.2926352024078369 seconds for one epoch ---
--- 1.0871920585632324 seconds for one epoch ---
--- 0.297992467880249 seconds for one epoch ---
--- 1.0878264904022217 seconds for one epoch ---
--- 0.30284738540649414 seconds for one epoch ---
--- 1.0777218341827393 seconds for one epoch ---
--- 0.2928926944732666 seconds for one epoch ---
--- 1.1047348976135254 seconds for one epoch ---
--- 0.2842390537261963 seconds for one epoch ---
--- 1.100456714630127 seconds for one epoch ---
--- 0.29953575134277344 seconds for one epoch ---
--- 1.0828700065612793 seconds for one epoch ---
--- 0.2933471202850342 seconds for one epoch ---
--- 1.0781729221343994 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18712677]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.674297]
 [ -0.      ]]
--- 0.2910137176513672 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4937.310546875, (1766.474, 3.3590257, 3167.3606, 0.11699064)
   validation loss 1050.0289306640625, (718.18115, 0.6572757, 331.07355, 0.11699064)
decoder loss ratio: 27823.584659, decoder SINDy loss  ratio: 0.714669
--- 0.2748444080352783 seconds for one epoch ---
--- 0.30303025245666504 seconds for one epoch ---
--- 1.0696454048156738 seconds for one epoch ---
--- 0.30020689964294434 seconds for one epoch ---
--- 1.102640151977539 seconds for one epoch ---
--- 0.30179476737976074 seconds for one epoch ---
--- 1.0939311981201172 seconds for one epoch ---
--- 0.2959461212158203 seconds for one epoch ---
--- 1.111729383468628 seconds for one epoch ---
--- 0.3034505844116211 seconds for one epoch ---
--- 1.090379238128662 seconds for one epoch ---
--- 0.3079953193664551 seconds for one epoch ---
--- 1.1205334663391113 seconds for one epoch ---
--- 0.30519747734069824 seconds for one epoch ---
--- 1.0931181907653809 seconds for one epoch ---
--- 0.31242871284484863 seconds for one epoch ---
--- 1.1058895587921143 seconds for one epoch ---
--- 0.2978229522705078 seconds for one epoch ---
--- 1.1083738803863525 seconds for one epoch ---
--- 0.303363561630249 seconds for one epoch ---
--- 1.1183342933654785 seconds for one epoch ---
--- 0.29539012908935547 seconds for one epoch ---
--- 1.1175227165222168 seconds for one epoch ---
--- 0.31047892570495605 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18625176]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.772639]
 [ -0.      ]]
--- 0.2701437473297119 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2644.466796875, (1594.9514, 0.60839415, 1048.7893, 0.11763813)
   validation loss 1274.33740234375, (917.8772, 0.6328289, 355.70978, 0.11763813)
decoder loss ratio: 35560.156127, decoder SINDy loss  ratio: 0.767850
--- 0.296123743057251 seconds for one epoch ---
--- 1.0954279899597168 seconds for one epoch ---
--- 0.30150794982910156 seconds for one epoch ---
--- 1.1260986328125 seconds for one epoch ---
--- 0.30596208572387695 seconds for one epoch ---
--- 1.1142785549163818 seconds for one epoch ---
--- 0.29864001274108887 seconds for one epoch ---
--- 1.0815918445587158 seconds for one epoch ---
--- 0.31902050971984863 seconds for one epoch ---
--- 1.1175720691680908 seconds for one epoch ---
--- 0.29555463790893555 seconds for one epoch ---
--- 1.1116206645965576 seconds for one epoch ---
--- 0.3110041618347168 seconds for one epoch ---
--- 1.1205263137817383 seconds for one epoch ---
--- 0.3118438720703125 seconds for one epoch ---
--- 1.1337685585021973 seconds for one epoch ---
--- 0.30216360092163086 seconds for one epoch ---
--- 1.116720199584961 seconds for one epoch ---
--- 0.3099956512451172 seconds for one epoch ---
--- 1.1297812461853027 seconds for one epoch ---
--- 0.3257124423980713 seconds for one epoch ---
--- 1.153963327407837 seconds for one epoch ---
--- 0.31265997886657715 seconds for one epoch ---
--- 1.1390964984893799 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18528387]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.874827]
 [  0.      ]]
--- 0.3042867183685303 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3457.3720703125, (1252.8412, 11.143669, 2193.269, 0.11825188)
   validation loss 762.8276977539062, (451.51736, 0.55461794, 310.6375, 0.11825188)
decoder loss ratio: 17492.566569, decoder SINDy loss  ratio: 0.670555
--- 0.25153064727783203 seconds for one epoch ---
--- 0.26650404930114746 seconds for one epoch ---
--- 1.1101007461547852 seconds for one epoch ---
--- 0.3170278072357178 seconds for one epoch ---
--- 1.0892789363861084 seconds for one epoch ---
--- 0.27909278869628906 seconds for one epoch ---
--- 1.0873630046844482 seconds for one epoch ---
--- 0.28079843521118164 seconds for one epoch ---
--- 1.083542823791504 seconds for one epoch ---
--- 0.2978227138519287 seconds for one epoch ---
--- 1.1134133338928223 seconds for one epoch ---
--- 0.30059075355529785 seconds for one epoch ---
--- 1.115990400314331 seconds for one epoch ---
--- 0.3018507957458496 seconds for one epoch ---
--- 1.132462501525879 seconds for one epoch ---
--- 0.29842376708984375 seconds for one epoch ---
--- 1.1281535625457764 seconds for one epoch ---
--- 0.3083467483520508 seconds for one epoch ---
--- 1.1226661205291748 seconds for one epoch ---
--- 0.3000912666320801 seconds for one epoch ---
--- 1.125978946685791 seconds for one epoch ---
--- 0.3030381202697754 seconds for one epoch ---
--- 1.1374518871307373 seconds for one epoch ---
--- 0.29216933250427246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18406361]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.995662]
 [  0.      ]]
--- 0.26163411140441895 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4443.138671875, (1468.9763, 4.5044, 2969.539, 0.11898228)
   validation loss 869.340087890625, (573.05225, 0.39666912, 295.77222, 0.11898228)
decoder loss ratio: 22201.038876, decoder SINDy loss  ratio: 0.638466
--- 0.2962625026702881 seconds for one epoch ---
--- 1.088310718536377 seconds for one epoch ---
--- 0.30586791038513184 seconds for one epoch ---
--- 1.1494393348693848 seconds for one epoch ---
--- 0.28911352157592773 seconds for one epoch ---
--- 1.1365954875946045 seconds for one epoch ---
--- 0.3077085018157959 seconds for one epoch ---
--- 1.1542327404022217 seconds for one epoch ---
--- 0.3067009449005127 seconds for one epoch ---
--- 1.141599416732788 seconds for one epoch ---
--- 0.2899627685546875 seconds for one epoch ---
--- 1.130347490310669 seconds for one epoch ---
--- 0.29995298385620117 seconds for one epoch ---
--- 1.1312894821166992 seconds for one epoch ---
--- 0.30022740364074707 seconds for one epoch ---
--- 1.165466547012329 seconds for one epoch ---
--- 0.2986178398132324 seconds for one epoch ---
--- 1.1440696716308594 seconds for one epoch ---
--- 0.29635190963745117 seconds for one epoch ---
--- 1.1421804428100586 seconds for one epoch ---
--- 0.2912886142730713 seconds for one epoch ---
--- 1.1497559547424316 seconds for one epoch ---
--- 0.2870316505432129 seconds for one epoch ---
--- 1.1354570388793945 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18295982]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.098629]
 [ -0.      ]]
--- 0.29641222953796387 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4236.3115234375, (2200.9214, 2.7108955, 2032.5594, 0.11957314)
   validation loss 912.4479370117188, (608.29266, 0.4795944, 303.55606, 0.11957314)
decoder loss ratio: 23566.313829, decoder SINDy loss  ratio: 0.655268
--- 0.2541184425354004 seconds for one epoch ---
--- 0.2866833209991455 seconds for one epoch ---
--- 1.1116087436676025 seconds for one epoch ---
--- 0.29395508766174316 seconds for one epoch ---
--- 1.119121789932251 seconds for one epoch ---
--- 0.3337998390197754 seconds for one epoch ---
--- 1.149651288986206 seconds for one epoch ---
--- 0.33516383171081543 seconds for one epoch ---
--- 1.140315055847168 seconds for one epoch ---
--- 0.32936835289001465 seconds for one epoch ---
--- 1.1823644638061523 seconds for one epoch ---
--- 0.3290433883666992 seconds for one epoch ---
--- 1.1586790084838867 seconds for one epoch ---
--- 0.3197643756866455 seconds for one epoch ---
--- 1.172832727432251 seconds for one epoch ---
--- 0.333756685256958 seconds for one epoch ---
--- 1.1491453647613525 seconds for one epoch ---
--- 0.33231568336486816 seconds for one epoch ---
--- 1.141890048980713 seconds for one epoch ---
--- 0.32886672019958496 seconds for one epoch ---
--- 1.1569104194641113 seconds for one epoch ---
--- 0.3614692687988281 seconds for one epoch ---
--- 1.1706278324127197 seconds for one epoch ---
--- 0.31927037239074707 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18170065]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.210024]
 [ -0.      ]]
--- 0.2633633613586426 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3839.32861328125, (1939.3058, 1.7617271, 1898.1409, 0.12018379)
   validation loss 1105.063232421875, (783.8424, 0.4622413, 320.6384, 0.12018379)
decoder loss ratio: 30367.415666, decoder SINDy loss  ratio: 0.692143
--- 0.2954099178314209 seconds for one epoch ---
--- 1.117922306060791 seconds for one epoch ---
--- 0.2973933219909668 seconds for one epoch ---
--- 1.158646583557129 seconds for one epoch ---
--- 0.31719326972961426 seconds for one epoch ---
--- 1.1783149242401123 seconds for one epoch ---
--- 0.31113600730895996 seconds for one epoch ---
--- 1.175661325454712 seconds for one epoch ---
--- 0.3293721675872803 seconds for one epoch ---
--- 1.153926134109497 seconds for one epoch ---
--- 0.322981595993042 seconds for one epoch ---
--- 1.1669957637786865 seconds for one epoch ---
--- 0.31156158447265625 seconds for one epoch ---
--- 1.1841843128204346 seconds for one epoch ---
--- 0.32452964782714844 seconds for one epoch ---
--- 1.2061421871185303 seconds for one epoch ---
--- 0.3061981201171875 seconds for one epoch ---
--- 1.179748773574829 seconds for one epoch ---
--- 0.32473111152648926 seconds for one epoch ---
--- 1.1783339977264404 seconds for one epoch ---
--- 0.30846738815307617 seconds for one epoch ---
--- 1.1823854446411133 seconds for one epoch ---
--- 0.3075995445251465 seconds for one epoch ---
--- 1.1969614028930664 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.18051751]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.309685]
 [  0.      ]]
--- 0.29404187202453613 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3662.162841796875, (1946.0154, 2.4277248, 1713.5989, 0.12075462)
   validation loss 1128.3179931640625, (804.7221, 0.37399653, 323.1012, 0.12075462)
decoder loss ratio: 31176.331482, decoder SINDy loss  ratio: 0.697459
--- 0.25097036361694336 seconds for one epoch ---
--- 0.2872436046600342 seconds for one epoch ---
--- 1.11527419090271 seconds for one epoch ---
--- 0.29049086570739746 seconds for one epoch ---
--- 1.178675889968872 seconds for one epoch ---
--- 0.3179950714111328 seconds for one epoch ---
--- 1.1472570896148682 seconds for one epoch ---
--- 0.32285547256469727 seconds for one epoch ---
--- 1.158686637878418 seconds for one epoch ---
--- 0.3124420642852783 seconds for one epoch ---
--- 1.1948258876800537 seconds for one epoch ---
--- 0.31065940856933594 seconds for one epoch ---
--- 1.1662161350250244 seconds for one epoch ---
--- 0.30319833755493164 seconds for one epoch ---
--- 1.1877446174621582 seconds for one epoch ---
--- 0.3175075054168701 seconds for one epoch ---
--- 1.1832492351531982 seconds for one epoch ---
--- 0.306201696395874 seconds for one epoch ---
--- 1.1644244194030762 seconds for one epoch ---
--- 0.30605292320251465 seconds for one epoch ---
--- 1.1882693767547607 seconds for one epoch ---
--- 0.2975766658782959 seconds for one epoch ---
--- 1.1682991981506348 seconds for one epoch ---
--- 0.303408145904541 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17935188]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.403804]
 [  0.      ]]
--- 0.25905895233154297 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2381.038330078125, (1135.2404, 2.2115855, 1243.4651, 0.12125204)
   validation loss 925.4697265625, (577.16766, 0.7435162, 347.43726, 0.12125204)
decoder loss ratio: 22360.477294, decoder SINDy loss  ratio: 0.749992
--- 0.27991628646850586 seconds for one epoch ---
--- 1.131232500076294 seconds for one epoch ---
--- 0.29900574684143066 seconds for one epoch ---
--- 1.153271198272705 seconds for one epoch ---
--- 0.2848680019378662 seconds for one epoch ---
--- 1.1586658954620361 seconds for one epoch ---
--- 0.31877899169921875 seconds for one epoch ---
--- 1.210707426071167 seconds for one epoch ---
--- 0.299579381942749 seconds for one epoch ---
--- 1.2167651653289795 seconds for one epoch ---
--- 0.31034302711486816 seconds for one epoch ---
--- 1.1941163539886475 seconds for one epoch ---
--- 0.30153322219848633 seconds for one epoch ---
--- 1.2189033031463623 seconds for one epoch ---
--- 0.3028726577758789 seconds for one epoch ---
--- 1.2035243511199951 seconds for one epoch ---
--- 0.31093645095825195 seconds for one epoch ---
--- 1.1888232231140137 seconds for one epoch ---
--- 0.3165569305419922 seconds for one epoch ---
--- 1.2054946422576904 seconds for one epoch ---
--- 0.316547155380249 seconds for one epoch ---
--- 1.2159876823425293 seconds for one epoch ---
--- 0.3021259307861328 seconds for one epoch ---
--- 1.1873950958251953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17823273]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.490892]
 [ -0.      ]]
--- 0.2996785640716553 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5333.07763671875, (1450.7272, 7.7186317, 3874.5103, 0.12170806)
   validation loss 825.1131591796875, (486.4581, 0.7383442, 337.795, 0.12170806)
decoder loss ratio: 18846.231298, decoder SINDy loss  ratio: 0.729178
--- 0.25499677658081055 seconds for one epoch ---
--- 0.2990865707397461 seconds for one epoch ---
--- 1.1143827438354492 seconds for one epoch ---
--- 0.2814037799835205 seconds for one epoch ---
--- 1.1601176261901855 seconds for one epoch ---
--- 0.30177950859069824 seconds for one epoch ---
--- 1.197312593460083 seconds for one epoch ---
--- 0.30283570289611816 seconds for one epoch ---
--- 1.1884021759033203 seconds for one epoch ---
--- 0.27904629707336426 seconds for one epoch ---
--- 1.2357547283172607 seconds for one epoch ---
--- 0.30060553550720215 seconds for one epoch ---
--- 1.198948860168457 seconds for one epoch ---
--- 0.2937204837799072 seconds for one epoch ---
--- 1.2134976387023926 seconds for one epoch ---
--- 0.2932932376861572 seconds for one epoch ---
--- 1.2091083526611328 seconds for one epoch ---
--- 0.2999134063720703 seconds for one epoch ---
--- 1.1987144947052002 seconds for one epoch ---
--- 0.28977203369140625 seconds for one epoch ---
--- 1.2028591632843018 seconds for one epoch ---
--- 0.29258131980895996 seconds for one epoch ---
--- 1.2202904224395752 seconds for one epoch ---
--- 0.291428804397583 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17689222]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.591416]
 [ -0.      ]]
--- 0.2695167064666748 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1812.51806640625, (888.6077, 0.81755066, 922.9705, 0.12225554)
   validation loss 1228.991943359375, (867.6664, 0.4364538, 360.7668, 0.12225554)
decoder loss ratio: 33614.901967, decoder SINDy loss  ratio: 0.778766
--- 0.2867293357849121 seconds for one epoch ---
--- 1.1453046798706055 seconds for one epoch ---
--- 0.3049652576446533 seconds for one epoch ---
--- 1.1769320964813232 seconds for one epoch ---
--- 0.30162835121154785 seconds for one epoch ---
--- 1.1574440002441406 seconds for one epoch ---
--- 0.29239940643310547 seconds for one epoch ---
--- 1.205453634262085 seconds for one epoch ---
--- 0.3010592460632324 seconds for one epoch ---
--- 1.219761848449707 seconds for one epoch ---
--- 0.3030869960784912 seconds for one epoch ---
--- 1.1973187923431396 seconds for one epoch ---
--- 0.2993924617767334 seconds for one epoch ---
--- 1.2179083824157715 seconds for one epoch ---
--- 0.3035271167755127 seconds for one epoch ---
--- 1.2079768180847168 seconds for one epoch ---
--- 0.296816349029541 seconds for one epoch ---
--- 1.1613671779632568 seconds for one epoch ---
--- 0.2780721187591553 seconds for one epoch ---
--- 1.2162115573883057 seconds for one epoch ---
--- 0.32272911071777344 seconds for one epoch ---
--- 1.251612901687622 seconds for one epoch ---
--- 0.30164098739624023 seconds for one epoch ---
--- 1.2178285121917725 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17563224]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.682642]
 [  0.      ]]
--- 0.30588531494140625 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3506.329833984375, (1584.198, 2.1651418, 1919.8439, 0.122717395)
   validation loss 878.542236328125, (575.81946, 0.6293867, 301.97064, 0.122717395)
decoder loss ratio: 22308.245470, decoder SINDy loss  ratio: 0.651846
THRESHOLDING: 1 active coefficients
--- 1.2300629615783691 seconds for one epoch ---
--- 0.29786181449890137 seconds for one epoch ---
--- 1.1702632904052734 seconds for one epoch ---
--- 0.2958362102508545 seconds for one epoch ---
--- 1.2119238376617432 seconds for one epoch ---
--- 0.2967078685760498 seconds for one epoch ---
--- 1.2271473407745361 seconds for one epoch ---
--- 0.29990148544311523 seconds for one epoch ---
--- 1.2158000469207764 seconds for one epoch ---
--- 0.2869281768798828 seconds for one epoch ---
--- 1.2033045291900635 seconds for one epoch ---
--- 0.27777719497680664 seconds for one epoch ---
--- 1.2316703796386719 seconds for one epoch ---
--- 0.2830512523651123 seconds for one epoch ---
--- 1.2311618328094482 seconds for one epoch ---
--- 0.310927152633667 seconds for one epoch ---
--- 1.2380106449127197 seconds for one epoch ---
--- 0.303741455078125 seconds for one epoch ---
--- 1.2096335887908936 seconds for one epoch ---
--- 0.2836458683013916 seconds for one epoch ---
--- 1.189819097518921 seconds for one epoch ---
--- 0.2987394332885742 seconds for one epoch ---
--- 1.1917126178741455 seconds for one epoch ---
--- 0.3065836429595947 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1742562]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.779057]
 [  0.      ]]
--- 0.26747918128967285 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3868.465576171875, (1996.9465, 0.48557758, 1870.9103, 0.1232062)
   validation loss 929.3358764648438, (599.85846, 0.65678334, 328.6974, 0.1232062)
decoder loss ratio: 23239.558120, decoder SINDy loss  ratio: 0.709540
--- 0.296799898147583 seconds for one epoch ---
--- 1.1715850830078125 seconds for one epoch ---
--- 0.28800535202026367 seconds for one epoch ---
--- 1.2132408618927002 seconds for one epoch ---
--- 0.29901790618896484 seconds for one epoch ---
--- 1.241774559020996 seconds for one epoch ---
--- 0.29871535301208496 seconds for one epoch ---
--- 1.2053172588348389 seconds for one epoch ---
--- 0.29985547065734863 seconds for one epoch ---
--- 1.2077884674072266 seconds for one epoch ---
--- 0.29497838020324707 seconds for one epoch ---
--- 1.239389419555664 seconds for one epoch ---
--- 0.29822349548339844 seconds for one epoch ---
--- 1.219390630722046 seconds for one epoch ---
--- 0.30031824111938477 seconds for one epoch ---
--- 1.2164409160614014 seconds for one epoch ---
--- 0.28153061866760254 seconds for one epoch ---
--- 1.253908395767212 seconds for one epoch ---
--- 0.2994384765625 seconds for one epoch ---
--- 1.2088489532470703 seconds for one epoch ---
--- 0.2993628978729248 seconds for one epoch ---
--- 1.2448711395263672 seconds for one epoch ---
--- 0.3036017417907715 seconds for one epoch ---
--- 1.2250030040740967 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17290804]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.870641]
 [ -0.      ]]
--- 0.29710865020751953 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5066.89697265625, (2839.9348, 1.4450107, 2225.3936, 0.12363273)
   validation loss 950.9475708007812, (621.46655, 0.71016973, 328.64722, 0.12363273)
decoder loss ratio: 24076.693166, decoder SINDy loss  ratio: 0.709431
--- 0.26682233810424805 seconds for one epoch ---
--- 0.29706788063049316 seconds for one epoch ---
--- 1.191577434539795 seconds for one epoch ---
--- 0.29225993156433105 seconds for one epoch ---
--- 1.2063629627227783 seconds for one epoch ---
--- 0.2847723960876465 seconds for one epoch ---
--- 1.219897747039795 seconds for one epoch ---
--- 0.27907419204711914 seconds for one epoch ---
--- 1.21889328956604 seconds for one epoch ---
--- 0.30214905738830566 seconds for one epoch ---
--- 1.211007833480835 seconds for one epoch ---
--- 0.29650068283081055 seconds for one epoch ---
--- 1.2317993640899658 seconds for one epoch ---
--- 0.2979404926300049 seconds for one epoch ---
--- 1.2429101467132568 seconds for one epoch ---
--- 0.296553373336792 seconds for one epoch ---
--- 1.2365286350250244 seconds for one epoch ---
--- 0.29415297508239746 seconds for one epoch ---
--- 1.2338354587554932 seconds for one epoch ---
--- 0.2945587635040283 seconds for one epoch ---
--- 1.2568373680114746 seconds for one epoch ---
--- 0.2982981204986572 seconds for one epoch ---
--- 1.2333550453186035 seconds for one epoch ---
--- 0.3010988235473633 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17163277]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.954878]
 [ -0.      ]]
--- 0.26184749603271484 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3259.08740234375, (1783.1893, 0.751565, 1475.0225, 0.1240676)
   validation loss 881.1456909179688, (552.956, 0.56394655, 327.50165, 0.1240676)
decoder loss ratio: 21422.475168, decoder SINDy loss  ratio: 0.706958
--- 0.29641079902648926 seconds for one epoch ---
--- 1.2131752967834473 seconds for one epoch ---
--- 0.3055753707885742 seconds for one epoch ---
--- 1.2166128158569336 seconds for one epoch ---
--- 0.3013312816619873 seconds for one epoch ---
--- 1.2231245040893555 seconds for one epoch ---
--- 0.29302382469177246 seconds for one epoch ---
--- 1.2440340518951416 seconds for one epoch ---
--- 0.29732441902160645 seconds for one epoch ---
--- 1.2601470947265625 seconds for one epoch ---
--- 0.298187255859375 seconds for one epoch ---
--- 1.2538156509399414 seconds for one epoch ---
--- 0.3041701316833496 seconds for one epoch ---
--- 1.2521617412567139 seconds for one epoch ---
--- 0.29781627655029297 seconds for one epoch ---
--- 1.2530510425567627 seconds for one epoch ---
--- 0.29746150970458984 seconds for one epoch ---
--- 1.2535490989685059 seconds for one epoch ---
--- 0.2763097286224365 seconds for one epoch ---
--- 1.2620251178741455 seconds for one epoch ---
--- 0.2965853214263916 seconds for one epoch ---
--- 1.2768018245697021 seconds for one epoch ---
--- 0.3057994842529297 seconds for one epoch ---
--- 1.2477984428405762 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17003737]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.057374]
 [  0.      ]]
--- 0.3006925582885742 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1845.13427734375, (875.7924, 2.6684473, 966.5488, 0.12451767)
   validation loss 1018.02392578125, (648.8533, 0.7400982, 368.306, 0.12451767)
decoder loss ratio: 25137.702196, decoder SINDy loss  ratio: 0.795040
--- 0.2613539695739746 seconds for one epoch ---
--- 0.2979741096496582 seconds for one epoch ---
--- 1.2462401390075684 seconds for one epoch ---
--- 0.30438899993896484 seconds for one epoch ---
--- 1.2761831283569336 seconds for one epoch ---
--- 0.2801971435546875 seconds for one epoch ---
--- 1.2667582035064697 seconds for one epoch ---
--- 0.310042142868042 seconds for one epoch ---
--- 1.248976469039917 seconds for one epoch ---
--- 0.300445556640625 seconds for one epoch ---
--- 1.2745115756988525 seconds for one epoch ---
--- 0.30640196800231934 seconds for one epoch ---
--- 1.258981466293335 seconds for one epoch ---
--- 0.30605530738830566 seconds for one epoch ---
--- 1.2687382698059082 seconds for one epoch ---
--- 0.2878563404083252 seconds for one epoch ---
--- 1.2333455085754395 seconds for one epoch ---
--- 0.2979288101196289 seconds for one epoch ---
--- 1.2778427600860596 seconds for one epoch ---
--- 0.2942845821380615 seconds for one epoch ---
--- 1.2770802974700928 seconds for one epoch ---
--- 0.3014373779296875 seconds for one epoch ---
--- 1.2790031433105469 seconds for one epoch ---
--- 0.30060768127441406 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16858077]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-12.14843]
 [  0.     ]]
--- 0.2611868381500244 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2692.35888671875, (1449.6655, 1.5585779, 1241.0098, 0.124906875)
   validation loss 1167.85595703125, (822.7124, 0.60435945, 344.41434, 0.124906875)
decoder loss ratio: 31873.306758, decoder SINDy loss  ratio: 0.743467
--- 0.29404473304748535 seconds for one epoch ---
--- 1.2357347011566162 seconds for one epoch ---
--- 0.2921786308288574 seconds for one epoch ---
--- 1.2622272968292236 seconds for one epoch ---
--- 0.2945864200592041 seconds for one epoch ---
--- 1.2564690113067627 seconds for one epoch ---
--- 0.29175567626953125 seconds for one epoch ---
--- 1.252737045288086 seconds for one epoch ---
--- 0.29920125007629395 seconds for one epoch ---
--- 1.292182207107544 seconds for one epoch ---
--- 0.30121445655822754 seconds for one epoch ---
--- 1.2847001552581787 seconds for one epoch ---
--- 0.29289674758911133 seconds for one epoch ---
--- 1.2750012874603271 seconds for one epoch ---
--- 0.3045670986175537 seconds for one epoch ---
--- 1.298412799835205 seconds for one epoch ---
--- 0.30262136459350586 seconds for one epoch ---
--- 1.2700672149658203 seconds for one epoch ---
--- 0.3010294437408447 seconds for one epoch ---
--- 1.267549991607666 seconds for one epoch ---
--- 0.30246925354003906 seconds for one epoch ---
--- 1.2921473979949951 seconds for one epoch ---
--- 0.30755019187927246 seconds for one epoch ---
--- 1.2755134105682373 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16709957]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.238763]
 [ -0.      ]]
--- 0.2888190746307373 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5321.79638671875, (1142.4095, 2.3280149, 4176.9336, 0.12531169)
   validation loss 920.67578125, (609.9128, 0.4867893, 310.15088, 0.12531169)
decoder loss ratio: 23629.079982, decoder SINDy loss  ratio: 0.669504
--- 0.24346685409545898 seconds for one epoch ---
--- 0.3064610958099365 seconds for one epoch ---
--- 1.2390460968017578 seconds for one epoch ---
--- 0.30272579193115234 seconds for one epoch ---
--- 1.2780370712280273 seconds for one epoch ---
--- 0.29763364791870117 seconds for one epoch ---
--- 1.2986607551574707 seconds for one epoch ---
--- 0.3045380115509033 seconds for one epoch ---
--- 1.2715511322021484 seconds for one epoch ---
--- 0.26514244079589844 seconds for one epoch ---
--- 1.2715606689453125 seconds for one epoch ---
--- 0.3209209442138672 seconds for one epoch ---
--- 1.2972688674926758 seconds for one epoch ---
--- 0.3038022518157959 seconds for one epoch ---
--- 1.3176140785217285 seconds for one epoch ---
--- 0.29215431213378906 seconds for one epoch ---
--- 1.3343472480773926 seconds for one epoch ---
--- 0.30242443084716797 seconds for one epoch ---
--- 1.307318925857544 seconds for one epoch ---
--- 0.3057851791381836 seconds for one epoch ---
--- 1.291557788848877 seconds for one epoch ---
--- 0.31064891815185547 seconds for one epoch ---
--- 1.3078298568725586 seconds for one epoch ---
--- 0.3138718605041504 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16570279]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.322094]
 [ -0.      ]]
--- 0.26175451278686523 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2398.282470703125, (1198.0388, 2.731503, 1197.3864, 0.12570079)
   validation loss 938.360595703125, (588.99945, 0.5406146, 348.6949, 0.12570079)
decoder loss ratio: 22818.861267, decoder SINDy loss  ratio: 0.752707
--- 0.2962617874145508 seconds for one epoch ---
--- 1.2571539878845215 seconds for one epoch ---
--- 0.3091418743133545 seconds for one epoch ---
--- 1.275883674621582 seconds for one epoch ---
--- 0.2864246368408203 seconds for one epoch ---
--- 1.2870006561279297 seconds for one epoch ---
--- 0.2965531349182129 seconds for one epoch ---
--- 1.2985212802886963 seconds for one epoch ---
--- 0.2972738742828369 seconds for one epoch ---
--- 1.288792371749878 seconds for one epoch ---
--- 0.3008761405944824 seconds for one epoch ---
--- 1.3123295307159424 seconds for one epoch ---
--- 0.3072373867034912 seconds for one epoch ---
--- 1.3071820735931396 seconds for one epoch ---
--- 0.2998924255371094 seconds for one epoch ---
--- 1.3091621398925781 seconds for one epoch ---
--- 0.2999250888824463 seconds for one epoch ---
--- 1.3044979572296143 seconds for one epoch ---
--- 0.30863237380981445 seconds for one epoch ---
--- 1.3085010051727295 seconds for one epoch ---
--- 0.2957472801208496 seconds for one epoch ---
--- 1.309007167816162 seconds for one epoch ---
--- 0.2994053363800049 seconds for one epoch ---
--- 1.32179856300354 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16403979]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.419128]
 [  0.      ]]
--- 0.2989325523376465 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3030.66650390625, (1047.0393, 2.105187, 1981.3959, 0.12607658)
   validation loss 1354.9576416015625, (994.4903, 0.4412996, 359.89996, 0.12607658)
decoder loss ratio: 38528.280555, decoder SINDy loss  ratio: 0.776895
--- 0.25972604751586914 seconds for one epoch ---
--- 0.29468417167663574 seconds for one epoch ---
--- 1.2545230388641357 seconds for one epoch ---
--- 0.2962977886199951 seconds for one epoch ---
--- 1.295583724975586 seconds for one epoch ---
--- 0.29388952255249023 seconds for one epoch ---
--- 1.3043859004974365 seconds for one epoch ---
--- 0.29531049728393555 seconds for one epoch ---
--- 1.2998747825622559 seconds for one epoch ---
--- 0.29625701904296875 seconds for one epoch ---
--- 1.3274314403533936 seconds for one epoch ---
--- 0.30348682403564453 seconds for one epoch ---
--- 1.3313877582550049 seconds for one epoch ---
--- 0.29420900344848633 seconds for one epoch ---
--- 1.3318991661071777 seconds for one epoch ---
--- 0.3022758960723877 seconds for one epoch ---
--- 1.328901767730713 seconds for one epoch ---
--- 0.3001420497894287 seconds for one epoch ---
--- 1.3443946838378906 seconds for one epoch ---
--- 0.30163097381591797 seconds for one epoch ---
--- 1.3478245735168457 seconds for one epoch ---
--- 0.3014087677001953 seconds for one epoch ---
--- 1.3308701515197754 seconds for one epoch ---
--- 0.2973673343658447 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1625146]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.506254]
 [  0.      ]]
--- 0.2532534599304199 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2427.25830078125, (1260.4666, 0.64088213, 1166.0244, 0.12643965)
   validation loss 922.0972900390625, (606.27716, 0.52817196, 315.1655, 0.12643965)
decoder loss ratio: 23488.229747, decoder SINDy loss  ratio: 0.680329
--- 0.29608941078186035 seconds for one epoch ---
--- 1.2754335403442383 seconds for one epoch ---
--- 0.29636383056640625 seconds for one epoch ---
--- 1.2861695289611816 seconds for one epoch ---
--- 0.31107378005981445 seconds for one epoch ---
--- 1.322153091430664 seconds for one epoch ---
--- 0.2964050769805908 seconds for one epoch ---
--- 1.303276538848877 seconds for one epoch ---
--- 0.3084549903869629 seconds for one epoch ---
--- 1.3414387702941895 seconds for one epoch ---
--- 0.31494998931884766 seconds for one epoch ---
--- 1.3435752391815186 seconds for one epoch ---
--- 0.31720519065856934 seconds for one epoch ---
--- 1.3428280353546143 seconds for one epoch ---
--- 0.33027005195617676 seconds for one epoch ---
--- 1.343522071838379 seconds for one epoch ---
--- 0.3222081661224365 seconds for one epoch ---
--- 1.3268566131591797 seconds for one epoch ---
--- 0.30715489387512207 seconds for one epoch ---
--- 1.344115972518921 seconds for one epoch ---
--- 0.3074219226837158 seconds for one epoch ---
--- 1.3117256164550781 seconds for one epoch ---
--- 0.3102989196777344 seconds for one epoch ---
--- 1.3420886993408203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16095658]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.593564]
 [ -0.      ]]
--- 0.29604482650756836 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2610.583251953125, (1370.6702, 1.2141982, 1238.572, 0.12678665)
   validation loss 764.9811401367188, (446.82422, 0.5753387, 317.45483, 0.12678665)
decoder loss ratio: 17310.745955, decoder SINDy loss  ratio: 0.685271
--- 0.2635352611541748 seconds for one epoch ---
--- 0.29213523864746094 seconds for one epoch ---
--- 1.319533109664917 seconds for one epoch ---
--- 0.29706811904907227 seconds for one epoch ---
--- 1.2994623184204102 seconds for one epoch ---
--- 0.29319262504577637 seconds for one epoch ---
--- 1.3368732929229736 seconds for one epoch ---
--- 0.3071901798248291 seconds for one epoch ---
--- 1.323399543762207 seconds for one epoch ---
--- 0.5467476844787598 seconds for one epoch ---
--- 1.3236217498779297 seconds for one epoch ---
--- 0.32015442848205566 seconds for one epoch ---
--- 1.3505444526672363 seconds for one epoch ---
--- 0.3285789489746094 seconds for one epoch ---
--- 1.332962989807129 seconds for one epoch ---
--- 0.3247189521789551 seconds for one epoch ---
--- 1.3406426906585693 seconds for one epoch ---
--- 0.32465410232543945 seconds for one epoch ---
--- 1.3477706909179688 seconds for one epoch ---
--- 0.314129114151001 seconds for one epoch ---
--- 1.3424038887023926 seconds for one epoch ---
--- 0.31307458877563477 seconds for one epoch ---
--- 1.341202974319458 seconds for one epoch ---
--- 0.3234288692474365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15967128]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.664383]
 [ -0.      ]]
--- 0.26499104499816895 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3170.697265625, (1208.6237, 1.3930634, 1960.5535, 0.12705301)
   validation loss 1278.16845703125, (906.4217, 0.78034335, 370.8394, 0.12705301)
decoder loss ratio: 35116.349961, decoder SINDy loss  ratio: 0.800509
--- 0.31064748764038086 seconds for one epoch ---
--- 1.303722620010376 seconds for one epoch ---
--- 0.30977582931518555 seconds for one epoch ---
--- 1.3330917358398438 seconds for one epoch ---
--- 0.2987039089202881 seconds for one epoch ---
--- 1.3237299919128418 seconds for one epoch ---
--- 0.31728386878967285 seconds for one epoch ---
--- 1.344825267791748 seconds for one epoch ---
--- 0.32094430923461914 seconds for one epoch ---
--- 1.3353791236877441 seconds for one epoch ---
--- 0.31690502166748047 seconds for one epoch ---
--- 1.333768367767334 seconds for one epoch ---
--- 0.3232133388519287 seconds for one epoch ---
--- 1.3416988849639893 seconds for one epoch ---
--- 0.3133838176727295 seconds for one epoch ---
--- 1.3390123844146729 seconds for one epoch ---
--- 0.32203030586242676 seconds for one epoch ---
--- 1.337763786315918 seconds for one epoch ---
--- 0.3126029968261719 seconds for one epoch ---
--- 1.350970983505249 seconds for one epoch ---
--- 0.31134605407714844 seconds for one epoch ---
--- 1.342583417892456 seconds for one epoch ---
--- 0.32436609268188477 seconds for one epoch ---
--- 1.3781344890594482 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15816656]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-12.74605]
 [  0.     ]]
--- 0.288677453994751 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6463.048828125, (2188.612, 9.92077, 4264.3887, 0.12735997)
   validation loss 1020.5376586914062, (664.4274, 0.60905015, 355.3738, 0.12735997)
decoder loss ratio: 25741.072104, decoder SINDy loss  ratio: 0.767124
--- 0.2614102363586426 seconds for one epoch ---
--- 0.29618334770202637 seconds for one epoch ---
--- 1.2718560695648193 seconds for one epoch ---
--- 0.2970848083496094 seconds for one epoch ---
--- 1.322584867477417 seconds for one epoch ---
--- 0.2983686923980713 seconds for one epoch ---
--- 1.3432791233062744 seconds for one epoch ---
--- 0.29718565940856934 seconds for one epoch ---
--- 1.361402988433838 seconds for one epoch ---
--- 0.2757117748260498 seconds for one epoch ---
--- 1.358191967010498 seconds for one epoch ---
--- 0.28907227516174316 seconds for one epoch ---
--- 1.3683381080627441 seconds for one epoch ---
--- 0.2923111915588379 seconds for one epoch ---
--- 1.373779058456421 seconds for one epoch ---
--- 0.29920482635498047 seconds for one epoch ---
--- 1.3487074375152588 seconds for one epoch ---
--- 0.3062727451324463 seconds for one epoch ---
--- 1.3394534587860107 seconds for one epoch ---
--- 0.287858247756958 seconds for one epoch ---
--- 1.3540961742401123 seconds for one epoch ---
--- 0.2940804958343506 seconds for one epoch ---
--- 1.3747482299804688 seconds for one epoch ---
--- 0.2981395721435547 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15689102]
 [0.        ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-12.8143015]
 [  0.       ]]
--- 0.25827789306640625 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3984.164306640625, (1857.5846, 4.725642, 2121.7263, 0.12761419)
   validation loss 1324.9923095703125, (977.58777, 0.5428667, 346.73413, 0.12761419)
decoder loss ratio: 37873.447321, decoder SINDy loss  ratio: 0.748474
--- 0.30304861068725586 seconds for one epoch ---
--- 1.376150131225586 seconds for one epoch ---
--- 0.29898834228515625 seconds for one epoch ---
--- 1.3173496723175049 seconds for one epoch ---
--- 0.2959780693054199 seconds for one epoch ---
--- 1.2986326217651367 seconds for one epoch ---
--- 0.29447078704833984 seconds for one epoch ---
--- 1.380314826965332 seconds for one epoch ---
--- 0.30434513092041016 seconds for one epoch ---
--- 1.3956232070922852 seconds for one epoch ---
--- 0.31929850578308105 seconds for one epoch ---
--- 1.381298542022705 seconds for one epoch ---
--- 0.30254101753234863 seconds for one epoch ---
--- 1.3839383125305176 seconds for one epoch ---
--- 0.3183274269104004 seconds for one epoch ---
--- 1.3983356952667236 seconds for one epoch ---
--- 0.31125569343566895 seconds for one epoch ---
--- 1.3727304935455322 seconds for one epoch ---
--- 0.3255014419555664 seconds for one epoch ---
--- 1.400742530822754 seconds for one epoch ---
--- 0.32984113693237305 seconds for one epoch ---
--- 1.3826801776885986 seconds for one epoch ---
--- 0.319744348526001 seconds for one epoch ---
--- 1.4074292182922363 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15506461]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.910561]
 [ -0.      ]]
--- 0.29139041900634766 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3876.6572265625, (1297.4711, 0.9647263, 2578.0935, 0.12795775)
   validation loss 1106.6561279296875, (750.43134, 0.6352967, 355.46158, 0.12795775)
decoder loss ratio: 29073.012741, decoder SINDy loss  ratio: 0.767314
--- 0.2682762145996094 seconds for one epoch ---
--- 0.2961137294769287 seconds for one epoch ---
--- 1.3618040084838867 seconds for one epoch ---
--- 0.2743525505065918 seconds for one epoch ---
--- 1.3519282341003418 seconds for one epoch ---
--- 0.2900402545928955 seconds for one epoch ---
--- 1.3469786643981934 seconds for one epoch ---
--- 0.28774428367614746 seconds for one epoch ---
--- 1.3968262672424316 seconds for one epoch ---
--- 0.3153343200683594 seconds for one epoch ---
--- 1.395359754562378 seconds for one epoch ---
--- 0.30304527282714844 seconds for one epoch ---
--- 1.393432378768921 seconds for one epoch ---
--- 0.30724310874938965 seconds for one epoch ---
--- 1.4201345443725586 seconds for one epoch ---
--- 0.3128538131713867 seconds for one epoch ---
--- 1.4028229713439941 seconds for one epoch ---
--- 0.29797911643981934 seconds for one epoch ---
--- 1.4090099334716797 seconds for one epoch ---
--- 0.31553006172180176 seconds for one epoch ---
--- 1.4084892272949219 seconds for one epoch ---
--- 0.31213927268981934 seconds for one epoch ---
--- 1.3979547023773193 seconds for one epoch ---
--- 0.31465935707092285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15320069]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.007163]
 [ -0.      ]]
--- 0.24896740913391113 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2335.437744140625, (998.8592, 6.556183, 1329.894, 0.12829237)
   validation loss 2027.910888671875, (1615.0522, 0.38496864, 412.34534, 0.12829237)
decoder loss ratio: 62569.927868, decoder SINDy loss  ratio: 0.890105
--- 0.2956111431121826 seconds for one epoch ---
--- 1.4072492122650146 seconds for one epoch ---
--- 0.31437230110168457 seconds for one epoch ---
--- 1.3500709533691406 seconds for one epoch ---
--- 0.29689693450927734 seconds for one epoch ---
--- 1.3490071296691895 seconds for one epoch ---
--- 0.2933621406555176 seconds for one epoch ---
--- 1.3767750263214111 seconds for one epoch ---
--- 0.2920866012573242 seconds for one epoch ---
--- 1.365297555923462 seconds for one epoch ---
--- 0.2932274341583252 seconds for one epoch ---
--- 1.3977272510528564 seconds for one epoch ---
--- 0.29464077949523926 seconds for one epoch ---
--- 1.3999090194702148 seconds for one epoch ---
--- 0.29843807220458984 seconds for one epoch ---
--- 1.4034061431884766 seconds for one epoch ---
--- 0.30725908279418945 seconds for one epoch ---
--- 1.416860818862915 seconds for one epoch ---
--- 0.28362321853637695 seconds for one epoch ---
--- 1.3990113735198975 seconds for one epoch ---
--- 0.2970457077026367 seconds for one epoch ---
--- 1.400522232055664 seconds for one epoch ---
--- 0.2985546588897705 seconds for one epoch ---
--- 1.3970117568969727 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15167433]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-13.0851555]
 [  0.       ]]
--- 0.31066370010375977 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3103.025390625, (1594.4574, 3.6802945, 1504.759, 0.12856165)
   validation loss 875.4066162109375, (566.2851, 0.7205505, 308.2725, 0.12856165)
decoder loss ratio: 21938.867703, decoder SINDy loss  ratio: 0.665450
--- 0.26421523094177246 seconds for one epoch ---
--- 0.2931027412414551 seconds for one epoch ---
--- 1.3824524879455566 seconds for one epoch ---
--- 0.30576157569885254 seconds for one epoch ---
--- 1.383131980895996 seconds for one epoch ---
--- 0.292130708694458 seconds for one epoch ---
--- 1.367661714553833 seconds for one epoch ---
--- 0.2885258197784424 seconds for one epoch ---
--- 1.3852050304412842 seconds for one epoch ---
--- 0.27419114112854004 seconds for one epoch ---
--- 1.4240837097167969 seconds for one epoch ---
--- 0.31736302375793457 seconds for one epoch ---
--- 1.395658254623413 seconds for one epoch ---
--- 0.3303351402282715 seconds for one epoch ---
--- 1.3956854343414307 seconds for one epoch ---
--- 0.3360629081726074 seconds for one epoch ---
--- 1.4220247268676758 seconds for one epoch ---
--- 0.3320789337158203 seconds for one epoch ---
--- 1.4089806079864502 seconds for one epoch ---
--- 0.3446495532989502 seconds for one epoch ---
--- 1.441594123840332 seconds for one epoch ---
--- 0.3297262191772461 seconds for one epoch ---
--- 1.4459013938903809 seconds for one epoch ---
--- 0.33455729484558105 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1501784]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-13.1606865]
 [  0.       ]]
--- 0.2627854347229004 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2861.89208984375, (1510.9963, 0.48685947, 1350.28, 0.12879817)
   validation loss 1056.5970458984375, (717.9786, 0.6268582, 337.86282, 0.12879817)
decoder loss ratio: 27815.736525, decoder SINDy loss  ratio: 0.729324
--- 0.29649782180786133 seconds for one epoch ---
--- 1.415536880493164 seconds for one epoch ---
--- 0.3046588897705078 seconds for one epoch ---
--- 1.4317140579223633 seconds for one epoch ---
--- 0.29158520698547363 seconds for one epoch ---
--- 1.353010892868042 seconds for one epoch ---
--- 0.2925703525543213 seconds for one epoch ---
--- 1.3792359828948975 seconds for one epoch ---
--- 0.29338741302490234 seconds for one epoch ---
--- 1.4019920825958252 seconds for one epoch ---
--- 0.3017442226409912 seconds for one epoch ---
--- 1.402925968170166 seconds for one epoch ---
--- 0.29657912254333496 seconds for one epoch ---
--- 1.4225847721099854 seconds for one epoch ---
--- 0.286846399307251 seconds for one epoch ---
--- 1.4066338539123535 seconds for one epoch ---
--- 0.28094029426574707 seconds for one epoch ---
--- 1.4375126361846924 seconds for one epoch ---
--- 0.29007935523986816 seconds for one epoch ---
--- 1.4051077365875244 seconds for one epoch ---
--- 0.2964198589324951 seconds for one epoch ---
--- 1.4046404361724854 seconds for one epoch ---
--- 0.2650878429412842 seconds for one epoch ---
--- 1.4314980506896973 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14842165]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.248326]
 [ -0.      ]]
--- 0.27010655403137207 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4715.7783203125, (1080.9569, 2.4302878, 3632.262, 0.12908505)
   validation loss 1025.020263671875, (666.01215, 0.7126043, 358.16647, 0.12908505)
decoder loss ratio: 25802.466784, decoder SINDy loss  ratio: 0.773153
--- 0.258267879486084 seconds for one epoch ---
--- 0.30173778533935547 seconds for one epoch ---
--- 1.4166252613067627 seconds for one epoch ---
--- 0.29025959968566895 seconds for one epoch ---
--- 1.4221844673156738 seconds for one epoch ---
--- 0.29528212547302246 seconds for one epoch ---
--- 1.4098896980285645 seconds for one epoch ---
--- 0.3052339553833008 seconds for one epoch ---
--- 1.3787314891815186 seconds for one epoch ---
--- 0.2750678062438965 seconds for one epoch ---
--- 1.3868112564086914 seconds for one epoch ---
--- 0.2997448444366455 seconds for one epoch ---
--- 1.4278414249420166 seconds for one epoch ---
--- 0.3158688545227051 seconds for one epoch ---
--- 1.4640021324157715 seconds for one epoch ---
--- 0.30608439445495605 seconds for one epoch ---
--- 1.4239685535430908 seconds for one epoch ---
--- 0.2932162284851074 seconds for one epoch ---
--- 1.435575246810913 seconds for one epoch ---
--- 0.31062984466552734 seconds for one epoch ---
--- 1.427271842956543 seconds for one epoch ---
--- 0.313723087310791 seconds for one epoch ---
--- 1.430150032043457 seconds for one epoch ---
--- 0.3222975730895996 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14690274]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.323268]
 [ -0.      ]]
--- 0.25850820541381836 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3116.70166015625, (1803.8568, 0.6447201, 1312.0706, 0.12932892)
   validation loss 948.9413452148438, (631.6089, 0.728429, 316.4747, 0.12932892)
decoder loss ratio: 24469.624793, decoder SINDy loss  ratio: 0.683155
--- 0.3127758502960205 seconds for one epoch ---
--- 1.4709479808807373 seconds for one epoch ---
--- 0.2928285598754883 seconds for one epoch ---
--- 1.4618744850158691 seconds for one epoch ---
--- 0.2954249382019043 seconds for one epoch ---
--- 1.4268639087677002 seconds for one epoch ---
--- 0.30049967765808105 seconds for one epoch ---
--- 1.4080755710601807 seconds for one epoch ---
--- 0.2939765453338623 seconds for one epoch ---
--- 1.4319424629211426 seconds for one epoch ---
--- 0.31163930892944336 seconds for one epoch ---
--- 1.438950538635254 seconds for one epoch ---
--- 0.2940404415130615 seconds for one epoch ---
--- 1.4193685054779053 seconds for one epoch ---
--- 0.29402971267700195 seconds for one epoch ---
--- 1.444059133529663 seconds for one epoch ---
--- 0.28827977180480957 seconds for one epoch ---
--- 1.4470062255859375 seconds for one epoch ---
--- 0.28304195404052734 seconds for one epoch ---
--- 1.455230951309204 seconds for one epoch ---
--- 0.2958810329437256 seconds for one epoch ---
--- 1.440298080444336 seconds for one epoch ---
--- 0.30205321311950684 seconds for one epoch ---
--- 1.4442286491394043 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14544488]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.394487]
 [  0.      ]]
--- 0.2921299934387207 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1701.5711669921875, (621.2003, 1.8943654, 1078.347, 0.12953834)
   validation loss 1130.654296875, (800.44, 0.7217794, 329.36298, 0.12953834)
decoder loss ratio: 31010.435320, decoder SINDy loss  ratio: 0.710976
THRESHOLDING: 1 active coefficients
--- 1.444476842880249 seconds for one epoch ---
--- 0.2942371368408203 seconds for one epoch ---
--- 1.472475528717041 seconds for one epoch ---
--- 0.3044452667236328 seconds for one epoch ---
--- 1.4870212078094482 seconds for one epoch ---
--- 0.2966897487640381 seconds for one epoch ---
--- 1.421893835067749 seconds for one epoch ---
--- 0.2934575080871582 seconds for one epoch ---
--- 1.423224687576294 seconds for one epoch ---
--- 0.2934412956237793 seconds for one epoch ---
--- 1.4392967224121094 seconds for one epoch ---
--- 0.30075860023498535 seconds for one epoch ---
--- 1.458409070968628 seconds for one epoch ---
--- 0.29877328872680664 seconds for one epoch ---
--- 1.4610750675201416 seconds for one epoch ---
--- 0.29288816452026367 seconds for one epoch ---
--- 1.4560072422027588 seconds for one epoch ---
--- 0.28600549697875977 seconds for one epoch ---
--- 1.443795919418335 seconds for one epoch ---
--- 0.2918717861175537 seconds for one epoch ---
--- 1.4704391956329346 seconds for one epoch ---
--- 0.2817978858947754 seconds for one epoch ---
--- 1.4592311382293701 seconds for one epoch ---
--- 0.2898576259613037 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14379089]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.474551]
 [  0.      ]]
--- 0.26981353759765625 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2239.1015625, (1180.1014, 1.3133926, 1057.557, 0.12978618)
   validation loss 784.0330200195312, (477.58823, 0.7428646, 305.57217, 0.12978618)
decoder loss ratio: 18502.597017, decoder SINDy loss  ratio: 0.659621
--- 0.29918980598449707 seconds for one epoch ---
--- 1.4344933032989502 seconds for one epoch ---
--- 0.3012199401855469 seconds for one epoch ---
--- 1.4600703716278076 seconds for one epoch ---
--- 0.2992091178894043 seconds for one epoch ---
--- 1.4199855327606201 seconds for one epoch ---
--- 0.29347968101501465 seconds for one epoch ---
--- 1.4265170097351074 seconds for one epoch ---
--- 0.30063962936401367 seconds for one epoch ---
--- 1.440566062927246 seconds for one epoch ---
--- 0.2981388568878174 seconds for one epoch ---
--- 1.4615662097930908 seconds for one epoch ---
--- 0.29558253288269043 seconds for one epoch ---
--- 1.4450926780700684 seconds for one epoch ---
--- 0.30509185791015625 seconds for one epoch ---
--- 1.4477543830871582 seconds for one epoch ---
--- 0.28805041313171387 seconds for one epoch ---
--- 1.4694066047668457 seconds for one epoch ---
--- 0.30692625045776367 seconds for one epoch ---
--- 1.467348337173462 seconds for one epoch ---
--- 0.305757999420166 seconds for one epoch ---
--- 1.4883618354797363 seconds for one epoch ---
--- 0.30242061614990234 seconds for one epoch ---
--- 1.4642002582550049 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14239867]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.541354]
 [ -0.      ]]
--- 0.289625883102417 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4309.68359375, (2196.3818, 2.6796386, 2110.4922, 0.12997977)
   validation loss 1016.4698486328125, (701.0777, 0.6378061, 314.62433, 0.12997977)
decoder loss ratio: 27160.967135, decoder SINDy loss  ratio: 0.679161
--- 0.2700963020324707 seconds for one epoch ---
--- 0.29753613471984863 seconds for one epoch ---
--- 1.4866182804107666 seconds for one epoch ---
--- 0.3068852424621582 seconds for one epoch ---
--- 1.4732298851013184 seconds for one epoch ---
--- 0.3001217842102051 seconds for one epoch ---
--- 1.4466288089752197 seconds for one epoch ---
--- 0.2978835105895996 seconds for one epoch ---
--- 1.4529454708099365 seconds for one epoch ---
--- 0.2886018753051758 seconds for one epoch ---
--- 1.469376564025879 seconds for one epoch ---
--- 0.2789764404296875 seconds for one epoch ---
--- 1.5084681510925293 seconds for one epoch ---
--- 0.29143738746643066 seconds for one epoch ---
--- 1.4958832263946533 seconds for one epoch ---
--- 0.3007926940917969 seconds for one epoch ---
--- 1.4676635265350342 seconds for one epoch ---
--- 0.3050804138183594 seconds for one epoch ---
--- 1.4916446208953857 seconds for one epoch ---
--- 0.3126802444458008 seconds for one epoch ---
--- 1.4741764068603516 seconds for one epoch ---
--- 0.3128345012664795 seconds for one epoch ---
--- 1.4805550575256348 seconds for one epoch ---
--- 0.30477452278137207 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14107947]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.604192]
 [ -0.      ]]
--- 0.26101231575012207 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3091.22900390625, (1513.7095, 0.3220257, 1577.0674, 0.13017063)
   validation loss 859.0939331054688, (545.4053, 0.73002946, 312.82846, 0.13017063)
decoder loss ratio: 21129.947158, decoder SINDy loss  ratio: 0.675284
--- 0.3010697364807129 seconds for one epoch ---
--- 1.4880049228668213 seconds for one epoch ---
--- 0.3017387390136719 seconds for one epoch ---
--- 1.4915821552276611 seconds for one epoch ---
--- 0.2943756580352783 seconds for one epoch ---
--- 1.434868574142456 seconds for one epoch ---
--- 0.2966318130493164 seconds for one epoch ---
--- 1.4287734031677246 seconds for one epoch ---
--- 0.29642748832702637 seconds for one epoch ---
--- 1.4630286693572998 seconds for one epoch ---
--- 0.29572081565856934 seconds for one epoch ---
--- 1.4593737125396729 seconds for one epoch ---
--- 0.2921910285949707 seconds for one epoch ---
--- 1.5117132663726807 seconds for one epoch ---
--- 0.29123783111572266 seconds for one epoch ---
--- 1.5083775520324707 seconds for one epoch ---
--- 0.29785752296447754 seconds for one epoch ---
--- 1.5060975551605225 seconds for one epoch ---
--- 0.2927224636077881 seconds for one epoch ---
--- 1.5035674571990967 seconds for one epoch ---
--- 0.2941710948944092 seconds for one epoch ---
--- 1.4940826892852783 seconds for one epoch ---
--- 0.2944028377532959 seconds for one epoch ---
--- 1.5250794887542725 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13965905]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.671413]
 [  0.      ]]
--- 0.2906007766723633 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4297.0078125, (1075.8054, 1.5070462, 3219.565, 0.13032691)
   validation loss 807.6068725585938, (509.15753, 0.7211932, 297.5978, 0.13032691)
decoder loss ratio: 19725.646716, decoder SINDy loss  ratio: 0.642407
--- 0.25663304328918457 seconds for one epoch ---
--- 0.3074226379394531 seconds for one epoch ---
--- 1.500004768371582 seconds for one epoch ---
--- 0.29103612899780273 seconds for one epoch ---
--- 1.4784259796142578 seconds for one epoch ---
--- 0.3038949966430664 seconds for one epoch ---
--- 1.4726612567901611 seconds for one epoch ---
--- 0.30730175971984863 seconds for one epoch ---
--- 1.45790696144104 seconds for one epoch ---
--- 0.28480958938598633 seconds for one epoch ---
--- 1.4602301120758057 seconds for one epoch ---
--- 0.30371618270874023 seconds for one epoch ---
--- 1.5159790515899658 seconds for one epoch ---
--- 0.3173348903656006 seconds for one epoch ---
--- 1.4874663352966309 seconds for one epoch ---
--- 0.3253953456878662 seconds for one epoch ---
--- 1.4913694858551025 seconds for one epoch ---
--- 0.3143463134765625 seconds for one epoch ---
--- 1.5098271369934082 seconds for one epoch ---
--- 0.3081369400024414 seconds for one epoch ---
--- 1.541644811630249 seconds for one epoch ---
--- 0.30246782302856445 seconds for one epoch ---
--- 1.5271294116973877 seconds for one epoch ---
--- 0.33023905754089355 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13815625]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.742036]
 [  0.      ]]
--- 0.25743675231933594 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2466.83154296875, (1142.5688, 1.3270556, 1322.805, 0.13053621)
   validation loss 878.2150268554688, (551.3364, 0.8020889, 325.94595, 0.13053621)
decoder loss ratio: 21359.730297, decoder SINDy loss  ratio: 0.703600
--- 0.3035893440246582 seconds for one epoch ---
--- 1.513563632965088 seconds for one epoch ---
--- 0.29686856269836426 seconds for one epoch ---
--- 1.5451819896697998 seconds for one epoch ---
--- 0.31455421447753906 seconds for one epoch ---
--- 1.504004716873169 seconds for one epoch ---
--- 0.29543066024780273 seconds for one epoch ---
--- 1.4752750396728516 seconds for one epoch ---
--- 0.2972836494445801 seconds for one epoch ---
--- 1.4848618507385254 seconds for one epoch ---
--- 0.29964637756347656 seconds for one epoch ---
--- 1.5012693405151367 seconds for one epoch ---
--- 0.31200480461120605 seconds for one epoch ---
--- 1.5291812419891357 seconds for one epoch ---
--- 0.32334041595458984 seconds for one epoch ---
--- 1.5329928398132324 seconds for one epoch ---
--- 0.3219339847564697 seconds for one epoch ---
--- 1.543081283569336 seconds for one epoch ---
--- 0.3130626678466797 seconds for one epoch ---
--- 1.5424423217773438 seconds for one epoch ---
--- 0.36237382888793945 seconds for one epoch ---
--- 1.528273582458496 seconds for one epoch ---
--- 0.3391580581665039 seconds for one epoch ---
--- 1.5486772060394287 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13705112]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.793668]
 [ -0.      ]]
--- 0.29036426544189453 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2340.526611328125, (1149.624, 1.6641488, 1189.1078, 0.13067554)
   validation loss 888.0398559570312, (560.6264, 0.8133997, 326.4694, 0.13067554)
decoder loss ratio: 21719.640174, decoder SINDy loss  ratio: 0.704730
--- 0.2638711929321289 seconds for one epoch ---
--- 0.30115389823913574 seconds for one epoch ---
--- 1.5256152153015137 seconds for one epoch ---
--- 0.2954752445220947 seconds for one epoch ---
--- 1.555025577545166 seconds for one epoch ---
--- 0.2977278232574463 seconds for one epoch ---
--- 1.485408067703247 seconds for one epoch ---
--- 0.2943427562713623 seconds for one epoch ---
--- 1.505495309829712 seconds for one epoch ---
--- 0.31038999557495117 seconds for one epoch ---
--- 1.519425392150879 seconds for one epoch ---
--- 0.29316186904907227 seconds for one epoch ---
--- 1.5326130390167236 seconds for one epoch ---
--- 0.3003230094909668 seconds for one epoch ---
--- 1.5507988929748535 seconds for one epoch ---
--- 0.30428099632263184 seconds for one epoch ---
--- 1.5230696201324463 seconds for one epoch ---
--- 0.29665541648864746 seconds for one epoch ---
--- 1.5416789054870605 seconds for one epoch ---
--- 0.30538487434387207 seconds for one epoch ---
--- 1.560800313949585 seconds for one epoch ---
--- 0.2946767807006836 seconds for one epoch ---
--- 1.5444166660308838 seconds for one epoch ---
--- 0.2972891330718994 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13523759]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.877904]
 [ -0.      ]]
--- 0.25831174850463867 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3718.279296875, (1398.7197, 2.9098628, 2316.5188, 0.13089465)
   validation loss 1083.296142578125, (780.93256, 0.7747796, 301.45798, 0.13089465)
decoder loss ratio: 30254.682984, decoder SINDy loss  ratio: 0.650739
--- 0.3017845153808594 seconds for one epoch ---
--- 1.5261166095733643 seconds for one epoch ---
--- 0.2879295349121094 seconds for one epoch ---
--- 1.5601484775543213 seconds for one epoch ---
--- 0.293748140335083 seconds for one epoch ---
--- 1.4942121505737305 seconds for one epoch ---
--- 0.30278468132019043 seconds for one epoch ---
--- 1.4942433834075928 seconds for one epoch ---
--- 0.2879960536956787 seconds for one epoch ---
--- 1.5426034927368164 seconds for one epoch ---
--- 0.2973506450653076 seconds for one epoch ---
--- 1.5560340881347656 seconds for one epoch ---
--- 0.3075876235961914 seconds for one epoch ---
--- 1.5509893894195557 seconds for one epoch ---
--- 0.2970426082611084 seconds for one epoch ---
--- 1.5237681865692139 seconds for one epoch ---
--- 0.30193662643432617 seconds for one epoch ---
--- 1.5398986339569092 seconds for one epoch ---
--- 0.285968542098999 seconds for one epoch ---
--- 1.5391132831573486 seconds for one epoch ---
--- 0.2984168529510498 seconds for one epoch ---
--- 1.5479865074157715 seconds for one epoch ---
--- 0.2957799434661865 seconds for one epoch ---
--- 1.5365631580352783 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13406494]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.932061]
 [  0.      ]]
--- 0.29419827461242676 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2813.257568359375, (1232.6078, 1.6770062, 1578.8417, 0.1310307)
   validation loss 1451.555419921875, (1075.6837, 0.89646757, 374.8442, 0.1310307)
decoder loss ratio: 41673.854620, decoder SINDy loss  ratio: 0.809154
--- 0.2672240734100342 seconds for one epoch ---
--- 0.3025784492492676 seconds for one epoch ---
--- 1.5367498397827148 seconds for one epoch ---
--- 0.3012733459472656 seconds for one epoch ---
--- 1.5309953689575195 seconds for one epoch ---
--- 0.30577540397644043 seconds for one epoch ---
--- 1.4779984951019287 seconds for one epoch ---
--- 0.2898378372192383 seconds for one epoch ---
--- 1.4923419952392578 seconds for one epoch ---
--- 0.2735888957977295 seconds for one epoch ---
--- 1.523714542388916 seconds for one epoch ---
--- 0.29001522064208984 seconds for one epoch ---
--- 1.5755829811096191 seconds for one epoch ---
--- 0.3036515712738037 seconds for one epoch ---
--- 1.5487542152404785 seconds for one epoch ---
--- 0.3064141273498535 seconds for one epoch ---
--- 1.5609588623046875 seconds for one epoch ---
--- 0.3117823600769043 seconds for one epoch ---
--- 1.5515670776367188 seconds for one epoch ---
--- 0.3116135597229004 seconds for one epoch ---
--- 1.5653226375579834 seconds for one epoch ---
--- 0.30559229850769043 seconds for one epoch ---
--- 1.545508861541748 seconds for one epoch ---
--- 0.31251072883605957 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13260351]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.999252]
 [  0.      ]]
--- 0.25705552101135254 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3772.4765625, (1294.6064, 0.6974506, 2477.0415, 0.13119048)
   validation loss 923.9231567382812, (572.71515, 1.093517, 349.98334, 0.13119048)
decoder loss ratio: 22187.979147, decoder SINDy loss  ratio: 0.755488
--- 0.29748010635375977 seconds for one epoch ---
--- 1.5444014072418213 seconds for one epoch ---
--- 0.30528759956359863 seconds for one epoch ---
--- 1.5640921592712402 seconds for one epoch ---
--- 0.2989058494567871 seconds for one epoch ---
--- 1.5358619689941406 seconds for one epoch ---
--- 0.2935614585876465 seconds for one epoch ---
--- 1.5061063766479492 seconds for one epoch ---
--- 0.30904364585876465 seconds for one epoch ---
--- 1.4936285018920898 seconds for one epoch ---
--- 0.29569172859191895 seconds for one epoch ---
--- 1.563621997833252 seconds for one epoch ---
--- 0.30988025665283203 seconds for one epoch ---
--- 1.5457561016082764 seconds for one epoch ---
--- 0.2936275005340576 seconds for one epoch ---
--- 1.5603725910186768 seconds for one epoch ---
--- 0.29671764373779297 seconds for one epoch ---
--- 1.5750131607055664 seconds for one epoch ---
--- 0.2945585250854492 seconds for one epoch ---
--- 1.5812816619873047 seconds for one epoch ---
--- 0.30246758460998535 seconds for one epoch ---
--- 1.5647003650665283 seconds for one epoch ---
--- 0.28877902030944824 seconds for one epoch ---
--- 1.601210594177246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13146052]
 [0.        ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.0515585]
 [ -0.       ]]
--- 0.2852489948272705 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2882.398193359375, (922.63934, 1.1910944, 1958.4364, 0.13132556)
   validation loss 791.473876953125, (485.29672, 0.87551266, 305.17032, 0.13132556)
decoder loss ratio: 18801.237538, decoder SINDy loss  ratio: 0.658753
--- 0.2580287456512451 seconds for one epoch ---
--- 0.2946023941040039 seconds for one epoch ---
--- 1.5452661514282227 seconds for one epoch ---
--- 0.2879929542541504 seconds for one epoch ---
--- 1.581944465637207 seconds for one epoch ---
--- 0.3099186420440674 seconds for one epoch ---
--- 1.5641779899597168 seconds for one epoch ---
--- 0.29175662994384766 seconds for one epoch ---
--- 1.5249297618865967 seconds for one epoch ---
--- 0.29324936866760254 seconds for one epoch ---
--- 1.5140678882598877 seconds for one epoch ---
--- 0.2930004596710205 seconds for one epoch ---
--- 1.5479307174682617 seconds for one epoch ---
--- 0.29691267013549805 seconds for one epoch ---
--- 1.5545825958251953 seconds for one epoch ---
--- 0.32983851432800293 seconds for one epoch ---
--- 1.581861972808838 seconds for one epoch ---
--- 0.33481454849243164 seconds for one epoch ---
--- 1.587404727935791 seconds for one epoch ---
--- 0.3297736644744873 seconds for one epoch ---
--- 1.596757411956787 seconds for one epoch ---
--- 0.3283243179321289 seconds for one epoch ---
--- 1.5766263008117676 seconds for one epoch ---
--- 0.3173978328704834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13017741]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.110067]
 [ -0.      ]]
--- 0.2622251510620117 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2543.00634765625, (1361.1512, 2.1083825, 1179.6151, 0.13146989)
   validation loss 1915.0921630859375, (1565.3267, 0.9959902, 348.63803, 0.13146989)
decoder loss ratio: 60643.472341, decoder SINDy loss  ratio: 0.752584
--- 0.2944810390472412 seconds for one epoch ---
--- 1.5838663578033447 seconds for one epoch ---
--- 0.30158352851867676 seconds for one epoch ---
--- 1.5801587104797363 seconds for one epoch ---
--- 0.29903650283813477 seconds for one epoch ---
--- 1.6044292449951172 seconds for one epoch ---
--- 0.28733086585998535 seconds for one epoch ---
--- 1.5549166202545166 seconds for one epoch ---
--- 0.28795480728149414 seconds for one epoch ---
--- 1.5485954284667969 seconds for one epoch ---
--- 0.30266618728637695 seconds for one epoch ---
--- 1.536262035369873 seconds for one epoch ---
--- 0.2976796627044678 seconds for one epoch ---
--- 1.5885272026062012 seconds for one epoch ---
--- 0.29541993141174316 seconds for one epoch ---
--- 1.574721336364746 seconds for one epoch ---
--- 0.2958409786224365 seconds for one epoch ---
--- 1.6073720455169678 seconds for one epoch ---
--- 0.29908180236816406 seconds for one epoch ---
--- 1.5798580646514893 seconds for one epoch ---
--- 0.2930130958557129 seconds for one epoch ---
--- 1.6018593311309814 seconds for one epoch ---
--- 0.31488728523254395 seconds for one epoch ---
--- 1.6056137084960938 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12892228]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.167097]
 [  0.      ]]
--- 0.29413294792175293 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2414.40234375, (961.70605, 0.5728153, 1451.9918, 0.13161175)
   validation loss 938.7181396484375, (605.7949, 0.87468004, 331.9169, 0.13161175)
decoder loss ratio: 23469.546980, decoder SINDy loss  ratio: 0.716489
--- 0.2678248882293701 seconds for one epoch ---
--- 0.3016180992126465 seconds for one epoch ---
--- 1.5898182392120361 seconds for one epoch ---
--- 0.2988452911376953 seconds for one epoch ---
--- 1.6259510517120361 seconds for one epoch ---
--- 0.2987532615661621 seconds for one epoch ---
--- 1.5827817916870117 seconds for one epoch ---
--- 0.2968282699584961 seconds for one epoch ---
--- 1.5707931518554688 seconds for one epoch ---
--- 0.290982723236084 seconds for one epoch ---
--- 1.5483818054199219 seconds for one epoch ---
--- 0.2979731559753418 seconds for one epoch ---
--- 1.6114776134490967 seconds for one epoch ---
--- 0.300396203994751 seconds for one epoch ---
--- 1.5936524868011475 seconds for one epoch ---
--- 0.3006417751312256 seconds for one epoch ---
--- 1.6147539615631104 seconds for one epoch ---
--- 0.29875659942626953 seconds for one epoch ---
--- 1.619950294494629 seconds for one epoch ---
--- 0.28438830375671387 seconds for one epoch ---
--- 1.605348825454712 seconds for one epoch ---
--- 0.29486536979675293 seconds for one epoch ---
--- 1.5765759944915771 seconds for one epoch ---
--- 0.2991328239440918 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12788662]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.214005]
 [  0.      ]]
--- 0.2550961971282959 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2490.929443359375, (997.4846, 1.5066191, 1491.8068, 0.13170683)
   validation loss 1157.148681640625, (801.1682, 0.7932464, 355.05548, 0.13170683)
decoder loss ratio: 31038.647457, decoder SINDy loss  ratio: 0.766437
--- 0.2948274612426758 seconds for one epoch ---
--- 1.5870985984802246 seconds for one epoch ---
--- 0.29592084884643555 seconds for one epoch ---
--- 1.5767593383789062 seconds for one epoch ---
--- 0.2934553623199463 seconds for one epoch ---
--- 1.6071531772613525 seconds for one epoch ---
--- 0.26324963569641113 seconds for one epoch ---
--- 1.5526187419891357 seconds for one epoch ---
--- 0.2897005081176758 seconds for one epoch ---
--- 1.5597331523895264 seconds for one epoch ---
--- 0.30161333084106445 seconds for one epoch ---
--- 1.5468907356262207 seconds for one epoch ---
--- 0.3354911804199219 seconds for one epoch ---
--- 1.5712392330169678 seconds for one epoch ---
--- 0.332003116607666 seconds for one epoch ---
--- 1.6392943859100342 seconds for one epoch ---
--- 0.32915496826171875 seconds for one epoch ---
--- 1.6123013496398926 seconds for one epoch ---
--- 0.32012033462524414 seconds for one epoch ---
--- 1.6294262409210205 seconds for one epoch ---
--- 0.33683180809020996 seconds for one epoch ---
--- 1.6036550998687744 seconds for one epoch ---
--- 0.3381783962249756 seconds for one epoch ---
--- 1.645543098449707 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12636101]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.282895]
 [ -0.      ]]
--- 0.2855660915374756 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2548.23388671875, (1125.2308, 0.88753515, 1421.9836, 0.13186106)
   validation loss 822.3096313476562, (522.7988, 0.8168396, 298.56213, 0.13186106)
decoder loss ratio: 20254.134220, decoder SINDy loss  ratio: 0.644488
--- 0.2639317512512207 seconds for one epoch ---
--- 0.2977933883666992 seconds for one epoch ---
--- 1.6162443161010742 seconds for one epoch ---
--- 0.30292224884033203 seconds for one epoch ---
--- 1.6107604503631592 seconds for one epoch ---
--- 0.3034830093383789 seconds for one epoch ---
--- 1.6420834064483643 seconds for one epoch ---
--- 0.2979390621185303 seconds for one epoch ---
--- 1.5724456310272217 seconds for one epoch ---
--- 0.2939472198486328 seconds for one epoch ---
--- 1.5767815113067627 seconds for one epoch ---
--- 0.29699277877807617 seconds for one epoch ---
--- 1.5878376960754395 seconds for one epoch ---
--- 0.2888808250427246 seconds for one epoch ---
--- 1.622657299041748 seconds for one epoch ---
--- 0.33122992515563965 seconds for one epoch ---
--- 1.6061890125274658 seconds for one epoch ---
--- 0.3018321990966797 seconds for one epoch ---
--- 1.612532377243042 seconds for one epoch ---
--- 0.30246782302856445 seconds for one epoch ---
--- 1.631500005722046 seconds for one epoch ---
--- 0.296722412109375 seconds for one epoch ---
--- 1.6369633674621582 seconds for one epoch ---
--- 0.30176782608032227 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1254229]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-14.3251505]
 [ -0.       ]]
--- 0.25130748748779297 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2316.732666015625, (949.73376, 1.2948862, 1365.5723, 0.13195474)
   validation loss 974.4696655273438, (655.81146, 0.8373395, 317.6889, 0.13195474)
decoder loss ratio: 25407.274592, decoder SINDy loss  ratio: 0.685776
--- 0.2818636894226074 seconds for one epoch ---
--- 1.624525785446167 seconds for one epoch ---
--- 0.283186674118042 seconds for one epoch ---
--- 1.6374316215515137 seconds for one epoch ---
--- 0.2974586486816406 seconds for one epoch ---
--- 1.6616532802581787 seconds for one epoch ---
--- 0.2932295799255371 seconds for one epoch ---
--- 1.5961568355560303 seconds for one epoch ---
--- 0.2893083095550537 seconds for one epoch ---
--- 1.6152026653289795 seconds for one epoch ---
--- 0.29800939559936523 seconds for one epoch ---
--- 1.5971705913543701 seconds for one epoch ---
--- 0.28943371772766113 seconds for one epoch ---
--- 1.6379683017730713 seconds for one epoch ---
--- 0.30517101287841797 seconds for one epoch ---
--- 1.6199324131011963 seconds for one epoch ---
--- 0.3173048496246338 seconds for one epoch ---
--- 1.6493539810180664 seconds for one epoch ---
--- 0.3185000419616699 seconds for one epoch ---
--- 1.6586921215057373 seconds for one epoch ---
--- 0.3218553066253662 seconds for one epoch ---
--- 1.6560440063476562 seconds for one epoch ---
--- 0.32314157485961914 seconds for one epoch ---
--- 1.6746275424957275 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12433424]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.374076]
 [  0.      ]]
--- 0.29917144775390625 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3161.971435546875, (1438.4226, 1.3683504, 1722.0485, 0.13206023)
   validation loss 824.5980224609375, (523.81055, 0.8256573, 299.8297, 0.13206023)
decoder loss ratio: 20293.329961, decoder SINDy loss  ratio: 0.647225
--- 0.2659952640533447 seconds for one epoch ---
--- 0.29809117317199707 seconds for one epoch ---
--- 1.6482837200164795 seconds for one epoch ---
--- 0.29377174377441406 seconds for one epoch ---
--- 1.6470160484313965 seconds for one epoch ---
--- 0.3093562126159668 seconds for one epoch ---
--- 1.652005672454834 seconds for one epoch ---
--- 0.28508973121643066 seconds for one epoch ---
--- 1.6031558513641357 seconds for one epoch ---
--- 0.30045151710510254 seconds for one epoch ---
--- 1.6024277210235596 seconds for one epoch ---
--- 0.29505014419555664 seconds for one epoch ---
--- 1.639098882675171 seconds for one epoch ---
--- 0.2966771125793457 seconds for one epoch ---
--- 1.6749012470245361 seconds for one epoch ---
--- 0.2946288585662842 seconds for one epoch ---
--- 1.6262950897216797 seconds for one epoch ---
--- 0.2919180393218994 seconds for one epoch ---
--- 1.658078908920288 seconds for one epoch ---
--- 0.3016061782836914 seconds for one epoch ---
--- 1.6888196468353271 seconds for one epoch ---
--- 0.30230140686035156 seconds for one epoch ---
--- 1.659492015838623 seconds for one epoch ---
--- 0.3057742118835449 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12316451]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.426536]
 [  0.      ]]
--- 0.25296759605407715 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2597.884033203125, (1180.562, 0.6663306, 1416.5236, 0.13217795)
   validation loss 925.8528442382812, (591.41296, 0.91497505, 333.3927, 0.13217795)
decoder loss ratio: 22912.364958, decoder SINDy loss  ratio: 0.719675
--- 0.2964622974395752 seconds for one epoch ---
--- 1.6576733589172363 seconds for one epoch ---
--- 0.30444836616516113 seconds for one epoch ---
--- 1.653665542602539 seconds for one epoch ---
--- 0.3060290813446045 seconds for one epoch ---
--- 1.6578412055969238 seconds for one epoch ---
--- 0.29590463638305664 seconds for one epoch ---
--- 1.622314691543579 seconds for one epoch ---
--- 0.2980458736419678 seconds for one epoch ---
--- 1.6423742771148682 seconds for one epoch ---
--- 0.29830074310302734 seconds for one epoch ---
--- 1.6624717712402344 seconds for one epoch ---
--- 0.2932133674621582 seconds for one epoch ---
--- 1.6756455898284912 seconds for one epoch ---
--- 0.3183107376098633 seconds for one epoch ---
--- 1.656219720840454 seconds for one epoch ---
--- 0.30359530448913574 seconds for one epoch ---
--- 1.6225697994232178 seconds for one epoch ---
--- 0.6027622222900391 seconds for one epoch ---
--- 1.648733377456665 seconds for one epoch ---
--- 0.26027727127075195 seconds for one epoch ---
--- 1.648360252380371 seconds for one epoch ---
--- 0.30109286308288574 seconds for one epoch ---
--- 1.6628749370574951 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12185369]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.485194]
 [ -0.      ]]
--- 0.2890803813934326 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2626.115234375, (1092.523, 1.5209129, 1531.939, 0.1323008)
   validation loss 779.9605712890625, (480.66193, 0.94106346, 298.22525, 0.1323008)
decoder loss ratio: 18621.677489, decoder SINDy loss  ratio: 0.643761
--- 0.25141072273254395 seconds for one epoch ---
--- 0.305880069732666 seconds for one epoch ---
--- 1.644975185394287 seconds for one epoch ---
--- 0.3010556697845459 seconds for one epoch ---
--- 1.6696486473083496 seconds for one epoch ---
--- 0.3069021701812744 seconds for one epoch ---
--- 1.6668872833251953 seconds for one epoch ---
--- 0.27338504791259766 seconds for one epoch ---
--- 1.6248338222503662 seconds for one epoch ---
--- 0.2904539108276367 seconds for one epoch ---
--- 1.6295135021209717 seconds for one epoch ---
--- 0.2837984561920166 seconds for one epoch ---
--- 1.607682704925537 seconds for one epoch ---
--- 0.2960469722747803 seconds for one epoch ---
--- 1.667630672454834 seconds for one epoch ---
--- 0.31897616386413574 seconds for one epoch ---
--- 1.6492247581481934 seconds for one epoch ---
--- 0.30700159072875977 seconds for one epoch ---
--- 1.6727302074432373 seconds for one epoch ---
--- 0.31090235710144043 seconds for one epoch ---
--- 1.6771774291992188 seconds for one epoch ---
--- 0.31895875930786133 seconds for one epoch ---
--- 1.6964938640594482 seconds for one epoch ---
--- 0.3123610019683838 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12068901]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.537223]
 [ -0.      ]]
--- 0.2555673122406006 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1673.1102294921875, (964.8234, 0.9158006, 707.2386, 0.1324138)
   validation loss 934.193115234375, (619.3253, 0.88319635, 313.85223, 0.1324138)
decoder loss ratio: 23993.737991, decoder SINDy loss  ratio: 0.677494
--- 0.2950890064239502 seconds for one epoch ---
--- 1.672766923904419 seconds for one epoch ---
--- 0.2939579486846924 seconds for one epoch ---
--- 1.6705594062805176 seconds for one epoch ---
--- 0.29167795181274414 seconds for one epoch ---
--- 1.6714913845062256 seconds for one epoch ---
--- 0.29119873046875 seconds for one epoch ---
--- 1.6232120990753174 seconds for one epoch ---
--- 0.2948911190032959 seconds for one epoch ---
--- 1.6490685939788818 seconds for one epoch ---
--- 0.30233311653137207 seconds for one epoch ---
--- 1.6055448055267334 seconds for one epoch ---
--- 0.30216217041015625 seconds for one epoch ---
--- 1.6595110893249512 seconds for one epoch ---
--- 0.3017902374267578 seconds for one epoch ---
--- 1.6353142261505127 seconds for one epoch ---
--- 0.29993367195129395 seconds for one epoch ---
--- 1.707930326461792 seconds for one epoch ---
--- 0.2737877368927002 seconds for one epoch ---
--- 1.6783685684204102 seconds for one epoch ---
--- 0.2769429683685303 seconds for one epoch ---
--- 1.6641016006469727 seconds for one epoch ---
--- 0.28929924964904785 seconds for one epoch ---
--- 1.6833627223968506 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11931354]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.598557]
 [  0.      ]]
--- 0.303006649017334 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2656.378173828125, (1353.5531, 1.3126843, 1301.3798, 0.13253848)
   validation loss 952.226806640625, (611.0468, 1.0143294, 340.0331, 0.13253848)
decoder loss ratio: 23673.014397, decoder SINDy loss  ratio: 0.734009
THRESHOLDING: 1 active coefficients
--- 0.2538948059082031 seconds for one epoch ---
--- 0.2958834171295166 seconds for one epoch ---
--- 1.7012972831726074 seconds for one epoch ---
--- 0.303973913192749 seconds for one epoch ---
--- 1.7012763023376465 seconds for one epoch ---
--- 0.29967188835144043 seconds for one epoch ---
--- 1.6752941608428955 seconds for one epoch ---
--- 0.30289745330810547 seconds for one epoch ---
--- 1.7003049850463867 seconds for one epoch ---
--- 0.2830691337585449 seconds for one epoch ---
--- 1.6979773044586182 seconds for one epoch ---
--- 0.2960495948791504 seconds for one epoch ---
--- 1.694929838180542 seconds for one epoch ---
--- 0.2845737934112549 seconds for one epoch ---
--- 1.6833314895629883 seconds for one epoch ---
--- 0.2910139560699463 seconds for one epoch ---
--- 1.7056605815887451 seconds for one epoch ---
--- 0.2944145202636719 seconds for one epoch ---
--- 1.7168679237365723 seconds for one epoch ---
--- 0.30172252655029297 seconds for one epoch ---
--- 1.7162988185882568 seconds for one epoch ---
--- 0.29569315910339355 seconds for one epoch ---
--- 1.719855546951294 seconds for one epoch ---
--- 0.28974056243896484 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11810941]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.652184]
 [  0.      ]]
--- 0.25438475608825684 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4994.45166015625, (1477.6606, 2.2888458, 3514.3694, 0.13264246)
   validation loss 802.0700073242188, (489.35382, 1.0534295, 311.53015, 0.13264246)
decoder loss ratio: 18958.416573, decoder SINDy loss  ratio: 0.672482
--- 0.29213953018188477 seconds for one epoch ---
--- 1.6742079257965088 seconds for one epoch ---
--- 0.28318357467651367 seconds for one epoch ---
--- 1.6859114170074463 seconds for one epoch ---
--- 0.299882173538208 seconds for one epoch ---
--- 1.697916030883789 seconds for one epoch ---
--- 0.28678417205810547 seconds for one epoch ---
--- 1.6875474452972412 seconds for one epoch ---
--- 0.29641056060791016 seconds for one epoch ---
--- 1.6911327838897705 seconds for one epoch ---
--- 0.2882041931152344 seconds for one epoch ---
--- 1.7242679595947266 seconds for one epoch ---
--- 0.2984168529510498 seconds for one epoch ---
--- 1.7265188694000244 seconds for one epoch ---
--- 0.29498887062072754 seconds for one epoch ---
--- 1.7175321578979492 seconds for one epoch ---
--- 0.2988307476043701 seconds for one epoch ---
--- 1.7098257541656494 seconds for one epoch ---
--- 0.30365729331970215 seconds for one epoch ---
--- 1.7056941986083984 seconds for one epoch ---
--- 0.3024740219116211 seconds for one epoch ---
--- 1.7137463092803955 seconds for one epoch ---
--- 0.3007347583770752 seconds for one epoch ---
--- 1.7108614444732666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11702375]
 [0.        ]]
[[ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.7004795]
 [ -0.       ]]
--- 0.29041433334350586 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2327.411865234375, (1018.88715, 3.7581596, 1304.6337, 0.13273518)
   validation loss 836.2883911132812, (518.3445, 1.1534084, 316.65778, 0.13273518)
decoder loss ratio: 20081.565135, decoder SINDy loss  ratio: 0.683550
--- 0.26618146896362305 seconds for one epoch ---
--- 0.2892720699310303 seconds for one epoch ---
--- 1.709892988204956 seconds for one epoch ---
--- 0.29448461532592773 seconds for one epoch ---
--- 1.717473030090332 seconds for one epoch ---
--- 0.2988450527191162 seconds for one epoch ---
--- 1.7233407497406006 seconds for one epoch ---
--- 0.29511451721191406 seconds for one epoch ---
--- 1.7057106494903564 seconds for one epoch ---
--- 0.28823089599609375 seconds for one epoch ---
--- 1.7445425987243652 seconds for one epoch ---
--- 0.29241085052490234 seconds for one epoch ---
--- 1.7215886116027832 seconds for one epoch ---
--- 0.3024919033050537 seconds for one epoch ---
--- 1.726893663406372 seconds for one epoch ---
--- 0.28720617294311523 seconds for one epoch ---
--- 1.7052524089813232 seconds for one epoch ---
--- 0.30389952659606934 seconds for one epoch ---
--- 1.7162315845489502 seconds for one epoch ---
--- 0.29144835472106934 seconds for one epoch ---
--- 1.7177956104278564 seconds for one epoch ---
--- 0.29451918601989746 seconds for one epoch ---
--- 1.7291197776794434 seconds for one epoch ---
--- 0.29289817810058594 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11599565]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.746173]
 [ -0.      ]]
--- 0.26703310012817383 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2050.58447265625, (1122.1506, 1.3585798, 926.9426, 0.1328266)
   validation loss 1005.9266967773438, (701.17194, 1.0096638, 303.6123, 0.1328266)
decoder loss ratio: 27164.618090, decoder SINDy loss  ratio: 0.655390
--- 0.3017852306365967 seconds for one epoch ---
--- 1.7575082778930664 seconds for one epoch ---
--- 0.2957723140716553 seconds for one epoch ---
--- 1.7439806461334229 seconds for one epoch ---
--- 0.3177506923675537 seconds for one epoch ---
--- 1.73016357421875 seconds for one epoch ---
--- 0.33328866958618164 seconds for one epoch ---
--- 1.736854076385498 seconds for one epoch ---
--- 0.2957432270050049 seconds for one epoch ---
--- 1.7373542785644531 seconds for one epoch ---
--- 0.29342150688171387 seconds for one epoch ---
--- 1.7508020401000977 seconds for one epoch ---
--- 0.2906620502471924 seconds for one epoch ---
--- 1.7493338584899902 seconds for one epoch ---
--- 0.29618239402770996 seconds for one epoch ---
--- 1.7597401142120361 seconds for one epoch ---
--- 0.29798436164855957 seconds for one epoch ---
--- 1.7598114013671875 seconds for one epoch ---
--- 0.287203311920166 seconds for one epoch ---
--- 1.743807315826416 seconds for one epoch ---
--- 0.3058907985687256 seconds for one epoch ---
--- 1.7544634342193604 seconds for one epoch ---
--- 0.3125343322753906 seconds for one epoch ---
--- 1.723555088043213 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11484681]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.797208]
 [  0.      ]]
--- 0.29416608810424805 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2518.7978515625, (1126.2965, 2.998236, 1389.3702, 0.1329248)
   validation loss 756.9407958984375, (449.16226, 1.0553671, 306.5902, 0.1329248)
decoder loss ratio: 17401.325808, decoder SINDy loss  ratio: 0.661818
--- 0.257798433303833 seconds for one epoch ---
--- 0.295304536819458 seconds for one epoch ---
--- 1.7343990802764893 seconds for one epoch ---
--- 0.3022890090942383 seconds for one epoch ---
--- 1.6892521381378174 seconds for one epoch ---
--- 0.28986644744873047 seconds for one epoch ---
--- 1.7283034324645996 seconds for one epoch ---
--- 0.2824685573577881 seconds for one epoch ---
--- 1.7206459045410156 seconds for one epoch ---
--- 0.29404139518737793 seconds for one epoch ---
--- 1.7119145393371582 seconds for one epoch ---
--- 0.27487874031066895 seconds for one epoch ---
--- 1.7405283451080322 seconds for one epoch ---
--- 0.299999475479126 seconds for one epoch ---
--- 1.7533645629882812 seconds for one epoch ---
--- 0.2953507900238037 seconds for one epoch ---
--- 1.7658581733703613 seconds for one epoch ---
--- 0.2982635498046875 seconds for one epoch ---
--- 1.7537882328033447 seconds for one epoch ---
--- 0.30128979682922363 seconds for one epoch ---
--- 1.760838270187378 seconds for one epoch ---
--- 0.29749226570129395 seconds for one epoch ---
--- 1.7723734378814697 seconds for one epoch ---
--- 0.29077672958374023 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11360537]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.852316]
 [  0.      ]]
--- 0.26297521591186523 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1585.951416015625, (819.3228, 0.3796923, 766.1159, 0.1330254)
   validation loss 1474.3358154296875, (1098.7823, 1.2819123, 374.13858, 0.1330254)
decoder loss ratio: 42568.735756, decoder SINDy loss  ratio: 0.807631
--- 0.2964808940887451 seconds for one epoch ---
--- 1.7642431259155273 seconds for one epoch ---
--- 0.2871897220611572 seconds for one epoch ---
--- 1.7630925178527832 seconds for one epoch ---
--- 0.29824280738830566 seconds for one epoch ---
--- 1.7555584907531738 seconds for one epoch ---
--- 0.29993271827697754 seconds for one epoch ---
--- 1.778597354888916 seconds for one epoch ---
--- 0.30783748626708984 seconds for one epoch ---
--- 1.7465476989746094 seconds for one epoch ---
--- 0.3053152561187744 seconds for one epoch ---
--- 1.7440056800842285 seconds for one epoch ---
--- 0.314849853515625 seconds for one epoch ---
--- 1.7796506881713867 seconds for one epoch ---
--- 0.3292574882507324 seconds for one epoch ---
--- 1.7678897380828857 seconds for one epoch ---
--- 0.3373379707336426 seconds for one epoch ---
--- 1.7775704860687256 seconds for one epoch ---
--- 0.3368978500366211 seconds for one epoch ---
--- 1.7868239879608154 seconds for one epoch ---
--- 0.33777761459350586 seconds for one epoch ---
--- 1.774993896484375 seconds for one epoch ---
--- 0.34230899810791016 seconds for one epoch ---
--- 1.794189453125 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1123528]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.907914]
 [ -0.      ]]
--- 0.2879066467285156 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1709.9080810546875, (646.25305, 2.3543994, 1061.1675, 0.13313575)
   validation loss 911.6124877929688, (605.64325, 1.138049, 304.6981, 0.13313575)
decoder loss ratio: 23463.670929, decoder SINDy loss  ratio: 0.657734
--- 0.25625014305114746 seconds for one epoch ---
--- 0.31557202339172363 seconds for one epoch ---
--- 1.7781119346618652 seconds for one epoch ---
--- 0.2962942123413086 seconds for one epoch ---
--- 1.7789297103881836 seconds for one epoch ---
--- 0.27664732933044434 seconds for one epoch ---
--- 1.7881381511688232 seconds for one epoch ---
--- 0.2921264171600342 seconds for one epoch ---
--- 1.7448985576629639 seconds for one epoch ---
--- 0.28619813919067383 seconds for one epoch ---
--- 1.7668132781982422 seconds for one epoch ---
--- 0.29645371437072754 seconds for one epoch ---
--- 1.7867369651794434 seconds for one epoch ---
--- 0.2969837188720703 seconds for one epoch ---
--- 1.7815649509429932 seconds for one epoch ---
--- 0.2962150573730469 seconds for one epoch ---
--- 1.7731719017028809 seconds for one epoch ---
--- 0.29057979583740234 seconds for one epoch ---
--- 1.7699370384216309 seconds for one epoch ---
--- 0.29197216033935547 seconds for one epoch ---
--- 1.754610538482666 seconds for one epoch ---
--- 0.3005204200744629 seconds for one epoch ---
--- 1.7758140563964844 seconds for one epoch ---
--- 0.29760050773620605 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11088524]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.973044]
 [ -0.      ]]
--- 0.2599787712097168 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3036.15625, (1251.1504, 0.9297744, 1783.9429, 0.13325149)
   validation loss 938.8692016601562, (624.77765, 1.1230506, 312.8353, 0.13325149)
decoder loss ratio: 24204.970781, decoder SINDy loss  ratio: 0.675299
--- 0.3095128536224365 seconds for one epoch ---
--- 1.7717454433441162 seconds for one epoch ---
--- 0.30986738204956055 seconds for one epoch ---
--- 1.780860185623169 seconds for one epoch ---
--- 0.31148266792297363 seconds for one epoch ---
--- 1.780024766921997 seconds for one epoch ---
--- 0.3017096519470215 seconds for one epoch ---
--- 1.7747437953948975 seconds for one epoch ---
--- 0.3063390254974365 seconds for one epoch ---
--- 1.7711169719696045 seconds for one epoch ---
--- 0.2915012836456299 seconds for one epoch ---
--- 1.7694478034973145 seconds for one epoch ---
--- 0.30760669708251953 seconds for one epoch ---
--- 1.7509243488311768 seconds for one epoch ---
--- 0.29840779304504395 seconds for one epoch ---
--- 1.7789554595947266 seconds for one epoch ---
--- 0.3074822425842285 seconds for one epoch ---
--- 1.7432293891906738 seconds for one epoch ---
--- 0.29585742950439453 seconds for one epoch ---
--- 1.7812578678131104 seconds for one epoch ---
--- 0.27590227127075195 seconds for one epoch ---
--- 1.798332691192627 seconds for one epoch ---
--- 0.2937889099121094 seconds for one epoch ---
--- 1.7920374870300293 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11001839]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.011511]
 [  0.      ]]
--- 0.31946444511413574 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2873.709228515625, (1259.397, 0.9150909, 1613.2639, 0.13331911)
   validation loss 843.0626831054688, (526.3231, 1.1157433, 315.49054, 0.13331911)
decoder loss ratio: 20390.671410, decoder SINDy loss  ratio: 0.681031
--- 0.2789285182952881 seconds for one epoch ---
--- 0.3354780673980713 seconds for one epoch ---
--- 1.8033640384674072 seconds for one epoch ---
--- 0.30451178550720215 seconds for one epoch ---
--- 1.8160810470581055 seconds for one epoch ---
--- 0.29738950729370117 seconds for one epoch ---
--- 1.7938401699066162 seconds for one epoch ---
--- 0.2999114990234375 seconds for one epoch ---
--- 1.7651197910308838 seconds for one epoch ---
--- 0.29645848274230957 seconds for one epoch ---
--- 1.7986888885498047 seconds for one epoch ---
--- 0.29920220375061035 seconds for one epoch ---
--- 1.7767255306243896 seconds for one epoch ---
--- 0.30602598190307617 seconds for one epoch ---
--- 1.7926135063171387 seconds for one epoch ---
--- 0.311692476272583 seconds for one epoch ---
--- 1.8037967681884766 seconds for one epoch ---
--- 0.2971823215484619 seconds for one epoch ---
--- 1.789217233657837 seconds for one epoch ---
--- 0.3063931465148926 seconds for one epoch ---
--- 1.7908658981323242 seconds for one epoch ---
--- 0.3005638122558594 seconds for one epoch ---
--- 1.7854948043823242 seconds for one epoch ---
--- 0.28920650482177734 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10913134]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.050893]
 [  0.      ]]
--- 0.2529914379119873 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2950.879638671875, (1294.3055, 7.1688957, 1649.2719, 0.13339113)
   validation loss 969.4672241210938, (587.46027, 1.2131445, 380.66043, 0.13339113)
decoder loss ratio: 22759.230585, decoder SINDy loss  ratio: 0.821709
--- 0.2884976863861084 seconds for one epoch ---
--- 1.7898101806640625 seconds for one epoch ---
--- 0.3033254146575928 seconds for one epoch ---
--- 1.795060634613037 seconds for one epoch ---
--- 0.30338001251220703 seconds for one epoch ---
--- 1.7826778888702393 seconds for one epoch ---
--- 0.31182265281677246 seconds for one epoch ---
--- 1.7852683067321777 seconds for one epoch ---
--- 0.2998218536376953 seconds for one epoch ---
--- 1.8158290386199951 seconds for one epoch ---
--- 0.3000454902648926 seconds for one epoch ---
--- 1.7756855487823486 seconds for one epoch ---
--- 0.295928955078125 seconds for one epoch ---
--- 1.8212370872497559 seconds for one epoch ---
--- 0.30281686782836914 seconds for one epoch ---
--- 1.7998671531677246 seconds for one epoch ---
--- 0.29756999015808105 seconds for one epoch ---
--- 1.7989709377288818 seconds for one epoch ---
--- 0.2848975658416748 seconds for one epoch ---
--- 1.787569284439087 seconds for one epoch ---
--- 0.28408336639404297 seconds for one epoch ---
--- 1.825120449066162 seconds for one epoch ---
--- 0.28289794921875 seconds for one epoch ---
--- 1.8110980987548828 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10810088]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-15.09665]
 [ -0.     ]]
--- 0.29506540298461914 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1470.3612060546875, (647.3104, 2.3084743, 820.60895, 0.13347314)
   validation loss 963.6629028320312, (653.61743, 1.0622871, 308.8497, 0.13347314)
decoder loss ratio: 25322.274032, decoder SINDy loss  ratio: 0.666696
--- 0.2595820426940918 seconds for one epoch ---
--- 0.29718565940856934 seconds for one epoch ---
--- 1.8004848957061768 seconds for one epoch ---
--- 0.28746533393859863 seconds for one epoch ---
--- 1.8159162998199463 seconds for one epoch ---
--- 0.2876701354980469 seconds for one epoch ---
--- 1.7986271381378174 seconds for one epoch ---
--- 0.2942209243774414 seconds for one epoch ---
--- 1.80845308303833 seconds for one epoch ---
--- 0.3100779056549072 seconds for one epoch ---
--- 1.809899091720581 seconds for one epoch ---
--- 0.29463648796081543 seconds for one epoch ---
--- 1.8062670230865479 seconds for one epoch ---
--- 0.29169321060180664 seconds for one epoch ---
--- 1.8181748390197754 seconds for one epoch ---
--- 0.30582404136657715 seconds for one epoch ---
--- 1.8052575588226318 seconds for one epoch ---
--- 0.2943840026855469 seconds for one epoch ---
--- 1.8146321773529053 seconds for one epoch ---
--- 0.3073246479034424 seconds for one epoch ---
--- 1.8206346035003662 seconds for one epoch ---
--- 0.3014400005340576 seconds for one epoch ---
--- 1.7896614074707031 seconds for one epoch ---
--- 0.30400848388671875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10709694]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.141256]
 [ -0.      ]]
--- 0.2501847743988037 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2761.587158203125, (1633.8029, 0.8527452, 1126.7981, 0.13355312)
   validation loss 1048.1895751953125, (693.3518, 1.1336223, 353.57065, 0.13355312)
decoder loss ratio: 26861.652701, decoder SINDy loss  ratio: 0.763232
--- 0.29432058334350586 seconds for one epoch ---
--- 1.7858028411865234 seconds for one epoch ---
--- 0.3012850284576416 seconds for one epoch ---
--- 1.836432933807373 seconds for one epoch ---
--- 0.305431604385376 seconds for one epoch ---
--- 1.8239028453826904 seconds for one epoch ---
--- 0.2858765125274658 seconds for one epoch ---
--- 1.8319792747497559 seconds for one epoch ---
--- 0.30118513107299805 seconds for one epoch ---
--- 1.8207173347473145 seconds for one epoch ---
--- 0.29888153076171875 seconds for one epoch ---
--- 1.8178536891937256 seconds for one epoch ---
--- 0.30540966987609863 seconds for one epoch ---
--- 1.8129172325134277 seconds for one epoch ---
--- 0.31116485595703125 seconds for one epoch ---
--- 1.7955913543701172 seconds for one epoch ---
--- 0.2994356155395508 seconds for one epoch ---
--- 1.831578016281128 seconds for one epoch ---
--- 0.3114173412322998 seconds for one epoch ---
--- 1.8036723136901855 seconds for one epoch ---
--- 0.31219005584716797 seconds for one epoch ---
--- 1.7994141578674316 seconds for one epoch ---
--- 0.30476999282836914 seconds for one epoch ---
--- 1.8445167541503906 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10605906]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.187403]
 [  0.      ]]
--- 0.3130013942718506 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3411.170166015625, (1211.0226, 1.268631, 2198.7454, 0.13363004)
   validation loss 1098.4844970703125, (740.9468, 1.209891, 356.19412, 0.13363004)
decoder loss ratio: 28705.564494, decoder SINDy loss  ratio: 0.768895
--- 0.2721574306488037 seconds for one epoch ---
--- 0.32386183738708496 seconds for one epoch ---
--- 1.8353123664855957 seconds for one epoch ---
--- 0.321688175201416 seconds for one epoch ---
--- 1.8664937019348145 seconds for one epoch ---
--- 0.30788660049438477 seconds for one epoch ---
--- 1.842499017715454 seconds for one epoch ---
--- 0.30086588859558105 seconds for one epoch ---
--- 1.8143985271453857 seconds for one epoch ---
--- 0.290360689163208 seconds for one epoch ---
--- 1.836397647857666 seconds for one epoch ---
--- 0.2929039001464844 seconds for one epoch ---
--- 1.8258635997772217 seconds for one epoch ---
--- 0.3101825714111328 seconds for one epoch ---
--- 1.8004541397094727 seconds for one epoch ---
--- 0.3049943447113037 seconds for one epoch ---
--- 1.8102643489837646 seconds for one epoch ---
--- 0.29634881019592285 seconds for one epoch ---
--- 1.8546473979949951 seconds for one epoch ---
--- 0.29234790802001953 seconds for one epoch ---
--- 1.8670127391815186 seconds for one epoch ---
--- 0.3085026741027832 seconds for one epoch ---
--- 1.841517448425293 seconds for one epoch ---
--- 0.30291128158569336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10505483]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.232098]
 [  0.      ]]
--- 0.2567024230957031 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2440.723876953125, (925.4037, 1.8524743, 1513.3339, 0.13370474)
   validation loss 788.5165405273438, (480.1184, 0.9657148, 307.2987, 0.13370474)
decoder loss ratio: 18600.620656, decoder SINDy loss  ratio: 0.663347
--- 0.2972114086151123 seconds for one epoch ---
--- 1.8322601318359375 seconds for one epoch ---
--- 0.2871894836425781 seconds for one epoch ---
--- 1.8465244770050049 seconds for one epoch ---
--- 0.29360508918762207 seconds for one epoch ---
--- 1.8464350700378418 seconds for one epoch ---
--- 0.28553128242492676 seconds for one epoch ---
--- 1.809976577758789 seconds for one epoch ---
--- 0.2845945358276367 seconds for one epoch ---
--- 1.8173515796661377 seconds for one epoch ---
--- 0.2994542121887207 seconds for one epoch ---
--- 1.810875654220581 seconds for one epoch ---
--- 0.30582642555236816 seconds for one epoch ---
--- 1.8207931518554688 seconds for one epoch ---
--- 0.2995314598083496 seconds for one epoch ---
--- 1.8428535461425781 seconds for one epoch ---
--- 0.29914164543151855 seconds for one epoch ---
--- 1.8233368396759033 seconds for one epoch ---
--- 0.29469919204711914 seconds for one epoch ---
--- 1.8343582153320312 seconds for one epoch ---
--- 0.2915000915527344 seconds for one epoch ---
--- 1.8114190101623535 seconds for one epoch ---
--- 0.29324913024902344 seconds for one epoch ---
--- 1.8186323642730713 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10418184]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.270978]
 [ -0.      ]]
--- 0.30404067039489746 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4101.2841796875, (1194.5211, 2.3988192, 2904.2302, 0.13377194)
   validation loss 812.1678466796875, (511.84146, 0.9734123, 299.21918, 0.13377194)
decoder loss ratio: 19829.626802, decoder SINDy loss  ratio: 0.645907
--- 0.26404452323913574 seconds for one epoch ---
--- 0.2951538562774658 seconds for one epoch ---
--- 1.8438377380371094 seconds for one epoch ---
--- 0.2959868907928467 seconds for one epoch ---
--- 1.8692474365234375 seconds for one epoch ---
--- 0.30141568183898926 seconds for one epoch ---
--- 1.8479621410369873 seconds for one epoch ---
--- 0.2961766719818115 seconds for one epoch ---
--- 1.8549244403839111 seconds for one epoch ---
--- 0.29132509231567383 seconds for one epoch ---
--- 1.870187520980835 seconds for one epoch ---
--- 0.28565478324890137 seconds for one epoch ---
--- 1.8616042137145996 seconds for one epoch ---
--- 0.27729153633117676 seconds for one epoch ---
--- 1.8746788501739502 seconds for one epoch ---
--- 0.29772233963012695 seconds for one epoch ---
--- 1.864175796508789 seconds for one epoch ---
--- 0.29691362380981445 seconds for one epoch ---
--- 1.8785967826843262 seconds for one epoch ---
--- 0.28724074363708496 seconds for one epoch ---
--- 1.9039134979248047 seconds for one epoch ---
--- 0.29285264015197754 seconds for one epoch ---
--- 1.8871302604675293 seconds for one epoch ---
--- 0.29293274879455566 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10306311]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.320854]
 [ -0.      ]]
--- 0.2723839282989502 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1739.3292236328125, (969.1475, 0.6144537, 769.4333, 0.13385172)
   validation loss 1061.2740478515625, (757.3862, 0.96290356, 302.79108, 0.13385172)
decoder loss ratio: 29342.457449, decoder SINDy loss  ratio: 0.653617
--- 0.3135673999786377 seconds for one epoch ---
--- 1.8843231201171875 seconds for one epoch ---
--- 0.3170590400695801 seconds for one epoch ---
--- 1.8558332920074463 seconds for one epoch ---
--- 0.341829776763916 seconds for one epoch ---
--- 1.8555004596710205 seconds for one epoch ---
--- 0.32985424995422363 seconds for one epoch ---
--- 1.8320331573486328 seconds for one epoch ---
--- 0.315962553024292 seconds for one epoch ---
--- 1.8746812343597412 seconds for one epoch ---
--- 0.31731724739074707 seconds for one epoch ---
--- 1.8826136589050293 seconds for one epoch ---
--- 0.3092200756072998 seconds for one epoch ---
--- 1.8709208965301514 seconds for one epoch ---
--- 0.30690932273864746 seconds for one epoch ---
--- 1.8874962329864502 seconds for one epoch ---
--- 0.29790234565734863 seconds for one epoch ---
--- 1.8983960151672363 seconds for one epoch ---
--- 0.29768872261047363 seconds for one epoch ---
--- 1.8912382125854492 seconds for one epoch ---
--- 0.29615283012390137 seconds for one epoch ---
--- 1.9020931720733643 seconds for one epoch ---
--- 0.2899954319000244 seconds for one epoch ---
--- 1.8905584812164307 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10222577]
 [0.        ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.3582325]
 [  0.       ]]
--- 0.2961137294769287 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3312.157470703125, (866.1218, 2.0836475, 2443.8179, 0.13391715)
   validation loss 1323.5875244140625, (977.12024, 1.129872, 345.20352, 0.13391715)
decoder loss ratio: 37855.334424, decoder SINDy loss  ratio: 0.745170
--- 0.2372574806213379 seconds for one epoch ---
--- 0.3043482303619385 seconds for one epoch ---
--- 1.8710567951202393 seconds for one epoch ---
--- 0.28202128410339355 seconds for one epoch ---
--- 1.8512413501739502 seconds for one epoch ---
--- 0.29250597953796387 seconds for one epoch ---
--- 1.892155408859253 seconds for one epoch ---
--- 0.2856636047363281 seconds for one epoch ---
--- 1.8525910377502441 seconds for one epoch ---
--- 0.29522228240966797 seconds for one epoch ---
--- 1.8585765361785889 seconds for one epoch ---
--- 0.2862722873687744 seconds for one epoch ---
--- 1.8432157039642334 seconds for one epoch ---
--- 0.30591249465942383 seconds for one epoch ---
--- 1.8862559795379639 seconds for one epoch ---
--- 0.32360124588012695 seconds for one epoch ---
--- 1.8946096897125244 seconds for one epoch ---
--- 0.3368515968322754 seconds for one epoch ---
--- 1.8562204837799072 seconds for one epoch ---
--- 0.30512356758117676 seconds for one epoch ---
--- 1.879077434539795 seconds for one epoch ---
--- 0.30601978302001953 seconds for one epoch ---
--- 1.8756535053253174 seconds for one epoch ---
--- 0.31043410301208496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10134968]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.397389]
 [  0.      ]]
--- 0.25849175453186035 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4173.44189453125, (1772.6221, 3.478505, 2397.2075, 0.13397758)
   validation loss 1134.6121826171875, (803.76904, 1.1374947, 329.5716, 0.13397758)
decoder loss ratio: 31139.408129, decoder SINDy loss  ratio: 0.711427
--- 0.3001060485839844 seconds for one epoch ---
--- 1.8583831787109375 seconds for one epoch ---
--- 0.30345654487609863 seconds for one epoch ---
--- 1.8964974880218506 seconds for one epoch ---
--- 0.2996842861175537 seconds for one epoch ---
--- 1.9050781726837158 seconds for one epoch ---
--- 0.2912266254425049 seconds for one epoch ---
--- 1.8818767070770264 seconds for one epoch ---
--- 0.2827761173248291 seconds for one epoch ---
--- 1.8838648796081543 seconds for one epoch ---
--- 0.2962014675140381 seconds for one epoch ---
--- 1.8715941905975342 seconds for one epoch ---
--- 0.3001220226287842 seconds for one epoch ---
--- 1.890233039855957 seconds for one epoch ---
--- 0.2914299964904785 seconds for one epoch ---
--- 1.8663463592529297 seconds for one epoch ---
--- 0.2929656505584717 seconds for one epoch ---
--- 1.8850152492523193 seconds for one epoch ---
--- 0.2919487953186035 seconds for one epoch ---
--- 1.8954129219055176 seconds for one epoch ---
--- 0.2992861270904541 seconds for one epoch ---
--- 1.8851900100708008 seconds for one epoch ---
--- 0.29920363426208496 seconds for one epoch ---
--- 1.9068362712860107 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1005477]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-15.4332695]
 [ -0.       ]]
--- 0.3075904846191406 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2924.892333984375, (1112.1029, 2.0232024, 1810.6323, 0.13403565)
   validation loss 762.77099609375, (475.82794, 1.02777, 285.78122, 0.13403565)
decoder loss ratio: 18434.400543, decoder SINDy loss  ratio: 0.616899
--- 0.26883649826049805 seconds for one epoch ---
--- 0.31850361824035645 seconds for one epoch ---
--- 1.8937346935272217 seconds for one epoch ---
--- 0.3292210102081299 seconds for one epoch ---
--- 1.9061975479125977 seconds for one epoch ---
--- 0.32657623291015625 seconds for one epoch ---
--- 1.8748531341552734 seconds for one epoch ---
--- 0.3311324119567871 seconds for one epoch ---
--- 1.877903699874878 seconds for one epoch ---
--- 0.2873237133026123 seconds for one epoch ---
--- 1.900864601135254 seconds for one epoch ---
--- 0.2964763641357422 seconds for one epoch ---
--- 1.8572921752929688 seconds for one epoch ---
--- 0.2911827564239502 seconds for one epoch ---
--- 1.920267105102539 seconds for one epoch ---
--- 0.2960953712463379 seconds for one epoch ---
--- 1.9071342945098877 seconds for one epoch ---
--- 0.3008253574371338 seconds for one epoch ---
--- 1.913968563079834 seconds for one epoch ---
--- 0.2961137294769287 seconds for one epoch ---
--- 1.9054365158081055 seconds for one epoch ---
--- 0.30103087425231934 seconds for one epoch ---
--- 1.9109020233154297 seconds for one epoch ---
--- 0.3028092384338379 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09980054]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.466744]
 [ -0.      ]]
--- 0.2583620548248291 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2462.9375, (1222.2728, 2.116792, 1238.4138, 0.13409518)
   validation loss 849.9225463867188, (533.9911, 1.1216122, 314.67578, 0.13409518)
decoder loss ratio: 20687.741832, decoder SINDy loss  ratio: 0.679272
--- 0.29922938346862793 seconds for one epoch ---
--- 1.8853833675384521 seconds for one epoch ---
--- 0.2934091091156006 seconds for one epoch ---
--- 1.9236948490142822 seconds for one epoch ---
--- 0.298778772354126 seconds for one epoch ---
--- 1.895688772201538 seconds for one epoch ---
--- 0.30224084854125977 seconds for one epoch ---
--- 1.906247615814209 seconds for one epoch ---
--- 0.2971196174621582 seconds for one epoch ---
--- 1.9105925559997559 seconds for one epoch ---
--- 0.30542492866516113 seconds for one epoch ---
--- 1.9335486888885498 seconds for one epoch ---
--- 0.30615663528442383 seconds for one epoch ---
--- 1.9169690608978271 seconds for one epoch ---
--- 0.30929088592529297 seconds for one epoch ---
--- 1.926457166671753 seconds for one epoch ---
--- 0.31026434898376465 seconds for one epoch ---
--- 1.8886096477508545 seconds for one epoch ---
--- 0.29123997688293457 seconds for one epoch ---
--- 1.9321403503417969 seconds for one epoch ---
--- 0.2815515995025635 seconds for one epoch ---
--- 1.9004313945770264 seconds for one epoch ---
--- 0.28038692474365234 seconds for one epoch ---
--- 1.9486463069915771 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09905036]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.500394]
 [  0.      ]]
--- 0.2936747074127197 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6216.82666015625, (2698.9182, 4.21414, 3513.5603, 0.13415168)
   validation loss 1034.0072021484375, (709.4644, 1.1977199, 323.21088, 0.13415168)
decoder loss ratio: 27485.883180, decoder SINDy loss  ratio: 0.697696
THRESHOLDING: 0 active coefficients
--- 1.896613359451294 seconds for one epoch ---
--- 0.3114748001098633 seconds for one epoch ---
--- 1.943955898284912 seconds for one epoch ---
--- 0.30474019050598145 seconds for one epoch ---
--- 1.9274623394012451 seconds for one epoch ---
--- 0.2988319396972656 seconds for one epoch ---
--- 1.9183058738708496 seconds for one epoch ---
--- 0.30193495750427246 seconds for one epoch ---
--- 1.914616346359253 seconds for one epoch ---
--- 0.29274559020996094 seconds for one epoch ---
--- 1.9469413757324219 seconds for one epoch ---
--- 0.29572367668151855 seconds for one epoch ---
--- 1.8876571655273438 seconds for one epoch ---
--- 0.30420565605163574 seconds for one epoch ---
--- 1.900163173675537 seconds for one epoch ---
--- 0.30068325996398926 seconds for one epoch ---
--- 1.9247403144836426 seconds for one epoch ---
--- 0.3005051612854004 seconds for one epoch ---
--- 1.910149097442627 seconds for one epoch ---
--- 0.29836344718933105 seconds for one epoch ---
--- 1.945901870727539 seconds for one epoch ---
--- 0.309978723526001 seconds for one epoch ---
--- 1.9625535011291504 seconds for one epoch ---
--- 0.3013954162597656 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2570009231567383 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1456.5616455078125, (948.91547, 3.738186, 503.88513, 0.022769501)
   validation loss 1257.4859619140625, (902.32153, 1.1179974, 354.02356, 0.022769501)
decoder loss ratio: 34957.502695, decoder SINDy loss  ratio: 0.764210
--- 0.32647156715393066 seconds for one epoch ---
--- 1.9322278499603271 seconds for one epoch ---
--- 0.3294236660003662 seconds for one epoch ---
--- 1.962393045425415 seconds for one epoch ---
--- 0.3236198425292969 seconds for one epoch ---
--- 1.9503746032714844 seconds for one epoch ---
--- 0.29700398445129395 seconds for one epoch ---
--- 1.968904972076416 seconds for one epoch ---
--- 0.30677175521850586 seconds for one epoch ---
--- 1.9657363891601562 seconds for one epoch ---
--- 0.30594515800476074 seconds for one epoch ---
--- 1.9428293704986572 seconds for one epoch ---
--- 0.3046422004699707 seconds for one epoch ---
--- 1.95774507522583 seconds for one epoch ---
--- 0.2983996868133545 seconds for one epoch ---
--- 1.9466774463653564 seconds for one epoch ---
--- 0.2848222255706787 seconds for one epoch ---
--- 1.9538812637329102 seconds for one epoch ---
--- 0.29304075241088867 seconds for one epoch ---
--- 1.974043607711792 seconds for one epoch ---
--- 0.30603623390197754 seconds for one epoch ---
--- 1.928865909576416 seconds for one epoch ---
--- 0.27738070487976074 seconds for one epoch ---
--- 1.9999923706054688 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29410696029663086 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3251.702392578125, (1177.6238, 2.2212684, 2071.8347, 0.022769501)
   validation loss 963.9577026367188, (585.9254, 1.0636278, 376.9459, 0.022769501)
decoder loss ratio: 22699.767790, decoder SINDy loss  ratio: 0.813691
--- 0.26242589950561523 seconds for one epoch ---
--- 0.28411865234375 seconds for one epoch ---
--- 1.9487011432647705 seconds for one epoch ---
--- 0.2893240451812744 seconds for one epoch ---
--- 1.9582014083862305 seconds for one epoch ---
--- 0.2998695373535156 seconds for one epoch ---
--- 1.9693903923034668 seconds for one epoch ---
--- 0.3082582950592041 seconds for one epoch ---
--- 1.9716792106628418 seconds for one epoch ---
--- 0.2946052551269531 seconds for one epoch ---
--- 1.9974477291107178 seconds for one epoch ---
--- 0.30743980407714844 seconds for one epoch ---
--- 2.0020852088928223 seconds for one epoch ---
--- 0.30742359161376953 seconds for one epoch ---
--- 2.027404546737671 seconds for one epoch ---
--- 0.32503747940063477 seconds for one epoch ---
--- 1.9956340789794922 seconds for one epoch ---
--- 0.332810640335083 seconds for one epoch ---
--- 1.9833970069885254 seconds for one epoch ---
--- 0.3288846015930176 seconds for one epoch ---
--- 1.9602677822113037 seconds for one epoch ---
--- 0.327897310256958 seconds for one epoch ---
--- 1.9906840324401855 seconds for one epoch ---
--- 0.30339598655700684 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26128339767456055 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2021.0555419921875, (1120.4961, 1.4409485, 899.09576, 0.022769501)
   validation loss 918.1439819335938, (557.77466, 1.0596137, 359.2869, 0.022769501)
decoder loss ratio: 21609.158598, decoder SINDy loss  ratio: 0.775571
--- 0.2892918586730957 seconds for one epoch ---
--- 1.9847655296325684 seconds for one epoch ---
--- 0.30035996437072754 seconds for one epoch ---
--- 1.9266326427459717 seconds for one epoch ---
--- 0.30466318130493164 seconds for one epoch ---
--- 2.0034914016723633 seconds for one epoch ---
--- 0.2921123504638672 seconds for one epoch ---
--- 1.9835054874420166 seconds for one epoch ---
--- 0.2987406253814697 seconds for one epoch ---
--- 2.003408908843994 seconds for one epoch ---
--- 0.2855851650238037 seconds for one epoch ---
--- 2.0107839107513428 seconds for one epoch ---
--- 0.2968122959136963 seconds for one epoch ---
--- 2.0132029056549072 seconds for one epoch ---
--- 0.281766414642334 seconds for one epoch ---
--- 2.0241994857788086 seconds for one epoch ---
--- 0.30526304244995117 seconds for one epoch ---
--- 1.9721589088439941 seconds for one epoch ---
--- 0.3041810989379883 seconds for one epoch ---
--- 1.9815189838409424 seconds for one epoch ---
--- 0.2790515422821045 seconds for one epoch ---
--- 1.9995250701904297 seconds for one epoch ---
--- 0.3043100833892822 seconds for one epoch ---
--- 2.0074477195739746 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28925108909606934 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2529.177734375, (1180.9391, 3.2049742, 1345.011, 0.022769501)
   validation loss 1007.6846923828125, (671.8095, 0.8757695, 334.97662, 0.022769501)
decoder loss ratio: 26027.066702, decoder SINDy loss  ratio: 0.723094
--- 0.2701716423034668 seconds for one epoch ---
--- 0.29074978828430176 seconds for one epoch ---
--- 1.9970991611480713 seconds for one epoch ---
--- 0.33094143867492676 seconds for one epoch ---
--- 2.03143048286438 seconds for one epoch ---
--- 0.32807302474975586 seconds for one epoch ---
--- 1.99578857421875 seconds for one epoch ---
--- 0.2988097667694092 seconds for one epoch ---
--- 2.04457950592041 seconds for one epoch ---
--- 0.29617929458618164 seconds for one epoch ---
--- 2.0017149448394775 seconds for one epoch ---
--- 0.29413461685180664 seconds for one epoch ---
--- 1.9950001239776611 seconds for one epoch ---
--- 0.2857682704925537 seconds for one epoch ---
--- 1.9910948276519775 seconds for one epoch ---
--- 0.2951078414916992 seconds for one epoch ---
--- 1.9985015392303467 seconds for one epoch ---
--- 0.2972733974456787 seconds for one epoch ---
--- 2.0118308067321777 seconds for one epoch ---
--- 0.2973759174346924 seconds for one epoch ---
--- 1.9946167469024658 seconds for one epoch ---
--- 0.29236531257629395 seconds for one epoch ---
--- 2.0319182872772217 seconds for one epoch ---
--- 0.2962050437927246 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26819300651550293 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2976.277587890625, (949.63165, 2.271379, 2024.3518, 0.022769501)
   validation loss 838.1854858398438, (496.25497, 0.92320174, 340.98453, 0.022769501)
decoder loss ratio: 19225.779243, decoder SINDy loss  ratio: 0.736063
--- 0.3119025230407715 seconds for one epoch ---
--- 2.0255520343780518 seconds for one epoch ---
--- 0.2993350028991699 seconds for one epoch ---
--- 2.044323205947876 seconds for one epoch ---
--- 0.2896692752838135 seconds for one epoch ---
--- 2.0087246894836426 seconds for one epoch ---
--- 0.2989950180053711 seconds for one epoch ---
--- 2.0457711219787598 seconds for one epoch ---
--- 0.3019382953643799 seconds for one epoch ---
--- 2.034207820892334 seconds for one epoch ---
--- 0.3041038513183594 seconds for one epoch ---
--- 2.0607786178588867 seconds for one epoch ---
--- 0.28689098358154297 seconds for one epoch ---
--- 2.0645580291748047 seconds for one epoch ---
--- 0.2998192310333252 seconds for one epoch ---
--- 2.0528337955474854 seconds for one epoch ---
--- 0.2974357604980469 seconds for one epoch ---
--- 2.0685338973999023 seconds for one epoch ---
--- 0.2854185104370117 seconds for one epoch ---
--- 2.0562851428985596 seconds for one epoch ---
--- 0.2975597381591797 seconds for one epoch ---
--- 2.042980670928955 seconds for one epoch ---
--- 0.29720592498779297 seconds for one epoch ---
--- 2.0540034770965576 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3014559745788574 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2194.760498046875, (963.10986, 1.5269393, 1230.1011, 0.02277117)
   validation loss 1033.1121826171875, (668.1285, 1.0672079, 363.89374, 0.02277117)
decoder loss ratio: 25884.457199, decoder SINDy loss  ratio: 0.785516
--- 0.2579481601715088 seconds for one epoch ---
--- 0.2988097667694092 seconds for one epoch ---
--- 2.0055880546569824 seconds for one epoch ---
--- 0.3013417720794678 seconds for one epoch ---
--- 2.0222835540771484 seconds for one epoch ---
--- 0.2919175624847412 seconds for one epoch ---
--- 2.0557563304901123 seconds for one epoch ---
--- 0.3055417537689209 seconds for one epoch ---
--- 2.027864694595337 seconds for one epoch ---
--- 0.3133809566497803 seconds for one epoch ---
--- 2.0751633644104004 seconds for one epoch ---
--- 0.29970884323120117 seconds for one epoch ---
--- 2.0806965827941895 seconds for one epoch ---
--- 0.2913351058959961 seconds for one epoch ---
--- 2.050349712371826 seconds for one epoch ---
--- 0.2916536331176758 seconds for one epoch ---
--- 2.014336109161377 seconds for one epoch ---
--- 0.29659247398376465 seconds for one epoch ---
--- 2.0623815059661865 seconds for one epoch ---
--- 0.2951793670654297 seconds for one epoch ---
--- 2.0596861839294434 seconds for one epoch ---
--- 0.3094632625579834 seconds for one epoch ---
--- 2.059724807739258 seconds for one epoch ---
--- 0.3031628131866455 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2646782398223877 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2029.38134765625, (972.9456, 0.67570484, 1055.7372, 0.02277581)
   validation loss 922.2842407226562, (605.0605, 0.96409976, 316.2369, 0.02277581)
decoder loss ratio: 23441.093653, decoder SINDy loss  ratio: 0.682642
--- 0.30023193359375 seconds for one epoch ---
--- 2.051771402359009 seconds for one epoch ---
--- 0.3011455535888672 seconds for one epoch ---
--- 2.0828635692596436 seconds for one epoch ---
--- 0.28826189041137695 seconds for one epoch ---
--- 2.0719048976898193 seconds for one epoch ---
--- 0.3006703853607178 seconds for one epoch ---
--- 2.0666277408599854 seconds for one epoch ---
--- 0.3012697696685791 seconds for one epoch ---
--- 2.0624382495880127 seconds for one epoch ---
--- 0.2949390411376953 seconds for one epoch ---
--- 2.03369402885437 seconds for one epoch ---
--- 0.3035902976989746 seconds for one epoch ---
--- 2.0437793731689453 seconds for one epoch ---
--- 0.2892646789550781 seconds for one epoch ---
--- 2.0549678802490234 seconds for one epoch ---
--- 0.2955915927886963 seconds for one epoch ---
--- 2.067678213119507 seconds for one epoch ---
--- 0.2846543788909912 seconds for one epoch ---
--- 2.0397744178771973 seconds for one epoch ---
--- 0.30179286003112793 seconds for one epoch ---
--- 2.066364288330078 seconds for one epoch ---
--- 0.2900657653808594 seconds for one epoch ---
--- 2.0424931049346924 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.30023956298828125 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3136.660400390625, (1751.6504, 1.7430981, 1383.2443, 0.022780469)
   validation loss 1000.5838012695312, (639.1783, 0.980583, 360.40213, 0.022780469)
decoder loss ratio: 24762.876373, decoder SINDy loss  ratio: 0.777979
--- 0.2536332607269287 seconds for one epoch ---
--- 0.287935733795166 seconds for one epoch ---
--- 2.0312886238098145 seconds for one epoch ---
--- 0.29706335067749023 seconds for one epoch ---
--- 2.0489487648010254 seconds for one epoch ---
--- 0.28853631019592285 seconds for one epoch ---
--- 2.0512712001800537 seconds for one epoch ---
--- 0.30711841583251953 seconds for one epoch ---
--- 2.032465934753418 seconds for one epoch ---
--- 0.3054790496826172 seconds for one epoch ---
--- 2.070786476135254 seconds for one epoch ---
--- 0.3027658462524414 seconds for one epoch ---
--- 2.0704996585845947 seconds for one epoch ---
--- 0.29747700691223145 seconds for one epoch ---
--- 2.067068576812744 seconds for one epoch ---
--- 0.2917044162750244 seconds for one epoch ---
--- 2.021328926086426 seconds for one epoch ---
--- 0.2876918315887451 seconds for one epoch ---
--- 2.048572063446045 seconds for one epoch ---
--- 0.31912660598754883 seconds for one epoch ---
--- 2.0863311290740967 seconds for one epoch ---
--- 0.30077672004699707 seconds for one epoch ---
--- 2.0796477794647217 seconds for one epoch ---
--- 0.2988700866699219 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2588179111480713 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2254.730712890625, (1190.5103, 0.67238164, 1063.5254, 0.022789648)
   validation loss 826.3955078125, (476.55637, 0.98806924, 348.8283, 0.022789648)
decoder loss ratio: 18462.620956, decoder SINDy loss  ratio: 0.752995
--- 0.2998490333557129 seconds for one epoch ---
--- 2.0712287425994873 seconds for one epoch ---
--- 0.2896602153778076 seconds for one epoch ---
--- 2.0640783309936523 seconds for one epoch ---
--- 0.2951850891113281 seconds for one epoch ---
--- 2.070753812789917 seconds for one epoch ---
--- 0.2973511219024658 seconds for one epoch ---
--- 2.0605340003967285 seconds for one epoch ---
--- 0.2995312213897705 seconds for one epoch ---
--- 2.104948043823242 seconds for one epoch ---
--- 0.3129005432128906 seconds for one epoch ---
--- 2.1081490516662598 seconds for one epoch ---
--- 0.32208251953125 seconds for one epoch ---
--- 2.1182475090026855 seconds for one epoch ---
--- 0.3477051258087158 seconds for one epoch ---
--- 2.1121456623077393 seconds for one epoch ---
--- 0.32801175117492676 seconds for one epoch ---
--- 2.122753143310547 seconds for one epoch ---
--- 0.31859493255615234 seconds for one epoch ---
--- 2.088022232055664 seconds for one epoch ---
--- 0.30025696754455566 seconds for one epoch ---
--- 2.1193339824676514 seconds for one epoch ---
--- 0.30773234367370605 seconds for one epoch ---
--- 2.1133668422698975 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2995126247406006 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6400.8662109375, (1661.9978, 2.491964, 4736.3535, 0.022803664)
   validation loss 878.37109375, (539.4343, 1.0073935, 337.90652, 0.022803664)
decoder loss ratio: 20898.622295, decoder SINDy loss  ratio: 0.729419
--- 0.2691926956176758 seconds for one epoch ---
--- 0.3113892078399658 seconds for one epoch ---
--- 2.121915340423584 seconds for one epoch ---
--- 0.30731868743896484 seconds for one epoch ---
--- 2.1377387046813965 seconds for one epoch ---
--- 0.3037395477294922 seconds for one epoch ---
--- 2.113265037536621 seconds for one epoch ---
--- 0.27570366859436035 seconds for one epoch ---
--- 2.125037670135498 seconds for one epoch ---
--- 0.30442214012145996 seconds for one epoch ---
--- 2.085965156555176 seconds for one epoch ---
--- 0.30243897438049316 seconds for one epoch ---
--- 2.0951366424560547 seconds for one epoch ---
--- 0.3093535900115967 seconds for one epoch ---
--- 2.0948615074157715 seconds for one epoch ---
--- 0.2918393611907959 seconds for one epoch ---
--- 2.163623809814453 seconds for one epoch ---
--- 0.29529619216918945 seconds for one epoch ---
--- 2.163823127746582 seconds for one epoch ---
--- 0.29508280754089355 seconds for one epoch ---
--- 2.170241355895996 seconds for one epoch ---
--- 0.2995433807373047 seconds for one epoch ---
--- 2.190688371658325 seconds for one epoch ---
--- 0.3005387783050537 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2644350528717041 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4692.51220703125, (2205.9934, 0.9559735, 2485.5396, 0.022825887)
   validation loss 1102.884521484375, (761.78723, 0.95950466, 340.11496, 0.022825887)
decoder loss ratio: 29512.959867, decoder SINDy loss  ratio: 0.734186
--- 0.29187870025634766 seconds for one epoch ---
--- 2.1215977668762207 seconds for one epoch ---
--- 0.29438185691833496 seconds for one epoch ---
--- 2.1028099060058594 seconds for one epoch ---
--- 0.30290746688842773 seconds for one epoch ---
--- 2.104421615600586 seconds for one epoch ---
--- 0.27637314796447754 seconds for one epoch ---
--- 2.0908031463623047 seconds for one epoch ---
--- 0.2956697940826416 seconds for one epoch ---
--- 2.095452070236206 seconds for one epoch ---
--- 0.2947676181793213 seconds for one epoch ---
--- 2.1357738971710205 seconds for one epoch ---
--- 0.30156707763671875 seconds for one epoch ---
--- 2.2171590328216553 seconds for one epoch ---
--- 0.2965514659881592 seconds for one epoch ---
--- 2.2322402000427246 seconds for one epoch ---
--- 0.3041994571685791 seconds for one epoch ---
--- 2.234848737716675 seconds for one epoch ---
--- 0.2992360591888428 seconds for one epoch ---
--- 2.137230634689331 seconds for one epoch ---
--- 0.291903018951416 seconds for one epoch ---
--- 2.1996712684631348 seconds for one epoch ---
--- 0.6530442237854004 seconds for one epoch ---
--- 2.1986453533172607 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3184943199157715 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3523.2451171875, (1047.5912, 1.6922541, 2473.9387, 0.022860885)
   validation loss 910.3892822265625, (568.9213, 1.0713756, 340.37372, 0.022860885)
decoder loss ratio: 22040.999848, decoder SINDy loss  ratio: 0.734745
--- 0.2628788948059082 seconds for one epoch ---
--- 0.2995188236236572 seconds for one epoch ---
--- 2.1064624786376953 seconds for one epoch ---
--- 0.3042795658111572 seconds for one epoch ---
--- 2.105958938598633 seconds for one epoch ---
--- 0.2721850872039795 seconds for one epoch ---
--- 2.1319501399993896 seconds for one epoch ---
--- 0.2937917709350586 seconds for one epoch ---
--- 2.126375436782837 seconds for one epoch ---
--- 0.3007054328918457 seconds for one epoch ---
--- 2.1511762142181396 seconds for one epoch ---
--- 0.30124950408935547 seconds for one epoch ---
--- 2.1367461681365967 seconds for one epoch ---
--- 0.2951929569244385 seconds for one epoch ---
--- 2.1268515586853027 seconds for one epoch ---
--- 0.3008248805999756 seconds for one epoch ---
--- 2.1289420127868652 seconds for one epoch ---
--- 0.29560279846191406 seconds for one epoch ---
--- 2.1703360080718994 seconds for one epoch ---
--- 0.30497074127197266 seconds for one epoch ---
--- 2.1346325874328613 seconds for one epoch ---
--- 0.30097174644470215 seconds for one epoch ---
--- 2.1656551361083984 seconds for one epoch ---
--- 0.3086574077606201 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2552297115325928 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1938.552490234375, (995.45233, 2.9802017, 940.09705, 0.022916785)
   validation loss 835.7417602539062, (500.207, 0.97464687, 334.53726, 0.022916785)
decoder loss ratio: 19378.887606, decoder SINDy loss  ratio: 0.722146
--- 0.3091742992401123 seconds for one epoch ---
--- 2.1530632972717285 seconds for one epoch ---
--- 0.2935647964477539 seconds for one epoch ---
--- 2.155961513519287 seconds for one epoch ---
--- 0.2976870536804199 seconds for one epoch ---
--- 2.153200149536133 seconds for one epoch ---
--- 0.29967713356018066 seconds for one epoch ---
--- 2.1569716930389404 seconds for one epoch ---
--- 0.3010704517364502 seconds for one epoch ---
--- 2.1553916931152344 seconds for one epoch ---
--- 0.3034176826477051 seconds for one epoch ---
--- 2.1863744258880615 seconds for one epoch ---
--- 0.29692935943603516 seconds for one epoch ---
--- 2.1373586654663086 seconds for one epoch ---
--- 0.3195943832397461 seconds for one epoch ---
--- 2.16973876953125 seconds for one epoch ---
--- 0.3263859748840332 seconds for one epoch ---
--- 2.1516857147216797 seconds for one epoch ---
--- 0.3323781490325928 seconds for one epoch ---
--- 2.143500328063965 seconds for one epoch ---
--- 0.31474804878234863 seconds for one epoch ---
--- 2.139666795730591 seconds for one epoch ---
--- 0.30011892318725586 seconds for one epoch ---
--- 2.1345181465148926 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29784202575683594 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3346.9892578125, (1459.3596, 2.5850768, 1885.0217, 0.023005268)
   validation loss 1022.865966796875, (701.1484, 0.8926908, 320.80188, 0.023005268)
decoder loss ratio: 27163.705351, decoder SINDy loss  ratio: 0.692496
--- 0.26831841468811035 seconds for one epoch ---
--- 0.30068349838256836 seconds for one epoch ---
--- 2.1618103981018066 seconds for one epoch ---
--- 0.3022580146789551 seconds for one epoch ---
--- 2.174717664718628 seconds for one epoch ---
--- 0.29782986640930176 seconds for one epoch ---
--- 2.1796343326568604 seconds for one epoch ---
--- 0.31174612045288086 seconds for one epoch ---
--- 2.1939380168914795 seconds for one epoch ---
--- 0.2972428798675537 seconds for one epoch ---
--- 2.1879401206970215 seconds for one epoch ---
--- 0.29201388359069824 seconds for one epoch ---
--- 2.1531906127929688 seconds for one epoch ---
--- 0.2915642261505127 seconds for one epoch ---
--- 2.1808786392211914 seconds for one epoch ---
--- 0.2856569290161133 seconds for one epoch ---
--- 2.1633002758026123 seconds for one epoch ---
--- 0.2967500686645508 seconds for one epoch ---
--- 2.1959612369537354 seconds for one epoch ---
--- 0.2877473831176758 seconds for one epoch ---
--- 2.199918270111084 seconds for one epoch ---
--- 0.29166746139526367 seconds for one epoch ---
--- 2.1863138675689697 seconds for one epoch ---
--- 0.293872594833374 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2560253143310547 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2897.51318359375, (1184.493, 0.7680411, 1712.2289, 0.0231452)
   validation loss 956.5349731445312, (622.6567, 0.94068736, 332.9145, 0.0231452)
decoder loss ratio: 24122.800656, decoder SINDy loss  ratio: 0.718643
--- 0.2897822856903076 seconds for one epoch ---
--- 2.183642625808716 seconds for one epoch ---
--- 0.295687198638916 seconds for one epoch ---
--- 2.1487720012664795 seconds for one epoch ---
--- 0.3023378849029541 seconds for one epoch ---
--- 2.184035062789917 seconds for one epoch ---
--- 0.28969669342041016 seconds for one epoch ---
--- 2.1948156356811523 seconds for one epoch ---
--- 0.29505157470703125 seconds for one epoch ---
--- 2.2060389518737793 seconds for one epoch ---
--- 0.2973201274871826 seconds for one epoch ---
--- 2.1935033798217773 seconds for one epoch ---
--- 0.2858123779296875 seconds for one epoch ---
--- 2.178441286087036 seconds for one epoch ---
--- 0.2936391830444336 seconds for one epoch ---
--- 2.177448272705078 seconds for one epoch ---
--- 0.3314943313598633 seconds for one epoch ---
--- 2.236772060394287 seconds for one epoch ---
--- 0.31049036979675293 seconds for one epoch ---
--- 2.2139315605163574 seconds for one epoch ---
--- 0.29936742782592773 seconds for one epoch ---
--- 2.195263147354126 seconds for one epoch ---
--- 0.2993481159210205 seconds for one epoch ---
--- 2.2061972618103027 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.277587890625 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3050.069580078125, (1128.2223, 2.5679827, 1919.2559, 0.023365427)
   validation loss 849.0606079101562, (501.47653, 1.0864052, 346.4743, 0.023365427)
decoder loss ratio: 19428.071451, decoder SINDy loss  ratio: 0.747914
--- 1.017641305923462 seconds for one epoch ---
--- 0.30533528327941895 seconds for one epoch ---
--- 2.1958820819854736 seconds for one epoch ---
--- 0.31479668617248535 seconds for one epoch ---
--- 2.1691370010375977 seconds for one epoch ---
--- 0.28963446617126465 seconds for one epoch ---
--- 2.2206716537475586 seconds for one epoch ---
--- 0.307387113571167 seconds for one epoch ---
--- 2.2107315063476562 seconds for one epoch ---
--- 0.2981681823730469 seconds for one epoch ---
--- 2.168718099594116 seconds for one epoch ---
--- 0.2983570098876953 seconds for one epoch ---
--- 2.179635763168335 seconds for one epoch ---
--- 0.2988905906677246 seconds for one epoch ---
--- 2.174464225769043 seconds for one epoch ---
--- 0.2931649684906006 seconds for one epoch ---
--- 2.1814539432525635 seconds for one epoch ---
--- 0.3045532703399658 seconds for one epoch ---
--- 2.215559959411621 seconds for one epoch ---
--- 0.2924222946166992 seconds for one epoch ---
--- 2.2233142852783203 seconds for one epoch ---
--- 0.29660582542419434 seconds for one epoch ---
--- 2.186350107192993 seconds for one epoch ---
--- 0.29390382766723633 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25926804542541504 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2368.62353515625, (822.50165, 3.7762148, 1542.322, 0.02370719)
   validation loss 900.264892578125, (565.31085, 0.9573206, 333.97305, 0.02370719)
decoder loss ratio: 21901.123831, decoder SINDy loss  ratio: 0.720928
--- 0.3150815963745117 seconds for one epoch ---
--- 2.1922473907470703 seconds for one epoch ---
--- 0.308413028717041 seconds for one epoch ---
--- 2.2115371227264404 seconds for one epoch ---
--- 0.30678582191467285 seconds for one epoch ---
--- 2.1752896308898926 seconds for one epoch ---
--- 0.29564499855041504 seconds for one epoch ---
--- 2.1927802562713623 seconds for one epoch ---
--- 0.2980058193206787 seconds for one epoch ---
--- 2.194206476211548 seconds for one epoch ---
--- 0.3031423091888428 seconds for one epoch ---
--- 2.198744058609009 seconds for one epoch ---
--- 0.29006457328796387 seconds for one epoch ---
--- 2.1841864585876465 seconds for one epoch ---
--- 0.294872522354126 seconds for one epoch ---
--- 2.1952908039093018 seconds for one epoch ---
--- 0.291212797164917 seconds for one epoch ---
--- 2.19445538520813 seconds for one epoch ---
--- 0.2924344539642334 seconds for one epoch ---
--- 2.2104344367980957 seconds for one epoch ---
--- 0.29765939712524414 seconds for one epoch ---
--- 2.2163572311401367 seconds for one epoch ---
--- 0.3048667907714844 seconds for one epoch ---
--- 2.225337266921997 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3165731430053711 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2460.83984375, (1180.5177, 2.974311, 1277.3236, 0.02422133)
   validation loss 1015.3693237304688, (658.19836, 1.0604787, 356.0862, 0.02422133)
decoder loss ratio: 25499.747314, decoder SINDy loss  ratio: 0.768662
--- 0.25612330436706543 seconds for one epoch ---
--- 0.30713415145874023 seconds for one epoch ---
--- 2.221256971359253 seconds for one epoch ---
--- 0.3007962703704834 seconds for one epoch ---
--- 2.2446823120117188 seconds for one epoch ---
--- 0.2942380905151367 seconds for one epoch ---
--- 2.227217197418213 seconds for one epoch ---
--- 0.29272007942199707 seconds for one epoch ---
--- 2.2100043296813965 seconds for one epoch ---
--- 0.2944517135620117 seconds for one epoch ---
--- 2.185663938522339 seconds for one epoch ---
--- 0.29720306396484375 seconds for one epoch ---
--- 2.242194175720215 seconds for one epoch ---
--- 0.29743480682373047 seconds for one epoch ---
--- 2.237902879714966 seconds for one epoch ---
--- 0.3028903007507324 seconds for one epoch ---
--- 2.164637804031372 seconds for one epoch ---
--- 0.2981889247894287 seconds for one epoch ---
--- 2.2022194862365723 seconds for one epoch ---
--- 0.3074359893798828 seconds for one epoch ---
--- 2.2509820461273193 seconds for one epoch ---
--- 0.29259610176086426 seconds for one epoch ---
--- 2.2310070991516113 seconds for one epoch ---
--- 0.29227161407470703 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2570607662200928 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2086.427734375, (1023.8788, 2.0783675, 1060.4456, 0.024949228)
   validation loss 966.1386108398438, (648.0506, 1.0871744, 316.9759, 0.024949228)
decoder loss ratio: 25106.605237, decoder SINDy loss  ratio: 0.684237
--- 0.2867448329925537 seconds for one epoch ---
--- 2.1962642669677734 seconds for one epoch ---
--- 0.2940986156463623 seconds for one epoch ---
--- 2.239126682281494 seconds for one epoch ---
--- 0.30574750900268555 seconds for one epoch ---
--- 2.210081100463867 seconds for one epoch ---
--- 0.2966430187225342 seconds for one epoch ---
--- 2.2173147201538086 seconds for one epoch ---
--- 0.2977428436279297 seconds for one epoch ---
--- 2.2301523685455322 seconds for one epoch ---
--- 0.2945427894592285 seconds for one epoch ---
--- 2.2516424655914307 seconds for one epoch ---
--- 0.285980224609375 seconds for one epoch ---
--- 2.2277939319610596 seconds for one epoch ---
--- 0.2857053279876709 seconds for one epoch ---
--- 2.2493324279785156 seconds for one epoch ---
--- 0.28215599060058594 seconds for one epoch ---
--- 2.2292022705078125 seconds for one epoch ---
--- 0.31130099296569824 seconds for one epoch ---
--- 2.2359957695007324 seconds for one epoch ---
--- 0.30649781227111816 seconds for one epoch ---
--- 2.2777717113494873 seconds for one epoch ---
--- 0.3040032386779785 seconds for one epoch ---
--- 2.2466022968292236 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29825568199157715 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5554.228515625, (2272.9407, 0.69009554, 3280.5718, 0.025886824)
   validation loss 896.2347412109375, (540.45844, 1.101278, 354.64914, 0.025886824)
decoder loss ratio: 20938.298051, decoder SINDy loss  ratio: 0.765560
THRESHOLDING: 0 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1153.99609375, (552.17334, 0.67570066, 601.14703, 0.0)
   validation loss 812.5362548828125, (508.6903, 0.7180123, 303.1279, 0.0)
decoder loss ratio: 19707.545642, decoder SINDy loss  ratio: 0.654344
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1121.3519287109375, (603.3739, 0.35610485, 517.62195, 0.0)
   validation loss 910.3328857421875, (634.5183, 0.49238142, 275.3222, 0.0)
decoder loss ratio: 24582.340923, decoder SINDy loss  ratio: 0.594322
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 910.671142578125, (395.59146, 0.28100738, 514.7987, 0.0)
   validation loss 641.0880126953125, (371.35272, 0.3771909, 269.35812, 0.0)
decoder loss ratio: 14386.849153, decoder SINDy loss  ratio: 0.581447
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 993.802001953125, (488.917, 0.24690048, 504.63815, 0.0)
   validation loss 722.65087890625, (454.59262, 0.33127224, 267.727, 0.0)
decoder loss ratio: 17611.707339, decoder SINDy loss  ratio: 0.577926
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1031.2763671875, (449.40442, 0.25176919, 581.6202, 0.0)
   validation loss 652.2885131835938, (361.53122, 0.32396632, 290.43332, 0.0)
decoder loss ratio: 14006.347089, decoder SINDy loss  ratio: 0.626941
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 925.47265625, (423.93683, 0.21237463, 501.32346, 0.0)
   validation loss 644.4483642578125, (380.27087, 0.29408583, 263.88342, 0.0)
decoder loss ratio: 14732.353839, decoder SINDy loss  ratio: 0.569629
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 897.61962890625, (397.838, 0.20480509, 499.57684, 0.0)
   validation loss 610.37939453125, (346.92526, 0.2869836, 263.16714, 0.0)
decoder loss ratio: 13440.486956, decoder SINDy loss  ratio: 0.568083
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2545.891845703125, (1836.637, 0.19181488, 709.06305, 0.0)
   validation loss 2035.6834716796875, (1681.8715, 0.2959253, 353.51614, 0.0)
decoder loss ratio: 65158.620216, decoder SINDy loss  ratio: 0.763114
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.71826171875, (301.30518, 0.19667768, 505.21637, 0.0)
   validation loss 508.1387023925781, (245.13483, 0.28222534, 262.72165, 0.0)
decoder loss ratio: 9496.948758, decoder SINDy loss  ratio: 0.567122
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.5477905273438, (258.78665, 0.21644868, 507.54468, 0.0)
   validation loss 471.53863525390625, (207.63435, 0.2832672, 263.62103, 0.0)
decoder loss ratio: 8044.115329, decoder SINDy loss  ratio: 0.569063
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 948.0480346679688, (455.43253, 0.20891245, 492.4066, 0.0)
   validation loss 661.8837890625, (399.66568, 0.27817616, 261.93994, 0.0)
decoder loss ratio: 15483.742291, decoder SINDy loss  ratio: 0.565434
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.7378540039062, (321.08942, 0.20585269, 497.4426, 0.0)
   validation loss 522.4098510742188, (260.56482, 0.28066438, 261.56436, 0.0)
decoder loss ratio: 10094.733461, decoder SINDy loss  ratio: 0.564623
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.1234130859375, (384.28302, 0.21950147, 492.6209, 0.0)
   validation loss 585.5235595703125, (322.7184, 0.27608114, 262.52902, 0.0)
decoder loss ratio: 12502.671634, decoder SINDy loss  ratio: 0.566706
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.731689453125, (297.5961, 0.20513098, 498.93048, 0.0)
   validation loss 498.29693603515625, (235.91064, 0.28197476, 262.10434, 0.0)
decoder loss ratio: 9139.587928, decoder SINDy loss  ratio: 0.565789
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1080.382080078125, (515.1994, 0.20387885, 564.9789, 0.0)
   validation loss 727.8748779296875, (441.0191, 0.2830025, 286.57278, 0.0)
decoder loss ratio: 17085.845732, decoder SINDy loss  ratio: 0.618608
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 840.3079833984375, (347.5161, 0.21335053, 492.57852, 0.0)
   validation loss 553.260498046875, (290.71005, 0.28421745, 262.2662, 0.0)
decoder loss ratio: 11262.612128, decoder SINDy loss  ratio: 0.566138
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 915.3197021484375, (428.00827, 0.22168635, 487.08972, 0.0)
   validation loss 623.3841552734375, (361.97852, 0.2842657, 261.1214, 0.0)
decoder loss ratio: 14023.676118, decoder SINDy loss  ratio: 0.563667
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1280.1488037109375, (801.58936, 0.22979099, 478.32965, 0.0)
   validation loss 1008.819580078125, (746.4026, 0.29716846, 262.11978, 0.0)
decoder loss ratio: 28916.932067, decoder SINDy loss  ratio: 0.565822
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 966.8094482421875, (482.22726, 0.2306009, 484.3516, 0.0)
   validation loss 674.1895751953125, (412.31427, 0.2870296, 261.58826, 0.0)
decoder loss ratio: 15973.770630, decoder SINDy loss  ratio: 0.564675
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1805.6812744140625, (1147.1658, 0.2832369, 658.2323, 0.0)
   validation loss 1341.315673828125, (1013.9569, 0.28442678, 327.07428, 0.0)
decoder loss ratio: 39282.450968, decoder SINDy loss  ratio: 0.706036
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 928.2835083007812, (443.8976, 0.23544358, 484.15045, 0.0)
   validation loss 638.5772094726562, (376.3469, 0.28964967, 261.94067, 0.0)
decoder loss ratio: 14580.332014, decoder SINDy loss  ratio: 0.565436
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.3206176757812, (241.934, 0.25579673, 502.13083, 0.0)
   validation loss 450.4608459472656, (185.58514, 0.29195684, 264.58374, 0.0)
decoder loss ratio: 7189.890670, decoder SINDy loss  ratio: 0.571141
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 860.33154296875, (373.7682, 0.24600056, 486.31732, 0.0)
   validation loss 572.023193359375, (309.08804, 0.2926044, 262.64252, 0.0)
decoder loss ratio: 11974.607395, decoder SINDy loss  ratio: 0.566951
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.3568725585938, (261.39413, 0.25609452, 495.70663, 0.0)
   validation loss 463.7833251953125, (200.1418, 0.29512134, 263.3464, 0.0)
decoder loss ratio: 7753.840791, decoder SINDy loss  ratio: 0.568470
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 933.4954833984375, (451.74792, 0.25490537, 481.49265, 0.0)
   validation loss 648.66015625, (385.24197, 0.2962717, 263.12195, 0.0)
decoder loss ratio: 14924.942877, decoder SINDy loss  ratio: 0.567986
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 759.93359375, (266.61414, 0.2567817, 493.06265, 0.0)
   validation loss 469.32623291015625, (205.52716, 0.2965854, 263.50247, 0.0)
decoder loss ratio: 7962.479014, decoder SINDy loss  ratio: 0.568807
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.0799560546875, (419.9123, 0.26025674, 481.9074, 0.0)
   validation loss 618.2623291015625, (354.2876, 0.29967305, 263.67508, 0.0)
decoder loss ratio: 13725.716604, decoder SINDy loss  ratio: 0.569180
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 770.1026611328125, (279.64987, 0.26206905, 490.19073, 0.0)
   validation loss 478.29058837890625, (214.89867, 0.3016643, 263.09027, 0.0)
decoder loss ratio: 8325.547416, decoder SINDy loss  ratio: 0.567917
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 888.3328857421875, (406.16803, 0.26690635, 481.89798, 0.0)
   validation loss 604.9945068359375, (340.5267, 0.30352595, 264.16425, 0.0)
decoder loss ratio: 13192.595650, decoder SINDy loss  ratio: 0.570236
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.92333984375, (278.10135, 0.26556394, 489.55643, 0.0)
   validation loss 476.7060546875, (212.98058, 0.30432904, 263.42114, 0.0)
decoder loss ratio: 8251.237248, decoder SINDy loss  ratio: 0.568632
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 969.5716552734375, (491.51617, 0.27360877, 477.7819, 0.0)
   validation loss 687.202880859375, (422.24277, 0.30675805, 264.65335, 0.0)
decoder loss ratio: 16358.417852, decoder SINDy loss  ratio: 0.571291
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 948.385986328125, (469.75827, 0.2677555, 478.36, 0.0)
   validation loss 652.5160522460938, (390.05344, 0.3061687, 262.15643, 0.0)
decoder loss ratio: 15111.347284, decoder SINDy loss  ratio: 0.565902
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 807.3341064453125, (281.84372, 0.2716145, 525.21875, 0.0)
   validation loss 471.87347412109375, (195.65472, 0.31158328, 275.90717, 0.0)
decoder loss ratio: 7580.003684, decoder SINDy loss  ratio: 0.595584
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 893.404052734375, (413.90067, 0.26037845, 479.24304, 0.0)
   validation loss 605.3095703125, (340.42685, 0.30580372, 264.57687, 0.0)
decoder loss ratio: 13188.727151, decoder SINDy loss  ratio: 0.571126
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 976.1754150390625, (499.67538, 0.27398872, 476.226, 0.0)
   validation loss 689.686279296875, (424.6381, 0.31220448, 264.73602, 0.0)
decoder loss ratio: 16451.216890, decoder SINDy loss  ratio: 0.571470
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.5823364257812, (244.83209, 0.28751898, 497.4627, 0.0)
   validation loss 451.23419189453125, (182.55896, 0.31321448, 268.36203, 0.0)
decoder loss ratio: 7072.651045, decoder SINDy loss  ratio: 0.579297
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 876.8653564453125, (397.73895, 0.28724107, 478.8392, 0.0)
   validation loss 596.712158203125, (330.5258, 0.31499046, 265.8714, 0.0)
decoder loss ratio: 12805.142820, decoder SINDy loss  ratio: 0.573921
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.5167236328125, (246.42322, 0.2906695, 492.80283, 0.0)
   validation loss 452.07891845703125, (185.20592, 0.31627953, 266.55673, 0.0)
decoder loss ratio: 7175.198770, decoder SINDy loss  ratio: 0.575400
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 893.5559692382812, (416.04773, 0.2872684, 477.22098, 0.0)
   validation loss 613.1650390625, (347.35074, 0.31602734, 265.49823, 0.0)
decoder loss ratio: 13456.970638, decoder SINDy loss  ratio: 0.573115
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 805.1396484375, (323.97662, 0.2886761, 480.8744, 0.0)
   validation loss 520.2659912109375, (256.9135, 0.31701508, 263.03543, 0.0)
decoder loss ratio: 9953.275522, decoder SINDy loss  ratio: 0.567799
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.4588623046875, (292.3548, 0.28745294, 483.81662, 0.0)
   validation loss 489.36700439453125, (222.79543, 0.31553316, 266.25604, 0.0)
decoder loss ratio: 8631.481570, decoder SINDy loss  ratio: 0.574751
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 950.9462890625, (475.73502, 0.28414258, 474.92712, 0.0)
   validation loss 656.2418212890625, (393.27545, 0.3200283, 262.64636, 0.0)
decoder loss ratio: 15236.173754, decoder SINDy loss  ratio: 0.566959
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.671142578125, (299.34912, 0.2867933, 491.0352, 0.0)
   validation loss 497.64776611328125, (229.49632, 0.3204342, 267.83102, 0.0)
decoder loss ratio: 8891.085962, decoder SINDy loss  ratio: 0.578151
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.03857421875, (295.462, 0.27364674, 482.30295, 0.0)
   validation loss 492.2076721191406, (227.55153, 0.31590322, 264.34024, 0.0)
decoder loss ratio: 8815.741278, decoder SINDy loss  ratio: 0.570616
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1368.454833984375, (887.5918, 0.31719208, 480.5458, 0.0)
   validation loss 1024.4276123046875, (751.62494, 0.32058534, 272.4821, 0.0)
decoder loss ratio: 29119.255014, decoder SINDy loss  ratio: 0.588191
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.7545166015625, (269.7591, 0.28141147, 485.71402, 0.0)
   validation loss 465.5116882324219, (200.51006, 0.3195593, 264.68207, 0.0)
decoder loss ratio: 7768.107652, decoder SINDy loss  ratio: 0.571353
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 811.800048828125, (329.37515, 0.29377544, 482.13113, 0.0)
   validation loss 527.7911376953125, (261.12073, 0.3197166, 266.35074, 0.0)
decoder loss ratio: 10116.270310, decoder SINDy loss  ratio: 0.574956
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.962646484375, (402.84656, 0.28367662, 474.83243, 0.0)
   validation loss 586.210693359375, (323.67944, 0.32127964, 262.20996, 0.0)
decoder loss ratio: 12539.903568, decoder SINDy loss  ratio: 0.566017
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.1488037109375, (252.6261, 0.2903398, 507.2324, 0.0)
   validation loss 457.60107421875, (183.33817, 0.31739983, 273.94553, 0.0)
decoder loss ratio: 7102.838812, decoder SINDy loss  ratio: 0.591350
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.6390380859375, (273.2941, 0.29692, 483.04803, 0.0)
   validation loss 474.5988464355469, (209.9784, 0.3216237, 264.29883, 0.0)
decoder loss ratio: 8134.927505, decoder SINDy loss  ratio: 0.570526
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.86669921875, (252.0791, 0.2832166, 491.5044, 0.0)
   validation loss 452.63226318359375, (183.61995, 0.31912035, 268.69318, 0.0)
decoder loss ratio: 7113.755616, decoder SINDy loss  ratio: 0.580012
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.844482421875, (285.64838, 0.27228218, 481.92386, 0.0)
   validation loss 485.6025390625, (220.88792, 0.31051058, 264.40408, 0.0)
decoder loss ratio: 8557.581662, decoder SINDy loss  ratio: 0.570753
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1039.1224365234375, (488.88705, 0.30326793, 549.9321, 0.0)
   validation loss 714.7540283203125, (420.08655, 0.31349114, 294.35403, 0.0)
decoder loss ratio: 16274.882166, decoder SINDy loss  ratio: 0.635405
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 978.0682373046875, (505.97275, 0.28736773, 471.80814, 0.0)
   validation loss 687.4284057617188, (421.459, 0.322444, 265.64694, 0.0)
decoder loss ratio: 16328.053922, decoder SINDy loss  ratio: 0.573436
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1184.927490234375, (716.9341, 0.27398118, 467.71936, 0.0)
   validation loss 884.3128051757812, (617.90515, 0.32727715, 266.08038, 0.0)
decoder loss ratio: 23938.718294, decoder SINDy loss  ratio: 0.574372
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 826.4573974609375, (303.07834, 0.30325022, 523.0758, 0.0)
   validation loss 517.4120483398438, (234.43376, 0.32057157, 282.6577, 0.0)
decoder loss ratio: 9082.370919, decoder SINDy loss  ratio: 0.610156
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 771.8299560546875, (293.0644, 0.28425252, 478.48135, 0.0)
   validation loss 490.60272216796875, (225.54373, 0.32151058, 264.7375, 0.0)
decoder loss ratio: 8737.955727, decoder SINDy loss  ratio: 0.571473
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2195.5107421875, (1719.6302, 0.29165658, 475.58878, 0.0)
   validation loss 1907.968505859375, (1620.5709, 0.33205062, 287.0655, 0.0)
decoder loss ratio: 62783.730986, decoder SINDy loss  ratio: 0.619671
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.4273071289062, (268.49185, 0.28119436, 481.65427, 0.0)
   validation loss 466.5733642578125, (200.77977, 0.32012227, 265.47348, 0.0)
decoder loss ratio: 7778.556855, decoder SINDy loss  ratio: 0.573062
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1205.450439453125, (735.51227, 0.283317, 469.6548, 0.0)
   validation loss 899.9276123046875, (633.5068, 0.32261387, 266.09824, 0.0)
decoder loss ratio: 24543.152276, decoder SINDy loss  ratio: 0.574410
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.9071655273438, (250.10919, 0.28465506, 501.5133, 0.0)
   validation loss 452.309814453125, (178.69049, 0.32045132, 273.29886, 0.0)
decoder loss ratio: 6922.779831, decoder SINDy loss  ratio: 0.589954
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 947.39404296875, (476.84454, 0.28881547, 470.26065, 0.0)
   validation loss 655.0941162109375, (391.68192, 0.32297173, 263.0892, 0.0)
decoder loss ratio: 15174.437388, decoder SINDy loss  ratio: 0.567915
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.1680297851562, (236.21318, 0.29550037, 488.65933, 0.0)
   validation loss 443.1519775390625, (173.91145, 0.3154898, 268.92502, 0.0)
decoder loss ratio: 6737.631622, decoder SINDy loss  ratio: 0.580512
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 887.81689453125, (417.19382, 0.27697906, 470.3461, 0.0)
   validation loss 602.6129150390625, (338.15295, 0.31832924, 264.14163, 0.0)
decoder loss ratio: 13100.632501, decoder SINDy loss  ratio: 0.570187
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 928.9627075195312, (403.66562, 0.2769378, 525.02014, 0.0)
   validation loss 620.1619262695312, (338.48618, 0.31916988, 281.35657, 0.0)
decoder loss ratio: 13113.542078, decoder SINDy loss  ratio: 0.607348
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 907.3172607421875, (436.9431, 0.2917433, 470.0824, 0.0)
   validation loss 624.78369140625, (358.90265, 0.32097197, 265.5601, 0.0)
decoder loss ratio: 13904.511702, decoder SINDy loss  ratio: 0.573249
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.8080444335938, (300.95847, 0.27748847, 474.57208, 0.0)
   validation loss 496.6490478515625, (232.72195, 0.3150238, 263.6121, 0.0)
decoder loss ratio: 9016.052534, decoder SINDy loss  ratio: 0.569044
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 863.0091552734375, (327.7781, 0.3035851, 534.9274, 0.0)
   validation loss 519.01123046875, (233.7447, 0.31867453, 284.94788, 0.0)
decoder loss ratio: 9055.675678, decoder SINDy loss  ratio: 0.615100
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.00146484375, (259.29898, 0.2899562, 480.41254, 0.0)
   validation loss 458.5818176269531, (193.34048, 0.3167099, 264.92462, 0.0)
decoder loss ratio: 7490.346028, decoder SINDy loss  ratio: 0.571877
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1000.084228515625, (530.5057, 0.2978681, 469.2807, 0.0)
   validation loss 702.5252685546875, (437.87793, 0.32148406, 264.32587, 0.0)
decoder loss ratio: 16964.151186, decoder SINDy loss  ratio: 0.570585
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.5091552734375, (256.39398, 0.2890343, 505.82614, 0.0)
   validation loss 472.5272216796875, (196.27461, 0.31524858, 275.93738, 0.0)
decoder loss ratio: 7604.019233, decoder SINDy loss  ratio: 0.595650
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.2608642578125, (244.0578, 0.2862538, 483.9168, 0.0)
   validation loss 447.68695068359375, (180.54417, 0.31437814, 266.8284, 0.0)
decoder loss ratio: 6994.594747, decoder SINDy loss  ratio: 0.575987
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.1343994140625, (232.20604, 0.3286203, 489.59973, 0.0)
   validation loss 447.4376525878906, (179.83424, 0.32310337, 267.2803, 0.0)
decoder loss ratio: 6967.090810, decoder SINDy loss  ratio: 0.576962
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.079833984375, (245.51814, 0.2910393, 497.27063, 0.0)
   validation loss 452.44061279296875, (180.98322, 0.31309202, 271.1443, 0.0)
decoder loss ratio: 7011.603963, decoder SINDy loss  ratio: 0.585303
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 815.0263061523438, (343.89117, 0.28090596, 470.85422, 0.0)
   validation loss 534.73828125, (270.43204, 0.31527457, 263.99094, 0.0)
decoder loss ratio: 10477.006618, decoder SINDy loss  ratio: 0.569862
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.9029541015625, (236.16187, 0.3211749, 496.41992, 0.0)
   validation loss 461.7607727050781, (190.07242, 0.31488714, 271.37347, 0.0)
decoder loss ratio: 7363.735462, decoder SINDy loss  ratio: 0.585798
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.9818115234375, (239.53105, 0.29815218, 492.1526, 0.0)
   validation loss 443.73529052734375, (174.10191, 0.31024644, 269.32315, 0.0)
decoder loss ratio: 6745.010381, decoder SINDy loss  ratio: 0.581372
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 881.3514404296875, (413.1621, 0.2756934, 467.91364, 0.0)
   validation loss 594.6605224609375, (330.8601, 0.31249174, 263.48788, 0.0)
decoder loss ratio: 12818.094960, decoder SINDy loss  ratio: 0.568776
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.447509765625, (242.66893, 0.31436756, 491.4642, 0.0)
   validation loss 461.7750244140625, (193.129, 0.3117196, 268.33432, 0.0)
decoder loss ratio: 7482.152662, decoder SINDy loss  ratio: 0.579237
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 832.9415893554688, (362.96863, 0.2929079, 469.68005, 0.0)
   validation loss 552.04248046875, (288.45364, 0.31209052, 263.2767, 0.0)
decoder loss ratio: 11175.194938, decoder SINDy loss  ratio: 0.568320
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.451416015625, (272.71518, 0.27723163, 474.459, 0.0)
   validation loss 471.5492858886719, (206.62842, 0.30977657, 264.61108, 0.0)
decoder loss ratio: 8005.143635, decoder SINDy loss  ratio: 0.571200
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1156.2696533203125, (687.82697, 0.301935, 468.14078, 0.0)
   validation loss 847.576416015625, (579.22406, 0.32052, 268.0319, 0.0)
decoder loss ratio: 22440.145664, decoder SINDy loss  ratio: 0.578585
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.2826538085938, (240.97809, 0.28897017, 482.0156, 0.0)
   validation loss 443.1180419921875, (176.88733, 0.30715284, 265.92355, 0.0)
decoder loss ratio: 6852.922219, decoder SINDy loss  ratio: 0.574033
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.3818969726562, (262.43228, 0.31204683, 506.63757, 0.0)
   validation loss 470.44073486328125, (194.9278, 0.30879378, 275.20413, 0.0)
decoder loss ratio: 7551.841204, decoder SINDy loss  ratio: 0.594067
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.7139892578125, (275.01736, 0.29145044, 475.40515, 0.0)
   validation loss 474.315185546875, (208.27602, 0.3096935, 265.7295, 0.0)
decoder loss ratio: 8068.974452, decoder SINDy loss  ratio: 0.573614
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.01171875, (349.77698, 0.2860766, 468.9487, 0.0)
   validation loss 534.5186767578125, (271.5961, 0.3075789, 262.61502, 0.0)
decoder loss ratio: 10522.104420, decoder SINDy loss  ratio: 0.566891
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 933.2025756835938, (410.72534, 0.3109239, 522.1663, 0.0)
   validation loss 652.2039794921875, (368.60553, 0.2998495, 283.29858, 0.0)
decoder loss ratio: 14280.418151, decoder SINDy loss  ratio: 0.611540
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.8453369140625, (430.73022, 0.28440437, 465.83075, 0.0)
   validation loss 613.8350830078125, (349.342, 0.30958042, 264.18353, 0.0)
decoder loss ratio: 13534.115971, decoder SINDy loss  ratio: 0.570277
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.3980712890625, (239.24088, 0.29724014, 489.86, 0.0)
   validation loss 450.71697998046875, (180.68407, 0.30532724, 269.7276, 0.0)
decoder loss ratio: 7000.014428, decoder SINDy loss  ratio: 0.582245
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.437744140625, (254.11009, 0.33220306, 480.99548, 0.0)
   validation loss 450.0263671875, (183.39085, 0.31041557, 266.3251, 0.0)
decoder loss ratio: 7104.880060, decoder SINDy loss  ratio: 0.574900
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.23095703125, (236.14595, 0.29380333, 484.7912, 0.0)
   validation loss 441.221923828125, (174.26968, 0.30373198, 266.6485, 0.0)
decoder loss ratio: 6751.510097, decoder SINDy loss  ratio: 0.575598
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 873.701171875, (355.13788, 0.32821468, 518.2351, 0.0)
   validation loss 591.2131958007812, (310.20004, 0.29900804, 280.71414, 0.0)
decoder loss ratio: 12017.688186, decoder SINDy loss  ratio: 0.605961
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 831.97705078125, (318.9014, 0.2975135, 512.77814, 0.0)
   validation loss 544.6102294921875, (265.24615, 0.30014837, 279.06396, 0.0)
decoder loss ratio: 10276.096524, decoder SINDy loss  ratio: 0.602399
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 941.7523193359375, (475.92538, 0.28592134, 465.541, 0.0)
   validation loss 643.3861083984375, (380.6551, 0.3044045, 262.42657, 0.0)
decoder loss ratio: 14747.239046, decoder SINDy loss  ratio: 0.566485
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1151.4771728515625, (688.936, 0.28536692, 462.25583, 0.0)
   validation loss 852.28271484375, (586.7789, 0.30584192, 265.198, 0.0)
decoder loss ratio: 22732.832102, decoder SINDy loss  ratio: 0.572467
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 936.918701171875, (472.08203, 0.2975038, 464.53912, 0.0)
   validation loss 653.0479736328125, (389.0381, 0.30678082, 263.70312, 0.0)
decoder loss ratio: 15072.010849, decoder SINDy loss  ratio: 0.569240
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.9215698242188, (313.97092, 0.2760661, 468.6746, 0.0)
   validation loss 502.6409912109375, (239.22319, 0.2997088, 263.11807, 0.0)
decoder loss ratio: 9267.921702, decoder SINDy loss  ratio: 0.567977
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1029.4188232421875, (497.72537, 0.3259796, 531.3675, 0.0)
   validation loss 747.2374267578125, (458.48114, 0.30063096, 288.4557, 0.0)
decoder loss ratio: 17762.355327, decoder SINDy loss  ratio: 0.622672
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.3244018554688, (310.28195, 0.31575015, 519.7267, 0.0)
   validation loss 528.3396606445312, (246.10802, 0.30166543, 281.92996, 0.0)
decoder loss ratio: 9534.651840, decoder SINDy loss  ratio: 0.608585
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.6290893554688, (236.01515, 0.2787411, 485.3352, 0.0)
   validation loss 448.28131103515625, (179.12126, 0.2957473, 268.8643, 0.0)
decoder loss ratio: 6939.468642, decoder SINDy loss  ratio: 0.580381
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.7279052734375, (387.55438, 0.27103314, 464.90247, 0.0)
   validation loss 564.09423828125, (301.8257, 0.2987248, 261.9698, 0.0)
decoder loss ratio: 11693.252157, decoder SINDy loss  ratio: 0.565499
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1572.95458984375, (984.39343, 0.40720594, 588.15393, 0.0)
   validation loss 1256.25537109375, (938.2438, 0.29990342, 317.7117, 0.0)
decoder loss ratio: 36349.192684, decoder SINDy loss  ratio: 0.685825
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 791.6702270507812, (322.99487, 0.29440743, 468.38095, 0.0)
   validation loss 511.25018310546875, (248.16115, 0.29950914, 262.78952, 0.0)
decoder loss ratio: 9614.193703, decoder SINDy loss  ratio: 0.567268
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 719.4144287109375, (229.2931, 0.3149951, 489.8063, 0.0)
   validation loss 446.01666259765625, (176.61305, 0.3003195, 269.10327, 0.0)
decoder loss ratio: 6842.296262, decoder SINDy loss  ratio: 0.580897
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.7542724609375, (282.42276, 0.31895974, 513.0125, 0.0)
   validation loss 481.28643798828125, (204.93224, 0.2994605, 276.05475, 0.0)
decoder loss ratio: 7939.430590, decoder SINDy loss  ratio: 0.595903
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.2130126953125, (239.01971, 0.2894614, 489.9038, 0.0)
   validation loss 450.98590087890625, (182.10913, 0.29407996, 268.58267, 0.0)
decoder loss ratio: 7055.223885, decoder SINDy loss  ratio: 0.579773
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.2061767578125, (373.36462, 0.2769609, 465.56458, 0.0)
   validation loss 558.1239013671875, (295.68295, 0.2967491, 262.1442, 0.0)
decoder loss ratio: 11455.270923, decoder SINDy loss  ratio: 0.565875
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 713.9537963867188, (232.64404, 0.26914686, 481.0406, 0.0)
   validation loss 441.93438720703125, (175.29454, 0.29192212, 266.34793, 0.0)
decoder loss ratio: 6791.214820, decoder SINDy loss  ratio: 0.574949
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1053.9921875, (593.24097, 0.27244875, 460.4787, 0.0)
   validation loss 760.2734985351562, (495.89252, 0.29830408, 264.08267, 0.0)
decoder loss ratio: 19211.737019, decoder SINDy loss  ratio: 0.570060
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.2180786132812, (229.6642, 0.27531865, 486.27856, 0.0)
   validation loss 445.5189208984375, (175.94539, 0.2921896, 269.28134, 0.0)
decoder loss ratio: 6816.429817, decoder SINDy loss  ratio: 0.581282
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.9946899414062, (241.44576, 0.27987567, 474.26907, 0.0)
   validation loss 447.62847900390625, (181.74243, 0.29365307, 265.59238, 0.0)
decoder loss ratio: 7041.017320, decoder SINDy loss  ratio: 0.573319
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2545.603759765625, (2031.7178, 0.27229956, 513.61365, 0.0)
   validation loss 2035.7867431640625, (1730.8453, 0.30731004, 304.6342, 0.0)
decoder loss ratio: 67055.953232, decoder SINDy loss  ratio: 0.657596
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 989.5950927734375, (529.0686, 0.27294785, 460.25354, 0.0)
   validation loss 699.1558837890625, (434.88666, 0.298198, 263.971, 0.0)
decoder loss ratio: 16848.264116, decoder SINDy loss  ratio: 0.569819
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1572.4600830078125, (1106.4834, 0.2624416, 465.71426, 0.0)
   validation loss 1234.1671142578125, (960.2595, 0.29910868, 273.6085, 0.0)
decoder loss ratio: 37202.120946, decoder SINDy loss  ratio: 0.590622
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 908.758056640625, (444.0426, 0.29422367, 464.4212, 0.0)
   validation loss 619.672607421875, (355.6671, 0.29771346, 263.70782, 0.0)
decoder loss ratio: 13779.161472, decoder SINDy loss  ratio: 0.569250
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.1875610351562, (246.69682, 0.28579152, 473.20496, 0.0)
   validation loss 447.85833740234375, (182.68939, 0.29309356, 264.87585, 0.0)
decoder loss ratio: 7077.704212, decoder SINDy loss  ratio: 0.571772
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.8841552734375, (247.75056, 0.30615544, 475.82742, 0.0)
   validation loss 451.47296142578125, (185.73401, 0.29540008, 265.44357, 0.0)
decoder loss ratio: 7195.657949, decoder SINDy loss  ratio: 0.572997
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.0284423828125, (350.1131, 0.29589942, 471.61948, 0.0)
   validation loss 541.9597778320312, (278.61246, 0.29604745, 263.05127, 0.0)
decoder loss ratio: 10793.930287, decoder SINDy loss  ratio: 0.567833
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 910.1484375, (446.1114, 0.2918203, 463.7452, 0.0)
   validation loss 614.679931640625, (352.12878, 0.29340678, 262.25778, 0.0)
decoder loss ratio: 13642.080422, decoder SINDy loss  ratio: 0.566120
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.8944702148438, (339.92902, 0.26799753, 463.69745, 0.0)
   validation loss 522.6566162109375, (261.09918, 0.28932935, 261.26813, 0.0)
decoder loss ratio: 10115.435604, decoder SINDy loss  ratio: 0.563984
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.6270751953125, (258.25574, 0.30959326, 499.06177, 0.0)
   validation loss 485.9903564453125, (212.55298, 0.28900352, 273.14838, 0.0)
decoder loss ratio: 8234.671396, decoder SINDy loss  ratio: 0.589629
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1023.2296142578125, (561.9509, 0.29129195, 460.9874, 0.0)
   validation loss 730.494873046875, (467.25708, 0.28954914, 262.9482, 0.0)
decoder loss ratio: 18102.350476, decoder SINDy loss  ratio: 0.567611
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.6904907226562, (231.08714, 0.28014803, 478.3232, 0.0)
   validation loss 436.49481201171875, (170.74376, 0.28555658, 265.46548, 0.0)
decoder loss ratio: 6614.909654, decoder SINDy loss  ratio: 0.573045
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.1128540039062, (251.00517, 0.2881507, 473.81952, 0.0)
   validation loss 452.138427734375, (187.68498, 0.28569242, 264.16776, 0.0)
decoder loss ratio: 7271.242050, decoder SINDy loss  ratio: 0.570243
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2363.366943359375, (1887.1127, 0.2493575, 476.00485, 0.0)
   validation loss 1987.16943359375, (1701.8555, 0.2951193, 285.01877, 0.0)
decoder loss ratio: 65932.835410, decoder SINDy loss  ratio: 0.615253
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.0565185546875, (241.35071, 0.29897836, 478.40683, 0.0)
   validation loss 447.2969970703125, (181.02762, 0.2859574, 265.98343, 0.0)
decoder loss ratio: 7013.324215, decoder SINDy loss  ratio: 0.574163
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.2282104492188, (227.97484, 0.2756298, 483.97772, 0.0)
   validation loss 441.9842529296875, (173.6504, 0.2795928, 268.05426, 0.0)
decoder loss ratio: 6727.518194, decoder SINDy loss  ratio: 0.578633
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.7843017578125, (238.0742, 0.32062984, 495.3895, 0.0)
   validation loss 457.79803466796875, (185.47581, 0.28570592, 272.0365, 0.0)
decoder loss ratio: 7185.655066, decoder SINDy loss  ratio: 0.587229
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 865.968994140625, (349.49576, 0.29048973, 516.18274, 0.0)
   validation loss 580.01708984375, (299.18845, 0.28157443, 280.54706, 0.0)
decoder loss ratio: 11591.079814, decoder SINDy loss  ratio: 0.605600
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.4071044921875, (282.04202, 0.27175766, 468.09335, 0.0)
   validation loss 477.7532958984375, (214.02272, 0.28272656, 263.44785, 0.0)
decoder loss ratio: 8291.611746, decoder SINDy loss  ratio: 0.568689
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.7044677734375, (227.84871, 0.28331184, 476.57245, 0.0)
   validation loss 438.1557312011719, (171.86041, 0.28235218, 266.01297, 0.0)
decoder loss ratio: 6658.170747, decoder SINDy loss  ratio: 0.574226
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1077.273681640625, (619.4776, 0.25751904, 457.53857, 0.0)
   validation loss 788.3463134765625, (525.88184, 0.28667378, 262.17776, 0.0)
decoder loss ratio: 20373.575295, decoder SINDy loss  ratio: 0.565948
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.75390625, (240.33606, 0.31393412, 482.10394, 0.0)
   validation loss 447.3909912109375, (179.5304, 0.28700268, 267.5736, 0.0)
decoder loss ratio: 6955.319200, decoder SINDy loss  ratio: 0.577595
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.7923583984375, (226.8559, 0.28543237, 481.65106, 0.0)
   validation loss 443.4678955078125, (174.32758, 0.28100547, 268.8593, 0.0)
decoder loss ratio: 6753.752928, decoder SINDy loss  ratio: 0.580371
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1013.2875366210938, (555.00104, 0.27152994, 458.01495, 0.0)
   validation loss 726.422119140625, (463.4899, 0.2803979, 262.65186, 0.0)
decoder loss ratio: 17956.403329, decoder SINDy loss  ratio: 0.566971
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.5736083984375, (283.0442, 0.2716412, 465.25778, 0.0)
   validation loss 472.5234069824219, (209.5595, 0.27693167, 262.68698, 0.0)
decoder loss ratio: 8118.698610, decoder SINDy loss  ratio: 0.567047
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.4166259765625, (309.14932, 0.2583031, 465.00903, 0.0)
   validation loss 498.2431640625, (235.40392, 0.28170502, 262.55756, 0.0)
decoder loss ratio: 9119.956362, decoder SINDy loss  ratio: 0.566767
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1005.9241943359375, (547.84735, 0.26141587, 457.81546, 0.0)
   validation loss 722.537109375, (458.27222, 0.28122005, 263.9837, 0.0)
decoder loss ratio: 17754.261274, decoder SINDy loss  ratio: 0.569846
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 899.452392578125, (434.761, 0.28894588, 464.40244, 0.0)
   validation loss 598.2611083984375, (334.4608, 0.2825185, 263.51782, 0.0)
decoder loss ratio: 12957.591457, decoder SINDy loss  ratio: 0.568840
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.7610473632812, (379.78787, 0.2872806, 461.68588, 0.0)
   validation loss 554.588623046875, (292.45285, 0.28327027, 261.8525, 0.0)
decoder loss ratio: 11330.131143, decoder SINDy loss  ratio: 0.565245
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.641357421875, (232.6641, 0.2818957, 484.6954, 0.0)
   validation loss 445.84197998046875, (177.40266, 0.27496597, 268.16434, 0.0)
decoder loss ratio: 6872.887195, decoder SINDy loss  ratio: 0.578870
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.0620727539062, (358.41013, 0.27166176, 463.38028, 0.0)
   validation loss 530.0638427734375, (267.89862, 0.27882415, 261.88638, 0.0)
decoder loss ratio: 10378.857655, decoder SINDy loss  ratio: 0.565319
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.1018676757812, (233.9753, 0.26734936, 476.85922, 0.0)
   validation loss 436.0758056640625, (170.16078, 0.27466342, 265.64038, 0.0)
decoder loss ratio: 6592.324101, decoder SINDy loss  ratio: 0.573422
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1157.720947265625, (697.984, 0.25127906, 459.4856, 0.0)
   validation loss 842.00732421875, (575.9738, 0.27891514, 265.75458, 0.0)
decoder loss ratio: 22314.225563, decoder SINDy loss  ratio: 0.573669
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.718505859375, (234.40698, 0.263887, 482.0476, 0.0)
   validation loss 449.441162109375, (182.0003, 0.26983458, 267.17102, 0.0)
decoder loss ratio: 7051.007789, decoder SINDy loss  ratio: 0.576726
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.3187866210938, (261.1504, 0.30318975, 498.8652, 0.0)
   validation loss 488.7039489746094, (213.92622, 0.27440262, 274.50333, 0.0)
decoder loss ratio: 8287.873301, decoder SINDy loss  ratio: 0.592554
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1172.3385009765625, (711.7167, 0.28266314, 460.33914, 0.0)
   validation loss 867.2380981445312, (601.15796, 0.27827808, 265.80188, 0.0)
decoder loss ratio: 23289.902987, decoder SINDy loss  ratio: 0.573771
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.0965576171875, (269.70886, 0.28479096, 496.10287, 0.0)
   validation loss 490.43658447265625, (217.67088, 0.27281368, 272.4929, 0.0)
decoder loss ratio: 8432.947908, decoder SINDy loss  ratio: 0.588214
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 835.6718139648438, (373.9237, 0.27364886, 461.47446, 0.0)
   validation loss 549.9261474609375, (288.30762, 0.27493805, 261.3436, 0.0)
decoder loss ratio: 11169.537614, decoder SINDy loss  ratio: 0.564147
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.8369140625, (237.82623, 0.2832815, 473.7274, 0.0)
   validation loss 438.89678955078125, (174.60898, 0.2725771, 264.01523, 0.0)
decoder loss ratio: 6764.654953, decoder SINDy loss  ratio: 0.569914
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1209.225341796875, (748.64075, 0.25846428, 460.32605, 0.0)
   validation loss 876.0052490234375, (609.9311, 0.26951614, 265.80466, 0.0)
decoder loss ratio: 23629.789364, decoder SINDy loss  ratio: 0.573777
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.4241943359375, (408.07147, 0.27916232, 469.07355, 0.0)
   validation loss 542.4017333984375, (279.25165, 0.2719076, 262.87814, 0.0)
decoder loss ratio: 10818.693644, decoder SINDy loss  ratio: 0.567459
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.436279296875, (240.87663, 0.26980487, 488.28983, 0.0)
   validation loss 458.4761047363281, (189.05267, 0.26636, 269.15707, 0.0)
decoder loss ratio: 7324.228775, decoder SINDy loss  ratio: 0.581013
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.6484375, (360.75467, 0.2646047, 460.62915, 0.0)
   validation loss 538.7968139648438, (277.90414, 0.2690818, 260.6236, 0.0)
decoder loss ratio: 10766.489012, decoder SINDy loss  ratio: 0.562593
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.050537109375, (244.51012, 0.31248313, 499.2279, 0.0)
   validation loss 468.2415466308594, (195.59631, 0.26483074, 272.3804, 0.0)
decoder loss ratio: 7577.740754, decoder SINDy loss  ratio: 0.587971
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.838623046875, (313.9375, 0.2801964, 464.6209, 0.0)
   validation loss 504.77496337890625, (243.18683, 0.26643124, 261.32172, 0.0)
decoder loss ratio: 9421.479931, decoder SINDy loss  ratio: 0.564100
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.8182373046875, (298.09964, 0.25474226, 464.46384, 0.0)
   validation loss 488.5009460449219, (227.46234, 0.2675427, 260.77106, 0.0)
decoder loss ratio: 8812.285994, decoder SINDy loss  ratio: 0.562911
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.944580078125, (335.69168, 0.2574602, 462.99545, 0.0)
   validation loss 513.5579833984375, (251.39731, 0.26734105, 261.89334, 0.0)
decoder loss ratio: 9739.568170, decoder SINDy loss  ratio: 0.565334
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.8070678710938, (223.72449, 0.26430085, 478.81827, 0.0)
   validation loss 432.57855224609375, (166.03606, 0.26538038, 266.2771, 0.0)
decoder loss ratio: 6432.525081, decoder SINDy loss  ratio: 0.574797
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.8173828125, (232.96603, 0.29446355, 475.5569, 0.0)
   validation loss 441.12994384765625, (176.49234, 0.2696932, 264.3679, 0.0)
decoder loss ratio: 6837.619659, decoder SINDy loss  ratio: 0.570675
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.992431640625, (289.1076, 0.29040298, 507.59445, 0.0)
   validation loss 511.8302001953125, (235.00671, 0.26717252, 276.55634, 0.0)
decoder loss ratio: 9104.568085, decoder SINDy loss  ratio: 0.596986
params['save_name']
pendulum_2023_10_26_04_58_23_871554
