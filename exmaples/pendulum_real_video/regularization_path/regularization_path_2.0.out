nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 23:24:25.279767: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 23:24:25.287402: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 23:24:25.289135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5580866fbae0 executing computations on platform Host. Devices:
2023-10-25 23:24:25.289171: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 23:24:25.291128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 23:24:25.424482: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5580867a3c20 executing computations on platform CUDA. Devices:
2023-10-25 23:24:25.424527: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 23:24:25.425154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-10-25 23:24:25.425531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 23:24:25.429015: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 23:24:25.432133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 23:24:25.432753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 23:24:25.436510: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 23:24:25.437944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 23:24:25.443274: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 23:24:25.444186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 23:24:25.444240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 23:24:25.444765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 23:24:25.444780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 23:24:25.444789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 23:24:25.445653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-10-25 23:24:26.686439: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 2.0, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.9263412952423096 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 102992.0859375, (92793.98, 0.005637929, 10180.576, 2.5317814)
   validation loss 81047.3671875, (79829.086, 0.003699807, 1200.7543, 2.5317814)
decoder loss ratio: 3092717.378607, decoder SINDy loss  ratio: 2.591997
--- 0.26502299308776855 seconds for one epoch ---
--- 0.348036527633667 seconds for one epoch ---
--- 0.33858442306518555 seconds for one epoch ---
--- 0.34544992446899414 seconds for one epoch ---
--- 0.3472564220428467 seconds for one epoch ---
--- 0.3415091037750244 seconds for one epoch ---
--- 0.35744762420654297 seconds for one epoch ---
--- 0.3325018882751465 seconds for one epoch ---
--- 0.34578657150268555 seconds for one epoch ---
--- 0.3123626708984375 seconds for one epoch ---
--- 0.3388376235961914 seconds for one epoch ---
--- 0.3523597717285156 seconds for one epoch ---
--- 0.34795236587524414 seconds for one epoch ---
--- 0.3460104465484619 seconds for one epoch ---
--- 0.3346521854400635 seconds for one epoch ---
--- 0.35178494453430176 seconds for one epoch ---
--- 0.34542202949523926 seconds for one epoch ---
--- 0.34983181953430176 seconds for one epoch ---
--- 0.3357822895050049 seconds for one epoch ---
--- 0.3432126045227051 seconds for one epoch ---
--- 0.3378119468688965 seconds for one epoch ---
--- 0.33824706077575684 seconds for one epoch ---
--- 0.3272709846496582 seconds for one epoch ---
--- 0.3449568748474121 seconds for one epoch ---
=========================
[[0.78041154]
 [0.7805944 ]
 [0.78144324]
 [0.7816178 ]
 [0.77881455]
 [0.7826538 ]
 [0.78141576]
 [0.7786644 ]
 [0.77835894]
 [0.786263  ]
 [0.77927417]]
[[ 0.54517287]
 [ 0.5883076 ]
 [-0.78053313]
 [-0.81855863]
 [-0.13632716]
 [-1.0345865 ]
 [ 0.7744916 ]
 [-0.09458219]
 [ 0.00723187]
 [-1.6894307 ]
 [ 0.2605152 ]]
--- 0.28968191146850586 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 81140.609375, (73428.445, 50.553688, 7619.055, 2.5317523)
   validation loss 45896.3515625, (44545.145, 21.1132, 1287.5405, 2.5317523)
decoder loss ratio: 1725756.232912, decoder SINDy loss  ratio: 2.779337
--- 0.3402974605560303 seconds for one epoch ---
--- 0.3466484546661377 seconds for one epoch ---
--- 0.3432464599609375 seconds for one epoch ---
--- 0.3669753074645996 seconds for one epoch ---
--- 0.3511085510253906 seconds for one epoch ---
--- 0.3558309078216553 seconds for one epoch ---
--- 0.3475320339202881 seconds for one epoch ---
--- 0.3434121608734131 seconds for one epoch ---
--- 0.3457913398742676 seconds for one epoch ---
--- 0.3433101177215576 seconds for one epoch ---
--- 0.3321566581726074 seconds for one epoch ---
--- 0.3327174186706543 seconds for one epoch ---
--- 0.32607555389404297 seconds for one epoch ---
--- 0.3538548946380615 seconds for one epoch ---
--- 0.3364222049713135 seconds for one epoch ---
--- 0.37920522689819336 seconds for one epoch ---
--- 0.34954190254211426 seconds for one epoch ---
--- 0.36052513122558594 seconds for one epoch ---
--- 0.35344862937927246 seconds for one epoch ---
--- 0.36992502212524414 seconds for one epoch ---
--- 0.3521130084991455 seconds for one epoch ---
--- 0.338909387588501 seconds for one epoch ---
--- 0.3631100654602051 seconds for one epoch ---
--- 0.35343480110168457 seconds for one epoch ---
=========================
[[0.62981176]
 [0.6226425 ]
 [0.62347233]
 [0.6234439 ]
 [0.62109137]
 [0.6302003 ]
 [0.6251838 ]
 [0.6219485 ]
 [0.62080795]
 [0.6256323 ]
 [0.62195134]]
[[ 1.2232208 ]
 [ 0.3011684 ]
 [-0.42440635]
 [-0.42026055]
 [-0.05444005]
 [-1.2659575 ]
 [ 0.66231406]
 [ 0.19358002]
 [ 0.00672181]
 [-0.7216241 ]
 [ 0.19406809]]
--- 0.31908297538757324 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 54171.328125, (49184.746, 2.1068377, 4923.6094, 2.5317254)
   validation loss 33345.9921875, (32112.45, 9.37973, 1163.295, 2.5317254)
decoder loss ratio: 1244092.032398, decoder SINDy loss  ratio: 2.511136
--- 0.29712462425231934 seconds for one epoch ---
--- 0.33237743377685547 seconds for one epoch ---
--- 0.3602180480957031 seconds for one epoch ---
--- 0.3334066867828369 seconds for one epoch ---
--- 0.3603184223175049 seconds for one epoch ---
--- 0.33527135848999023 seconds for one epoch ---
--- 0.37111520767211914 seconds for one epoch ---
--- 0.3307671546936035 seconds for one epoch ---
--- 0.37238574028015137 seconds for one epoch ---
--- 0.34113049507141113 seconds for one epoch ---
--- 0.35070204734802246 seconds for one epoch ---
--- 0.3442683219909668 seconds for one epoch ---
--- 0.3506925106048584 seconds for one epoch ---
--- 0.3013880252838135 seconds for one epoch ---
--- 0.3900160789489746 seconds for one epoch ---
--- 0.42456698417663574 seconds for one epoch ---
--- 0.35311365127563477 seconds for one epoch ---
--- 0.3308720588684082 seconds for one epoch ---
--- 0.35610270500183105 seconds for one epoch ---
--- 0.33389735221862793 seconds for one epoch ---
--- 0.36158156394958496 seconds for one epoch ---
--- 0.3431057929992676 seconds for one epoch ---
--- 0.36265134811401367 seconds for one epoch ---
--- 0.3395848274230957 seconds for one epoch ---
=========================
[[0.50200427]
 [0.4898565 ]
 [0.49122864]
 [0.49133995]
 [0.48954377]
 [0.50699836]
 [0.49383485]
 [0.49112785]
 [0.4888291 ]
 [0.49157706]
 [0.48906067]]
[[ 1.3061862 ]
 [ 0.13133882]
 [-0.29123992]
 [-0.30378032]
 [-0.09347828]
 [-1.6838486 ]
 [ 0.5711589 ]
 [ 0.27976415]
 [ 0.00485241]
 [-0.33038625]
 [ 0.03391739]]
--- 0.28160691261291504 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 44352.95703125, (41610.51, 2.0017238, 2665.1467, 2.5317278)
   validation loss 19922.7265625, (18826.904, 0.55807555, 1019.9694, 2.5317278)
decoder loss ratio: 729386.957404, decoder SINDy loss  ratio: 2.201747
--- 0.31771039962768555 seconds for one epoch ---
--- 0.3883979320526123 seconds for one epoch ---
--- 0.32841944694519043 seconds for one epoch ---
--- 0.38549232482910156 seconds for one epoch ---
--- 0.31415271759033203 seconds for one epoch ---
--- 0.3759453296661377 seconds for one epoch ---
--- 0.3159329891204834 seconds for one epoch ---
--- 0.36552906036376953 seconds for one epoch ---
--- 0.3218088150024414 seconds for one epoch ---
--- 0.36134862899780273 seconds for one epoch ---
--- 0.34132838249206543 seconds for one epoch ---
--- 0.37350964546203613 seconds for one epoch ---
--- 0.3368244171142578 seconds for one epoch ---
--- 0.3539762496948242 seconds for one epoch ---
--- 0.3108837604522705 seconds for one epoch ---
--- 0.3408219814300537 seconds for one epoch ---
--- 0.3383209705352783 seconds for one epoch ---
--- 0.38744688034057617 seconds for one epoch ---
--- 0.34366393089294434 seconds for one epoch ---
--- 0.38683485984802246 seconds for one epoch ---
--- 0.34920549392700195 seconds for one epoch ---
--- 0.3738081455230713 seconds for one epoch ---
--- 0.3394162654876709 seconds for one epoch ---
--- 0.37967562675476074 seconds for one epoch ---
=========================
[[0.4053983 ]
 [0.39471152]
 [0.39486974]
 [0.39662972]
 [0.39533526]
 [0.42479113]
 [0.39935845]
 [0.39741516]
 [0.39441493]
 [0.39874506]
 [0.39596155]]
[[ 9.7511023e-01]
 [ 3.3479784e-02]
 [-5.0103649e-02]
 [-2.2798164e-01]
 [-9.8315641e-02]
 [-2.1819000e+00]
 [ 4.8238638e-01]
 [ 3.0371237e-01]
 [-2.0223141e-03]
 [-4.2724821e-01]
 [ 1.6186577e-01]]
--- 0.33809614181518555 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 23649.20703125, (19057.793, 5.963524, 4494.7314, 2.5317369)
   validation loss 10265.470703125, (9312.307, 0.42234844, 862.024, 2.5317369)
decoder loss ratio: 360774.926133, decoder SINDy loss  ratio: 1.860800
--- 0.2880539894104004 seconds for one epoch ---
--- 0.3219938278198242 seconds for one epoch ---
--- 0.37918615341186523 seconds for one epoch ---
--- 0.33816099166870117 seconds for one epoch ---
--- 0.40270352363586426 seconds for one epoch ---
--- 0.32206273078918457 seconds for one epoch ---
--- 0.39133286476135254 seconds for one epoch ---
--- 0.3066580295562744 seconds for one epoch ---
--- 0.38203883171081543 seconds for one epoch ---
--- 0.3171830177307129 seconds for one epoch ---
--- 0.3839685916900635 seconds for one epoch ---
--- 0.3266723155975342 seconds for one epoch ---
--- 0.3909757137298584 seconds for one epoch ---
--- 0.3130650520324707 seconds for one epoch ---
--- 0.3960399627685547 seconds for one epoch ---
--- 0.32111454010009766 seconds for one epoch ---
--- 0.36061882972717285 seconds for one epoch ---
--- 0.31090879440307617 seconds for one epoch ---
--- 0.3867626190185547 seconds for one epoch ---
--- 0.33193159103393555 seconds for one epoch ---
--- 0.4127824306488037 seconds for one epoch ---
--- 0.3294100761413574 seconds for one epoch ---
--- 0.3858771324157715 seconds for one epoch ---
--- 0.33870434761047363 seconds for one epoch ---
=========================
[[0.3207626 ]
 [0.31546152]
 [0.31741682]
 [0.31602353]
 [0.31505698]
 [0.35913876]
 [0.32017675]
 [0.31838998]
 [0.3149145 ]
 [0.32473636]
 [0.3177393 ]]
[[ 0.505793  ]
 [-0.05707008]
 [ 0.23144649]
 [-0.10839541]
 [-0.01949825]
 [-2.6210783 ]
 [ 0.4596896 ]
 [ 0.31412813]
 [-0.00612874]
 [-0.8000722 ]
 [ 0.25914782]]
--- 0.26486992835998535 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 16158.4326171875, (9087.456, 20.897667, 6946.525, 2.5317593)
   validation loss 7528.6015625, (6697.727, 0.21374692, 727.10815, 2.5317593)
decoder loss ratio: 259481.573713, decoder SINDy loss  ratio: 1.569565
--- 0.3450338840484619 seconds for one epoch ---
--- 0.3695333003997803 seconds for one epoch ---
--- 0.33447885513305664 seconds for one epoch ---
--- 0.38196730613708496 seconds for one epoch ---
--- 0.3364396095275879 seconds for one epoch ---
--- 0.3780961036682129 seconds for one epoch ---
--- 0.32922863960266113 seconds for one epoch ---
--- 0.3827965259552002 seconds for one epoch ---
--- 0.34555649757385254 seconds for one epoch ---
--- 0.39215540885925293 seconds for one epoch ---
--- 0.3408174514770508 seconds for one epoch ---
--- 0.3914940357208252 seconds for one epoch ---
--- 0.33037328720092773 seconds for one epoch ---
--- 0.38372015953063965 seconds for one epoch ---
--- 0.34825730323791504 seconds for one epoch ---
--- 0.4100320339202881 seconds for one epoch ---
--- 0.3254127502441406 seconds for one epoch ---
--- 0.39230847358703613 seconds for one epoch ---
--- 0.31442737579345703 seconds for one epoch ---
--- 0.40961313247680664 seconds for one epoch ---
--- 0.332871675491333 seconds for one epoch ---
--- 0.4138765335083008 seconds for one epoch ---
--- 0.3272385597229004 seconds for one epoch ---
--- 0.39112401008605957 seconds for one epoch ---
=========================
[[0.25824237]
 [0.25896788]
 [0.2627969 ]
 [0.2580807 ]
 [0.25771517]
 [0.31714383]
 [0.2634657 ]
 [0.26140356]
 [0.25764763]
 [0.27448997]
 [0.26201642]]
[[ 0.0543275 ]
 [-0.11540525]
 [ 0.4163868 ]
 [-0.04049074]
 [-0.00901184]
 [-3.050551  ]
 [ 0.46567586]
 [ 0.31072247]
 [-0.00313216]
 [-1.1761688 ]
 [ 0.35772777]]
--- 0.33452939987182617 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 15409.263671875, (11138.966, 4.639682, 4150.211, 2.531793)
   validation loss 5011.50390625, (4299.7744, 0.17728472, 596.1062, 2.531793)
decoder loss ratio: 166580.725537, decoder SINDy loss  ratio: 1.286779
--- 0.29206275939941406 seconds for one epoch ---
--- 0.33986973762512207 seconds for one epoch ---
--- 0.38924288749694824 seconds for one epoch ---
--- 0.3401002883911133 seconds for one epoch ---
--- 0.41960692405700684 seconds for one epoch ---
--- 0.33893799781799316 seconds for one epoch ---
--- 0.42905378341674805 seconds for one epoch ---
--- 0.35080695152282715 seconds for one epoch ---
--- 0.4088478088378906 seconds for one epoch ---
--- 0.35187482833862305 seconds for one epoch ---
--- 0.38501453399658203 seconds for one epoch ---
--- 0.3514859676361084 seconds for one epoch ---
--- 0.3900902271270752 seconds for one epoch ---
--- 0.3491847515106201 seconds for one epoch ---
--- 0.3907012939453125 seconds for one epoch ---
--- 0.3345761299133301 seconds for one epoch ---
--- 0.4255688190460205 seconds for one epoch ---
--- 0.34233736991882324 seconds for one epoch ---
--- 0.3919394016265869 seconds for one epoch ---
--- 0.30536413192749023 seconds for one epoch ---
--- 0.3797156810760498 seconds for one epoch ---
--- 0.32616257667541504 seconds for one epoch ---
--- 0.43241286277770996 seconds for one epoch ---
--- 0.331815242767334 seconds for one epoch ---
=========================
[[0.21324232]
 [0.21139337]
 [0.21737127]
 [0.20970227]
 [0.2093417 ]
 [0.2824602 ]
 [0.2147647 ]
 [0.21353188]
 [0.20924316]
 [0.23365882]
 [0.2156391 ]]
[[-0.31876436]
 [-0.18152162]
 [ 0.6024064 ]
 [-0.04942562]
 [ 0.02037894]
 [-3.3736882 ]
 [ 0.426765  ]
 [ 0.33965605]
 [-0.01236828]
 [-1.5129764 ]
 [ 0.4869261 ]]
--- 0.28043580055236816 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7035.837890625, (4808.482, 21.548346, 2081.6826, 2.5318363)
   validation loss 5069.484375, (4387.0312, 0.08999691, 558.2381, 2.5318363)
decoder loss ratio: 169961.206846, decoder SINDy loss  ratio: 1.205035
--- 0.3205831050872803 seconds for one epoch ---
--- 0.40311479568481445 seconds for one epoch ---
--- 0.32992124557495117 seconds for one epoch ---
--- 0.40706920623779297 seconds for one epoch ---
--- 0.3374185562133789 seconds for one epoch ---
--- 0.44086265563964844 seconds for one epoch ---
--- 0.33461833000183105 seconds for one epoch ---
--- 0.4270322322845459 seconds for one epoch ---
--- 0.33097028732299805 seconds for one epoch ---
--- 0.41042208671569824 seconds for one epoch ---
--- 0.33166027069091797 seconds for one epoch ---
--- 0.4290139675140381 seconds for one epoch ---
--- 0.3385944366455078 seconds for one epoch ---
--- 0.40365028381347656 seconds for one epoch ---
--- 0.3363163471221924 seconds for one epoch ---
--- 0.4199559688568115 seconds for one epoch ---
--- 0.34903693199157715 seconds for one epoch ---
--- 0.41727519035339355 seconds for one epoch ---
--- 0.33951592445373535 seconds for one epoch ---
--- 0.4136970043182373 seconds for one epoch ---
--- 0.3268752098083496 seconds for one epoch ---
--- 0.38892483711242676 seconds for one epoch ---
--- 0.317058801651001 seconds for one epoch ---
--- 0.39435601234436035 seconds for one epoch ---
=========================
[[0.18253629]
 [0.17701069]
 [0.18533859]
 [0.17488582]
 [0.17432788]
 [0.25781116]
 [0.17911707]
 [0.17871556]
 [0.17411014]
 [0.20574348]
 [0.18203947]]
[[-0.597146  ]
 [-0.2273621 ]
 [ 0.7675591 ]
 [-0.07045697]
 [ 0.02763067]
 [-3.588035  ]
 [ 0.3742507 ]
 [ 0.34687126]
 [-0.01074784]
 [-1.7864834 ]
 [ 0.5658412 ]]
--- 0.3050851821899414 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7411.23828125, (3172.905, 0.86007273, 4105.0815, 2.531872)
   validation loss 4979.81640625, (4376.9834, 0.07689465, 470.3646, 2.531872)
decoder loss ratio: 169571.935633, decoder SINDy loss  ratio: 1.015348
--- 0.28372907638549805 seconds for one epoch ---
--- 0.31485462188720703 seconds for one epoch ---
--- 0.4257347583770752 seconds for one epoch ---
--- 0.3267092704772949 seconds for one epoch ---
--- 0.42867231369018555 seconds for one epoch ---
--- 0.31341099739074707 seconds for one epoch ---
--- 0.42844319343566895 seconds for one epoch ---
--- 0.3237924575805664 seconds for one epoch ---
--- 0.4258596897125244 seconds for one epoch ---
--- 0.30953502655029297 seconds for one epoch ---
--- 0.42651891708374023 seconds for one epoch ---
--- 0.3071000576019287 seconds for one epoch ---
--- 0.4314460754394531 seconds for one epoch ---
--- 0.3252403736114502 seconds for one epoch ---
--- 0.42604756355285645 seconds for one epoch ---
--- 0.4085228443145752 seconds for one epoch ---
--- 0.4244685173034668 seconds for one epoch ---
--- 0.31935787200927734 seconds for one epoch ---
--- 0.45043516159057617 seconds for one epoch ---
--- 0.3134777545928955 seconds for one epoch ---
--- 0.4183080196380615 seconds for one epoch ---
--- 0.31621289253234863 seconds for one epoch ---
--- 0.40700316429138184 seconds for one epoch ---
--- 0.30091309547424316 seconds for one epoch ---
=========================
[[0.1571238 ]
 [0.14815246]
 [0.158312  ]
 [0.14432457]
 [0.14425556]
 [0.2361924 ]
 [0.14880641]
 [0.14893182]
 [0.14416084]
 [0.1834195 ]
 [0.15326625]]
[[-0.841557  ]
 [-0.29387543]
 [ 0.9068593 ]
 [-0.02208621]
 [ 0.01692275]
 [-3.7354593 ]
 [ 0.33764863]
 [ 0.34597304]
 [-0.00980883]
 [-2.0458415 ]
 [ 0.61893   ]]
--- 0.2697105407714844 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9864.099609375, (5079.0605, 4.0590506, 4640.903, 2.5319042)
   validation loss 2678.424072265625, (2099.571, 0.076596536, 438.6997, 2.5319042)
decoder loss ratio: 81341.027296, decoder SINDy loss  ratio: 0.946995
--- 0.3350839614868164 seconds for one epoch ---
--- 0.4160919189453125 seconds for one epoch ---
--- 0.3351409435272217 seconds for one epoch ---
--- 0.4151332378387451 seconds for one epoch ---
--- 0.3469657897949219 seconds for one epoch ---
--- 0.426084041595459 seconds for one epoch ---
--- 0.3432950973510742 seconds for one epoch ---
--- 0.4370574951171875 seconds for one epoch ---
--- 0.34424614906311035 seconds for one epoch ---
--- 0.414201021194458 seconds for one epoch ---
--- 0.33447837829589844 seconds for one epoch ---
--- 0.44061279296875 seconds for one epoch ---
--- 0.3359074592590332 seconds for one epoch ---
--- 0.4555346965789795 seconds for one epoch ---
--- 0.3403785228729248 seconds for one epoch ---
--- 0.44457578659057617 seconds for one epoch ---
--- 0.3106708526611328 seconds for one epoch ---
--- 0.40215492248535156 seconds for one epoch ---
--- 0.3470320701599121 seconds for one epoch ---
--- 0.4307084083557129 seconds for one epoch ---
--- 0.32443857192993164 seconds for one epoch ---
--- 0.44704723358154297 seconds for one epoch ---
--- 0.31241798400878906 seconds for one epoch ---
--- 0.44659972190856934 seconds for one epoch ---
=========================
[[0.13997583]
 [0.12716658]
 [0.13934588]
 [0.12225406]
 [0.12230622]
 [0.22127824]
 [0.12673566]
 [0.12723729]
 [0.12241998]
 [0.16931927]
 [0.13214965]]
[[-1.0667106e+00]
 [-3.3991721e-01]
 [ 1.0348649e+00]
 [-1.4564709e-03]
 [ 5.2896906e-03]
 [-3.8565145e+00]
 [ 3.1189519e-01]
 [ 3.4449077e-01]
 [-1.3635399e-02]
 [-2.2910438e+00]
 [ 6.4482605e-01]]
--- 0.313159704208374 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6370.74853515625, (3671.3528, 2.8815162, 2549.7063, 2.5319345)
   validation loss 2678.02734375, (2097.75, 0.083806366, 433.38538, 2.5319345)
decoder loss ratio: 81270.476854, decoder SINDy loss  ratio: 0.935523
--- 0.2862660884857178 seconds for one epoch ---
--- 0.3421440124511719 seconds for one epoch ---
--- 0.43567752838134766 seconds for one epoch ---
--- 0.35477685928344727 seconds for one epoch ---
--- 0.44077229499816895 seconds for one epoch ---
--- 0.3442721366882324 seconds for one epoch ---
--- 0.4389979839324951 seconds for one epoch ---
--- 0.34331274032592773 seconds for one epoch ---
--- 0.434370756149292 seconds for one epoch ---
--- 0.3414163589477539 seconds for one epoch ---
--- 0.4326789379119873 seconds for one epoch ---
--- 0.3395721912384033 seconds for one epoch ---
--- 0.42670702934265137 seconds for one epoch ---
--- 0.34089088439941406 seconds for one epoch ---
--- 0.43538427352905273 seconds for one epoch ---
--- 0.3360307216644287 seconds for one epoch ---
--- 0.4375932216644287 seconds for one epoch ---
--- 0.3431050777435303 seconds for one epoch ---
--- 0.42704343795776367 seconds for one epoch ---
--- 0.3449850082397461 seconds for one epoch ---
--- 0.4430415630340576 seconds for one epoch ---
--- 0.3303706645965576 seconds for one epoch ---
--- 0.43242549896240234 seconds for one epoch ---
--- 0.3262772560119629 seconds for one epoch ---
=========================
[[0.12489127]
 [0.10895763]
 [0.12321952]
 [0.10470396]
 [0.10389208]
 [0.20671637]
 [0.10812311]
 [0.1089349 ]
 [0.10369667]
 [0.15688896]
 [0.11398687]]
[[-1.2216839 ]
 [-0.3635235 ]
 [ 1.1423267 ]
 [ 0.0821183 ]
 [ 0.02480914]
 [-3.908634  ]
 [ 0.3105981 ]
 [ 0.3620918 ]
 [-0.01083421]
 [-2.4700627 ]
 [ 0.6626101 ]]
--- 0.26341795921325684 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7776.01123046875, (3656.2349, 1.8674638, 3965.8047, 2.531958)
   validation loss 5030.48681640625, (4457.686, 0.056693785, 420.6401, 2.531958)
decoder loss ratio: 172698.495885, decoder SINDy loss  ratio: 0.908011
--- 0.31075096130371094 seconds for one epoch ---
--- 0.44478321075439453 seconds for one epoch ---
--- 0.32444286346435547 seconds for one epoch ---
--- 0.45980095863342285 seconds for one epoch ---
--- 0.32268691062927246 seconds for one epoch ---
--- 0.4491767883300781 seconds for one epoch ---
--- 0.3239781856536865 seconds for one epoch ---
--- 0.47161388397216797 seconds for one epoch ---
--- 0.32828593254089355 seconds for one epoch ---
--- 0.4432563781738281 seconds for one epoch ---
--- 0.3372225761413574 seconds for one epoch ---
--- 0.4690978527069092 seconds for one epoch ---
--- 0.3453409671783447 seconds for one epoch ---
--- 0.43932247161865234 seconds for one epoch ---
--- 0.3372189998626709 seconds for one epoch ---
--- 0.44246768951416016 seconds for one epoch ---
--- 0.32994961738586426 seconds for one epoch ---
--- 0.45475196838378906 seconds for one epoch ---
--- 0.3413660526275635 seconds for one epoch ---
--- 0.4484713077545166 seconds for one epoch ---
--- 0.3447592258453369 seconds for one epoch ---
--- 0.45783281326293945 seconds for one epoch ---
--- 0.35628247261047363 seconds for one epoch ---
--- 0.4752991199493408 seconds for one epoch ---
=========================
[[0.11430354]
 [0.09540787]
 [0.1113627 ]
 [0.09168738]
 [0.08996141]
 [0.19551343]
 [0.09467404]
 [0.09519053]
 [0.089973  ]
 [0.14877242]
 [0.10207098]]
[[-1.3469613 ]
 [-0.3664803 ]
 [ 1.2136406 ]
 [ 0.12617016]
 [ 0.00678079]
 [-3.9314964 ]
 [ 0.32075825]
 [ 0.35302565]
 [-0.00760562]
 [-2.623427  ]
 [ 0.750465  ]]
--- 0.29801225662231445 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6556.087890625, (2637.3425, 3.2290056, 3758.316, 2.5319774)
   validation loss 1944.0382080078125, (1400.2377, 0.061562363, 386.5387, 2.5319774)
decoder loss ratio: 54247.638290, decoder SINDy loss  ratio: 0.834398
--- 0.2729148864746094 seconds for one epoch ---
--- 0.30872583389282227 seconds for one epoch ---
--- 0.4490361213684082 seconds for one epoch ---
--- 0.30623483657836914 seconds for one epoch ---
--- 0.4651510715484619 seconds for one epoch ---
--- 0.3176536560058594 seconds for one epoch ---
--- 0.47539615631103516 seconds for one epoch ---
--- 0.3259713649749756 seconds for one epoch ---
--- 0.47675395011901855 seconds for one epoch ---
--- 0.3346598148345947 seconds for one epoch ---
--- 0.4892253875732422 seconds for one epoch ---
--- 0.32050609588623047 seconds for one epoch ---
--- 0.4528782367706299 seconds for one epoch ---
--- 0.32511138916015625 seconds for one epoch ---
--- 0.46770381927490234 seconds for one epoch ---
--- 0.3300650119781494 seconds for one epoch ---
--- 0.4562208652496338 seconds for one epoch ---
--- 0.3367128372192383 seconds for one epoch ---
--- 0.4729444980621338 seconds for one epoch ---
--- 0.32613563537597656 seconds for one epoch ---
--- 0.46938395500183105 seconds for one epoch ---
--- 0.34902310371398926 seconds for one epoch ---
--- 0.46806764602661133 seconds for one epoch ---
--- 0.33594655990600586 seconds for one epoch ---
=========================
[[0.10427841]
 [0.0841938 ]
 [0.10210776]
 [0.0799933 ]
 [0.07812257]
 [0.1835847 ]
 [0.08266553]
 [0.08343817]
 [0.07823198]
 [0.14083113]
 [0.09143342]]
[[-1.4100286e+00]
 [-3.9730385e-01]
 [ 1.3153019e+00]
 [ 1.3125910e-01]
 [ 3.5629505e-03]
 [-3.8938687e+00]
 [ 3.0353320e-01]
 [ 3.5134515e-01]
 [-1.1209274e-02]
 [-2.7192342e+00]
 [ 8.0310082e-01]]
--- 0.29531145095825195 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6601.80517578125, (3295.4404, 0.28328326, 3144.6104, 2.531986)
   validation loss 2368.927734375, (1873.5118, 0.04021302, 333.90472, 2.531986)
decoder loss ratio: 72583.101273, decoder SINDy loss  ratio: 0.720780
--- 0.3017702102661133 seconds for one epoch ---
--- 0.4706761837005615 seconds for one epoch ---
--- 0.31043434143066406 seconds for one epoch ---
--- 0.44983792304992676 seconds for one epoch ---
--- 0.3100919723510742 seconds for one epoch ---
--- 0.46314215660095215 seconds for one epoch ---
--- 0.3144187927246094 seconds for one epoch ---
--- 0.4631516933441162 seconds for one epoch ---
--- 0.3215484619140625 seconds for one epoch ---
--- 0.4600956439971924 seconds for one epoch ---
--- 0.32549142837524414 seconds for one epoch ---
--- 0.47666192054748535 seconds for one epoch ---
--- 0.3229243755340576 seconds for one epoch ---
--- 0.4787890911102295 seconds for one epoch ---
--- 0.32956981658935547 seconds for one epoch ---
--- 0.4711158275604248 seconds for one epoch ---
--- 0.3283226490020752 seconds for one epoch ---
--- 0.47092437744140625 seconds for one epoch ---
--- 0.3289816379547119 seconds for one epoch ---
--- 0.4941446781158447 seconds for one epoch ---
--- 0.3288733959197998 seconds for one epoch ---
--- 0.4828479290008545 seconds for one epoch ---
--- 0.3273923397064209 seconds for one epoch ---
--- 0.4797482490539551 seconds for one epoch ---
=========================
[[0.09709421]
 [0.0757455 ]
 [0.09605379]
 [0.0714175 ]
 [0.06955463]
 [0.17332736]
 [0.0739098 ]
 [0.07460593]
 [0.06947268]
 [0.13583873]
 [0.08337665]]
[[-1.4628626 ]
 [-0.40772167]
 [ 1.4189354 ]
 [ 0.13698258]
 [ 0.01133001]
 [-3.8297381 ]
 [ 0.29620957]
 [ 0.33903557]
 [-0.00566453]
 [-2.8124907 ]
 [ 0.82878816]]
--- 0.31974244117736816 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5609.58935546875, (2544.98, 3.149674, 2896.8237, 2.5319922)
   validation loss 1644.8299560546875, (1109.3477, 0.042837042, 370.80353, 2.5319922)
decoder loss ratio: 42978.054115, decoder SINDy loss  ratio: 0.800432
--- 0.26970767974853516 seconds for one epoch ---
--- 0.32074618339538574 seconds for one epoch ---
--- 0.47298455238342285 seconds for one epoch ---
--- 0.3206312656402588 seconds for one epoch ---
--- 0.46788525581359863 seconds for one epoch ---
--- 0.3041365146636963 seconds for one epoch ---
--- 0.4616105556488037 seconds for one epoch ---
--- 0.31346774101257324 seconds for one epoch ---
--- 0.47554564476013184 seconds for one epoch ---
--- 0.3188502788543701 seconds for one epoch ---
--- 0.4755702018737793 seconds for one epoch ---
--- 0.3095877170562744 seconds for one epoch ---
--- 0.4628603458404541 seconds for one epoch ---
--- 0.3153986930847168 seconds for one epoch ---
--- 0.4775998592376709 seconds for one epoch ---
--- 0.3080785274505615 seconds for one epoch ---
--- 0.49624180793762207 seconds for one epoch ---
--- 0.31448817253112793 seconds for one epoch ---
--- 0.474088191986084 seconds for one epoch ---
--- 0.3210422992706299 seconds for one epoch ---
--- 0.48561811447143555 seconds for one epoch ---
--- 0.3216731548309326 seconds for one epoch ---
--- 0.4979081153869629 seconds for one epoch ---
--- 0.3116292953491211 seconds for one epoch ---
=========================
[[0.09178726]
 [0.0686329 ]
 [0.09024478]
 [0.06461724]
 [0.06190398]
 [0.16474013]
 [0.06582709]
 [0.0669737 ]
 [0.0619295 ]
 [0.13319321]
 [0.07676487]]
[[-1.5447839e+00]
 [-4.2889506e-01]
 [ 1.4815549e+00]
 [ 1.8277146e-01]
 [ 2.5376703e-03]
 [-3.7822669e+00]
 [ 2.5931942e-01]
 [ 3.2990623e-01]
 [-4.2887777e-03]
 [-2.9392374e+00]
 [ 8.6919600e-01]]
--- 0.2857847213745117 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6994.74365234375, (3153.2913, 4.039496, 3669.51, 2.5320022)
   validation loss 1501.6827392578125, (1018.35895, 0.03900797, 315.38196, 2.5320022)
decoder loss ratio: 39452.993585, decoder SINDy loss  ratio: 0.680796
--- 0.34293103218078613 seconds for one epoch ---
--- 0.4995114803314209 seconds for one epoch ---
--- 0.34333205223083496 seconds for one epoch ---
--- 0.48105525970458984 seconds for one epoch ---
--- 0.3202393054962158 seconds for one epoch ---
--- 0.4748876094818115 seconds for one epoch ---
--- 0.3081502914428711 seconds for one epoch ---
--- 0.4767739772796631 seconds for one epoch ---
--- 0.3529355525970459 seconds for one epoch ---
--- 0.4906761646270752 seconds for one epoch ---
--- 0.33481550216674805 seconds for one epoch ---
--- 0.4925401210784912 seconds for one epoch ---
--- 0.3408472537994385 seconds for one epoch ---
--- 0.49177098274230957 seconds for one epoch ---
--- 0.35672664642333984 seconds for one epoch ---
--- 0.4878511428833008 seconds for one epoch ---
--- 0.35544347763061523 seconds for one epoch ---
--- 0.5033748149871826 seconds for one epoch ---
--- 0.35248351097106934 seconds for one epoch ---
--- 0.5014932155609131 seconds for one epoch ---
--- 0.35048437118530273 seconds for one epoch ---
--- 0.5118615627288818 seconds for one epoch ---
--- 0.3417022228240967 seconds for one epoch ---
--- 0.5252985954284668 seconds for one epoch ---
=========================
[[0.08816846]
 [0.06297211]
 [0.08720842]
 [0.05885611]
 [0.05652452]
 [0.15683825]
 [0.05950207]
 [0.06123622]
 [0.05635699]
 [0.13239655]
 [0.07232251]]
[[-1.6155475 ]
 [-0.42110023]
 [ 1.5773653 ]
 [ 0.16932432]
 [ 0.01533697]
 [-3.7086363 ]
 [ 0.21043843]
 [ 0.31776628]
 [ 0.00390668]
 [-3.062343  ]
 [ 0.92050815]]
--- 0.4369206428527832 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3379.53564453125, (1600.3333, 0.40132537, 1607.9146, 2.5320108)
   validation loss 1412.66748046875, (908.0763, 0.03702952, 333.66772, 2.5320108)
decoder loss ratio: 35180.452117, decoder SINDy loss  ratio: 0.720269
--- 0.27715229988098145 seconds for one epoch ---
--- 0.34340858459472656 seconds for one epoch ---
--- 0.5082576274871826 seconds for one epoch ---
--- 0.32683396339416504 seconds for one epoch ---
--- 0.4831578731536865 seconds for one epoch ---
--- 0.3062915802001953 seconds for one epoch ---
--- 0.5032477378845215 seconds for one epoch ---
--- 0.3072843551635742 seconds for one epoch ---
--- 0.5084247589111328 seconds for one epoch ---
--- 0.3221118450164795 seconds for one epoch ---
--- 0.483121395111084 seconds for one epoch ---
--- 0.3054797649383545 seconds for one epoch ---
--- 0.50264573097229 seconds for one epoch ---
--- 0.3157389163970947 seconds for one epoch ---
--- 0.5129528045654297 seconds for one epoch ---
--- 0.3003041744232178 seconds for one epoch ---
--- 0.5103738307952881 seconds for one epoch ---
--- 0.31132078170776367 seconds for one epoch ---
--- 0.5115127563476562 seconds for one epoch ---
--- 0.3162379264831543 seconds for one epoch ---
--- 0.49680233001708984 seconds for one epoch ---
--- 0.311354398727417 seconds for one epoch ---
--- 0.512749195098877 seconds for one epoch ---
--- 0.3157045841217041 seconds for one epoch ---
=========================
[[0.0849295 ]
 [0.05902308]
 [0.0845084 ]
 [0.0542906 ]
 [0.05160271]
 [0.14893852]
 [0.05411357]
 [0.05636244]
 [0.05149094]
 [0.13193749]
 [0.06873409]]
[[-1.6720586e+00]
 [-4.7104052e-01]
 [ 1.6557148e+00]
 [ 1.8661605e-01]
 [ 1.0422939e-02]
 [-3.6188879e+00]
 [ 1.7537293e-01]
 [ 3.1483287e-01]
 [ 2.8311838e-03]
 [-3.1725757e+00]
 [ 9.7757375e-01]]
--- 0.29337525367736816 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2348.529052734375, (1181.8942, 1.3131732, 992.5107, 2.5320194)
   validation loss 1126.511474609375, (641.3225, 0.03195164, 312.34607, 2.5320194)
decoder loss ratio: 24845.947413, decoder SINDy loss  ratio: 0.674243
--- 0.33712291717529297 seconds for one epoch ---
--- 0.504380464553833 seconds for one epoch ---
--- 0.33875536918640137 seconds for one epoch ---
--- 0.5211219787597656 seconds for one epoch ---
--- 0.35036230087280273 seconds for one epoch ---
--- 0.5105938911437988 seconds for one epoch ---
--- 0.34473681449890137 seconds for one epoch ---
--- 0.5234756469726562 seconds for one epoch ---
--- 0.3457984924316406 seconds for one epoch ---
--- 0.5246901512145996 seconds for one epoch ---
--- 0.30373620986938477 seconds for one epoch ---
--- 0.4873087406158447 seconds for one epoch ---
--- 0.3013336658477783 seconds for one epoch ---
--- 0.5048089027404785 seconds for one epoch ---
--- 0.3165931701660156 seconds for one epoch ---
--- 0.5124969482421875 seconds for one epoch ---
--- 0.31394076347351074 seconds for one epoch ---
--- 0.5087358951568604 seconds for one epoch ---
--- 0.30905628204345703 seconds for one epoch ---
--- 0.5112404823303223 seconds for one epoch ---
--- 0.3010880947113037 seconds for one epoch ---
--- 0.49915075302124023 seconds for one epoch ---
--- 0.302440881729126 seconds for one epoch ---
--- 0.5171780586242676 seconds for one epoch ---
=========================
[[0.08266155]
 [0.05598379]
 [0.0828438 ]
 [0.05084763]
 [0.04809313]
 [0.14261095]
 [0.0505516 ]
 [0.05257229]
 [0.04789707]
 [0.13203397]
 [0.06586624]]
[[-1.7185191 ]
 [-0.5015598 ]
 [ 1.7254502 ]
 [ 0.19632834]
 [ 0.01700876]
 [-3.5404232 ]
 [ 0.1776324 ]
 [ 0.30270088]
 [-0.00376224]
 [-3.26417   ]
 [ 1.0095922 ]]
--- 0.3062419891357422 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4820.44140625, (3026.9993, 1.3463106, 1617.2861, 2.5320253)
   validation loss 1342.08837890625, (772.95374, 0.044900186, 394.28046, 2.5320253)
decoder loss ratio: 29945.569614, decoder SINDy loss  ratio: 0.851110
--- 0.2815096378326416 seconds for one epoch ---
--- 0.3066117763519287 seconds for one epoch ---
--- 0.5335257053375244 seconds for one epoch ---
--- 0.30515408515930176 seconds for one epoch ---
--- 0.5326972007751465 seconds for one epoch ---
--- 0.33503079414367676 seconds for one epoch ---
--- 0.5351119041442871 seconds for one epoch ---
--- 0.31967926025390625 seconds for one epoch ---
--- 0.5318868160247803 seconds for one epoch ---
--- 0.31050848960876465 seconds for one epoch ---
--- 0.5526642799377441 seconds for one epoch ---
--- 0.3107948303222656 seconds for one epoch ---
--- 0.5323195457458496 seconds for one epoch ---
--- 0.3250575065612793 seconds for one epoch ---
--- 0.513951301574707 seconds for one epoch ---
--- 0.3180043697357178 seconds for one epoch ---
--- 0.5023283958435059 seconds for one epoch ---
--- 0.3093750476837158 seconds for one epoch ---
--- 0.4996917247772217 seconds for one epoch ---
--- 0.31371116638183594 seconds for one epoch ---
--- 0.4956817626953125 seconds for one epoch ---
--- 0.31870055198669434 seconds for one epoch ---
--- 0.5397214889526367 seconds for one epoch ---
--- 0.35216808319091797 seconds for one epoch ---
=========================
[[0.08070613]
 [0.05342355]
 [0.08138996]
 [0.04748985]
 [0.044775  ]
 [0.13620432]
 [0.04744783]
 [0.049452  ]
 [0.04470466]
 [0.13265884]
 [0.06281554]]
[[-1.7595781e+00]
 [-5.3343803e-01]
 [ 1.7851384e+00]
 [ 1.8322167e-01]
 [ 6.2662582e-03]
 [-3.4490931e+00]
 [ 1.8057223e-01]
 [ 3.0410603e-01]
 [-1.5128722e-03]
 [-3.3568189e+00]
 [ 1.0118896e+00]]
--- 0.26766324043273926 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5843.4501953125, (2652.7092, 2.7145317, 3011.1692, 2.53203)
   validation loss 1125.531005859375, (634.28674, 0.03273038, 314.35422, 2.53203)
decoder loss ratio: 24573.369600, decoder SINDy loss  ratio: 0.678578
--- 0.34221339225769043 seconds for one epoch ---
--- 0.5391616821289062 seconds for one epoch ---
--- 0.34728407859802246 seconds for one epoch ---
--- 0.5261154174804688 seconds for one epoch ---
--- 0.35828161239624023 seconds for one epoch ---
--- 0.513810396194458 seconds for one epoch ---
--- 0.3359560966491699 seconds for one epoch ---
--- 0.5344178676605225 seconds for one epoch ---
--- 0.33092665672302246 seconds for one epoch ---
--- 0.5204300880432129 seconds for one epoch ---
--- 0.3331634998321533 seconds for one epoch ---
--- 0.5320000648498535 seconds for one epoch ---
--- 0.34623074531555176 seconds for one epoch ---
--- 0.530642032623291 seconds for one epoch ---
--- 0.3476121425628662 seconds for one epoch ---
--- 0.5283219814300537 seconds for one epoch ---
--- 0.3388950824737549 seconds for one epoch ---
--- 0.5303184986114502 seconds for one epoch ---
--- 0.30783939361572266 seconds for one epoch ---
--- 0.5165250301361084 seconds for one epoch ---
--- 0.3082413673400879 seconds for one epoch ---
--- 0.5345885753631592 seconds for one epoch ---
--- 0.31420016288757324 seconds for one epoch ---
--- 0.5400104522705078 seconds for one epoch ---
=========================
[[0.07956424]
 [0.05149703]
 [0.08050998]
 [0.04515921]
 [0.04254552]
 [0.13102038]
 [0.04508283]
 [0.0470072 ]
 [0.04232609]
 [0.1339385 ]
 [0.06116245]]
[[-1.8016446e+00]
 [-5.5621272e-01]
 [ 1.8364508e+00]
 [ 1.8474025e-01]
 [ 1.5136359e-02]
 [-3.3700321e+00]
 [ 1.7993730e-01]
 [ 2.9840052e-01]
 [ 3.7775707e-04]
 [-3.4457319e+00]
 [ 1.0428873e+00]]
--- 0.29653167724609375 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4071.183349609375, (1880.3268, 0.71896863, 2011.2341, 2.5320356)
   validation loss 1435.7286376953125, (943.77155, 0.035654847, 313.0177, 2.5320356)
decoder loss ratio: 36563.348129, decoder SINDy loss  ratio: 0.675693
THRESHOLDING: 2 active coefficients
--- 0.5403223037719727 seconds for one epoch ---
--- 0.32517480850219727 seconds for one epoch ---
--- 0.525219202041626 seconds for one epoch ---
--- 0.3333733081817627 seconds for one epoch ---
--- 0.5609586238861084 seconds for one epoch ---
--- 0.3283195495605469 seconds for one epoch ---
--- 0.5420088768005371 seconds for one epoch ---
--- 0.3358187675476074 seconds for one epoch ---
--- 0.556373119354248 seconds for one epoch ---
--- 0.33690977096557617 seconds for one epoch ---
--- 0.5478270053863525 seconds for one epoch ---
--- 0.35870790481567383 seconds for one epoch ---
--- 0.547705888748169 seconds for one epoch ---
--- 0.33991336822509766 seconds for one epoch ---
--- 0.5717067718505859 seconds for one epoch ---
--- 0.31191253662109375 seconds for one epoch ---
--- 0.5282003879547119 seconds for one epoch ---
--- 0.3032686710357666 seconds for one epoch ---
--- 0.5339677333831787 seconds for one epoch ---
--- 0.31548595428466797 seconds for one epoch ---
--- 0.5531637668609619 seconds for one epoch ---
--- 0.30910181999206543 seconds for one epoch ---
--- 0.548203706741333 seconds for one epoch ---
--- 0.32049989700317383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.093325  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11734758]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.3427196]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.0544682]
 [ 0.       ]]
--- 0.2796034812927246 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3778.739013671875, (2142.29, 0.3034652, 1635.9443, 0.20123072)
   validation loss 1773.97998046875, (1371.9938, 0.089541756, 401.6955, 0.20123072)
decoder loss ratio: 53153.420707, decoder SINDy loss  ratio: 0.867116
--- 0.29758548736572266 seconds for one epoch ---
--- 0.5362305641174316 seconds for one epoch ---
--- 0.3239407539367676 seconds for one epoch ---
--- 0.544090986251831 seconds for one epoch ---
--- 0.3182520866394043 seconds for one epoch ---
--- 0.5524835586547852 seconds for one epoch ---
--- 0.31777143478393555 seconds for one epoch ---
--- 0.5356354713439941 seconds for one epoch ---
--- 0.32534360885620117 seconds for one epoch ---
--- 0.5628073215484619 seconds for one epoch ---
--- 0.3329923152923584 seconds for one epoch ---
--- 0.5415999889373779 seconds for one epoch ---
--- 0.3088057041168213 seconds for one epoch ---
--- 0.5297262668609619 seconds for one epoch ---
--- 0.30870485305786133 seconds for one epoch ---
--- 0.5346953868865967 seconds for one epoch ---
--- 0.3129160404205322 seconds for one epoch ---
--- 0.5682315826416016 seconds for one epoch ---
--- 0.31354713439941406 seconds for one epoch ---
--- 0.5711398124694824 seconds for one epoch ---
--- 0.32016754150390625 seconds for one epoch ---
--- 0.565770149230957 seconds for one epoch ---
--- 0.33675265312194824 seconds for one epoch ---
--- 0.5704429149627686 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07662618]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10921212]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.8222289]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8667657]
 [ 0.       ]]
--- 0.30011630058288574 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2181.881591796875, (1064.3204, 0.27195972, 1117.0978, 0.191447)
   validation loss 1027.745361328125, (722.62976, 0.06250345, 304.8617, 0.191447)
decoder loss ratio: 27995.931472, decoder SINDy loss  ratio: 0.658087
--- 0.2844974994659424 seconds for one epoch ---
--- 0.3147575855255127 seconds for one epoch ---
--- 0.5692875385284424 seconds for one epoch ---
--- 0.31618356704711914 seconds for one epoch ---
--- 0.5733482837677002 seconds for one epoch ---
--- 0.31691813468933105 seconds for one epoch ---
--- 0.5728092193603516 seconds for one epoch ---
--- 0.32045912742614746 seconds for one epoch ---
--- 0.5739133358001709 seconds for one epoch ---
--- 0.33035898208618164 seconds for one epoch ---
--- 0.5742623805999756 seconds for one epoch ---
--- 0.33699631690979004 seconds for one epoch ---
--- 0.5780642032623291 seconds for one epoch ---
--- 0.30995726585388184 seconds for one epoch ---
--- 0.5658431053161621 seconds for one epoch ---
--- 0.30684590339660645 seconds for one epoch ---
--- 0.5722239017486572 seconds for one epoch ---
--- 0.29725122451782227 seconds for one epoch ---
--- 0.581104040145874 seconds for one epoch ---
--- 0.32293701171875 seconds for one epoch ---
--- 0.599320650100708 seconds for one epoch ---
--- 0.32625436782836914 seconds for one epoch ---
--- 0.5792844295501709 seconds for one epoch ---
--- 0.31948399543762207 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06663962]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10515852]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.4903738]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.7870457]
 [ 0.       ]]
--- 0.2753891944885254 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2739.03662109375, (1775.2035, 0.425322, 963.2218, 0.18607357)
   validation loss 2011.481201171875, (1714.7607, 0.08438606, 296.45013, 0.18607357)
decoder loss ratio: 66432.808108, decoder SINDy loss  ratio: 0.639929
--- 0.3324141502380371 seconds for one epoch ---
--- 0.5652360916137695 seconds for one epoch ---
--- 0.30898594856262207 seconds for one epoch ---
--- 0.5793600082397461 seconds for one epoch ---
--- 0.318509578704834 seconds for one epoch ---
--- 0.5557093620300293 seconds for one epoch ---
--- 0.32763004302978516 seconds for one epoch ---
--- 0.5507283210754395 seconds for one epoch ---
--- 0.3085296154022217 seconds for one epoch ---
--- 0.570629358291626 seconds for one epoch ---
--- 0.3173789978027344 seconds for one epoch ---
--- 0.5554051399230957 seconds for one epoch ---
--- 0.31537771224975586 seconds for one epoch ---
--- 0.5638694763183594 seconds for one epoch ---
--- 0.3226749897003174 seconds for one epoch ---
--- 0.5653495788574219 seconds for one epoch ---
--- 0.3063466548919678 seconds for one epoch ---
--- 0.579735517501831 seconds for one epoch ---
--- 0.30483508110046387 seconds for one epoch ---
--- 0.5482275485992432 seconds for one epoch ---
--- 0.30462098121643066 seconds for one epoch ---
--- 0.5858407020568848 seconds for one epoch ---
--- 0.3033177852630615 seconds for one epoch ---
--- 0.5803542137145996 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06271415]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10488576]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3711741]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8071504]
 [ 0.       ]]
--- 0.3222062587738037 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5633.51904296875, (2743.9514, 1.0544338, 2888.3284, 0.18496172)
   validation loss 4328.2900390625, (3945.286, 0.08799359, 382.73135, 0.18496172)
decoder loss ratio: 152847.224645, decoder SINDy loss  ratio: 0.826179
--- 0.2778661251068115 seconds for one epoch ---
--- 0.3450789451599121 seconds for one epoch ---
--- 0.5768427848815918 seconds for one epoch ---
--- 0.3463146686553955 seconds for one epoch ---
--- 0.5710656642913818 seconds for one epoch ---
--- 0.33459997177124023 seconds for one epoch ---
--- 0.6004712581634521 seconds for one epoch ---
--- 0.3410212993621826 seconds for one epoch ---
--- 0.5823080539703369 seconds for one epoch ---
--- 0.34024882316589355 seconds for one epoch ---
--- 0.5754795074462891 seconds for one epoch ---
--- 0.33544492721557617 seconds for one epoch ---
--- 0.5929737091064453 seconds for one epoch ---
--- 0.32755279541015625 seconds for one epoch ---
--- 0.5785868167877197 seconds for one epoch ---
--- 0.3218045234680176 seconds for one epoch ---
--- 0.5745241641998291 seconds for one epoch ---
--- 0.3161897659301758 seconds for one epoch ---
--- 0.5656614303588867 seconds for one epoch ---
--- 0.30602025985717773 seconds for one epoch ---
--- 0.5686490535736084 seconds for one epoch ---
--- 0.3156912326812744 seconds for one epoch ---
--- 0.5865902900695801 seconds for one epoch ---
--- 0.3299541473388672 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06026527]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10413653]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.3061333]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.810343 ]
 [ 0.       ]]
--- 0.2869076728820801 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4203.02001953125, (2261.969, 1.2428185, 1939.624, 0.18405755)
   validation loss 1146.859130859375, (842.03455, 0.084754385, 304.55576, 0.18405755)
decoder loss ratio: 32621.880144, decoder SINDy loss  ratio: 0.657426
--- 0.31108784675598145 seconds for one epoch ---
--- 0.5915176868438721 seconds for one epoch ---
--- 0.438251256942749 seconds for one epoch ---
--- 0.6228244304656982 seconds for one epoch ---
--- 0.31873250007629395 seconds for one epoch ---
--- 0.6225333213806152 seconds for one epoch ---
--- 0.3045365810394287 seconds for one epoch ---
--- 0.6039376258850098 seconds for one epoch ---
--- 0.3138761520385742 seconds for one epoch ---
--- 0.6014022827148438 seconds for one epoch ---
--- 0.31302595138549805 seconds for one epoch ---
--- 0.6151518821716309 seconds for one epoch ---
--- 0.307783842086792 seconds for one epoch ---
--- 0.6146037578582764 seconds for one epoch ---
--- 0.30702924728393555 seconds for one epoch ---
--- 0.6202452182769775 seconds for one epoch ---
--- 0.31261301040649414 seconds for one epoch ---
--- 0.6050353050231934 seconds for one epoch ---
--- 0.30359530448913574 seconds for one epoch ---
--- 0.6045219898223877 seconds for one epoch ---
--- 0.3065052032470703 seconds for one epoch ---
--- 0.6120045185089111 seconds for one epoch ---
--- 0.30358457565307617 seconds for one epoch ---
--- 0.6095592975616455 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05918154]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10653865]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2891469]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.8973973]
 [ 0.       ]]
--- 0.33414268493652344 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2588.520751953125, (1602.8486, 0.3874204, 985.0994, 0.1853643)
   validation loss 2052.827880859375, (1734.1663, 0.09790403, 318.3783, 0.1853643)
decoder loss ratio: 67184.611548, decoder SINDy loss  ratio: 0.687264
--- 0.2703132629394531 seconds for one epoch ---
--- 0.33751463890075684 seconds for one epoch ---
--- 0.6071128845214844 seconds for one epoch ---
--- 0.35091137886047363 seconds for one epoch ---
--- 0.5851559638977051 seconds for one epoch ---
--- 0.3422694206237793 seconds for one epoch ---
--- 0.597283124923706 seconds for one epoch ---
--- 0.3432598114013672 seconds for one epoch ---
--- 0.5938141345977783 seconds for one epoch ---
--- 0.33635449409484863 seconds for one epoch ---
--- 0.5871188640594482 seconds for one epoch ---
--- 0.32877063751220703 seconds for one epoch ---
--- 0.5934700965881348 seconds for one epoch ---
--- 0.31893110275268555 seconds for one epoch ---
--- 0.6125555038452148 seconds for one epoch ---
--- 0.3364439010620117 seconds for one epoch ---
--- 0.6039450168609619 seconds for one epoch ---
--- 0.31215429306030273 seconds for one epoch ---
--- 0.603264331817627 seconds for one epoch ---
--- 0.30738306045532227 seconds for one epoch ---
--- 0.6078155040740967 seconds for one epoch ---
--- 0.3071887493133545 seconds for one epoch ---
--- 0.6096062660217285 seconds for one epoch ---
--- 0.30433154106140137 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05747233]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.10892705]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2420216]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-2.9805148]
 [ 0.       ]]
--- 0.27743005752563477 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4344.99267578125, (2078.3162, 0.70390755, 2265.7866, 0.1858977)
   validation loss 1727.1954345703125, (1421.0853, 0.11063869, 305.81366, 0.1858977)
decoder loss ratio: 55055.312686, decoder SINDy loss  ratio: 0.660142
--- 0.33582210540771484 seconds for one epoch ---
--- 0.6170265674591064 seconds for one epoch ---
--- 0.3328437805175781 seconds for one epoch ---
--- 0.6263153553009033 seconds for one epoch ---
--- 0.3364837169647217 seconds for one epoch ---
--- 0.6380834579467773 seconds for one epoch ---
--- 0.3428962230682373 seconds for one epoch ---
--- 0.6334576606750488 seconds for one epoch ---
--- 0.3490724563598633 seconds for one epoch ---
--- 0.6338298320770264 seconds for one epoch ---
--- 0.34515976905822754 seconds for one epoch ---
--- 0.6341965198516846 seconds for one epoch ---
--- 0.3381369113922119 seconds for one epoch ---
--- 0.62839674949646 seconds for one epoch ---
--- 0.3398895263671875 seconds for one epoch ---
--- 0.6249234676361084 seconds for one epoch ---
--- 0.3357858657836914 seconds for one epoch ---
--- 0.6677241325378418 seconds for one epoch ---
--- 0.3467130661010742 seconds for one epoch ---
--- 0.6073827743530273 seconds for one epoch ---
--- 0.3030533790588379 seconds for one epoch ---
--- 0.6314048767089844 seconds for one epoch ---
--- 0.3042144775390625 seconds for one epoch ---
--- 0.6214737892150879 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05747173]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11284567]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.262066 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.1001353]
 [ 0.       ]]
--- 0.30846691131591797 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5005.65185546875, (1971.6835, 3.765556, 3030.0146, 0.18811078)
   validation loss 1235.391357421875, (949.73267, 0.11613375, 285.35446, 0.18811078)
decoder loss ratio: 36794.292290, decoder SINDy loss  ratio: 0.615978
--- 0.2768871784210205 seconds for one epoch ---
--- 0.30707550048828125 seconds for one epoch ---
--- 0.630225419998169 seconds for one epoch ---
--- 0.3210172653198242 seconds for one epoch ---
--- 0.6152915954589844 seconds for one epoch ---
--- 0.3192880153656006 seconds for one epoch ---
--- 0.6372387409210205 seconds for one epoch ---
--- 0.31350231170654297 seconds for one epoch ---
--- 0.6223340034484863 seconds for one epoch ---
--- 0.30010533332824707 seconds for one epoch ---
--- 0.622889518737793 seconds for one epoch ---
--- 0.3136773109436035 seconds for one epoch ---
--- 0.6426832675933838 seconds for one epoch ---
--- 0.3118143081665039 seconds for one epoch ---
--- 0.6396186351776123 seconds for one epoch ---
--- 0.30820345878601074 seconds for one epoch ---
--- 0.627253532409668 seconds for one epoch ---
--- 0.3108189105987549 seconds for one epoch ---
--- 0.6712896823883057 seconds for one epoch ---
--- 0.31191372871398926 seconds for one epoch ---
--- 0.6350269317626953 seconds for one epoch ---
--- 0.306793212890625 seconds for one epoch ---
--- 0.6419730186462402 seconds for one epoch ---
--- 0.30760717391967773 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05747074]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11616894]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2798969]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2      ]
 [ 0.       ]]
--- 0.27469325065612793 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3149.363525390625, (1848.6459, 0.14079478, 1300.3873, 0.18959638)
   validation loss 856.898193359375, (579.3412, 0.085345484, 277.28214, 0.18959638)
decoder loss ratio: 22444.683346, decoder SINDy loss  ratio: 0.598552
--- 0.34334683418273926 seconds for one epoch ---
--- 0.6252377033233643 seconds for one epoch ---
--- 0.34734582901000977 seconds for one epoch ---
--- 0.656702995300293 seconds for one epoch ---
--- 0.33695435523986816 seconds for one epoch ---
--- 0.656165599822998 seconds for one epoch ---
--- 0.34567809104919434 seconds for one epoch ---
--- 0.6585566997528076 seconds for one epoch ---
--- 0.35654234886169434 seconds for one epoch ---
--- 0.6682274341583252 seconds for one epoch ---
--- 0.3428823947906494 seconds for one epoch ---
--- 0.6526222229003906 seconds for one epoch ---
--- 0.3490302562713623 seconds for one epoch ---
--- 0.6407601833343506 seconds for one epoch ---
--- 0.35606932640075684 seconds for one epoch ---
--- 0.6414763927459717 seconds for one epoch ---
--- 0.34647679328918457 seconds for one epoch ---
--- 0.6242907047271729 seconds for one epoch ---
--- 0.3292734622955322 seconds for one epoch ---
--- 0.6620702743530273 seconds for one epoch ---
--- 0.33052849769592285 seconds for one epoch ---
--- 0.6290111541748047 seconds for one epoch ---
--- 0.31195664405822754 seconds for one epoch ---
--- 0.6467185020446777 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05613081]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11952358]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.236059 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.2964442]
 [ 0.       ]]
--- 0.29850316047668457 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3908.885009765625, (1700.6245, 0.750497, 2207.319, 0.19095209)
   validation loss 1140.8446044921875, (801.9438, 0.18283017, 338.52713, 0.19095209)
decoder loss ratio: 31068.694529, decoder SINDy loss  ratio: 0.730758
--- 0.2916069030761719 seconds for one epoch ---
--- 0.31137704849243164 seconds for one epoch ---
--- 0.6376044750213623 seconds for one epoch ---
--- 0.3161485195159912 seconds for one epoch ---
--- 0.6525275707244873 seconds for one epoch ---
--- 0.29610562324523926 seconds for one epoch ---
--- 0.6469724178314209 seconds for one epoch ---
--- 0.31362152099609375 seconds for one epoch ---
--- 0.6612250804901123 seconds for one epoch ---
--- 0.32025718688964844 seconds for one epoch ---
--- 0.6454379558563232 seconds for one epoch ---
--- 0.3169057369232178 seconds for one epoch ---
--- 0.666109561920166 seconds for one epoch ---
--- 0.310192346572876 seconds for one epoch ---
--- 0.6717531681060791 seconds for one epoch ---
--- 0.32537102699279785 seconds for one epoch ---
--- 0.6663355827331543 seconds for one epoch ---
--- 0.32915759086608887 seconds for one epoch ---
--- 0.6839001178741455 seconds for one epoch ---
--- 0.32246994972229004 seconds for one epoch ---
--- 0.6799600124359131 seconds for one epoch ---
--- 0.321835994720459 seconds for one epoch ---
--- 0.6659934520721436 seconds for one epoch ---
--- 0.306124210357666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05578576]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12347237]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.233592 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4057636]
 [ 0.       ]]
--- 0.26761484146118164 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5269.32568359375, (1904.4011, 0.8265236, 3363.9058, 0.19229247)
   validation loss 1376.5751953125, (1038.927, 0.09761585, 337.35828, 0.19229247)
decoder loss ratio: 40249.835712, decoder SINDy loss  ratio: 0.728235
--- 0.32849955558776855 seconds for one epoch ---
--- 0.6540038585662842 seconds for one epoch ---
--- 0.32867980003356934 seconds for one epoch ---
--- 0.6714792251586914 seconds for one epoch ---
--- 0.34108924865722656 seconds for one epoch ---
--- 0.6614956855773926 seconds for one epoch ---
--- 0.34527111053466797 seconds for one epoch ---
--- 0.6609799861907959 seconds for one epoch ---
--- 0.34168028831481934 seconds for one epoch ---
--- 0.6554076671600342 seconds for one epoch ---
--- 0.325758695602417 seconds for one epoch ---
--- 0.6596107482910156 seconds for one epoch ---
--- 0.32570672035217285 seconds for one epoch ---
--- 0.6720497608184814 seconds for one epoch ---
--- 0.3307468891143799 seconds for one epoch ---
--- 0.6639134883880615 seconds for one epoch ---
--- 0.32815122604370117 seconds for one epoch ---
--- 0.6790485382080078 seconds for one epoch ---
--- 0.33339357376098633 seconds for one epoch ---
--- 0.6483211517333984 seconds for one epoch ---
--- 0.327303409576416 seconds for one epoch ---
--- 0.6630380153656006 seconds for one epoch ---
--- 0.32210564613342285 seconds for one epoch ---
--- 0.6672039031982422 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05590687]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1269415 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2483726]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4994075]
 [ 0.       ]]
--- 0.30532002449035645 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4563.080078125, (2321.4905, 0.42578086, 2240.97, 0.19392952)
   validation loss 1289.930908203125, (982.80414, 0.21628952, 306.71652, 0.19392952)
decoder loss ratio: 38075.538536, decoder SINDy loss  ratio: 0.662091
--- 0.30033326148986816 seconds for one epoch ---
--- 0.30142831802368164 seconds for one epoch ---
--- 0.6864063739776611 seconds for one epoch ---
--- 0.3064596652984619 seconds for one epoch ---
--- 0.6839718818664551 seconds for one epoch ---
--- 0.3031785488128662 seconds for one epoch ---
--- 0.6771907806396484 seconds for one epoch ---
--- 0.30629873275756836 seconds for one epoch ---
--- 0.6727240085601807 seconds for one epoch ---
--- 0.31150174140930176 seconds for one epoch ---
--- 0.6941244602203369 seconds for one epoch ---
--- 0.30519866943359375 seconds for one epoch ---
--- 0.6990888118743896 seconds for one epoch ---
--- 0.31606507301330566 seconds for one epoch ---
--- 0.6848440170288086 seconds for one epoch ---
--- 0.3035109043121338 seconds for one epoch ---
--- 0.6911118030548096 seconds for one epoch ---
--- 0.3108062744140625 seconds for one epoch ---
--- 0.7001123428344727 seconds for one epoch ---
--- 0.33298349380493164 seconds for one epoch ---
--- 0.694361686706543 seconds for one epoch ---
--- 0.32302331924438477 seconds for one epoch ---
--- 0.7049379348754883 seconds for one epoch ---
--- 0.30660104751586914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0558935 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13109039]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2564036]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.60808  ]
 [ 0.       ]]
--- 0.2647075653076172 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3764.65283203125, (1645.5002, 0.88252616, 2118.0742, 0.19572866)
   validation loss 1119.6036376953125, (797.58514, 0.18092574, 321.64197, 0.19572866)
decoder loss ratio: 30899.833149, decoder SINDy loss  ratio: 0.694309
--- 0.32541704177856445 seconds for one epoch ---
--- 0.6833498477935791 seconds for one epoch ---
--- 0.3478202819824219 seconds for one epoch ---
--- 0.6889224052429199 seconds for one epoch ---
--- 0.34507322311401367 seconds for one epoch ---
--- 0.6848227977752686 seconds for one epoch ---
--- 0.3489723205566406 seconds for one epoch ---
--- 0.6746759414672852 seconds for one epoch ---
--- 0.3544762134552002 seconds for one epoch ---
--- 0.6868019104003906 seconds for one epoch ---
--- 0.3417167663574219 seconds for one epoch ---
--- 0.6962835788726807 seconds for one epoch ---
--- 0.3472561836242676 seconds for one epoch ---
--- 0.6880218982696533 seconds for one epoch ---
--- 0.33886122703552246 seconds for one epoch ---
--- 0.6868233680725098 seconds for one epoch ---
--- 0.34008073806762695 seconds for one epoch ---
--- 0.705622673034668 seconds for one epoch ---
--- 0.33912158012390137 seconds for one epoch ---
--- 0.7258734703063965 seconds for one epoch ---
--- 0.33959436416625977 seconds for one epoch ---
--- 0.6929829120635986 seconds for one epoch ---
--- 0.3458671569824219 seconds for one epoch ---
--- 0.7047679424285889 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05453163]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13322085]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2041332]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.6643457]
 [ 0.       ]]
--- 0.3008310794830322 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2788.671142578125, (1208.7717, 0.8726572, 1578.8308, 0.19601381)
   validation loss 1841.388671875, (1341.8583, 0.22694628, 499.10745, 0.19601381)
decoder loss ratio: 51985.919195, decoder SINDy loss  ratio: 1.077394
--- 0.27459192276000977 seconds for one epoch ---
--- 0.30240678787231445 seconds for one epoch ---
--- 0.705010175704956 seconds for one epoch ---
--- 0.3020038604736328 seconds for one epoch ---
--- 0.7049357891082764 seconds for one epoch ---
--- 0.3053765296936035 seconds for one epoch ---
--- 0.7206001281738281 seconds for one epoch ---
--- 0.3044393062591553 seconds for one epoch ---
--- 0.6952457427978516 seconds for one epoch ---
--- 0.30774831771850586 seconds for one epoch ---
--- 0.7106797695159912 seconds for one epoch ---
--- 0.3092825412750244 seconds for one epoch ---
--- 0.7143955230712891 seconds for one epoch ---
--- 0.31077051162719727 seconds for one epoch ---
--- 0.7076995372772217 seconds for one epoch ---
--- 0.3144838809967041 seconds for one epoch ---
--- 0.6912877559661865 seconds for one epoch ---
--- 0.3227269649505615 seconds for one epoch ---
--- 0.7189760208129883 seconds for one epoch ---
--- 0.3248448371887207 seconds for one epoch ---
--- 0.7188630104064941 seconds for one epoch ---
--- 0.3272435665130615 seconds for one epoch ---
--- 0.7165448665618896 seconds for one epoch ---
--- 0.33443379402160645 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05440167]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13686931]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2045898]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.75684  ]
 [ 0.       ]]
--- 0.2689857482910156 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4563.83203125, (2671.6213, 1.7471973, 1890.2659, 0.19721277)
   validation loss 840.4337768554688, (562.14923, 0.16608103, 277.92123, 0.19721277)
decoder loss ratio: 21778.637141, decoder SINDy loss  ratio: 0.599932
--- 0.2997472286224365 seconds for one epoch ---
--- 0.6846699714660645 seconds for one epoch ---
--- 0.30842137336730957 seconds for one epoch ---
--- 0.696164608001709 seconds for one epoch ---
--- 0.3285636901855469 seconds for one epoch ---
--- 0.704242467880249 seconds for one epoch ---
--- 0.32094359397888184 seconds for one epoch ---
--- 0.7041425704956055 seconds for one epoch ---
--- 0.3222789764404297 seconds for one epoch ---
--- 0.7042660713195801 seconds for one epoch ---
--- 0.31000399589538574 seconds for one epoch ---
--- 0.7081146240234375 seconds for one epoch ---
--- 0.31465673446655273 seconds for one epoch ---
--- 0.720055103302002 seconds for one epoch ---
--- 0.3436264991760254 seconds for one epoch ---
--- 0.7046942710876465 seconds for one epoch ---
--- 0.30965733528137207 seconds for one epoch ---
--- 0.7253990173339844 seconds for one epoch ---
--- 0.3131110668182373 seconds for one epoch ---
--- 0.7249526977539062 seconds for one epoch ---
--- 0.31070876121520996 seconds for one epoch ---
--- 0.7119357585906982 seconds for one epoch ---
--- 0.3059689998626709 seconds for one epoch ---
--- 0.7143998146057129 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05405059]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.13927987]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1940016]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.8176384]
 [ 0.       ]]
--- 0.3042483329772949 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3492.754150390625, (1825.9661, 0.61414206, 1665.976, 0.19789015)
   validation loss 3613.90966796875, (3083.4417, 0.16230586, 530.1076, 0.19789015)
decoder loss ratio: 119457.882626, decoder SINDy loss  ratio: 1.144312
--- 0.2778000831604004 seconds for one epoch ---
--- 0.3144721984863281 seconds for one epoch ---
--- 0.7013177871704102 seconds for one epoch ---
--- 0.314652681350708 seconds for one epoch ---
--- 0.7154853343963623 seconds for one epoch ---
--- 0.30247044563293457 seconds for one epoch ---
--- 0.7133047580718994 seconds for one epoch ---
--- 0.3017086982727051 seconds for one epoch ---
--- 0.7098250389099121 seconds for one epoch ---
--- 0.3026764392852783 seconds for one epoch ---
--- 0.7352497577667236 seconds for one epoch ---
--- 0.3079836368560791 seconds for one epoch ---
--- 0.7278172969818115 seconds for one epoch ---
--- 0.4493706226348877 seconds for one epoch ---
--- 0.7009701728820801 seconds for one epoch ---
--- 0.30739545822143555 seconds for one epoch ---
--- 0.7191827297210693 seconds for one epoch ---
--- 0.30428075790405273 seconds for one epoch ---
--- 0.7010838985443115 seconds for one epoch ---
--- 0.3014838695526123 seconds for one epoch ---
--- 0.7032508850097656 seconds for one epoch ---
--- 0.2996199131011963 seconds for one epoch ---
--- 0.7289793491363525 seconds for one epoch ---
--- 0.3031182289123535 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05375195]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14270176]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.185263 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.9018736]
 [ 0.       ]]
--- 0.2663381099700928 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5306.2490234375, (1970.671, 1.306087, 3334.0728, 0.19898403)
   validation loss 992.176025390625, (675.6257, 0.16660884, 316.18478, 0.19898403)
decoder loss ratio: 26174.911447, decoder SINDy loss  ratio: 0.682529
--- 0.3072206974029541 seconds for one epoch ---
--- 0.7221682071685791 seconds for one epoch ---
--- 0.30345726013183594 seconds for one epoch ---
--- 0.7235603332519531 seconds for one epoch ---
--- 0.32462573051452637 seconds for one epoch ---
--- 0.7545926570892334 seconds for one epoch ---
--- 0.31052207946777344 seconds for one epoch ---
--- 0.7403209209442139 seconds for one epoch ---
--- 0.30329394340515137 seconds for one epoch ---
--- 0.7262675762176514 seconds for one epoch ---
--- 0.3150773048400879 seconds for one epoch ---
--- 0.7174835205078125 seconds for one epoch ---
--- 0.2950866222381592 seconds for one epoch ---
--- 0.7454280853271484 seconds for one epoch ---
--- 0.33157777786254883 seconds for one epoch ---
--- 0.7598879337310791 seconds for one epoch ---
--- 0.3288266658782959 seconds for one epoch ---
--- 0.7584428787231445 seconds for one epoch ---
--- 0.32752037048339844 seconds for one epoch ---
--- 0.7349786758422852 seconds for one epoch ---
--- 0.34605836868286133 seconds for one epoch ---
--- 0.7349452972412109 seconds for one epoch ---
--- 0.3206751346588135 seconds for one epoch ---
--- 0.7769558429718018 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0542836]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1474073]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2118751]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.014946 ]
 [ 0.       ]]
--- 0.30338025093078613 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3775.98095703125, (1821.5946, 0.26982763, 1953.9159, 0.20058285)
   validation loss 1115.455322265625, (816.70404, 0.24044101, 298.31033, 0.20058285)
decoder loss ratio: 31640.532391, decoder SINDy loss  ratio: 0.643945
--- 0.2795982360839844 seconds for one epoch ---
--- 0.33413219451904297 seconds for one epoch ---
--- 0.7439558506011963 seconds for one epoch ---
--- 0.3245868682861328 seconds for one epoch ---
--- 0.7359614372253418 seconds for one epoch ---
--- 0.3112823963165283 seconds for one epoch ---
--- 0.7380168437957764 seconds for one epoch ---
--- 0.30850672721862793 seconds for one epoch ---
--- 0.748802900314331 seconds for one epoch ---
--- 0.30242347717285156 seconds for one epoch ---
--- 0.7424812316894531 seconds for one epoch ---
--- 0.29917407035827637 seconds for one epoch ---
--- 0.7245974540710449 seconds for one epoch ---
--- 0.312166690826416 seconds for one epoch ---
--- 0.7487082481384277 seconds for one epoch ---
--- 0.2999112606048584 seconds for one epoch ---
--- 0.7205626964569092 seconds for one epoch ---
--- 0.3002791404724121 seconds for one epoch ---
--- 0.7375149726867676 seconds for one epoch ---
--- 0.30321359634399414 seconds for one epoch ---
--- 0.7351524829864502 seconds for one epoch ---
--- 0.30840253829956055 seconds for one epoch ---
--- 0.7533204555511475 seconds for one epoch ---
--- 0.3017716407775879 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05373397]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1516639 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.1909642]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.1159086]
 [ 0.       ]]
--- 0.2604713439941406 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4630.2373046875, (2207.957, 0.613032, 2421.466, 0.20127352)
   validation loss 2034.006103515625, (1740.436, 0.22413823, 293.14462, 0.20127352)
decoder loss ratio: 67427.513532, decoder SINDy loss  ratio: 0.632794
--- 0.32390785217285156 seconds for one epoch ---
--- 0.7519466876983643 seconds for one epoch ---
--- 0.33852505683898926 seconds for one epoch ---
--- 0.7383279800415039 seconds for one epoch ---
--- 0.32907772064208984 seconds for one epoch ---
--- 0.7645103931427002 seconds for one epoch ---
--- 0.3283364772796631 seconds for one epoch ---
--- 0.7685732841491699 seconds for one epoch ---
--- 0.31963133811950684 seconds for one epoch ---
--- 0.7706005573272705 seconds for one epoch ---
--- 0.34304046630859375 seconds for one epoch ---
--- 0.74472975730896 seconds for one epoch ---
--- 0.32376956939697266 seconds for one epoch ---
--- 0.7562081813812256 seconds for one epoch ---
--- 0.32419848442077637 seconds for one epoch ---
--- 0.7694094181060791 seconds for one epoch ---
--- 0.3249051570892334 seconds for one epoch ---
--- 0.766756534576416 seconds for one epoch ---
--- 0.30358242988586426 seconds for one epoch ---
--- 0.7605676651000977 seconds for one epoch ---
--- 0.30135655403137207 seconds for one epoch ---
--- 0.7704892158508301 seconds for one epoch ---
--- 0.3069021701812744 seconds for one epoch ---
--- 0.7319583892822266 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05376094]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.15613557]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.194563 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.2203193]
 [ 0.       ]]
--- 0.2992217540740967 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5111.64013671875, (3106.7935, 2.417719, 2002.2268, 0.20191653)
   validation loss 1112.3154296875, (760.8956, 0.23345722, 350.98447, 0.20191653)
decoder loss ratio: 29478.417675, decoder SINDy loss  ratio: 0.757649
THRESHOLDING: 1 active coefficients
--- 0.7697210311889648 seconds for one epoch ---
--- 0.328519344329834 seconds for one epoch ---
--- 0.7778632640838623 seconds for one epoch ---
--- 0.32213521003723145 seconds for one epoch ---
--- 0.7576899528503418 seconds for one epoch ---
--- 0.33397769927978516 seconds for one epoch ---
--- 0.7773194313049316 seconds for one epoch ---
--- 0.32944560050964355 seconds for one epoch ---
--- 0.761150598526001 seconds for one epoch ---
--- 0.34757089614868164 seconds for one epoch ---
--- 0.7700762748718262 seconds for one epoch ---
--- 0.31223154067993164 seconds for one epoch ---
--- 0.7652215957641602 seconds for one epoch ---
--- 0.30970215797424316 seconds for one epoch ---
--- 0.7822825908660889 seconds for one epoch ---
--- 0.31268739700317383 seconds for one epoch ---
--- 0.7611315250396729 seconds for one epoch ---
--- 0.30562782287597656 seconds for one epoch ---
--- 0.7594192028045654 seconds for one epoch ---
--- 0.32822608947753906 seconds for one epoch ---
--- 0.7778842449188232 seconds for one epoch ---
--- 0.34596800804138184 seconds for one epoch ---
--- 0.7760107517242432 seconds for one epoch ---
--- 0.3561367988586426 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1751077]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.647985]
 [ 0.      ]]
--- 0.26307129859924316 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3290.672607421875, (1448.9908, 1.3448293, 1840.2468, 0.09019698)
   validation loss 1556.3331298828125, (1184.0803, 0.21639374, 371.94623, 0.09019698)
decoder loss ratio: 45873.327338, decoder SINDy loss  ratio: 0.802898
--- 0.30351758003234863 seconds for one epoch ---
--- 0.7533783912658691 seconds for one epoch ---
--- 0.3033425807952881 seconds for one epoch ---
--- 0.7683248519897461 seconds for one epoch ---
--- 0.30803728103637695 seconds for one epoch ---
--- 0.7611870765686035 seconds for one epoch ---
--- 0.30332350730895996 seconds for one epoch ---
--- 0.7590999603271484 seconds for one epoch ---
--- 0.311784029006958 seconds for one epoch ---
--- 0.7835116386413574 seconds for one epoch ---
--- 0.3477284908294678 seconds for one epoch ---
--- 0.7778007984161377 seconds for one epoch ---
--- 0.34763050079345703 seconds for one epoch ---
--- 0.7863204479217529 seconds for one epoch ---
--- 0.3267817497253418 seconds for one epoch ---
--- 0.7735259532928467 seconds for one epoch ---
--- 0.32172274589538574 seconds for one epoch ---
--- 0.7747700214385986 seconds for one epoch ---
--- 0.3231203556060791 seconds for one epoch ---
--- 0.7945799827575684 seconds for one epoch ---
--- 0.3312366008758545 seconds for one epoch ---
--- 0.7928650379180908 seconds for one epoch ---
--- 0.31119775772094727 seconds for one epoch ---
--- 0.7882370948791504 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.1953809]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.0897136]
 [ 0.       ]]
--- 0.3169698715209961 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2916.49609375, (1512.7607, 1.4224696, 1402.2147, 0.09819188)
   validation loss 1202.62158203125, (835.7248, 0.31503162, 366.48364, 0.09819188)
decoder loss ratio: 32377.429343, decoder SINDy loss  ratio: 0.791106
--- 0.2826085090637207 seconds for one epoch ---
--- 0.30909061431884766 seconds for one epoch ---
--- 0.7704658508300781 seconds for one epoch ---
--- 0.3084681034088135 seconds for one epoch ---
--- 0.7479221820831299 seconds for one epoch ---
--- 0.3084716796875 seconds for one epoch ---
--- 0.7640624046325684 seconds for one epoch ---
--- 0.30597996711730957 seconds for one epoch ---
--- 0.7634310722351074 seconds for one epoch ---
--- 0.32032275199890137 seconds for one epoch ---
--- 0.7825324535369873 seconds for one epoch ---
--- 0.31111812591552734 seconds for one epoch ---
--- 0.8041253089904785 seconds for one epoch ---
--- 0.3104548454284668 seconds for one epoch ---
--- 0.8187713623046875 seconds for one epoch ---
--- 0.3083775043487549 seconds for one epoch ---
--- 0.8052258491516113 seconds for one epoch ---
--- 0.30461597442626953 seconds for one epoch ---
--- 0.8156371116638184 seconds for one epoch ---
--- 0.3071706295013428 seconds for one epoch ---
--- 0.8192708492279053 seconds for one epoch ---
--- 0.30769968032836914 seconds for one epoch ---
--- 0.8250904083251953 seconds for one epoch ---
--- 0.3137331008911133 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.21716157]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.5545163]
 [ 0.       ]]
--- 0.2971336841583252 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4697.07861328125, (1775.8506, 2.78907, 2918.3325, 0.10659527)
   validation loss 1102.6092529296875, (745.63446, 0.31325135, 356.55502, 0.10659527)
decoder loss ratio: 28887.173476, decoder SINDy loss  ratio: 0.769674
--- 0.3131701946258545 seconds for one epoch ---
--- 0.8187487125396729 seconds for one epoch ---
--- 0.3034958839416504 seconds for one epoch ---
--- 0.7839810848236084 seconds for one epoch ---
--- 0.3079490661621094 seconds for one epoch ---
--- 0.77655029296875 seconds for one epoch ---
--- 0.30873632431030273 seconds for one epoch ---
--- 0.8053960800170898 seconds for one epoch ---
--- 0.30858445167541504 seconds for one epoch ---
--- 0.7750768661499023 seconds for one epoch ---
--- 0.30707573890686035 seconds for one epoch ---
--- 0.786252498626709 seconds for one epoch ---
--- 0.34328436851501465 seconds for one epoch ---
--- 0.7965679168701172 seconds for one epoch ---
--- 0.32407307624816895 seconds for one epoch ---
--- 0.7896616458892822 seconds for one epoch ---
--- 0.32953691482543945 seconds for one epoch ---
--- 0.8030097484588623 seconds for one epoch ---
--- 0.35317397117614746 seconds for one epoch ---
--- 0.8164231777191162 seconds for one epoch ---
--- 0.34377026557922363 seconds for one epoch ---
--- 0.8021013736724854 seconds for one epoch ---
--- 0.32900094985961914 seconds for one epoch ---
--- 0.8343651294708252 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.23832346]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.003158]
 [ 0.      ]]
--- 0.3219883441925049 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3712.588623046875, (1769.14, 0.39969248, 1942.9341, 0.11493148)
   validation loss 1141.976806640625, (816.19904, 0.3348792, 325.32785, 0.11493148)
decoder loss ratio: 31620.967625, decoder SINDy loss  ratio: 0.702266
--- 0.2707393169403076 seconds for one epoch ---
--- 0.3606221675872803 seconds for one epoch ---
--- 0.81650710105896 seconds for one epoch ---
--- 0.3224043846130371 seconds for one epoch ---
--- 0.8003201484680176 seconds for one epoch ---
--- 0.30349063873291016 seconds for one epoch ---
--- 0.8048765659332275 seconds for one epoch ---
--- 0.3093571662902832 seconds for one epoch ---
--- 0.8208119869232178 seconds for one epoch ---
--- 0.3064279556274414 seconds for one epoch ---
--- 0.8152813911437988 seconds for one epoch ---
--- 0.297412633895874 seconds for one epoch ---
--- 0.807941198348999 seconds for one epoch ---
--- 0.3036003112792969 seconds for one epoch ---
--- 0.8223645687103271 seconds for one epoch ---
--- 0.3144350051879883 seconds for one epoch ---
--- 0.7960138320922852 seconds for one epoch ---
--- 0.3069767951965332 seconds for one epoch ---
--- 0.7969696521759033 seconds for one epoch ---
--- 0.312427282333374 seconds for one epoch ---
--- 0.802093505859375 seconds for one epoch ---
--- 0.3187062740325928 seconds for one epoch ---
--- 0.8043792247772217 seconds for one epoch ---
--- 0.2994263172149658 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.25680166]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.397652]
 [ 0.      ]]
--- 0.26099205017089844 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6632.587890625, (2143.1091, 1.0798839, 4488.277, 0.12215479)
   validation loss 1098.446044921875, (768.1184, 0.30404335, 329.90146, 0.12215479)
decoder loss ratio: 29758.240646, decoder SINDy loss  ratio: 0.712139
--- 0.29903388023376465 seconds for one epoch ---
--- 0.8155386447906494 seconds for one epoch ---
--- 0.3181595802307129 seconds for one epoch ---
--- 0.8179244995117188 seconds for one epoch ---
--- 0.307267427444458 seconds for one epoch ---
--- 0.7941956520080566 seconds for one epoch ---
--- 0.3191068172454834 seconds for one epoch ---
--- 0.8136758804321289 seconds for one epoch ---
--- 0.3257460594177246 seconds for one epoch ---
--- 0.8131206035614014 seconds for one epoch ---
--- 0.31919288635253906 seconds for one epoch ---
--- 0.8240935802459717 seconds for one epoch ---
--- 0.32668280601501465 seconds for one epoch ---
--- 0.8457188606262207 seconds for one epoch ---
--- 0.3472898006439209 seconds for one epoch ---
--- 0.8518378734588623 seconds for one epoch ---
--- 0.3323202133178711 seconds for one epoch ---
--- 0.8418145179748535 seconds for one epoch ---
--- 0.34465837478637695 seconds for one epoch ---
--- 0.8359575271606445 seconds for one epoch ---
--- 0.33944225311279297 seconds for one epoch ---
--- 0.8280515670776367 seconds for one epoch ---
--- 0.3391153812408447 seconds for one epoch ---
--- 0.8479969501495361 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.27585015]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.811735]
 [ 0.      ]]
--- 0.3010404109954834 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3323.0732421875, (1454.6624, 0.5217812, 1867.7594, 0.12990184)
   validation loss 1637.5843505859375, (1305.3348, 0.23531762, 331.88428, 0.12990184)
decoder loss ratio: 50570.937819, decoder SINDy loss  ratio: 0.716419
--- 0.26589226722717285 seconds for one epoch ---
--- 0.30896830558776855 seconds for one epoch ---
--- 0.819246768951416 seconds for one epoch ---
--- 0.3169667720794678 seconds for one epoch ---
--- 0.8349504470825195 seconds for one epoch ---
--- 0.3065788745880127 seconds for one epoch ---
--- 0.8388314247131348 seconds for one epoch ---
--- 0.3064448833465576 seconds for one epoch ---
--- 0.8415584564208984 seconds for one epoch ---
--- 0.31252503395080566 seconds for one epoch ---
--- 0.8214778900146484 seconds for one epoch ---
--- 0.3008852005004883 seconds for one epoch ---
--- 0.832348108291626 seconds for one epoch ---
--- 0.3242373466491699 seconds for one epoch ---
--- 0.8272311687469482 seconds for one epoch ---
--- 0.3296675682067871 seconds for one epoch ---
--- 0.8542900085449219 seconds for one epoch ---
--- 0.3243081569671631 seconds for one epoch ---
--- 0.84024977684021 seconds for one epoch ---
--- 0.32986903190612793 seconds for one epoch ---
--- 0.8525869846343994 seconds for one epoch ---
--- 0.3396778106689453 seconds for one epoch ---
--- 0.8687903881072998 seconds for one epoch ---
--- 0.3479914665222168 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29357243]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.2086005]
 [-0.       ]]
--- 0.28915953636169434 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3555.42626953125, (1482.9086, 1.295313, 2071.0852, 0.13711432)
   validation loss 1374.9676513671875, (1028.1525, 0.37806508, 346.30002, 0.13711432)
decoder loss ratio: 39832.411477, decoder SINDy loss  ratio: 0.747537
--- 0.31635117530822754 seconds for one epoch ---
--- 0.8268423080444336 seconds for one epoch ---
--- 0.31699323654174805 seconds for one epoch ---
--- 0.8354408740997314 seconds for one epoch ---
--- 0.3181188106536865 seconds for one epoch ---
--- 0.811485767364502 seconds for one epoch ---
--- 0.3036656379699707 seconds for one epoch ---
--- 0.8217024803161621 seconds for one epoch ---
--- 0.30853748321533203 seconds for one epoch ---
--- 0.832108736038208 seconds for one epoch ---
--- 0.3070204257965088 seconds for one epoch ---
--- 0.8029143810272217 seconds for one epoch ---
--- 0.3111603260040283 seconds for one epoch ---
--- 0.8463129997253418 seconds for one epoch ---
--- 0.3057897090911865 seconds for one epoch ---
--- 0.8450174331665039 seconds for one epoch ---
--- 0.3056375980377197 seconds for one epoch ---
--- 0.8519787788391113 seconds for one epoch ---
--- 0.30611085891723633 seconds for one epoch ---
--- 0.8605921268463135 seconds for one epoch ---
--- 0.31018495559692383 seconds for one epoch ---
--- 0.8319642543792725 seconds for one epoch ---
--- 0.30695676803588867 seconds for one epoch ---
--- 0.8678717613220215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31046253]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.6022315]
 [-0.       ]]
--- 0.32297587394714355 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4997.3212890625, (1853.2494, 1.1973375, 3142.73, 0.14428769)
   validation loss 1324.9874267578125, (956.3158, 0.38804397, 368.13928, 0.14428769)
decoder loss ratio: 37049.334170, decoder SINDy loss  ratio: 0.794680
--- 0.2608907222747803 seconds for one epoch ---
--- 0.35167956352233887 seconds for one epoch ---
--- 0.858933687210083 seconds for one epoch ---
--- 0.3066895008087158 seconds for one epoch ---
--- 0.8696627616882324 seconds for one epoch ---
--- 0.31191229820251465 seconds for one epoch ---
--- 0.8477027416229248 seconds for one epoch ---
--- 0.31576037406921387 seconds for one epoch ---
--- 0.8502373695373535 seconds for one epoch ---
--- 0.30898356437683105 seconds for one epoch ---
--- 0.8743765354156494 seconds for one epoch ---
--- 0.31847262382507324 seconds for one epoch ---
--- 0.8369600772857666 seconds for one epoch ---
--- 0.3076655864715576 seconds for one epoch ---
--- 0.8576712608337402 seconds for one epoch ---
--- 0.3379957675933838 seconds for one epoch ---
--- 0.8915176391601562 seconds for one epoch ---
--- 0.3439915180206299 seconds for one epoch ---
--- 0.8718404769897461 seconds for one epoch ---
--- 0.3324739933013916 seconds for one epoch ---
--- 0.8881947994232178 seconds for one epoch ---
--- 0.3323354721069336 seconds for one epoch ---
--- 0.8699605464935303 seconds for one epoch ---
--- 0.3273742198944092 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3238788]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-7.929733]
 [-0.      ]]
--- 0.2746424674987793 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4121.42626953125, (1690.2369, 0.6760093, 2430.363, 0.15016206)
   validation loss 1168.8486328125, (795.71875, 0.3814361, 372.59833, 0.15016206)
decoder loss ratio: 30827.525804, decoder SINDy loss  ratio: 0.804306
--- 0.3130185604095459 seconds for one epoch ---
--- 0.8648312091827393 seconds for one epoch ---
--- 0.31026268005371094 seconds for one epoch ---
--- 0.8628787994384766 seconds for one epoch ---
--- 0.3154456615447998 seconds for one epoch ---
--- 0.8553340435028076 seconds for one epoch ---
--- 0.30574703216552734 seconds for one epoch ---
--- 0.8476026058197021 seconds for one epoch ---
--- 0.31339168548583984 seconds for one epoch ---
--- 0.8746588230133057 seconds for one epoch ---
--- 0.3134338855743408 seconds for one epoch ---
--- 0.8660461902618408 seconds for one epoch ---
--- 0.304354190826416 seconds for one epoch ---
--- 0.871894121170044 seconds for one epoch ---
--- 0.30346083641052246 seconds for one epoch ---
--- 0.8500580787658691 seconds for one epoch ---
--- 0.34362244606018066 seconds for one epoch ---
--- 0.9112575054168701 seconds for one epoch ---
--- 0.33652591705322266 seconds for one epoch ---
--- 0.8685064315795898 seconds for one epoch ---
--- 0.3262064456939697 seconds for one epoch ---
--- 0.8945732116699219 seconds for one epoch ---
--- 0.3378944396972656 seconds for one epoch ---
--- 0.8664577007293701 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33687824]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.263664]
 [ 0.      ]]
--- 0.3086583614349365 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7539.22412109375, (2818.6272, 2.5241091, 4717.9165, 0.15614578)
   validation loss 1429.3936767578125, (1097.6124, 0.34658992, 331.27853, 0.15614578)
decoder loss ratio: 42523.410952, decoder SINDy loss  ratio: 0.715111
--- 0.27026987075805664 seconds for one epoch ---
--- 0.32392215728759766 seconds for one epoch ---
--- 0.8554058074951172 seconds for one epoch ---
--- 0.30580687522888184 seconds for one epoch ---
--- 0.8450772762298584 seconds for one epoch ---
--- 0.31499242782592773 seconds for one epoch ---
--- 0.8659653663635254 seconds for one epoch ---
--- 0.3070361614227295 seconds for one epoch ---
--- 0.8711376190185547 seconds for one epoch ---
--- 0.30915093421936035 seconds for one epoch ---
--- 0.8969631195068359 seconds for one epoch ---
--- 0.31243133544921875 seconds for one epoch ---
--- 0.8973381519317627 seconds for one epoch ---
--- 0.3067498207092285 seconds for one epoch ---
--- 0.883084774017334 seconds for one epoch ---
--- 0.3174765110015869 seconds for one epoch ---
--- 0.8598449230194092 seconds for one epoch ---
--- 0.47901153564453125 seconds for one epoch ---
--- 0.872492790222168 seconds for one epoch ---
--- 0.30943775177001953 seconds for one epoch ---
--- 0.8836984634399414 seconds for one epoch ---
--- 0.30635881423950195 seconds for one epoch ---
--- 0.8861422538757324 seconds for one epoch ---
--- 0.32665300369262695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34894398]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.592722]
 [ 0.      ]]
--- 0.2917649745941162 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3419.693603515625, (1187.7882, 4.0438256, 2227.6997, 0.16198103)
   validation loss 1262.9359130859375, (945.53033, 0.30457276, 316.93903, 0.16198103)
decoder loss ratio: 36631.486670, decoder SINDy loss  ratio: 0.684157
--- 0.3306288719177246 seconds for one epoch ---
--- 0.8896703720092773 seconds for one epoch ---
--- 0.3309762477874756 seconds for one epoch ---
--- 0.8713786602020264 seconds for one epoch ---
--- 0.33376622200012207 seconds for one epoch ---
--- 0.8777236938476562 seconds for one epoch ---
--- 0.3060932159423828 seconds for one epoch ---
--- 0.8703429698944092 seconds for one epoch ---
--- 0.3129243850708008 seconds for one epoch ---
--- 0.8658459186553955 seconds for one epoch ---
--- 0.3009648323059082 seconds for one epoch ---
--- 0.889962911605835 seconds for one epoch ---
--- 0.30503320693969727 seconds for one epoch ---
--- 0.8623752593994141 seconds for one epoch ---
--- 0.3016970157623291 seconds for one epoch ---
--- 0.8846774101257324 seconds for one epoch ---
--- 0.31439995765686035 seconds for one epoch ---
--- 0.9155611991882324 seconds for one epoch ---
--- 0.35762882232666016 seconds for one epoch ---
--- 0.8887503147125244 seconds for one epoch ---
--- 0.3535592555999756 seconds for one epoch ---
--- 0.8950035572052002 seconds for one epoch ---
--- 0.3511791229248047 seconds for one epoch ---
--- 0.8923802375793457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35885686]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.880962]
 [ 0.      ]]
--- 0.3029153347015381 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3484.903076171875, (1679.1232, 2.6361089, 1802.9768, 0.16698359)
   validation loss 1242.1082763671875, (899.088, 0.36239457, 342.49088, 0.16698359)
decoder loss ratio: 34832.230497, decoder SINDy loss  ratio: 0.739315
--- 0.27089595794677734 seconds for one epoch ---
--- 0.3122894763946533 seconds for one epoch ---
--- 0.8991718292236328 seconds for one epoch ---
--- 0.303037166595459 seconds for one epoch ---
--- 0.869511604309082 seconds for one epoch ---
--- 0.310302734375 seconds for one epoch ---
--- 0.8692164421081543 seconds for one epoch ---
--- 0.31803202629089355 seconds for one epoch ---
--- 0.8880290985107422 seconds for one epoch ---
--- 0.3032548427581787 seconds for one epoch ---
--- 0.8760561943054199 seconds for one epoch ---
--- 0.3033030033111572 seconds for one epoch ---
--- 0.8981213569641113 seconds for one epoch ---
--- 0.3051471710205078 seconds for one epoch ---
--- 0.9022092819213867 seconds for one epoch ---
--- 0.30119967460632324 seconds for one epoch ---
--- 0.9010767936706543 seconds for one epoch ---
--- 0.3033277988433838 seconds for one epoch ---
--- 0.8764712810516357 seconds for one epoch ---
--- 0.30277323722839355 seconds for one epoch ---
--- 0.9100360870361328 seconds for one epoch ---
--- 0.3018472194671631 seconds for one epoch ---
--- 0.8918344974517822 seconds for one epoch ---
--- 0.3054318428039551 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3674348]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-9.147168]
 [-0.      ]]
--- 0.2879617214202881 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2793.595947265625, (1439.1392, 1.4154164, 1352.8699, 0.17153202)
   validation loss 1207.2733154296875, (878.9863, 0.36546144, 327.74994, 0.17153202)
decoder loss ratio: 34053.456339, decoder SINDy loss  ratio: 0.707494
--- 0.30698657035827637 seconds for one epoch ---
--- 0.9358413219451904 seconds for one epoch ---
--- 0.32036280632019043 seconds for one epoch ---
--- 0.9205491542816162 seconds for one epoch ---
--- 0.32271885871887207 seconds for one epoch ---
--- 0.9178462028503418 seconds for one epoch ---
--- 0.34047675132751465 seconds for one epoch ---
--- 0.9191172122955322 seconds for one epoch ---
--- 0.3133277893066406 seconds for one epoch ---
--- 0.9121277332305908 seconds for one epoch ---
--- 0.30520153045654297 seconds for one epoch ---
--- 0.9110128879547119 seconds for one epoch ---
--- 0.3022637367248535 seconds for one epoch ---
--- 0.902299165725708 seconds for one epoch ---
--- 0.30805063247680664 seconds for one epoch ---
--- 0.8851110935211182 seconds for one epoch ---
--- 0.3008081912994385 seconds for one epoch ---
--- 0.9091300964355469 seconds for one epoch ---
--- 0.3095884323120117 seconds for one epoch ---
--- 0.9524381160736084 seconds for one epoch ---
--- 0.3574526309967041 seconds for one epoch ---
--- 0.9177205562591553 seconds for one epoch ---
--- 0.34079647064208984 seconds for one epoch ---
--- 0.9477536678314209 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3761637]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.438679]
 [-0.      ]]
--- 0.3442037105560303 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3737.19189453125, (997.0379, 1.0617031, 2738.9158, 0.17650731)
   validation loss 1385.43408203125, (1045.7395, 0.34256822, 339.17554, 0.17650731)
decoder loss ratio: 40513.763789, decoder SINDy loss  ratio: 0.732158
--- 0.2643451690673828 seconds for one epoch ---
--- 0.33954358100891113 seconds for one epoch ---
--- 0.9274938106536865 seconds for one epoch ---
--- 0.34723758697509766 seconds for one epoch ---
--- 0.902667760848999 seconds for one epoch ---
--- 0.3439905643463135 seconds for one epoch ---
--- 0.9118268489837646 seconds for one epoch ---
--- 0.342714786529541 seconds for one epoch ---
--- 0.9040002822875977 seconds for one epoch ---
--- 0.3086733818054199 seconds for one epoch ---
--- 0.9066402912139893 seconds for one epoch ---
--- 0.30049753189086914 seconds for one epoch ---
--- 0.900493860244751 seconds for one epoch ---
--- 0.3024754524230957 seconds for one epoch ---
--- 0.9124002456665039 seconds for one epoch ---
--- 0.3073558807373047 seconds for one epoch ---
--- 0.9161820411682129 seconds for one epoch ---
--- 0.305835485458374 seconds for one epoch ---
--- 0.9162929058074951 seconds for one epoch ---
--- 0.3068430423736572 seconds for one epoch ---
--- 0.9325218200683594 seconds for one epoch ---
--- 0.29497528076171875 seconds for one epoch ---
--- 0.9471316337585449 seconds for one epoch ---
--- 0.3063361644744873 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.38379192]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.715788]
 [-0.      ]]
--- 0.2716388702392578 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4556.57373046875, (1799.8054, 1.5422492, 2755.0447, 0.18113984)
   validation loss 807.3853149414062, (484.21054, 0.38999897, 322.60364, 0.18113984)
decoder loss ratio: 18759.156976, decoder SINDy loss  ratio: 0.696385
--- 0.30304932594299316 seconds for one epoch ---
--- 0.9562928676605225 seconds for one epoch ---
--- 0.3213462829589844 seconds for one epoch ---
--- 0.9654510021209717 seconds for one epoch ---
--- 0.30005908012390137 seconds for one epoch ---
--- 0.9675052165985107 seconds for one epoch ---
--- 0.306520938873291 seconds for one epoch ---
--- 0.9812066555023193 seconds for one epoch ---
--- 0.31087350845336914 seconds for one epoch ---
--- 0.9258847236633301 seconds for one epoch ---
--- 0.3032402992248535 seconds for one epoch ---
--- 0.9361293315887451 seconds for one epoch ---
--- 0.3006782531738281 seconds for one epoch ---
--- 0.9277639389038086 seconds for one epoch ---
--- 0.30500268936157227 seconds for one epoch ---
--- 0.9451968669891357 seconds for one epoch ---
--- 0.3011658191680908 seconds for one epoch ---
--- 0.8970541954040527 seconds for one epoch ---
--- 0.2922632694244385 seconds for one epoch ---
--- 0.9397311210632324 seconds for one epoch ---
--- 0.3304269313812256 seconds for one epoch ---
--- 0.9661962985992432 seconds for one epoch ---
--- 0.32999300956726074 seconds for one epoch ---
--- 0.9441440105438232 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3903235]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-9.975234]
 [ 0.      ]]
--- 0.3283231258392334 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2685.894775390625, (1214.2513, 1.6961988, 1469.7621, 0.18529147)
   validation loss 822.6029052734375, (528.11334, 0.24293086, 294.06134, 0.18529147)
decoder loss ratio: 20460.027725, decoder SINDy loss  ratio: 0.634773
--- 0.29978227615356445 seconds for one epoch ---
--- 0.3401002883911133 seconds for one epoch ---
--- 0.9568352699279785 seconds for one epoch ---
--- 0.34200549125671387 seconds for one epoch ---
--- 0.956622838973999 seconds for one epoch ---
--- 0.34857630729675293 seconds for one epoch ---
--- 0.9601712226867676 seconds for one epoch ---
--- 0.35389256477355957 seconds for one epoch ---
--- 0.9584200382232666 seconds for one epoch ---
--- 0.3459150791168213 seconds for one epoch ---
--- 0.9507231712341309 seconds for one epoch ---
--- 0.3134901523590088 seconds for one epoch ---
--- 0.94384765625 seconds for one epoch ---
--- 0.3128011226654053 seconds for one epoch ---
--- 0.9503223896026611 seconds for one epoch ---
--- 0.3070363998413086 seconds for one epoch ---
--- 0.9512965679168701 seconds for one epoch ---
--- 0.3123152256011963 seconds for one epoch ---
--- 0.9515359401702881 seconds for one epoch ---
--- 0.29805779457092285 seconds for one epoch ---
--- 0.9302761554718018 seconds for one epoch ---
--- 0.32919859886169434 seconds for one epoch ---
--- 0.9400250911712646 seconds for one epoch ---
--- 0.31996941566467285 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.395983]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.222343]
 [  0.      ]]
--- 0.275970458984375 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3020.656005859375, (1576.8544, 0.7633448, 1442.8491, 0.1892674)
   validation loss 859.2384643554688, (562.4435, 0.2805622, 296.32516, 0.1892674)
decoder loss ratio: 21790.036916, decoder SINDy loss  ratio: 0.639660
--- 0.35347580909729004 seconds for one epoch ---
--- 0.9566094875335693 seconds for one epoch ---
--- 0.35631346702575684 seconds for one epoch ---
--- 0.9434847831726074 seconds for one epoch ---
--- 0.3485872745513916 seconds for one epoch ---
--- 0.9696815013885498 seconds for one epoch ---
--- 0.3595421314239502 seconds for one epoch ---
--- 0.9462604522705078 seconds for one epoch ---
--- 0.35529088973999023 seconds for one epoch ---
--- 0.9618754386901855 seconds for one epoch ---
--- 0.3242220878601074 seconds for one epoch ---
--- 0.9738931655883789 seconds for one epoch ---
--- 0.31802940368652344 seconds for one epoch ---
--- 0.9816174507141113 seconds for one epoch ---
--- 0.31257128715515137 seconds for one epoch ---
--- 0.9820890426635742 seconds for one epoch ---
--- 0.31242966651916504 seconds for one epoch ---
--- 0.9811680316925049 seconds for one epoch ---
--- 0.3080904483795166 seconds for one epoch ---
--- 0.9486136436462402 seconds for one epoch ---
--- 0.30495595932006836 seconds for one epoch ---
--- 0.9645860195159912 seconds for one epoch ---
--- 0.3097801208496094 seconds for one epoch ---
--- 0.9981787204742432 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40099248]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.464773]
 [  0.      ]]
--- 0.3001725673675537 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5041.5224609375, (1667.6754, 1.0279243, 3372.6262, 0.19306426)
   validation loss 975.9971923828125, (644.1792, 0.37242115, 331.2525, 0.19306426)
decoder loss ratio: 24956.620522, decoder SINDy loss  ratio: 0.715055
--- 0.263916015625 seconds for one epoch ---
--- 0.31522107124328613 seconds for one epoch ---
--- 0.9480109214782715 seconds for one epoch ---
--- 0.31386303901672363 seconds for one epoch ---
--- 0.9573595523834229 seconds for one epoch ---
--- 0.31699347496032715 seconds for one epoch ---
--- 0.9662489891052246 seconds for one epoch ---
--- 0.32282161712646484 seconds for one epoch ---
--- 0.9603400230407715 seconds for one epoch ---
--- 0.30602335929870605 seconds for one epoch ---
--- 0.9635322093963623 seconds for one epoch ---
--- 0.319072961807251 seconds for one epoch ---
--- 0.9589235782623291 seconds for one epoch ---
--- 0.3041682243347168 seconds for one epoch ---
--- 1.015587568283081 seconds for one epoch ---
--- 0.31638622283935547 seconds for one epoch ---
--- 0.9785504341125488 seconds for one epoch ---
--- 0.30656933784484863 seconds for one epoch ---
--- 0.9673018455505371 seconds for one epoch ---
--- 0.3140232563018799 seconds for one epoch ---
--- 0.9524021148681641 seconds for one epoch ---
--- 0.2992668151855469 seconds for one epoch ---
--- 0.9653372764587402 seconds for one epoch ---
--- 0.30834531784057617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40494725]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.677985]
 [ -0.      ]]
--- 0.2668602466583252 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5075.2470703125, (2218.3853, 2.5654404, 2854.1003, 0.19637592)
   validation loss 912.3707885742188, (604.2773, 0.347068, 307.55008, 0.19637592)
decoder loss ratio: 23410.751004, decoder SINDy loss  ratio: 0.663890
--- 0.30312252044677734 seconds for one epoch ---
--- 0.9552977085113525 seconds for one epoch ---
--- 0.30550336837768555 seconds for one epoch ---
--- 0.9508209228515625 seconds for one epoch ---
--- 0.30329084396362305 seconds for one epoch ---
--- 0.9552240371704102 seconds for one epoch ---
--- 0.3150899410247803 seconds for one epoch ---
--- 0.9585037231445312 seconds for one epoch ---
--- 0.3037741184234619 seconds for one epoch ---
--- 0.9820404052734375 seconds for one epoch ---
--- 0.30175089836120605 seconds for one epoch ---
--- 0.9371440410614014 seconds for one epoch ---
--- 0.2987840175628662 seconds for one epoch ---
--- 0.9585781097412109 seconds for one epoch ---
--- 0.3232259750366211 seconds for one epoch ---
--- 0.984375 seconds for one epoch ---
--- 0.3262202739715576 seconds for one epoch ---
--- 0.9920830726623535 seconds for one epoch ---
--- 0.32427120208740234 seconds for one epoch ---
--- 0.9922647476196289 seconds for one epoch ---
--- 0.31029391288757324 seconds for one epoch ---
--- 0.9843885898590088 seconds for one epoch ---
--- 0.32297325134277344 seconds for one epoch ---
--- 0.9811334609985352 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4084013]
 [0.       ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-10.8864355]
 [ -0.       ]]
--- 0.3347644805908203 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4807.06396484375, (2096.247, 0.922413, 2709.6946, 0.19953246)
   validation loss 1113.5118408203125, (796.252, 0.38520896, 316.6751, 0.19953246)
decoder loss ratio: 30848.185383, decoder SINDy loss  ratio: 0.683588
THRESHOLDING: 1 active coefficients
--- 0.2723996639251709 seconds for one epoch ---
--- 0.31191515922546387 seconds for one epoch ---
--- 0.9597506523132324 seconds for one epoch ---
--- 0.31128764152526855 seconds for one epoch ---
--- 0.9599354267120361 seconds for one epoch ---
--- 0.3009672164916992 seconds for one epoch ---
--- 0.9859881401062012 seconds for one epoch ---
--- 0.31655335426330566 seconds for one epoch ---
--- 0.9976053237915039 seconds for one epoch ---
--- 0.31270599365234375 seconds for one epoch ---
--- 0.9929823875427246 seconds for one epoch ---
--- 0.3136436939239502 seconds for one epoch ---
--- 0.9867362976074219 seconds for one epoch ---
--- 0.3069000244140625 seconds for one epoch ---
--- 0.9914097785949707 seconds for one epoch ---
--- 0.3234689235687256 seconds for one epoch ---
--- 0.99806809425354 seconds for one epoch ---
--- 0.3152017593383789 seconds for one epoch ---
--- 1.0142178535461426 seconds for one epoch ---
--- 0.33246397972106934 seconds for one epoch ---
--- 0.9969320297241211 seconds for one epoch ---
--- 0.3012981414794922 seconds for one epoch ---
--- 0.9753828048706055 seconds for one epoch ---
--- 0.3193166255950928 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4109254]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.057307]
 [ -0.      ]]
--- 0.26143503189086914 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2981.210693359375, (1072.4084, 1.2295221, 1907.3823, 0.19043274)
   validation loss 883.15185546875, (586.55786, 0.3688318, 296.03473, 0.19043274)
decoder loss ratio: 22724.269857, decoder SINDy loss  ratio: 0.639033
--- 0.3328859806060791 seconds for one epoch ---
--- 0.9785692691802979 seconds for one epoch ---
--- 0.3469393253326416 seconds for one epoch ---
--- 1.011106014251709 seconds for one epoch ---
--- 0.366473913192749 seconds for one epoch ---
--- 0.9820394515991211 seconds for one epoch ---
--- 0.345261812210083 seconds for one epoch ---
--- 1.0122878551483154 seconds for one epoch ---
--- 0.3538818359375 seconds for one epoch ---
--- 0.9904041290283203 seconds for one epoch ---
--- 0.3389933109283447 seconds for one epoch ---
--- 0.9841594696044922 seconds for one epoch ---
--- 0.32570457458496094 seconds for one epoch ---
--- 0.9904112815856934 seconds for one epoch ---
--- 0.30519866943359375 seconds for one epoch ---
--- 0.9863438606262207 seconds for one epoch ---
--- 0.3068559169769287 seconds for one epoch ---
--- 0.9953346252441406 seconds for one epoch ---
--- 0.308286190032959 seconds for one epoch ---
--- 1.0020110607147217 seconds for one epoch ---
--- 0.30454540252685547 seconds for one epoch ---
--- 0.9631938934326172 seconds for one epoch ---
--- 0.3008894920349121 seconds for one epoch ---
--- 0.9950671195983887 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4132073]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.231095]
 [  0.      ]]
--- 0.30445170402526855 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1993.0511474609375, (1277.836, 0.47738633, 714.54474, 0.19295466)
   validation loss 941.012939453125, (622.2563, 0.4272718, 318.13647, 0.19295466)
decoder loss ratio: 24107.288828, decoder SINDy loss  ratio: 0.686742
--- 0.2785613536834717 seconds for one epoch ---
--- 0.31229567527770996 seconds for one epoch ---
--- 0.9980144500732422 seconds for one epoch ---
--- 0.306105375289917 seconds for one epoch ---
--- 0.9936001300811768 seconds for one epoch ---
--- 0.3156003952026367 seconds for one epoch ---
--- 0.9930000305175781 seconds for one epoch ---
--- 0.3124551773071289 seconds for one epoch ---
--- 1.0189518928527832 seconds for one epoch ---
--- 0.30738115310668945 seconds for one epoch ---
--- 1.0108401775360107 seconds for one epoch ---
--- 0.30415916442871094 seconds for one epoch ---
--- 1.0133531093597412 seconds for one epoch ---
--- 0.30643534660339355 seconds for one epoch ---
--- 1.0343708992004395 seconds for one epoch ---
--- 0.3112974166870117 seconds for one epoch ---
--- 1.0368072986602783 seconds for one epoch ---
--- 0.3164980411529541 seconds for one epoch ---
--- 1.0223853588104248 seconds for one epoch ---
--- 0.3147106170654297 seconds for one epoch ---
--- 1.0444395542144775 seconds for one epoch ---
--- 0.3199644088745117 seconds for one epoch ---
--- 1.0006988048553467 seconds for one epoch ---
--- 0.30474424362182617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41511536]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.396971]
 [  0.      ]]
--- 0.2950928211212158 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4279.72509765625, (1694.4988, 2.2104359, 2582.8206, 0.19544052)
   validation loss 1155.44873046875, (805.71094, 0.5966132, 348.94574, 0.19544052)
decoder loss ratio: 31214.640494, decoder SINDy loss  ratio: 0.753248
--- 0.3043539524078369 seconds for one epoch ---
--- 1.0152997970581055 seconds for one epoch ---
--- 0.3083522319793701 seconds for one epoch ---
--- 1.0171544551849365 seconds for one epoch ---
--- 0.3127627372741699 seconds for one epoch ---
--- 1.0346219539642334 seconds for one epoch ---
--- 0.3060898780822754 seconds for one epoch ---
--- 1.0042035579681396 seconds for one epoch ---
--- 0.30847740173339844 seconds for one epoch ---
--- 1.0338969230651855 seconds for one epoch ---
--- 0.306382417678833 seconds for one epoch ---
--- 1.0312449932098389 seconds for one epoch ---
--- 0.3199734687805176 seconds for one epoch ---
--- 1.0388591289520264 seconds for one epoch ---
--- 0.30874156951904297 seconds for one epoch ---
--- 1.0181074142456055 seconds for one epoch ---
--- 0.3150475025177002 seconds for one epoch ---
--- 1.017589807510376 seconds for one epoch ---
--- 0.3079111576080322 seconds for one epoch ---
--- 1.038808822631836 seconds for one epoch ---
--- 0.310899019241333 seconds for one epoch ---
--- 1.0382094383239746 seconds for one epoch ---
--- 0.29847145080566406 seconds for one epoch ---
--- 0.9803779125213623 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41673827]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.560658]
 [  0.      ]]
--- 0.325026273727417 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3326.897216796875, (1237.9338, 1.5268478, 2087.2388, 0.1977015)
   validation loss 873.3584594726562, (580.58276, 0.2909256, 292.28708, 0.1977015)
decoder loss ratio: 22492.784201, decoder SINDy loss  ratio: 0.630943
--- 0.29192423820495605 seconds for one epoch ---
--- 0.34917402267456055 seconds for one epoch ---
--- 1.0517017841339111 seconds for one epoch ---
--- 0.3465428352355957 seconds for one epoch ---
--- 1.0526416301727295 seconds for one epoch ---
--- 0.3470578193664551 seconds for one epoch ---
--- 1.0537083148956299 seconds for one epoch ---
--- 0.3430061340332031 seconds for one epoch ---
--- 1.0497069358825684 seconds for one epoch ---
--- 0.34498071670532227 seconds for one epoch ---
--- 1.068946123123169 seconds for one epoch ---
--- 0.33724331855773926 seconds for one epoch ---
--- 1.0773906707763672 seconds for one epoch ---
--- 0.3227827548980713 seconds for one epoch ---
--- 1.0488309860229492 seconds for one epoch ---
--- 0.3187844753265381 seconds for one epoch ---
--- 1.0314207077026367 seconds for one epoch ---
--- 0.3088204860687256 seconds for one epoch ---
--- 1.0547783374786377 seconds for one epoch ---
--- 0.2981104850769043 seconds for one epoch ---
--- 1.053999423980713 seconds for one epoch ---
--- 0.31027650833129883 seconds for one epoch ---
--- 1.0499505996704102 seconds for one epoch ---
--- 0.30362844467163086 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41805106]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.717524]
 [ -0.      ]]
--- 0.28955745697021484 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4261.52685546875, (1938.7139, 2.944186, 2319.6687, 0.19998324)
   validation loss 1295.669921875, (943.3446, 0.44177392, 351.68365, 0.19998324)
decoder loss ratio: 36546.807696, decoder SINDy loss  ratio: 0.759159
--- 0.3189358711242676 seconds for one epoch ---
--- 1.0451362133026123 seconds for one epoch ---
--- 0.32604289054870605 seconds for one epoch ---
--- 1.05055570602417 seconds for one epoch ---
--- 0.3319718837738037 seconds for one epoch ---
--- 1.053515911102295 seconds for one epoch ---
--- 0.3336455821990967 seconds for one epoch ---
--- 1.06254243850708 seconds for one epoch ---
--- 0.3460659980773926 seconds for one epoch ---
--- 1.0386343002319336 seconds for one epoch ---
--- 0.33528780937194824 seconds for one epoch ---
--- 1.0724139213562012 seconds for one epoch ---
--- 0.3365345001220703 seconds for one epoch ---
--- 1.0663444995880127 seconds for one epoch ---
--- 0.3210623264312744 seconds for one epoch ---
--- 1.0597078800201416 seconds for one epoch ---
--- 0.3032844066619873 seconds for one epoch ---
--- 1.0654997825622559 seconds for one epoch ---
--- 0.30940985679626465 seconds for one epoch ---
--- 1.0465366840362549 seconds for one epoch ---
--- 0.3280363082885742 seconds for one epoch ---
--- 1.0829262733459473 seconds for one epoch ---
--- 0.30405116081237793 seconds for one epoch ---
--- 1.009796380996704 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41918415]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.884204]
 [ -0.      ]]
--- 0.34170079231262207 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2426.29248046875, (987.5109, 0.9466146, 1437.6326, 0.20233802)
   validation loss 830.2376098632812, (525.0931, 0.399599, 304.5426, 0.20233802)
decoder loss ratio: 20343.017467, decoder SINDy loss  ratio: 0.657398
--- 0.2730398178100586 seconds for one epoch ---
--- 0.3582134246826172 seconds for one epoch ---
--- 1.0381808280944824 seconds for one epoch ---
--- 0.31327080726623535 seconds for one epoch ---
--- 1.0141398906707764 seconds for one epoch ---
--- 0.3026702404022217 seconds for one epoch ---
--- 1.0424354076385498 seconds for one epoch ---
--- 0.30766868591308594 seconds for one epoch ---
--- 1.0439298152923584 seconds for one epoch ---
--- 0.30382490158081055 seconds for one epoch ---
--- 1.0502073764801025 seconds for one epoch ---
--- 0.3043513298034668 seconds for one epoch ---
--- 1.0438640117645264 seconds for one epoch ---
--- 0.31035709381103516 seconds for one epoch ---
--- 1.0451197624206543 seconds for one epoch ---
--- 0.3053865432739258 seconds for one epoch ---
--- 1.0589256286621094 seconds for one epoch ---
--- 0.30435633659362793 seconds for one epoch ---
--- 1.0669915676116943 seconds for one epoch ---
--- 0.30266523361206055 seconds for one epoch ---
--- 1.062459945678711 seconds for one epoch ---
--- 0.30093884468078613 seconds for one epoch ---
--- 1.0735363960266113 seconds for one epoch ---
--- 0.30431246757507324 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41998133]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.035728]
 [ -0.      ]]
--- 0.2809154987335205 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4331.97265625, (1330.6472, 3.775305, 2997.3457, 0.20439425)
   validation loss 926.0220336914062, (621.758, 0.3667372, 303.69284, 0.20439425)
decoder loss ratio: 24087.984169, decoder SINDy loss  ratio: 0.655564
--- 0.3173685073852539 seconds for one epoch ---
--- 1.0740399360656738 seconds for one epoch ---
--- 0.3237724304199219 seconds for one epoch ---
--- 1.0661442279815674 seconds for one epoch ---
--- 0.32494163513183594 seconds for one epoch ---
--- 1.0691680908203125 seconds for one epoch ---
--- 0.3363683223724365 seconds for one epoch ---
--- 1.085796594619751 seconds for one epoch ---
--- 0.33684778213500977 seconds for one epoch ---
--- 1.090217113494873 seconds for one epoch ---
--- 0.3314626216888428 seconds for one epoch ---
--- 1.069338083267212 seconds for one epoch ---
--- 0.3377344608306885 seconds for one epoch ---
--- 1.1210942268371582 seconds for one epoch ---
--- 0.33875203132629395 seconds for one epoch ---
--- 1.0817615985870361 seconds for one epoch ---
--- 0.31007885932922363 seconds for one epoch ---
--- 1.0691640377044678 seconds for one epoch ---
--- 0.3011200428009033 seconds for one epoch ---
--- 1.072843313217163 seconds for one epoch ---
--- 0.3082737922668457 seconds for one epoch ---
--- 1.062506914138794 seconds for one epoch ---
--- 0.3047199249267578 seconds for one epoch ---
--- 1.0988550186157227 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.42056894]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.192089]
 [  0.      ]]
--- 0.2964446544647217 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3081.235595703125, (908.7246, 1.2057981, 2171.0986, 0.20651019)
   validation loss 1403.0118408203125, (1045.2994, 0.5672087, 356.93863, 0.20651019)
decoder loss ratio: 40496.714966, decoder SINDy loss  ratio: 0.770502
--- 0.27669525146484375 seconds for one epoch ---
--- 0.3085329532623291 seconds for one epoch ---
--- 1.047278642654419 seconds for one epoch ---
--- 0.3036623001098633 seconds for one epoch ---
--- 1.0548696517944336 seconds for one epoch ---
--- 0.3058662414550781 seconds for one epoch ---
--- 1.0773396492004395 seconds for one epoch ---
--- 0.30942511558532715 seconds for one epoch ---
--- 1.0917620658874512 seconds for one epoch ---
--- 0.30230093002319336 seconds for one epoch ---
--- 1.1150379180908203 seconds for one epoch ---
--- 0.5233626365661621 seconds for one epoch ---
--- 1.0654091835021973 seconds for one epoch ---
--- 0.3024890422821045 seconds for one epoch ---
--- 1.080995798110962 seconds for one epoch ---
--- 0.3116109371185303 seconds for one epoch ---
--- 1.0978715419769287 seconds for one epoch ---
--- 0.3056347370147705 seconds for one epoch ---
--- 1.1149542331695557 seconds for one epoch ---
--- 0.31086087226867676 seconds for one epoch ---
--- 1.112825632095337 seconds for one epoch ---
--- 0.3274245262145996 seconds for one epoch ---
--- 1.0955264568328857 seconds for one epoch ---
--- 0.31614041328430176 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.42090622]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.340453]
 [  0.      ]]
--- 0.27224135398864746 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3438.21728515625, (1316.1736, 3.423212, 2118.412, 0.20848577)
   validation loss 931.4322509765625, (604.87604, 0.53829, 325.80948, 0.20848577)
decoder loss ratio: 23433.947808, decoder SINDy loss  ratio: 0.703306
--- 0.3042898178100586 seconds for one epoch ---
--- 1.0675134658813477 seconds for one epoch ---
--- 0.3010861873626709 seconds for one epoch ---
--- 1.0859527587890625 seconds for one epoch ---
--- 0.30738353729248047 seconds for one epoch ---
--- 1.0891690254211426 seconds for one epoch ---
--- 0.3088798522949219 seconds for one epoch ---
--- 1.0863208770751953 seconds for one epoch ---
--- 0.30526065826416016 seconds for one epoch ---
--- 1.1078591346740723 seconds for one epoch ---
--- 0.3073160648345947 seconds for one epoch ---
--- 1.1151854991912842 seconds for one epoch ---
--- 0.3117973804473877 seconds for one epoch ---
--- 1.1084659099578857 seconds for one epoch ---
--- 0.3032557964324951 seconds for one epoch ---
--- 1.1077253818511963 seconds for one epoch ---
--- 0.30410051345825195 seconds for one epoch ---
--- 1.1073110103607178 seconds for one epoch ---
--- 0.3136250972747803 seconds for one epoch ---
--- 1.111032485961914 seconds for one epoch ---
--- 0.3136322498321533 seconds for one epoch ---
--- 1.1107511520385742 seconds for one epoch ---
--- 0.31010866165161133 seconds for one epoch ---
--- 1.1410331726074219 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4210285]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.484411]
 [  0.      ]]
--- 0.31319355964660645 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3543.204833984375, (1421.351, 2.5973048, 2119.0461, 0.21036096)
   validation loss 907.275390625, (572.5504, 0.468634, 334.04596, 0.21036096)
decoder loss ratio: 22181.597070, decoder SINDy loss  ratio: 0.721085
--- 0.2659482955932617 seconds for one epoch ---
--- 0.306246280670166 seconds for one epoch ---
--- 1.0762228965759277 seconds for one epoch ---
--- 0.30953097343444824 seconds for one epoch ---
--- 1.0736703872680664 seconds for one epoch ---
--- 0.30737876892089844 seconds for one epoch ---
--- 1.0739412307739258 seconds for one epoch ---
--- 0.3114449977874756 seconds for one epoch ---
--- 1.0939862728118896 seconds for one epoch ---
--- 0.3067312240600586 seconds for one epoch ---
--- 1.1210265159606934 seconds for one epoch ---
--- 0.302854061126709 seconds for one epoch ---
--- 1.1056323051452637 seconds for one epoch ---
--- 0.304976224899292 seconds for one epoch ---
--- 1.1110997200012207 seconds for one epoch ---
--- 0.30727553367614746 seconds for one epoch ---
--- 1.1268436908721924 seconds for one epoch ---
--- 0.31087231636047363 seconds for one epoch ---
--- 1.1298537254333496 seconds for one epoch ---
--- 0.304821252822876 seconds for one epoch ---
--- 1.1171202659606934 seconds for one epoch ---
--- 0.31026339530944824 seconds for one epoch ---
--- 1.1323540210723877 seconds for one epoch ---
--- 0.3076603412628174 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.420968]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.611939]
 [ -0.      ]]
--- 0.2822530269622803 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4513.0185546875, (1585.6149, 2.0471869, 2925.1448, 0.21198492)
   validation loss 955.5347290039062, (643.868, 0.40514523, 311.04962, 0.21198492)
decoder loss ratio: 24944.563386, decoder SINDy loss  ratio: 0.671444
--- 0.3007216453552246 seconds for one epoch ---
--- 1.1046743392944336 seconds for one epoch ---
--- 0.32153749465942383 seconds for one epoch ---
--- 1.1190030574798584 seconds for one epoch ---
--- 0.3104691505432129 seconds for one epoch ---
--- 1.1213645935058594 seconds for one epoch ---
--- 0.304166316986084 seconds for one epoch ---
--- 1.123600721359253 seconds for one epoch ---
--- 0.3078138828277588 seconds for one epoch ---
--- 1.1520414352416992 seconds for one epoch ---
--- 0.3158249855041504 seconds for one epoch ---
--- 1.1481480598449707 seconds for one epoch ---
--- 0.30878567695617676 seconds for one epoch ---
--- 1.1272783279418945 seconds for one epoch ---
--- 0.321840763092041 seconds for one epoch ---
--- 1.1388304233551025 seconds for one epoch ---
--- 0.31847143173217773 seconds for one epoch ---
--- 1.1003844738006592 seconds for one epoch ---
--- 0.30304694175720215 seconds for one epoch ---
--- 1.110459804534912 seconds for one epoch ---
--- 0.30785417556762695 seconds for one epoch ---
--- 1.1297252178192139 seconds for one epoch ---
--- 0.3047823905944824 seconds for one epoch ---
--- 1.1468303203582764 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4207558]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.736829]
 [ -0.      ]]
--- 0.3114771842956543 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3003.36083984375, (1538.175, 1.1655464, 1463.8066, 0.21354882)
   validation loss 843.2719116210938, (511.6688, 0.48579046, 330.90378, 0.21354882)
decoder loss ratio: 19822.937326, decoder SINDy loss  ratio: 0.714302
--- 0.2659451961517334 seconds for one epoch ---
--- 0.3243374824523926 seconds for one epoch ---
--- 1.1129813194274902 seconds for one epoch ---
--- 0.3286924362182617 seconds for one epoch ---
--- 1.1338605880737305 seconds for one epoch ---
--- 0.32978057861328125 seconds for one epoch ---
--- 1.1488416194915771 seconds for one epoch ---
--- 0.3193848133087158 seconds for one epoch ---
--- 1.1571154594421387 seconds for one epoch ---
--- 0.34013795852661133 seconds for one epoch ---
--- 1.1500048637390137 seconds for one epoch ---
--- 0.32826924324035645 seconds for one epoch ---
--- 1.151496171951294 seconds for one epoch ---
--- 0.3561129570007324 seconds for one epoch ---
--- 1.1447725296020508 seconds for one epoch ---
--- 0.3479180335998535 seconds for one epoch ---
--- 1.1406939029693604 seconds for one epoch ---
--- 0.3292505741119385 seconds for one epoch ---
--- 1.1496694087982178 seconds for one epoch ---
--- 0.3056492805480957 seconds for one epoch ---
--- 1.140273094177246 seconds for one epoch ---
--- 0.3007822036743164 seconds for one epoch ---
--- 1.1190998554229736 seconds for one epoch ---
--- 0.3037586212158203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.42029327]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.888488]
 [ -0.      ]]
--- 0.2771124839782715 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3816.052734375, (1769.8185, 0.6671114, 2045.3517, 0.21542464)
   validation loss 986.3677978515625, (670.3767, 0.5583619, 315.2173, 0.21542464)
decoder loss ratio: 25971.557531, decoder SINDy loss  ratio: 0.680441
--- 0.3021509647369385 seconds for one epoch ---
--- 1.1466751098632812 seconds for one epoch ---
--- 0.30240416526794434 seconds for one epoch ---
--- 1.1623878479003906 seconds for one epoch ---
--- 0.30261683464050293 seconds for one epoch ---
--- 1.1853060722351074 seconds for one epoch ---
--- 0.30358123779296875 seconds for one epoch ---
--- 1.1857779026031494 seconds for one epoch ---
--- 0.31073522567749023 seconds for one epoch ---
--- 1.1603569984436035 seconds for one epoch ---
--- 0.32027292251586914 seconds for one epoch ---
--- 1.1469290256500244 seconds for one epoch ---
--- 0.30062222480773926 seconds for one epoch ---
--- 1.1876153945922852 seconds for one epoch ---
--- 0.3025050163269043 seconds for one epoch ---
--- 1.167752981185913 seconds for one epoch ---
--- 0.30310964584350586 seconds for one epoch ---
--- 1.164612054824829 seconds for one epoch ---
--- 0.30774831771850586 seconds for one epoch ---
--- 1.1694610118865967 seconds for one epoch ---
--- 0.3056652545928955 seconds for one epoch ---
--- 1.1426191329956055 seconds for one epoch ---
--- 0.31480908393859863 seconds for one epoch ---
--- 1.1305654048919678 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41972905]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.016344]
 [  0.      ]]
--- 0.3123354911804199 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2079.6748046875, (711.6578, 1.1909182, 1366.609, 0.21699707)
   validation loss 1243.24365234375, (902.33154, 0.4206433, 340.27444, 0.21699707)
decoder loss ratio: 34957.890491, decoder SINDy loss  ratio: 0.734530
--- 0.3025176525115967 seconds for one epoch ---
--- 0.3168511390686035 seconds for one epoch ---
--- 1.1779608726501465 seconds for one epoch ---
--- 0.30853891372680664 seconds for one epoch ---
--- 1.1726155281066895 seconds for one epoch ---
--- 0.30674123764038086 seconds for one epoch ---
--- 1.177145004272461 seconds for one epoch ---
--- 0.3107314109802246 seconds for one epoch ---
--- 1.1704914569854736 seconds for one epoch ---
--- 0.32497191429138184 seconds for one epoch ---
--- 1.1758337020874023 seconds for one epoch ---
--- 0.3258953094482422 seconds for one epoch ---
--- 1.171806812286377 seconds for one epoch ---
--- 0.31558847427368164 seconds for one epoch ---
--- 1.150620460510254 seconds for one epoch ---
--- 0.3294646739959717 seconds for one epoch ---
--- 1.1548287868499756 seconds for one epoch ---
--- 0.31289124488830566 seconds for one epoch ---
--- 1.1829509735107422 seconds for one epoch ---
--- 0.32642579078674316 seconds for one epoch ---
--- 1.157106876373291 seconds for one epoch ---
--- 0.3089776039123535 seconds for one epoch ---
--- 1.164109706878662 seconds for one epoch ---
--- 0.30866336822509766 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41899306]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.146247]
 [  0.      ]]
--- 0.28620243072509766 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3558.336181640625, (1266.8588, 2.6559777, 2288.603, 0.21855326)
   validation loss 976.5779418945312, (596.47534, 0.7119542, 379.1721, 0.21855326)
decoder loss ratio: 23108.490268, decoder SINDy loss  ratio: 0.818496
--- 0.3104722499847412 seconds for one epoch ---
--- 1.1705517768859863 seconds for one epoch ---
--- 0.3310973644256592 seconds for one epoch ---
--- 1.173095464706421 seconds for one epoch ---
--- 0.31157469749450684 seconds for one epoch ---
--- 1.1856510639190674 seconds for one epoch ---
--- 0.33292722702026367 seconds for one epoch ---
--- 1.187035083770752 seconds for one epoch ---
--- 0.32128262519836426 seconds for one epoch ---
--- 1.1930387020111084 seconds for one epoch ---
--- 0.3215794563293457 seconds for one epoch ---
--- 1.2004663944244385 seconds for one epoch ---
--- 0.32286882400512695 seconds for one epoch ---
--- 1.185166597366333 seconds for one epoch ---
--- 0.3161487579345703 seconds for one epoch ---
--- 1.1907598972320557 seconds for one epoch ---
--- 0.3342399597167969 seconds for one epoch ---
--- 1.2256832122802734 seconds for one epoch ---
--- 0.33480310440063477 seconds for one epoch ---
--- 1.1661429405212402 seconds for one epoch ---
--- 0.30974674224853516 seconds for one epoch ---
--- 1.1853840351104736 seconds for one epoch ---
--- 0.3028383255004883 seconds for one epoch ---
--- 1.1918692588806152 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41807163]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.279045]
 [  0.      ]]
--- 0.29953789710998535 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2807.215576171875, (1290.2072, 1.5980568, 1515.1904, 0.2200541)
   validation loss 948.7791137695312, (607.0606, 0.597209, 340.90125, 0.2200541)
decoder loss ratio: 23518.581854, decoder SINDy loss  ratio: 0.735883
--- 0.2760813236236572 seconds for one epoch ---
--- 0.31702184677124023 seconds for one epoch ---
--- 1.1788933277130127 seconds for one epoch ---
--- 0.3323216438293457 seconds for one epoch ---
--- 1.1627817153930664 seconds for one epoch ---
--- 0.324329137802124 seconds for one epoch ---
--- 1.161531686782837 seconds for one epoch ---
--- 0.3063786029815674 seconds for one epoch ---
--- 1.1752715110778809 seconds for one epoch ---
--- 0.30030155181884766 seconds for one epoch ---
--- 1.1544926166534424 seconds for one epoch ---
--- 0.28850817680358887 seconds for one epoch ---
--- 1.1686506271362305 seconds for one epoch ---
--- 0.3044610023498535 seconds for one epoch ---
--- 1.1850612163543701 seconds for one epoch ---
--- 0.30439066886901855 seconds for one epoch ---
--- 1.182267189025879 seconds for one epoch ---
--- 0.3055093288421631 seconds for one epoch ---
--- 1.1806950569152832 seconds for one epoch ---
--- 0.3047013282775879 seconds for one epoch ---
--- 1.1867403984069824 seconds for one epoch ---
--- 0.31115031242370605 seconds for one epoch ---
--- 1.200286865234375 seconds for one epoch ---
--- 0.3074305057525635 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41721725]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.384586]
 [ -0.      ]]
--- 0.2637927532196045 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2393.83544921875, (1311.0127, 0.87405634, 1081.7277, 0.22128163)
   validation loss 1298.129638671875, (903.7757, 0.7053196, 393.4273, 0.22128163)
decoder loss ratio: 35013.839479, decoder SINDy loss  ratio: 0.849268
--- 0.29659104347229004 seconds for one epoch ---
--- 1.1485862731933594 seconds for one epoch ---
--- 0.3002438545227051 seconds for one epoch ---
--- 1.167219877243042 seconds for one epoch ---
--- 0.3067657947540283 seconds for one epoch ---
--- 1.165287971496582 seconds for one epoch ---
--- 0.3118886947631836 seconds for one epoch ---
--- 1.169386386871338 seconds for one epoch ---
--- 0.3054828643798828 seconds for one epoch ---
--- 1.170543909072876 seconds for one epoch ---
--- 0.3100605010986328 seconds for one epoch ---
--- 1.1907958984375 seconds for one epoch ---
--- 0.30000948905944824 seconds for one epoch ---
--- 1.1826097965240479 seconds for one epoch ---
--- 0.30396223068237305 seconds for one epoch ---
--- 1.1821389198303223 seconds for one epoch ---
--- 0.3075730800628662 seconds for one epoch ---
--- 1.186647891998291 seconds for one epoch ---
--- 0.3012866973876953 seconds for one epoch ---
--- 1.1756184101104736 seconds for one epoch ---
--- 0.3044266700744629 seconds for one epoch ---
--- 1.1901700496673584 seconds for one epoch ---
--- 0.30637025833129883 seconds for one epoch ---
--- 1.1947910785675049 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41630042]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.485423]
 [ -0.      ]]
--- 0.30089402198791504 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3127.0927734375, (1350.8514, 0.9679217, 1775.051, 0.22240117)
   validation loss 921.424560546875, (565.61206, 0.66076183, 354.92935, 0.22240117)
decoder loss ratio: 21912.793171, decoder SINDy loss  ratio: 0.766165
--- 0.26639628410339355 seconds for one epoch ---
--- 0.30248355865478516 seconds for one epoch ---
--- 1.200122356414795 seconds for one epoch ---
--- 0.30347633361816406 seconds for one epoch ---
--- 1.1840436458587646 seconds for one epoch ---
--- 0.30215907096862793 seconds for one epoch ---
--- 1.2125051021575928 seconds for one epoch ---
--- 0.3108055591583252 seconds for one epoch ---
--- 1.1641595363616943 seconds for one epoch ---
--- 0.29880332946777344 seconds for one epoch ---
--- 1.1640841960906982 seconds for one epoch ---
--- 0.31112241744995117 seconds for one epoch ---
--- 1.242835283279419 seconds for one epoch ---
--- 0.3141441345214844 seconds for one epoch ---
--- 1.2152090072631836 seconds for one epoch ---
--- 0.3036501407623291 seconds for one epoch ---
--- 1.2651746273040771 seconds for one epoch ---
--- 0.30382251739501953 seconds for one epoch ---
--- 1.2216744422912598 seconds for one epoch ---
--- 0.3078920841217041 seconds for one epoch ---
--- 1.2274680137634277 seconds for one epoch ---
--- 0.30655550956726074 seconds for one epoch ---
--- 1.2200324535369873 seconds for one epoch ---
--- 0.3069939613342285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41525754]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.588863]
 [ -0.      ]]
--- 0.27622175216674805 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2208.26904296875, (1347.7568, 1.2697607, 859.0188, 0.22359839)
   validation loss 1105.10009765625, (767.5938, 0.4812799, 336.80145, 0.22359839)
decoder loss ratio: 29737.916841, decoder SINDy loss  ratio: 0.727033
--- 0.30591702461242676 seconds for one epoch ---
--- 1.2142765522003174 seconds for one epoch ---
--- 0.30665016174316406 seconds for one epoch ---
--- 1.2160818576812744 seconds for one epoch ---
--- 0.317058801651001 seconds for one epoch ---
--- 1.2313971519470215 seconds for one epoch ---
--- 0.3090851306915283 seconds for one epoch ---
--- 1.1699392795562744 seconds for one epoch ---
--- 0.3034682273864746 seconds for one epoch ---
--- 1.2025432586669922 seconds for one epoch ---
--- 0.3063211441040039 seconds for one epoch ---
--- 1.2324702739715576 seconds for one epoch ---
--- 0.3043351173400879 seconds for one epoch ---
--- 1.198986530303955 seconds for one epoch ---
--- 0.3063933849334717 seconds for one epoch ---
--- 1.208188772201538 seconds for one epoch ---
--- 0.3070642948150635 seconds for one epoch ---
--- 1.2070066928863525 seconds for one epoch ---
--- 0.3089315891265869 seconds for one epoch ---
--- 1.2172198295593262 seconds for one epoch ---
--- 0.3089439868927002 seconds for one epoch ---
--- 1.214477300643921 seconds for one epoch ---
--- 0.3041970729827881 seconds for one epoch ---
--- 1.2388603687286377 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41396022]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.705352]
 [  0.      ]]
--- 0.29836153984069824 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3563.861328125, (1410.8344, 2.1172535, 2150.6848, 0.22482128)
   validation loss 973.3115844726562, (622.38, 0.56491995, 350.1418, 0.22482128)
decoder loss ratio: 24112.081888, decoder SINDy loss  ratio: 0.755830
THRESHOLDING: 1 active coefficients
--- 1.2258682250976562 seconds for one epoch ---
--- 0.3135693073272705 seconds for one epoch ---
--- 1.2079243659973145 seconds for one epoch ---
--- 0.3114175796508789 seconds for one epoch ---
--- 1.2392141819000244 seconds for one epoch ---
--- 0.31894588470458984 seconds for one epoch ---
--- 1.231999397277832 seconds for one epoch ---
--- 0.3086075782775879 seconds for one epoch ---
--- 1.2362909317016602 seconds for one epoch ---
--- 0.32532358169555664 seconds for one epoch ---
--- 1.240239143371582 seconds for one epoch ---
--- 0.31798315048217773 seconds for one epoch ---
--- 1.191856861114502 seconds for one epoch ---
--- 0.3184034824371338 seconds for one epoch ---
--- 1.2314338684082031 seconds for one epoch ---
--- 0.30900049209594727 seconds for one epoch ---
--- 1.2329530715942383 seconds for one epoch ---
--- 0.3041541576385498 seconds for one epoch ---
--- 1.2150421142578125 seconds for one epoch ---
--- 0.30454254150390625 seconds for one epoch ---
--- 1.2097947597503662 seconds for one epoch ---
--- 0.30713415145874023 seconds for one epoch ---
--- 1.2377023696899414 seconds for one epoch ---
--- 0.31809544563293457 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41276282]
 [0.        ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-13.8037405]
 [  0.       ]]
--- 0.27708911895751953 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3418.5595703125, (1194.3906, 1.4382955, 2222.5044, 0.22596052)
   validation loss 967.5641479492188, (641.0027, 0.4400913, 325.89545, 0.22596052)
decoder loss ratio: 24833.556868, decoder SINDy loss  ratio: 0.703491
--- 0.31420326232910156 seconds for one epoch ---
--- 1.2201635837554932 seconds for one epoch ---
--- 0.30492401123046875 seconds for one epoch ---
--- 1.2543613910675049 seconds for one epoch ---
--- 0.307908296585083 seconds for one epoch ---
--- 1.2580342292785645 seconds for one epoch ---
--- 0.3100407123565674 seconds for one epoch ---
--- 1.232858419418335 seconds for one epoch ---
--- 0.30562806129455566 seconds for one epoch ---
--- 1.235530138015747 seconds for one epoch ---
--- 0.304795503616333 seconds for one epoch ---
--- 1.2431390285491943 seconds for one epoch ---
--- 0.30895376205444336 seconds for one epoch ---
--- 1.2416086196899414 seconds for one epoch ---
--- 0.3075988292694092 seconds for one epoch ---
--- 1.250521183013916 seconds for one epoch ---
--- 0.3120992183685303 seconds for one epoch ---
--- 1.2748522758483887 seconds for one epoch ---
--- 0.3161005973815918 seconds for one epoch ---
--- 1.2404649257659912 seconds for one epoch ---
--- 0.3077504634857178 seconds for one epoch ---
--- 1.2520170211791992 seconds for one epoch ---
--- 0.3023371696472168 seconds for one epoch ---
--- 1.224942922592163 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.41152772]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.898033]
 [  0.      ]]
--- 0.31620049476623535 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3526.173583984375, (1636.4506, 1.0406132, 1888.4554, 0.22689109)
   validation loss 976.6804809570312, (625.95764, 0.69031847, 349.80563, 0.22689109)
decoder loss ratio: 24250.685746, decoder SINDy loss  ratio: 0.755105
--- 0.3145720958709717 seconds for one epoch ---
--- 0.32172131538391113 seconds for one epoch ---
--- 1.2564830780029297 seconds for one epoch ---
--- 0.33058857917785645 seconds for one epoch ---
--- 1.2517590522766113 seconds for one epoch ---
--- 0.3215982913970947 seconds for one epoch ---
--- 1.2244338989257812 seconds for one epoch ---
--- 0.32957911491394043 seconds for one epoch ---
--- 1.2685770988464355 seconds for one epoch ---
--- 0.33928537368774414 seconds for one epoch ---
--- 1.2946186065673828 seconds for one epoch ---
--- 0.3245542049407959 seconds for one epoch ---
--- 1.2664246559143066 seconds for one epoch ---
--- 0.33202528953552246 seconds for one epoch ---
--- 1.25960111618042 seconds for one epoch ---
--- 0.3274228572845459 seconds for one epoch ---
--- 1.280350923538208 seconds for one epoch ---
--- 0.33922481536865234 seconds for one epoch ---
--- 1.2712457180023193 seconds for one epoch ---
--- 0.32916903495788574 seconds for one epoch ---
--- 1.2608246803283691 seconds for one epoch ---
--- 0.32999181747436523 seconds for one epoch ---
--- 1.2741615772247314 seconds for one epoch ---
--- 0.3254566192626953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40973446]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.024815]
 [ -0.      ]]
--- 0.2710082530975342 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3314.5361328125, (860.81683, 2.131945, 2451.3591, 0.22819968)
   validation loss 1219.8218994140625, (874.48004, 0.4918182, 344.62195, 0.22819968)
decoder loss ratio: 33878.874972, decoder SINDy loss  ratio: 0.743915
--- 0.30236077308654785 seconds for one epoch ---
--- 1.2330529689788818 seconds for one epoch ---
--- 0.30686283111572266 seconds for one epoch ---
--- 1.2359459400177002 seconds for one epoch ---
--- 0.3058052062988281 seconds for one epoch ---
--- 1.2474825382232666 seconds for one epoch ---
--- 0.31391286849975586 seconds for one epoch ---
--- 1.2314441204071045 seconds for one epoch ---
--- 0.3025071620941162 seconds for one epoch ---
--- 1.2820799350738525 seconds for one epoch ---
--- 0.3014700412750244 seconds for one epoch ---
--- 1.2850453853607178 seconds for one epoch ---
--- 0.3045828342437744 seconds for one epoch ---
--- 1.2494781017303467 seconds for one epoch ---
--- 0.30708909034729004 seconds for one epoch ---
--- 1.2867047786712646 seconds for one epoch ---
--- 0.3273754119873047 seconds for one epoch ---
--- 1.269423007965088 seconds for one epoch ---
--- 0.30939292907714844 seconds for one epoch ---
--- 1.2560606002807617 seconds for one epoch ---
--- 0.30475759506225586 seconds for one epoch ---
--- 1.262782096862793 seconds for one epoch ---
--- 0.30648326873779297 seconds for one epoch ---
--- 1.2574408054351807 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40838367]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.113847]
 [ -0.      ]]
--- 0.29701852798461914 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3370.92724609375, (1315.6373, 1.8514982, 2053.2095, 0.22907606)
   validation loss 952.2955322265625, (566.2096, 0.7793483, 385.0775, 0.22907606)
decoder loss ratio: 21935.942683, decoder SINDy loss  ratio: 0.831244
--- 0.2770411968231201 seconds for one epoch ---
--- 0.3057401180267334 seconds for one epoch ---
--- 1.3022818565368652 seconds for one epoch ---
--- 0.30831074714660645 seconds for one epoch ---
--- 1.3128132820129395 seconds for one epoch ---
--- 0.31037259101867676 seconds for one epoch ---
--- 1.2942640781402588 seconds for one epoch ---
--- 0.3110673427581787 seconds for one epoch ---
--- 1.312398910522461 seconds for one epoch ---
--- 0.31998562812805176 seconds for one epoch ---
--- 1.287430763244629 seconds for one epoch ---
--- 0.3058319091796875 seconds for one epoch ---
--- 1.28779935836792 seconds for one epoch ---
--- 0.3133385181427002 seconds for one epoch ---
--- 1.3208551406860352 seconds for one epoch ---
--- 0.30962252616882324 seconds for one epoch ---
--- 1.2981164455413818 seconds for one epoch ---
--- 0.32127904891967773 seconds for one epoch ---
--- 1.300269365310669 seconds for one epoch ---
--- 0.3145763874053955 seconds for one epoch ---
--- 1.302994728088379 seconds for one epoch ---
--- 0.307206392288208 seconds for one epoch ---
--- 1.3034508228302002 seconds for one epoch ---
--- 0.3067295551300049 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40716383]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.190264]
 [ -0.      ]]
--- 0.27992749214172363 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6207.08544921875, (1178.1897, 1.4954615, 5027.1704, 0.22984591)
   validation loss 1218.9229736328125, (800.99194, 0.758728, 416.9425, 0.22984591)
decoder loss ratio: 31031.818469, decoder SINDy loss  ratio: 0.900029
--- 0.30448102951049805 seconds for one epoch ---
--- 1.2854065895080566 seconds for one epoch ---
--- 0.3091707229614258 seconds for one epoch ---
--- 1.3117413520812988 seconds for one epoch ---
--- 0.3144228458404541 seconds for one epoch ---
--- 1.299379825592041 seconds for one epoch ---
--- 0.30837082862854004 seconds for one epoch ---
--- 1.3009076118469238 seconds for one epoch ---
--- 0.309706449508667 seconds for one epoch ---
--- 1.2957563400268555 seconds for one epoch ---
--- 0.297518253326416 seconds for one epoch ---
--- 1.307723045349121 seconds for one epoch ---
--- 0.3046748638153076 seconds for one epoch ---
--- 1.2735209465026855 seconds for one epoch ---
--- 0.3006737232208252 seconds for one epoch ---
--- 1.284925937652588 seconds for one epoch ---
--- 0.31548190116882324 seconds for one epoch ---
--- 1.2923972606658936 seconds for one epoch ---
--- 0.32176733016967773 seconds for one epoch ---
--- 1.3017432689666748 seconds for one epoch ---
--- 0.30915069580078125 seconds for one epoch ---
--- 1.3214001655578613 seconds for one epoch ---
--- 0.3124210834503174 seconds for one epoch ---
--- 1.295530080795288 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4056026]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.283433]
 [  0.      ]]
--- 0.3161590099334717 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8178.22998046875, (2047.3185, 9.281973, 6121.3984, 0.23077948)
   validation loss 1332.9888916015625, (948.434, 0.69850904, 383.6255, 0.23077948)
decoder loss ratio: 36743.980527, decoder SINDy loss  ratio: 0.828110
--- 0.2733433246612549 seconds for one epoch ---
--- 0.3144083023071289 seconds for one epoch ---
--- 1.3006975650787354 seconds for one epoch ---
--- 0.3212573528289795 seconds for one epoch ---
--- 1.3027982711791992 seconds for one epoch ---
--- 0.30606818199157715 seconds for one epoch ---
--- 1.2792291641235352 seconds for one epoch ---
--- 0.30640554428100586 seconds for one epoch ---
--- 1.304863452911377 seconds for one epoch ---
--- 0.3048985004425049 seconds for one epoch ---
--- 1.2795195579528809 seconds for one epoch ---
--- 0.3086507320404053 seconds for one epoch ---
--- 1.3161981105804443 seconds for one epoch ---
--- 0.3092513084411621 seconds for one epoch ---
--- 1.320089340209961 seconds for one epoch ---
--- 0.308077335357666 seconds for one epoch ---
--- 1.318199634552002 seconds for one epoch ---
--- 0.3238353729248047 seconds for one epoch ---
--- 1.322901725769043 seconds for one epoch ---
--- 0.3151435852050781 seconds for one epoch ---
--- 1.2956891059875488 seconds for one epoch ---
--- 0.3035850524902344 seconds for one epoch ---
--- 1.3024990558624268 seconds for one epoch ---
--- 0.3034372329711914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40394956]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.377133]
 [  0.      ]]
--- 0.26924586296081543 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3172.263916015625, (1263.3276, 1.1584203, 1907.5461, 0.23160365)
   validation loss 1080.6949462890625, (737.09906, 0.5658451, 342.7985, 0.23160365)
decoder loss ratio: 28556.497247, decoder SINDy loss  ratio: 0.739979
--- 0.3177969455718994 seconds for one epoch ---
--- 1.3168163299560547 seconds for one epoch ---
--- 0.30468034744262695 seconds for one epoch ---
--- 1.2936174869537354 seconds for one epoch ---
--- 0.30632805824279785 seconds for one epoch ---
--- 1.3305261135101318 seconds for one epoch ---
--- 0.3206000328063965 seconds for one epoch ---
--- 1.3284788131713867 seconds for one epoch ---
--- 0.31310057640075684 seconds for one epoch ---
--- 1.3169283866882324 seconds for one epoch ---
--- 0.30377650260925293 seconds for one epoch ---
--- 1.3221063613891602 seconds for one epoch ---
--- 0.3045053482055664 seconds for one epoch ---
--- 1.3165626525878906 seconds for one epoch ---
--- 0.3028080463409424 seconds for one epoch ---
--- 1.3324065208435059 seconds for one epoch ---
--- 0.3028888702392578 seconds for one epoch ---
--- 1.3055939674377441 seconds for one epoch ---
--- 0.31729626655578613 seconds for one epoch ---
--- 1.324352741241455 seconds for one epoch ---
--- 0.31226277351379395 seconds for one epoch ---
--- 1.332430124282837 seconds for one epoch ---
--- 0.3123655319213867 seconds for one epoch ---
--- 1.340829610824585 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.4026538]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.447494]
 [  0.      ]]
--- 0.3027763366699219 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3696.958740234375, (1855.6686, 1.1634567, 1839.8945, 0.23226714)
   validation loss 1029.9580078125, (666.0384, 0.47737426, 363.20996, 0.23226714)
decoder loss ratio: 25803.483565, decoder SINDy loss  ratio: 0.784040
--- 0.27228426933288574 seconds for one epoch ---
--- 0.3015899658203125 seconds for one epoch ---
--- 1.3245697021484375 seconds for one epoch ---
--- 0.31204962730407715 seconds for one epoch ---
--- 1.311798095703125 seconds for one epoch ---
--- 0.30002593994140625 seconds for one epoch ---
--- 1.297548532485962 seconds for one epoch ---
--- 0.3070518970489502 seconds for one epoch ---
--- 1.2975354194641113 seconds for one epoch ---
--- 0.3127155303955078 seconds for one epoch ---
--- 1.3032441139221191 seconds for one epoch ---
--- 0.3023676872253418 seconds for one epoch ---
--- 1.2995960712432861 seconds for one epoch ---
--- 0.3056824207305908 seconds for one epoch ---
--- 1.2953598499298096 seconds for one epoch ---
--- 0.3028695583343506 seconds for one epoch ---
--- 1.3093845844268799 seconds for one epoch ---
--- 0.30408406257629395 seconds for one epoch ---
--- 1.295276403427124 seconds for one epoch ---
--- 0.2923927307128906 seconds for one epoch ---
--- 1.3262298107147217 seconds for one epoch ---
--- 0.3033156394958496 seconds for one epoch ---
--- 1.31681227684021 seconds for one epoch ---
--- 0.3074831962585449 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40151238]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.507514]
 [ -0.      ]]
--- 0.26523828506469727 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4750.169921875, (1550.36, 3.3966186, 3196.1804, 0.2327801)
   validation loss 919.8527221679688, (569.9989, 0.665218, 348.9558, 0.2327801)
decoder loss ratio: 22082.747001, decoder SINDy loss  ratio: 0.753270
--- 0.31057286262512207 seconds for one epoch ---
--- 1.3395237922668457 seconds for one epoch ---
--- 0.31105518341064453 seconds for one epoch ---
--- 1.3525865077972412 seconds for one epoch ---
--- 0.30991697311401367 seconds for one epoch ---
--- 1.3609976768493652 seconds for one epoch ---
--- 0.31539058685302734 seconds for one epoch ---
--- 1.3413314819335938 seconds for one epoch ---
--- 0.30581116676330566 seconds for one epoch ---
--- 1.3372056484222412 seconds for one epoch ---
--- 0.3133525848388672 seconds for one epoch ---
--- 1.356337547302246 seconds for one epoch ---
--- 0.31781482696533203 seconds for one epoch ---
--- 1.3430192470550537 seconds for one epoch ---
--- 0.30917811393737793 seconds for one epoch ---
--- 1.333754301071167 seconds for one epoch ---
--- 0.3074324131011963 seconds for one epoch ---
--- 1.3273818492889404 seconds for one epoch ---
--- 0.3072960376739502 seconds for one epoch ---
--- 1.3251185417175293 seconds for one epoch ---
--- 0.31188249588012695 seconds for one epoch ---
--- 1.3501722812652588 seconds for one epoch ---
--- 0.3128318786621094 seconds for one epoch ---
--- 1.346313714981079 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40015596]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.576669]
 [ -0.      ]]
--- 0.30257320404052734 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3160.4423828125, (2122.757, 1.2041292, 1036.2478, 0.2334342)
   validation loss 915.6630249023438, (534.41943, 0.73752093, 380.27258, 0.2334342)
decoder loss ratio: 20704.336650, decoder SINDy loss  ratio: 0.820872
--- 0.26817846298217773 seconds for one epoch ---
--- 0.3137640953063965 seconds for one epoch ---
--- 1.3504974842071533 seconds for one epoch ---
--- 0.32796478271484375 seconds for one epoch ---
--- 1.343604564666748 seconds for one epoch ---
--- 0.30744457244873047 seconds for one epoch ---
--- 1.3401870727539062 seconds for one epoch ---
--- 0.3098447322845459 seconds for one epoch ---
--- 1.3211157321929932 seconds for one epoch ---
--- 0.556969165802002 seconds for one epoch ---
--- 1.3622636795043945 seconds for one epoch ---
--- 0.3147916793823242 seconds for one epoch ---
--- 1.3460111618041992 seconds for one epoch ---
--- 0.31186342239379883 seconds for one epoch ---
--- 1.3420970439910889 seconds for one epoch ---
--- 0.3083333969116211 seconds for one epoch ---
--- 1.3483190536499023 seconds for one epoch ---
--- 0.30353522300720215 seconds for one epoch ---
--- 1.3498589992523193 seconds for one epoch ---
--- 0.31589293479919434 seconds for one epoch ---
--- 1.370551347732544 seconds for one epoch ---
--- 0.3086254596710205 seconds for one epoch ---
--- 1.3470149040222168 seconds for one epoch ---
--- 0.309326171875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39881998]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.642659]
 [ -0.      ]]
--- 0.2688107490539551 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4855.7470703125, (1396.3535, 1.146459, 3458.0132, 0.23402332)
   validation loss 1011.331787109375, (662.3994, 0.6208326, 348.07748, 0.23402332)
decoder loss ratio: 25662.503277, decoder SINDy loss  ratio: 0.751374
--- 0.2992112636566162 seconds for one epoch ---
--- 1.3444511890411377 seconds for one epoch ---
--- 0.30318427085876465 seconds for one epoch ---
--- 1.3632316589355469 seconds for one epoch ---
--- 0.3100166320800781 seconds for one epoch ---
--- 1.3747684955596924 seconds for one epoch ---
--- 0.31212902069091797 seconds for one epoch ---
--- 1.3729701042175293 seconds for one epoch ---
--- 0.3109440803527832 seconds for one epoch ---
--- 1.3763096332550049 seconds for one epoch ---
--- 0.3135700225830078 seconds for one epoch ---
--- 1.3934252262115479 seconds for one epoch ---
--- 0.31442832946777344 seconds for one epoch ---
--- 1.3790178298950195 seconds for one epoch ---
--- 0.31142282485961914 seconds for one epoch ---
--- 1.3728156089782715 seconds for one epoch ---
--- 0.2992725372314453 seconds for one epoch ---
--- 1.36045503616333 seconds for one epoch ---
--- 0.3076965808868408 seconds for one epoch ---
--- 1.3885600566864014 seconds for one epoch ---
--- 0.3055455684661865 seconds for one epoch ---
--- 1.3738138675689697 seconds for one epoch ---
--- 0.30152201652526855 seconds for one epoch ---
--- 1.3775999546051025 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39709872]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.724895]
 [  0.      ]]
--- 0.3014218807220459 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3520.069580078125, (1451.1986, 0.99457186, 2067.6418, 0.2347277)
   validation loss 862.9537353515625, (502.53708, 0.70225143, 359.4797, 0.2347277)
decoder loss ratio: 19469.158878, decoder SINDy loss  ratio: 0.775988
--- 0.26335644721984863 seconds for one epoch ---
--- 0.3143589496612549 seconds for one epoch ---
--- 1.3382823467254639 seconds for one epoch ---
--- 0.30355286598205566 seconds for one epoch ---
--- 1.378427505493164 seconds for one epoch ---
--- 0.30903196334838867 seconds for one epoch ---
--- 1.391772985458374 seconds for one epoch ---
--- 0.3332479000091553 seconds for one epoch ---
--- 1.3810145854949951 seconds for one epoch ---
--- 0.3249673843383789 seconds for one epoch ---
--- 1.3525142669677734 seconds for one epoch ---
--- 0.33307981491088867 seconds for one epoch ---
--- 1.3840279579162598 seconds for one epoch ---
--- 0.33703088760375977 seconds for one epoch ---
--- 1.3628966808319092 seconds for one epoch ---
--- 0.327376127243042 seconds for one epoch ---
--- 1.3699378967285156 seconds for one epoch ---
--- 0.32640743255615234 seconds for one epoch ---
--- 1.354339838027954 seconds for one epoch ---
--- 0.33201098442077637 seconds for one epoch ---
--- 1.391465187072754 seconds for one epoch ---
--- 0.32797932624816895 seconds for one epoch ---
--- 1.395439863204956 seconds for one epoch ---
--- 0.33703136444091797 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39541408]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.802672]
 [  0.      ]]
--- 0.26549792289733887 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7662.716796875, (1282.6112, 0.82463807, 6379.046, 0.23538743)
   validation loss 961.6472778320312, (563.162, 0.9061192, 397.34378, 0.23538743)
decoder loss ratio: 21817.873080, decoder SINDy loss  ratio: 0.857722
--- 0.3051295280456543 seconds for one epoch ---
--- 1.3320870399475098 seconds for one epoch ---
--- 0.30942773818969727 seconds for one epoch ---
--- 1.3756263256072998 seconds for one epoch ---
--- 0.30353236198425293 seconds for one epoch ---
--- 1.3802499771118164 seconds for one epoch ---
--- 0.31368136405944824 seconds for one epoch ---
--- 1.381403923034668 seconds for one epoch ---
--- 0.3121457099914551 seconds for one epoch ---
--- 1.3635029792785645 seconds for one epoch ---
--- 0.30389928817749023 seconds for one epoch ---
--- 1.3659212589263916 seconds for one epoch ---
--- 0.307405948638916 seconds for one epoch ---
--- 1.3871548175811768 seconds for one epoch ---
--- 0.3155550956726074 seconds for one epoch ---
--- 1.3831615447998047 seconds for one epoch ---
--- 0.31165504455566406 seconds for one epoch ---
--- 1.4030656814575195 seconds for one epoch ---
--- 0.30644655227661133 seconds for one epoch ---
--- 1.3893206119537354 seconds for one epoch ---
--- 0.31157684326171875 seconds for one epoch ---
--- 1.3840785026550293 seconds for one epoch ---
--- 0.3137669563293457 seconds for one epoch ---
--- 1.395179033279419 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39405832]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.863471]
 [  0.      ]]
--- 0.2998387813568115 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4212.26513671875, (1116.1458, 2.8406558, 3093.0427, 0.23593326)
   validation loss 1535.531005859375, (1117.5885, 0.89192086, 416.81458, 0.23593326)
decoder loss ratio: 43297.318747, decoder SINDy loss  ratio: 0.899753
--- 0.26204371452331543 seconds for one epoch ---
--- 0.3050570487976074 seconds for one epoch ---
--- 1.3350956439971924 seconds for one epoch ---
--- 0.3029510974884033 seconds for one epoch ---
--- 1.3859844207763672 seconds for one epoch ---
--- 0.30743932723999023 seconds for one epoch ---
--- 1.393418312072754 seconds for one epoch ---
--- 0.3177988529205322 seconds for one epoch ---
--- 1.3757355213165283 seconds for one epoch ---
--- 0.3255646228790283 seconds for one epoch ---
--- 1.41279935836792 seconds for one epoch ---
--- 0.3283841609954834 seconds for one epoch ---
--- 1.4034183025360107 seconds for one epoch ---
--- 0.32010507583618164 seconds for one epoch ---
--- 1.428175687789917 seconds for one epoch ---
--- 0.3146517276763916 seconds for one epoch ---
--- 1.4230237007141113 seconds for one epoch ---
--- 0.3115222454071045 seconds for one epoch ---
--- 1.4269046783447266 seconds for one epoch ---
--- 0.31522083282470703 seconds for one epoch ---
--- 1.3943767547607422 seconds for one epoch ---
--- 0.3152940273284912 seconds for one epoch ---
--- 1.4192299842834473 seconds for one epoch ---
--- 0.3106844425201416 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3924987]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.931617]
 [ -0.      ]]
--- 0.2755274772644043 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3588.255859375, (1006.77576, 0.74039364, 2580.5032, 0.23645835)
   validation loss 1316.0943603515625, (934.219, 0.7427436, 380.89615, 0.23645835)
decoder loss ratio: 36193.265709, decoder SINDy loss  ratio: 0.822218
--- 0.30855417251586914 seconds for one epoch ---
--- 1.360851764678955 seconds for one epoch ---
--- 0.3099522590637207 seconds for one epoch ---
--- 1.3884246349334717 seconds for one epoch ---
--- 0.3117644786834717 seconds for one epoch ---
--- 1.4213948249816895 seconds for one epoch ---
--- 0.31302309036254883 seconds for one epoch ---
--- 1.4230165481567383 seconds for one epoch ---
--- 0.32486438751220703 seconds for one epoch ---
--- 1.4175159931182861 seconds for one epoch ---
--- 0.3158228397369385 seconds for one epoch ---
--- 1.4059433937072754 seconds for one epoch ---
--- 0.31951045989990234 seconds for one epoch ---
--- 1.4407613277435303 seconds for one epoch ---
--- 0.32839155197143555 seconds for one epoch ---
--- 1.40718412399292 seconds for one epoch ---
--- 0.3269181251525879 seconds for one epoch ---
--- 1.419926643371582 seconds for one epoch ---
--- 0.3287637233734131 seconds for one epoch ---
--- 1.433563470840454 seconds for one epoch ---
--- 0.32113170623779297 seconds for one epoch ---
--- 1.443697452545166 seconds for one epoch ---
--- 0.31436800956726074 seconds for one epoch ---
--- 1.436976432800293 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3911108]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.990796]
 [ -0.      ]]
--- 0.3043642044067383 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3270.85498046875, (1531.784, 1.0146898, 1737.8195, 0.2369354)
   validation loss 884.6058349609375, (550.8627, 0.7537907, 332.7524, 0.2369354)
decoder loss ratio: 21341.376210, decoder SINDy loss  ratio: 0.718293
--- 0.26914525032043457 seconds for one epoch ---
--- 0.30454373359680176 seconds for one epoch ---
--- 1.3690338134765625 seconds for one epoch ---
--- 0.31801843643188477 seconds for one epoch ---
--- 1.3849220275878906 seconds for one epoch ---
--- 0.31424403190612793 seconds for one epoch ---
--- 1.3919463157653809 seconds for one epoch ---
--- 0.3065922260284424 seconds for one epoch ---
--- 1.4415898323059082 seconds for one epoch ---
--- 0.32000041007995605 seconds for one epoch ---
--- 1.397679328918457 seconds for one epoch ---
--- 0.3094820976257324 seconds for one epoch ---
--- 1.4449198246002197 seconds for one epoch ---
--- 0.31305456161499023 seconds for one epoch ---
--- 1.414475917816162 seconds for one epoch ---
--- 0.3123660087585449 seconds for one epoch ---
--- 1.4454472064971924 seconds for one epoch ---
--- 0.324296236038208 seconds for one epoch ---
--- 1.4262516498565674 seconds for one epoch ---
--- 0.31660890579223633 seconds for one epoch ---
--- 1.4454314708709717 seconds for one epoch ---
--- 0.32610440254211426 seconds for one epoch ---
--- 1.4345862865447998 seconds for one epoch ---
--- 0.3221395015716553 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.38933146]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.064748]
 [ -0.      ]]
--- 0.27028822898864746 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2757.44677734375, (1108.6576, 1.4737619, 1647.0779, 0.23752086)
   validation loss 972.9423217773438, (619.3112, 0.7626071, 352.63092, 0.23752086)
decoder loss ratio: 23993.191767, decoder SINDy loss  ratio: 0.761203
--- 0.31351661682128906 seconds for one epoch ---
--- 1.3741326332092285 seconds for one epoch ---
--- 0.30300354957580566 seconds for one epoch ---
--- 1.382868766784668 seconds for one epoch ---
--- 0.3111724853515625 seconds for one epoch ---
--- 1.409860372543335 seconds for one epoch ---
--- 0.31313109397888184 seconds for one epoch ---
--- 1.4087021350860596 seconds for one epoch ---
--- 0.3077223300933838 seconds for one epoch ---
--- 1.4069056510925293 seconds for one epoch ---
--- 0.32001590728759766 seconds for one epoch ---
--- 1.4235458374023438 seconds for one epoch ---
--- 0.30843424797058105 seconds for one epoch ---
--- 1.4318573474884033 seconds for one epoch ---
--- 0.3072326183319092 seconds for one epoch ---
--- 1.4165294170379639 seconds for one epoch ---
--- 0.3103172779083252 seconds for one epoch ---
--- 1.4294517040252686 seconds for one epoch ---
--- 0.30799341201782227 seconds for one epoch ---
--- 1.4459083080291748 seconds for one epoch ---
--- 0.3221302032470703 seconds for one epoch ---
--- 1.43623948097229 seconds for one epoch ---
--- 0.31627988815307617 seconds for one epoch ---
--- 1.4487175941467285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.38728338]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.147465]
 [  0.      ]]
--- 0.30420374870300293 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2898.46630859375, (1090.0862, 1.4813341, 1806.6608, 0.23813029)
   validation loss 989.9737548828125, (598.51135, 0.95869315, 390.26553, 0.23813029)
decoder loss ratio: 23187.368859, decoder SINDy loss  ratio: 0.842443
--- 0.26787710189819336 seconds for one epoch ---
--- 0.30773043632507324 seconds for one epoch ---
--- 1.3999097347259521 seconds for one epoch ---
--- 0.30991172790527344 seconds for one epoch ---
--- 1.4050004482269287 seconds for one epoch ---
--- 0.30530595779418945 seconds for one epoch ---
--- 1.414121150970459 seconds for one epoch ---
--- 0.3055284023284912 seconds for one epoch ---
--- 1.4400224685668945 seconds for one epoch ---
--- 0.30600738525390625 seconds for one epoch ---
--- 1.4302868843078613 seconds for one epoch ---
--- 0.3041086196899414 seconds for one epoch ---
--- 1.4172687530517578 seconds for one epoch ---
--- 0.30410099029541016 seconds for one epoch ---
--- 1.4324877262115479 seconds for one epoch ---
--- 0.31270909309387207 seconds for one epoch ---
--- 1.427884817123413 seconds for one epoch ---
--- 0.30745720863342285 seconds for one epoch ---
--- 1.3957507610321045 seconds for one epoch ---
--- 0.30184197425842285 seconds for one epoch ---
--- 1.386366844177246 seconds for one epoch ---
--- 0.3028676509857178 seconds for one epoch ---
--- 1.4035553932189941 seconds for one epoch ---
--- 0.30541110038757324 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.38568902]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.210193]
 [  0.      ]]
--- 0.296053409576416 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3089.337646484375, (1327.9755, 0.5858795, 1760.5378, 0.23864321)
   validation loss 1081.3682861328125, (710.0726, 0.8939422, 370.1632, 0.23864321)
decoder loss ratio: 27509.444133, decoder SINDy loss  ratio: 0.799049
--- 0.30779194831848145 seconds for one epoch ---
--- 1.4621365070343018 seconds for one epoch ---
--- 0.30551791191101074 seconds for one epoch ---
--- 1.4585559368133545 seconds for one epoch ---
--- 0.3046746253967285 seconds for one epoch ---
--- 1.4865484237670898 seconds for one epoch ---
--- 0.3074486255645752 seconds for one epoch ---
--- 1.4607007503509521 seconds for one epoch ---
--- 0.31255555152893066 seconds for one epoch ---
--- 1.4593665599822998 seconds for one epoch ---
--- 0.3107912540435791 seconds for one epoch ---
--- 1.470613718032837 seconds for one epoch ---
--- 0.315532922744751 seconds for one epoch ---
--- 1.4445765018463135 seconds for one epoch ---
--- 0.30540037155151367 seconds for one epoch ---
--- 1.4865033626556396 seconds for one epoch ---
--- 0.3229484558105469 seconds for one epoch ---
--- 1.4392054080963135 seconds for one epoch ---
--- 0.31026268005371094 seconds for one epoch ---
--- 1.438887357711792 seconds for one epoch ---
--- 0.3120265007019043 seconds for one epoch ---
--- 1.448526382446289 seconds for one epoch ---
--- 0.3022005558013916 seconds for one epoch ---
--- 1.4406018257141113 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.38378406]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.283452]
 [  0.      ]]
--- 0.29527783393859863 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4583.65380859375, (1927.1497, 1.065148, 2655.1997, 0.23915842)
   validation loss 1158.425048828125, (768.9105, 0.83947515, 388.43588, 0.23915842)
decoder loss ratio: 29788.928528, decoder SINDy loss  ratio: 0.838493
THRESHOLDING: 1 active coefficients
--- 1.475501537322998 seconds for one epoch ---
--- 0.33308982849121094 seconds for one epoch ---
--- 1.4915993213653564 seconds for one epoch ---
--- 0.3292407989501953 seconds for one epoch ---
--- 1.469304084777832 seconds for one epoch ---
--- 0.33046817779541016 seconds for one epoch ---
--- 1.48872971534729 seconds for one epoch ---
--- 0.3355700969696045 seconds for one epoch ---
--- 1.4697210788726807 seconds for one epoch ---
--- 0.3340601921081543 seconds for one epoch ---
--- 1.458737850189209 seconds for one epoch ---
--- 0.3289308547973633 seconds for one epoch ---
--- 1.453244686126709 seconds for one epoch ---
--- 0.31395697593688965 seconds for one epoch ---
--- 1.4877924919128418 seconds for one epoch ---
--- 0.30410289764404297 seconds for one epoch ---
--- 1.4827485084533691 seconds for one epoch ---
--- 0.31166505813598633 seconds for one epoch ---
--- 1.4891433715820312 seconds for one epoch ---
--- 0.3126711845397949 seconds for one epoch ---
--- 1.4726035594940186 seconds for one epoch ---
--- 0.31886982917785645 seconds for one epoch ---
--- 1.4689207077026367 seconds for one epoch ---
--- 0.31313467025756836 seconds for one epoch ---
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.38175]
 [0.     ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.359725]
 [ -0.      ]]
--- 0.2783384323120117 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5307.00048828125, (1346.0107, 2.1308358, 3958.6191, 0.23969732)
   validation loss 910.7322998046875, (543.4845, 0.84497535, 366.16315, 0.23969732)
decoder loss ratio: 21055.532947, decoder SINDy loss  ratio: 0.790415
--- 0.31081151962280273 seconds for one epoch ---
--- 1.469031810760498 seconds for one epoch ---
--- 0.3108515739440918 seconds for one epoch ---
--- 1.4017882347106934 seconds for one epoch ---
--- 0.31398510932922363 seconds for one epoch ---
--- 1.409130334854126 seconds for one epoch ---
--- 0.30544567108154297 seconds for one epoch ---
--- 1.458899974822998 seconds for one epoch ---
--- 0.3092010021209717 seconds for one epoch ---
--- 1.5037634372711182 seconds for one epoch ---
--- 0.3060035705566406 seconds for one epoch ---
--- 1.4760832786560059 seconds for one epoch ---
--- 0.310863733291626 seconds for one epoch ---
--- 1.507239818572998 seconds for one epoch ---
--- 0.3082582950592041 seconds for one epoch ---
--- 1.509214162826538 seconds for one epoch ---
--- 0.3135490417480469 seconds for one epoch ---
--- 1.5116393566131592 seconds for one epoch ---
--- 0.3169100284576416 seconds for one epoch ---
--- 1.5117504596710205 seconds for one epoch ---
--- 0.3095839023590088 seconds for one epoch ---
--- 1.4783194065093994 seconds for one epoch ---
--- 0.3100392818450928 seconds for one epoch ---
--- 1.50931978225708 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37969637]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.434887]
 [ -0.      ]]
--- 0.30431222915649414 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3120.5830078125, (1285.505, 1.0587654, 1833.779, 0.24021593)
   validation loss 954.1370849609375, (621.2822, 0.6481572, 331.96652, 0.24021593)
decoder loss ratio: 24069.552050, decoder SINDy loss  ratio: 0.716596
--- 0.2744913101196289 seconds for one epoch ---
--- 0.326007604598999 seconds for one epoch ---
--- 1.4689128398895264 seconds for one epoch ---
--- 0.3094503879547119 seconds for one epoch ---
--- 1.4561755657196045 seconds for one epoch ---
--- 0.3182199001312256 seconds for one epoch ---
--- 1.4685611724853516 seconds for one epoch ---
--- 0.3108973503112793 seconds for one epoch ---
--- 1.4813523292541504 seconds for one epoch ---
--- 0.3221147060394287 seconds for one epoch ---
--- 1.4963326454162598 seconds for one epoch ---
--- 0.316021203994751 seconds for one epoch ---
--- 1.4896459579467773 seconds for one epoch ---
--- 0.31969332695007324 seconds for one epoch ---
--- 1.514479160308838 seconds for one epoch ---
--- 0.3112783432006836 seconds for one epoch ---
--- 1.5064239501953125 seconds for one epoch ---
--- 0.3115561008453369 seconds for one epoch ---
--- 1.520232915878296 seconds for one epoch ---
--- 0.3087177276611328 seconds for one epoch ---
--- 1.5116450786590576 seconds for one epoch ---
--- 0.3101465702056885 seconds for one epoch ---
--- 1.5024659633636475 seconds for one epoch ---
--- 0.3058028221130371 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37801313]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.495175]
 [ -0.      ]]
--- 0.2747538089752197 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6719.98095703125, (1672.0164, 3.4674115, 5044.2563, 0.24064203)
   validation loss 1098.2569580078125, (718.3982, 0.80428404, 378.81396, 0.24064203)
decoder loss ratio: 27831.993205, decoder SINDy loss  ratio: 0.817723
--- 0.31003308296203613 seconds for one epoch ---
--- 1.528635025024414 seconds for one epoch ---
--- 0.3078129291534424 seconds for one epoch ---
--- 1.4770617485046387 seconds for one epoch ---
--- 0.30512142181396484 seconds for one epoch ---
--- 1.4771323204040527 seconds for one epoch ---
--- 0.3153800964355469 seconds for one epoch ---
--- 1.4936635494232178 seconds for one epoch ---
--- 0.3071022033691406 seconds for one epoch ---
--- 1.5002853870391846 seconds for one epoch ---
--- 0.31423330307006836 seconds for one epoch ---
--- 1.4982454776763916 seconds for one epoch ---
--- 0.30292534828186035 seconds for one epoch ---
--- 1.4981601238250732 seconds for one epoch ---
--- 0.3224797248840332 seconds for one epoch ---
--- 1.5093274116516113 seconds for one epoch ---
--- 0.30959653854370117 seconds for one epoch ---
--- 1.5176424980163574 seconds for one epoch ---
--- 0.32002782821655273 seconds for one epoch ---
--- 1.4924488067626953 seconds for one epoch ---
--- 0.30911684036254883 seconds for one epoch ---
--- 1.4814770221710205 seconds for one epoch ---
--- 0.30979084968566895 seconds for one epoch ---
--- 1.5020313262939453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37645954]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.54989]
 [  0.     ]]
--- 0.3076353073120117 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4145.8974609375, (1629.98, 2.339096, 2513.3372, 0.24099624)
   validation loss 1009.91748046875, (618.8918, 0.864485, 389.92026, 0.24099624)
decoder loss ratio: 23976.942181, decoder SINDy loss  ratio: 0.841698
--- 0.27021145820617676 seconds for one epoch ---
--- 0.3191542625427246 seconds for one epoch ---
--- 1.4773800373077393 seconds for one epoch ---
--- 0.3118152618408203 seconds for one epoch ---
--- 1.4558544158935547 seconds for one epoch ---
--- 0.30840325355529785 seconds for one epoch ---
--- 1.4680664539337158 seconds for one epoch ---
--- 0.2922823429107666 seconds for one epoch ---
--- 1.5057635307312012 seconds for one epoch ---
--- 0.31456732749938965 seconds for one epoch ---
--- 1.5118627548217773 seconds for one epoch ---
--- 0.33506107330322266 seconds for one epoch ---
--- 1.5093464851379395 seconds for one epoch ---
--- 0.3473336696624756 seconds for one epoch ---
--- 1.4937231540679932 seconds for one epoch ---
--- 0.3503568172454834 seconds for one epoch ---
--- 1.5271949768066406 seconds for one epoch ---
--- 0.3526277542114258 seconds for one epoch ---
--- 1.5255167484283447 seconds for one epoch ---
--- 0.33698081970214844 seconds for one epoch ---
--- 1.5420503616333008 seconds for one epoch ---
--- 0.3493835926055908 seconds for one epoch ---
--- 1.5168156623840332 seconds for one epoch ---
--- 0.36476898193359375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37472445]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.609936]
 [  0.      ]]
--- 0.266432523727417 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3706.738525390625, (1089.323, 1.5954037, 2615.5786, 0.24137998)
   validation loss 1064.518310546875, (678.4324, 0.8764438, 384.9681, 0.24137998)
decoder loss ratio: 26283.647942, decoder SINDy loss  ratio: 0.831008
--- 0.30188560485839844 seconds for one epoch ---
--- 1.5162556171417236 seconds for one epoch ---
--- 0.3171555995941162 seconds for one epoch ---
--- 1.514681339263916 seconds for one epoch ---
--- 0.31559157371520996 seconds for one epoch ---
--- 1.4564568996429443 seconds for one epoch ---
--- 0.3063511848449707 seconds for one epoch ---
--- 1.4723384380340576 seconds for one epoch ---
--- 0.3019678592681885 seconds for one epoch ---
--- 1.520458459854126 seconds for one epoch ---
--- 0.31020236015319824 seconds for one epoch ---
--- 1.538496494293213 seconds for one epoch ---
--- 0.3058621883392334 seconds for one epoch ---
--- 1.5128486156463623 seconds for one epoch ---
--- 0.30820655822753906 seconds for one epoch ---
--- 1.507887840270996 seconds for one epoch ---
--- 0.30782485008239746 seconds for one epoch ---
--- 1.5219621658325195 seconds for one epoch ---
--- 0.3058433532714844 seconds for one epoch ---
--- 1.5202014446258545 seconds for one epoch ---
--- 0.3071329593658447 seconds for one epoch ---
--- 1.5184273719787598 seconds for one epoch ---
--- 0.3038327693939209 seconds for one epoch ---
--- 1.5089633464813232 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37268123]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.679332]
 [  0.      ]]
--- 0.30174851417541504 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4766.25439453125, (1727.9291, 1.4219044, 3036.6616, 0.24183555)
   validation loss 1006.1494140625, (682.3279, 0.64092696, 322.93878, 0.24183555)
decoder loss ratio: 26434.566678, decoder SINDy loss  ratio: 0.697109
--- 0.2734973430633545 seconds for one epoch ---
--- 0.31444358825683594 seconds for one epoch ---
--- 1.5208077430725098 seconds for one epoch ---
--- 0.3053445816040039 seconds for one epoch ---
--- 1.4933481216430664 seconds for one epoch ---
--- 0.2990760803222656 seconds for one epoch ---
--- 1.4791114330291748 seconds for one epoch ---
--- 0.30255985260009766 seconds for one epoch ---
--- 1.4660069942474365 seconds for one epoch ---
--- 0.29540276527404785 seconds for one epoch ---
--- 1.5255370140075684 seconds for one epoch ---
--- 0.29776597023010254 seconds for one epoch ---
--- 1.5209965705871582 seconds for one epoch ---
--- 0.34339237213134766 seconds for one epoch ---
--- 1.5183849334716797 seconds for one epoch ---
--- 0.32439160346984863 seconds for one epoch ---
--- 1.548405408859253 seconds for one epoch ---
--- 0.3470897674560547 seconds for one epoch ---
--- 1.5431044101715088 seconds for one epoch ---
--- 0.3319075107574463 seconds for one epoch ---
--- 1.5515894889831543 seconds for one epoch ---
--- 0.3353707790374756 seconds for one epoch ---
--- 1.5582473278045654 seconds for one epoch ---
--- 0.34133124351501465 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37120527]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.728644]
 [ -0.      ]]
--- 0.25447869300842285 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3172.693115234375, (1442.5048, 2.2463489, 1727.6998, 0.24214363)
   validation loss 1708.6959228515625, (1355.5009, 0.7230568, 352.22983, 0.24214363)
decoder loss ratio: 52514.456356, decoder SINDy loss  ratio: 0.760338
--- 0.3052692413330078 seconds for one epoch ---
--- 1.5557472705841064 seconds for one epoch ---
--- 0.3094339370727539 seconds for one epoch ---
--- 1.568840742111206 seconds for one epoch ---
--- 0.31862354278564453 seconds for one epoch ---
--- 1.5230894088745117 seconds for one epoch ---
--- 0.30143237113952637 seconds for one epoch ---
--- 1.5228898525238037 seconds for one epoch ---
--- 0.3092658519744873 seconds for one epoch ---
--- 1.5374364852905273 seconds for one epoch ---
--- 0.3097219467163086 seconds for one epoch ---
--- 1.549816608428955 seconds for one epoch ---
--- 0.32661890983581543 seconds for one epoch ---
--- 1.5448503494262695 seconds for one epoch ---
--- 0.34199047088623047 seconds for one epoch ---
--- 1.559812307357788 seconds for one epoch ---
--- 0.3414428234100342 seconds for one epoch ---
--- 1.5757133960723877 seconds for one epoch ---
--- 0.33156514167785645 seconds for one epoch ---
--- 1.5615668296813965 seconds for one epoch ---
--- 0.3241856098175049 seconds for one epoch ---
--- 1.5740995407104492 seconds for one epoch ---
--- 0.31690263748168945 seconds for one epoch ---
--- 1.5667650699615479 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3689962]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-15.8012]
 [ -0.    ]]
--- 0.3151700496673584 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2572.183837890625, (1035.8746, 1.4257895, 1534.6409, 0.24254385)
   validation loss 1256.7891845703125, (851.86804, 0.8691425, 403.80945, 0.24254385)
decoder loss ratio: 33002.846855, decoder SINDy loss  ratio: 0.871679
--- 0.280458927154541 seconds for one epoch ---
--- 0.32813048362731934 seconds for one epoch ---
--- 1.5680344104766846 seconds for one epoch ---
--- 0.324810266494751 seconds for one epoch ---
--- 1.523256540298462 seconds for one epoch ---
--- 0.31251049041748047 seconds for one epoch ---
--- 1.535346269607544 seconds for one epoch ---
--- 0.30673885345458984 seconds for one epoch ---
--- 1.5380656719207764 seconds for one epoch ---
--- 0.31266140937805176 seconds for one epoch ---
--- 1.5650465488433838 seconds for one epoch ---
--- 0.30663061141967773 seconds for one epoch ---
--- 1.5555150508880615 seconds for one epoch ---
--- 0.30698442459106445 seconds for one epoch ---
--- 1.542186975479126 seconds for one epoch ---
--- 0.3109736442565918 seconds for one epoch ---
--- 1.5337939262390137 seconds for one epoch ---
--- 0.30664920806884766 seconds for one epoch ---
--- 1.5818240642547607 seconds for one epoch ---
--- 0.30232930183410645 seconds for one epoch ---
--- 1.5551831722259521 seconds for one epoch ---
--- 0.3141744136810303 seconds for one epoch ---
--- 1.5678629875183105 seconds for one epoch ---
--- 0.30688905715942383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.36703303]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.864509]
 [ -0.      ]]
--- 0.2745349407196045 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2726.04541015625, (1624.0544, 1.9888216, 1099.7593, 0.24295126)
   validation loss 941.2063598632812, (596.51965, 0.73698574, 343.70673, 0.24295126)
decoder loss ratio: 23110.206973, decoder SINDy loss  ratio: 0.741939
--- 0.31074070930480957 seconds for one epoch ---
--- 1.5945780277252197 seconds for one epoch ---
--- 0.32149291038513184 seconds for one epoch ---
--- 1.5646638870239258 seconds for one epoch ---
--- 0.30763888359069824 seconds for one epoch ---
--- 1.545076847076416 seconds for one epoch ---
--- 0.30224180221557617 seconds for one epoch ---
--- 1.5301909446716309 seconds for one epoch ---
--- 0.30597710609436035 seconds for one epoch ---
--- 1.5906357765197754 seconds for one epoch ---
--- 0.3066554069519043 seconds for one epoch ---
--- 1.5741121768951416 seconds for one epoch ---
--- 0.3045482635498047 seconds for one epoch ---
--- 1.545591115951538 seconds for one epoch ---
--- 0.30650925636291504 seconds for one epoch ---
--- 1.561530590057373 seconds for one epoch ---
--- 0.3096189498901367 seconds for one epoch ---
--- 1.5936405658721924 seconds for one epoch ---
--- 0.3079550266265869 seconds for one epoch ---
--- 1.5524702072143555 seconds for one epoch ---
--- 0.3125615119934082 seconds for one epoch ---
--- 1.5620863437652588 seconds for one epoch ---
--- 0.3036680221557617 seconds for one epoch ---
--- 1.5574729442596436 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.36507094]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.926768]
 [  0.      ]]
--- 0.3014352321624756 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2632.27099609375, (1401.0963, 0.9749551, 1229.9563, 0.24330156)
   validation loss 960.13427734375, (580.9206, 0.90705484, 378.06332, 0.24330156)
decoder loss ratio: 22505.872305, decoder SINDy loss  ratio: 0.816103
--- 0.26763200759887695 seconds for one epoch ---
--- 0.3161172866821289 seconds for one epoch ---
--- 1.5871453285217285 seconds for one epoch ---
--- 0.3064274787902832 seconds for one epoch ---
--- 1.5017244815826416 seconds for one epoch ---
--- 0.30124592781066895 seconds for one epoch ---
--- 1.5320751667022705 seconds for one epoch ---
--- 0.29959869384765625 seconds for one epoch ---
--- 1.5262181758880615 seconds for one epoch ---
--- 0.3178131580352783 seconds for one epoch ---
--- 1.550652265548706 seconds for one epoch ---
--- 0.30887293815612793 seconds for one epoch ---
--- 1.5740642547607422 seconds for one epoch ---
--- 0.3245408535003662 seconds for one epoch ---
--- 1.5753576755523682 seconds for one epoch ---
--- 0.3160097599029541 seconds for one epoch ---
--- 1.6053237915039062 seconds for one epoch ---
--- 0.33852410316467285 seconds for one epoch ---
--- 1.5646247863769531 seconds for one epoch ---
--- 0.3288435935974121 seconds for one epoch ---
--- 1.5701088905334473 seconds for one epoch ---
--- 0.32265591621398926 seconds for one epoch ---
--- 1.5919041633605957 seconds for one epoch ---
--- 0.3275144100189209 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.36301845]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.990843]
 [  0.      ]]
--- 0.2646448612213135 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2870.9169921875, (1034.6648, 0.52183545, 1835.4866, 0.24366121)
   validation loss 881.997314453125, (538.04736, 0.8022001, 342.90414, 0.24366121)
decoder loss ratio: 20844.888945, decoder SINDy loss  ratio: 0.740207
--- 0.3018019199371338 seconds for one epoch ---
--- 1.5545172691345215 seconds for one epoch ---
--- 0.30667901039123535 seconds for one epoch ---
--- 1.596761703491211 seconds for one epoch ---
--- 0.3065915107727051 seconds for one epoch ---
--- 1.5712485313415527 seconds for one epoch ---
--- 0.3021094799041748 seconds for one epoch ---
--- 1.5485484600067139 seconds for one epoch ---
--- 0.3117940425872803 seconds for one epoch ---
--- 1.5275187492370605 seconds for one epoch ---
--- 0.30339813232421875 seconds for one epoch ---
--- 1.5723326206207275 seconds for one epoch ---
--- 0.305633544921875 seconds for one epoch ---
--- 1.5804684162139893 seconds for one epoch ---
--- 0.3112823963165283 seconds for one epoch ---
--- 1.6035468578338623 seconds for one epoch ---
--- 0.3047800064086914 seconds for one epoch ---
--- 1.6140491962432861 seconds for one epoch ---
--- 0.30440592765808105 seconds for one epoch ---
--- 1.574277400970459 seconds for one epoch ---
--- 0.30736541748046875 seconds for one epoch ---
--- 1.5802397727966309 seconds for one epoch ---
--- 0.31007981300354004 seconds for one epoch ---
--- 1.62933349609375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.36083958]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.057766]
 [  0.      ]]
--- 0.3090827465057373 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3125.0859375, (1744.7128, 2.2726092, 1377.8566, 0.24402814)
   validation loss 883.1900634765625, (524.03937, 0.9017007, 358.00504, 0.24402814)
decoder loss ratio: 20302.194876, decoder SINDy loss  ratio: 0.772804
--- 0.27069926261901855 seconds for one epoch ---
--- 0.30785536766052246 seconds for one epoch ---
--- 1.5890717506408691 seconds for one epoch ---
--- 0.30841803550720215 seconds for one epoch ---
--- 1.6052217483520508 seconds for one epoch ---
--- 0.3091118335723877 seconds for one epoch ---
--- 1.525526523590088 seconds for one epoch ---
--- 0.31589579582214355 seconds for one epoch ---
--- 1.5308525562286377 seconds for one epoch ---
--- 0.30463647842407227 seconds for one epoch ---
--- 1.5533268451690674 seconds for one epoch ---
--- 0.30623817443847656 seconds for one epoch ---
--- 1.5866296291351318 seconds for one epoch ---
--- 0.30780720710754395 seconds for one epoch ---
--- 1.5943341255187988 seconds for one epoch ---
--- 0.30759549140930176 seconds for one epoch ---
--- 1.6160736083984375 seconds for one epoch ---
--- 0.309293270111084 seconds for one epoch ---
--- 1.612030267715454 seconds for one epoch ---
--- 0.3015406131744385 seconds for one epoch ---
--- 1.656855583190918 seconds for one epoch ---
--- 0.30584049224853516 seconds for one epoch ---
--- 1.6471755504608154 seconds for one epoch ---
--- 0.3040125370025635 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35905093]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.111906]
 [ -0.      ]]
--- 0.2661857604980469 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7376.6767578125, (1329.3622, 1.7478466, 6045.3228, 0.24431024)
   validation loss 933.9677734375, (590.65405, 0.7947095, 342.27466, 0.24431024)
decoder loss ratio: 22882.963423, decoder SINDy loss  ratio: 0.738848
--- 0.3243873119354248 seconds for one epoch ---
--- 1.6063215732574463 seconds for one epoch ---
--- 0.302807092666626 seconds for one epoch ---
--- 1.6104228496551514 seconds for one epoch ---
--- 0.30753564834594727 seconds for one epoch ---
--- 1.6286745071411133 seconds for one epoch ---
--- 0.3146634101867676 seconds for one epoch ---
--- 1.5947606563568115 seconds for one epoch ---
--- 0.3061385154724121 seconds for one epoch ---
--- 1.5839331150054932 seconds for one epoch ---
--- 0.32089900970458984 seconds for one epoch ---
--- 1.5892014503479004 seconds for one epoch ---
--- 0.325359582901001 seconds for one epoch ---
--- 1.6456091403961182 seconds for one epoch ---
--- 0.3201918601989746 seconds for one epoch ---
--- 1.667067289352417 seconds for one epoch ---
--- 0.313323974609375 seconds for one epoch ---
--- 1.6301939487457275 seconds for one epoch ---
--- 0.319429874420166 seconds for one epoch ---
--- 1.6002764701843262 seconds for one epoch ---
--- 0.31554079055786133 seconds for one epoch ---
--- 1.6455705165863037 seconds for one epoch ---
--- 0.3139657974243164 seconds for one epoch ---
--- 1.6371052265167236 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35674945]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.18058]
 [ -0.     ]]
--- 0.29923224449157715 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4350.46923828125, (1514.6663, 0.88632643, 2834.6719, 0.2446604)
   validation loss 1384.2269287109375, (1018.80383, 0.7787474, 364.3997, 0.2446604)
decoder loss ratio: 39470.229212, decoder SINDy loss  ratio: 0.786608
--- 0.27135133743286133 seconds for one epoch ---
--- 0.3109266757965088 seconds for one epoch ---
--- 1.6364736557006836 seconds for one epoch ---
--- 0.31263041496276855 seconds for one epoch ---
--- 1.6396534442901611 seconds for one epoch ---
--- 0.31481456756591797 seconds for one epoch ---
--- 1.6027331352233887 seconds for one epoch ---
--- 0.3091423511505127 seconds for one epoch ---
--- 1.610229730606079 seconds for one epoch ---
--- 0.31784963607788086 seconds for one epoch ---
--- 1.5906355381011963 seconds for one epoch ---
--- 0.30155229568481445 seconds for one epoch ---
--- 1.622399091720581 seconds for one epoch ---
--- 0.30872201919555664 seconds for one epoch ---
--- 1.6276335716247559 seconds for one epoch ---
--- 0.32213664054870605 seconds for one epoch ---
--- 1.6589446067810059 seconds for one epoch ---
--- 0.30611753463745117 seconds for one epoch ---
--- 1.6751201152801514 seconds for one epoch ---
--- 0.3186206817626953 seconds for one epoch ---
--- 1.6484870910644531 seconds for one epoch ---
--- 0.32450270652770996 seconds for one epoch ---
--- 1.6612279415130615 seconds for one epoch ---
--- 0.3364396095275879 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35464716]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.242367]
 [ -0.      ]]
--- 0.2654902935028076 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3382.333251953125, (1316.8325, 1.2530442, 2064.0027, 0.24497044)
   validation loss 990.22265625, (632.08136, 0.81557804, 357.08078, 0.24497044)
decoder loss ratio: 24487.929223, decoder SINDy loss  ratio: 0.770809
--- 0.3103492259979248 seconds for one epoch ---
--- 1.651094913482666 seconds for one epoch ---
--- 0.3052659034729004 seconds for one epoch ---
--- 1.6339919567108154 seconds for one epoch ---
--- 0.3123319149017334 seconds for one epoch ---
--- 1.6705996990203857 seconds for one epoch ---
--- 0.3054826259613037 seconds for one epoch ---
--- 1.6283116340637207 seconds for one epoch ---
--- 0.32061243057250977 seconds for one epoch ---
--- 1.6189677715301514 seconds for one epoch ---
--- 0.3060905933380127 seconds for one epoch ---
--- 1.6120011806488037 seconds for one epoch ---
--- 0.3061861991882324 seconds for one epoch ---
--- 1.6643996238708496 seconds for one epoch ---
--- 0.33191847801208496 seconds for one epoch ---
--- 1.6379797458648682 seconds for one epoch ---
--- 0.35973405838012695 seconds for one epoch ---
--- 1.6299610137939453 seconds for one epoch ---
--- 0.35619473457336426 seconds for one epoch ---
--- 1.6777920722961426 seconds for one epoch ---
--- 0.3567240238189697 seconds for one epoch ---
--- 1.6772129535675049 seconds for one epoch ---
--- 0.35714077949523926 seconds for one epoch ---
--- 1.6492230892181396 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35271233]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.29849]
 [  0.     ]]
--- 0.2987346649169922 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1930.324951171875, (1250.5876, 0.38192347, 679.1101, 0.24521811)
   validation loss 1347.073974609375, (965.74646, 0.9040359, 380.17822, 0.24521811)
decoder loss ratio: 37414.694468, decoder SINDy loss  ratio: 0.820668
--- 0.2747352123260498 seconds for one epoch ---
--- 0.3080606460571289 seconds for one epoch ---
--- 1.6279630661010742 seconds for one epoch ---
--- 0.308117151260376 seconds for one epoch ---
--- 1.655487298965454 seconds for one epoch ---
--- 0.31646132469177246 seconds for one epoch ---
--- 1.6233336925506592 seconds for one epoch ---
--- 0.3015294075012207 seconds for one epoch ---
--- 1.6109156608581543 seconds for one epoch ---
--- 0.3039968013763428 seconds for one epoch ---
--- 1.5858008861541748 seconds for one epoch ---
--- 0.29911041259765625 seconds for one epoch ---
--- 1.6196250915527344 seconds for one epoch ---
--- 0.3197965621948242 seconds for one epoch ---
--- 1.6543653011322021 seconds for one epoch ---
--- 0.3092312812805176 seconds for one epoch ---
--- 1.678218126296997 seconds for one epoch ---
--- 0.316906213760376 seconds for one epoch ---
--- 1.669942855834961 seconds for one epoch ---
--- 0.3136327266693115 seconds for one epoch ---
--- 1.6749320030212402 seconds for one epoch ---
--- 0.31529903411865234 seconds for one epoch ---
--- 1.6400477886199951 seconds for one epoch ---
--- 0.3073394298553467 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35098994]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.347889]
 [  0.      ]]
--- 0.2664353847503662 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5265.93115234375, (2256.0278, 3.7005074, 3005.957, 0.24544902)
   validation loss 1161.6458740234375, (745.09644, 1.0724075, 415.23157, 0.24544902)
decoder loss ratio: 28866.329457, decoder SINDy loss  ratio: 0.896336
--- 0.3057088851928711 seconds for one epoch ---
--- 1.6694114208221436 seconds for one epoch ---
--- 0.3308558464050293 seconds for one epoch ---
--- 1.6643612384796143 seconds for one epoch ---
--- 0.30927228927612305 seconds for one epoch ---
--- 1.6949377059936523 seconds for one epoch ---
--- 0.32219672203063965 seconds for one epoch ---
--- 1.6547205448150635 seconds for one epoch ---
--- 0.31287336349487305 seconds for one epoch ---
--- 1.6498692035675049 seconds for one epoch ---
--- 0.3182559013366699 seconds for one epoch ---
--- 1.6429004669189453 seconds for one epoch ---
--- 0.30793237686157227 seconds for one epoch ---
--- 1.6758332252502441 seconds for one epoch ---
--- 0.31881093978881836 seconds for one epoch ---
--- 1.6802468299865723 seconds for one epoch ---
--- 0.313784122467041 seconds for one epoch ---
--- 1.6890602111816406 seconds for one epoch ---
--- 0.6135165691375732 seconds for one epoch ---
--- 1.6420633792877197 seconds for one epoch ---
--- 0.3049595355987549 seconds for one epoch ---
--- 1.6685388088226318 seconds for one epoch ---
--- 0.30823659896850586 seconds for one epoch ---
--- 1.6614084243774414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34932822]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.395048]
 [  0.      ]]
--- 0.30794858932495117 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3155.19921875, (2006.3751, 2.548691, 1146.0298, 0.24568506)
   validation loss 949.8577880859375, (588.2902, 0.9157527, 360.40613, 0.24568506)
decoder loss ratio: 22791.384524, decoder SINDy loss  ratio: 0.777987
--- 0.2774958610534668 seconds for one epoch ---
--- 0.3200869560241699 seconds for one epoch ---
--- 1.6775660514831543 seconds for one epoch ---
--- 0.3096485137939453 seconds for one epoch ---
--- 1.7081925868988037 seconds for one epoch ---
--- 0.3087890148162842 seconds for one epoch ---
--- 1.6457476615905762 seconds for one epoch ---
--- 0.30817651748657227 seconds for one epoch ---
--- 1.6501517295837402 seconds for one epoch ---
--- 0.308746337890625 seconds for one epoch ---
--- 1.645240068435669 seconds for one epoch ---
--- 0.3055291175842285 seconds for one epoch ---
--- 1.6879620552062988 seconds for one epoch ---
--- 0.3139047622680664 seconds for one epoch ---
--- 1.6953489780426025 seconds for one epoch ---
--- 0.3096766471862793 seconds for one epoch ---
--- 1.7073450088500977 seconds for one epoch ---
--- 0.3060901165008545 seconds for one epoch ---
--- 1.7239863872528076 seconds for one epoch ---
--- 0.31384754180908203 seconds for one epoch ---
--- 1.7045187950134277 seconds for one epoch ---
--- 0.31218457221984863 seconds for one epoch ---
--- 1.7073614597320557 seconds for one epoch ---
--- 0.30779409408569336 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3472745]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.452684]
 [ -0.      ]]
--- 0.3073413372039795 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2375.920166015625, (895.58234, 1.6010001, 1478.4908, 0.24591842)
   validation loss 1508.84033203125, (1106.2054, 0.96754783, 401.42136, 0.24591842)
decoder loss ratio: 42856.319371, decoder SINDy loss  ratio: 0.866524
--- 0.3202998638153076 seconds for one epoch ---
--- 1.695108413696289 seconds for one epoch ---
--- 0.3447301387786865 seconds for one epoch ---
--- 1.6934640407562256 seconds for one epoch ---
--- 0.3367183208465576 seconds for one epoch ---
--- 1.715557336807251 seconds for one epoch ---
--- 0.3280613422393799 seconds for one epoch ---
--- 1.688154935836792 seconds for one epoch ---
--- 0.33678483963012695 seconds for one epoch ---
--- 1.714524269104004 seconds for one epoch ---
--- 0.3405139446258545 seconds for one epoch ---
--- 1.726440191268921 seconds for one epoch ---
--- 0.3343229293823242 seconds for one epoch ---
--- 1.721865177154541 seconds for one epoch ---
--- 0.31519317626953125 seconds for one epoch ---
--- 1.7103214263916016 seconds for one epoch ---
--- 0.3170814514160156 seconds for one epoch ---
--- 1.711562156677246 seconds for one epoch ---
--- 0.31505608558654785 seconds for one epoch ---
--- 1.7188215255737305 seconds for one epoch ---
--- 0.30824780464172363 seconds for one epoch ---
--- 1.7070941925048828 seconds for one epoch ---
--- 0.3157927989959717 seconds for one epoch ---
--- 1.7309982776641846 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34538674]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.505066]
 [ -0.      ]]
--- 0.3056373596191406 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3398.502685546875, (1225.2101, 2.4119487, 2170.6345, 0.24614036)
   validation loss 1223.2523193359375, (815.2955, 0.9737543, 406.737, 0.24614036)
decoder loss ratio: 31585.961969, decoder SINDy loss  ratio: 0.877999
THRESHOLDING: 1 active coefficients
--- 0.2758524417877197 seconds for one epoch ---
--- 0.31195712089538574 seconds for one epoch ---
--- 1.720384120941162 seconds for one epoch ---
--- 0.3082876205444336 seconds for one epoch ---
--- 1.7100722789764404 seconds for one epoch ---
--- 0.3023500442504883 seconds for one epoch ---
--- 1.713073492050171 seconds for one epoch ---
--- 0.3124196529388428 seconds for one epoch ---
--- 1.7175192832946777 seconds for one epoch ---
--- 0.3058009147644043 seconds for one epoch ---
--- 1.6767628192901611 seconds for one epoch ---
--- 0.30557751655578613 seconds for one epoch ---
--- 1.7122721672058105 seconds for one epoch ---
--- 0.3099658489227295 seconds for one epoch ---
--- 1.7077231407165527 seconds for one epoch ---
--- 0.3087193965911865 seconds for one epoch ---
--- 1.6991052627563477 seconds for one epoch ---
--- 0.30747008323669434 seconds for one epoch ---
--- 1.7351696491241455 seconds for one epoch ---
--- 0.31305456161499023 seconds for one epoch ---
--- 1.7036502361297607 seconds for one epoch ---
--- 0.32088780403137207 seconds for one epoch ---
--- 1.6752965450286865 seconds for one epoch ---
--- 0.3078477382659912 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34408462]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.540897]
 [ -0.      ]]
--- 0.2741100788116455 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4744.8623046875, (1239.1915, 1.1448225, 3504.28, 0.2462991)
   validation loss 1300.1695556640625, (891.6201, 0.8863368, 407.41678, 0.2462991)
decoder loss ratio: 34542.911260, decoder SINDy loss  ratio: 0.879466
--- 0.31172609329223633 seconds for one epoch ---
--- 1.7099344730377197 seconds for one epoch ---
--- 0.31502699851989746 seconds for one epoch ---
--- 1.7486364841461182 seconds for one epoch ---
--- 0.3153245449066162 seconds for one epoch ---
--- 1.710327386856079 seconds for one epoch ---
--- 0.3132774829864502 seconds for one epoch ---
--- 1.6801633834838867 seconds for one epoch ---
--- 0.32717204093933105 seconds for one epoch ---
--- 1.679452657699585 seconds for one epoch ---
--- 0.3104569911956787 seconds for one epoch ---
--- 1.7094714641571045 seconds for one epoch ---
--- 0.31826305389404297 seconds for one epoch ---
--- 1.7421791553497314 seconds for one epoch ---
--- 0.3412361145019531 seconds for one epoch ---
--- 1.702713966369629 seconds for one epoch ---
--- 0.32390785217285156 seconds for one epoch ---
--- 1.7565796375274658 seconds for one epoch ---
--- 0.3351318836212158 seconds for one epoch ---
--- 1.7529184818267822 seconds for one epoch ---
--- 0.3326568603515625 seconds for one epoch ---
--- 1.7692272663116455 seconds for one epoch ---
--- 0.3232429027557373 seconds for one epoch ---
--- 1.7287929058074951 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3419476]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.599154]
 [  0.      ]]
--- 0.3039233684539795 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3198.5224609375, (1295.3085, 2.3566246, 1900.6108, 0.24652469)
   validation loss 1218.655517578125, (831.8531, 0.90938103, 385.6465, 0.24652469)
decoder loss ratio: 32227.432804, decoder SINDy loss  ratio: 0.832472
--- 0.2739834785461426 seconds for one epoch ---
--- 0.30575108528137207 seconds for one epoch ---
--- 1.7125272750854492 seconds for one epoch ---
--- 0.3123199939727783 seconds for one epoch ---
--- 1.734865665435791 seconds for one epoch ---
--- 0.30933690071105957 seconds for one epoch ---
--- 1.6596715450286865 seconds for one epoch ---
--- 0.30510807037353516 seconds for one epoch ---
--- 1.678776741027832 seconds for one epoch ---
--- 0.3049604892730713 seconds for one epoch ---
--- 1.6838159561157227 seconds for one epoch ---
--- 0.3057091236114502 seconds for one epoch ---
--- 1.7154207229614258 seconds for one epoch ---
--- 0.30553102493286133 seconds for one epoch ---
--- 1.7071318626403809 seconds for one epoch ---
--- 0.30611085891723633 seconds for one epoch ---
--- 1.7312088012695312 seconds for one epoch ---
--- 0.30805015563964844 seconds for one epoch ---
--- 1.7226300239562988 seconds for one epoch ---
--- 0.3061962127685547 seconds for one epoch ---
--- 1.724759578704834 seconds for one epoch ---
--- 0.3083786964416504 seconds for one epoch ---
--- 1.7316157817840576 seconds for one epoch ---
--- 0.3176281452178955 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34027243]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.644354]
 [  0.      ]]
--- 0.27642321586608887 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2130.279052734375, (1017.6412, 2.4054391, 1109.9855, 0.24670501)
   validation loss 1212.33447265625, (845.46735, 0.82881397, 365.79163, 0.24670501)
decoder loss ratio: 32754.872787, decoder SINDy loss  ratio: 0.789613
--- 0.30549120903015137 seconds for one epoch ---
--- 1.7119135856628418 seconds for one epoch ---
--- 0.3094048500061035 seconds for one epoch ---
--- 1.740779161453247 seconds for one epoch ---
--- 0.3116719722747803 seconds for one epoch ---
--- 1.754650592803955 seconds for one epoch ---
--- 0.31448984146118164 seconds for one epoch ---
--- 1.6920862197875977 seconds for one epoch ---
--- 0.31441545486450195 seconds for one epoch ---
--- 1.6897249221801758 seconds for one epoch ---
--- 0.30869054794311523 seconds for one epoch ---
--- 1.7074828147888184 seconds for one epoch ---
--- 0.30661487579345703 seconds for one epoch ---
--- 1.715853214263916 seconds for one epoch ---
--- 0.30734872817993164 seconds for one epoch ---
--- 1.7278857231140137 seconds for one epoch ---
--- 0.34541773796081543 seconds for one epoch ---
--- 1.7769629955291748 seconds for one epoch ---
--- 0.3367428779602051 seconds for one epoch ---
--- 1.7796051502227783 seconds for one epoch ---
--- 0.33415746688842773 seconds for one epoch ---
--- 1.7899580001831055 seconds for one epoch ---
--- 0.32482481002807617 seconds for one epoch ---
--- 1.7744026184082031 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3384341]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.693535]
 [  0.      ]]
--- 0.2989225387573242 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3125.59375, (1453.532, 0.25482035, 1671.5602, 0.24688677)
   validation loss 913.9990844726562, (562.1163, 0.9330844, 350.7028, 0.24688677)
decoder loss ratio: 21777.360253, decoder SINDy loss  ratio: 0.757041
--- 0.2745215892791748 seconds for one epoch ---
--- 0.3209357261657715 seconds for one epoch ---
--- 1.7148544788360596 seconds for one epoch ---
--- 0.3113749027252197 seconds for one epoch ---
--- 1.7452428340911865 seconds for one epoch ---
--- 0.31159043312072754 seconds for one epoch ---
--- 1.7504324913024902 seconds for one epoch ---
--- 0.3111457824707031 seconds for one epoch ---
--- 1.6882193088531494 seconds for one epoch ---
--- 0.31180596351623535 seconds for one epoch ---
--- 1.6896862983703613 seconds for one epoch ---
--- 0.3051009178161621 seconds for one epoch ---
--- 1.698943853378296 seconds for one epoch ---
--- 0.3084285259246826 seconds for one epoch ---
--- 1.7512013912200928 seconds for one epoch ---
--- 0.3125123977661133 seconds for one epoch ---
--- 1.7612674236297607 seconds for one epoch ---
--- 0.31711816787719727 seconds for one epoch ---
--- 1.7638285160064697 seconds for one epoch ---
--- 0.3155982494354248 seconds for one epoch ---
--- 1.774397611618042 seconds for one epoch ---
--- 0.30063796043395996 seconds for one epoch ---
--- 1.7557268142700195 seconds for one epoch ---
--- 0.31060171127319336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33681768]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.736397]
 [ -0.      ]]
--- 0.2676839828491211 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3948.744140625, (1733.759, 3.7574952, 2210.9807, 0.24704318)
   validation loss 1065.0245361328125, (732.46356, 0.77640224, 331.5375, 0.24704318)
decoder loss ratio: 28376.910005, decoder SINDy loss  ratio: 0.715670
--- 0.30911707878112793 seconds for one epoch ---
--- 1.7662279605865479 seconds for one epoch ---
--- 0.3173182010650635 seconds for one epoch ---
--- 1.7511405944824219 seconds for one epoch ---
--- 0.31053733825683594 seconds for one epoch ---
--- 1.7883477210998535 seconds for one epoch ---
--- 0.31154775619506836 seconds for one epoch ---
--- 1.7755849361419678 seconds for one epoch ---
--- 0.3197641372680664 seconds for one epoch ---
--- 1.731992244720459 seconds for one epoch ---
--- 0.31226396560668945 seconds for one epoch ---
--- 1.7379767894744873 seconds for one epoch ---
--- 0.3077857494354248 seconds for one epoch ---
--- 1.7357659339904785 seconds for one epoch ---
--- 0.3008859157562256 seconds for one epoch ---
--- 1.8015193939208984 seconds for one epoch ---
--- 0.32440900802612305 seconds for one epoch ---
--- 1.7861287593841553 seconds for one epoch ---
--- 0.35913920402526855 seconds for one epoch ---
--- 1.7845659255981445 seconds for one epoch ---
--- 0.3499181270599365 seconds for one epoch ---
--- 1.7669756412506104 seconds for one epoch ---
--- 0.3400745391845703 seconds for one epoch ---
--- 1.7562007904052734 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33532465]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.775696]
 [ -0.      ]]
--- 0.30275487899780273 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4493.7509765625, (2066.3428, 2.613806, 2424.5476, 0.2471851)
   validation loss 1161.599853515625, (825.56464, 0.7481097, 335.03995, 0.2471851)
decoder loss ratio: 31983.807251, decoder SINDy loss  ratio: 0.723231
--- 0.2710592746734619 seconds for one epoch ---
--- 0.3131849765777588 seconds for one epoch ---
--- 1.7369797229766846 seconds for one epoch ---
--- 0.3100895881652832 seconds for one epoch ---
--- 1.7556495666503906 seconds for one epoch ---
--- 0.31269240379333496 seconds for one epoch ---
--- 1.7692747116088867 seconds for one epoch ---
--- 0.3050832748413086 seconds for one epoch ---
--- 1.7114582061767578 seconds for one epoch ---
--- 0.30765557289123535 seconds for one epoch ---
--- 1.71500825881958 seconds for one epoch ---
--- 0.30333900451660156 seconds for one epoch ---
--- 1.7073338031768799 seconds for one epoch ---
--- 0.30391597747802734 seconds for one epoch ---
--- 1.7581629753112793 seconds for one epoch ---
--- 0.30929994583129883 seconds for one epoch ---
--- 1.7724602222442627 seconds for one epoch ---
--- 0.3052082061767578 seconds for one epoch ---
--- 1.7513177394866943 seconds for one epoch ---
--- 0.3150672912597656 seconds for one epoch ---
--- 1.7544398307800293 seconds for one epoch ---
--- 0.30518674850463867 seconds for one epoch ---
--- 1.7859776020050049 seconds for one epoch ---
--- 0.31217432022094727 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.333523]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.822771]
 [ -0.      ]]
--- 0.26669740676879883 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6337.796875, (1812.6891, 1.9750383, 4522.8853, 0.24734075)
   validation loss 890.843994140625, (515.3172, 1.0557246, 374.22375, 0.24734075)
decoder loss ratio: 19964.282947, decoder SINDy loss  ratio: 0.807815
--- 0.30916357040405273 seconds for one epoch ---
--- 1.778223991394043 seconds for one epoch ---
--- 0.3162240982055664 seconds for one epoch ---
--- 1.7551937103271484 seconds for one epoch ---
--- 0.30344080924987793 seconds for one epoch ---
--- 1.7487492561340332 seconds for one epoch ---
--- 0.31350064277648926 seconds for one epoch ---
--- 1.794806718826294 seconds for one epoch ---
--- 0.32009267807006836 seconds for one epoch ---
--- 1.7336974143981934 seconds for one epoch ---
--- 0.3126962184906006 seconds for one epoch ---
--- 1.7184062004089355 seconds for one epoch ---
--- 0.30480194091796875 seconds for one epoch ---
--- 1.7177832126617432 seconds for one epoch ---
--- 0.30687546730041504 seconds for one epoch ---
--- 1.7182347774505615 seconds for one epoch ---
--- 0.2978365421295166 seconds for one epoch ---
--- 1.7695660591125488 seconds for one epoch ---
--- 0.30783653259277344 seconds for one epoch ---
--- 1.7772889137268066 seconds for one epoch ---
--- 0.30645203590393066 seconds for one epoch ---
--- 1.8098180294036865 seconds for one epoch ---
--- 0.3085751533508301 seconds for one epoch ---
--- 1.8007111549377441 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.331797]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.867506]
 [  0.      ]]
--- 0.3033435344696045 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4473.08056640625, (1388.9585, 1.5857915, 3082.2886, 0.24748722)
   validation loss 946.4962768554688, (588.5091, 0.916246, 356.8234, 0.24748722)
decoder loss ratio: 22799.864008, decoder SINDy loss  ratio: 0.770253
--- 0.27243518829345703 seconds for one epoch ---
--- 0.30895519256591797 seconds for one epoch ---
--- 1.7980878353118896 seconds for one epoch ---
--- 0.31448793411254883 seconds for one epoch ---
--- 1.8075916767120361 seconds for one epoch ---
--- 0.3146073818206787 seconds for one epoch ---
--- 1.8141064643859863 seconds for one epoch ---
--- 0.3132450580596924 seconds for one epoch ---
--- 1.7936298847198486 seconds for one epoch ---
--- 0.3095088005065918 seconds for one epoch ---
--- 1.7728767395019531 seconds for one epoch ---
--- 0.3015413284301758 seconds for one epoch ---
--- 1.753371238708496 seconds for one epoch ---
--- 0.309751033782959 seconds for one epoch ---
--- 1.792781114578247 seconds for one epoch ---
--- 0.31009674072265625 seconds for one epoch ---
--- 1.8035485744476318 seconds for one epoch ---
--- 0.3279871940612793 seconds for one epoch ---
--- 1.7871942520141602 seconds for one epoch ---
--- 0.339235782623291 seconds for one epoch ---
--- 1.819760799407959 seconds for one epoch ---
--- 0.37319493293762207 seconds for one epoch ---
--- 1.81829833984375 seconds for one epoch ---
--- 0.3657724857330322 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33025017]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.90729]
 [  0.     ]]
--- 0.2736544609069824 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4128.4423828125, (1993.248, 0.47149837, 2134.4753, 0.24759968)
   validation loss 854.4602661132812, (487.03116, 0.9374242, 366.24402, 0.24759968)
decoder loss ratio: 18868.432602, decoder SINDy loss  ratio: 0.790589
--- 0.3096017837524414 seconds for one epoch ---
--- 1.7849183082580566 seconds for one epoch ---
--- 0.30599069595336914 seconds for one epoch ---
--- 1.7757792472839355 seconds for one epoch ---
--- 0.30516982078552246 seconds for one epoch ---
--- 1.7950584888458252 seconds for one epoch ---
--- 0.3106989860534668 seconds for one epoch ---
--- 1.807116985321045 seconds for one epoch ---
--- 0.3081214427947998 seconds for one epoch ---
--- 1.7848176956176758 seconds for one epoch ---
--- 0.30509305000305176 seconds for one epoch ---
--- 1.7338268756866455 seconds for one epoch ---
--- 0.30519628524780273 seconds for one epoch ---
--- 1.7459337711334229 seconds for one epoch ---
--- 0.30330371856689453 seconds for one epoch ---
--- 1.769639492034912 seconds for one epoch ---
--- 0.30237746238708496 seconds for one epoch ---
--- 1.8165740966796875 seconds for one epoch ---
--- 0.31696653366088867 seconds for one epoch ---
--- 1.824232816696167 seconds for one epoch ---
--- 0.3118927478790283 seconds for one epoch ---
--- 1.8112373352050781 seconds for one epoch ---
--- 0.3073747158050537 seconds for one epoch ---
--- 1.837651014328003 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32897925]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.939806]
 [  0.      ]]
--- 0.3030858039855957 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2189.375244140625, (1263.1313, 0.7183581, 925.27765, 0.24770947)
   validation loss 979.9149780273438, (641.30804, 0.8723073, 337.48694, 0.24770947)
decoder loss ratio: 24845.387001, decoder SINDy loss  ratio: 0.728513
--- 0.26569294929504395 seconds for one epoch ---
--- 0.31387758255004883 seconds for one epoch ---
--- 1.8150389194488525 seconds for one epoch ---
--- 0.3090026378631592 seconds for one epoch ---
--- 1.8164122104644775 seconds for one epoch ---
--- 0.315427303314209 seconds for one epoch ---
--- 1.8298635482788086 seconds for one epoch ---
--- 0.31618595123291016 seconds for one epoch ---
--- 1.8412182331085205 seconds for one epoch ---
--- 0.3062772750854492 seconds for one epoch ---
--- 1.7927546501159668 seconds for one epoch ---
--- 0.3079831600189209 seconds for one epoch ---
--- 1.7841205596923828 seconds for one epoch ---
--- 0.32239365577697754 seconds for one epoch ---
--- 1.7791566848754883 seconds for one epoch ---
--- 0.3038370609283447 seconds for one epoch ---
--- 1.8161311149597168 seconds for one epoch ---
--- 0.3057088851928711 seconds for one epoch ---
--- 1.8437511920928955 seconds for one epoch ---
--- 0.31351256370544434 seconds for one epoch ---
--- 1.8404290676116943 seconds for one epoch ---
--- 0.3103036880493164 seconds for one epoch ---
--- 1.840240716934204 seconds for one epoch ---
--- 0.3162713050842285 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32710114]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.987534]
 [ -0.      ]]
--- 0.2618753910064697 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3693.555419921875, (905.0237, 0.83122605, 2787.4526, 0.24784873)
   validation loss 1290.732666015625, (862.08264, 1.0818591, 427.32034, 0.24784873)
decoder loss ratio: 33398.578177, decoder SINDy loss  ratio: 0.922431
--- 0.3106966018676758 seconds for one epoch ---
--- 1.821810007095337 seconds for one epoch ---
--- 0.31853413581848145 seconds for one epoch ---
--- 1.83262300491333 seconds for one epoch ---
--- 0.3174009323120117 seconds for one epoch ---
--- 1.834662914276123 seconds for one epoch ---
--- 0.3205373287200928 seconds for one epoch ---
--- 1.8511896133422852 seconds for one epoch ---
--- 0.31653571128845215 seconds for one epoch ---
--- 1.80061936378479 seconds for one epoch ---
--- 0.3039429187774658 seconds for one epoch ---
--- 1.8138360977172852 seconds for one epoch ---
--- 0.3103218078613281 seconds for one epoch ---
--- 1.8106396198272705 seconds for one epoch ---
--- 0.3152315616607666 seconds for one epoch ---
--- 1.8192918300628662 seconds for one epoch ---
--- 0.3097951412200928 seconds for one epoch ---
--- 1.8369758129119873 seconds for one epoch ---
--- 0.33018040657043457 seconds for one epoch ---
--- 1.8301734924316406 seconds for one epoch ---
--- 0.3183403015136719 seconds for one epoch ---
--- 1.808413028717041 seconds for one epoch ---
--- 0.31114959716796875 seconds for one epoch ---
--- 1.8329029083251953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32548004]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.028427]
 [ -0.      ]]
--- 0.30461621284484863 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2607.794677734375, (687.56934, 1.8648208, 1918.1125, 0.24797438)
   validation loss 978.0775756835938, (617.95325, 0.98801714, 358.88828, 0.24797438)
decoder loss ratio: 23940.581606, decoder SINDy loss  ratio: 0.774711
--- 0.27317237854003906 seconds for one epoch ---
--- 0.30643248558044434 seconds for one epoch ---
--- 1.807096242904663 seconds for one epoch ---
--- 0.3052701950073242 seconds for one epoch ---
--- 1.8156342506408691 seconds for one epoch ---
--- 0.3101377487182617 seconds for one epoch ---
--- 1.8346645832061768 seconds for one epoch ---
--- 0.3114166259765625 seconds for one epoch ---
--- 1.8382503986358643 seconds for one epoch ---
--- 0.30623674392700195 seconds for one epoch ---
--- 1.7978088855743408 seconds for one epoch ---
--- 0.3068380355834961 seconds for one epoch ---
--- 1.7961726188659668 seconds for one epoch ---
--- 0.30424952507019043 seconds for one epoch ---
--- 1.8008406162261963 seconds for one epoch ---
--- 0.31235456466674805 seconds for one epoch ---
--- 1.8033370971679688 seconds for one epoch ---
--- 0.310117244720459 seconds for one epoch ---
--- 1.8768947124481201 seconds for one epoch ---
--- 0.31432271003723145 seconds for one epoch ---
--- 1.8847706317901611 seconds for one epoch ---
--- 0.3165709972381592 seconds for one epoch ---
--- 1.859757900238037 seconds for one epoch ---
--- 0.308086633682251 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32417458]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.061172]
 [ -0.      ]]
--- 0.2704346179962158 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3554.6396484375, (1408.6958, 2.3957279, 2143.3, 0.24805765)
   validation loss 979.5631103515625, (629.4969, 0.8761496, 348.94205, 0.24805765)
decoder loss ratio: 24387.802265, decoder SINDy loss  ratio: 0.753240
--- 0.3133885860443115 seconds for one epoch ---
--- 1.8571367263793945 seconds for one epoch ---
--- 0.30959391593933105 seconds for one epoch ---
--- 1.859260082244873 seconds for one epoch ---
--- 0.30347657203674316 seconds for one epoch ---
--- 1.8633418083190918 seconds for one epoch ---
--- 0.3215501308441162 seconds for one epoch ---
--- 1.879262924194336 seconds for one epoch ---
--- 0.31621837615966797 seconds for one epoch ---
--- 1.8726365566253662 seconds for one epoch ---
--- 0.31070828437805176 seconds for one epoch ---
--- 1.8191359043121338 seconds for one epoch ---
--- 0.31124448776245117 seconds for one epoch ---
--- 1.8435935974121094 seconds for one epoch ---
--- 0.3067970275878906 seconds for one epoch ---
--- 1.8447847366333008 seconds for one epoch ---
--- 0.3097653388977051 seconds for one epoch ---
--- 1.8566009998321533 seconds for one epoch ---
--- 0.31084179878234863 seconds for one epoch ---
--- 1.8617713451385498 seconds for one epoch ---
--- 0.30704283714294434 seconds for one epoch ---
--- 1.8415324687957764 seconds for one epoch ---
--- 0.3066082000732422 seconds for one epoch ---
--- 1.8317413330078125 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3225935]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.100595]
 [  0.      ]]
--- 0.30781102180480957 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2167.349853515625, (1227.4045, 1.5469568, 938.1502, 0.24816294)
   validation loss 962.3187255859375, (588.688, 1.0722674, 372.31027, 0.24816294)
decoder loss ratio: 22806.794673, decoder SINDy loss  ratio: 0.803684
--- 0.2677788734436035 seconds for one epoch ---
--- 0.30376601219177246 seconds for one epoch ---
--- 1.858036994934082 seconds for one epoch ---
--- 0.3084278106689453 seconds for one epoch ---
--- 1.8230984210968018 seconds for one epoch ---
--- 0.3048367500305176 seconds for one epoch ---
--- 1.836975336074829 seconds for one epoch ---
--- 0.3176579475402832 seconds for one epoch ---
--- 1.8484137058258057 seconds for one epoch ---
--- 0.30617189407348633 seconds for one epoch ---
--- 1.7824347019195557 seconds for one epoch ---
--- 0.3027341365814209 seconds for one epoch ---
--- 1.8001775741577148 seconds for one epoch ---
--- 0.32422733306884766 seconds for one epoch ---
--- 1.808701753616333 seconds for one epoch ---
--- 0.30786800384521484 seconds for one epoch ---
--- 1.807873010635376 seconds for one epoch ---
--- 0.3143126964569092 seconds for one epoch ---
--- 1.877938985824585 seconds for one epoch ---
--- 0.31031250953674316 seconds for one epoch ---
--- 1.8512132167816162 seconds for one epoch ---
--- 0.29929113388061523 seconds for one epoch ---
--- 1.8726987838745117 seconds for one epoch ---
--- 0.3146030902862549 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32100126]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.14008]
 [  0.     ]]
--- 0.2649972438812256 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3608.718017578125, (1676.0966, 2.9910414, 1929.3822, 0.2482673)
   validation loss 929.8895263671875, (574.3521, 0.9987931, 354.29034, 0.2482673)
decoder loss ratio: 22251.397931, decoder SINDy loss  ratio: 0.764786
--- 0.31096339225769043 seconds for one epoch ---
--- 1.878960132598877 seconds for one epoch ---
--- 0.3291623592376709 seconds for one epoch ---
--- 1.8815810680389404 seconds for one epoch ---
--- 0.31812262535095215 seconds for one epoch ---
--- 1.8684756755828857 seconds for one epoch ---
--- 0.31176066398620605 seconds for one epoch ---
--- 1.8900954723358154 seconds for one epoch ---
--- 0.3073110580444336 seconds for one epoch ---
--- 1.8950574398040771 seconds for one epoch ---
--- 0.31433773040771484 seconds for one epoch ---
--- 1.855217456817627 seconds for one epoch ---
--- 0.30563998222351074 seconds for one epoch ---
--- 1.8624849319458008 seconds for one epoch ---
--- 0.3063380718231201 seconds for one epoch ---
--- 1.8657288551330566 seconds for one epoch ---
--- 0.30568575859069824 seconds for one epoch ---
--- 1.8526606559753418 seconds for one epoch ---
--- 0.2835197448730469 seconds for one epoch ---
--- 1.8549549579620361 seconds for one epoch ---
--- 0.3053436279296875 seconds for one epoch ---
--- 1.8790528774261475 seconds for one epoch ---
--- 0.30742645263671875 seconds for one epoch ---
--- 1.8958091735839844 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31954902]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.175877]
 [  0.      ]]
--- 0.30328941345214844 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2802.835693359375, (1151.1201, 2.4710238, 1648.9961, 0.24835916)
   validation loss 1002.5186157226562, (596.89355, 1.1732594, 404.20343, 0.24835916)
decoder loss ratio: 23124.692561, decoder SINDy loss  ratio: 0.872530
--- 0.2740356922149658 seconds for one epoch ---
--- 0.31599903106689453 seconds for one epoch ---
--- 1.8409557342529297 seconds for one epoch ---
--- 0.3117811679840088 seconds for one epoch ---
--- 1.8463423252105713 seconds for one epoch ---
--- 0.3089110851287842 seconds for one epoch ---
--- 1.8599565029144287 seconds for one epoch ---
--- 0.30532050132751465 seconds for one epoch ---
--- 1.8954579830169678 seconds for one epoch ---
--- 0.30921363830566406 seconds for one epoch ---
--- 1.8427083492279053 seconds for one epoch ---
--- 0.302065372467041 seconds for one epoch ---
--- 1.8404955863952637 seconds for one epoch ---
--- 0.309917688369751 seconds for one epoch ---
--- 1.8315160274505615 seconds for one epoch ---
--- 0.30977392196655273 seconds for one epoch ---
--- 1.8448436260223389 seconds for one epoch ---
--- 0.30318188667297363 seconds for one epoch ---
--- 1.8552258014678955 seconds for one epoch ---
--- 0.30570387840270996 seconds for one epoch ---
--- 1.8843743801116943 seconds for one epoch ---
--- 0.307340145111084 seconds for one epoch ---
--- 1.8949484825134277 seconds for one epoch ---
--- 0.32283735275268555 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31816787]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.209768]
 [ -0.      ]]
--- 0.26875901222229004 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2987.96142578125, (1122.645, 0.689731, 1864.3782, 0.2484392)
   validation loss 916.3803100585938, (545.8745, 0.9867392, 369.27063, 0.2484392)
decoder loss ratio: 21148.126264, decoder SINDy loss  ratio: 0.797123
--- 0.3056645393371582 seconds for one epoch ---
--- 1.8875186443328857 seconds for one epoch ---
--- 0.3126187324523926 seconds for one epoch ---
--- 1.8804552555084229 seconds for one epoch ---
--- 0.3047604560852051 seconds for one epoch ---
--- 1.8823213577270508 seconds for one epoch ---
--- 0.30381321907043457 seconds for one epoch ---
--- 1.8665673732757568 seconds for one epoch ---
--- 0.30669236183166504 seconds for one epoch ---
--- 1.8957490921020508 seconds for one epoch ---
--- 0.30640101432800293 seconds for one epoch ---
--- 1.9189796447753906 seconds for one epoch ---
--- 0.30911946296691895 seconds for one epoch ---
--- 1.842653751373291 seconds for one epoch ---
--- 0.3043947219848633 seconds for one epoch ---
--- 1.839043140411377 seconds for one epoch ---
--- 0.30674099922180176 seconds for one epoch ---
--- 1.844635009765625 seconds for one epoch ---
--- 0.3027491569519043 seconds for one epoch ---
--- 1.8501429557800293 seconds for one epoch ---
--- 0.30632472038269043 seconds for one epoch ---
--- 1.9103100299835205 seconds for one epoch ---
--- 0.31851768493652344 seconds for one epoch ---
--- 1.895164966583252 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31669706]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.245653]
 [ -0.      ]]
--- 0.303555965423584 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3479.896484375, (1802.5728, 0.844292, 1676.2311, 0.24852037)
   validation loss 933.6318359375, (518.23914, 1.1639007, 413.98026, 0.24852037)
decoder loss ratio: 20077.483821, decoder SINDy loss  ratio: 0.893635
--- 0.27425098419189453 seconds for one epoch ---
--- 0.3052220344543457 seconds for one epoch ---
--- 1.9096877574920654 seconds for one epoch ---
--- 0.3081820011138916 seconds for one epoch ---
--- 1.9314188957214355 seconds for one epoch ---
--- 0.3122591972351074 seconds for one epoch ---
--- 1.9245107173919678 seconds for one epoch ---
--- 0.3271760940551758 seconds for one epoch ---
--- 1.926513671875 seconds for one epoch ---
--- 0.32010722160339355 seconds for one epoch ---
--- 1.9447503089904785 seconds for one epoch ---
--- 0.3198204040527344 seconds for one epoch ---
--- 1.888502836227417 seconds for one epoch ---
--- 0.3177306652069092 seconds for one epoch ---
--- 1.9052140712738037 seconds for one epoch ---
--- 0.315448522567749 seconds for one epoch ---
--- 1.8894784450531006 seconds for one epoch ---
--- 0.30167531967163086 seconds for one epoch ---
--- 1.908583402633667 seconds for one epoch ---
--- 0.30895519256591797 seconds for one epoch ---
--- 1.9254629611968994 seconds for one epoch ---
--- 0.30313754081726074 seconds for one epoch ---
--- 1.8881330490112305 seconds for one epoch ---
--- 0.29827880859375 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31539518]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.277279]
 [ -0.      ]]
--- 0.2691464424133301 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3652.50927734375, (1704.0684, 1.5432802, 1946.649, 0.24859396)
   validation loss 1014.1014404296875, (580.06396, 1.1802238, 432.60864, 0.24859396)
decoder loss ratio: 22472.685033, decoder SINDy loss  ratio: 0.933847
--- 0.3054780960083008 seconds for one epoch ---
--- 1.912278652191162 seconds for one epoch ---
--- 0.31343770027160645 seconds for one epoch ---
--- 1.9084327220916748 seconds for one epoch ---
--- 0.32836222648620605 seconds for one epoch ---
--- 1.886582851409912 seconds for one epoch ---
--- 0.30621981620788574 seconds for one epoch ---
--- 1.9031338691711426 seconds for one epoch ---
--- 0.3042893409729004 seconds for one epoch ---
--- 1.9065804481506348 seconds for one epoch ---
--- 0.3075683116912842 seconds for one epoch ---
--- 1.9077723026275635 seconds for one epoch ---
--- 0.306671142578125 seconds for one epoch ---
--- 1.9053435325622559 seconds for one epoch ---
--- 0.30481505393981934 seconds for one epoch ---
--- 1.9259459972381592 seconds for one epoch ---
--- 0.3072655200958252 seconds for one epoch ---
--- 1.910266637802124 seconds for one epoch ---
--- 0.3130195140838623 seconds for one epoch ---
--- 1.8981359004974365 seconds for one epoch ---
--- 0.3126859664916992 seconds for one epoch ---
--- 1.905837059020996 seconds for one epoch ---
--- 0.3134958744049072 seconds for one epoch ---
--- 1.9412765502929688 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3137892]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.316092]
 [  0.      ]]
--- 0.30989623069763184 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2254.34814453125, (1300.6017, 1.748524, 951.7491, 0.24867082)
   validation loss 1084.2860107421875, (649.4331, 1.2555532, 433.34872, 0.24867082)
decoder loss ratio: 25160.165971, decoder SINDy loss  ratio: 0.935444
THRESHOLDING: 1 active coefficients
--- 1.8667523860931396 seconds for one epoch ---
--- 0.3065183162689209 seconds for one epoch ---
--- 1.9018404483795166 seconds for one epoch ---
--- 0.3072786331176758 seconds for one epoch ---
--- 1.9294779300689697 seconds for one epoch ---
--- 0.3159501552581787 seconds for one epoch ---
--- 1.9419701099395752 seconds for one epoch ---
--- 0.3372211456298828 seconds for one epoch ---
--- 1.943514108657837 seconds for one epoch ---
--- 0.3480408191680908 seconds for one epoch ---
--- 1.938478708267212 seconds for one epoch ---
--- 0.34932637214660645 seconds for one epoch ---
--- 1.9127306938171387 seconds for one epoch ---
--- 0.3654813766479492 seconds for one epoch ---
--- 1.9527852535247803 seconds for one epoch ---
--- 0.349348783493042 seconds for one epoch ---
--- 1.979384183883667 seconds for one epoch ---
--- 0.3652637004852295 seconds for one epoch ---
--- 1.9119632244110107 seconds for one epoch ---
--- 0.35416388511657715 seconds for one epoch ---
--- 1.9819443225860596 seconds for one epoch ---
--- 0.34824705123901367 seconds for one epoch ---
--- 1.9688823223114014 seconds for one epoch ---
--- 0.34793996810913086 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3119925]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.35928]
 [  0.     ]]
--- 0.27401018142700195 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4065.881103515625, (1406.7296, 1.4612465, 2657.4414, 0.24876527)
   validation loss 1129.0289306640625, (690.45306, 1.2710916, 437.05594, 0.24876527)
decoder loss ratio: 26749.350377, decoder SINDy loss  ratio: 0.943447
--- 0.30248570442199707 seconds for one epoch ---
--- 1.9558093547821045 seconds for one epoch ---
--- 0.32065582275390625 seconds for one epoch ---
--- 1.9808268547058105 seconds for one epoch ---
--- 0.30794548988342285 seconds for one epoch ---
--- 1.970580816268921 seconds for one epoch ---
--- 0.3158848285675049 seconds for one epoch ---
--- 1.9684972763061523 seconds for one epoch ---
--- 0.3165464401245117 seconds for one epoch ---
--- 1.9808895587921143 seconds for one epoch ---
--- 0.31569743156433105 seconds for one epoch ---
--- 1.9589805603027344 seconds for one epoch ---
--- 0.3160512447357178 seconds for one epoch ---
--- 2.022263288497925 seconds for one epoch ---
--- 0.3145449161529541 seconds for one epoch ---
--- 1.9398446083068848 seconds for one epoch ---
--- 0.30759334564208984 seconds for one epoch ---
--- 1.949066400527954 seconds for one epoch ---
--- 0.3053774833679199 seconds for one epoch ---
--- 1.9528000354766846 seconds for one epoch ---
--- 0.3077676296234131 seconds for one epoch ---
--- 1.9571409225463867 seconds for one epoch ---
--- 0.3087751865386963 seconds for one epoch ---
--- 1.9760403633117676 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31072378]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.389624]
 [  0.      ]]
--- 0.3106966018676758 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3003.191650390625, (1412.0917, 1.0558012, 1589.7953, 0.24881482)
   validation loss 1286.994873046875, (859.5283, 1.1782023, 426.03958, 0.24881482)
decoder loss ratio: 33299.619336, decoder SINDy loss  ratio: 0.919666
--- 0.2783203125 seconds for one epoch ---
--- 0.31279730796813965 seconds for one epoch ---
--- 1.994720220565796 seconds for one epoch ---
--- 0.3119053840637207 seconds for one epoch ---
--- 1.9929461479187012 seconds for one epoch ---
--- 0.31678032875061035 seconds for one epoch ---
--- 1.9925076961517334 seconds for one epoch ---
--- 0.3121206760406494 seconds for one epoch ---
--- 1.9940497875213623 seconds for one epoch ---
--- 0.32135486602783203 seconds for one epoch ---
--- 2.0083396434783936 seconds for one epoch ---
--- 0.3170444965362549 seconds for one epoch ---
--- 2.010732889175415 seconds for one epoch ---
--- 0.32373690605163574 seconds for one epoch ---
--- 1.9383268356323242 seconds for one epoch ---
--- 0.31224679946899414 seconds for one epoch ---
--- 1.9676861763000488 seconds for one epoch ---
--- 0.30838847160339355 seconds for one epoch ---
--- 1.9662351608276367 seconds for one epoch ---
--- 0.3132059574127197 seconds for one epoch ---
--- 1.954521894454956 seconds for one epoch ---
--- 0.27721667289733887 seconds for one epoch ---
--- 1.9996180534362793 seconds for one epoch ---
--- 0.32114362716674805 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30961525]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.416052]
 [ -0.      ]]
--- 0.27238035202026367 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4066.032958984375, (1096.1226, 3.3840015, 2966.2776, 0.24886584)
   validation loss 1028.5263671875, (672.6711, 1.0170664, 354.58926, 0.24886584)
decoder loss ratio: 26060.445507, decoder SINDy loss  ratio: 0.765431
--- 0.3355700969696045 seconds for one epoch ---
--- 1.965632677078247 seconds for one epoch ---
--- 0.31374502182006836 seconds for one epoch ---
--- 1.9898178577423096 seconds for one epoch ---
--- 0.31578707695007324 seconds for one epoch ---
--- 1.9644017219543457 seconds for one epoch ---
--- 0.3034627437591553 seconds for one epoch ---
--- 1.9709961414337158 seconds for one epoch ---
--- 0.3086514472961426 seconds for one epoch ---
--- 1.9768574237823486 seconds for one epoch ---
--- 0.3072850704193115 seconds for one epoch ---
--- 1.982689619064331 seconds for one epoch ---
--- 0.3116018772125244 seconds for one epoch ---
--- 1.993333339691162 seconds for one epoch ---
--- 0.3031575679779053 seconds for one epoch ---
--- 1.9388773441314697 seconds for one epoch ---
--- 0.31010866165161133 seconds for one epoch ---
--- 1.9581019878387451 seconds for one epoch ---
--- 0.3055868148803711 seconds for one epoch ---
--- 1.9590394496917725 seconds for one epoch ---
--- 0.30629801750183105 seconds for one epoch ---
--- 1.9339261054992676 seconds for one epoch ---
--- 0.2879002094268799 seconds for one epoch ---
--- 1.9868390560150146 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30873784]
 [0.        ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-17.4369]
 [ -0.    ]]
--- 0.31209588050842285 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2226.3662109375, (918.9459, 0.84743416, 1306.3239, 0.24890505)
   validation loss 1189.3497314453125, (808.27484, 1.106735, 379.71918, 0.24890505)
decoder loss ratio: 31313.970579, decoder SINDy loss  ratio: 0.819677
--- 0.26625561714172363 seconds for one epoch ---
--- 0.309018611907959 seconds for one epoch ---
--- 2.0151429176330566 seconds for one epoch ---
--- 0.3117105960845947 seconds for one epoch ---
--- 1.9766740798950195 seconds for one epoch ---
--- 0.30950117111206055 seconds for one epoch ---
--- 1.993389368057251 seconds for one epoch ---
--- 0.3039431571960449 seconds for one epoch ---
--- 1.9907426834106445 seconds for one epoch ---
--- 0.3042452335357666 seconds for one epoch ---
--- 1.9876031875610352 seconds for one epoch ---
--- 0.3090949058532715 seconds for one epoch ---
--- 2.0019476413726807 seconds for one epoch ---
--- 0.3080782890319824 seconds for one epoch ---
--- 1.9529180526733398 seconds for one epoch ---
--- 0.30228686332702637 seconds for one epoch ---
--- 1.9435632228851318 seconds for one epoch ---
--- 0.3047811985015869 seconds for one epoch ---
--- 1.941206693649292 seconds for one epoch ---
--- 0.31329917907714844 seconds for one epoch ---
--- 1.9401092529296875 seconds for one epoch ---
--- 0.303255558013916 seconds for one epoch ---
--- 1.9953725337982178 seconds for one epoch ---
--- 0.31351208686828613 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30774513]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.460415]
 [ -0.      ]]
--- 0.26627445220947266 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3924.369873046875, (2262.6643, 1.7415601, 1659.7151, 0.24894504)
   validation loss 1246.795166015625, (878.7761, 1.1023486, 366.66782, 0.24894504)
decoder loss ratio: 34045.312629, decoder SINDy loss  ratio: 0.791504
--- 0.3026289939880371 seconds for one epoch ---
--- 1.9761805534362793 seconds for one epoch ---
--- 0.31392335891723633 seconds for one epoch ---
--- 2.0315725803375244 seconds for one epoch ---
--- 0.312422513961792 seconds for one epoch ---
--- 2.0342183113098145 seconds for one epoch ---
--- 0.3085930347442627 seconds for one epoch ---
--- 2.010618209838867 seconds for one epoch ---
--- 0.30600523948669434 seconds for one epoch ---
--- 2.017294406890869 seconds for one epoch ---
--- 0.31582093238830566 seconds for one epoch ---
--- 2.016505241394043 seconds for one epoch ---
--- 0.3087732791900635 seconds for one epoch ---
--- 2.039931297302246 seconds for one epoch ---
--- 0.3150458335876465 seconds for one epoch ---
--- 2.0378317832946777 seconds for one epoch ---
--- 0.31020188331604004 seconds for one epoch ---
--- 1.9721240997314453 seconds for one epoch ---
--- 0.31586694717407227 seconds for one epoch ---
--- 2.000748634338379 seconds for one epoch ---
--- 0.310680627822876 seconds for one epoch ---
--- 1.982025146484375 seconds for one epoch ---
--- 0.3069794178009033 seconds for one epoch ---
--- 1.9877848625183105 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30639493]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.492287]
 [  0.      ]]
--- 0.2992429733276367 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3926.658935546875, (1689.6779, 0.85266715, 2235.8794, 0.24899876)
   validation loss 1041.177978515625, (695.5935, 1.003525, 344.3319, 0.24899876)
decoder loss ratio: 26948.500020, decoder SINDy loss  ratio: 0.743289
--- 0.2742457389831543 seconds for one epoch ---
--- 0.30539989471435547 seconds for one epoch ---
--- 2.021395444869995 seconds for one epoch ---
--- 0.305631160736084 seconds for one epoch ---
--- 2.007403612136841 seconds for one epoch ---
--- 0.3138160705566406 seconds for one epoch ---
--- 2.007383346557617 seconds for one epoch ---
--- 0.3071780204772949 seconds for one epoch ---
--- 2.0090091228485107 seconds for one epoch ---
--- 0.3078477382659912 seconds for one epoch ---
--- 1.9874560832977295 seconds for one epoch ---
--- 0.31173110008239746 seconds for one epoch ---
--- 2.006392478942871 seconds for one epoch ---
--- 0.31024813652038574 seconds for one epoch ---
--- 2.037064790725708 seconds for one epoch ---
--- 0.3100714683532715 seconds for one epoch ---
--- 1.9716672897338867 seconds for one epoch ---
--- 0.3005392551422119 seconds for one epoch ---
--- 1.9857397079467773 seconds for one epoch ---
--- 0.30788445472717285 seconds for one epoch ---
--- 1.9661178588867188 seconds for one epoch ---
--- 0.30477261543273926 seconds for one epoch ---
--- 1.9809892177581787 seconds for one epoch ---
--- 0.30538344383239746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3053502]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.516874]
 [  0.      ]]
--- 0.27320218086242676 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2412.90087890625, (983.9948, 1.3666481, 1427.2903, 0.24903722)
   validation loss 1095.1456298828125, (755.13586, 0.9425548, 338.81815, 0.24903722)
decoder loss ratio: 29255.274355, decoder SINDy loss  ratio: 0.731387
--- 0.3290829658508301 seconds for one epoch ---
--- 2.075078010559082 seconds for one epoch ---
--- 0.34056782722473145 seconds for one epoch ---
--- 2.056730031967163 seconds for one epoch ---
--- 0.33516955375671387 seconds for one epoch ---
--- 2.049715757369995 seconds for one epoch ---
--- 0.3162052631378174 seconds for one epoch ---
--- 2.0456326007843018 seconds for one epoch ---
--- 0.31439971923828125 seconds for one epoch ---
--- 2.040895938873291 seconds for one epoch ---
--- 0.3044443130493164 seconds for one epoch ---
--- 2.0300650596618652 seconds for one epoch ---
--- 0.31421327590942383 seconds for one epoch ---
--- 2.0470314025878906 seconds for one epoch ---
--- 0.31296706199645996 seconds for one epoch ---
--- 2.0978288650512695 seconds for one epoch ---
--- 0.3071463108062744 seconds for one epoch ---
--- 2.032864809036255 seconds for one epoch ---
--- 0.31092119216918945 seconds for one epoch ---
--- 2.022902727127075 seconds for one epoch ---
--- 0.3088352680206299 seconds for one epoch ---
--- 2.0220398902893066 seconds for one epoch ---
--- 0.3078420162200928 seconds for one epoch ---
--- 2.0230696201324463 seconds for one epoch ---
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.30452]
 [0.     ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.536346]
 [  0.      ]]
--- 0.3056797981262207 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4663.2392578125, (2181.3936, 1.7049274, 2479.892, 0.24906543)
   validation loss 1148.2803955078125, (759.2854, 1.2115748, 387.5344, 0.24906543)
decoder loss ratio: 29416.034589, decoder SINDy loss  ratio: 0.836547
--- 0.2768104076385498 seconds for one epoch ---
--- 0.31776881217956543 seconds for one epoch ---
--- 2.0607454776763916 seconds for one epoch ---
--- 0.3078746795654297 seconds for one epoch ---
--- 2.0398242473602295 seconds for one epoch ---
--- 0.31152796745300293 seconds for one epoch ---
--- 2.0680770874023438 seconds for one epoch ---
--- 0.30664753913879395 seconds for one epoch ---
--- 2.0704257488250732 seconds for one epoch ---
--- 0.310347318649292 seconds for one epoch ---
--- 2.061209201812744 seconds for one epoch ---
--- 0.3177967071533203 seconds for one epoch ---
--- 2.0516695976257324 seconds for one epoch ---
--- 0.31442785263061523 seconds for one epoch ---
--- 2.083625555038452 seconds for one epoch ---
--- 0.3120462894439697 seconds for one epoch ---
--- 2.0138676166534424 seconds for one epoch ---
--- 0.3055531978607178 seconds for one epoch ---
--- 2.0252292156219482 seconds for one epoch ---
--- 0.31432127952575684 seconds for one epoch ---
--- 2.0369081497192383 seconds for one epoch ---
--- 0.3102242946624756 seconds for one epoch ---
--- 2.032474994659424 seconds for one epoch ---
--- 0.3209707736968994 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30356193]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.558784]
 [ -0.      ]]
--- 0.2646923065185547 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3003.2958984375, (1148.5564, 0.50934976, 1853.981, 0.2491016)
   validation loss 903.6932983398438, (545.8217, 1.1191138, 356.50333, 0.2491016)
decoder loss ratio: 21146.080878, decoder SINDy loss  ratio: 0.769563
--- 0.3180222511291504 seconds for one epoch ---
--- 2.0451483726501465 seconds for one epoch ---
--- 0.31190013885498047 seconds for one epoch ---
--- 2.0507373809814453 seconds for one epoch ---
--- 0.31069064140319824 seconds for one epoch ---
--- 2.0650389194488525 seconds for one epoch ---
--- 0.30755019187927246 seconds for one epoch ---
--- 2.0477564334869385 seconds for one epoch ---
--- 0.3104417324066162 seconds for one epoch ---
--- 2.050973892211914 seconds for one epoch ---
--- 0.3095993995666504 seconds for one epoch ---
--- 2.06308913230896 seconds for one epoch ---
--- 0.30792689323425293 seconds for one epoch ---
--- 2.0825464725494385 seconds for one epoch ---
--- 0.3221256732940674 seconds for one epoch ---
--- 2.0625669956207275 seconds for one epoch ---
--- 0.3044474124908447 seconds for one epoch ---
--- 2.0002806186676025 seconds for one epoch ---
--- 0.3073453903198242 seconds for one epoch ---
--- 2.0186452865600586 seconds for one epoch ---
--- 0.3093373775482178 seconds for one epoch ---
--- 2.0227279663085938 seconds for one epoch ---
--- 0.30785298347473145 seconds for one epoch ---
--- 2.0332446098327637 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3025049]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.583456]
 [ -0.      ]]
--- 0.3067171573638916 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2547.830078125, (1075.0028, 3.0880346, 1469.4901, 0.2491365)
   validation loss 1051.8817138671875, (710.3112, 1.051736, 340.26965, 0.2491365)
decoder loss ratio: 27518.689750, decoder SINDy loss  ratio: 0.734520
--- 0.2853050231933594 seconds for one epoch ---
--- 0.31421589851379395 seconds for one epoch ---
--- 2.0821897983551025 seconds for one epoch ---
--- 0.31171488761901855 seconds for one epoch ---
--- 2.114502429962158 seconds for one epoch ---
--- 0.3118464946746826 seconds for one epoch ---
--- 2.113548755645752 seconds for one epoch ---
--- 0.31110382080078125 seconds for one epoch ---
--- 2.105504035949707 seconds for one epoch ---
--- 0.3126387596130371 seconds for one epoch ---
--- 2.077622413635254 seconds for one epoch ---
--- 0.3132314682006836 seconds for one epoch ---
--- 2.0962073802948 seconds for one epoch ---
--- 0.3260767459869385 seconds for one epoch ---
--- 2.1141088008880615 seconds for one epoch ---
--- 0.3190155029296875 seconds for one epoch ---
--- 2.1031455993652344 seconds for one epoch ---
--- 0.3182196617126465 seconds for one epoch ---
--- 2.0664286613464355 seconds for one epoch ---
--- 0.3170967102050781 seconds for one epoch ---
--- 2.0629007816314697 seconds for one epoch ---
--- 0.3166780471801758 seconds for one epoch ---
--- 2.066488265991211 seconds for one epoch ---
--- 0.3148519992828369 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.301284]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.611866]
 [ -0.      ]]
--- 0.273773193359375 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3391.843017578125, (1858.6919, 1.1330638, 1531.7688, 0.24917498)
   validation loss 1223.7900390625, (849.4988, 1.1098337, 372.93225, 0.24917498)
decoder loss ratio: 32911.057505, decoder SINDy loss  ratio: 0.805027
--- 0.30419158935546875 seconds for one epoch ---
--- 2.0757858753204346 seconds for one epoch ---
--- 0.30753111839294434 seconds for one epoch ---
--- 2.08418869972229 seconds for one epoch ---
--- 0.30675458908081055 seconds for one epoch ---
--- 2.0613479614257812 seconds for one epoch ---
--- 0.3072342872619629 seconds for one epoch ---
--- 2.077268123626709 seconds for one epoch ---
--- 0.30894899368286133 seconds for one epoch ---
--- 2.0629539489746094 seconds for one epoch ---
--- 0.30460047721862793 seconds for one epoch ---
--- 2.088329315185547 seconds for one epoch ---
--- 0.3054990768432617 seconds for one epoch ---
--- 2.0702264308929443 seconds for one epoch ---
--- 0.31502795219421387 seconds for one epoch ---
--- 2.102111339569092 seconds for one epoch ---
--- 0.30913853645324707 seconds for one epoch ---
--- 2.057314395904541 seconds for one epoch ---
--- 0.315723180770874 seconds for one epoch ---
--- 2.046403646469116 seconds for one epoch ---
--- 0.30300354957580566 seconds for one epoch ---
--- 2.039217233657837 seconds for one epoch ---
--- 0.6677088737487793 seconds for one epoch ---
--- 2.0530588626861572 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29988343]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.644342]
 [  0.      ]]
--- 0.3315153121948242 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3099.687255859375, (1396.047, 5.605566, 1697.7855, 0.24922256)
   validation loss 843.4953002929688, (492.1754, 0.97345215, 350.09726, 0.24922256)
decoder loss ratio: 19067.730033, decoder SINDy loss  ratio: 0.755734
--- 0.2924997806549072 seconds for one epoch ---
--- 0.3529856204986572 seconds for one epoch ---
--- 2.0916030406951904 seconds for one epoch ---
--- 0.35318732261657715 seconds for one epoch ---
--- 2.0921173095703125 seconds for one epoch ---
--- 0.3271610736846924 seconds for one epoch ---
--- 2.096661329269409 seconds for one epoch ---
--- 0.30963802337646484 seconds for one epoch ---
--- 2.0686588287353516 seconds for one epoch ---
--- 0.306976318359375 seconds for one epoch ---
--- 2.1017074584960938 seconds for one epoch ---
--- 0.3083171844482422 seconds for one epoch ---
--- 2.0732510089874268 seconds for one epoch ---
--- 0.31074070930480957 seconds for one epoch ---
--- 2.117295503616333 seconds for one epoch ---
--- 0.3186912536621094 seconds for one epoch ---
--- 2.097311496734619 seconds for one epoch ---
--- 0.30341553688049316 seconds for one epoch ---
--- 2.051201581954956 seconds for one epoch ---
--- 0.3022892475128174 seconds for one epoch ---
--- 2.0489614009857178 seconds for one epoch ---
--- 0.3076446056365967 seconds for one epoch ---
--- 2.0679242610931396 seconds for one epoch ---
--- 0.3083639144897461 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29886776]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.667816]
 [  0.      ]]
--- 0.2848846912384033 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3344.477294921875, (1139.3262, 4.0934305, 2200.8086, 0.24924736)
   validation loss 902.702392578125, (547.9041, 1.0896748, 353.45935, 0.24924736)
decoder loss ratio: 21226.756571, decoder SINDy loss  ratio: 0.762992
--- 0.3005049228668213 seconds for one epoch ---
--- 2.0911855697631836 seconds for one epoch ---
--- 0.318342924118042 seconds for one epoch ---
--- 2.1188061237335205 seconds for one epoch ---
--- 0.31422853469848633 seconds for one epoch ---
--- 2.088425874710083 seconds for one epoch ---
--- 0.30810976028442383 seconds for one epoch ---
--- 2.1131441593170166 seconds for one epoch ---
--- 0.31386542320251465 seconds for one epoch ---
--- 2.081230640411377 seconds for one epoch ---
--- 0.30992650985717773 seconds for one epoch ---
--- 2.094879627227783 seconds for one epoch ---
--- 0.30756473541259766 seconds for one epoch ---
--- 2.0957956314086914 seconds for one epoch ---
--- 0.30501389503479004 seconds for one epoch ---
--- 2.101743698120117 seconds for one epoch ---
--- 0.30869126319885254 seconds for one epoch ---
--- 2.146392822265625 seconds for one epoch ---
--- 0.30362558364868164 seconds for one epoch ---
--- 2.0744950771331787 seconds for one epoch ---
--- 0.3021891117095947 seconds for one epoch ---
--- 2.0793354511260986 seconds for one epoch ---
--- 0.3036215305328369 seconds for one epoch ---
--- 2.1031384468078613 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29773748]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.693886]
 [  0.      ]]
--- 0.30518150329589844 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5905.43994140625, (1395.8204, 1.6632432, 4507.7065, 0.24927826)
   validation loss 1008.318115234375, (663.98285, 1.0275955, 343.05844, 0.24927826)
decoder loss ratio: 25723.848300, decoder SINDy loss  ratio: 0.740540
--- 0.2798900604248047 seconds for one epoch ---
--- 0.30850672721862793 seconds for one epoch ---
--- 2.10880970954895 seconds for one epoch ---
--- 0.3112986087799072 seconds for one epoch ---
--- 2.135683059692383 seconds for one epoch ---
--- 0.31105518341064453 seconds for one epoch ---
--- 2.1089818477630615 seconds for one epoch ---
--- 0.30718088150024414 seconds for one epoch ---
--- 2.1176958084106445 seconds for one epoch ---
--- 0.31085801124572754 seconds for one epoch ---
--- 2.089395523071289 seconds for one epoch ---
--- 0.3153197765350342 seconds for one epoch ---
--- 2.0881497859954834 seconds for one epoch ---
--- 0.31943655014038086 seconds for one epoch ---
--- 2.1092584133148193 seconds for one epoch ---
--- 0.3081200122833252 seconds for one epoch ---
--- 2.14678955078125 seconds for one epoch ---
--- 0.33109378814697266 seconds for one epoch ---
--- 2.1122853755950928 seconds for one epoch ---
--- 0.3068108558654785 seconds for one epoch ---
--- 2.0857462882995605 seconds for one epoch ---
--- 0.3045365810394287 seconds for one epoch ---
--- 2.0794382095336914 seconds for one epoch ---
--- 0.30960822105407715 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29664958]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.718887]
 [ -0.      ]]
--- 0.2676689624786377 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2284.782958984375, (1096.42, 1.0953412, 1187.0183, 0.24930389)
   validation loss 966.6878051757812, (633.74567, 0.9769781, 331.7158, 0.24930389)
decoder loss ratio: 24552.407351, decoder SINDy loss  ratio: 0.716055
--- 0.30443835258483887 seconds for one epoch ---
--- 2.160946846008301 seconds for one epoch ---
--- 0.31722021102905273 seconds for one epoch ---
--- 2.129481077194214 seconds for one epoch ---
--- 0.3163425922393799 seconds for one epoch ---
--- 2.1437556743621826 seconds for one epoch ---
--- 0.30748486518859863 seconds for one epoch ---
--- 2.132324695587158 seconds for one epoch ---
--- 0.3041548728942871 seconds for one epoch ---
--- 2.140956401824951 seconds for one epoch ---
--- 0.29752469062805176 seconds for one epoch ---
--- 2.1303958892822266 seconds for one epoch ---
--- 0.3083357810974121 seconds for one epoch ---
--- 2.131042242050171 seconds for one epoch ---
--- 0.3067028522491455 seconds for one epoch ---
--- 2.152498245239258 seconds for one epoch ---
--- 0.30647706985473633 seconds for one epoch ---
--- 2.123600959777832 seconds for one epoch ---
--- 0.3125934600830078 seconds for one epoch ---
--- 2.166388511657715 seconds for one epoch ---
--- 0.309828519821167 seconds for one epoch ---
--- 2.105654239654541 seconds for one epoch ---
--- 0.3096771240234375 seconds for one epoch ---
--- 2.0966503620147705 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2956661]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.741432]
 [ -0.      ]]
--- 0.30596184730529785 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3729.654052734375, (1308.7052, 5.8815126, 2414.818, 0.2493304)
   validation loss 863.2734375, (516.24194, 1.0634972, 345.7187, 0.2493304)
decoder loss ratio: 20000.109121, decoder SINDy loss  ratio: 0.746282
--- 0.9870121479034424 seconds for one epoch ---
--- 0.2978780269622803 seconds for one epoch ---
--- 2.1419599056243896 seconds for one epoch ---
--- 0.3170175552368164 seconds for one epoch ---
--- 2.1479053497314453 seconds for one epoch ---
--- 0.32381463050842285 seconds for one epoch ---
--- 2.1567089557647705 seconds for one epoch ---
--- 0.3138301372528076 seconds for one epoch ---
--- 2.161065101623535 seconds for one epoch ---
--- 0.31282806396484375 seconds for one epoch ---
--- 2.1603872776031494 seconds for one epoch ---
--- 0.32172393798828125 seconds for one epoch ---
--- 2.1578986644744873 seconds for one epoch ---
--- 0.3258960247039795 seconds for one epoch ---
--- 2.176757574081421 seconds for one epoch ---
--- 0.31374526023864746 seconds for one epoch ---
--- 2.1894679069519043 seconds for one epoch ---
--- 0.3137028217315674 seconds for one epoch ---
--- 2.2208762168884277 seconds for one epoch ---
--- 0.3169550895690918 seconds for one epoch ---
--- 2.1668689250946045 seconds for one epoch ---
--- 0.3133983612060547 seconds for one epoch ---
--- 2.1466126441955566 seconds for one epoch ---
--- 0.3076291084289551 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29462758]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.765202]
 [ -0.      ]]
--- 0.2679893970489502 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3308.404296875, (1572.8359, 2.7057202, 1732.6134, 0.24935375)
   validation loss 926.16064453125, (580.9162, 1.0293278, 343.96576, 0.24935375)
decoder loss ratio: 22505.702054, decoder SINDy loss  ratio: 0.742498
--- 0.3109719753265381 seconds for one epoch ---
--- 2.1647682189941406 seconds for one epoch ---
--- 0.30783510208129883 seconds for one epoch ---
--- 2.162523031234741 seconds for one epoch ---
--- 0.31676173210144043 seconds for one epoch ---
--- 2.155526638031006 seconds for one epoch ---
--- 0.30297112464904785 seconds for one epoch ---
--- 2.1463494300842285 seconds for one epoch ---
--- 0.30419278144836426 seconds for one epoch ---
--- 2.1684155464172363 seconds for one epoch ---
--- 0.3083646297454834 seconds for one epoch ---
--- 2.131870746612549 seconds for one epoch ---
--- 0.30414915084838867 seconds for one epoch ---
--- 2.1770036220550537 seconds for one epoch ---
--- 0.30877041816711426 seconds for one epoch ---
--- 2.1290838718414307 seconds for one epoch ---
--- 0.3040592670440674 seconds for one epoch ---
--- 2.1746022701263428 seconds for one epoch ---
--- 0.306382417678833 seconds for one epoch ---
--- 2.1885933876037598 seconds for one epoch ---
--- 0.31415843963623047 seconds for one epoch ---
--- 2.1203155517578125 seconds for one epoch ---
--- 0.3035850524902344 seconds for one epoch ---
--- 2.1253676414489746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.2939402]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.780884]
 [  0.      ]]
--- 0.31092333793640137 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2450.310302734375, (1028.4833, 0.735324, 1420.8423, 0.24937049)
   validation loss 1069.654541015625, (712.23065, 1.0852557, 356.08923, 0.24937049)
decoder loss ratio: 27593.051940, decoder SINDy loss  ratio: 0.768669
--- 0.282470703125 seconds for one epoch ---
--- 0.3082003593444824 seconds for one epoch ---
--- 2.1849966049194336 seconds for one epoch ---
--- 0.30643439292907715 seconds for one epoch ---
--- 2.1704957485198975 seconds for one epoch ---
--- 0.3029899597167969 seconds for one epoch ---
--- 2.2030909061431885 seconds for one epoch ---
--- 0.3036036491394043 seconds for one epoch ---
--- 2.1883389949798584 seconds for one epoch ---
--- 0.30736374855041504 seconds for one epoch ---
--- 2.164566993713379 seconds for one epoch ---
--- 0.30881571769714355 seconds for one epoch ---
--- 2.1594173908233643 seconds for one epoch ---
--- 0.3115246295928955 seconds for one epoch ---
--- 2.1685123443603516 seconds for one epoch ---
--- 0.311276912689209 seconds for one epoch ---
--- 2.1514434814453125 seconds for one epoch ---
--- 0.3040783405303955 seconds for one epoch ---
--- 2.1972506046295166 seconds for one epoch ---
--- 0.3085660934448242 seconds for one epoch ---
--- 2.178189754486084 seconds for one epoch ---
--- 0.30830860137939453 seconds for one epoch ---
--- 2.1214370727539062 seconds for one epoch ---
--- 0.30692505836486816 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29331765]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.795073]
 [  0.      ]]
--- 0.270857572555542 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2704.427978515625, (928.24725, 1.7046529, 1774.2268, 0.24938035)
   validation loss 1302.2806396484375, (931.45044, 1.1068474, 369.4739, 0.24938035)
decoder loss ratio: 36086.007093, decoder SINDy loss  ratio: 0.797561
--- 0.3031284809112549 seconds for one epoch ---
--- 2.129347324371338 seconds for one epoch ---
--- 0.303530216217041 seconds for one epoch ---
--- 2.135023355484009 seconds for one epoch ---
--- 0.3028731346130371 seconds for one epoch ---
--- 2.1371757984161377 seconds for one epoch ---
--- 0.3036468029022217 seconds for one epoch ---
--- 2.1329197883605957 seconds for one epoch ---
--- 0.30675578117370605 seconds for one epoch ---
--- 2.1641743183135986 seconds for one epoch ---
--- 0.3087787628173828 seconds for one epoch ---
--- 2.165587902069092 seconds for one epoch ---
--- 0.30642008781433105 seconds for one epoch ---
--- 2.1828646659851074 seconds for one epoch ---
--- 0.30485105514526367 seconds for one epoch ---
--- 2.2002341747283936 seconds for one epoch ---
--- 0.3090240955352783 seconds for one epoch ---
--- 2.166043519973755 seconds for one epoch ---
--- 0.30869626998901367 seconds for one epoch ---
--- 2.1519696712493896 seconds for one epoch ---
--- 0.30521273612976074 seconds for one epoch ---
--- 2.160181999206543 seconds for one epoch ---
--- 0.30670785903930664 seconds for one epoch ---
--- 2.179741621017456 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29251403]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.813368]
 [  0.      ]]
--- 0.3074769973754883 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3205.804443359375, (1418.5748, 2.899277, 1784.0808, 0.24939764)
   validation loss 981.508056640625, (643.2152, 1.0197095, 337.02374, 0.24939764)
decoder loss ratio: 24919.273905, decoder SINDy loss  ratio: 0.727513
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29247135]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.814337]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1287.420654296875, (690.7235, 0.6938643, 596.00323, 0.24940169)
   validation loss 823.6233520507812, (541.9328, 0.5685249, 281.122, 0.24940169)
decoder loss ratio: 20995.417520, decoder SINDy loss  ratio: 0.606841
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29019174]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.941742]
 [ -0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 847.8848876953125, (350.6583, 0.24338225, 496.9832, 0.24943829)
   validation loss 523.31494140625, (291.72266, 0.16743541, 231.42482, 0.24943829)
decoder loss ratio: 11301.842156, decoder SINDy loss  ratio: 0.499563
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29336408]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.764542]
 [ -0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.81298828125, (289.1838, 0.22581127, 486.4034, 0.24937606)
   validation loss 460.4474792480469, (233.38405, 0.11574213, 226.9477, 0.24937606)
decoder loss ratio: 9041.703210, decoder SINDy loss  ratio: 0.489899
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.29812253]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.693659]
 [ -0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.4949951171875, (259.78177, 0.25565195, 482.4576, 0.24926057)
   validation loss 424.6703796386719, (202.8382, 0.09847922, 221.7337, 0.24926057)
decoder loss ratio: 7858.303848, decoder SINDy loss  ratio: 0.478643
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30358002]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.56071]
 [ -0.     ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.5423583984375, (315.0627, 0.22358471, 480.25607, 0.24908927)
   validation loss 471.06207275390625, (254.83035, 0.09325124, 216.13849, 0.24908927)
decoder loss ratio: 9872.570272, decoder SINDy loss  ratio: 0.466565
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30869344]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.51697]
 [ -0.     ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 945.0191650390625, (450.19608, 0.21116325, 494.61194, 0.24889393)
   validation loss 603.5802612304688, (389.36627, 0.091769524, 214.12222, 0.24889393)
decoder loss ratio: 15084.725346, decoder SINDy loss  ratio: 0.462213
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31339926]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.31941]
 [ -0.     ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.4241943359375, (274.5133, 0.3103193, 481.60052, 0.24868193)
   validation loss 434.83203125, (212.68689, 0.082844, 222.0623, 0.24868193)
decoder loss ratio: 8239.859346, decoder SINDy loss  ratio: 0.479353
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31799996]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.178745]
 [  0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.6004638671875, (257.43436, 0.20351717, 475.96262, 0.24843274)
   validation loss 418.69390869140625, (204.51999, 0.07880503, 214.09511, 0.24843274)
decoder loss ratio: 7923.459437, decoder SINDy loss  ratio: 0.462154
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32199112]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.084438]
 [ -0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 861.3798828125, (375.19354, 0.20324326, 485.9831, 0.24818826)
   validation loss 543.02880859375, (330.48303, 0.08046254, 212.46533, 0.24818826)
decoder loss ratio: 12803.486412, decoder SINDy loss  ratio: 0.458636
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3256755]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.987019]
 [  0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.10546875, (399.44293, 0.27775714, 502.3848, 0.2479507)
   validation loss 553.4733276367188, (339.33777, 0.077109784, 214.05844, 0.2479507)
decoder loss ratio: 13146.534270, decoder SINDy loss  ratio: 0.462075
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32896087]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.965702]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1325.1640625, (806.641, 0.19611302, 518.32697, 0.24769573)
   validation loss 985.6181640625, (767.37604, 0.07266597, 218.1694, 0.24769573)
decoder loss ratio: 29729.479920, decoder SINDy loss  ratio: 0.470949
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33164787]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.949564]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.8464965820312, (234.40724, 0.21079734, 469.22845, 0.24748276)
   validation loss 394.7293701171875, (179.84947, 0.072920516, 214.80698, 0.24748276)
decoder loss ratio: 6967.680779, decoder SINDy loss  ratio: 0.463691
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33408105]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.806776]
 [ -0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.1866455078125, (234.36276, 0.23761638, 469.58627, 0.24727564)
   validation loss 392.4033508300781, (176.98044, 0.07465402, 215.34825, 0.24727564)
decoder loss ratio: 6856.529429, decoder SINDy loss  ratio: 0.464859
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33643448]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.737549]
 [  0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1008.8360595703125, (528.40643, 0.23367375, 480.19592, 0.24706446)
   validation loss 657.12060546875, (422.37473, 0.06976849, 234.67612, 0.24706446)
decoder loss ratio: 16363.530135, decoder SINDy loss  ratio: 0.506581
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33819336]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.687334]
 [  0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.23876953125, (232.30803, 0.2087295, 467.722, 0.24689475)
   validation loss 394.0452880859375, (179.99524, 0.07159382, 213.97847, 0.24689475)
decoder loss ratio: 6973.328054, decoder SINDy loss  ratio: 0.461903
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3399717]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.629642]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 993.4923706054688, (519.7843, 0.22470835, 473.48334, 0.24672297)
   validation loss 658.4033813476562, (426.08023, 0.07179103, 232.25136, 0.24672297)
decoder loss ratio: 16507.087846, decoder SINDy loss  ratio: 0.501347
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34123126]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.55388]
 [ -0.     ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.5438232421875, (231.90433, 0.2302484, 465.40927, 0.2465899)
   validation loss 387.8169250488281, (173.07356, 0.06903856, 214.67432, 0.2465899)
decoder loss ratio: 6705.170285, decoder SINDy loss  ratio: 0.463405
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34264368]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.556263]
 [ -0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1757.3070068359375, (1203.1404, 0.22182472, 553.9448, 0.2464441)
   validation loss 1404.173095703125, (1171.6041, 0.073478445, 232.49545, 0.2464441)
decoder loss ratio: 45389.977835, decoder SINDy loss  ratio: 0.501874
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34362304]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.525887]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.4902954101562, (380.63626, 0.22950597, 469.62454, 0.24633451)
   validation loss 513.06298828125, (287.60626, 0.07491129, 225.38184, 0.24633451)
decoder loss ratio: 11142.365904, decoder SINDy loss  ratio: 0.486518
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34442163]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.529564]
 [  0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.431396484375, (230.57523, 0.2077709, 464.64838, 0.24624495)
   validation loss 393.7170104980469, (179.82968, 0.07288081, 213.81445, 0.24624495)
decoder loss ratio: 6966.914055, decoder SINDy loss  ratio: 0.461549
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3451634]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.542269]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 936.432373046875, (468.36694, 0.21919982, 467.84622, 0.24616571)
   validation loss 609.43359375, (380.11002, 0.07568348, 229.2479, 0.24616571)
decoder loss ratio: 14726.121915, decoder SINDy loss  ratio: 0.494864
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3454926]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.445156]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.700927734375, (232.83597, 0.21901205, 462.64597, 0.24612498)
   validation loss 389.37213134765625, (174.08064, 0.07404421, 215.21744, 0.24612498)
decoder loss ratio: 6744.186315, decoder SINDy loss  ratio: 0.464577
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34601226]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.498693]
 [  0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 886.630615234375, (399.17056, 0.19362694, 487.2664, 0.24606645)
   validation loss 579.8533935546875, (367.38986, 0.07451758, 212.38904, 0.24606645)
decoder loss ratio: 14233.321073, decoder SINDy loss  ratio: 0.458472
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34630448]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.501032]
 [ -0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.7059936523438, (228.68562, 0.2035956, 462.81677, 0.24603167)
   validation loss 394.9986572265625, (181.24332, 0.07629868, 213.67905, 0.24603167)
decoder loss ratio: 7021.680739, decoder SINDy loss  ratio: 0.461256
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34646648]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.491758]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.5496826171875, (240.28468, 0.22354566, 465.04147, 0.24601746)
   validation loss 405.8656005859375, (191.92532, 0.07451205, 213.86577, 0.24601746)
decoder loss ratio: 7435.520229, decoder SINDy loss  ratio: 0.461659
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34648907]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.493183]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.1644897460938, (231.4222, 0.20214392, 462.54016, 0.24600975)
   validation loss 400.39599609375, (186.94812, 0.077844135, 213.37003, 0.24600975)
decoder loss ratio: 7242.694730, decoder SINDy loss  ratio: 0.460589
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3464225]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.50975]
 [  0.     ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 789.8497314453125, (318.0001, 0.19950968, 471.65015, 0.24601524)
   validation loss 499.4691162109375, (287.64005, 0.07718014, 211.75189, 0.24601524)
decoder loss ratio: 11143.674715, decoder SINDy loss  ratio: 0.457096
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34622705]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.477783]
 [  0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.8262939453125, (226.9726, 0.20694782, 459.64676, 0.24604197)
   validation loss 390.74249267578125, (175.92186, 0.07799532, 214.74265, 0.24604197)
decoder loss ratio: 6815.518260, decoder SINDy loss  ratio: 0.463552
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34603274]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.522991]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1230.950439453125, (709.9068, 0.24055034, 520.8031, 0.24607407)
   validation loss 900.8487548828125, (678.2941, 0.080795445, 222.47382, 0.24607407)
decoder loss ratio: 26278.292105, decoder SINDy loss  ratio: 0.480241
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3457064]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.511019]
 [ -0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.994873046875, (258.00635, 0.1980259, 465.7905, 0.24610801)
   validation loss 432.3824157714844, (220.59833, 0.078739405, 211.70535, 0.24610801)
decoder loss ratio: 8546.362188, decoder SINDy loss  ratio: 0.456996
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34536332]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.510809]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.4505004882812, (244.61432, 0.2014331, 464.63477, 0.24614394)
   validation loss 419.4605712890625, (206.33554, 0.08213082, 213.0429, 0.24614394)
decoder loss ratio: 7993.797064, decoder SINDy loss  ratio: 0.459883
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34497142]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.574266]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 780.9154052734375, (321.79764, 0.21603529, 458.9017, 0.24619214)
   validation loss 465.0409240722656, (242.56322, 0.08235355, 222.39536, 0.24619214)
decoder loss ratio: 9397.320141, decoder SINDy loss  ratio: 0.480072
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34446234]
 [0.        ]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.5065]
 [  0.    ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2508.178955078125, (1935.8931, 0.18574788, 572.10016, 0.24624224)
   validation loss 2217.5810546875, (1969.7482, 0.07556805, 247.75745, 0.24624224)
decoder loss ratio: 76311.463698, decoder SINDy loss  ratio: 0.534819
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34403592]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.512558]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1000.375732421875, (505.44083, 0.19215329, 494.74277, 0.24629591)
   validation loss 696.5642700195312, (479.83542, 0.080353685, 216.64848, 0.24629591)
decoder loss ratio: 18589.657151, decoder SINDy loss  ratio: 0.467666
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34326637]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.55047]
 [  0.     ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 989.197998046875, (522.48865, 0.22577268, 466.4836, 0.246387)
   validation loss 657.210693359375, (423.1253, 0.0856592, 233.99973, 0.246387)
decoder loss ratio: 16392.608900, decoder SINDy loss  ratio: 0.505121
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34262684]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.56221]
 [  0.     ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.9443359375, (240.87445, 0.20153883, 460.86838, 0.24644887)
   validation loss 417.5224914550781, (203.84091, 0.08378912, 213.5978, 0.24644887)
decoder loss ratio: 7897.150809, decoder SINDy loss  ratio: 0.461081
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34186625]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.598913]
 [  0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.9353637695312, (235.82603, 0.21447828, 454.89484, 0.24652949)
   validation loss 394.9244384765625, (178.34332, 0.08474926, 216.49635, 0.24652949)
decoder loss ratio: 6909.329941, decoder SINDy loss  ratio: 0.467338
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3411127]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.676685]
 [ -0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.173583984375, (328.50122, 0.19614017, 470.47623, 0.24661055)
   validation loss 518.218505859375, (304.38092, 0.08254176, 213.75504, 0.24661055)
decoder loss ratio: 11792.245285, decoder SINDy loss  ratio: 0.461420
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.34016052]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.656517]
 [  0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.3422241210938, (294.40475, 0.25537667, 479.6821, 0.2467186)
   validation loss 469.1171875, (254.20108, 0.08825214, 214.82785, 0.2467186)
decoder loss ratio: 9848.191164, decoder SINDy loss  ratio: 0.463736
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33937362]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.554853]
 [ -0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 889.77197265625, (412.995, 0.19416504, 476.58282, 0.24678917)
   validation loss 608.137451171875, (393.84998, 0.08092954, 214.20657, 0.24678917)
decoder loss ratio: 15258.431808, decoder SINDy loss  ratio: 0.462395
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3382281]
 [0.       ]]
[[ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [-16.7057]
 [  0.    ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2120.34521484375, (1609.0188, 0.22977474, 511.0968, 0.2469081)
   validation loss 1700.9443359375, (1416.4347, 0.0952656, 284.4144, 0.2469081)
decoder loss ratio: 54875.139022, decoder SINDy loss  ratio: 0.613948
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33729142]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.760149]
 [  0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 906.5719604492188, (443.4274, 0.23067385, 462.91388, 0.24699442)
   validation loss 565.94677734375, (335.75403, 0.087069005, 230.10567, 0.24699442)
decoder loss ratio: 13007.693952, decoder SINDy loss  ratio: 0.496715
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33602607]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.787786]
 [ -0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.8818359375, (253.43236, 0.24830475, 453.20117, 0.24711196)
   validation loss 401.0621337890625, (182.52504, 0.08027648, 218.4568, 0.24711196)
decoder loss ratio: 7071.336914, decoder SINDy loss  ratio: 0.471570
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33505768]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.833387]
 [  0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.2112426757812, (338.515, 0.19676234, 467.49945, 0.2472003)
   validation loss 529.0323486328125, (315.47034, 0.08148525, 213.48053, 0.2472003)
decoder loss ratio: 12221.868533, decoder SINDy loss  ratio: 0.460828
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3337344]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.81489]
 [  0.     ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.4595947265625, (262.54776, 0.25550273, 472.65634, 0.24732845)
   validation loss 429.3558349609375, (212.47337, 0.089085475, 216.79338, 0.24732845)
decoder loss ratio: 8231.587356, decoder SINDy loss  ratio: 0.467979
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.33264565]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.761602]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.255126953125, (380.54843, 0.19751744, 471.50916, 0.24741247)
   validation loss 575.47998046875, (360.89536, 0.08204835, 214.50258, 0.24741247)
decoder loss ratio: 13981.712603, decoder SINDy loss  ratio: 0.463034
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3312395]
 [0.       ]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.9208]
 [ -0.    ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1166.173095703125, (651.99756, 0.24327199, 513.9322, 0.24753606)
   validation loss 829.8391723632812, (606.24133, 0.087399535, 223.51042, 0.24753606)
decoder loss ratio: 23486.841722, decoder SINDy loss  ratio: 0.482479
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.330033]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.911915]
 [  0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1679.476318359375, (1158.1488, 0.19168909, 521.1359, 0.2476236)
   validation loss 1393.0208740234375, (1163.3326, 0.07825347, 229.60997, 0.2476236)
decoder loss ratio: 45069.526170, decoder SINDy loss  ratio: 0.495645
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3286333]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.973576]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 976.12939453125, (513.59174, 0.22536233, 462.31235, 0.24773853)
   validation loss 644.3564453125, (408.97162, 0.08662233, 235.2982, 0.24773853)
decoder loss ratio: 15844.270513, decoder SINDy loss  ratio: 0.507924
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3273193]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.03207]
 [  0.     ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 897.8470458984375, (437.58087, 0.22244485, 460.04376, 0.24783842)
   validation loss 562.0682983398438, (331.01376, 0.08841993, 230.96613, 0.24783842)
decoder loss ratio: 12824.047860, decoder SINDy loss  ratio: 0.498573
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32596564]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.02712]
 [  0.     ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.3017578125, (273.86487, 0.22470343, 461.21222, 0.24794011)
   validation loss 453.9255676269531, (239.38632, 0.08318302, 214.45607, 0.24794011)
decoder loss ratio: 9274.241708, decoder SINDy loss  ratio: 0.462934
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32461458]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.035437]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 971.21923828125, (507.02905, 0.22745329, 463.9627, 0.24803162)
   validation loss 623.470703125, (388.60992, 0.08840987, 234.77238, 0.24803162)
decoder loss ratio: 15055.423125, decoder SINDy loss  ratio: 0.506789
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32318938]
 [0.        ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [-17.0333]
 [  0.    ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1644.6199951171875, (1092.9148, 0.24354038, 551.4617, 0.24813083)
   validation loss 1260.3896484375, (1023.75433, 0.086834624, 236.54848, 0.24813083)
decoder loss ratio: 39662.020195, decoder SINDy loss  ratio: 0.510623
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32193387]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.131588]
 [  0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 993.5357666015625, (528.1727, 0.23473774, 465.1283, 0.248209)
   validation loss 641.9545288085938, (406.15445, 0.08818527, 235.7119, 0.248209)
decoder loss ratio: 15735.128487, decoder SINDy loss  ratio: 0.508817
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.32059678]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.176888]
 [  0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.33642578125, (223.10841, 0.21400785, 450.01404, 0.24829054)
   validation loss 386.4257507324219, (169.27966, 0.08252304, 217.06357, 0.24829054)
decoder loss ratio: 6558.188030, decoder SINDy loss  ratio: 0.468562
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31943527]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.160566]
 [ -0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1057.56982421875, (592.8835, 0.23117423, 464.45517, 0.24836278)
   validation loss 715.4127807617188, (476.06537, 0.08837114, 239.25903, 0.24836278)
decoder loss ratio: 18443.598867, decoder SINDy loss  ratio: 0.516474
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31811577]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.13099]
 [ -0.     ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.1111450195312, (221.20064, 0.2070898, 449.7034, 0.24843743)
   validation loss 390.93896484375, (174.63303, 0.08439854, 216.22156, 0.24843743)
decoder loss ratio: 6765.586608, decoder SINDy loss  ratio: 0.466745
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31696883]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.225185]
 [ -0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.0205078125, (252.30383, 0.2256728, 449.49097, 0.24850224)
   validation loss 400.60162353515625, (181.28069, 0.08549723, 219.23543, 0.24850224)
decoder loss ratio: 7023.128470, decoder SINDy loss  ratio: 0.473251
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31583753]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.296938]
 [  0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.9168701171875, (382.41403, 0.19981338, 468.30307, 0.24856393)
   validation loss 573.6277465820312, (358.79236, 0.082809485, 214.75258, 0.24856393)
decoder loss ratio: 13900.238855, decoder SINDy loss  ratio: 0.463574
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3146764]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.288258]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 747.734130859375, (298.93732, 0.21488184, 448.58197, 0.24862543)
   validation loss 445.5804138183594, (221.8232, 0.08489956, 223.67232, 0.24862543)
decoder loss ratio: 8593.815731, decoder SINDy loss  ratio: 0.482828
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3136493]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.298378]
 [ -0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.9452514648438, (225.42163, 0.20570393, 449.3179, 0.24867664)
   validation loss 401.1159362792969, (185.7322, 0.08464365, 215.2991, 0.24867664)
decoder loss ratio: 7195.587602, decoder SINDy loss  ratio: 0.464753
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31263617]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.34762]
 [  0.     ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1010.899658203125, (552.5577, 0.21796228, 458.12405, 0.24872795)
   validation loss 680.8223266601562, (441.98557, 0.08884709, 238.74792, 0.24872795)
decoder loss ratio: 17123.288116, decoder SINDy loss  ratio: 0.515371
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31154495]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.402071]
 [ -0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.2396850585938, (224.8194, 0.21842265, 446.20187, 0.24877842)
   validation loss 386.39923095703125, (168.63087, 0.08486886, 217.68347, 0.24877842)
decoder loss ratio: 6533.052839, decoder SINDy loss  ratio: 0.469900
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31071734]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.414219]
 [  0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1073.4630126953125, (611.206, 0.23002163, 462.02695, 0.24881724)
   validation loss 735.052490234375, (493.79797, 0.09050049, 241.16403, 0.24881724)
decoder loss ratio: 19130.590770, decoder SINDy loss  ratio: 0.520586
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30963042]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.475039]
 [ -0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.2297973632812, (239.74863, 0.19908835, 443.28207, 0.24886306)
   validation loss 399.799072265625, (180.25783, 0.08737281, 219.45386, 0.24886306)
decoder loss ratio: 6983.501189, decoder SINDy loss  ratio: 0.473722
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3088052]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.447489]
 [ -0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.778564453125, (234.40828, 0.21675612, 445.15356, 0.24890006)
   validation loss 391.53009033203125, (172.1206, 0.08575332, 219.32373, 0.24890006)
decoder loss ratio: 6668.251070, decoder SINDy loss  ratio: 0.473441
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3080561]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.529045]
 [ -0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1101.618896484375, (621.92224, 0.20354837, 479.4931, 0.24892998)
   validation loss 825.4876708984375, (606.5512, 0.082265414, 218.85419, 0.24892998)
decoder loss ratio: 23498.846836, decoder SINDy loss  ratio: 0.472428
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30724362]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.43765]
 [  0.     ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.0455322265625, (223.04451, 0.22049592, 444.78052, 0.248964)
   validation loss 384.41937255859375, (166.41411, 0.0845181, 217.92073, 0.248964)
decoder loss ratio: 6447.171462, decoder SINDy loss  ratio: 0.470413
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3065129]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.483086]
 [ -0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.1862182617188, (372.50757, 0.20049822, 457.47815, 0.24898927)
   validation loss 559.260009765625, (345.14166, 0.081054516, 214.0373, 0.24898927)
decoder loss ratio: 13371.387201, decoder SINDy loss  ratio: 0.462030
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30596533]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.52588]
 [ -0.     ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.3348388671875, (244.27396, 0.24061823, 448.82025, 0.24901651)
   validation loss 393.0989990234375, (173.66718, 0.08264583, 219.3492, 0.24901651)
decoder loss ratio: 6728.167870, decoder SINDy loss  ratio: 0.473496
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30516985]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.60277]
 [ -0.     ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 890.064697265625, (426.6259, 0.20032455, 463.23853, 0.24904017)
   validation loss 616.462646484375, (401.00848, 0.08103423, 215.37314, 0.24904017)
decoder loss ratio: 15535.764847, decoder SINDy loss  ratio: 0.464913
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30470976]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.576479]
 [  0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 726.978759765625, (277.41452, 0.2397458, 449.32452, 0.24906226)
   validation loss 417.32476806640625, (194.72012, 0.08418432, 222.52045, 0.24906226)
decoder loss ratio: 7543.795625, decoder SINDy loss  ratio: 0.480342
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30416417]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.544987]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.6787109375, (290.87332, 0.21667412, 445.5887, 0.24908042)
   validation loss 439.5553894042969, (214.83377, 0.08573992, 224.63588, 0.24908042)
decoder loss ratio: 8323.033247, decoder SINDy loss  ratio: 0.484908
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.303697]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.560516]
 [ -0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 998.5853881835938, (543.7948, 0.2157877, 454.57483, 0.24909611)
   validation loss 672.12109375, (432.45242, 0.090300515, 239.57838, 0.24909611)
decoder loss ratio: 16753.957641, decoder SINDy loss  ratio: 0.517164
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30328032]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.531729]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 958.532958984375, (491.24356, 0.20366879, 467.08572, 0.24910736)
   validation loss 683.47607421875, (466.9266, 0.07951077, 216.47, 0.24910736)
decoder loss ratio: 18089.547307, decoder SINDy loss  ratio: 0.467281
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30300608]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.59411]
 [ -0.     ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.2589111328125, (232.73672, 0.23925875, 446.2829, 0.2491207)
   validation loss 387.20587158203125, (169.1927, 0.08129478, 217.93185, 0.2491207)
decoder loss ratio: 6554.819055, decoder SINDy loss  ratio: 0.470437
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3026179]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.615444]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.0257568359375, (243.95868, 0.22169805, 443.84537, 0.24913259)
   validation loss 398.93048095703125, (178.41408, 0.08327174, 220.43314, 0.24913259)
decoder loss ratio: 6912.071113, decoder SINDy loss  ratio: 0.475836
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30227637]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.530207]
 [ -0.      ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1050.1697998046875, (592.2423, 0.22144718, 457.70605, 0.24914432)
   validation loss 711.816650390625, (469.83582, 0.08866064, 241.8922, 0.24914432)
decoder loss ratio: 18202.255161, decoder SINDy loss  ratio: 0.522158
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30192256]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.596792]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.236572265625, (258.27582, 0.20831066, 446.75244, 0.24915318)
   validation loss 436.8976135253906, (223.51111, 0.0811665, 213.30534, 0.24915318)
decoder loss ratio: 8659.208372, decoder SINDy loss  ratio: 0.460450
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30160144]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.580223]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.5634765625, (320.72406, 0.23222838, 445.60715, 0.24916592)
   validation loss 458.41961669921875, (233.94048, 0.08301698, 224.3961, 0.24916592)
decoder loss ratio: 9063.260158, decoder SINDy loss  ratio: 0.484391
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30127358]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.603851]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.8518676757812, (223.62016, 0.21749148, 443.0142, 0.24917407)
   validation loss 397.229736328125, (183.41496, 0.0800841, 213.7347, 0.24917407)
decoder loss ratio: 7105.814080, decoder SINDy loss  ratio: 0.461376
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30119818]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.62619]
 [  0.     ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.681640625, (217.48973, 0.22379045, 441.96814, 0.24917696)
   validation loss 381.09521484375, (165.31157, 0.077587016, 215.70604, 0.24917696)
decoder loss ratio: 6404.457185, decoder SINDy loss  ratio: 0.465632
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30104735]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.590221]
 [  0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.73876953125, (229.99532, 0.2207159, 443.5227, 0.24918137)
   validation loss 404.4206237792969, (191.1245, 0.077214904, 213.21892, 0.24918137)
decoder loss ratio: 7404.494800, decoder SINDy loss  ratio: 0.460263
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30087686]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.625448]
 [ -0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.8902587890625, (222.95859, 0.25803155, 443.67365, 0.24918786)
   validation loss 382.05352783203125, (166.12346, 0.07436425, 215.85571, 0.24918786)
decoder loss ratio: 6435.911199, decoder SINDy loss  ratio: 0.465955
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3009174]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.593052]
 [  0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1147.4019775390625, (670.9766, 0.2130758, 476.21228, 0.24918447)
   validation loss 882.9010620117188, (665.0387, 0.070242055, 217.79211, 0.24918447)
decoder loss ratio: 25764.753652, decoder SINDy loss  ratio: 0.470135
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30056804]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.601748]
 [  0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.3367309570312, (221.39632, 0.25617167, 442.68427, 0.24919699)
   validation loss 380.7244873046875, (165.00867, 0.076330155, 215.63948, 0.24919699)
decoder loss ratio: 6392.722227, decoder SINDy loss  ratio: 0.465488
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30065387]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.619616]
 [ -0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.4212646484375, (262.38016, 0.21799372, 439.8231, 0.24919558)
   validation loss 420.2833251953125, (200.99065, 0.07547604, 219.21721, 0.24919558)
decoder loss ratio: 7786.726575, decoder SINDy loss  ratio: 0.473211
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3007287]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.714584]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.5819702148438, (276.8998, 0.22749601, 441.45465, 0.249191)
   validation loss 420.9191589355469, (200.10245, 0.07595819, 220.74075, 0.249191)
decoder loss ratio: 7752.316210, decoder SINDy loss  ratio: 0.476500
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3007564]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.616102]
 [  0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.2510986328125, (294.77786, 0.21365154, 449.25958, 0.24918962)
   validation loss 482.1783752441406, (270.12848, 0.07178479, 211.97812, 0.24918962)
decoder loss ratio: 10465.246240, decoder SINDy loss  ratio: 0.457585
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30088288]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.554482]
 [ -0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.1104736328125, (320.1606, 0.24647336, 452.70337, 0.24918862)
   validation loss 499.97869873046875, (286.25342, 0.06737689, 213.6579, 0.24918862)
decoder loss ratio: 11089.954370, decoder SINDy loss  ratio: 0.461211
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3009606]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.626041]
 [ -0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.1767578125, (218.53206, 0.21680707, 441.4279, 0.24918441)
   validation loss 388.67449951171875, (174.59834, 0.07026214, 214.00589, 0.24918441)
decoder loss ratio: 6764.242920, decoder SINDy loss  ratio: 0.461962
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30115646]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.57694]
 [  0.     ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.6347045898438, (279.21198, 0.233032, 442.1897, 0.24917927)
   validation loss 422.771484375, (201.81636, 0.07525141, 220.87988, 0.24917927)
decoder loss ratio: 7818.716173, decoder SINDy loss  ratio: 0.476800
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30132124]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.659786]
 [ -0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.9660034179688, (235.43018, 0.22638297, 442.30945, 0.24917494)
   validation loss 389.39642333984375, (171.46202, 0.072221324, 217.86217, 0.24917494)
decoder loss ratio: 6642.736360, decoder SINDy loss  ratio: 0.470286
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.301291]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.679108]
 [  0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.5458984375, (225.62868, 0.22386636, 438.69333, 0.24917392)
   validation loss 382.18438720703125, (165.72447, 0.07227045, 216.38763, 0.24917392)
decoder loss ratio: 6420.453757, decoder SINDy loss  ratio: 0.467103
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30151916]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.673668]
 [  0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 966.9771728515625, (519.3361, 0.21299198, 447.428, 0.24916802)
   validation loss 654.0464477539062, (417.90884, 0.0768791, 236.06075, 0.24916802)
decoder loss ratio: 16190.514138, decoder SINDy loss  ratio: 0.509570
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30155292]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.655977]
 [  0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.8892822265625, (223.65997, 0.22291772, 438.0064, 0.2491653)
   validation loss 381.1859130859375, (164.98376, 0.072043285, 216.1301, 0.2491653)
decoder loss ratio: 6391.757467, decoder SINDy loss  ratio: 0.466547
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30181807]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.587845]
 [  0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.21240234375, (223.78177, 0.20352718, 441.22708, 0.24915741)
   validation loss 396.0531005859375, (183.42635, 0.072361074, 212.5544, 0.24915741)
decoder loss ratio: 7106.255079, decoder SINDy loss  ratio: 0.458829
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30211076]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.55799]
 [ -0.     ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.1715698242188, (404.0074, 0.23188783, 447.93228, 0.2491478)
   validation loss 525.6477661132812, (296.73068, 0.075850576, 228.84125, 0.2491478)
decoder loss ratio: 11495.861782, decoder SINDy loss  ratio: 0.493986
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30238372]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.568583]
 [  0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.8583374023438, (251.00618, 0.21109022, 440.64108, 0.24913755)
   validation loss 429.15203857421875, (217.20746, 0.06923936, 211.87535, 0.24913755)
decoder loss ratio: 8414.994031, decoder SINDy loss  ratio: 0.457363
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30250582]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.557137]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1040.37353515625, (586.06335, 0.2181138, 454.09207, 0.24913536)
   validation loss 696.0559692382812, (456.2314, 0.080627985, 239.74394, 0.24913536)
decoder loss ratio: 17675.197062, decoder SINDy loss  ratio: 0.517521
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30271202]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.592636]
 [ -0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.0647583007812, (220.81837, 0.2007974, 437.0456, 0.24912639)
   validation loss 391.52056884765625, (178.49663, 0.07262538, 212.95131, 0.24912639)
decoder loss ratio: 6915.269245, decoder SINDy loss  ratio: 0.459685
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3030256]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.575907]
 [ -0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.7252197265625, (416.68625, 0.2065265, 440.8325, 0.24911772)
   validation loss 555.3562622070312, (325.29694, 0.07793579, 229.98138, 0.24911772)
decoder loss ratio: 12602.568042, decoder SINDy loss  ratio: 0.496447
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30326298]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.585281]
 [  0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.1968994140625, (247.38528, 0.19517393, 439.61646, 0.24910744)
   validation loss 425.36944580078125, (213.46405, 0.07049133, 211.83488, 0.24910744)
decoder loss ratio: 8269.967898, decoder SINDy loss  ratio: 0.457275
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3036241]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.521292]
 [  0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.0232543945312, (250.86943, 0.21799365, 438.93582, 0.2490989)
   validation loss 397.71514892578125, (178.58557, 0.0705632, 219.059, 0.2490989)
decoder loss ratio: 6918.715070, decoder SINDy loss  ratio: 0.472870
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3039279]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.54051]
 [  0.     ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.7224731445312, (269.09607, 0.21440895, 439.412, 0.24908784)
   validation loss 415.65838623046875, (194.12881, 0.072290264, 221.45726, 0.24908784)
decoder loss ratio: 7520.887304, decoder SINDy loss  ratio: 0.478047
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30422068]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.462238]
 [  0.      ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1027.6614990234375, (576.4515, 0.20920435, 451.0008, 0.2490773)
   validation loss 694.4064331054688, (454.43332, 0.07895781, 239.89417, 0.2490773)
decoder loss ratio: 17605.535713, decoder SINDy loss  ratio: 0.517845
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30453444]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.602802]
 [  0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 883.1144409179688, (427.47577, 0.19575681, 455.4429, 0.24906145)
   validation loss 620.0161743164062, (406.6044, 0.06665356, 213.34514, 0.24906145)
decoder loss ratio: 15752.560377, decoder SINDy loss  ratio: 0.460535
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3049507]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.562452]
 [ -0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.640380859375, (225.11185, 0.2269042, 440.3016, 0.24905184)
   validation loss 384.0303955078125, (168.76015, 0.06708271, 215.20317, 0.24905184)
decoder loss ratio: 6538.061079, decoder SINDy loss  ratio: 0.464546
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30522066]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.48187]
 [  0.     ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.638671875, (246.42563, 0.21409722, 437.99896, 0.24904148)
   validation loss 397.7540283203125, (178.24077, 0.07105971, 219.4422, 0.24904148)
decoder loss ratio: 6905.356809, decoder SINDy loss  ratio: 0.473697
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30549842]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.525002]
 [  0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1060.541259765625, (607.4595, 0.21078195, 452.87097, 0.24903063)
   validation loss 720.5210571289062, (478.98248, 0.07819716, 241.46039, 0.24903063)
decoder loss ratio: 18556.612938, decoder SINDy loss  ratio: 0.521226
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30576217]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.47433]
 [  0.     ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 888.2259521484375, (431.85605, 0.19667947, 456.17322, 0.24901663)
   validation loss 625.446044921875, (412.02325, 0.06633739, 213.35641, 0.24901663)
decoder loss ratio: 15962.496179, decoder SINDy loss  ratio: 0.460560
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30610484]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.536497]
 [ -0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.2706298828125, (228.48627, 0.22506781, 440.55933, 0.24900894)
   validation loss 394.1004943847656, (180.28925, 0.06595302, 213.7453, 0.24900894)
decoder loss ratio: 6984.718371, decoder SINDy loss  ratio: 0.461399
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30633056]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.451113]
 [ -0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.5616455078125, (399.1394, 0.20682551, 439.21545, 0.24899974)
   validation loss 540.2019653320312, (311.3958, 0.07289675, 228.73326, 0.24899974)
decoder loss ratio: 12064.014402, decoder SINDy loss  ratio: 0.493753
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30648994]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.497051]
 [  0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.807861328125, (489.57126, 0.22763331, 451.00894, 0.24899288)
   validation loss 599.5240478515625, (366.46628, 0.07093339, 232.98682, 0.24899288)
decoder loss ratio: 14197.539826, decoder SINDy loss  ratio: 0.502935
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30643994]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.523918]
 [ -0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.1842651367188, (214.36255, 0.22416398, 437.59753, 0.24899392)
   validation loss 382.68316650390625, (169.98483, 0.06817148, 212.63014, 0.24899392)
decoder loss ratio: 6585.507528, decoder SINDy loss  ratio: 0.458992
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30672026]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.515564]
 [ -0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1107.411376953125, (624.13165, 0.24452837, 483.03522, 0.2489852)
   validation loss 823.0084838867188, (602.21985, 0.06394303, 220.72469, 0.2489852)
decoder loss ratio: 23331.042436, decoder SINDy loss  ratio: 0.476465
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30687192]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.500826]
 [  0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 908.0025634765625, (445.35928, 0.20746869, 462.4358, 0.24897735)
   validation loss 640.2251586914062, (427.8695, 0.06425149, 212.29143, 0.24897735)
decoder loss ratio: 16576.407509, decoder SINDy loss  ratio: 0.458261
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30732965]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.489485]
 [ -0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.4788208007812, (276.80325, 0.22715221, 440.44843, 0.24895754)
   validation loss 406.9718017578125, (187.776, 0.06742396, 219.12836, 0.24895754)
decoder loss ratio: 7274.768271, decoder SINDy loss  ratio: 0.473019
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30766663]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.47137]
 [ -0.     ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.6602172851562, (316.90244, 0.20483832, 448.55295, 0.2489448)
   validation loss 508.00823974609375, (296.865, 0.06310982, 211.08014, 0.2489448)
decoder loss ratio: 11501.065102, decoder SINDy loss  ratio: 0.455646
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30791327]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.443806]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.220703125, (223.96996, 0.21252497, 435.03824, 0.24893498)
   validation loss 379.703857421875, (164.34152, 0.065044716, 215.29727, 0.24893498)
decoder loss ratio: 6366.875880, decoder SINDy loss  ratio: 0.464749
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3082012]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.38979]
 [  0.     ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.0049438476562, (219.58968, 0.21854253, 434.19675, 0.24892302)
   validation loss 377.31219482421875, (162.8628, 0.06604975, 214.38335, 0.24892302)
decoder loss ratio: 6309.587342, decoder SINDy loss  ratio: 0.462777
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3086455]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.43522]
 [  0.     ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1070.2994384765625, (580.30914, 0.25349036, 489.73682, 0.24890919)
   validation loss 762.5723266601562, (542.0234, 0.059205994, 220.48976, 0.24890919)
decoder loss ratio: 20998.926598, decoder SINDy loss  ratio: 0.475958
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30893913]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.436937]
 [  0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.50537109375, (243.90207, 0.20415188, 440.39917, 0.24889313)
   validation loss 423.50970458984375, (212.88141, 0.06386521, 210.56442, 0.24889313)
decoder loss ratio: 8247.395351, decoder SINDy loss  ratio: 0.454533
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30932713]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.49402]
 [ -0.     ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1422.501953125, (953.972, 0.22017264, 468.30975, 0.24887763)
   validation loss 1049.1983642578125, (792.2141, 0.07152872, 256.91272, 0.24887763)
decoder loss ratio: 30691.750017, decoder SINDy loss  ratio: 0.554582
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.30945727]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.412159]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 660.2010498046875, (224.31345, 0.19805734, 435.68958, 0.24886875)
   validation loss 399.09588623046875, (187.29996, 0.06333655, 211.73259, 0.24886875)
decoder loss ratio: 7256.325512, decoder SINDy loss  ratio: 0.457055
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3098209]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.422104]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.964599609375, (229.6681, 0.2176384, 439.07883, 0.2488569)
   validation loss 398.12884521484375, (185.24283, 0.05940919, 212.8266, 0.2488569)
decoder loss ratio: 7176.628767, decoder SINDy loss  ratio: 0.459416
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31015784]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.483576]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.5811767578125, (290.64938, 0.20505534, 436.7267, 0.24884085)
   validation loss 433.31109619140625, (210.8739, 0.06660011, 222.3706, 0.24884085)
decoder loss ratio: 8169.621032, decoder SINDy loss  ratio: 0.480018
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31050926]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.375269]
 [ -0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1041.9029541015625, (592.76495, 0.20202199, 448.93594, 0.2488247)
   validation loss 706.7637329101562, (466.57068, 0.07403675, 240.119, 0.2488247)
decoder loss ratio: 18075.758096, decoder SINDy loss  ratio: 0.518331
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3108798]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.364037]
 [ -0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 787.2789916992188, (342.379, 0.18919483, 444.7108, 0.2488031)
   validation loss 532.0126342773438, (320.33865, 0.0605553, 211.61343, 0.2488031)
decoder loss ratio: 12410.475571, decoder SINDy loss  ratio: 0.456797
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3113283]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.353935]
 [ -0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.4239501953125, (245.91997, 0.21586674, 437.2881, 0.24878891)
   validation loss 393.18804931640625, (174.66772, 0.06295229, 218.45737, 0.24878891)
decoder loss ratio: 6766.930888, decoder SINDy loss  ratio: 0.471571
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3116188]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.319998]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.4019165039062, (292.54977, 0.20375693, 435.64838, 0.24877477)
   validation loss 437.367431640625, (214.05219, 0.06816647, 223.24707, 0.24877477)
decoder loss ratio: 8292.753260, decoder SINDy loss  ratio: 0.481910
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31191772]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.419437]
 [ -0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1017.39697265625, (570.12445, 0.2012383, 447.07126, 0.24875991)
   validation loss 688.6777954101562, (449.18442, 0.07514529, 239.41824, 0.24875991)
decoder loss ratio: 17402.184161, decoder SINDy loss  ratio: 0.516818
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31220123]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.290462]
 [ -0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 832.2890014648438, (383.68338, 0.19170077, 448.4139, 0.24874151)
   validation loss 575.7806396484375, (362.8971, 0.061180517, 212.82234, 0.24874151)
decoder loss ratio: 14059.263467, decoder SINDy loss  ratio: 0.459407
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31255797]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.30658]
 [ -0.     ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.52294921875, (224.51389, 0.21829137, 436.79074, 0.24873142)
   validation loss 382.13775634765625, (166.19533, 0.06252053, 215.8799, 0.24873142)
decoder loss ratio: 6438.695525, decoder SINDy loss  ratio: 0.466007
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31275892]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.36777]
 [ -0.     ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.506591796875, (239.03278, 0.20932505, 434.26447, 0.24872012)
   validation loss 392.65185546875, (173.81932, 0.06685456, 218.76567, 0.24872012)
decoder loss ratio: 6734.062247, decoder SINDy loss  ratio: 0.472236
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31295347]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.324892]
 [  0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1075.9971923828125, (624.51544, 0.2069451, 451.27475, 0.24871157)
   validation loss 732.9525756835938, (490.82025, 0.07506888, 242.05724, 0.24871157)
decoder loss ratio: 19015.228643, decoder SINDy loss  ratio: 0.522515
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31310955]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.331778]
 [ -0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 906.6950073242188, (451.1445, 0.19669865, 455.35382, 0.24869819)
   validation loss 648.5411987304688, (434.65048, 0.061532293, 213.8292, 0.24869819)
decoder loss ratio: 16839.114266, decoder SINDy loss  ratio: 0.461580
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31324837]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.325413]
 [  0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.6246337890625, (317.47382, 0.2488369, 458.902, 0.24869804)
   validation loss 496.8050537109375, (281.99384, 0.06281032, 214.74841, 0.24869804)
decoder loss ratio: 10924.930748, decoder SINDy loss  ratio: 0.463565
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31340548]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.384789]
 [  0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.7009887695312, (250.59247, 0.22052886, 441.88797, 0.24868982)
   validation loss 430.30426025390625, (217.8513, 0.061842497, 212.3911, 0.24868982)
decoder loss ratio: 8439.937689, decoder SINDy loss  ratio: 0.458476
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31365287]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.34816]
 [  0.     ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.9339599609375, (255.92441, 0.20986794, 431.7997, 0.2486732)
   validation loss 408.1998291015625, (190.5795, 0.065956965, 217.55437, 0.2486732)
decoder loss ratio: 7383.380624, decoder SINDy loss  ratio: 0.469622
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3137643]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.392653]
 [ -0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.2606201171875, (377.59067, 0.21525154, 441.4547, 0.24867053)
   validation loss 496.3294677734375, (270.09036, 0.06563064, 226.17348, 0.24867053)
decoder loss ratio: 10463.769543, decoder SINDy loss  ratio: 0.488227
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31377903]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.368074]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.09033203125, (210.98737, 0.2250265, 432.87796, 0.24866815)
   validation loss 374.8369140625, (161.97461, 0.06509431, 212.7972, 0.24866815)
decoder loss ratio: 6275.177567, decoder SINDy loss  ratio: 0.459353
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31393474]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.299593]
 [  0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.2113647460938, (219.8261, 0.22490156, 436.16037, 0.24866359)
   validation loss 378.89471435546875, (164.19589, 0.06466574, 214.63417, 0.24866359)
decoder loss ratio: 6361.233926, decoder SINDy loss  ratio: 0.463318
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31398427]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.292768]
 [  0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.2779541015625, (214.69124, 0.20878926, 434.37796, 0.24865809)
   validation loss 384.2021789550781, (172.54327, 0.06308477, 211.59583, 0.24865809)
decoder loss ratio: 6684.625980, decoder SINDy loss  ratio: 0.456759
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31436038]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.325005]
 [  0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.5030517578125, (233.3924, 0.2133019, 431.89737, 0.2486382)
   validation loss 389.01153564453125, (174.17192, 0.064610586, 214.77501, 0.2486382)
decoder loss ratio: 6747.722587, decoder SINDy loss  ratio: 0.463622
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3145129]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.259737]
 [ -0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.9462280273438, (250.0454, 0.20838588, 439.69244, 0.24863027)
   validation loss 434.33233642578125, (223.69829, 0.059543964, 210.57451, 0.24863027)
decoder loss ratio: 8666.460033, decoder SINDy loss  ratio: 0.454555
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31484365]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.268917]
 [  0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 956.8675537109375, (510.30786, 0.22597255, 446.3337, 0.24862018)
   validation loss 620.464111328125, (389.19757, 0.06295456, 231.2036, 0.24862018)
decoder loss ratio: 15078.189570, decoder SINDy loss  ratio: 0.499085
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31494817]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.319185]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.6220092773438, (213.14664, 0.2035339, 432.27182, 0.2486085)
   validation loss 375.8223571777344, (163.01596, 0.060188584, 212.7462, 0.2486085)
decoder loss ratio: 6315.521325, decoder SINDy loss  ratio: 0.459243
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31525058]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.256504]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.7462768554688, (298.79077, 0.20381059, 433.7517, 0.24859333)
   validation loss 434.0611267089844, (214.10068, 0.061835546, 219.89862, 0.24859333)
decoder loss ratio: 8294.631941, decoder SINDy loss  ratio: 0.474682
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31552684]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.257626]
 [ -0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.7618408203125, (283.55377, 0.21325693, 445.99484, 0.24858068)
   validation loss 472.46392822265625, (260.40823, 0.05493654, 212.00076, 0.24858068)
decoder loss ratio: 10088.667060, decoder SINDy loss  ratio: 0.457633
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31574273]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.268871]
 [ -0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.6702880859375, (243.71587, 0.20219861, 431.7522, 0.24856763)
   validation loss 391.0611572265625, (174.77509, 0.05974992, 216.22632, 0.24856763)
decoder loss ratio: 6771.090233, decoder SINDy loss  ratio: 0.466755
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3160425]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.17895]
 [  0.     ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.2844848632812, (215.5279, 0.19289164, 432.5637, 0.24854985)
   validation loss 389.5030517578125, (178.77866, 0.059716277, 210.66469, 0.24854985)
decoder loss ratio: 6926.195507, decoder SINDy loss  ratio: 0.454749
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31640926]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.212706]
 [  0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 803.4512329101562, (354.78302, 0.21594928, 448.45227, 0.24853478)
   validation loss 545.4707641601562, (332.58755, 0.049933225, 212.83328, 0.24853478)
decoder loss ratio: 12885.019275, decoder SINDy loss  ratio: 0.459431
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31643003]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.255806]
 [ -0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 995.2698974609375, (533.4519, 0.19561535, 461.62234, 0.24852724)
   validation loss 743.514404296875, (529.4489, 0.05410963, 214.01134, 0.24852724)
decoder loss ratio: 20511.770076, decoder SINDy loss  ratio: 0.461974
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3167112]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.202738]
 [ -0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.9196166992188, (233.83226, 0.21218747, 435.87515, 0.24851565)
   validation loss 399.0554504394531, (187.4886, 0.05396602, 211.51288, 0.24851565)
decoder loss ratio: 7263.633924, decoder SINDy loss  ratio: 0.456580
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3169075]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.209238]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.046142578125, (329.04565, 0.19784243, 445.8026, 0.24850288)
   validation loss 522.0169677734375, (311.64304, 0.05667543, 210.31729, 0.24850288)
decoder loss ratio: 12073.592246, decoder SINDy loss  ratio: 0.453999
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31705064]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.216358]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 961.81787109375, (518.20355, 0.1985744, 443.41577, 0.24849673)
   validation loss 626.4671020507812, (392.40265, 0.06782742, 233.9966, 0.24849673)
decoder loss ratio: 15202.359860, decoder SINDy loss  ratio: 0.505115
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31726465]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.206615]
 [ -0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.5707397460938, (224.26282, 0.19532247, 433.1126, 0.2484827)
   validation loss 399.89569091796875, (188.76302, 0.057530027, 211.07516, 0.2484827)
decoder loss ratio: 7313.006937, decoder SINDy loss  ratio: 0.455635
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.317486]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.235382]
 [  0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.8041381835938, (321.3755, 0.24504009, 456.18362, 0.24847531)
   validation loss 504.89178466796875, (291.20428, 0.055312805, 213.63219, 0.24847531)
decoder loss ratio: 11281.759541, decoder SINDy loss  ratio: 0.461155
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.3177244]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.21447]
 [ -0.     ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1110.581787109375, (643.6554, 0.19841528, 466.7279, 0.24845581)
   validation loss 863.373046875, (647.87305, 0.053110108, 215.44693, 0.24845581)
decoder loss ratio: 25099.726593, decoder SINDy loss  ratio: 0.465073
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.31794965]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.193695]
 [  0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 988.83740234375, (541.4959, 0.20939948, 447.1321, 0.24844646)
   validation loss 645.867431640625, (411.27972, 0.06312256, 234.52461, 0.24844646)
decoder loss ratio: 15933.690525, decoder SINDy loss  ratio: 0.506254
params['save_name']
pendulum_2023_10_25_23_24_23_184006
