nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-11-09 20:24:32.485249: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-11-09 20:24:32.503473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-11-09 20:24:32.505727: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9f93d9a50 executing computations on platform Host. Devices:
2023-11-09 20:24:32.505779: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-11-09 20:24:32.510261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-11-09 20:24:32.623507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9fab51da0 executing computations on platform CUDA. Devices:
2023-11-09 20:24:32.623544: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-11-09 20:24:32.624032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-11-09 20:24:32.624331: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-09 20:24:32.629699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-11-09 20:24:32.631469: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-11-09 20:24:32.632925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-11-09 20:24:32.634928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-11-09 20:24:32.636890: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-11-09 20:24:32.648275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-11-09 20:24:32.649914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-11-09 20:24:32.649996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-09 20:24:32.650650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-11-09 20:24:32.650669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-11-09 20:24:32.650681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-11-09 20:24:32.651747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-11-09 20:24:33.970203: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.5, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.9084219932556152 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 111762.140625, (106825.34, 0.0017212619, 4918.18, 2.5317798)
   validation loss 87328.375, (86109.0, 0.0027717152, 1200.7563, 2.5317798)
decoder loss ratio: 3336012.151798, decoder SINDy loss  ratio: 2.592001
--- 0.14800477027893066 seconds for one epoch ---
--- 0.15549564361572266 seconds for one epoch ---
--- 0.2154836654663086 seconds for one epoch ---
--- 0.18526101112365723 seconds for one epoch ---
--- 0.2315378189086914 seconds for one epoch ---
--- 0.20041131973266602 seconds for one epoch ---
--- 0.21684956550598145 seconds for one epoch ---
--- 0.16921019554138184 seconds for one epoch ---
--- 0.2262730598449707 seconds for one epoch ---
--- 0.18567323684692383 seconds for one epoch ---
--- 0.223846435546875 seconds for one epoch ---
--- 0.17333340644836426 seconds for one epoch ---
--- 0.23743867874145508 seconds for one epoch ---
--- 0.18735671043395996 seconds for one epoch ---
--- 0.19817423820495605 seconds for one epoch ---
--- 0.17464447021484375 seconds for one epoch ---
--- 0.20110726356506348 seconds for one epoch ---
--- 0.21270298957824707 seconds for one epoch ---
--- 0.28966808319091797 seconds for one epoch ---
--- 0.18628358840942383 seconds for one epoch ---
--- 0.21849775314331055 seconds for one epoch ---
--- 0.1983168125152588 seconds for one epoch ---
--- 0.24284124374389648 seconds for one epoch ---
--- 0.16878890991210938 seconds for one epoch ---
=========================
[[0.7736961 ]
 [0.7757375 ]
 [0.7784782 ]
 [0.77952015]
 [0.7738994 ]
 [0.8010374 ]
 [0.7781112 ]
 [0.7741158 ]
 [0.77311623]
 [0.8598065 ]
 [0.7744311 ]]
[[-0.15111227]
 [ 0.4611137 ]
 [-0.7085692 ]
 [-0.7793451 ]
 [-0.1916541 ]
 [-1.4875143 ]
 [ 0.6812787 ]
 [-0.23156449]
 [ 0.0142189 ]
 [-2.2351916 ]
 [ 0.2847895 ]]
--- 0.13517427444458008 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 81525.015625, (77937.87, 4.5076942, 3544.8347, 2.531779)
   validation loss 46096.5703125, (44693.48, 24.545877, 1340.7356, 2.531779)
decoder loss ratio: 1731503.024654, decoder SINDy loss  ratio: 2.894166
--- 0.1980283260345459 seconds for one epoch ---
--- 0.22693967819213867 seconds for one epoch ---
--- 0.17882180213928223 seconds for one epoch ---
--- 0.23564863204956055 seconds for one epoch ---
--- 0.17462921142578125 seconds for one epoch ---
--- 0.21609163284301758 seconds for one epoch ---
--- 0.1625213623046875 seconds for one epoch ---
--- 0.28005290031433105 seconds for one epoch ---
--- 0.22674894332885742 seconds for one epoch ---
--- 0.21692585945129395 seconds for one epoch ---
--- 0.1684262752532959 seconds for one epoch ---
--- 0.22596311569213867 seconds for one epoch ---
--- 0.17014145851135254 seconds for one epoch ---
--- 0.2351827621459961 seconds for one epoch ---
--- 0.17165660858154297 seconds for one epoch ---
--- 0.2426760196685791 seconds for one epoch ---
--- 0.15568900108337402 seconds for one epoch ---
--- 0.24768853187561035 seconds for one epoch ---
--- 0.19078540802001953 seconds for one epoch ---
--- 0.2117938995361328 seconds for one epoch ---
--- 0.16656017303466797 seconds for one epoch ---
--- 0.2452411651611328 seconds for one epoch ---
--- 0.1676781177520752 seconds for one epoch ---
--- 0.2490708827972412 seconds for one epoch ---
=========================
[[0.62131155]
 [0.61434054]
 [0.6181276 ]
 [0.6175662 ]
 [0.612388  ]
 [0.67966807]
 [0.6152483 ]
 [0.61288273]
 [0.6118264 ]
 [0.6351414 ]
 [0.61390865]]
[[ 0.72098136]
 [ 0.3076702 ]
 [-0.56997657]
 [-0.53839374]
 [-0.09406377]
 [-1.6902753 ]
 [ 0.38337687]
 [ 0.15701029]
 [ 0.01183178]
 [-1.116005  ]
 [ 0.26736674]]
--- 0.1516590118408203 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 65524.88671875, (60911.67, 4.5612693, 4551.56, 2.5317378)
   validation loss 44664.375, (43388.516, 8.08548, 1210.6793, 2.5317378)
decoder loss ratio: 1680946.421088, decoder SINDy loss  ratio: 2.613422
--- 0.14219999313354492 seconds for one epoch ---
--- 0.17415690422058105 seconds for one epoch ---
--- 0.2225503921508789 seconds for one epoch ---
--- 0.19128179550170898 seconds for one epoch ---
--- 0.22075271606445312 seconds for one epoch ---
--- 0.1512465476989746 seconds for one epoch ---
--- 0.26175427436828613 seconds for one epoch ---
--- 0.16752910614013672 seconds for one epoch ---
--- 0.24184441566467285 seconds for one epoch ---
--- 0.18813037872314453 seconds for one epoch ---
--- 0.22965240478515625 seconds for one epoch ---
--- 0.18069839477539062 seconds for one epoch ---
--- 0.24099326133728027 seconds for one epoch ---
--- 0.17377519607543945 seconds for one epoch ---
--- 0.21763062477111816 seconds for one epoch ---
--- 0.23602700233459473 seconds for one epoch ---
--- 0.2502319812774658 seconds for one epoch ---
--- 0.15319418907165527 seconds for one epoch ---
--- 0.2542538642883301 seconds for one epoch ---
--- 0.17207765579223633 seconds for one epoch ---
--- 0.23256826400756836 seconds for one epoch ---
--- 0.16376352310180664 seconds for one epoch ---
--- 0.29311466217041016 seconds for one epoch ---
--- 0.19267702102661133 seconds for one epoch ---
=========================
[[0.50013983]
 [0.47695327]
 [0.48439667]
 [0.48401508]
 [0.47672462]
 [0.65158075]
 [0.4794328 ]
 [0.47965768]
 [0.47666746]
 [0.48491785]
 [0.47883084]]
[[ 0.97772914]
 [ 0.03674207]
 [-0.53505147]
 [-0.5182577 ]
 [ 0.01040924]
 [-2.1275291 ]
 [ 0.2593696 ]
 [ 0.27552134]
 [ 0.00361641]
 [-0.55716455]
 [ 0.21341671]]
--- 0.1451723575592041 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 42827.33984375, (38378.703, 2.987952, 4368.0977, 2.5317447)
   validation loss 23071.37109375, (21928.635, 0.7367857, 1064.4496, 2.5317447)
decoder loss ratio: 849553.380604, decoder SINDy loss  ratio: 2.297764
--- 0.15999722480773926 seconds for one epoch ---
--- 0.21363425254821777 seconds for one epoch ---
--- 0.16292810440063477 seconds for one epoch ---
--- 0.2966270446777344 seconds for one epoch ---
--- 0.1994457244873047 seconds for one epoch ---
--- 0.26575541496276855 seconds for one epoch ---
--- 0.17493700981140137 seconds for one epoch ---
--- 0.2811915874481201 seconds for one epoch ---
--- 0.17070412635803223 seconds for one epoch ---
--- 0.23952531814575195 seconds for one epoch ---
--- 0.16399717330932617 seconds for one epoch ---
--- 0.24489402770996094 seconds for one epoch ---
--- 0.1861860752105713 seconds for one epoch ---
--- 0.22655200958251953 seconds for one epoch ---
--- 0.1941967010498047 seconds for one epoch ---
--- 0.25647783279418945 seconds for one epoch ---
--- 0.1821284294128418 seconds for one epoch ---
--- 0.2671971321105957 seconds for one epoch ---
--- 0.17886137962341309 seconds for one epoch ---
--- 0.3063924312591553 seconds for one epoch ---
--- 0.21082782745361328 seconds for one epoch ---
--- 0.27404308319091797 seconds for one epoch ---
--- 0.18573594093322754 seconds for one epoch ---
--- 0.27907729148864746 seconds for one epoch ---
=========================
[[0.40198043]
 [0.38112256]
 [0.39296666]
 [0.38756838]
 [0.38090816]
 [0.72080463]
 [0.38272256]
 [0.3844065 ]
 [0.38003954]
 [0.38603473]
 [0.38263655]]
[[ 0.87243164]
 [-0.10325722]
 [-0.65793705]
 [-0.47218195]
 [ 0.08506565]
 [-2.588868  ]
 [ 0.22182101]
 [ 0.32291344]
 [ 0.00413169]
 [-0.40502447]
 [ 0.21611923]]
--- 0.17192649841308594 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 25738.41015625, (19688.79, 21.187115, 5933.6665, 2.5317667)
   validation loss 11622.484375, (10603.699, 0.19848971, 923.8188, 2.5317667)
decoder loss ratio: 410805.716566, decoder SINDy loss  ratio: 1.994193
--- 0.1707324981689453 seconds for one epoch ---
--- 0.22783803939819336 seconds for one epoch ---
--- 0.26575732231140137 seconds for one epoch ---
--- 0.2227792739868164 seconds for one epoch ---
--- 0.27039670944213867 seconds for one epoch ---
--- 0.16880583763122559 seconds for one epoch ---
--- 0.2710840702056885 seconds for one epoch ---
--- 0.1635129451751709 seconds for one epoch ---
--- 0.2537417411804199 seconds for one epoch ---
--- 0.21122050285339355 seconds for one epoch ---
--- 0.2572450637817383 seconds for one epoch ---
--- 0.19154977798461914 seconds for one epoch ---
--- 0.2665369510650635 seconds for one epoch ---
--- 0.19251227378845215 seconds for one epoch ---
--- 0.27762269973754883 seconds for one epoch ---
--- 0.17922329902648926 seconds for one epoch ---
--- 0.2721080780029297 seconds for one epoch ---
--- 0.2261521816253662 seconds for one epoch ---
--- 0.2617049217224121 seconds for one epoch ---
--- 0.18994784355163574 seconds for one epoch ---
--- 0.2777125835418701 seconds for one epoch ---
--- 0.1996920108795166 seconds for one epoch ---
--- 0.27080345153808594 seconds for one epoch ---
--- 0.1912374496459961 seconds for one epoch ---
=========================
[[0.30778572]
 [0.30107275]
 [0.3277657 ]
 [0.30685282]
 [0.2991456 ]
 [0.82212746]
 [0.30133772]
 [0.30439118]
 [0.29857984]
 [0.3125198 ]
 [0.3023863 ]]
[[ 4.9567676e-01]
 [-1.8731302e-01]
 [-9.4344282e-01]
 [-4.6217787e-01]
 [ 5.0034307e-02]
 [-3.0532770e+00]
 [ 2.0363608e-01]
 [ 3.6208436e-01]
 [-1.6565284e-03]
 [-6.3927335e-01]
 [ 2.6362026e-01]]
--- 0.17971062660217285 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 24114.001953125, (18424.578, 1.808758, 5576.578, 2.531799)
   validation loss 6708.21533203125, (5748.713, 0.18922791, 848.2759, 2.531799)
decoder loss ratio: 222715.117587, decoder SINDy loss  ratio: 1.831123
--- 0.17076539993286133 seconds for one epoch ---
--- 0.29498744010925293 seconds for one epoch ---
--- 0.20108318328857422 seconds for one epoch ---
--- 0.25110816955566406 seconds for one epoch ---
--- 0.18268609046936035 seconds for one epoch ---
--- 0.25392794609069824 seconds for one epoch ---
--- 0.1880660057067871 seconds for one epoch ---
--- 0.2527139186859131 seconds for one epoch ---
--- 0.20405030250549316 seconds for one epoch ---
--- 0.26734495162963867 seconds for one epoch ---
--- 0.19147992134094238 seconds for one epoch ---
--- 0.29590606689453125 seconds for one epoch ---
--- 0.17574429512023926 seconds for one epoch ---
--- 0.3117973804473877 seconds for one epoch ---
--- 0.19689607620239258 seconds for one epoch ---
--- 0.31633901596069336 seconds for one epoch ---
--- 0.15282678604125977 seconds for one epoch ---
--- 0.2736678123474121 seconds for one epoch ---
--- 0.20661020278930664 seconds for one epoch ---
--- 0.27715182304382324 seconds for one epoch ---
--- 0.16582608222961426 seconds for one epoch ---
--- 0.2979743480682373 seconds for one epoch ---
--- 0.1901993751525879 seconds for one epoch ---
--- 0.2854032516479492 seconds for one epoch ---
=========================
[[0.24154924]
 [0.24391517]
 [0.28881317]
 [0.24815316]
 [0.24071285]
 [0.8935534 ]
 [0.24301618]
 [0.24609344]
 [0.24001691]
 [0.27158305]
 [0.24458148]]
[[ 0.117253  ]
 [-0.25395718]
 [-1.147584  ]
 [-0.4343297 ]
 [ 0.05877949]
 [-3.4457023 ]
 [ 0.2061661 ]
 [ 0.35434696]
 [ 0.00448368]
 [-0.9431074 ]
 [ 0.2867608 ]]
--- 0.1874847412109375 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14317.73046875, (8887.575, 15.2704, 5291.201, 2.5318346)
   validation loss 5319.47119140625, (4579.4014, 0.11493352, 616.2724, 2.5318346)
decoder loss ratio: 177413.959155, decoder SINDy loss  ratio: 1.330311
--- 0.15173006057739258 seconds for one epoch ---
--- 0.21546578407287598 seconds for one epoch ---
--- 0.28368091583251953 seconds for one epoch ---
--- 0.1910414695739746 seconds for one epoch ---
--- 0.2783682346343994 seconds for one epoch ---
--- 0.18178701400756836 seconds for one epoch ---
--- 0.27720069885253906 seconds for one epoch ---
--- 0.17776274681091309 seconds for one epoch ---
--- 0.2846639156341553 seconds for one epoch ---
--- 0.21192193031311035 seconds for one epoch ---
--- 0.28240227699279785 seconds for one epoch ---
--- 0.17418360710144043 seconds for one epoch ---
--- 0.2919626235961914 seconds for one epoch ---
--- 0.1725912094116211 seconds for one epoch ---
--- 0.2832143306732178 seconds for one epoch ---
--- 0.2026381492614746 seconds for one epoch ---
--- 0.28540873527526855 seconds for one epoch ---
--- 0.18422269821166992 seconds for one epoch ---
--- 0.3932218551635742 seconds for one epoch ---
--- 0.23936772346496582 seconds for one epoch ---
--- 0.26053380966186523 seconds for one epoch ---
--- 0.16819381713867188 seconds for one epoch ---
--- 0.31401681900024414 seconds for one epoch ---
--- 0.1648695468902588 seconds for one epoch ---
=========================
[[0.19276653]
 [0.19653766]
 [0.26743832]
 [0.19606683]
 [0.19063523]
 [0.92987996]
 [0.1931282 ]
 [0.19740438]
 [0.19034389]
 [0.24713796]
 [0.19445723]]
[[-0.16395018]
 [-0.3430863 ]
 [-1.3479502 ]
 [-0.32379824]
 [ 0.02629142]
 [-3.7368686 ]
 [ 0.18406485]
 [ 0.37683353]
 [-0.00425908]
 [-1.1912565 ]
 [ 0.2519169 ]]
--- 0.1540679931640625 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11399.1396484375, (6976.9517, 15.711271, 4272.647, 2.531869)
   validation loss 2949.513427734375, (2225.9812, 0.06446283, 589.6387, 2.531869)
decoder loss ratio: 86238.376207, decoder SINDy loss  ratio: 1.272818
--- 0.18066143989562988 seconds for one epoch ---
--- 0.3071472644805908 seconds for one epoch ---
--- 0.17084932327270508 seconds for one epoch ---
--- 0.3265540599822998 seconds for one epoch ---
--- 0.22070789337158203 seconds for one epoch ---
--- 0.2762186527252197 seconds for one epoch ---
--- 0.1796739101409912 seconds for one epoch ---
--- 0.30165719985961914 seconds for one epoch ---
--- 0.19210219383239746 seconds for one epoch ---
--- 0.325869083404541 seconds for one epoch ---
--- 0.17528176307678223 seconds for one epoch ---
--- 0.32321786880493164 seconds for one epoch ---
--- 0.18346881866455078 seconds for one epoch ---
--- 0.31598949432373047 seconds for one epoch ---
--- 0.218827486038208 seconds for one epoch ---
--- 0.3096580505371094 seconds for one epoch ---
--- 0.21706366539001465 seconds for one epoch ---
--- 0.33647775650024414 seconds for one epoch ---
--- 0.20641469955444336 seconds for one epoch ---
--- 0.3599114418029785 seconds for one epoch ---
--- 0.18158364295959473 seconds for one epoch ---
--- 0.35114455223083496 seconds for one epoch ---
--- 0.18581914901733398 seconds for one epoch ---
--- 0.33995485305786133 seconds for one epoch ---
=========================
[[0.162851  ]
 [0.1614832 ]
 [0.25585678]
 [0.15927944]
 [0.15459676]
 [0.95419073]
 [0.1588085 ]
 [0.16108052]
 [0.1543692 ]
 [0.24629039]
 [0.15903707]]
[[-4.1460639e-01]
 [-3.6648986e-01]
 [-1.4728490e+00]
 [-2.7832308e-01]
 [ 1.9139217e-02]
 [-4.0099020e+00]
 [ 2.5738832e-01]
 [ 3.5144633e-01]
 [ 2.5148329e-03]
 [-1.4186442e+00]
 [ 2.6765099e-01]]
--- 0.189896821975708 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11284.626953125, (5855.6743, 8.685744, 5276.8887, 2.5319061)
   validation loss 3522.515625, (2755.5408, 0.043413114, 623.55286, 2.5319061)
decoder loss ratio: 106754.433316, decoder SINDy loss  ratio: 1.346027
--- 0.1728527545928955 seconds for one epoch ---
--- 0.2082831859588623 seconds for one epoch ---
--- 0.2978801727294922 seconds for one epoch ---
--- 0.20968055725097656 seconds for one epoch ---
--- 0.31471943855285645 seconds for one epoch ---
--- 0.19196510314941406 seconds for one epoch ---
--- 0.32497525215148926 seconds for one epoch ---
--- 0.2017366886138916 seconds for one epoch ---
--- 0.3393595218658447 seconds for one epoch ---
--- 0.1851041316986084 seconds for one epoch ---
--- 0.36011433601379395 seconds for one epoch ---
--- 0.20782732963562012 seconds for one epoch ---
--- 0.29737329483032227 seconds for one epoch ---
--- 0.2121257781982422 seconds for one epoch ---
--- 0.2896912097930908 seconds for one epoch ---
--- 0.28612542152404785 seconds for one epoch ---
--- 0.32389092445373535 seconds for one epoch ---
--- 0.18933892250061035 seconds for one epoch ---
--- 0.3345615863800049 seconds for one epoch ---
--- 0.18042516708374023 seconds for one epoch ---
--- 0.340618371963501 seconds for one epoch ---
--- 0.18579721450805664 seconds for one epoch ---
--- 0.3629140853881836 seconds for one epoch ---
--- 0.20292043685913086 seconds for one epoch ---
=========================
[[0.13929075]
 [0.13405883]
 [0.2441549 ]
 [0.12834106]
 [0.12403816]
 [0.9625419 ]
 [0.12775114]
 [0.13049866]
 [0.12375108]
 [0.2583349 ]
 [0.12830888]]
[[-0.59880817]
 [-0.46273154]
 [-1.5489564 ]
 [-0.25844586]
 [ 0.02504367]
 [-4.145332  ]
 [ 0.23201631]
 [ 0.3450958 ]
 [-0.00497468]
 [-1.6131968 ]
 [ 0.2570372 ]]
--- 0.17245697975158691 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8968.708984375, (5621.15, 2.2976263, 3194.7925, 2.531931)
   validation loss 3372.359130859375, (2753.3225, 0.058879282, 468.50983, 2.531931)
decoder loss ratio: 106668.494006, decoder SINDy loss  ratio: 1.011344
--- 0.20472264289855957 seconds for one epoch ---
--- 0.3552558422088623 seconds for one epoch ---
--- 0.20877385139465332 seconds for one epoch ---
--- 0.3680901527404785 seconds for one epoch ---
--- 0.17590951919555664 seconds for one epoch ---
--- 0.3565223217010498 seconds for one epoch ---
--- 0.20270323753356934 seconds for one epoch ---
--- 0.32741785049438477 seconds for one epoch ---
--- 0.18062043190002441 seconds for one epoch ---
--- 0.3725109100341797 seconds for one epoch ---
--- 0.19660639762878418 seconds for one epoch ---
--- 0.33948612213134766 seconds for one epoch ---
--- 0.17581582069396973 seconds for one epoch ---
--- 0.33748793601989746 seconds for one epoch ---
--- 0.21367812156677246 seconds for one epoch ---
--- 0.3207283020019531 seconds for one epoch ---
--- 0.1804955005645752 seconds for one epoch ---
--- 0.3643975257873535 seconds for one epoch ---
--- 0.21628308296203613 seconds for one epoch ---
--- 0.3336200714111328 seconds for one epoch ---
--- 0.17842578887939453 seconds for one epoch ---
--- 0.31479716300964355 seconds for one epoch ---
--- 0.1624765396118164 seconds for one epoch ---
--- 0.34037232398986816 seconds for one epoch ---
=========================
[[0.12450138]
 [0.11315658]
 [0.24672112]
 [0.10528678]
 [0.10137971]
 [0.96457464]
 [0.10574345]
 [0.1093183 ]
 [0.10139363]
 [0.28410053]
 [0.10679866]]
[[-7.3876786e-01]
 [-4.9490768e-01]
 [-1.6434076e+00]
 [-2.2052692e-01]
 [ 8.8191754e-04]
 [-4.1913538e+00]
 [ 2.4104218e-01]
 [ 3.7868178e-01]
 [-1.8673815e-03]
 [-1.7832390e+00]
 [ 2.8556746e-01]]
--- 0.16924810409545898 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6814.23046875, (4191.232, 0.64019287, 2465.215, 2.5319493)
   validation loss 2663.40234375, (2022.983, 0.06427417, 483.21152, 2.5319493)
decoder loss ratio: 78373.874721, decoder SINDy loss  ratio: 1.043080
--- 0.16511178016662598 seconds for one epoch ---
--- 0.18323326110839844 seconds for one epoch ---
--- 0.3201632499694824 seconds for one epoch ---
--- 0.19582891464233398 seconds for one epoch ---
--- 0.3693380355834961 seconds for one epoch ---
--- 0.22243690490722656 seconds for one epoch ---
--- 0.3804655075073242 seconds for one epoch ---
--- 0.20624399185180664 seconds for one epoch ---
--- 0.3516273498535156 seconds for one epoch ---
--- 0.1577918529510498 seconds for one epoch ---
--- 0.39829516410827637 seconds for one epoch ---
--- 0.16752147674560547 seconds for one epoch ---
--- 0.36433839797973633 seconds for one epoch ---
--- 0.18415188789367676 seconds for one epoch ---
--- 0.3315849304199219 seconds for one epoch ---
--- 0.19233155250549316 seconds for one epoch ---
--- 0.3189105987548828 seconds for one epoch ---
--- 0.17724084854125977 seconds for one epoch ---
--- 0.3607594966888428 seconds for one epoch ---
--- 0.16928505897521973 seconds for one epoch ---
--- 0.37456607818603516 seconds for one epoch ---
--- 0.18999242782592773 seconds for one epoch ---
--- 0.36550235748291016 seconds for one epoch ---
--- 0.20465826988220215 seconds for one epoch ---
=========================
[[0.11535889]
 [0.0958287 ]
 [0.24971676]
 [0.08615634]
 [0.0824394 ]
 [0.96575767]
 [0.08709702]
 [0.09076168]
 [0.08232476]
 [0.32661515]
 [0.08800777]]
[[-0.88018376]
 [-0.5347484 ]
 [-1.7160105 ]
 [-0.21686801]
 [-0.01389006]
 [-4.2225943 ]
 [ 0.25771606]
 [ 0.39199442]
 [-0.00615928]
 [-1.9613839 ]
 [ 0.29443642]]
--- 0.17121553421020508 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4449.62939453125, (2834.988, 2.4196222, 1447.4348, 2.531967)
   validation loss 2416.541015625, (1748.08, 0.057424333, 503.61682, 2.531967)
decoder loss ratio: 67723.652298, decoder SINDy loss  ratio: 1.087128
--- 0.16784358024597168 seconds for one epoch ---
--- 0.33902716636657715 seconds for one epoch ---
--- 0.17211699485778809 seconds for one epoch ---
--- 0.35949134826660156 seconds for one epoch ---
--- 0.17369461059570312 seconds for one epoch ---
--- 0.33910369873046875 seconds for one epoch ---
--- 0.18902015686035156 seconds for one epoch ---
--- 0.3860790729522705 seconds for one epoch ---
--- 0.1928420066833496 seconds for one epoch ---
--- 0.37906765937805176 seconds for one epoch ---
--- 0.2008533477783203 seconds for one epoch ---
--- 0.34398627281188965 seconds for one epoch ---
--- 0.16969704627990723 seconds for one epoch ---
--- 0.35126233100891113 seconds for one epoch ---
--- 0.24884557723999023 seconds for one epoch ---
--- 0.35080862045288086 seconds for one epoch ---
--- 0.21728754043579102 seconds for one epoch ---
--- 0.3355705738067627 seconds for one epoch ---
--- 0.1749715805053711 seconds for one epoch ---
--- 0.470775842666626 seconds for one epoch ---
--- 0.18349575996398926 seconds for one epoch ---
--- 0.3669595718383789 seconds for one epoch ---
--- 0.20989251136779785 seconds for one epoch ---
--- 0.35506153106689453 seconds for one epoch ---
=========================
[[0.1182696 ]
 [0.08461259]
 [0.24739303]
 [0.07216637]
 [0.06847677]
 [0.967991  ]
 [0.07358898]
 [0.07660066]
 [0.06826978]
 [0.40277576]
 [0.07518063]]
[[-1.0609916e+00]
 [-5.9417784e-01]
 [-1.7482237e+00]
 [-2.1488899e-01]
 [ 1.6506542e-02]
 [-4.2693801e+00]
 [ 2.7485225e-01]
 [ 3.8282043e-01]
 [-2.7510561e-03]
 [-2.1838665e+00]
 [ 3.3466452e-01]]
--- 0.1971735954284668 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6984.1884765625, (2770.5703, 0.5234296, 4041.6453, 2.5319896)
   validation loss 6539.1435546875, (5871.4727, 0.05464834, 496.1666, 2.5319896)
decoder loss ratio: 227471.044028, decoder SINDy loss  ratio: 1.071045
--- 0.19990181922912598 seconds for one epoch ---
--- 0.1979537010192871 seconds for one epoch ---
--- 0.3681793212890625 seconds for one epoch ---
--- 0.181488037109375 seconds for one epoch ---
--- 0.36373233795166016 seconds for one epoch ---
--- 0.2198340892791748 seconds for one epoch ---
--- 0.3796677589416504 seconds for one epoch ---
--- 0.1865997314453125 seconds for one epoch ---
--- 0.3858804702758789 seconds for one epoch ---
--- 0.17124700546264648 seconds for one epoch ---
--- 0.4044511318206787 seconds for one epoch ---
--- 0.17499208450317383 seconds for one epoch ---
--- 0.38704919815063477 seconds for one epoch ---
--- 0.1961827278137207 seconds for one epoch ---
--- 0.39861440658569336 seconds for one epoch ---
--- 0.22158455848693848 seconds for one epoch ---
--- 0.4846460819244385 seconds for one epoch ---
--- 0.20850515365600586 seconds for one epoch ---
--- 0.35824012756347656 seconds for one epoch ---
--- 0.18675899505615234 seconds for one epoch ---
--- 0.43893909454345703 seconds for one epoch ---
--- 0.1600499153137207 seconds for one epoch ---
--- 0.36398959159851074 seconds for one epoch ---
--- 0.20199799537658691 seconds for one epoch ---
=========================
[[0.12195183]
 [0.07564531]
 [0.2542228 ]
 [0.06087365]
 [0.05647586]
 [0.9677798 ]
 [0.06168177]
 [0.06346864]
 [0.05619285]
 [0.4681327 ]
 [0.06434038]]
[[-1.1877149e+00]
 [-6.5311635e-01]
 [-1.8032178e+00]
 [-2.4615477e-01]
 [ 2.1035114e-02]
 [-4.2729530e+00]
 [ 2.7867818e-01]
 [ 3.4412265e-01]
 [-2.5419376e-03]
 [-2.3515859e+00]
 [ 3.7331802e-01]]
--- 0.1658015251159668 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10371.640625, (3171.1624, 0.7451731, 7022.114, 2.5320053)
   validation loss 1918.720703125, (1285.1875, 0.032141887, 455.88196, 2.5320053)
decoder loss ratio: 49790.394934, decoder SINDy loss  ratio: 0.984085
--- 0.20888257026672363 seconds for one epoch ---
--- 0.35817718505859375 seconds for one epoch ---
--- 0.186021089553833 seconds for one epoch ---
--- 0.3813309669494629 seconds for one epoch ---
--- 0.1900928020477295 seconds for one epoch ---
--- 0.3734006881713867 seconds for one epoch ---
--- 0.20958614349365234 seconds for one epoch ---
--- 0.3693196773529053 seconds for one epoch ---
--- 0.1798267364501953 seconds for one epoch ---
--- 0.3845546245574951 seconds for one epoch ---
--- 0.16896486282348633 seconds for one epoch ---
--- 0.3941459655761719 seconds for one epoch ---
--- 0.1872704029083252 seconds for one epoch ---
--- 0.44719839096069336 seconds for one epoch ---
--- 0.2162952423095703 seconds for one epoch ---
--- 0.397275447845459 seconds for one epoch ---
--- 0.1785116195678711 seconds for one epoch ---
--- 0.3616657257080078 seconds for one epoch ---
--- 0.20149588584899902 seconds for one epoch ---
--- 0.37746620178222656 seconds for one epoch ---
--- 0.20352721214294434 seconds for one epoch ---
--- 0.3951249122619629 seconds for one epoch ---
--- 0.21546030044555664 seconds for one epoch ---
--- 0.470029354095459 seconds for one epoch ---
=========================
[[0.12434503]
 [0.07011887]
 [0.27272093]
 [0.05228873]
 [0.04789371]
 [0.962285  ]
 [0.05295637]
 [0.05474135]
 [0.04737135]
 [0.52400005]
 [0.05534724]]
[[-1.2628781 ]
 [-0.71068215]
 [-1.8813248 ]
 [-0.2566491 ]
 [ 0.03987531]
 [-4.188983  ]
 [ 0.28289732]
 [ 0.3472177 ]
 [-0.00682288]
 [-2.4853895 ]
 [ 0.36737314]]
--- 0.1961994171142578 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7601.93115234375, (3579.4739, 1.4136072, 3839.0266, 2.5320127)
   validation loss 2206.883056640625, (1587.161, 0.038345702, 437.6671, 2.5320127)
decoder loss ratio: 61489.372989, decoder SINDy loss  ratio: 0.944766
--- 0.18451976776123047 seconds for one epoch ---
--- 0.2140805721282959 seconds for one epoch ---
--- 0.36432957649230957 seconds for one epoch ---
--- 0.1957254409790039 seconds for one epoch ---
--- 0.394075870513916 seconds for one epoch ---
--- 0.20171737670898438 seconds for one epoch ---
--- 0.3535146713256836 seconds for one epoch ---
--- 0.17535996437072754 seconds for one epoch ---
--- 0.38152170181274414 seconds for one epoch ---
--- 0.19520831108093262 seconds for one epoch ---
--- 0.4358067512512207 seconds for one epoch ---
--- 0.17479419708251953 seconds for one epoch ---
--- 0.39121007919311523 seconds for one epoch ---
--- 0.18975329399108887 seconds for one epoch ---
--- 0.42542457580566406 seconds for one epoch ---
--- 0.18430113792419434 seconds for one epoch ---
--- 0.3858356475830078 seconds for one epoch ---
--- 0.17450690269470215 seconds for one epoch ---
--- 0.46730971336364746 seconds for one epoch ---
--- 0.1777808666229248 seconds for one epoch ---
--- 0.3714883327484131 seconds for one epoch ---
--- 0.17640423774719238 seconds for one epoch ---
--- 0.3859269618988037 seconds for one epoch ---
--- 0.2048628330230713 seconds for one epoch ---
=========================
[[0.12871371]
 [0.06251191]
 [0.2979146 ]
 [0.04414061]
 [0.03994352]
 [0.95708907]
 [0.04542707]
 [0.04735128]
 [0.03958285]
 [0.57666117]
 [0.04762282]]
[[-1.3341745e+00]
 [-7.0916152e-01]
 [-1.9684391e+00]
 [-2.3683937e-01]
 [ 2.4290590e-02]
 [-4.1201205e+00]
 [ 2.8772178e-01]
 [ 3.5563302e-01]
 [-1.1748989e-03]
 [-2.6090987e+00]
 [ 3.6454678e-01]]
--- 0.14998555183410645 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4113.705078125, (2033.8516, 0.15689811, 1893.144, 2.5320196)
   validation loss 4433.51611328125, (3736.0183, 0.029404674, 510.91583, 2.5320196)
decoder loss ratio: 144739.835364, decoder SINDy loss  ratio: 1.102884
--- 0.19063854217529297 seconds for one epoch ---
--- 0.436260461807251 seconds for one epoch ---
--- 0.19482803344726562 seconds for one epoch ---
--- 0.40453052520751953 seconds for one epoch ---
--- 0.18802523612976074 seconds for one epoch ---
--- 0.4021263122558594 seconds for one epoch ---
--- 0.1796107292175293 seconds for one epoch ---
--- 0.3986952304840088 seconds for one epoch ---
--- 0.20022034645080566 seconds for one epoch ---
--- 0.45589232444763184 seconds for one epoch ---
--- 0.1990978717803955 seconds for one epoch ---
--- 0.39382410049438477 seconds for one epoch ---
--- 0.21224403381347656 seconds for one epoch ---
--- 0.38123035430908203 seconds for one epoch ---
--- 0.2235581874847412 seconds for one epoch ---
--- 0.4352123737335205 seconds for one epoch ---
--- 0.1906888484954834 seconds for one epoch ---
--- 0.4413418769836426 seconds for one epoch ---
--- 0.15818262100219727 seconds for one epoch ---
--- 0.4733147621154785 seconds for one epoch ---
--- 0.20726823806762695 seconds for one epoch ---
--- 0.4132719039916992 seconds for one epoch ---
--- 0.16675996780395508 seconds for one epoch ---
--- 0.47941040992736816 seconds for one epoch ---
=========================
[[0.13430168]
 [0.06005147]
 [0.30626518]
 [0.03793126]
 [0.03413888]
 [0.952723  ]
 [0.03881803]
 [0.04137029]
 [0.03387773]
 [0.6202767 ]
 [0.04367914]]
[[-1.3943814e+00]
 [-7.5954324e-01]
 [-2.0015519e+00]
 [-2.1417621e-01]
 [ 1.7562633e-02]
 [-4.0681667e+00]
 [ 2.5108996e-01]
 [ 3.4474203e-01]
 [-8.1164157e-04]
 [-2.7123251e+00]
 [ 4.1710928e-01]]
--- 0.334503173828125 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5957.00146484375, (2465.6025, 0.41994536, 3301.021, 2.532025)
   validation loss 2306.331787109375, (1689.9764, 0.037888978, 426.35968, 2.532025)
decoder loss ratio: 65472.621230, decoder SINDy loss  ratio: 0.920357
--- 0.1433262825012207 seconds for one epoch ---
--- 0.219038724899292 seconds for one epoch ---
--- 0.41310977935791016 seconds for one epoch ---
--- 0.23624825477600098 seconds for one epoch ---
--- 0.40621089935302734 seconds for one epoch ---
--- 0.176497220993042 seconds for one epoch ---
--- 0.45160412788391113 seconds for one epoch ---
--- 0.21105289459228516 seconds for one epoch ---
--- 0.4425818920135498 seconds for one epoch ---
--- 0.19360661506652832 seconds for one epoch ---
--- 0.4167966842651367 seconds for one epoch ---
--- 0.20008087158203125 seconds for one epoch ---
--- 0.48540711402893066 seconds for one epoch ---
--- 0.17052245140075684 seconds for one epoch ---
--- 0.3965950012207031 seconds for one epoch ---
--- 0.19685006141662598 seconds for one epoch ---
--- 0.40929412841796875 seconds for one epoch ---
--- 0.15878772735595703 seconds for one epoch ---
--- 0.48465442657470703 seconds for one epoch ---
--- 0.18357062339782715 seconds for one epoch ---
--- 0.4397594928741455 seconds for one epoch ---
--- 0.22749876976013184 seconds for one epoch ---
--- 0.422593355178833 seconds for one epoch ---
--- 0.15611672401428223 seconds for one epoch ---
=========================
[[0.142826  ]
 [0.05825619]
 [0.31764892]
 [0.03340038]
 [0.02909576]
 [0.9461262 ]
 [0.03312357]
 [0.03620767]
 [0.02899638]
 [0.668161  ]
 [0.04075282]]
[[-1.4601425 ]
 [-0.8045277 ]
 [-2.0398011 ]
 [-0.23165223]
 [ 0.0125977 ]
 [-3.9962    ]
 [ 0.22003672]
 [ 0.33681452]
 [ 0.00625978]
 [-2.828816  ]
 [ 0.47210738]]
--- 0.15686321258544922 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4485.48828125, (1607.2124, 0.49990633, 2684.96, 2.532032)
   validation loss 2051.11279296875, (1460.5961, 0.037651338, 397.66376, 2.532032)
decoder loss ratio: 56586.027432, decoder SINDy loss  ratio: 0.858413
--- 0.17396831512451172 seconds for one epoch ---
--- 0.4375278949737549 seconds for one epoch ---
--- 0.19180941581726074 seconds for one epoch ---
--- 0.4243175983428955 seconds for one epoch ---
--- 0.2126767635345459 seconds for one epoch ---
--- 0.43019986152648926 seconds for one epoch ---
--- 0.19031071662902832 seconds for one epoch ---
--- 0.4602210521697998 seconds for one epoch ---
--- 0.17018771171569824 seconds for one epoch ---
--- 0.5261948108673096 seconds for one epoch ---
--- 0.19620156288146973 seconds for one epoch ---
--- 0.516038179397583 seconds for one epoch ---
--- 0.1710495948791504 seconds for one epoch ---
--- 0.4470818042755127 seconds for one epoch ---
--- 0.18082380294799805 seconds for one epoch ---
--- 0.4373290538787842 seconds for one epoch ---
--- 0.17081880569458008 seconds for one epoch ---
--- 0.42258739471435547 seconds for one epoch ---
--- 0.19867610931396484 seconds for one epoch ---
--- 0.4199254512786865 seconds for one epoch ---
--- 0.18007612228393555 seconds for one epoch ---
--- 0.44388675689697266 seconds for one epoch ---
--- 0.17413783073425293 seconds for one epoch ---
--- 0.4633197784423828 seconds for one epoch ---
=========================
[[0.15103114]
 [0.05604409]
 [0.31727883]
 [0.02956142]
 [0.02552475]
 [0.9414771 ]
 [0.02878572]
 [0.03266367]
 [0.02528358]
 [0.70376027]
 [0.03831331]]
[[-1.5132886 ]
 [-0.823618  ]
 [-2.0453799 ]
 [-0.22489025]
 [ 0.02023352]
 [-3.9506938 ]
 [ 0.19134066]
 [ 0.34091446]
 [ 0.00500161]
 [-2.9203155 ]
 [ 0.50283843]]
--- 0.20971274375915527 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6561.17724609375, (3859.9592, 1.7149335, 2503.6812, 2.5320368)
   validation loss 4181.99169921875, (3459.084, 0.04504103, 527.0416, 2.5320368)
decoder loss ratio: 134010.918789, decoder SINDy loss  ratio: 1.137693
--- 0.18809723854064941 seconds for one epoch ---
--- 0.19955778121948242 seconds for one epoch ---
--- 0.42635655403137207 seconds for one epoch ---
--- 0.2117011547088623 seconds for one epoch ---
--- 0.43387365341186523 seconds for one epoch ---
--- 0.18172121047973633 seconds for one epoch ---
--- 0.45198678970336914 seconds for one epoch ---
--- 0.17665719985961914 seconds for one epoch ---
--- 0.43935060501098633 seconds for one epoch ---
--- 0.16693830490112305 seconds for one epoch ---
--- 0.4353492259979248 seconds for one epoch ---
--- 0.1657712459564209 seconds for one epoch ---
--- 0.44084787368774414 seconds for one epoch ---
--- 0.1935560703277588 seconds for one epoch ---
--- 0.515007495880127 seconds for one epoch ---
--- 0.1744844913482666 seconds for one epoch ---
--- 0.4564211368560791 seconds for one epoch ---
--- 0.16649556159973145 seconds for one epoch ---
--- 0.42490386962890625 seconds for one epoch ---
--- 0.19072341918945312 seconds for one epoch ---
--- 0.5014417171478271 seconds for one epoch ---
--- 0.16384673118591309 seconds for one epoch ---
--- 0.5036065578460693 seconds for one epoch ---
--- 0.20798444747924805 seconds for one epoch ---
=========================
[[0.16678318]
 [0.05273078]
 [0.31928706]
 [0.02653249]
 [0.02234177]
 [0.9368605 ]
 [0.02530389]
 [0.02932005]
 [0.02202872]
 [0.74707407]
 [0.03599658]]
[[-1.5916044e+00]
 [-8.2113761e-01]
 [-2.0559974e+00]
 [-2.3280564e-01]
 [ 2.3349941e-02]
 [-3.9086890e+00]
 [ 1.7966568e-01]
 [ 3.3641699e-01]
 [ 3.6778764e-03]
 [-3.0392692e+00]
 [ 5.2393603e-01]]
--- 0.1497185230255127 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5678.55419921875, (2052.0325, 0.10632793, 3428.26, 2.532045)
   validation loss 1341.9005126953125, (799.27716, 0.044932578, 344.42303, 2.532045)
decoder loss ratio: 30965.384810, decoder SINDy loss  ratio: 0.743486
--- 0.19155120849609375 seconds for one epoch ---
--- 0.4820878505706787 seconds for one epoch ---
--- 0.21161890029907227 seconds for one epoch ---
--- 0.4789998531341553 seconds for one epoch ---
--- 0.1602764129638672 seconds for one epoch ---
--- 0.43401575088500977 seconds for one epoch ---
--- 0.18480658531188965 seconds for one epoch ---
--- 0.5075328350067139 seconds for one epoch ---
--- 0.1691904067993164 seconds for one epoch ---
--- 0.4823567867279053 seconds for one epoch ---
--- 0.28940629959106445 seconds for one epoch ---
--- 0.4994943141937256 seconds for one epoch ---
--- 0.16681766510009766 seconds for one epoch ---
--- 0.4873542785644531 seconds for one epoch ---
--- 0.1918792724609375 seconds for one epoch ---
--- 0.448697566986084 seconds for one epoch ---
--- 0.1876225471496582 seconds for one epoch ---
--- 0.44473838806152344 seconds for one epoch ---
--- 0.1712048053741455 seconds for one epoch ---
--- 0.4752175807952881 seconds for one epoch ---
--- 0.19320034980773926 seconds for one epoch ---
--- 0.4572272300720215 seconds for one epoch ---
--- 0.1946098804473877 seconds for one epoch ---
--- 0.49713730812072754 seconds for one epoch ---
=========================
[[0.17406817]
 [0.05168008]
 [0.32454467]
 [0.0238224 ]
 [0.01983468]
 [0.9278151 ]
 [0.02284143]
 [0.02665656]
 [0.01970316]
 [0.7738115 ]
 [0.03429387]]
[[-1.6280456 ]
 [-0.83852994]
 [-2.0730305 ]
 [-0.22020686]
 [ 0.01777774]
 [-3.8322353 ]
 [ 0.17725928]
 [ 0.32746854]
 [ 0.00953672]
 [-3.1195974 ]
 [ 0.53976387]]
--- 0.20611238479614258 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3772.2333984375, (1478.7915, 1.2453945, 2091.9773, 2.5320458)
   validation loss 2853.8125, (2287.3647, 0.055779215, 366.17264, 2.5320458)
decoder loss ratio: 88616.481304, decoder SINDy loss  ratio: 0.790435
THRESHOLDING: 4 active coefficients
--- 0.4247419834136963 seconds for one epoch ---
--- 0.18613910675048828 seconds for one epoch ---
--- 0.4622335433959961 seconds for one epoch ---
--- 0.20789694786071777 seconds for one epoch ---
--- 0.4356989860534668 seconds for one epoch ---
--- 0.1645524501800537 seconds for one epoch ---
--- 0.522453784942627 seconds for one epoch ---
--- 0.17499780654907227 seconds for one epoch ---
--- 0.49199748039245605 seconds for one epoch ---
--- 0.24117040634155273 seconds for one epoch ---
--- 0.4695136547088623 seconds for one epoch ---
--- 0.2224135398864746 seconds for one epoch ---
--- 0.4667847156524658 seconds for one epoch ---
--- 0.18532705307006836 seconds for one epoch ---
--- 0.4981803894042969 seconds for one epoch ---
--- 0.18764972686767578 seconds for one epoch ---
--- 0.47473669052124023 seconds for one epoch ---
--- 0.18353629112243652 seconds for one epoch ---
--- 0.4431314468383789 seconds for one epoch ---
--- 0.1640615463256836 seconds for one epoch ---
--- 0.5010626316070557 seconds for one epoch ---
--- 0.18507099151611328 seconds for one epoch ---
--- 0.4434237480163574 seconds for one epoch ---
--- 0.17647767066955566 seconds for one epoch ---
=========================
[[0.04866993]
 [0.        ]
 [0.42042953]
 [0.        ]
 [0.        ]
 [0.6196867 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5549193 ]
 [0.        ]]
[[-0.8257873]
 [-0.       ]
 [-2.2956018]
 [-0.       ]
 [ 0.       ]
 [-2.725538 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.5832412]
 [ 0.       ]]
--- 0.1707906723022461 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3603.181884765625, (1894.2299, 0.14289506, 1708.2483, 0.56087047)
   validation loss 980.8748168945312, (656.45184, 0.06493309, 323.79715, 0.56087047)
decoder loss ratio: 25432.084058, decoder SINDy loss  ratio: 0.698962
--- 0.20380139350891113 seconds for one epoch ---
--- 0.42597484588623047 seconds for one epoch ---
--- 0.18445134162902832 seconds for one epoch ---
--- 0.4770030975341797 seconds for one epoch ---
--- 0.1782236099243164 seconds for one epoch ---
--- 0.5379502773284912 seconds for one epoch ---
--- 0.2030787467956543 seconds for one epoch ---
--- 0.46901512145996094 seconds for one epoch ---
--- 0.21204781532287598 seconds for one epoch ---
--- 0.5187182426452637 seconds for one epoch ---
--- 0.17743802070617676 seconds for one epoch ---
--- 0.5295953750610352 seconds for one epoch ---
--- 0.17000842094421387 seconds for one epoch ---
--- 0.49935173988342285 seconds for one epoch ---
--- 0.18526983261108398 seconds for one epoch ---
--- 0.4707801342010498 seconds for one epoch ---
--- 0.1814594268798828 seconds for one epoch ---
--- 0.5067861080169678 seconds for one epoch ---
--- 0.20268774032592773 seconds for one epoch ---
--- 0.4588611125946045 seconds for one epoch ---
--- 0.16849923133850098 seconds for one epoch ---
--- 0.5433483123779297 seconds for one epoch ---
--- 0.19643735885620117 seconds for one epoch ---
--- 0.5122296810150146 seconds for one epoch ---
=========================
[[0.02614969]
 [0.        ]
 [0.4256502 ]
 [0.        ]
 [0.        ]
 [0.37890276]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.42638618]
 [0.        ]]
[[-0.426385 ]
 [-0.       ]
 [-2.3089893]
 [-0.       ]
 [ 0.       ]
 [-2.2058618]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.310584 ]
 [ 0.       ]]
--- 0.1864185333251953 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4820.43505859375, (1947.1555, 1.6339262, 2871.1702, 0.47542784)
   validation loss 1741.7940673828125, (1372.0828, 0.07201815, 369.16382, 0.47542784)
decoder loss ratio: 53156.868305, decoder SINDy loss  ratio: 0.796892
--- 0.16493749618530273 seconds for one epoch ---
--- 0.20901966094970703 seconds for one epoch ---
--- 0.4971888065338135 seconds for one epoch ---
--- 0.20937156677246094 seconds for one epoch ---
--- 0.524059534072876 seconds for one epoch ---
--- 0.17684030532836914 seconds for one epoch ---
--- 0.48868513107299805 seconds for one epoch ---
--- 0.18772363662719727 seconds for one epoch ---
--- 0.5022449493408203 seconds for one epoch ---
--- 0.18410181999206543 seconds for one epoch ---
--- 0.5153946876525879 seconds for one epoch ---
--- 0.17072224617004395 seconds for one epoch ---
--- 0.5392041206359863 seconds for one epoch ---
--- 0.1765131950378418 seconds for one epoch ---
--- 0.5106420516967773 seconds for one epoch ---
--- 0.18396854400634766 seconds for one epoch ---
--- 0.46522021293640137 seconds for one epoch ---
--- 0.16912579536437988 seconds for one epoch ---
--- 0.5127761363983154 seconds for one epoch ---
--- 0.16370844841003418 seconds for one epoch ---
--- 0.5462307929992676 seconds for one epoch ---
--- 0.2042222023010254 seconds for one epoch ---
--- 0.48145151138305664 seconds for one epoch ---
--- 0.18179750442504883 seconds for one epoch ---
=========================
[[0.01944688]
 [0.        ]
 [0.41153163]
 [0.        ]
 [0.        ]
 [0.2687925 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37671533]
 [0.        ]]
[[-0.25033972]
 [-0.        ]
 [-2.2800891 ]
 [-0.        ]
 [ 0.        ]
 [-1.9398657 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2029457 ]
 [ 0.        ]]
--- 0.16550922393798828 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5109.2734375, (2120.8667, 0.67809856, 2987.296, 0.43280002)
   validation loss 914.4285888671875, (620.3426, 0.11234553, 293.54083, 0.43280002)
decoder loss ratio: 24033.148912, decoder SINDy loss  ratio: 0.633649
--- 0.2059481143951416 seconds for one epoch ---
--- 0.5508601665496826 seconds for one epoch ---
--- 0.22771763801574707 seconds for one epoch ---
--- 0.5158567428588867 seconds for one epoch ---
--- 0.1752917766571045 seconds for one epoch ---
--- 0.5445730686187744 seconds for one epoch ---
--- 0.16716623306274414 seconds for one epoch ---
--- 0.49843931198120117 seconds for one epoch ---
--- 0.14946937561035156 seconds for one epoch ---
--- 0.5443615913391113 seconds for one epoch ---
--- 0.22673964500427246 seconds for one epoch ---
--- 0.47983765602111816 seconds for one epoch ---
--- 0.17386102676391602 seconds for one epoch ---
--- 0.5538146495819092 seconds for one epoch ---
--- 0.17365360260009766 seconds for one epoch ---
--- 0.5407233238220215 seconds for one epoch ---
--- 0.19317269325256348 seconds for one epoch ---
--- 0.5976991653442383 seconds for one epoch ---
--- 0.20718884468078613 seconds for one epoch ---
--- 0.5042948722839355 seconds for one epoch ---
--- 0.16466689109802246 seconds for one epoch ---
--- 0.5517823696136475 seconds for one epoch ---
--- 0.17571234703063965 seconds for one epoch ---
--- 0.5397810935974121 seconds for one epoch ---
=========================
[[0.01637725]
 [0.        ]
 [0.36415726]
 [0.        ]
 [0.        ]
 [0.2174972 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35398012]
 [0.        ]]
[[-0.164504 ]
 [-0.       ]
 [-2.1760385]
 [-0.       ]
 [ 0.       ]
 [-1.7942432]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.152697 ]
 [ 0.       ]]
--- 0.19403648376464844 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4929.83154296875, (2197.664, 1.5427068, 2730.221, 0.4035921)
   validation loss 1109.4228515625, (788.2985, 0.08336434, 320.63745, 0.4035921)
decoder loss ratio: 30540.053325, decoder SINDy loss  ratio: 0.692141
--- 0.19657635688781738 seconds for one epoch ---
--- 0.23199057579040527 seconds for one epoch ---
--- 0.5586326122283936 seconds for one epoch ---
--- 0.18210148811340332 seconds for one epoch ---
--- 0.5532741546630859 seconds for one epoch ---
--- 0.1677711009979248 seconds for one epoch ---
--- 0.5280287265777588 seconds for one epoch ---
--- 0.17149686813354492 seconds for one epoch ---
--- 0.5275933742523193 seconds for one epoch ---
--- 0.1973109245300293 seconds for one epoch ---
--- 0.6025011539459229 seconds for one epoch ---
--- 0.21140289306640625 seconds for one epoch ---
--- 0.5234501361846924 seconds for one epoch ---
--- 0.20543360710144043 seconds for one epoch ---
--- 0.49150967597961426 seconds for one epoch ---
--- 0.1505262851715088 seconds for one epoch ---
--- 0.5401647090911865 seconds for one epoch ---
--- 0.16924095153808594 seconds for one epoch ---
--- 0.5176570415496826 seconds for one epoch ---
--- 0.17686247825622559 seconds for one epoch ---
--- 0.5341484546661377 seconds for one epoch ---
--- 0.20179486274719238 seconds for one epoch ---
--- 0.49863314628601074 seconds for one epoch ---
--- 0.15614557266235352 seconds for one epoch ---
=========================
[[0.01494529]
 [0.        ]
 [0.3134969 ]
 [0.        ]
 [0.        ]
 [0.19069296]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35471666]
 [0.        ]]
[[-0.14139126]
 [-0.        ]
 [-2.0581346 ]
 [-0.        ]
 [ 0.        ]
 [-1.7094291 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.1558242 ]
 [ 0.        ]]
--- 0.1700427532196045 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5554.0537109375, (1683.3599, 0.38140887, 3869.9253, 0.38710633)
   validation loss 1259.3275146484375, (978.1263, 0.119415686, 280.69476, 0.38710633)
decoder loss ratio: 37894.310256, decoder SINDy loss  ratio: 0.605919
--- 0.21745061874389648 seconds for one epoch ---
--- 0.5483174324035645 seconds for one epoch ---
--- 0.2923712730407715 seconds for one epoch ---
--- 0.5194802284240723 seconds for one epoch ---
--- 0.17397689819335938 seconds for one epoch ---
--- 0.5696794986724854 seconds for one epoch ---
--- 0.16814756393432617 seconds for one epoch ---
--- 0.5518736839294434 seconds for one epoch ---
--- 0.15998506546020508 seconds for one epoch ---
--- 0.5164072513580322 seconds for one epoch ---
--- 0.19905734062194824 seconds for one epoch ---
--- 0.6076149940490723 seconds for one epoch ---
--- 0.19576025009155273 seconds for one epoch ---
--- 0.567681074142456 seconds for one epoch ---
--- 0.1827547550201416 seconds for one epoch ---
--- 0.5423460006713867 seconds for one epoch ---
--- 0.20467019081115723 seconds for one epoch ---
--- 0.5743343830108643 seconds for one epoch ---
--- 0.1572730541229248 seconds for one epoch ---
--- 0.5651757717132568 seconds for one epoch ---
--- 0.17221570014953613 seconds for one epoch ---
--- 0.537381649017334 seconds for one epoch ---
--- 0.16857361793518066 seconds for one epoch ---
--- 0.5724818706512451 seconds for one epoch ---
=========================
[[0.01432219]
 [0.        ]
 [0.26982504]
 [0.        ]
 [0.        ]
 [0.17634499]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.3611264 ]
 [0.        ]]
[[-0.14593646]
 [-0.        ]
 [-1.9480616 ]
 [-0.        ]
 [ 0.        ]
 [-1.6610179 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.1715813 ]
 [ 0.        ]]
--- 0.17348933219909668 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5670.31591796875, (2607.8992, 0.570829, 3061.4712, 0.3747147)
   validation loss 5043.6552734375, (4506.5327, 0.0723685, 536.6759, 0.3747147)
decoder loss ratio: 174590.901058, decoder SINDy loss  ratio: 1.158490
--- 0.1463937759399414 seconds for one epoch ---
--- 0.18729543685913086 seconds for one epoch ---
--- 0.5799300670623779 seconds for one epoch ---
--- 0.17757058143615723 seconds for one epoch ---
--- 0.5375440120697021 seconds for one epoch ---
--- 0.17903923988342285 seconds for one epoch ---
--- 0.5996315479278564 seconds for one epoch ---
--- 0.2082536220550537 seconds for one epoch ---
--- 0.528566837310791 seconds for one epoch ---
--- 0.2161867618560791 seconds for one epoch ---
--- 0.527414083480835 seconds for one epoch ---
--- 0.18769049644470215 seconds for one epoch ---
--- 0.5674455165863037 seconds for one epoch ---
--- 0.17123770713806152 seconds for one epoch ---
--- 0.5244560241699219 seconds for one epoch ---
--- 0.17499780654907227 seconds for one epoch ---
--- 0.5430421829223633 seconds for one epoch ---
--- 0.1981372833251953 seconds for one epoch ---
--- 0.5309247970581055 seconds for one epoch ---
--- 0.20228338241577148 seconds for one epoch ---
--- 0.538783073425293 seconds for one epoch ---
--- 0.1951444149017334 seconds for one epoch ---
--- 0.5931687355041504 seconds for one epoch ---
--- 0.18242406845092773 seconds for one epoch ---
=========================
[[0.01417807]
 [0.        ]
 [0.23762809]
 [0.        ]
 [0.        ]
 [0.16687676]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.37795848]
 [0.        ]]
[[-0.16924407]
 [-0.        ]
 [-1.8600174 ]
 [-0.        ]
 [ 0.        ]
 [-1.6279796 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.210515  ]
 [ 0.        ]]
--- 0.15275812149047852 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4913.5712890625, (2260.8958, 0.40413603, 2651.9026, 0.3692071)
   validation loss 1852.6109619140625, (1473.6279, 0.14214873, 378.47165, 0.3692071)
decoder loss ratio: 57090.904327, decoder SINDy loss  ratio: 0.816984
--- 0.22698712348937988 seconds for one epoch ---
--- 0.59360671043396 seconds for one epoch ---
--- 0.1783313751220703 seconds for one epoch ---
--- 0.5381731986999512 seconds for one epoch ---
--- 0.22486019134521484 seconds for one epoch ---
--- 0.6165986061096191 seconds for one epoch ---
--- 0.2032475471496582 seconds for one epoch ---
--- 0.5673959255218506 seconds for one epoch ---
--- 0.15554404258728027 seconds for one epoch ---
--- 0.6176192760467529 seconds for one epoch ---
--- 0.1696619987487793 seconds for one epoch ---
--- 0.5501246452331543 seconds for one epoch ---
--- 0.21825051307678223 seconds for one epoch ---
--- 0.5955052375793457 seconds for one epoch ---
--- 0.16423511505126953 seconds for one epoch ---
--- 0.5438544750213623 seconds for one epoch ---
--- 0.15799927711486816 seconds for one epoch ---
--- 0.5452346801757812 seconds for one epoch ---
--- 0.19153642654418945 seconds for one epoch ---
--- 0.5566437244415283 seconds for one epoch ---
--- 0.19315600395202637 seconds for one epoch ---
--- 0.532233476638794 seconds for one epoch ---
--- 0.18645310401916504 seconds for one epoch ---
--- 0.5948784351348877 seconds for one epoch ---
=========================
[[0.01443279]
 [0.        ]
 [0.21169534]
 [0.        ]
 [0.        ]
 [0.15348577]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4048313 ]
 [0.        ]]
[[-0.20225693]
 [-0.        ]
 [-1.7830695 ]
 [-0.        ]
 [ 0.        ]
 [-1.5773604 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.2705188 ]
 [ 0.        ]]
--- 0.17398858070373535 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3488.07470703125, (1811.1902, 1.1899849, 1675.3279, 0.36675203)
   validation loss 1568.83642578125, (1288.871, 0.1271209, 279.4717, 0.36675203)
decoder loss ratio: 49933.099021, decoder SINDy loss  ratio: 0.603279
--- 0.16400480270385742 seconds for one epoch ---
--- 0.17319512367248535 seconds for one epoch ---
--- 0.5644283294677734 seconds for one epoch ---
--- 0.20088624954223633 seconds for one epoch ---
--- 0.570561408996582 seconds for one epoch ---
--- 0.15460467338562012 seconds for one epoch ---
--- 0.5685970783233643 seconds for one epoch ---
--- 0.1941204071044922 seconds for one epoch ---
--- 0.5396022796630859 seconds for one epoch ---
--- 0.15568327903747559 seconds for one epoch ---
--- 0.5547661781311035 seconds for one epoch ---
--- 0.15814208984375 seconds for one epoch ---
--- 0.5452573299407959 seconds for one epoch ---
--- 0.15267109870910645 seconds for one epoch ---
--- 0.5904242992401123 seconds for one epoch ---
--- 0.16115403175354004 seconds for one epoch ---
--- 0.5801084041595459 seconds for one epoch ---
--- 0.20450520515441895 seconds for one epoch ---
--- 0.5500743389129639 seconds for one epoch ---
--- 0.1768937110900879 seconds for one epoch ---
--- 0.6032922267913818 seconds for one epoch ---
--- 0.17702555656433105 seconds for one epoch ---
--- 0.5780856609344482 seconds for one epoch ---
--- 0.19642353057861328 seconds for one epoch ---
=========================
[[0.01528552]
 [0.        ]
 [0.19045329]
 [0.        ]
 [0.        ]
 [0.1532604 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4317874 ]
 [0.        ]]
[[-0.25503373]
 [-0.        ]
 [-1.7149913 ]
 [-0.        ]
 [ 0.        ]
 [-1.5779637 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.3293512 ]
 [ 0.        ]]
--- 0.1562938690185547 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4106.32666015625, (1397.1757, 1.3853773, 2707.3982, 0.36744696)
   validation loss 1253.658935546875, (897.8853, 0.113163695, 355.29306, 0.36744696)
decoder loss ratio: 34785.635898, decoder SINDy loss  ratio: 0.766950
--- 0.17285490036010742 seconds for one epoch ---
--- 0.6382732391357422 seconds for one epoch ---
--- 0.16830730438232422 seconds for one epoch ---
--- 0.618872880935669 seconds for one epoch ---
--- 0.18350815773010254 seconds for one epoch ---
--- 0.5685136318206787 seconds for one epoch ---
--- 0.2168288230895996 seconds for one epoch ---
--- 0.5785834789276123 seconds for one epoch ---
--- 0.17425322532653809 seconds for one epoch ---
--- 0.6121845245361328 seconds for one epoch ---
--- 0.17612075805664062 seconds for one epoch ---
--- 0.6053569316864014 seconds for one epoch ---
--- 0.17075228691101074 seconds for one epoch ---
--- 0.5805916786193848 seconds for one epoch ---
--- 0.16437101364135742 seconds for one epoch ---
--- 0.5548453330993652 seconds for one epoch ---
--- 0.19579029083251953 seconds for one epoch ---
--- 0.6446936130523682 seconds for one epoch ---
--- 0.1854839324951172 seconds for one epoch ---
--- 0.5825724601745605 seconds for one epoch ---
--- 0.1888573169708252 seconds for one epoch ---
--- 0.5830380916595459 seconds for one epoch ---
--- 0.17792129516601562 seconds for one epoch ---
--- 0.5941028594970703 seconds for one epoch ---
=========================
[[0.0163507 ]
 [0.        ]
 [0.16934176]
 [0.        ]
 [0.        ]
 [0.14581987]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4682042 ]
 [0.        ]]
[[-0.30681592]
 [-0.        ]
 [-1.6411791 ]
 [-0.        ]
 [ 0.        ]
 [-1.548591  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.4072044 ]
 [ 0.        ]]
--- 0.16105961799621582 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5432.97216796875, (2604.957, 1.6739427, 2825.9722, 0.36928234)
   validation loss 998.0737915039062, (713.00305, 0.12025919, 284.58124, 0.36928234)
decoder loss ratio: 27622.976053, decoder SINDy loss  ratio: 0.614309
--- 0.15088820457458496 seconds for one epoch ---
--- 0.18116283416748047 seconds for one epoch ---
--- 0.6162621974945068 seconds for one epoch ---
--- 0.18927550315856934 seconds for one epoch ---
--- 0.555692195892334 seconds for one epoch ---
--- 0.1923060417175293 seconds for one epoch ---
--- 0.6360242366790771 seconds for one epoch ---
--- 0.16977882385253906 seconds for one epoch ---
--- 0.573840856552124 seconds for one epoch ---
--- 0.18422365188598633 seconds for one epoch ---
--- 0.5852518081665039 seconds for one epoch ---
--- 0.17494869232177734 seconds for one epoch ---
--- 0.6622467041015625 seconds for one epoch ---
--- 0.21082282066345215 seconds for one epoch ---
--- 0.6003243923187256 seconds for one epoch ---
--- 0.18692994117736816 seconds for one epoch ---
--- 0.616680383682251 seconds for one epoch ---
--- 0.18781185150146484 seconds for one epoch ---
--- 0.6449697017669678 seconds for one epoch ---
--- 0.17199015617370605 seconds for one epoch ---
--- 0.6047084331512451 seconds for one epoch ---
--- 0.17321324348449707 seconds for one epoch ---
--- 0.6093540191650391 seconds for one epoch ---
--- 0.15984702110290527 seconds for one epoch ---
=========================
[[0.01765674]
 [0.        ]
 [0.15111879]
 [0.        ]
 [0.        ]
 [0.14073546]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5050446 ]
 [0.        ]]
[[-0.3605526]
 [-0.       ]
 [-1.5715109]
 [-0.       ]
 [ 0.       ]
 [-1.5281098]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.485237 ]
 [ 0.       ]]
--- 0.16094326972961426 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3050.602294921875, (1293.4668, 0.82157266, 1755.9404, 0.37352037)
   validation loss 1451.5291748046875, (1157.7751, 0.12802835, 293.2524, 0.37352037)
decoder loss ratio: 44854.219161, decoder SINDy loss  ratio: 0.633027
--- 0.1791372299194336 seconds for one epoch ---
--- 0.6108872890472412 seconds for one epoch ---
--- 0.16147255897521973 seconds for one epoch ---
--- 0.6670093536376953 seconds for one epoch ---
--- 0.18051457405090332 seconds for one epoch ---
--- 0.6860570907592773 seconds for one epoch ---
--- 0.197310209274292 seconds for one epoch ---
--- 0.5950615406036377 seconds for one epoch ---
--- 0.1794726848602295 seconds for one epoch ---
--- 0.7013881206512451 seconds for one epoch ---
--- 0.17576050758361816 seconds for one epoch ---
--- 0.5942962169647217 seconds for one epoch ---
--- 0.16967296600341797 seconds for one epoch ---
--- 0.6075963973999023 seconds for one epoch ---
--- 0.1743936538696289 seconds for one epoch ---
--- 0.615220308303833 seconds for one epoch ---
--- 0.17960882186889648 seconds for one epoch ---
--- 0.6910617351531982 seconds for one epoch ---
--- 0.20267796516418457 seconds for one epoch ---
--- 0.656292200088501 seconds for one epoch ---
--- 0.18818902969360352 seconds for one epoch ---
--- 0.586745023727417 seconds for one epoch ---
--- 0.18439197540283203 seconds for one epoch ---
--- 0.6601228713989258 seconds for one epoch ---
=========================
[[0.01933017]
 [0.        ]
 [0.13700461]
 [0.        ]
 [0.        ]
 [0.13508315]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5478831 ]
 [0.        ]]
[[-0.41784766]
 [-0.        ]
 [-1.5127531 ]
 [-0.        ]
 [ 0.        ]
 [-1.5042528 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.5761454 ]
 [ 0.        ]]
--- 0.18776917457580566 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2660.228759765625, (1442.252, 1.1085812, 1216.4905, 0.3777787)
   validation loss 1034.3802490234375, (746.01373, 0.13399385, 287.85477, 0.3777787)
decoder loss ratio: 28901.867150, decoder SINDy loss  ratio: 0.621375
--- 0.14069533348083496 seconds for one epoch ---
--- 0.18060946464538574 seconds for one epoch ---
--- 0.6090738773345947 seconds for one epoch ---
--- 0.1597003936767578 seconds for one epoch ---
--- 0.6329193115234375 seconds for one epoch ---
--- 0.17840290069580078 seconds for one epoch ---
--- 0.6074836254119873 seconds for one epoch ---
--- 0.18053841590881348 seconds for one epoch ---
--- 0.7188332080841064 seconds for one epoch ---
--- 0.21493959426879883 seconds for one epoch ---
--- 0.6236310005187988 seconds for one epoch ---
--- 0.22136616706848145 seconds for one epoch ---
--- 0.6280026435852051 seconds for one epoch ---
--- 0.15598487854003906 seconds for one epoch ---
--- 0.6413333415985107 seconds for one epoch ---
--- 0.17957615852355957 seconds for one epoch ---
--- 0.6696286201477051 seconds for one epoch ---
--- 0.22268915176391602 seconds for one epoch ---
--- 0.6119799613952637 seconds for one epoch ---
--- 0.17264461517333984 seconds for one epoch ---
--- 0.6472508907318115 seconds for one epoch ---
--- 0.18180084228515625 seconds for one epoch ---
--- 0.6281497478485107 seconds for one epoch ---
--- 0.16204833984375 seconds for one epoch ---
=========================
[[0.02178732]
 [0.        ]
 [0.13397391]
 [0.        ]
 [0.        ]
 [0.12683766]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6008512 ]
 [0.        ]]
[[-0.48886067]
 [-0.        ]
 [-1.5001224 ]
 [-0.        ]
 [ 0.        ]
 [-1.4674443 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.6909199 ]
 [ 0.        ]]
--- 0.1536698341369629 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7179.9130859375, (2760.8298, 0.6935817, 4418.0034, 0.3860804)
   validation loss 1451.1236572265625, (1138.9335, 0.11265547, 311.69138, 0.3860804)
decoder loss ratio: 44124.259968, decoder SINDy loss  ratio: 0.672830
--- 0.16768336296081543 seconds for one epoch ---
--- 0.639197587966919 seconds for one epoch ---
--- 0.17148375511169434 seconds for one epoch ---
--- 0.6242039203643799 seconds for one epoch ---
--- 0.1593470573425293 seconds for one epoch ---
--- 0.619464635848999 seconds for one epoch ---
--- 0.17445993423461914 seconds for one epoch ---
--- 0.6397557258605957 seconds for one epoch ---
--- 0.20624756813049316 seconds for one epoch ---
--- 0.6698684692382812 seconds for one epoch ---
--- 0.21779489517211914 seconds for one epoch ---
--- 0.6071786880493164 seconds for one epoch ---
--- 0.17123746871948242 seconds for one epoch ---
--- 0.6410095691680908 seconds for one epoch ---
--- 0.24348998069763184 seconds for one epoch ---
--- 0.6868956089019775 seconds for one epoch ---
--- 0.15483689308166504 seconds for one epoch ---
--- 0.6518878936767578 seconds for one epoch ---
--- 0.19083833694458008 seconds for one epoch ---
--- 0.7155203819274902 seconds for one epoch ---
--- 0.22709226608276367 seconds for one epoch ---
--- 0.6300148963928223 seconds for one epoch ---
--- 0.16543984413146973 seconds for one epoch ---
--- 0.6520586013793945 seconds for one epoch ---
=========================
[[0.02044244]
 [0.        ]
 [0.16455522]
 [0.        ]
 [0.        ]
 [0.11439419]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5957077 ]
 [0.        ]]
[[-0.45845985]
 [-0.        ]
 [-1.6261151 ]
 [-0.        ]
 [ 0.        ]
 [-1.4072477 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.679748  ]
 [ 0.        ]]
--- 0.1704113483428955 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4138.0576171875, (2025.8262, 1.905, 2109.938, 0.38882396)
   validation loss 868.2421875, (600.70166, 0.11143293, 267.0403, 0.38882396)
decoder loss ratio: 23272.225178, decoder SINDy loss  ratio: 0.576444
--- 0.16290688514709473 seconds for one epoch ---
--- 0.16653108596801758 seconds for one epoch ---
--- 0.6408796310424805 seconds for one epoch ---
--- 0.19564318656921387 seconds for one epoch ---
--- 0.723268985748291 seconds for one epoch ---
--- 0.1512451171875 seconds for one epoch ---
--- 0.6898024082183838 seconds for one epoch ---
--- 0.17457962036132812 seconds for one epoch ---
--- 0.685943603515625 seconds for one epoch ---
--- 0.17146086692810059 seconds for one epoch ---
--- 0.6799843311309814 seconds for one epoch ---
--- 0.17694449424743652 seconds for one epoch ---
--- 0.6327099800109863 seconds for one epoch ---
--- 0.18048477172851562 seconds for one epoch ---
--- 0.6945459842681885 seconds for one epoch ---
--- 0.1842052936553955 seconds for one epoch ---
--- 0.6439042091369629 seconds for one epoch ---
--- 0.19458341598510742 seconds for one epoch ---
--- 0.706371545791626 seconds for one epoch ---
--- 0.22999095916748047 seconds for one epoch ---
--- 0.7009124755859375 seconds for one epoch ---
--- 0.19278287887573242 seconds for one epoch ---
--- 0.6717374324798584 seconds for one epoch ---
--- 0.20108628273010254 seconds for one epoch ---
=========================
[[0.02198004]
 [0.        ]
 [0.1560229 ]
 [0.        ]
 [0.        ]
 [0.11385025]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.62280864]
 [0.        ]]
[[-0.50113565]
 [-0.        ]
 [-1.5936879 ]
 [-0.        ]
 [ 0.        ]
 [-1.4051352 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7401128 ]
 [ 0.        ]]
--- 0.14473915100097656 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4888.31298828125, (3619.6655, 0.34973532, 1267.9049, 0.39244422)
   validation loss 1209.199951171875, (898.7951, 0.09027766, 309.92212, 0.39244422)
decoder loss ratio: 34820.882744, decoder SINDy loss  ratio: 0.669010
--- 0.1634962558746338 seconds for one epoch ---
--- 0.6849088668823242 seconds for one epoch ---
--- 0.1891040802001953 seconds for one epoch ---
--- 0.65110182762146 seconds for one epoch ---
--- 0.17161870002746582 seconds for one epoch ---
--- 0.6698629856109619 seconds for one epoch ---
--- 0.18162918090820312 seconds for one epoch ---
--- 0.599139928817749 seconds for one epoch ---
--- 0.1560192108154297 seconds for one epoch ---
--- 0.6229941844940186 seconds for one epoch ---
--- 0.16099953651428223 seconds for one epoch ---
--- 0.7976081371307373 seconds for one epoch ---
--- 0.17523550987243652 seconds for one epoch ---
--- 0.6755342483520508 seconds for one epoch ---
--- 0.17873072624206543 seconds for one epoch ---
--- 0.6603736877441406 seconds for one epoch ---
--- 0.15935564041137695 seconds for one epoch ---
--- 0.7394759654998779 seconds for one epoch ---
--- 0.18224787712097168 seconds for one epoch ---
--- 0.6402802467346191 seconds for one epoch ---
--- 0.19478511810302734 seconds for one epoch ---
--- 0.7159514427185059 seconds for one epoch ---
--- 0.1792736053466797 seconds for one epoch ---
--- 0.653162956237793 seconds for one epoch ---
=========================
[[0.02321668]
 [0.        ]
 [0.14612326]
 [0.        ]
 [0.        ]
 [0.11343341]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.64078414]
 [0.        ]]
[[-0.53303415]
 [-0.        ]
 [-1.5540544 ]
 [-0.        ]
 [ 0.        ]
 [-1.4035175 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.7811258 ]
 [ 0.        ]]
--- 0.17046642303466797 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2956.953125, (1612.1051, 0.93436265, 1343.5193, 0.3945314)
   validation loss 927.4950561523438, (603.0651, 0.098703384, 323.9367, 0.3945314)
decoder loss ratio: 23363.789891, decoder SINDy loss  ratio: 0.699263
--- 0.21704769134521484 seconds for one epoch ---
--- 0.2480177879333496 seconds for one epoch ---
--- 0.6372873783111572 seconds for one epoch ---
--- 0.16204524040222168 seconds for one epoch ---
--- 0.6972973346710205 seconds for one epoch ---
--- 0.16879963874816895 seconds for one epoch ---
--- 0.645117998123169 seconds for one epoch ---
--- 0.20191526412963867 seconds for one epoch ---
--- 0.6645033359527588 seconds for one epoch ---
--- 0.1680011749267578 seconds for one epoch ---
--- 0.6821193695068359 seconds for one epoch ---
--- 0.20390915870666504 seconds for one epoch ---
--- 0.7019541263580322 seconds for one epoch ---
--- 0.3354332447052002 seconds for one epoch ---
--- 0.6378779411315918 seconds for one epoch ---
--- 0.16498494148254395 seconds for one epoch ---
--- 0.694037675857544 seconds for one epoch ---
--- 0.18050479888916016 seconds for one epoch ---
--- 0.6478583812713623 seconds for one epoch ---
--- 0.17606735229492188 seconds for one epoch ---
--- 0.7099609375 seconds for one epoch ---
--- 0.18941450119018555 seconds for one epoch ---
--- 0.7201979160308838 seconds for one epoch ---
--- 0.185258150100708 seconds for one epoch ---
=========================
[[0.02551325]
 [0.        ]
 [0.13969831]
 [0.        ]
 [0.        ]
 [0.11757641]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.66390914]
 [0.        ]]
[[-0.5854407]
 [-0.       ]
 [-1.5272658]
 [-0.       ]
 [ 0.       ]
 [-1.4249583]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.835261 ]
 [ 0.       ]]
--- 0.1584033966064453 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3651.43408203125, (1474.0239, 0.07008203, 2176.9395, 0.40059996)
   validation loss 1687.85302734375, (1340.2482, 0.09069055, 347.11353, 0.40059996)
decoder loss ratio: 51923.540838, decoder SINDy loss  ratio: 0.749293
--- 0.17272377014160156 seconds for one epoch ---
--- 0.7278242111206055 seconds for one epoch ---
--- 0.16015625 seconds for one epoch ---
--- 0.7470831871032715 seconds for one epoch ---
--- 0.21347641944885254 seconds for one epoch ---
--- 0.6896810531616211 seconds for one epoch ---
--- 0.17658090591430664 seconds for one epoch ---
--- 0.795067310333252 seconds for one epoch ---
--- 0.18907642364501953 seconds for one epoch ---
--- 0.6369638442993164 seconds for one epoch ---
--- 0.16109919548034668 seconds for one epoch ---
--- 0.6529500484466553 seconds for one epoch ---
--- 0.17872881889343262 seconds for one epoch ---
--- 0.6924166679382324 seconds for one epoch ---
--- 0.1684269905090332 seconds for one epoch ---
--- 0.741020679473877 seconds for one epoch ---
--- 0.16645193099975586 seconds for one epoch ---
--- 0.6734440326690674 seconds for one epoch ---
--- 0.20795416831970215 seconds for one epoch ---
--- 0.7035236358642578 seconds for one epoch ---
--- 0.21175551414489746 seconds for one epoch ---
--- 0.7801446914672852 seconds for one epoch ---
--- 0.16520214080810547 seconds for one epoch ---
--- 0.6949031352996826 seconds for one epoch ---
=========================
[[0.02709669]
 [0.        ]
 [0.12970938]
 [0.        ]
 [0.        ]
 [0.11350716]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.685726  ]
 [0.        ]]
[[-0.6189839]
 [-0.       ]
 [-1.483228 ]
 [-0.       ]
 [ 0.       ]
 [-1.4047464]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8880823]
 [ 0.       ]]
--- 0.15601181983947754 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3111.6259765625, (1525.025, 1.0056837, 1585.1948, 0.4003272)
   validation loss 928.7495727539062, (579.25116, 0.07798709, 349.02008, 0.4003272)
decoder loss ratio: 22441.195550, decoder SINDy loss  ratio: 0.753409
--- 0.14141035079956055 seconds for one epoch ---
--- 0.1731112003326416 seconds for one epoch ---
--- 0.6922686100006104 seconds for one epoch ---
--- 0.18629837036132812 seconds for one epoch ---
--- 0.6667900085449219 seconds for one epoch ---
--- 0.17129969596862793 seconds for one epoch ---
--- 0.8005814552307129 seconds for one epoch ---
--- 0.18175745010375977 seconds for one epoch ---
--- 0.7589530944824219 seconds for one epoch ---
--- 0.17537212371826172 seconds for one epoch ---
--- 0.6718716621398926 seconds for one epoch ---
--- 0.17800259590148926 seconds for one epoch ---
--- 0.6725549697875977 seconds for one epoch ---
--- 0.17698025703430176 seconds for one epoch ---
--- 0.6710870265960693 seconds for one epoch ---
--- 0.2015852928161621 seconds for one epoch ---
--- 0.8230209350585938 seconds for one epoch ---
--- 0.1830136775970459 seconds for one epoch ---
--- 0.680666446685791 seconds for one epoch ---
--- 0.17867064476013184 seconds for one epoch ---
--- 0.7238051891326904 seconds for one epoch ---
--- 0.20013999938964844 seconds for one epoch ---
--- 0.6817944049835205 seconds for one epoch ---
--- 0.17461395263671875 seconds for one epoch ---
=========================
[[0.02853738]
 [0.        ]
 [0.12192363]
 [0.        ]
 [0.        ]
 [0.10805363]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.7071874 ]
 [0.        ]]
[[-0.6477978]
 [-0.       ]
 [-1.4469445]
 [-0.       ]
 [ 0.       ]
 [-1.3765106]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9420688]
 [ 0.       ]]
--- 0.16799330711364746 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4275.09619140625, (1606.84, 0.94326806, 2666.911, 0.40191007)
   validation loss 1452.86865234375, (1075.5281, 0.080481775, 376.85822, 0.40191007)
decoder loss ratio: 41667.824870, decoder SINDy loss  ratio: 0.813501
--- 0.17936158180236816 seconds for one epoch ---
--- 0.7061722278594971 seconds for one epoch ---
--- 0.17296504974365234 seconds for one epoch ---
--- 0.7012503147125244 seconds for one epoch ---
--- 0.1790330410003662 seconds for one epoch ---
--- 0.7158489227294922 seconds for one epoch ---
--- 0.16625332832336426 seconds for one epoch ---
--- 0.7881405353546143 seconds for one epoch ---
--- 0.19136285781860352 seconds for one epoch ---
--- 0.7874026298522949 seconds for one epoch ---
--- 0.21203279495239258 seconds for one epoch ---
--- 0.7053029537200928 seconds for one epoch ---
--- 0.21053266525268555 seconds for one epoch ---
--- 0.7241811752319336 seconds for one epoch ---
--- 0.19035720825195312 seconds for one epoch ---
--- 0.67374587059021 seconds for one epoch ---
--- 0.16068005561828613 seconds for one epoch ---
--- 0.686455488204956 seconds for one epoch ---
--- 0.17348027229309082 seconds for one epoch ---
--- 0.7836289405822754 seconds for one epoch ---
--- 0.16213202476501465 seconds for one epoch ---
--- 0.7023065090179443 seconds for one epoch ---
--- 0.18193697929382324 seconds for one epoch ---
--- 0.7550196647644043 seconds for one epoch ---
=========================
[[0.03126206]
 [0.        ]
 [0.11501458]
 [0.        ]
 [0.        ]
 [0.10601141]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.73279166]
 [0.        ]]
[[-0.69706684]
 [-0.        ]
 [-1.4130371 ]
 [-0.        ]
 [ 0.        ]
 [-1.3657703 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.009677  ]
 [ 0.        ]]
--- 0.17845582962036133 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2733.294921875, (1351.9822, 0.8763284, 1380.0321, 0.40424046)
   validation loss 1599.49951171875, (1285.0769, 0.13645847, 313.88184, 0.40424046)
decoder loss ratio: 49786.110264, decoder SINDy loss  ratio: 0.677558
THRESHOLDING: 3 active coefficients
--- 0.6795165538787842 seconds for one epoch ---
--- 0.22839879989624023 seconds for one epoch ---
--- 0.7462654113769531 seconds for one epoch ---
--- 0.19813036918640137 seconds for one epoch ---
--- 0.6826777458190918 seconds for one epoch ---
--- 0.18168902397155762 seconds for one epoch ---
--- 0.7138912677764893 seconds for one epoch ---
--- 0.17331409454345703 seconds for one epoch ---
--- 0.7851781845092773 seconds for one epoch ---
--- 0.17587995529174805 seconds for one epoch ---
--- 0.7161493301391602 seconds for one epoch ---
--- 0.1547989845275879 seconds for one epoch ---
--- 0.7639617919921875 seconds for one epoch ---
--- 0.155259370803833 seconds for one epoch ---
--- 0.6985652446746826 seconds for one epoch ---
--- 0.21169281005859375 seconds for one epoch ---
--- 0.7714717388153076 seconds for one epoch ---
--- 0.20437335968017578 seconds for one epoch ---
--- 0.7948813438415527 seconds for one epoch ---
--- 0.1678304672241211 seconds for one epoch ---
--- 0.7406737804412842 seconds for one epoch ---
--- 0.18896913528442383 seconds for one epoch ---
--- 0.7320504188537598 seconds for one epoch ---
--- 0.18021655082702637 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11461928]
 [0.        ]
 [0.        ]
 [0.12030824]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.77687484]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.4112716]
 [-0.       ]
 [ 0.       ]
 [-1.4395878]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1369035]
 [ 0.       ]]
--- 0.1469879150390625 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3287.615966796875, (1709.0302, 0.60396355, 1577.62, 0.36192042)
   validation loss 1357.781982421875, (961.373, 0.07492283, 395.97214, 0.36192042)
decoder loss ratio: 37245.258488, decoder SINDy loss  ratio: 0.854762
--- 0.1791994571685791 seconds for one epoch ---
--- 0.7380104064941406 seconds for one epoch ---
--- 0.20204591751098633 seconds for one epoch ---
--- 0.741008996963501 seconds for one epoch ---
--- 0.20105481147766113 seconds for one epoch ---
--- 0.7804348468780518 seconds for one epoch ---
--- 0.20283722877502441 seconds for one epoch ---
--- 0.739459753036499 seconds for one epoch ---
--- 0.16773486137390137 seconds for one epoch ---
--- 0.7372071743011475 seconds for one epoch ---
--- 0.1747748851776123 seconds for one epoch ---
--- 0.7268221378326416 seconds for one epoch ---
--- 0.22118520736694336 seconds for one epoch ---
--- 0.7851400375366211 seconds for one epoch ---
--- 0.18121600151062012 seconds for one epoch ---
--- 0.8135747909545898 seconds for one epoch ---
--- 0.15865778923034668 seconds for one epoch ---
--- 0.751218318939209 seconds for one epoch ---
--- 0.18642354011535645 seconds for one epoch ---
--- 0.7546353340148926 seconds for one epoch ---
--- 0.17138457298278809 seconds for one epoch ---
--- 0.7864184379577637 seconds for one epoch ---
--- 0.22305512428283691 seconds for one epoch ---
--- 0.7310924530029297 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.11421616]
 [0.        ]
 [0.        ]
 [0.121213  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.81199896]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.4094098]
 [-0.       ]
 [ 0.       ]
 [-1.4441642]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2520466]
 [ 0.       ]]
--- 0.16728520393371582 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2675.06787109375, (1258.8942, 1.5821317, 1414.2246, 0.36692128)
   validation loss 1120.947509765625, (796.75995, 0.111031674, 323.70963, 0.36692128)
decoder loss ratio: 30867.863650, decoder SINDy loss  ratio: 0.698773
--- 0.1518862247467041 seconds for one epoch ---
--- 0.1665198802947998 seconds for one epoch ---
--- 0.7239065170288086 seconds for one epoch ---
--- 0.17712831497192383 seconds for one epoch ---
--- 0.719271183013916 seconds for one epoch ---
--- 0.1782979965209961 seconds for one epoch ---
--- 0.7899482250213623 seconds for one epoch ---
--- 0.1639573574066162 seconds for one epoch ---
--- 0.7806823253631592 seconds for one epoch ---
--- 0.16484951972961426 seconds for one epoch ---
--- 0.7993648052215576 seconds for one epoch ---
--- 0.17674756050109863 seconds for one epoch ---
--- 0.718468189239502 seconds for one epoch ---
--- 0.1776256561279297 seconds for one epoch ---
--- 0.7651717662811279 seconds for one epoch ---
--- 0.1486525535583496 seconds for one epoch ---
--- 0.799795389175415 seconds for one epoch ---
--- 0.19210314750671387 seconds for one epoch ---
--- 0.6948678493499756 seconds for one epoch ---
--- 0.15594077110290527 seconds for one epoch ---
--- 0.8180062770843506 seconds for one epoch ---
--- 0.18615150451660156 seconds for one epoch ---
--- 0.8043067455291748 seconds for one epoch ---
--- 0.18388032913208008 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10807431]
 [0.        ]
 [0.        ]
 [0.12070332]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.83580106]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3775415]
 [-0.       ]
 [ 0.       ]
 [-1.441857 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3400054]
 [ 0.       ]]
--- 0.14397430419921875 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2927.93603515625, (1567.9792, 0.534203, 1359.053, 0.36950693)
   validation loss 1579.8707275390625, (1135.0548, 0.09738979, 444.34897, 0.36950693)
decoder loss ratio: 43973.993865, decoder SINDy loss  ratio: 0.959190
--- 0.17215991020202637 seconds for one epoch ---
--- 0.7880959510803223 seconds for one epoch ---
--- 0.17872047424316406 seconds for one epoch ---
--- 0.7418127059936523 seconds for one epoch ---
--- 0.21402931213378906 seconds for one epoch ---
--- 0.8286771774291992 seconds for one epoch ---
--- 0.17432236671447754 seconds for one epoch ---
--- 0.7384593486785889 seconds for one epoch ---
--- 0.1490476131439209 seconds for one epoch ---
--- 0.8088641166687012 seconds for one epoch ---
--- 0.1483447551727295 seconds for one epoch ---
--- 0.8408298492431641 seconds for one epoch ---
--- 0.15199804306030273 seconds for one epoch ---
--- 0.7750468254089355 seconds for one epoch ---
--- 0.15950655937194824 seconds for one epoch ---
--- 0.7359285354614258 seconds for one epoch ---
--- 0.1936659812927246 seconds for one epoch ---
--- 0.8119800090789795 seconds for one epoch ---
--- 0.17644715309143066 seconds for one epoch ---
--- 0.764702320098877 seconds for one epoch ---
--- 0.1986067295074463 seconds for one epoch ---
--- 0.7669541835784912 seconds for one epoch ---
--- 0.212388277053833 seconds for one epoch ---
--- 0.7490277290344238 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10981394]
 [0.        ]
 [0.        ]
 [0.11956845]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.86130667]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.386918 ]
 [-0.       ]
 [ 0.       ]
 [-1.436452 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4467027]
 [ 0.       ]]
--- 0.1797335147857666 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3703.02685546875, (2054.9177, 1.4928232, 1646.2434, 0.37278548)
   validation loss 1753.1654052734375, (1222.1344, 0.09699927, 530.56116, 0.37278548)
decoder loss ratio: 47347.608352, decoder SINDy loss  ratio: 1.145291
--- 0.13384604454040527 seconds for one epoch ---
--- 0.20066499710083008 seconds for one epoch ---
--- 0.7547492980957031 seconds for one epoch ---
--- 0.2075037956237793 seconds for one epoch ---
--- 0.8007493019104004 seconds for one epoch ---
--- 0.20345115661621094 seconds for one epoch ---
--- 0.7171564102172852 seconds for one epoch ---
--- 0.1856541633605957 seconds for one epoch ---
--- 0.7683284282684326 seconds for one epoch ---
--- 0.17502450942993164 seconds for one epoch ---
--- 0.7343568801879883 seconds for one epoch ---
--- 0.1983504295349121 seconds for one epoch ---
--- 0.7496011257171631 seconds for one epoch ---
--- 0.19507241249084473 seconds for one epoch ---
--- 0.8257155418395996 seconds for one epoch ---
--- 0.16311168670654297 seconds for one epoch ---
--- 0.7964277267456055 seconds for one epoch ---
--- 0.16907572746276855 seconds for one epoch ---
--- 0.8125865459442139 seconds for one epoch ---
--- 0.16504693031311035 seconds for one epoch ---
--- 0.837435245513916 seconds for one epoch ---
--- 0.16490602493286133 seconds for one epoch ---
--- 0.7566654682159424 seconds for one epoch ---
--- 0.1780562400817871 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.1093991 ]
 [0.        ]
 [0.        ]
 [0.11944655]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.88593996]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.384861 ]
 [-0.       ]
 [ 0.       ]
 [-1.4359767]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5670316]
 [ 0.       ]]
--- 0.1681969165802002 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4088.418701171875, (2258.0952, 1.0325053, 1828.9142, 0.37682983)
   validation loss 2367.804931640625, (1753.8345, 0.15367745, 613.44, 0.37682983)
decoder loss ratio: 67946.592261, decoder SINDy loss  ratio: 1.324197
--- 0.17738866806030273 seconds for one epoch ---
--- 0.7791740894317627 seconds for one epoch ---
--- 0.18503713607788086 seconds for one epoch ---
--- 0.7824966907501221 seconds for one epoch ---
--- 0.17933058738708496 seconds for one epoch ---
--- 0.752373456954956 seconds for one epoch ---
--- 0.18563103675842285 seconds for one epoch ---
--- 0.7793817520141602 seconds for one epoch ---
--- 0.19103002548217773 seconds for one epoch ---
--- 0.8363072872161865 seconds for one epoch ---
--- 0.1636512279510498 seconds for one epoch ---
--- 0.7787189483642578 seconds for one epoch ---
--- 0.17318439483642578 seconds for one epoch ---
--- 0.7718095779418945 seconds for one epoch ---
--- 0.1721634864807129 seconds for one epoch ---
--- 0.8445370197296143 seconds for one epoch ---
--- 0.17714285850524902 seconds for one epoch ---
--- 0.7993054389953613 seconds for one epoch ---
--- 0.18920683860778809 seconds for one epoch ---
--- 0.8668394088745117 seconds for one epoch ---
--- 0.17165756225585938 seconds for one epoch ---
--- 0.8877711296081543 seconds for one epoch ---
--- 0.18190717697143555 seconds for one epoch ---
--- 0.8251664638519287 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10615272]
 [0.        ]
 [0.        ]
 [0.12049256]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9047044 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3675854]
 [-0.       ]
 [ 0.       ]
 [-1.4411793]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.6752331]
 [-0.       ]]
--- 0.19120025634765625 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2853.23095703125, (1302.2178, 0.20816496, 1550.427, 0.37798533)
   validation loss 1991.099609375, (1595.0356, 0.14772555, 395.53833, 0.37798533)
decoder loss ratio: 61794.449973, decoder SINDy loss  ratio: 0.853825
--- 0.1892225742340088 seconds for one epoch ---
--- 0.22275733947753906 seconds for one epoch ---
--- 0.7445604801177979 seconds for one epoch ---
--- 0.19089102745056152 seconds for one epoch ---
--- 0.825439453125 seconds for one epoch ---
--- 0.17696475982666016 seconds for one epoch ---
--- 0.8220682144165039 seconds for one epoch ---
--- 0.18379807472229004 seconds for one epoch ---
--- 0.763624906539917 seconds for one epoch ---
--- 0.15802669525146484 seconds for one epoch ---
--- 0.9174528121948242 seconds for one epoch ---
--- 0.2132253646850586 seconds for one epoch ---
--- 0.7834603786468506 seconds for one epoch ---
--- 0.1524813175201416 seconds for one epoch ---
--- 0.7860109806060791 seconds for one epoch ---
--- 0.1735825538635254 seconds for one epoch ---
--- 0.8203637599945068 seconds for one epoch ---
--- 0.1820390224456787 seconds for one epoch ---
--- 0.7528681755065918 seconds for one epoch ---
--- 0.17380046844482422 seconds for one epoch ---
--- 0.8032410144805908 seconds for one epoch ---
--- 0.17090439796447754 seconds for one epoch ---
--- 0.8181335926055908 seconds for one epoch ---
--- 0.1929490566253662 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10604321]
 [0.        ]
 [0.        ]
 [0.11869621]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91728544]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3670913]
 [ 0.       ]
 [ 0.       ]
 [-1.4324765]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7591867]
 [ 0.       ]]
--- 0.14490747451782227 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2989.87451171875, (2224.7876, 0.142139, 764.5645, 0.38043037)
   validation loss 1374.033447265625, (992.4977, 0.11247619, 381.04294, 0.38043037)
decoder loss ratio: 38451.083201, decoder SINDy loss  ratio: 0.822535
--- 0.18306398391723633 seconds for one epoch ---
--- 0.7574858665466309 seconds for one epoch ---
--- 0.17018985748291016 seconds for one epoch ---
--- 0.8078925609588623 seconds for one epoch ---
--- 0.17299914360046387 seconds for one epoch ---
--- 0.9424419403076172 seconds for one epoch ---
--- 0.1681966781616211 seconds for one epoch ---
--- 0.761582612991333 seconds for one epoch ---
--- 0.15550899505615234 seconds for one epoch ---
--- 0.8021435737609863 seconds for one epoch ---
--- 0.15575122833251953 seconds for one epoch ---
--- 0.8464832305908203 seconds for one epoch ---
--- 0.2062671184539795 seconds for one epoch ---
--- 0.7977333068847656 seconds for one epoch ---
--- 0.19754600524902344 seconds for one epoch ---
--- 0.7916052341461182 seconds for one epoch ---
--- 0.15816903114318848 seconds for one epoch ---
--- 0.9323880672454834 seconds for one epoch ---
--- 0.15300464630126953 seconds for one epoch ---
--- 0.8796806335449219 seconds for one epoch ---
--- 0.1928577423095703 seconds for one epoch ---
--- 0.9060993194580078 seconds for one epoch ---
--- 0.17363309860229492 seconds for one epoch ---
--- 0.8301770687103271 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10337868]
 [0.        ]
 [0.        ]
 [0.11729214]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9283702 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3525478]
 [ 0.       ]
 [-0.       ]
 [-1.4255977]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.843561 ]
 [ 0.       ]]
--- 0.17920207977294922 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2455.81396484375, (1109.9686, 0.9466323, 1344.518, 0.3808814)
   validation loss 1931.547119140625, (1567.426, 0.16233402, 363.57794, 0.3808814)
decoder loss ratio: 60724.805395, decoder SINDy loss  ratio: 0.784834
--- 0.1680455207824707 seconds for one epoch ---
--- 0.15264558792114258 seconds for one epoch ---
--- 0.797560453414917 seconds for one epoch ---
--- 0.1396181583404541 seconds for one epoch ---
--- 0.8632829189300537 seconds for one epoch ---
--- 0.1865689754486084 seconds for one epoch ---
--- 0.9762485027313232 seconds for one epoch ---
--- 0.1758406162261963 seconds for one epoch ---
--- 0.8736433982849121 seconds for one epoch ---
--- 0.17344188690185547 seconds for one epoch ---
--- 0.9012978076934814 seconds for one epoch ---
--- 0.20879197120666504 seconds for one epoch ---
--- 0.8007895946502686 seconds for one epoch ---
--- 0.15989351272583008 seconds for one epoch ---
--- 0.825139045715332 seconds for one epoch ---
--- 0.16184401512145996 seconds for one epoch ---
--- 0.8432016372680664 seconds for one epoch ---
--- 0.16174101829528809 seconds for one epoch ---
--- 0.8626019954681396 seconds for one epoch ---
--- 0.2125997543334961 seconds for one epoch ---
--- 0.8199594020843506 seconds for one epoch ---
--- 0.2077350616455078 seconds for one epoch ---
--- 0.8653931617736816 seconds for one epoch ---
--- 0.17373204231262207 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10423914]
 [0.        ]
 [0.        ]
 [0.11122015]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9386637 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3573815]
 [-0.       ]
 [-0.       ]
 [-1.3947642]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.933657 ]
 [ 0.       ]]
--- 0.13767027854919434 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3690.854736328125, (1344.882, 1.6017244, 2343.9907, 0.3804346)
   validation loss 1806.6318359375, (1448.5406, 0.13097756, 357.57974, 0.3804346)
decoder loss ratio: 56118.979535, decoder SINDy loss  ratio: 0.771886
--- 0.16435503959655762 seconds for one epoch ---
--- 0.8328473567962646 seconds for one epoch ---
--- 0.19039320945739746 seconds for one epoch ---
--- 0.8201215267181396 seconds for one epoch ---
--- 0.15042853355407715 seconds for one epoch ---
--- 0.8023817539215088 seconds for one epoch ---
--- 0.19123625755310059 seconds for one epoch ---
--- 0.8279581069946289 seconds for one epoch ---
--- 0.23148274421691895 seconds for one epoch ---
--- 0.834911584854126 seconds for one epoch ---
--- 0.17413830757141113 seconds for one epoch ---
--- 0.911998987197876 seconds for one epoch ---
--- 0.195451021194458 seconds for one epoch ---
--- 0.9403228759765625 seconds for one epoch ---
--- 0.2302243709564209 seconds for one epoch ---
--- 0.8101754188537598 seconds for one epoch ---
--- 0.16428589820861816 seconds for one epoch ---
--- 0.8258123397827148 seconds for one epoch ---
--- 0.16693615913391113 seconds for one epoch ---
--- 0.8394186496734619 seconds for one epoch ---
--- 0.21351122856140137 seconds for one epoch ---
--- 0.8350787162780762 seconds for one epoch ---
--- 0.16857099533081055 seconds for one epoch ---
--- 0.8315820693969727 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10278939]
 [0.        ]
 [0.        ]
 [0.11079478]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.947213  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3494068]
 [-0.       ]
 [-0.       ]
 [-1.3926023]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.0201306]
 [-0.       ]]
--- 0.18447661399841309 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2841.70166015625, (1197.7019, 1.2903147, 1642.3287, 0.38096237)
   validation loss 1524.2593994140625, (1124.6923, 0.12342197, 399.06277, 0.38096237)
decoder loss ratio: 43572.530733, decoder SINDy loss  ratio: 0.861433
--- 0.17109918594360352 seconds for one epoch ---
--- 0.1927196979522705 seconds for one epoch ---
--- 0.8248190879821777 seconds for one epoch ---
--- 0.1811835765838623 seconds for one epoch ---
--- 0.8337523937225342 seconds for one epoch ---
--- 0.17836737632751465 seconds for one epoch ---
--- 0.8566315174102783 seconds for one epoch ---
--- 0.16932964324951172 seconds for one epoch ---
--- 0.9100897312164307 seconds for one epoch ---
--- 0.21067023277282715 seconds for one epoch ---
--- 0.8637547492980957 seconds for one epoch ---
--- 0.16316914558410645 seconds for one epoch ---
--- 0.9396450519561768 seconds for one epoch ---
--- 0.23287487030029297 seconds for one epoch ---
--- 0.8698914051055908 seconds for one epoch ---
--- 0.185746431350708 seconds for one epoch ---
--- 0.8432824611663818 seconds for one epoch ---
--- 0.37827539443969727 seconds for one epoch ---
--- 0.9834768772125244 seconds for one epoch ---
--- 0.18872809410095215 seconds for one epoch ---
--- 0.9614591598510742 seconds for one epoch ---
--- 0.17271041870117188 seconds for one epoch ---
--- 0.8925478458404541 seconds for one epoch ---
--- 0.1747140884399414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.10008713]
 [0.        ]
 [0.        ]
 [0.11163485]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9533845 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.3342208]
 [ 0.       ]
 [ 0.       ]
 [-1.3970294]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.0913267]
 [ 0.       ]]
--- 0.15408539772033691 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1966.2728271484375, (1197.6006, 0.81255, 767.478, 0.38171396)
   validation loss 964.595947265625, (676.0094, 0.1612408, 288.0436, 0.38171396)
decoder loss ratio: 26189.777737, decoder SINDy loss  ratio: 0.621783
--- 0.17291617393493652 seconds for one epoch ---
--- 0.8350787162780762 seconds for one epoch ---
--- 0.17793607711791992 seconds for one epoch ---
--- 0.8156335353851318 seconds for one epoch ---
--- 0.19759202003479004 seconds for one epoch ---
--- 0.863832950592041 seconds for one epoch ---
--- 0.18940019607543945 seconds for one epoch ---
--- 0.8509433269500732 seconds for one epoch ---
--- 0.16134142875671387 seconds for one epoch ---
--- 0.8490695953369141 seconds for one epoch ---
--- 0.190201997756958 seconds for one epoch ---
--- 0.891932487487793 seconds for one epoch ---
--- 0.18929600715637207 seconds for one epoch ---
--- 0.9089980125427246 seconds for one epoch ---
--- 0.17403411865234375 seconds for one epoch ---
--- 0.862534761428833 seconds for one epoch ---
--- 0.17496657371520996 seconds for one epoch ---
--- 0.9231722354888916 seconds for one epoch ---
--- 0.18190646171569824 seconds for one epoch ---
--- 0.9428133964538574 seconds for one epoch ---
--- 0.15328502655029297 seconds for one epoch ---
--- 0.885930061340332 seconds for one epoch ---
--- 0.19479584693908691 seconds for one epoch ---
--- 0.8534562587738037 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09669814]
 [0.        ]
 [0.        ]
 [0.11219434]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9579312 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.3146329]
 [-0.       ]
 [-0.       ]
 [-1.3999689]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.1498528]
 [-0.       ]]
--- 0.16986989974975586 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3261.365478515625, (1632.5016, 1.8394834, 1626.6433, 0.38117433)
   validation loss 1356.77734375, (993.071, 0.12486264, 363.2003, 0.38117433)
decoder loss ratio: 38473.293963, decoder SINDy loss  ratio: 0.784019
--- 0.1535172462463379 seconds for one epoch ---
--- 0.17914533615112305 seconds for one epoch ---
--- 0.8347759246826172 seconds for one epoch ---
--- 0.16983270645141602 seconds for one epoch ---
--- 0.877124547958374 seconds for one epoch ---
--- 0.17745542526245117 seconds for one epoch ---
--- 0.9244155883789062 seconds for one epoch ---
--- 0.20718121528625488 seconds for one epoch ---
--- 0.8198516368865967 seconds for one epoch ---
--- 0.16262125968933105 seconds for one epoch ---
--- 0.8810749053955078 seconds for one epoch ---
--- 0.1930835247039795 seconds for one epoch ---
--- 0.9179062843322754 seconds for one epoch ---
--- 0.19051861763000488 seconds for one epoch ---
--- 0.9334816932678223 seconds for one epoch ---
--- 0.19228601455688477 seconds for one epoch ---
--- 0.8709077835083008 seconds for one epoch ---
--- 0.20744657516479492 seconds for one epoch ---
--- 0.9541735649108887 seconds for one epoch ---
--- 0.15774917602539062 seconds for one epoch ---
--- 0.9969692230224609 seconds for one epoch ---
--- 0.1895303726196289 seconds for one epoch ---
--- 0.9203274250030518 seconds for one epoch ---
--- 0.19203495979309082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09335937]
 [0.        ]
 [0.        ]
 [0.11352364]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9611816 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2947332]
 [ 0.       ]
 [ 0.       ]
 [-1.4068414]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.195566 ]
 [-0.       ]]
--- 0.14002394676208496 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3407.9794921875, (1910.8562, 0.42823845, 1496.3137, 0.3813589)
   validation loss 1075.3555908203125, (756.3014, 0.19051898, 318.48233, 0.3813589)
decoder loss ratio: 29300.428908, decoder SINDy loss  ratio: 0.687489
--- 0.1751265525817871 seconds for one epoch ---
--- 0.9274766445159912 seconds for one epoch ---
--- 0.1885216236114502 seconds for one epoch ---
--- 0.8691954612731934 seconds for one epoch ---
--- 0.19840168952941895 seconds for one epoch ---
--- 0.8811993598937988 seconds for one epoch ---
--- 0.17617082595825195 seconds for one epoch ---
--- 0.9751846790313721 seconds for one epoch ---
--- 0.20096135139465332 seconds for one epoch ---
--- 0.9488804340362549 seconds for one epoch ---
--- 0.2025599479675293 seconds for one epoch ---
--- 0.8538141250610352 seconds for one epoch ---
--- 0.1689140796661377 seconds for one epoch ---
--- 0.9232282638549805 seconds for one epoch ---
--- 0.18923187255859375 seconds for one epoch ---
--- 0.8577628135681152 seconds for one epoch ---
--- 0.1867532730102539 seconds for one epoch ---
--- 0.8812375068664551 seconds for one epoch ---
--- 0.1715562343597412 seconds for one epoch ---
--- 0.9117281436920166 seconds for one epoch ---
--- 0.18260836601257324 seconds for one epoch ---
--- 0.9357786178588867 seconds for one epoch ---
--- 0.225297212600708 seconds for one epoch ---
--- 0.9054553508758545 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09217736]
 [0.        ]
 [0.        ]
 [0.11117549]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9663248 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.287559 ]
 [-0.       ]
 [ 0.       ]
 [-1.3947548]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-4.276132 ]
 [ 0.       ]]
--- 0.1601274013519287 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2276.3818359375, (1115.148, 0.3632753, 1160.4896, 0.38080156)
   validation loss 964.1502075195312, (608.96204, 0.16589558, 354.64148, 0.38080156)
decoder loss ratio: 23592.246484, decoder SINDy loss  ratio: 0.765544
--- 0.13614320755004883 seconds for one epoch ---
--- 0.1913316249847412 seconds for one epoch ---
--- 0.8504250049591064 seconds for one epoch ---
--- 0.18240857124328613 seconds for one epoch ---
--- 0.9776198863983154 seconds for one epoch ---
--- 0.1857292652130127 seconds for one epoch ---
--- 0.8727037906646729 seconds for one epoch ---
--- 0.19037747383117676 seconds for one epoch ---
--- 0.9648897647857666 seconds for one epoch ---
--- 0.15566110610961914 seconds for one epoch ---
--- 0.9404675960540771 seconds for one epoch ---
--- 0.19542503356933594 seconds for one epoch ---
--- 1.000624656677246 seconds for one epoch ---
--- 0.18247103691101074 seconds for one epoch ---
--- 0.9248239994049072 seconds for one epoch ---
--- 0.20497727394104004 seconds for one epoch ---
--- 0.9132769107818604 seconds for one epoch ---
--- 0.1877143383026123 seconds for one epoch ---
--- 0.9261689186096191 seconds for one epoch ---
--- 0.18777704238891602 seconds for one epoch ---
--- 0.9687316417694092 seconds for one epoch ---
--- 0.17821979522705078 seconds for one epoch ---
--- 0.9035022258758545 seconds for one epoch ---
--- 0.19948935508728027 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.09129725]
 [0.        ]
 [0.        ]
 [0.11003942]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.970924  ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.2821716]
 [ 0.       ]
 [-0.       ]
 [-1.3888427]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.359093 ]
 [-0.       ]]
--- 0.16594505310058594 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3119.884033203125, (1324.399, 1.4809963, 1793.623, 0.38113567)
   validation loss 869.0338745117188, (577.86975, 0.15400024, 290.629, 0.38113567)
decoder loss ratio: 22387.677379, decoder SINDy loss  ratio: 0.627364
--- 0.2197415828704834 seconds for one epoch ---
--- 0.8370976448059082 seconds for one epoch ---
--- 0.16088604927062988 seconds for one epoch ---
--- 0.9249465465545654 seconds for one epoch ---
--- 0.1973114013671875 seconds for one epoch ---
--- 1.0955955982208252 seconds for one epoch ---
--- 0.20822429656982422 seconds for one epoch ---
--- 0.8805410861968994 seconds for one epoch ---
--- 0.16408061981201172 seconds for one epoch ---
--- 0.8986480236053467 seconds for one epoch ---
--- 0.213789701461792 seconds for one epoch ---
--- 0.8809967041015625 seconds for one epoch ---
--- 0.18282318115234375 seconds for one epoch ---
--- 0.9400568008422852 seconds for one epoch ---
--- 0.1809988021850586 seconds for one epoch ---
--- 1.1328918933868408 seconds for one epoch ---
--- 0.2030043601989746 seconds for one epoch ---
--- 0.970442533493042 seconds for one epoch ---
--- 0.16367316246032715 seconds for one epoch ---
--- 0.9693448543548584 seconds for one epoch ---
--- 0.19436025619506836 seconds for one epoch ---
--- 0.9542033672332764 seconds for one epoch ---
--- 0.16998934745788574 seconds for one epoch ---
--- 0.9970674514770508 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08454474]
 [0.        ]
 [0.        ]
 [0.11143453]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97340703]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2389711]
 [ 0.       ]
 [ 0.       ]
 [-1.3961562]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.409414 ]
 [ 0.       ]]
--- 0.1777479648590088 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2851.85205078125, (1843.5197, 1.9995164, 1005.9537, 0.37913543)
   validation loss 1013.2557983398438, (730.5746, 0.19567649, 282.10638, 0.37913543)
decoder loss ratio: 28303.727755, decoder SINDy loss  ratio: 0.608966
--- 0.13901996612548828 seconds for one epoch ---
--- 0.17705917358398438 seconds for one epoch ---
--- 0.9627373218536377 seconds for one epoch ---
--- 0.1724081039428711 seconds for one epoch ---
--- 0.8875565528869629 seconds for one epoch ---
--- 0.14979338645935059 seconds for one epoch ---
--- 1.034501314163208 seconds for one epoch ---
--- 0.20153331756591797 seconds for one epoch ---
--- 0.9478697776794434 seconds for one epoch ---
--- 0.16878700256347656 seconds for one epoch ---
--- 0.9213502407073975 seconds for one epoch ---
--- 0.20853233337402344 seconds for one epoch ---
--- 0.9471900463104248 seconds for one epoch ---
--- 0.19379401206970215 seconds for one epoch ---
--- 0.8902661800384521 seconds for one epoch ---
--- 0.22677850723266602 seconds for one epoch ---
--- 0.8674900531768799 seconds for one epoch ---
--- 0.170684814453125 seconds for one epoch ---
--- 0.9497389793395996 seconds for one epoch ---
--- 0.19386792182922363 seconds for one epoch ---
--- 0.9188404083251953 seconds for one epoch ---
--- 0.21644282341003418 seconds for one epoch ---
--- 0.8846931457519531 seconds for one epoch ---
--- 0.17291879653930664 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08459874]
 [0.        ]
 [0.        ]
 [0.10843125]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9758191 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2393591]
 [-0.       ]
 [-0.       ]
 [-1.3803879]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.4629626]
 [ 0.       ]]
--- 0.1584911346435547 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3086.25732421875, (1759.7819, 1.091814, 1325.0046, 0.37881958)
   validation loss 888.695556640625, (555.6272, 0.20887256, 332.48065, 0.37881958)
decoder loss ratio: 21525.962233, decoder SINDy loss  ratio: 0.717706
--- 0.1839127540588379 seconds for one epoch ---
--- 0.966116189956665 seconds for one epoch ---
--- 0.16427230834960938 seconds for one epoch ---
--- 0.9412674903869629 seconds for one epoch ---
--- 0.1634209156036377 seconds for one epoch ---
--- 0.9086079597473145 seconds for one epoch ---
--- 0.1979691982269287 seconds for one epoch ---
--- 0.9670751094818115 seconds for one epoch ---
--- 0.1864161491394043 seconds for one epoch ---
--- 0.9163722991943359 seconds for one epoch ---
--- 0.15994024276733398 seconds for one epoch ---
--- 0.9413712024688721 seconds for one epoch ---
--- 0.18900227546691895 seconds for one epoch ---
--- 0.9367713928222656 seconds for one epoch ---
--- 0.20292997360229492 seconds for one epoch ---
--- 0.958446741104126 seconds for one epoch ---
--- 0.19075369834899902 seconds for one epoch ---
--- 0.9522726535797119 seconds for one epoch ---
--- 0.17593598365783691 seconds for one epoch ---
--- 1.0961356163024902 seconds for one epoch ---
--- 0.168687105178833 seconds for one epoch ---
--- 0.9782929420471191 seconds for one epoch ---
--- 0.21456170082092285 seconds for one epoch ---
--- 0.9336178302764893 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.0831586 ]
 [0.        ]
 [0.        ]
 [0.10592384]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9778773 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.2297714]
 [-0.       ]
 [-0.       ]
 [-1.366931 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5129805]
 [ 0.       ]]
--- 0.20281243324279785 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2661.906494140625, (1102.4545, 1.5711746, 1557.5033, 0.37779495)
   validation loss 787.5135498046875, (465.2344, 0.18929753, 321.712, 0.37779495)
decoder loss ratio: 18023.988552, decoder SINDy loss  ratio: 0.694461
--- 0.1323535442352295 seconds for one epoch ---
--- 0.18256759643554688 seconds for one epoch ---
--- 1.0148732662200928 seconds for one epoch ---
--- 0.19752812385559082 seconds for one epoch ---
--- 0.9742996692657471 seconds for one epoch ---
--- 0.18274497985839844 seconds for one epoch ---
--- 0.9280099868774414 seconds for one epoch ---
--- 0.1840822696685791 seconds for one epoch ---
--- 0.9490106105804443 seconds for one epoch ---
--- 0.19758272171020508 seconds for one epoch ---
--- 1.0619947910308838 seconds for one epoch ---
--- 0.17835450172424316 seconds for one epoch ---
--- 0.9201955795288086 seconds for one epoch ---
--- 0.1786208152770996 seconds for one epoch ---
--- 1.002450942993164 seconds for one epoch ---
--- 0.22440147399902344 seconds for one epoch ---
--- 0.9286093711853027 seconds for one epoch ---
--- 0.2555398941040039 seconds for one epoch ---
--- 0.9780142307281494 seconds for one epoch ---
--- 0.19751763343811035 seconds for one epoch ---
--- 0.9529361724853516 seconds for one epoch ---
--- 0.17532110214233398 seconds for one epoch ---
--- 0.9682633876800537 seconds for one epoch ---
--- 0.20084643363952637 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08016022]
 [0.        ]
 [0.        ]
 [0.10700939]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97981286]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-1.2092947]
 [ 0.       ]
 [-0.       ]
 [-1.372817 ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.564401 ]
 [-0.       ]]
--- 0.1509099006652832 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2617.104736328125, (1423.3235, 0.17365654, 1193.23, 0.37759218)
   validation loss 1810.3349609375, (1339.1619, 0.16232407, 470.63315, 0.37759218)
decoder loss ratio: 51881.455546, decoder SINDy loss  ratio: 1.015928
--- 0.19578981399536133 seconds for one epoch ---
--- 1.0078942775726318 seconds for one epoch ---
--- 0.18414807319641113 seconds for one epoch ---
--- 0.9378314018249512 seconds for one epoch ---
--- 0.16444015502929688 seconds for one epoch ---
--- 0.9764339923858643 seconds for one epoch ---
--- 0.19602727890014648 seconds for one epoch ---
--- 0.9680685997009277 seconds for one epoch ---
--- 0.19103312492370605 seconds for one epoch ---
--- 0.977200984954834 seconds for one epoch ---
--- 0.1633460521697998 seconds for one epoch ---
--- 0.9926159381866455 seconds for one epoch ---
--- 0.16464018821716309 seconds for one epoch ---
--- 1.0118629932403564 seconds for one epoch ---
--- 0.19294977188110352 seconds for one epoch ---
--- 1.0024597644805908 seconds for one epoch ---
--- 0.1815507411956787 seconds for one epoch ---
--- 0.9584684371948242 seconds for one epoch ---
--- 0.1577284336090088 seconds for one epoch ---
--- 1.081552267074585 seconds for one epoch ---
--- 0.1833360195159912 seconds for one epoch ---
--- 0.983057975769043 seconds for one epoch ---
--- 0.16629886627197266 seconds for one epoch ---
--- 1.036184549331665 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.08393077]
 [0.        ]
 [0.        ]
 [0.10560001]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9815947 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-1.2349842]
 [ 0.       ]
 [ 0.       ]
 [-1.365203 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.616288 ]
 [ 0.       ]]
--- 0.19736433029174805 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2764.326416015625, (1468.1816, 3.6171162, 1292.1495, 0.37821218)
   validation loss 875.9293823242188, (509.93027, 0.1915201, 365.42932, 0.37821218)
decoder loss ratio: 19755.583834, decoder SINDy loss  ratio: 0.788831
THRESHOLDING: 2 active coefficients
--- 0.1745753288269043 seconds for one epoch ---
--- 0.19376063346862793 seconds for one epoch ---
--- 1.0355756282806396 seconds for one epoch ---
--- 0.16255664825439453 seconds for one epoch ---
--- 0.9769363403320312 seconds for one epoch ---
--- 0.15941309928894043 seconds for one epoch ---
--- 1.0055687427520752 seconds for one epoch ---
--- 0.21022272109985352 seconds for one epoch ---
--- 1.0492634773254395 seconds for one epoch ---
--- 0.17496919631958008 seconds for one epoch ---
--- 0.9573144912719727 seconds for one epoch ---
--- 0.2194807529449463 seconds for one epoch ---
--- 0.9365394115447998 seconds for one epoch ---
--- 0.20232391357421875 seconds for one epoch ---
--- 1.0230379104614258 seconds for one epoch ---
--- 0.163069486618042 seconds for one epoch ---
--- 1.099268913269043 seconds for one epoch ---
--- 0.15697932243347168 seconds for one epoch ---
--- 1.030745506286621 seconds for one epoch ---
--- 0.17110157012939453 seconds for one epoch ---
--- 0.9275131225585938 seconds for one epoch ---
--- 0.1651442050933838 seconds for one epoch ---
--- 1.0532896518707275 seconds for one epoch ---
--- 0.1822953224182129 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09376606]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9849682 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2973982]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-4.729838 ]
 [-0.       ]]
--- 0.13548874855041504 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3434.53564453125, (1548.0889, 1.8215437, 1884.2964, 0.32894832)
   validation loss 1070.1314697265625, (782.0101, 0.2568105, 287.53555, 0.32894832)
decoder loss ratio: 30296.427772, decoder SINDy loss  ratio: 0.620686
--- 0.18595647811889648 seconds for one epoch ---
--- 0.9972941875457764 seconds for one epoch ---
--- 0.19289302825927734 seconds for one epoch ---
--- 1.1035151481628418 seconds for one epoch ---
--- 0.19169402122497559 seconds for one epoch ---
--- 0.9888691902160645 seconds for one epoch ---
--- 0.1900646686553955 seconds for one epoch ---
--- 0.9672505855560303 seconds for one epoch ---
--- 0.1771376132965088 seconds for one epoch ---
--- 1.0171637535095215 seconds for one epoch ---
--- 0.16025757789611816 seconds for one epoch ---
--- 1.0405092239379883 seconds for one epoch ---
--- 0.18809151649475098 seconds for one epoch ---
--- 0.9641921520233154 seconds for one epoch ---
--- 0.15781688690185547 seconds for one epoch ---
--- 0.922398567199707 seconds for one epoch ---
--- 0.18948721885681152 seconds for one epoch ---
--- 1.0192234516143799 seconds for one epoch ---
--- 0.20212173461914062 seconds for one epoch ---
--- 1.0174078941345215 seconds for one epoch ---
--- 0.19434595108032227 seconds for one epoch ---
--- 1.0102860927581787 seconds for one epoch ---
--- 0.17689108848571777 seconds for one epoch ---
--- 1.0641658306121826 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09153356]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98827076]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2837772]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-4.868916 ]
 [-0.       ]]
--- 0.19837331771850586 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3376.5361328125, (1710.081, 0.6627539, 1665.4631, 0.32899544)
   validation loss 992.7188110351562, (670.72565, 0.20767003, 321.45654, 0.32899544)
decoder loss ratio: 25985.075995, decoder SINDy loss  ratio: 0.693909
--- 0.156341552734375 seconds for one epoch ---
--- 0.15024542808532715 seconds for one epoch ---
--- 0.9271335601806641 seconds for one epoch ---
--- 0.16681289672851562 seconds for one epoch ---
--- 0.9583663940429688 seconds for one epoch ---
--- 0.16219449043273926 seconds for one epoch ---
--- 1.081712245941162 seconds for one epoch ---
--- 0.1835026741027832 seconds for one epoch ---
--- 0.9892454147338867 seconds for one epoch ---
--- 0.15971803665161133 seconds for one epoch ---
--- 1.015810489654541 seconds for one epoch ---
--- 0.17528867721557617 seconds for one epoch ---
--- 1.1580896377563477 seconds for one epoch ---
--- 0.162184476852417 seconds for one epoch ---
--- 1.0023503303527832 seconds for one epoch ---
--- 0.20366859436035156 seconds for one epoch ---
--- 1.087409257888794 seconds for one epoch ---
--- 0.2325434684753418 seconds for one epoch ---
--- 1.0425660610198975 seconds for one epoch ---
--- 0.15101194381713867 seconds for one epoch ---
--- 0.9522981643676758 seconds for one epoch ---
--- 0.18651843070983887 seconds for one epoch ---
--- 0.9774637222290039 seconds for one epoch ---
--- 0.17977190017700195 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08897147]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99041957]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2677753]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.982359 ]
 [ 0.       ]]
--- 0.15535807609558105 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2616.8720703125, (1012.8181, 1.079578, 1602.6447, 0.32960674)
   validation loss 1384.49560546875, (1012.7692, 0.21122514, 371.18552, 0.32960674)
decoder loss ratio: 39236.438063, decoder SINDy loss  ratio: 0.801256
--- 0.17718195915222168 seconds for one epoch ---
--- 1.0781183242797852 seconds for one epoch ---
--- 0.16030359268188477 seconds for one epoch ---
--- 1.0767548084259033 seconds for one epoch ---
--- 0.1653122901916504 seconds for one epoch ---
--- 1.0519118309020996 seconds for one epoch ---
--- 0.17408394813537598 seconds for one epoch ---
--- 0.9767138957977295 seconds for one epoch ---
--- 0.18866181373596191 seconds for one epoch ---
--- 1.0126795768737793 seconds for one epoch ---
--- 0.16591691970825195 seconds for one epoch ---
--- 0.9995756149291992 seconds for one epoch ---
--- 0.16739606857299805 seconds for one epoch ---
--- 1.003082513809204 seconds for one epoch ---
--- 0.18096184730529785 seconds for one epoch ---
--- 1.0266327857971191 seconds for one epoch ---
--- 0.16648578643798828 seconds for one epoch ---
--- 1.0707101821899414 seconds for one epoch ---
--- 0.18238162994384766 seconds for one epoch ---
--- 1.0615549087524414 seconds for one epoch ---
--- 0.1855611801147461 seconds for one epoch ---
--- 1.0457918643951416 seconds for one epoch ---
--- 0.18629717826843262 seconds for one epoch ---
--- 1.004446268081665 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08778124]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99227715]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2602066]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.1032567]
 [-0.       ]]
--- 0.15081572532653809 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4562.80810546875, (1574.0953, 4.8472586, 2983.5356, 0.32979986)
   validation loss 1314.7537841796875, (926.67017, 0.20876063, 387.54507, 0.32979986)
decoder loss ratio: 35900.811002, decoder SINDy loss  ratio: 0.836571
--- 0.15150141716003418 seconds for one epoch ---
--- 0.169968843460083 seconds for one epoch ---
--- 1.0824213027954102 seconds for one epoch ---
--- 0.1977694034576416 seconds for one epoch ---
--- 1.016000747680664 seconds for one epoch ---
--- 0.16707801818847656 seconds for one epoch ---
--- 1.0605309009552002 seconds for one epoch ---
--- 0.18726634979248047 seconds for one epoch ---
--- 1.044790506362915 seconds for one epoch ---
--- 0.15791654586791992 seconds for one epoch ---
--- 0.9911391735076904 seconds for one epoch ---
--- 0.16065382957458496 seconds for one epoch ---
--- 1.0962343215942383 seconds for one epoch ---
--- 0.1764841079711914 seconds for one epoch ---
--- 0.983609676361084 seconds for one epoch ---
--- 0.16037368774414062 seconds for one epoch ---
--- 1.0765812397003174 seconds for one epoch ---
--- 0.20242524147033691 seconds for one epoch ---
--- 1.094299077987671 seconds for one epoch ---
--- 0.16359734535217285 seconds for one epoch ---
--- 1.0490179061889648 seconds for one epoch ---
--- 0.17079448699951172 seconds for one epoch ---
--- 1.0913281440734863 seconds for one epoch ---
--- 0.15192055702209473 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08830686]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.993587  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2635752]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.2076325]
 [ 0.       ]]
--- 0.15408062934875488 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3503.405517578125, (2297.1602, 0.73378444, 1205.1804, 0.33094707)
   validation loss 1302.8773193359375, (955.5055, 0.20896836, 346.83188, 0.33094707)
decoder loss ratio: 37017.941636, decoder SINDy loss  ratio: 0.748685
--- 0.17266154289245605 seconds for one epoch ---
--- 1.026036024093628 seconds for one epoch ---
--- 0.1603095531463623 seconds for one epoch ---
--- 1.0686962604522705 seconds for one epoch ---
--- 0.1624007225036621 seconds for one epoch ---
--- 1.0731618404388428 seconds for one epoch ---
--- 0.19509029388427734 seconds for one epoch ---
--- 1.073986530303955 seconds for one epoch ---
--- 0.17537283897399902 seconds for one epoch ---
--- 1.010685920715332 seconds for one epoch ---
--- 0.18560528755187988 seconds for one epoch ---
--- 0.9936490058898926 seconds for one epoch ---
--- 0.16579842567443848 seconds for one epoch ---
--- 1.1223928928375244 seconds for one epoch ---
--- 0.17293524742126465 seconds for one epoch ---
--- 1.0201737880706787 seconds for one epoch ---
--- 0.18147516250610352 seconds for one epoch ---
--- 0.9784057140350342 seconds for one epoch ---
--- 0.1648714542388916 seconds for one epoch ---
--- 1.0843489170074463 seconds for one epoch ---
--- 0.19017481803894043 seconds for one epoch ---
--- 1.0261993408203125 seconds for one epoch ---
--- 0.18260955810546875 seconds for one epoch ---
--- 1.1448583602905273 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08854784]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.994904  ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2651173]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.3368015]
 [ 0.       ]]
--- 0.1887204647064209 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2027.0291748046875, (1119.2064, 1.3442849, 906.14655, 0.3319015)
   validation loss 936.5884399414062, (622.07056, 0.21660736, 313.96936, 0.3319015)
decoder loss ratio: 24100.093326, decoder SINDy loss  ratio: 0.677747
--- 0.1690080165863037 seconds for one epoch ---
--- 0.1958482265472412 seconds for one epoch ---
--- 1.0424776077270508 seconds for one epoch ---
--- 0.17924070358276367 seconds for one epoch ---
--- 1.1018614768981934 seconds for one epoch ---
--- 0.16533112525939941 seconds for one epoch ---
--- 1.0690834522247314 seconds for one epoch ---
--- 0.15279245376586914 seconds for one epoch ---
--- 1.1026792526245117 seconds for one epoch ---
--- 0.17595505714416504 seconds for one epoch ---
--- 1.0555460453033447 seconds for one epoch ---
--- 0.18230509757995605 seconds for one epoch ---
--- 1.0406618118286133 seconds for one epoch ---
--- 0.207566499710083 seconds for one epoch ---
--- 1.0483238697052002 seconds for one epoch ---
--- 0.15952467918395996 seconds for one epoch ---
--- 1.1530344486236572 seconds for one epoch ---
--- 0.16702914237976074 seconds for one epoch ---
--- 1.0143945217132568 seconds for one epoch ---
--- 0.14980530738830566 seconds for one epoch ---
--- 1.0583338737487793 seconds for one epoch ---
--- 0.17720389366149902 seconds for one epoch ---
--- 1.0612199306488037 seconds for one epoch ---
--- 0.16866421699523926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08995588]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99586916]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2740127]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-5.454935 ]
 [ 0.       ]]
--- 0.1351456642150879 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6688.89990234375, (1628.3346, 4.3858824, 5055.846, 0.3333581)
   validation loss 780.899658203125, (499.2869, 0.23157626, 281.04785, 0.3333581)
decoder loss ratio: 19343.241142, decoder SINDy loss  ratio: 0.606681
--- 0.16804957389831543 seconds for one epoch ---
--- 1.0780656337738037 seconds for one epoch ---
--- 0.1694474220275879 seconds for one epoch ---
--- 1.027113676071167 seconds for one epoch ---
--- 0.167616605758667 seconds for one epoch ---
--- 1.049037218093872 seconds for one epoch ---
--- 0.18965816497802734 seconds for one epoch ---
--- 1.0054428577423096 seconds for one epoch ---
--- 0.16154861450195312 seconds for one epoch ---
--- 1.1279025077819824 seconds for one epoch ---
--- 0.19394779205322266 seconds for one epoch ---
--- 1.1806156635284424 seconds for one epoch ---
--- 0.1650381088256836 seconds for one epoch ---
--- 1.2069714069366455 seconds for one epoch ---
--- 0.16565990447998047 seconds for one epoch ---
--- 1.0325140953063965 seconds for one epoch ---
--- 0.16727185249328613 seconds for one epoch ---
--- 1.0362815856933594 seconds for one epoch ---
--- 0.16557526588439941 seconds for one epoch ---
--- 1.1086246967315674 seconds for one epoch ---
--- 0.17523574829101562 seconds for one epoch ---
--- 1.0833182334899902 seconds for one epoch ---
--- 0.1774156093597412 seconds for one epoch ---
--- 1.0469489097595215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08746011]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99652195]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2581787]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.55191  ]
 [-0.       ]]
--- 0.1930549144744873 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4765.43994140625, (2406.5752, 1.846148, 2356.685, 0.33338603)
   validation loss 1115.13330078125, (810.4756, 0.23047774, 304.0939, 0.33338603)
decoder loss ratio: 31399.231247, decoder SINDy loss  ratio: 0.656429
--- 0.1399397850036621 seconds for one epoch ---
--- 0.20218849182128906 seconds for one epoch ---
--- 1.149465560913086 seconds for one epoch ---
--- 0.1594102382659912 seconds for one epoch ---
--- 1.1135714054107666 seconds for one epoch ---
--- 0.16962528228759766 seconds for one epoch ---
--- 1.0705859661102295 seconds for one epoch ---
--- 0.22713088989257812 seconds for one epoch ---
--- 1.0488929748535156 seconds for one epoch ---
--- 0.19347882270812988 seconds for one epoch ---
--- 1.0718064308166504 seconds for one epoch ---
--- 0.3905777931213379 seconds for one epoch ---
--- 1.1474213600158691 seconds for one epoch ---
--- 0.19924497604370117 seconds for one epoch ---
--- 1.0885117053985596 seconds for one epoch ---
--- 0.21103143692016602 seconds for one epoch ---
--- 1.0896801948547363 seconds for one epoch ---
--- 0.21133065223693848 seconds for one epoch ---
--- 1.072444200515747 seconds for one epoch ---
--- 0.22534465789794922 seconds for one epoch ---
--- 1.1851611137390137 seconds for one epoch ---
--- 0.18491792678833008 seconds for one epoch ---
--- 1.0680370330810547 seconds for one epoch ---
--- 0.16136908531188965 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08560628]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9971432 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2461557]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.6631308]
 [ 0.       ]]
--- 0.14038300514221191 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2190.628173828125, (1248.5928, 0.12742276, 941.5739, 0.33390749)
   validation loss 1511.3603515625, (1182.1626, 0.24426267, 328.61963, 0.33390749)
decoder loss ratio: 45799.031358, decoder SINDy loss  ratio: 0.709372
--- 0.16201210021972656 seconds for one epoch ---
--- 1.1703407764434814 seconds for one epoch ---
--- 0.15755319595336914 seconds for one epoch ---
--- 1.0727424621582031 seconds for one epoch ---
--- 0.16326165199279785 seconds for one epoch ---
--- 1.0520732402801514 seconds for one epoch ---
--- 0.17183232307434082 seconds for one epoch ---
--- 1.07297945022583 seconds for one epoch ---
--- 0.17380023002624512 seconds for one epoch ---
--- 1.0590543746948242 seconds for one epoch ---
--- 0.16787075996398926 seconds for one epoch ---
--- 1.2693171501159668 seconds for one epoch ---
--- 0.17449569702148438 seconds for one epoch ---
--- 1.0827796459197998 seconds for one epoch ---
--- 0.18451881408691406 seconds for one epoch ---
--- 1.091937780380249 seconds for one epoch ---
--- 0.1768813133239746 seconds for one epoch ---
--- 1.1348261833190918 seconds for one epoch ---
--- 0.15342259407043457 seconds for one epoch ---
--- 1.2129154205322266 seconds for one epoch ---
--- 0.1790783405303955 seconds for one epoch ---
--- 1.136855125427246 seconds for one epoch ---
--- 0.18055939674377441 seconds for one epoch ---
--- 1.114478349685669 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08438464]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99747765]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2381059]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.7335815]
 [-0.       ]]
--- 0.20356130599975586 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2783.504150390625, (1290.0688, 0.07483282, 1493.0267, 0.333779)
   validation loss 1091.832275390625, (732.7019, 0.24672544, 358.5499, 0.333779)
decoder loss ratio: 28386.143799, decoder SINDy loss  ratio: 0.773980
--- 0.15584826469421387 seconds for one epoch ---
--- 0.1574995517730713 seconds for one epoch ---
--- 1.0927348136901855 seconds for one epoch ---
--- 0.18997812271118164 seconds for one epoch ---
--- 1.0854427814483643 seconds for one epoch ---
--- 0.1794109344482422 seconds for one epoch ---
--- 1.1264419555664062 seconds for one epoch ---
--- 0.168198823928833 seconds for one epoch ---
--- 1.1648967266082764 seconds for one epoch ---
--- 0.18325209617614746 seconds for one epoch ---
--- 1.1667189598083496 seconds for one epoch ---
--- 0.1732487678527832 seconds for one epoch ---
--- 1.0878973007202148 seconds for one epoch ---
--- 0.19798898696899414 seconds for one epoch ---
--- 1.1377675533294678 seconds for one epoch ---
--- 0.1836857795715332 seconds for one epoch ---
--- 1.1455693244934082 seconds for one epoch ---
--- 0.1706986427307129 seconds for one epoch ---
--- 1.1009910106658936 seconds for one epoch ---
--- 0.16168904304504395 seconds for one epoch ---
--- 1.0897574424743652 seconds for one epoch ---
--- 0.18103289604187012 seconds for one epoch ---
--- 1.2458922863006592 seconds for one epoch ---
--- 0.1671140193939209 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08442463]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9978261 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2383764]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-5.817897 ]
 [-0.       ]]
--- 0.2424173355102539 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2939.8603515625, (968.49384, 0.16525769, 1970.867, 0.33430946)
   validation loss 877.617919921875, (577.41473, 0.28936064, 299.57953, 0.33430946)
decoder loss ratio: 22370.049227, decoder SINDy loss  ratio: 0.646685
--- 0.20125269889831543 seconds for one epoch ---
--- 1.0985291004180908 seconds for one epoch ---
--- 0.17989730834960938 seconds for one epoch ---
--- 1.0742321014404297 seconds for one epoch ---
--- 0.17381858825683594 seconds for one epoch ---
--- 1.1367390155792236 seconds for one epoch ---
--- 0.19851183891296387 seconds for one epoch ---
--- 1.148716688156128 seconds for one epoch ---
--- 0.18406391143798828 seconds for one epoch ---
--- 1.1532557010650635 seconds for one epoch ---
--- 0.21142148971557617 seconds for one epoch ---
--- 1.1277639865875244 seconds for one epoch ---
--- 0.17621755599975586 seconds for one epoch ---
--- 1.089552879333496 seconds for one epoch ---
--- 0.161057710647583 seconds for one epoch ---
--- 1.1422274112701416 seconds for one epoch ---
--- 0.17292499542236328 seconds for one epoch ---
--- 1.150479793548584 seconds for one epoch ---
--- 0.1758711338043213 seconds for one epoch ---
--- 1.1410982608795166 seconds for one epoch ---
--- 0.16411876678466797 seconds for one epoch ---
--- 1.1343574523925781 seconds for one epoch ---
--- 0.16793251037597656 seconds for one epoch ---
--- 1.1328215599060059 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0832269 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99815416]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2303847]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.910664 ]
 [ 0.       ]]
--- 0.19680261611938477 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2237.556396484375, (831.53723, 0.4332059, 1405.2511, 0.33478)
   validation loss 1088.3101806640625, (757.6134, 0.271443, 330.09045, 0.33478)
decoder loss ratio: 29351.258519, decoder SINDy loss  ratio: 0.712547
--- 0.15680360794067383 seconds for one epoch ---
--- 0.16765332221984863 seconds for one epoch ---
--- 1.0777366161346436 seconds for one epoch ---
--- 0.16382288932800293 seconds for one epoch ---
--- 1.1872596740722656 seconds for one epoch ---
--- 0.21027278900146484 seconds for one epoch ---
--- 1.1059010028839111 seconds for one epoch ---
--- 0.1904745101928711 seconds for one epoch ---
--- 1.1656136512756348 seconds for one epoch ---
--- 0.16554617881774902 seconds for one epoch ---
--- 1.3753268718719482 seconds for one epoch ---
--- 0.17311716079711914 seconds for one epoch ---
--- 1.207265853881836 seconds for one epoch ---
--- 0.19737839698791504 seconds for one epoch ---
--- 1.1864831447601318 seconds for one epoch ---
--- 0.14876151084899902 seconds for one epoch ---
--- 1.180412769317627 seconds for one epoch ---
--- 0.1977982521057129 seconds for one epoch ---
--- 1.1118109226226807 seconds for one epoch ---
--- 0.18115448951721191 seconds for one epoch ---
--- 1.1323485374450684 seconds for one epoch ---
--- 0.1561753749847412 seconds for one epoch ---
--- 1.1629664897918701 seconds for one epoch ---
--- 0.16617059707641602 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08559208]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9984262 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2460805]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.001356 ]
 [-0.       ]]
--- 0.18947410583496094 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4340.189453125, (1204.8423, 0.86855245, 3134.1423, 0.33647472)
   validation loss 1450.71435546875, (1144.7275, 0.3616719, 305.28864, 0.33647472)
decoder loss ratio: 44348.732198, decoder SINDy loss  ratio: 0.659008
--- 0.17804789543151855 seconds for one epoch ---
--- 1.1871767044067383 seconds for one epoch ---
--- 0.18449163436889648 seconds for one epoch ---
--- 1.2158663272857666 seconds for one epoch ---
--- 0.16477298736572266 seconds for one epoch ---
--- 1.199012279510498 seconds for one epoch ---
--- 0.19029593467712402 seconds for one epoch ---
--- 1.159299373626709 seconds for one epoch ---
--- 0.1756117343902588 seconds for one epoch ---
--- 1.2524631023406982 seconds for one epoch ---
--- 0.18673467636108398 seconds for one epoch ---
--- 1.2074599266052246 seconds for one epoch ---
--- 0.17494726181030273 seconds for one epoch ---
--- 1.1108098030090332 seconds for one epoch ---
--- 0.17710018157958984 seconds for one epoch ---
--- 1.1382875442504883 seconds for one epoch ---
--- 0.17899274826049805 seconds for one epoch ---
--- 1.1875925064086914 seconds for one epoch ---
--- 0.18361186981201172 seconds for one epoch ---
--- 1.1435446739196777 seconds for one epoch ---
--- 0.184828519821167 seconds for one epoch ---
--- 1.1368355751037598 seconds for one epoch ---
--- 0.15494060516357422 seconds for one epoch ---
--- 1.1464669704437256 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08354486]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9986291 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2325246]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.080117 ]
 [ 0.       ]]
--- 0.2030315399169922 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3219.106201171875, (1203.0134, 1.5040895, 2014.2523, 0.33627054)
   validation loss 1032.67919921875, (734.8795, 0.33970404, 297.12366, 0.33627054)
decoder loss ratio: 28470.508280, decoder SINDy loss  ratio: 0.641383
--- 0.15480256080627441 seconds for one epoch ---
--- 0.18148469924926758 seconds for one epoch ---
--- 1.1752798557281494 seconds for one epoch ---
--- 0.1653144359588623 seconds for one epoch ---
--- 1.1478402614593506 seconds for one epoch ---
--- 0.173203706741333 seconds for one epoch ---
--- 1.2659146785736084 seconds for one epoch ---
--- 0.19334101676940918 seconds for one epoch ---
--- 1.2375407218933105 seconds for one epoch ---
--- 0.1738147735595703 seconds for one epoch ---
--- 1.1280372142791748 seconds for one epoch ---
--- 0.16968059539794922 seconds for one epoch ---
--- 1.186772108078003 seconds for one epoch ---
--- 0.1793839931488037 seconds for one epoch ---
--- 1.1620781421661377 seconds for one epoch ---
--- 0.17072057723999023 seconds for one epoch ---
--- 1.208789348602295 seconds for one epoch ---
--- 0.18227028846740723 seconds for one epoch ---
--- 1.1727581024169922 seconds for one epoch ---
--- 0.17398858070373535 seconds for one epoch ---
--- 1.2206201553344727 seconds for one epoch ---
--- 0.19678950309753418 seconds for one epoch ---
--- 1.122436761856079 seconds for one epoch ---
--- 0.16674399375915527 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08173712]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9988179 ]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-1.220304]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.164302]
 [ 0.      ]]
--- 0.19676780700683594 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5668.49072265625, (1635.0686, 1.0147457, 4032.0708, 0.33651543)
   validation loss 839.7982788085938, (523.72235, 0.32915035, 315.4103, 0.33651543)
decoder loss ratio: 20289.913103, decoder SINDy loss  ratio: 0.680858
--- 0.17244482040405273 seconds for one epoch ---
--- 1.1484253406524658 seconds for one epoch ---
--- 0.2036731243133545 seconds for one epoch ---
--- 1.1936204433441162 seconds for one epoch ---
--- 0.17777347564697266 seconds for one epoch ---
--- 1.2601392269134521 seconds for one epoch ---
--- 0.21824359893798828 seconds for one epoch ---
--- 1.2380166053771973 seconds for one epoch ---
--- 0.19658827781677246 seconds for one epoch ---
--- 1.1303560733795166 seconds for one epoch ---
--- 0.17188048362731934 seconds for one epoch ---
--- 1.1782841682434082 seconds for one epoch ---
--- 0.17572331428527832 seconds for one epoch ---
--- 1.1290664672851562 seconds for one epoch ---
--- 0.18249249458312988 seconds for one epoch ---
--- 1.2063465118408203 seconds for one epoch ---
--- 0.15207576751708984 seconds for one epoch ---
--- 1.241851806640625 seconds for one epoch ---
--- 0.1642453670501709 seconds for one epoch ---
--- 1.1691629886627197 seconds for one epoch ---
--- 0.1572561264038086 seconds for one epoch ---
--- 1.1800878047943115 seconds for one epoch ---
--- 0.18046212196350098 seconds for one epoch ---
--- 1.1341612339019775 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08238892]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9989739 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2247419]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.2455406]
 [ 0.       ]]
--- 0.20700907707214355 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3666.998046875, (1171.5857, 0.8853846, 2494.1902, 0.33696017)
   validation loss 1034.0369873046875, (726.37756, 0.36167324, 306.96082, 0.33696017)
decoder loss ratio: 28141.127856, decoder SINDy loss  ratio: 0.662618
--- 0.15856337547302246 seconds for one epoch ---
--- 0.1716928482055664 seconds for one epoch ---
--- 1.1877212524414062 seconds for one epoch ---
--- 0.16459178924560547 seconds for one epoch ---
--- 1.2104642391204834 seconds for one epoch ---
--- 0.20585989952087402 seconds for one epoch ---
--- 1.1447803974151611 seconds for one epoch ---
--- 0.17262697219848633 seconds for one epoch ---
--- 1.235182523727417 seconds for one epoch ---
--- 0.19663667678833008 seconds for one epoch ---
--- 1.2289013862609863 seconds for one epoch ---
--- 0.15519428253173828 seconds for one epoch ---
--- 1.3155100345611572 seconds for one epoch ---
--- 0.1614687442779541 seconds for one epoch ---
--- 1.1651337146759033 seconds for one epoch ---
--- 0.1948716640472412 seconds for one epoch ---
--- 1.2624437808990479 seconds for one epoch ---
--- 0.19561123847961426 seconds for one epoch ---
--- 1.1710550785064697 seconds for one epoch ---
--- 0.15873169898986816 seconds for one epoch ---
--- 1.2105870246887207 seconds for one epoch ---
--- 0.17216205596923828 seconds for one epoch ---
--- 1.2760694026947021 seconds for one epoch ---
--- 0.17765522003173828 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08187072]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9991129 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-1.2212226]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.328956 ]
 [-0.       ]]
--- 0.16013526916503906 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5474.416015625, (1284.8842, 2.588913, 4186.605, 0.33767262)
   validation loss 1263.877685546875, (907.1398, 0.3674538, 356.03284, 0.33767262)
decoder loss ratio: 35144.169573, decoder SINDy loss  ratio: 0.768547
--- 0.19236302375793457 seconds for one epoch ---
--- 1.1349403858184814 seconds for one epoch ---
--- 0.18792152404785156 seconds for one epoch ---
--- 1.2348320484161377 seconds for one epoch ---
--- 0.15938401222229004 seconds for one epoch ---
--- 1.1871273517608643 seconds for one epoch ---
--- 0.17693543434143066 seconds for one epoch ---
--- 1.205610990524292 seconds for one epoch ---
--- 0.15590834617614746 seconds for one epoch ---
--- 1.2177860736846924 seconds for one epoch ---
--- 0.16111302375793457 seconds for one epoch ---
--- 1.2001733779907227 seconds for one epoch ---
--- 0.16085052490234375 seconds for one epoch ---
--- 1.2385714054107666 seconds for one epoch ---
--- 0.18867826461791992 seconds for one epoch ---
--- 1.2646183967590332 seconds for one epoch ---
--- 0.17733430862426758 seconds for one epoch ---
--- 1.2335875034332275 seconds for one epoch ---
--- 0.16990065574645996 seconds for one epoch ---
--- 1.1388909816741943 seconds for one epoch ---
--- 0.1619877815246582 seconds for one epoch ---
--- 1.1884472370147705 seconds for one epoch ---
--- 0.16826415061950684 seconds for one epoch ---
--- 1.3375542163848877 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08256522]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9992281 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2259411]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.4083233]
 [ 0.       ]]
--- 0.18422770500183105 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2496.017333984375, (834.2249, 0.5160505, 1660.938, 0.33841774)
   validation loss 732.9655151367188, (466.2937, 0.38820693, 265.9452, 0.33841774)
decoder loss ratio: 18065.027505, decoder SINDy loss  ratio: 0.574080
--- 0.15170693397521973 seconds for one epoch ---
--- 0.21677255630493164 seconds for one epoch ---
--- 1.3965325355529785 seconds for one epoch ---
--- 0.16581010818481445 seconds for one epoch ---
--- 1.214918613433838 seconds for one epoch ---
--- 0.18767571449279785 seconds for one epoch ---
--- 1.1855604648590088 seconds for one epoch ---
--- 0.18267416954040527 seconds for one epoch ---
--- 1.2872462272644043 seconds for one epoch ---
--- 0.17740964889526367 seconds for one epoch ---
--- 1.1959640979766846 seconds for one epoch ---
--- 0.16531729698181152 seconds for one epoch ---
--- 1.2084705829620361 seconds for one epoch ---
--- 0.18222332000732422 seconds for one epoch ---
--- 1.2611486911773682 seconds for one epoch ---
--- 0.20969319343566895 seconds for one epoch ---
--- 1.22434401512146 seconds for one epoch ---
--- 0.1984860897064209 seconds for one epoch ---
--- 1.1550333499908447 seconds for one epoch ---
--- 0.19732260704040527 seconds for one epoch ---
--- 1.1866176128387451 seconds for one epoch ---
--- 0.19480490684509277 seconds for one epoch ---
--- 1.203596591949463 seconds for one epoch ---
--- 0.17285704612731934 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08192374]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99931186]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-1.2215877]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-6.4750066]
 [-0.       ]]
--- 0.17060375213623047 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5612.53564453125, (1917.1235, 1.0498286, 3694.0242, 0.33815122)
   validation loss 1216.962890625, (893.7404, 0.38068914, 322.5036, 0.33815122)
decoder loss ratio: 34625.055375, decoder SINDy loss  ratio: 0.696169
--- 0.22320938110351562 seconds for one epoch ---
--- 1.2687134742736816 seconds for one epoch ---
--- 0.17588090896606445 seconds for one epoch ---
--- 1.220336675643921 seconds for one epoch ---
--- 0.19238805770874023 seconds for one epoch ---
--- 1.48358154296875 seconds for one epoch ---
--- 0.18560314178466797 seconds for one epoch ---
--- 1.224670648574829 seconds for one epoch ---
--- 0.16083455085754395 seconds for one epoch ---
--- 1.2432513236999512 seconds for one epoch ---
--- 0.19872784614562988 seconds for one epoch ---
--- 1.2446138858795166 seconds for one epoch ---
--- 0.16340851783752441 seconds for one epoch ---
--- 1.22568678855896 seconds for one epoch ---
--- 0.1958470344543457 seconds for one epoch ---
--- 1.3346953392028809 seconds for one epoch ---
--- 0.2036294937133789 seconds for one epoch ---
--- 1.1965272426605225 seconds for one epoch ---
--- 0.1882002353668213 seconds for one epoch ---
--- 1.2058022022247314 seconds for one epoch ---
--- 0.18129611015319824 seconds for one epoch ---
--- 1.279022216796875 seconds for one epoch ---
--- 0.17467880249023438 seconds for one epoch ---
--- 1.3136932849884033 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07954117]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99936104]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2051365]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-6.5171156]
 [-0.       ]]
--- 0.16271138191223145 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2730.670166015625, (1203.2396, 0.9571809, 1526.1364, 0.3371447)
   validation loss 971.3123779296875, (694.7192, 0.40030822, 275.85574, 0.3371447)
decoder loss ratio: 26914.627012, decoder SINDy loss  ratio: 0.595473
THRESHOLDING: 1 active coefficients
--- 1.157395362854004 seconds for one epoch ---
--- 0.16186904907226562 seconds for one epoch ---
--- 1.4254393577575684 seconds for one epoch ---
--- 0.16939663887023926 seconds for one epoch ---
--- 1.237792730331421 seconds for one epoch ---
--- 0.2069227695465088 seconds for one epoch ---
--- 1.2889161109924316 seconds for one epoch ---
--- 0.19557499885559082 seconds for one epoch ---
--- 1.2791848182678223 seconds for one epoch ---
--- 0.18236613273620605 seconds for one epoch ---
--- 1.336698293685913 seconds for one epoch ---
--- 0.15965008735656738 seconds for one epoch ---
--- 1.2709946632385254 seconds for one epoch ---
--- 0.18861103057861328 seconds for one epoch ---
--- 1.3159222602844238 seconds for one epoch ---
--- 0.1970076560974121 seconds for one epoch ---
--- 1.198155403137207 seconds for one epoch ---
--- 0.17190957069396973 seconds for one epoch ---
--- 1.2296538352966309 seconds for one epoch ---
--- 0.1553027629852295 seconds for one epoch ---
--- 1.2909965515136719 seconds for one epoch ---
--- 0.197282075881958 seconds for one epoch ---
--- 1.3601689338684082 seconds for one epoch ---
--- 0.1863250732421875 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9996407]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.8511825]
 [ 0.       ]]
--- 0.1506967544555664 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3301.8203125, (1240.0634, 1.9625945, 2059.5117, 0.28269824)
   validation loss 1091.8565673828125, (763.98804, 0.3997976, 327.18607, 0.28269824)
decoder loss ratio: 29598.222899, decoder SINDy loss  ratio: 0.706277
--- 0.18871045112609863 seconds for one epoch ---
--- 1.3662705421447754 seconds for one epoch ---
--- 0.16746139526367188 seconds for one epoch ---
--- 1.306246042251587 seconds for one epoch ---
--- 0.16786670684814453 seconds for one epoch ---
--- 1.2477915287017822 seconds for one epoch ---
--- 0.1869816780090332 seconds for one epoch ---
--- 1.2476081848144531 seconds for one epoch ---
--- 0.16440939903259277 seconds for one epoch ---
--- 1.2391467094421387 seconds for one epoch ---
--- 0.18845582008361816 seconds for one epoch ---
--- 1.2704918384552002 seconds for one epoch ---
--- 0.17032527923583984 seconds for one epoch ---
--- 1.3454031944274902 seconds for one epoch ---
--- 0.19780778884887695 seconds for one epoch ---
--- 1.2614810466766357 seconds for one epoch ---
--- 0.2141120433807373 seconds for one epoch ---
--- 1.3275127410888672 seconds for one epoch ---
--- 0.17395710945129395 seconds for one epoch ---
--- 1.2460129261016846 seconds for one epoch ---
--- 0.15793180465698242 seconds for one epoch ---
--- 1.3195099830627441 seconds for one epoch ---
--- 0.18905878067016602 seconds for one epoch ---
--- 1.2411444187164307 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9997792]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-7.135207]
 [-0.      ]]
--- 0.16719341278076172 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2549.472412109375, (1128.0355, 0.25700894, 1420.8943, 0.28557625)
   validation loss 1118.1556396484375, (805.6353, 0.35322696, 311.88156, 0.28557625)
decoder loss ratio: 31211.710745, decoder SINDy loss  ratio: 0.673240
--- 0.14818739891052246 seconds for one epoch ---
--- 0.160963773727417 seconds for one epoch ---
--- 1.2893016338348389 seconds for one epoch ---
--- 0.1515638828277588 seconds for one epoch ---
--- 1.245119333267212 seconds for one epoch ---
--- 0.17152190208435059 seconds for one epoch ---
--- 1.2912611961364746 seconds for one epoch ---
--- 0.16462087631225586 seconds for one epoch ---
--- 1.2153818607330322 seconds for one epoch ---
--- 0.1932392120361328 seconds for one epoch ---
--- 1.4016087055206299 seconds for one epoch ---
--- 0.17924880981445312 seconds for one epoch ---
--- 1.332362174987793 seconds for one epoch ---
--- 0.20380926132202148 seconds for one epoch ---
--- 1.3575794696807861 seconds for one epoch ---
--- 0.25115418434143066 seconds for one epoch ---
--- 1.221123218536377 seconds for one epoch ---
--- 0.1679527759552002 seconds for one epoch ---
--- 1.3699560165405273 seconds for one epoch ---
--- 0.19324254989624023 seconds for one epoch ---
--- 1.3182482719421387 seconds for one epoch ---
--- 0.17203330993652344 seconds for one epoch ---
--- 1.2832322120666504 seconds for one epoch ---
--- 0.15912079811096191 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9998608]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-7.4115877]
 [ 0.       ]]
--- 0.1406848430633545 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3293.06103515625, (1433.2423, 0.56257963, 1858.9675, 0.28850704)
   validation loss 1440.3311767578125, (1108.6476, 0.3701741, 331.0251, 0.28850704)
decoder loss ratio: 42950.932063, decoder SINDy loss  ratio: 0.714564
--- 0.20224714279174805 seconds for one epoch ---
--- 1.3026087284088135 seconds for one epoch ---
--- 0.16301631927490234 seconds for one epoch ---
--- 1.245643138885498 seconds for one epoch ---
--- 0.17846989631652832 seconds for one epoch ---
--- 1.2637717723846436 seconds for one epoch ---
--- 0.1928844451904297 seconds for one epoch ---
--- 1.321483850479126 seconds for one epoch ---
--- 0.15395832061767578 seconds for one epoch ---
--- 1.2609071731567383 seconds for one epoch ---
--- 0.16897916793823242 seconds for one epoch ---
--- 1.3889963626861572 seconds for one epoch ---
--- 0.17473864555358887 seconds for one epoch ---
--- 1.2504074573516846 seconds for one epoch ---
--- 0.1683359146118164 seconds for one epoch ---
--- 1.3477227687835693 seconds for one epoch ---
--- 0.18304443359375 seconds for one epoch ---
--- 1.2862892150878906 seconds for one epoch ---
--- 0.16865181922912598 seconds for one epoch ---
--- 1.2950794696807861 seconds for one epoch ---
--- 0.19154715538024902 seconds for one epoch ---
--- 1.3051111698150635 seconds for one epoch ---
--- 0.16592812538146973 seconds for one epoch ---
--- 1.361328363418579 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99990815]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.6619015]
 [ 0.       ]]
--- 0.16174602508544922 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4045.696044921875, (1057.6672, 1.7862757, 2985.9514, 0.29129192)
   validation loss 897.3709106445312, (593.23645, 0.43798724, 303.40518, 0.29129192)
decoder loss ratio: 22983.009984, decoder SINDy loss  ratio: 0.654943
--- 0.15692830085754395 seconds for one epoch ---
--- 0.16652321815490723 seconds for one epoch ---
--- 1.2672874927520752 seconds for one epoch ---
--- 0.16672325134277344 seconds for one epoch ---
--- 1.3310573101043701 seconds for one epoch ---
--- 0.17650485038757324 seconds for one epoch ---
--- 1.2670800685882568 seconds for one epoch ---
--- 0.16852045059204102 seconds for one epoch ---
--- 1.338921308517456 seconds for one epoch ---
--- 0.15900754928588867 seconds for one epoch ---
--- 1.2908921241760254 seconds for one epoch ---
--- 0.15627145767211914 seconds for one epoch ---
--- 1.4190762042999268 seconds for one epoch ---
--- 0.18479490280151367 seconds for one epoch ---
--- 1.3593683242797852 seconds for one epoch ---
--- 0.17296099662780762 seconds for one epoch ---
--- 1.3591811656951904 seconds for one epoch ---
--- 0.1934187412261963 seconds for one epoch ---
--- 1.3228259086608887 seconds for one epoch ---
--- 0.17325949668884277 seconds for one epoch ---
--- 1.3630623817443848 seconds for one epoch ---
--- 0.17874932289123535 seconds for one epoch ---
--- 1.2795515060424805 seconds for one epoch ---
--- 0.19121336936950684 seconds for one epoch ---
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.99994]
 [0.     ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.9114213]
 [ 0.       ]]
--- 0.13697266578674316 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3297.685546875, (1968.8225, 1.2489908, 1327.3198, 0.29411396)
   validation loss 983.608642578125, (654.5186, 0.46958226, 328.3263, 0.29411396)
decoder loss ratio: 25357.187467, decoder SINDy loss  ratio: 0.708738
--- 0.20015668869018555 seconds for one epoch ---
--- 1.3577191829681396 seconds for one epoch ---
--- 0.18082475662231445 seconds for one epoch ---
--- 1.3653740882873535 seconds for one epoch ---
--- 0.1605837345123291 seconds for one epoch ---
--- 1.380725622177124 seconds for one epoch ---
--- 0.18827605247497559 seconds for one epoch ---
--- 1.4035005569458008 seconds for one epoch ---
--- 0.2059309482574463 seconds for one epoch ---
--- 1.326139211654663 seconds for one epoch ---
--- 0.1638960838317871 seconds for one epoch ---
--- 1.3314027786254883 seconds for one epoch ---
--- 0.17784571647644043 seconds for one epoch ---
--- 1.3239262104034424 seconds for one epoch ---
--- 0.15810751914978027 seconds for one epoch ---
--- 1.2752251625061035 seconds for one epoch ---
--- 0.1558396816253662 seconds for one epoch ---
--- 1.2765753269195557 seconds for one epoch ---
--- 0.19705796241760254 seconds for one epoch ---
--- 1.3384549617767334 seconds for one epoch ---
--- 0.19801902770996094 seconds for one epoch ---
--- 1.273949384689331 seconds for one epoch ---
--- 0.205519437789917 seconds for one epoch ---
--- 1.322127103805542 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99995685]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.149193]
 [-0.      ]]
--- 0.16683149337768555 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3694.4140625, (1790.7183, 0.62156284, 1902.7775, 0.2968658)
   validation loss 1316.541259765625, (995.33124, 0.4597468, 320.45346, 0.2968658)
decoder loss ratio: 38560.860123, decoder SINDy loss  ratio: 0.691744
--- 0.1524038314819336 seconds for one epoch ---
--- 0.16174936294555664 seconds for one epoch ---
--- 1.402953863143921 seconds for one epoch ---
--- 0.16025543212890625 seconds for one epoch ---
--- 1.317009687423706 seconds for one epoch ---
--- 0.20495271682739258 seconds for one epoch ---
--- 1.4479987621307373 seconds for one epoch ---
--- 0.19154691696166992 seconds for one epoch ---
--- 1.334782600402832 seconds for one epoch ---
--- 0.17076516151428223 seconds for one epoch ---
--- 1.3805084228515625 seconds for one epoch ---
--- 0.15404510498046875 seconds for one epoch ---
--- 1.3847999572753906 seconds for one epoch ---
--- 0.1474924087524414 seconds for one epoch ---
--- 1.3244292736053467 seconds for one epoch ---
--- 0.1754913330078125 seconds for one epoch ---
--- 1.3202826976776123 seconds for one epoch ---
--- 0.17680048942565918 seconds for one epoch ---
--- 1.363234281539917 seconds for one epoch ---
--- 0.18077921867370605 seconds for one epoch ---
--- 1.436598539352417 seconds for one epoch ---
--- 0.19595909118652344 seconds for one epoch ---
--- 1.4677975177764893 seconds for one epoch ---
--- 0.16497445106506348 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999735]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.384609]
 [ 0.      ]]
--- 0.16274213790893555 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3336.53857421875, (1515.9543, 1.9917142, 1818.2926, 0.29973248)
   validation loss 1044.6728515625, (718.3878, 0.6129235, 325.37247, 0.29973248)
decoder loss ratio: 27831.591222, decoder SINDy loss  ratio: 0.702362
--- 0.18665456771850586 seconds for one epoch ---
--- 1.3609588146209717 seconds for one epoch ---
--- 0.15982866287231445 seconds for one epoch ---
--- 1.3613004684448242 seconds for one epoch ---
--- 0.20158910751342773 seconds for one epoch ---
--- 1.3286082744598389 seconds for one epoch ---
--- 0.19108176231384277 seconds for one epoch ---
--- 1.3098609447479248 seconds for one epoch ---
--- 0.15644359588623047 seconds for one epoch ---
--- 1.354783058166504 seconds for one epoch ---
--- 0.17811012268066406 seconds for one epoch ---
--- 1.2636258602142334 seconds for one epoch ---
--- 0.17019224166870117 seconds for one epoch ---
--- 1.3424832820892334 seconds for one epoch ---
--- 0.1492631435394287 seconds for one epoch ---
--- 1.3105823993682861 seconds for one epoch ---
--- 0.17716670036315918 seconds for one epoch ---
--- 1.419074535369873 seconds for one epoch ---
--- 0.17999839782714844 seconds for one epoch ---
--- 1.4004766941070557 seconds for one epoch ---
--- 0.16772818565368652 seconds for one epoch ---
--- 1.4561662673950195 seconds for one epoch ---
--- 0.17435121536254883 seconds for one epoch ---
--- 1.449082374572754 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997467]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.604913]
 [-0.      ]]
--- 0.15291714668273926 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2862.390380859375, (1188.1101, 2.2274094, 1671.7504, 0.3024108)
   validation loss 873.2192993164062, (570.42914, 0.58877265, 301.89896, 0.3024108)
decoder loss ratio: 22099.415122, decoder SINDy loss  ratio: 0.651691
--- 0.13709425926208496 seconds for one epoch ---
--- 0.19274568557739258 seconds for one epoch ---
--- 1.339212417602539 seconds for one epoch ---
--- 0.18877911567687988 seconds for one epoch ---
--- 1.3330845832824707 seconds for one epoch ---
--- 0.17560958862304688 seconds for one epoch ---
--- 1.3021273612976074 seconds for one epoch ---
--- 0.16171979904174805 seconds for one epoch ---
--- 1.5294866561889648 seconds for one epoch ---
--- 0.18039178848266602 seconds for one epoch ---
--- 1.299692153930664 seconds for one epoch ---
--- 0.16217613220214844 seconds for one epoch ---
--- 1.322026014328003 seconds for one epoch ---
--- 0.1823105812072754 seconds for one epoch ---
--- 1.3975489139556885 seconds for one epoch ---
--- 0.18036818504333496 seconds for one epoch ---
--- 1.4075334072113037 seconds for one epoch ---
--- 0.18986272811889648 seconds for one epoch ---
--- 1.3238091468811035 seconds for one epoch ---
--- 0.18500947952270508 seconds for one epoch ---
--- 1.4417788982391357 seconds for one epoch ---
--- 0.15375685691833496 seconds for one epoch ---
--- 1.351292371749878 seconds for one epoch ---
--- 0.1587669849395752 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999887]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-8.824927]
 [-0.      ]]
--- 0.14905261993408203 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3187.895263671875, (1165.844, 1.7417623, 2020.0043, 0.30518764)
   validation loss 1329.9532470703125, (953.50714, 0.59067607, 375.5502, 0.30518764)
decoder loss ratio: 36940.522008, decoder SINDy loss  ratio: 0.810678
--- 0.17035269737243652 seconds for one epoch ---
--- 1.3280353546142578 seconds for one epoch ---
--- 0.1891336441040039 seconds for one epoch ---
--- 1.3457646369934082 seconds for one epoch ---
--- 0.16469192504882812 seconds for one epoch ---
--- 1.3802242279052734 seconds for one epoch ---
--- 0.16326069831848145 seconds for one epoch ---
--- 1.37269926071167 seconds for one epoch ---
--- 0.17249083518981934 seconds for one epoch ---
--- 1.3449339866638184 seconds for one epoch ---
--- 0.16797232627868652 seconds for one epoch ---
--- 1.329573392868042 seconds for one epoch ---
--- 0.1880788803100586 seconds for one epoch ---
--- 1.3427565097808838 seconds for one epoch ---
--- 0.15946054458618164 seconds for one epoch ---
--- 1.4112114906311035 seconds for one epoch ---
--- 0.1833341121673584 seconds for one epoch ---
--- 1.3702106475830078 seconds for one epoch ---
--- 0.19291472434997559 seconds for one epoch ---
--- 1.4536974430084229 seconds for one epoch ---
--- 0.17749357223510742 seconds for one epoch ---
--- 1.4514579772949219 seconds for one epoch ---
--- 0.16734838485717773 seconds for one epoch ---
--- 1.5058906078338623 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999908]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.036969]
 [ 0.      ]]
--- 0.17886114120483398 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4148.6044921875, (1810.5099, 1.0210397, 2336.7654, 0.30797124)
   validation loss 778.7293701171875, (487.7671, 0.6782309, 289.97607, 0.30797124)
decoder loss ratio: 18896.943861, decoder SINDy loss  ratio: 0.625954
--- 0.15071463584899902 seconds for one epoch ---
--- 0.16463351249694824 seconds for one epoch ---
--- 1.477832317352295 seconds for one epoch ---
--- 0.20000076293945312 seconds for one epoch ---
--- 1.3341882228851318 seconds for one epoch ---
--- 0.16490530967712402 seconds for one epoch ---
--- 1.3955106735229492 seconds for one epoch ---
--- 0.16264700889587402 seconds for one epoch ---
--- 1.4577662944793701 seconds for one epoch ---
--- 0.45568323135375977 seconds for one epoch ---
--- 1.3792731761932373 seconds for one epoch ---
--- 0.14920282363891602 seconds for one epoch ---
--- 1.3817284107208252 seconds for one epoch ---
--- 0.20070743560791016 seconds for one epoch ---
--- 1.385024070739746 seconds for one epoch ---
--- 0.20729351043701172 seconds for one epoch ---
--- 1.3256678581237793 seconds for one epoch ---
--- 0.18226313591003418 seconds for one epoch ---
--- 1.3950905799865723 seconds for one epoch ---
--- 0.1815328598022461 seconds for one epoch ---
--- 1.6665575504302979 seconds for one epoch ---
--- 0.16449427604675293 seconds for one epoch ---
--- 1.415496587753296 seconds for one epoch ---
--- 0.1827106475830078 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999907]
 [0.       ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-9.240121]
 [-0.      ]]
--- 0.1438922882080078 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2284.853759765625, (1125.4575, 0.5367933, 1158.5487, 0.31068712)
   validation loss 891.6934814453125, (614.2901, 0.6908952, 276.40176, 0.31068712)
decoder loss ratio: 23798.664932, decoder SINDy loss  ratio: 0.596652
--- 0.19498229026794434 seconds for one epoch ---
--- 1.3224396705627441 seconds for one epoch ---
--- 0.1788942813873291 seconds for one epoch ---
--- 1.4722199440002441 seconds for one epoch ---
--- 0.18002939224243164 seconds for one epoch ---
--- 1.3850953578948975 seconds for one epoch ---
--- 0.1649484634399414 seconds for one epoch ---
--- 1.3564846515655518 seconds for one epoch ---
--- 0.19437718391418457 seconds for one epoch ---
--- 1.324080228805542 seconds for one epoch ---
--- 0.17780351638793945 seconds for one epoch ---
--- 1.4603605270385742 seconds for one epoch ---
--- 0.17711997032165527 seconds for one epoch ---
--- 1.3482954502105713 seconds for one epoch ---
--- 0.1713109016418457 seconds for one epoch ---
--- 1.3635060787200928 seconds for one epoch ---
--- 0.15242838859558105 seconds for one epoch ---
--- 1.4670405387878418 seconds for one epoch ---
--- 0.18400335311889648 seconds for one epoch ---
--- 1.488243579864502 seconds for one epoch ---
--- 0.21379709243774414 seconds for one epoch ---
--- 1.388974666595459 seconds for one epoch ---
--- 0.19896817207336426 seconds for one epoch ---
--- 1.3741555213928223 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999906]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.446391]
 [ 0.      ]]
--- 0.16772150993347168 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2286.58740234375, (1007.1461, 0.42263526, 1278.7053, 0.31348297)
   validation loss 876.4421997070312, (593.243, 0.6461387, 282.23962, 0.31348297)
decoder loss ratio: 22983.262997, decoder SINDy loss  ratio: 0.609254
--- 0.15695738792419434 seconds for one epoch ---
--- 0.17386984825134277 seconds for one epoch ---
--- 1.3456768989562988 seconds for one epoch ---
--- 0.1707913875579834 seconds for one epoch ---
--- 1.406709909439087 seconds for one epoch ---
--- 0.18515253067016602 seconds for one epoch ---
--- 1.362983226776123 seconds for one epoch ---
--- 0.19483017921447754 seconds for one epoch ---
--- 1.3736484050750732 seconds for one epoch ---
--- 0.18150639533996582 seconds for one epoch ---
--- 1.4409611225128174 seconds for one epoch ---
--- 0.16686606407165527 seconds for one epoch ---
--- 1.401609182357788 seconds for one epoch ---
--- 0.1732339859008789 seconds for one epoch ---
--- 1.3949034214019775 seconds for one epoch ---
--- 0.17970871925354004 seconds for one epoch ---
--- 1.3625328540802002 seconds for one epoch ---
--- 0.17229843139648438 seconds for one epoch ---
--- 1.4130065441131592 seconds for one epoch ---
--- 0.15021252632141113 seconds for one epoch ---
--- 1.411681890487671 seconds for one epoch ---
--- 0.18990683555603027 seconds for one epoch ---
--- 1.395967960357666 seconds for one epoch ---
--- 0.1708238124847412 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999046]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.628906]
 [ 0.      ]]
--- 0.1685621738433838 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2082.62744140625, (1060.1459, 3.400717, 1018.76495, 0.31599545)
   validation loss 1461.47900390625, (1156.8665, 0.66536635, 303.63113, 0.31599545)
decoder loss ratio: 44819.014878, decoder SINDy loss  ratio: 0.655431
--- 0.18207693099975586 seconds for one epoch ---
--- 1.384058952331543 seconds for one epoch ---
--- 0.1984870433807373 seconds for one epoch ---
--- 1.4311747550964355 seconds for one epoch ---
--- 0.1573631763458252 seconds for one epoch ---
--- 1.4694736003875732 seconds for one epoch ---
--- 0.1966078281402588 seconds for one epoch ---
--- 1.4538991451263428 seconds for one epoch ---
--- 0.17073583602905273 seconds for one epoch ---
--- 1.4212424755096436 seconds for one epoch ---
--- 0.16281962394714355 seconds for one epoch ---
--- 1.4350371360778809 seconds for one epoch ---
--- 0.1784672737121582 seconds for one epoch ---
--- 1.4515211582183838 seconds for one epoch ---
--- 0.16413354873657227 seconds for one epoch ---
--- 1.386310338973999 seconds for one epoch ---
--- 0.16375470161437988 seconds for one epoch ---
--- 1.389052152633667 seconds for one epoch ---
--- 0.17972874641418457 seconds for one epoch ---
--- 1.57448410987854 seconds for one epoch ---
--- 0.15608930587768555 seconds for one epoch ---
--- 1.4376606941223145 seconds for one epoch ---
--- 0.1938316822052002 seconds for one epoch ---
--- 1.526872158050537 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999906]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.795245]
 [ 0.      ]]
--- 0.15916061401367188 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4501.8125, (1067.8451, 1.5977665, 3432.0513, 0.31833446)
   validation loss 795.3727416992188, (522.1972, 0.7760451, 272.08112, 0.31833446)
decoder loss ratio: 20230.826280, decoder SINDy loss  ratio: 0.587325
--- 0.15520834922790527 seconds for one epoch ---
--- 0.20788955688476562 seconds for one epoch ---
--- 1.4040818214416504 seconds for one epoch ---
--- 0.18670201301574707 seconds for one epoch ---
--- 1.3527674674987793 seconds for one epoch ---
--- 0.17751646041870117 seconds for one epoch ---
--- 1.4885179996490479 seconds for one epoch ---
--- 0.16214656829833984 seconds for one epoch ---
--- 1.401838779449463 seconds for one epoch ---
--- 0.18021368980407715 seconds for one epoch ---
--- 1.4491991996765137 seconds for one epoch ---
--- 0.19450688362121582 seconds for one epoch ---
--- 1.3735461235046387 seconds for one epoch ---
--- 0.18204545974731445 seconds for one epoch ---
--- 1.454587697982788 seconds for one epoch ---
--- 0.16825032234191895 seconds for one epoch ---
--- 1.4152445793151855 seconds for one epoch ---
--- 0.15819025039672852 seconds for one epoch ---
--- 1.5154964923858643 seconds for one epoch ---
--- 0.17345595359802246 seconds for one epoch ---
--- 1.3807635307312012 seconds for one epoch ---
--- 0.17903923988342285 seconds for one epoch ---
--- 1.4452056884765625 seconds for one epoch ---
--- 0.19565439224243164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999046]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.976488]
 [-0.      ]]
--- 0.17464399337768555 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2929.3095703125, (1176.862, 1.0463356, 1751.0803, 0.3209024)
   validation loss 851.6298828125, (576.2414, 0.68265396, 274.38492, 0.3209024)
decoder loss ratio: 22324.592004, decoder SINDy loss  ratio: 0.592298
--- 0.2047429084777832 seconds for one epoch ---
--- 1.4526007175445557 seconds for one epoch ---
--- 0.16770267486572266 seconds for one epoch ---
--- 1.4141185283660889 seconds for one epoch ---
--- 0.19287800788879395 seconds for one epoch ---
--- 1.4657392501831055 seconds for one epoch ---
--- 0.1726844310760498 seconds for one epoch ---
--- 1.3639891147613525 seconds for one epoch ---
--- 0.17608165740966797 seconds for one epoch ---
--- 1.4102323055267334 seconds for one epoch ---
--- 0.1659386157989502 seconds for one epoch ---
--- 1.4510788917541504 seconds for one epoch ---
--- 0.16254901885986328 seconds for one epoch ---
--- 1.4374923706054688 seconds for one epoch ---
--- 0.17927908897399902 seconds for one epoch ---
--- 1.4440560340881348 seconds for one epoch ---
--- 0.17995190620422363 seconds for one epoch ---
--- 1.4820377826690674 seconds for one epoch ---
--- 0.1632826328277588 seconds for one epoch ---
--- 1.4518673419952393 seconds for one epoch ---
--- 0.1544656753540039 seconds for one epoch ---
--- 1.5203378200531006 seconds for one epoch ---
--- 0.17316412925720215 seconds for one epoch ---
--- 1.5498411655426025 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999908]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.150015]
 [  0.      ]]
--- 0.18345046043395996 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2839.199462890625, (1242.1625, 0.42278534, 1596.2908, 0.32337472)
   validation loss 985.280029296875, (689.8894, 0.6749812, 294.39224, 0.32337472)
decoder loss ratio: 26727.513223, decoder SINDy loss  ratio: 0.635487
--- 0.17359304428100586 seconds for one epoch ---
--- 0.19288277626037598 seconds for one epoch ---
--- 1.5476500988006592 seconds for one epoch ---
--- 0.17183232307434082 seconds for one epoch ---
--- 1.442228078842163 seconds for one epoch ---
--- 0.1936039924621582 seconds for one epoch ---
--- 1.463785171508789 seconds for one epoch ---
--- 0.17961764335632324 seconds for one epoch ---
--- 1.3992834091186523 seconds for one epoch ---
--- 0.17842841148376465 seconds for one epoch ---
--- 1.4536163806915283 seconds for one epoch ---
--- 0.18038511276245117 seconds for one epoch ---
--- 1.4660978317260742 seconds for one epoch ---
--- 0.19723129272460938 seconds for one epoch ---
--- 1.4368295669555664 seconds for one epoch ---
--- 0.16983962059020996 seconds for one epoch ---
--- 1.4229495525360107 seconds for one epoch ---
--- 0.16802382469177246 seconds for one epoch ---
--- 1.4210309982299805 seconds for one epoch ---
--- 0.1939244270324707 seconds for one epoch ---
--- 1.415299892425537 seconds for one epoch ---
--- 0.15390729904174805 seconds for one epoch ---
--- 1.4467487335205078 seconds for one epoch ---
--- 0.18811821937561035 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999908]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.317803]
 [ -0.      ]]
--- 0.1368575096130371 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2983.099853515625, (1376.9191, 0.54961866, 1605.3053, 0.32583937)
   validation loss 955.3041381835938, (660.40906, 0.6470093, 293.92215, 0.32583937)
decoder loss ratio: 25585.393413, decoder SINDy loss  ratio: 0.634472
--- 0.16296648979187012 seconds for one epoch ---
--- 1.497206449508667 seconds for one epoch ---
--- 0.18806028366088867 seconds for one epoch ---
--- 1.4750912189483643 seconds for one epoch ---
--- 0.16599273681640625 seconds for one epoch ---
--- 1.4416990280151367 seconds for one epoch ---
--- 0.2199234962463379 seconds for one epoch ---
--- 1.4061777591705322 seconds for one epoch ---
--- 0.15741419792175293 seconds for one epoch ---
--- 1.5899560451507568 seconds for one epoch ---
--- 0.21139097213745117 seconds for one epoch ---
--- 1.4328029155731201 seconds for one epoch ---
--- 0.19837379455566406 seconds for one epoch ---
--- 1.4810922145843506 seconds for one epoch ---
--- 0.16871404647827148 seconds for one epoch ---
--- 1.5720269680023193 seconds for one epoch ---
--- 0.18731117248535156 seconds for one epoch ---
--- 1.567962646484375 seconds for one epoch ---
--- 0.1660616397857666 seconds for one epoch ---
--- 1.5467798709869385 seconds for one epoch ---
--- 0.18482375144958496 seconds for one epoch ---
--- 1.4786057472229004 seconds for one epoch ---
--- 0.1683516502380371 seconds for one epoch ---
--- 1.5206372737884521 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999914]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.474985]
 [ -0.      ]]
--- 0.16292190551757812 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3059.4384765625, (1366.8337, 0.67627466, 1691.6002, 0.32812282)
   validation loss 835.79931640625, (575.68896, 0.76374644, 259.01852, 0.32812282)
decoder loss ratio: 22303.189938, decoder SINDy loss  ratio: 0.559128
--- 0.14350509643554688 seconds for one epoch ---
--- 0.18201088905334473 seconds for one epoch ---
--- 1.5276494026184082 seconds for one epoch ---
--- 0.17771029472351074 seconds for one epoch ---
--- 1.423637866973877 seconds for one epoch ---
--- 0.1544792652130127 seconds for one epoch ---
--- 1.5000169277191162 seconds for one epoch ---
--- 0.19338154792785645 seconds for one epoch ---
--- 1.4422943592071533 seconds for one epoch ---
--- 0.1667165756225586 seconds for one epoch ---
--- 1.5059561729431152 seconds for one epoch ---
--- 0.1986072063446045 seconds for one epoch ---
--- 1.476085901260376 seconds for one epoch ---
--- 0.15808987617492676 seconds for one epoch ---
--- 1.4929327964782715 seconds for one epoch ---
--- 0.20010757446289062 seconds for one epoch ---
--- 1.5271124839782715 seconds for one epoch ---
--- 0.15897297859191895 seconds for one epoch ---
--- 1.7334725856781006 seconds for one epoch ---
--- 0.19315552711486816 seconds for one epoch ---
--- 1.4399058818817139 seconds for one epoch ---
--- 0.1744370460510254 seconds for one epoch ---
--- 1.5090959072113037 seconds for one epoch ---
--- 0.19466733932495117 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999919]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.633637]
 [  0.      ]]
--- 0.16788887977600098 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5935.98974609375, (1681.2538, 2.4443038, 4251.961, 0.33042714)
   validation loss 1168.5577392578125, (879.02527, 0.7757003, 288.4264, 0.33042714)
decoder loss ratio: 34054.964959, decoder SINDy loss  ratio: 0.622609
--- 0.1598072052001953 seconds for one epoch ---
--- 1.5283184051513672 seconds for one epoch ---
--- 0.1951899528503418 seconds for one epoch ---
--- 1.4924976825714111 seconds for one epoch ---
--- 0.16738390922546387 seconds for one epoch ---
--- 1.4454796314239502 seconds for one epoch ---
--- 0.17185497283935547 seconds for one epoch ---
--- 1.7392284870147705 seconds for one epoch ---
--- 0.1722426414489746 seconds for one epoch ---
--- 1.4691250324249268 seconds for one epoch ---
--- 0.17726659774780273 seconds for one epoch ---
--- 1.517573595046997 seconds for one epoch ---
--- 0.2117908000946045 seconds for one epoch ---
--- 1.491469383239746 seconds for one epoch ---
--- 0.16782617568969727 seconds for one epoch ---
--- 1.5708858966827393 seconds for one epoch ---
--- 0.16884279251098633 seconds for one epoch ---
--- 1.537198543548584 seconds for one epoch ---
--- 0.2190108299255371 seconds for one epoch ---
--- 1.6245079040527344 seconds for one epoch ---
--- 0.17573332786560059 seconds for one epoch ---
--- 1.4750442504882812 seconds for one epoch ---
--- 0.18217873573303223 seconds for one epoch ---
--- 1.5254805088043213 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999924]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.778072]
 [ -0.      ]]
--- 0.2341477870941162 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5077.72021484375, (1653.4028, 2.9809523, 3421.004, 0.33241078)
   validation loss 871.5128173828125, (593.019, 0.69585145, 277.46558, 0.33241078)
decoder loss ratio: 22974.584886, decoder SINDy loss  ratio: 0.598948
THRESHOLDING: 1 active coefficients
--- 1.5646157264709473 seconds for one epoch ---
--- 0.1753990650177002 seconds for one epoch ---
--- 1.6222789287567139 seconds for one epoch ---
--- 0.15973496437072754 seconds for one epoch ---
--- 1.6293153762817383 seconds for one epoch ---
--- 0.1609935760498047 seconds for one epoch ---
--- 1.5691895484924316 seconds for one epoch ---
--- 0.16987371444702148 seconds for one epoch ---
--- 1.5926501750946045 seconds for one epoch ---
--- 0.17562007904052734 seconds for one epoch ---
--- 1.5880262851715088 seconds for one epoch ---
--- 0.17119789123535156 seconds for one epoch ---
--- 1.525679349899292 seconds for one epoch ---
--- 0.20369529724121094 seconds for one epoch ---
--- 1.6100490093231201 seconds for one epoch ---
--- 0.17957139015197754 seconds for one epoch ---
--- 1.6223104000091553 seconds for one epoch ---
--- 0.21799087524414062 seconds for one epoch ---
--- 1.4704957008361816 seconds for one epoch ---
--- 0.15097856521606445 seconds for one epoch ---
--- 1.5407676696777344 seconds for one epoch ---
--- 0.16355371475219727 seconds for one epoch ---
--- 1.5512056350708008 seconds for one epoch ---
--- 0.16068696975708008 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999356]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.906045]
 [  0.      ]]
--- 0.15388083457946777 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2665.428955078125, (1409.8914, 0.975508, 1254.2456, 0.31674683)
   validation loss 1108.0743408203125, (786.778, 0.66123796, 320.31833, 0.31674683)
decoder loss ratio: 30481.146213, decoder SINDy loss  ratio: 0.691452
--- 0.16899561882019043 seconds for one epoch ---
--- 1.5488390922546387 seconds for one epoch ---
--- 0.1714622974395752 seconds for one epoch ---
--- 1.5721259117126465 seconds for one epoch ---
--- 0.20263075828552246 seconds for one epoch ---
--- 1.527083396911621 seconds for one epoch ---
--- 0.17368006706237793 seconds for one epoch ---
--- 1.4457216262817383 seconds for one epoch ---
--- 0.16521692276000977 seconds for one epoch ---
--- 1.5638725757598877 seconds for one epoch ---
--- 0.15968656539916992 seconds for one epoch ---
--- 1.4862170219421387 seconds for one epoch ---
--- 0.1822071075439453 seconds for one epoch ---
--- 1.5256638526916504 seconds for one epoch ---
--- 0.18580007553100586 seconds for one epoch ---
--- 1.4420530796051025 seconds for one epoch ---
--- 0.16404294967651367 seconds for one epoch ---
--- 1.699455976486206 seconds for one epoch ---
--- 0.16437220573425293 seconds for one epoch ---
--- 1.493326187133789 seconds for one epoch ---
--- 0.16452288627624512 seconds for one epoch ---
--- 1.6095690727233887 seconds for one epoch ---
--- 0.1817460060119629 seconds for one epoch ---
--- 1.461850643157959 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999958]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.028366]
 [  0.      ]]
--- 0.1661972999572754 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3566.156005859375, (1670.0767, 0.24772519, 1895.5131, 0.31865472)
   validation loss 792.5360107421875, (511.3603, 0.6130247, 280.24402, 0.31865472)
decoder loss ratio: 19810.985416, decoder SINDy loss  ratio: 0.604946
--- 0.1438755989074707 seconds for one epoch ---
--- 0.15285229682922363 seconds for one epoch ---
--- 1.5390896797180176 seconds for one epoch ---
--- 0.2059180736541748 seconds for one epoch ---
--- 1.4855239391326904 seconds for one epoch ---
--- 0.18810248374938965 seconds for one epoch ---
--- 1.5224034786224365 seconds for one epoch ---
--- 0.19118452072143555 seconds for one epoch ---
--- 1.4734346866607666 seconds for one epoch ---
--- 0.15339446067810059 seconds for one epoch ---
--- 1.6232640743255615 seconds for one epoch ---
--- 0.1696324348449707 seconds for one epoch ---
--- 1.520747184753418 seconds for one epoch ---
--- 0.20599961280822754 seconds for one epoch ---
--- 1.5206239223480225 seconds for one epoch ---
--- 0.1891789436340332 seconds for one epoch ---
--- 1.5828464031219482 seconds for one epoch ---
--- 0.1945030689239502 seconds for one epoch ---
--- 1.540647029876709 seconds for one epoch ---
--- 0.15474891662597656 seconds for one epoch ---
--- 1.461043119430542 seconds for one epoch ---
--- 0.16802692413330078 seconds for one epoch ---
--- 1.5304057598114014 seconds for one epoch ---
--- 0.186722993850708 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999958]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.169653]
 [  0.      ]]
--- 0.14188671112060547 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3267.366455078125, (1422.6062, 0.853342, 1843.5857, 0.32097363)
   validation loss 1000.42333984375, (703.7885, 0.6666391, 295.64722, 0.32097363)
decoder loss ratio: 27265.988831, decoder SINDy loss  ratio: 0.638196
--- 0.15963244438171387 seconds for one epoch ---
--- 1.6295688152313232 seconds for one epoch ---
--- 0.1716148853302002 seconds for one epoch ---
--- 1.495551586151123 seconds for one epoch ---
--- 0.1727895736694336 seconds for one epoch ---
--- 1.4725751876831055 seconds for one epoch ---
--- 0.16527390480041504 seconds for one epoch ---
--- 1.6325528621673584 seconds for one epoch ---
--- 0.19286894798278809 seconds for one epoch ---
--- 1.5711698532104492 seconds for one epoch ---
--- 0.20175433158874512 seconds for one epoch ---
--- 1.5387964248657227 seconds for one epoch ---
--- 0.19335031509399414 seconds for one epoch ---
--- 1.601717233657837 seconds for one epoch ---
--- 0.20140337944030762 seconds for one epoch ---
--- 1.6430385112762451 seconds for one epoch ---
--- 0.20352625846862793 seconds for one epoch ---
--- 1.4944336414337158 seconds for one epoch ---
--- 0.19668889045715332 seconds for one epoch ---
--- 1.523315191268921 seconds for one epoch ---
--- 0.17531061172485352 seconds for one epoch ---
--- 1.6706721782684326 seconds for one epoch ---
--- 0.18131113052368164 seconds for one epoch ---
--- 1.6255130767822266 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999998]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.316974]
 [ -0.      ]]
--- 0.17634320259094238 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4377.37646484375, (1482.8455, 3.4454477, 2890.7622, 0.32332906)
   validation loss 1227.1668701171875, (902.6772, 0.6335741, 323.5327, 0.32332906)
decoder loss ratio: 34971.281266, decoder SINDy loss  ratio: 0.698391
--- 0.1579575538635254 seconds for one epoch ---
--- 0.17597365379333496 seconds for one epoch ---
--- 1.5310933589935303 seconds for one epoch ---
--- 0.18571949005126953 seconds for one epoch ---
--- 1.5649921894073486 seconds for one epoch ---
--- 0.1676177978515625 seconds for one epoch ---
--- 1.556394338607788 seconds for one epoch ---
--- 0.1758894920349121 seconds for one epoch ---
--- 1.622166395187378 seconds for one epoch ---
--- 0.16890549659729004 seconds for one epoch ---
--- 1.568342924118042 seconds for one epoch ---
--- 0.1679835319519043 seconds for one epoch ---
--- 1.655245304107666 seconds for one epoch ---
--- 0.16735363006591797 seconds for one epoch ---
--- 1.567812442779541 seconds for one epoch ---
--- 0.2055187225341797 seconds for one epoch ---
--- 1.5326151847839355 seconds for one epoch ---
--- 0.22199630737304688 seconds for one epoch ---
--- 1.6287651062011719 seconds for one epoch ---
--- 0.18749761581420898 seconds for one epoch ---
--- 1.6328392028808594 seconds for one epoch ---
--- 0.14909863471984863 seconds for one epoch ---
--- 1.603287935256958 seconds for one epoch ---
--- 0.18492889404296875 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999998]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.455858]
 [  0.      ]]
--- 0.1515202522277832 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7904.783203125, (1608.2332, 2.953216, 6293.271, 0.32571474)
   validation loss 815.6748657226562, (534.33606, 0.73041123, 280.28262, 0.32571474)
decoder loss ratio: 20701.106596, decoder SINDy loss  ratio: 0.605029
--- 0.17257380485534668 seconds for one epoch ---
--- 1.506659984588623 seconds for one epoch ---
--- 0.17821431159973145 seconds for one epoch ---
--- 1.5456383228302002 seconds for one epoch ---
--- 0.1684119701385498 seconds for one epoch ---
--- 1.5440185070037842 seconds for one epoch ---
--- 0.17479515075683594 seconds for one epoch ---
--- 1.6554865837097168 seconds for one epoch ---
--- 0.17854809761047363 seconds for one epoch ---
--- 1.5418758392333984 seconds for one epoch ---
--- 0.19728803634643555 seconds for one epoch ---
--- 1.6146893501281738 seconds for one epoch ---
--- 0.1565871238708496 seconds for one epoch ---
--- 1.5498809814453125 seconds for one epoch ---
--- 0.19402670860290527 seconds for one epoch ---
--- 1.605133056640625 seconds for one epoch ---
--- 0.16684746742248535 seconds for one epoch ---
--- 1.6783976554870605 seconds for one epoch ---
--- 0.1695725917816162 seconds for one epoch ---
--- 1.6573131084442139 seconds for one epoch ---
--- 0.21245980262756348 seconds for one epoch ---
--- 1.58254075050354 seconds for one epoch ---
--- 0.16502785682678223 seconds for one epoch ---
--- 1.5764391422271729 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-11.5771675]
 [ -0.       ]]
--- 0.18614459037780762 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2030.6962890625, (816.5643, 1.2532216, 1212.551, 0.32770085)
   validation loss 912.7997436523438, (630.03015, 0.80407804, 281.63782, 0.32770085)
decoder loss ratio: 24408.461844, decoder SINDy loss  ratio: 0.607955
--- 0.14296627044677734 seconds for one epoch ---
--- 0.1971123218536377 seconds for one epoch ---
--- 1.5542793273925781 seconds for one epoch ---
--- 0.18695664405822754 seconds for one epoch ---
--- 1.6231675148010254 seconds for one epoch ---
--- 0.16553807258605957 seconds for one epoch ---
--- 1.6198389530181885 seconds for one epoch ---
--- 0.19614315032958984 seconds for one epoch ---
--- 1.7219557762145996 seconds for one epoch ---
--- 0.18716192245483398 seconds for one epoch ---
--- 1.5783958435058594 seconds for one epoch ---
--- 0.16752171516418457 seconds for one epoch ---
--- 1.6369612216949463 seconds for one epoch ---
--- 0.16116070747375488 seconds for one epoch ---
--- 1.6942236423492432 seconds for one epoch ---
--- 0.16294002532958984 seconds for one epoch ---
--- 1.6332054138183594 seconds for one epoch ---
--- 0.2172994613647461 seconds for one epoch ---
--- 1.6659913063049316 seconds for one epoch ---
--- 0.20224714279174805 seconds for one epoch ---
--- 1.6085383892059326 seconds for one epoch ---
--- 0.19020557403564453 seconds for one epoch ---
--- 1.568178653717041 seconds for one epoch ---
--- 0.21442198753356934 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.681103]
 [ -0.      ]]
--- 0.17465972900390625 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5406.62158203125, (2055.3003, 0.8852285, 3350.1064, 0.3294243)
   validation loss 836.0510864257812, (573.18756, 0.7717856, 261.7623, 0.3294243)
decoder loss ratio: 22206.281212, decoder SINDy loss  ratio: 0.565051
--- 0.17417025566101074 seconds for one epoch ---
--- 1.5803256034851074 seconds for one epoch ---
--- 0.22846031188964844 seconds for one epoch ---
--- 1.5766785144805908 seconds for one epoch ---
--- 0.21406269073486328 seconds for one epoch ---
--- 1.5019021034240723 seconds for one epoch ---
--- 0.1678323745727539 seconds for one epoch ---
--- 1.645216941833496 seconds for one epoch ---
--- 0.19590473175048828 seconds for one epoch ---
--- 1.6413159370422363 seconds for one epoch ---
--- 0.18250179290771484 seconds for one epoch ---
--- 1.7014122009277344 seconds for one epoch ---
--- 0.1725177764892578 seconds for one epoch ---
--- 1.6546826362609863 seconds for one epoch ---
--- 0.1847848892211914 seconds for one epoch ---
--- 1.5706534385681152 seconds for one epoch ---
--- 0.17511820793151855 seconds for one epoch ---
--- 1.6440153121948242 seconds for one epoch ---
--- 0.15764737129211426 seconds for one epoch ---
--- 1.589343547821045 seconds for one epoch ---
--- 0.1692202091217041 seconds for one epoch ---
--- 1.6736412048339844 seconds for one epoch ---
--- 0.16230535507202148 seconds for one epoch ---
--- 1.595029354095459 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.795983]
 [  0.      ]]
--- 0.1630418300628662 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3393.473876953125, (1374.3308, 2.694079, 2016.1177, 0.33138108)
   validation loss 868.1340942382812, (576.0613, 0.7855138, 290.9559, 0.33138108)
decoder loss ratio: 22317.614046, decoder SINDy loss  ratio: 0.628069
--- 0.1474747657775879 seconds for one epoch ---
--- 0.21188592910766602 seconds for one epoch ---
--- 1.509368658065796 seconds for one epoch ---
--- 0.1829242706298828 seconds for one epoch ---
--- 1.6221392154693604 seconds for one epoch ---
--- 0.18560481071472168 seconds for one epoch ---
--- 1.60365891456604 seconds for one epoch ---
--- 0.2042384147644043 seconds for one epoch ---
--- 1.6600689888000488 seconds for one epoch ---
--- 0.15337252616882324 seconds for one epoch ---
--- 1.596111536026001 seconds for one epoch ---
--- 0.18571066856384277 seconds for one epoch ---
--- 1.6795330047607422 seconds for one epoch ---
--- 0.19264864921569824 seconds for one epoch ---
--- 1.5728087425231934 seconds for one epoch ---
--- 0.19875335693359375 seconds for one epoch ---
--- 1.6058566570281982 seconds for one epoch ---
--- 0.1799020767211914 seconds for one epoch ---
--- 1.7207410335540771 seconds for one epoch ---
--- 0.19202470779418945 seconds for one epoch ---
--- 1.6371920108795166 seconds for one epoch ---
--- 0.19194841384887695 seconds for one epoch ---
--- 1.598109245300293 seconds for one epoch ---
--- 0.18938636779785156 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.892296]
 [ -0.      ]]
--- 0.16016697883605957 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2485.872802734375, (1469.3259, 0.79048073, 1015.42334, 0.3330287)
   validation loss 1146.1241455078125, (874.5815, 0.86123985, 270.3484, 0.3330287)
decoder loss ratio: 33882.804950, decoder SINDy loss  ratio: 0.583585
--- 0.18205785751342773 seconds for one epoch ---
--- 1.5829322338104248 seconds for one epoch ---
--- 0.1737074851989746 seconds for one epoch ---
--- 1.5674841403961182 seconds for one epoch ---
--- 0.19752097129821777 seconds for one epoch ---
--- 1.598564624786377 seconds for one epoch ---
--- 0.16921091079711914 seconds for one epoch ---
--- 1.5787315368652344 seconds for one epoch ---
--- 0.1532573699951172 seconds for one epoch ---
--- 1.681267499923706 seconds for one epoch ---
--- 0.19602704048156738 seconds for one epoch ---
--- 1.599109411239624 seconds for one epoch ---
--- 0.19421625137329102 seconds for one epoch ---
--- 1.7418737411499023 seconds for one epoch ---
--- 0.17973709106445312 seconds for one epoch ---
--- 1.6607728004455566 seconds for one epoch ---
--- 0.1861283779144287 seconds for one epoch ---
--- 1.7499070167541504 seconds for one epoch ---
--- 0.16517162322998047 seconds for one epoch ---
--- 1.677757740020752 seconds for one epoch ---
--- 0.17011713981628418 seconds for one epoch ---
--- 1.7361221313476562 seconds for one epoch ---
--- 0.17950892448425293 seconds for one epoch ---
--- 1.6381945610046387 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.999866]
 [  0.      ]]
--- 0.18252182006835938 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3321.45751953125, (1290.4943, 1.3518881, 2029.2764, 0.33498526)
   validation loss 1203.618896484375, (881.58636, 0.8011181, 320.8964, 0.33498526)
decoder loss ratio: 34154.186271, decoder SINDy loss  ratio: 0.692700
--- 0.15515375137329102 seconds for one epoch ---
--- 0.17553234100341797 seconds for one epoch ---
--- 1.6098523139953613 seconds for one epoch ---
--- 0.15497064590454102 seconds for one epoch ---
--- 1.564589500427246 seconds for one epoch ---
--- 0.17738652229309082 seconds for one epoch ---
--- 1.5929932594299316 seconds for one epoch ---
--- 0.18142271041870117 seconds for one epoch ---
--- 1.6360547542572021 seconds for one epoch ---
--- 0.17240524291992188 seconds for one epoch ---
--- 1.652702808380127 seconds for one epoch ---
--- 0.1912240982055664 seconds for one epoch ---
--- 1.589766025543213 seconds for one epoch ---
--- 0.18779325485229492 seconds for one epoch ---
--- 1.6052861213684082 seconds for one epoch ---
--- 0.1593763828277588 seconds for one epoch ---
--- 1.6687757968902588 seconds for one epoch ---
--- 0.20838642120361328 seconds for one epoch ---
--- 1.6292142868041992 seconds for one epoch ---
--- 0.19714736938476562 seconds for one epoch ---
--- 1.689598798751831 seconds for one epoch ---
--- 0.1611180305480957 seconds for one epoch ---
--- 1.6425635814666748 seconds for one epoch ---
--- 0.1806809902191162 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.104788]
 [  0.      ]]
--- 0.13789033889770508 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2893.4833984375, (1141.2532, 2.890974, 1749.0023, 0.33681726)
   validation loss 1078.9468994140625, (783.9576, 0.9154223, 293.73715, 0.33681726)
decoder loss ratio: 30371.877681, decoder SINDy loss  ratio: 0.634073
--- 0.16374945640563965 seconds for one epoch ---
--- 1.6224331855773926 seconds for one epoch ---
--- 0.17201757431030273 seconds for one epoch ---
--- 1.6436095237731934 seconds for one epoch ---
--- 0.16069388389587402 seconds for one epoch ---
--- 1.7256195545196533 seconds for one epoch ---
--- 0.18934845924377441 seconds for one epoch ---
--- 1.6701581478118896 seconds for one epoch ---
--- 0.1803898811340332 seconds for one epoch ---
--- 1.7847838401794434 seconds for one epoch ---
--- 0.17914700508117676 seconds for one epoch ---
--- 1.6793813705444336 seconds for one epoch ---
--- 0.17656612396240234 seconds for one epoch ---
--- 1.6088871955871582 seconds for one epoch ---
--- 0.18230843544006348 seconds for one epoch ---
--- 1.6804149150848389 seconds for one epoch ---
--- 0.16466522216796875 seconds for one epoch ---
--- 1.6466054916381836 seconds for one epoch ---
--- 0.1850147247314453 seconds for one epoch ---
--- 1.7807378768920898 seconds for one epoch ---
--- 0.16621994972229004 seconds for one epoch ---
--- 1.617630958557129 seconds for one epoch ---
--- 0.19104313850402832 seconds for one epoch ---
--- 1.7259960174560547 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.190185]
 [  0.      ]]
--- 0.22406506538391113 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2663.498779296875, (995.65216, 2.256752, 1665.2518, 0.3382363)
   validation loss 872.859619140625, (585.852, 0.8678314, 285.8015, 0.3382363)
decoder loss ratio: 22696.923167, decoder SINDy loss  ratio: 0.616943
--- 0.14229416847229004 seconds for one epoch ---
--- 0.19359803199768066 seconds for one epoch ---
--- 1.6900367736816406 seconds for one epoch ---
--- 0.1877439022064209 seconds for one epoch ---
--- 1.6358921527862549 seconds for one epoch ---
--- 0.16871166229248047 seconds for one epoch ---
--- 1.7133641242980957 seconds for one epoch ---
--- 0.17482995986938477 seconds for one epoch ---
--- 1.656395435333252 seconds for one epoch ---
--- 0.1831200122833252 seconds for one epoch ---
--- 1.6173033714294434 seconds for one epoch ---
--- 0.19412016868591309 seconds for one epoch ---
--- 1.768890380859375 seconds for one epoch ---
--- 0.16834330558776855 seconds for one epoch ---
--- 1.626967191696167 seconds for one epoch ---
--- 0.1709902286529541 seconds for one epoch ---
--- 1.6827421188354492 seconds for one epoch ---
--- 0.19086813926696777 seconds for one epoch ---
--- 1.6584038734436035 seconds for one epoch ---
--- 0.16527533531188965 seconds for one epoch ---
--- 1.636733055114746 seconds for one epoch ---
--- 0.16884112358093262 seconds for one epoch ---
--- 1.661536693572998 seconds for one epoch ---
--- 0.17319893836975098 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.285606]
 [ -0.      ]]
--- 0.14928174018859863 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2179.58056640625, (1062.2717, 0.39629775, 1116.5725, 0.33997342)
   validation loss 790.4864501953125, (530.05383, 0.9212691, 259.17142, 0.33997342)
decoder loss ratio: 20535.205705, decoder SINDy loss  ratio: 0.559458
--- 0.17602133750915527 seconds for one epoch ---
--- 1.6716527938842773 seconds for one epoch ---
--- 0.16963505744934082 seconds for one epoch ---
--- 1.670074701309204 seconds for one epoch ---
--- 0.17877483367919922 seconds for one epoch ---
--- 1.6762053966522217 seconds for one epoch ---
--- 0.19440078735351562 seconds for one epoch ---
--- 1.7126445770263672 seconds for one epoch ---
--- 0.20908761024475098 seconds for one epoch ---
--- 1.6936192512512207 seconds for one epoch ---
--- 0.16927719116210938 seconds for one epoch ---
--- 1.6742799282073975 seconds for one epoch ---
--- 0.18982863426208496 seconds for one epoch ---
--- 1.6954960823059082 seconds for one epoch ---
--- 0.18996262550354004 seconds for one epoch ---
--- 1.7028477191925049 seconds for one epoch ---
--- 0.18174529075622559 seconds for one epoch ---
--- 1.6269042491912842 seconds for one epoch ---
--- 0.20377159118652344 seconds for one epoch ---
--- 1.8636298179626465 seconds for one epoch ---
--- 0.17299556732177734 seconds for one epoch ---
--- 1.6968803405761719 seconds for one epoch ---
--- 0.2128303050994873 seconds for one epoch ---
--- 1.742384672164917 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.387398]
 [  0.      ]]
--- 0.18636560440063477 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3016.65087890625, (1126.7815, 1.9853462, 1887.5424, 0.34177485)
   validation loss 1030.3955078125, (742.98016, 0.74602437, 286.3275, 0.34177485)
decoder loss ratio: 28784.341407, decoder SINDy loss  ratio: 0.618078
--- 0.1475515365600586 seconds for one epoch ---
--- 0.17130398750305176 seconds for one epoch ---
--- 1.6638445854187012 seconds for one epoch ---
--- 0.17080330848693848 seconds for one epoch ---
--- 1.7450919151306152 seconds for one epoch ---
--- 0.1587362289428711 seconds for one epoch ---
--- 1.6883544921875 seconds for one epoch ---
--- 0.17076969146728516 seconds for one epoch ---
--- 1.6974194049835205 seconds for one epoch ---
--- 0.18724870681762695 seconds for one epoch ---
--- 1.6829986572265625 seconds for one epoch ---
--- 0.17250275611877441 seconds for one epoch ---
--- 1.6736702919006348 seconds for one epoch ---
--- 0.1808915138244629 seconds for one epoch ---
--- 1.6942572593688965 seconds for one epoch ---
--- 0.15891385078430176 seconds for one epoch ---
--- 1.777397871017456 seconds for one epoch ---
--- 0.1867837905883789 seconds for one epoch ---
--- 1.8018453121185303 seconds for one epoch ---
--- 0.17213153839111328 seconds for one epoch ---
--- 1.7591278553009033 seconds for one epoch ---
--- 0.17696595191955566 seconds for one epoch ---
--- 1.6515257358551025 seconds for one epoch ---
--- 0.17783761024475098 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-12.4663315]
 [ -0.       ]]
--- 0.17430424690246582 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2993.56201171875, (1376.9783, 2.4021828, 1613.8383, 0.34324566)
   validation loss 856.7749633789062, (579.4791, 0.7914921, 276.16107, 0.34324566)
decoder loss ratio: 22450.027360, decoder SINDy loss  ratio: 0.596133
--- 0.17954230308532715 seconds for one epoch ---
--- 1.6556644439697266 seconds for one epoch ---
--- 0.16868829727172852 seconds for one epoch ---
--- 1.8045446872711182 seconds for one epoch ---
--- 0.16544675827026367 seconds for one epoch ---
--- 1.7336053848266602 seconds for one epoch ---
--- 0.1891942024230957 seconds for one epoch ---
--- 1.8410377502441406 seconds for one epoch ---
--- 0.162064790725708 seconds for one epoch ---
--- 1.741415023803711 seconds for one epoch ---
--- 0.17864775657653809 seconds for one epoch ---
--- 1.6828670501708984 seconds for one epoch ---
--- 0.16756439208984375 seconds for one epoch ---
--- 1.701284408569336 seconds for one epoch ---
--- 0.16996097564697266 seconds for one epoch ---
--- 1.786665916442871 seconds for one epoch ---
--- 0.17325353622436523 seconds for one epoch ---
--- 1.710430383682251 seconds for one epoch ---
--- 0.1952345371246338 seconds for one epoch ---
--- 1.6628353595733643 seconds for one epoch ---
--- 0.15358400344848633 seconds for one epoch ---
--- 1.8361124992370605 seconds for one epoch ---
--- 0.17918968200683594 seconds for one epoch ---
--- 1.7136304378509521 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.557974]
 [ -0.      ]]
--- 0.18411827087402344 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3594.147705078125, (1490.1885, 1.1926621, 2102.4216, 0.34493166)
   validation loss 1085.862548828125, (762.22266, 0.78358376, 322.51138, 0.34493166)
decoder loss ratio: 29529.828980, decoder SINDy loss  ratio: 0.696186
--- 0.1408824920654297 seconds for one epoch ---
--- 0.17329072952270508 seconds for one epoch ---
--- 1.8053362369537354 seconds for one epoch ---
--- 0.1811199188232422 seconds for one epoch ---
--- 1.6653218269348145 seconds for one epoch ---
--- 0.17161154747009277 seconds for one epoch ---
--- 1.726501703262329 seconds for one epoch ---
--- 0.16728544235229492 seconds for one epoch ---
--- 1.850693941116333 seconds for one epoch ---
--- 0.2209022045135498 seconds for one epoch ---
--- 1.805370569229126 seconds for one epoch ---
--- 0.19179487228393555 seconds for one epoch ---
--- 1.7558023929595947 seconds for one epoch ---
--- 0.15697932243347168 seconds for one epoch ---
--- 1.6904475688934326 seconds for one epoch ---
--- 0.16150903701782227 seconds for one epoch ---
--- 1.819272756576538 seconds for one epoch ---
--- 0.17769169807434082 seconds for one epoch ---
--- 1.7111599445343018 seconds for one epoch ---
--- 0.1674058437347412 seconds for one epoch ---
--- 1.713564395904541 seconds for one epoch ---
--- 0.21175146102905273 seconds for one epoch ---
--- 1.9014883041381836 seconds for one epoch ---
--- 0.1916179656982422 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.632039]
 [  0.      ]]
--- 0.14968657493591309 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1898.8582763671875, (853.703, 0.28267843, 1044.5262, 0.34628853)
   validation loss 900.9302368164062, (608.79156, 0.8063574, 290.98602, 0.34628853)
decoder loss ratio: 23585.642134, decoder SINDy loss  ratio: 0.628134
--- 0.18036675453186035 seconds for one epoch ---
--- 1.7127840518951416 seconds for one epoch ---
--- 0.1601276397705078 seconds for one epoch ---
--- 1.9252042770385742 seconds for one epoch ---
--- 0.17417693138122559 seconds for one epoch ---
--- 1.7123878002166748 seconds for one epoch ---
--- 0.202927827835083 seconds for one epoch ---
--- 1.726438283920288 seconds for one epoch ---
--- 0.19870495796203613 seconds for one epoch ---
--- 1.8343732357025146 seconds for one epoch ---
--- 0.16579532623291016 seconds for one epoch ---
--- 1.6949377059936523 seconds for one epoch ---
--- 0.1803593635559082 seconds for one epoch ---
--- 1.7771601676940918 seconds for one epoch ---
--- 0.17516541481018066 seconds for one epoch ---
--- 1.717557668685913 seconds for one epoch ---
--- 0.15820956230163574 seconds for one epoch ---
--- 1.7151148319244385 seconds for one epoch ---
--- 0.5013523101806641 seconds for one epoch ---
--- 1.788806438446045 seconds for one epoch ---
--- 0.18214058876037598 seconds for one epoch ---
--- 1.6916277408599854 seconds for one epoch ---
--- 0.19189763069152832 seconds for one epoch ---
--- 1.7443959712982178 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.702043]
 [ -0.      ]]
--- 0.1648392677307129 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2341.265380859375, (1061.2113, 1.8113595, 1277.8954, 0.34749636)
   validation loss 865.3973999023438, (608.48755, 0.94844174, 255.61398, 0.34749636)
decoder loss ratio: 23573.864022, decoder SINDy loss  ratio: 0.551779
--- 0.18392372131347656 seconds for one epoch ---
--- 0.18662691116333008 seconds for one epoch ---
--- 1.827650547027588 seconds for one epoch ---
--- 0.16776013374328613 seconds for one epoch ---
--- 1.6923997402191162 seconds for one epoch ---
--- 0.15895915031433105 seconds for one epoch ---
--- 1.9550464153289795 seconds for one epoch ---
--- 0.19031834602355957 seconds for one epoch ---
--- 1.7436468601226807 seconds for one epoch ---
--- 0.16238880157470703 seconds for one epoch ---
--- 1.7261569499969482 seconds for one epoch ---
--- 0.18090200424194336 seconds for one epoch ---
--- 1.7867367267608643 seconds for one epoch ---
--- 0.1605532169342041 seconds for one epoch ---
--- 1.692549228668213 seconds for one epoch ---
--- 0.16585230827331543 seconds for one epoch ---
--- 1.837557315826416 seconds for one epoch ---
--- 0.16440725326538086 seconds for one epoch ---
--- 1.7084908485412598 seconds for one epoch ---
--- 0.18317627906799316 seconds for one epoch ---
--- 1.7966892719268799 seconds for one epoch ---
--- 0.18075084686279297 seconds for one epoch ---
--- 1.7304811477661133 seconds for one epoch ---
--- 0.18392539024353027 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-12.78489]
 [  0.     ]]
--- 0.1542673110961914 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2250.4365234375, (1421.6354, 1.4381963, 827.0138, 0.34910342)
   validation loss 910.8590087890625, (615.0831, 0.77871114, 294.64807, 0.34910342)
decoder loss ratio: 23829.388283, decoder SINDy loss  ratio: 0.636039
--- 0.17450761795043945 seconds for one epoch ---
--- 1.7928781509399414 seconds for one epoch ---
--- 0.17870187759399414 seconds for one epoch ---
--- 1.7733895778656006 seconds for one epoch ---
--- 0.1599419116973877 seconds for one epoch ---
--- 1.80379056930542 seconds for one epoch ---
--- 0.23032259941101074 seconds for one epoch ---
--- 1.7614595890045166 seconds for one epoch ---
--- 0.17188668251037598 seconds for one epoch ---
--- 1.8291754722595215 seconds for one epoch ---
--- 0.18038368225097656 seconds for one epoch ---
--- 1.7335410118103027 seconds for one epoch ---
--- 0.16455507278442383 seconds for one epoch ---
--- 1.826827049255371 seconds for one epoch ---
--- 0.2159881591796875 seconds for one epoch ---
--- 1.8759982585906982 seconds for one epoch ---
--- 0.22400355339050293 seconds for one epoch ---
--- 1.7683022022247314 seconds for one epoch ---
--- 0.18839168548583984 seconds for one epoch ---
--- 1.9028067588806152 seconds for one epoch ---
--- 0.17179560661315918 seconds for one epoch ---
--- 1.8212289810180664 seconds for one epoch ---
--- 0.15908551216125488 seconds for one epoch ---
--- 1.6962015628814697 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.860025]
 [  0.      ]]
--- 0.16578102111816406 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3134.55078125, (1547.9128, 0.7493107, 1585.5382, 0.35050178)
   validation loss 1060.7637939453125, (726.0715, 0.7334251, 333.60852, 0.35050178)
decoder loss ratio: 28129.269347, decoder SINDy loss  ratio: 0.720141
THRESHOLDING: 1 active coefficients
--- 0.15212416648864746 seconds for one epoch ---
--- 0.18224334716796875 seconds for one epoch ---
--- 1.799999475479126 seconds for one epoch ---
--- 0.1787407398223877 seconds for one epoch ---
--- 1.7189056873321533 seconds for one epoch ---
--- 0.1587510108947754 seconds for one epoch ---
--- 1.7421393394470215 seconds for one epoch ---
--- 0.17101097106933594 seconds for one epoch ---
--- 1.7221767902374268 seconds for one epoch ---
--- 0.16785025596618652 seconds for one epoch ---
--- 1.9129104614257812 seconds for one epoch ---
--- 0.1775801181793213 seconds for one epoch ---
--- 1.8144094944000244 seconds for one epoch ---
--- 0.193558931350708 seconds for one epoch ---
--- 1.711778163909912 seconds for one epoch ---
--- 0.18584227561950684 seconds for one epoch ---
--- 1.8041412830352783 seconds for one epoch ---
--- 0.1823439598083496 seconds for one epoch ---
--- 1.7905702590942383 seconds for one epoch ---
--- 0.16534209251403809 seconds for one epoch ---
--- 1.8667948246002197 seconds for one epoch ---
--- 0.19282770156860352 seconds for one epoch ---
--- 1.8227710723876953 seconds for one epoch ---
--- 0.20128393173217773 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.932369]
 [  0.      ]]
--- 0.1400136947631836 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3306.625244140625, (1667.6611, 1.2908151, 1637.3215, 0.3517703)
   validation loss 935.2145385742188, (637.86914, 0.81112486, 296.18256, 0.3517703)
decoder loss ratio: 24712.157897, decoder SINDy loss  ratio: 0.639352
--- 0.16210436820983887 seconds for one epoch ---
--- 1.866913080215454 seconds for one epoch ---
--- 0.20383810997009277 seconds for one epoch ---
--- 1.7523508071899414 seconds for one epoch ---
--- 0.1909334659576416 seconds for one epoch ---
--- 1.7716972827911377 seconds for one epoch ---
--- 0.17598271369934082 seconds for one epoch ---
--- 1.914607048034668 seconds for one epoch ---
--- 0.19267559051513672 seconds for one epoch ---
--- 1.758636713027954 seconds for one epoch ---
--- 0.19321608543395996 seconds for one epoch ---
--- 1.735672950744629 seconds for one epoch ---
--- 0.18135523796081543 seconds for one epoch ---
--- 1.8163001537322998 seconds for one epoch ---
--- 0.16334223747253418 seconds for one epoch ---
--- 1.8389155864715576 seconds for one epoch ---
--- 0.1682591438293457 seconds for one epoch ---
--- 1.8151507377624512 seconds for one epoch ---
--- 0.15863776206970215 seconds for one epoch ---
--- 1.817871332168579 seconds for one epoch ---
--- 0.19273686408996582 seconds for one epoch ---
--- 1.7839469909667969 seconds for one epoch ---
--- 0.18364477157592773 seconds for one epoch ---
--- 1.8530917167663574 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.006112]
 [ -0.      ]]
--- 0.16417908668518066 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2733.801513671875, (1176.7148, 1.3271121, 1555.4064, 0.35321498)
   validation loss 979.022216796875, (703.0032, 0.84842575, 274.81738, 0.35321498)
decoder loss ratio: 27235.563421, decoder SINDy loss  ratio: 0.593232
--- 0.1450634002685547 seconds for one epoch ---
--- 0.1807706356048584 seconds for one epoch ---
--- 1.7816457748413086 seconds for one epoch ---
--- 0.1743016242980957 seconds for one epoch ---
--- 1.7759838104248047 seconds for one epoch ---
--- 0.19328546524047852 seconds for one epoch ---
--- 1.9379971027374268 seconds for one epoch ---
--- 0.15648818016052246 seconds for one epoch ---
--- 1.7951107025146484 seconds for one epoch ---
--- 0.17168974876403809 seconds for one epoch ---
--- 1.8378973007202148 seconds for one epoch ---
--- 0.18018054962158203 seconds for one epoch ---
--- 1.890845537185669 seconds for one epoch ---
--- 0.17740583419799805 seconds for one epoch ---
--- 1.8456687927246094 seconds for one epoch ---
--- 0.16370606422424316 seconds for one epoch ---
--- 1.8325831890106201 seconds for one epoch ---
--- 0.16889667510986328 seconds for one epoch ---
--- 1.839869737625122 seconds for one epoch ---
--- 0.16291499137878418 seconds for one epoch ---
--- 1.8090620040893555 seconds for one epoch ---
--- 0.17854857444763184 seconds for one epoch ---
--- 1.7510311603546143 seconds for one epoch ---
--- 0.1560971736907959 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.073278]
 [  0.      ]]
--- 0.1381981372833252 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2783.83251953125, (1118.6854, 1.5489843, 1663.2437, 0.3545125)
   validation loss 824.5650024414062, (567.44684, 0.86439645, 255.8993, 0.3545125)
decoder loss ratio: 21983.875650, decoder SINDy loss  ratio: 0.552395
--- 0.20565485954284668 seconds for one epoch ---
--- 1.881561517715454 seconds for one epoch ---
--- 0.19211268424987793 seconds for one epoch ---
--- 1.8075013160705566 seconds for one epoch ---
--- 0.1920032501220703 seconds for one epoch ---
--- 1.7674694061279297 seconds for one epoch ---
--- 0.18822145462036133 seconds for one epoch ---
--- 1.886704683303833 seconds for one epoch ---
--- 0.185699462890625 seconds for one epoch ---
--- 1.9327454566955566 seconds for one epoch ---
--- 0.16921281814575195 seconds for one epoch ---
--- 1.9742183685302734 seconds for one epoch ---
--- 0.20383214950561523 seconds for one epoch ---
--- 1.9768493175506592 seconds for one epoch ---
--- 0.19822192192077637 seconds for one epoch ---
--- 1.9265632629394531 seconds for one epoch ---
--- 0.20192289352416992 seconds for one epoch ---
--- 1.775367021560669 seconds for one epoch ---
--- 0.1913754940032959 seconds for one epoch ---
--- 1.88161301612854 seconds for one epoch ---
--- 0.18738532066345215 seconds for one epoch ---
--- 1.8424921035766602 seconds for one epoch ---
--- 0.1638484001159668 seconds for one epoch ---
--- 1.835357666015625 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.138803]
 [ -0.      ]]
--- 0.17859530448913574 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2985.57373046875, (1232.4696, 1.5288205, 1751.2196, 0.3556799)
   validation loss 1355.96728515625, (1065.6738, 0.87263036, 289.06512, 0.3556799)
decoder loss ratio: 41286.054193, decoder SINDy loss  ratio: 0.623988
--- 0.13738322257995605 seconds for one epoch ---
--- 0.16923069953918457 seconds for one epoch ---
--- 1.8368563652038574 seconds for one epoch ---
--- 0.17014718055725098 seconds for one epoch ---
--- 1.9866266250610352 seconds for one epoch ---
--- 0.17962265014648438 seconds for one epoch ---
--- 2.070664167404175 seconds for one epoch ---
--- 0.15671944618225098 seconds for one epoch ---
--- 1.786576509475708 seconds for one epoch ---
--- 0.19613385200500488 seconds for one epoch ---
--- 1.8810203075408936 seconds for one epoch ---
--- 0.17363905906677246 seconds for one epoch ---
--- 1.830925703048706 seconds for one epoch ---
--- 0.1658940315246582 seconds for one epoch ---
--- 1.807098150253296 seconds for one epoch ---
--- 0.1618483066558838 seconds for one epoch ---
--- 1.9613146781921387 seconds for one epoch ---
--- 0.2233259677886963 seconds for one epoch ---
--- 1.8081722259521484 seconds for one epoch ---
--- 0.1831657886505127 seconds for one epoch ---
--- 1.9176874160766602 seconds for one epoch ---
--- 0.16528105735778809 seconds for one epoch ---
--- 1.8494625091552734 seconds for one epoch ---
--- 0.18278980255126953 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.196113]
 [ -0.      ]]
--- 0.14902400970458984 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3649.3203125, (1321.3018, 1.6724824, 2325.989, 0.35684645)
   validation loss 1177.1484375, (854.8081, 0.86996275, 321.1136, 0.35684645)
decoder loss ratio: 33116.750018, decoder SINDy loss  ratio: 0.693169
--- 0.18196415901184082 seconds for one epoch ---
--- 1.9930977821350098 seconds for one epoch ---
--- 0.17689943313598633 seconds for one epoch ---
--- 1.8024630546569824 seconds for one epoch ---
--- 0.16080427169799805 seconds for one epoch ---
--- 1.848930835723877 seconds for one epoch ---
--- 0.1826171875 seconds for one epoch ---
--- 1.93430495262146 seconds for one epoch ---
--- 0.2045881748199463 seconds for one epoch ---
--- 1.7871007919311523 seconds for one epoch ---
--- 0.1764674186706543 seconds for one epoch ---
--- 1.8679661750793457 seconds for one epoch ---
--- 0.16515684127807617 seconds for one epoch ---
--- 1.8903791904449463 seconds for one epoch ---
--- 0.16387701034545898 seconds for one epoch ---
--- 1.8552844524383545 seconds for one epoch ---
--- 0.16610145568847656 seconds for one epoch ---
--- 1.9289987087249756 seconds for one epoch ---
--- 0.1861426830291748 seconds for one epoch ---
--- 1.87969970703125 seconds for one epoch ---
--- 0.21679949760437012 seconds for one epoch ---
--- 1.8662149906158447 seconds for one epoch ---
--- 0.1689920425415039 seconds for one epoch ---
--- 1.8648419380187988 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.259217]
 [  0.      ]]
--- 0.17673325538635254 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3238.815673828125, (1968.7151, 0.6787109, 1269.0637, 0.3580331)
   validation loss 808.5023193359375, (541.8839, 0.89413404, 265.36627, 0.3580331)
decoder loss ratio: 20993.523469, decoder SINDy loss  ratio: 0.572830
--- 0.1679670810699463 seconds for one epoch ---
--- 0.18312716484069824 seconds for one epoch ---
--- 1.8261635303497314 seconds for one epoch ---
--- 0.18823862075805664 seconds for one epoch ---
--- 1.9290499687194824 seconds for one epoch ---
--- 0.1741495132446289 seconds for one epoch ---
--- 1.8013949394226074 seconds for one epoch ---
--- 0.18367362022399902 seconds for one epoch ---
--- 1.869248867034912 seconds for one epoch ---
--- 0.15896058082580566 seconds for one epoch ---
--- 1.8592517375946045 seconds for one epoch ---
--- 0.20302724838256836 seconds for one epoch ---
--- 1.9167606830596924 seconds for one epoch ---
--- 0.1774277687072754 seconds for one epoch ---
--- 1.7881700992584229 seconds for one epoch ---
--- 0.16982531547546387 seconds for one epoch ---
--- 1.8524422645568848 seconds for one epoch ---
--- 0.1509556770324707 seconds for one epoch ---
--- 1.8658983707427979 seconds for one epoch ---
--- 0.22903156280517578 seconds for one epoch ---
--- 1.8304829597473145 seconds for one epoch ---
--- 0.15805554389953613 seconds for one epoch ---
--- 1.9751098155975342 seconds for one epoch ---
--- 0.17223596572875977 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.319694]
 [ -0.      ]]
--- 0.14945077896118164 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2646.89013671875, (1286.6561, 5.284511, 1354.5902, 0.3592572)
   validation loss 778.7012329101562, (492.33456, 1.0080286, 284.9994, 0.3592572)
decoder loss ratio: 19073.895748, decoder SINDy loss  ratio: 0.615211
--- 0.19207763671875 seconds for one epoch ---
--- 1.8543627262115479 seconds for one epoch ---
--- 0.16022062301635742 seconds for one epoch ---
--- 1.9183413982391357 seconds for one epoch ---
--- 0.17841577529907227 seconds for one epoch ---
--- 1.8234083652496338 seconds for one epoch ---
--- 0.16296100616455078 seconds for one epoch ---
--- 1.9050593376159668 seconds for one epoch ---
--- 0.17464900016784668 seconds for one epoch ---
--- 1.8163998126983643 seconds for one epoch ---
--- 0.17155098915100098 seconds for one epoch ---
--- 1.9874413013458252 seconds for one epoch ---
--- 0.19419074058532715 seconds for one epoch ---
--- 1.957585334777832 seconds for one epoch ---
--- 0.1971290111541748 seconds for one epoch ---
--- 1.820547103881836 seconds for one epoch ---
--- 0.18486833572387695 seconds for one epoch ---
--- 2.014195203781128 seconds for one epoch ---
--- 0.19480395317077637 seconds for one epoch ---
--- 1.8905394077301025 seconds for one epoch ---
--- 0.16392064094543457 seconds for one epoch ---
--- 1.8797595500946045 seconds for one epoch ---
--- 0.1806492805480957 seconds for one epoch ---
--- 2.0803205966949463 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.387655]
 [  0.      ]]
--- 0.22103357315063477 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1919.951171875, (765.7847, 1.9256957, 1151.8801, 0.36058575)
   validation loss 1076.1617431640625, (782.8144, 0.9804093, 292.00638, 0.36058575)
decoder loss ratio: 30327.588575, decoder SINDy loss  ratio: 0.630337
--- 0.1368732452392578 seconds for one epoch ---
--- 0.1817483901977539 seconds for one epoch ---
--- 1.9466826915740967 seconds for one epoch ---
--- 0.1920633316040039 seconds for one epoch ---
--- 1.7862465381622314 seconds for one epoch ---
--- 0.18315553665161133 seconds for one epoch ---
--- 1.8550174236297607 seconds for one epoch ---
--- 0.17890334129333496 seconds for one epoch ---
--- 2.0393762588500977 seconds for one epoch ---
--- 0.16723394393920898 seconds for one epoch ---
--- 1.9272851943969727 seconds for one epoch ---
--- 0.20721077919006348 seconds for one epoch ---
--- 2.006052255630493 seconds for one epoch ---
--- 0.1951889991760254 seconds for one epoch ---
--- 1.8610851764678955 seconds for one epoch ---
--- 0.16497039794921875 seconds for one epoch ---
--- 1.9065332412719727 seconds for one epoch ---
--- 0.2109687328338623 seconds for one epoch ---
--- 1.895369052886963 seconds for one epoch ---
--- 0.18157076835632324 seconds for one epoch ---
--- 1.988983392715454 seconds for one epoch ---
--- 0.18071365356445312 seconds for one epoch ---
--- 1.8415403366088867 seconds for one epoch ---
--- 0.17546653747558594 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.447529]
 [  0.      ]]
--- 0.16362833976745605 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1773.9171142578125, (999.46405, 0.48998368, 773.6014, 0.3617193)
   validation loss 773.150146484375, (501.92578, 0.99029624, 269.8724, 0.3617193)
decoder loss ratio: 19445.476147, decoder SINDy loss  ratio: 0.582558
--- 0.23274612426757812 seconds for one epoch ---
--- 1.8677663803100586 seconds for one epoch ---
--- 0.17564797401428223 seconds for one epoch ---
--- 1.8862385749816895 seconds for one epoch ---
--- 0.17815017700195312 seconds for one epoch ---
--- 1.9112868309020996 seconds for one epoch ---
--- 0.17131447792053223 seconds for one epoch ---
--- 1.8616430759429932 seconds for one epoch ---
--- 0.1659717559814453 seconds for one epoch ---
--- 1.8800909519195557 seconds for one epoch ---
--- 0.20402836799621582 seconds for one epoch ---
--- 1.8787202835083008 seconds for one epoch ---
--- 0.1736903190612793 seconds for one epoch ---
--- 1.9350290298461914 seconds for one epoch ---
--- 0.17498445510864258 seconds for one epoch ---
--- 2.141522169113159 seconds for one epoch ---
--- 0.15972113609313965 seconds for one epoch ---
--- 1.893282175064087 seconds for one epoch ---
--- 0.2116379737854004 seconds for one epoch ---
--- 1.9542324542999268 seconds for one epoch ---
--- 0.18983888626098633 seconds for one epoch ---
--- 1.9083023071289062 seconds for one epoch ---
--- 0.18520379066467285 seconds for one epoch ---
--- 1.904280424118042 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.509278]
 [  0.      ]]
--- 0.18383550643920898 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2080.41796875, (913.5423, 0.9438453, 1165.569, 0.3629148)
   validation loss 999.515869140625, (698.87805, 0.8695375, 299.40533, 0.3629148)
decoder loss ratio: 27075.749031, decoder SINDy loss  ratio: 0.646309
--- 0.14778399467468262 seconds for one epoch ---
--- 0.16504812240600586 seconds for one epoch ---
--- 1.8858284950256348 seconds for one epoch ---
--- 0.19620227813720703 seconds for one epoch ---
--- 1.8192031383514404 seconds for one epoch ---
--- 0.15830397605895996 seconds for one epoch ---
--- 1.9968616962432861 seconds for one epoch ---
--- 0.18441176414489746 seconds for one epoch ---
--- 1.8529601097106934 seconds for one epoch ---
--- 0.17584967613220215 seconds for one epoch ---
--- 1.8888840675354004 seconds for one epoch ---
--- 0.19550013542175293 seconds for one epoch ---
--- 1.979637622833252 seconds for one epoch ---
--- 0.18867754936218262 seconds for one epoch ---
--- 1.8963720798492432 seconds for one epoch ---
--- 0.16746115684509277 seconds for one epoch ---
--- 1.9760262966156006 seconds for one epoch ---
--- 0.18967175483703613 seconds for one epoch ---
--- 2.0271036624908447 seconds for one epoch ---
--- 0.16775178909301758 seconds for one epoch ---
--- 1.9143564701080322 seconds for one epoch ---
--- 0.19224238395690918 seconds for one epoch ---
--- 1.9138686656951904 seconds for one epoch ---
--- 0.17412853240966797 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.580333]
 [ -0.      ]]
--- 0.13774800300598145 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2421.05126953125, (757.645, 1.1101446, 1661.9318, 0.3643497)
   validation loss 894.6995849609375, (594.0997, 0.9807533, 299.25476, 0.3643497)
decoder loss ratio: 23016.452634, decoder SINDy loss  ratio: 0.645983
--- 0.17912697792053223 seconds for one epoch ---
--- 1.9679443836212158 seconds for one epoch ---
--- 0.18926572799682617 seconds for one epoch ---
--- 2.0642948150634766 seconds for one epoch ---
--- 0.18268108367919922 seconds for one epoch ---
--- 1.9875812530517578 seconds for one epoch ---
--- 0.15801358222961426 seconds for one epoch ---
--- 1.9074547290802002 seconds for one epoch ---
--- 0.18336081504821777 seconds for one epoch ---
--- 2.066492795944214 seconds for one epoch ---
--- 0.15842390060424805 seconds for one epoch ---
--- 1.8818528652191162 seconds for one epoch ---
--- 0.17476630210876465 seconds for one epoch ---
--- 1.9466006755828857 seconds for one epoch ---
--- 0.1828012466430664 seconds for one epoch ---
--- 1.9022183418273926 seconds for one epoch ---
--- 0.19771933555603027 seconds for one epoch ---
--- 1.8291714191436768 seconds for one epoch ---
--- 0.18164896965026855 seconds for one epoch ---
--- 1.9390208721160889 seconds for one epoch ---
--- 0.1689465045928955 seconds for one epoch ---
--- 2.0701651573181152 seconds for one epoch ---
--- 0.1669456958770752 seconds for one epoch ---
--- 1.851715326309204 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.616625]
 [  0.      ]]
--- 0.19716238975524902 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2497.3466796875, (981.40924, 1.3142394, 1514.2583, 0.36503673)
   validation loss 789.2188110351562, (501.3386, 0.8893978, 286.62576, 0.36503673)
decoder loss ratio: 19422.727437, decoder SINDy loss  ratio: 0.618722
--- 0.1413860321044922 seconds for one epoch ---
--- 0.21645665168762207 seconds for one epoch ---
--- 2.000347852706909 seconds for one epoch ---
--- 0.17478489875793457 seconds for one epoch ---
--- 1.8791346549987793 seconds for one epoch ---
--- 0.19115900993347168 seconds for one epoch ---
--- 2.0169143676757812 seconds for one epoch ---
--- 0.17749381065368652 seconds for one epoch ---
--- 1.9305949211120605 seconds for one epoch ---
--- 0.18958425521850586 seconds for one epoch ---
--- 1.9399116039276123 seconds for one epoch ---
--- 0.2021653652191162 seconds for one epoch ---
--- 1.9403765201568604 seconds for one epoch ---
--- 0.17862343788146973 seconds for one epoch ---
--- 1.9729995727539062 seconds for one epoch ---
--- 0.1839601993560791 seconds for one epoch ---
--- 1.948840618133545 seconds for one epoch ---
--- 0.17617154121398926 seconds for one epoch ---
--- 2.042097806930542 seconds for one epoch ---
--- 0.18854665756225586 seconds for one epoch ---
--- 1.9036035537719727 seconds for one epoch ---
--- 0.19617700576782227 seconds for one epoch ---
--- 2.0879883766174316 seconds for one epoch ---
--- 0.1711733341217041 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.669144]
 [ -0.      ]]
--- 0.15327119827270508 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2701.452392578125, (1137.3429, 0.26111272, 1563.4823, 0.3660532)
   validation loss 1166.128662109375, (852.0147, 0.9316847, 312.81613, 0.3660532)
decoder loss ratio: 33008.529008, decoder SINDy loss  ratio: 0.675258
--- 0.16435980796813965 seconds for one epoch ---
--- 1.9407780170440674 seconds for one epoch ---
--- 0.1901850700378418 seconds for one epoch ---
--- 2.1617767810821533 seconds for one epoch ---
--- 0.1822805404663086 seconds for one epoch ---
--- 2.0648016929626465 seconds for one epoch ---
--- 0.18665671348571777 seconds for one epoch ---
--- 2.0062451362609863 seconds for one epoch ---
--- 0.19168353080749512 seconds for one epoch ---
--- 1.938476800918579 seconds for one epoch ---
--- 0.1674795150756836 seconds for one epoch ---
--- 1.8848519325256348 seconds for one epoch ---
--- 0.17837023735046387 seconds for one epoch ---
--- 1.9578628540039062 seconds for one epoch ---
--- 0.20432662963867188 seconds for one epoch ---
--- 2.003154993057251 seconds for one epoch ---
--- 0.1734762191772461 seconds for one epoch ---
--- 1.9531080722808838 seconds for one epoch ---
--- 0.17175030708312988 seconds for one epoch ---
--- 1.9371740818023682 seconds for one epoch ---
--- 0.18005681037902832 seconds for one epoch ---
--- 1.9772963523864746 seconds for one epoch ---
--- 0.17004179954528809 seconds for one epoch ---
--- 1.9518492221832275 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.720235]
 [ -0.      ]]
--- 0.18172526359558105 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2337.231201171875, (1200.9652, 1.1357795, 1134.7631, 0.3671123)
   validation loss 864.6757202148438, (571.77985, 0.9170247, 291.61172, 0.3671123)
decoder loss ratio: 22151.743895, decoder SINDy loss  ratio: 0.629485
--- 0.14215683937072754 seconds for one epoch ---
--- 0.17870426177978516 seconds for one epoch ---
--- 1.9438107013702393 seconds for one epoch ---
--- 0.1585698127746582 seconds for one epoch ---
--- 1.9536337852478027 seconds for one epoch ---
--- 0.16672039031982422 seconds for one epoch ---
--- 1.9737050533294678 seconds for one epoch ---
--- 0.17040681838989258 seconds for one epoch ---
--- 2.057126045227051 seconds for one epoch ---
--- 0.17623043060302734 seconds for one epoch ---
--- 1.915041208267212 seconds for one epoch ---
--- 0.16804718971252441 seconds for one epoch ---
--- 2.059169054031372 seconds for one epoch ---
--- 0.1788482666015625 seconds for one epoch ---
--- 1.9499962329864502 seconds for one epoch ---
--- 0.16144084930419922 seconds for one epoch ---
--- 1.9599649906158447 seconds for one epoch ---
--- 0.17478179931640625 seconds for one epoch ---
--- 2.035989284515381 seconds for one epoch ---
--- 0.15553903579711914 seconds for one epoch ---
--- 1.966524362564087 seconds for one epoch ---
--- 0.16631126403808594 seconds for one epoch ---
--- 1.9069225788116455 seconds for one epoch ---
--- 0.15767931938171387 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.779379]
 [  0.      ]]
--- 0.137190580368042 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3710.2158203125, (1550.0962, 4.7664204, 2154.985, 0.36826172)
   validation loss 836.6431884765625, (550.0488, 0.9215131, 285.30453, 0.36826172)
decoder loss ratio: 21309.846528, decoder SINDy loss  ratio: 0.615870
--- 0.19798517227172852 seconds for one epoch ---
--- 2.005554676055908 seconds for one epoch ---
--- 0.1563878059387207 seconds for one epoch ---
--- 1.9762790203094482 seconds for one epoch ---
--- 0.17833328247070312 seconds for one epoch ---
--- 1.9942967891693115 seconds for one epoch ---
--- 0.1621708869934082 seconds for one epoch ---
--- 2.0410122871398926 seconds for one epoch ---
--- 0.1742870807647705 seconds for one epoch ---
--- 2.0028209686279297 seconds for one epoch ---
--- 0.178741455078125 seconds for one epoch ---
--- 1.9776341915130615 seconds for one epoch ---
--- 0.18659043312072754 seconds for one epoch ---
--- 1.9590258598327637 seconds for one epoch ---
--- 0.17986226081848145 seconds for one epoch ---
--- 1.9769020080566406 seconds for one epoch ---
--- 0.1766376495361328 seconds for one epoch ---
--- 1.9561641216278076 seconds for one epoch ---
--- 0.15865421295166016 seconds for one epoch ---
--- 2.023650884628296 seconds for one epoch ---
--- 0.1931605339050293 seconds for one epoch ---
--- 1.9549553394317627 seconds for one epoch ---
--- 0.16912031173706055 seconds for one epoch ---
--- 2.3342792987823486 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.834588]
 [ -0.      ]]
--- 0.18813514709472656 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2181.811767578125, (1190.9668, 0.38838774, 990.08704, 0.36933678)
   validation loss 1043.1778564453125, (730.5075, 0.9251529, 311.37582, 0.36933678)
decoder loss ratio: 28301.129051, decoder SINDy loss  ratio: 0.672149
--- 0.15958833694458008 seconds for one epoch ---
--- 0.19067931175231934 seconds for one epoch ---
--- 1.9075894355773926 seconds for one epoch ---
--- 0.2059330940246582 seconds for one epoch ---
--- 1.9586186408996582 seconds for one epoch ---
--- 0.1909933090209961 seconds for one epoch ---
--- 2.0209150314331055 seconds for one epoch ---
--- 0.19057083129882812 seconds for one epoch ---
--- 1.8729569911956787 seconds for one epoch ---
--- 0.20133113861083984 seconds for one epoch ---
--- 2.0556797981262207 seconds for one epoch ---
--- 0.18726730346679688 seconds for one epoch ---
--- 1.9598720073699951 seconds for one epoch ---
--- 0.18474745750427246 seconds for one epoch ---
--- 1.952019453048706 seconds for one epoch ---
--- 0.211747407913208 seconds for one epoch ---
--- 2.1243739128112793 seconds for one epoch ---
--- 0.19988346099853516 seconds for one epoch ---
--- 1.958491325378418 seconds for one epoch ---
--- 0.1746673583984375 seconds for one epoch ---
--- 2.003957748413086 seconds for one epoch ---
--- 0.18195557594299316 seconds for one epoch ---
--- 2.0365283489227295 seconds for one epoch ---
--- 0.16486191749572754 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.879396]
 [  0.      ]]
--- 0.13974499702453613 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2455.42724609375, (1166.7278, 1.5366209, 1286.7927, 0.37019134)
   validation loss 823.4238891601562, (558.7442, 1.0140922, 263.2954, 0.37019134)
decoder loss ratio: 21646.720395, decoder SINDy loss  ratio: 0.568360
--- 0.1696169376373291 seconds for one epoch ---
--- 1.9284939765930176 seconds for one epoch ---
--- 0.1578199863433838 seconds for one epoch ---
--- 2.1352028846740723 seconds for one epoch ---
--- 0.16945910453796387 seconds for one epoch ---
--- 2.163761615753174 seconds for one epoch ---
--- 0.235213041305542 seconds for one epoch ---
--- 1.9351813793182373 seconds for one epoch ---
--- 0.17792677879333496 seconds for one epoch ---
--- 2.0337679386138916 seconds for one epoch ---
--- 0.17290353775024414 seconds for one epoch ---
--- 1.952815055847168 seconds for one epoch ---
--- 0.17255043983459473 seconds for one epoch ---
--- 2.0055932998657227 seconds for one epoch ---
--- 0.16682171821594238 seconds for one epoch ---
--- 2.081087827682495 seconds for one epoch ---
--- 0.165924072265625 seconds for one epoch ---
--- 2.0150034427642822 seconds for one epoch ---
--- 0.2779664993286133 seconds for one epoch ---
--- 1.9729247093200684 seconds for one epoch ---
--- 0.16638612747192383 seconds for one epoch ---
--- 1.9899206161499023 seconds for one epoch ---
--- 0.19289398193359375 seconds for one epoch ---
--- 2.0219221115112305 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.929639]
 [  0.      ]]
--- 0.16995620727539062 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1736.974609375, (833.5446, 0.31088385, 902.7477, 0.37129542)
   validation loss 943.5248413085938, (652.3819, 0.98212224, 289.78958, 0.37129542)
decoder loss ratio: 25274.407274, decoder SINDy loss  ratio: 0.625552
--- 0.22153401374816895 seconds for one epoch ---
--- 0.15938377380371094 seconds for one epoch ---
--- 1.975029706954956 seconds for one epoch ---
--- 0.19621753692626953 seconds for one epoch ---
--- 2.037597179412842 seconds for one epoch ---
--- 0.18085598945617676 seconds for one epoch ---
--- 1.9866323471069336 seconds for one epoch ---
--- 0.15562963485717773 seconds for one epoch ---
--- 2.0099294185638428 seconds for one epoch ---
--- 0.17422127723693848 seconds for one epoch ---
--- 2.0122551918029785 seconds for one epoch ---
--- 0.21204614639282227 seconds for one epoch ---
--- 2.158557653427124 seconds for one epoch ---
--- 0.17793846130371094 seconds for one epoch ---
--- 2.1278932094573975 seconds for one epoch ---
--- 0.16066718101501465 seconds for one epoch ---
--- 1.998389482498169 seconds for one epoch ---
--- 0.16170406341552734 seconds for one epoch ---
--- 2.1463887691497803 seconds for one epoch ---
--- 0.1690351963043213 seconds for one epoch ---
--- 2.107874870300293 seconds for one epoch ---
--- 0.1913461685180664 seconds for one epoch ---
--- 1.9492099285125732 seconds for one epoch ---
--- 0.17710185050964355 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.979396]
 [  0.      ]]
--- 0.14006614685058594 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2415.098876953125, (977.589, 2.7333095, 1434.4043, 0.3723254)
   validation loss 1010.8070068359375, (707.02545, 1.0095581, 302.39966, 0.3723254)
decoder loss ratio: 27391.393447, decoder SINDy loss  ratio: 0.652772
--- 0.17406320571899414 seconds for one epoch ---
--- 2.06620454788208 seconds for one epoch ---
--- 0.1886754035949707 seconds for one epoch ---
--- 2.0013623237609863 seconds for one epoch ---
--- 0.17678475379943848 seconds for one epoch ---
--- 2.0163161754608154 seconds for one epoch ---
--- 0.19128656387329102 seconds for one epoch ---
--- 2.0479588508605957 seconds for one epoch ---
--- 0.1706714630126953 seconds for one epoch ---
--- 2.012582302093506 seconds for one epoch ---
--- 0.18828201293945312 seconds for one epoch ---
--- 2.069791078567505 seconds for one epoch ---
--- 0.16583871841430664 seconds for one epoch ---
--- 2.155167579650879 seconds for one epoch ---
--- 0.15846896171569824 seconds for one epoch ---
--- 2.0840601921081543 seconds for one epoch ---
--- 0.17417407035827637 seconds for one epoch ---
--- 1.9964938163757324 seconds for one epoch ---
--- 0.16658401489257812 seconds for one epoch ---
--- 2.053008556365967 seconds for one epoch ---
--- 0.17189764976501465 seconds for one epoch ---
--- 2.04231595993042 seconds for one epoch ---
--- 0.17463397979736328 seconds for one epoch ---
--- 2.119626045227051 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.028892]
 [ -0.      ]]
--- 0.18052077293395996 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2047.245361328125, (1035.97, 1.3414751, 1009.5607, 0.37329412)
   validation loss 835.5589599609375, (558.6887, 0.97704, 275.51993, 0.37329412)
decoder loss ratio: 21644.570966, decoder SINDy loss  ratio: 0.594749
THRESHOLDING: 1 active coefficients
--- 1.949164628982544 seconds for one epoch ---
--- 0.21260762214660645 seconds for one epoch ---
--- 1.9881930351257324 seconds for one epoch ---
--- 0.17470121383666992 seconds for one epoch ---
--- 1.9125282764434814 seconds for one epoch ---
--- 0.18600177764892578 seconds for one epoch ---
--- 2.0593149662017822 seconds for one epoch ---
--- 0.1923813819885254 seconds for one epoch ---
--- 2.069261074066162 seconds for one epoch ---
--- 0.18552064895629883 seconds for one epoch ---
--- 2.092057466506958 seconds for one epoch ---
--- 0.156419038772583 seconds for one epoch ---
--- 2.0870556831359863 seconds for one epoch ---
--- 0.18785357475280762 seconds for one epoch ---
--- 2.1659786701202393 seconds for one epoch ---
--- 0.20464539527893066 seconds for one epoch ---
--- 2.0193302631378174 seconds for one epoch ---
--- 0.21582722663879395 seconds for one epoch ---
--- 1.9996767044067383 seconds for one epoch ---
--- 0.1690387725830078 seconds for one epoch ---
--- 2.1115734577178955 seconds for one epoch ---
--- 0.17403173446655273 seconds for one epoch ---
--- 2.133096218109131 seconds for one epoch ---
--- 0.20015358924865723 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.072855]
 [  0.      ]]
--- 0.12975406646728516 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2967.690185546875, (1235.958, 0.48239604, 1730.8756, 0.37422395)
   validation loss 911.1904907226562, (631.171, 1.0431386, 278.60214, 0.37422395)
decoder loss ratio: 24452.661096, decoder SINDy loss  ratio: 0.601402
--- 0.17653203010559082 seconds for one epoch ---
--- 2.063584327697754 seconds for one epoch ---
--- 0.15464186668395996 seconds for one epoch ---
--- 2.2064778804779053 seconds for one epoch ---
--- 0.18205547332763672 seconds for one epoch ---
--- 2.081897258758545 seconds for one epoch ---
--- 0.1647028923034668 seconds for one epoch ---
--- 2.0580902099609375 seconds for one epoch ---
--- 0.19114255905151367 seconds for one epoch ---
--- 2.049377918243408 seconds for one epoch ---
--- 0.18062472343444824 seconds for one epoch ---
--- 2.167711019515991 seconds for one epoch ---
--- 0.19065070152282715 seconds for one epoch ---
--- 2.011875867843628 seconds for one epoch ---
--- 0.1658482551574707 seconds for one epoch ---
--- 2.0427918434143066 seconds for one epoch ---
--- 0.18976974487304688 seconds for one epoch ---
--- 2.1223959922790527 seconds for one epoch ---
--- 0.17021536827087402 seconds for one epoch ---
--- 2.0789456367492676 seconds for one epoch ---
--- 0.1803269386291504 seconds for one epoch ---
--- 2.03897762298584 seconds for one epoch ---
--- 0.17348575592041016 seconds for one epoch ---
--- 2.2359743118286133 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.119103]
 [ -0.      ]]
--- 0.16986513137817383 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2796.160888671875, (1187.4319, 1.077297, 1607.2764, 0.375141)
   validation loss 1001.854248046875, (707.5024, 1.1026927, 292.87402, 0.375141)
decoder loss ratio: 27409.870494, decoder SINDy loss  ratio: 0.632210
--- 0.2285010814666748 seconds for one epoch ---
--- 0.190751314163208 seconds for one epoch ---
--- 2.117487668991089 seconds for one epoch ---
--- 0.16607427597045898 seconds for one epoch ---
--- 2.1740329265594482 seconds for one epoch ---
--- 0.24305009841918945 seconds for one epoch ---
--- 2.049844980239868 seconds for one epoch ---
--- 0.19951748847961426 seconds for one epoch ---
--- 2.0884664058685303 seconds for one epoch ---
--- 0.1683356761932373 seconds for one epoch ---
--- 2.07454514503479 seconds for one epoch ---
--- 0.17977595329284668 seconds for one epoch ---
--- 2.1750009059906006 seconds for one epoch ---
--- 0.17684173583984375 seconds for one epoch ---
--- 2.0389974117279053 seconds for one epoch ---
--- 0.16790175437927246 seconds for one epoch ---
--- 2.0448622703552246 seconds for one epoch ---
--- 0.16904401779174805 seconds for one epoch ---
--- 2.177337646484375 seconds for one epoch ---
--- 0.19478845596313477 seconds for one epoch ---
--- 2.2382850646972656 seconds for one epoch ---
--- 0.20906901359558105 seconds for one epoch ---
--- 2.07633638381958 seconds for one epoch ---
--- 0.17089390754699707 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.159658]
 [ -0.      ]]
--- 0.15013599395751953 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3844.95703125, (1206.1082, 3.6362855, 2634.8367, 0.37599277)
   validation loss 825.3629150390625, (541.48395, 1.1026607, 282.40036, 0.37599277)
decoder loss ratio: 20978.028193, decoder SINDy loss  ratio: 0.609601
--- 0.22097516059875488 seconds for one epoch ---
--- 2.0565946102142334 seconds for one epoch ---
--- 0.18492794036865234 seconds for one epoch ---
--- 2.074977397918701 seconds for one epoch ---
--- 0.16220879554748535 seconds for one epoch ---
--- 2.109940528869629 seconds for one epoch ---
--- 0.1575624942779541 seconds for one epoch ---
--- 2.2253620624542236 seconds for one epoch ---
--- 0.17151474952697754 seconds for one epoch ---
--- 2.116647243499756 seconds for one epoch ---
--- 0.17615532875061035 seconds for one epoch ---
--- 2.27178955078125 seconds for one epoch ---
--- 0.2831737995147705 seconds for one epoch ---
--- 2.05894136428833 seconds for one epoch ---
--- 0.1765751838684082 seconds for one epoch ---
--- 2.0695152282714844 seconds for one epoch ---
--- 0.17724013328552246 seconds for one epoch ---
--- 2.1765072345733643 seconds for one epoch ---
--- 0.1736598014831543 seconds for one epoch ---
--- 2.299175977706909 seconds for one epoch ---
--- 0.18356704711914062 seconds for one epoch ---
--- 2.2366294860839844 seconds for one epoch ---
--- 0.20922231674194336 seconds for one epoch ---
--- 2.1292879581451416 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.199936]
 [  0.      ]]
--- 0.21055150032043457 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1557.8389892578125, (835.0356, 1.0557721, 721.3708, 0.37681365)
   validation loss 1027.580322265625, (715.8048, 1.0409455, 310.35773, 0.37681365)
decoder loss ratio: 27731.521015, decoder SINDy loss  ratio: 0.669951
--- 0.15377020835876465 seconds for one epoch ---
--- 0.19127321243286133 seconds for one epoch ---
--- 2.1587862968444824 seconds for one epoch ---
--- 0.179091215133667 seconds for one epoch ---
--- 2.156029462814331 seconds for one epoch ---
--- 0.17822980880737305 seconds for one epoch ---
--- 2.1114678382873535 seconds for one epoch ---
--- 0.19084787368774414 seconds for one epoch ---
--- 2.1276915073394775 seconds for one epoch ---
--- 0.20302200317382812 seconds for one epoch ---
--- 2.118077516555786 seconds for one epoch ---
--- 0.19598889350891113 seconds for one epoch ---
--- 2.072723865509033 seconds for one epoch ---
--- 0.1725449562072754 seconds for one epoch ---
--- 2.0584473609924316 seconds for one epoch ---
--- 0.17989039421081543 seconds for one epoch ---
--- 2.1096670627593994 seconds for one epoch ---
--- 0.17655563354492188 seconds for one epoch ---
--- 2.0767874717712402 seconds for one epoch ---
--- 0.16998910903930664 seconds for one epoch ---
--- 2.125150203704834 seconds for one epoch ---
--- 0.1858539581298828 seconds for one epoch ---
--- 2.137833833694458 seconds for one epoch ---
--- 0.2814505100250244 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.247865]
 [ -0.      ]]
--- 0.15073180198669434 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2469.7861328125, (967.99316, 0.76143306, 1500.6536, 0.37783355)
   validation loss 1146.7630615234375, (808.4059, 1.0385365, 336.94086, 0.37783355)
decoder loss ratio: 31319.047392, decoder SINDy loss  ratio: 0.727334
--- 0.228790283203125 seconds for one epoch ---
--- 2.050081729888916 seconds for one epoch ---
--- 0.2259049415588379 seconds for one epoch ---
--- 2.204385757446289 seconds for one epoch ---
--- 0.20201706886291504 seconds for one epoch ---
--- 2.092515230178833 seconds for one epoch ---
--- 0.19486474990844727 seconds for one epoch ---
--- 2.206868886947632 seconds for one epoch ---
--- 0.19643783569335938 seconds for one epoch ---
--- 2.156766653060913 seconds for one epoch ---
--- 0.1819770336151123 seconds for one epoch ---
--- 2.1630148887634277 seconds for one epoch ---
--- 0.19033098220825195 seconds for one epoch ---
--- 2.1854536533355713 seconds for one epoch ---
--- 0.1606147289276123 seconds for one epoch ---
--- 2.162261486053467 seconds for one epoch ---
--- 0.1758558750152588 seconds for one epoch ---
--- 2.2140684127807617 seconds for one epoch ---
--- 0.19834256172180176 seconds for one epoch ---
--- 2.1533071994781494 seconds for one epoch ---
--- 0.18507909774780273 seconds for one epoch ---
--- 2.1464734077453613 seconds for one epoch ---
--- 0.1915264129638672 seconds for one epoch ---
--- 2.075730323791504 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.282414]
 [  0.      ]]
--- 0.1753864288330078 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2397.104736328125, (733.9577, 0.619361, 1662.1493, 0.3785224)
   validation loss 1127.633056640625, (816.8001, 1.1220518, 309.33234, 0.3785224)
decoder loss ratio: 31644.254283, decoder SINDy loss  ratio: 0.667737
--- 0.14944005012512207 seconds for one epoch ---
--- 0.17063474655151367 seconds for one epoch ---
--- 2.0714917182922363 seconds for one epoch ---
--- 0.17026853561401367 seconds for one epoch ---
--- 2.1349565982818604 seconds for one epoch ---
--- 0.15550947189331055 seconds for one epoch ---
--- 2.1833131313323975 seconds for one epoch ---
--- 0.1608262062072754 seconds for one epoch ---
--- 2.248594284057617 seconds for one epoch ---
--- 0.1747910976409912 seconds for one epoch ---
--- 2.2176060676574707 seconds for one epoch ---
--- 0.20149874687194824 seconds for one epoch ---
--- 2.1120553016662598 seconds for one epoch ---
--- 0.18322539329528809 seconds for one epoch ---
--- 2.135096549987793 seconds for one epoch ---
--- 0.19199800491333008 seconds for one epoch ---
--- 2.065415143966675 seconds for one epoch ---
--- 0.1768815517425537 seconds for one epoch ---
--- 2.2194936275482178 seconds for one epoch ---
--- 0.16478943824768066 seconds for one epoch ---
--- 2.1994216442108154 seconds for one epoch ---
--- 0.192030668258667 seconds for one epoch ---
--- 2.212998151779175 seconds for one epoch ---
--- 0.19906163215637207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.321932]
 [  0.      ]]
--- 0.17475438117980957 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3334.20068359375, (1709.339, 0.70059484, 1623.7819, 0.3793532)
   validation loss 840.0697631835938, (570.24615, 1.1657039, 268.27853, 0.3793532)
decoder loss ratio: 22092.326027, decoder SINDy loss  ratio: 0.579117
--- 0.21924757957458496 seconds for one epoch ---
--- 2.244426727294922 seconds for one epoch ---
--- 0.1973285675048828 seconds for one epoch ---
--- 2.179945707321167 seconds for one epoch ---
--- 0.17916345596313477 seconds for one epoch ---
--- 2.106778144836426 seconds for one epoch ---
--- 0.15704965591430664 seconds for one epoch ---
--- 2.117567539215088 seconds for one epoch ---
--- 0.20288324356079102 seconds for one epoch ---
--- 2.1984877586364746 seconds for one epoch ---
--- 0.17871809005737305 seconds for one epoch ---
--- 2.1460659503936768 seconds for one epoch ---
--- 0.1851215362548828 seconds for one epoch ---
--- 2.2688276767730713 seconds for one epoch ---
--- 0.1674809455871582 seconds for one epoch ---
--- 2.0885486602783203 seconds for one epoch ---
--- 0.16910219192504883 seconds for one epoch ---
--- 2.3268141746520996 seconds for one epoch ---
--- 0.165848970413208 seconds for one epoch ---
--- 2.212958574295044 seconds for one epoch ---
--- 0.17844557762145996 seconds for one epoch ---
--- 2.302424430847168 seconds for one epoch ---
--- 0.18114995956420898 seconds for one epoch ---
--- 2.123774290084839 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-14.3501]
 [  0.    ]]
--- 0.19263505935668945 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2100.3203125, (1051.8618, 1.3286787, 1046.75, 0.37996012)
   validation loss 878.4931030273438, (571.47766, 1.0856386, 305.54984, 0.37996012)
decoder loss ratio: 22140.036721, decoder SINDy loss  ratio: 0.659572
--- 0.14734196662902832 seconds for one epoch ---
--- 0.17130017280578613 seconds for one epoch ---
--- 2.167271137237549 seconds for one epoch ---
--- 0.17629790306091309 seconds for one epoch ---
--- 2.197345495223999 seconds for one epoch ---
--- 0.1820073127746582 seconds for one epoch ---
--- 2.296783924102783 seconds for one epoch ---
--- 0.18254637718200684 seconds for one epoch ---
--- 2.1349599361419678 seconds for one epoch ---
--- 0.16509699821472168 seconds for one epoch ---
--- 2.212777614593506 seconds for one epoch ---
--- 0.16811490058898926 seconds for one epoch ---
--- 2.0936880111694336 seconds for one epoch ---
--- 0.16838502883911133 seconds for one epoch ---
--- 2.2326180934906006 seconds for one epoch ---
--- 0.1688070297241211 seconds for one epoch ---
--- 2.1976563930511475 seconds for one epoch ---
--- 0.21289396286010742 seconds for one epoch ---
--- 2.0945310592651367 seconds for one epoch ---
--- 0.15969419479370117 seconds for one epoch ---
--- 2.3043038845062256 seconds for one epoch ---
--- 0.20118999481201172 seconds for one epoch ---
--- 2.1162893772125244 seconds for one epoch ---
--- 0.17812204360961914 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.381702]
 [ -0.      ]]
--- 0.14188170433044434 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4420.1787109375, (1533.0927, 0.99870664, 2885.707, 0.38059416)
   validation loss 794.782958984375, (528.54944, 1.1705899, 264.68228, 0.38059416)
decoder loss ratio: 20476.922849, decoder SINDy loss  ratio: 0.571354
--- 0.18474411964416504 seconds for one epoch ---
--- 2.2662763595581055 seconds for one epoch ---
--- 0.19924068450927734 seconds for one epoch ---
--- 2.19006085395813 seconds for one epoch ---
--- 0.17726993560791016 seconds for one epoch ---
--- 2.1936557292938232 seconds for one epoch ---
--- 0.19537639617919922 seconds for one epoch ---
--- 2.0960562229156494 seconds for one epoch ---
--- 0.16017842292785645 seconds for one epoch ---
--- 2.1340725421905518 seconds for one epoch ---
--- 0.18963050842285156 seconds for one epoch ---
--- 2.382805824279785 seconds for one epoch ---
--- 0.15918588638305664 seconds for one epoch ---
--- 2.288384199142456 seconds for one epoch ---
--- 0.18570423126220703 seconds for one epoch ---
--- 2.1262879371643066 seconds for one epoch ---
--- 0.1636338233947754 seconds for one epoch ---
--- 2.1944189071655273 seconds for one epoch ---
--- 0.18093061447143555 seconds for one epoch ---
--- 2.4083309173583984 seconds for one epoch ---
--- 0.16624021530151367 seconds for one epoch ---
--- 2.4095468521118164 seconds for one epoch ---
--- 0.17997121810913086 seconds for one epoch ---
--- 2.159073829650879 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.404979]
 [  0.      ]]
--- 0.1747300624847412 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3211.9208984375, (1760.1631, 1.9686185, 1449.4081, 0.38107505)
   validation loss 1040.306396484375, (749.7127, 1.1273592, 289.08524, 0.38107505)
decoder loss ratio: 29045.171848, decoder SINDy loss  ratio: 0.624031
--- 0.13863611221313477 seconds for one epoch ---
--- 0.18982386589050293 seconds for one epoch ---
--- 2.2273683547973633 seconds for one epoch ---
--- 0.18087172508239746 seconds for one epoch ---
--- 2.1680829524993896 seconds for one epoch ---
--- 0.1640470027923584 seconds for one epoch ---
--- 2.2474491596221924 seconds for one epoch ---
--- 0.19864702224731445 seconds for one epoch ---
--- 2.1548969745635986 seconds for one epoch ---
--- 0.159651517868042 seconds for one epoch ---
--- 2.1189615726470947 seconds for one epoch ---
--- 0.16195011138916016 seconds for one epoch ---
--- 2.185145139694214 seconds for one epoch ---
--- 0.1771395206451416 seconds for one epoch ---
--- 2.2439465522766113 seconds for one epoch ---
--- 0.16797518730163574 seconds for one epoch ---
--- 2.168064832687378 seconds for one epoch ---
--- 0.17218255996704102 seconds for one epoch ---
--- 2.1905581951141357 seconds for one epoch ---
--- 0.1710071563720703 seconds for one epoch ---
--- 2.182532787322998 seconds for one epoch ---
--- 0.14997482299804688 seconds for one epoch ---
--- 2.3374183177948 seconds for one epoch ---
--- 0.20560359954833984 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.4330435]
 [ -0.       ]]
--- 0.1479039192199707 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4308.609375, (959.23004, 1.6137317, 3347.3835, 0.38167366)
   validation loss 925.5557861328125, (631.15765, 1.0768627, 292.93964, 0.38167366)
decoder loss ratio: 24452.143246, decoder SINDy loss  ratio: 0.632351
--- 0.18669486045837402 seconds for one epoch ---
--- 2.442147731781006 seconds for one epoch ---
--- 0.1844618320465088 seconds for one epoch ---
--- 2.2729220390319824 seconds for one epoch ---
--- 0.20885658264160156 seconds for one epoch ---
--- 2.164233446121216 seconds for one epoch ---
--- 0.17216849327087402 seconds for one epoch ---
--- 2.203263521194458 seconds for one epoch ---
--- 0.1735076904296875 seconds for one epoch ---
--- 2.2539851665496826 seconds for one epoch ---
--- 0.17524170875549316 seconds for one epoch ---
--- 2.2543561458587646 seconds for one epoch ---
--- 0.17293548583984375 seconds for one epoch ---
--- 2.246100664138794 seconds for one epoch ---
--- 0.2234206199645996 seconds for one epoch ---
--- 2.221494197845459 seconds for one epoch ---
--- 0.1659996509552002 seconds for one epoch ---
--- 2.278650999069214 seconds for one epoch ---
--- 0.18232035636901855 seconds for one epoch ---
--- 2.245968818664551 seconds for one epoch ---
--- 0.16928505897521973 seconds for one epoch ---
--- 2.225811719894409 seconds for one epoch ---
--- 0.5897645950317383 seconds for one epoch ---
--- 2.210839033126831 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.466576]
 [ -0.      ]]
--- 0.1785118579864502 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4252.87646484375, (2230.831, 5.1818805, 2016.4814, 0.382366)
   validation loss 974.7819213867188, (684.0758, 1.0826162, 289.2411, 0.382366)
decoder loss ratio: 26502.284319, decoder SINDy loss  ratio: 0.624368
--- 0.14247775077819824 seconds for one epoch ---
--- 0.20607566833496094 seconds for one epoch ---
--- 2.3548829555511475 seconds for one epoch ---
--- 0.1733543872833252 seconds for one epoch ---
--- 2.246523141860962 seconds for one epoch ---
--- 0.17865228652954102 seconds for one epoch ---
--- 2.1882200241088867 seconds for one epoch ---
--- 0.19387507438659668 seconds for one epoch ---
--- 2.162097215652466 seconds for one epoch ---
--- 0.1724381446838379 seconds for one epoch ---
--- 2.176921844482422 seconds for one epoch ---
--- 0.20259952545166016 seconds for one epoch ---
--- 2.198280096054077 seconds for one epoch ---
--- 0.22130060195922852 seconds for one epoch ---
--- 2.155235528945923 seconds for one epoch ---
--- 0.1627964973449707 seconds for one epoch ---
--- 2.406630516052246 seconds for one epoch ---
--- 0.1799328327178955 seconds for one epoch ---
--- 2.3207547664642334 seconds for one epoch ---
--- 0.19666337966918945 seconds for one epoch ---
--- 2.2389016151428223 seconds for one epoch ---
--- 0.2025296688079834 seconds for one epoch ---
--- 2.219078779220581 seconds for one epoch ---
--- 0.16718149185180664 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-14.4959755]
 [  0.       ]]
--- 0.15268993377685547 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3891.812255859375, (1329.3662, 1.4537574, 2560.6091, 0.38300154)
   validation loss 867.9127807617188, (597.9887, 1.1802022, 268.3609, 0.38300154)
decoder loss ratio: 23167.120721, decoder SINDy loss  ratio: 0.579295
--- 0.15797662734985352 seconds for one epoch ---
--- 2.25718355178833 seconds for one epoch ---
--- 0.19333481788635254 seconds for one epoch ---
--- 2.2782671451568604 seconds for one epoch ---
--- 0.17424750328063965 seconds for one epoch ---
--- 2.2175538539886475 seconds for one epoch ---
--- 0.16345620155334473 seconds for one epoch ---
--- 2.221592426300049 seconds for one epoch ---
--- 0.15845346450805664 seconds for one epoch ---
--- 2.196906566619873 seconds for one epoch ---
--- 0.16323184967041016 seconds for one epoch ---
--- 2.2298734188079834 seconds for one epoch ---
--- 0.15354061126708984 seconds for one epoch ---
--- 2.214512348175049 seconds for one epoch ---
--- 0.20193982124328613 seconds for one epoch ---
--- 2.2261054515838623 seconds for one epoch ---
--- 0.18286633491516113 seconds for one epoch ---
--- 2.2153635025024414 seconds for one epoch ---
--- 0.17597627639770508 seconds for one epoch ---
--- 2.458519458770752 seconds for one epoch ---
--- 0.17360949516296387 seconds for one epoch ---
--- 2.279811143875122 seconds for one epoch ---
--- 0.1930243968963623 seconds for one epoch ---
--- 2.354179859161377 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.530226]
 [ -0.      ]]
--- 0.1835918426513672 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2550.76416015625, (1454.6318, 1.1655061, 1094.583, 0.38369203)
   validation loss 800.7315673828125, (526.8319, 1.1922965, 272.32364, 0.38369203)
decoder loss ratio: 20410.382782, decoder SINDy loss  ratio: 0.587849
--- 0.14977240562438965 seconds for one epoch ---
--- 0.17156648635864258 seconds for one epoch ---
--- 2.3999102115631104 seconds for one epoch ---
--- 0.20531511306762695 seconds for one epoch ---
--- 2.239184617996216 seconds for one epoch ---
--- 0.1556851863861084 seconds for one epoch ---
--- 2.4426145553588867 seconds for one epoch ---
--- 0.181046724319458 seconds for one epoch ---
--- 2.340268135070801 seconds for one epoch ---
--- 0.19008255004882812 seconds for one epoch ---
--- 2.323457717895508 seconds for one epoch ---
--- 0.16427874565124512 seconds for one epoch ---
--- 2.4882664680480957 seconds for one epoch ---
--- 0.1855778694152832 seconds for one epoch ---
--- 2.3452532291412354 seconds for one epoch ---
--- 0.16224193572998047 seconds for one epoch ---
--- 2.2088961601257324 seconds for one epoch ---
--- 0.20680642127990723 seconds for one epoch ---
--- 2.290280342102051 seconds for one epoch ---
--- 0.16537928581237793 seconds for one epoch ---
--- 2.4098544120788574 seconds for one epoch ---
--- 0.19010496139526367 seconds for one epoch ---
--- 2.4221956729888916 seconds for one epoch ---
--- 0.18367719650268555 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.556638]
 [  0.      ]]
--- 0.13651084899902344 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2271.915283203125, (1174.0453, 2.4445536, 1095.0411, 0.3842969)
   validation loss 1189.6387939453125, (873.9741, 1.1853687, 314.09506, 0.3842969)
decoder loss ratio: 33859.274737, decoder SINDy loss  ratio: 0.678018
--- 0.20049166679382324 seconds for one epoch ---
--- 2.307537317276001 seconds for one epoch ---
--- 0.23289990425109863 seconds for one epoch ---
--- 2.262490749359131 seconds for one epoch ---
--- 0.20063281059265137 seconds for one epoch ---
--- 2.2037603855133057 seconds for one epoch ---
--- 0.1620481014251709 seconds for one epoch ---
--- 2.394176721572876 seconds for one epoch ---
--- 0.1980607509613037 seconds for one epoch ---
--- 2.343888521194458 seconds for one epoch ---
--- 0.15694570541381836 seconds for one epoch ---
--- 2.2748525142669678 seconds for one epoch ---
--- 0.1773090362548828 seconds for one epoch ---
--- 2.289522886276245 seconds for one epoch ---
--- 0.15171337127685547 seconds for one epoch ---
--- 2.257072687149048 seconds for one epoch ---
--- 0.21370792388916016 seconds for one epoch ---
--- 2.373406171798706 seconds for one epoch ---
--- 0.1650984287261963 seconds for one epoch ---
--- 2.410494089126587 seconds for one epoch ---
--- 0.17565321922302246 seconds for one epoch ---
--- 2.373621940612793 seconds for one epoch ---
--- 0.19695115089416504 seconds for one epoch ---
--- 2.309858560562134 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.582537]
 [  0.      ]]
--- 0.21607637405395508 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1845.91845703125, (1193.0651, 0.4154284, 652.0533, 0.3848021)
   validation loss 943.3796997070312, (650.7947, 1.1430374, 291.0571, 0.3848021)
decoder loss ratio: 25212.915645, decoder SINDy loss  ratio: 0.628288
--- 0.9416537284851074 seconds for one epoch ---
--- 0.21658062934875488 seconds for one epoch ---
--- 2.346768379211426 seconds for one epoch ---
--- 0.1607069969177246 seconds for one epoch ---
--- 2.3439695835113525 seconds for one epoch ---
--- 0.18746542930603027 seconds for one epoch ---
--- 2.422825574874878 seconds for one epoch ---
--- 0.21262598037719727 seconds for one epoch ---
--- 2.56050443649292 seconds for one epoch ---
--- 0.18035507202148438 seconds for one epoch ---
--- 2.386380672454834 seconds for one epoch ---
--- 0.22942209243774414 seconds for one epoch ---
--- 2.4022154808044434 seconds for one epoch ---
--- 0.1705613136291504 seconds for one epoch ---
--- 2.352543592453003 seconds for one epoch ---
--- 0.16252875328063965 seconds for one epoch ---
--- 2.386420726776123 seconds for one epoch ---
--- 0.19638705253601074 seconds for one epoch ---
--- 2.3012497425079346 seconds for one epoch ---
--- 0.23967337608337402 seconds for one epoch ---
--- 2.494553565979004 seconds for one epoch ---
--- 0.15819072723388672 seconds for one epoch ---
--- 2.3160722255706787 seconds for one epoch ---
--- 0.16517972946166992 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.619634]
 [  0.      ]]
--- 0.14490365982055664 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3444.549072265625, (1584.4097, 1.2928889, 1858.4612, 0.3856156)
   validation loss 765.681640625, (501.45828, 1.1361617, 262.70154, 0.3856156)
decoder loss ratio: 19427.364433, decoder SINDy loss  ratio: 0.567078
--- 0.1616954803466797 seconds for one epoch ---
--- 2.3234198093414307 seconds for one epoch ---
--- 0.15845537185668945 seconds for one epoch ---
--- 2.283374071121216 seconds for one epoch ---
--- 0.17731952667236328 seconds for one epoch ---
--- 2.357957124710083 seconds for one epoch ---
--- 0.21223020553588867 seconds for one epoch ---
--- 2.2462105751037598 seconds for one epoch ---
--- 0.15877652168273926 seconds for one epoch ---
--- 2.2855756282806396 seconds for one epoch ---
--- 0.18258905410766602 seconds for one epoch ---
--- 2.4749526977539062 seconds for one epoch ---
--- 0.18861627578735352 seconds for one epoch ---
--- 2.3783457279205322 seconds for one epoch ---
--- 0.1967768669128418 seconds for one epoch ---
--- 2.4896650314331055 seconds for one epoch ---
--- 0.1883094310760498 seconds for one epoch ---
--- 2.206472396850586 seconds for one epoch ---
--- 0.18097567558288574 seconds for one epoch ---
--- 2.3008575439453125 seconds for one epoch ---
--- 0.22000694274902344 seconds for one epoch ---
--- 2.3810346126556396 seconds for one epoch ---
--- 0.17345976829528809 seconds for one epoch ---
--- 2.446695327758789 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.650013]
 [ -0.      ]]
--- 0.19538211822509766 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2152.85546875, (1078.1147, 0.7175653, 1073.637, 0.3862432)
   validation loss 770.3067626953125, (492.13834, 1.1756161, 276.60654, 0.3862432)
decoder loss ratio: 19066.293533, decoder SINDy loss  ratio: 0.597094
--- 0.13915371894836426 seconds for one epoch ---
--- 0.18047809600830078 seconds for one epoch ---
--- 2.3509321212768555 seconds for one epoch ---
--- 0.21111011505126953 seconds for one epoch ---
--- 2.3249552249908447 seconds for one epoch ---
--- 0.2130260467529297 seconds for one epoch ---
--- 2.30804181098938 seconds for one epoch ---
--- 0.16503572463989258 seconds for one epoch ---
--- 2.423234701156616 seconds for one epoch ---
--- 0.1790165901184082 seconds for one epoch ---
--- 2.383254289627075 seconds for one epoch ---
--- 0.1796886920928955 seconds for one epoch ---
--- 2.2995662689208984 seconds for one epoch ---
--- 0.18526434898376465 seconds for one epoch ---
--- 2.36470365524292 seconds for one epoch ---
--- 0.1771223545074463 seconds for one epoch ---
--- 2.4206106662750244 seconds for one epoch ---
--- 0.20768046379089355 seconds for one epoch ---
--- 2.31292724609375 seconds for one epoch ---
--- 0.15642642974853516 seconds for one epoch ---
--- 2.401710271835327 seconds for one epoch ---
--- 0.17898297309875488 seconds for one epoch ---
--- 2.3555822372436523 seconds for one epoch ---
--- 0.1579267978668213 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.676027]
 [  0.      ]]
--- 0.156951904296875 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2983.704345703125, (1149.28, 1.0900165, 1832.9475, 0.3868466)
   validation loss 970.1993408203125, (674.16406, 1.15654, 294.4919, 0.3868466)
decoder loss ratio: 26118.286182, decoder SINDy loss  ratio: 0.635702
--- 0.17472052574157715 seconds for one epoch ---
--- 2.2888553142547607 seconds for one epoch ---
--- 0.16011261940002441 seconds for one epoch ---
--- 2.28212571144104 seconds for one epoch ---
--- 0.1754140853881836 seconds for one epoch ---
--- 2.5661113262176514 seconds for one epoch ---
--- 0.16849136352539062 seconds for one epoch ---
--- 2.373319387435913 seconds for one epoch ---
--- 0.18941497802734375 seconds for one epoch ---
--- 2.4065258502960205 seconds for one epoch ---
--- 0.17477011680603027 seconds for one epoch ---
--- 2.334320545196533 seconds for one epoch ---
--- 0.15904808044433594 seconds for one epoch ---
--- 2.289079427719116 seconds for one epoch ---
--- 0.19186115264892578 seconds for one epoch ---
--- 2.33851957321167 seconds for one epoch ---
--- 0.18869733810424805 seconds for one epoch ---
--- 2.4343955516815186 seconds for one epoch ---
--- 0.17861247062683105 seconds for one epoch ---
--- 2.4320831298828125 seconds for one epoch ---
--- 0.19153785705566406 seconds for one epoch ---
--- 2.330136299133301 seconds for one epoch ---
--- 0.16217541694641113 seconds for one epoch ---
--- 2.501922607421875 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.708188]
 [ -0.      ]]
--- 0.17645597457885742 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2190.324951171875, (1103.034, 1.2287315, 1085.6748, 0.38750297)
   validation loss 1233.7939453125, (928.29846, 1.171413, 303.9366, 0.38750297)
decoder loss ratio: 35963.894012, decoder SINDy loss  ratio: 0.656090
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.709298]
 [  0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1131.0830078125, (519.0512, 1.018074, 611.0137, 0.38753065)
   validation loss 719.4107666015625, (443.7353, 0.92927116, 274.7462, 0.38753065)
decoder loss ratio: 17191.075513, decoder SINDy loss  ratio: 0.593078
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.773827]
 [  0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.9893798828125, (394.69592, 0.2735356, 546.0199, 0.38839602)
   validation loss 520.5443115234375, (302.2963, 0.39107504, 217.85693, 0.38839602)
decoder loss ratio: 11711.483284, decoder SINDy loss  ratio: 0.470275
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.63846]
 [ -0.     ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.1304931640625, (273.14023, 0.17842402, 511.8118, 0.3872416)
   validation loss 430.5603332519531, (214.67963, 0.23814297, 215.64256, 0.3872416)
decoder loss ratio: 8317.061429, decoder SINDy loss  ratio: 0.465495
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-14.6771145]
 [ -0.       ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 875.5428466796875, (380.3066, 0.13161217, 495.10464, 0.38567874)
   validation loss 558.5759887695312, (334.78455, 0.13719814, 223.65425, 0.38567874)
decoder loss ratio: 12970.134520, decoder SINDy loss  ratio: 0.482789
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.491503]
 [ -0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.2972412109375, (271.91333, 0.11203231, 486.2719, 0.384003)
   validation loss 429.81707763671875, (216.0013, 0.090986475, 213.72478, 0.384003)
decoder loss ratio: 8368.265240, decoder SINDy loss  ratio: 0.461355
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.520975]
 [ -0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 843.8499755859375, (364.15332, 0.122145966, 479.57452, 0.38241482)
   validation loss 523.5787963867188, (303.86987, 0.074009985, 219.63492, 0.38241482)
decoder loss ratio: 11772.446423, decoder SINDy loss  ratio: 0.474113
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.411933]
 [ -0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 816.6165771484375, (340.47473, 0.123750106, 476.0181, 0.3808092)
   validation loss 498.4887390136719, (283.7747, 0.06071392, 214.65335, 0.3808092)
decoder loss ratio: 10993.924096, decoder SINDy loss  ratio: 0.463359
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.274267]
 [  0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.9393920898438, (267.7141, 0.12256629, 472.10272, 0.37935027)
   validation loss 416.4203186035156, (204.62439, 0.054282457, 211.74165, 0.37935027)
decoder loss ratio: 7927.504099, decoder SINDy loss  ratio: 0.457074
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.288921]
 [ -0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 843.371337890625, (373.30533, 0.13241334, 469.9336, 0.37806126)
   validation loss 524.5467529296875, (306.13297, 0.05097975, 218.36281, 0.37806126)
decoder loss ratio: 11860.122538, decoder SINDy loss  ratio: 0.471367
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.142806]
 [ -0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1136.660400390625, (658.20886, 0.128185, 478.3234, 0.37679228)
   validation loss 803.4698486328125, (568.51276, 0.044144895, 234.91295, 0.37679228)
decoder loss ratio: 22025.171162, decoder SINDy loss  ratio: 0.507093
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.246759]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.3349609375, (321.9826, 0.14573596, 487.2066, 0.37591878)
   validation loss 466.3721923828125, (258.09872, 0.04434287, 208.22913, 0.37591878)
decoder loss ratio: 9999.192661, decoder SINDy loss  ratio: 0.449492
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.086152]
 [  0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1043.181396484375, (572.934, 0.1393895, 470.10797, 0.3749406)
   validation loss 730.085205078125, (499.713, 0.04273088, 230.32945, 0.3749406)
decoder loss ratio: 19359.749652, decoder SINDy loss  ratio: 0.497199
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-14.06026]
 [ -0.     ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.2724609375, (242.68013, 0.13548408, 466.45685, 0.37418723)
   validation loss 391.294921875, (181.45134, 0.044253834, 209.79932, 0.37418723)
decoder loss ratio: 7029.739914, decoder SINDy loss  ratio: 0.452881
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.974908]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 769.922119140625, (308.06577, 0.14607516, 461.7103, 0.3735175)
   validation loss 456.94073486328125, (242.54672, 0.04490655, 214.3491, 0.3735175)
decoder loss ratio: 9396.681106, decoder SINDy loss  ratio: 0.462703
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.002182]
 [  0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.7698974609375, (273.39902, 0.13870083, 465.23215, 0.37284645)
   validation loss 417.2772216796875, (207.08162, 0.043259732, 210.15236, 0.37284645)
decoder loss ratio: 8022.701440, decoder SINDy loss  ratio: 0.453643
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.000678]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.9083251953125, (283.4395, 0.1391116, 460.3297, 0.37238535)
   validation loss 428.38018798828125, (215.70673, 0.04421031, 212.62926, 0.37238535)
decoder loss ratio: 8356.853051, decoder SINDy loss  ratio: 0.458990
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.01536]
 [  0.     ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.827392578125, (343.03738, 0.13437188, 461.6556, 0.37189266)
   validation loss 498.70550537109375, (279.18753, 0.037828423, 219.48012, 0.37189266)
decoder loss ratio: 10816.209623, decoder SINDy loss  ratio: 0.473779
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.903308]
 [  0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.8626098632812, (240.706, 0.14257051, 461.01404, 0.37160397)
   validation loss 395.84320068359375, (183.96387, 0.04322868, 211.8361, 0.37160397)
decoder loss ratio: 7127.079590, decoder SINDy loss  ratio: 0.457278
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.888573]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.4769897460938, (319.90634, 0.1358232, 458.4348, 0.37126327)
   validation loss 472.6586608886719, (255.12323, 0.039089154, 217.49634, 0.37126327)
decoder loss ratio: 9883.916843, decoder SINDy loss  ratio: 0.469496
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.938188]
 [ -0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.1921997070312, (239.15236, 0.14421943, 458.8956, 0.3711135)
   validation loss 394.95086669921875, (183.72058, 0.044275768, 211.18599, 0.3711135)
decoder loss ratio: 7117.654263, decoder SINDy loss  ratio: 0.455875
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.901521]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 963.050537109375, (502.2142, 0.13955402, 460.6968, 0.3709397)
   validation loss 642.7344360351562, (416.0079, 0.042067364, 226.68446, 0.3709397)
decoder loss ratio: 16116.868424, decoder SINDy loss  ratio: 0.489330
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.924948]
 [  0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.4312133789062, (245.1065, 0.1437376, 458.18097, 0.37092176)
   validation loss 394.1786193847656, (183.33163, 0.044528678, 210.80246, 0.37092176)
decoder loss ratio: 7102.585799, decoder SINDy loss  ratio: 0.455047
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.970946]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 990.2264404296875, (530.007, 0.14146578, 460.0779, 0.37084132)
   validation loss 667.234130859375, (439.27188, 0.043296903, 227.91898, 0.37084132)
decoder loss ratio: 17018.155283, decoder SINDy loss  ratio: 0.491995
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-13.8467045]
 [ -0.       ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.3177490234375, (235.55083, 0.14585108, 459.62106, 0.37090793)
   validation loss 391.3121032714844, (181.18379, 0.045083866, 210.08322, 0.37090793)
decoder loss ratio: 7019.374655, decoder SINDy loss  ratio: 0.453494
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.860247]
 [ -0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.5877685546875, (234.7414, 0.16547038, 457.6809, 0.37103054)
   validation loss 382.32379150390625, (172.95335, 0.05150986, 209.31891, 0.37103054)
decoder loss ratio: 6700.513190, decoder SINDy loss  ratio: 0.451844
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-13.86955]
 [ -0.     ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 886.8607177734375, (431.10315, 0.13916779, 455.6184, 0.37109533)
   validation loss 568.2435913085938, (345.61404, 0.044658452, 222.58492, 0.37109533)
decoder loss ratio: 13389.688084, decoder SINDy loss  ratio: 0.480481
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.033217]
 [ -0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.2196044921875, (240.07764, 0.15138881, 454.9906, 0.37122738)
   validation loss 388.85784912109375, (178.01314, 0.048551515, 210.79614, 0.37122738)
decoder loss ratio: 6896.538003, decoder SINDy loss  ratio: 0.455033
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.911731]
 [  0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 834.354248046875, (352.33118, 0.17739503, 481.84564, 0.3713599)
   validation loss 500.93975830078125, (291.26205, 0.051859174, 209.62585, 0.3713599)
decoder loss ratio: 11283.997642, decoder SINDy loss  ratio: 0.452507
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.870101]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.8942260742188, (377.12024, 0.14154074, 472.63245, 0.37142602)
   validation loss 538.0311279296875, (328.07373, 0.050037798, 209.90738, 0.37142602)
decoder loss ratio: 12710.145879, decoder SINDy loss  ratio: 0.453115
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.023258]
 [  0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1347.45703125, (813.82526, 0.17258763, 533.45917, 0.37156853)
   validation loss 917.9234008789062, (696.5125, 0.051291943, 221.35963, 0.37156853)
decoder loss ratio: 26984.103922, decoder SINDy loss  ratio: 0.477836
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.878229]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.8844604492188, (305.1344, 0.14402145, 472.60605, 0.37168857)
   validation loss 454.627685546875, (244.42781, 0.05035461, 210.14954, 0.37168857)
decoder loss ratio: 9469.557731, decoder SINDy loss  ratio: 0.453637
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.00742]
 [ -0.     ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 907.3955688476562, (451.9248, 0.14016704, 455.3306, 0.37183833)
   validation loss 588.5621337890625, (363.28854, 0.046463355, 225.22708, 0.37183833)
decoder loss ratio: 14074.428880, decoder SINDy loss  ratio: 0.486184
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.919054]
 [ -0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.3094482421875, (236.96106, 0.13724749, 453.21112, 0.37203607)
   validation loss 385.1651611328125, (173.29663, 0.048324406, 211.82019, 0.37203607)
decoder loss ratio: 6713.812336, decoder SINDy loss  ratio: 0.457244
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.009238]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.449951171875, (285.38687, 0.13921654, 449.92383, 0.37218395)
   validation loss 426.7337951660156, (211.48734, 0.048923474, 215.19754, 0.37218395)
decoder loss ratio: 8193.386524, decoder SINDy loss  ratio: 0.464534
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.980692]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.6267700195312, (272.77313, 0.13572545, 449.71793, 0.37237647)
   validation loss 413.1968078613281, (198.81682, 0.048928507, 214.33105, 0.37237647)
decoder loss ratio: 7702.508700, decoder SINDy loss  ratio: 0.462664
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.044503]
 [  0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.4024047851562, (400.37543, 0.14357762, 450.8834, 0.37255865)
   validation loss 530.134033203125, (310.07614, 0.050079625, 220.00783, 0.37255865)
decoder loss ratio: 12012.888032, decoder SINDy loss  ratio: 0.474918
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-13.9939375]
 [ -0.       ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.1773681640625, (236.309, 0.1368888, 453.73145, 0.37271553)
   validation loss 384.932861328125, (174.1788, 0.049508415, 210.70456, 0.37271553)
decoder loss ratio: 6747.989196, decoder SINDy loss  ratio: 0.454835
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.038926]
 [ -0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.3064575195312, (270.67465, 0.13941176, 449.4924, 0.372938)
   validation loss 415.3018493652344, (200.40576, 0.050290707, 214.8458, 0.372938)
decoder loss ratio: 7764.067129, decoder SINDy loss  ratio: 0.463775
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.046169]
 [ -0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.9178466796875, (259.38953, 0.13978206, 448.38852, 0.3731645)
   validation loss 402.83880615234375, (190.20958, 0.05023689, 212.57901, 0.3731645)
decoder loss ratio: 7369.049327, decoder SINDy loss  ratio: 0.458882
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.070732]
 [  0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.30078125, (254.74405, 0.13557075, 448.42114, 0.37335333)
   validation loss 397.41064453125, (184.26894, 0.050785027, 213.09091, 0.37335333)
decoder loss ratio: 7138.898492, decoder SINDy loss  ratio: 0.459987
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.0327425]
 [  0.       ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.186767578125, (277.21042, 0.13938648, 447.83694, 0.37357226)
   validation loss 415.5787048339844, (201.0746, 0.050714288, 214.45338, 0.37357226)
decoder loss ratio: 7789.979093, decoder SINDy loss  ratio: 0.462928
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.108289]
 [ -0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.837890625, (320.02597, 0.13655044, 445.6754, 0.37376434)
   validation loss 451.7880554199219, (235.42773, 0.050188866, 216.31013, 0.37376434)
decoder loss ratio: 9120.879150, decoder SINDy loss  ratio: 0.466936
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.016195]
 [  0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 717.8929443359375, (271.51196, 0.13651657, 446.24445, 0.37396607)
   validation loss 414.185302734375, (199.93076, 0.051084, 214.20348, 0.37396607)
decoder loss ratio: 7745.664568, decoder SINDy loss  ratio: 0.462388
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.162086]
 [ -0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1002.4119873046875, (549.0847, 0.13882147, 453.18845, 0.3742256)
   validation loss 670.3380126953125, (442.37665, 0.05016538, 227.91122, 0.3742256)
decoder loss ratio: 17138.439341, decoder SINDy loss  ratio: 0.491978
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.112352]
 [ -0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.3826904296875, (375.35803, 0.1393961, 446.88522, 0.37443498)
   validation loss 504.5669250488281, (285.59683, 0.05241254, 218.9177, 0.37443498)
decoder loss ratio: 11064.517100, decoder SINDy loss  ratio: 0.472565
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-14.04615]
 [  0.     ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.310302734375, (251.1144, 0.13846657, 447.0574, 0.3746629)
   validation loss 399.90972900390625, (186.38339, 0.0511867, 213.47513, 0.3746629)
decoder loss ratio: 7220.816195, decoder SINDy loss  ratio: 0.460816
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.175452]
 [ -0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.90576171875, (353.06876, 0.13726038, 446.6997, 0.37488112)
   validation loss 480.12664794921875, (261.68353, 0.052394755, 218.39073, 0.37488112)
decoder loss ratio: 10138.074360, decoder SINDy loss  ratio: 0.471427
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.182576]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.02880859375, (348.17462, 0.13712507, 445.71704, 0.3751007)
   validation loss 475.001220703125, (257.3256, 0.053106505, 217.62254, 0.3751007)
decoder loss ratio: 9969.240173, decoder SINDy loss  ratio: 0.469769
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.149572]
 [  0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1010.9210205078125, (562.51825, 0.1339169, 448.26883, 0.3753212)
   validation loss 675.3609008789062, (448.80878, 0.05081288, 226.5013, 0.3753212)
decoder loss ratio: 17387.631182, decoder SINDy loss  ratio: 0.488935
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.15059]
 [  0.     ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.2724609375, (228.61177, 0.14386676, 449.51685, 0.3755043)
   validation loss 382.373779296875, (172.6152, 0.05520956, 209.70335, 0.3755043)
decoder loss ratio: 6687.412671, decoder SINDy loss  ratio: 0.452674
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.147951]
 [ -0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 703.9326171875, (259.42743, 0.15666875, 444.34854, 0.3758068)
   validation loss 400.02099609375, (188.92262, 0.057573996, 211.0408, 0.3758068)
decoder loss ratio: 7319.190387, decoder SINDy loss  ratio: 0.455561
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.15938]
 [ -0.     ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.7418212890625, (227.66026, 0.16936572, 451.9122, 0.37593332)
   validation loss 382.09124755859375, (173.66277, 0.056445286, 208.37206, 0.37593332)
decoder loss ratio: 6727.997027, decoder SINDy loss  ratio: 0.449800
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.194074]
 [  0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1867.924560546875, (1300.0754, 0.1688071, 567.6803, 0.37613207)
   validation loss 1435.2884521484375, (1198.0002, 0.061235655, 237.22691, 0.37613207)
decoder loss ratio: 46412.609278, decoder SINDy loss  ratio: 0.512088
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.132384]
 [  0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1704.1602783203125, (1179.0006, 0.14509614, 525.0145, 0.37617707)
   validation loss 1385.1895751953125, (1157.5378, 0.056958623, 227.59474, 0.37617707)
decoder loss ratio: 44845.025565, decoder SINDy loss  ratio: 0.491295
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.1427965]
 [ -0.       ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 870.6973266601562, (401.9037, 0.1452103, 468.64844, 0.37634423)
   validation loss 582.4035034179688, (370.16107, 0.056814574, 212.18561, 0.37634423)
decoder loss ratio: 14340.682549, decoder SINDy loss  ratio: 0.458032
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.220322]
 [  0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1442.2376708984375, (987.8483, 0.13649848, 454.25287, 0.37659332)
   validation loss 1087.1168212890625, (847.63446, 0.051789023, 239.43057, 0.37659332)
decoder loss ratio: 32838.830556, decoder SINDy loss  ratio: 0.516845
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.223002]
 [  0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.642578125, (250.11801, 0.14000466, 444.38458, 0.376669)
   validation loss 394.39794921875, (181.72484, 0.05455481, 212.61855, 0.376669)
decoder loss ratio: 7040.335722, decoder SINDy loss  ratio: 0.458967
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.219266]
 [ -0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 878.6356201171875, (435.3163, 0.12672621, 443.1926, 0.37682086)
   validation loss 548.4326171875, (327.22696, 0.05074427, 221.15492, 0.37682086)
decoder loss ratio: 12677.340491, decoder SINDy loss  ratio: 0.477394
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.225844]
 [  0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.2972412109375, (251.31842, 0.14253013, 443.83627, 0.37700734)
   validation loss 394.00799560546875, (181.08838, 0.054421905, 212.8652, 0.37700734)
decoder loss ratio: 7015.678182, decoder SINDy loss  ratio: 0.459499
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.174108]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.2203369140625, (259.18604, 0.13499738, 442.89932, 0.3771505)
   validation loss 395.7539367675781, (182.54659, 0.054214403, 213.15314, 0.3771505)
decoder loss ratio: 7072.171621, decoder SINDy loss  ratio: 0.460121
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.238008]
 [  0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.6347045898438, (230.75102, 0.13046947, 446.75323, 0.37729174)
   validation loss 379.482177734375, (169.34106, 0.05451416, 210.08658, 0.37729174)
decoder loss ratio: 6560.566826, decoder SINDy loss  ratio: 0.453501
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.247924]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.8148193359375, (308.35168, 0.13174818, 441.3314, 0.37743223)
   validation loss 433.8280029296875, (218.94913, 0.05396231, 214.82492, 0.37743223)
decoder loss ratio: 8482.469300, decoder SINDy loss  ratio: 0.463730
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.163736]
 [ -0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.156494140625, (233.8266, 0.13393581, 442.19598, 0.3775568)
   validation loss 378.94219970703125, (168.55058, 0.054895237, 210.3367, 0.3775568)
decoder loss ratio: 6529.942198, decoder SINDy loss  ratio: 0.454041
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.233157]
 [ -0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.2284545898438, (226.13626, 0.14535941, 443.94684, 0.37763372)
   validation loss 381.30218505859375, (172.71439, 0.05583692, 208.53198, 0.37763372)
decoder loss ratio: 6691.255158, decoder SINDy loss  ratio: 0.450146
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.220401]
 [ -0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.77001953125, (242.92937, 0.16702223, 442.67365, 0.37775365)
   validation loss 392.9120178222656, (184.5463, 0.055446945, 208.31027, 0.37775365)
decoder loss ratio: 7149.643861, decoder SINDy loss  ratio: 0.449667
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.202988]
 [ -0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1362.098876953125, (849.69635, 0.13481835, 512.2677, 0.37774038)
   validation loss 1031.58740234375, (809.2814, 0.055642065, 222.25038, 0.37774038)
decoder loss ratio: 31352.965328, decoder SINDy loss  ratio: 0.479759
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.170731]
 [ -0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1385.230224609375, (875.6342, 0.15423983, 509.4417, 0.37796432)
   validation loss 1071.921630859375, (849.69495, 0.06133104, 222.16537, 0.37796432)
decoder loss ratio: 32918.657355, decoder SINDy loss  ratio: 0.479575
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.267403]
 [  0.      ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 907.08203125, (425.15732, 0.15886319, 481.76584, 0.37819085)
   validation loss 585.5328979492188, (372.7614, 0.057745114, 212.71376, 0.37819085)
decoder loss ratio: 14441.424304, decoder SINDy loss  ratio: 0.459173
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.247844]
 [ -0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.4786376953125, (242.09586, 0.15782009, 441.22498, 0.37839812)
   validation loss 381.4110107421875, (172.20888, 0.05752084, 209.1446, 0.37839812)
decoder loss ratio: 6671.670885, decoder SINDy loss  ratio: 0.451468
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.242291]
 [ -0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 772.9313354492188, (333.55005, 0.14409733, 439.23718, 0.3786511)
   validation loss 451.17730712890625, (237.21167, 0.05739845, 213.90823, 0.3786511)
decoder loss ratio: 9189.991910, decoder SINDy loss  ratio: 0.461751
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.302127]
 [  0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.8469848632812, (248.54286, 0.13903129, 440.1651, 0.37873718)
   validation loss 387.27630615234375, (175.71008, 0.057030484, 211.5092, 0.37873718)
decoder loss ratio: 6807.313662, decoder SINDy loss  ratio: 0.456572
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.285026]
 [  0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.5201416015625, (228.69966, 0.1368391, 443.68365, 0.37884876)
   validation loss 385.5220947265625, (176.48564, 0.055869687, 208.98059, 0.37884876)
decoder loss ratio: 6837.360143, decoder SINDy loss  ratio: 0.451114
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.322164]
 [ -0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.7177734375, (330.894, 0.14919934, 464.67453, 0.3789122)
   validation loss 488.6165466308594, (278.5338, 0.054991867, 210.02774, 0.3789122)
decoder loss ratio: 10790.883490, decoder SINDy loss  ratio: 0.453374
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.3030205]
 [  0.       ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.2977294921875, (288.8577, 0.1504804, 438.28955, 0.37926695)
   validation loss 410.68157958984375, (199.50063, 0.05793232, 211.123, 0.37926695)
decoder loss ratio: 7729.000584, decoder SINDy loss  ratio: 0.455739
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.340863]
 [  0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 918.7152099609375, (439.5545, 0.1593857, 479.0013, 0.3792894)
   validation loss 611.7584228515625, (399.12204, 0.05718896, 212.5792, 0.3792894)
decoder loss ratio: 15462.680728, decoder SINDy loss  ratio: 0.458882
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-14.33301]
 [ -0.     ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.493896484375, (274.94073, 0.12542592, 436.42773, 0.3794249)
   validation loss 402.8597412109375, (191.77174, 0.051931616, 211.03607, 0.3794249)
decoder loss ratio: 7429.570284, decoder SINDy loss  ratio: 0.455551
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.368723]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.8004760742188, (240.07385, 0.12709068, 444.59952, 0.37948176)
   validation loss 394.97491455078125, (185.76334, 0.051412195, 209.16019, 0.37948176)
decoder loss ratio: 7196.794143, decoder SINDy loss  ratio: 0.451502
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.2818985]
 [  0.       ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.4774169921875, (230.42027, 0.1400289, 438.91708, 0.37964988)
   validation loss 377.4439697265625, (167.6153, 0.056104492, 209.77255, 0.37964988)
decoder loss ratio: 6493.707537, decoder SINDy loss  ratio: 0.452824
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.36035]
 [  0.     ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.1640625, (325.81152, 0.15411937, 464.19846, 0.3798349)
   validation loss 493.0681457519531, (282.96964, 0.05703096, 210.04147, 0.3798349)
decoder loss ratio: 10962.734917, decoder SINDy loss  ratio: 0.453404
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.331405]
 [ -0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1414.4447021484375, (904.69183, 0.15944287, 509.5934, 0.37995744)
   validation loss 1091.2220458984375, (867.9437, 0.05750404, 223.22081, 0.37995744)
decoder loss ratio: 33625.646746, decoder SINDy loss  ratio: 0.481854
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.320434]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.6143798828125, (260.12122, 0.13208821, 439.36108, 0.38000688)
   validation loss 398.16864013671875, (184.88702, 0.052415635, 213.2292, 0.38000688)
decoder loss ratio: 7162.844285, decoder SINDy loss  ratio: 0.460285
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.332626]
 [  0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.4952392578125, (237.10164, 0.121539086, 445.2721, 0.38010517)
   validation loss 383.98681640625, (174.01617, 0.052800745, 209.91785, 0.38010517)
decoder loss ratio: 6741.688698, decoder SINDy loss  ratio: 0.453137
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.362741]
 [ -0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.5160522460938, (279.2548, 0.13200198, 451.12927, 0.3802913)
   validation loss 450.01910400390625, (240.08678, 0.053481888, 209.87883, 0.3802913)
decoder loss ratio: 9301.378540, decoder SINDy loss  ratio: 0.453053
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.327623]
 [  0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 831.98193359375, (393.3631, 0.12603678, 438.49277, 0.38041326)
   validation loss 507.70343017578125, (288.95428, 0.0540704, 218.69507, 0.38041326)
decoder loss ratio: 11194.590635, decoder SINDy loss  ratio: 0.472084
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.434915]
 [  0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.2495727539062, (239.94527, 0.13146392, 439.17282, 0.38048226)
   validation loss 382.8665771484375, (170.79602, 0.053833794, 212.01672, 0.38048226)
decoder loss ratio: 6616.934349, decoder SINDy loss  ratio: 0.457668
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.363809]
 [ -0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.2115478515625, (281.5121, 0.124654025, 436.57483, 0.380562)
   validation loss 411.6153564453125, (198.13791, 0.053237744, 213.42422, 0.380562)
decoder loss ratio: 7676.206575, decoder SINDy loss  ratio: 0.460706
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.358705]
 [  0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.2464599609375, (222.61372, 0.12613922, 438.50662, 0.38062415)
   validation loss 372.14569091796875, (162.3786, 0.055339538, 209.71175, 0.38062415)
decoder loss ratio: 6290.828907, decoder SINDy loss  ratio: 0.452692
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.447458]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.1109619140625, (271.12405, 0.15115355, 455.83572, 0.3807164)
   validation loss 434.68780517578125, (226.07222, 0.058351878, 208.55722, 0.3807164)
decoder loss ratio: 8758.430276, decoder SINDy loss  ratio: 0.450200
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.425424]
 [  0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.16357421875, (296.8396, 0.15523623, 461.16876, 0.38076034)
   validation loss 459.0134582519531, (250.18495, 0.057314377, 208.7712, 0.38076034)
decoder loss ratio: 9692.599372, decoder SINDy loss  ratio: 0.450662
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.459049]
 [  0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.4271240234375, (281.89996, 0.14704452, 454.38013, 0.38089442)
   validation loss 447.9486999511719, (238.52138, 0.06018447, 209.36714, 0.38089442)
decoder loss ratio: 9240.732258, decoder SINDy loss  ratio: 0.451948
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.416822]
 [  0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.3675537109375, (249.77959, 0.15348734, 451.43445, 0.380973)
   validation loss 411.2220458984375, (203.7175, 0.05634201, 207.44823, 0.380973)
decoder loss ratio: 7892.369572, decoder SINDy loss  ratio: 0.447806
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.375113]
 [  0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.682373046875, (260.14166, 0.13391972, 437.40683, 0.3809082)
   validation loss 392.3240966796875, (179.1866, 0.05359575, 213.08392, 0.3809082)
decoder loss ratio: 6941.999955, decoder SINDy loss  ratio: 0.459972
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.392193]
 [ -0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.7047119140625, (233.89192, 0.117801584, 443.695, 0.38109967)
   validation loss 389.6412353515625, (180.58951, 0.053311083, 208.99841, 0.38109967)
decoder loss ratio: 6996.351059, decoder SINDy loss  ratio: 0.451152
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.532584]
 [  0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 855.8078002929688, (398.41397, 0.13897069, 457.25485, 0.38123626)
   validation loss 592.6068725585938, (382.1621, 0.0545593, 210.3902, 0.38123626)
decoder loss ratio: 14805.623580, decoder SINDy loss  ratio: 0.454157
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.453887]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.6728515625, (343.40143, 0.1512875, 466.12018, 0.38138705)
   validation loss 513.3154907226562, (303.38867, 0.05834718, 209.86847, 0.38138705)
decoder loss ratio: 11753.803854, decoder SINDy loss  ratio: 0.453031
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.460488]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.27978515625, (394.0344, 0.16871941, 463.07663, 0.38147026)
   validation loss 564.9104614257812, (354.60065, 0.053437047, 210.2564, 0.38147026)
decoder loss ratio: 13737.844678, decoder SINDy loss  ratio: 0.453868
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.452862]
 [ -0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.9124145507812, (241.73665, 0.12396853, 442.05182, 0.38150156)
   validation loss 402.9476318359375, (195.21979, 0.05399586, 207.67386, 0.38150156)
decoder loss ratio: 7563.153488, decoder SINDy loss  ratio: 0.448293
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.349264]
 [ -0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.6368408203125, (234.65625, 0.125237, 436.85538, 0.38156134)
   validation loss 376.789306640625, (165.63808, 0.05276152, 211.09845, 0.38156134)
decoder loss ratio: 6417.106655, decoder SINDy loss  ratio: 0.455686
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.50065]
 [ -0.     ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 879.920654296875, (415.78403, 0.12326958, 464.0134, 0.38170895)
   validation loss 600.3023681640625, (389.68677, 0.053023558, 210.5626, 0.38170895)
decoder loss ratio: 15097.141902, decoder SINDy loss  ratio: 0.454529
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.394981]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.420654296875, (367.89374, 0.14843501, 470.37848, 0.38184983)
   validation loss 535.0051879882812, (324.19702, 0.056785077, 210.75139, 0.38184983)
decoder loss ratio: 12559.955443, decoder SINDy loss  ratio: 0.454937
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.368152]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 837.0587158203125, (369.49683, 0.16083325, 467.40103, 0.38192892)
   validation loss 531.722412109375, (322.47156, 0.054286014, 209.19658, 0.38192892)
decoder loss ratio: 12493.107977, decoder SINDy loss  ratio: 0.451580
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.42912]
 [ -0.     ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.6072998046875, (312.40598, 0.12615368, 455.0752, 0.38196397)
   validation loss 483.78717041015625, (274.36163, 0.05599777, 209.36952, 0.38196397)
decoder loss ratio: 10629.245987, decoder SINDy loss  ratio: 0.451954
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.4962435]
 [  0.       ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1806.756591796875, (1335.8882, 0.11841641, 470.75, 0.38216773)
   validation loss 1361.4451904296875, (1107.4027, 0.051463433, 253.99101, 0.38216773)
decoder loss ratio: 42902.703520, decoder SINDy loss  ratio: 0.548275
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.46415]
 [ -0.     ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 939.060546875, (458.4762, 0.14897291, 480.4354, 0.38226768)
   validation loss 627.3925170898438, (413.82452, 0.05835924, 213.50966, 0.38226768)
decoder loss ratio: 16032.280488, decoder SINDy loss  ratio: 0.460891
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.   ]
 [ -0.   ]
 [  0.   ]
 [ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [  0.   ]
 [  0.   ]
 [ -0.   ]
 [-14.376]
 [ -0.   ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.6402587890625, (225.76004, 0.14091787, 442.73932, 0.38239598)
   validation loss 385.73870849609375, (178.05698, 0.05862891, 207.62312, 0.38239598)
decoder loss ratio: 6898.236383, decoder SINDy loss  ratio: 0.448184
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.4173155]
 [ -0.       ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.0482788085938, (285.09283, 0.11310052, 432.84235, 0.38245425)
   validation loss 408.4709777832031, (196.32224, 0.05227761, 212.09647, 0.38245425)
decoder loss ratio: 7605.864218, decoder SINDy loss  ratio: 0.457840
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.491324]
 [  0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.9791259765625, (299.965, 0.1434531, 455.8707, 0.382586)
   validation loss 471.13250732421875, (262.47522, 0.060135808, 208.59714, 0.382586)
decoder loss ratio: 10168.745689, decoder SINDy loss  ratio: 0.450286
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.577036]
 [  0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 866.6614990234375, (395.89212, 0.13368207, 470.63574, 0.3826575)
   validation loss 547.8397216796875, (337.18466, 0.052076932, 210.60303, 0.3826575)
decoder loss ratio: 13063.119179, decoder SINDy loss  ratio: 0.454616
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.422322]
 [ -0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.748779296875, (260.09125, 0.12965424, 445.52783, 0.38261712)
   validation loss 428.20172119140625, (218.9596, 0.054650236, 209.18747, 0.38261712)
decoder loss ratio: 8482.874830, decoder SINDy loss  ratio: 0.451561
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.451037]
 [ -0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.9724731445312, (240.59451, 0.11480605, 435.26315, 0.38274074)
   validation loss 378.36260986328125, (169.07912, 0.051615037, 209.23189, 0.38274074)
decoder loss ratio: 6550.418520, decoder SINDy loss  ratio: 0.451656
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.480281]
 [ -0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.293212890625, (244.16098, 0.11021424, 432.02203, 0.3827704)
   validation loss 379.3869934082031, (170.1294, 0.051158246, 209.20644, 0.3827704)
decoder loss ratio: 6591.108102, decoder SINDy loss  ratio: 0.451602
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.580589]
 [ -0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.5689086914062, (234.33272, 0.118383996, 433.11783, 0.3828441)
   validation loss 376.4295654296875, (168.47871, 0.05332707, 207.89754, 0.3828441)
decoder loss ratio: 6527.157872, decoder SINDy loss  ratio: 0.448776
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.456454]
 [  0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.7783203125, (436.7206, 0.1259971, 463.93173, 0.3827812)
   validation loss 627.021240234375, (416.4622, 0.05411047, 210.50491, 0.3827812)
decoder loss ratio: 16134.468201, decoder SINDy loss  ratio: 0.454404
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-14.4863405]
 [  0.       ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 751.8809204101562, (319.65393, 0.11053767, 432.11646, 0.3828484)
   validation loss 437.75262451171875, (224.13779, 0.051917497, 213.56294, 0.3828484)
decoder loss ratio: 8683.486983, decoder SINDy loss  ratio: 0.461006
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.526031]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.856201171875, (245.95737, 0.12112288, 431.7777, 0.38305384)
   validation loss 381.41015625, (173.07782, 0.05433132, 208.278, 0.38305384)
decoder loss ratio: 6705.335216, decoder SINDy loss  ratio: 0.449597
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.541729]
 [ -0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1135.505126953125, (666.5904, 0.13989022, 468.77478, 0.3829089)
   validation loss 892.7532348632812, (679.72986, 0.05449606, 212.96887, 0.3829089)
decoder loss ratio: 26333.914777, decoder SINDy loss  ratio: 0.459723
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.422726]
 [ -0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.1500244140625, (242.83894, 0.11893716, 433.19217, 0.38326508)
   validation loss 380.33929443359375, (171.71452, 0.054006357, 208.57077, 0.38326508)
decoder loss ratio: 6652.518743, decoder SINDy loss  ratio: 0.450229
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.588116]
 [  0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.8141479492188, (240.64731, 0.12102312, 432.04584, 0.3833053)
   validation loss 378.0684814453125, (170.47488, 0.053143505, 207.54045, 0.3833053)
decoder loss ratio: 6604.492965, decoder SINDy loss  ratio: 0.448005
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.5650835]
 [  0.       ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 810.906982421875, (378.92215, 0.122084156, 431.8628, 0.3835116)
   validation loss 478.64288330078125, (264.8962, 0.05528423, 213.69138, 0.3835116)
decoder loss ratio: 10262.539044, decoder SINDy loss  ratio: 0.461283
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.477317]
 [ -0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 683.80029296875, (252.336, 0.11221699, 431.35208, 0.3835009)
   validation loss 386.21929931640625, (176.79968, 0.051249266, 209.36835, 0.3835009)
decoder loss ratio: 6849.526642, decoder SINDy loss  ratio: 0.451951
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.553498]
 [ -0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.3218383789062, (232.20879, 0.11607226, 431.99698, 0.3835344)
   validation loss 375.3341979980469, (167.58199, 0.052267395, 207.69995, 0.3835344)
decoder loss ratio: 6492.417052, decoder SINDy loss  ratio: 0.448350
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.553923]
 [ -0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 777.011962890625, (338.41302, 0.13106355, 438.4679, 0.38341123)
   validation loss 516.9152221679688, (311.1497, 0.054226678, 205.71129, 0.38341123)
decoder loss ratio: 12054.479121, decoder SINDy loss  ratio: 0.444057
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.517998]
 [  0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.35009765625, (268.77707, 0.11615737, 431.4569, 0.3834788)
   validation loss 399.14459228515625, (188.02666, 0.051361058, 211.06659, 0.3834788)
decoder loss ratio: 7284.479125, decoder SINDy loss  ratio: 0.455617
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.460364]
 [ -0.      ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.3541259765625, (297.79782, 0.11077447, 430.44556, 0.38347766)
   validation loss 417.1448974609375, (205.54755, 0.05179992, 211.54556, 0.38347766)
decoder loss ratio: 7963.268793, decoder SINDy loss  ratio: 0.456651
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.508694]
 [  0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.5782470703125, (330.37503, 0.107818, 430.0954, 0.3836607)
   validation loss 442.0367431640625, (228.8962, 0.05045076, 213.09009, 0.3836607)
decoder loss ratio: 8867.835955, decoder SINDy loss  ratio: 0.459985
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.650845]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.2758178710938, (311.7367, 0.10849509, 431.43063, 0.38365474)
   validation loss 429.4432373046875, (216.24367, 0.04947272, 213.15012, 0.38365474)
decoder loss ratio: 8377.655098, decoder SINDy loss  ratio: 0.460115
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.510272]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.2684936523438, (254.10855, 0.10795504, 430.052, 0.38369846)
   validation loss 386.2564697265625, (175.96817, 0.050339818, 210.23798, 0.38369846)
decoder loss ratio: 6817.312406, decoder SINDy loss  ratio: 0.453828
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.602191]
 [  0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.3193969726562, (251.07721, 0.11808077, 429.1241, 0.38372168)
   validation loss 384.64642333984375, (176.16998, 0.052728966, 208.42372, 0.38372168)
decoder loss ratio: 6825.130982, decoder SINDy loss  ratio: 0.449912
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.525824]
 [ -0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 696.7859497070312, (267.47275, 0.10856474, 429.20465, 0.38383442)
   validation loss 392.22833251953125, (182.72314, 0.050329465, 209.45485, 0.38383442)
decoder loss ratio: 7079.011840, decoder SINDy loss  ratio: 0.452138
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.547213]
 [  0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 746.3436889648438, (316.45822, 0.1255775, 429.7599, 0.38411164)
   validation loss 427.59600830078125, (216.4081, 0.056160893, 211.13176, 0.38411164)
decoder loss ratio: 8384.025352, decoder SINDy loss  ratio: 0.455758
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.655497]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 846.355712890625, (383.22336, 0.13031048, 463.00204, 0.3841037)
   validation loss 565.8524780273438, (355.9182, 0.052713238, 209.88156, 0.3841037)
decoder loss ratio: 13788.889469, decoder SINDy loss  ratio: 0.453059
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.61234]
 [  0.     ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 966.0729370117188, (527.96826, 0.108427085, 437.99628, 0.38418937)
   validation loss 601.9707641601562, (379.85764, 0.049590696, 222.06352, 0.38418937)
decoder loss ratio: 14716.344261, decoder SINDy loss  ratio: 0.479355
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.548847]
 [ -0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.3397827148438, (252.55238, 0.10901172, 428.6784, 0.38434157)
   validation loss 383.07440185546875, (174.38066, 0.04978246, 208.64397, 0.38434157)
decoder loss ratio: 6755.809546, decoder SINDy loss  ratio: 0.450387
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.630751]
 [  0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 675.0562744140625, (244.96712, 0.109706074, 429.97943, 0.3843917)
   validation loss 381.23760986328125, (172.31273, 0.051307883, 208.87355, 0.3843917)
decoder loss ratio: 6675.694265, decoder SINDy loss  ratio: 0.450883
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.555163]
 [  0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1399.1201171875, (907.4837, 0.13388477, 491.50253, 0.38444766)
   validation loss 1152.7022705078125, (931.5746, 0.054005094, 221.07362, 0.38444766)
decoder loss ratio: 36090.816706, decoder SINDy loss  ratio: 0.477219
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.639564]
 [ -0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 729.620849609375, (300.5766, 0.11236206, 428.93192, 0.38447878)
   validation loss 419.87310791015625, (207.782, 0.050442338, 212.04068, 0.38447878)
decoder loss ratio: 8049.835316, decoder SINDy loss  ratio: 0.457720
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.565242]
 [  0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.985107421875, (295.25388, 0.117742576, 449.6135, 0.3844975)
   validation loss 469.4569091796875, (260.55878, 0.048140727, 208.84999, 0.3844975)
decoder loss ratio: 10094.499365, decoder SINDy loss  ratio: 0.450832
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.590077]
 [  0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.7085571289062, (237.77411, 0.10676478, 441.82767, 0.38466868)
   validation loss 383.340576171875, (174.87746, 0.049555957, 208.41357, 0.38466868)
decoder loss ratio: 6775.056272, decoder SINDy loss  ratio: 0.449890
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.589446]
 [  0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.4173583984375, (222.62903, 0.10994724, 431.6784, 0.3847582)
   validation loss 368.74334716796875, (160.24107, 0.048781272, 208.45348, 0.3847582)
decoder loss ratio: 6208.017382, decoder SINDy loss  ratio: 0.449976
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.496432]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 688.0009155273438, (259.16006, 0.11138298, 428.72946, 0.38478765)
   validation loss 390.1543273925781, (180.12608, 0.05073273, 209.97751, 0.38478765)
decoder loss ratio: 6978.397183, decoder SINDy loss  ratio: 0.453266
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.611952]
 [ -0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.128173828125, (240.71257, 0.119672485, 437.29596, 0.38461843)
   validation loss 381.46636962890625, (172.67871, 0.048934475, 208.73872, 0.38461843)
decoder loss ratio: 6689.873045, decoder SINDy loss  ratio: 0.450592
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.682809]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.0418090820312, (222.59612, 0.10710624, 435.3386, 0.38481918)
   validation loss 378.5710754394531, (171.45062, 0.04875866, 207.0717, 0.38481918)
decoder loss ratio: 6642.294769, decoder SINDy loss  ratio: 0.446993
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.646567]
 [  0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.9842529296875, (234.47684, 0.11414472, 430.39328, 0.38497287)
   validation loss 375.55377197265625, (166.50621, 0.04950223, 208.99805, 0.38497287)
decoder loss ratio: 6450.739656, decoder SINDy loss  ratio: 0.451152
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.539483]
 [ -0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.952880859375, (287.56342, 0.10284486, 428.28662, 0.38501683)
   validation loss 409.3609619140625, (197.57468, 0.046305377, 211.73996, 0.38501683)
decoder loss ratio: 7654.385973, decoder SINDy loss  ratio: 0.457070
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.617726]
 [  0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 818.730712890625, (387.36224, 0.10397748, 431.26447, 0.38510233)
   validation loss 481.80731201171875, (266.00113, 0.04700764, 215.75917, 0.38510233)
decoder loss ratio: 10305.345542, decoder SINDy loss  ratio: 0.465747
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.503609]
 [  0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 680.3104858398438, (252.59015, 0.118397325, 427.60193, 0.38529092)
   validation loss 383.0955810546875, (174.70578, 0.051832553, 208.33797, 0.38529092)
decoder loss ratio: 6768.405221, decoder SINDy loss  ratio: 0.449727
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.677519]
 [ -0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1198.7762451171875, (707.5365, 0.13245583, 491.10727, 0.3852759)
   validation loss 910.9276733398438, (693.64844, 0.050111704, 217.22914, 0.3852759)
decoder loss ratio: 26873.144695, decoder SINDy loss  ratio: 0.468920
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.627563]
 [  0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1243.4661865234375, (743.7509, 0.13776149, 499.5775, 0.3853244)
   validation loss 929.2343139648438, (710.75464, 0.055479992, 218.4242, 0.3853244)
decoder loss ratio: 27535.868626, decoder SINDy loss  ratio: 0.471499
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.603894]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.360595703125, (247.4331, 0.14475502, 444.7827, 0.3854471)
   validation loss 411.04583740234375, (205.1442, 0.05386347, 205.8478, 0.3854471)
decoder loss ratio: 7947.642282, decoder SINDy loss  ratio: 0.444351
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.4690485]
 [ -0.       ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 939.7058715820312, (477.3267, 0.15061975, 462.22855, 0.38543954)
   validation loss 669.0728149414062, (457.76608, 0.051289257, 211.25545, 0.38543954)
decoder loss ratio: 17734.652763, decoder SINDy loss  ratio: 0.456025
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.577849]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.739501953125, (268.0265, 0.109727584, 438.60324, 0.38543603)
   validation loss 402.47930908203125, (193.78624, 0.0460568, 208.647, 0.38543603)
decoder loss ratio: 7507.615351, decoder SINDy loss  ratio: 0.450394
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.664325]
 [ -0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.4132690429688, (423.2924, 0.115349144, 433.00552, 0.3854896)
   validation loss 516.2820434570312, (297.43948, 0.046467543, 218.7961, 0.3854896)
decoder loss ratio: 11523.321974, decoder SINDy loss  ratio: 0.472302
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.612333]
 [  0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.87109375, (233.41666, 0.10796563, 438.34647, 0.38557276)
   validation loss 390.20855712890625, (183.2644, 0.0471779, 206.89699, 0.38557276)
decoder loss ratio: 7099.981183, decoder SINDy loss  ratio: 0.446616
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.643291]
 [ -0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.8673095703125, (374.55392, 0.1101093, 430.20328, 0.38577294)
   validation loss 479.042724609375, (263.0458, 0.046565045, 215.95035, 0.38577294)
decoder loss ratio: 10190.851226, decoder SINDy loss  ratio: 0.466159
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.61288]
 [ -0.     ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.224609375, (226.97368, 0.10345362, 428.1475, 0.3857749)
   validation loss 367.81610107421875, (159.9816, 0.04610469, 207.7884, 0.3857749)
decoder loss ratio: 6197.964843, decoder SINDy loss  ratio: 0.448541
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.646059]
 [  0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.0567626953125, (299.25946, 0.10926047, 427.68808, 0.3859453)
   validation loss 417.18695068359375, (205.85649, 0.0463176, 211.28413, 0.3859453)
decoder loss ratio: 7975.237847, decoder SINDy loss  ratio: 0.456087
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-14.6807995]
 [ -0.       ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.5650024414062, (219.80635, 0.10664846, 431.652, 0.38593903)
   validation loss 373.18939208984375, (166.71713, 0.047697186, 206.42455, 0.38593903)
decoder loss ratio: 6458.911149, decoder SINDy loss  ratio: 0.445596
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.577646]
 [  0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 937.9512939453125, (465.78986, 0.14788772, 472.01352, 0.38590923)
   validation loss 643.246826171875, (431.8478, 0.051257707, 211.34776, 0.38590923)
decoder loss ratio: 16730.533835, decoder SINDy loss  ratio: 0.456224
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.60476]
 [ -0.     ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.2131958007812, (221.79764, 0.10993551, 430.30563, 0.38583872)
   validation loss 372.8220520019531, (165.93193, 0.045335382, 206.84479, 0.38583872)
decoder loss ratio: 6428.491060, decoder SINDy loss  ratio: 0.446504
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.642629]
 [  0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1226.58447265625, (783.9034, 0.10353821, 442.5775, 0.38593093)
   validation loss 833.0596313476562, (601.41675, 0.04282262, 231.60002, 0.38593093)
decoder loss ratio: 23299.928925, decoder SINDy loss  ratio: 0.499941
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.712418]
 [ -0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.4913330078125, (299.89005, 0.1072148, 427.4941, 0.38599554)
   validation loss 417.9662170410156, (206.28786, 0.046448093, 211.63191, 0.38599554)
decoder loss ratio: 7991.949714, decoder SINDy loss  ratio: 0.456837
params['save_name']
pendulum_2023_11_09_20_24_30_180785
