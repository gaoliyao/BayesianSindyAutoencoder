nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-10-25 04:17:11.133697: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-10-25 04:17:11.141134: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-10-25 04:17:11.142803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5637575d4c00 executing computations on platform Host. Devices:
2023-10-25 04:17:11.142831: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-10-25 04:17:11.144700: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-10-25 04:17:11.245658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563758ca0cf0 executing computations on platform CUDA. Devices:
2023-10-25 04:17:11.245770: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-10-25 04:17:11.246215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2023-10-25 04:17:11.246461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 04:17:11.248048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-10-25 04:17:11.249500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-10-25 04:17:11.249820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-10-25 04:17:11.251426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-10-25 04:17:11.252246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-10-25 04:17:11.255432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-10-25 04:17:11.256048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-10-25 04:17:11.256086: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-10-25 04:17:11.256448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-10-25 04:17:11.256457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-10-25 04:17:11.256463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-10-25 04:17:11.257044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2023-10-25 04:17:12.389166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 0.4, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8567264080047607 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 112555.2578125, (105063.984, 0.039407916, 7472.3984, 2.53178)
   validation loss 82556.3515625, (81336.74, 0.033148862, 1200.7433, 2.53178)
decoder loss ratio: 3151126.599138, decoder SINDy loss  ratio: 2.591973
--- 0.27591896057128906 seconds for one epoch ---
--- 0.29874730110168457 seconds for one epoch ---
--- 0.3024601936340332 seconds for one epoch ---
--- 0.2942025661468506 seconds for one epoch ---
--- 0.30504631996154785 seconds for one epoch ---
--- 0.2939305305480957 seconds for one epoch ---
--- 0.30794763565063477 seconds for one epoch ---
--- 0.28967785835266113 seconds for one epoch ---
--- 0.3067188262939453 seconds for one epoch ---
--- 0.30222344398498535 seconds for one epoch ---
--- 0.32180333137512207 seconds for one epoch ---
--- 0.29631614685058594 seconds for one epoch ---
--- 0.31659936904907227 seconds for one epoch ---
--- 0.29564523696899414 seconds for one epoch ---
--- 0.327470064163208 seconds for one epoch ---
--- 0.29215025901794434 seconds for one epoch ---
--- 0.33052945137023926 seconds for one epoch ---
--- 0.29757189750671387 seconds for one epoch ---
--- 0.313798189163208 seconds for one epoch ---
--- 0.2960338592529297 seconds for one epoch ---
--- 0.3047144412994385 seconds for one epoch ---
--- 0.29119062423706055 seconds for one epoch ---
--- 0.3290433883666992 seconds for one epoch ---
--- 0.2914254665374756 seconds for one epoch ---
=========================
[[0.7767277 ]
 [0.7779799 ]
 [0.7813342 ]
 [0.7822776 ]
 [0.7728534 ]
 [0.7824625 ]
 [0.7840506 ]
 [0.7727574 ]
 [0.7727221 ]
 [0.83494055]
 [0.77392644]]
[[ 0.54034996]
 [ 0.62576294]
 [-0.7955725 ]
 [-0.8335734 ]
 [ 0.03941257]
 [-0.8406619 ]
 [ 0.8973698 ]
 [-0.01453284]
 [ 0.00497073]
 [-1.662391  ]
 [ 0.24692594]]
--- 0.25678348541259766 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 73114.0859375, (64750.57, 17.934532, 8307.494, 2.53175)
   validation loss 51686.5625, (50402.81, 5.1309896, 1240.5355, 2.53175)
decoder loss ratio: 1952692.308046, decoder SINDy loss  ratio: 2.677870
--- 0.30738019943237305 seconds for one epoch ---
--- 0.32202696800231934 seconds for one epoch ---
--- 0.29361915588378906 seconds for one epoch ---
--- 0.3125038146972656 seconds for one epoch ---
--- 0.293825626373291 seconds for one epoch ---
--- 0.32466840744018555 seconds for one epoch ---
--- 0.2958247661590576 seconds for one epoch ---
--- 0.31586241722106934 seconds for one epoch ---
--- 0.30754995346069336 seconds for one epoch ---
--- 0.3284749984741211 seconds for one epoch ---
--- 0.2960090637207031 seconds for one epoch ---
--- 0.3268568515777588 seconds for one epoch ---
--- 0.29224300384521484 seconds for one epoch ---
--- 0.3169980049133301 seconds for one epoch ---
--- 0.2936265468597412 seconds for one epoch ---
--- 0.3193655014038086 seconds for one epoch ---
--- 0.312694787979126 seconds for one epoch ---
--- 0.3225839138031006 seconds for one epoch ---
--- 0.29112863540649414 seconds for one epoch ---
--- 0.31616640090942383 seconds for one epoch ---
--- 0.2937815189361572 seconds for one epoch ---
--- 0.31675100326538086 seconds for one epoch ---
--- 0.2916746139526367 seconds for one epoch ---
--- 0.320507287979126 seconds for one epoch ---
=========================
[[0.6363824 ]
 [0.6160767 ]
 [0.6263732 ]
 [0.63208133]
 [0.6112443 ]
 [0.67314065]
 [0.6206918 ]
 [0.61223   ]
 [0.6111807 ]
 [0.6222257 ]
 [0.61319214]]
[[ 0.99976915]
 [ 0.44454995]
 [-0.8070172 ]
 [-0.92652893]
 [ 0.01710424]
 [-1.3873861 ]
 [ 0.64448446]
 [ 0.14714171]
 [ 0.00704588]
 [-0.6945999 ]
 [ 0.2437147 ]]
--- 0.2907710075378418 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 36888.5859375, (31586.506, 8.516904, 5235.586, 2.5317426)
   validation loss 37217.94140625, (35950.16, 8.1134, 1201.6896, 2.5317426)
decoder loss ratio: 1392771.616676, decoder SINDy loss  ratio: 2.594016
--- 0.2551546096801758 seconds for one epoch ---
--- 0.2912256717681885 seconds for one epoch ---
--- 0.3215310573577881 seconds for one epoch ---
--- 0.2982618808746338 seconds for one epoch ---
--- 0.3226492404937744 seconds for one epoch ---
--- 0.29267072677612305 seconds for one epoch ---
--- 0.3270430564880371 seconds for one epoch ---
--- 0.29077816009521484 seconds for one epoch ---
--- 0.34712719917297363 seconds for one epoch ---
--- 0.2973935604095459 seconds for one epoch ---
--- 0.35225391387939453 seconds for one epoch ---
--- 0.3051879405975342 seconds for one epoch ---
--- 0.3285863399505615 seconds for one epoch ---
--- 0.30591368675231934 seconds for one epoch ---
--- 0.33303332328796387 seconds for one epoch ---
--- 0.3709378242492676 seconds for one epoch ---
--- 0.3298676013946533 seconds for one epoch ---
--- 0.29523777961730957 seconds for one epoch ---
--- 0.368847131729126 seconds for one epoch ---
--- 0.29933714866638184 seconds for one epoch ---
--- 0.3504061698913574 seconds for one epoch ---
--- 0.29212212562561035 seconds for one epoch ---
--- 0.33431196212768555 seconds for one epoch ---
--- 0.29427456855773926 seconds for one epoch ---
=========================
[[0.53745675]
 [0.4775964 ]
 [0.487189  ]
 [0.49248925]
 [0.4758272 ]
 [0.64256066]
 [0.483171  ]
 [0.47825104]
 [0.47592264]
 [0.47638577]
 [0.4761531 ]]
[[ 1.248734  ]
 [ 0.17283535]
 [-0.6041629 ]
 [-0.73262626]
 [-0.00244569]
 [-1.7486414 ]
 [ 0.47252816]
 [ 0.22144261]
 [ 0.01368373]
 [-0.06425944]
 [ 0.03961883]]
--- 0.2788052558898926 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 72572.2734375, (63386.08, 20.498083, 9091.179, 2.531735)
   validation loss 23143.826171875, (21955.746, 0.4715415, 1113.0908, 2.531735)
decoder loss ratio: 850603.720523, decoder SINDy loss  ratio: 2.402763
--- 0.2983253002166748 seconds for one epoch ---
--- 0.32704997062683105 seconds for one epoch ---
--- 0.2944505214691162 seconds for one epoch ---
--- 0.33644795417785645 seconds for one epoch ---
--- 0.28363609313964844 seconds for one epoch ---
--- 0.33122992515563965 seconds for one epoch ---
--- 0.3113365173339844 seconds for one epoch ---
--- 0.34934115409851074 seconds for one epoch ---
--- 0.29860568046569824 seconds for one epoch ---
--- 0.34339332580566406 seconds for one epoch ---
--- 0.29561948776245117 seconds for one epoch ---
--- 0.3396015167236328 seconds for one epoch ---
--- 0.29135632514953613 seconds for one epoch ---
--- 0.3359999656677246 seconds for one epoch ---
--- 0.2922053337097168 seconds for one epoch ---
--- 0.3566620349884033 seconds for one epoch ---
--- 0.29151487350463867 seconds for one epoch ---
--- 0.34287142753601074 seconds for one epoch ---
--- 0.29624032974243164 seconds for one epoch ---
--- 0.35108160972595215 seconds for one epoch ---
--- 0.3065018653869629 seconds for one epoch ---
--- 0.3483388423919678 seconds for one epoch ---
--- 0.30994081497192383 seconds for one epoch ---
--- 0.3493232727050781 seconds for one epoch ---
=========================
[[0.42381915]
 [0.37936974]
 [0.38580424]
 [0.39306137]
 [0.37946072]
 [0.7137028 ]
 [0.38411137]
 [0.3826254 ]
 [0.37901565]
 [0.37964162]
 [0.37990996]]
[[ 1.04219306e+00]
 [ 3.45295854e-02]
 [-4.04640824e-01]
 [-6.17362320e-01]
 [-4.29108329e-02]
 [-2.12449241e+00]
 [ 3.34636480e-01]
 [ 2.61722118e-01]
 [-1.19595396e-04]
 [-5.91285862e-02]
 [-8.20208117e-02]]
--- 0.29018282890319824 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 24800.234375, (16390.572, 1.9569099, 8318.247, 2.531737)
   validation loss 15746.671875, (14628.826, 0.3648642, 1028.0232, 2.531737)
decoder loss ratio: 566746.122658, decoder SINDy loss  ratio: 2.219133
--- 0.25029635429382324 seconds for one epoch ---
--- 0.2963066101074219 seconds for one epoch ---
--- 0.33115625381469727 seconds for one epoch ---
--- 0.2923004627227783 seconds for one epoch ---
--- 0.34361839294433594 seconds for one epoch ---
--- 0.31605029106140137 seconds for one epoch ---
--- 0.3631434440612793 seconds for one epoch ---
--- 0.3072638511657715 seconds for one epoch ---
--- 0.34842371940612793 seconds for one epoch ---
--- 0.3005833625793457 seconds for one epoch ---
--- 0.3491322994232178 seconds for one epoch ---
--- 0.2899749279022217 seconds for one epoch ---
--- 0.34697461128234863 seconds for one epoch ---
--- 0.32106971740722656 seconds for one epoch ---
--- 0.3735971450805664 seconds for one epoch ---
--- 0.2950465679168701 seconds for one epoch ---
--- 0.36562299728393555 seconds for one epoch ---
--- 0.2937610149383545 seconds for one epoch ---
--- 0.3638484477996826 seconds for one epoch ---
--- 0.286602258682251 seconds for one epoch ---
--- 0.37766194343566895 seconds for one epoch ---
--- 0.3060624599456787 seconds for one epoch ---
--- 0.34845519065856934 seconds for one epoch ---
--- 0.29329466819763184 seconds for one epoch ---
=========================
[[0.32013267]
 [0.29771176]
 [0.29962137]
 [0.30710036]
 [0.29786605]
 [0.80283165]
 [0.3036281 ]
 [0.30183482]
 [0.29750472]
 [0.3017669 ]
 [0.2989087 ]]
[[ 0.73770195]
 [-0.02300304]
 [-0.15937439]
 [-0.4662356 ]
 [-0.03586783]
 [-2.4492342 ]
 [ 0.35078737]
 [ 0.27579153]
 [-0.00506547]
 [-0.2726621 ]
 [-0.11362   ]]
--- 0.25631213188171387 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 17823.193359375, (15802.445, 9.942826, 1907.5304, 2.5317433)
   validation loss 9804.9130859375, (8863.664, 0.21246496, 837.75946, 2.5317433)
decoder loss ratio: 343393.733779, decoder SINDy loss  ratio: 1.808422
--- 0.28850436210632324 seconds for one epoch ---
--- 0.359893798828125 seconds for one epoch ---
--- 0.3151543140411377 seconds for one epoch ---
--- 0.3551456928253174 seconds for one epoch ---
--- 0.2935206890106201 seconds for one epoch ---
--- 0.35929059982299805 seconds for one epoch ---
--- 0.3029944896697998 seconds for one epoch ---
--- 0.3495333194732666 seconds for one epoch ---
--- 0.2946648597717285 seconds for one epoch ---
--- 0.3698868751525879 seconds for one epoch ---
--- 0.31252527236938477 seconds for one epoch ---
--- 0.36660003662109375 seconds for one epoch ---
--- 0.2899329662322998 seconds for one epoch ---
--- 0.3456745147705078 seconds for one epoch ---
--- 0.2961606979370117 seconds for one epoch ---
--- 0.35361528396606445 seconds for one epoch ---
--- 0.291301965713501 seconds for one epoch ---
--- 0.34639811515808105 seconds for one epoch ---
--- 0.2916562557220459 seconds for one epoch ---
--- 0.3753180503845215 seconds for one epoch ---
--- 0.2940661907196045 seconds for one epoch ---
--- 0.35332274436950684 seconds for one epoch ---
--- 0.2954850196838379 seconds for one epoch ---
--- 0.35903120040893555 seconds for one epoch ---
=========================
[[0.24626665]
 [0.24092452]
 [0.23945606]
 [0.24565221]
 [0.23941559]
 [0.8785622 ]
 [0.24553718]
 [0.24334672]
 [0.23881267]
 [0.25508043]
 [0.23964737]]
[[ 0.37859356]
 [-0.14876896]
 [ 0.05414959]
 [-0.3577826 ]
 [-0.05121985]
 [-2.7494104 ]
 [ 0.35377124]
 [ 0.26883596]
 [-0.00464818]
 [-0.6001566 ]
 [-0.06779121]]
--- 0.30299901962280273 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 19583.97265625, (14313.703, 8.794514, 5143.8027, 2.531757)
   validation loss 5790.75537109375, (4910.2866, 0.17948137, 762.61676, 2.531757)
decoder loss ratio: 190233.028334, decoder SINDy loss  ratio: 1.646216
--- 0.2618074417114258 seconds for one epoch ---
--- 0.3006010055541992 seconds for one epoch ---
--- 0.37230706214904785 seconds for one epoch ---
--- 0.30475544929504395 seconds for one epoch ---
--- 0.36246824264526367 seconds for one epoch ---
--- 0.3044140338897705 seconds for one epoch ---
--- 0.380892276763916 seconds for one epoch ---
--- 0.30577945709228516 seconds for one epoch ---
--- 0.36823368072509766 seconds for one epoch ---
--- 0.29514527320861816 seconds for one epoch ---
--- 0.3663187026977539 seconds for one epoch ---
--- 0.2994697093963623 seconds for one epoch ---
--- 0.3979771137237549 seconds for one epoch ---
--- 0.30007123947143555 seconds for one epoch ---
--- 0.3762319087982178 seconds for one epoch ---
--- 0.28433799743652344 seconds for one epoch ---
--- 0.36292147636413574 seconds for one epoch ---
--- 0.2931098937988281 seconds for one epoch ---
--- 0.3869516849517822 seconds for one epoch ---
--- 0.2955296039581299 seconds for one epoch ---
--- 0.3655815124511719 seconds for one epoch ---
--- 0.29140686988830566 seconds for one epoch ---
--- 0.3766467571258545 seconds for one epoch ---
--- 0.30089783668518066 seconds for one epoch ---
=========================
[[0.18989968]
 [0.19359767]
 [0.1955368 ]
 [0.19367488]
 [0.18950225]
 [0.9116846 ]
 [0.19559418]
 [0.19388759]
 [0.18910326]
 [0.23408163]
 [0.18901804]]
[[ 6.4268857e-02]
 [-2.5667557e-01]
 [ 3.3037272e-01]
 [-2.5988346e-01]
 [-3.7002865e-02]
 [-2.9337358e+00]
 [ 3.3236024e-01]
 [ 2.6856989e-01]
 [-7.6600639e-03]
 [-9.3870771e-01]
 [-1.1105256e-03]]
--- 0.256145715713501 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14661.509765625, (9394.249, 0.7385272, 5137.263, 2.5317743)
   validation loss 6034.24462890625, (5340.2427, 0.16222644, 564.5806, 2.5317743)
decoder loss ratio: 206890.272329, decoder SINDy loss  ratio: 1.218727
--- 0.29755187034606934 seconds for one epoch ---
--- 0.36080121994018555 seconds for one epoch ---
--- 0.299393892288208 seconds for one epoch ---
--- 0.3852207660675049 seconds for one epoch ---
--- 0.29302191734313965 seconds for one epoch ---
--- 0.38762879371643066 seconds for one epoch ---
--- 0.2958071231842041 seconds for one epoch ---
--- 0.37943148612976074 seconds for one epoch ---
--- 0.2910194396972656 seconds for one epoch ---
--- 0.3814220428466797 seconds for one epoch ---
--- 0.311251163482666 seconds for one epoch ---
--- 0.37605857849121094 seconds for one epoch ---
--- 0.3002612590789795 seconds for one epoch ---
--- 0.3790438175201416 seconds for one epoch ---
--- 0.2968478202819824 seconds for one epoch ---
--- 0.37342405319213867 seconds for one epoch ---
--- 0.29789185523986816 seconds for one epoch ---
--- 0.40526294708251953 seconds for one epoch ---
--- 0.3147885799407959 seconds for one epoch ---
--- 0.38320159912109375 seconds for one epoch ---
--- 0.30436110496520996 seconds for one epoch ---
--- 0.380216121673584 seconds for one epoch ---
--- 0.28930139541625977 seconds for one epoch ---
--- 0.3815877437591553 seconds for one epoch ---
=========================
[[0.15611304]
 [0.16086534]
 [0.17166843]
 [0.156685  ]
 [0.1534531 ]
 [0.9254877 ]
 [0.15968697]
 [0.1584629 ]
 [0.15301338]
 [0.25003698]
 [0.15327042]]
[[-1.8381037e-01]
 [-3.6396047e-01]
 [ 6.0908693e-01]
 [-2.1012376e-01]
 [-3.2857053e-02]
 [-3.0330553e+00]
 [ 3.2603472e-01]
 [ 2.8261036e-01]
 [-1.5128209e-03]
 [-1.2372133e+00]
 [ 2.0114362e-02]]
--- 0.2917752265930176 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 14729.1279296875, (7669.838, 1.8205454, 6918.892, 2.5317974)
   validation loss 3759.823486328125, (3121.1567, 0.18430397, 499.90582, 2.5317974)
decoder loss ratio: 120919.030607, decoder SINDy loss  ratio: 1.079117
--- 0.26108479499816895 seconds for one epoch ---
--- 0.29152369499206543 seconds for one epoch ---
--- 0.39803552627563477 seconds for one epoch ---
--- 0.2967088222503662 seconds for one epoch ---
--- 0.39154934883117676 seconds for one epoch ---
--- 0.30259013175964355 seconds for one epoch ---
--- 0.39753174781799316 seconds for one epoch ---
--- 0.29207825660705566 seconds for one epoch ---
--- 0.3811197280883789 seconds for one epoch ---
--- 0.29497385025024414 seconds for one epoch ---
--- 0.39119839668273926 seconds for one epoch ---
--- 0.2959616184234619 seconds for one epoch ---
--- 0.4098210334777832 seconds for one epoch ---
--- 0.31163835525512695 seconds for one epoch ---
--- 0.37502336502075195 seconds for one epoch ---
--- 0.39317846298217773 seconds for one epoch ---
--- 0.3886241912841797 seconds for one epoch ---
--- 0.2844197750091553 seconds for one epoch ---
--- 0.3834207057952881 seconds for one epoch ---
--- 0.2799835205078125 seconds for one epoch ---
--- 0.40749597549438477 seconds for one epoch ---
--- 0.29311442375183105 seconds for one epoch ---
--- 0.4029397964477539 seconds for one epoch ---
--- 0.2930302619934082 seconds for one epoch ---
=========================
[[0.13105619]
 [0.13616636]
 [0.16295095]
 [0.12531005]
 [0.12253954]
 [0.9281718 ]
 [0.12707599]
 [0.12754183]
 [0.12236829]
 [0.30247712]
 [0.12340409]]
[[-0.3816343 ]
 [-0.5065467 ]
 [ 0.86908114]
 [-0.17390749]
 [-0.01748242]
 [-3.066257  ]
 [ 0.249452  ]
 [ 0.26727384]
 [-0.00555322]
 [-1.5102941 ]
 [ 0.07298978]]
--- 0.252852201461792 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7085.56298828125, (3920.807, 4.9368753, 3012.9233, 2.5318182)
   validation loss 2504.29443359375, (1892.6251, 0.15014462, 464.62308, 2.5318182)
decoder loss ratio: 73323.582971, decoder SINDy loss  ratio: 1.002954
--- 0.3139045238494873 seconds for one epoch ---
--- 0.40077805519104004 seconds for one epoch ---
--- 0.29628419876098633 seconds for one epoch ---
--- 0.38716936111450195 seconds for one epoch ---
--- 0.28808093070983887 seconds for one epoch ---
--- 0.3875093460083008 seconds for one epoch ---
--- 0.29381275177001953 seconds for one epoch ---
--- 0.38628220558166504 seconds for one epoch ---
--- 0.295943021774292 seconds for one epoch ---
--- 0.3934905529022217 seconds for one epoch ---
--- 0.294802188873291 seconds for one epoch ---
--- 0.4091036319732666 seconds for one epoch ---
--- 0.29351258277893066 seconds for one epoch ---
--- 0.38919734954833984 seconds for one epoch ---
--- 0.29624342918395996 seconds for one epoch ---
--- 0.3848574161529541 seconds for one epoch ---
--- 0.29317665100097656 seconds for one epoch ---
--- 0.41168737411499023 seconds for one epoch ---
--- 0.29669666290283203 seconds for one epoch ---
--- 0.39348316192626953 seconds for one epoch ---
--- 0.29607105255126953 seconds for one epoch ---
--- 0.4028489589691162 seconds for one epoch ---
--- 0.29470372200012207 seconds for one epoch ---
--- 0.4015216827392578 seconds for one epoch ---
=========================
[[0.11434343]
 [0.11661419]
 [0.16719209]
 [0.10200922]
 [0.10006267]
 [0.92338574]
 [0.10510161]
 [0.10496711]
 [0.09998836]
 [0.37030992]
 [0.10288391]]
[[-0.51012075]
 [-0.5542257 ]
 [ 1.056408  ]
 [-0.12393964]
 [-0.00845272]
 [-3.0482035 ]
 [ 0.25901884]
 [ 0.25397742]
 [-0.0033347 ]
 [-1.7149755 ]
 [ 0.16684031]]
--- 0.2861301898956299 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7441.01318359375, (4144.5703, 7.6969132, 3133.6182, 2.5318334)
   validation loss 2874.35009765625, (2248.638, 0.13562958, 470.4487, 2.5318334)
decoder loss ratio: 87116.137582, decoder SINDy loss  ratio: 1.015530
--- 0.2597532272338867 seconds for one epoch ---
--- 0.2942929267883301 seconds for one epoch ---
--- 0.4059295654296875 seconds for one epoch ---
--- 0.29137086868286133 seconds for one epoch ---
--- 0.3993847370147705 seconds for one epoch ---
--- 0.3061678409576416 seconds for one epoch ---
--- 0.40122175216674805 seconds for one epoch ---
--- 0.30400681495666504 seconds for one epoch ---
--- 0.40360116958618164 seconds for one epoch ---
--- 0.2917754650115967 seconds for one epoch ---
--- 0.407595157623291 seconds for one epoch ---
--- 0.30289578437805176 seconds for one epoch ---
--- 0.4221315383911133 seconds for one epoch ---
--- 0.28619956970214844 seconds for one epoch ---
--- 0.4040641784667969 seconds for one epoch ---
--- 0.2946445941925049 seconds for one epoch ---
--- 0.40877628326416016 seconds for one epoch ---
--- 0.2939732074737549 seconds for one epoch ---
--- 0.3994297981262207 seconds for one epoch ---
--- 0.30042505264282227 seconds for one epoch ---
--- 0.4163374900817871 seconds for one epoch ---
--- 0.29378223419189453 seconds for one epoch ---
--- 0.4048347473144531 seconds for one epoch ---
--- 0.29764652252197266 seconds for one epoch ---
=========================
[[0.10568185]
 [0.10044157]
 [0.18590342]
 [0.08247079]
 [0.08120129]
 [0.9233057 ]
 [0.08580925]
 [0.08631087]
 [0.08079135]
 [0.48068815]
 [0.08685847]]
[[-6.7716509e-01]
 [-5.9937632e-01]
 [ 1.2364113e+00]
 [-1.0212641e-01]
 [-2.8037962e-02]
 [-3.0573959e+00]
 [ 2.5019300e-01]
 [ 2.6847032e-01]
 [-9.3049824e-04]
 [-1.9530443e+00]
 [ 2.8755417e-01]]
--- 0.2657325267791748 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6412.00146484375, (3112.226, 0.6428974, 3138.2505, 2.531855)
   validation loss 3180.985595703125, (2586.4402, 0.14905019, 433.514, 2.531855)
decoder loss ratio: 100203.183046, decoder SINDy loss  ratio: 0.935801
--- 0.2935802936553955 seconds for one epoch ---
--- 0.40952062606811523 seconds for one epoch ---
--- 0.29996299743652344 seconds for one epoch ---
--- 0.41469478607177734 seconds for one epoch ---
--- 0.2936832904815674 seconds for one epoch ---
--- 0.4132661819458008 seconds for one epoch ---
--- 0.2914927005767822 seconds for one epoch ---
--- 0.4184441566467285 seconds for one epoch ---
--- 0.29646778106689453 seconds for one epoch ---
--- 0.4075596332550049 seconds for one epoch ---
--- 0.29947757720947266 seconds for one epoch ---
--- 0.41002774238586426 seconds for one epoch ---
--- 0.29154229164123535 seconds for one epoch ---
--- 0.4108715057373047 seconds for one epoch ---
--- 0.30841827392578125 seconds for one epoch ---
--- 0.42850756645202637 seconds for one epoch ---
--- 0.29452943801879883 seconds for one epoch ---
--- 0.42283058166503906 seconds for one epoch ---
--- 0.29758572578430176 seconds for one epoch ---
--- 0.41602253913879395 seconds for one epoch ---
--- 0.3043076992034912 seconds for one epoch ---
--- 0.43344879150390625 seconds for one epoch ---
--- 0.29114699363708496 seconds for one epoch ---
--- 0.4121568202972412 seconds for one epoch ---
=========================
[[0.10322618]
 [0.09195852]
 [0.22760932]
 [0.06816807]
 [0.0672198 ]
 [0.91832244]
 [0.07116608]
 [0.07245994]
 [0.06679722]
 [0.5891395 ]
 [0.07483345]]
[[-0.80611384]
 [-0.6761531 ]
 [ 1.4244108 ]
 [-0.08599918]
 [-0.03054885]
 [-3.0354266 ]
 [ 0.22396903]
 [ 0.27170575]
 [-0.00317762]
 [-2.1591005 ]
 [ 0.34714243]]
--- 0.29499340057373047 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6651.67138671875, (3081.9258, 1.9218712, 3401.373, 2.531874)
   validation loss 1704.5506591796875, (1107.9154, 0.10482892, 430.0796, 2.531874)
decoder loss ratio: 42922.566226, decoder SINDy loss  ratio: 0.928387
--- 0.2671017646789551 seconds for one epoch ---
--- 0.2976725101470947 seconds for one epoch ---
--- 0.42586755752563477 seconds for one epoch ---
--- 0.2949647903442383 seconds for one epoch ---
--- 0.4289851188659668 seconds for one epoch ---
--- 0.29041457176208496 seconds for one epoch ---
--- 0.4230778217315674 seconds for one epoch ---
--- 0.3197047710418701 seconds for one epoch ---
--- 0.4325587749481201 seconds for one epoch ---
--- 0.2929549217224121 seconds for one epoch ---
--- 0.4315469264984131 seconds for one epoch ---
--- 0.2975451946258545 seconds for one epoch ---
--- 0.4332084655761719 seconds for one epoch ---
--- 0.29345107078552246 seconds for one epoch ---
--- 0.4488108158111572 seconds for one epoch ---
--- 0.2942526340484619 seconds for one epoch ---
--- 0.4209132194519043 seconds for one epoch ---
--- 0.2947258949279785 seconds for one epoch ---
--- 0.42884325981140137 seconds for one epoch ---
--- 0.29998111724853516 seconds for one epoch ---
--- 0.43421196937561035 seconds for one epoch ---
--- 0.32703423500061035 seconds for one epoch ---
--- 0.42235875129699707 seconds for one epoch ---
--- 0.29562830924987793 seconds for one epoch ---
=========================
[[0.10710023]
 [0.08259883]
 [0.27948982]
 [0.05537605]
 [0.05496886]
 [0.91223407]
 [0.05890411]
 [0.06072769]
 [0.05468437]
 [0.6959454 ]
 [0.06434557]]
[[-9.3795562e-01]
 [-7.0692855e-01]
 [ 1.5860927e+00]
 [-4.5340557e-02]
 [-2.0302201e-02]
 [-3.0081768e+00]
 [ 2.1516408e-01]
 [ 2.8147587e-01]
 [-1.8526372e-03]
 [-2.3683338e+00]
 [ 3.8813606e-01]]
--- 0.2636094093322754 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5949.56298828125, (2319.6714, 1.2919959, 3458.3403, 2.5318933)
   validation loss 2930.3212890625, (2295.0952, 0.16090643, 464.80563, 2.5318933)
decoder loss ratio: 88915.973084, decoder SINDy loss  ratio: 1.003348
--- 0.3077526092529297 seconds for one epoch ---
--- 0.4472332000732422 seconds for one epoch ---
--- 0.29874634742736816 seconds for one epoch ---
--- 0.4267890453338623 seconds for one epoch ---
--- 0.28058719635009766 seconds for one epoch ---
--- 0.42142581939697266 seconds for one epoch ---
--- 0.30143237113952637 seconds for one epoch ---
--- 0.4435272216796875 seconds for one epoch ---
--- 0.29285383224487305 seconds for one epoch ---
--- 0.43062281608581543 seconds for one epoch ---
--- 0.297440767288208 seconds for one epoch ---
--- 0.4375739097595215 seconds for one epoch ---
--- 0.3034844398498535 seconds for one epoch ---
--- 0.4433252811431885 seconds for one epoch ---
--- 0.3039374351501465 seconds for one epoch ---
--- 0.4599766731262207 seconds for one epoch ---
--- 0.30150508880615234 seconds for one epoch ---
--- 0.4512500762939453 seconds for one epoch ---
--- 0.30282163619995117 seconds for one epoch ---
--- 0.4309678077697754 seconds for one epoch ---
--- 0.29358744621276855 seconds for one epoch ---
--- 0.44234395027160645 seconds for one epoch ---
--- 0.3034372329711914 seconds for one epoch ---
--- 0.43471503257751465 seconds for one epoch ---
=========================
[[0.12614292]
 [0.07764193]
 [0.33202922]
 [0.046052  ]
 [0.04624701]
 [0.90973663]
 [0.04975002]
 [0.05148587]
 [0.04584397]
 [0.8011474 ]
 [0.05716445]]
[[-1.1058081 ]
 [-0.7497967 ]
 [ 1.7142231 ]
 [-0.01913245]
 [-0.03123708]
 [-2.99952   ]
 [ 0.2035604 ]
 [ 0.26801962]
 [-0.00581103]
 [-2.6129048 ]
 [ 0.42815205]]
--- 0.29181385040283203 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4434.4384765625, (1607.2355, 0.5573059, 2652.8857, 2.5319166)
   validation loss 3420.804931640625, (2813.3418, 0.10058466, 433.6026, 2.5319166)
decoder loss ratio: 108993.745387, decoder SINDy loss  ratio: 0.935992
--- 0.25760316848754883 seconds for one epoch ---
--- 0.2967696189880371 seconds for one epoch ---
--- 0.43599796295166016 seconds for one epoch ---
--- 0.291593074798584 seconds for one epoch ---
--- 0.4572770595550537 seconds for one epoch ---
--- 0.2913830280303955 seconds for one epoch ---
--- 0.45206522941589355 seconds for one epoch ---
--- 0.30718135833740234 seconds for one epoch ---
--- 0.4453084468841553 seconds for one epoch ---
--- 0.28534913063049316 seconds for one epoch ---
--- 0.44714879989624023 seconds for one epoch ---
--- 0.29415345191955566 seconds for one epoch ---
--- 0.42562246322631836 seconds for one epoch ---
--- 0.29129981994628906 seconds for one epoch ---
--- 0.46894145011901855 seconds for one epoch ---
--- 0.3087880611419678 seconds for one epoch ---
--- 0.46047115325927734 seconds for one epoch ---
--- 0.30167412757873535 seconds for one epoch ---
--- 0.44211435317993164 seconds for one epoch ---
--- 0.2987401485443115 seconds for one epoch ---
--- 0.47159814834594727 seconds for one epoch ---
--- 0.28890061378479004 seconds for one epoch ---
--- 0.44992995262145996 seconds for one epoch ---
--- 0.2843449115753174 seconds for one epoch ---
=========================
[[0.14682683]
 [0.07028925]
 [0.397773  ]
 [0.03810339]
 [0.03856551]
 [0.90065736]
 [0.04169395]
 [0.04379936]
 [0.03804351]
 [0.866695  ]
 [0.05237485]]
[[-1.2314909e+00]
 [-7.5094450e-01]
 [ 1.8492277e+00]
 [ 4.1100564e-03]
 [-3.3021323e-02]
 [-2.9586294e+00]
 [ 1.8839826e-01]
 [ 2.6740599e-01]
 [-2.0500339e-04]
 [-2.8185804e+00]
 [ 4.8934454e-01]]
--- 0.2492682933807373 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5560.3056640625, (1903.9053, 1.8364115, 3477.7183, 2.5319364)
   validation loss 1571.4974365234375, (952.5089, 0.09356018, 442.04904, 2.5319364)
decoder loss ratio: 36901.848845, decoder SINDy loss  ratio: 0.954225
--- 0.292513370513916 seconds for one epoch ---
--- 0.46236157417297363 seconds for one epoch ---
--- 0.2810072898864746 seconds for one epoch ---
--- 0.45227742195129395 seconds for one epoch ---
--- 0.29578280448913574 seconds for one epoch ---
--- 0.48567748069763184 seconds for one epoch ---
--- 0.29834747314453125 seconds for one epoch ---
--- 0.46431875228881836 seconds for one epoch ---
--- 0.2866508960723877 seconds for one epoch ---
--- 0.46945834159851074 seconds for one epoch ---
--- 0.29604291915893555 seconds for one epoch ---
--- 0.4538097381591797 seconds for one epoch ---
--- 0.30796194076538086 seconds for one epoch ---
--- 0.45351433753967285 seconds for one epoch ---
--- 0.3018498420715332 seconds for one epoch ---
--- 0.483656644821167 seconds for one epoch ---
--- 0.2984893321990967 seconds for one epoch ---
--- 0.4746694564819336 seconds for one epoch ---
--- 0.29657626152038574 seconds for one epoch ---
--- 0.4771568775177002 seconds for one epoch ---
--- 0.2862379550933838 seconds for one epoch ---
--- 0.4608187675476074 seconds for one epoch ---
--- 0.30481576919555664 seconds for one epoch ---
--- 0.46198034286499023 seconds for one epoch ---
=========================
[[0.17461294]
 [0.06444579]
 [0.44965363]
 [0.03327928]
 [0.0330611 ]
 [0.8915478 ]
 [0.03634838]
 [0.03817542]
 [0.03235232]
 [0.9114662 ]
 [0.04900472]]
[[-1.3495706e+00]
 [-7.4736959e-01]
 [ 1.9467274e+00]
 [ 5.7452563e-02]
 [-4.4919960e-02]
 [-2.9201746e+00]
 [ 2.0220053e-01]
 [ 2.6911724e-01]
 [ 1.3436406e-03]
 [-3.0149453e+00]
 [ 5.3215957e-01]]
--- 0.3948535919189453 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7012.59521484375, (2310.1519, 3.0366457, 4519.0234, 2.5319557)
   validation loss 1308.3240966796875, (767.8092, 0.09854121, 360.0329, 2.5319557)
decoder loss ratio: 29746.261542, decoder SINDy loss  ratio: 0.777182
--- 0.2662162780761719 seconds for one epoch ---
--- 0.30437350273132324 seconds for one epoch ---
--- 0.4721381664276123 seconds for one epoch ---
--- 0.2848985195159912 seconds for one epoch ---
--- 0.46492981910705566 seconds for one epoch ---
--- 0.29149389266967773 seconds for one epoch ---
--- 0.45853519439697266 seconds for one epoch ---
--- 0.29291248321533203 seconds for one epoch ---
--- 0.45776939392089844 seconds for one epoch ---
--- 0.29236721992492676 seconds for one epoch ---
--- 0.483687162399292 seconds for one epoch ---
--- 0.29038071632385254 seconds for one epoch ---
--- 0.4836602210998535 seconds for one epoch ---
--- 0.29267144203186035 seconds for one epoch ---
--- 0.47400975227355957 seconds for one epoch ---
--- 0.29642271995544434 seconds for one epoch ---
--- 0.4740283489227295 seconds for one epoch ---
--- 0.2975339889526367 seconds for one epoch ---
--- 0.4810912609100342 seconds for one epoch ---
--- 0.3084831237792969 seconds for one epoch ---
--- 0.4897584915161133 seconds for one epoch ---
--- 0.29849839210510254 seconds for one epoch ---
--- 0.4910316467285156 seconds for one epoch ---
--- 0.3017251491546631 seconds for one epoch ---
=========================
[[0.21324581]
 [0.06127702]
 [0.50474244]
 [0.02858437]
 [0.02813467]
 [0.8861254 ]
 [0.03122292]
 [0.03287876]
 [0.02737369]
 [0.9423795 ]
 [0.04788481]]
[[-1.4746456e+00]
 [-7.6496804e-01]
 [ 2.0451350e+00]
 [ 7.2582670e-02]
 [-4.7439780e-02]
 [-2.8995051e+00]
 [ 1.9532396e-01]
 [ 2.5706717e-01]
 [ 1.0156629e-03]
 [-3.2125006e+00]
 [ 5.9505659e-01]]
--- 0.26271891593933105 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3457.685302734375, (1823.7742, 0.3335887, 1450.0675, 2.531978)
   validation loss 1326.4906005859375, (744.52423, 0.112350374, 398.34402, 2.531978)
decoder loss ratio: 28844.161258, decoder SINDy loss  ratio: 0.859882
--- 0.2940511703491211 seconds for one epoch ---
--- 0.46515893936157227 seconds for one epoch ---
--- 0.2966785430908203 seconds for one epoch ---
--- 0.48888254165649414 seconds for one epoch ---
--- 0.29132652282714844 seconds for one epoch ---
--- 0.46787405014038086 seconds for one epoch ---
--- 0.31804943084716797 seconds for one epoch ---
--- 0.48503851890563965 seconds for one epoch ---
--- 0.29813337326049805 seconds for one epoch ---
--- 0.4785463809967041 seconds for one epoch ---
--- 0.32404327392578125 seconds for one epoch ---
--- 0.48604679107666016 seconds for one epoch ---
--- 0.29984021186828613 seconds for one epoch ---
--- 0.4843921661376953 seconds for one epoch ---
--- 0.294281005859375 seconds for one epoch ---
--- 0.47681379318237305 seconds for one epoch ---
--- 0.30681419372558594 seconds for one epoch ---
--- 0.4845442771911621 seconds for one epoch ---
--- 0.3026552200317383 seconds for one epoch ---
--- 0.49716711044311523 seconds for one epoch ---
--- 0.30224132537841797 seconds for one epoch ---
--- 0.5053632259368896 seconds for one epoch ---
--- 0.3054826259613037 seconds for one epoch ---
--- 0.5004446506500244 seconds for one epoch ---
=========================
[[0.24854329]
 [0.05984782]
 [0.56627   ]
 [0.0247179 ]
 [0.02438655]
 [0.87539613]
 [0.02688386]
 [0.02964857]
 [0.02370454]
 [0.96061265]
 [0.04331867]]
[[-1.5692796e+00]
 [-7.8686416e-01]
 [ 2.1524279e+00]
 [ 6.3197896e-02]
 [-4.4461310e-02]
 [-2.8583398e+00]
 [ 1.6823421e-01]
 [ 2.7225378e-01]
 [ 2.9571117e-03]
 [-3.3831015e+00]
 [ 5.8018917e-01]]
--- 0.2961463928222656 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3697.119873046875, (1759.9048, 0.9354438, 1749.2546, 2.5319958)
   validation loss 1543.6607666015625, (995.47314, 0.097604804, 361.06488, 2.5319958)
decoder loss ratio: 38566.357837, decoder SINDy loss  ratio: 0.779409
--- 0.25618982315063477 seconds for one epoch ---
--- 0.2979097366333008 seconds for one epoch ---
--- 0.4920082092285156 seconds for one epoch ---
--- 0.2893495559692383 seconds for one epoch ---
--- 0.5064432621002197 seconds for one epoch ---
--- 0.29429006576538086 seconds for one epoch ---
--- 0.491987943649292 seconds for one epoch ---
--- 0.30770301818847656 seconds for one epoch ---
--- 0.5004875659942627 seconds for one epoch ---
--- 0.2940399646759033 seconds for one epoch ---
--- 0.4910309314727783 seconds for one epoch ---
--- 0.3022329807281494 seconds for one epoch ---
--- 0.5179102420806885 seconds for one epoch ---
--- 0.30358362197875977 seconds for one epoch ---
--- 0.48221325874328613 seconds for one epoch ---
--- 0.3031196594238281 seconds for one epoch ---
--- 0.5130672454833984 seconds for one epoch ---
--- 0.30371642112731934 seconds for one epoch ---
--- 0.5004305839538574 seconds for one epoch ---
--- 0.3024930953979492 seconds for one epoch ---
--- 0.5021486282348633 seconds for one epoch ---
--- 0.2979145050048828 seconds for one epoch ---
--- 0.5179786682128906 seconds for one epoch ---
--- 0.30786561965942383 seconds for one epoch ---
=========================
[[0.3107648 ]
 [0.05725243]
 [0.60973567]
 [0.02142073]
 [0.02126683]
 [0.8723403 ]
 [0.02348801]
 [0.02619243]
 [0.02049648]
 [0.9757457 ]
 [0.04483143]]
[[-1.7072481 ]
 [-0.7920466 ]
 [ 2.2300696 ]
 [ 0.05981671]
 [-0.05117751]
 [-2.848284  ]
 [ 0.16105056]
 [ 0.2643401 ]
 [-0.0049527 ]
 [-3.5966907 ]
 [ 0.64915895]]
--- 0.2604224681854248 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4030.18896484375, (1660.6249, 0.3440082, 2180.311, 2.5320208)
   validation loss 1831.7923583984375, (1274.6583, 0.138411, 368.08636, 2.5320208)
decoder loss ratio: 49382.476422, decoder SINDy loss  ratio: 0.794566
--- 0.2922499179840088 seconds for one epoch ---
--- 0.48450565338134766 seconds for one epoch ---
--- 0.28902220726013184 seconds for one epoch ---
--- 0.5341165065765381 seconds for one epoch ---
--- 0.30396318435668945 seconds for one epoch ---
--- 0.5130088329315186 seconds for one epoch ---
--- 0.29030632972717285 seconds for one epoch ---
--- 0.5085563659667969 seconds for one epoch ---
--- 0.30327749252319336 seconds for one epoch ---
--- 0.538902997970581 seconds for one epoch ---
--- 0.3008737564086914 seconds for one epoch ---
--- 0.49240732192993164 seconds for one epoch ---
--- 0.2942352294921875 seconds for one epoch ---
--- 0.5118370056152344 seconds for one epoch ---
--- 0.2959921360015869 seconds for one epoch ---
--- 0.5200669765472412 seconds for one epoch ---
--- 0.30275511741638184 seconds for one epoch ---
--- 0.5050983428955078 seconds for one epoch ---
--- 0.29759955406188965 seconds for one epoch ---
--- 0.5229449272155762 seconds for one epoch ---
--- 0.29048991203308105 seconds for one epoch ---
--- 0.5222914218902588 seconds for one epoch ---
--- 0.31619715690612793 seconds for one epoch ---
--- 0.5096917152404785 seconds for one epoch ---
=========================
[[0.3666136 ]
 [0.05868283]
 [0.64550436]
 [0.01902085]
 [0.0186658 ]
 [0.8682814 ]
 [0.02079477]
 [0.02377293]
 [0.01802454]
 [0.9838116 ]
 [0.04221422]]
[[-1.8158739e+00]
 [-8.2749248e-01]
 [ 2.2957704e+00]
 [ 6.0889613e-02]
 [-4.0780153e-02]
 [-2.8343749e+00]
 [ 1.4878693e-01]
 [ 2.6393417e-01]
 [-1.7474850e-03]
 [-3.7731609e+00]
 [ 6.4567453e-01]]
--- 0.309628963470459 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4126.994140625, (2092.2058, 3.1772242, 1840.2766, 2.5320413)
   validation loss 1440.3271484375, (928.14264, 0.08340105, 320.7665, 2.5320413)
decoder loss ratio: 35957.857168, decoder SINDy loss  ratio: 0.692420
THRESHOLDING: 4 active coefficients
--- 0.518244743347168 seconds for one epoch ---
--- 0.3045048713684082 seconds for one epoch ---
--- 0.5249276161193848 seconds for one epoch ---
--- 0.29207730293273926 seconds for one epoch ---
--- 0.5055506229400635 seconds for one epoch ---
--- 0.2897763252258301 seconds for one epoch ---
--- 0.5000467300415039 seconds for one epoch ---
--- 0.29583144187927246 seconds for one epoch ---
--- 0.5209133625030518 seconds for one epoch ---
--- 0.28957128524780273 seconds for one epoch ---
--- 0.5204770565032959 seconds for one epoch ---
--- 0.29186081886291504 seconds for one epoch ---
--- 0.5046868324279785 seconds for one epoch ---
--- 0.30325770378112793 seconds for one epoch ---
--- 0.513169527053833 seconds for one epoch ---
--- 0.2926149368286133 seconds for one epoch ---
--- 0.5261936187744141 seconds for one epoch ---
--- 0.29827308654785156 seconds for one epoch ---
--- 0.522057056427002 seconds for one epoch ---
--- 0.29275012016296387 seconds for one epoch ---
--- 0.5236847400665283 seconds for one epoch ---
--- 0.29262685775756836 seconds for one epoch ---
--- 0.5009922981262207 seconds for one epoch ---
--- 0.29617857933044434 seconds for one epoch ---
=========================
[[0.12500885]
 [0.        ]
 [0.7868413 ]
 [0.        ]
 [0.        ]
 [0.47731516]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9650393 ]
 [0.        ]]
[[-1.2229524]
 [-0.       ]
 [ 2.5924668]
 [ 0.       ]
 [-0.       ]
 [-2.009065 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4390044]
 [ 0.       ]]
--- 0.25762128829956055 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6660.822265625, (3781.3958, 8.005291, 2870.7156, 0.7054917)
   validation loss 2997.559326171875, (2602.202, 0.09948524, 394.55252, 0.7054917)
decoder loss ratio: 100813.819394, decoder SINDy loss  ratio: 0.851697
--- 0.2968456745147705 seconds for one epoch ---
--- 0.5057177543640137 seconds for one epoch ---
--- 0.29303979873657227 seconds for one epoch ---
--- 0.5227303504943848 seconds for one epoch ---
--- 0.295818567276001 seconds for one epoch ---
--- 0.5299079418182373 seconds for one epoch ---
--- 0.2903127670288086 seconds for one epoch ---
--- 0.5093190670013428 seconds for one epoch ---
--- 0.29817891120910645 seconds for one epoch ---
--- 0.5373079776763916 seconds for one epoch ---
--- 0.2975146770477295 seconds for one epoch ---
--- 0.5090792179107666 seconds for one epoch ---
--- 0.29195618629455566 seconds for one epoch ---
--- 0.5344767570495605 seconds for one epoch ---
--- 0.29838109016418457 seconds for one epoch ---
--- 0.5015401840209961 seconds for one epoch ---
--- 0.2881960868835449 seconds for one epoch ---
--- 0.5313479900360107 seconds for one epoch ---
--- 0.2924771308898926 seconds for one epoch ---
--- 0.5180149078369141 seconds for one epoch ---
--- 0.28632664680480957 seconds for one epoch ---
--- 0.5321967601776123 seconds for one epoch ---
--- 0.29654645919799805 seconds for one epoch ---
--- 0.5458862781524658 seconds for one epoch ---
=========================
[[0.07523407]
 [0.        ]
 [0.7916527 ]
 [0.        ]
 [0.        ]
 [0.28801352]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9527116 ]
 [0.        ]]
[[-0.9805522]
 [-0.       ]
 [ 2.6054296]
 [ 0.       ]
 [-0.       ]
 [-1.6702809]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3065243]
 [ 0.       ]]
--- 0.2928812503814697 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3695.739013671875, (1497.8944, 2.9295936, 2194.2651, 0.64983326)
   validation loss 1550.5816650390625, (1203.1743, 0.07074453, 346.68677, 0.64983326)
decoder loss ratio: 46613.061820, decoder SINDy loss  ratio: 0.748372
--- 0.25414180755615234 seconds for one epoch ---
--- 0.2914268970489502 seconds for one epoch ---
--- 0.5244467258453369 seconds for one epoch ---
--- 0.29180455207824707 seconds for one epoch ---
--- 0.5380470752716064 seconds for one epoch ---
--- 0.29842495918273926 seconds for one epoch ---
--- 0.5301682949066162 seconds for one epoch ---
--- 0.29094648361206055 seconds for one epoch ---
--- 0.5221521854400635 seconds for one epoch ---
--- 0.29911351203918457 seconds for one epoch ---
--- 0.5487518310546875 seconds for one epoch ---
--- 0.2902381420135498 seconds for one epoch ---
--- 0.5599665641784668 seconds for one epoch ---
--- 0.29982829093933105 seconds for one epoch ---
--- 0.5451180934906006 seconds for one epoch ---
--- 0.29801082611083984 seconds for one epoch ---
--- 0.5515727996826172 seconds for one epoch ---
--- 0.30031299591064453 seconds for one epoch ---
--- 0.5771021842956543 seconds for one epoch ---
--- 0.3014094829559326 seconds for one epoch ---
--- 0.5549361705780029 seconds for one epoch ---
--- 0.29439210891723633 seconds for one epoch ---
--- 0.5465869903564453 seconds for one epoch ---
--- 0.2958333492279053 seconds for one epoch ---
=========================
[[0.06223141]
 [0.        ]
 [0.75250125]
 [0.        ]
 [0.        ]
 [0.22529665]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94806516]
 [0.        ]]
[[-0.89817774]
 [-0.        ]
 [ 2.513032  ]
 [ 0.        ]
 [-0.        ]
 [-1.5342228 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2655144 ]
 [ 0.        ]]
--- 0.2564413547515869 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3143.8505859375, (1845.2651, 2.2924151, 1295.6693, 0.6238853)
   validation loss 1222.2318115234375, (887.77704, 0.055451464, 333.77533, 0.6238853)
decoder loss ratio: 34394.023723, decoder SINDy loss  ratio: 0.720501
--- 0.31664276123046875 seconds for one epoch ---
--- 0.5579192638397217 seconds for one epoch ---
--- 0.2925846576690674 seconds for one epoch ---
--- 0.538442850112915 seconds for one epoch ---
--- 0.2926499843597412 seconds for one epoch ---
--- 0.5589885711669922 seconds for one epoch ---
--- 0.3090178966522217 seconds for one epoch ---
--- 0.555079460144043 seconds for one epoch ---
--- 0.30461573600769043 seconds for one epoch ---
--- 0.5410561561584473 seconds for one epoch ---
--- 0.2952902317047119 seconds for one epoch ---
--- 0.5603206157684326 seconds for one epoch ---
--- 0.2990102767944336 seconds for one epoch ---
--- 0.5588829517364502 seconds for one epoch ---
--- 0.298586368560791 seconds for one epoch ---
--- 0.548818826675415 seconds for one epoch ---
--- 0.2919299602508545 seconds for one epoch ---
--- 0.5564048290252686 seconds for one epoch ---
--- 0.30575990676879883 seconds for one epoch ---
--- 0.5462367534637451 seconds for one epoch ---
--- 0.29239463806152344 seconds for one epoch ---
--- 0.5463314056396484 seconds for one epoch ---
--- 0.2943150997161865 seconds for one epoch ---
--- 0.5416486263275146 seconds for one epoch ---
=========================
[[0.05757548]
 [0.        ]
 [0.6981972 ]
 [0.        ]
 [0.        ]
 [0.20139273]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94613737]
 [0.        ]]
[[-0.8692071]
 [-0.       ]
 [ 2.3996148]
 [ 0.       ]
 [-0.       ]
 [-1.4765948]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2497528]
 [ 0.       ]]
--- 0.2924363613128662 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3642.555908203125, (1889.261, 0.6334467, 1752.0537, 0.6077663)
   validation loss 1034.3668212890625, (710.52985, 0.11309436, 323.11606, 0.6077663)
decoder loss ratio: 27527.159776, decoder SINDy loss  ratio: 0.697491
--- 0.263857364654541 seconds for one epoch ---
--- 0.2982804775238037 seconds for one epoch ---
--- 0.5460107326507568 seconds for one epoch ---
--- 0.29654836654663086 seconds for one epoch ---
--- 0.5407168865203857 seconds for one epoch ---
--- 0.29914188385009766 seconds for one epoch ---
--- 0.5930109024047852 seconds for one epoch ---
--- 0.2970712184906006 seconds for one epoch ---
--- 0.5577428340911865 seconds for one epoch ---
--- 0.29403018951416016 seconds for one epoch ---
--- 0.5548827648162842 seconds for one epoch ---
--- 0.2994253635406494 seconds for one epoch ---
--- 0.5778679847717285 seconds for one epoch ---
--- 0.2902100086212158 seconds for one epoch ---
--- 0.5485215187072754 seconds for one epoch ---
--- 0.2937479019165039 seconds for one epoch ---
--- 0.5563094615936279 seconds for one epoch ---
--- 0.2964210510253906 seconds for one epoch ---
--- 0.6015417575836182 seconds for one epoch ---
--- 0.2986791133880615 seconds for one epoch ---
--- 0.5662534236907959 seconds for one epoch ---
--- 0.29485607147216797 seconds for one epoch ---
--- 0.5778651237487793 seconds for one epoch ---
--- 0.3042457103729248 seconds for one epoch ---
=========================
[[0.05108231]
 [0.        ]
 [0.6414059 ]
 [0.        ]
 [0.        ]
 [0.17698254]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9413935 ]
 [0.        ]]
[[-0.8208685]
 [-0.       ]
 [ 2.293033 ]
 [ 0.       ]
 [-0.       ]
 [-1.4120584]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.212448 ]
 [ 0.       ]]
--- 0.26941847801208496 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4608.10107421875, (1147.2323, 0.79649526, 3459.485, 0.5875889)
   validation loss 1275.688232421875, (884.7533, 0.15129422, 390.19592, 0.5875889)
decoder loss ratio: 34276.878682, decoder SINDy loss  ratio: 0.842293
--- 0.2982044219970703 seconds for one epoch ---
--- 0.5646615028381348 seconds for one epoch ---
--- 0.4143977165222168 seconds for one epoch ---
--- 0.5685040950775146 seconds for one epoch ---
--- 0.29294371604919434 seconds for one epoch ---
--- 0.5788733959197998 seconds for one epoch ---
--- 0.29321813583374023 seconds for one epoch ---
--- 0.5650570392608643 seconds for one epoch ---
--- 0.2954287528991699 seconds for one epoch ---
--- 0.5604128837585449 seconds for one epoch ---
--- 0.3097858428955078 seconds for one epoch ---
--- 0.5929579734802246 seconds for one epoch ---
--- 0.2923870086669922 seconds for one epoch ---
--- 0.5934016704559326 seconds for one epoch ---
--- 0.29711365699768066 seconds for one epoch ---
--- 0.5869009494781494 seconds for one epoch ---
--- 0.3055858612060547 seconds for one epoch ---
--- 0.5791378021240234 seconds for one epoch ---
--- 0.29652905464172363 seconds for one epoch ---
--- 0.575101375579834 seconds for one epoch ---
--- 0.29636287689208984 seconds for one epoch ---
--- 0.5688319206237793 seconds for one epoch ---
--- 0.3148505687713623 seconds for one epoch ---
--- 0.5777630805969238 seconds for one epoch ---
=========================
[[0.05088909]
 [0.        ]
 [0.6042446 ]
 [0.        ]
 [0.        ]
 [0.16926058]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9422811 ]
 [0.        ]]
[[-0.82538664]
 [-0.        ]
 [ 2.227662  ]
 [ 0.        ]
 [-0.        ]
 [-1.3912909 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.2196085 ]
 [ 0.        ]]
--- 0.2909965515136719 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2972.134521484375, (1703.356, 0.33766097, 1267.8608, 0.5800652)
   validation loss 1962.0042724609375, (1565.9459, 0.10700163, 395.37122, 0.5800652)
decoder loss ratio: 60667.463653, decoder SINDy loss  ratio: 0.853464
--- 0.26529526710510254 seconds for one epoch ---
--- 0.30623555183410645 seconds for one epoch ---
--- 0.5641744136810303 seconds for one epoch ---
--- 0.29660654067993164 seconds for one epoch ---
--- 0.5918612480163574 seconds for one epoch ---
--- 0.28912854194641113 seconds for one epoch ---
--- 0.5915229320526123 seconds for one epoch ---
--- 0.29786109924316406 seconds for one epoch ---
--- 0.5775506496429443 seconds for one epoch ---
--- 0.31584835052490234 seconds for one epoch ---
--- 0.597529411315918 seconds for one epoch ---
--- 0.2940497398376465 seconds for one epoch ---
--- 0.6003499031066895 seconds for one epoch ---
--- 0.29110002517700195 seconds for one epoch ---
--- 0.576754093170166 seconds for one epoch ---
--- 0.3150327205657959 seconds for one epoch ---
--- 0.6065058708190918 seconds for one epoch ---
--- 0.28824377059936523 seconds for one epoch ---
--- 0.5820071697235107 seconds for one epoch ---
--- 0.30202531814575195 seconds for one epoch ---
--- 0.5952188968658447 seconds for one epoch ---
--- 0.2918863296508789 seconds for one epoch ---
--- 0.5845198631286621 seconds for one epoch ---
--- 0.2941904067993164 seconds for one epoch ---
=========================
[[0.04763244]
 [0.        ]
 [0.5482691 ]
 [0.        ]
 [0.        ]
 [0.16579627]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9364381 ]
 [0.        ]]
[[-0.8008988]
 [-0.       ]
 [ 2.132768 ]
 [ 0.       ]
 [-0.       ]
 [-1.3825638]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.176617 ]
 [ 0.       ]]
--- 0.25211644172668457 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3593.660888671875, (1821.9535, 0.4157956, 1770.7238, 0.56788605)
   validation loss 2177.450927734375, (1778.0204, 0.10915704, 398.75345, 0.56788605)
decoder loss ratio: 68883.596523, decoder SINDy loss  ratio: 0.860765
--- 0.3023998737335205 seconds for one epoch ---
--- 0.5899093151092529 seconds for one epoch ---
--- 0.3023509979248047 seconds for one epoch ---
--- 0.5867805480957031 seconds for one epoch ---
--- 0.3000514507293701 seconds for one epoch ---
--- 0.578683614730835 seconds for one epoch ---
--- 0.2953805923461914 seconds for one epoch ---
--- 0.5859894752502441 seconds for one epoch ---
--- 0.2952568531036377 seconds for one epoch ---
--- 0.5918259620666504 seconds for one epoch ---
--- 0.3008425235748291 seconds for one epoch ---
--- 0.5933356285095215 seconds for one epoch ---
--- 0.2978801727294922 seconds for one epoch ---
--- 0.6012349128723145 seconds for one epoch ---
--- 0.29760169982910156 seconds for one epoch ---
--- 0.6074094772338867 seconds for one epoch ---
--- 0.29311275482177734 seconds for one epoch ---
--- 0.5777227878570557 seconds for one epoch ---
--- 0.2826402187347412 seconds for one epoch ---
--- 0.6145706176757812 seconds for one epoch ---
--- 0.31825709342956543 seconds for one epoch ---
--- 0.6074802875518799 seconds for one epoch ---
--- 0.2942993640899658 seconds for one epoch ---
--- 0.5967938899993896 seconds for one epoch ---
=========================
[[0.04433233]
 [0.        ]
 [0.51945335]
 [0.        ]
 [0.        ]
 [0.15846306]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9310606 ]
 [0.        ]]
[[-0.7730972]
 [-0.       ]
 [ 2.085082 ]
 [ 0.       ]
 [-0.       ]
 [-1.361413 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1401923]
 [ 0.       ]]
--- 0.29230308532714844 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5475.10302734375, (1772.103, 0.70334506, 3701.7397, 0.5569846)
   validation loss 1021.1009521484375, (675.968, 0.07584138, 344.50006, 0.5569846)
decoder loss ratio: 26188.174533, decoder SINDy loss  ratio: 0.743652
--- 0.2594296932220459 seconds for one epoch ---
--- 0.3201591968536377 seconds for one epoch ---
--- 0.6038501262664795 seconds for one epoch ---
--- 0.2953941822052002 seconds for one epoch ---
--- 0.6009724140167236 seconds for one epoch ---
--- 0.29076647758483887 seconds for one epoch ---
--- 0.6067898273468018 seconds for one epoch ---
--- 0.3106040954589844 seconds for one epoch ---
--- 0.6217870712280273 seconds for one epoch ---
--- 0.29247474670410156 seconds for one epoch ---
--- 0.6207637786865234 seconds for one epoch ---
--- 0.3046393394470215 seconds for one epoch ---
--- 0.604581356048584 seconds for one epoch ---
--- 0.318159818649292 seconds for one epoch ---
--- 0.6027958393096924 seconds for one epoch ---
--- 0.2994110584259033 seconds for one epoch ---
--- 0.625016450881958 seconds for one epoch ---
--- 0.30484914779663086 seconds for one epoch ---
--- 0.6092734336853027 seconds for one epoch ---
--- 0.2911670207977295 seconds for one epoch ---
--- 0.6023685932159424 seconds for one epoch ---
--- 0.2823753356933594 seconds for one epoch ---
--- 0.605414867401123 seconds for one epoch ---
--- 0.30248403549194336 seconds for one epoch ---
=========================
[[0.04308999]
 [0.        ]
 [0.48307994]
 [0.        ]
 [0.        ]
 [0.15207718]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92763305]
 [0.        ]]
[[-0.76471895]
 [-0.        ]
 [ 2.0251    ]
 [ 0.        ]
 [-0.        ]
 [-1.342421  ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1184034 ]
 [ 0.        ]]
--- 0.2614588737487793 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2962.327392578125, (1513.6161, 0.1400124, 1448.0221, 0.5489774)
   validation loss 1109.8077392578125, (794.6794, 0.11165669, 314.46777, 0.5489774)
decoder loss ratio: 30787.258895, decoder SINDy loss  ratio: 0.678823
--- 0.2931652069091797 seconds for one epoch ---
--- 0.593759298324585 seconds for one epoch ---
--- 0.29717040061950684 seconds for one epoch ---
--- 0.6140406131744385 seconds for one epoch ---
--- 0.29985833168029785 seconds for one epoch ---
--- 0.602745771408081 seconds for one epoch ---
--- 0.29683637619018555 seconds for one epoch ---
--- 0.6229994297027588 seconds for one epoch ---
--- 0.30767250061035156 seconds for one epoch ---
--- 0.5917294025421143 seconds for one epoch ---
--- 0.31798791885375977 seconds for one epoch ---
--- 0.614832878112793 seconds for one epoch ---
--- 0.288053035736084 seconds for one epoch ---
--- 0.6295216083526611 seconds for one epoch ---
--- 0.3012518882751465 seconds for one epoch ---
--- 0.6152076721191406 seconds for one epoch ---
--- 0.3142075538635254 seconds for one epoch ---
--- 0.6249196529388428 seconds for one epoch ---
--- 0.2944478988647461 seconds for one epoch ---
--- 0.6365828514099121 seconds for one epoch ---
--- 0.29816627502441406 seconds for one epoch ---
--- 0.6267306804656982 seconds for one epoch ---
--- 0.29520606994628906 seconds for one epoch ---
--- 0.6237349510192871 seconds for one epoch ---
=========================
[[0.04266601]
 [0.        ]
 [0.46156207]
 [0.        ]
 [0.        ]
 [0.1497203 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.924769  ]
 [0.        ]]
[[-0.76368904]
 [-0.        ]
 [ 1.9896295 ]
 [ 0.        ]
 [-0.        ]
 [-1.3357433 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-3.1009116 ]
 [ 0.        ]]
--- 0.29805731773376465 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4958.50341796875, (2203.7925, 0.8562226, 2753.3115, 0.54370046)
   validation loss 985.91796875, (684.4204, 0.1410914, 300.81274, 0.54370046)
decoder loss ratio: 26515.634896, decoder SINDy loss  ratio: 0.649347
--- 0.2607154846191406 seconds for one epoch ---
--- 0.3067436218261719 seconds for one epoch ---
--- 0.6094598770141602 seconds for one epoch ---
--- 0.29627251625061035 seconds for one epoch ---
--- 0.5895748138427734 seconds for one epoch ---
--- 0.2871723175048828 seconds for one epoch ---
--- 0.6182205677032471 seconds for one epoch ---
--- 0.31736302375793457 seconds for one epoch ---
--- 0.6226623058319092 seconds for one epoch ---
--- 0.29148268699645996 seconds for one epoch ---
--- 0.6102831363677979 seconds for one epoch ---
--- 0.2862889766693115 seconds for one epoch ---
--- 0.644777774810791 seconds for one epoch ---
--- 0.308490514755249 seconds for one epoch ---
--- 0.6373717784881592 seconds for one epoch ---
--- 0.29866695404052734 seconds for one epoch ---
--- 0.6411628723144531 seconds for one epoch ---
--- 0.3020811080932617 seconds for one epoch ---
--- 0.6318528652191162 seconds for one epoch ---
--- 0.3091278076171875 seconds for one epoch ---
--- 0.6117954254150391 seconds for one epoch ---
--- 0.2953307628631592 seconds for one epoch ---
--- 0.638336181640625 seconds for one epoch ---
--- 0.28478264808654785 seconds for one epoch ---
=========================
[[0.04115097]
 [0.        ]
 [0.4617427 ]
 [0.        ]
 [0.        ]
 [0.1442987 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.92029744]
 [0.        ]]
[[-0.7508543]
 [-0.       ]
 [ 1.9902039]
 [ 0.       ]
 [-0.       ]
 [-1.3187515]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0747166]
 [ 0.       ]]
--- 0.2517523765563965 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6120.234375, (2027.1566, 0.37281543, 4092.1648, 0.5399442)
   validation loss 1400.45947265625, (1063.44, 0.087818794, 336.3918, 0.5399442)
decoder loss ratio: 41199.509543, decoder SINDy loss  ratio: 0.726149
--- 0.2953641414642334 seconds for one epoch ---
--- 0.6307377815246582 seconds for one epoch ---
--- 0.29637575149536133 seconds for one epoch ---
--- 0.6556494235992432 seconds for one epoch ---
--- 0.29303693771362305 seconds for one epoch ---
--- 0.6244118213653564 seconds for one epoch ---
--- 0.29548072814941406 seconds for one epoch ---
--- 0.6321954727172852 seconds for one epoch ---
--- 0.29881834983825684 seconds for one epoch ---
--- 0.6492679119110107 seconds for one epoch ---
--- 0.29254770278930664 seconds for one epoch ---
--- 0.6199636459350586 seconds for one epoch ---
--- 0.2832012176513672 seconds for one epoch ---
--- 0.6412363052368164 seconds for one epoch ---
--- 0.28345489501953125 seconds for one epoch ---
--- 0.6499316692352295 seconds for one epoch ---
--- 0.2898428440093994 seconds for one epoch ---
--- 0.6431465148925781 seconds for one epoch ---
--- 0.29490184783935547 seconds for one epoch ---
--- 0.6531679630279541 seconds for one epoch ---
--- 0.2908947467803955 seconds for one epoch ---
--- 0.6588985919952393 seconds for one epoch ---
--- 0.29603004455566406 seconds for one epoch ---
--- 0.6633028984069824 seconds for one epoch ---
=========================
[[0.03860581]
 [0.        ]
 [0.44620574]
 [0.        ]
 [0.        ]
 [0.13940513]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9116021 ]
 [0.        ]]
[[-0.7254341]
 [-0.       ]
 [ 1.9644798]
 [ 0.       ]
 [-0.       ]
 [-1.3028618]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0272777]
 [ 0.       ]]
--- 0.29294848442077637 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3881.372314453125, (1010.1441, 1.5700824, 2869.1248, 0.53345245)
   validation loss 1458.920166015625, (1043.6027, 0.0942845, 414.68982, 0.53345245)
decoder loss ratio: 40430.978866, decoder SINDy loss  ratio: 0.895166
--- 0.26302480697631836 seconds for one epoch ---
--- 0.30500316619873047 seconds for one epoch ---
--- 0.6599771976470947 seconds for one epoch ---
--- 0.29314708709716797 seconds for one epoch ---
--- 0.6527464389801025 seconds for one epoch ---
--- 0.28848814964294434 seconds for one epoch ---
--- 0.6549930572509766 seconds for one epoch ---
--- 0.2941775321960449 seconds for one epoch ---
--- 0.6546947956085205 seconds for one epoch ---
--- 0.289447546005249 seconds for one epoch ---
--- 0.6376092433929443 seconds for one epoch ---
--- 0.29235339164733887 seconds for one epoch ---
--- 0.6549639701843262 seconds for one epoch ---
--- 0.2859654426574707 seconds for one epoch ---
--- 0.6495819091796875 seconds for one epoch ---
--- 0.29094457626342773 seconds for one epoch ---
--- 0.6410655975341797 seconds for one epoch ---
--- 0.2957606315612793 seconds for one epoch ---
--- 0.6713666915893555 seconds for one epoch ---
--- 0.2952260971069336 seconds for one epoch ---
--- 0.6526050567626953 seconds for one epoch ---
--- 0.29108548164367676 seconds for one epoch ---
--- 0.6606545448303223 seconds for one epoch ---
--- 0.3055143356323242 seconds for one epoch ---
=========================
[[0.03750674]
 [0.        ]
 [0.42710707]
 [0.        ]
 [0.        ]
 [0.13750808]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.90330446]
 [0.        ]]
[[-0.7152229]
 [-0.       ]
 [ 1.9325703]
 [ 0.       ]
 [-0.       ]
 [-1.2969457]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.985827 ]
 [ 0.       ]]
--- 0.2593052387237549 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3937.1318359375, (1814.9419, 0.62248224, 2121.04, 0.5273757)
   validation loss 1526.077392578125, (1189.6434, 0.11828258, 335.78836, 0.5273757)
decoder loss ratio: 46088.851891, decoder SINDy loss  ratio: 0.724846
--- 0.2933464050292969 seconds for one epoch ---
--- 0.6608409881591797 seconds for one epoch ---
--- 0.3008155822753906 seconds for one epoch ---
--- 0.6626567840576172 seconds for one epoch ---
--- 0.29741978645324707 seconds for one epoch ---
--- 0.6613748073577881 seconds for one epoch ---
--- 0.29988932609558105 seconds for one epoch ---
--- 0.6699039936065674 seconds for one epoch ---
--- 0.29172658920288086 seconds for one epoch ---
--- 0.6622247695922852 seconds for one epoch ---
--- 0.29753589630126953 seconds for one epoch ---
--- 0.6990466117858887 seconds for one epoch ---
--- 0.30649304389953613 seconds for one epoch ---
--- 0.6827919483184814 seconds for one epoch ---
--- 0.2946960926055908 seconds for one epoch ---
--- 0.6515893936157227 seconds for one epoch ---
--- 0.29405832290649414 seconds for one epoch ---
--- 0.6743159294128418 seconds for one epoch ---
--- 0.2940330505371094 seconds for one epoch ---
--- 0.6681973934173584 seconds for one epoch ---
--- 0.2912006378173828 seconds for one epoch ---
--- 0.6498355865478516 seconds for one epoch ---
--- 0.29125094413757324 seconds for one epoch ---
--- 0.6722843647003174 seconds for one epoch ---
=========================
[[0.03732322]
 [0.        ]
 [0.4141692 ]
 [0.        ]
 [0.        ]
 [0.13630728]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8978132 ]
 [0.        ]]
[[-0.71492195]
 [-0.        ]
 [ 1.9107887 ]
 [ 0.        ]
 [-0.        ]
 [-1.2932589 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.9601412 ]
 [ 0.        ]]
--- 0.30100131034851074 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3593.814453125, (1851.9866, 1.8374363, 1739.4666, 0.5238958)
   validation loss 1012.896484375, (684.286, 0.12446252, 327.96207, 0.5238958)
decoder loss ratio: 26510.428029, decoder SINDy loss  ratio: 0.707952
--- 0.25768589973449707 seconds for one epoch ---
--- 0.29065799713134766 seconds for one epoch ---
--- 0.6673073768615723 seconds for one epoch ---
--- 0.292553186416626 seconds for one epoch ---
--- 0.678647518157959 seconds for one epoch ---
--- 0.2947866916656494 seconds for one epoch ---
--- 0.6490662097930908 seconds for one epoch ---
--- 0.2966275215148926 seconds for one epoch ---
--- 0.6792054176330566 seconds for one epoch ---
--- 0.2961459159851074 seconds for one epoch ---
--- 0.6752722263336182 seconds for one epoch ---
--- 0.29338908195495605 seconds for one epoch ---
--- 0.6896247863769531 seconds for one epoch ---
--- 0.28247737884521484 seconds for one epoch ---
--- 0.6830029487609863 seconds for one epoch ---
--- 0.29231834411621094 seconds for one epoch ---
--- 0.6746478080749512 seconds for one epoch ---
--- 0.3014795780181885 seconds for one epoch ---
--- 0.6765100955963135 seconds for one epoch ---
--- 0.2897782325744629 seconds for one epoch ---
--- 0.673781156539917 seconds for one epoch ---
--- 0.28653812408447266 seconds for one epoch ---
--- 0.6721689701080322 seconds for one epoch ---
--- 0.3112199306488037 seconds for one epoch ---
=========================
[[0.03578457]
 [0.        ]
 [0.40187135]
 [0.        ]
 [0.        ]
 [0.1312349 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8886719 ]
 [0.        ]]
[[-0.6985078]
 [-0.       ]
 [ 1.8899069]
 [ 0.       ]
 [-0.       ]
 [-1.2757336]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9199467]
 [ 0.       ]]
--- 0.25218653678894043 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4563.5830078125, (1538.5773, 1.9902366, 3022.4988, 0.5167779)
   validation loss 967.6694946289062, (632.264, 0.10172596, 334.78696, 0.5167779)
decoder loss ratio: 24495.004129, decoder SINDy loss  ratio: 0.722685
--- 0.2957906723022461 seconds for one epoch ---
--- 0.6878800392150879 seconds for one epoch ---
--- 0.29814863204956055 seconds for one epoch ---
--- 0.669816255569458 seconds for one epoch ---
--- 0.29819321632385254 seconds for one epoch ---
--- 0.696662187576294 seconds for one epoch ---
--- 0.29021334648132324 seconds for one epoch ---
--- 0.6891107559204102 seconds for one epoch ---
--- 0.2981150150299072 seconds for one epoch ---
--- 0.6655690670013428 seconds for one epoch ---
--- 0.297454833984375 seconds for one epoch ---
--- 0.6725296974182129 seconds for one epoch ---
--- 0.2990093231201172 seconds for one epoch ---
--- 0.6847996711730957 seconds for one epoch ---
--- 0.31085658073425293 seconds for one epoch ---
--- 0.6741864681243896 seconds for one epoch ---
--- 0.29338741302490234 seconds for one epoch ---
--- 0.6936769485473633 seconds for one epoch ---
--- 0.3012099266052246 seconds for one epoch ---
--- 0.6833994388580322 seconds for one epoch ---
--- 0.3045182228088379 seconds for one epoch ---
--- 0.6869845390319824 seconds for one epoch ---
--- 0.31531476974487305 seconds for one epoch ---
--- 0.7153830528259277 seconds for one epoch ---
=========================
[[0.03588436]
 [0.        ]
 [0.37913898]
 [0.        ]
 [0.        ]
 [0.13417585]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8809423 ]
 [0.        ]]
[[-0.7010262]
 [-0.       ]
 [ 1.8505913]
 [ 0.       ]
 [-0.       ]
 [-1.2865759]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8881752]
 [ 0.       ]]
--- 0.26737475395202637 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3430.278564453125, (1845.9506, 0.74434483, 1583.0713, 0.5124507)
   validation loss 976.0745849609375, (658.37946, 0.11764844, 317.065, 0.5124507)
decoder loss ratio: 25506.763106, decoder SINDy loss  ratio: 0.684429
--- 0.2509324550628662 seconds for one epoch ---
--- 0.3016989231109619 seconds for one epoch ---
--- 0.6980626583099365 seconds for one epoch ---
--- 0.28408002853393555 seconds for one epoch ---
--- 0.6877782344818115 seconds for one epoch ---
--- 0.29868102073669434 seconds for one epoch ---
--- 0.6882491111755371 seconds for one epoch ---
--- 0.2977573871612549 seconds for one epoch ---
--- 0.6797235012054443 seconds for one epoch ---
--- 0.29337430000305176 seconds for one epoch ---
--- 0.6931290626525879 seconds for one epoch ---
--- 0.29573607444763184 seconds for one epoch ---
--- 0.6874144077301025 seconds for one epoch ---
--- 0.4482734203338623 seconds for one epoch ---
--- 0.6758689880371094 seconds for one epoch ---
--- 0.294691801071167 seconds for one epoch ---
--- 0.6902148723602295 seconds for one epoch ---
--- 0.30203938484191895 seconds for one epoch ---
--- 0.7065553665161133 seconds for one epoch ---
--- 0.3033626079559326 seconds for one epoch ---
--- 0.7004311084747314 seconds for one epoch ---
--- 0.3014538288116455 seconds for one epoch ---
--- 0.691554069519043 seconds for one epoch ---
--- 0.32271456718444824 seconds for one epoch ---
=========================
[[0.03561158]
 [0.        ]
 [0.38063428]
 [0.        ]
 [0.        ]
 [0.12904091]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8752222 ]
 [0.        ]]
[[-0.6989772]
 [-0.       ]
 [ 1.8533248]
 [ 0.       ]
 [-0.       ]
 [-1.2684767]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8658166]
 [ 0.       ]]
--- 0.27335309982299805 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2257.531494140625, (1268.8035, 0.68577373, 987.5316, 0.51051736)
   validation loss 2063.870849609375, (1675.5693, 0.099449076, 387.6915, 0.51051736)
decoder loss ratio: 64914.464991, decoder SINDy loss  ratio: 0.836887
--- 0.3018498420715332 seconds for one epoch ---
--- 0.6947290897369385 seconds for one epoch ---
--- 0.3010289669036865 seconds for one epoch ---
--- 0.6987471580505371 seconds for one epoch ---
--- 0.30303120613098145 seconds for one epoch ---
--- 0.7223615646362305 seconds for one epoch ---
--- 0.3056325912475586 seconds for one epoch ---
--- 0.7033078670501709 seconds for one epoch ---
--- 0.2951202392578125 seconds for one epoch ---
--- 0.716973066329956 seconds for one epoch ---
--- 0.2958977222442627 seconds for one epoch ---
--- 0.701876163482666 seconds for one epoch ---
--- 0.3104219436645508 seconds for one epoch ---
--- 0.7070493698120117 seconds for one epoch ---
--- 0.30709314346313477 seconds for one epoch ---
--- 0.6959877014160156 seconds for one epoch ---
--- 0.316694974899292 seconds for one epoch ---
--- 0.6982834339141846 seconds for one epoch ---
--- 0.30891990661621094 seconds for one epoch ---
--- 0.7128300666809082 seconds for one epoch ---
--- 0.3094162940979004 seconds for one epoch ---
--- 0.7160234451293945 seconds for one epoch ---
--- 0.29170823097229004 seconds for one epoch ---
--- 0.7217686176300049 seconds for one epoch ---
=========================
[[0.03914417]
 [0.        ]
 [0.3733167 ]
 [0.        ]
 [0.        ]
 [0.13251469]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.87924355]
 [0.        ]]
[[-0.74019814]
 [-0.        ]
 [ 1.8405603 ]
 [ 0.        ]
 [-0.        ]
 [-1.2812567 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8815145 ]
 [ 0.        ]]
--- 0.2874484062194824 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4214.23583984375, (1650.8715, 0.8380231, 2562.0144, 0.51223415)
   validation loss 1699.38916015625, (1330.8342, 0.13572058, 367.90695, 0.51223415)
decoder loss ratio: 51558.828443, decoder SINDy loss  ratio: 0.794179
--- 0.26387548446655273 seconds for one epoch ---
--- 0.2916407585144043 seconds for one epoch ---
--- 0.7150778770446777 seconds for one epoch ---
--- 0.30437541007995605 seconds for one epoch ---
--- 0.7282543182373047 seconds for one epoch ---
--- 0.2960035800933838 seconds for one epoch ---
--- 0.7097311019897461 seconds for one epoch ---
--- 0.28582334518432617 seconds for one epoch ---
--- 0.7137537002563477 seconds for one epoch ---
--- 0.3087046146392822 seconds for one epoch ---
--- 0.7115371227264404 seconds for one epoch ---
--- 0.2913057804107666 seconds for one epoch ---
--- 0.7367525100708008 seconds for one epoch ---
--- 0.29851317405700684 seconds for one epoch ---
--- 0.7193379402160645 seconds for one epoch ---
--- 0.29184818267822266 seconds for one epoch ---
--- 0.7039601802825928 seconds for one epoch ---
--- 0.2996523380279541 seconds for one epoch ---
--- 0.7316787242889404 seconds for one epoch ---
--- 0.3129386901855469 seconds for one epoch ---
--- 0.717766284942627 seconds for one epoch ---
--- 0.3037221431732178 seconds for one epoch ---
--- 0.7288661003112793 seconds for one epoch ---
--- 0.3016083240509033 seconds for one epoch ---
=========================
[[0.04129443]
 [0.        ]
 [0.3577084 ]
 [0.        ]
 [0.        ]
 [0.12987857]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8808159 ]
 [0.        ]]
[[-0.76376987]
 [-0.        ]
 [ 1.8128877 ]
 [ 0.        ]
 [-0.        ]
 [-1.2720168 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8877962 ]
 [ 0.        ]]
--- 0.25328993797302246 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3042.56005859375, (970.167, 0.18589662, 2071.6995, 0.5077922)
   validation loss 865.8243408203125, (551.8184, 0.15923615, 313.33887, 0.5077922)
decoder loss ratio: 21378.403606, decoder SINDy loss  ratio: 0.676386
--- 0.29674482345581055 seconds for one epoch ---
--- 0.7238881587982178 seconds for one epoch ---
--- 0.3131442070007324 seconds for one epoch ---
--- 0.7239670753479004 seconds for one epoch ---
--- 0.2871241569519043 seconds for one epoch ---
--- 0.7219200134277344 seconds for one epoch ---
--- 0.3292405605316162 seconds for one epoch ---
--- 0.7149674892425537 seconds for one epoch ---
--- 0.29975247383117676 seconds for one epoch ---
--- 0.735708475112915 seconds for one epoch ---
--- 0.29795122146606445 seconds for one epoch ---
--- 0.7170901298522949 seconds for one epoch ---
--- 0.2990093231201172 seconds for one epoch ---
--- 0.7547264099121094 seconds for one epoch ---
--- 0.3016171455383301 seconds for one epoch ---
--- 0.747443675994873 seconds for one epoch ---
--- 0.29990530014038086 seconds for one epoch ---
--- 0.7223176956176758 seconds for one epoch ---
--- 0.2802107334136963 seconds for one epoch ---
--- 0.7495558261871338 seconds for one epoch ---
--- 0.2908773422241211 seconds for one epoch ---
--- 0.7310755252838135 seconds for one epoch ---
--- 0.30803751945495605 seconds for one epoch ---
--- 0.7403666973114014 seconds for one epoch ---
=========================
[[0.03950589]
 [0.        ]
 [0.35591048]
 [0.        ]
 [0.        ]
 [0.1194815 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.87269473]
 [0.        ]]
[[-0.74550074]
 [-0.        ]
 [ 1.8097256 ]
 [ 0.        ]
 [-0.        ]
 [-1.2331933 ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-2.8563027 ]
 [ 0.        ]]
--- 0.2863893508911133 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2772.555908203125, (1306.5829, 1.3082595, 1464.1621, 0.50264543)
   validation loss 1260.56787109375, (912.9702, 0.15957528, 346.93542, 0.50264543)
decoder loss ratio: 35370.051109, decoder SINDy loss  ratio: 0.748909
THRESHOLDING: 3 active coefficients
--- 0.7156813144683838 seconds for one epoch ---
--- 0.2902839183807373 seconds for one epoch ---
--- 0.7051119804382324 seconds for one epoch ---
--- 0.2902851104736328 seconds for one epoch ---
--- 0.7560639381408691 seconds for one epoch ---
--- 0.29563331604003906 seconds for one epoch ---
--- 0.720667839050293 seconds for one epoch ---
--- 0.28147053718566895 seconds for one epoch ---
--- 0.7386050224304199 seconds for one epoch ---
--- 0.29646944999694824 seconds for one epoch ---
--- 0.7262253761291504 seconds for one epoch ---
--- 0.2935311794281006 seconds for one epoch ---
--- 0.7464292049407959 seconds for one epoch ---
--- 0.29706239700317383 seconds for one epoch ---
--- 0.7434277534484863 seconds for one epoch ---
--- 0.29285216331481934 seconds for one epoch ---
--- 0.7474546432495117 seconds for one epoch ---
--- 0.29396891593933105 seconds for one epoch ---
--- 0.7669482231140137 seconds for one epoch ---
--- 0.3034250736236572 seconds for one epoch ---
--- 0.7463133335113525 seconds for one epoch ---
--- 0.29704880714416504 seconds for one epoch ---
--- 0.7440636157989502 seconds for one epoch ---
--- 0.2835853099822998 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.35612303]
 [0.        ]
 [0.        ]
 [0.13551256]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.885719  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.8101702]
 [ 0.       ]
 [-0.       ]
 [-1.2924055]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9077997]
 [ 0.       ]]
--- 0.25349903106689453 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3503.760986328125, (1491.6141, 2.1354413, 2009.5615, 0.45001516)
   validation loss 1467.4573974609375, (1121.558, 0.17535384, 345.27408, 0.45001516)
decoder loss ratio: 43451.103387, decoder SINDy loss  ratio: 0.745323
--- 0.2939589023590088 seconds for one epoch ---
--- 0.7199020385742188 seconds for one epoch ---
--- 0.2924063205718994 seconds for one epoch ---
--- 0.7360472679138184 seconds for one epoch ---
--- 0.29755401611328125 seconds for one epoch ---
--- 0.7598550319671631 seconds for one epoch ---
--- 0.29355502128601074 seconds for one epoch ---
--- 0.7343614101409912 seconds for one epoch ---
--- 0.28933262825012207 seconds for one epoch ---
--- 0.7486402988433838 seconds for one epoch ---
--- 0.29222989082336426 seconds for one epoch ---
--- 0.7282185554504395 seconds for one epoch ---
--- 0.2893247604370117 seconds for one epoch ---
--- 0.7435336112976074 seconds for one epoch ---
--- 0.2837953567504883 seconds for one epoch ---
--- 0.7352728843688965 seconds for one epoch ---
--- 0.28956055641174316 seconds for one epoch ---
--- 0.7273304462432861 seconds for one epoch ---
--- 0.29474616050720215 seconds for one epoch ---
--- 0.7781352996826172 seconds for one epoch ---
--- 0.2983694076538086 seconds for one epoch ---
--- 0.7517597675323486 seconds for one epoch ---
--- 0.29446935653686523 seconds for one epoch ---
--- 0.7237381935119629 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.3456738]
 [0.       ]
 [0.       ]
 [0.1394393]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9019494]
 [0.       ]]
[[-0.       ]
 [-0.       ]
 [ 1.7913126]
 [ 0.       ]
 [-0.       ]
 [-1.306084 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.979742 ]
 [ 0.       ]]
--- 0.2989470958709717 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3622.14111328125, (1502.0312, 0.56032497, 2119.0984, 0.45115492)
   validation loss 1199.3912353515625, (819.8592, 0.14566442, 378.9352, 0.45115492)
decoder loss ratio: 31762.768432, decoder SINDy loss  ratio: 0.817985
--- 0.255420446395874 seconds for one epoch ---
--- 0.29188036918640137 seconds for one epoch ---
--- 0.7501888275146484 seconds for one epoch ---
--- 0.2984766960144043 seconds for one epoch ---
--- 0.7594127655029297 seconds for one epoch ---
--- 0.29625916481018066 seconds for one epoch ---
--- 0.7609913349151611 seconds for one epoch ---
--- 0.28304362297058105 seconds for one epoch ---
--- 0.7520344257354736 seconds for one epoch ---
--- 0.27959537506103516 seconds for one epoch ---
--- 0.774531364440918 seconds for one epoch ---
--- 0.293870210647583 seconds for one epoch ---
--- 0.7532863616943359 seconds for one epoch ---
--- 0.29491496086120605 seconds for one epoch ---
--- 0.7583847045898438 seconds for one epoch ---
--- 0.29833292961120605 seconds for one epoch ---
--- 0.7614319324493408 seconds for one epoch ---
--- 0.2927970886230469 seconds for one epoch ---
--- 0.7713758945465088 seconds for one epoch ---
--- 0.3039536476135254 seconds for one epoch ---
--- 0.7651524543762207 seconds for one epoch ---
--- 0.2993490695953369 seconds for one epoch ---
--- 0.7735214233398438 seconds for one epoch ---
--- 0.2906332015991211 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.34358364]
 [0.        ]
 [0.        ]
 [0.138155  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9072658 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7875463]
 [ 0.       ]
 [-0.       ]
 [-1.301802 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0056496]
 [ 0.       ]]
--- 0.2504911422729492 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3201.318115234375, (1561.2605, 1.2268918, 1638.3793, 0.45135456)
   validation loss 1105.6895751953125, (741.87695, 0.12424078, 363.23706, 0.45135456)
decoder loss ratio: 28741.601119, decoder SINDy loss  ratio: 0.784098
--- 0.28000903129577637 seconds for one epoch ---
--- 0.7353997230529785 seconds for one epoch ---
--- 0.31272411346435547 seconds for one epoch ---
--- 0.7698380947113037 seconds for one epoch ---
--- 0.28147196769714355 seconds for one epoch ---
--- 0.7719714641571045 seconds for one epoch ---
--- 0.29462742805480957 seconds for one epoch ---
--- 0.7818880081176758 seconds for one epoch ---
--- 0.29815077781677246 seconds for one epoch ---
--- 0.7603240013122559 seconds for one epoch ---
--- 0.29715609550476074 seconds for one epoch ---
--- 0.7656447887420654 seconds for one epoch ---
--- 0.286740779876709 seconds for one epoch ---
--- 0.7790617942810059 seconds for one epoch ---
--- 0.27956342697143555 seconds for one epoch ---
--- 0.7891988754272461 seconds for one epoch ---
--- 0.2974889278411865 seconds for one epoch ---
--- 0.7802035808563232 seconds for one epoch ---
--- 0.31163477897644043 seconds for one epoch ---
--- 0.7778635025024414 seconds for one epoch ---
--- 0.29398512840270996 seconds for one epoch ---
--- 0.8038730621337891 seconds for one epoch ---
--- 0.28899669647216797 seconds for one epoch ---
--- 0.8038456439971924 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.34147677]
 [0.        ]
 [0.        ]
 [0.13659613]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91857994]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7837294]
 [ 0.       ]
 [-0.       ]
 [-1.2965121]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0655816]
 [ 0.       ]]
--- 0.3080728054046631 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3086.81005859375, (1541.4678, 1.1249133, 1543.7655, 0.45195714)
   validation loss 1212.083251953125, (856.4649, 0.14017409, 355.02618, 0.45195714)
decoder loss ratio: 33180.937300, decoder SINDy loss  ratio: 0.766374
--- 0.2511296272277832 seconds for one epoch ---
--- 0.29755496978759766 seconds for one epoch ---
--- 0.7730238437652588 seconds for one epoch ---
--- 0.2924938201904297 seconds for one epoch ---
--- 0.797196626663208 seconds for one epoch ---
--- 0.29439234733581543 seconds for one epoch ---
--- 0.7886629104614258 seconds for one epoch ---
--- 0.2963900566101074 seconds for one epoch ---
--- 0.8167176246643066 seconds for one epoch ---
--- 0.294583797454834 seconds for one epoch ---
--- 0.785377025604248 seconds for one epoch ---
--- 0.3083615303039551 seconds for one epoch ---
--- 0.783440113067627 seconds for one epoch ---
--- 0.309251070022583 seconds for one epoch ---
--- 0.7978994846343994 seconds for one epoch ---
--- 0.28421902656555176 seconds for one epoch ---
--- 0.7941799163818359 seconds for one epoch ---
--- 0.30028247833251953 seconds for one epoch ---
--- 0.7941081523895264 seconds for one epoch ---
--- 0.29950571060180664 seconds for one epoch ---
--- 0.7965481281280518 seconds for one epoch ---
--- 0.28762149810791016 seconds for one epoch ---
--- 0.7706422805786133 seconds for one epoch ---
--- 0.3121378421783447 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.34190655]
 [0.        ]
 [0.        ]
 [0.13748659]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9294645 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7845507]
 [ 0.       ]
 [-0.       ]
 [-1.2996761]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1309464]
 [-0.       ]]
--- 0.25655460357666016 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3502.878173828125, (1656.3337, 3.662051, 1842.429, 0.45348045)
   validation loss 1668.215087890625, (1338.8643, 0.20113821, 328.6962, 0.45348045)
decoder loss ratio: 51869.925718, decoder SINDy loss  ratio: 0.709537
--- 0.29442691802978516 seconds for one epoch ---
--- 0.783282995223999 seconds for one epoch ---
--- 0.29000091552734375 seconds for one epoch ---
--- 0.7863531112670898 seconds for one epoch ---
--- 0.2907896041870117 seconds for one epoch ---
--- 0.7700016498565674 seconds for one epoch ---
--- 0.2900393009185791 seconds for one epoch ---
--- 0.7512693405151367 seconds for one epoch ---
--- 0.2845168113708496 seconds for one epoch ---
--- 0.8067841529846191 seconds for one epoch ---
--- 0.2915477752685547 seconds for one epoch ---
--- 0.7913076877593994 seconds for one epoch ---
--- 0.29546070098876953 seconds for one epoch ---
--- 0.7911789417266846 seconds for one epoch ---
--- 0.29656076431274414 seconds for one epoch ---
--- 0.7892055511474609 seconds for one epoch ---
--- 0.2979435920715332 seconds for one epoch ---
--- 0.8246879577636719 seconds for one epoch ---
--- 0.306685209274292 seconds for one epoch ---
--- 0.786060094833374 seconds for one epoch ---
--- 0.29840683937072754 seconds for one epoch ---
--- 0.8036994934082031 seconds for one epoch ---
--- 0.29227423667907715 seconds for one epoch ---
--- 0.8065650463104248 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.3286727 ]
 [0.        ]
 [0.        ]
 [0.13861814]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9388607 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7601228]
 [ 0.       ]
 [-0.       ]
 [-1.3036306]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.1954265]
 [ 0.       ]]
--- 0.2896614074707031 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2886.88134765625, (1106.1263, 0.67958266, 1779.6233, 0.45213953)
   validation loss 854.8941040039062, (553.13763, 0.17134568, 301.133, 0.45213953)
decoder loss ratio: 21429.512241, decoder SINDy loss  ratio: 0.650038
--- 0.26479673385620117 seconds for one epoch ---
--- 0.2977485656738281 seconds for one epoch ---
--- 0.782850980758667 seconds for one epoch ---
--- 0.2889425754547119 seconds for one epoch ---
--- 0.785813570022583 seconds for one epoch ---
--- 0.29372692108154297 seconds for one epoch ---
--- 0.7918441295623779 seconds for one epoch ---
--- 0.29613780975341797 seconds for one epoch ---
--- 0.8092339038848877 seconds for one epoch ---
--- 0.2928447723388672 seconds for one epoch ---
--- 0.7976274490356445 seconds for one epoch ---
--- 0.2894597053527832 seconds for one epoch ---
--- 0.8075170516967773 seconds for one epoch ---
--- 0.29657506942749023 seconds for one epoch ---
--- 0.8158249855041504 seconds for one epoch ---
--- 0.28495216369628906 seconds for one epoch ---
--- 0.8197574615478516 seconds for one epoch ---
--- 0.3046689033508301 seconds for one epoch ---
--- 0.7942290306091309 seconds for one epoch ---
--- 0.288707971572876 seconds for one epoch ---
--- 0.8128757476806641 seconds for one epoch ---
--- 0.30231690406799316 seconds for one epoch ---
--- 0.8250775337219238 seconds for one epoch ---
--- 0.29140281677246094 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.32758346]
 [0.        ]
 [0.        ]
 [0.13402677]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9421655 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7581145]
 [-0.       ]
 [-0.       ]
 [-1.2877486]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2203553]
 [-0.       ]]
--- 0.2619960308074951 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2457.282958984375, (1293.1102, 5.2653747, 1158.4558, 0.45135298)
   validation loss 946.5252075195312, (624.99664, 0.25309604, 320.82407, 0.45135298)
decoder loss ratio: 24213.454994, decoder SINDy loss  ratio: 0.692544
--- 0.2957613468170166 seconds for one epoch ---
--- 0.8076779842376709 seconds for one epoch ---
--- 0.2969663143157959 seconds for one epoch ---
--- 0.7944736480712891 seconds for one epoch ---
--- 0.2994086742401123 seconds for one epoch ---
--- 0.7927517890930176 seconds for one epoch ---
--- 0.29377150535583496 seconds for one epoch ---
--- 0.8016531467437744 seconds for one epoch ---
--- 0.2813231945037842 seconds for one epoch ---
--- 0.8106338977813721 seconds for one epoch ---
--- 0.2903006076812744 seconds for one epoch ---
--- 0.8339176177978516 seconds for one epoch ---
--- 0.2994496822357178 seconds for one epoch ---
--- 0.8864071369171143 seconds for one epoch ---
--- 0.30154848098754883 seconds for one epoch ---
--- 0.8012042045593262 seconds for one epoch ---
--- 0.2898561954498291 seconds for one epoch ---
--- 0.8192620277404785 seconds for one epoch ---
--- 0.32528233528137207 seconds for one epoch ---
--- 0.8168954849243164 seconds for one epoch ---
--- 0.29448413848876953 seconds for one epoch ---
--- 0.834122896194458 seconds for one epoch ---
--- 0.3051595687866211 seconds for one epoch ---
--- 0.8117513656616211 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.32380623]
 [0.        ]
 [0.        ]
 [0.13090746]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9486326 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7510557]
 [-0.       ]
 [-0.       ]
 [-1.276705 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2732759]
 [-0.       ]]
--- 0.29678821563720703 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2404.217041015625, (1152.3773, 0.81653935, 1250.572, 0.45107293)
   validation loss 950.9732666015625, (621.12964, 0.2353935, 329.1572, 0.45107293)
decoder loss ratio: 24063.640531, decoder SINDy loss  ratio: 0.710532
--- 0.2605733871459961 seconds for one epoch ---
--- 0.29830455780029297 seconds for one epoch ---
--- 0.8150026798248291 seconds for one epoch ---
--- 0.29830312728881836 seconds for one epoch ---
--- 0.812809944152832 seconds for one epoch ---
--- 0.29262876510620117 seconds for one epoch ---
--- 0.8273031711578369 seconds for one epoch ---
--- 0.325009822845459 seconds for one epoch ---
--- 0.8087718486785889 seconds for one epoch ---
--- 0.29667186737060547 seconds for one epoch ---
--- 0.8315672874450684 seconds for one epoch ---
--- 0.2821629047393799 seconds for one epoch ---
--- 0.8226981163024902 seconds for one epoch ---
--- 0.2897827625274658 seconds for one epoch ---
--- 0.8322300910949707 seconds for one epoch ---
--- 0.29381299018859863 seconds for one epoch ---
--- 0.8517410755157471 seconds for one epoch ---
--- 0.29138875007629395 seconds for one epoch ---
--- 0.8292236328125 seconds for one epoch ---
--- 0.30100131034851074 seconds for one epoch ---
--- 0.8333451747894287 seconds for one epoch ---
--- 0.31172609329223633 seconds for one epoch ---
--- 0.845717191696167 seconds for one epoch ---
--- 0.3030872344970703 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.32066652]
 [0.        ]
 [0.        ]
 [0.13198993]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9519216 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.745158 ]
 [ 0.       ]
 [ 0.       ]
 [-1.2806269]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3026795]
 [ 0.       ]]
--- 0.2445669174194336 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3633.33837890625, (1649.6252, 1.5336444, 1981.7285, 0.4508667)
   validation loss 762.8905029296875, (480.5493, 0.1800351, 281.71033, 0.4508667)
decoder loss ratio: 18617.313606, decoder SINDy loss  ratio: 0.608111
--- 0.2903900146484375 seconds for one epoch ---
--- 0.8264875411987305 seconds for one epoch ---
--- 0.29819369316101074 seconds for one epoch ---
--- 0.8153195381164551 seconds for one epoch ---
--- 0.29643893241882324 seconds for one epoch ---
--- 0.8374059200286865 seconds for one epoch ---
--- 0.302854061126709 seconds for one epoch ---
--- 0.8331358432769775 seconds for one epoch ---
--- 0.29448771476745605 seconds for one epoch ---
--- 0.8248496055603027 seconds for one epoch ---
--- 0.310962438583374 seconds for one epoch ---
--- 0.8329591751098633 seconds for one epoch ---
--- 0.2972278594970703 seconds for one epoch ---
--- 0.8549966812133789 seconds for one epoch ---
--- 0.29471588134765625 seconds for one epoch ---
--- 0.8373963832855225 seconds for one epoch ---
--- 0.2832906246185303 seconds for one epoch ---
--- 0.8382017612457275 seconds for one epoch ---
--- 0.28398776054382324 seconds for one epoch ---
--- 0.8745794296264648 seconds for one epoch ---
--- 0.29389357566833496 seconds for one epoch ---
--- 0.8293356895446777 seconds for one epoch ---
--- 0.2922039031982422 seconds for one epoch ---
--- 0.8510453701019287 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.32257947]
 [0.        ]
 [0.        ]
 [0.12876576]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.95639676]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.7487823]
 [ 0.       ]
 [-0.       ]
 [-1.2690457]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3459444]
 [-0.       ]]
--- 0.30181241035461426 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4076.46630859375, (2168.7139, 1.202074, 1906.0994, 0.45088974)
   validation loss 1052.4210205078125, (727.69556, 0.19483608, 324.07974, 0.45088974)
decoder loss ratio: 28192.189199, decoder SINDy loss  ratio: 0.699572
--- 0.2667083740234375 seconds for one epoch ---
--- 0.2988011837005615 seconds for one epoch ---
--- 0.842700719833374 seconds for one epoch ---
--- 0.2947676181793213 seconds for one epoch ---
--- 0.8492693901062012 seconds for one epoch ---
--- 0.2903754711151123 seconds for one epoch ---
--- 0.850421667098999 seconds for one epoch ---
--- 0.2952151298522949 seconds for one epoch ---
--- 0.8423187732696533 seconds for one epoch ---
--- 0.2978360652923584 seconds for one epoch ---
--- 0.8522937297821045 seconds for one epoch ---
--- 0.29403185844421387 seconds for one epoch ---
--- 0.8643558025360107 seconds for one epoch ---
--- 0.2834196090698242 seconds for one epoch ---
--- 0.8549225330352783 seconds for one epoch ---
--- 0.29103660583496094 seconds for one epoch ---
--- 0.8645272254943848 seconds for one epoch ---
--- 0.46582603454589844 seconds for one epoch ---
--- 0.8483748435974121 seconds for one epoch ---
--- 0.29115724563598633 seconds for one epoch ---
--- 0.84952712059021 seconds for one epoch ---
--- 0.2876100540161133 seconds for one epoch ---
--- 0.8622274398803711 seconds for one epoch ---
--- 0.29296445846557617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.32346043]
 [0.        ]
 [0.        ]
 [0.127951  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9647118 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.7504545]
 [ 0.       ]
 [-0.       ]
 [-1.2661076]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4390981]
 [ 0.       ]]
--- 0.2515237331390381 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3023.24755859375, (980.06476, 1.639584, 2041.0914, 0.45173153)
   validation loss 1093.869140625, (781.0172, 0.16053024, 312.23965, 0.45173153)
decoder loss ratio: 30257.962695, decoder SINDy loss  ratio: 0.674013
--- 0.291736364364624 seconds for one epoch ---
--- 0.8325409889221191 seconds for one epoch ---
--- 0.3042938709259033 seconds for one epoch ---
--- 0.8546795845031738 seconds for one epoch ---
--- 0.29473304748535156 seconds for one epoch ---
--- 0.8506145477294922 seconds for one epoch ---
--- 0.29242539405822754 seconds for one epoch ---
--- 0.8445613384246826 seconds for one epoch ---
--- 0.2926828861236572 seconds for one epoch ---
--- 0.8555872440338135 seconds for one epoch ---
--- 0.285205602645874 seconds for one epoch ---
--- 0.8664445877075195 seconds for one epoch ---
--- 0.2971463203430176 seconds for one epoch ---
--- 0.8596274852752686 seconds for one epoch ---
--- 0.2958090305328369 seconds for one epoch ---
--- 0.8687927722930908 seconds for one epoch ---
--- 0.31619739532470703 seconds for one epoch ---
--- 0.8658721446990967 seconds for one epoch ---
--- 0.290738582611084 seconds for one epoch ---
--- 0.8553731441497803 seconds for one epoch ---
--- 0.29625892639160156 seconds for one epoch ---
--- 0.8616609573364258 seconds for one epoch ---
--- 0.29398417472839355 seconds for one epoch ---
--- 0.8780765533447266 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.3197705 ]
 [0.        ]
 [0.        ]
 [0.12528436]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9660371 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.7435056]
 [-0.       ]
 [ 0.       ]
 [-1.2562875]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4558861]
 [ 0.       ]]
--- 0.288102388381958 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2948.944091796875, (898.0359, 0.8189449, 2049.639, 0.450512)
   validation loss 1024.8126220703125, (708.71564, 0.18267302, 315.4637, 0.450512)
decoder loss ratio: 27456.874170, decoder SINDy loss  ratio: 0.680973
--- 0.2568016052246094 seconds for one epoch ---
--- 0.29585790634155273 seconds for one epoch ---
--- 0.8673861026763916 seconds for one epoch ---
--- 0.28139567375183105 seconds for one epoch ---
--- 0.8477921485900879 seconds for one epoch ---
--- 0.3041837215423584 seconds for one epoch ---
--- 0.865647554397583 seconds for one epoch ---
--- 0.2928645610809326 seconds for one epoch ---
--- 0.8837363719940186 seconds for one epoch ---
--- 0.29515910148620605 seconds for one epoch ---
--- 0.8648459911346436 seconds for one epoch ---
--- 0.28653454780578613 seconds for one epoch ---
--- 0.882335901260376 seconds for one epoch ---
--- 0.3045048713684082 seconds for one epoch ---
--- 0.8785371780395508 seconds for one epoch ---
--- 0.29433274269104004 seconds for one epoch ---
--- 0.8658277988433838 seconds for one epoch ---
--- 0.28471970558166504 seconds for one epoch ---
--- 0.8648867607116699 seconds for one epoch ---
--- 0.2832808494567871 seconds for one epoch ---
--- 0.8690056800842285 seconds for one epoch ---
--- 0.2951807975769043 seconds for one epoch ---
--- 0.8834807872772217 seconds for one epoch ---
--- 0.29202890396118164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.30467603]
 [0.        ]
 [0.        ]
 [0.12423613]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9679327 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.7145925]
 [ 0.       ]
 [ 0.       ]
 [-1.252395 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.4810574]
 [-0.       ]]
--- 0.27148938179016113 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2395.815673828125, (1298.3676, 1.3157105, 1095.6852, 0.44730812)
   validation loss 1213.1282958984375, (916.2502, 0.18330795, 296.24756, 0.44730812)
decoder loss ratio: 35497.122774, decoder SINDy loss  ratio: 0.639492
--- 0.3090400695800781 seconds for one epoch ---
--- 0.8878440856933594 seconds for one epoch ---
--- 0.29570579528808594 seconds for one epoch ---
--- 0.8990225791931152 seconds for one epoch ---
--- 0.2730519771575928 seconds for one epoch ---
--- 0.8910717964172363 seconds for one epoch ---
--- 0.3101766109466553 seconds for one epoch ---
--- 0.901660680770874 seconds for one epoch ---
--- 0.29764485359191895 seconds for one epoch ---
--- 0.8851897716522217 seconds for one epoch ---
--- 0.28627991676330566 seconds for one epoch ---
--- 0.8720583915710449 seconds for one epoch ---
--- 0.28696656227111816 seconds for one epoch ---
--- 0.880683183670044 seconds for one epoch ---
--- 0.2899470329284668 seconds for one epoch ---
--- 0.8941271305084229 seconds for one epoch ---
--- 0.28895115852355957 seconds for one epoch ---
--- 0.8863861560821533 seconds for one epoch ---
--- 0.29808545112609863 seconds for one epoch ---
--- 0.8907005786895752 seconds for one epoch ---
--- 0.30266547203063965 seconds for one epoch ---
--- 0.9041907787322998 seconds for one epoch ---
--- 0.28325963020324707 seconds for one epoch ---
--- 0.9010260105133057 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.29971915]
 [0.        ]
 [0.        ]
 [0.12009752]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97108454]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.7049325]
 [-0.       ]
 [-0.       ]
 [-1.2366599]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.5262735]
 [-0.       ]]
--- 0.28757333755493164 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3332.368408203125, (957.7663, 2.5930917, 2371.5635, 0.4455529)
   validation loss 945.0355224609375, (662.8349, 0.20712548, 281.5479, 0.4455529)
decoder loss ratio: 25679.374754, decoder SINDy loss  ratio: 0.607761
--- 0.2545464038848877 seconds for one epoch ---
--- 0.29594945907592773 seconds for one epoch ---
--- 0.8837325572967529 seconds for one epoch ---
--- 0.29227495193481445 seconds for one epoch ---
--- 0.879540205001831 seconds for one epoch ---
--- 0.28931164741516113 seconds for one epoch ---
--- 0.8733799457550049 seconds for one epoch ---
--- 0.290621280670166 seconds for one epoch ---
--- 0.8869447708129883 seconds for one epoch ---
--- 0.28809595108032227 seconds for one epoch ---
--- 0.8976695537567139 seconds for one epoch ---
--- 0.3102242946624756 seconds for one epoch ---
--- 0.9056499004364014 seconds for one epoch ---
--- 0.2966115474700928 seconds for one epoch ---
--- 0.8995375633239746 seconds for one epoch ---
--- 0.30864691734313965 seconds for one epoch ---
--- 0.9094221591949463 seconds for one epoch ---
--- 0.29169464111328125 seconds for one epoch ---
--- 0.9195611476898193 seconds for one epoch ---
--- 0.2904326915740967 seconds for one epoch ---
--- 0.9080431461334229 seconds for one epoch ---
--- 0.28687143325805664 seconds for one epoch ---
--- 0.9230372905731201 seconds for one epoch ---
--- 0.2983376979827881 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.29324937]
 [0.        ]
 [0.        ]
 [0.12121109]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97609615]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.6921866]
 [-0.       ]
 [ 0.       ]
 [-1.2409669]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.6092072]
 [ 0.       ]]
--- 0.26217031478881836 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2852.499267578125, (1307.1256, 0.43829462, 1544.49, 0.44527623)
   validation loss 1040.3399658203125, (721.10223, 0.28143343, 318.51096, 0.44527623)
decoder loss ratio: 27936.752429, decoder SINDy loss  ratio: 0.687551
--- 0.28860902786254883 seconds for one epoch ---
--- 0.9050755500793457 seconds for one epoch ---
--- 0.3013033866882324 seconds for one epoch ---
--- 0.8946726322174072 seconds for one epoch ---
--- 0.30680418014526367 seconds for one epoch ---
--- 0.8889956474304199 seconds for one epoch ---
--- 0.28390002250671387 seconds for one epoch ---
--- 0.9138424396514893 seconds for one epoch ---
--- 0.2946486473083496 seconds for one epoch ---
--- 0.8984644412994385 seconds for one epoch ---
--- 0.2969670295715332 seconds for one epoch ---
--- 0.9046251773834229 seconds for one epoch ---
--- 0.3062915802001953 seconds for one epoch ---
--- 0.9198513031005859 seconds for one epoch ---
--- 0.2933006286621094 seconds for one epoch ---
--- 0.9006242752075195 seconds for one epoch ---
--- 0.28968334197998047 seconds for one epoch ---
--- 0.9098465442657471 seconds for one epoch ---
--- 0.2968437671661377 seconds for one epoch ---
--- 0.927783727645874 seconds for one epoch ---
--- 0.30197572708129883 seconds for one epoch ---
--- 0.9150996208190918 seconds for one epoch ---
--- 0.2914135456085205 seconds for one epoch ---
--- 0.9169731140136719 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.28294358]
 [0.        ]
 [0.        ]
 [0.11983565]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97986275]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.6715343]
 [ 0.       ]
 [-0.       ]
 [-1.2356874]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.683677 ]
 [-0.       ]]
--- 0.29303979873657227 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4028.64111328125, (2502.964, 3.3567965, 1521.8771, 0.4432532)
   validation loss 1046.7379150390625, (739.6877, 0.3467556, 306.2602, 0.4432532)
decoder loss ratio: 28656.784998, decoder SINDy loss  ratio: 0.661106
--- 0.24712109565734863 seconds for one epoch ---
--- 0.28797149658203125 seconds for one epoch ---
--- 0.9126439094543457 seconds for one epoch ---
--- 0.2878737449645996 seconds for one epoch ---
--- 0.8962314128875732 seconds for one epoch ---
--- 0.2823200225830078 seconds for one epoch ---
--- 0.8923976421356201 seconds for one epoch ---
--- 0.29244065284729004 seconds for one epoch ---
--- 0.9256579875946045 seconds for one epoch ---
--- 0.30078935623168945 seconds for one epoch ---
--- 0.9183130264282227 seconds for one epoch ---
--- 0.29493284225463867 seconds for one epoch ---
--- 0.9178860187530518 seconds for one epoch ---
--- 0.2932114601135254 seconds for one epoch ---
--- 0.9302494525909424 seconds for one epoch ---
--- 0.3068656921386719 seconds for one epoch ---
--- 0.8908355236053467 seconds for one epoch ---
--- 0.2928731441497803 seconds for one epoch ---
--- 0.9063630104064941 seconds for one epoch ---
--- 0.30461812019348145 seconds for one epoch ---
--- 0.9188113212585449 seconds for one epoch ---
--- 0.29472994804382324 seconds for one epoch ---
--- 0.9247779846191406 seconds for one epoch ---
--- 0.31580018997192383 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.279383 ]
 [0.       ]
 [0.       ]
 [0.1198349]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9824563]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 1.6643009]
 [-0.       ]
 [-0.       ]
 [-1.2357012]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.7434306]
 [ 0.       ]]
--- 0.25937366485595703 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2855.207763671875, (1225.7933, 1.0703299, 1627.9015, 0.44257736)
   validation loss 1313.394775390625, (937.8536, 0.35201883, 374.74655, 0.44257736)
decoder loss ratio: 36334.075745, decoder SINDy loss  ratio: 0.808943
--- 0.2918095588684082 seconds for one epoch ---
--- 0.9377233982086182 seconds for one epoch ---
--- 0.29792237281799316 seconds for one epoch ---
--- 0.949953556060791 seconds for one epoch ---
--- 0.29775452613830566 seconds for one epoch ---
--- 0.9157254695892334 seconds for one epoch ---
--- 0.2956540584564209 seconds for one epoch ---
--- 0.9203166961669922 seconds for one epoch ---
--- 0.29698967933654785 seconds for one epoch ---
--- 0.9132721424102783 seconds for one epoch ---
--- 0.2994670867919922 seconds for one epoch ---
--- 0.9172186851501465 seconds for one epoch ---
--- 0.291196346282959 seconds for one epoch ---
--- 0.9193899631500244 seconds for one epoch ---
--- 0.30053186416625977 seconds for one epoch ---
--- 0.9273948669433594 seconds for one epoch ---
--- 0.2961387634277344 seconds for one epoch ---
--- 0.9272017478942871 seconds for one epoch ---
--- 0.29712867736816406 seconds for one epoch ---
--- 0.9423720836639404 seconds for one epoch ---
--- 0.2911100387573242 seconds for one epoch ---
--- 0.9238550662994385 seconds for one epoch ---
--- 0.2918407917022705 seconds for one epoch ---
--- 0.952031135559082 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2624132 ]
 [0.        ]
 [0.        ]
 [0.12258033]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9847914 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.6289978]
 [ 0.       ]
 [ 0.       ]
 [-1.2462361]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.8052642]
 [ 0.       ]]
--- 0.29064154624938965 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3328.11474609375, (1661.263, 4.486525, 1661.9255, 0.4397132)
   validation loss 1124.516357421875, (812.1293, 0.22251797, 311.7249, 0.4397132)
decoder loss ratio: 31463.297934, decoder SINDy loss  ratio: 0.672902
--- 0.2626800537109375 seconds for one epoch ---
--- 0.3129754066467285 seconds for one epoch ---
--- 0.9336566925048828 seconds for one epoch ---
--- 0.30301737785339355 seconds for one epoch ---
--- 0.9399259090423584 seconds for one epoch ---
--- 0.2967529296875 seconds for one epoch ---
--- 0.9412667751312256 seconds for one epoch ---
--- 0.2894902229309082 seconds for one epoch ---
--- 0.9385385513305664 seconds for one epoch ---
--- 0.2949972152709961 seconds for one epoch ---
--- 0.9381198883056641 seconds for one epoch ---
--- 0.30594444274902344 seconds for one epoch ---
--- 0.9482917785644531 seconds for one epoch ---
--- 0.29683685302734375 seconds for one epoch ---
--- 0.9420323371887207 seconds for one epoch ---
--- 0.29297494888305664 seconds for one epoch ---
--- 0.9530086517333984 seconds for one epoch ---
--- 0.29941344261169434 seconds for one epoch ---
--- 0.9580678939819336 seconds for one epoch ---
--- 0.290799617767334 seconds for one epoch ---
--- 0.9353423118591309 seconds for one epoch ---
--- 0.29861021041870117 seconds for one epoch ---
--- 0.9682598114013672 seconds for one epoch ---
--- 0.2908494472503662 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.26189795]
 [0.        ]
 [0.        ]
 [0.11490216]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98632646]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.6279097]
 [ 0.       ]
 [ 0.       ]
 [-1.2162931]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.851258 ]
 [-0.       ]]
--- 0.2630488872528076 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2619.971435546875, (1138.8695, 0.8980748, 1479.7665, 0.43727198)
   validation loss 893.828125, (612.54443, 0.20621401, 280.6402, 0.43727198)
decoder loss ratio: 23731.034781, decoder SINDy loss  ratio: 0.605801
--- 0.28969454765319824 seconds for one epoch ---
--- 0.9059417247772217 seconds for one epoch ---
--- 0.296367883682251 seconds for one epoch ---
--- 0.9406111240386963 seconds for one epoch ---
--- 0.3200838565826416 seconds for one epoch ---
--- 0.9376962184906006 seconds for one epoch ---
--- 0.299224853515625 seconds for one epoch ---
--- 0.9465818405151367 seconds for one epoch ---
--- 0.30421948432922363 seconds for one epoch ---
--- 0.9402065277099609 seconds for one epoch ---
--- 0.2907130718231201 seconds for one epoch ---
--- 0.9385170936584473 seconds for one epoch ---
--- 0.2942218780517578 seconds for one epoch ---
--- 0.9404206275939941 seconds for one epoch ---
--- 0.29513001441955566 seconds for one epoch ---
--- 0.9711134433746338 seconds for one epoch ---
--- 0.29531335830688477 seconds for one epoch ---
--- 0.9522013664245605 seconds for one epoch ---
--- 0.2931027412414551 seconds for one epoch ---
--- 0.9749491214752197 seconds for one epoch ---
--- 0.2930276393890381 seconds for one epoch ---
--- 0.9582772254943848 seconds for one epoch ---
--- 0.28960514068603516 seconds for one epoch ---
--- 0.9691164493560791 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.26043543]
 [0.        ]
 [0.        ]
 [0.11280609]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9882796 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.6248012]
 [ 0.       ]
 [-0.       ]
 [-1.2078273]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.9177961]
 [-0.       ]]
--- 0.2871215343475342 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2837.316650390625, (1363.6594, 0.69569254, 1472.5259, 0.43583688)
   validation loss 915.6967163085938, (602.53046, 0.2864317, 312.44394, 0.43583688)
decoder loss ratio: 23343.075925, decoder SINDy loss  ratio: 0.674454
THRESHOLDING: 3 active coefficients
--- 0.26112890243530273 seconds for one epoch ---
--- 0.29218506813049316 seconds for one epoch ---
--- 0.971027135848999 seconds for one epoch ---
--- 0.29881739616394043 seconds for one epoch ---
--- 0.9810791015625 seconds for one epoch ---
--- 0.2829608917236328 seconds for one epoch ---
--- 0.9653253555297852 seconds for one epoch ---
--- 0.2916254997253418 seconds for one epoch ---
--- 0.9612154960632324 seconds for one epoch ---
--- 0.31243038177490234 seconds for one epoch ---
--- 0.9533874988555908 seconds for one epoch ---
--- 0.2926671504974365 seconds for one epoch ---
--- 0.9715108871459961 seconds for one epoch ---
--- 0.2731492519378662 seconds for one epoch ---
--- 0.9680521488189697 seconds for one epoch ---
--- 0.2974815368652344 seconds for one epoch ---
--- 0.949866533279419 seconds for one epoch ---
--- 0.29134440422058105 seconds for one epoch ---
--- 0.974186897277832 seconds for one epoch ---
--- 0.2951655387878418 seconds for one epoch ---
--- 0.9882035255432129 seconds for one epoch ---
--- 0.29024267196655273 seconds for one epoch ---
--- 0.9766850471496582 seconds for one epoch ---
--- 0.2850618362426758 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.244778  ]
 [0.        ]
 [0.        ]
 [0.11341481]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9900316 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.590746 ]
 [-0.       ]
 [ 0.       ]
 [-1.2103131]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-3.9877424]
 [ 0.       ]]
--- 0.2496471405029297 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4339.33447265625, (1324.8739, 2.6533363, 3011.3801, 0.42701873)
   validation loss 1144.4560546875, (855.8625, 0.2485853, 287.9179, 0.42701873)
decoder loss ratio: 33157.598620, decoder SINDy loss  ratio: 0.621511
--- 0.2926506996154785 seconds for one epoch ---
--- 0.9510800838470459 seconds for one epoch ---
--- 0.2919952869415283 seconds for one epoch ---
--- 0.97090744972229 seconds for one epoch ---
--- 0.2939469814300537 seconds for one epoch ---
--- 0.9568581581115723 seconds for one epoch ---
--- 0.2910728454589844 seconds for one epoch ---
--- 0.9761168956756592 seconds for one epoch ---
--- 0.29287004470825195 seconds for one epoch ---
--- 0.9679417610168457 seconds for one epoch ---
--- 0.29596948623657227 seconds for one epoch ---
--- 0.9626617431640625 seconds for one epoch ---
--- 0.30002641677856445 seconds for one epoch ---
--- 1.0041742324829102 seconds for one epoch ---
--- 0.29985809326171875 seconds for one epoch ---
--- 0.9611310958862305 seconds for one epoch ---
--- 0.28989100456237793 seconds for one epoch ---
--- 0.9578065872192383 seconds for one epoch ---
--- 0.3108336925506592 seconds for one epoch ---
--- 0.9847300052642822 seconds for one epoch ---
--- 0.2946279048919678 seconds for one epoch ---
--- 0.9597012996673584 seconds for one epoch ---
--- 0.31314516067504883 seconds for one epoch ---
--- 0.9981975555419922 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2452883 ]
 [0.        ]
 [0.        ]
 [0.11013658]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9912471 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.5918822]
 [ 0.       ]
 [-0.       ]
 [-1.1968514]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.043836 ]
 [-0.       ]]
--- 0.29920101165771484 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7970.81103515625, (2344.2234, 3.10661, 5623.0537, 0.42710957)
   validation loss 877.1301879882812, (578.4327, 0.1943668, 298.076, 0.42710957)
decoder loss ratio: 22409.486158, decoder SINDy loss  ratio: 0.643439
--- 0.24350237846374512 seconds for one epoch ---
--- 0.28897690773010254 seconds for one epoch ---
--- 0.9695935249328613 seconds for one epoch ---
--- 0.2936112880706787 seconds for one epoch ---
--- 0.9536135196685791 seconds for one epoch ---
--- 0.29007792472839355 seconds for one epoch ---
--- 0.9845478534698486 seconds for one epoch ---
--- 0.30138731002807617 seconds for one epoch ---
--- 0.992095947265625 seconds for one epoch ---
--- 0.29552793502807617 seconds for one epoch ---
--- 1.0018188953399658 seconds for one epoch ---
--- 0.305553674697876 seconds for one epoch ---
--- 0.9823601245880127 seconds for one epoch ---
--- 0.29979372024536133 seconds for one epoch ---
--- 0.9810116291046143 seconds for one epoch ---
--- 0.3058164119720459 seconds for one epoch ---
--- 0.9811587333679199 seconds for one epoch ---
--- 0.2882957458496094 seconds for one epoch ---
--- 0.9924149513244629 seconds for one epoch ---
--- 0.31711435317993164 seconds for one epoch ---
--- 0.9802510738372803 seconds for one epoch ---
--- 0.2879171371459961 seconds for one epoch ---
--- 0.9875397682189941 seconds for one epoch ---
--- 0.2786095142364502 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2385489 ]
 [0.        ]
 [0.        ]
 [0.11332559]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.992239  ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.5768027]
 [-0.       ]
 [-0.       ]
 [-1.2099673]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.0957174]
 [ 0.       ]]
--- 0.2430119514465332 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4312.62744140625, (1917.3214, 0.62626046, 2394.2527, 0.42703652)
   validation loss 1779.210205078125, (1375.0675, 0.25515023, 403.46057, 0.42703652)
decoder loss ratio: 53272.502361, decoder SINDy loss  ratio: 0.870926
--- 0.30394768714904785 seconds for one epoch ---
--- 1.010742425918579 seconds for one epoch ---
--- 0.29755520820617676 seconds for one epoch ---
--- 0.9844241142272949 seconds for one epoch ---
--- 0.3089473247528076 seconds for one epoch ---
--- 1.0130784511566162 seconds for one epoch ---
--- 0.28536343574523926 seconds for one epoch ---
--- 0.9821364879608154 seconds for one epoch ---
--- 0.29906129837036133 seconds for one epoch ---
--- 0.9989221096038818 seconds for one epoch ---
--- 0.29128503799438477 seconds for one epoch ---
--- 1.0044019222259521 seconds for one epoch ---
--- 0.2934763431549072 seconds for one epoch ---
--- 1.0048165321350098 seconds for one epoch ---
--- 0.2917659282684326 seconds for one epoch ---
--- 0.9769783020019531 seconds for one epoch ---
--- 0.29279232025146484 seconds for one epoch ---
--- 0.9932448863983154 seconds for one epoch ---
--- 0.28936171531677246 seconds for one epoch ---
--- 1.0033602714538574 seconds for one epoch ---
--- 0.29980921745300293 seconds for one epoch ---
--- 1.0150365829467773 seconds for one epoch ---
--- 0.2937908172607422 seconds for one epoch ---
--- 0.9854445457458496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.23851609]
 [0.        ]
 [0.        ]
 [0.11164524]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9935459 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.5767319]
 [-0.       ]
 [ 0.       ]
 [-1.2031076]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.1752253]
 [ 0.       ]]
--- 0.27697086334228516 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3546.377685546875, (1897.8489, 3.1392305, 1644.9631, 0.42642614)
   validation loss 955.7550659179688, (667.41846, 0.24955568, 287.66058, 0.42642614)
decoder loss ratio: 25856.949715, decoder SINDy loss  ratio: 0.620956
--- 0.2499408721923828 seconds for one epoch ---
--- 0.30452919006347656 seconds for one epoch ---
--- 0.995919942855835 seconds for one epoch ---
--- 0.28960084915161133 seconds for one epoch ---
--- 0.9916548728942871 seconds for one epoch ---
--- 0.29584336280822754 seconds for one epoch ---
--- 1.0226385593414307 seconds for one epoch ---
--- 0.29364562034606934 seconds for one epoch ---
--- 1.0058224201202393 seconds for one epoch ---
--- 0.28452539443969727 seconds for one epoch ---
--- 1.0101873874664307 seconds for one epoch ---
--- 0.2958872318267822 seconds for one epoch ---
--- 1.0161914825439453 seconds for one epoch ---
--- 0.2960374355316162 seconds for one epoch ---
--- 1.0027995109558105 seconds for one epoch ---
--- 0.2932016849517822 seconds for one epoch ---
--- 1.0300233364105225 seconds for one epoch ---
--- 0.29296326637268066 seconds for one epoch ---
--- 1.011232852935791 seconds for one epoch ---
--- 0.2849252223968506 seconds for one epoch ---
--- 1.009512186050415 seconds for one epoch ---
--- 0.2976498603820801 seconds for one epoch ---
--- 1.013920783996582 seconds for one epoch ---
--- 0.2898216247558594 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24109074]
 [0.        ]
 [0.        ]
 [0.10883984]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9945587 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.5825305]
 [ 0.       ]
 [ 0.       ]
 [-1.1914483]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.248903 ]
 [-0.       ]]
--- 0.2564811706542969 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2533.34326171875, (1048.776, 3.025555, 1481.1152, 0.42651674)
   validation loss 863.2886962890625, (567.88947, 0.18351334, 294.7892, 0.42651674)
decoder loss ratio: 22001.023786, decoder SINDy loss  ratio: 0.636344
--- 0.2923600673675537 seconds for one epoch ---
--- 0.9957549571990967 seconds for one epoch ---
--- 0.28754210472106934 seconds for one epoch ---
--- 0.9933335781097412 seconds for one epoch ---
--- 0.29393696784973145 seconds for one epoch ---
--- 1.0186591148376465 seconds for one epoch ---
--- 0.3148684501647949 seconds for one epoch ---
--- 1.0176122188568115 seconds for one epoch ---
--- 0.2892029285430908 seconds for one epoch ---
--- 1.0336296558380127 seconds for one epoch ---
--- 0.31350183486938477 seconds for one epoch ---
--- 1.0351061820983887 seconds for one epoch ---
--- 0.2892465591430664 seconds for one epoch ---
--- 1.0112950801849365 seconds for one epoch ---
--- 0.3121790885925293 seconds for one epoch ---
--- 1.0359408855438232 seconds for one epoch ---
--- 0.2891666889190674 seconds for one epoch ---
--- 1.0222814083099365 seconds for one epoch ---
--- 0.31319761276245117 seconds for one epoch ---
--- 1.0162172317504883 seconds for one epoch ---
--- 0.2866828441619873 seconds for one epoch ---
--- 0.9971778392791748 seconds for one epoch ---
--- 0.2944169044494629 seconds for one epoch ---
--- 1.0378522872924805 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2338524 ]
 [0.        ]
 [0.        ]
 [0.11006541]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.995237  ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.5661287]
 [-0.       ]
 [-0.       ]
 [-1.1965817]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.3063974]
 [-0.       ]]
--- 0.27144813537597656 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4816.2255859375, (2741.2375, 3.0880976, 2071.4739, 0.42591143)
   validation loss 986.612060546875, (702.4839, 0.16914077, 283.53314, 0.42591143)
decoder loss ratio: 27215.445337, decoder SINDy loss  ratio: 0.612046
--- 0.262540340423584 seconds for one epoch ---
--- 0.31294989585876465 seconds for one epoch ---
--- 1.0126194953918457 seconds for one epoch ---
--- 0.30367541313171387 seconds for one epoch ---
--- 1.0239007472991943 seconds for one epoch ---
--- 0.29569268226623535 seconds for one epoch ---
--- 1.035677433013916 seconds for one epoch ---
--- 0.2994394302368164 seconds for one epoch ---
--- 1.0209155082702637 seconds for one epoch ---
--- 0.28458189964294434 seconds for one epoch ---
--- 1.0424308776855469 seconds for one epoch ---
--- 0.30801987648010254 seconds for one epoch ---
--- 1.052300214767456 seconds for one epoch ---
--- 0.29274535179138184 seconds for one epoch ---
--- 1.0425610542297363 seconds for one epoch ---
--- 0.30281782150268555 seconds for one epoch ---
--- 1.0284221172332764 seconds for one epoch ---
--- 0.29448819160461426 seconds for one epoch ---
--- 1.0316343307495117 seconds for one epoch ---
--- 0.3024716377258301 seconds for one epoch ---
--- 1.030780553817749 seconds for one epoch ---
--- 0.29328012466430664 seconds for one epoch ---
--- 1.0365185737609863 seconds for one epoch ---
--- 0.2982823848724365 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22980146]
 [0.        ]
 [0.        ]
 [0.10880581]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99580705]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.5567982]
 [ 0.       ]
 [ 0.       ]
 [-1.1913154]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.361402 ]
 [ 0.       ]]
--- 0.2487010955810547 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4497.47216796875, (1443.295, 1.981542, 3051.7708, 0.42494574)
   validation loss 917.7591552734375, (628.63727, 0.23264502, 288.46432, 0.42494574)
decoder loss ratio: 24354.499127, decoder SINDy loss  ratio: 0.622691
--- 0.2893331050872803 seconds for one epoch ---
--- 1.0326173305511475 seconds for one epoch ---
--- 0.3009963035583496 seconds for one epoch ---
--- 1.0219533443450928 seconds for one epoch ---
--- 0.3011128902435303 seconds for one epoch ---
--- 1.0355548858642578 seconds for one epoch ---
--- 0.29584479331970215 seconds for one epoch ---
--- 1.0346858501434326 seconds for one epoch ---
--- 0.286466121673584 seconds for one epoch ---
--- 1.0326523780822754 seconds for one epoch ---
--- 0.30418896675109863 seconds for one epoch ---
--- 1.0687968730926514 seconds for one epoch ---
--- 0.2961387634277344 seconds for one epoch ---
--- 1.0385444164276123 seconds for one epoch ---
--- 0.32834649085998535 seconds for one epoch ---
--- 1.0469520092010498 seconds for one epoch ---
--- 0.29718494415283203 seconds for one epoch ---
--- 1.0537610054016113 seconds for one epoch ---
--- 0.3260011672973633 seconds for one epoch ---
--- 1.0580554008483887 seconds for one epoch ---
--- 0.29288768768310547 seconds for one epoch ---
--- 1.0400943756103516 seconds for one epoch ---
--- 0.29917263984680176 seconds for one epoch ---
--- 1.06321120262146 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22710562]
 [0.        ]
 [0.        ]
 [0.10783076]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9963169 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 1.5505261]
 [ 0.       ]
 [-0.       ]
 [-1.1872023]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.417375 ]
 [-0.       ]]
--- 0.2771120071411133 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5157.921875, (1574.9048, 1.1119924, 3581.4807, 0.42407608)
   validation loss 1344.0718994140625, (1043.7183, 0.2126954, 299.7169, 0.42407608)
decoder loss ratio: 40435.457434, decoder SINDy loss  ratio: 0.646981
--- 0.2577347755432129 seconds for one epoch ---
--- 0.3084893226623535 seconds for one epoch ---
--- 1.0528125762939453 seconds for one epoch ---
--- 0.29462218284606934 seconds for one epoch ---
--- 1.0201523303985596 seconds for one epoch ---
--- 0.31244564056396484 seconds for one epoch ---
--- 1.0436100959777832 seconds for one epoch ---
--- 0.29783177375793457 seconds for one epoch ---
--- 1.03694748878479 seconds for one epoch ---
--- 0.3225553035736084 seconds for one epoch ---
--- 1.0644941329956055 seconds for one epoch ---
--- 0.5004141330718994 seconds for one epoch ---
--- 1.061037302017212 seconds for one epoch ---
--- 0.3059678077697754 seconds for one epoch ---
--- 1.0614216327667236 seconds for one epoch ---
--- 0.2950460910797119 seconds for one epoch ---
--- 1.0826282501220703 seconds for one epoch ---
--- 0.3039710521697998 seconds for one epoch ---
--- 1.0743215084075928 seconds for one epoch ---
--- 0.29221105575561523 seconds for one epoch ---
--- 1.0830562114715576 seconds for one epoch ---
--- 0.2936289310455322 seconds for one epoch ---
--- 1.090404987335205 seconds for one epoch ---
--- 0.2954592704772949 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22268574]
 [0.        ]
 [0.        ]
 [0.10747315]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9967794 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 1.5401278]
 [ 0.       ]
 [-0.       ]
 [-1.185689 ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.4753275]
 [ 0.       ]]
--- 0.27652907371520996 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5943.45849609375, (2365.3643, 2.646469, 3575.0244, 0.42321512)
   validation loss 830.4434814453125, (563.7279, 0.24237189, 266.04996, 0.42321512)
decoder loss ratio: 21839.797725, decoder SINDy loss  ratio: 0.574306
--- 0.3117706775665283 seconds for one epoch ---
--- 1.074455976486206 seconds for one epoch ---
--- 0.29064249992370605 seconds for one epoch ---
--- 1.0682871341705322 seconds for one epoch ---
--- 0.31326866149902344 seconds for one epoch ---
--- 1.0438945293426514 seconds for one epoch ---
--- 0.2964298725128174 seconds for one epoch ---
--- 1.0566091537475586 seconds for one epoch ---
--- 0.30409693717956543 seconds for one epoch ---
--- 1.0899715423583984 seconds for one epoch ---
--- 0.29274916648864746 seconds for one epoch ---
--- 1.0776281356811523 seconds for one epoch ---
--- 0.3115222454071045 seconds for one epoch ---
--- 1.0784010887145996 seconds for one epoch ---
--- 0.29656195640563965 seconds for one epoch ---
--- 1.094871997833252 seconds for one epoch ---
--- 0.30564236640930176 seconds for one epoch ---
--- 1.066199779510498 seconds for one epoch ---
--- 0.29434823989868164 seconds for one epoch ---
--- 1.0976598262786865 seconds for one epoch ---
--- 0.2964205741882324 seconds for one epoch ---
--- 1.0676586627960205 seconds for one epoch ---
--- 0.28817272186279297 seconds for one epoch ---
--- 1.1064293384552002 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22289395]
 [0.        ]
 [0.        ]
 [0.10520688]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9971838 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 1.540623 ]
 [-0.       ]
 [ 0.       ]
 [-1.1759682]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.533352 ]
 [ 0.       ]]
--- 0.2892465591430664 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4005.332275390625, (2245.481, 2.6841002, 1756.7441, 0.42298672)
   validation loss 984.3720092773438, (691.44196, 0.23453215, 292.27252, 0.42298672)
decoder loss ratio: 26787.661755, decoder SINDy loss  ratio: 0.630911
--- 0.2562084197998047 seconds for one epoch ---
--- 0.2710402011871338 seconds for one epoch ---
--- 1.0688810348510742 seconds for one epoch ---
--- 0.29222869873046875 seconds for one epoch ---
--- 1.0777835845947266 seconds for one epoch ---
--- 0.2934844493865967 seconds for one epoch ---
--- 1.0899536609649658 seconds for one epoch ---
--- 0.30202174186706543 seconds for one epoch ---
--- 1.088282823562622 seconds for one epoch ---
--- 0.2973766326904297 seconds for one epoch ---
--- 1.0916211605072021 seconds for one epoch ---
--- 0.2938506603240967 seconds for one epoch ---
--- 1.0918614864349365 seconds for one epoch ---
--- 0.2941291332244873 seconds for one epoch ---
--- 1.0988869667053223 seconds for one epoch ---
--- 0.28993821144104004 seconds for one epoch ---
--- 1.0919992923736572 seconds for one epoch ---
--- 0.2956392765045166 seconds for one epoch ---
--- 1.0916118621826172 seconds for one epoch ---
--- 0.28018903732299805 seconds for one epoch ---
--- 1.1004621982574463 seconds for one epoch ---
--- 0.2905399799346924 seconds for one epoch ---
--- 1.0855920314788818 seconds for one epoch ---
--- 0.28978753089904785 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22112213]
 [0.        ]
 [0.        ]
 [0.10489648]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9974911 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.5364177]
 [ 0.       ]
 [ 0.       ]
 [-1.174626 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.583334 ]
 [-0.       ]]
--- 0.25241851806640625 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3617.08837890625, (1911.7168, 1.9832433, 1702.9648, 0.4233164)
   validation loss 1243.0809326171875, (938.35834, 0.2221684, 304.07706, 0.4233164)
decoder loss ratio: 36353.631053, decoder SINDy loss  ratio: 0.656393
--- 0.2968106269836426 seconds for one epoch ---
--- 1.0795795917510986 seconds for one epoch ---
--- 0.2989201545715332 seconds for one epoch ---
--- 1.0857880115509033 seconds for one epoch ---
--- 0.2869601249694824 seconds for one epoch ---
--- 1.068359375 seconds for one epoch ---
--- 0.28460025787353516 seconds for one epoch ---
--- 1.0859816074371338 seconds for one epoch ---
--- 0.29887938499450684 seconds for one epoch ---
--- 1.0914099216461182 seconds for one epoch ---
--- 0.2945098876953125 seconds for one epoch ---
--- 1.1003339290618896 seconds for one epoch ---
--- 0.2949864864349365 seconds for one epoch ---
--- 1.0992603302001953 seconds for one epoch ---
--- 0.3016071319580078 seconds for one epoch ---
--- 1.109436273574829 seconds for one epoch ---
--- 0.30065178871154785 seconds for one epoch ---
--- 1.0892333984375 seconds for one epoch ---
--- 0.273529052734375 seconds for one epoch ---
--- 1.1065316200256348 seconds for one epoch ---
--- 0.30121803283691406 seconds for one epoch ---
--- 1.0957739353179932 seconds for one epoch ---
--- 0.27947998046875 seconds for one epoch ---
--- 1.1020128726959229 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.21641544]
 [0.        ]
 [0.        ]
 [0.10540369]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9977041 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.5251263]
 [-0.       ]
 [-0.       ]
 [-1.1768266]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.6216645]
 [-0.       ]]
--- 0.2964813709259033 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3839.49609375, (1568.5675, 3.7062685, 2266.7998, 0.42236552)
   validation loss 887.2420043945312, (604.9905, 0.27175894, 281.55743, 0.42236552)
decoder loss ratio: 23438.381447, decoder SINDy loss  ratio: 0.607781
--- 0.26311492919921875 seconds for one epoch ---
--- 0.29733848571777344 seconds for one epoch ---
--- 1.0819401741027832 seconds for one epoch ---
--- 0.2817854881286621 seconds for one epoch ---
--- 1.1040818691253662 seconds for one epoch ---
--- 0.2878091335296631 seconds for one epoch ---
--- 1.1192445755004883 seconds for one epoch ---
--- 0.29590439796447754 seconds for one epoch ---
--- 1.1019597053527832 seconds for one epoch ---
--- 0.2923734188079834 seconds for one epoch ---
--- 1.1038062572479248 seconds for one epoch ---
--- 0.275895357131958 seconds for one epoch ---
--- 1.1294078826904297 seconds for one epoch ---
--- 0.29691219329833984 seconds for one epoch ---
--- 1.0855684280395508 seconds for one epoch ---
--- 0.2901287078857422 seconds for one epoch ---
--- 1.1189606189727783 seconds for one epoch ---
--- 0.2879636287689209 seconds for one epoch ---
--- 1.096731424331665 seconds for one epoch ---
--- 0.2896268367767334 seconds for one epoch ---
--- 1.0966320037841797 seconds for one epoch ---
--- 0.2903106212615967 seconds for one epoch ---
--- 1.1228840351104736 seconds for one epoch ---
--- 0.2981395721435547 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.21211538]
 [0.        ]
 [0.        ]
 [0.1043524 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9980273 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.5146561]
 [-0.       ]
 [ 0.       ]
 [-1.172263 ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.68759  ]
 [ 0.       ]]
--- 0.24394822120666504 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3568.337646484375, (1633.1022, 3.7270982, 1931.0868, 0.42155075)
   validation loss 1036.573974609375, (740.896, 0.23410791, 295.0223, 0.42155075)
decoder loss ratio: 28703.597141, decoder SINDy loss  ratio: 0.636847
--- 0.28038454055786133 seconds for one epoch ---
--- 1.1327006816864014 seconds for one epoch ---
--- 0.2952461242675781 seconds for one epoch ---
--- 1.1225521564483643 seconds for one epoch ---
--- 0.2915785312652588 seconds for one epoch ---
--- 1.1300086975097656 seconds for one epoch ---
--- 0.3108828067779541 seconds for one epoch ---
--- 1.1182732582092285 seconds for one epoch ---
--- 0.2950465679168701 seconds for one epoch ---
--- 1.1324729919433594 seconds for one epoch ---
--- 0.3000476360321045 seconds for one epoch ---
--- 1.121556043624878 seconds for one epoch ---
--- 0.2925410270690918 seconds for one epoch ---
--- 1.095247507095337 seconds for one epoch ---
--- 0.3061079978942871 seconds for one epoch ---
--- 1.1416394710540771 seconds for one epoch ---
--- 0.29054689407348633 seconds for one epoch ---
--- 1.118241310119629 seconds for one epoch ---
--- 0.2922046184539795 seconds for one epoch ---
--- 1.1156866550445557 seconds for one epoch ---
--- 0.29585862159729004 seconds for one epoch ---
--- 1.096402883529663 seconds for one epoch ---
--- 0.28643369674682617 seconds for one epoch ---
--- 1.1251094341278076 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.21040355]
 [0.        ]
 [0.        ]
 [0.10329546]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9982729 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 1.510445 ]
 [ 0.       ]
 [-0.       ]
 [-1.167635 ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.7450604]
 [-0.       ]]
--- 0.2839803695678711 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3316.286376953125, (2156.271, 1.3555355, 1158.2394, 0.4206625)
   validation loss 750.74951171875, (475.41553, 0.25528857, 274.65805, 0.4206625)
decoder loss ratio: 18418.422887, decoder SINDy loss  ratio: 0.592888
--- 0.26090121269226074 seconds for one epoch ---
--- 0.29908299446105957 seconds for one epoch ---
--- 1.1201908588409424 seconds for one epoch ---
--- 0.29471564292907715 seconds for one epoch ---
--- 1.1239452362060547 seconds for one epoch ---
--- 0.29267263412475586 seconds for one epoch ---
--- 1.128190279006958 seconds for one epoch ---
--- 0.2880988121032715 seconds for one epoch ---
--- 1.0979273319244385 seconds for one epoch ---
--- 0.2782735824584961 seconds for one epoch ---
--- 1.1330981254577637 seconds for one epoch ---
--- 0.27594923973083496 seconds for one epoch ---
--- 1.1104907989501953 seconds for one epoch ---
--- 0.28532862663269043 seconds for one epoch ---
--- 1.1241865158081055 seconds for one epoch ---
--- 0.2942235469818115 seconds for one epoch ---
--- 1.1401069164276123 seconds for one epoch ---
--- 0.2916603088378906 seconds for one epoch ---
--- 1.1254360675811768 seconds for one epoch ---
--- 0.2908308506011963 seconds for one epoch ---
--- 1.1177771091461182 seconds for one epoch ---
--- 0.3081846237182617 seconds for one epoch ---
--- 1.1144194602966309 seconds for one epoch ---
--- 0.30731940269470215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.20650122]
 [0.        ]
 [0.        ]
 [0.10064659]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9985672 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 1.5007524]
 [-0.       ]
 [-0.       ]
 [-1.1558461]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.8261805]
 [ 0.       ]]
--- 0.2567603588104248 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2769.16943359375, (1342.8507, 0.8853232, 1425.0142, 0.41914922)
   validation loss 1032.652587890625, (736.66296, 0.23240942, 295.33795, 0.41914922)
decoder loss ratio: 28539.602123, decoder SINDy loss  ratio: 0.637529
--- 0.3096628189086914 seconds for one epoch ---
--- 1.1355273723602295 seconds for one epoch ---
--- 0.29747843742370605 seconds for one epoch ---
--- 1.1573982238769531 seconds for one epoch ---
--- 0.3009622097015381 seconds for one epoch ---
--- 1.1524302959442139 seconds for one epoch ---
--- 0.29364514350891113 seconds for one epoch ---
--- 1.1363410949707031 seconds for one epoch ---
--- 0.25803685188293457 seconds for one epoch ---
--- 1.1691112518310547 seconds for one epoch ---
--- 0.2926623821258545 seconds for one epoch ---
--- 1.143991470336914 seconds for one epoch ---
--- 0.2933633327484131 seconds for one epoch ---
--- 1.1560325622558594 seconds for one epoch ---
--- 0.28849291801452637 seconds for one epoch ---
--- 1.159684419631958 seconds for one epoch ---
--- 0.28929853439331055 seconds for one epoch ---
--- 1.1598234176635742 seconds for one epoch ---
--- 0.29175758361816406 seconds for one epoch ---
--- 1.140472173690796 seconds for one epoch ---
--- 0.28618574142456055 seconds for one epoch ---
--- 1.1578612327575684 seconds for one epoch ---
--- 0.29958653450012207 seconds for one epoch ---
--- 1.1603796482086182 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.20437247]
 [0.        ]
 [0.        ]
 [0.10154808]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9987059 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 1.4954079]
 [ 0.       ]
 [ 0.       ]
 [-1.1598911]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.8703256]
 [ 0.       ]]
--- 0.3051118850708008 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3507.8251953125, (1369.8762, 8.747866, 2128.7817, 0.41950303)
   validation loss 734.004150390625, (467.44687, 0.1914387, 265.94635, 0.41950303)
decoder loss ratio: 18109.703225, decoder SINDy loss  ratio: 0.574083
--- 0.2579641342163086 seconds for one epoch ---
--- 0.29340243339538574 seconds for one epoch ---
--- 1.1191203594207764 seconds for one epoch ---
--- 0.2932014465332031 seconds for one epoch ---
--- 1.1602511405944824 seconds for one epoch ---
--- 0.2949240207672119 seconds for one epoch ---
--- 1.1515834331512451 seconds for one epoch ---
--- 0.2838935852050781 seconds for one epoch ---
--- 1.1560416221618652 seconds for one epoch ---
--- 0.30758118629455566 seconds for one epoch ---
--- 1.1648600101470947 seconds for one epoch ---
--- 0.30674076080322266 seconds for one epoch ---
--- 1.1511154174804688 seconds for one epoch ---
--- 0.30284786224365234 seconds for one epoch ---
--- 1.1761949062347412 seconds for one epoch ---
--- 0.28592920303344727 seconds for one epoch ---
--- 1.1612637042999268 seconds for one epoch ---
--- 0.2963268756866455 seconds for one epoch ---
--- 1.1652355194091797 seconds for one epoch ---
--- 0.2988910675048828 seconds for one epoch ---
--- 1.1635451316833496 seconds for one epoch ---
--- 0.28628110885620117 seconds for one epoch ---
--- 1.1526548862457275 seconds for one epoch ---
--- 0.29540228843688965 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.20067614]
 [0.        ]
 [0.        ]
 [0.10027731]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9988711 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.4860307]
 [ 0.       ]
 [ 0.       ]
 [-1.1541843]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.929696 ]
 [-0.       ]]
--- 0.2475903034210205 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4444.9833984375, (2159.716, 1.552307, 2283.2964, 0.4189323)
   validation loss 776.5496215820312, (515.806, 0.17812674, 260.14655, 0.4189323)
decoder loss ratio: 19983.221091, decoder SINDy loss  ratio: 0.561563
--- 0.29990124702453613 seconds for one epoch ---
--- 1.1438837051391602 seconds for one epoch ---
--- 0.2922048568725586 seconds for one epoch ---
--- 1.151895523071289 seconds for one epoch ---
--- 0.2921559810638428 seconds for one epoch ---
--- 1.1555166244506836 seconds for one epoch ---
--- 0.29307055473327637 seconds for one epoch ---
--- 1.1605160236358643 seconds for one epoch ---
--- 0.28656721115112305 seconds for one epoch ---
--- 1.1496303081512451 seconds for one epoch ---
--- 0.2847414016723633 seconds for one epoch ---
--- 1.1997292041778564 seconds for one epoch ---
--- 0.3101515769958496 seconds for one epoch ---
--- 1.1724762916564941 seconds for one epoch ---
--- 0.3042171001434326 seconds for one epoch ---
--- 1.182384729385376 seconds for one epoch ---
--- 0.2960011959075928 seconds for one epoch ---
--- 1.2103443145751953 seconds for one epoch ---
--- 0.28819823265075684 seconds for one epoch ---
--- 1.1795272827148438 seconds for one epoch ---
--- 0.29457688331604004 seconds for one epoch ---
--- 1.1675376892089844 seconds for one epoch ---
--- 0.3103153705596924 seconds for one epoch ---
--- 1.1684370040893555 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19659093]
 [0.        ]
 [0.        ]
 [0.10128754]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905384]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [ 1.4755162]
 [ 0.       ]
 [-0.       ]
 [-1.1587284]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.0063596]
 [-0.       ]]
--- 0.27942323684692383 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2580.32421875, (1312.0354, 1.7142582, 1266.1562, 0.41838)
   validation loss 1336.8902587890625, (1035.0283, 0.17241758, 301.27127, 0.41838)
decoder loss ratio: 40098.794017, decoder SINDy loss  ratio: 0.650336
--- 0.2637336254119873 seconds for one epoch ---
--- 0.29337215423583984 seconds for one epoch ---
--- 1.184898853302002 seconds for one epoch ---
--- 0.2904231548309326 seconds for one epoch ---
--- 1.1905665397644043 seconds for one epoch ---
--- 0.29665112495422363 seconds for one epoch ---
--- 1.1707863807678223 seconds for one epoch ---
--- 0.2862405776977539 seconds for one epoch ---
--- 1.1915550231933594 seconds for one epoch ---
--- 0.296736478805542 seconds for one epoch ---
--- 1.174999713897705 seconds for one epoch ---
--- 0.30097293853759766 seconds for one epoch ---
--- 1.1624526977539062 seconds for one epoch ---
--- 0.31267285346984863 seconds for one epoch ---
--- 1.1851873397827148 seconds for one epoch ---
--- 0.2916743755340576 seconds for one epoch ---
--- 1.1845407485961914 seconds for one epoch ---
--- 0.28934550285339355 seconds for one epoch ---
--- 1.1541671752929688 seconds for one epoch ---
--- 0.295734167098999 seconds for one epoch ---
--- 1.1878819465637207 seconds for one epoch ---
--- 0.2960014343261719 seconds for one epoch ---
--- 1.1841809749603271 seconds for one epoch ---
--- 0.3042302131652832 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19443572]
 [0.        ]
 [0.        ]
 [0.10147659]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99919105]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.4699035]
 [-0.       ]
 [ 0.       ]
 [-1.1595762]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.0747943]
 [ 0.       ]]
--- 0.27597928047180176 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2649.171142578125, (1089.0531, 1.8214246, 1557.8783, 0.41824642)
   validation loss 914.688232421875, (646.9155, 0.20442387, 267.15002, 0.41824642)
decoder loss ratio: 25062.630624, decoder SINDy loss  ratio: 0.576681
--- 0.308337926864624 seconds for one epoch ---
--- 1.1808044910430908 seconds for one epoch ---
--- 0.3020050525665283 seconds for one epoch ---
--- 1.1475393772125244 seconds for one epoch ---
--- 0.28046560287475586 seconds for one epoch ---
--- 1.1833045482635498 seconds for one epoch ---
--- 0.2867097854614258 seconds for one epoch ---
--- 1.1867618560791016 seconds for one epoch ---
--- 0.28809571266174316 seconds for one epoch ---
--- 1.1956284046173096 seconds for one epoch ---
--- 0.29376888275146484 seconds for one epoch ---
--- 1.179589033126831 seconds for one epoch ---
--- 0.2878279685974121 seconds for one epoch ---
--- 1.1977734565734863 seconds for one epoch ---
--- 0.30458688735961914 seconds for one epoch ---
--- 1.1919598579406738 seconds for one epoch ---
--- 0.32301807403564453 seconds for one epoch ---
--- 1.2064995765686035 seconds for one epoch ---
--- 0.3028452396392822 seconds for one epoch ---
--- 1.2036457061767578 seconds for one epoch ---
--- 0.29924869537353516 seconds for one epoch ---
--- 1.2005650997161865 seconds for one epoch ---
--- 0.3005943298339844 seconds for one epoch ---
--- 1.2080929279327393 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19048424]
 [0.        ]
 [0.        ]
 [0.09800419]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9992876 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 1.4594896]
 [ 0.       ]
 [-0.       ]
 [-1.1438166]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.1298785]
 [-0.       ]]
--- 0.2866790294647217 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3454.408203125, (1208.2603, 4.047571, 2241.684, 0.4162004)
   validation loss 943.1438598632812, (660.8939, 0.23526174, 281.59845, 0.4162004)
decoder loss ratio: 25604.177858, decoder SINDy loss  ratio: 0.607870
THRESHOLDING: 2 active coefficients
--- 1.2075200080871582 seconds for one epoch ---
--- 0.30081987380981445 seconds for one epoch ---
--- 1.196009635925293 seconds for one epoch ---
--- 0.30458641052246094 seconds for one epoch ---
--- 1.2241113185882568 seconds for one epoch ---
--- 0.2819552421569824 seconds for one epoch ---
--- 1.2091283798217773 seconds for one epoch ---
--- 0.31179118156433105 seconds for one epoch ---
--- 1.1801254749298096 seconds for one epoch ---
--- 0.2952115535736084 seconds for one epoch ---
--- 1.1999084949493408 seconds for one epoch ---
--- 0.2838616371154785 seconds for one epoch ---
--- 1.2234058380126953 seconds for one epoch ---
--- 0.2932302951812744 seconds for one epoch ---
--- 1.2118678092956543 seconds for one epoch ---
--- 0.30246806144714355 seconds for one epoch ---
--- 1.171299934387207 seconds for one epoch ---
--- 0.2999434471130371 seconds for one epoch ---
--- 1.191291332244873 seconds for one epoch ---
--- 0.288311243057251 seconds for one epoch ---
--- 1.194061517715454 seconds for one epoch ---
--- 0.29604220390319824 seconds for one epoch ---
--- 1.2147009372711182 seconds for one epoch ---
--- 0.29149341583251953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.07470426]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99955595]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [ 1.0229275]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.336915 ]
 [ 0.       ]]
--- 0.2507662773132324 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3100.71142578125, (1308.558, 5.8824635, 1785.9386, 0.33241984)
   validation loss 879.4901123046875, (582.46814, 0.26546103, 296.42416, 0.33241984)
decoder loss ratio: 22565.826939, decoder SINDy loss  ratio: 0.639873
--- 0.3008158206939697 seconds for one epoch ---
--- 1.2253880500793457 seconds for one epoch ---
--- 0.3098635673522949 seconds for one epoch ---
--- 1.2303342819213867 seconds for one epoch ---
--- 0.30823254585266113 seconds for one epoch ---
--- 1.2377126216888428 seconds for one epoch ---
--- 0.2820730209350586 seconds for one epoch ---
--- 1.2206778526306152 seconds for one epoch ---
--- 0.29014039039611816 seconds for one epoch ---
--- 1.2141516208648682 seconds for one epoch ---
--- 0.2997856140136719 seconds for one epoch ---
--- 1.2083430290222168 seconds for one epoch ---
--- 0.2931516170501709 seconds for one epoch ---
--- 1.2104477882385254 seconds for one epoch ---
--- 0.29526305198669434 seconds for one epoch ---
--- 1.2188982963562012 seconds for one epoch ---
--- 0.2982490062713623 seconds for one epoch ---
--- 1.213791847229004 seconds for one epoch ---
--- 0.3069741725921631 seconds for one epoch ---
--- 1.2005736827850342 seconds for one epoch ---
--- 0.3149111270904541 seconds for one epoch ---
--- 1.2176427841186523 seconds for one epoch ---
--- 0.29999756813049316 seconds for one epoch ---
--- 1.2359998226165771 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.03753008]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99972034]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [ 0.7276673]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.5405416]
 [ 0.       ]]
--- 0.27628302574157715 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3223.84326171875, (2076.4927, 3.3399374, 1143.696, 0.3147522)
   validation loss 949.6051025390625, (619.2055, 0.2708403, 329.81403, 0.3147522)
decoder loss ratio: 23989.096266, decoder SINDy loss  ratio: 0.711950
--- 0.25974416732788086 seconds for one epoch ---
--- 0.303480863571167 seconds for one epoch ---
--- 1.196869134902954 seconds for one epoch ---
--- 0.2944300174713135 seconds for one epoch ---
--- 1.220682144165039 seconds for one epoch ---
--- 0.2959742546081543 seconds for one epoch ---
--- 1.2269697189331055 seconds for one epoch ---
--- 0.29520344734191895 seconds for one epoch ---
--- 1.2329189777374268 seconds for one epoch ---
--- 0.29831981658935547 seconds for one epoch ---
--- 1.2325818538665771 seconds for one epoch ---
--- 0.30510544776916504 seconds for one epoch ---
--- 1.240427017211914 seconds for one epoch ---
--- 0.31873464584350586 seconds for one epoch ---
--- 1.2078394889831543 seconds for one epoch ---
--- 0.29883837699890137 seconds for one epoch ---
--- 1.254770040512085 seconds for one epoch ---
--- 0.2980692386627197 seconds for one epoch ---
--- 1.2454912662506104 seconds for one epoch ---
--- 0.27881479263305664 seconds for one epoch ---
--- 1.2194163799285889 seconds for one epoch ---
--- 0.29221153259277344 seconds for one epoch ---
--- 1.2347629070281982 seconds for one epoch ---
--- 0.29456138610839844 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02257589]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.999833  ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [ 0.51607615]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-5.7699347 ]
 [-0.        ]]
--- 0.24425935745239258 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4369.3251953125, (2166.3862, 1.3901113, 2201.2446, 0.30419287)
   validation loss 701.8682861328125, (428.8753, 0.21026254, 272.47855, 0.30419287)
decoder loss ratio: 16615.373883, decoder SINDy loss  ratio: 0.588183
--- 0.2980020046234131 seconds for one epoch ---
--- 1.219214916229248 seconds for one epoch ---
--- 0.32174110412597656 seconds for one epoch ---
--- 1.2165863513946533 seconds for one epoch ---
--- 0.297443151473999 seconds for one epoch ---
--- 1.210312843322754 seconds for one epoch ---
--- 0.29372167587280273 seconds for one epoch ---
--- 1.2260372638702393 seconds for one epoch ---
--- 0.3017289638519287 seconds for one epoch ---
--- 1.265002727508545 seconds for one epoch ---
--- 0.3253326416015625 seconds for one epoch ---
--- 1.234208345413208 seconds for one epoch ---
--- 0.3033115863800049 seconds for one epoch ---
--- 1.2369205951690674 seconds for one epoch ---
--- 0.29848146438598633 seconds for one epoch ---
--- 1.2376344203948975 seconds for one epoch ---
--- 0.30547118186950684 seconds for one epoch ---
--- 1.23331880569458 seconds for one epoch ---
--- 0.28546810150146484 seconds for one epoch ---
--- 1.2435500621795654 seconds for one epoch ---
--- 0.29611778259277344 seconds for one epoch ---
--- 1.2571210861206055 seconds for one epoch ---
--- 0.3000984191894531 seconds for one epoch ---
--- 1.254439353942871 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01503282]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99989223]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [ 0.34917176]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-5.968181  ]
 [-0.        ]]
--- 0.30519771575927734 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3064.317138671875, (1186.9353, 0.97017264, 1876.1146, 0.29702008)
   validation loss 1487.8355712890625, (1130.9102, 0.2617411, 356.3667, 0.29702008)
decoder loss ratio: 43813.422799, decoder SINDy loss  ratio: 0.769268
--- 0.25636959075927734 seconds for one epoch ---
--- 0.2978827953338623 seconds for one epoch ---
--- 1.2502291202545166 seconds for one epoch ---
--- 0.29783105850219727 seconds for one epoch ---
--- 1.2440910339355469 seconds for one epoch ---
--- 0.30310511589050293 seconds for one epoch ---
--- 1.2686707973480225 seconds for one epoch ---
--- 0.2805619239807129 seconds for one epoch ---
--- 1.241978645324707 seconds for one epoch ---
--- 0.2961597442626953 seconds for one epoch ---
--- 1.245147705078125 seconds for one epoch ---
--- 0.28925585746765137 seconds for one epoch ---
--- 1.241417407989502 seconds for one epoch ---
--- 0.30727362632751465 seconds for one epoch ---
--- 1.2530627250671387 seconds for one epoch ---
--- 0.2987487316131592 seconds for one epoch ---
--- 1.2628605365753174 seconds for one epoch ---
--- 0.31682729721069336 seconds for one epoch ---
--- 1.2335078716278076 seconds for one epoch ---
--- 0.3018801212310791 seconds for one epoch ---
--- 1.2653357982635498 seconds for one epoch ---
--- 0.29562950134277344 seconds for one epoch ---
--- 1.230360746383667 seconds for one epoch ---
--- 0.2972893714904785 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01097772]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999294 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.2211827]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-6.1678004]
 [ 0.       ]]
--- 0.2549118995666504 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3765.84521484375, (1657.0848, 1.852497, 2106.6155, 0.2923629)
   validation loss 1149.1026611328125, (805.8735, 0.3010661, 342.6357, 0.2923629)
decoder loss ratio: 31220.937445, decoder SINDy loss  ratio: 0.739627
--- 0.3027520179748535 seconds for one epoch ---
--- 1.2517693042755127 seconds for one epoch ---
--- 0.31374144554138184 seconds for one epoch ---
--- 1.2652347087860107 seconds for one epoch ---
--- 0.3000025749206543 seconds for one epoch ---
--- 1.2644269466400146 seconds for one epoch ---
--- 0.2917153835296631 seconds for one epoch ---
--- 1.261016607284546 seconds for one epoch ---
--- 0.3011167049407959 seconds for one epoch ---
--- 1.2921051979064941 seconds for one epoch ---
--- 0.3097212314605713 seconds for one epoch ---
--- 1.264228343963623 seconds for one epoch ---
--- 0.30338144302368164 seconds for one epoch ---
--- 1.2604291439056396 seconds for one epoch ---
--- 0.30063819885253906 seconds for one epoch ---
--- 1.2759993076324463 seconds for one epoch ---
--- 0.3168001174926758 seconds for one epoch ---
--- 1.2945582866668701 seconds for one epoch ---
--- 0.30521297454833984 seconds for one epoch ---
--- 1.2788467407226562 seconds for one epoch ---
--- 0.29826903343200684 seconds for one epoch ---
--- 1.2533526420593262 seconds for one epoch ---
--- 0.29504847526550293 seconds for one epoch ---
--- 1.274582862854004 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.00815613]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999564 ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.10087726]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.3732834 ]
 [-0.        ]]
--- 0.27986693382263184 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2583.90625, (873.8342, 0.51911414, 1709.2648, 0.28815013)
   validation loss 863.9988403320312, (558.51953, 0.32098025, 304.87015, 0.28815013)
decoder loss ratio: 21638.016273, decoder SINDy loss  ratio: 0.658105
--- 0.26108837127685547 seconds for one epoch ---
--- 0.3009917736053467 seconds for one epoch ---
--- 1.282099723815918 seconds for one epoch ---
--- 0.2966310977935791 seconds for one epoch ---
--- 1.293036699295044 seconds for one epoch ---
--- 0.31023740768432617 seconds for one epoch ---
--- 1.2673070430755615 seconds for one epoch ---
--- 0.2867274284362793 seconds for one epoch ---
--- 1.272188425064087 seconds for one epoch ---
--- 0.2993602752685547 seconds for one epoch ---
--- 1.279710292816162 seconds for one epoch ---
--- 0.2971341609954834 seconds for one epoch ---
--- 1.298154592514038 seconds for one epoch ---
--- 0.2874741554260254 seconds for one epoch ---
--- 1.2633438110351562 seconds for one epoch ---
--- 0.3020200729370117 seconds for one epoch ---
--- 1.2939980030059814 seconds for one epoch ---
--- 0.2906174659729004 seconds for one epoch ---
--- 1.2542781829833984 seconds for one epoch ---
--- 0.298583984375 seconds for one epoch ---
--- 1.288379430770874 seconds for one epoch ---
--- 0.30737948417663574 seconds for one epoch ---
--- 1.3021483421325684 seconds for one epoch ---
--- 0.2988317012786865 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.00666233]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99997354]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [ 0.01926596]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-6.597682  ]
 [ 0.        ]]
--- 0.25112175941467285 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3153.28271484375, (1681.3474, 1.5834632, 1470.0654, 0.2862924)
   validation loss 839.5628051757812, (538.2791, 0.3843395, 300.61307, 0.2862924)
decoder loss ratio: 20853.867361, decoder SINDy loss  ratio: 0.648916
--- 0.2973198890686035 seconds for one epoch ---
--- 1.2789475917816162 seconds for one epoch ---
--- 0.30164551734924316 seconds for one epoch ---
--- 1.2702062129974365 seconds for one epoch ---
--- 0.2959897518157959 seconds for one epoch ---
--- 1.2878305912017822 seconds for one epoch ---
--- 0.2950873374938965 seconds for one epoch ---
--- 1.3072705268859863 seconds for one epoch ---
--- 0.2874882221221924 seconds for one epoch ---
--- 1.2925796508789062 seconds for one epoch ---
--- 0.2976393699645996 seconds for one epoch ---
--- 1.2921011447906494 seconds for one epoch ---
--- 0.28652453422546387 seconds for one epoch ---
--- 1.2886016368865967 seconds for one epoch ---
--- 0.2907414436340332 seconds for one epoch ---
--- 1.304183006286621 seconds for one epoch ---
--- 0.28234267234802246 seconds for one epoch ---
--- 1.309295892715454 seconds for one epoch ---
--- 0.2855656147003174 seconds for one epoch ---
--- 1.2915115356445312 seconds for one epoch ---
--- 0.2814035415649414 seconds for one epoch ---
--- 1.2652268409729004 seconds for one epoch ---
--- 0.2801220417022705 seconds for one epoch ---
--- 1.2925846576690674 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.00750247]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999788 ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.06715993]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.8023562 ]
 [ 0.        ]]
--- 0.28345322608947754 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5532.328125, (1301.5162, 1.4594172, 4229.0615, 0.29105848)
   validation loss 1213.1748046875, (897.2981, 0.35301322, 315.23264, 0.29105848)
decoder loss ratio: 34762.886006, decoder SINDy loss  ratio: 0.680474
--- 0.26511645317077637 seconds for one epoch ---
--- 0.29300928115844727 seconds for one epoch ---
--- 1.3132078647613525 seconds for one epoch ---
--- 0.3269846439361572 seconds for one epoch ---
--- 1.2870988845825195 seconds for one epoch ---
--- 0.2912936210632324 seconds for one epoch ---
--- 1.286872386932373 seconds for one epoch ---
--- 0.28522205352783203 seconds for one epoch ---
--- 1.2875616550445557 seconds for one epoch ---
--- 0.28235387802124023 seconds for one epoch ---
--- 1.2981953620910645 seconds for one epoch ---
--- 0.2972686290740967 seconds for one epoch ---
--- 1.267643690109253 seconds for one epoch ---
--- 0.29349231719970703 seconds for one epoch ---
--- 1.309389591217041 seconds for one epoch ---
--- 0.2989766597747803 seconds for one epoch ---
--- 1.3135707378387451 seconds for one epoch ---
--- 0.3145914077758789 seconds for one epoch ---
--- 1.303452968597412 seconds for one epoch ---
--- 0.2925224304199219 seconds for one epoch ---
--- 1.3313591480255127 seconds for one epoch ---
--- 0.29131531715393066 seconds for one epoch ---
--- 1.2836503982543945 seconds for one epoch ---
--- 0.297029972076416 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.00858864]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999094]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.12178022]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.023854  ]
 [-0.        ]]
--- 0.25836825370788574 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3807.105712890625, (1223.518, 1.4303612, 2581.8616, 0.29577538)
   validation loss 862.2987060546875, (559.5527, 0.33171812, 302.11856, 0.29577538)
decoder loss ratio: 21678.041991, decoder SINDy loss  ratio: 0.652165
--- 0.29927730560302734 seconds for one epoch ---
--- 1.321373462677002 seconds for one epoch ---
--- 0.297931432723999 seconds for one epoch ---
--- 1.289229393005371 seconds for one epoch ---
--- 0.30898380279541016 seconds for one epoch ---
--- 1.3031611442565918 seconds for one epoch ---
--- 0.29245448112487793 seconds for one epoch ---
--- 1.2834272384643555 seconds for one epoch ---
--- 0.2723720073699951 seconds for one epoch ---
--- 1.2954132556915283 seconds for one epoch ---
--- 0.29087066650390625 seconds for one epoch ---
--- 1.317204475402832 seconds for one epoch ---
--- 0.28893375396728516 seconds for one epoch ---
--- 1.3176312446594238 seconds for one epoch ---
--- 0.2941129207611084 seconds for one epoch ---
--- 1.3286235332489014 seconds for one epoch ---
--- 0.3025352954864502 seconds for one epoch ---
--- 1.3096396923065186 seconds for one epoch ---
--- 0.30748891830444336 seconds for one epoch ---
--- 1.299250602722168 seconds for one epoch ---
--- 0.29660940170288086 seconds for one epoch ---
--- 1.312424898147583 seconds for one epoch ---
--- 0.2963881492614746 seconds for one epoch ---
--- 1.3093597888946533 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.0094277]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999908]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [-0.1594992]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.22646  ]
 [-0.       ]]
--- 0.2977175712585449 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2382.461669921875, (1124.8239, 0.5770999, 1256.7609, 0.29988343)
   validation loss 912.1327514648438, (592.25745, 0.29956737, 319.27588, 0.29988343)
decoder loss ratio: 22945.081673, decoder SINDy loss  ratio: 0.689202
--- 0.25822949409484863 seconds for one epoch ---
--- 0.29201793670654297 seconds for one epoch ---
--- 1.3045752048492432 seconds for one epoch ---
--- 0.2917933464050293 seconds for one epoch ---
--- 1.292008399963379 seconds for one epoch ---
--- 0.29778170585632324 seconds for one epoch ---
--- 1.2988581657409668 seconds for one epoch ---
--- 0.30045557022094727 seconds for one epoch ---
--- 1.3308279514312744 seconds for one epoch ---
--- 0.5386736392974854 seconds for one epoch ---
--- 1.3648316860198975 seconds for one epoch ---
--- 0.29568982124328613 seconds for one epoch ---
--- 1.3116247653961182 seconds for one epoch ---
--- 0.30484676361083984 seconds for one epoch ---
--- 1.3726599216461182 seconds for one epoch ---
--- 0.30025386810302734 seconds for one epoch ---
--- 1.3095240592956543 seconds for one epoch ---
--- 0.31916379928588867 seconds for one epoch ---
--- 1.3421878814697266 seconds for one epoch ---
--- 0.29331541061401367 seconds for one epoch ---
--- 1.3312890529632568 seconds for one epoch ---
--- 0.2922031879425049 seconds for one epoch ---
--- 1.3377797603607178 seconds for one epoch ---
--- 0.29495763778686523 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01043825]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999907 ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.20076519]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.4113607 ]
 [ 0.        ]]
--- 0.24334430694580078 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4235.21923828125, (1389.2024, 2.7013566, 2843.0117, 0.3039401)
   validation loss 744.9715576171875, (472.547, 0.26143527, 271.8592, 0.3039401)
decoder loss ratio: 18307.291044, decoder SINDy loss  ratio: 0.586846
--- 0.28774452209472656 seconds for one epoch ---
--- 1.3340446949005127 seconds for one epoch ---
--- 0.29550814628601074 seconds for one epoch ---
--- 1.338479995727539 seconds for one epoch ---
--- 0.2928946018218994 seconds for one epoch ---
--- 1.3060493469238281 seconds for one epoch ---
--- 0.29403162002563477 seconds for one epoch ---
--- 1.3268213272094727 seconds for one epoch ---
--- 0.28326940536499023 seconds for one epoch ---
--- 1.3297605514526367 seconds for one epoch ---
--- 0.2996342182159424 seconds for one epoch ---
--- 1.3492026329040527 seconds for one epoch ---
--- 0.2924232482910156 seconds for one epoch ---
--- 1.3373723030090332 seconds for one epoch ---
--- 0.26845574378967285 seconds for one epoch ---
--- 1.3091423511505127 seconds for one epoch ---
--- 0.29007530212402344 seconds for one epoch ---
--- 1.3327407836914062 seconds for one epoch ---
--- 0.29437994956970215 seconds for one epoch ---
--- 1.3526451587677002 seconds for one epoch ---
--- 0.29093217849731445 seconds for one epoch ---
--- 1.3520221710205078 seconds for one epoch ---
--- 0.29924488067626953 seconds for one epoch ---
--- 1.3449106216430664 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01116791]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999906 ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.22818743]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-7.5963473 ]
 [-0.        ]]
--- 0.2757885456085205 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7170.83935546875, (803.94794, 2.584366, 6364.0, 0.3073133)
   validation loss 995.4712524414062, (704.7428, 0.25761724, 290.1635, 0.3073133)
decoder loss ratio: 27302.959476, decoder SINDy loss  ratio: 0.626359
--- 0.24948573112487793 seconds for one epoch ---
--- 0.28165769577026367 seconds for one epoch ---
--- 1.3247897624969482 seconds for one epoch ---
--- 0.29061245918273926 seconds for one epoch ---
--- 1.334214210510254 seconds for one epoch ---
--- 0.29671621322631836 seconds for one epoch ---
--- 1.3289058208465576 seconds for one epoch ---
--- 0.30036306381225586 seconds for one epoch ---
--- 1.3341646194458008 seconds for one epoch ---
--- 0.29457545280456543 seconds for one epoch ---
--- 1.3564000129699707 seconds for one epoch ---
--- 0.28633666038513184 seconds for one epoch ---
--- 1.3228018283843994 seconds for one epoch ---
--- 0.3057258129119873 seconds for one epoch ---
--- 1.3439419269561768 seconds for one epoch ---
--- 0.3087034225463867 seconds for one epoch ---
--- 1.3468997478485107 seconds for one epoch ---
--- 0.2955751419067383 seconds for one epoch ---
--- 1.3526427745819092 seconds for one epoch ---
--- 0.2928042411804199 seconds for one epoch ---
--- 1.3563497066497803 seconds for one epoch ---
--- 0.28482627868652344 seconds for one epoch ---
--- 1.355072021484375 seconds for one epoch ---
--- 0.2889277935028076 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01194374]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999906 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.2554778]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.793916 ]
 [ 0.       ]]
--- 0.2638721466064453 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2573.831787109375, (1404.925, 0.651557, 1167.9443, 0.3108596)
   validation loss 1031.248779296875, (727.08234, 0.20685805, 303.64868, 0.3108596)
decoder loss ratio: 28168.431984, decoder SINDy loss  ratio: 0.655468
--- 0.25310373306274414 seconds for one epoch ---
--- 1.3445720672607422 seconds for one epoch ---
--- 0.2958662509918213 seconds for one epoch ---
--- 1.337522029876709 seconds for one epoch ---
--- 0.30019402503967285 seconds for one epoch ---
--- 1.339095115661621 seconds for one epoch ---
--- 0.2937049865722656 seconds for one epoch ---
--- 1.3423423767089844 seconds for one epoch ---
--- 0.29656052589416504 seconds for one epoch ---
--- 1.369328260421753 seconds for one epoch ---
--- 0.2987380027770996 seconds for one epoch ---
--- 1.3600268363952637 seconds for one epoch ---
--- 0.2902514934539795 seconds for one epoch ---
--- 1.3400695323944092 seconds for one epoch ---
--- 0.30066490173339844 seconds for one epoch ---
--- 1.359041452407837 seconds for one epoch ---
--- 0.30371665954589844 seconds for one epoch ---
--- 1.3896369934082031 seconds for one epoch ---
--- 0.2973644733428955 seconds for one epoch ---
--- 1.3640668392181396 seconds for one epoch ---
--- 0.2958686351776123 seconds for one epoch ---
--- 1.3724725246429443 seconds for one epoch ---
--- 0.2999839782714844 seconds for one epoch ---
--- 1.3791439533233643 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01255002]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999094]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.27561867]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.969084  ]
 [ 0.        ]]
--- 0.30396366119384766 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1962.265869140625, (1284.7463, 0.8203174, 676.38544, 0.3137353)
   validation loss 1594.4913330078125, (1291.362, 0.2674203, 302.54813, 0.3137353)
decoder loss ratio: 50029.608129, decoder SINDy loss  ratio: 0.653093
--- 0.2594718933105469 seconds for one epoch ---
--- 0.29003071784973145 seconds for one epoch ---
--- 1.3392119407653809 seconds for one epoch ---
--- 0.28318285942077637 seconds for one epoch ---
--- 1.372736930847168 seconds for one epoch ---
--- 0.28790950775146484 seconds for one epoch ---
--- 1.3764874935150146 seconds for one epoch ---
--- 0.28475022315979004 seconds for one epoch ---
--- 1.3754920959472656 seconds for one epoch ---
--- 0.2891218662261963 seconds for one epoch ---
--- 1.392381191253662 seconds for one epoch ---
--- 0.2901878356933594 seconds for one epoch ---
--- 1.3582580089569092 seconds for one epoch ---
--- 0.2913832664489746 seconds for one epoch ---
--- 1.3939354419708252 seconds for one epoch ---
--- 0.2923102378845215 seconds for one epoch ---
--- 1.3894596099853516 seconds for one epoch ---
--- 0.27497124671936035 seconds for one epoch ---
--- 1.3760440349578857 seconds for one epoch ---
--- 0.29399633407592773 seconds for one epoch ---
--- 1.3736708164215088 seconds for one epoch ---
--- 0.2950565814971924 seconds for one epoch ---
--- 1.3603026866912842 seconds for one epoch ---
--- 0.2860887050628662 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01351797]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999918 ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.30587485]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.141081  ]
 [-0.        ]]
--- 0.25344133377075195 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4659.1015625, (2327.9417, 1.6660378, 2329.1768, 0.31742883)
   validation loss 949.5780639648438, (641.85016, 0.32703653, 307.0834, 0.31742883)
decoder loss ratio: 24866.389449, decoder SINDy loss  ratio: 0.662883
--- 0.2954866886138916 seconds for one epoch ---
--- 1.3930156230926514 seconds for one epoch ---
--- 0.29316139221191406 seconds for one epoch ---
--- 1.3786964416503906 seconds for one epoch ---
--- 0.29384851455688477 seconds for one epoch ---
--- 1.397601842880249 seconds for one epoch ---
--- 0.2879164218902588 seconds for one epoch ---
--- 1.3707606792449951 seconds for one epoch ---
--- 0.2989075183868408 seconds for one epoch ---
--- 1.3873581886291504 seconds for one epoch ---
--- 0.29444193840026855 seconds for one epoch ---
--- 1.3870885372161865 seconds for one epoch ---
--- 0.29052233695983887 seconds for one epoch ---
--- 1.3687596321105957 seconds for one epoch ---
--- 0.3025522232055664 seconds for one epoch ---
--- 1.3651301860809326 seconds for one epoch ---
--- 0.2913072109222412 seconds for one epoch ---
--- 1.366598129272461 seconds for one epoch ---
--- 0.3005063533782959 seconds for one epoch ---
--- 1.3785035610198975 seconds for one epoch ---
--- 0.2883121967315674 seconds for one epoch ---
--- 1.3764724731445312 seconds for one epoch ---
--- 0.2917912006378174 seconds for one epoch ---
--- 1.38442063331604 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01399862]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999925 ]
 [0.        ]]
[[-0.        ]
 [ 0.        ]
 [-0.32011953]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-8.302765  ]
 [-0.        ]]
--- 0.2942996025085449 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1614.785400390625, (801.0828, 0.44254115, 812.94006, 0.31993482)
   validation loss 903.92041015625, (617.28796, 0.27655953, 286.03598, 0.31993482)
decoder loss ratio: 23914.807379, decoder SINDy loss  ratio: 0.617449
--- 0.2583146095275879 seconds for one epoch ---
--- 0.28690552711486816 seconds for one epoch ---
--- 1.364271640777588 seconds for one epoch ---
--- 0.29315996170043945 seconds for one epoch ---
--- 1.3910634517669678 seconds for one epoch ---
--- 0.2971055507659912 seconds for one epoch ---
--- 1.4113843441009521 seconds for one epoch ---
--- 0.2943906784057617 seconds for one epoch ---
--- 1.3772809505462646 seconds for one epoch ---
--- 0.2985095977783203 seconds for one epoch ---
--- 1.3635993003845215 seconds for one epoch ---
--- 0.28068017959594727 seconds for one epoch ---
--- 1.379690408706665 seconds for one epoch ---
--- 0.3048362731933594 seconds for one epoch ---
--- 1.3769111633300781 seconds for one epoch ---
--- 0.29621076583862305 seconds for one epoch ---
--- 1.3997344970703125 seconds for one epoch ---
--- 0.31823301315307617 seconds for one epoch ---
--- 1.3800945281982422 seconds for one epoch ---
--- 0.2932412624359131 seconds for one epoch ---
--- 1.3999578952789307 seconds for one epoch ---
--- 0.2807793617248535 seconds for one epoch ---
--- 1.4046008586883545 seconds for one epoch ---
--- 0.28365445137023926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01461829]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999939 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.3377922]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-8.45912  ]
 [ 0.       ]]
--- 0.25774264335632324 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2329.140625, (1142.367, 2.3451896, 1184.1058, 0.3228507)
   validation loss 1028.5450439453125, (730.91156, 0.34401506, 296.96658, 0.3228507)
decoder loss ratio: 28316.782755, decoder SINDy loss  ratio: 0.641044
--- 0.30476880073547363 seconds for one epoch ---
--- 1.3642661571502686 seconds for one epoch ---
--- 0.29249095916748047 seconds for one epoch ---
--- 1.3878400325775146 seconds for one epoch ---
--- 0.3019084930419922 seconds for one epoch ---
--- 1.4174258708953857 seconds for one epoch ---
--- 0.29363155364990234 seconds for one epoch ---
--- 1.4000298976898193 seconds for one epoch ---
--- 0.2988240718841553 seconds for one epoch ---
--- 1.3904471397399902 seconds for one epoch ---
--- 0.29448390007019043 seconds for one epoch ---
--- 1.4015758037567139 seconds for one epoch ---
--- 0.29912495613098145 seconds for one epoch ---
--- 1.4071409702301025 seconds for one epoch ---
--- 0.2919025421142578 seconds for one epoch ---
--- 1.4030890464782715 seconds for one epoch ---
--- 0.3070392608642578 seconds for one epoch ---
--- 1.3960225582122803 seconds for one epoch ---
--- 0.29451775550842285 seconds for one epoch ---
--- 1.4104502201080322 seconds for one epoch ---
--- 0.2851736545562744 seconds for one epoch ---
--- 1.4060442447662354 seconds for one epoch ---
--- 0.29923319816589355 seconds for one epoch ---
--- 1.4044265747070312 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01537975]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999963 ]
 [0.        ]]
[[ 0.        ]
 [ 0.        ]
 [-0.35853082]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-8.626092  ]
 [-0.        ]]
--- 0.2854640483856201 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3936.692626953125, (1899.5, 12.828052, 2024.039, 0.32580277)
   validation loss 821.22802734375, (542.1139, 0.3111012, 278.47723, 0.32580277)
decoder loss ratio: 21002.433312, decoder SINDy loss  ratio: 0.601132
--- 0.2627851963043213 seconds for one epoch ---
--- 0.30083250999450684 seconds for one epoch ---
--- 1.4010491371154785 seconds for one epoch ---
--- 0.2885262966156006 seconds for one epoch ---
--- 1.4021110534667969 seconds for one epoch ---
--- 0.29667067527770996 seconds for one epoch ---
--- 1.403717041015625 seconds for one epoch ---
--- 0.31267642974853516 seconds for one epoch ---
--- 1.414088487625122 seconds for one epoch ---
--- 0.2975003719329834 seconds for one epoch ---
--- 1.429414987564087 seconds for one epoch ---
--- 0.2955930233001709 seconds for one epoch ---
--- 1.4064226150512695 seconds for one epoch ---
--- 0.294780969619751 seconds for one epoch ---
--- 1.3930389881134033 seconds for one epoch ---
--- 0.2975502014160156 seconds for one epoch ---
--- 1.421823501586914 seconds for one epoch ---
--- 0.3156299591064453 seconds for one epoch ---
--- 1.407963514328003 seconds for one epoch ---
--- 0.2944948673248291 seconds for one epoch ---
--- 1.403069019317627 seconds for one epoch ---
--- 0.2909882068634033 seconds for one epoch ---
--- 1.4366059303283691 seconds for one epoch ---
--- 0.29375171661376953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01577212]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99999845]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.3688289]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-8.773347 ]
 [ 0.       ]]
--- 0.24919819831848145 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2333.45849609375, (1194.6418, 0.86559755, 1137.6228, 0.32809067)
   validation loss 784.5679931640625, (499.08743, 0.3062487, 284.84625, 0.32809067)
decoder loss ratio: 19335.513603, decoder SINDy loss  ratio: 0.614881
--- 0.31407880783081055 seconds for one epoch ---
--- 1.433973789215088 seconds for one epoch ---
--- 0.30030322074890137 seconds for one epoch ---
--- 1.4171438217163086 seconds for one epoch ---
--- 0.29233646392822266 seconds for one epoch ---
--- 1.4434750080108643 seconds for one epoch ---
--- 0.2957329750061035 seconds for one epoch ---
--- 1.4130499362945557 seconds for one epoch ---
--- 0.3062479496002197 seconds for one epoch ---
--- 1.4292972087860107 seconds for one epoch ---
--- 0.2879195213317871 seconds for one epoch ---
--- 1.4185914993286133 seconds for one epoch ---
--- 0.3013899326324463 seconds for one epoch ---
--- 1.4343822002410889 seconds for one epoch ---
--- 0.29685163497924805 seconds for one epoch ---
--- 1.417316198348999 seconds for one epoch ---
--- 0.2987818717956543 seconds for one epoch ---
--- 1.4154527187347412 seconds for one epoch ---
--- 0.29164648056030273 seconds for one epoch ---
--- 1.4199175834655762 seconds for one epoch ---
--- 0.3016228675842285 seconds for one epoch ---
--- 1.4243621826171875 seconds for one epoch ---
--- 0.28618574142456055 seconds for one epoch ---
--- 1.4137628078460693 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01602883]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9999995 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.3754318]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-8.936664 ]
 [ 0.       ]]
--- 0.29861974716186523 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6242.15771484375, (1959.8245, 2.4805365, 4279.522, 0.33035943)
   validation loss 1015.798095703125, (733.3801, 0.304598, 281.78296, 0.33035943)
decoder loss ratio: 28412.419322, decoder SINDy loss  ratio: 0.608268
THRESHOLDING: 1 active coefficients
--- 1.3828668594360352 seconds for one epoch ---
--- 0.2867755889892578 seconds for one epoch ---
--- 1.4020359516143799 seconds for one epoch ---
--- 0.300048828125 seconds for one epoch ---
--- 1.4468145370483398 seconds for one epoch ---
--- 0.3135507106781006 seconds for one epoch ---
--- 1.4153494834899902 seconds for one epoch ---
--- 0.29460716247558594 seconds for one epoch ---
--- 1.4273922443389893 seconds for one epoch ---
--- 0.2970104217529297 seconds for one epoch ---
--- 1.3914027214050293 seconds for one epoch ---
--- 0.2896256446838379 seconds for one epoch ---
--- 1.4267752170562744 seconds for one epoch ---
--- 0.29363346099853516 seconds for one epoch ---
--- 1.4272880554199219 seconds for one epoch ---
--- 0.29746294021606445 seconds for one epoch ---
--- 1.4130306243896484 seconds for one epoch ---
--- 0.2859516143798828 seconds for one epoch ---
--- 1.4427766799926758 seconds for one epoch ---
--- 0.3026862144470215 seconds for one epoch ---
--- 1.4459693431854248 seconds for one epoch ---
--- 0.3027172088623047 seconds for one epoch ---
--- 1.445091962814331 seconds for one epoch ---
--- 0.29976797103881836 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999995]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.078467]
 [-0.      ]]
--- 0.2737150192260742 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5490.1435546875, (1984.4893, 2.0338109, 3503.3264, 0.2938548)
   validation loss 807.8685913085938, (527.99, 0.3061631, 279.27856, 0.2938548)
decoder loss ratio: 20455.248853, decoder SINDy loss  ratio: 0.602862
--- 0.295177698135376 seconds for one epoch ---
--- 1.440281867980957 seconds for one epoch ---
--- 0.2960083484649658 seconds for one epoch ---
--- 1.4387898445129395 seconds for one epoch ---
--- 0.27315640449523926 seconds for one epoch ---
--- 1.4189159870147705 seconds for one epoch ---
--- 0.30599379539489746 seconds for one epoch ---
--- 1.428523063659668 seconds for one epoch ---
--- 0.2946748733520508 seconds for one epoch ---
--- 1.4460902214050293 seconds for one epoch ---
--- 0.29959702491760254 seconds for one epoch ---
--- 1.4531376361846924 seconds for one epoch ---
--- 0.29477572441101074 seconds for one epoch ---
--- 1.4525904655456543 seconds for one epoch ---
--- 0.3061339855194092 seconds for one epoch ---
--- 1.449453353881836 seconds for one epoch ---
--- 0.292360782623291 seconds for one epoch ---
--- 1.4552688598632812 seconds for one epoch ---
--- 0.28305888175964355 seconds for one epoch ---
--- 1.4740095138549805 seconds for one epoch ---
--- 0.3074667453765869 seconds for one epoch ---
--- 1.457948923110962 seconds for one epoch ---
--- 0.29047584533691406 seconds for one epoch ---
--- 1.441321849822998 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.206897]
 [-0.      ]]
--- 0.3080763816833496 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3129.408447265625, (1538.4283, 2.2167358, 1588.4679, 0.29556194)
   validation loss 765.1524658203125, (471.98132, 0.3987246, 292.4769, 0.29556194)
decoder loss ratio: 18285.375858, decoder SINDy loss  ratio: 0.631353
--- 0.2521679401397705 seconds for one epoch ---
--- 0.3016359806060791 seconds for one epoch ---
--- 1.4636929035186768 seconds for one epoch ---
--- 0.2969856262207031 seconds for one epoch ---
--- 1.4869868755340576 seconds for one epoch ---
--- 0.2950432300567627 seconds for one epoch ---
--- 1.4685754776000977 seconds for one epoch ---
--- 0.3056964874267578 seconds for one epoch ---
--- 1.4605107307434082 seconds for one epoch ---
--- 0.3069460391998291 seconds for one epoch ---
--- 1.4596974849700928 seconds for one epoch ---
--- 0.3059401512145996 seconds for one epoch ---
--- 1.4780941009521484 seconds for one epoch ---
--- 0.2910957336425781 seconds for one epoch ---
--- 1.4952857494354248 seconds for one epoch ---
--- 0.3124394416809082 seconds for one epoch ---
--- 1.45143723487854 seconds for one epoch ---
--- 0.28154897689819336 seconds for one epoch ---
--- 1.4426441192626953 seconds for one epoch ---
--- 0.2971479892730713 seconds for one epoch ---
--- 1.44858980178833 seconds for one epoch ---
--- 0.31587934494018555 seconds for one epoch ---
--- 1.4745523929595947 seconds for one epoch ---
--- 0.2967245578765869 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9999994]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.344836]
 [ 0.      ]]
--- 0.25846242904663086 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2329.037353515625, (1115.3224, 1.440111, 1211.9775, 0.29741403)
   validation loss 822.0585327148438, (514.8019, 0.42697206, 306.5322, 0.29741403)
decoder loss ratio: 19944.318562, decoder SINDy loss  ratio: 0.661693
--- 0.2942545413970947 seconds for one epoch ---
--- 1.462533712387085 seconds for one epoch ---
--- 0.3066890239715576 seconds for one epoch ---
--- 1.4745428562164307 seconds for one epoch ---
--- 0.2988419532775879 seconds for one epoch ---
--- 1.4735934734344482 seconds for one epoch ---
--- 0.29685354232788086 seconds for one epoch ---
--- 1.4835896492004395 seconds for one epoch ---
--- 0.30582094192504883 seconds for one epoch ---
--- 1.4503231048583984 seconds for one epoch ---
--- 0.300384521484375 seconds for one epoch ---
--- 1.46337890625 seconds for one epoch ---
--- 0.2873203754425049 seconds for one epoch ---
--- 1.445666790008545 seconds for one epoch ---
--- 0.2976830005645752 seconds for one epoch ---
--- 1.470829963684082 seconds for one epoch ---
--- 0.3043050765991211 seconds for one epoch ---
--- 1.462517499923706 seconds for one epoch ---
--- 0.3144035339355469 seconds for one epoch ---
--- 1.4779791831970215 seconds for one epoch ---
--- 0.29273533821105957 seconds for one epoch ---
--- 1.4825770854949951 seconds for one epoch ---
--- 0.2903010845184326 seconds for one epoch ---
--- 1.4836547374725342 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.474449]
 [-0.      ]]
--- 0.28627848625183105 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1789.2705078125, (853.9221, 1.5478921, 933.5013, 0.29918322)
   validation loss 825.7705078125, (522.06775, 0.40940735, 302.99414, 0.29918322)
decoder loss ratio: 20225.810947, decoder SINDy loss  ratio: 0.654055
--- 0.25045084953308105 seconds for one epoch ---
--- 0.29738712310791016 seconds for one epoch ---
--- 1.4757544994354248 seconds for one epoch ---
--- 0.2894613742828369 seconds for one epoch ---
--- 1.478041410446167 seconds for one epoch ---
--- 0.28719449043273926 seconds for one epoch ---
--- 1.4902064800262451 seconds for one epoch ---
--- 0.28743505477905273 seconds for one epoch ---
--- 1.5133330821990967 seconds for one epoch ---
--- 0.3205862045288086 seconds for one epoch ---
--- 1.4690382480621338 seconds for one epoch ---
--- 0.29892873764038086 seconds for one epoch ---
--- 1.487497329711914 seconds for one epoch ---
--- 0.3054978847503662 seconds for one epoch ---
--- 1.498152732849121 seconds for one epoch ---
--- 0.29480695724487305 seconds for one epoch ---
--- 1.4510822296142578 seconds for one epoch ---
--- 0.2964510917663574 seconds for one epoch ---
--- 1.4861209392547607 seconds for one epoch ---
--- 0.28850483894348145 seconds for one epoch ---
--- 1.487830638885498 seconds for one epoch ---
--- 0.2859983444213867 seconds for one epoch ---
--- 1.506361484527588 seconds for one epoch ---
--- 0.3074190616607666 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.593657]
 [ 0.      ]]
--- 0.25856685638427734 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3883.91162109375, (1293.8605, 8.631871, 2581.1184, 0.3008646)
   validation loss 867.7252807617188, (586.3432, 0.3462942, 280.73492, 0.3008646)
decoder loss ratio: 22715.953531, decoder SINDy loss  ratio: 0.606006
--- 0.3084433078765869 seconds for one epoch ---
--- 1.4955370426177979 seconds for one epoch ---
--- 0.2984464168548584 seconds for one epoch ---
--- 1.5089824199676514 seconds for one epoch ---
--- 0.3155710697174072 seconds for one epoch ---
--- 1.5247340202331543 seconds for one epoch ---
--- 0.2938387393951416 seconds for one epoch ---
--- 1.501938819885254 seconds for one epoch ---
--- 0.299602746963501 seconds for one epoch ---
--- 1.4891798496246338 seconds for one epoch ---
--- 0.29733991622924805 seconds for one epoch ---
--- 1.4829459190368652 seconds for one epoch ---
--- 0.30535340309143066 seconds for one epoch ---
--- 1.487884759902954 seconds for one epoch ---
--- 0.30579566955566406 seconds for one epoch ---
--- 1.493387222290039 seconds for one epoch ---
--- 0.3103926181793213 seconds for one epoch ---
--- 1.5046265125274658 seconds for one epoch ---
--- 0.2913508415222168 seconds for one epoch ---
--- 1.4853570461273193 seconds for one epoch ---
--- 0.3028140068054199 seconds for one epoch ---
--- 1.5043644905090332 seconds for one epoch ---
--- 0.29751086235046387 seconds for one epoch ---
--- 1.5246059894561768 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.720052]
 [ 0.      ]]
--- 0.30103397369384766 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4309.14111328125, (1563.2239, 3.3885639, 2742.226, 0.3026487)
   validation loss 784.7328491210938, (492.04694, 0.36282963, 292.02045, 0.3026487)
decoder loss ratio: 19062.752533, decoder SINDy loss  ratio: 0.630367
--- 0.2660868167877197 seconds for one epoch ---
--- 0.2878262996673584 seconds for one epoch ---
--- 1.5086145401000977 seconds for one epoch ---
--- 0.2859199047088623 seconds for one epoch ---
--- 1.4929680824279785 seconds for one epoch ---
--- 0.2990124225616455 seconds for one epoch ---
--- 1.4970149993896484 seconds for one epoch ---
--- 0.2981998920440674 seconds for one epoch ---
--- 1.510408878326416 seconds for one epoch ---
--- 0.2947206497192383 seconds for one epoch ---
--- 1.5126347541809082 seconds for one epoch ---
--- 0.29848432540893555 seconds for one epoch ---
--- 1.5007622241973877 seconds for one epoch ---
--- 0.29912304878234863 seconds for one epoch ---
--- 1.5023131370544434 seconds for one epoch ---
--- 0.2770061492919922 seconds for one epoch ---
--- 1.5083403587341309 seconds for one epoch ---
--- 0.2904703617095947 seconds for one epoch ---
--- 1.4987854957580566 seconds for one epoch ---
--- 0.30374622344970703 seconds for one epoch ---
--- 1.5028321743011475 seconds for one epoch ---
--- 0.2899444103240967 seconds for one epoch ---
--- 1.4980666637420654 seconds for one epoch ---
--- 0.29659557342529297 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.838878]
 [-0.      ]]
--- 0.2618138790130615 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2338.44091796875, (1103.1749, 1.4209412, 1233.5406, 0.30433497)
   validation loss 1313.7645263671875, (1000.43787, 0.4438101, 312.57855, 0.30433497)
decoder loss ratio: 38758.699774, decoder SINDy loss  ratio: 0.674745
--- 0.3069734573364258 seconds for one epoch ---
--- 1.5123341083526611 seconds for one epoch ---
--- 0.2951490879058838 seconds for one epoch ---
--- 1.5315930843353271 seconds for one epoch ---
--- 0.299832820892334 seconds for one epoch ---
--- 1.5019946098327637 seconds for one epoch ---
--- 0.29939866065979004 seconds for one epoch ---
--- 1.5176782608032227 seconds for one epoch ---
--- 0.2969684600830078 seconds for one epoch ---
--- 1.5087029933929443 seconds for one epoch ---
--- 0.2991318702697754 seconds for one epoch ---
--- 1.4991800785064697 seconds for one epoch ---
--- 0.3009510040283203 seconds for one epoch ---
--- 1.5126638412475586 seconds for one epoch ---
--- 0.31188082695007324 seconds for one epoch ---
--- 1.5159199237823486 seconds for one epoch ---
--- 0.28896522521972656 seconds for one epoch ---
--- 1.5447640419006348 seconds for one epoch ---
--- 0.30242252349853516 seconds for one epoch ---
--- 1.523855447769165 seconds for one epoch ---
--- 0.27992844581604004 seconds for one epoch ---
--- 1.5067343711853027 seconds for one epoch ---
--- 0.29681897163391113 seconds for one epoch ---
--- 1.5333619117736816 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-9.962694]
 [-0.      ]]
--- 0.29323625564575195 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2675.0751953125, (1429.9226, 1.8490034, 1242.9973, 0.30608484)
   validation loss 935.4880981445312, (638.6204, 0.41994002, 296.1417, 0.30608484)
decoder loss ratio: 24741.263856, decoder SINDy loss  ratio: 0.639263
--- 0.2694704532623291 seconds for one epoch ---
--- 0.3050856590270996 seconds for one epoch ---
--- 1.5281729698181152 seconds for one epoch ---
--- 0.30528998374938965 seconds for one epoch ---
--- 1.544365406036377 seconds for one epoch ---
--- 0.2984447479248047 seconds for one epoch ---
--- 1.559037446975708 seconds for one epoch ---
--- 0.3128046989440918 seconds for one epoch ---
--- 1.5207264423370361 seconds for one epoch ---
--- 0.29641294479370117 seconds for one epoch ---
--- 1.5091781616210938 seconds for one epoch ---
--- 0.2969944477081299 seconds for one epoch ---
--- 1.5466666221618652 seconds for one epoch ---
--- 0.3447103500366211 seconds for one epoch ---
--- 1.5105571746826172 seconds for one epoch ---
--- 0.29634618759155273 seconds for one epoch ---
--- 1.5484585762023926 seconds for one epoch ---
--- 0.3019065856933594 seconds for one epoch ---
--- 1.5340356826782227 seconds for one epoch ---
--- 0.2964606285095215 seconds for one epoch ---
--- 1.5172512531280518 seconds for one epoch ---
--- 0.30225515365600586 seconds for one epoch ---
--- 1.5293736457824707 seconds for one epoch ---
--- 0.2953360080718994 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.085527]
 [  0.      ]]
--- 0.248915433883667 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2652.510986328125, (862.3307, 3.6363108, 1786.2362, 0.30790153)
   validation loss 849.7683715820312, (552.4896, 0.46236372, 296.50845, 0.30790153)
decoder loss ratio: 21404.407199, decoder SINDy loss  ratio: 0.640055
--- 0.3000297546386719 seconds for one epoch ---
--- 1.5645365715026855 seconds for one epoch ---
--- 0.30582642555236816 seconds for one epoch ---
--- 1.531308889389038 seconds for one epoch ---
--- 0.2926771640777588 seconds for one epoch ---
--- 1.539107084274292 seconds for one epoch ---
--- 0.297623872756958 seconds for one epoch ---
--- 1.560953140258789 seconds for one epoch ---
--- 0.30327296257019043 seconds for one epoch ---
--- 1.5309665203094482 seconds for one epoch ---
--- 0.28955960273742676 seconds for one epoch ---
--- 1.5283453464508057 seconds for one epoch ---
--- 0.2970621585845947 seconds for one epoch ---
--- 1.5507168769836426 seconds for one epoch ---
--- 0.3088109493255615 seconds for one epoch ---
--- 1.526019811630249 seconds for one epoch ---
--- 0.27680349349975586 seconds for one epoch ---
--- 1.5337965488433838 seconds for one epoch ---
--- 0.2988862991333008 seconds for one epoch ---
--- 1.5360963344573975 seconds for one epoch ---
--- 0.2903783321380615 seconds for one epoch ---
--- 1.5482416152954102 seconds for one epoch ---
--- 0.30249786376953125 seconds for one epoch ---
--- 1.5851516723632812 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.192008]
 [ -0.      ]]
--- 0.29767537117004395 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2389.762451171875, (1346.2964, 1.3693476, 1041.7871, 0.3094684)
   validation loss 794.6990356445312, (510.48697, 0.3906719, 283.51193, 0.3094684)
decoder loss ratio: 19777.151423, decoder SINDy loss  ratio: 0.612000
--- 0.2581324577331543 seconds for one epoch ---
--- 0.29512834548950195 seconds for one epoch ---
--- 1.5586988925933838 seconds for one epoch ---
--- 0.30042362213134766 seconds for one epoch ---
--- 1.5645549297332764 seconds for one epoch ---
--- 0.2897336483001709 seconds for one epoch ---
--- 1.5439903736114502 seconds for one epoch ---
--- 0.30051732063293457 seconds for one epoch ---
--- 1.5612778663635254 seconds for one epoch ---
--- 0.3135395050048828 seconds for one epoch ---
--- 1.5269718170166016 seconds for one epoch ---
--- 0.3006420135498047 seconds for one epoch ---
--- 1.5728182792663574 seconds for one epoch ---
--- 0.2915685176849365 seconds for one epoch ---
--- 1.5493733882904053 seconds for one epoch ---
--- 0.3106992244720459 seconds for one epoch ---
--- 1.5788617134094238 seconds for one epoch ---
--- 0.29898905754089355 seconds for one epoch ---
--- 1.5628437995910645 seconds for one epoch ---
--- 0.2978205680847168 seconds for one epoch ---
--- 1.5741724967956543 seconds for one epoch ---
--- 0.29839372634887695 seconds for one epoch ---
--- 1.571925401687622 seconds for one epoch ---
--- 0.27741241455078125 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.284009]
 [  0.      ]]
--- 0.25042271614074707 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2564.847900390625, (1676.6238, 1.092924, 886.82043, 0.3108464)
   validation loss 748.2218627929688, (445.0519, 0.4571505, 302.40195, 0.3108464)
decoder loss ratio: 17242.083653, decoder SINDy loss  ratio: 0.652777
--- 0.28543806076049805 seconds for one epoch ---
--- 1.565115213394165 seconds for one epoch ---
--- 0.29871296882629395 seconds for one epoch ---
--- 1.5574071407318115 seconds for one epoch ---
--- 0.31337857246398926 seconds for one epoch ---
--- 1.5589604377746582 seconds for one epoch ---
--- 0.2938554286956787 seconds for one epoch ---
--- 1.5658254623413086 seconds for one epoch ---
--- 0.3058459758758545 seconds for one epoch ---
--- 1.5565543174743652 seconds for one epoch ---
--- 0.2884676456451416 seconds for one epoch ---
--- 1.562471866607666 seconds for one epoch ---
--- 0.28544139862060547 seconds for one epoch ---
--- 1.5803337097167969 seconds for one epoch ---
--- 0.2890334129333496 seconds for one epoch ---
--- 1.5741689205169678 seconds for one epoch ---
--- 0.2978377342224121 seconds for one epoch ---
--- 1.5834405422210693 seconds for one epoch ---
--- 0.29851722717285156 seconds for one epoch ---
--- 1.565063714981079 seconds for one epoch ---
--- 0.28655529022216797 seconds for one epoch ---
--- 1.574211597442627 seconds for one epoch ---
--- 0.28719115257263184 seconds for one epoch ---
--- 1.580453634262085 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.379704]
 [  0.      ]]
--- 0.2919788360595703 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4169.5595703125, (1639.1179, 2.3938053, 2527.735, 0.31228012)
   validation loss 789.6556396484375, (493.10907, 0.44638613, 295.78793, 0.31228012)
decoder loss ratio: 19103.901440, decoder SINDy loss  ratio: 0.638500
--- 0.2519538402557373 seconds for one epoch ---
--- 0.2935638427734375 seconds for one epoch ---
--- 1.5891051292419434 seconds for one epoch ---
--- 0.29360437393188477 seconds for one epoch ---
--- 1.611070156097412 seconds for one epoch ---
--- 0.3052995204925537 seconds for one epoch ---
--- 1.5497393608093262 seconds for one epoch ---
--- 0.3017117977142334 seconds for one epoch ---
--- 1.5665268898010254 seconds for one epoch ---
--- 0.30522775650024414 seconds for one epoch ---
--- 1.5951569080352783 seconds for one epoch ---
--- 0.3029751777648926 seconds for one epoch ---
--- 1.5888252258300781 seconds for one epoch ---
--- 0.2960989475250244 seconds for one epoch ---
--- 1.600123405456543 seconds for one epoch ---
--- 0.29295802116394043 seconds for one epoch ---
--- 1.6085145473480225 seconds for one epoch ---
--- 0.28951501846313477 seconds for one epoch ---
--- 1.592559576034546 seconds for one epoch ---
--- 0.30008578300476074 seconds for one epoch ---
--- 1.5859532356262207 seconds for one epoch ---
--- 0.27487659454345703 seconds for one epoch ---
--- 1.6003782749176025 seconds for one epoch ---
--- 0.2943854331970215 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-10.48736]
 [ -0.     ]]
--- 0.22665834426879883 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2280.17822265625, (1108.6116, 4.4907017, 1166.7618, 0.31388077)
   validation loss 781.0109252929688, (493.61478, 0.4643147, 286.6179, 0.31388077)
decoder loss ratio: 19123.493399, decoder SINDy loss  ratio: 0.618705
--- 0.29886651039123535 seconds for one epoch ---
--- 1.5589814186096191 seconds for one epoch ---
--- 0.2896852493286133 seconds for one epoch ---
--- 1.5991649627685547 seconds for one epoch ---
--- 0.3057417869567871 seconds for one epoch ---
--- 1.5785658359527588 seconds for one epoch ---
--- 0.28220582008361816 seconds for one epoch ---
--- 1.5953216552734375 seconds for one epoch ---
--- 0.29845523834228516 seconds for one epoch ---
--- 1.5874547958374023 seconds for one epoch ---
--- 0.3152439594268799 seconds for one epoch ---
--- 1.6255323886871338 seconds for one epoch ---
--- 0.3209562301635742 seconds for one epoch ---
--- 1.5770173072814941 seconds for one epoch ---
--- 0.3240492343902588 seconds for one epoch ---
--- 1.5688025951385498 seconds for one epoch ---
--- 0.2905879020690918 seconds for one epoch ---
--- 1.5726604461669922 seconds for one epoch ---
--- 0.28568601608276367 seconds for one epoch ---
--- 1.5789532661437988 seconds for one epoch ---
--- 0.29796814918518066 seconds for one epoch ---
--- 1.5931329727172852 seconds for one epoch ---
--- 0.2856748104095459 seconds for one epoch ---
--- 1.5858516693115234 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.593054]
 [ -0.      ]]
--- 0.28595471382141113 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3440.4873046875, (1711.6249, 1.2798584, 1727.2671, 0.3155103)
   validation loss 779.3045043945312, (490.23172, 0.4423134, 288.315, 0.3155103)
decoder loss ratio: 18992.427911, decoder SINDy loss  ratio: 0.622368
--- 0.2609987258911133 seconds for one epoch ---
--- 0.29886817932128906 seconds for one epoch ---
--- 1.5692555904388428 seconds for one epoch ---
--- 0.29938459396362305 seconds for one epoch ---
--- 1.589339256286621 seconds for one epoch ---
--- 0.30019593238830566 seconds for one epoch ---
--- 1.6061382293701172 seconds for one epoch ---
--- 0.29428577423095703 seconds for one epoch ---
--- 1.5854105949401855 seconds for one epoch ---
--- 0.2882556915283203 seconds for one epoch ---
--- 1.6097209453582764 seconds for one epoch ---
--- 0.29995203018188477 seconds for one epoch ---
--- 1.6006064414978027 seconds for one epoch ---
--- 0.29760026931762695 seconds for one epoch ---
--- 1.5835919380187988 seconds for one epoch ---
--- 0.3034830093383789 seconds for one epoch ---
--- 1.6117839813232422 seconds for one epoch ---
--- 0.30019116401672363 seconds for one epoch ---
--- 1.6120572090148926 seconds for one epoch ---
--- 0.28698039054870605 seconds for one epoch ---
--- 1.618539571762085 seconds for one epoch ---
--- 0.3056154251098633 seconds for one epoch ---
--- 1.621161937713623 seconds for one epoch ---
--- 0.2839512825012207 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-10.6946]
 [  0.    ]]
--- 0.26611948013305664 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2320.728271484375, (1240.0396, 1.3123242, 1079.0592, 0.3170893)
   validation loss 782.1663208007812, (502.73407, 0.41454047, 278.70065, 0.3170893)
decoder loss ratio: 19476.790650, decoder SINDy loss  ratio: 0.601615
--- 0.3067624568939209 seconds for one epoch ---
--- 1.588411569595337 seconds for one epoch ---
--- 0.3008899688720703 seconds for one epoch ---
--- 1.6256921291351318 seconds for one epoch ---
--- 0.30799007415771484 seconds for one epoch ---
--- 1.6108081340789795 seconds for one epoch ---
--- 0.3140575885772705 seconds for one epoch ---
--- 1.630638837814331 seconds for one epoch ---
--- 0.2916834354400635 seconds for one epoch ---
--- 1.6412773132324219 seconds for one epoch ---
--- 0.29856419563293457 seconds for one epoch ---
--- 1.6414239406585693 seconds for one epoch ---
--- 0.2972984313964844 seconds for one epoch ---
--- 1.611046314239502 seconds for one epoch ---
--- 0.2987816333770752 seconds for one epoch ---
--- 1.6186144351959229 seconds for one epoch ---
--- 0.3139369487762451 seconds for one epoch ---
--- 1.5994858741760254 seconds for one epoch ---
--- 0.30022335052490234 seconds for one epoch ---
--- 1.613288402557373 seconds for one epoch ---
--- 0.29228639602661133 seconds for one epoch ---
--- 1.627063512802124 seconds for one epoch ---
--- 0.29573750495910645 seconds for one epoch ---
--- 1.6358144283294678 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-10.7846]
 [ -0.    ]]
--- 0.3023223876953125 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2981.567138671875, (1450.7498, 0.28153002, 1530.2175, 0.31842968)
   validation loss 896.529052734375, (621.0663, 0.41839638, 274.72595, 0.31842968)
decoder loss ratio: 24061.186068, decoder SINDy loss  ratio: 0.593035
--- 0.25863003730773926 seconds for one epoch ---
--- 0.291820764541626 seconds for one epoch ---
--- 1.6144728660583496 seconds for one epoch ---
--- 0.28089404106140137 seconds for one epoch ---
--- 1.619901180267334 seconds for one epoch ---
--- 0.3310854434967041 seconds for one epoch ---
--- 1.6321327686309814 seconds for one epoch ---
--- 0.2947123050689697 seconds for one epoch ---
--- 1.6457304954528809 seconds for one epoch ---
--- 0.2884857654571533 seconds for one epoch ---
--- 1.6587047576904297 seconds for one epoch ---
--- 0.31896138191223145 seconds for one epoch ---
--- 1.6333279609680176 seconds for one epoch ---
--- 0.3012685775756836 seconds for one epoch ---
--- 1.6432325839996338 seconds for one epoch ---
--- 0.3043961524963379 seconds for one epoch ---
--- 1.6236488819122314 seconds for one epoch ---
--- 0.3044154644012451 seconds for one epoch ---
--- 1.6487400531768799 seconds for one epoch ---
--- 0.2978549003601074 seconds for one epoch ---
--- 1.6247584819793701 seconds for one epoch ---
--- 0.29434633255004883 seconds for one epoch ---
--- 1.6786866188049316 seconds for one epoch ---
--- 0.2890486717224121 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.873723]
 [  0.      ]]
--- 0.2515075206756592 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2271.6396484375, (1054.4568, 0.60101324, 1216.2621, 0.31988272)
   validation loss 1909.8258056640625, (1579.1613, 0.40935704, 329.9354, 0.31988272)
decoder loss ratio: 61179.448559, decoder SINDy loss  ratio: 0.712212
--- 0.28901147842407227 seconds for one epoch ---
--- 1.6152992248535156 seconds for one epoch ---
--- 0.2920365333557129 seconds for one epoch ---
--- 1.6465444564819336 seconds for one epoch ---
--- 0.30861854553222656 seconds for one epoch ---
--- 1.6150486469268799 seconds for one epoch ---
--- 0.2964327335357666 seconds for one epoch ---
--- 1.6333589553833008 seconds for one epoch ---
--- 0.295513391494751 seconds for one epoch ---
--- 1.6447710990905762 seconds for one epoch ---
--- 0.2910764217376709 seconds for one epoch ---
--- 1.6403799057006836 seconds for one epoch ---
--- 0.29428696632385254 seconds for one epoch ---
--- 1.6500139236450195 seconds for one epoch ---
--- 0.29575538635253906 seconds for one epoch ---
--- 1.6800413131713867 seconds for one epoch ---
--- 0.3203120231628418 seconds for one epoch ---
--- 1.6329448223114014 seconds for one epoch ---
--- 0.598461389541626 seconds for one epoch ---
--- 1.6668696403503418 seconds for one epoch ---
--- 0.30030131340026855 seconds for one epoch ---
--- 1.657651662826538 seconds for one epoch ---
--- 0.29791855812072754 seconds for one epoch ---
--- 1.6554715633392334 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-10.9641]
 [  0.    ]]
--- 0.29272890090942383 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2273.044921875, (1300.8065, 8.166473, 963.7507, 0.32128188)
   validation loss 844.1295776367188, (568.09644, 0.46565995, 275.24622, 0.32128188)
decoder loss ratio: 22009.042172, decoder SINDy loss  ratio: 0.594158
--- 0.2584662437438965 seconds for one epoch ---
--- 0.27813267707824707 seconds for one epoch ---
--- 1.654515266418457 seconds for one epoch ---
--- 0.2987091541290283 seconds for one epoch ---
--- 1.6308584213256836 seconds for one epoch ---
--- 0.28319859504699707 seconds for one epoch ---
--- 1.6397156715393066 seconds for one epoch ---
--- 0.2943246364593506 seconds for one epoch ---
--- 1.6518142223358154 seconds for one epoch ---
--- 0.29613733291625977 seconds for one epoch ---
--- 1.654219388961792 seconds for one epoch ---
--- 0.2759418487548828 seconds for one epoch ---
--- 1.662961483001709 seconds for one epoch ---
--- 0.29659199714660645 seconds for one epoch ---
--- 1.6403942108154297 seconds for one epoch ---
--- 0.2846338748931885 seconds for one epoch ---
--- 1.6555607318878174 seconds for one epoch ---
--- 0.29382991790771484 seconds for one epoch ---
--- 1.6308674812316895 seconds for one epoch ---
--- 0.29621005058288574 seconds for one epoch ---
--- 1.631699800491333 seconds for one epoch ---
--- 0.2938966751098633 seconds for one epoch ---
--- 1.6567113399505615 seconds for one epoch ---
--- 0.2969520092010498 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-11.04678]
 [ -0.     ]]
--- 0.2787759304046631 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2532.5087890625, (1199.121, 1.7886872, 1331.2766, 0.3225817)
   validation loss 1030.9927978515625, (714.92255, 0.470243, 315.27734, 0.3225817)
decoder loss ratio: 27697.340607, decoder SINDy loss  ratio: 0.680570
--- 0.309246301651001 seconds for one epoch ---
--- 1.6705057621002197 seconds for one epoch ---
--- 0.2911398410797119 seconds for one epoch ---
--- 1.6523466110229492 seconds for one epoch ---
--- 0.300431489944458 seconds for one epoch ---
--- 1.660705327987671 seconds for one epoch ---
--- 0.2955291271209717 seconds for one epoch ---
--- 1.658306360244751 seconds for one epoch ---
--- 0.30112695693969727 seconds for one epoch ---
--- 1.6858510971069336 seconds for one epoch ---
--- 0.2973334789276123 seconds for one epoch ---
--- 1.6763992309570312 seconds for one epoch ---
--- 0.28981876373291016 seconds for one epoch ---
--- 1.666691541671753 seconds for one epoch ---
--- 0.30837011337280273 seconds for one epoch ---
--- 1.6644301414489746 seconds for one epoch ---
--- 0.30117273330688477 seconds for one epoch ---
--- 1.6523194313049316 seconds for one epoch ---
--- 0.2907421588897705 seconds for one epoch ---
--- 1.6583077907562256 seconds for one epoch ---
--- 0.32486844062805176 seconds for one epoch ---
--- 1.6807429790496826 seconds for one epoch ---
--- 0.30440187454223633 seconds for one epoch ---
--- 1.6863505840301514 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.131645]
 [ -0.      ]]
--- 0.3004791736602783 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3340.351318359375, (1352.5579, 3.6527672, 1983.8167, 0.3239654)
   validation loss 884.1812744140625, (586.3676, 0.4967617, 296.9929, 0.3239654)
decoder loss ratio: 22716.899374, decoder SINDy loss  ratio: 0.641101
THRESHOLDING: 1 active coefficients
--- 0.25469160079956055 seconds for one epoch ---
--- 0.2985377311706543 seconds for one epoch ---
--- 1.6807153224945068 seconds for one epoch ---
--- 0.2876930236816406 seconds for one epoch ---
--- 1.6539716720581055 seconds for one epoch ---
--- 0.27919769287109375 seconds for one epoch ---
--- 1.6903259754180908 seconds for one epoch ---
--- 0.3096001148223877 seconds for one epoch ---
--- 1.6843669414520264 seconds for one epoch ---
--- 0.2970106601715088 seconds for one epoch ---
--- 1.6961629390716553 seconds for one epoch ---
--- 0.2905697822570801 seconds for one epoch ---
--- 1.7251124382019043 seconds for one epoch ---
--- 0.2966620922088623 seconds for one epoch ---
--- 1.6509206295013428 seconds for one epoch ---
--- 0.2902185916900635 seconds for one epoch ---
--- 1.662445306777954 seconds for one epoch ---
--- 0.2804889678955078 seconds for one epoch ---
--- 1.68821382522583 seconds for one epoch ---
--- 0.2945396900177002 seconds for one epoch ---
--- 1.6757991313934326 seconds for one epoch ---
--- 0.29856157302856445 seconds for one epoch ---
--- 1.6566648483276367 seconds for one epoch ---
--- 0.29860901832580566 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.226779]
 [  0.      ]]
--- 0.25478434562683105 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1369.8468017578125, (697.8242, 1.5614873, 670.1392, 0.3218734)
   validation loss 898.1875, (603.2843, 0.4573431, 294.124, 0.3218734)
decoder loss ratio: 23372.281198, decoder SINDy loss  ratio: 0.634908
--- 0.31764769554138184 seconds for one epoch ---
--- 1.648237943649292 seconds for one epoch ---
--- 0.2871522903442383 seconds for one epoch ---
--- 1.6732995510101318 seconds for one epoch ---
--- 0.27487707138061523 seconds for one epoch ---
--- 1.6651105880737305 seconds for one epoch ---
--- 0.3154594898223877 seconds for one epoch ---
--- 1.6749122142791748 seconds for one epoch ---
--- 0.2945704460144043 seconds for one epoch ---
--- 1.7032196521759033 seconds for one epoch ---
--- 0.29694294929504395 seconds for one epoch ---
--- 1.6922798156738281 seconds for one epoch ---
--- 0.30150365829467773 seconds for one epoch ---
--- 1.7201199531555176 seconds for one epoch ---
--- 0.2940187454223633 seconds for one epoch ---
--- 1.702488660812378 seconds for one epoch ---
--- 0.3004605770111084 seconds for one epoch ---
--- 1.6888163089752197 seconds for one epoch ---
--- 0.28813767433166504 seconds for one epoch ---
--- 1.7163257598876953 seconds for one epoch ---
--- 0.3006563186645508 seconds for one epoch ---
--- 1.7167243957519531 seconds for one epoch ---
--- 0.3084716796875 seconds for one epoch ---
--- 1.6786820888519287 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-11.2954]
 [ -0.    ]]
--- 0.2753946781158447 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2310.757080078125, (1573.5326, 1.7195863, 735.18176, 0.32297063)
   validation loss 828.4014892578125, (537.9121, 0.4352713, 289.73114, 0.32297063)
decoder loss ratio: 20839.648974, decoder SINDy loss  ratio: 0.625425
--- 0.2749042510986328 seconds for one epoch ---
--- 0.30788278579711914 seconds for one epoch ---
--- 1.727771282196045 seconds for one epoch ---
--- 0.3017895221710205 seconds for one epoch ---
--- 1.6827912330627441 seconds for one epoch ---
--- 0.29329872131347656 seconds for one epoch ---
--- 1.7349271774291992 seconds for one epoch ---
--- 0.30114102363586426 seconds for one epoch ---
--- 1.7222459316253662 seconds for one epoch ---
--- 0.29529762268066406 seconds for one epoch ---
--- 1.7139403820037842 seconds for one epoch ---
--- 0.3147120475769043 seconds for one epoch ---
--- 1.688709020614624 seconds for one epoch ---
--- 0.3007376194000244 seconds for one epoch ---
--- 1.7120468616485596 seconds for one epoch ---
--- 0.3029909133911133 seconds for one epoch ---
--- 1.6967146396636963 seconds for one epoch ---
--- 0.30610156059265137 seconds for one epoch ---
--- 1.7024290561676025 seconds for one epoch ---
--- 0.30225586891174316 seconds for one epoch ---
--- 1.690453290939331 seconds for one epoch ---
--- 0.30379605293273926 seconds for one epoch ---
--- 1.7016515731811523 seconds for one epoch ---
--- 0.303985595703125 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.375108]
 [  0.      ]]
--- 0.255051851272583 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5699.7373046875, (2384.1228, 0.9043031, 3314.386, 0.3242757)
   validation loss 753.089111328125, (477.61316, 0.425576, 274.7261, 0.3242757)
decoder loss ratio: 18503.562960, decoder SINDy loss  ratio: 0.593035
--- 0.298417329788208 seconds for one epoch ---
--- 1.7112140655517578 seconds for one epoch ---
--- 0.301023006439209 seconds for one epoch ---
--- 1.6639645099639893 seconds for one epoch ---
--- 0.28992509841918945 seconds for one epoch ---
--- 1.6568303108215332 seconds for one epoch ---
--- 0.28954386711120605 seconds for one epoch ---
--- 1.6769821643829346 seconds for one epoch ---
--- 0.3011810779571533 seconds for one epoch ---
--- 1.6859004497528076 seconds for one epoch ---
--- 0.2768213748931885 seconds for one epoch ---
--- 1.6985163688659668 seconds for one epoch ---
--- 0.2942354679107666 seconds for one epoch ---
--- 1.7311525344848633 seconds for one epoch ---
--- 0.28975987434387207 seconds for one epoch ---
--- 1.6902472972869873 seconds for one epoch ---
--- 0.2931637763977051 seconds for one epoch ---
--- 1.7052302360534668 seconds for one epoch ---
--- 0.29380130767822266 seconds for one epoch ---
--- 1.7382736206054688 seconds for one epoch ---
--- 0.3081231117248535 seconds for one epoch ---
--- 1.7071642875671387 seconds for one epoch ---
--- 0.296588659286499 seconds for one epoch ---
--- 1.742516040802002 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.449188]
 [  0.      ]]
--- 0.29424190521240234 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4872.38818359375, (2100.132, 1.0961227, 2770.8345, 0.32552087)
   validation loss 974.1080932617188, (680.47345, 0.47622705, 292.83286, 0.32552087)
decoder loss ratio: 26362.722796, decoder SINDy loss  ratio: 0.632121
--- 0.26753687858581543 seconds for one epoch ---
--- 0.2934887409210205 seconds for one epoch ---
--- 1.6850318908691406 seconds for one epoch ---
--- 0.30559253692626953 seconds for one epoch ---
--- 1.7115650177001953 seconds for one epoch ---
--- 0.3087897300720215 seconds for one epoch ---
--- 1.7100725173950195 seconds for one epoch ---
--- 0.2855193614959717 seconds for one epoch ---
--- 1.7276954650878906 seconds for one epoch ---
--- 0.28244614601135254 seconds for one epoch ---
--- 1.7411723136901855 seconds for one epoch ---
--- 0.30210232734680176 seconds for one epoch ---
--- 1.7117061614990234 seconds for one epoch ---
--- 0.29903650283813477 seconds for one epoch ---
--- 1.706695556640625 seconds for one epoch ---
--- 0.30704188346862793 seconds for one epoch ---
--- 1.7606754302978516 seconds for one epoch ---
--- 0.2967526912689209 seconds for one epoch ---
--- 1.7372283935546875 seconds for one epoch ---
--- 0.3052051067352295 seconds for one epoch ---
--- 1.7476890087127686 seconds for one epoch ---
--- 0.29810309410095215 seconds for one epoch ---
--- 1.7368080615997314 seconds for one epoch ---
--- 0.2987697124481201 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-11.52614]
 [ -0.     ]]
--- 0.2638671398162842 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4467.00634765625, (1323.1791, 8.352502, 3135.148, 0.3268453)
   validation loss 1013.5028076171875, (668.5817, 0.47941443, 344.1148, 0.3268453)
decoder loss ratio: 25902.016777, decoder SINDy loss  ratio: 0.742820
--- 0.28855085372924805 seconds for one epoch ---
--- 1.746734619140625 seconds for one epoch ---
--- 0.306072473526001 seconds for one epoch ---
--- 1.7293882369995117 seconds for one epoch ---
--- 0.298964262008667 seconds for one epoch ---
--- 1.7319910526275635 seconds for one epoch ---
--- 0.30352306365966797 seconds for one epoch ---
--- 1.741950511932373 seconds for one epoch ---
--- 0.30399441719055176 seconds for one epoch ---
--- 1.7054572105407715 seconds for one epoch ---
--- 0.291060209274292 seconds for one epoch ---
--- 1.7186610698699951 seconds for one epoch ---
--- 0.3095228672027588 seconds for one epoch ---
--- 1.7229535579681396 seconds for one epoch ---
--- 0.29474854469299316 seconds for one epoch ---
--- 1.73781418800354 seconds for one epoch ---
--- 0.3042337894439697 seconds for one epoch ---
--- 1.7222225666046143 seconds for one epoch ---
--- 0.30001091957092285 seconds for one epoch ---
--- 1.7253055572509766 seconds for one epoch ---
--- 0.2997324466705322 seconds for one epoch ---
--- 1.770204782485962 seconds for one epoch ---
--- 0.30824851989746094 seconds for one epoch ---
--- 1.7572553157806396 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.618995]
 [ -0.      ]]
--- 0.2869281768798828 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3646.201416015625, (1165.6996, 2.370544, 2477.803, 0.32839498)
   validation loss 856.0011596679688, (572.4442, 0.44451204, 282.78406, 0.32839498)
decoder loss ratio: 22177.482652, decoder SINDy loss  ratio: 0.610429
--- 0.2570343017578125 seconds for one epoch ---
--- 0.27071142196655273 seconds for one epoch ---
--- 1.7384390830993652 seconds for one epoch ---
--- 0.2985670566558838 seconds for one epoch ---
--- 1.736579179763794 seconds for one epoch ---
--- 0.3173859119415283 seconds for one epoch ---
--- 1.7349441051483154 seconds for one epoch ---
--- 0.2898843288421631 seconds for one epoch ---
--- 1.7361834049224854 seconds for one epoch ---
--- 0.300656795501709 seconds for one epoch ---
--- 1.7687559127807617 seconds for one epoch ---
--- 0.3158082962036133 seconds for one epoch ---
--- 1.704953670501709 seconds for one epoch ---
--- 0.29687952995300293 seconds for one epoch ---
--- 1.7246448993682861 seconds for one epoch ---
--- 0.2955167293548584 seconds for one epoch ---
--- 1.7380108833312988 seconds for one epoch ---
--- 0.30009937286376953 seconds for one epoch ---
--- 1.7814733982086182 seconds for one epoch ---
--- 0.3013901710510254 seconds for one epoch ---
--- 1.7598838806152344 seconds for one epoch ---
--- 0.3023827075958252 seconds for one epoch ---
--- 1.722989559173584 seconds for one epoch ---
--- 0.2957131862640381 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.689748]
 [  0.      ]]
--- 0.24883055686950684 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2718.8056640625, (1154.4083, 6.055756, 1558.0118, 0.3295878)
   validation loss 1003.830078125, (690.3966, 0.46559486, 312.63828, 0.3295878)
decoder loss ratio: 26747.163115, decoder SINDy loss  ratio: 0.674874
--- 0.29705381393432617 seconds for one epoch ---
--- 1.7618000507354736 seconds for one epoch ---
--- 0.2964470386505127 seconds for one epoch ---
--- 1.742464542388916 seconds for one epoch ---
--- 0.29618334770202637 seconds for one epoch ---
--- 1.7774689197540283 seconds for one epoch ---
--- 0.29702210426330566 seconds for one epoch ---
--- 1.7687690258026123 seconds for one epoch ---
--- 0.2911210060119629 seconds for one epoch ---
--- 1.7407174110412598 seconds for one epoch ---
--- 0.2973334789276123 seconds for one epoch ---
--- 1.7440659999847412 seconds for one epoch ---
--- 0.2800028324127197 seconds for one epoch ---
--- 1.7278573513031006 seconds for one epoch ---
--- 0.29670214653015137 seconds for one epoch ---
--- 1.7628211975097656 seconds for one epoch ---
--- 0.30738091468811035 seconds for one epoch ---
--- 1.7116425037384033 seconds for one epoch ---
--- 0.29318785667419434 seconds for one epoch ---
--- 1.7392115592956543 seconds for one epoch ---
--- 0.2991597652435303 seconds for one epoch ---
--- 1.7704548835754395 seconds for one epoch ---
--- 0.3008902072906494 seconds for one epoch ---
--- 1.759087085723877 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-11.760099]
 [ -0.      ]]
--- 0.2942471504211426 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2086.641845703125, (1021.6011, 0.78505206, 1063.9248, 0.3307801)
   validation loss 1430.3248291015625, (1104.0464, 0.4287247, 325.51895, 0.3307801)
decoder loss ratio: 42772.673730, decoder SINDy loss  ratio: 0.702678
--- 0.28062963485717773 seconds for one epoch ---
--- 0.2997751235961914 seconds for one epoch ---
--- 1.7711279392242432 seconds for one epoch ---
--- 0.2791621685028076 seconds for one epoch ---
--- 1.747938632965088 seconds for one epoch ---
--- 0.30629801750183105 seconds for one epoch ---
--- 1.7308385372161865 seconds for one epoch ---
--- 0.30135345458984375 seconds for one epoch ---
--- 1.750941276550293 seconds for one epoch ---
--- 0.2900855541229248 seconds for one epoch ---
--- 1.791295051574707 seconds for one epoch ---
--- 0.29996705055236816 seconds for one epoch ---
--- 1.7438368797302246 seconds for one epoch ---
--- 0.2967653274536133 seconds for one epoch ---
--- 1.7623481750488281 seconds for one epoch ---
--- 0.3124692440032959 seconds for one epoch ---
--- 1.759167194366455 seconds for one epoch ---
--- 0.3016057014465332 seconds for one epoch ---
--- 1.728001594543457 seconds for one epoch ---
--- 0.30686092376708984 seconds for one epoch ---
--- 1.765089988708496 seconds for one epoch ---
--- 0.3211538791656494 seconds for one epoch ---
--- 1.775041103363037 seconds for one epoch ---
--- 0.2942836284637451 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.824955]
 [  0.      ]]
--- 0.25138401985168457 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4167.7724609375, (1978.4661, 5.196929, 2183.7776, 0.3318716)
   validation loss 803.5764770507812, (532.77795, 0.45111895, 270.01553, 0.3318716)
decoder loss ratio: 20640.742885, decoder SINDy loss  ratio: 0.582867
--- 0.2902224063873291 seconds for one epoch ---
--- 1.7801401615142822 seconds for one epoch ---
--- 0.2943096160888672 seconds for one epoch ---
--- 1.756392240524292 seconds for one epoch ---
--- 0.2977423667907715 seconds for one epoch ---
--- 1.7814137935638428 seconds for one epoch ---
--- 0.3031127452850342 seconds for one epoch ---
--- 1.796095371246338 seconds for one epoch ---
--- 0.28353309631347656 seconds for one epoch ---
--- 1.776604413986206 seconds for one epoch ---
--- 0.28581953048706055 seconds for one epoch ---
--- 1.7907414436340332 seconds for one epoch ---
--- 0.29520630836486816 seconds for one epoch ---
--- 1.8011388778686523 seconds for one epoch ---
--- 0.2924385070800781 seconds for one epoch ---
--- 1.7924549579620361 seconds for one epoch ---
--- 0.29993271827697754 seconds for one epoch ---
--- 1.815110206604004 seconds for one epoch ---
--- 0.28945159912109375 seconds for one epoch ---
--- 1.7931911945343018 seconds for one epoch ---
--- 0.3148324489593506 seconds for one epoch ---
--- 1.7619845867156982 seconds for one epoch ---
--- 0.28972554206848145 seconds for one epoch ---
--- 1.815349817276001 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.895106]
 [  0.      ]]
--- 0.2886841297149658 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3040.5263671875, (1317.5239, 9.822267, 1712.8472, 0.33309874)
   validation loss 837.7529907226562, (554.3549, 0.51691276, 282.54807, 0.33309874)
decoder loss ratio: 21476.671981, decoder SINDy loss  ratio: 0.609920
--- 0.26563549041748047 seconds for one epoch ---
--- 0.30011868476867676 seconds for one epoch ---
--- 1.8061323165893555 seconds for one epoch ---
--- 0.2966005802154541 seconds for one epoch ---
--- 1.7986760139465332 seconds for one epoch ---
--- 0.29657983779907227 seconds for one epoch ---
--- 1.8022887706756592 seconds for one epoch ---
--- 0.29818081855773926 seconds for one epoch ---
--- 1.7797422409057617 seconds for one epoch ---
--- 0.2915947437286377 seconds for one epoch ---
--- 1.7930495738983154 seconds for one epoch ---
--- 0.2934889793395996 seconds for one epoch ---
--- 1.7976155281066895 seconds for one epoch ---
--- 0.28301215171813965 seconds for one epoch ---
--- 1.8073673248291016 seconds for one epoch ---
--- 0.29933834075927734 seconds for one epoch ---
--- 1.7742488384246826 seconds for one epoch ---
--- 0.31739044189453125 seconds for one epoch ---
--- 1.8031129837036133 seconds for one epoch ---
--- 0.2852592468261719 seconds for one epoch ---
--- 1.8231685161590576 seconds for one epoch ---
--- 0.2971041202545166 seconds for one epoch ---
--- 1.812340259552002 seconds for one epoch ---
--- 0.2962338924407959 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.975909]
 [ -0.      ]]
--- 0.2547750473022461 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3259.03515625, (1365.5166, 1.7515475, 1891.4325, 0.334509)
   validation loss 855.8995971679688, (567.5191, 0.42846522, 287.61752, 0.334509)
decoder loss ratio: 21986.675346, decoder SINDy loss  ratio: 0.620863
--- 0.28611063957214355 seconds for one epoch ---
--- 1.847289800643921 seconds for one epoch ---
--- 0.29706788063049316 seconds for one epoch ---
--- 1.7986583709716797 seconds for one epoch ---
--- 0.29736948013305664 seconds for one epoch ---
--- 1.804182529449463 seconds for one epoch ---
--- 0.30104660987854004 seconds for one epoch ---
--- 1.8208940029144287 seconds for one epoch ---
--- 0.29622578620910645 seconds for one epoch ---
--- 1.828991413116455 seconds for one epoch ---
--- 0.3056650161743164 seconds for one epoch ---
--- 1.8040108680725098 seconds for one epoch ---
--- 0.2988617420196533 seconds for one epoch ---
--- 1.8227312564849854 seconds for one epoch ---
--- 0.3009605407714844 seconds for one epoch ---
--- 1.803417444229126 seconds for one epoch ---
--- 0.30121684074401855 seconds for one epoch ---
--- 1.812366247177124 seconds for one epoch ---
--- 0.30103182792663574 seconds for one epoch ---
--- 1.826671838760376 seconds for one epoch ---
--- 0.2999916076660156 seconds for one epoch ---
--- 1.8178071975708008 seconds for one epoch ---
--- 0.319110631942749 seconds for one epoch ---
--- 1.7686066627502441 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.033889]
 [ -0.      ]]
--- 0.27985692024230957 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2520.6787109375, (911.15894, 1.7829939, 1607.4012, 0.33554384)
   validation loss 809.4935302734375, (536.7638, 0.49525222, 271.89896, 0.33554384)
decoder loss ratio: 20795.161240, decoder SINDy loss  ratio: 0.586932
--- 0.25724291801452637 seconds for one epoch ---
--- 0.30504918098449707 seconds for one epoch ---
--- 1.7792026996612549 seconds for one epoch ---
--- 0.30145883560180664 seconds for one epoch ---
--- 1.8086457252502441 seconds for one epoch ---
--- 0.3320317268371582 seconds for one epoch ---
--- 1.8110921382904053 seconds for one epoch ---
--- 0.29022645950317383 seconds for one epoch ---
--- 1.8032164573669434 seconds for one epoch ---
--- 0.3040926456451416 seconds for one epoch ---
--- 1.794086217880249 seconds for one epoch ---
--- 0.29279541969299316 seconds for one epoch ---
--- 1.8340349197387695 seconds for one epoch ---
--- 0.30847644805908203 seconds for one epoch ---
--- 1.802417278289795 seconds for one epoch ---
--- 0.30290913581848145 seconds for one epoch ---
--- 1.783900260925293 seconds for one epoch ---
--- 0.2946779727935791 seconds for one epoch ---
--- 1.8344488143920898 seconds for one epoch ---
--- 0.29920101165771484 seconds for one epoch ---
--- 1.8299572467803955 seconds for one epoch ---
--- 0.30333900451660156 seconds for one epoch ---
--- 1.8489930629730225 seconds for one epoch ---
--- 0.29030513763427734 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.117211]
 [  0.      ]]
--- 0.2565956115722656 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2591.9453125, (1044.2347, 4.750491, 1542.623, 0.33697376)
   validation loss 905.1119384765625, (625.6627, 0.44297805, 278.66925, 0.33697376)
decoder loss ratio: 24239.259960, decoder SINDy loss  ratio: 0.601547
--- 0.3018791675567627 seconds for one epoch ---
--- 1.8164539337158203 seconds for one epoch ---
--- 0.30622196197509766 seconds for one epoch ---
--- 1.7583539485931396 seconds for one epoch ---
--- 0.2949249744415283 seconds for one epoch ---
--- 1.8032917976379395 seconds for one epoch ---
--- 0.28688740730285645 seconds for one epoch ---
--- 1.8270559310913086 seconds for one epoch ---
--- 0.32202935218811035 seconds for one epoch ---
--- 1.8385324478149414 seconds for one epoch ---
--- 0.29910755157470703 seconds for one epoch ---
--- 1.7911262512207031 seconds for one epoch ---
--- 0.3021109104156494 seconds for one epoch ---
--- 1.8119916915893555 seconds for one epoch ---
--- 0.30206942558288574 seconds for one epoch ---
--- 1.8124949932098389 seconds for one epoch ---
--- 0.3090972900390625 seconds for one epoch ---
--- 1.852489709854126 seconds for one epoch ---
--- 0.30601978302001953 seconds for one epoch ---
--- 1.8719372749328613 seconds for one epoch ---
--- 0.2831752300262451 seconds for one epoch ---
--- 1.8343117237091064 seconds for one epoch ---
--- 0.30876994132995605 seconds for one epoch ---
--- 1.8337349891662598 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.179735]
 [ -0.      ]]
--- 0.2930796146392822 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2901.372314453125, (1184.8483, 1.1857847, 1715.0002, 0.3380732)
   validation loss 769.5435180664062, (506.65152, 0.5087993, 262.04514, 0.3380732)
decoder loss ratio: 19628.559462, decoder SINDy loss  ratio: 0.565661
--- 0.26114869117736816 seconds for one epoch ---
--- 0.3161005973815918 seconds for one epoch ---
--- 1.8243701457977295 seconds for one epoch ---
--- 0.29482460021972656 seconds for one epoch ---
--- 1.824021816253662 seconds for one epoch ---
--- 0.28328728675842285 seconds for one epoch ---
--- 1.8484349250793457 seconds for one epoch ---
--- 0.2940406799316406 seconds for one epoch ---
--- 1.8163654804229736 seconds for one epoch ---
--- 0.29154443740844727 seconds for one epoch ---
--- 1.8020474910736084 seconds for one epoch ---
--- 0.3060474395751953 seconds for one epoch ---
--- 1.8220195770263672 seconds for one epoch ---
--- 0.28989529609680176 seconds for one epoch ---
--- 1.8230845928192139 seconds for one epoch ---
--- 0.3091886043548584 seconds for one epoch ---
--- 1.8459362983703613 seconds for one epoch ---
--- 0.2866702079772949 seconds for one epoch ---
--- 1.8571851253509521 seconds for one epoch ---
--- 0.29935669898986816 seconds for one epoch ---
--- 1.8516075611114502 seconds for one epoch ---
--- 0.29375219345092773 seconds for one epoch ---
--- 1.865077257156372 seconds for one epoch ---
--- 0.299868106842041 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.241012]
 [  0.      ]]
--- 0.2567863464355469 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3478.612548828125, (1401.2281, 5.9482055, 2071.097, 0.339187)
   validation loss 829.9216918945312, (577.0274, 0.4415708, 252.11354, 0.339187)
decoder loss ratio: 22355.043425, decoder SINDy loss  ratio: 0.544223
--- 0.3013463020324707 seconds for one epoch ---
--- 1.8444807529449463 seconds for one epoch ---
--- 0.30048298835754395 seconds for one epoch ---
--- 1.844970703125 seconds for one epoch ---
--- 0.2992520332336426 seconds for one epoch ---
--- 1.86911940574646 seconds for one epoch ---
--- 0.3028707504272461 seconds for one epoch ---
--- 1.860471248626709 seconds for one epoch ---
--- 0.30614209175109863 seconds for one epoch ---
--- 1.8655240535736084 seconds for one epoch ---
--- 0.28841733932495117 seconds for one epoch ---
--- 1.8680593967437744 seconds for one epoch ---
--- 0.2973504066467285 seconds for one epoch ---
--- 1.8825254440307617 seconds for one epoch ---
--- 0.29317140579223633 seconds for one epoch ---
--- 1.8747806549072266 seconds for one epoch ---
--- 0.2978661060333252 seconds for one epoch ---
--- 1.866028070449829 seconds for one epoch ---
--- 0.3050413131713867 seconds for one epoch ---
--- 1.873182773590088 seconds for one epoch ---
--- 0.29335832595825195 seconds for one epoch ---
--- 1.887573003768921 seconds for one epoch ---
--- 0.3058199882507324 seconds for one epoch ---
--- 1.8065998554229736 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.305126]
 [  0.      ]]
--- 0.29601335525512695 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8676.3818359375, (2404.2595, 2.6825175, 6269.0996, 0.340283)
   validation loss 673.8529052734375, (421.14545, 0.46861455, 251.89854, 0.340283)
decoder loss ratio: 16315.905749, decoder SINDy loss  ratio: 0.543758
--- 0.26262784004211426 seconds for one epoch ---
--- 0.2848057746887207 seconds for one epoch ---
--- 1.8469243049621582 seconds for one epoch ---
--- 0.30411791801452637 seconds for one epoch ---
--- 1.8717856407165527 seconds for one epoch ---
--- 0.2951240539550781 seconds for one epoch ---
--- 1.8300542831420898 seconds for one epoch ---
--- 0.28335070610046387 seconds for one epoch ---
--- 1.8253834247589111 seconds for one epoch ---
--- 0.29015493392944336 seconds for one epoch ---
--- 1.8651375770568848 seconds for one epoch ---
--- 0.305267333984375 seconds for one epoch ---
--- 1.85959792137146 seconds for one epoch ---
--- 0.31867265701293945 seconds for one epoch ---
--- 1.8639323711395264 seconds for one epoch ---
--- 0.3054842948913574 seconds for one epoch ---
--- 1.8838765621185303 seconds for one epoch ---
--- 0.2999701499938965 seconds for one epoch ---
--- 1.8893249034881592 seconds for one epoch ---
--- 0.28778076171875 seconds for one epoch ---
--- 1.857088565826416 seconds for one epoch ---
--- 0.29413366317749023 seconds for one epoch ---
--- 1.8593459129333496 seconds for one epoch ---
--- 0.2883143424987793 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.371895]
 [ -0.      ]]
--- 0.2526693344116211 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1890.4942626953125, (930.3462, 0.7786291, 959.0279, 0.34151125)
   validation loss 898.3861694335938, (629.9581, 0.47968662, 267.60684, 0.34151125)
decoder loss ratio: 24405.671607, decoder SINDy loss  ratio: 0.577667
--- 0.29658937454223633 seconds for one epoch ---
--- 1.8706440925598145 seconds for one epoch ---
--- 0.2856862545013428 seconds for one epoch ---
--- 1.8772025108337402 seconds for one epoch ---
--- 0.2941765785217285 seconds for one epoch ---
--- 1.8656270503997803 seconds for one epoch ---
--- 0.2911818027496338 seconds for one epoch ---
--- 1.8921597003936768 seconds for one epoch ---
--- 0.2917914390563965 seconds for one epoch ---
--- 1.9138450622558594 seconds for one epoch ---
--- 0.30499887466430664 seconds for one epoch ---
--- 1.8655989170074463 seconds for one epoch ---
--- 0.2921590805053711 seconds for one epoch ---
--- 1.8740692138671875 seconds for one epoch ---
--- 0.297482967376709 seconds for one epoch ---
--- 1.9068701267242432 seconds for one epoch ---
--- 0.2777061462402344 seconds for one epoch ---
--- 1.8769233226776123 seconds for one epoch ---
--- 0.3181948661804199 seconds for one epoch ---
--- 1.871924638748169 seconds for one epoch ---
--- 0.29723596572875977 seconds for one epoch ---
--- 1.8474838733673096 seconds for one epoch ---
--- 0.29239487648010254 seconds for one epoch ---
--- 1.8644344806671143 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.430982]
 [ -0.      ]]
--- 0.31049609184265137 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1372.463623046875, (806.2211, 1.2577751, 564.64215, 0.342566)
   validation loss 1006.9886474609375, (705.0991, 0.4431971, 301.10376, 0.342566)
decoder loss ratio: 27316.764057, decoder SINDy loss  ratio: 0.649975
--- 0.25389766693115234 seconds for one epoch ---
--- 0.2979879379272461 seconds for one epoch ---
--- 1.8729188442230225 seconds for one epoch ---
--- 0.30032825469970703 seconds for one epoch ---
--- 1.8885307312011719 seconds for one epoch ---
--- 0.29599761962890625 seconds for one epoch ---
--- 1.9001691341400146 seconds for one epoch ---
--- 0.2797276973724365 seconds for one epoch ---
--- 1.881218671798706 seconds for one epoch ---
--- 0.30559587478637695 seconds for one epoch ---
--- 1.9039416313171387 seconds for one epoch ---
--- 0.302584171295166 seconds for one epoch ---
--- 1.9034719467163086 seconds for one epoch ---
--- 0.2753622531890869 seconds for one epoch ---
--- 1.8864307403564453 seconds for one epoch ---
--- 0.3004133701324463 seconds for one epoch ---
--- 1.902085304260254 seconds for one epoch ---
--- 0.2915530204772949 seconds for one epoch ---
--- 1.8730347156524658 seconds for one epoch ---
--- 0.30281877517700195 seconds for one epoch ---
--- 1.9153399467468262 seconds for one epoch ---
--- 0.2946796417236328 seconds for one epoch ---
--- 1.8695151805877686 seconds for one epoch ---
--- 0.2917182445526123 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.495082]
 [  0.      ]]
--- 0.250194787979126 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4672.15673828125, (1096.4219, 6.298904, 3569.0923, 0.34375292)
   validation loss 712.5973510742188, (460.83124, 0.45887938, 250.96347, 0.34375292)
decoder loss ratio: 17853.402190, decoder SINDy loss  ratio: 0.541740
--- 0.2912940979003906 seconds for one epoch ---
--- 1.901628017425537 seconds for one epoch ---
--- 0.3276021480560303 seconds for one epoch ---
--- 1.8462083339691162 seconds for one epoch ---
--- 0.30077481269836426 seconds for one epoch ---
--- 1.8672001361846924 seconds for one epoch ---
--- 0.30073022842407227 seconds for one epoch ---
--- 1.8779644966125488 seconds for one epoch ---
--- 0.29764366149902344 seconds for one epoch ---
--- 1.8702726364135742 seconds for one epoch ---
--- 0.2949850559234619 seconds for one epoch ---
--- 1.8812851905822754 seconds for one epoch ---
--- 0.2807350158691406 seconds for one epoch ---
--- 1.873666763305664 seconds for one epoch ---
--- 0.314284086227417 seconds for one epoch ---
--- 1.8720085620880127 seconds for one epoch ---
--- 0.2890048027038574 seconds for one epoch ---
--- 1.8953118324279785 seconds for one epoch ---
--- 0.3000950813293457 seconds for one epoch ---
--- 1.9004323482513428 seconds for one epoch ---
--- 0.2980208396911621 seconds for one epoch ---
--- 1.8903443813323975 seconds for one epoch ---
--- 0.3016211986541748 seconds for one epoch ---
--- 1.920771837234497 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-12.5559]
 [ -0.    ]]
--- 0.3082859516143799 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3166.665283203125, (1298.3882, 0.8389801, 1867.0933, 0.34485754)
   validation loss 806.40283203125, (537.0837, 0.5273297, 268.44693, 0.34485754)
decoder loss ratio: 20807.554150, decoder SINDy loss  ratio: 0.579480
THRESHOLDING: 1 active coefficients
--- 1.8966214656829834 seconds for one epoch ---
--- 0.296222448348999 seconds for one epoch ---
--- 1.8968279361724854 seconds for one epoch ---
--- 0.2965095043182373 seconds for one epoch ---
--- 1.9216094017028809 seconds for one epoch ---
--- 0.28253674507141113 seconds for one epoch ---
--- 1.9219138622283936 seconds for one epoch ---
--- 0.2874307632446289 seconds for one epoch ---
--- 1.860278844833374 seconds for one epoch ---
--- 0.29877781867980957 seconds for one epoch ---
--- 1.912909984588623 seconds for one epoch ---
--- 0.3201477527618408 seconds for one epoch ---
--- 1.8781909942626953 seconds for one epoch ---
--- 0.30938076972961426 seconds for one epoch ---
--- 1.883443832397461 seconds for one epoch ---
--- 0.30147266387939453 seconds for one epoch ---
--- 1.8879411220550537 seconds for one epoch ---
--- 0.2837045192718506 seconds for one epoch ---
--- 1.9052577018737793 seconds for one epoch ---
--- 0.32633090019226074 seconds for one epoch ---
--- 1.9301905632019043 seconds for one epoch ---
--- 0.3004331588745117 seconds for one epoch ---
--- 1.9239296913146973 seconds for one epoch ---
--- 0.2963078022003174 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.616959]
 [  0.      ]]
--- 0.26988959312438965 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3593.419677734375, (1340.5881, 0.5082694, 2251.9773, 0.345968)
   validation loss 739.7977294921875, (466.27115, 0.5644742, 272.61612, 0.345968)
decoder loss ratio: 18064.153782, decoder SINDy loss  ratio: 0.588480
--- 0.3035416603088379 seconds for one epoch ---
--- 1.9416887760162354 seconds for one epoch ---
--- 0.29349565505981445 seconds for one epoch ---
--- 1.9524261951446533 seconds for one epoch ---
--- 0.29898834228515625 seconds for one epoch ---
--- 1.9540345668792725 seconds for one epoch ---
--- 0.3260955810546875 seconds for one epoch ---
--- 1.9293317794799805 seconds for one epoch ---
--- 0.29752254486083984 seconds for one epoch ---
--- 1.9400975704193115 seconds for one epoch ---
--- 0.3033742904663086 seconds for one epoch ---
--- 1.9807684421539307 seconds for one epoch ---
--- 0.3254575729370117 seconds for one epoch ---
--- 1.9683010578155518 seconds for one epoch ---
--- 0.2997148036956787 seconds for one epoch ---
--- 1.9429547786712646 seconds for one epoch ---
--- 0.3101949691772461 seconds for one epoch ---
--- 1.9762980937957764 seconds for one epoch ---
--- 0.2986793518066406 seconds for one epoch ---
--- 1.9517018795013428 seconds for one epoch ---
--- 0.3170015811920166 seconds for one epoch ---
--- 1.957322120666504 seconds for one epoch ---
--- 0.29804253578186035 seconds for one epoch ---
--- 1.9334163665771484 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.676186]
 [  0.      ]]
--- 0.30290746688842773 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3033.210693359375, (1293.9789, 2.5180287, 1736.3668, 0.3470121)
   validation loss 821.5614624023438, (543.69336, 0.5495878, 276.97153, 0.3470121)
decoder loss ratio: 21063.624635, decoder SINDy loss  ratio: 0.597882
--- 0.26537394523620605 seconds for one epoch ---
--- 0.2886943817138672 seconds for one epoch ---
--- 1.96036696434021 seconds for one epoch ---
--- 0.302915096282959 seconds for one epoch ---
--- 1.9464542865753174 seconds for one epoch ---
--- 0.3023831844329834 seconds for one epoch ---
--- 1.9695913791656494 seconds for one epoch ---
--- 0.29929089546203613 seconds for one epoch ---
--- 1.9615254402160645 seconds for one epoch ---
--- 0.3018827438354492 seconds for one epoch ---
--- 1.9697787761688232 seconds for one epoch ---
--- 0.2968881130218506 seconds for one epoch ---
--- 1.9782452583312988 seconds for one epoch ---
--- 0.30077624320983887 seconds for one epoch ---
--- 1.9377140998840332 seconds for one epoch ---
--- 0.3007667064666748 seconds for one epoch ---
--- 1.957772970199585 seconds for one epoch ---
--- 0.2851424217224121 seconds for one epoch ---
--- 1.9945435523986816 seconds for one epoch ---
--- 0.296644926071167 seconds for one epoch ---
--- 1.9791040420532227 seconds for one epoch ---
--- 0.3208482265472412 seconds for one epoch ---
--- 1.9766082763671875 seconds for one epoch ---
--- 0.3040585517883301 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-12.73239]
 [ -0.     ]]
--- 0.2522304058074951 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4484.6572265625, (2072.2693, 4.139407, 2407.9004, 0.34807202)
   validation loss 1305.7713623046875, (1008.48114, 0.5571368, 296.38507, 0.34807202)
decoder loss ratio: 39070.310169, decoder SINDy loss  ratio: 0.639789
--- 0.2946305274963379 seconds for one epoch ---
--- 1.9402520656585693 seconds for one epoch ---
--- 0.31583118438720703 seconds for one epoch ---
--- 1.980574607849121 seconds for one epoch ---
--- 0.30315065383911133 seconds for one epoch ---
--- 1.9703500270843506 seconds for one epoch ---
--- 0.2971174716949463 seconds for one epoch ---
--- 1.9913806915283203 seconds for one epoch ---
--- 0.2967090606689453 seconds for one epoch ---
--- 1.9796662330627441 seconds for one epoch ---
--- 0.31430625915527344 seconds for one epoch ---
--- 1.9787170886993408 seconds for one epoch ---
--- 0.2980537414550781 seconds for one epoch ---
--- 1.9752311706542969 seconds for one epoch ---
--- 0.29541802406311035 seconds for one epoch ---
--- 1.950683355331421 seconds for one epoch ---
--- 0.2969961166381836 seconds for one epoch ---
--- 1.9835219383239746 seconds for one epoch ---
--- 0.30365610122680664 seconds for one epoch ---
--- 1.9639205932617188 seconds for one epoch ---
--- 0.2995891571044922 seconds for one epoch ---
--- 1.9536426067352295 seconds for one epoch ---
--- 0.2849118709564209 seconds for one epoch ---
--- 1.9609346389770508 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.789671]
 [ -0.      ]]
--- 0.28865838050842285 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3567.772216796875, (1361.0565, 3.6073172, 2202.7593, 0.34913167)
   validation loss 806.2425537109375, (534.5643, 0.5427116, 270.78644, 0.34913167)
decoder loss ratio: 20709.947865, decoder SINDy loss  ratio: 0.584531
--- 0.26452207565307617 seconds for one epoch ---
--- 0.29489731788635254 seconds for one epoch ---
--- 1.9904780387878418 seconds for one epoch ---
--- 0.2891836166381836 seconds for one epoch ---
--- 1.967550277709961 seconds for one epoch ---
--- 0.3028404712677002 seconds for one epoch ---
--- 1.99068284034729 seconds for one epoch ---
--- 0.28801655769348145 seconds for one epoch ---
--- 1.9573278427124023 seconds for one epoch ---
--- 0.2927849292755127 seconds for one epoch ---
--- 2.01123309135437 seconds for one epoch ---
--- 0.30634212493896484 seconds for one epoch ---
--- 1.9889371395111084 seconds for one epoch ---
--- 0.28615617752075195 seconds for one epoch ---
--- 2.003699779510498 seconds for one epoch ---
--- 0.30032777786254883 seconds for one epoch ---
--- 2.001964807510376 seconds for one epoch ---
--- 0.3180088996887207 seconds for one epoch ---
--- 1.958439826965332 seconds for one epoch ---
--- 0.29625725746154785 seconds for one epoch ---
--- 1.9905788898468018 seconds for one epoch ---
--- 0.3075220584869385 seconds for one epoch ---
--- 1.9969782829284668 seconds for one epoch ---
--- 0.2935523986816406 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.844632]
 [  0.      ]]
--- 0.26079797744750977 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3364.2392578125, (733.08887, 1.5312985, 2629.269, 0.35021645)
   validation loss 925.608154296875, (630.64075, 0.54104644, 294.0761, 0.35021645)
decoder loss ratio: 24432.117382, decoder SINDy loss  ratio: 0.634805
--- 0.2993288040161133 seconds for one epoch ---
--- 1.9950778484344482 seconds for one epoch ---
--- 0.2895967960357666 seconds for one epoch ---
--- 1.9971036911010742 seconds for one epoch ---
--- 0.2970423698425293 seconds for one epoch ---
--- 2.0030300617218018 seconds for one epoch ---
--- 0.320087194442749 seconds for one epoch ---
--- 1.9997384548187256 seconds for one epoch ---
--- 0.2964024543762207 seconds for one epoch ---
--- 2.000624895095825 seconds for one epoch ---
--- 0.3069643974304199 seconds for one epoch ---
--- 1.949634313583374 seconds for one epoch ---
--- 0.2955176830291748 seconds for one epoch ---
--- 1.971269130706787 seconds for one epoch ---
--- 0.3067951202392578 seconds for one epoch ---
--- 1.9706377983093262 seconds for one epoch ---
--- 0.29078030586242676 seconds for one epoch ---
--- 2.0001235008239746 seconds for one epoch ---
--- 0.29801249504089355 seconds for one epoch ---
--- 2.005918264389038 seconds for one epoch ---
--- 0.2901289463043213 seconds for one epoch ---
--- 2.0009665489196777 seconds for one epoch ---
--- 0.29715657234191895 seconds for one epoch ---
--- 1.9873077869415283 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-12.89277]
 [ -0.     ]]
--- 0.29381394386291504 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2621.875, (1105.458, 1.9298332, 1514.1361, 0.35110822)
   validation loss 770.1047973632812, (500.98306, 0.59733284, 268.17325, 0.35110822)
decoder loss ratio: 19408.953596, decoder SINDy loss  ratio: 0.578890
--- 0.25026488304138184 seconds for one epoch ---
--- 0.2985682487487793 seconds for one epoch ---
--- 1.9678428173065186 seconds for one epoch ---
--- 0.2919607162475586 seconds for one epoch ---
--- 1.9728467464447021 seconds for one epoch ---
--- 0.3085508346557617 seconds for one epoch ---
--- 1.975351333618164 seconds for one epoch ---
--- 0.26979684829711914 seconds for one epoch ---
--- 1.962104320526123 seconds for one epoch ---
--- 0.28812623023986816 seconds for one epoch ---
--- 1.9885497093200684 seconds for one epoch ---
--- 0.30483293533325195 seconds for one epoch ---
--- 2.0006260871887207 seconds for one epoch ---
--- 0.3175971508026123 seconds for one epoch ---
--- 2.00927996635437 seconds for one epoch ---
--- 0.2962162494659424 seconds for one epoch ---
--- 1.994509220123291 seconds for one epoch ---
--- 0.3002147674560547 seconds for one epoch ---
--- 2.023081064224243 seconds for one epoch ---
--- 0.2848200798034668 seconds for one epoch ---
--- 2.0360093116760254 seconds for one epoch ---
--- 0.29181647300720215 seconds for one epoch ---
--- 1.964968204498291 seconds for one epoch ---
--- 0.29194116592407227 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.944564]
 [  0.      ]]
--- 0.25839853286743164 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3987.3623046875, (2022.5303, 3.2961156, 1961.1838, 0.35206613)
   validation loss 819.0511474609375, (535.5344, 0.62616366, 282.5385, 0.35206613)
decoder loss ratio: 20747.533308, decoder SINDy loss  ratio: 0.609899
--- 0.28675150871276855 seconds for one epoch ---
--- 1.9805536270141602 seconds for one epoch ---
--- 0.2835977077484131 seconds for one epoch ---
--- 1.9943020343780518 seconds for one epoch ---
--- 0.2897615432739258 seconds for one epoch ---
--- 1.991546392440796 seconds for one epoch ---
--- 0.28925395011901855 seconds for one epoch ---
--- 1.991393804550171 seconds for one epoch ---
--- 0.29470252990722656 seconds for one epoch ---
--- 1.9972472190856934 seconds for one epoch ---
--- 0.2945239543914795 seconds for one epoch ---
--- 1.9710562229156494 seconds for one epoch ---
--- 0.29150986671447754 seconds for one epoch ---
--- 2.013065814971924 seconds for one epoch ---
--- 0.2985837459564209 seconds for one epoch ---
--- 2.035858392715454 seconds for one epoch ---
--- 0.29050683975219727 seconds for one epoch ---
--- 2.03153395652771 seconds for one epoch ---
--- 0.3081834316253662 seconds for one epoch ---
--- 2.0420098304748535 seconds for one epoch ---
--- 0.2931182384490967 seconds for one epoch ---
--- 2.0430872440338135 seconds for one epoch ---
--- 0.28833580017089844 seconds for one epoch ---
--- 2.019275188446045 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.986471]
 [  0.      ]]
--- 0.2972445487976074 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5012.07275390625, (1240.4012, 2.0106921, 3769.3076, 0.35287872)
   validation loss 1237.8463134765625, (952.21924, 0.5789989, 284.69516, 0.35287872)
decoder loss ratio: 36890.626416, decoder SINDy loss  ratio: 0.614555
--- 0.2644650936126709 seconds for one epoch ---
--- 0.3105440139770508 seconds for one epoch ---
--- 1.991734266281128 seconds for one epoch ---
--- 0.2891554832458496 seconds for one epoch ---
--- 1.9929189682006836 seconds for one epoch ---
--- 0.29176926612854004 seconds for one epoch ---
--- 2.011282444000244 seconds for one epoch ---
--- 0.29200315475463867 seconds for one epoch ---
--- 2.039120674133301 seconds for one epoch ---
--- 0.30216526985168457 seconds for one epoch ---
--- 1.9904248714447021 seconds for one epoch ---
--- 0.29256248474121094 seconds for one epoch ---
--- 1.9914839267730713 seconds for one epoch ---
--- 0.29023098945617676 seconds for one epoch ---
--- 2.009011745452881 seconds for one epoch ---
--- 0.2882533073425293 seconds for one epoch ---
--- 1.9865531921386719 seconds for one epoch ---
--- 0.2931039333343506 seconds for one epoch ---
--- 2.0002384185791016 seconds for one epoch ---
--- 0.2984306812286377 seconds for one epoch ---
--- 2.035320520401001 seconds for one epoch ---
--- 0.29392361640930176 seconds for one epoch ---
--- 2.0533559322357178 seconds for one epoch ---
--- 0.29924917221069336 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.035865]
 [ -0.      ]]
--- 0.25432443618774414 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3411.123779296875, (1433.6738, 1.8528879, 1975.2433, 0.35376292)
   validation loss 872.6959838867188, (592.89355, 0.6311384, 278.8175, 0.35376292)
decoder loss ratio: 22969.725617, decoder SINDy loss  ratio: 0.601867
--- 0.29763150215148926 seconds for one epoch ---
--- 2.048610210418701 seconds for one epoch ---
--- 0.3008289337158203 seconds for one epoch ---
--- 2.0527822971343994 seconds for one epoch ---
--- 0.30569887161254883 seconds for one epoch ---
--- 2.0581791400909424 seconds for one epoch ---
--- 0.31110525131225586 seconds for one epoch ---
--- 2.0188565254211426 seconds for one epoch ---
--- 0.2963409423828125 seconds for one epoch ---
--- 2.0072288513183594 seconds for one epoch ---
--- 0.2961442470550537 seconds for one epoch ---
--- 2.0271317958831787 seconds for one epoch ---
--- 0.2932093143463135 seconds for one epoch ---
--- 2.0408544540405273 seconds for one epoch ---
--- 0.29715991020202637 seconds for one epoch ---
--- 2.0685911178588867 seconds for one epoch ---
--- 0.2789435386657715 seconds for one epoch ---
--- 2.0152857303619385 seconds for one epoch ---
--- 0.2983224391937256 seconds for one epoch ---
--- 2.038562059402466 seconds for one epoch ---
--- 0.29938507080078125 seconds for one epoch ---
--- 2.0341126918792725 seconds for one epoch ---
--- 0.2882375717163086 seconds for one epoch ---
--- 2.0310704708099365 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.085452]
 [ -0.      ]]
--- 0.2987949848175049 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2072.724853515625, (979.7295, 1.4532847, 1091.1874, 0.35471997)
   validation loss 998.7914428710938, (705.2733, 0.70421624, 292.45917, 0.35471997)
decoder loss ratio: 27323.512648, decoder SINDy loss  ratio: 0.631314
--- 0.2635829448699951 seconds for one epoch ---
--- 0.30751633644104004 seconds for one epoch ---
--- 2.0589587688446045 seconds for one epoch ---
--- 0.28675246238708496 seconds for one epoch ---
--- 2.046658754348755 seconds for one epoch ---
--- 0.30046939849853516 seconds for one epoch ---
--- 2.0385730266571045 seconds for one epoch ---
--- 0.2962069511413574 seconds for one epoch ---
--- 2.0650880336761475 seconds for one epoch ---
--- 0.3188047409057617 seconds for one epoch ---
--- 2.0602593421936035 seconds for one epoch ---
--- 0.2929646968841553 seconds for one epoch ---
--- 2.0631542205810547 seconds for one epoch ---
--- 0.29074716567993164 seconds for one epoch ---
--- 2.046644687652588 seconds for one epoch ---
--- 0.295360803604126 seconds for one epoch ---
--- 2.084581136703491 seconds for one epoch ---
--- 0.2833232879638672 seconds for one epoch ---
--- 2.086146354675293 seconds for one epoch ---
--- 0.2913515567779541 seconds for one epoch ---
--- 2.0934996604919434 seconds for one epoch ---
--- 0.29244017601013184 seconds for one epoch ---
--- 2.0194778442382812 seconds for one epoch ---
--- 0.29459381103515625 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.139792]
 [  0.      ]]
--- 0.24983000755310059 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2335.375732421875, (1225.857, 2.7602835, 1106.4026, 0.35572726)
   validation loss 788.0449829101562, (524.8983, 0.63511133, 262.15582, 0.35572726)
decoder loss ratio: 20335.472003, decoder SINDy loss  ratio: 0.565900
--- 0.2983088493347168 seconds for one epoch ---
--- 2.0753896236419678 seconds for one epoch ---
--- 0.2876768112182617 seconds for one epoch ---
--- 2.039123773574829 seconds for one epoch ---
--- 0.30548858642578125 seconds for one epoch ---
--- 2.088533878326416 seconds for one epoch ---
--- 0.3026576042175293 seconds for one epoch ---
--- 2.0984480381011963 seconds for one epoch ---
--- 0.2975006103515625 seconds for one epoch ---
--- 2.0875937938690186 seconds for one epoch ---
--- 0.29009246826171875 seconds for one epoch ---
--- 2.0883800983428955 seconds for one epoch ---
--- 0.30292248725891113 seconds for one epoch ---
--- 2.084233283996582 seconds for one epoch ---
--- 0.30133962631225586 seconds for one epoch ---
--- 2.0711302757263184 seconds for one epoch ---
--- 0.29511356353759766 seconds for one epoch ---
--- 2.090871572494507 seconds for one epoch ---
--- 0.2990238666534424 seconds for one epoch ---
--- 2.089573621749878 seconds for one epoch ---
--- 0.2973203659057617 seconds for one epoch ---
--- 2.1021623611450195 seconds for one epoch ---
--- 0.6587588787078857 seconds for one epoch ---
--- 2.0958666801452637 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.185157]
 [ -0.      ]]
--- 0.29531192779541016 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3070.27978515625, (1355.4327, 5.621539, 1708.8688, 0.35662556)
   validation loss 1129.1607666015625, (828.6091, 0.69358003, 299.5016, 0.35662556)
decoder loss ratio: 32101.753894, decoder SINDy loss  ratio: 0.646516
--- 0.2539634704589844 seconds for one epoch ---
--- 0.29198193550109863 seconds for one epoch ---
--- 2.1067957878112793 seconds for one epoch ---
--- 0.28919148445129395 seconds for one epoch ---
--- 2.0855159759521484 seconds for one epoch ---
--- 0.27765989303588867 seconds for one epoch ---
--- 2.092390775680542 seconds for one epoch ---
--- 0.3087337017059326 seconds for one epoch ---
--- 2.073084831237793 seconds for one epoch ---
--- 0.2885885238647461 seconds for one epoch ---
--- 2.0890555381774902 seconds for one epoch ---
--- 0.30156540870666504 seconds for one epoch ---
--- 2.0883305072784424 seconds for one epoch ---
--- 0.2846410274505615 seconds for one epoch ---
--- 2.1129648685455322 seconds for one epoch ---
--- 0.2961997985839844 seconds for one epoch ---
--- 2.0852341651916504 seconds for one epoch ---
--- 0.31365251541137695 seconds for one epoch ---
--- 2.066793918609619 seconds for one epoch ---
--- 0.2990295886993408 seconds for one epoch ---
--- 2.050199270248413 seconds for one epoch ---
--- 0.28545618057250977 seconds for one epoch ---
--- 2.085531711578369 seconds for one epoch ---
--- 0.29216623306274414 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.225947]
 [  0.      ]]
--- 0.2610969543457031 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4074.800048828125, (1191.3175, 1.5189488, 2881.6062, 0.35739222)
   validation loss 959.274169921875, (682.392, 0.7001157, 275.82455, 0.35739222)
decoder loss ratio: 26437.051881, decoder SINDy loss  ratio: 0.595406
--- 0.2940993309020996 seconds for one epoch ---
--- 2.0926616191864014 seconds for one epoch ---
--- 0.2995028495788574 seconds for one epoch ---
--- 2.0807385444641113 seconds for one epoch ---
--- 0.32297658920288086 seconds for one epoch ---
--- 2.0857536792755127 seconds for one epoch ---
--- 0.292447566986084 seconds for one epoch ---
--- 2.111254930496216 seconds for one epoch ---
--- 0.30173230171203613 seconds for one epoch ---
--- 2.107778549194336 seconds for one epoch ---
--- 0.29021334648132324 seconds for one epoch ---
--- 2.1230275630950928 seconds for one epoch ---
--- 0.29091715812683105 seconds for one epoch ---
--- 2.110750913619995 seconds for one epoch ---
--- 0.31463623046875 seconds for one epoch ---
--- 2.078763246536255 seconds for one epoch ---
--- 0.29700303077697754 seconds for one epoch ---
--- 2.057904005050659 seconds for one epoch ---
--- 0.3011915683746338 seconds for one epoch ---
--- 2.0747125148773193 seconds for one epoch ---
--- 0.3021376132965088 seconds for one epoch ---
--- 2.0926897525787354 seconds for one epoch ---
--- 0.3104736804962158 seconds for one epoch ---
--- 2.077232837677002 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.276668]
 [  0.      ]]
--- 0.3089015483856201 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1513.3702392578125, (809.29865, 0.8953547, 702.8179, 0.3583649)
   validation loss 788.7211303710938, (509.07422, 0.66463256, 278.62396, 0.3583649)
decoder loss ratio: 19722.419026, decoder SINDy loss  ratio: 0.601449
--- 0.26213717460632324 seconds for one epoch ---
--- 0.29563426971435547 seconds for one epoch ---
--- 2.07882022857666 seconds for one epoch ---
--- 0.30634188652038574 seconds for one epoch ---
--- 2.1087751388549805 seconds for one epoch ---
--- 0.33063650131225586 seconds for one epoch ---
--- 2.1274287700653076 seconds for one epoch ---
--- 0.29930806159973145 seconds for one epoch ---
--- 2.1048483848571777 seconds for one epoch ---
--- 0.28757238388061523 seconds for one epoch ---
--- 2.1415324211120605 seconds for one epoch ---
--- 0.30452418327331543 seconds for one epoch ---
--- 2.09315824508667 seconds for one epoch ---
--- 0.292191743850708 seconds for one epoch ---
--- 2.0658633708953857 seconds for one epoch ---
--- 0.29860734939575195 seconds for one epoch ---
--- 2.103095531463623 seconds for one epoch ---
--- 0.2963404655456543 seconds for one epoch ---
--- 2.1151552200317383 seconds for one epoch ---
--- 0.29556822776794434 seconds for one epoch ---
--- 2.120835304260254 seconds for one epoch ---
--- 0.29166340827941895 seconds for one epoch ---
--- 2.085880994796753 seconds for one epoch ---
--- 0.2982611656188965 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.320289]
 [ -0.      ]]
--- 0.26109862327575684 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2766.912353515625, (1483.4587, 0.6458122, 1282.4487, 0.35919842)
   validation loss 765.96435546875, (484.47766, 0.6636085, 280.4639, 0.35919842)
decoder loss ratio: 18769.505682, decoder SINDy loss  ratio: 0.605421
--- 0.292341947555542 seconds for one epoch ---
--- 2.103224754333496 seconds for one epoch ---
--- 0.2805469036102295 seconds for one epoch ---
--- 2.084530830383301 seconds for one epoch ---
--- 0.2922518253326416 seconds for one epoch ---
--- 2.1134145259857178 seconds for one epoch ---
--- 0.3027076721191406 seconds for one epoch ---
--- 2.1305692195892334 seconds for one epoch ---
--- 0.30649375915527344 seconds for one epoch ---
--- 2.0846140384674072 seconds for one epoch ---
--- 0.29601573944091797 seconds for one epoch ---
--- 2.074723720550537 seconds for one epoch ---
--- 0.2956197261810303 seconds for one epoch ---
--- 2.1092469692230225 seconds for one epoch ---
--- 0.29607605934143066 seconds for one epoch ---
--- 2.1175596714019775 seconds for one epoch ---
--- 0.29688572883605957 seconds for one epoch ---
--- 2.08819842338562 seconds for one epoch ---
--- 0.3075714111328125 seconds for one epoch ---
--- 2.1371681690216064 seconds for one epoch ---
--- 0.293928861618042 seconds for one epoch ---
--- 2.1254889965057373 seconds for one epoch ---
--- 0.2929713726043701 seconds for one epoch ---
--- 2.135591506958008 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.360774]
 [ -0.      ]]
--- 0.2938649654388428 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3001.601318359375, (1117.3368, 2.0176928, 1881.8866, 0.36001974)
   validation loss 778.4266967773438, (493.04926, 0.6747706, 284.3426, 0.36001974)
decoder loss ratio: 19101.584124, decoder SINDy loss  ratio: 0.613793
--- 0.9651041030883789 seconds for one epoch ---
--- 0.28932714462280273 seconds for one epoch ---
--- 2.116030216217041 seconds for one epoch ---
--- 0.29882287979125977 seconds for one epoch ---
--- 2.1434121131896973 seconds for one epoch ---
--- 0.30937719345092773 seconds for one epoch ---
--- 2.1247408390045166 seconds for one epoch ---
--- 0.2983262538909912 seconds for one epoch ---
--- 2.1100265979766846 seconds for one epoch ---
--- 0.2992222309112549 seconds for one epoch ---
--- 2.138516664505005 seconds for one epoch ---
--- 0.29781055450439453 seconds for one epoch ---
--- 2.142812728881836 seconds for one epoch ---
--- 0.3014829158782959 seconds for one epoch ---
--- 2.1265809535980225 seconds for one epoch ---
--- 0.3230013847351074 seconds for one epoch ---
--- 2.096569538116455 seconds for one epoch ---
--- 0.29939961433410645 seconds for one epoch ---
--- 2.121605634689331 seconds for one epoch ---
--- 0.2922637462615967 seconds for one epoch ---
--- 2.121133804321289 seconds for one epoch ---
--- 0.3118095397949219 seconds for one epoch ---
--- 2.108424425125122 seconds for one epoch ---
--- 0.3037121295928955 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.404858]
 [  0.      ]]
--- 0.2616078853607178 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2156.93603515625, (923.0189, 2.1490178, 1231.4072, 0.36085722)
   validation loss 989.1646118164062, (710.189, 0.7175507, 277.89722, 0.36085722)
decoder loss ratio: 27513.955805, decoder SINDy loss  ratio: 0.599880
--- 0.2980220317840576 seconds for one epoch ---
--- 2.1191112995147705 seconds for one epoch ---
--- 0.2936711311340332 seconds for one epoch ---
--- 2.145179271697998 seconds for one epoch ---
--- 0.2946584224700928 seconds for one epoch ---
--- 2.11067795753479 seconds for one epoch ---
--- 0.3599579334259033 seconds for one epoch ---
--- 2.1491878032684326 seconds for one epoch ---
--- 0.2946765422821045 seconds for one epoch ---
--- 2.166234016418457 seconds for one epoch ---
--- 0.313096284866333 seconds for one epoch ---
--- 2.1565299034118652 seconds for one epoch ---
--- 0.29844236373901367 seconds for one epoch ---
--- 2.1695990562438965 seconds for one epoch ---
--- 0.28226399421691895 seconds for one epoch ---
--- 2.1414144039154053 seconds for one epoch ---
--- 0.310314416885376 seconds for one epoch ---
--- 2.1543030738830566 seconds for one epoch ---
--- 0.3016188144683838 seconds for one epoch ---
--- 2.138869047164917 seconds for one epoch ---
--- 0.2930114269256592 seconds for one epoch ---
--- 2.176492214202881 seconds for one epoch ---
--- 0.30312204360961914 seconds for one epoch ---
--- 2.1667017936706543 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-13.4473295]
 [ -0.       ]]
--- 0.27294373512268066 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1937.049560546875, (875.37585, 0.3961475, 1060.9159, 0.36171108)
   validation loss 808.701416015625, (540.0636, 0.68449694, 267.59164, 0.36171108)
decoder loss ratio: 20923.001403, decoder SINDy loss  ratio: 0.577634
--- 0.2682619094848633 seconds for one epoch ---
--- 0.2974252700805664 seconds for one epoch ---
--- 2.1280651092529297 seconds for one epoch ---
--- 0.29734063148498535 seconds for one epoch ---
--- 2.131500720977783 seconds for one epoch ---
--- 0.2934224605560303 seconds for one epoch ---
--- 2.123853921890259 seconds for one epoch ---
--- 0.324725866317749 seconds for one epoch ---
--- 2.1527862548828125 seconds for one epoch ---
--- 0.2947087287902832 seconds for one epoch ---
--- 2.181230068206787 seconds for one epoch ---
--- 0.29865527153015137 seconds for one epoch ---
--- 2.177647352218628 seconds for one epoch ---
--- 0.30341553688049316 seconds for one epoch ---
--- 2.1831815242767334 seconds for one epoch ---
--- 0.31305646896362305 seconds for one epoch ---
--- 2.180386543273926 seconds for one epoch ---
--- 0.29580140113830566 seconds for one epoch ---
--- 2.1918015480041504 seconds for one epoch ---
--- 0.29045987129211426 seconds for one epoch ---
--- 2.1706576347351074 seconds for one epoch ---
--- 0.3002901077270508 seconds for one epoch ---
--- 2.1871178150177 seconds for one epoch ---
--- 0.3001894950866699 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.490203]
 [  0.      ]]
--- 0.27185511589050293 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2622.063720703125, (1390.404, 1.0507301, 1230.2462, 0.36256734)
   validation loss 1073.0042724609375, (787.3767, 0.72700864, 284.538, 0.36256734)
decoder loss ratio: 30504.340652, decoder SINDy loss  ratio: 0.614215
--- 0.29664063453674316 seconds for one epoch ---
--- 2.1528453826904297 seconds for one epoch ---
--- 0.31812119483947754 seconds for one epoch ---
--- 2.1598198413848877 seconds for one epoch ---
--- 0.2933173179626465 seconds for one epoch ---
--- 2.1497654914855957 seconds for one epoch ---
--- 0.30539393424987793 seconds for one epoch ---
--- 2.180593967437744 seconds for one epoch ---
--- 0.29691362380981445 seconds for one epoch ---
--- 2.176222324371338 seconds for one epoch ---
--- 0.29392290115356445 seconds for one epoch ---
--- 2.1498007774353027 seconds for one epoch ---
--- 0.3178098201751709 seconds for one epoch ---
--- 2.165968894958496 seconds for one epoch ---
--- 0.2989058494567871 seconds for one epoch ---
--- 2.1254305839538574 seconds for one epoch ---
--- 0.2962779998779297 seconds for one epoch ---
--- 2.1647424697875977 seconds for one epoch ---
--- 0.29333043098449707 seconds for one epoch ---
--- 2.151019334793091 seconds for one epoch ---
--- 0.29867029190063477 seconds for one epoch ---
--- 2.1558213233947754 seconds for one epoch ---
--- 0.2970235347747803 seconds for one epoch ---
--- 2.148798704147339 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.537004]
 [  0.      ]]
--- 0.29838085174560547 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2800.788330078125, (741.1288, 1.7836131, 2057.5125, 0.36343732)
   validation loss 875.0155639648438, (592.15814, 0.7162665, 281.77774, 0.36343732)
decoder loss ratio: 22941.234456, decoder SINDy loss  ratio: 0.608257
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.537837]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1194.27587890625, (622.57355, 0.6231174, 571.0793, 0.3635001)
   validation loss 742.0504760742188, (483.33643, 0.51140016, 258.20264, 0.3635001)
decoder loss ratio: 18725.292244, decoder SINDy loss  ratio: 0.557367
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.650774]
 [ -0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 877.8138427734375, (417.84406, 0.23853002, 459.7313, 0.36535484)
   validation loss 631.5794677734375, (409.70944, 0.121160254, 221.74886, 0.36535484)
decoder loss ratio: 15872.855075, decoder SINDy loss  ratio: 0.478676
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.722362]
 [  0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1055.0849609375, (559.4301, 0.16407356, 495.49084, 0.36526895)
   validation loss 703.1700439453125, (479.6053, 0.10206763, 223.46268, 0.36526895)
decoder loss ratio: 18580.741397, decoder SINDy loss  ratio: 0.482376
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-13.50658]
 [ -0.     ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 738.04248046875, (291.06946, 0.13414074, 446.8389, 0.3646833)
   validation loss 449.2691955566406, (235.42783, 0.07751338, 213.76385, 0.3646833)
decoder loss ratio: 9120.882697, decoder SINDy loss  ratio: 0.461439
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.556884]
 [  0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.0226440429688, (259.3789, 0.113066405, 461.53067, 0.36403355)
   validation loss 418.22015380859375, (206.38948, 0.07297382, 211.75769, 0.36403355)
decoder loss ratio: 7995.886786, decoder SINDy loss  ratio: 0.457109
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.608514]
 [ -0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 723.9714965820312, (285.38757, 0.122682855, 438.46124, 0.36356494)
   validation loss 437.00726318359375, (227.04625, 0.06880251, 209.8922, 0.36356494)
decoder loss ratio: 8796.165871, decoder SINDy loss  ratio: 0.453082
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.501822]
 [ -0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.6073608398438, (243.20874, 0.11790457, 446.28073, 0.36299536)
   validation loss 406.8814697265625, (199.15437, 0.057169005, 207.66992, 0.36299536)
decoder loss ratio: 7715.586164, decoder SINDy loss  ratio: 0.448285
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.492033]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 782.3716430664062, (347.89035, 0.11117858, 434.37012, 0.36251575)
   validation loss 491.42938232421875, (280.0185, 0.058438305, 211.35246, 0.36251575)
decoder loss ratio: 10848.402578, decoder SINDy loss  ratio: 0.456234
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-13.48187]
 [ -0.     ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.6827392578125, (239.78448, 0.112817414, 436.78546, 0.36225566)
   validation loss 388.41119384765625, (181.83005, 0.057500828, 206.52364, 0.36225566)
decoder loss ratio: 7044.411715, decoder SINDy loss  ratio: 0.445810
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.556829]
 [ -0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1620.6036376953125, (1180.677, 0.12159074, 439.80502, 0.36199337)
   validation loss 1301.8441162109375, (1066.8386, 0.06259103, 234.94289, 0.36199337)
decoder loss ratio: 41331.180370, decoder SINDy loss  ratio: 0.507157
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.461466]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.49658203125, (255.05275, 0.11680569, 461.327, 0.36176142)
   validation loss 406.73175048828125, (197.26807, 0.05393098, 209.40974, 0.36176142)
decoder loss ratio: 7642.507365, decoder SINDy loss  ratio: 0.452040
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.508643]
 [  0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.3910522460938, (231.71338, 0.113878794, 434.5638, 0.3616812)
   validation loss 383.26715087890625, (177.37866, 0.051435106, 205.83704, 0.3616812)
decoder loss ratio: 6871.957313, decoder SINDy loss  ratio: 0.444328
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.444942]
 [  0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1152.73193359375, (720.6239, 0.11912904, 431.98886, 0.3617127)
   validation loss 827.8653564453125, (606.6269, 0.053327214, 221.18512, 0.3617127)
decoder loss ratio: 23501.778950, decoder SINDy loss  ratio: 0.477459
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.442916]
 [  0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.4576416015625, (220.18105, 0.11947102, 445.15714, 0.36173102)
   validation loss 381.391845703125, (174.96674, 0.047964063, 206.37717, 0.36173102)
decoder loss ratio: 6778.515102, decoder SINDy loss  ratio: 0.445494
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.432977]
 [ -0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 674.8190307617188, (226.92435, 0.12490495, 447.76978, 0.36186966)
   validation loss 386.19671630859375, (179.35236, 0.04663252, 206.79773, 0.36186966)
decoder loss ratio: 6948.421639, decoder SINDy loss  ratio: 0.446402
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.503156]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 836.2796020507812, (409.05826, 0.13786766, 427.08347, 0.36208844)
   validation loss 549.1876831054688, (337.2166, 0.0470316, 211.92403, 0.36208844)
decoder loss ratio: 13064.357051, decoder SINDy loss  ratio: 0.457468
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.477961]
 [ -0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.9595947265625, (258.2441, 0.13178568, 454.58368, 0.3623447)
   validation loss 419.20733642578125, (211.03728, 0.04414913, 208.12592, 0.3623447)
decoder loss ratio: 8175.950496, decoder SINDy loss  ratio: 0.449269
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.559792]
 [ -0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1172.291015625, (742.0451, 0.12515056, 430.12082, 0.36264256)
   validation loss 858.3310546875, (633.7525, 0.04593144, 224.53256, 0.36264256)
decoder loss ratio: 24552.672187, decoder SINDy loss  ratio: 0.484685
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.490381]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.898681640625, (317.00165, 0.1352996, 428.76172, 0.3630022)
   validation loss 468.93231201171875, (259.21194, 0.043541092, 209.6768, 0.3630022)
decoder loss ratio: 10042.320745, decoder SINDy loss  ratio: 0.452617
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.564636]
 [ -0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.3773193359375, (366.9179, 0.15592198, 426.30353, 0.36345753)
   validation loss 498.1070556640625, (287.30197, 0.044033464, 210.76103, 0.36345753)
decoder loss ratio: 11130.577152, decoder SINDy loss  ratio: 0.454957
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.568325]
 [ -0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.3740234375, (255.69582, 0.14465603, 428.53354, 0.36394677)
   validation loss 410.2310791015625, (203.3098, 0.042288452, 206.87898, 0.36394677)
decoder loss ratio: 7876.574582, decoder SINDy loss  ratio: 0.446577
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.600414]
 [  0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 947.8701782226562, (520.6578, 0.15605117, 427.05634, 0.36443412)
   validation loss 644.4495849609375, (425.6721, 0.042614195, 218.7349, 0.36443412)
decoder loss ratio: 16491.275713, decoder SINDy loss  ratio: 0.472170
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.576607]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.0185546875, (215.48102, 0.15994737, 431.3776, 0.3650106)
   validation loss 369.95477294921875, (163.09773, 0.040607598, 206.81642, 0.3650106)
decoder loss ratio: 6318.689309, decoder SINDy loss  ratio: 0.446442
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.588549]
 [ -0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.46728515625, (395.837, 0.15918852, 423.47107, 0.36568034)
   validation loss 522.3639526367188, (309.99435, 0.042150218, 212.32745, 0.36568034)
decoder loss ratio: 12009.719457, decoder SINDy loss  ratio: 0.458339
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-13.68725]
 [  0.     ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.218994140625, (304.8253, 0.19735628, 462.19638, 0.3663608)
   validation loss 464.66314697265625, (253.67271, 0.042309247, 210.9481, 0.3663608)
decoder loss ratio: 9827.721345, decoder SINDy loss  ratio: 0.455361
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.759856]
 [ -0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1091.0960693359375, (663.7048, 0.17777665, 427.21347, 0.36699694)
   validation loss 781.626220703125, (559.2638, 0.043588158, 222.31882, 0.36699694)
decoder loss ratio: 21666.850302, decoder SINDy loss  ratio: 0.479906
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.684508]
 [ -0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 663.7693481445312, (236.90749, 0.16577892, 426.69608, 0.36766723)
   validation loss 384.9666748046875, (178.3668, 0.041389775, 206.55847, 0.36766723)
decoder loss ratio: 6910.239724, decoder SINDy loss  ratio: 0.445886
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.786032]
 [ -0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.4564819335938, (303.33072, 0.18060373, 423.94516, 0.36835527)
   validation loss 437.95184326171875, (228.61163, 0.041629456, 209.29857, 0.36835527)
decoder loss ratio: 8856.811561, decoder SINDy loss  ratio: 0.451800
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.866063]
 [ -0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.0992431640625, (296.9143, 0.1650275, 425.0199, 0.36908436)
   validation loss 444.2327575683594, (235.13097, 0.041104846, 209.06068, 0.36908436)
decoder loss ratio: 9109.381835, decoder SINDy loss  ratio: 0.451287
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.875447]
 [ -0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.5262451171875, (317.10498, 0.16194876, 420.25934, 0.36976367)
   validation loss 451.36676025390625, (241.8641, 0.041038837, 209.46161, 0.36976367)
decoder loss ratio: 9370.235331, decoder SINDy loss  ratio: 0.452152
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.851915]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.4967041015625, (284.04892, 0.16040993, 421.28738, 0.3704988)
   validation loss 425.760986328125, (217.57642, 0.040032033, 208.14452, 0.3704988)
decoder loss ratio: 8429.288086, decoder SINDy loss  ratio: 0.449309
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.975336]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.8875732421875, (215.04141, 0.17928998, 425.6669, 0.37122148)
   validation loss 365.5830078125, (161.57751, 0.042135775, 203.96338, 0.37122148)
decoder loss ratio: 6259.793428, decoder SINDy loss  ratio: 0.440284
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.897652]
 [  0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 676.7872314453125, (246.75375, 0.17158626, 429.8619, 0.37191817)
   validation loss 396.71185302734375, (189.9747, 0.039733652, 206.69742, 0.37191817)
decoder loss ratio: 7359.949725, decoder SINDy loss  ratio: 0.446185
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.984128]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.5823364257812, (282.6351, 0.18348107, 437.76376, 0.37259498)
   validation loss 453.65716552734375, (246.263, 0.042101957, 207.35205, 0.37259498)
decoder loss ratio: 9540.656170, decoder SINDy loss  ratio: 0.447599
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.00527]
 [ -0.     ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.2236938476562, (250.87338, 0.17189899, 447.1784, 0.37332585)
   validation loss 409.9811096191406, (201.13441, 0.038051434, 208.80864, 0.37332585)
decoder loss ratio: 7792.296409, decoder SINDy loss  ratio: 0.450743
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.031826]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.2553100585938, (336.3229, 0.16661778, 417.76578, 0.37402806)
   validation loss 464.48675537109375, (255.08208, 0.04116641, 209.36351, 0.37402806)
decoder loss ratio: 9882.322506, decoder SINDy loss  ratio: 0.451941
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.101307]
 [  0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.9534912109375, (360.43127, 0.16180299, 418.3604, 0.37476286)
   validation loss 497.8306884765625, (288.0545, 0.039917655, 209.73627, 0.37476286)
decoder loss ratio: 11159.731585, decoder SINDy loss  ratio: 0.452745
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.093078]
 [ -0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 926.0733642578125, (506.13235, 0.166192, 419.7748, 0.37548292)
   validation loss 609.7787475585938, (393.03915, 0.04271185, 216.69688, 0.37548292)
decoder loss ratio: 15227.019174, decoder SINDy loss  ratio: 0.467771
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.1870575]
 [  0.       ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.2971801757812, (286.29535, 0.16240902, 418.83942, 0.376217)
   validation loss 426.51507568359375, (218.57033, 0.039189927, 207.90558, 0.376217)
decoder loss ratio: 8467.793952, decoder SINDy loss  ratio: 0.448793
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.151532]
 [ -0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.1505737304688, (268.9635, 0.16229185, 417.02478, 0.37688044)
   validation loss 405.31671142578125, (198.52353, 0.040389504, 206.7528, 0.37688044)
decoder loss ratio: 7691.146168, decoder SINDy loss  ratio: 0.446305
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.296929]
 [  0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1165.84912109375, (744.9498, 0.17503433, 420.72427, 0.37761956)
   validation loss 838.9620361328125, (617.68726, 0.04502731, 221.22972, 0.37761956)
decoder loss ratio: 23930.276644, decoder SINDy loss  ratio: 0.477555
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.294757]
 [ -0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 932.6444091796875, (453.22208, 0.22288609, 479.19943, 0.37833092)
   validation loss 617.8562622070312, (400.39917, 0.046071466, 217.41103, 0.37833092)
decoder loss ratio: 15512.158966, decoder SINDy loss  ratio: 0.469312
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.295444]
 [  0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 915.0576171875, (454.60736, 0.17817941, 460.27203, 0.3788959)
   validation loss 654.30712890625, (441.62082, 0.039249707, 212.64706, 0.3788959)
decoder loss ratio: 17109.157219, decoder SINDy loss  ratio: 0.459029
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.243415]
 [  0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.068115234375, (222.29312, 0.1793711, 420.59564, 0.37955746)
   validation loss 365.84912109375, (162.7888, 0.04203942, 203.0183, 0.37955746)
decoder loss ratio: 6306.720846, decoder SINDy loss  ratio: 0.438244
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.338528]
 [  0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 633.2489624023438, (208.00488, 0.16057257, 425.08353, 0.3801911)
   validation loss 362.5623779296875, (159.13618, 0.039369296, 203.38683, 0.3801911)
decoder loss ratio: 6165.212068, decoder SINDy loss  ratio: 0.439039
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.375046]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1721.0936279296875, (1294.1799, 0.1680505, 426.74557, 0.38080403)
   validation loss 1392.6510009765625, (1152.3809, 0.043985065, 240.22617, 0.38080403)
decoder loss ratio: 44645.235113, decoder SINDy loss  ratio: 0.518562
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.393557]
 [ -0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.1572265625, (277.00812, 0.17435457, 442.9748, 0.38133606)
   validation loss 449.23614501953125, (242.37447, 0.038472388, 206.8232, 0.38133606)
decoder loss ratio: 9390.007591, decoder SINDy loss  ratio: 0.446457
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.484167]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 898.5440673828125, (479.69867, 0.16839758, 418.67697, 0.38196862)
   validation loss 572.62451171875, (357.50848, 0.042862836, 215.07315, 0.38196862)
decoder loss ratio: 13850.499328, decoder SINDy loss  ratio: 0.464266
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.525147]
 [  0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.2498168945312, (223.44995, 0.16577758, 432.6341, 0.38252884)
   validation loss 383.99542236328125, (179.47609, 0.037737645, 204.4816, 0.38252884)
decoder loss ratio: 6953.215291, decoder SINDy loss  ratio: 0.441402
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.559067]
 [  0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 894.067626953125, (427.02618, 0.20944853, 466.83197, 0.3831307)
   validation loss 610.116943359375, (396.21796, 0.041742533, 213.85725, 0.3831307)
decoder loss ratio: 15350.171501, decoder SINDy loss  ratio: 0.461641
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.508107]
 [  0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.6632080078125, (273.6963, 0.15784687, 431.80908, 0.38369223)
   validation loss 452.26702880859375, (247.898, 0.03838899, 204.33063, 0.38369223)
decoder loss ratio: 9603.998696, decoder SINDy loss  ratio: 0.441076
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.607802]
 [ -0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 795.3737182617188, (379.65106, 0.17062165, 415.55203, 0.38422966)
   validation loss 482.91046142578125, (272.76904, 0.041556384, 210.09985, 0.38422966)
decoder loss ratio: 10567.546272, decoder SINDy loss  ratio: 0.453530
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.601546]
 [  0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 629.40283203125, (210.00067, 0.16209625, 419.24008, 0.3847948)
   validation loss 357.0826416015625, (154.29565, 0.039284736, 202.74768, 0.3847948)
decoder loss ratio: 5977.681516, decoder SINDy loss  ratio: 0.437659
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.58683]
 [ -0.     ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.3619995117188, (221.21304, 0.16675933, 415.9822, 0.38536906)
   validation loss 362.8922119140625, (160.9058, 0.041591786, 201.94481, 0.38536906)
decoder loss ratio: 6233.770327, decoder SINDy loss  ratio: 0.435926
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.650871]
 [ -0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.85888671875, (227.44948, 0.19761917, 417.2118, 0.38595816)
   validation loss 366.79779052734375, (166.10237, 0.0451873, 200.65025, 0.38595816)
decoder loss ratio: 6435.094227, decoder SINDy loss  ratio: 0.433132
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.637461]
 [ -0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 846.996826171875, (433.4185, 0.17858414, 413.39972, 0.38643965)
   validation loss 542.16064453125, (332.66965, 0.0432747, 209.4477, 0.38643965)
decoder loss ratio: 12888.199673, decoder SINDy loss  ratio: 0.452122
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.689478]
 [  0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.3928833007812, (209.43463, 0.1622098, 416.79602, 0.38695094)
   validation loss 357.8749694824219, (156.92693, 0.04178636, 200.90625, 0.38695094)
decoder loss ratio: 6079.621537, decoder SINDy loss  ratio: 0.433684
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.648072]
 [ -0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1063.2078857421875, (649.1345, 0.17331967, 413.90002, 0.38751203)
   validation loss 727.5680541992188, (512.5013, 0.045294207, 215.02148, 0.38751203)
decoder loss ratio: 19855.189396, decoder SINDy loss  ratio: 0.464154
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.795916]
 [ -0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 958.4315185546875, (513.40625, 0.18226153, 444.84305, 0.38797075)
   validation loss 737.243408203125, (528.8706, 0.043767728, 208.32901, 0.38797075)
decoder loss ratio: 20489.365416, decoder SINDy loss  ratio: 0.449707
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.713429]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.9994506835938, (235.94244, 0.16082022, 432.89618, 0.38848615)
   validation loss 400.647216796875, (196.88184, 0.037439007, 203.72795, 0.38848615)
decoder loss ratio: 7627.544126, decoder SINDy loss  ratio: 0.439775
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.752248]
 [ -0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.7838134765625, (445.81567, 0.1898293, 457.7783, 0.38901806)
   validation loss 648.1819458007812, (436.48785, 0.040183164, 211.6539, 0.38901806)
decoder loss ratio: 16910.297240, decoder SINDy loss  ratio: 0.456885
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.775149]
 [  0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1482.04638671875, (987.71533, 0.1819639, 494.1491, 0.3894364)
   validation loss 1253.44970703125, (1024.3011, 0.035939846, 229.11269, 0.3894364)
decoder loss ratio: 39683.204718, decoder SINDy loss  ratio: 0.494572
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.773941]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.1246337890625, (230.03769, 0.16845022, 412.9185, 0.3898922)
   validation loss 366.657470703125, (164.44678, 0.039899316, 202.17079, 0.3898922)
decoder loss ratio: 6370.953646, decoder SINDy loss  ratio: 0.436414
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.878226]
 [ -0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.5217895507812, (220.39381, 0.16259213, 425.9654, 0.39038324)
   validation loss 380.1288146972656, (177.87117, 0.038346235, 202.2193, 0.39038324)
decoder loss ratio: 6891.037925, decoder SINDy loss  ratio: 0.436519
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.874585]
 [  0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1133.0736083984375, (719.1221, 0.15660225, 413.79495, 0.3908722)
   validation loss 803.9842529296875, (582.8946, 0.042353496, 221.04727, 0.3908722)
decoder loss ratio: 22582.348455, decoder SINDy loss  ratio: 0.477162
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.831551]
 [  0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.9346313476562, (213.63081, 0.159549, 426.14426, 0.39127344)
   validation loss 370.5644836425781, (167.43484, 0.037075765, 203.09256, 0.39127344)
decoder loss ratio: 6486.716574, decoder SINDy loss  ratio: 0.438404
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.914223]
 [ -0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 790.3951416015625, (381.91568, 0.15387498, 408.3256, 0.3917762)
   validation loss 483.3101806640625, (276.25128, 0.043789547, 207.01512, 0.3917762)
decoder loss ratio: 10702.454248, decoder SINDy loss  ratio: 0.446871
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-14.9427]
 [ -0.    ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.2343139648438, (207.39722, 0.16908458, 416.66803, 0.39220402)
   validation loss 363.4499206542969, (163.17046, 0.04122157, 200.23825, 0.39220402)
decoder loss ratio: 6321.506739, decoder SINDy loss  ratio: 0.432242
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.020681]
 [  0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.152587890625, (268.75662, 0.16727445, 409.2287, 0.39263335)
   validation loss 398.4727783203125, (195.47194, 0.04009078, 202.96077, 0.39263335)
decoder loss ratio: 7572.922274, decoder SINDy loss  ratio: 0.438119
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.014292]
 [ -0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.048828125, (308.46472, 0.15972671, 407.42435, 0.39314172)
   validation loss 418.58502197265625, (215.60663, 0.044303592, 202.9341, 0.39314172)
decoder loss ratio: 8352.975094, decoder SINDy loss  ratio: 0.438062
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.034603]
 [ -0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.3043823242188, (236.30852, 0.19009091, 412.80576, 0.39365482)
   validation loss 371.725830078125, (172.23402, 0.045191284, 199.44661, 0.39365482)
decoder loss ratio: 6672.645103, decoder SINDy loss  ratio: 0.430534
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.949265]
 [ -0.      ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1632.38232421875, (1152.4656, 0.16727558, 479.74945, 0.39394757)
   validation loss 1467.5040283203125, (1241.2656, 0.037348926, 226.20108, 0.39394757)
decoder loss ratio: 48088.785244, decoder SINDy loss  ratio: 0.488287
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.06443]
 [ -0.     ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.1573486328125, (277.30698, 0.17066903, 409.6797, 0.39438787)
   validation loss 399.9515380859375, (197.2714, 0.04223011, 202.63791, 0.39438787)
decoder loss ratio: 7642.636236, decoder SINDy loss  ratio: 0.437422
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.023224]
 [ -0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.4813232421875, (206.24492, 0.15466844, 415.08176, 0.39473993)
   validation loss 356.7571105957031, (157.12708, 0.040040094, 199.59, 0.39473993)
decoder loss ratio: 6087.375678, decoder SINDy loss  ratio: 0.430843
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-14.97693]
 [ -0.     ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 870.66748046875, (463.1924, 0.15702693, 407.31802, 0.3951548)
   validation loss 557.5816650390625, (350.04926, 0.04300092, 207.48944, 0.3951548)
decoder loss ratio: 13561.515865, decoder SINDy loss  ratio: 0.447895
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.01528]
 [  0.     ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.6327514648438, (220.99257, 0.15891041, 410.48126, 0.39546973)
   validation loss 362.0690002441406, (162.60107, 0.04218859, 199.42574, 0.39546973)
decoder loss ratio: 6299.447903, decoder SINDy loss  ratio: 0.430489
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.078282]
 [ -0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 916.728515625, (460.61725, 0.18197662, 455.92932, 0.39578518)
   validation loss 660.4345703125, (450.49127, 0.036040943, 209.90723, 0.39578518)
decoder loss ratio: 17452.813963, decoder SINDy loss  ratio: 0.453114
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [-15.1030445]
 [ -0.       ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.075927734375, (267.45343, 0.17571975, 436.4468, 0.39618635)
   validation loss 427.96856689453125, (223.37277, 0.038252264, 204.55756, 0.39618635)
decoder loss ratio: 8653.848988, decoder SINDy loss  ratio: 0.441566
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.097128]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 921.0648193359375, (508.81827, 0.16274866, 412.08383, 0.3964579)
   validation loss 582.5576782226562, (369.86948, 0.04325342, 212.64497, 0.3964579)
decoder loss ratio: 14329.385634, decoder SINDy loss  ratio: 0.459024
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.149751]
 [  0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 907.2952270507812, (440.36554, 0.18605454, 466.74362, 0.39681688)
   validation loss 620.977783203125, (407.55798, 0.036308058, 213.38348, 0.39681688)
decoder loss ratio: 15789.503829, decoder SINDy loss  ratio: 0.460618
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.130057]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.5465087890625, (227.76648, 0.14926222, 416.63077, 0.3971661)
   validation loss 364.93951416015625, (162.2312, 0.037936322, 202.6704, 0.3971661)
decoder loss ratio: 6285.118379, decoder SINDy loss  ratio: 0.437493
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.174054]
 [ -0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 771.6611328125, (348.3907, 0.16589826, 423.10458, 0.3974716)
   validation loss 536.6421508789062, (334.54437, 0.04160443, 202.05618, 0.3974716)
decoder loss ratio: 12960.829787, decoder SINDy loss  ratio: 0.436167
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.102114]
 [ -0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.5863037109375, (314.83514, 0.1603447, 439.59085, 0.39782515)
   validation loss 496.26971435546875, (290.6932, 0.037197977, 205.53932, 0.39782515)
decoder loss ratio: 11261.959497, decoder SINDy loss  ratio: 0.443686
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.165327]
 [  0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.841552734375, (361.82156, 0.15285249, 406.8671, 0.39812678)
   validation loss 458.8770751953125, (252.42424, 0.042475175, 206.41037, 0.39812678)
decoder loss ratio: 9779.353290, decoder SINDy loss  ratio: 0.445566
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.163456]
 [  0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.7083740234375, (274.98483, 0.15416804, 436.56934, 0.39837083)
   validation loss 439.74725341796875, (234.97081, 0.03654986, 204.73988, 0.39837083)
decoder loss ratio: 9103.177104, decoder SINDy loss  ratio: 0.441960
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.226252]
 [  0.      ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 764.376953125, (359.29514, 0.15429418, 404.92752, 0.3986852)
   validation loss 475.76458740234375, (270.1016, 0.041006677, 205.62196, 0.3986852)
decoder loss ratio: 10464.204630, decoder SINDy loss  ratio: 0.443864
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.213157]
 [  0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.8438720703125, (220.94646, 0.15133832, 423.7461, 0.3989156)
   validation loss 378.44403076171875, (176.24959, 0.03656907, 202.15785, 0.3989156)
decoder loss ratio: 6828.215022, decoder SINDy loss  ratio: 0.436386
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.232611]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.5090942382812, (259.57413, 0.15765867, 427.7773, 0.39924505)
   validation loss 426.7752380371094, (224.25009, 0.037831243, 202.48732, 0.39924505)
decoder loss ratio: 8687.837862, decoder SINDy loss  ratio: 0.437097
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.343931]
 [  0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 629.0211791992188, (216.30684, 0.16475831, 412.5496, 0.39951593)
   validation loss 371.3520202636719, (170.47462, 0.03944313, 200.83795, 0.39951593)
decoder loss ratio: 6604.482915, decoder SINDy loss  ratio: 0.433537
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.228222]
 [ -0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.64990234375, (274.60635, 0.15237232, 422.89114, 0.39982682)
   validation loss 451.6865234375, (250.34645, 0.037875805, 201.3022, 0.39982682)
decoder loss ratio: 9698.856125, decoder SINDy loss  ratio: 0.434539
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [-15.2203]
 [ -0.    ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.64990234375, (229.57343, 0.15356576, 425.9229, 0.40007097)
   validation loss 387.6081237792969, (184.84215, 0.036757294, 202.72922, 0.40007097)
decoder loss ratio: 7161.105707, decoder SINDy loss  ratio: 0.437620
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.233071]
 [ -0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.908447265625, (338.3168, 0.15323684, 403.43845, 0.40035555)
   validation loss 450.140625, (244.38428, 0.041676767, 205.71466, 0.40035555)
decoder loss ratio: 9467.871174, decoder SINDy loss  ratio: 0.444064
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.373693]
 [ -0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.546875, (244.57794, 0.15062243, 410.81833, 0.40066215)
   validation loss 391.697265625, (192.73328, 0.041412864, 198.92258, 0.40066215)
decoder loss ratio: 7466.821726, decoder SINDy loss  ratio: 0.429402
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.277442]
 [ -0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.6087646484375, (233.89735, 0.14407998, 412.56732, 0.40086904)
   validation loss 372.188232421875, (168.89253, 0.036315776, 203.2594, 0.40086904)
decoder loss ratio: 6543.189914, decoder SINDy loss  ratio: 0.438764
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.364755]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.1082763671875, (322.86267, 0.17086832, 418.07474, 0.40107533)
   validation loss 477.66607666015625, (275.4591, 0.043034013, 202.16393, 0.40107533)
decoder loss ratio: 10671.764002, decoder SINDy loss  ratio: 0.436399
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.416311]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.68212890625, (334.57596, 0.13298623, 404.97314, 0.40138778)
   validation loss 458.13201904296875, (252.73817, 0.038209613, 205.35562, 0.40138778)
decoder loss ratio: 9791.515651, decoder SINDy loss  ratio: 0.443289
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.362069]
 [  0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.384033203125, (275.96683, 0.15464954, 403.2625, 0.40161338)
   validation loss 398.68157958984375, (195.5385, 0.040212788, 203.10287, 0.40161338)
decoder loss ratio: 7575.500879, decoder SINDy loss  ratio: 0.438426
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.332021]
 [  0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 695.171142578125, (291.84155, 0.14948565, 403.18008, 0.40178806)
   validation loss 406.4092712402344, (203.53067, 0.042470984, 202.83614, 0.40178806)
decoder loss ratio: 7885.131507, decoder SINDy loss  ratio: 0.437850
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.372798]
 [ -0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.9915771484375, (326.67966, 0.14566366, 402.16626, 0.4020166)
   validation loss 439.41619873046875, (235.04848, 0.04231268, 204.32541, 0.4020166)
decoder loss ratio: 9106.186068, decoder SINDy loss  ratio: 0.441065
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.324437]
 [  0.      ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.509033203125, (221.14307, 0.14006698, 418.2259, 0.4021907)
   validation loss 373.79107666015625, (172.99187, 0.036606044, 200.76259, 0.4021907)
decoder loss ratio: 6702.005257, decoder SINDy loss  ratio: 0.433374
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.365651]
 [ -0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.1812133789062, (214.12042, 0.14444461, 405.91635, 0.4024256)
   validation loss 353.0408935546875, (153.74283, 0.041920915, 199.25615, 0.4024256)
decoder loss ratio: 5956.264080, decoder SINDy loss  ratio: 0.430122
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.428564]
 [  0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.1454467773438, (232.33784, 0.14751655, 416.66006, 0.4025751)
   validation loss 393.9810791015625, (194.58047, 0.040334504, 199.36026, 0.4025751)
decoder loss ratio: 7538.385402, decoder SINDy loss  ratio: 0.430347
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.318216]
 [  0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1046.08203125, (636.07806, 0.15518253, 409.84872, 0.4027245)
   validation loss 699.1268920898438, (482.2097, 0.044738732, 216.87245, 0.4027245)
decoder loss ratio: 18681.640399, decoder SINDy loss  ratio: 0.468150
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.408959]
 [  0.      ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.450927734375, (333.83307, 0.13536194, 401.4825, 0.4029412)
   validation loss 446.9036865234375, (242.81682, 0.041233707, 204.04565, 0.4029412)
decoder loss ratio: 9407.145087, decoder SINDy loss  ratio: 0.440461
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.473933]
 [  0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.5115966796875, (216.0329, 0.15313037, 409.32553, 0.40313974)
   validation loss 364.31768798828125, (166.39047, 0.043680243, 197.88353, 0.40313974)
decoder loss ratio: 6446.255768, decoder SINDy loss  ratio: 0.427159
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.45087]
 [  0.     ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 980.45068359375, (577.5867, 0.13140908, 402.73264, 0.40327245)
   validation loss 680.4392700195312, (467.33224, 0.04099732, 213.06602, 0.40327245)
decoder loss ratio: 18105.262491, decoder SINDy loss  ratio: 0.459933
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.462525]
 [  0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 649.45751953125, (247.3787, 0.13929787, 401.9395, 0.40333167)
   validation loss 372.56988525390625, (172.31308, 0.041504424, 200.21532, 0.40333167)
decoder loss ratio: 6675.707861, decoder SINDy loss  ratio: 0.432193
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.401862]
 [  0.      ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.8115844726562, (218.8898, 0.1401559, 404.78165, 0.40350118)
   validation loss 359.388427734375, (160.98499, 0.04220785, 198.36122, 0.40350118)
decoder loss ratio: 6236.837815, decoder SINDy loss  ratio: 0.428191
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.466874]
 [  0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1007.8529052734375, (554.388, 0.14902464, 453.31586, 0.40365028)
   validation loss 759.5704345703125, (550.2938, 0.037461754, 209.23914, 0.40365028)
decoder loss ratio: 21319.338064, decoder SINDy loss  ratio: 0.451672
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.448464]
 [ -0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 628.8307495117188, (218.10118, 0.17089452, 410.5587, 0.40373832)
   validation loss 359.8286437988281, (159.35457, 0.03811834, 200.43596, 0.40373832)
decoder loss ratio: 6173.672635, decoder SINDy loss  ratio: 0.432669
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.494872]
 [  0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.9186401367188, (210.97833, 0.14070788, 409.7996, 0.4039054)
   validation loss 355.7658386230469, (156.92918, 0.038428877, 198.79823, 0.4039054)
decoder loss ratio: 6079.709028, decoder SINDy loss  ratio: 0.429134
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.558501]
 [ -0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.6187744140625, (318.19696, 0.1762908, 438.24554, 0.40415755)
   validation loss 498.1077880859375, (292.90863, 0.0413801, 205.15779, 0.40415755)
decoder loss ratio: 11347.788852, decoder SINDy loss  ratio: 0.442862
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.47903]
 [  0.     ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1201.528564453125, (757.749, 0.1620609, 443.61743, 0.4041712)
   validation loss 1014.6575927734375, (804.436, 0.041452333, 210.18016, 0.4041712)
decoder loss ratio: 31165.246200, decoder SINDy loss  ratio: 0.453703
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.494729]
 [ -0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 628.9757690429688, (214.16492, 0.147172, 414.6637, 0.40427437)
   validation loss 355.5103759765625, (155.7605, 0.038636077, 199.71126, 0.40427437)
decoder loss ratio: 6034.432106, decoder SINDy loss  ratio: 0.431105
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.486996]
 [  0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.8436279296875, (314.77475, 0.14137831, 399.9275, 0.40437326)
   validation loss 421.14093017578125, (219.48431, 0.04364284, 201.61296, 0.40437326)
decoder loss ratio: 8503.203365, decoder SINDy loss  ratio: 0.435210
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.526602]
 [ -0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.3814697265625, (228.9337, 0.14186911, 402.30588, 0.40453872)
   validation loss 355.2224426269531, (157.65587, 0.045015547, 197.52156, 0.40453872)
decoder loss ratio: 6107.862049, decoder SINDy loss  ratio: 0.426378
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.534137]
 [  0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 665.0987548828125, (259.85266, 0.15130942, 405.09476, 0.40463254)
   validation loss 385.28765869140625, (187.87184, 0.044825584, 197.37097, 0.40463254)
decoder loss ratio: 7278.481297, decoder SINDy loss  ratio: 0.426053
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.465616]
 [ -0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1145.392822265625, (737.3976, 0.12085106, 407.87445, 0.40465316)
   validation loss 800.3095703125, (581.1424, 0.042749036, 219.12448, 0.40465316)
decoder loss ratio: 22514.465291, decoder SINDy loss  ratio: 0.473011
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.452072]
 [  0.      ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 959.0119018554688, (493.5139, 0.15888393, 465.33914, 0.4047372)
   validation loss 677.5848388671875, (465.09067, 0.03731514, 212.45683, 0.4047372)
decoder loss ratio: 18018.419901, decoder SINDy loss  ratio: 0.458618
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.483562]
 [  0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 907.6524047851562, (503.90695, 0.10146943, 403.64398, 0.40481827)
   validation loss 578.63671875, (367.5375, 0.04129943, 211.05789, 0.40481827)
decoder loss ratio: 14239.041060, decoder SINDy loss  ratio: 0.455598
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [-15.5381775]
 [ -0.       ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 629.747802734375, (225.60979, 0.13578647, 404.0022, 0.40486836)
   validation loss 357.0534973144531, (157.8758, 0.039104108, 199.1386, 0.40486836)
decoder loss ratio: 6116.382323, decoder SINDy loss  ratio: 0.429869
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.490097]
 [ -0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.4996337890625, (210.19646, 0.127414, 410.17578, 0.4049019)
   validation loss 360.79644775390625, (162.40112, 0.037601236, 198.35771, 0.4049019)
decoder loss ratio: 6291.701448, decoder SINDy loss  ratio: 0.428183
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.51388]
 [  0.     ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.0869140625, (223.53015, 0.12877224, 400.428, 0.40500006)
   validation loss 353.4833679199219, (156.08626, 0.043320805, 197.35379, 0.40500006)
decoder loss ratio: 6047.052610, decoder SINDy loss  ratio: 0.426016
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.55147]
 [  0.     ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.4955444335938, (331.64917, 0.14942332, 430.69696, 0.40510342)
   validation loss 488.23681640625, (285.185, 0.045500983, 203.00633, 0.40510342)
decoder loss ratio: 11048.561908, decoder SINDy loss  ratio: 0.438218
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.518507]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.8319702148438, (299.72153, 0.13160896, 401.97882, 0.40512666)
   validation loss 401.24798583984375, (197.85828, 0.041246872, 203.34848, 0.40512666)
decoder loss ratio: 7665.373124, decoder SINDy loss  ratio: 0.438956
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.483278]
 [ -0.      ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1049.194580078125, (647.0127, 0.13475299, 402.04715, 0.40528914)
   validation loss 728.4991455078125, (513.68945, 0.044713102, 214.76498, 0.40528914)
decoder loss ratio: 19901.221218, decoder SINDy loss  ratio: 0.463600
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.512751]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.0527954101562, (238.31209, 0.14176136, 400.59894, 0.40532017)
   validation loss 368.9358825683594, (168.56429, 0.04001822, 200.33157, 0.40532017)
decoder loss ratio: 6530.473052, decoder SINDy loss  ratio: 0.432444
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.53078]
 [  0.     ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.86962890625, (213.51686, 0.13051152, 402.22226, 0.4054118)
   validation loss 348.6377258300781, (150.89957, 0.041218188, 197.69695, 0.4054118)
decoder loss ratio: 5846.111185, decoder SINDy loss  ratio: 0.426757
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.571606]
 [  0.      ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.4459838867188, (217.28072, 0.13674462, 401.02853, 0.40555015)
   validation loss 351.51416015625, (154.93633, 0.04390041, 196.53392, 0.40555015)
decoder loss ratio: 6002.502215, decoder SINDy loss  ratio: 0.424246
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.514725]
 [ -0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.5104370117188, (539.7821, 0.12202072, 400.60632, 0.40561482)
   validation loss 628.5785522460938, (417.55923, 0.042413257, 210.97691, 0.40561482)
decoder loss ratio: 16176.969664, decoder SINDy loss  ratio: 0.455423
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.54419]
 [  0.     ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1011.6080932617188, (569.5767, 0.13741101, 441.89398, 0.4056643)
   validation loss 793.7466430664062, (586.45874, 0.03723618, 207.25067, 0.4056643)
decoder loss ratio: 22720.429734, decoder SINDy loss  ratio: 0.447380
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.605457]
 [ -0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.3250732421875, (356.8533, 0.14235362, 409.32938, 0.40573594)
   validation loss 505.6158447265625, (306.27228, 0.042154584, 199.30142, 0.40573594)
decoder loss ratio: 11865.519755, decoder SINDy loss  ratio: 0.430220
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.519536]
 [  0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.103759765625, (217.6105, 0.13002421, 412.36325, 0.40583426)
   validation loss 363.1478576660156, (164.19295, 0.038679473, 198.91623, 0.40583426)
decoder loss ratio: 6361.119833, decoder SINDy loss  ratio: 0.429389
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.498256]
 [ -0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.6205444335938, (207.63292, 0.12494337, 402.8627, 0.4059077)
   validation loss 347.23748779296875, (149.55692, 0.03991773, 197.64067, 0.4059077)
decoder loss ratio: 5794.094540, decoder SINDy loss  ratio: 0.426635
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.559353]
 [  0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.5677490234375, (209.41933, 0.12996022, 406.01846, 0.40592852)
   validation loss 359.6165771484375, (162.3795, 0.041148566, 197.1959, 0.40592852)
decoder loss ratio: 6290.863785, decoder SINDy loss  ratio: 0.425675
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-15.52962]
 [  0.     ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.5576171875, (311.15152, 0.15380037, 433.25226, 0.40602618)
   validation loss 424.79278564453125, (219.00978, 0.03646733, 205.74654, 0.40602618)
decoder loss ratio: 8484.819129, decoder SINDy loss  ratio: 0.444133
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.59124]
 [ -0.     ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.6002807617188, (350.70483, 0.1576335, 442.73782, 0.4061163)
   validation loss 528.3145141601562, (320.18314, 0.039261293, 208.0921, 0.4061163)
decoder loss ratio: 12404.450550, decoder SINDy loss  ratio: 0.449196
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.558203]
 [ -0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.043701171875, (251.92809, 0.14019579, 428.9754, 0.40613323)
   validation loss 397.69732666015625, (194.85872, 0.036674067, 202.80194, 0.40613323)
decoder loss ratio: 7549.165059, decoder SINDy loss  ratio: 0.437777
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.600268]
 [ -0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 617.4542236328125, (211.81093, 0.12346936, 405.51984, 0.4061707)
   validation loss 362.91754150390625, (165.67633, 0.041711476, 197.19948, 0.4061707)
decoder loss ratio: 6418.588673, decoder SINDy loss  ratio: 0.425683
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.547066]
 [  0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1626.43017578125, (1177.5112, 0.17030086, 448.7487, 0.40613207)
   validation loss 1484.5093994140625, (1269.1052, 0.03671758, 215.36743, 0.40613207)
decoder loss ratio: 49167.339665, decoder SINDy loss  ratio: 0.464901
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.561729]
 [  0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.4716186523438, (226.11557, 0.13036613, 414.22568, 0.40618682)
   validation loss 380.9729919433594, (182.24081, 0.039434608, 198.69275, 0.40618682)
decoder loss ratio: 7060.325526, decoder SINDy loss  ratio: 0.428906
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.53301]
 [ -0.     ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 712.8983154296875, (317.4339, 0.12742218, 395.33698, 0.406238)
   validation loss 420.95709228515625, (220.34235, 0.045045957, 200.56969, 0.406238)
decoder loss ratio: 8536.445023, decoder SINDy loss  ratio: 0.432958
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.553458]
 [  0.      ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 612.3096923828125, (210.14113, 0.12320689, 402.04538, 0.40633497)
   validation loss 348.64825439453125, (151.70497, 0.04258827, 196.90071, 0.40633497)
decoder loss ratio: 5877.313960, decoder SINDy loss  ratio: 0.425038
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-15.65871]
 [  0.     ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.114990234375, (248.40771, 0.121559836, 415.5857, 0.40639082)
   validation loss 380.60205078125, (178.83679, 0.03541494, 201.72986, 0.40639082)
decoder loss ratio: 6928.447796, decoder SINDy loss  ratio: 0.435462
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.602766]
 [ -0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.6959838867188, (366.12198, 0.13946836, 396.43454, 0.4063626)
   validation loss 478.59161376953125, (274.79724, 0.04200326, 203.75238, 0.4063626)
decoder loss ratio: 10646.122194, decoder SINDy loss  ratio: 0.439828
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.510228]
 [  0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 617.6149291992188, (211.35298, 0.12476669, 406.13718, 0.40634164)
   validation loss 352.4456787109375, (154.54967, 0.03960811, 197.8564, 0.40634164)
decoder loss ratio: 5987.522423, decoder SINDy loss  ratio: 0.427101
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.66826]
 [  0.     ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 694.2696533203125, (299.58386, 0.12523597, 394.56058, 0.40630436)
   validation loss 407.64312744140625, (207.88455, 0.044278022, 199.71431, 0.40630436)
decoder loss ratio: 8053.808448, decoder SINDy loss  ratio: 0.431111
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.509452]
 [ -0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.0362548828125, (238.86853, 0.14695439, 398.02078, 0.40637064)
   validation loss 366.95819091796875, (170.75952, 0.046050865, 196.15263, 0.40637064)
decoder loss ratio: 6615.520314, decoder SINDy loss  ratio: 0.423423
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.531862]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1942.52587890625, (1409.6091, 0.16465633, 532.75214, 0.4062937)
   validation loss 1660.117431640625, (1416.1421, 0.032201316, 243.94316, 0.4062937)
decoder loss ratio: 54863.803091, decoder SINDy loss  ratio: 0.526586
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.528913]
 [  0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.9232788085938, (376.95895, 0.13440926, 396.82993, 0.4062108)
   validation loss 474.040283203125, (268.86755, 0.040945213, 205.13176, 0.4062108)
decoder loss ratio: 10416.395805, decoder SINDy loss  ratio: 0.442806
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.608331]
 [  0.      ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 656.166259765625, (260.13965, 0.13008887, 395.8965, 0.4061965)
   validation loss 378.84503173828125, (179.59975, 0.04233285, 199.20297, 0.4061965)
decoder loss ratio: 6958.005986, decoder SINDy loss  ratio: 0.430008
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.484993]
 [  0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.9669189453125, (211.55104, 0.119235896, 399.29666, 0.40615854)
   validation loss 347.460205078125, (150.85957, 0.041006744, 196.55963, 0.40615854)
decoder loss ratio: 5844.561776, decoder SINDy loss  ratio: 0.424302
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.582648]
 [ -0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.6636962890625, (224.63995, 0.13707869, 397.8867, 0.40615463)
   validation loss 355.7891845703125, (160.42772, 0.045171198, 195.31631, 0.40615463)
decoder loss ratio: 6215.248353, decoder SINDy loss  ratio: 0.421618
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.592221]
 [  0.      ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1170.6312255859375, (768.703, 0.0984086, 401.82983, 0.4061129)
   validation loss 830.269287109375, (611.40607, 0.046597768, 218.81667, 0.4061129)
decoder loss ratio: 23686.932479, decoder SINDy loss  ratio: 0.472347
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.52772]
 [  0.     ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.8839721679688, (309.5503, 0.13277176, 395.2009, 0.4060115)
   validation loss 414.13690185546875, (212.63164, 0.04189384, 201.46335, 0.4060115)
decoder loss ratio: 8237.718784, decoder SINDy loss  ratio: 0.434887
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.538644]
 [ -0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 611.9013671875, (209.46834, 0.12135895, 402.31165, 0.4059793)
   validation loss 350.00653076171875, (153.27676, 0.039921258, 196.68985, 0.4059793)
decoder loss ratio: 5938.207934, decoder SINDy loss  ratio: 0.424583
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.5733795]
 [  0.       ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.949951171875, (275.2107, 0.124028735, 393.6152, 0.4059526)
   validation loss 389.92010498046875, (192.04211, 0.04453518, 197.83344, 0.4059526)
decoder loss ratio: 7440.044906, decoder SINDy loss  ratio: 0.427051
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.550876]
 [  0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.029052734375, (222.41002, 0.12684372, 396.49222, 0.40589094)
   validation loss 357.6373291015625, (162.1827, 0.044135336, 195.41052, 0.40589094)
decoder loss ratio: 6283.239107, decoder SINDy loss  ratio: 0.421821
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.5798235]
 [ -0.       ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 959.7142333984375, (516.0713, 0.155744, 443.48718, 0.40590826)
   validation loss 584.2695922851562, (375.26462, 0.040834885, 208.96414, 0.40590826)
decoder loss ratio: 14538.402786, decoder SINDy loss  ratio: 0.451078
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.540292]
 [  0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.4733276367188, (249.97696, 0.13346116, 395.3629, 0.40580168)
   validation loss 372.4136962890625, (173.31421, 0.041644514, 199.05785, 0.40580168)
decoder loss ratio: 6714.493343, decoder SINDy loss  ratio: 0.429694
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.565542]
 [ -0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.4048461914062, (209.21744, 0.12589802, 401.06152, 0.40581995)
   validation loss 346.57415771484375, (149.47849, 0.04074046, 197.05495, 0.40581995)
decoder loss ratio: 5791.056019, decoder SINDy loss  ratio: 0.425371
params['save_name']
pendulum_2023_10_25_04_17_09_112959
