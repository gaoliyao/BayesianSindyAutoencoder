nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2023-11-11 05:23:21.050822: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-11-11 05:23:21.058219: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2023-11-11 05:23:21.060040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564ce6c9ed30 executing computations on platform Host. Devices:
2023-11-11 05:23:21.060076: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-11-11 05:23:21.061936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2023-11-11 05:23:21.160632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564ce6e12480 executing computations on platform CUDA. Devices:
2023-11-11 05:23:21.160695: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2023-11-11 05:23:21.161664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2023-11-11 05:23:21.162013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-11 05:23:21.163672: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2023-11-11 05:23:21.166150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2023-11-11 05:23:21.166456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2023-11-11 05:23:21.169568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2023-11-11 05:23:21.170476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2023-11-11 05:23:21.174458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2023-11-11 05:23:21.175105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2023-11-11 05:23:21.175145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2023-11-11 05:23:21.175494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-11-11 05:23:21.175503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2023-11-11 05:23:21.175508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2023-11-11 05:23:21.176065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2023-11-11 05:23:22.260683: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders_rebuttal/examples/rebuttal_real_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 4001, 'refinement_epochs': 4001, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 1.2, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8215527534484863 seconds for one epoch ---
463.2545009394289
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 117401.96875, (107801.01, 0.008958126, 9583.657, 2.5317829)
   validation loss 87727.4765625, (86509.414, 0.0053680907, 1200.7596, 2.5317829)
decoder loss ratio: 3351524.887729, decoder SINDy loss  ratio: 2.592009
--- 0.25676488876342773 seconds for one epoch ---
--- 0.1974952220916748 seconds for one epoch ---
--- 0.29011988639831543 seconds for one epoch ---
--- 0.29257869720458984 seconds for one epoch ---
--- 0.29654765129089355 seconds for one epoch ---
--- 0.29181456565856934 seconds for one epoch ---
--- 0.30808568000793457 seconds for one epoch ---
--- 0.29365110397338867 seconds for one epoch ---
--- 0.3100423812866211 seconds for one epoch ---
--- 0.2984764575958252 seconds for one epoch ---
--- 0.30350303649902344 seconds for one epoch ---
--- 0.2938394546508789 seconds for one epoch ---
--- 0.2966878414154053 seconds for one epoch ---
--- 0.2896280288696289 seconds for one epoch ---
--- 0.30437588691711426 seconds for one epoch ---
--- 0.2882671356201172 seconds for one epoch ---
--- 0.3077554702758789 seconds for one epoch ---
--- 0.28966403007507324 seconds for one epoch ---
--- 0.1806015968322754 seconds for one epoch ---
--- 0.24646401405334473 seconds for one epoch ---
--- 0.31358814239501953 seconds for one epoch ---
--- 0.30075645446777344 seconds for one epoch ---
--- 0.3104395866394043 seconds for one epoch ---
--- 0.2947840690612793 seconds for one epoch ---
=========================
[[0.77852833]
 [0.7775561 ]
 [0.781288  ]
 [0.77841854]
 [0.77618724]
 [0.778822  ]
 [0.77803534]
 [0.7759035 ]
 [0.77555865]
 [0.7853924 ]
 [0.77626735]]
[[ 6.5688682e-01]
 [ 4.7457951e-01]
 [-1.0751631e+00]
 [-6.3739336e-01]
 [-1.6874628e-01]
 [-7.0767689e-01]
 [ 5.6739777e-01]
 [-9.5688730e-02]
 [ 1.2165699e-03]
 [-1.5383575e+00]
 [ 1.8864657e-01]]
--- 0.25896716117858887 seconds for one epoch ---
463.2545009394289
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 57656.1640625, (49524.973, 42.660572, 8053.9053, 2.5317376)
   validation loss 47418.0703125, (46051.113, 20.979738, 1311.3525, 2.5317376)
decoder loss ratio: 1784100.076764, decoder SINDy loss  ratio: 2.830739
--- 0.2938351631164551 seconds for one epoch ---
--- 0.30962061882019043 seconds for one epoch ---
--- 0.2929110527038574 seconds for one epoch ---
--- 0.3105483055114746 seconds for one epoch ---
--- 0.28330421447753906 seconds for one epoch ---
--- 0.30829572677612305 seconds for one epoch ---
--- 0.2908620834350586 seconds for one epoch ---
--- 0.31572389602661133 seconds for one epoch ---
--- 0.2939155101776123 seconds for one epoch ---
--- 0.229400634765625 seconds for one epoch ---
--- 0.23802947998046875 seconds for one epoch ---
--- 0.2936887741088867 seconds for one epoch ---
--- 0.28469395637512207 seconds for one epoch ---
--- 0.3137931823730469 seconds for one epoch ---
--- 0.284151554107666 seconds for one epoch ---
--- 0.3070251941680908 seconds for one epoch ---
--- 0.29075169563293457 seconds for one epoch ---
--- 0.31868886947631836 seconds for one epoch ---
--- 0.2962512969970703 seconds for one epoch ---
--- 0.32369399070739746 seconds for one epoch ---
--- 0.28482913970947266 seconds for one epoch ---
--- 0.3153269290924072 seconds for one epoch ---
--- 0.2954075336456299 seconds for one epoch ---
--- 0.3063969612121582 seconds for one epoch ---
=========================
[[0.62849545]
 [0.6175614 ]
 [0.62356853]
 [0.61704934]
 [0.61608845]
 [0.6238404 ]
 [0.61813504]
 [0.6163386 ]
 [0.6160268 ]
 [0.6205597 ]
 [0.616907  ]]
[[ 1.2682613 ]
 [ 0.23527539]
 [-0.8903978 ]
 [-0.16196658]
 [ 0.01246447]
 [-0.91395485]
 [ 0.3130272 ]
 [ 0.05305788]
 [ 0.00232919]
 [-0.60009545]
 [ 0.14085743]]
--- 0.28241634368896484 seconds for one epoch ---
463.2545009394289
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 53435.7109375, (41747.203, 12.919531, 11626.368, 2.5317104)
   validation loss 38379.82421875, (37176.39, 4.519293, 1149.6927, 2.5317104)
decoder loss ratio: 1440277.913865, decoder SINDy loss  ratio: 2.481774
--- 0.1436469554901123 seconds for one epoch ---
--- 0.20607542991638184 seconds for one epoch ---
--- 0.30370450019836426 seconds for one epoch ---
--- 0.29505252838134766 seconds for one epoch ---
--- 0.32187819480895996 seconds for one epoch ---
--- 0.2960679531097412 seconds for one epoch ---
--- 0.3184969425201416 seconds for one epoch ---
--- 0.298675537109375 seconds for one epoch ---
--- 0.32268667221069336 seconds for one epoch ---
--- 0.28891801834106445 seconds for one epoch ---
--- 0.3185749053955078 seconds for one epoch ---
--- 0.2935974597930908 seconds for one epoch ---
--- 0.3209242820739746 seconds for one epoch ---
--- 0.2855980396270752 seconds for one epoch ---
--- 0.3214704990386963 seconds for one epoch ---
--- 0.37532711029052734 seconds for one epoch ---
--- 0.28097057342529297 seconds for one epoch ---
--- 0.19969677925109863 seconds for one epoch ---
--- 0.3203246593475342 seconds for one epoch ---
--- 0.2910923957824707 seconds for one epoch ---
--- 0.32201576232910156 seconds for one epoch ---
--- 0.2918572425842285 seconds for one epoch ---
--- 0.32640981674194336 seconds for one epoch ---
--- 0.2923703193664551 seconds for one epoch ---
=========================
[[0.5026342 ]
 [0.48332655]
 [0.48877254]
 [0.4832454 ]
 [0.48282534]
 [0.4993524 ]
 [0.4841317 ]
 [0.4835771 ]
 [0.48241356]
 [0.48246738]
 [0.48273814]]
[[ 1.4317774 ]
 [ 0.11181756]
 [-0.6208767 ]
 [ 0.10257694]
 [ 0.05376438]
 [-1.2756015 ]
 [ 0.20009166]
 [ 0.13994268]
 [ 0.00412966]
 [-0.0107472 ]
 [ 0.04340194]]
--- 0.25359630584716797 seconds for one epoch ---
463.2545009394289
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 25545.513671875, (21095.322, 10.48122, 4374.771, 2.5317087)
   validation loss 17470.724609375, (16339.023, 1.03223, 1065.7285, 2.5317087)
decoder loss ratio: 633002.133761, decoder SINDy loss  ratio: 2.300525
--- 0.29535984992980957 seconds for one epoch ---
--- 0.3323173522949219 seconds for one epoch ---
--- 0.29706907272338867 seconds for one epoch ---
--- 0.3309011459350586 seconds for one epoch ---
--- 0.2885737419128418 seconds for one epoch ---
--- 0.3298206329345703 seconds for one epoch ---
--- 0.2842214107513428 seconds for one epoch ---
--- 0.23864054679870605 seconds for one epoch ---
--- 0.2886025905609131 seconds for one epoch ---
--- 0.326763391494751 seconds for one epoch ---
--- 0.2955749034881592 seconds for one epoch ---
--- 0.3299832344055176 seconds for one epoch ---
--- 0.2972829341888428 seconds for one epoch ---
--- 0.3341491222381592 seconds for one epoch ---
--- 0.29427552223205566 seconds for one epoch ---
--- 0.3261752128601074 seconds for one epoch ---
--- 0.3022301197052002 seconds for one epoch ---
--- 0.33342719078063965 seconds for one epoch ---
--- 0.29027223587036133 seconds for one epoch ---
--- 0.3432955741882324 seconds for one epoch ---
--- 0.2986724376678467 seconds for one epoch ---
--- 0.35134053230285645 seconds for one epoch ---
--- 0.2774651050567627 seconds for one epoch ---
--- 0.3607776165008545 seconds for one epoch ---
=========================
[[0.4049866 ]
 [0.38834044]
 [0.39043447]
 [0.38876742]
 [0.3872053 ]
 [0.4199301 ]
 [0.3883871 ]
 [0.3886305 ]
 [0.38681924]
 [0.3894473 ]
 [0.38834697]]
[[ 1.1921147 ]
 [ 0.15119712]
 [-0.33295783]
 [ 0.19028488]
 [ 0.04133859]
 [-1.7476934 ]
 [ 0.15550777]
 [ 0.17785025]
 [ 0.00184401]
 [ 0.2502794 ]
 [ 0.15180123]]
--- 0.28977108001708984 seconds for one epoch ---
463.2545009394289
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 19773.353515625, (14729.255, 8.084964, 4957.227, 2.5317178)
   validation loss 13227.7314453125, (12222.712, 0.9181771, 925.3154, 2.5317178)
decoder loss ratio: 473529.079112, decoder SINDy loss  ratio: 1.997424
--- 0.2578444480895996 seconds for one epoch ---
--- 0.2984476089477539 seconds for one epoch ---
--- 0.3386096954345703 seconds for one epoch ---
--- 0.2946169376373291 seconds for one epoch ---
--- 0.33994030952453613 seconds for one epoch ---
--- 0.29381346702575684 seconds for one epoch ---
--- 0.3371927738189697 seconds for one epoch ---
--- 0.28978824615478516 seconds for one epoch ---
--- 0.3289940357208252 seconds for one epoch ---
--- 0.3026723861694336 seconds for one epoch ---
--- 0.3481144905090332 seconds for one epoch ---
--- 0.29242992401123047 seconds for one epoch ---
--- 0.22852826118469238 seconds for one epoch ---
--- 0.2916679382324219 seconds for one epoch ---
--- 0.3533158302307129 seconds for one epoch ---
--- 0.2930147647857666 seconds for one epoch ---
--- 0.34491825103759766 seconds for one epoch ---
--- 0.2887532711029053 seconds for one epoch ---
--- 0.34955716133117676 seconds for one epoch ---
--- 0.29355812072753906 seconds for one epoch ---
--- 0.35132622718811035 seconds for one epoch ---
--- 0.29779887199401855 seconds for one epoch ---
--- 0.3587324619293213 seconds for one epoch ---
--- 0.2958800792694092 seconds for one epoch ---
=========================
[[0.32050467]
 [0.307788  ]
 [0.30818385]
 [0.3091614 ]
 [0.30715084]
 [0.35771284]
 [0.30788094]
 [0.30840006]
 [0.30625987]
 [0.30917972]
 [0.30847046]]
[[ 9.1894013e-01]
 [ 1.3375430e-01]
 [-1.6629279e-01]
 [ 2.4342386e-01]
 [ 7.9688206e-02]
 [-2.0975459e+00]
 [ 1.4146942e-01]
 [ 1.8373448e-01]
 [ 1.5337387e-04]
 [ 2.4483477e-01]
 [ 1.8936379e-01]]
--- 0.2585408687591553 seconds for one epoch ---
463.2545009394289
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 19067.888671875, (11630.451, 12.232623, 7333.911, 2.5317247)
   validation loss 9186.318359375, (8230.068, 0.5769924, 864.3783, 2.5317247)
decoder loss ratio: 318847.136269, decoder SINDy loss  ratio: 1.865882
--- 0.30292296409606934 seconds for one epoch ---
--- 0.23552417755126953 seconds for one epoch ---
--- 0.19528460502624512 seconds for one epoch ---
--- 0.3805258274078369 seconds for one epoch ---
--- 0.29059743881225586 seconds for one epoch ---
--- 0.34845972061157227 seconds for one epoch ---
--- 0.29453492164611816 seconds for one epoch ---
--- 0.3622403144836426 seconds for one epoch ---
--- 0.2985224723815918 seconds for one epoch ---
--- 0.3568747043609619 seconds for one epoch ---
--- 0.3043234348297119 seconds for one epoch ---
--- 0.3729839324951172 seconds for one epoch ---
--- 0.294597864151001 seconds for one epoch ---
--- 0.35741686820983887 seconds for one epoch ---
--- 0.30890607833862305 seconds for one epoch ---
--- 0.3785390853881836 seconds for one epoch ---
--- 0.30823349952697754 seconds for one epoch ---
--- 0.37018489837646484 seconds for one epoch ---
--- 0.2135167121887207 seconds for one epoch ---
--- 0.35436081886291504 seconds for one epoch ---
--- 0.29050230979919434 seconds for one epoch ---
--- 0.3537478446960449 seconds for one epoch ---
--- 0.29123902320861816 seconds for one epoch ---
--- 0.3649115562438965 seconds for one epoch ---
=========================
[[0.25967768]
 [0.2496104 ]
 [0.25077873]
 [0.25161824]
 [0.24874808]
 [0.31594014]
 [0.25023863]
 [0.2505759 ]
 [0.24832639]
 [0.250855  ]
 [0.2510939 ]]
[[ 7.2932553e-01]
 [ 1.0665345e-01]
 [-1.9517840e-01]
 [ 2.5542420e-01]
 [ 3.7321959e-02]
 [-2.3307679e+00]
 [ 1.5497674e-01]
 [ 1.8022555e-01]
 [-2.0724100e-03]
 [ 2.0078467e-01]
 [ 2.1811143e-01]]
--- 0.2925581932067871 seconds for one epoch ---
463.2545009394289
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10358.205078125, (6888.1606, 1.5366845, 3365.5518, 2.531731)
   validation loss 6814.34912109375, (5931.104, 0.4502352, 779.8387, 2.531731)
decoder loss ratio: 229781.265961, decoder SINDy loss  ratio: 1.683391
--- 0.26072096824645996 seconds for one epoch ---
--- 0.29692530632019043 seconds for one epoch ---
--- 0.37186455726623535 seconds for one epoch ---
--- 0.2939772605895996 seconds for one epoch ---
--- 0.3546621799468994 seconds for one epoch ---
--- 0.2929821014404297 seconds for one epoch ---
--- 0.3496387004852295 seconds for one epoch ---
--- 0.19661402702331543 seconds for one epoch ---
--- 0.3550105094909668 seconds for one epoch ---
--- 0.2952897548675537 seconds for one epoch ---
--- 0.3585546016693115 seconds for one epoch ---
--- 0.28873753547668457 seconds for one epoch ---
--- 0.3688347339630127 seconds for one epoch ---
--- 0.2891969680786133 seconds for one epoch ---
--- 0.3578314781188965 seconds for one epoch ---
--- 0.29718899726867676 seconds for one epoch ---
--- 0.35626840591430664 seconds for one epoch ---
--- 0.30967116355895996 seconds for one epoch ---
--- 0.39238548278808594 seconds for one epoch ---
--- 0.2922515869140625 seconds for one epoch ---
--- 0.3622913360595703 seconds for one epoch ---
--- 0.293532133102417 seconds for one epoch ---
--- 0.2587893009185791 seconds for one epoch ---
--- 0.2297837734222412 seconds for one epoch ---
=========================
[[0.2078624 ]
 [0.19938053]
 [0.20150709]
 [0.2024704 ]
 [0.19941412]
 [0.282008  ]
 [0.20111994]
 [0.20178728]
 [0.19923161]
 [0.20088321]
 [0.20207125]]
[[ 0.55879575]
 [-0.01640783]
 [-0.17403516]
 [ 0.23978896]
 [ 0.01905108]
 [-2.508828  ]
 [ 0.1466894 ]
 [ 0.19349289]
 [-0.00461475]
 [ 0.12967135]
 [ 0.21292657]]
--- 0.24150896072387695 seconds for one epoch ---
463.2545009394289
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 17836.466796875, (5704.093, 1.7767156, 12018.102, 2.5317345)
   validation loss 3918.56005859375, (3108.8293, 0.34883174, 696.88544, 2.5317345)
decoder loss ratio: 120441.446018, decoder SINDy loss  ratio: 1.504325
--- 0.2919950485229492 seconds for one epoch ---
--- 0.35785555839538574 seconds for one epoch ---
--- 0.28995442390441895 seconds for one epoch ---
--- 0.37036943435668945 seconds for one epoch ---
--- 0.29799509048461914 seconds for one epoch ---
--- 0.3832430839538574 seconds for one epoch ---
--- 0.2778739929199219 seconds for one epoch ---
--- 0.370084285736084 seconds for one epoch ---
--- 0.29609036445617676 seconds for one epoch ---
--- 0.38863253593444824 seconds for one epoch ---
--- 0.2937150001525879 seconds for one epoch ---
--- 0.29071640968322754 seconds for one epoch ---
--- 0.22014093399047852 seconds for one epoch ---
--- 0.38126063346862793 seconds for one epoch ---
--- 0.29380178451538086 seconds for one epoch ---
--- 0.39064931869506836 seconds for one epoch ---
--- 0.2899284362792969 seconds for one epoch ---
--- 0.39986085891723633 seconds for one epoch ---
--- 0.3041036128997803 seconds for one epoch ---
--- 0.3963782787322998 seconds for one epoch ---
--- 0.28882312774658203 seconds for one epoch ---
--- 0.3799278736114502 seconds for one epoch ---
--- 0.2972080707550049 seconds for one epoch ---
--- 0.3927803039550781 seconds for one epoch ---
=========================
[[0.16974328]
 [0.16478896]
 [0.16545133]
 [0.16676621]
 [0.16365851]
 [0.2603009 ]
 [0.16591202]
 [0.16640398]
 [0.16366726]
 [0.16417275]
 [0.16751945]]
[[ 0.40115583]
 [-0.08671114]
 [-0.13322464]
 [ 0.22106266]
 [ 0.00337622]
 [-2.6571195 ]
 [ 0.16466038]
 [ 0.19743448]
 [-0.00401607]
 [ 0.0419184 ]
 [ 0.2689236 ]]
--- 0.2765614986419678 seconds for one epoch ---
463.2545009394289
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10706.2666015625, (4681.291, 1.9798374, 5901.7886, 2.53174)
   validation loss 4398.85009765625, (3578.385, 0.3924404, 698.8666, 2.53174)
decoder loss ratio: 138632.847628, decoder SINDy loss  ratio: 1.508602
--- 0.24734807014465332 seconds for one epoch ---
--- 0.30135250091552734 seconds for one epoch ---
--- 0.3817718029022217 seconds for one epoch ---
--- 0.29877758026123047 seconds for one epoch ---
--- 0.3809623718261719 seconds for one epoch ---
--- 0.2955136299133301 seconds for one epoch ---
--- 0.3982269763946533 seconds for one epoch ---
--- 0.2934417724609375 seconds for one epoch ---
--- 0.40007901191711426 seconds for one epoch ---
--- 0.2904853820800781 seconds for one epoch ---
--- 0.3935215473175049 seconds for one epoch ---
--- 0.28904175758361816 seconds for one epoch ---
--- 0.3899831771850586 seconds for one epoch ---
--- 0.2912459373474121 seconds for one epoch ---
--- 0.31256914138793945 seconds for one epoch ---
--- 0.3203403949737549 seconds for one epoch ---
--- 0.39390063285827637 seconds for one epoch ---
--- 0.3021419048309326 seconds for one epoch ---
--- 0.3822305202484131 seconds for one epoch ---
--- 0.29309511184692383 seconds for one epoch ---
--- 0.4100196361541748 seconds for one epoch ---
--- 0.3026442527770996 seconds for one epoch ---
--- 0.4187445640563965 seconds for one epoch ---
--- 0.2956728935241699 seconds for one epoch ---
=========================
[[0.13712466]
 [0.1356007 ]
 [0.13498372]
 [0.13732973]
 [0.1333123 ]
 [0.23926765]
 [0.135209  ]
 [0.13620855]
 [0.13335949]
 [0.13439599]
 [0.13847248]]
[[ 2.55667716e-01]
 [-1.59625888e-01]
 [-1.18711025e-01]
 [ 2.68089831e-01]
 [ 1.13968051e-03]
 [-2.73411512e+00]
 [ 1.33793414e-01]
 [ 1.98750883e-01]
 [-4.59852489e-03]
 [-7.85324723e-02]
 [ 3.35292965e-01]]
--- 0.2539336681365967 seconds for one epoch ---
463.2545009394289
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4360.93994140625, (2690.8923, 0.45329726, 1539.748, 2.5317447)
   validation loss 3378.805419921875, (2661.7644, 0.29911673, 586.8958, 2.5317447)
decoder loss ratio: 103121.374049, decoder SINDy loss  ratio: 1.266897
--- 0.2965843677520752 seconds for one epoch ---
--- 0.3942997455596924 seconds for one epoch ---
--- 0.17387771606445312 seconds for one epoch ---
--- 0.4143640995025635 seconds for one epoch ---
--- 0.30368566513061523 seconds for one epoch ---
--- 0.405214786529541 seconds for one epoch ---
--- 0.29605984687805176 seconds for one epoch ---
--- 0.3983643054962158 seconds for one epoch ---
--- 0.2957301139831543 seconds for one epoch ---
--- 0.39409732818603516 seconds for one epoch ---
--- 0.30026674270629883 seconds for one epoch ---
--- 0.4149210453033447 seconds for one epoch ---
--- 0.29831552505493164 seconds for one epoch ---
--- 0.4084153175354004 seconds for one epoch ---
--- 0.29639697074890137 seconds for one epoch ---
--- 0.400346040725708 seconds for one epoch ---
--- 0.2799255847930908 seconds for one epoch ---
--- 0.3155488967895508 seconds for one epoch ---
--- 0.2653069496154785 seconds for one epoch ---
--- 0.4189627170562744 seconds for one epoch ---
--- 0.30211496353149414 seconds for one epoch ---
--- 0.4164259433746338 seconds for one epoch ---
--- 0.3101329803466797 seconds for one epoch ---
--- 0.414487361907959 seconds for one epoch ---
=========================
[[0.11355809]
 [0.11462146]
 [0.11352836]
 [0.11560422]
 [0.11130672]
 [0.2202438 ]
 [0.11342542]
 [0.11428411]
 [0.11124963]
 [0.11374833]
 [0.11686093]]
[[ 1.5761638e-01]
 [-2.2379693e-01]
 [-1.5571938e-01]
 [ 2.8221229e-01]
 [ 5.6880829e-03]
 [-2.7385433e+00]
 [ 1.4912121e-01]
 [ 2.0314355e-01]
 [-1.5961477e-03]
 [-1.6969213e-01]
 [ 3.5343459e-01]]
--- 0.29936814308166504 seconds for one epoch ---
463.2545009394289
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7718.71826171875, (3336.899, 0.84872144, 4244.4004, 2.5317466)
   validation loss 3797.91845703125, (3113.785, 0.31416324, 547.24927, 2.5317466)
decoder loss ratio: 120633.433263, decoder SINDy loss  ratio: 1.181315
--- 0.24665284156799316 seconds for one epoch ---
--- 0.29167985916137695 seconds for one epoch ---
--- 0.3995084762573242 seconds for one epoch ---
--- 0.29166436195373535 seconds for one epoch ---
--- 0.3801705837249756 seconds for one epoch ---
--- 0.18689823150634766 seconds for one epoch ---
--- 0.3979029655456543 seconds for one epoch ---
--- 0.2977728843688965 seconds for one epoch ---
--- 0.40483975410461426 seconds for one epoch ---
--- 0.28798437118530273 seconds for one epoch ---
--- 0.42345428466796875 seconds for one epoch ---
--- 0.3035695552825928 seconds for one epoch ---
--- 0.4309382438659668 seconds for one epoch ---
--- 0.2945518493652344 seconds for one epoch ---
--- 0.41844987869262695 seconds for one epoch ---
--- 0.29291439056396484 seconds for one epoch ---
--- 0.420851469039917 seconds for one epoch ---
--- 0.2973170280456543 seconds for one epoch ---
--- 0.4093310832977295 seconds for one epoch ---
--- 0.22330713272094727 seconds for one epoch ---
--- 0.4163050651550293 seconds for one epoch ---
--- 0.2951700687408447 seconds for one epoch ---
--- 0.4138143062591553 seconds for one epoch ---
--- 0.28595829010009766 seconds for one epoch ---
=========================
[[0.0925456 ]
 [0.09651121]
 [0.09464863]
 [0.09677409]
 [0.09242843]
 [0.20629449]
 [0.09481075]
 [0.09556963]
 [0.09238645]
 [0.0972853 ]
 [0.09905629]]
[[ 0.01682803]
 [-0.26710436]
 [-0.15532091]
 [ 0.28216657]
 [ 0.00867245]
 [-2.7713573 ]
 [ 0.16543637]
 [ 0.21175699]
 [-0.00573511]
 [-0.310982  ]
 [ 0.4063643 ]]
--- 0.2484114170074463 seconds for one epoch ---
463.2545009394289
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7570.8017578125, (3788.838, 1.4920748, 3637.5984, 2.5317507)
   validation loss 2777.88671875, (2039.7839, 0.27015123, 594.9595, 2.5317507)
decoder loss ratio: 79024.770884, decoder SINDy loss  ratio: 1.284304
--- 0.30208253860473633 seconds for one epoch ---
--- 0.4223024845123291 seconds for one epoch ---
--- 0.30719709396362305 seconds for one epoch ---
--- 0.42319488525390625 seconds for one epoch ---
--- 0.29538822174072266 seconds for one epoch ---
--- 0.402843713760376 seconds for one epoch ---
--- 0.190263032913208 seconds for one epoch ---
--- 0.4230172634124756 seconds for one epoch ---
--- 0.2960543632507324 seconds for one epoch ---
--- 0.4536712169647217 seconds for one epoch ---
--- 0.2901730537414551 seconds for one epoch ---
--- 0.4311254024505615 seconds for one epoch ---
--- 0.294605016708374 seconds for one epoch ---
--- 0.4450194835662842 seconds for one epoch ---
--- 0.3027646541595459 seconds for one epoch ---
--- 0.41148996353149414 seconds for one epoch ---
--- 0.297879695892334 seconds for one epoch ---
--- 0.41988682746887207 seconds for one epoch ---
--- 0.28147268295288086 seconds for one epoch ---
--- 0.4547278881072998 seconds for one epoch ---
--- 0.20310378074645996 seconds for one epoch ---
--- 0.4172179698944092 seconds for one epoch ---
--- 0.2690248489379883 seconds for one epoch ---
--- 0.4224405288696289 seconds for one epoch ---
=========================
[[0.08030052]
 [0.08339711]
 [0.08137567]
 [0.08296321]
 [0.07891493]
 [0.19475658]
 [0.0814032 ]
 [0.08182065]
 [0.07852134]
 [0.08643985]
 [0.08483699]]
[[-0.12213422]
 [-0.304801  ]
 [-0.18839902]
 [ 0.28063735]
 [ 0.03162211]
 [-2.7782934 ]
 [ 0.19004524]
 [ 0.21489067]
 [-0.00473859]
 [-0.46321428]
 [ 0.3820367 ]]
--- 0.2935044765472412 seconds for one epoch ---
463.2545009394289
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6048.81298828125, (2555.3755, 5.165275, 3339.719, 2.5317557)
   validation loss 2147.81787109375, (1542.243, 0.2789378, 456.74246, 2.5317557)
decoder loss ratio: 59749.172898, decoder SINDy loss  ratio: 0.985943
--- 0.2756500244140625 seconds for one epoch ---
--- 0.2954444885253906 seconds for one epoch ---
--- 0.44354677200317383 seconds for one epoch ---
--- 0.31790590286254883 seconds for one epoch ---
--- 0.4567134380340576 seconds for one epoch ---
--- 0.28781700134277344 seconds for one epoch ---
--- 0.3139667510986328 seconds for one epoch ---
--- 0.20295500755310059 seconds for one epoch ---
--- 0.4306931495666504 seconds for one epoch ---
--- 0.2990891933441162 seconds for one epoch ---
--- 0.42102885246276855 seconds for one epoch ---
--- 0.2865750789642334 seconds for one epoch ---
--- 0.41714048385620117 seconds for one epoch ---
--- 0.2957777976989746 seconds for one epoch ---
--- 0.4373314380645752 seconds for one epoch ---
--- 0.30661845207214355 seconds for one epoch ---
--- 0.44072651863098145 seconds for one epoch ---
--- 0.2970418930053711 seconds for one epoch ---
--- 0.4329359531402588 seconds for one epoch ---
--- 0.29327964782714844 seconds for one epoch ---
--- 0.4206564426422119 seconds for one epoch ---
--- 0.1583876609802246 seconds for one epoch ---
--- 0.41334009170532227 seconds for one epoch ---
--- 0.286057710647583 seconds for one epoch ---
=========================
[[0.07050954]
 [0.07148771]
 [0.07019774]
 [0.07136402]
 [0.06684157]
 [0.18302812]
 [0.06939062]
 [0.06998404]
 [0.06651637]
 [0.07783219]
 [0.07329261]]
[[-2.4864064e-01]
 [-3.0307341e-01]
 [-2.3082143e-01]
 [ 2.9630619e-01]
 [ 2.2406274e-02]
 [-2.7628398e+00]
 [ 1.8357509e-01]
 [ 2.1847133e-01]
 [-3.7099578e-04]
 [-6.1186612e-01]
 [ 3.9815587e-01]]
--- 0.2639033794403076 seconds for one epoch ---
463.2545009394289
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4944.150390625, (4058.236, 0.21580835, 732.22845, 2.53176)
   validation loss 4082.1123046875, (3513.7974, 0.22850737, 414.6161, 2.53176)
decoder loss ratio: 136130.610074, decoder SINDy loss  ratio: 0.895007
--- 0.28423404693603516 seconds for one epoch ---
--- 0.42957258224487305 seconds for one epoch ---
--- 0.29734277725219727 seconds for one epoch ---
--- 0.45349740982055664 seconds for one epoch ---
--- 0.29023313522338867 seconds for one epoch ---
--- 0.4395277500152588 seconds for one epoch ---
--- 0.3077116012573242 seconds for one epoch ---
--- 0.430145263671875 seconds for one epoch ---
--- 0.29251599311828613 seconds for one epoch ---
--- 0.45860981941223145 seconds for one epoch ---
--- 0.2960927486419678 seconds for one epoch ---
--- 0.4421069622039795 seconds for one epoch ---
--- 0.28844547271728516 seconds for one epoch ---
--- 0.4677269458770752 seconds for one epoch ---
--- 0.3030881881713867 seconds for one epoch ---
--- 0.44403648376464844 seconds for one epoch ---
--- 0.3076767921447754 seconds for one epoch ---
--- 0.44984912872314453 seconds for one epoch ---
--- 0.30685901641845703 seconds for one epoch ---
--- 0.4453551769256592 seconds for one epoch ---
--- 0.27294206619262695 seconds for one epoch ---
--- 0.5096099376678467 seconds for one epoch ---
--- 0.30001235008239746 seconds for one epoch ---
--- 0.45058417320251465 seconds for one epoch ---
=========================
[[0.06412502]
 [0.06331941]
 [0.06196937]
 [0.06285729]
 [0.05819916]
 [0.1733428 ]
 [0.06026606]
 [0.0612704 ]
 [0.05781804]
 [0.07304276]
 [0.06589044]]
[[-0.37569278]
 [-0.33377048]
 [-0.26050404]
 [ 0.30912828]
 [ 0.03196624]
 [-2.739047  ]
 [ 0.16203168]
 [ 0.22095619]
 [-0.00653456]
 [-0.770987  ]
 [ 0.4633297 ]]
--- 0.3064596652984619 seconds for one epoch ---
463.2545009394289
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11711.19921875, (5067.564, 9.185762, 6476.642, 2.531766)
   validation loss 3242.450439453125, (2721.303, 0.23749672, 363.1024, 2.531766)
decoder loss ratio: 105428.001777, decoder SINDy loss  ratio: 0.783808
--- 0.2585160732269287 seconds for one epoch ---
--- 0.30390310287475586 seconds for one epoch ---
--- 0.42966270446777344 seconds for one epoch ---
--- 0.32519984245300293 seconds for one epoch ---
--- 0.44729089736938477 seconds for one epoch ---
--- 0.31119775772094727 seconds for one epoch ---
--- 0.33387207984924316 seconds for one epoch ---
--- 0.27179384231567383 seconds for one epoch ---
--- 0.4295387268066406 seconds for one epoch ---
--- 0.277618408203125 seconds for one epoch ---
--- 0.442429780960083 seconds for one epoch ---
--- 0.30414390563964844 seconds for one epoch ---
--- 0.4506564140319824 seconds for one epoch ---
--- 0.29933786392211914 seconds for one epoch ---
--- 0.4673142433166504 seconds for one epoch ---
--- 0.29108619689941406 seconds for one epoch ---
--- 0.46003031730651855 seconds for one epoch ---
--- 0.30355334281921387 seconds for one epoch ---
--- 0.47812461853027344 seconds for one epoch ---
--- 0.2891860008239746 seconds for one epoch ---
--- 0.4461958408355713 seconds for one epoch ---
--- 0.2980201244354248 seconds for one epoch ---
--- 0.4632875919342041 seconds for one epoch ---
--- 0.3034505844116211 seconds for one epoch ---
=========================
[[0.05909939]
 [0.05611702]
 [0.05453881]
 [0.05463186]
 [0.05048251]
 [0.16618018]
 [0.05245119]
 [0.05347034]
 [0.05011241]
 [0.06926516]
 [0.05902433]]
[[-4.9917838e-01]
 [-3.5305762e-01]
 [-2.6895261e-01]
 [ 2.7406031e-01]
 [ 2.5239969e-02]
 [-2.7333314e+00]
 [ 1.4904200e-01]
 [ 2.0891617e-01]
 [-6.2516297e-04]
 [-9.0694523e-01]
 [ 4.9568146e-01]]
--- 0.27226829528808594 seconds for one epoch ---
463.2545009394289
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5177.005859375, (2228.6868, 1.6261829, 2784.415, 2.5317712)
   validation loss 2744.643798828125, (2237.3643, 0.26761276, 344.7342, 2.5317712)
decoder loss ratio: 86679.375583, decoder SINDy loss  ratio: 0.744157
--- 0.3035423755645752 seconds for one epoch ---
--- 0.4733896255493164 seconds for one epoch ---
--- 0.30385398864746094 seconds for one epoch ---
--- 0.49084949493408203 seconds for one epoch ---
--- 0.2682526111602783 seconds for one epoch ---
--- 0.500072717666626 seconds for one epoch ---
--- 0.3006565570831299 seconds for one epoch ---
--- 0.48798274993896484 seconds for one epoch ---
--- 0.2959303855895996 seconds for one epoch ---
--- 0.45337557792663574 seconds for one epoch ---
--- 0.3075697422027588 seconds for one epoch ---
--- 0.47720789909362793 seconds for one epoch ---
--- 0.2872626781463623 seconds for one epoch ---
--- 0.4637141227722168 seconds for one epoch ---
--- 0.29859042167663574 seconds for one epoch ---
--- 0.47037839889526367 seconds for one epoch ---
--- 0.29584240913391113 seconds for one epoch ---
--- 0.44243764877319336 seconds for one epoch ---
--- 0.1911940574645996 seconds for one epoch ---
--- 0.5018472671508789 seconds for one epoch ---
--- 0.30542755126953125 seconds for one epoch ---
--- 0.47006702423095703 seconds for one epoch ---
--- 0.2998631000518799 seconds for one epoch ---
--- 0.4850003719329834 seconds for one epoch ---
=========================
[[0.05638117]
 [0.05088841]
 [0.04964624]
 [0.04801107]
 [0.04489937]
 [0.160151  ]
 [0.04689581]
 [0.04791942]
 [0.0445035 ]
 [0.06812394]
 [0.05435945]]
[[-6.2572050e-01]
 [-3.7208003e-01]
 [-3.0764690e-01]
 [ 2.1789630e-01]
 [ 2.8619846e-02]
 [-2.7204590e+00]
 [ 1.5308531e-01]
 [ 2.1268471e-01]
 [-2.5001676e-03]
 [-1.0516899e+00]
 [ 5.3764236e-01]]
--- 0.4116215705871582 seconds for one epoch ---
463.2545009394289
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5541.52001953125, (2383.34, 1.077217, 2990.8953, 2.531778)
   validation loss 1710.166748046875, (1222.4786, 0.22039294, 321.26038, 2.531778)
decoder loss ratio: 47360.944741, decoder SINDy loss  ratio: 0.693486
--- 0.26746654510498047 seconds for one epoch ---
--- 0.2937796115875244 seconds for one epoch ---
--- 0.49536967277526855 seconds for one epoch ---
--- 0.3101928234100342 seconds for one epoch ---
--- 0.49038004875183105 seconds for one epoch ---
--- 0.30550312995910645 seconds for one epoch ---
--- 0.52364182472229 seconds for one epoch ---
--- 0.28998708724975586 seconds for one epoch ---
--- 0.49701905250549316 seconds for one epoch ---
--- 0.29036998748779297 seconds for one epoch ---
--- 0.47477245330810547 seconds for one epoch ---
--- 0.2980780601501465 seconds for one epoch ---
--- 0.5092058181762695 seconds for one epoch ---
--- 0.2975344657897949 seconds for one epoch ---
--- 0.4105353355407715 seconds for one epoch ---
--- 0.22896313667297363 seconds for one epoch ---
--- 0.4851679801940918 seconds for one epoch ---
--- 0.30725789070129395 seconds for one epoch ---
--- 0.4532279968261719 seconds for one epoch ---
--- 0.2818315029144287 seconds for one epoch ---
--- 0.5004012584686279 seconds for one epoch ---
--- 0.297088623046875 seconds for one epoch ---
--- 0.48442506790161133 seconds for one epoch ---
--- 0.29627466201782227 seconds for one epoch ---
=========================
[[0.05358212]
 [0.04589707]
 [0.04556475]
 [0.04312836]
 [0.04011558]
 [0.15118118]
 [0.04162049]
 [0.04301872]
 [0.03957442]
 [0.06682272]
 [0.04997226]]
[[-7.0937937e-01]
 [-3.6637047e-01]
 [-3.4944436e-01]
 [ 2.1848308e-01]
 [ 3.6741167e-02]
 [-2.6644344e+00]
 [ 1.3059966e-01]
 [ 2.1228264e-01]
 [-1.3093207e-03]
 [-1.1570839e+00]
 [ 5.5865741e-01]]
--- 0.2411491870880127 seconds for one epoch ---
463.2545009394289
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7663.298828125, (1845.974, 1.4624162, 5646.578, 2.5317802)
   validation loss 1360.0545654296875, (848.84906, 0.35178754, 341.56958, 2.5317802)
decoder loss ratio: 32885.886253, decoder SINDy loss  ratio: 0.737326
--- 0.31232357025146484 seconds for one epoch ---
--- 0.4696352481842041 seconds for one epoch ---
--- 0.2936217784881592 seconds for one epoch ---
--- 0.4759821891784668 seconds for one epoch ---
--- 0.29213929176330566 seconds for one epoch ---
--- 0.4939298629760742 seconds for one epoch ---
--- 0.2957644462585449 seconds for one epoch ---
--- 0.4951803684234619 seconds for one epoch ---
--- 0.2951216697692871 seconds for one epoch ---
--- 0.48784518241882324 seconds for one epoch ---
--- 0.29020261764526367 seconds for one epoch ---
--- 0.44350099563598633 seconds for one epoch ---
--- 0.22023868560791016 seconds for one epoch ---
--- 0.5061788558959961 seconds for one epoch ---
--- 0.3099641799926758 seconds for one epoch ---
--- 0.47987890243530273 seconds for one epoch ---
--- 0.2954864501953125 seconds for one epoch ---
--- 0.5046155452728271 seconds for one epoch ---
--- 0.29088735580444336 seconds for one epoch ---
--- 0.49321699142456055 seconds for one epoch ---
--- 0.30618786811828613 seconds for one epoch ---
--- 0.49004650115966797 seconds for one epoch ---
--- 0.2931640148162842 seconds for one epoch ---
--- 0.508918046951294 seconds for one epoch ---
=========================
[[0.05269279]
 [0.04282798]
 [0.04276318]
 [0.03922181]
 [0.03620914]
 [0.14629863]
 [0.0381832 ]
 [0.03927981]
 [0.03590925]
 [0.06719348]
 [0.0468025 ]]
[[-8.1251544e-01]
 [-3.9431775e-01]
 [-3.9111286e-01]
 [ 2.0338485e-01]
 [ 2.0191655e-02]
 [-2.6442299e+00]
 [ 1.4301495e-01]
 [ 2.0667720e-01]
 [ 5.0124084e-04]
 [-1.2669456e+00]
 [ 5.7799727e-01]]
--- 0.29833436012268066 seconds for one epoch ---
463.2545009394289
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5154.208984375, (2266.4998, 0.5286687, 2714.8735, 2.5317857)
   validation loss 1413.1842041015625, (911.0788, 0.33144373, 329.46713, 2.5317857)
decoder loss ratio: 35296.774274, decoder SINDy loss  ratio: 0.711201
--- 0.2529001235961914 seconds for one epoch ---
--- 0.29894232749938965 seconds for one epoch ---
--- 0.5030748844146729 seconds for one epoch ---
--- 0.290132999420166 seconds for one epoch ---
--- 0.49074244499206543 seconds for one epoch ---
--- 0.30033397674560547 seconds for one epoch ---
--- 0.5156185626983643 seconds for one epoch ---
--- 0.2944371700286865 seconds for one epoch ---
--- 0.5075945854187012 seconds for one epoch ---
--- 0.2936117649078369 seconds for one epoch ---
--- 0.5183379650115967 seconds for one epoch ---
--- 0.3006899356842041 seconds for one epoch ---
--- 0.49724864959716797 seconds for one epoch ---
--- 0.30225253105163574 seconds for one epoch ---
--- 0.5084319114685059 seconds for one epoch ---
--- 0.3053300380706787 seconds for one epoch ---
--- 0.5110125541687012 seconds for one epoch ---
--- 0.3129880428314209 seconds for one epoch ---
--- 0.5022995471954346 seconds for one epoch ---
--- 0.3021552562713623 seconds for one epoch ---
--- 0.5015285015106201 seconds for one epoch ---
--- 0.3000187873840332 seconds for one epoch ---
--- 0.43215227127075195 seconds for one epoch ---
--- 0.28711652755737305 seconds for one epoch ---
=========================
[[0.05212067]
 [0.04024956]
 [0.0400133 ]
 [0.03588675]
 [0.03338175]
 [0.14054166]
 [0.03509313]
 [0.03610269]
 [0.03278107]
 [0.06798152]
 [0.04469328]]
[[-0.903679  ]
 [-0.42343917]
 [-0.41199863]
 [ 0.19502144]
 [ 0.04404498]
 [-2.6081414 ]
 [ 0.1490018 ]
 [ 0.20727588]
 [ 0.00515667]
 [-1.3681978 ]
 [ 0.6227466 ]]
--- 0.2071237564086914 seconds for one epoch ---
463.2545009394289
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5988.103515625, (2299.6848, 1.526476, 3511.354, 2.5317914)
   validation loss 1384.3721923828125, (909.0434, 0.30486754, 299.4857, 2.5317914)
decoder loss ratio: 35217.919330, decoder SINDy loss  ratio: 0.646482
--- 0.29399919509887695 seconds for one epoch ---
--- 0.5049140453338623 seconds for one epoch ---
--- 0.2909681797027588 seconds for one epoch ---
--- 0.49005627632141113 seconds for one epoch ---
--- 0.28997802734375 seconds for one epoch ---
--- 0.49389004707336426 seconds for one epoch ---
--- 0.2539360523223877 seconds for one epoch ---
--- 0.5387129783630371 seconds for one epoch ---
--- 0.29821300506591797 seconds for one epoch ---
--- 0.5106201171875 seconds for one epoch ---
--- 0.2856900691986084 seconds for one epoch ---
--- 0.5379712581634521 seconds for one epoch ---
--- 0.286118745803833 seconds for one epoch ---
--- 0.5165746212005615 seconds for one epoch ---
--- 0.2962303161621094 seconds for one epoch ---
--- 0.5044505596160889 seconds for one epoch ---
--- 0.28511953353881836 seconds for one epoch ---
--- 0.5049700736999512 seconds for one epoch ---
--- 0.29778170585632324 seconds for one epoch ---
--- 0.4481167793273926 seconds for one epoch ---
--- 0.29538917541503906 seconds for one epoch ---
--- 0.5116515159606934 seconds for one epoch ---
--- 0.28389978408813477 seconds for one epoch ---
--- 0.5277740955352783 seconds for one epoch ---
=========================
[[0.05223457]
 [0.03825501]
 [0.03852446]
 [0.03360665]
 [0.03091761]
 [0.1348827 ]
 [0.03270674]
 [0.03371753]
 [0.03035748]
 [0.06955678]
 [0.04187904]]
[[-0.98558617]
 [-0.44151166]
 [-0.45424548]
 [ 0.20089096]
 [ 0.03929747]
 [-2.5637703 ]
 [ 0.14894849]
 [ 0.20715135]
 [-0.00303075]
 [-1.4629487 ]
 [ 0.6037466 ]]
--- 0.2897636890411377 seconds for one epoch ---
463.2545009394289
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5245.30712890625, (2047.7335, 0.903557, 3017.8987, 2.5317945)
   validation loss 2028.679443359375, (1405.6051, 0.3901876, 443.9129, 2.5317945)
decoder loss ratio: 54455.581910, decoder SINDy loss  ratio: 0.958248
THRESHOLDING: 1 active coefficients
--- 0.5107674598693848 seconds for one epoch ---
--- 0.29973721504211426 seconds for one epoch ---
--- 0.5040614604949951 seconds for one epoch ---
--- 0.2901740074157715 seconds for one epoch ---
--- 0.5279462337493896 seconds for one epoch ---
--- 0.3112924098968506 seconds for one epoch ---
--- 0.5137066841125488 seconds for one epoch ---
--- 0.3033926486968994 seconds for one epoch ---
--- 0.5239365100860596 seconds for one epoch ---
--- 0.30255675315856934 seconds for one epoch ---
--- 0.4932889938354492 seconds for one epoch ---
--- 0.2185685634613037 seconds for one epoch ---
--- 0.5327560901641846 seconds for one epoch ---
--- 0.29906344413757324 seconds for one epoch ---
--- 0.5252084732055664 seconds for one epoch ---
--- 0.2753159999847412 seconds for one epoch ---
--- 0.5410385131835938 seconds for one epoch ---
--- 0.3102560043334961 seconds for one epoch ---
--- 0.5324294567108154 seconds for one epoch ---
--- 0.28873109817504883 seconds for one epoch ---
--- 0.5758047103881836 seconds for one epoch ---
--- 0.3055150508880615 seconds for one epoch ---
--- 0.5187170505523682 seconds for one epoch ---
--- 0.23073983192443848 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07317221]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.5909363]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.26547813415527344 seconds for one epoch ---
463.2545009394289
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6150.67236328125, (2186.4402, 2.8034272, 3961.3008, 0.12785786)
   validation loss 1922.2596435546875, (1578.3788, 0.5507949, 343.20233, 0.12785786)
decoder loss ratio: 61149.134285, decoder SINDy loss  ratio: 0.740851
--- 0.2141108512878418 seconds for one epoch ---
--- 0.5442683696746826 seconds for one epoch ---
--- 0.28601884841918945 seconds for one epoch ---
--- 0.5501198768615723 seconds for one epoch ---
--- 0.30492281913757324 seconds for one epoch ---
--- 0.520796537399292 seconds for one epoch ---
--- 0.2906675338745117 seconds for one epoch ---
--- 0.5246589183807373 seconds for one epoch ---
--- 0.30068230628967285 seconds for one epoch ---
--- 0.5279631614685059 seconds for one epoch ---
--- 0.2992427349090576 seconds for one epoch ---
--- 0.5303447246551514 seconds for one epoch ---
--- 0.2037339210510254 seconds for one epoch ---
--- 0.5376541614532471 seconds for one epoch ---
--- 0.3075382709503174 seconds for one epoch ---
--- 0.5407547950744629 seconds for one epoch ---
--- 0.2901628017425537 seconds for one epoch ---
--- 0.5279619693756104 seconds for one epoch ---
--- 0.29693055152893066 seconds for one epoch ---
--- 0.5336220264434814 seconds for one epoch ---
--- 0.29525256156921387 seconds for one epoch ---
--- 0.522284746170044 seconds for one epoch ---
--- 0.2942056655883789 seconds for one epoch ---
--- 0.5303661823272705 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05663146]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.2238346]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.30133485794067383 seconds for one epoch ---
463.2545009394289
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2778.2275390625, (1490.5463, 0.6650638, 1286.8955, 0.120576814)
   validation loss 1125.4110107421875, (826.11847, 0.78494865, 298.387, 0.120576814)
decoder loss ratio: 32005.263703, decoder SINDy loss  ratio: 0.644110
--- 0.2583904266357422 seconds for one epoch ---
--- 0.30513548851013184 seconds for one epoch ---
--- 0.5357568264007568 seconds for one epoch ---
--- 0.3009645938873291 seconds for one epoch ---
--- 0.5338730812072754 seconds for one epoch ---
--- 0.2958493232727051 seconds for one epoch ---
--- 0.5500776767730713 seconds for one epoch ---
--- 0.17162847518920898 seconds for one epoch ---
--- 0.5551090240478516 seconds for one epoch ---
--- 0.289478063583374 seconds for one epoch ---
--- 0.5739450454711914 seconds for one epoch ---
--- 0.297121524810791 seconds for one epoch ---
--- 0.5438439846038818 seconds for one epoch ---
--- 0.2885725498199463 seconds for one epoch ---
--- 0.5480542182922363 seconds for one epoch ---
--- 0.29662156105041504 seconds for one epoch ---
--- 0.5566999912261963 seconds for one epoch ---
--- 0.2893378734588623 seconds for one epoch ---
--- 0.5378460884094238 seconds for one epoch ---
--- 0.23107147216796875 seconds for one epoch ---
--- 0.568859338760376 seconds for one epoch ---
--- 0.3051280975341797 seconds for one epoch ---
--- 0.5517370700836182 seconds for one epoch ---
--- 0.2929046154022217 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05025491]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0789794]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2628810405731201 seconds for one epoch ---
463.2545009394289
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5550.7783203125, (2008.138, 0.9813574, 3541.541, 0.11801008)
   validation loss 965.2716674804688, (639.6835, 0.8815742, 324.58865, 0.11801008)
decoder loss ratio: 24782.448232, decoder SINDy loss  ratio: 0.700670
--- 0.2865016460418701 seconds for one epoch ---
--- 0.4612107276916504 seconds for one epoch ---
--- 0.29540562629699707 seconds for one epoch ---
--- 0.5400207042694092 seconds for one epoch ---
--- 0.3031280040740967 seconds for one epoch ---
--- 0.5516176223754883 seconds for one epoch ---
--- 0.29685497283935547 seconds for one epoch ---
--- 0.55464768409729 seconds for one epoch ---
--- 0.2994811534881592 seconds for one epoch ---
--- 0.5408165454864502 seconds for one epoch ---
--- 0.3100922107696533 seconds for one epoch ---
--- 0.5435824394226074 seconds for one epoch ---
--- 0.2979888916015625 seconds for one epoch ---
--- 0.5647549629211426 seconds for one epoch ---
--- 0.2575674057006836 seconds for one epoch ---
--- 0.5605959892272949 seconds for one epoch ---
--- 0.2916755676269531 seconds for one epoch ---
--- 0.563605546951294 seconds for one epoch ---
--- 0.3037443161010742 seconds for one epoch ---
--- 0.577399730682373 seconds for one epoch ---
--- 0.2930734157562256 seconds for one epoch ---
--- 0.5579752922058105 seconds for one epoch ---
--- 0.2808647155761719 seconds for one epoch ---
--- 0.5717267990112305 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04720093]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0164051]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2983109951019287 seconds for one epoch ---
463.2545009394289
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7674.478515625, (2259.3994, 2.39403, 5412.5684, 0.11662381)
   validation loss 1237.65771484375, (829.95056, 0.8946235, 406.6959, 0.11662381)
decoder loss ratio: 32153.725611, decoder SINDy loss  ratio: 0.877910
--- 0.2590780258178711 seconds for one epoch ---
--- 0.30213022232055664 seconds for one epoch ---
--- 0.5601272583007812 seconds for one epoch ---
--- 0.28137707710266113 seconds for one epoch ---
--- 0.5748450756072998 seconds for one epoch ---
--- 0.3032402992248535 seconds for one epoch ---
--- 0.559760332107544 seconds for one epoch ---
--- 0.24553728103637695 seconds for one epoch ---
--- 0.5799379348754883 seconds for one epoch ---
--- 0.2923750877380371 seconds for one epoch ---
--- 0.5755531787872314 seconds for one epoch ---
--- 0.2930138111114502 seconds for one epoch ---
--- 0.5771212577819824 seconds for one epoch ---
--- 0.28876423835754395 seconds for one epoch ---
--- 0.5596568584442139 seconds for one epoch ---
--- 0.2949190139770508 seconds for one epoch ---
--- 0.5697813034057617 seconds for one epoch ---
--- 0.29932737350463867 seconds for one epoch ---
--- 0.5800755023956299 seconds for one epoch ---
--- 0.172652006149292 seconds for one epoch ---
--- 0.5933864116668701 seconds for one epoch ---
--- 0.2915611267089844 seconds for one epoch ---
--- 0.5733757019042969 seconds for one epoch ---
--- 0.29770374298095703 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04563649]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9958078]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.25102972984313965 seconds for one epoch ---
463.2545009394289
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5822.97265625, (2070.4092, 1.5089179, 3750.938, 0.1164118)
   validation loss 1685.808349609375, (1293.1318, 0.82378435, 391.73636, 0.1164118)
decoder loss ratio: 50098.172300, decoder SINDy loss  ratio: 0.845618
--- 0.2713913917541504 seconds for one epoch ---
--- 0.6242907047271729 seconds for one epoch ---
--- 0.4305605888366699 seconds for one epoch ---
--- 0.5903019905090332 seconds for one epoch ---
--- 0.2947421073913574 seconds for one epoch ---
--- 0.5848903656005859 seconds for one epoch ---
--- 0.29650068283081055 seconds for one epoch ---
--- 0.5833098888397217 seconds for one epoch ---
--- 0.2998538017272949 seconds for one epoch ---
--- 0.5864980220794678 seconds for one epoch ---
--- 0.31421780586242676 seconds for one epoch ---
--- 0.5143918991088867 seconds for one epoch ---
--- 0.1784524917602539 seconds for one epoch ---
--- 0.5935602188110352 seconds for one epoch ---
--- 0.2963700294494629 seconds for one epoch ---
--- 0.5756790637969971 seconds for one epoch ---
--- 0.29174208641052246 seconds for one epoch ---
--- 0.573082447052002 seconds for one epoch ---
--- 0.29558277130126953 seconds for one epoch ---
--- 0.5869154930114746 seconds for one epoch ---
--- 0.2881290912628174 seconds for one epoch ---
--- 0.5785531997680664 seconds for one epoch ---
--- 0.2976994514465332 seconds for one epoch ---
--- 0.5102384090423584 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04530799]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.0074627]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.3013913631439209 seconds for one epoch ---
463.2545009394289
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4019.25244140625, (1855.2307, 0.8502418, 2163.0547, 0.11663952)
   validation loss 1174.9013671875, (833.19653, 0.9226361, 340.6656, 0.11663952)
decoder loss ratio: 32279.480189, decoder SINDy loss  ratio: 0.735375
--- 0.26587748527526855 seconds for one epoch ---
--- 0.2869696617126465 seconds for one epoch ---
--- 0.5886168479919434 seconds for one epoch ---
--- 0.29885244369506836 seconds for one epoch ---
--- 0.5062432289123535 seconds for one epoch ---
--- 0.2658884525299072 seconds for one epoch ---
--- 0.598618745803833 seconds for one epoch ---
--- 0.309903621673584 seconds for one epoch ---
--- 0.5786828994750977 seconds for one epoch ---
--- 0.2912278175354004 seconds for one epoch ---
--- 0.5883870124816895 seconds for one epoch ---
--- 0.3037858009338379 seconds for one epoch ---
--- 0.6094872951507568 seconds for one epoch ---
--- 0.29506993293762207 seconds for one epoch ---
--- 0.6125574111938477 seconds for one epoch ---
--- 0.288785457611084 seconds for one epoch ---
--- 0.5468368530273438 seconds for one epoch ---
--- 0.29809093475341797 seconds for one epoch ---
--- 0.5950093269348145 seconds for one epoch ---
--- 0.2993030548095703 seconds for one epoch ---
--- 0.6019954681396484 seconds for one epoch ---
--- 0.29843640327453613 seconds for one epoch ---
--- 0.6158974170684814 seconds for one epoch ---
--- 0.3038206100463867 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04432158]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9958124]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.25864601135253906 seconds for one epoch ---
463.2545009394289
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5621.6494140625, (2271.1118, 1.3853041, 3349.0356, 0.11650442)
   validation loss 1180.650390625, (807.145, 0.7352278, 372.65372, 0.11650442)
decoder loss ratio: 31270.199322, decoder SINDy loss  ratio: 0.804425
--- 0.3056356906890869 seconds for one epoch ---
--- 0.5983736515045166 seconds for one epoch ---
--- 0.29581522941589355 seconds for one epoch ---
--- 0.5931072235107422 seconds for one epoch ---
--- 0.29219818115234375 seconds for one epoch ---
--- 0.6012039184570312 seconds for one epoch ---
--- 0.29819774627685547 seconds for one epoch ---
--- 0.5582356452941895 seconds for one epoch ---
--- 0.16954445838928223 seconds for one epoch ---
--- 0.5919928550720215 seconds for one epoch ---
--- 0.2974982261657715 seconds for one epoch ---
--- 0.607602596282959 seconds for one epoch ---
--- 0.2995281219482422 seconds for one epoch ---
--- 0.5894289016723633 seconds for one epoch ---
--- 0.30082058906555176 seconds for one epoch ---
--- 0.610527515411377 seconds for one epoch ---
--- 0.3030533790588379 seconds for one epoch ---
--- 0.6522848606109619 seconds for one epoch ---
--- 0.28850507736206055 seconds for one epoch ---
--- 0.5731616020202637 seconds for one epoch ---
--- 0.29986023902893066 seconds for one epoch ---
--- 0.6112508773803711 seconds for one epoch ---
--- 0.3006298542022705 seconds for one epoch ---
--- 0.6182961463928223 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04310984]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9720381]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.19124531745910645 seconds for one epoch ---
463.2545009394289
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5655.09619140625, (3665.612, 0.32744575, 1989.0408, 0.115732454)
   validation loss 3084.84521484375, (2615.4536, 0.66379553, 468.6121, 0.115732454)
decoder loss ratio: 101327.213606, decoder SINDy loss  ratio: 1.011565
--- 0.2637364864349365 seconds for one epoch ---
--- 0.28656506538391113 seconds for one epoch ---
--- 0.6123409271240234 seconds for one epoch ---
--- 0.299560546875 seconds for one epoch ---
--- 0.6103000640869141 seconds for one epoch ---
--- 0.29309844970703125 seconds for one epoch ---
--- 0.6168029308319092 seconds for one epoch ---
--- 0.2870824337005615 seconds for one epoch ---
--- 0.6275465488433838 seconds for one epoch ---
--- 0.2944176197052002 seconds for one epoch ---
--- 0.5417580604553223 seconds for one epoch ---
--- 0.2399599552154541 seconds for one epoch ---
--- 0.6221797466278076 seconds for one epoch ---
--- 0.2911522388458252 seconds for one epoch ---
--- 0.6306917667388916 seconds for one epoch ---
--- 0.2930154800415039 seconds for one epoch ---
--- 0.6274409294128418 seconds for one epoch ---
--- 0.2958083152770996 seconds for one epoch ---
--- 0.6123580932617188 seconds for one epoch ---
--- 0.290130615234375 seconds for one epoch ---
--- 0.6165719032287598 seconds for one epoch ---
--- 0.3059201240539551 seconds for one epoch ---
--- 0.6093020439147949 seconds for one epoch ---
--- 0.29734230041503906 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04255369]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9677484]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2574906349182129 seconds for one epoch ---
463.2545009394289
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3620.0673828125, (1966.9226, 0.9095201, 1652.1194, 0.11577579)
   validation loss 1192.176513671875, (856.94806, 0.7603573, 334.3524, 0.11577579)
decoder loss ratio: 33199.655536, decoder SINDy loss  ratio: 0.721747
--- 0.2985217571258545 seconds for one epoch ---
--- 0.5785000324249268 seconds for one epoch ---
--- 0.16622471809387207 seconds for one epoch ---
--- 0.641383171081543 seconds for one epoch ---
--- 0.30234575271606445 seconds for one epoch ---
--- 0.6014783382415771 seconds for one epoch ---
--- 0.29462361335754395 seconds for one epoch ---
--- 0.6181976795196533 seconds for one epoch ---
--- 0.29868197441101074 seconds for one epoch ---
--- 0.6253294944763184 seconds for one epoch ---
--- 0.2878241539001465 seconds for one epoch ---
--- 0.6262238025665283 seconds for one epoch ---
--- 0.28987956047058105 seconds for one epoch ---
--- 0.5749959945678711 seconds for one epoch ---
--- 0.28579139709472656 seconds for one epoch ---
--- 0.6174194812774658 seconds for one epoch ---
--- 0.2836434841156006 seconds for one epoch ---
--- 0.6316118240356445 seconds for one epoch ---
--- 0.300342321395874 seconds for one epoch ---
--- 0.6462485790252686 seconds for one epoch ---
--- 0.302325963973999 seconds for one epoch ---
--- 0.6636614799499512 seconds for one epoch ---
--- 0.2934744358062744 seconds for one epoch ---
--- 0.6233170032501221 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04168452]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.94994265]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]]
--- 0.29659581184387207 seconds for one epoch ---
463.2545009394289
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5732.33349609375, (2109.6235, 1.0579473, 3621.5361, 0.115512684)
   validation loss 1180.17529296875, (863.9973, 0.6578797, 315.40457, 0.115512684)
decoder loss ratio: 33472.755927, decoder SINDy loss  ratio: 0.680845
--- 0.27987074851989746 seconds for one epoch ---
--- 0.3093249797821045 seconds for one epoch ---
--- 0.6416809558868408 seconds for one epoch ---
--- 0.30097055435180664 seconds for one epoch ---
--- 0.6211304664611816 seconds for one epoch ---
--- 0.31493210792541504 seconds for one epoch ---
--- 0.6485741138458252 seconds for one epoch ---
--- 0.2951014041900635 seconds for one epoch ---
--- 0.6448526382446289 seconds for one epoch ---
--- 0.3009958267211914 seconds for one epoch ---
--- 0.6534759998321533 seconds for one epoch ---
--- 0.29366517066955566 seconds for one epoch ---
--- 0.6324529647827148 seconds for one epoch ---
--- 0.29370641708374023 seconds for one epoch ---
--- 0.5733006000518799 seconds for one epoch ---
--- 0.21729040145874023 seconds for one epoch ---
--- 0.6402270793914795 seconds for one epoch ---
--- 0.2974245548248291 seconds for one epoch ---
--- 0.6437759399414062 seconds for one epoch ---
--- 0.2951633930206299 seconds for one epoch ---
--- 0.6568512916564941 seconds for one epoch ---
--- 0.28974151611328125 seconds for one epoch ---
--- 0.6449065208435059 seconds for one epoch ---
--- 0.2959787845611572 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04087083]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.932703]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.26474642753601074 seconds for one epoch ---
463.2545009394289
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5547.1796875, (1846.2789, 2.379244, 3698.4062, 0.115069486)
   validation loss 1385.947998046875, (1021.49927, 0.5550092, 363.77866, 0.115069486)
decoder loss ratio: 39574.655027, decoder SINDy loss  ratio: 0.785267
--- 0.307875394821167 seconds for one epoch ---
--- 0.6594376564025879 seconds for one epoch ---
--- 0.28917527198791504 seconds for one epoch ---
--- 0.634852409362793 seconds for one epoch ---
--- 0.29511523246765137 seconds for one epoch ---
--- 0.6609289646148682 seconds for one epoch ---
--- 0.3005833625793457 seconds for one epoch ---
--- 0.6549544334411621 seconds for one epoch ---
--- 0.29613423347473145 seconds for one epoch ---
--- 0.6502389907836914 seconds for one epoch ---
--- 0.293182373046875 seconds for one epoch ---
--- 0.6505377292633057 seconds for one epoch ---
--- 0.3002970218658447 seconds for one epoch ---
--- 0.6506261825561523 seconds for one epoch ---
--- 0.29244232177734375 seconds for one epoch ---
--- 0.5927917957305908 seconds for one epoch ---
--- 0.2812347412109375 seconds for one epoch ---
--- 0.6687426567077637 seconds for one epoch ---
--- 0.29175233840942383 seconds for one epoch ---
--- 0.664879322052002 seconds for one epoch ---
--- 0.30015993118286133 seconds for one epoch ---
--- 0.6814281940460205 seconds for one epoch ---
--- 0.30220675468444824 seconds for one epoch ---
--- 0.6817364692687988 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.0401781]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.91705924]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]]
--- 0.281186580657959 seconds for one epoch ---
463.2545009394289
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4199.46484375, (1654.0616, 1.5109361, 2543.7776, 0.11468827)
   validation loss 896.3943481445312, (586.6856, 0.39583227, 309.19827, 0.11468827)
decoder loss ratio: 22729.218981, decoder SINDy loss  ratio: 0.667448
--- 0.2540287971496582 seconds for one epoch ---
--- 0.3009452819824219 seconds for one epoch ---
--- 0.6575570106506348 seconds for one epoch ---
--- 0.28701210021972656 seconds for one epoch ---
--- 0.5906121730804443 seconds for one epoch ---
--- 0.20943570137023926 seconds for one epoch ---
--- 0.673656702041626 seconds for one epoch ---
--- 0.285611629486084 seconds for one epoch ---
--- 0.6662721633911133 seconds for one epoch ---
--- 0.3009145259857178 seconds for one epoch ---
--- 0.6611547470092773 seconds for one epoch ---
--- 0.301816463470459 seconds for one epoch ---
--- 0.6631832122802734 seconds for one epoch ---
--- 0.29178547859191895 seconds for one epoch ---
--- 0.6715738773345947 seconds for one epoch ---
--- 0.28429317474365234 seconds for one epoch ---
--- 0.6714158058166504 seconds for one epoch ---
--- 0.28916311264038086 seconds for one epoch ---
--- 0.6632752418518066 seconds for one epoch ---
--- 0.3103470802307129 seconds for one epoch ---
--- 0.6741042137145996 seconds for one epoch ---
--- 0.28589391708374023 seconds for one epoch ---
--- 0.6720318794250488 seconds for one epoch ---
--- 0.2958064079284668 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03998755]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.9174908]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.25829100608825684 seconds for one epoch ---
463.2545009394289
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5377.59228515625, (2406.8018, 0.8555288, 2969.8206, 0.11471766)
   validation loss 1064.339599609375, (723.9469, 0.36665806, 339.91132, 0.11471766)
decoder loss ratio: 28046.959710, decoder SINDy loss  ratio: 0.733746
--- 0.28638362884521484 seconds for one epoch ---
--- 0.6772005558013916 seconds for one epoch ---
--- 0.2955355644226074 seconds for one epoch ---
--- 0.6669669151306152 seconds for one epoch ---
--- 0.27828025817871094 seconds for one epoch ---
--- 0.6850392818450928 seconds for one epoch ---
--- 0.29496097564697266 seconds for one epoch ---
--- 0.6735296249389648 seconds for one epoch ---
--- 0.28528356552124023 seconds for one epoch ---
--- 0.6841928958892822 seconds for one epoch ---
--- 0.2918663024902344 seconds for one epoch ---
--- 0.6914820671081543 seconds for one epoch ---
--- 0.29049062728881836 seconds for one epoch ---
--- 0.6908309459686279 seconds for one epoch ---
--- 0.27558064460754395 seconds for one epoch ---
--- 0.7026481628417969 seconds for one epoch ---
--- 0.28455352783203125 seconds for one epoch ---
--- 0.6867625713348389 seconds for one epoch ---
--- 0.2893400192260742 seconds for one epoch ---
--- 0.7307479381561279 seconds for one epoch ---
--- 0.2827870845794678 seconds for one epoch ---
--- 0.6760072708129883 seconds for one epoch ---
--- 0.2871124744415283 seconds for one epoch ---
--- 0.6887710094451904 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03964423]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.91122085]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]]
--- 0.29099154472351074 seconds for one epoch ---
463.2545009394289
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5577.9765625, (1824.0659, 2.7212467, 3751.075, 0.11435497)
   validation loss 1095.880126953125, (753.098, 0.38789174, 342.27985, 0.11435497)
decoder loss ratio: 29176.324826, decoder SINDy loss  ratio: 0.738859
--- 0.2598733901977539 seconds for one epoch ---
--- 0.2936258316040039 seconds for one epoch ---
--- 0.6737713813781738 seconds for one epoch ---
--- 0.25841236114501953 seconds for one epoch ---
--- 0.7231028079986572 seconds for one epoch ---
--- 0.32043957710266113 seconds for one epoch ---
--- 0.6888809204101562 seconds for one epoch ---
--- 0.2987189292907715 seconds for one epoch ---
--- 0.6958575248718262 seconds for one epoch ---
--- 0.2914721965789795 seconds for one epoch ---
--- 0.6896877288818359 seconds for one epoch ---
--- 0.308732271194458 seconds for one epoch ---
--- 0.6638765335083008 seconds for one epoch ---
--- 0.28757381439208984 seconds for one epoch ---
--- 0.7267472743988037 seconds for one epoch ---
--- 0.28745079040527344 seconds for one epoch ---
--- 0.6807074546813965 seconds for one epoch ---
--- 0.280839204788208 seconds for one epoch ---
--- 0.681311845779419 seconds for one epoch ---
--- 0.2972724437713623 seconds for one epoch ---
--- 0.7140066623687744 seconds for one epoch ---
--- 0.2923545837402344 seconds for one epoch ---
--- 0.6949028968811035 seconds for one epoch ---
--- 0.3010241985321045 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03867952]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8832225]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.25698089599609375 seconds for one epoch ---
463.2545009394289
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5510.79150390625, (2147.8848, 2.003323, 3360.7896, 0.1137424)
   validation loss 1069.32421875, (749.5136, 0.16454306, 319.5323, 0.1137424)
decoder loss ratio: 29037.458497, decoder SINDy loss  ratio: 0.689755
--- 0.2958981990814209 seconds for one epoch ---
--- 0.6816806793212891 seconds for one epoch ---
--- 0.20160531997680664 seconds for one epoch ---
--- 0.677619457244873 seconds for one epoch ---
--- 0.2958250045776367 seconds for one epoch ---
--- 0.6989531517028809 seconds for one epoch ---
--- 0.2844974994659424 seconds for one epoch ---
--- 0.7072315216064453 seconds for one epoch ---
--- 0.3065061569213867 seconds for one epoch ---
--- 0.6934502124786377 seconds for one epoch ---
--- 0.28770923614501953 seconds for one epoch ---
--- 0.6906514167785645 seconds for one epoch ---
--- 0.2657470703125 seconds for one epoch ---
--- 0.7479164600372314 seconds for one epoch ---
--- 0.286895751953125 seconds for one epoch ---
--- 0.7297546863555908 seconds for one epoch ---
--- 0.28364062309265137 seconds for one epoch ---
--- 0.7232263088226318 seconds for one epoch ---
--- 0.2801790237426758 seconds for one epoch ---
--- 0.7133853435516357 seconds for one epoch ---
--- 0.29526710510253906 seconds for one epoch ---
--- 0.7027232646942139 seconds for one epoch ---
--- 0.2566971778869629 seconds for one epoch ---
--- 0.7229416370391846 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03845375]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8792574]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.2954239845275879 seconds for one epoch ---
463.2545009394289
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4438.2275390625, (1578.4822, 5.1609883, 2854.4712, 0.113335095)
   validation loss 1047.439208984375, (705.1155, 0.28186214, 341.92865, 0.113335095)
decoder loss ratio: 27317.397772, decoder SINDy loss  ratio: 0.738101
--- 0.2703580856323242 seconds for one epoch ---
--- 0.2986304759979248 seconds for one epoch ---
--- 0.7124502658843994 seconds for one epoch ---
--- 0.28460073471069336 seconds for one epoch ---
--- 0.7210361957550049 seconds for one epoch ---
--- 0.2814524173736572 seconds for one epoch ---
--- 0.700850248336792 seconds for one epoch ---
--- 0.292604923248291 seconds for one epoch ---
--- 0.7120800018310547 seconds for one epoch ---
--- 0.28582239151000977 seconds for one epoch ---
--- 0.7347433567047119 seconds for one epoch ---
--- 0.31369781494140625 seconds for one epoch ---
--- 0.6995809078216553 seconds for one epoch ---
--- 0.4354276657104492 seconds for one epoch ---
--- 0.7205893993377686 seconds for one epoch ---
--- 0.29134130477905273 seconds for one epoch ---
--- 0.6900701522827148 seconds for one epoch ---
--- 0.3037245273590088 seconds for one epoch ---
--- 0.7193233966827393 seconds for one epoch ---
--- 0.30542635917663574 seconds for one epoch ---
--- 0.7504978179931641 seconds for one epoch ---
--- 0.29145288467407227 seconds for one epoch ---
--- 0.7295835018157959 seconds for one epoch ---
--- 0.2901737689971924 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03838641]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8804125]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.26435017585754395 seconds for one epoch ---
463.2545009394289
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3770.4169921875, (1525.3439, 2.799927, 2242.1606, 0.11262828)
   validation loss 1195.0919189453125, (858.2428, 0.27562568, 336.46075, 0.11262828)
decoder loss ratio: 33249.815964, decoder SINDy loss  ratio: 0.726298
--- 0.3067009449005127 seconds for one epoch ---
--- 0.7145278453826904 seconds for one epoch ---
--- 0.2897529602050781 seconds for one epoch ---
--- 0.7247698307037354 seconds for one epoch ---
--- 0.29703736305236816 seconds for one epoch ---
--- 0.71201491355896 seconds for one epoch ---
--- 0.30563807487487793 seconds for one epoch ---
--- 0.7658066749572754 seconds for one epoch ---
--- 0.2836601734161377 seconds for one epoch ---
--- 0.7343173027038574 seconds for one epoch ---
--- 0.2989673614501953 seconds for one epoch ---
--- 0.7130341529846191 seconds for one epoch ---
--- 0.30151844024658203 seconds for one epoch ---
--- 0.7353906631469727 seconds for one epoch ---
--- 0.29584765434265137 seconds for one epoch ---
--- 0.7254981994628906 seconds for one epoch ---
--- 0.2903764247894287 seconds for one epoch ---
--- 0.7360212802886963 seconds for one epoch ---
--- 0.28531599044799805 seconds for one epoch ---
--- 0.7298343181610107 seconds for one epoch ---
--- 0.28899502754211426 seconds for one epoch ---
--- 0.7433555126190186 seconds for one epoch ---
--- 0.29382896423339844 seconds for one epoch ---
--- 0.7207472324371338 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03821279]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.8771347]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]]
--- 0.27966880798339844 seconds for one epoch ---
463.2545009394289
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4391.9375, (1885.7281, 1.7532021, 2504.3442, 0.11181872)
   validation loss 1051.291259765625, (700.4566, 0.2376103, 350.48517, 0.11181872)
decoder loss ratio: 27136.904885, decoder SINDy loss  ratio: 0.756572
--- 0.2529306411743164 seconds for one epoch ---
--- 0.29988884925842285 seconds for one epoch ---
--- 0.7184853553771973 seconds for one epoch ---
--- 0.27886390686035156 seconds for one epoch ---
--- 0.7568316459655762 seconds for one epoch ---
--- 0.30307459831237793 seconds for one epoch ---
--- 0.7402067184448242 seconds for one epoch ---
--- 0.29729413986206055 seconds for one epoch ---
--- 0.7313566207885742 seconds for one epoch ---
--- 0.30950450897216797 seconds for one epoch ---
--- 0.7259881496429443 seconds for one epoch ---
--- 0.2869992256164551 seconds for one epoch ---
--- 0.7311382293701172 seconds for one epoch ---
--- 0.2170398235321045 seconds for one epoch ---
--- 0.7658977508544922 seconds for one epoch ---
--- 0.2939622402191162 seconds for one epoch ---
--- 0.7223362922668457 seconds for one epoch ---
--- 0.28746914863586426 seconds for one epoch ---
--- 0.7142245769500732 seconds for one epoch ---
--- 0.3003661632537842 seconds for one epoch ---
--- 0.7317631244659424 seconds for one epoch ---
--- 0.2923569679260254 seconds for one epoch ---
--- 0.7493822574615479 seconds for one epoch ---
--- 0.20490813255310059 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03812879]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.87671643]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]]
--- 0.25633811950683594 seconds for one epoch ---
463.2545009394289
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4760.2861328125, (2133.5723, 0.6368922, 2625.966, 0.110719144)
   validation loss 1359.2779541015625, (955.0787, 0.26570538, 403.82285, 0.110719144)
decoder loss ratio: 37001.405933, decoder SINDy loss  ratio: 0.871708
--- 0.16460800170898438 seconds for one epoch ---
--- 0.7740797996520996 seconds for one epoch ---
--- 0.2944307327270508 seconds for one epoch ---
--- 0.7255032062530518 seconds for one epoch ---
--- 0.3118095397949219 seconds for one epoch ---
--- 0.7303116321563721 seconds for one epoch ---
--- 0.2973635196685791 seconds for one epoch ---
--- 0.7366080284118652 seconds for one epoch ---
--- 0.3053469657897949 seconds for one epoch ---
--- 0.7195093631744385 seconds for one epoch ---
--- 0.15951204299926758 seconds for one epoch ---
--- 0.7533676624298096 seconds for one epoch ---
--- 0.31308841705322266 seconds for one epoch ---
--- 0.7436549663543701 seconds for one epoch ---
--- 0.2894551753997803 seconds for one epoch ---
--- 0.7379825115203857 seconds for one epoch ---
--- 0.29172468185424805 seconds for one epoch ---
--- 0.7501356601715088 seconds for one epoch ---
--- 0.29234790802001953 seconds for one epoch ---
--- 0.7162361145019531 seconds for one epoch ---
--- 0.15890026092529297 seconds for one epoch ---
--- 0.7427854537963867 seconds for one epoch ---
--- 0.29343414306640625 seconds for one epoch ---
--- 0.7455997467041016 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.03780496]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.867444]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]]
--- 0.2952992916107178 seconds for one epoch ---
463.2545009394289
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6598.00830078125, (1736.4996, 5.396228, 4856.0034, 0.108689606)
   validation loss 1211.7139892578125, (894.48737, 0.24409842, 316.8739, 0.108689606)
decoder loss ratio: 34653.993446, decoder SINDy loss  ratio: 0.684017
THRESHOLDING: 0 active coefficients
--- 0.7455153465270996 seconds for one epoch ---
--- 0.2951676845550537 seconds for one epoch ---
--- 0.7379372119903564 seconds for one epoch ---
--- 0.2957136631011963 seconds for one epoch ---
--- 0.757789134979248 seconds for one epoch ---
--- 0.29595160484313965 seconds for one epoch ---
--- 0.7513506412506104 seconds for one epoch ---
--- 0.283921480178833 seconds for one epoch ---
--- 0.7079463005065918 seconds for one epoch ---
--- 0.2954082489013672 seconds for one epoch ---
--- 0.7713863849639893 seconds for one epoch ---
--- 0.28418540954589844 seconds for one epoch ---
--- 0.7571122646331787 seconds for one epoch ---
--- 0.29371094703674316 seconds for one epoch ---
--- 0.7507607936859131 seconds for one epoch ---
--- 0.2937917709350586 seconds for one epoch ---
--- 0.7627725601196289 seconds for one epoch ---
--- 0.29480910301208496 seconds for one epoch ---
--- 0.8065943717956543 seconds for one epoch ---
--- 0.3123362064361572 seconds for one epoch ---
--- 0.7580780982971191 seconds for one epoch ---
--- 0.29390811920166016 seconds for one epoch ---
--- 0.7521951198577881 seconds for one epoch ---
--- 0.2901279926300049 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26151156425476074 seconds for one epoch ---
463.2545009394289
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4587.94921875, (2185.0525, 3.0664082, 2399.8215, 0.008682428)
   validation loss 2050.0693359375, (1660.9119, 0.36715394, 388.7814, 0.008682428)
decoder loss ratio: 64346.609129, decoder SINDy loss  ratio: 0.839239
--- 0.28099703788757324 seconds for one epoch ---
--- 0.7720251083374023 seconds for one epoch ---
--- 0.28980207443237305 seconds for one epoch ---
--- 0.7640998363494873 seconds for one epoch ---
--- 0.28035545349121094 seconds for one epoch ---
--- 0.7035980224609375 seconds for one epoch ---
--- 0.24606633186340332 seconds for one epoch ---
--- 0.7780110836029053 seconds for one epoch ---
--- 0.29816770553588867 seconds for one epoch ---
--- 0.7748594284057617 seconds for one epoch ---
--- 0.29120516777038574 seconds for one epoch ---
--- 0.7593255043029785 seconds for one epoch ---
--- 0.3067748546600342 seconds for one epoch ---
--- 0.7568056583404541 seconds for one epoch ---
--- 0.2919001579284668 seconds for one epoch ---
--- 0.7332801818847656 seconds for one epoch ---
--- 0.29456043243408203 seconds for one epoch ---
--- 0.7780182361602783 seconds for one epoch ---
--- 0.2883567810058594 seconds for one epoch ---
--- 0.7681529521942139 seconds for one epoch ---
--- 0.29825377464294434 seconds for one epoch ---
--- 0.7726001739501953 seconds for one epoch ---
--- 0.2857940196990967 seconds for one epoch ---
--- 0.78171706199646 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2969822883605957 seconds for one epoch ---
463.2545009394289
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5289.158203125, (2029.386, 2.521893, 3257.2415, 0.008682428)
   validation loss 959.4440307617188, (634.18585, 0.29117027, 324.9583, 0.008682428)
decoder loss ratio: 24569.460904, decoder SINDy loss  ratio: 0.701468
--- 0.2687218189239502 seconds for one epoch ---
--- 0.3037528991699219 seconds for one epoch ---
--- 0.7703478336334229 seconds for one epoch ---
--- 0.15903139114379883 seconds for one epoch ---
--- 0.7656512260437012 seconds for one epoch ---
--- 0.2938380241394043 seconds for one epoch ---
--- 0.7681882381439209 seconds for one epoch ---
--- 0.2960357666015625 seconds for one epoch ---
--- 0.7642161846160889 seconds for one epoch ---
--- 0.28760623931884766 seconds for one epoch ---
--- 0.7829298973083496 seconds for one epoch ---
--- 0.30101871490478516 seconds for one epoch ---
--- 0.710139274597168 seconds for one epoch ---
--- 0.22491455078125 seconds for one epoch ---
--- 0.8075637817382812 seconds for one epoch ---
--- 0.28551220893859863 seconds for one epoch ---
--- 0.7771599292755127 seconds for one epoch ---
--- 0.2801239490509033 seconds for one epoch ---
--- 0.8021156787872314 seconds for one epoch ---
--- 0.2947959899902344 seconds for one epoch ---
--- 0.803065299987793 seconds for one epoch ---
--- 0.287670373916626 seconds for one epoch ---
--- 0.8090226650238037 seconds for one epoch ---
--- 0.30002617835998535 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24666500091552734 seconds for one epoch ---
463.2545009394289
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3338.4462890625, (1386.5588, 2.502371, 1949.3763, 0.008682428)
   validation loss 1140.280029296875, (758.86334, 0.21516202, 381.19287, 0.008682428)
decoder loss ratio: 29399.683325, decoder SINDy loss  ratio: 0.822858
--- 0.22353601455688477 seconds for one epoch ---
--- 0.7869439125061035 seconds for one epoch ---
--- 0.28501033782958984 seconds for one epoch ---
--- 0.7835867404937744 seconds for one epoch ---
--- 0.29455137252807617 seconds for one epoch ---
--- 0.7874500751495361 seconds for one epoch ---
--- 0.29448533058166504 seconds for one epoch ---
--- 0.7988502979278564 seconds for one epoch ---
--- 0.30252528190612793 seconds for one epoch ---
--- 0.6790122985839844 seconds for one epoch ---
--- 0.2726402282714844 seconds for one epoch ---
--- 0.7921633720397949 seconds for one epoch ---
--- 0.29941868782043457 seconds for one epoch ---
--- 0.7954494953155518 seconds for one epoch ---
--- 0.2876927852630615 seconds for one epoch ---
--- 0.7969238758087158 seconds for one epoch ---
--- 0.2970154285430908 seconds for one epoch ---
--- 0.7733831405639648 seconds for one epoch ---
--- 0.28491926193237305 seconds for one epoch ---
--- 0.7859482765197754 seconds for one epoch ---
--- 0.2923295497894287 seconds for one epoch ---
--- 0.8002398014068604 seconds for one epoch ---
--- 0.29217004776000977 seconds for one epoch ---
--- 0.7912471294403076 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28136706352233887 seconds for one epoch ---
463.2545009394289
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3333.171875, (1685.8308, 1.4776235, 1645.8547, 0.008682428)
   validation loss 1180.820556640625, (782.4371, 0.22122106, 398.1536, 0.008682428)
decoder loss ratio: 30312.970569, decoder SINDy loss  ratio: 0.859471
--- 0.2588996887207031 seconds for one epoch ---
--- 0.3116598129272461 seconds for one epoch ---
--- 0.8112549781799316 seconds for one epoch ---
--- 0.2999875545501709 seconds for one epoch ---
--- 0.8056638240814209 seconds for one epoch ---
--- 0.29659056663513184 seconds for one epoch ---
--- 0.8735451698303223 seconds for one epoch ---
--- 0.2895171642303467 seconds for one epoch ---
--- 0.8116581439971924 seconds for one epoch ---
--- 0.290386438369751 seconds for one epoch ---
--- 0.7911653518676758 seconds for one epoch ---
--- 0.2890586853027344 seconds for one epoch ---
--- 0.7930586338043213 seconds for one epoch ---
--- 0.2958855628967285 seconds for one epoch ---
--- 0.7870137691497803 seconds for one epoch ---
--- 0.17447137832641602 seconds for one epoch ---
--- 0.7887840270996094 seconds for one epoch ---
--- 0.294217586517334 seconds for one epoch ---
--- 0.8210375308990479 seconds for one epoch ---
--- 0.28932738304138184 seconds for one epoch ---
--- 0.7980940341949463 seconds for one epoch ---
--- 0.29536962509155273 seconds for one epoch ---
--- 0.8144254684448242 seconds for one epoch ---
--- 0.279559850692749 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2479245662689209 seconds for one epoch ---
463.2545009394289
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3564.310791015625, (1547.8418, 3.6441917, 2012.816, 0.008682428)
   validation loss 910.8811645507812, (565.0859, 0.2438526, 345.5428, 0.008682428)
decoder loss ratio: 21892.407886, decoder SINDy loss  ratio: 0.745903
--- 0.2985556125640869 seconds for one epoch ---
--- 0.7790489196777344 seconds for one epoch ---
--- 0.2243037223815918 seconds for one epoch ---
--- 0.8107383251190186 seconds for one epoch ---
--- 0.28295469284057617 seconds for one epoch ---
--- 0.7988770008087158 seconds for one epoch ---
--- 0.29134273529052734 seconds for one epoch ---
--- 0.8094828128814697 seconds for one epoch ---
--- 0.2956240177154541 seconds for one epoch ---
--- 0.817908525466919 seconds for one epoch ---
--- 0.2835543155670166 seconds for one epoch ---
--- 0.8658866882324219 seconds for one epoch ---
--- 0.29874277114868164 seconds for one epoch ---
--- 0.8416283130645752 seconds for one epoch ---
--- 0.2996690273284912 seconds for one epoch ---
--- 0.8247020244598389 seconds for one epoch ---
--- 0.29306650161743164 seconds for one epoch ---
--- 0.821148157119751 seconds for one epoch ---
--- 0.28519463539123535 seconds for one epoch ---
--- 0.7876718044281006 seconds for one epoch ---
--- 0.15891480445861816 seconds for one epoch ---
--- 0.8224163055419922 seconds for one epoch ---
--- 0.2809927463531494 seconds for one epoch ---
--- 0.8227968215942383 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2771179676055908 seconds for one epoch ---
463.2545009394289
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4013.67529296875, (1719.8356, 1.5324143, 2292.2983, 0.008682428)
   validation loss 1811.9923095703125, (1419.6199, 0.32189345, 392.0418, 0.008682428)
decoder loss ratio: 54998.538450, decoder SINDy loss  ratio: 0.846277
--- 0.2591688632965088 seconds for one epoch ---
--- 0.28899383544921875 seconds for one epoch ---
--- 0.8103270530700684 seconds for one epoch ---
--- 0.28901147842407227 seconds for one epoch ---
--- 0.8233301639556885 seconds for one epoch ---
--- 0.29186320304870605 seconds for one epoch ---
--- 0.7506613731384277 seconds for one epoch ---
--- 0.3043069839477539 seconds for one epoch ---
--- 0.8174664974212646 seconds for one epoch ---
--- 0.27791380882263184 seconds for one epoch ---
--- 0.8621611595153809 seconds for one epoch ---
--- 0.3106684684753418 seconds for one epoch ---
--- 0.8203046321868896 seconds for one epoch ---
--- 0.2923305034637451 seconds for one epoch ---
--- 0.8322081565856934 seconds for one epoch ---
--- 0.29907870292663574 seconds for one epoch ---
--- 0.8326301574707031 seconds for one epoch ---
--- 0.3035397529602051 seconds for one epoch ---
--- 0.8472192287445068 seconds for one epoch ---
--- 0.29979968070983887 seconds for one epoch ---
--- 0.8664021492004395 seconds for one epoch ---
--- 0.2940328121185303 seconds for one epoch ---
--- 0.8302924633026123 seconds for one epoch ---
--- 0.29416513442993164 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25798726081848145 seconds for one epoch ---
463.2545009394289
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4044.12353515625, (1522.6316, 1.9341371, 2519.549, 0.008682428)
   validation loss 918.591064453125, (568.1983, 0.26076168, 350.12332, 0.008682428)
decoder loss ratio: 22012.988702, decoder SINDy loss  ratio: 0.755790
--- 0.274860143661499 seconds for one epoch ---
--- 0.8234562873840332 seconds for one epoch ---
--- 0.1854562759399414 seconds for one epoch ---
--- 0.8437943458557129 seconds for one epoch ---
--- 0.30048537254333496 seconds for one epoch ---
--- 0.8205685615539551 seconds for one epoch ---
--- 0.2985086441040039 seconds for one epoch ---
--- 0.8290941715240479 seconds for one epoch ---
--- 0.29122352600097656 seconds for one epoch ---
--- 0.8601701259613037 seconds for one epoch ---
--- 0.2811858654022217 seconds for one epoch ---
--- 0.8934729099273682 seconds for one epoch ---
--- 0.29991960525512695 seconds for one epoch ---
--- 0.8656353950500488 seconds for one epoch ---
--- 0.3063185214996338 seconds for one epoch ---
--- 0.8623254299163818 seconds for one epoch ---
--- 0.29769182205200195 seconds for one epoch ---
--- 0.855520486831665 seconds for one epoch ---
--- 0.2884080410003662 seconds for one epoch ---
--- 0.8113646507263184 seconds for one epoch ---
--- 0.13973426818847656 seconds for one epoch ---
--- 0.8796422481536865 seconds for one epoch ---
--- 0.2879626750946045 seconds for one epoch ---
--- 0.8495123386383057 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28592634201049805 seconds for one epoch ---
463.2545009394289
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3727.455078125, (1993.1445, 0.6818169, 1733.6199, 0.008682428)
   validation loss 1415.3199462890625, (1077.7551, 0.30725142, 337.24887, 0.008682428)
decoder loss ratio: 41754.104683, decoder SINDy loss  ratio: 0.727999
--- 0.2599644660949707 seconds for one epoch ---
--- 0.28055572509765625 seconds for one epoch ---
--- 0.8478755950927734 seconds for one epoch ---
--- 0.2955758571624756 seconds for one epoch ---
--- 0.8474619388580322 seconds for one epoch ---
--- 0.300950288772583 seconds for one epoch ---
--- 0.862335205078125 seconds for one epoch ---
--- 0.2934098243713379 seconds for one epoch ---
--- 0.8703148365020752 seconds for one epoch ---
--- 0.30254173278808594 seconds for one epoch ---
--- 0.864250659942627 seconds for one epoch ---
--- 0.29886770248413086 seconds for one epoch ---
--- 0.8687493801116943 seconds for one epoch ---
--- 0.30779170989990234 seconds for one epoch ---
--- 0.7344193458557129 seconds for one epoch ---
--- 0.2894754409790039 seconds for one epoch ---
--- 0.8659679889678955 seconds for one epoch ---
--- 0.28729939460754395 seconds for one epoch ---
--- 0.8676705360412598 seconds for one epoch ---
--- 0.29866862297058105 seconds for one epoch ---
--- 0.8434743881225586 seconds for one epoch ---
--- 0.289902925491333 seconds for one epoch ---
--- 0.8803427219390869 seconds for one epoch ---
--- 0.2947053909301758 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26055026054382324 seconds for one epoch ---
463.2545009394289
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5847.12890625, (2811.4685, 3.4026682, 3032.249, 0.008682194)
   validation loss 2266.576416015625, (1773.1467, 0.41273135, 493.0082, 0.008682194)
decoder loss ratio: 68694.782581, decoder SINDy loss  ratio: 1.064228
--- 0.28773999214172363 seconds for one epoch ---
--- 0.892108678817749 seconds for one epoch ---
--- 0.2927217483520508 seconds for one epoch ---
--- 0.8542561531066895 seconds for one epoch ---
--- 0.26738715171813965 seconds for one epoch ---
--- 0.8514208793640137 seconds for one epoch ---
--- 0.2801783084869385 seconds for one epoch ---
--- 0.8706333637237549 seconds for one epoch ---
--- 0.31424450874328613 seconds for one epoch ---
--- 0.8776822090148926 seconds for one epoch ---
--- 0.28659820556640625 seconds for one epoch ---
--- 0.8656072616577148 seconds for one epoch ---
--- 0.2910487651824951 seconds for one epoch ---
--- 0.838294267654419 seconds for one epoch ---
--- 0.3034341335296631 seconds for one epoch ---
--- 0.8610587120056152 seconds for one epoch ---
--- 0.28383946418762207 seconds for one epoch ---
--- 0.8560752868652344 seconds for one epoch ---
--- 0.17243242263793945 seconds for one epoch ---
--- 0.8760685920715332 seconds for one epoch ---
--- 0.28408384323120117 seconds for one epoch ---
--- 0.8589508533477783 seconds for one epoch ---
--- 0.28922367095947266 seconds for one epoch ---
--- 0.8949055671691895 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2933382987976074 seconds for one epoch ---
463.2545009394289
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4143.19921875, (1545.3451, 2.4166675, 2595.4287, 0.008681814)
   validation loss 956.3215942382812, (579.1829, 0.36527392, 376.7647, 0.008681814)
decoder loss ratio: 22438.551918, decoder SINDy loss  ratio: 0.813300
--- 0.26673102378845215 seconds for one epoch ---
--- 0.2922806739807129 seconds for one epoch ---
--- 0.8703796863555908 seconds for one epoch ---
--- 0.27956080436706543 seconds for one epoch ---
--- 0.9076032638549805 seconds for one epoch ---
--- 0.28995633125305176 seconds for one epoch ---
--- 0.8734884262084961 seconds for one epoch ---
--- 0.2806570529937744 seconds for one epoch ---
--- 0.8863804340362549 seconds for one epoch ---
--- 0.27726244926452637 seconds for one epoch ---
--- 0.8836231231689453 seconds for one epoch ---
--- 0.2909367084503174 seconds for one epoch ---
--- 0.9114949703216553 seconds for one epoch ---
--- 0.28993964195251465 seconds for one epoch ---
--- 0.8780539035797119 seconds for one epoch ---
--- 0.2976968288421631 seconds for one epoch ---
--- 0.8837165832519531 seconds for one epoch ---
--- 0.4513552188873291 seconds for one epoch ---
--- 0.8815903663635254 seconds for one epoch ---
--- 0.2901327610015869 seconds for one epoch ---
--- 0.8877980709075928 seconds for one epoch ---
--- 0.3027665615081787 seconds for one epoch ---
--- 0.8826632499694824 seconds for one epoch ---
--- 0.30172204971313477 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2555687427520752 seconds for one epoch ---
463.2545009394289
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3468.634765625, (1192.8331, 3.784668, 2272.008, 0.008681354)
   validation loss 1230.9693603515625, (895.0748, 0.34178704, 335.54404, 0.008681354)
decoder loss ratio: 34676.752798, decoder SINDy loss  ratio: 0.724319
--- 0.2889690399169922 seconds for one epoch ---
--- 0.8894171714782715 seconds for one epoch ---
--- 0.31201863288879395 seconds for one epoch ---
--- 0.9275598526000977 seconds for one epoch ---
--- 0.30525732040405273 seconds for one epoch ---
--- 0.9593620300292969 seconds for one epoch ---
--- 0.298051118850708 seconds for one epoch ---
--- 0.9020192623138428 seconds for one epoch ---
--- 0.30045580863952637 seconds for one epoch ---
--- 0.8982288837432861 seconds for one epoch ---
--- 0.28971123695373535 seconds for one epoch ---
--- 0.8926067352294922 seconds for one epoch ---
--- 0.29082369804382324 seconds for one epoch ---
--- 0.7959060668945312 seconds for one epoch ---
--- 0.2494497299194336 seconds for one epoch ---
--- 0.9072737693786621 seconds for one epoch ---
--- 0.2965586185455322 seconds for one epoch ---
--- 0.9121263027191162 seconds for one epoch ---
--- 0.2930722236633301 seconds for one epoch ---
--- 0.8772263526916504 seconds for one epoch ---
--- 0.3011956214904785 seconds for one epoch ---
--- 0.9050688743591309 seconds for one epoch ---
--- 0.23897528648376465 seconds for one epoch ---
--- 0.934666633605957 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.21556878089904785 seconds for one epoch ---
463.2545009394289
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5762.740234375, (2243.5012, 3.0391393, 3516.1914, 0.008680551)
   validation loss 1577.11083984375, (1187.6189, 0.2466708, 389.23654, 0.008680551)
decoder loss ratio: 46010.417847, decoder SINDy loss  ratio: 0.840222
--- 0.25206756591796875 seconds for one epoch ---
--- 0.27736496925354004 seconds for one epoch ---
--- 0.9116921424865723 seconds for one epoch ---
--- 0.29223036766052246 seconds for one epoch ---
--- 0.9023268222808838 seconds for one epoch ---
--- 0.2946763038635254 seconds for one epoch ---
--- 0.8936026096343994 seconds for one epoch ---
--- 0.2491602897644043 seconds for one epoch ---
--- 0.9562504291534424 seconds for one epoch ---
--- 0.2960851192474365 seconds for one epoch ---
--- 0.9180305004119873 seconds for one epoch ---
--- 0.2779209613800049 seconds for one epoch ---
--- 0.9109034538269043 seconds for one epoch ---
--- 0.28252720832824707 seconds for one epoch ---
--- 0.9134016036987305 seconds for one epoch ---
--- 0.2864236831665039 seconds for one epoch ---
--- 0.9158825874328613 seconds for one epoch ---
--- 0.29851555824279785 seconds for one epoch ---
--- 0.9051554203033447 seconds for one epoch ---
--- 0.2912018299102783 seconds for one epoch ---
--- 0.9259884357452393 seconds for one epoch ---
--- 0.31690502166748047 seconds for one epoch ---
--- 0.919086217880249 seconds for one epoch ---
--- 0.31178736686706543 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2576940059661865 seconds for one epoch ---
463.2545009394289
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2346.2275390625, (1436.8727, 2.5716438, 906.7744, 0.008679282)
   validation loss 1621.1593017578125, (1181.9789, 0.41659012, 438.75516, 0.008679282)
decoder loss ratio: 45791.913888, decoder SINDy loss  ratio: 0.947115
--- 0.2616567611694336 seconds for one epoch ---
--- 0.9374940395355225 seconds for one epoch ---
--- 0.29256176948547363 seconds for one epoch ---
--- 0.9249410629272461 seconds for one epoch ---
--- 0.29452943801879883 seconds for one epoch ---
--- 0.915076732635498 seconds for one epoch ---
--- 0.30698418617248535 seconds for one epoch ---
--- 0.9348807334899902 seconds for one epoch ---
--- 0.2973010540008545 seconds for one epoch ---
--- 0.9198257923126221 seconds for one epoch ---
--- 0.2930936813354492 seconds for one epoch ---
--- 0.9357891082763672 seconds for one epoch ---
--- 0.2976369857788086 seconds for one epoch ---
--- 0.9248425960540771 seconds for one epoch ---
--- 0.29786014556884766 seconds for one epoch ---
--- 0.9451746940612793 seconds for one epoch ---
--- 0.28420281410217285 seconds for one epoch ---
--- 0.9486587047576904 seconds for one epoch ---
--- 0.28101277351379395 seconds for one epoch ---
--- 0.9259185791015625 seconds for one epoch ---
--- 0.29241347312927246 seconds for one epoch ---
--- 0.9271955490112305 seconds for one epoch ---
--- 0.29235005378723145 seconds for one epoch ---
--- 0.9596655368804932 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2864348888397217 seconds for one epoch ---
463.2545009394289
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2379.22705078125, (923.4478, 0.75937104, 1455.0111, 0.008677283)
   validation loss 1115.0062255859375, (735.93384, 0.2708325, 378.7929, 0.008677283)
decoder loss ratio: 28511.354517, decoder SINDy loss  ratio: 0.817678
--- 0.2526109218597412 seconds for one epoch ---
--- 0.25023698806762695 seconds for one epoch ---
--- 0.9112660884857178 seconds for one epoch ---
--- 0.29177117347717285 seconds for one epoch ---
--- 0.9217159748077393 seconds for one epoch ---
--- 0.30268096923828125 seconds for one epoch ---
--- 0.9100687503814697 seconds for one epoch ---
--- 0.28731608390808105 seconds for one epoch ---
--- 0.9317758083343506 seconds for one epoch ---
--- 0.28337883949279785 seconds for one epoch ---
--- 0.9421348571777344 seconds for one epoch ---
--- 0.3036763668060303 seconds for one epoch ---
--- 0.9320008754730225 seconds for one epoch ---
--- 0.30805182456970215 seconds for one epoch ---
--- 0.9521064758300781 seconds for one epoch ---
--- 0.2822458744049072 seconds for one epoch ---
--- 0.9336488246917725 seconds for one epoch ---
--- 0.30269289016723633 seconds for one epoch ---
--- 0.9953434467315674 seconds for one epoch ---
--- 0.29988646507263184 seconds for one epoch ---
--- 0.9343366622924805 seconds for one epoch ---
--- 0.2935216426849365 seconds for one epoch ---
--- 0.9361193180084229 seconds for one epoch ---
--- 0.29358839988708496 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.246171236038208 seconds for one epoch ---
463.2545009394289
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2904.35205078125, (1357.6748, 3.603085, 1543.0656, 0.008674095)
   validation loss 832.965087890625, (483.98978, 0.30413097, 348.66254, 0.008674095)
decoder loss ratio: 18750.604189, decoder SINDy loss  ratio: 0.752637
--- 0.29124975204467773 seconds for one epoch ---
--- 0.9069724082946777 seconds for one epoch ---
--- 0.20662546157836914 seconds for one epoch ---
--- 0.9193801879882812 seconds for one epoch ---
--- 0.2902710437774658 seconds for one epoch ---
--- 0.9317371845245361 seconds for one epoch ---
--- 0.30449676513671875 seconds for one epoch ---
--- 0.9416193962097168 seconds for one epoch ---
--- 0.29486632347106934 seconds for one epoch ---
--- 0.9528298377990723 seconds for one epoch ---
--- 0.24023890495300293 seconds for one epoch ---
--- 0.9906706809997559 seconds for one epoch ---
--- 0.2871251106262207 seconds for one epoch ---
--- 0.9651970863342285 seconds for one epoch ---
--- 0.29909610748291016 seconds for one epoch ---
--- 0.9699718952178955 seconds for one epoch ---
--- 0.2864062786102295 seconds for one epoch ---
--- 0.9667372703552246 seconds for one epoch ---
--- 0.24362516403198242 seconds for one epoch ---
--- 1.002495527267456 seconds for one epoch ---
--- 0.2944986820220947 seconds for one epoch ---
--- 0.9521369934082031 seconds for one epoch ---
--- 0.2794640064239502 seconds for one epoch ---
--- 0.941744327545166 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2829608917236328 seconds for one epoch ---
463.2545009394289
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3187.55029296875, (1486.1385, 5.7306943, 1695.6724, 0.008669029)
   validation loss 890.3001708984375, (545.7904, 0.32087493, 344.1802, 0.008669029)
decoder loss ratio: 21144.867834, decoder SINDy loss  ratio: 0.742961
--- 0.26571059226989746 seconds for one epoch ---
--- 0.3026764392852783 seconds for one epoch ---
--- 0.9414050579071045 seconds for one epoch ---
--- 0.29093384742736816 seconds for one epoch ---
--- 0.9122004508972168 seconds for one epoch ---
--- 0.2897207736968994 seconds for one epoch ---
--- 0.9428963661193848 seconds for one epoch ---
--- 0.29996466636657715 seconds for one epoch ---
--- 0.950143575668335 seconds for one epoch ---
--- 0.30647802352905273 seconds for one epoch ---
--- 0.9464762210845947 seconds for one epoch ---
--- 0.291046142578125 seconds for one epoch ---
--- 0.9751272201538086 seconds for one epoch ---
--- 0.2986135482788086 seconds for one epoch ---
--- 0.9817256927490234 seconds for one epoch ---
--- 0.2960398197174072 seconds for one epoch ---
--- 0.9622023105621338 seconds for one epoch ---
--- 0.2971153259277344 seconds for one epoch ---
--- 0.9586269855499268 seconds for one epoch ---
--- 0.2966282367706299 seconds for one epoch ---
--- 0.9776797294616699 seconds for one epoch ---
--- 0.2986176013946533 seconds for one epoch ---
--- 0.9484508037567139 seconds for one epoch ---
--- 0.2959146499633789 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2504284381866455 seconds for one epoch ---
463.2545009394289
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4651.27685546875, (2048.648, 4.1569757, 2598.4631, 0.008660994)
   validation loss 870.1212158203125, (530.1456, 0.36640185, 339.60052, 0.008660994)
decoder loss ratio: 20538.762075, decoder SINDy loss  ratio: 0.733075
--- 0.29511070251464844 seconds for one epoch ---
--- 0.9654614925384521 seconds for one epoch ---
--- 0.181685209274292 seconds for one epoch ---
--- 0.9516229629516602 seconds for one epoch ---
--- 0.29691481590270996 seconds for one epoch ---
--- 0.9761013984680176 seconds for one epoch ---
--- 0.29561305046081543 seconds for one epoch ---
--- 0.9628434181213379 seconds for one epoch ---
--- 0.28807997703552246 seconds for one epoch ---
--- 0.9683265686035156 seconds for one epoch ---
--- 0.21155214309692383 seconds for one epoch ---
--- 1.0162031650543213 seconds for one epoch ---
--- 0.3063387870788574 seconds for one epoch ---
--- 0.9810245037078857 seconds for one epoch ---
--- 0.3049204349517822 seconds for one epoch ---
--- 0.9861111640930176 seconds for one epoch ---
--- 0.28673601150512695 seconds for one epoch ---
--- 0.9820199012756348 seconds for one epoch ---
--- 0.1710224151611328 seconds for one epoch ---
--- 0.9909780025482178 seconds for one epoch ---
--- 0.2897212505340576 seconds for one epoch ---
--- 0.9831931591033936 seconds for one epoch ---
--- 0.2860221862792969 seconds for one epoch ---
--- 0.9791638851165771 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2937452793121338 seconds for one epoch ---
463.2545009394289
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3684.889404296875, (1823.2776, 2.4851441, 1859.1183, 0.008648276)
   validation loss 914.81201171875, (555.9201, 0.3016197, 358.58157, 0.008648276)
decoder loss ratio: 21537.309987, decoder SINDy loss  ratio: 0.774049
--- 0.24413371086120605 seconds for one epoch ---
--- 0.29196715354919434 seconds for one epoch ---
--- 0.9701828956604004 seconds for one epoch ---
--- 0.2917041778564453 seconds for one epoch ---
--- 0.9862782955169678 seconds for one epoch ---
--- 0.29700779914855957 seconds for one epoch ---
--- 0.9638025760650635 seconds for one epoch ---
--- 0.2803983688354492 seconds for one epoch ---
--- 0.9975090026855469 seconds for one epoch ---
--- 0.2944374084472656 seconds for one epoch ---
--- 0.9999628067016602 seconds for one epoch ---
--- 0.27872371673583984 seconds for one epoch ---
--- 1.0116941928863525 seconds for one epoch ---
--- 0.2915186882019043 seconds for one epoch ---
--- 1.003260850906372 seconds for one epoch ---
--- 0.2808518409729004 seconds for one epoch ---
--- 1.0040347576141357 seconds for one epoch ---
--- 0.2868826389312744 seconds for one epoch ---
--- 1.022284746170044 seconds for one epoch ---
--- 0.30365538597106934 seconds for one epoch ---
--- 1.0072836875915527 seconds for one epoch ---
--- 0.30544424057006836 seconds for one epoch ---
--- 0.9846062660217285 seconds for one epoch ---
--- 0.2941322326660156 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26083970069885254 seconds for one epoch ---
463.2545009394289
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3607.11181640625, (2317.5347, 2.0160131, 1287.5525, 0.008628147)
   validation loss 1068.1778564453125, (704.7259, 0.30177093, 363.14148, 0.008628147)
decoder loss ratio: 27302.304480, decoder SINDy loss  ratio: 0.783892
--- 0.28388428688049316 seconds for one epoch ---
--- 1.000401258468628 seconds for one epoch ---
--- 0.262340784072876 seconds for one epoch ---
--- 0.9979853630065918 seconds for one epoch ---
--- 0.2927286624908447 seconds for one epoch ---
--- 0.9885854721069336 seconds for one epoch ---
--- 0.2860243320465088 seconds for one epoch ---
--- 0.9831018447875977 seconds for one epoch ---
--- 0.29614925384521484 seconds for one epoch ---
--- 1.0109786987304688 seconds for one epoch ---
--- 0.30159759521484375 seconds for one epoch ---
--- 0.9606568813323975 seconds for one epoch ---
--- 0.29933667182922363 seconds for one epoch ---
--- 1.0007822513580322 seconds for one epoch ---
--- 0.29825282096862793 seconds for one epoch ---
--- 0.9943578243255615 seconds for one epoch ---
--- 0.30410242080688477 seconds for one epoch ---
--- 1.0049092769622803 seconds for one epoch ---
--- 0.29154443740844727 seconds for one epoch ---
--- 1.0213589668273926 seconds for one epoch ---
--- 0.29486632347106934 seconds for one epoch ---
--- 1.0008296966552734 seconds for one epoch ---
--- 0.3002796173095703 seconds for one epoch ---
--- 1.003253698348999 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2933180332183838 seconds for one epoch ---
463.2545009394289
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4209.25390625, (1931.1421, 1.1563615, 2276.9465, 0.008596344)
   validation loss 1966.2943115234375, (1509.8816, 0.32940087, 456.07483, 0.008596344)
decoder loss ratio: 58495.434136, decoder SINDy loss  ratio: 0.984502
THRESHOLDING: 0 active coefficients
--- 0.25924181938171387 seconds for one epoch ---
--- 0.17712974548339844 seconds for one epoch ---
--- 0.970797061920166 seconds for one epoch ---
--- 0.2819490432739258 seconds for one epoch ---
--- 0.9985589981079102 seconds for one epoch ---
--- 0.2979884147644043 seconds for one epoch ---
--- 1.0127205848693848 seconds for one epoch ---
--- 0.29378676414489746 seconds for one epoch ---
--- 1.0092029571533203 seconds for one epoch ---
--- 0.16260170936584473 seconds for one epoch ---
--- 0.9990026950836182 seconds for one epoch ---
--- 0.2897684574127197 seconds for one epoch ---
--- 1.0174052715301514 seconds for one epoch ---
--- 0.2881922721862793 seconds for one epoch ---
--- 1.0230910778045654 seconds for one epoch ---
--- 0.2916135787963867 seconds for one epoch ---
--- 1.0013055801391602 seconds for one epoch ---
--- 0.16321516036987305 seconds for one epoch ---
--- 1.023665189743042 seconds for one epoch ---
--- 0.29291296005249023 seconds for one epoch ---
--- 1.0116758346557617 seconds for one epoch ---
--- 0.29805922508239746 seconds for one epoch ---
--- 1.0330405235290527 seconds for one epoch ---
--- 0.2907733917236328 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25504112243652344 seconds for one epoch ---
463.2545009394289
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4431.56201171875, (1857.2805, 1.6866304, 2572.5947, 0.0)
   validation loss 1201.0316162109375, (861.9692, 0.38268772, 338.67975, 0.0)
decoder loss ratio: 33394.182371, decoder SINDy loss  ratio: 0.731088
--- 0.28969287872314453 seconds for one epoch ---
--- 1.0207922458648682 seconds for one epoch ---
--- 0.2928469181060791 seconds for one epoch ---
--- 1.0115950107574463 seconds for one epoch ---
--- 0.30266547203063965 seconds for one epoch ---
--- 1.0217177867889404 seconds for one epoch ---
--- 0.2996206283569336 seconds for one epoch ---
--- 1.0405442714691162 seconds for one epoch ---
--- 0.30030322074890137 seconds for one epoch ---
--- 1.0107321739196777 seconds for one epoch ---
--- 0.29223036766052246 seconds for one epoch ---
--- 1.013026237487793 seconds for one epoch ---
--- 0.3053109645843506 seconds for one epoch ---
--- 1.0497353076934814 seconds for one epoch ---
--- 0.2516319751739502 seconds for one epoch ---
--- 1.0297460556030273 seconds for one epoch ---
--- 0.2957420349121094 seconds for one epoch ---
--- 1.026493787765503 seconds for one epoch ---
--- 0.2905123233795166 seconds for one epoch ---
--- 1.0371477603912354 seconds for one epoch ---
--- 0.2878148555755615 seconds for one epoch ---
--- 1.0018541812896729 seconds for one epoch ---
--- 0.21869683265686035 seconds for one epoch ---
--- 1.039332628250122 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28992700576782227 seconds for one epoch ---
463.2545009394289
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3052.93896484375, (1763.2726, 2.9116926, 1286.7545, 0.0)
   validation loss 919.1273193359375, (567.5796, 0.3795912, 351.16815, 0.0)
decoder loss ratio: 21989.018672, decoder SINDy loss  ratio: 0.758046
--- 0.2500722408294678 seconds for one epoch ---
--- 0.28487730026245117 seconds for one epoch ---
--- 1.0175418853759766 seconds for one epoch ---
--- 0.29651689529418945 seconds for one epoch ---
--- 1.056302785873413 seconds for one epoch ---
--- 0.18095850944519043 seconds for one epoch ---
--- 1.0342700481414795 seconds for one epoch ---
--- 0.3033409118652344 seconds for one epoch ---
--- 1.033681869506836 seconds for one epoch ---
--- 0.2890892028808594 seconds for one epoch ---
--- 1.0513172149658203 seconds for one epoch ---
--- 0.2851121425628662 seconds for one epoch ---
--- 0.9566197395324707 seconds for one epoch ---
--- 0.2327735424041748 seconds for one epoch ---
--- 1.0293724536895752 seconds for one epoch ---
--- 0.28930234909057617 seconds for one epoch ---
--- 1.0318880081176758 seconds for one epoch ---
--- 0.28456759452819824 seconds for one epoch ---
--- 1.028141736984253 seconds for one epoch ---
--- 0.29860854148864746 seconds for one epoch ---
--- 0.940274715423584 seconds for one epoch ---
--- 0.27892065048217773 seconds for one epoch ---
--- 1.044870138168335 seconds for one epoch ---
--- 0.29917097091674805 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24389362335205078 seconds for one epoch ---
463.2545009394289
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5637.3916015625, (2926.932, 2.2843373, 2708.1755, 0.0)
   validation loss 989.0400390625, (659.2166, 0.38819277, 329.43524, 0.0)
decoder loss ratio: 25539.196068, decoder SINDy loss  ratio: 0.711132
--- 0.29035329818725586 seconds for one epoch ---
--- 1.0147230625152588 seconds for one epoch ---
--- 0.29982972145080566 seconds for one epoch ---
--- 1.1081175804138184 seconds for one epoch ---
--- 0.2843046188354492 seconds for one epoch ---
--- 1.0449461936950684 seconds for one epoch ---
--- 0.271714448928833 seconds for one epoch ---
--- 1.0647475719451904 seconds for one epoch ---
--- 0.2870666980743408 seconds for one epoch ---
--- 1.0369014739990234 seconds for one epoch ---
--- 0.3071260452270508 seconds for one epoch ---
--- 1.0865333080291748 seconds for one epoch ---
--- 0.30265188217163086 seconds for one epoch ---
--- 1.0689525604248047 seconds for one epoch ---
--- 0.31720924377441406 seconds for one epoch ---
--- 1.065882682800293 seconds for one epoch ---
--- 0.2919273376464844 seconds for one epoch ---
--- 1.0452826023101807 seconds for one epoch ---
--- 0.2043449878692627 seconds for one epoch ---
--- 1.049560785293579 seconds for one epoch ---
--- 0.30277395248413086 seconds for one epoch ---
--- 1.0852429866790771 seconds for one epoch ---
--- 0.2918868064880371 seconds for one epoch ---
--- 1.071371078491211 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2832162380218506 seconds for one epoch ---
463.2545009394289
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4204.46240234375, (2133.8096, 1.1024655, 2069.5503, 0.0)
   validation loss 1294.9658203125, (974.69904, 0.41131794, 319.85553, 0.0)
decoder loss ratio: 37761.532793, decoder SINDy loss  ratio: 0.690453
--- 0.19007539749145508 seconds for one epoch ---
--- 0.2951180934906006 seconds for one epoch ---
--- 1.0646045207977295 seconds for one epoch ---
--- 0.2926969528198242 seconds for one epoch ---
--- 1.0344717502593994 seconds for one epoch ---
--- 0.2896144390106201 seconds for one epoch ---
--- 1.046208381652832 seconds for one epoch ---
--- 0.29456233978271484 seconds for one epoch ---
--- 1.0656373500823975 seconds for one epoch ---
--- 0.2933380603790283 seconds for one epoch ---
--- 1.046252965927124 seconds for one epoch ---
--- 0.28323912620544434 seconds for one epoch ---
--- 1.0677671432495117 seconds for one epoch ---
--- 0.28769874572753906 seconds for one epoch ---
--- 1.050943374633789 seconds for one epoch ---
--- 0.2866983413696289 seconds for one epoch ---
--- 1.1269659996032715 seconds for one epoch ---
--- 0.2847115993499756 seconds for one epoch ---
--- 1.0618681907653809 seconds for one epoch ---
--- 0.30727648735046387 seconds for one epoch ---
--- 1.087782621383667 seconds for one epoch ---
--- 0.30682945251464844 seconds for one epoch ---
--- 0.9857990741729736 seconds for one epoch ---
--- 0.22852277755737305 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26043009757995605 seconds for one epoch ---
463.2545009394289
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5611.8212890625, (2382.8914, 5.4913416, 3223.4387, 0.0)
   validation loss 1180.2137451171875, (772.4099, 0.25407174, 407.5497, 0.0)
decoder loss ratio: 29924.500958, decoder SINDy loss  ratio: 0.879753
--- 0.2848515510559082 seconds for one epoch ---
--- 1.0514531135559082 seconds for one epoch ---
--- 0.28723978996276855 seconds for one epoch ---
--- 1.0682413578033447 seconds for one epoch ---
--- 0.30016589164733887 seconds for one epoch ---
--- 1.0372114181518555 seconds for one epoch ---
--- 0.16566991806030273 seconds for one epoch ---
--- 1.0445492267608643 seconds for one epoch ---
--- 0.288787841796875 seconds for one epoch ---
--- 1.0625925064086914 seconds for one epoch ---
--- 0.2919135093688965 seconds for one epoch ---
--- 1.0985422134399414 seconds for one epoch ---
--- 0.2983705997467041 seconds for one epoch ---
--- 0.9645030498504639 seconds for one epoch ---
--- 0.2877981662750244 seconds for one epoch ---
--- 1.0687596797943115 seconds for one epoch ---
--- 0.3015742301940918 seconds for one epoch ---
--- 1.0642542839050293 seconds for one epoch ---
--- 0.29456400871276855 seconds for one epoch ---
--- 1.0607192516326904 seconds for one epoch ---
--- 0.2885403633117676 seconds for one epoch ---
--- 1.1172575950622559 seconds for one epoch ---
--- 0.28891801834106445 seconds for one epoch ---
--- 1.074169635772705 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29665136337280273 seconds for one epoch ---
463.2545009394289
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7257.43408203125, (1529.0408, 2.2424316, 5726.151, 0.0)
   validation loss 1025.28955078125, (593.79956, 0.5552749, 430.93475, 0.0)
decoder loss ratio: 23004.825857, decoder SINDy loss  ratio: 0.930233
--- 0.2564361095428467 seconds for one epoch ---
--- 0.2780780792236328 seconds for one epoch ---
--- 1.067176103591919 seconds for one epoch ---
--- 0.29427409172058105 seconds for one epoch ---
--- 1.1341679096221924 seconds for one epoch ---
--- 0.2931022644042969 seconds for one epoch ---
--- 1.0747535228729248 seconds for one epoch ---
--- 0.2902679443359375 seconds for one epoch ---
--- 1.0969538688659668 seconds for one epoch ---
--- 0.2982821464538574 seconds for one epoch ---
--- 0.9817230701446533 seconds for one epoch ---
--- 0.26496124267578125 seconds for one epoch ---
--- 1.0806307792663574 seconds for one epoch ---
--- 0.29652833938598633 seconds for one epoch ---
--- 1.092444658279419 seconds for one epoch ---
--- 0.2893977165222168 seconds for one epoch ---
--- 1.0838818550109863 seconds for one epoch ---
--- 0.2975175380706787 seconds for one epoch ---
--- 1.1477241516113281 seconds for one epoch ---
--- 0.31454968452453613 seconds for one epoch ---
--- 1.1066749095916748 seconds for one epoch ---
--- 0.2982752323150635 seconds for one epoch ---
--- 1.0912573337554932 seconds for one epoch ---
--- 0.2859182357788086 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2611067295074463 seconds for one epoch ---
463.2545009394289
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7239.39111328125, (1669.1847, 1.4079707, 5568.7983, 0.0)
   validation loss 1362.1435546875, (1001.55237, 0.37570083, 360.21545, 0.0)
decoder loss ratio: 38801.877514, decoder SINDy loss  ratio: 0.777576
--- 0.14404845237731934 seconds for one epoch ---
--- 1.0594007968902588 seconds for one epoch ---
--- 0.29411816596984863 seconds for one epoch ---
--- 1.0799269676208496 seconds for one epoch ---
--- 0.28851890563964844 seconds for one epoch ---
--- 1.0917840003967285 seconds for one epoch ---
--- 0.2888219356536865 seconds for one epoch ---
--- 0.9733076095581055 seconds for one epoch ---
--- 0.24878215789794922 seconds for one epoch ---
--- 1.1451342105865479 seconds for one epoch ---
--- 0.29323601722717285 seconds for one epoch ---
--- 1.1199092864990234 seconds for one epoch ---
--- 0.2873852252960205 seconds for one epoch ---
--- 1.1188745498657227 seconds for one epoch ---
--- 0.2951974868774414 seconds for one epoch ---
--- 1.0987627506256104 seconds for one epoch ---
--- 0.2844526767730713 seconds for one epoch ---
--- 1.1083259582519531 seconds for one epoch ---
--- 0.29964184761047363 seconds for one epoch ---
--- 1.1009926795959473 seconds for one epoch ---
--- 0.2938539981842041 seconds for one epoch ---
--- 1.138460636138916 seconds for one epoch ---
--- 0.2980043888092041 seconds for one epoch ---
--- 1.1285607814788818 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2773759365081787 seconds for one epoch ---
463.2545009394289
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3852.64306640625, (1687.7003, 3.5573604, 2161.3853, 0.0)
   validation loss 865.2286987304688, (528.4323, 0.3934268, 336.40295, 0.0)
decoder loss ratio: 20472.385166, decoder SINDy loss  ratio: 0.726173
--- 0.25902366638183594 seconds for one epoch ---
--- 0.29366564750671387 seconds for one epoch ---
--- 1.1019501686096191 seconds for one epoch ---
--- 0.2898552417755127 seconds for one epoch ---
--- 1.1197404861450195 seconds for one epoch ---
--- 0.18522334098815918 seconds for one epoch ---
--- 1.122413158416748 seconds for one epoch ---
--- 0.2901179790496826 seconds for one epoch ---
--- 1.107715368270874 seconds for one epoch ---
--- 0.2937815189361572 seconds for one epoch ---
--- 1.1242389678955078 seconds for one epoch ---
--- 0.4944496154785156 seconds for one epoch ---
--- 1.128983974456787 seconds for one epoch ---
--- 0.2875831127166748 seconds for one epoch ---
--- 1.1576306819915771 seconds for one epoch ---
--- 0.28919315338134766 seconds for one epoch ---
--- 1.1702642440795898 seconds for one epoch ---
--- 0.31062984466552734 seconds for one epoch ---
--- 1.1756606101989746 seconds for one epoch ---
--- 0.2985572814941406 seconds for one epoch ---
--- 1.1970713138580322 seconds for one epoch ---
--- 0.30236244201660156 seconds for one epoch ---
--- 1.1332640647888184 seconds for one epoch ---
--- 0.291473388671875 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2606618404388428 seconds for one epoch ---
463.2545009394289
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4254.263671875, (2668.5474, 0.81612295, 1584.9, 0.0)
   validation loss 1051.800048828125, (677.09814, 0.4068608, 374.2951, 0.0)
decoder loss ratio: 26231.957613, decoder SINDy loss  ratio: 0.807969
--- 0.2983677387237549 seconds for one epoch ---
--- 1.1000871658325195 seconds for one epoch ---
--- 0.27501773834228516 seconds for one epoch ---
--- 1.1205074787139893 seconds for one epoch ---
--- 0.28738999366760254 seconds for one epoch ---
--- 1.121063470840454 seconds for one epoch ---
--- 0.30203676223754883 seconds for one epoch ---
--- 1.124084234237671 seconds for one epoch ---
--- 0.1805706024169922 seconds for one epoch ---
--- 1.1226470470428467 seconds for one epoch ---
--- 0.29131102561950684 seconds for one epoch ---
--- 1.127467393875122 seconds for one epoch ---
--- 0.2885622978210449 seconds for one epoch ---
--- 1.1701297760009766 seconds for one epoch ---
--- 0.2894754409790039 seconds for one epoch ---
--- 1.172234058380127 seconds for one epoch ---
--- 0.29756879806518555 seconds for one epoch ---
--- 1.1165008544921875 seconds for one epoch ---
--- 0.2881629467010498 seconds for one epoch ---
--- 1.1209042072296143 seconds for one epoch ---
--- 0.2941322326660156 seconds for one epoch ---
--- 1.118837594985962 seconds for one epoch ---
--- 0.258465051651001 seconds for one epoch ---
--- 1.1825780868530273 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27694129943847656 seconds for one epoch ---
463.2545009394289
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3236.78076171875, (1513.0112, 1.9623519, 1721.807, 0.0)
   validation loss 978.6935424804688, (636.1225, 0.36870974, 342.20233, 0.0)
decoder loss ratio: 24644.489913, decoder SINDy loss  ratio: 0.738692
--- 0.265286922454834 seconds for one epoch ---
--- 0.28616976737976074 seconds for one epoch ---
--- 1.1488556861877441 seconds for one epoch ---
--- 0.2958385944366455 seconds for one epoch ---
--- 1.1407184600830078 seconds for one epoch ---
--- 0.29738330841064453 seconds for one epoch ---
--- 1.1545183658599854 seconds for one epoch ---
--- 0.2958414554595947 seconds for one epoch ---
--- 1.149601936340332 seconds for one epoch ---
--- 0.29034852981567383 seconds for one epoch ---
--- 1.1250033378601074 seconds for one epoch ---
--- 0.22324657440185547 seconds for one epoch ---
--- 1.184354543685913 seconds for one epoch ---
--- 0.29366230964660645 seconds for one epoch ---
--- 1.146785020828247 seconds for one epoch ---
--- 0.2936668395996094 seconds for one epoch ---
--- 1.1429393291473389 seconds for one epoch ---
--- 0.2787477970123291 seconds for one epoch ---
--- 1.1799819469451904 seconds for one epoch ---
--- 0.3143148422241211 seconds for one epoch ---
--- 1.1745998859405518 seconds for one epoch ---
--- 0.29926609992980957 seconds for one epoch ---
--- 1.185401201248169 seconds for one epoch ---
--- 0.2840588092803955 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25591397285461426 seconds for one epoch ---
463.2545009394289
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8568.546875, (1447.1813, 13.141749, 7108.2236, 0.0)
   validation loss 961.5711669921875, (631.9703, 0.43474263, 329.16617, 0.0)
decoder loss ratio: 24483.625636, decoder SINDy loss  ratio: 0.710551
--- 0.2861201763153076 seconds for one epoch ---
--- 1.1442499160766602 seconds for one epoch ---
--- 0.2930030822753906 seconds for one epoch ---
--- 1.1551995277404785 seconds for one epoch ---
--- 0.2930154800415039 seconds for one epoch ---
--- 1.0991649627685547 seconds for one epoch ---
--- 0.2270832061767578 seconds for one epoch ---
--- 1.1659393310546875 seconds for one epoch ---
--- 0.2914566993713379 seconds for one epoch ---
--- 1.149611473083496 seconds for one epoch ---
--- 0.29692554473876953 seconds for one epoch ---
--- 1.1303751468658447 seconds for one epoch ---
--- 0.29709577560424805 seconds for one epoch ---
--- 1.1354198455810547 seconds for one epoch ---
--- 0.29190564155578613 seconds for one epoch ---
--- 1.171827793121338 seconds for one epoch ---
--- 0.29808998107910156 seconds for one epoch ---
--- 1.1588115692138672 seconds for one epoch ---
--- 0.29937100410461426 seconds for one epoch ---
--- 1.1606762409210205 seconds for one epoch ---
--- 0.2390141487121582 seconds for one epoch ---
--- 1.1807589530944824 seconds for one epoch ---
--- 0.31516051292419434 seconds for one epoch ---
--- 1.173344373703003 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2965857982635498 seconds for one epoch ---
463.2545009394289
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3682.352783203125, (1809.5997, 1.8808837, 1870.8722, 0.0)
   validation loss 982.927490234375, (648.3358, 0.54901695, 334.04263, 0.0)
decoder loss ratio: 25117.655050, decoder SINDy loss  ratio: 0.721078
--- 0.2570004463195801 seconds for one epoch ---
--- 0.2901573181152344 seconds for one epoch ---
--- 1.1806304454803467 seconds for one epoch ---
--- 0.28711962699890137 seconds for one epoch ---
--- 1.1723761558532715 seconds for one epoch ---
--- 0.29412841796875 seconds for one epoch ---
--- 1.1585440635681152 seconds for one epoch ---
--- 0.2845458984375 seconds for one epoch ---
--- 1.08982515335083 seconds for one epoch ---
--- 0.24918770790100098 seconds for one epoch ---
--- 1.180544137954712 seconds for one epoch ---
--- 0.2928619384765625 seconds for one epoch ---
--- 1.204885721206665 seconds for one epoch ---
--- 0.2906975746154785 seconds for one epoch ---
--- 1.1974899768829346 seconds for one epoch ---
--- 0.29752135276794434 seconds for one epoch ---
--- 1.2098867893218994 seconds for one epoch ---
--- 0.2984938621520996 seconds for one epoch ---
--- 1.1750476360321045 seconds for one epoch ---
--- 0.29706692695617676 seconds for one epoch ---
--- 1.168313980102539 seconds for one epoch ---
--- 0.2889595031738281 seconds for one epoch ---
--- 1.1935863494873047 seconds for one epoch ---
--- 0.2932751178741455 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2552952766418457 seconds for one epoch ---
463.2545009394289
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3404.83837890625, (1175.9855, 4.4440155, 2224.409, 0.0)
   validation loss 864.781494140625, (530.5605, 0.3849744, 333.83606, 0.0)
decoder loss ratio: 20554.834315, decoder SINDy loss  ratio: 0.720632
--- 0.2847626209259033 seconds for one epoch ---
--- 1.1761372089385986 seconds for one epoch ---
--- 0.3000195026397705 seconds for one epoch ---
--- 1.0625300407409668 seconds for one epoch ---
--- 0.2261810302734375 seconds for one epoch ---
--- 1.207756757736206 seconds for one epoch ---
--- 0.3049201965332031 seconds for one epoch ---
--- 1.1833713054656982 seconds for one epoch ---
--- 0.29114222526550293 seconds for one epoch ---
--- 1.1686437129974365 seconds for one epoch ---
--- 0.2928926944732666 seconds for one epoch ---
--- 1.2042806148529053 seconds for one epoch ---
--- 0.2969672679901123 seconds for one epoch ---
--- 1.2104132175445557 seconds for one epoch ---
--- 0.29477691650390625 seconds for one epoch ---
--- 1.193401575088501 seconds for one epoch ---
--- 0.28731203079223633 seconds for one epoch ---
--- 1.1949868202209473 seconds for one epoch ---
--- 0.3028712272644043 seconds for one epoch ---
--- 1.1989951133728027 seconds for one epoch ---
--- 0.29305553436279297 seconds for one epoch ---
--- 1.210325002670288 seconds for one epoch ---
--- 0.303088903427124 seconds for one epoch ---
--- 1.2015151977539062 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2837686538696289 seconds for one epoch ---
463.2545009394289
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4361.521484375, (1543.3279, 1.6403879, 2816.5532, 0.0)
   validation loss 1450.9346923828125, (1129.2196, 0.5111947, 321.2039, 0.0)
decoder loss ratio: 43747.927889, decoder SINDy loss  ratio: 0.693364
--- 0.264803409576416 seconds for one epoch ---
--- 0.28035664558410645 seconds for one epoch ---
--- 1.186471939086914 seconds for one epoch ---
--- 0.289592981338501 seconds for one epoch ---
--- 1.1477763652801514 seconds for one epoch ---
--- 0.1464529037475586 seconds for one epoch ---
--- 1.1875 seconds for one epoch ---
--- 0.2811915874481201 seconds for one epoch ---
--- 1.2102835178375244 seconds for one epoch ---
--- 0.28276968002319336 seconds for one epoch ---
--- 1.1977365016937256 seconds for one epoch ---
--- 0.29099464416503906 seconds for one epoch ---
--- 1.2134075164794922 seconds for one epoch ---
--- 0.2883312702178955 seconds for one epoch ---
--- 1.213484764099121 seconds for one epoch ---
--- 0.29317569732666016 seconds for one epoch ---
--- 1.2043535709381104 seconds for one epoch ---
--- 0.2886927127838135 seconds for one epoch ---
--- 1.2013585567474365 seconds for one epoch ---
--- 0.2875232696533203 seconds for one epoch ---
--- 1.2284235954284668 seconds for one epoch ---
--- 0.2964599132537842 seconds for one epoch ---
--- 1.2330944538116455 seconds for one epoch ---
--- 0.2951474189758301 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.254016637802124 seconds for one epoch ---
463.2545009394289
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3081.71875, (1325.7034, 2.054219, 1753.961, 0.0)
   validation loss 1031.987060546875, (686.73425, 0.3411759, 344.91165, 0.0)
decoder loss ratio: 26605.277182, decoder SINDy loss  ratio: 0.744540
--- 0.303699254989624 seconds for one epoch ---
--- 1.0693178176879883 seconds for one epoch ---
--- 0.2695610523223877 seconds for one epoch ---
--- 1.2136690616607666 seconds for one epoch ---
--- 0.29236721992492676 seconds for one epoch ---
--- 1.2267284393310547 seconds for one epoch ---
--- 0.2989633083343506 seconds for one epoch ---
--- 1.1920218467712402 seconds for one epoch ---
--- 0.2897379398345947 seconds for one epoch ---
--- 1.226381540298462 seconds for one epoch ---
--- 0.29036927223205566 seconds for one epoch ---
--- 1.2270424365997314 seconds for one epoch ---
--- 0.29105186462402344 seconds for one epoch ---
--- 1.1572904586791992 seconds for one epoch ---
--- 0.28382396697998047 seconds for one epoch ---
--- 1.2389411926269531 seconds for one epoch ---
--- 0.2983095645904541 seconds for one epoch ---
--- 1.2195706367492676 seconds for one epoch ---
--- 0.2893240451812744 seconds for one epoch ---
--- 1.2210357189178467 seconds for one epoch ---
--- 0.29651403427124023 seconds for one epoch ---
--- 1.2109038829803467 seconds for one epoch ---
--- 0.15167021751403809 seconds for one epoch ---
--- 1.237999677658081 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29166221618652344 seconds for one epoch ---
463.2545009394289
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6425.5, (1803.1323, 6.5787115, 4615.789, 0.0)
   validation loss 1342.7684326171875, (974.2581, 0.30907005, 368.20126, 0.0)
decoder loss ratio: 37744.450865, decoder SINDy loss  ratio: 0.794814
--- 0.25621700286865234 seconds for one epoch ---
--- 0.28386878967285156 seconds for one epoch ---
--- 1.1392815113067627 seconds for one epoch ---
--- 0.22108674049377441 seconds for one epoch ---
--- 1.2083725929260254 seconds for one epoch ---
--- 0.29544615745544434 seconds for one epoch ---
--- 1.2004868984222412 seconds for one epoch ---
--- 0.27718496322631836 seconds for one epoch ---
--- 1.2449491024017334 seconds for one epoch ---
--- 0.29184722900390625 seconds for one epoch ---
--- 1.2551493644714355 seconds for one epoch ---
--- 0.29999470710754395 seconds for one epoch ---
--- 1.2282960414886475 seconds for one epoch ---
--- 0.2914109230041504 seconds for one epoch ---
--- 1.252380132675171 seconds for one epoch ---
--- 0.29485106468200684 seconds for one epoch ---
--- 1.2195978164672852 seconds for one epoch ---
--- 0.2896263599395752 seconds for one epoch ---
--- 1.2372405529022217 seconds for one epoch ---
--- 0.2959885597229004 seconds for one epoch ---
--- 1.2285935878753662 seconds for one epoch ---
--- 0.2882261276245117 seconds for one epoch ---
--- 1.0971357822418213 seconds for one epoch ---
--- 0.24357938766479492 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2543454170227051 seconds for one epoch ---
463.2545009394289
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3868.1162109375, (1602.552, 2.0300982, 2263.534, 0.0)
   validation loss 885.0175170898438, (552.8206, 0.36463276, 331.83228, 0.0)
decoder loss ratio: 21417.230468, decoder SINDy loss  ratio: 0.716307
--- 0.29418134689331055 seconds for one epoch ---
--- 1.2179677486419678 seconds for one epoch ---
--- 0.29407596588134766 seconds for one epoch ---
--- 1.2251026630401611 seconds for one epoch ---
--- 0.2305736541748047 seconds for one epoch ---
--- 1.2460975646972656 seconds for one epoch ---
--- 0.29396891593933105 seconds for one epoch ---
--- 1.2218530178070068 seconds for one epoch ---
--- 0.2984578609466553 seconds for one epoch ---
--- 1.2360084056854248 seconds for one epoch ---
--- 0.28127121925354004 seconds for one epoch ---
--- 1.2591893672943115 seconds for one epoch ---
--- 0.28710246086120605 seconds for one epoch ---
--- 1.2361955642700195 seconds for one epoch ---
--- 0.29023146629333496 seconds for one epoch ---
--- 1.2456014156341553 seconds for one epoch ---
--- 0.2942659854888916 seconds for one epoch ---
--- 1.1338067054748535 seconds for one epoch ---
--- 0.28865480422973633 seconds for one epoch ---
--- 1.2392375469207764 seconds for one epoch ---
--- 0.30460643768310547 seconds for one epoch ---
--- 1.2425174713134766 seconds for one epoch ---
--- 0.2925593852996826 seconds for one epoch ---
--- 1.2468485832214355 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.31124162673950195 seconds for one epoch ---
463.2545009394289
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3893.6123046875, (1677.3259, 5.427822, 2210.8586, 0.0)
   validation loss 1001.576904296875, (637.82904, 0.3362663, 363.4116, 0.0)
decoder loss ratio: 24710.604350, decoder SINDy loss  ratio: 0.784475
--- 0.27420687675476074 seconds for one epoch ---
--- 0.2991311550140381 seconds for one epoch ---
--- 1.234412670135498 seconds for one epoch ---
--- 0.29376220703125 seconds for one epoch ---
--- 1.2258055210113525 seconds for one epoch ---
--- 0.29259681701660156 seconds for one epoch ---
--- 1.2434453964233398 seconds for one epoch ---
--- 0.2944958209991455 seconds for one epoch ---
--- 1.240046739578247 seconds for one epoch ---
--- 0.2878124713897705 seconds for one epoch ---
--- 1.2604906558990479 seconds for one epoch ---
--- 0.20329523086547852 seconds for one epoch ---
--- 1.2775452136993408 seconds for one epoch ---
--- 0.27261900901794434 seconds for one epoch ---
--- 1.2609586715698242 seconds for one epoch ---
--- 0.29373693466186523 seconds for one epoch ---
--- 1.257939100265503 seconds for one epoch ---
--- 0.28759765625 seconds for one epoch ---
--- 1.3155107498168945 seconds for one epoch ---
--- 0.2924349308013916 seconds for one epoch ---
--- 1.2287328243255615 seconds for one epoch ---
--- 0.28844547271728516 seconds for one epoch ---
--- 1.235379695892334 seconds for one epoch ---
--- 0.291485071182251 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25716280937194824 seconds for one epoch ---
463.2545009394289
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2888.201904296875, (1488.1293, 1.2265348, 1398.8461, 0.0)
   validation loss 1062.15478515625, (741.4595, 0.43192133, 320.26334, 0.0)
decoder loss ratio: 28725.427201, decoder SINDy loss  ratio: 0.691333
--- 0.2883117198944092 seconds for one epoch ---
--- 1.270277500152588 seconds for one epoch ---
--- 0.29055023193359375 seconds for one epoch ---
--- 1.2337298393249512 seconds for one epoch ---
--- 0.29595279693603516 seconds for one epoch ---
--- 1.2688853740692139 seconds for one epoch ---
--- 0.2982504367828369 seconds for one epoch ---
--- 1.227034091949463 seconds for one epoch ---
--- 0.2987043857574463 seconds for one epoch ---
--- 1.2613561153411865 seconds for one epoch ---
--- 0.2966320514678955 seconds for one epoch ---
--- 1.334859848022461 seconds for one epoch ---
--- 0.30266451835632324 seconds for one epoch ---
--- 1.271517038345337 seconds for one epoch ---
--- 0.2960953712463379 seconds for one epoch ---
--- 1.2760379314422607 seconds for one epoch ---
--- 0.2907731533050537 seconds for one epoch ---
--- 1.2943305969238281 seconds for one epoch ---
--- 0.2838456630706787 seconds for one epoch ---
--- 1.258786678314209 seconds for one epoch ---
--- 0.28861141204833984 seconds for one epoch ---
--- 1.2915258407592773 seconds for one epoch ---
--- 0.2947068214416504 seconds for one epoch ---
--- 1.1069750785827637 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3011298179626465 seconds for one epoch ---
463.2545009394289
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4522.21044921875, (1398.1223, 0.59056425, 3123.4976, 0.0)
   validation loss 1040.6488037109375, (693.27094, 0.35257286, 347.02527, 0.0)
decoder loss ratio: 26858.519595, decoder SINDy loss  ratio: 0.749103
THRESHOLDING: 0 active coefficients
--- 1.2525129318237305 seconds for one epoch ---
--- 0.30043983459472656 seconds for one epoch ---
--- 1.2765882015228271 seconds for one epoch ---
--- 0.26424717903137207 seconds for one epoch ---
--- 1.3423378467559814 seconds for one epoch ---
--- 0.2948033809661865 seconds for one epoch ---
--- 1.2853877544403076 seconds for one epoch ---
--- 0.2915527820587158 seconds for one epoch ---
--- 1.2930400371551514 seconds for one epoch ---
--- 0.28081345558166504 seconds for one epoch ---
--- 1.3016934394836426 seconds for one epoch ---
--- 0.2917344570159912 seconds for one epoch ---
--- 1.28513503074646 seconds for one epoch ---
--- 0.296184778213501 seconds for one epoch ---
--- 1.280242681503296 seconds for one epoch ---
--- 0.28778505325317383 seconds for one epoch ---
--- 1.3328001499176025 seconds for one epoch ---
--- 0.3065667152404785 seconds for one epoch ---
--- 1.2947754859924316 seconds for one epoch ---
--- 0.30126094818115234 seconds for one epoch ---
--- 1.2518470287322998 seconds for one epoch ---
--- 0.28832197189331055 seconds for one epoch ---
--- 1.3371069431304932 seconds for one epoch ---
--- 0.28223299980163574 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.23882603645324707 seconds for one epoch ---
463.2545009394289
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4066.7041015625, (1941.2478, 9.011417, 2116.4448, 0.0)
   validation loss 1265.6485595703125, (895.4209, 0.41861504, 369.80905, 0.0)
decoder loss ratio: 34690.160125, decoder SINDy loss  ratio: 0.798285
--- 0.29633665084838867 seconds for one epoch ---
--- 1.2479302883148193 seconds for one epoch ---
--- 0.3010673522949219 seconds for one epoch ---
--- 1.2679412364959717 seconds for one epoch ---
--- 0.29193711280822754 seconds for one epoch ---
--- 1.2729904651641846 seconds for one epoch ---
--- 0.29936647415161133 seconds for one epoch ---
--- 1.2523949146270752 seconds for one epoch ---
--- 0.2952537536621094 seconds for one epoch ---
--- 1.281252145767212 seconds for one epoch ---
--- 0.28638768196105957 seconds for one epoch ---
--- 1.1204042434692383 seconds for one epoch ---
--- 0.2408757209777832 seconds for one epoch ---
--- 1.2445027828216553 seconds for one epoch ---
--- 0.2960219383239746 seconds for one epoch ---
--- 1.274482011795044 seconds for one epoch ---
--- 0.29169249534606934 seconds for one epoch ---
--- 1.2985434532165527 seconds for one epoch ---
--- 0.26136040687561035 seconds for one epoch ---
--- 1.2916560173034668 seconds for one epoch ---
--- 0.2875697612762451 seconds for one epoch ---
--- 1.2762305736541748 seconds for one epoch ---
--- 0.2986116409301758 seconds for one epoch ---
--- 1.2591545581817627 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28626370429992676 seconds for one epoch ---
463.2545009394289
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2486.3046875, (1156.7755, 3.2133389, 1326.3157, 0.0)
   validation loss 980.0794677734375, (582.31305, 0.510897, 397.25546, 0.0)
decoder loss ratio: 22559.818470, decoder SINDy loss  ratio: 0.857532
--- 0.266066312789917 seconds for one epoch ---
--- 0.2888469696044922 seconds for one epoch ---
--- 1.2923665046691895 seconds for one epoch ---
--- 0.3019084930419922 seconds for one epoch ---
--- 1.178194284439087 seconds for one epoch ---
--- 0.2411203384399414 seconds for one epoch ---
--- 1.2901651859283447 seconds for one epoch ---
--- 0.29067015647888184 seconds for one epoch ---
--- 1.2805118560791016 seconds for one epoch ---
--- 0.29147839546203613 seconds for one epoch ---
--- 1.2997150421142578 seconds for one epoch ---
--- 0.20142173767089844 seconds for one epoch ---
--- 1.2991583347320557 seconds for one epoch ---
--- 0.29326367378234863 seconds for one epoch ---
--- 1.3099982738494873 seconds for one epoch ---
--- 0.28873634338378906 seconds for one epoch ---
--- 1.2418460845947266 seconds for one epoch ---
--- 0.2785637378692627 seconds for one epoch ---
--- 1.3438339233398438 seconds for one epoch ---
--- 0.2902061939239502 seconds for one epoch ---
--- 1.2892327308654785 seconds for one epoch ---
--- 0.30559372901916504 seconds for one epoch ---
--- 1.3181934356689453 seconds for one epoch ---
--- 0.2943992614746094 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26090383529663086 seconds for one epoch ---
463.2545009394289
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6368.3837890625, (1672.5507, 3.9641922, 4691.8687, 0.0)
   validation loss 988.935302734375, (645.6196, 0.42257002, 342.8931, 0.0)
decoder loss ratio: 25012.425269, decoder SINDy loss  ratio: 0.740183
--- 0.2967245578765869 seconds for one epoch ---
--- 1.3127377033233643 seconds for one epoch ---
--- 0.2946479320526123 seconds for one epoch ---
--- 1.314565896987915 seconds for one epoch ---
--- 0.2974393367767334 seconds for one epoch ---
--- 1.335111379623413 seconds for one epoch ---
--- 0.2980685234069824 seconds for one epoch ---
--- 1.3218915462493896 seconds for one epoch ---
--- 0.2964932918548584 seconds for one epoch ---
--- 1.314333438873291 seconds for one epoch ---
--- 0.29936790466308594 seconds for one epoch ---
--- 1.2866885662078857 seconds for one epoch ---
--- 0.2909059524536133 seconds for one epoch ---
--- 1.2957344055175781 seconds for one epoch ---
--- 0.28929829597473145 seconds for one epoch ---
--- 1.256948471069336 seconds for one epoch ---
--- 0.2810659408569336 seconds for one epoch ---
--- 1.2987427711486816 seconds for one epoch ---
--- 0.2931480407714844 seconds for one epoch ---
--- 1.2671246528625488 seconds for one epoch ---
--- 0.2928919792175293 seconds for one epoch ---
--- 1.3011298179626465 seconds for one epoch ---
--- 0.20580053329467773 seconds for one epoch ---
--- 1.313882827758789 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2987711429595947 seconds for one epoch ---
463.2545009394289
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3392.462158203125, (1949.1577, 1.8939718, 1441.4105, 0.0)
   validation loss 903.8934326171875, (564.69836, 0.43317753, 338.76193, 0.0)
decoder loss ratio: 21877.394991, decoder SINDy loss  ratio: 0.731265
--- 0.22582101821899414 seconds for one epoch ---
--- 0.2505185604095459 seconds for one epoch ---
--- 1.3910822868347168 seconds for one epoch ---
--- 0.2919924259185791 seconds for one epoch ---
--- 1.304426908493042 seconds for one epoch ---
--- 0.2893364429473877 seconds for one epoch ---
--- 1.3379735946655273 seconds for one epoch ---
--- 0.2966458797454834 seconds for one epoch ---
--- 1.3419742584228516 seconds for one epoch ---
--- 0.2695345878601074 seconds for one epoch ---
--- 1.2948617935180664 seconds for one epoch ---
--- 0.28392863273620605 seconds for one epoch ---
--- 1.31248140335083 seconds for one epoch ---
--- 0.28530216217041016 seconds for one epoch ---
--- 1.332350254058838 seconds for one epoch ---
--- 0.2989523410797119 seconds for one epoch ---
--- 1.311858892440796 seconds for one epoch ---
--- 0.2972238063812256 seconds for one epoch ---
--- 1.3058223724365234 seconds for one epoch ---
--- 0.2917168140411377 seconds for one epoch ---
--- 1.2752606868743896 seconds for one epoch ---
--- 0.2940826416015625 seconds for one epoch ---
--- 1.2947030067443848 seconds for one epoch ---
--- 0.3047821521759033 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2495415210723877 seconds for one epoch ---
463.2545009394289
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3209.97607421875, (1400.3347, 3.0056038, 1806.6359, 0.0)
   validation loss 1940.481689453125, (1582.5336, 0.47894603, 357.46915, 0.0)
decoder loss ratio: 61310.097875, decoder SINDy loss  ratio: 0.771647
--- 0.29131650924682617 seconds for one epoch ---
--- 1.3419506549835205 seconds for one epoch ---
--- 0.29021120071411133 seconds for one epoch ---
--- 1.32948637008667 seconds for one epoch ---
--- 0.2863335609436035 seconds for one epoch ---
--- 1.3141529560089111 seconds for one epoch ---
--- 0.3082551956176758 seconds for one epoch ---
--- 1.32248854637146 seconds for one epoch ---
--- 0.3169713020324707 seconds for one epoch ---
--- 1.340094804763794 seconds for one epoch ---
--- 0.29862499237060547 seconds for one epoch ---
--- 1.3192548751831055 seconds for one epoch ---
--- 0.2962014675140381 seconds for one epoch ---
--- 1.419109582901001 seconds for one epoch ---
--- 0.2895846366882324 seconds for one epoch ---
--- 1.3163669109344482 seconds for one epoch ---
--- 0.29080724716186523 seconds for one epoch ---
--- 1.3382766246795654 seconds for one epoch ---
--- 0.30058836936950684 seconds for one epoch ---
--- 1.3267254829406738 seconds for one epoch ---
--- 0.29397153854370117 seconds for one epoch ---
--- 1.3404524326324463 seconds for one epoch ---
--- 0.28452181816101074 seconds for one epoch ---
--- 1.3466124534606934 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27942562103271484 seconds for one epoch ---
463.2545009394289
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5405.17236328125, (1927.9994, 4.7421713, 3472.4307, 0.0)
   validation loss 874.6077880859375, (549.1805, 0.56733114, 324.86002, 0.0)
decoder loss ratio: 21276.205252, decoder SINDy loss  ratio: 0.701256
--- 0.2556936740875244 seconds for one epoch ---
--- 0.28997111320495605 seconds for one epoch ---
--- 1.335434913635254 seconds for one epoch ---
--- 0.30216455459594727 seconds for one epoch ---
--- 1.414992094039917 seconds for one epoch ---
--- 0.30457043647766113 seconds for one epoch ---
--- 1.2890417575836182 seconds for one epoch ---
--- 0.29680895805358887 seconds for one epoch ---
--- 1.318310022354126 seconds for one epoch ---
--- 0.28258419036865234 seconds for one epoch ---
--- 1.360825777053833 seconds for one epoch ---
--- 0.3079712390899658 seconds for one epoch ---
--- 1.3504490852355957 seconds for one epoch ---
--- 0.3024022579193115 seconds for one epoch ---
--- 1.3190243244171143 seconds for one epoch ---
--- 0.28868651390075684 seconds for one epoch ---
--- 1.3155601024627686 seconds for one epoch ---
--- 0.31114697456359863 seconds for one epoch ---
--- 1.3353662490844727 seconds for one epoch ---
--- 0.298602819442749 seconds for one epoch ---
--- 1.3399627208709717 seconds for one epoch ---
--- 0.28702783584594727 seconds for one epoch ---
--- 1.2382497787475586 seconds for one epoch ---
--- 0.24068093299865723 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26233959197998047 seconds for one epoch ---
463.2545009394289
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3540.76806640625, (1232.8156, 6.1415544, 2301.811, 0.0)
   validation loss 856.8646240234375, (534.79694, 0.5176701, 321.54996, 0.0)
decoder loss ratio: 20718.961750, decoder SINDy loss  ratio: 0.694111
--- 0.29774975776672363 seconds for one epoch ---
--- 1.340242624282837 seconds for one epoch ---
--- 0.29227232933044434 seconds for one epoch ---
--- 1.3805725574493408 seconds for one epoch ---
--- 0.29372072219848633 seconds for one epoch ---
--- 1.3536310195922852 seconds for one epoch ---
--- 0.28001928329467773 seconds for one epoch ---
--- 1.367985486984253 seconds for one epoch ---
--- 0.288299560546875 seconds for one epoch ---
--- 1.3280813694000244 seconds for one epoch ---
--- 0.2901623249053955 seconds for one epoch ---
--- 1.3534438610076904 seconds for one epoch ---
--- 0.2961587905883789 seconds for one epoch ---
--- 1.3562250137329102 seconds for one epoch ---
--- 0.28493332862854004 seconds for one epoch ---
--- 1.3747007846832275 seconds for one epoch ---
--- 0.2810518741607666 seconds for one epoch ---
--- 1.3600058555603027 seconds for one epoch ---
--- 0.2896745204925537 seconds for one epoch ---
--- 1.349182367324829 seconds for one epoch ---
--- 0.29451894760131836 seconds for one epoch ---
--- 1.3531172275543213 seconds for one epoch ---
--- 0.29409027099609375 seconds for one epoch ---
--- 1.3775200843811035 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2979393005371094 seconds for one epoch ---
463.2545009394289
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4641.42578125, (1625.1464, 6.527751, 3009.7515, 0.0)
   validation loss 1062.4580078125, (735.8603, 0.5152327, 326.0824, 0.0)
decoder loss ratio: 28508.505165, decoder SINDy loss  ratio: 0.703895
--- 0.25980305671691895 seconds for one epoch ---
--- 0.2955322265625 seconds for one epoch ---
--- 1.3696422576904297 seconds for one epoch ---
--- 0.28969907760620117 seconds for one epoch ---
--- 1.379683494567871 seconds for one epoch ---
--- 0.29067087173461914 seconds for one epoch ---
--- 1.3541407585144043 seconds for one epoch ---
--- 0.292283296585083 seconds for one epoch ---
--- 1.3954663276672363 seconds for one epoch ---
--- 0.28925085067749023 seconds for one epoch ---
--- 1.38853120803833 seconds for one epoch ---
--- 0.29160404205322266 seconds for one epoch ---
--- 1.356290340423584 seconds for one epoch ---
--- 0.29823899269104004 seconds for one epoch ---
--- 1.3643386363983154 seconds for one epoch ---
--- 0.30940890312194824 seconds for one epoch ---
--- 1.3946099281311035 seconds for one epoch ---
--- 0.288440465927124 seconds for one epoch ---
--- 1.2534348964691162 seconds for one epoch ---
--- 0.24835968017578125 seconds for one epoch ---
--- 1.4297804832458496 seconds for one epoch ---
--- 0.29529237747192383 seconds for one epoch ---
--- 1.3935868740081787 seconds for one epoch ---
--- 0.2963435649871826 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26103711128234863 seconds for one epoch ---
463.2545009394289
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5857.9150390625, (1713.5137, 13.615653, 4130.7856, 0.0)
   validation loss 1144.0076904296875, (797.7214, 0.44416836, 345.84213, 0.0)
decoder loss ratio: 30905.110954, decoder SINDy loss  ratio: 0.746549
--- 0.30208349227905273 seconds for one epoch ---
--- 1.3715941905975342 seconds for one epoch ---
--- 0.29068446159362793 seconds for one epoch ---
--- 1.3783957958221436 seconds for one epoch ---
--- 0.1459522247314453 seconds for one epoch ---
--- 1.4197862148284912 seconds for one epoch ---
--- 0.289400577545166 seconds for one epoch ---
--- 1.4035098552703857 seconds for one epoch ---
--- 0.2922489643096924 seconds for one epoch ---
--- 1.4045472145080566 seconds for one epoch ---
--- 0.20416879653930664 seconds for one epoch ---
--- 1.4116618633270264 seconds for one epoch ---
--- 0.2862086296081543 seconds for one epoch ---
--- 1.3976552486419678 seconds for one epoch ---
--- 0.29755425453186035 seconds for one epoch ---
--- 1.4116871356964111 seconds for one epoch ---
--- 0.2630128860473633 seconds for one epoch ---
--- 1.4317288398742676 seconds for one epoch ---
--- 0.29346132278442383 seconds for one epoch ---
--- 1.4080901145935059 seconds for one epoch ---
--- 0.3012964725494385 seconds for one epoch ---
--- 1.3837354183197021 seconds for one epoch ---
--- 0.26703715324401855 seconds for one epoch ---
--- 1.411907434463501 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29309701919555664 seconds for one epoch ---
463.2545009394289
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3352.61865234375, (1130.3904, 1.323166, 2220.905, 0.0)
   validation loss 919.6390380859375, (604.7786, 0.53786606, 314.32257, 0.0)
decoder loss ratio: 23430.173893, decoder SINDy loss  ratio: 0.678509
--- 0.26918911933898926 seconds for one epoch ---
--- 0.23573899269104004 seconds for one epoch ---
--- 1.351285696029663 seconds for one epoch ---
--- 0.29509687423706055 seconds for one epoch ---
--- 1.4196515083312988 seconds for one epoch ---
--- 0.2937760353088379 seconds for one epoch ---
--- 1.424858570098877 seconds for one epoch ---
--- 0.24977540969848633 seconds for one epoch ---
--- 1.4308631420135498 seconds for one epoch ---
--- 0.5367019176483154 seconds for one epoch ---
--- 1.403074026107788 seconds for one epoch ---
--- 0.3080732822418213 seconds for one epoch ---
--- 1.329796314239502 seconds for one epoch ---
--- 0.1542963981628418 seconds for one epoch ---
--- 1.4137675762176514 seconds for one epoch ---
--- 0.28079771995544434 seconds for one epoch ---
--- 1.4351403713226318 seconds for one epoch ---
--- 0.2934846878051758 seconds for one epoch ---
--- 1.39632248878479 seconds for one epoch ---
--- 0.18599343299865723 seconds for one epoch ---
--- 1.4150502681732178 seconds for one epoch ---
--- 0.2955355644226074 seconds for one epoch ---
--- 1.399970531463623 seconds for one epoch ---
--- 0.27771425247192383 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25717997550964355 seconds for one epoch ---
463.2545009394289
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3997.959228515625, (1523.9045, 4.530062, 2469.5247, 0.0)
   validation loss 842.6427612304688, (519.92786, 0.48350883, 322.23138, 0.0)
decoder loss ratio: 20142.907793, decoder SINDy loss  ratio: 0.695582
--- 0.2805964946746826 seconds for one epoch ---
--- 1.4630978107452393 seconds for one epoch ---
--- 0.28876590728759766 seconds for one epoch ---
--- 1.2838895320892334 seconds for one epoch ---
--- 0.27883172035217285 seconds for one epoch ---
--- 1.4128973484039307 seconds for one epoch ---
--- 0.29508256912231445 seconds for one epoch ---
--- 1.4382853507995605 seconds for one epoch ---
--- 0.2987055778503418 seconds for one epoch ---
--- 1.3077113628387451 seconds for one epoch ---
--- 0.24258923530578613 seconds for one epoch ---
--- 1.3920283317565918 seconds for one epoch ---
--- 0.29286885261535645 seconds for one epoch ---
--- 1.4173541069030762 seconds for one epoch ---
--- 0.2963898181915283 seconds for one epoch ---
--- 1.3796534538269043 seconds for one epoch ---
--- 0.25447916984558105 seconds for one epoch ---
--- 1.425252914428711 seconds for one epoch ---
--- 0.2978241443634033 seconds for one epoch ---
--- 1.4293546676635742 seconds for one epoch ---
--- 0.2782256603240967 seconds for one epoch ---
--- 1.3694448471069336 seconds for one epoch ---
--- 0.2962181568145752 seconds for one epoch ---
--- 1.4168522357940674 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2914915084838867 seconds for one epoch ---
463.2545009394289
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6805.3076171875, (4601.768, 14.972106, 2188.5676, 0.0)
   validation loss 895.7586669921875, (582.70374, 0.48114687, 312.57376, 0.0)
decoder loss ratio: 22574.954326, decoder SINDy loss  ratio: 0.674734
--- 0.15472412109375 seconds for one epoch ---
--- 0.2881155014038086 seconds for one epoch ---
--- 1.4106614589691162 seconds for one epoch ---
--- 0.28835129737854004 seconds for one epoch ---
--- 1.4052813053131104 seconds for one epoch ---
--- 0.2883470058441162 seconds for one epoch ---
--- 1.3880884647369385 seconds for one epoch ---
--- 0.29122209548950195 seconds for one epoch ---
--- 1.3817343711853027 seconds for one epoch ---
--- 0.2839789390563965 seconds for one epoch ---
--- 1.4148099422454834 seconds for one epoch ---
--- 0.29381346702575684 seconds for one epoch ---
--- 1.4405570030212402 seconds for one epoch ---
--- 0.289017915725708 seconds for one epoch ---
--- 1.4098496437072754 seconds for one epoch ---
--- 0.2935776710510254 seconds for one epoch ---
--- 1.446122407913208 seconds for one epoch ---
--- 0.2886695861816406 seconds for one epoch ---
--- 1.437211036682129 seconds for one epoch ---
--- 0.30167603492736816 seconds for one epoch ---
--- 1.420048475265503 seconds for one epoch ---
--- 0.2994256019592285 seconds for one epoch ---
--- 1.4316589832305908 seconds for one epoch ---
--- 0.2948029041290283 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25124287605285645 seconds for one epoch ---
463.2545009394289
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4971.21826171875, (1823.4816, 4.877543, 3142.8591, 0.0)
   validation loss 1157.4273681640625, (818.9088, 0.47922346, 338.0393, 0.0)
decoder loss ratio: 31725.949122, decoder SINDy loss  ratio: 0.729705
--- 0.288433313369751 seconds for one epoch ---
--- 1.437741756439209 seconds for one epoch ---
--- 0.2908608913421631 seconds for one epoch ---
--- 1.4568183422088623 seconds for one epoch ---
--- 0.30195045471191406 seconds for one epoch ---
--- 1.444338083267212 seconds for one epoch ---
--- 0.2848985195159912 seconds for one epoch ---
--- 1.4369966983795166 seconds for one epoch ---
--- 0.29338645935058594 seconds for one epoch ---
--- 1.4558935165405273 seconds for one epoch ---
--- 0.29412126541137695 seconds for one epoch ---
--- 1.4006679058074951 seconds for one epoch ---
--- 0.29938244819641113 seconds for one epoch ---
--- 1.446502685546875 seconds for one epoch ---
--- 0.2744910717010498 seconds for one epoch ---
--- 1.4386417865753174 seconds for one epoch ---
--- 0.31692028045654297 seconds for one epoch ---
--- 1.4454550743103027 seconds for one epoch ---
--- 0.306488037109375 seconds for one epoch ---
--- 1.456324577331543 seconds for one epoch ---
--- 0.29120635986328125 seconds for one epoch ---
--- 1.4617302417755127 seconds for one epoch ---
--- 0.2903895378112793 seconds for one epoch ---
--- 1.464134931564331 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28870439529418945 seconds for one epoch ---
463.2545009394289
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8416.8291015625, (1057.3153, 5.6044354, 7353.909, 0.0)
   validation loss 889.4921875, (564.63885, 0.48327538, 324.3701, 0.0)
decoder loss ratio: 21875.089498, decoder SINDy loss  ratio: 0.700198
--- 0.2553582191467285 seconds for one epoch ---
--- 0.291262149810791 seconds for one epoch ---
--- 1.4393720626831055 seconds for one epoch ---
--- 0.2923879623413086 seconds for one epoch ---
--- 1.455124855041504 seconds for one epoch ---
--- 0.22821402549743652 seconds for one epoch ---
--- 1.4571301937103271 seconds for one epoch ---
--- 0.29166650772094727 seconds for one epoch ---
--- 1.4406628608703613 seconds for one epoch ---
--- 0.2942323684692383 seconds for one epoch ---
--- 1.4236807823181152 seconds for one epoch ---
--- 0.14132952690124512 seconds for one epoch ---
--- 1.4688920974731445 seconds for one epoch ---
--- 0.28824949264526367 seconds for one epoch ---
--- 1.4295647144317627 seconds for one epoch ---
--- 0.2905421257019043 seconds for one epoch ---
--- 1.403031587600708 seconds for one epoch ---
--- 0.22173571586608887 seconds for one epoch ---
--- 1.4462299346923828 seconds for one epoch ---
--- 0.2968020439147949 seconds for one epoch ---
--- 1.4439961910247803 seconds for one epoch ---
--- 0.29763150215148926 seconds for one epoch ---
--- 1.445505142211914 seconds for one epoch ---
--- 0.2462022304534912 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24956202507019043 seconds for one epoch ---
463.2545009394289
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6185.2685546875, (1773.5958, 1.7066153, 4409.9663, 0.0)
   validation loss 1154.432373046875, (767.7699, 0.54373175, 386.11868, 0.0)
decoder loss ratio: 29744.738735, decoder SINDy loss  ratio: 0.833491
--- 0.2889533042907715 seconds for one epoch ---
--- 1.473003625869751 seconds for one epoch ---
--- 0.29409122467041016 seconds for one epoch ---
--- 1.476137638092041 seconds for one epoch ---
--- 0.291736364364624 seconds for one epoch ---
--- 1.4686670303344727 seconds for one epoch ---
--- 0.27840280532836914 seconds for one epoch ---
--- 1.4860141277313232 seconds for one epoch ---
--- 0.2867560386657715 seconds for one epoch ---
--- 1.446793556213379 seconds for one epoch ---
--- 0.2875847816467285 seconds for one epoch ---
--- 1.4649982452392578 seconds for one epoch ---
--- 0.2807903289794922 seconds for one epoch ---
--- 1.4819374084472656 seconds for one epoch ---
--- 0.2971467971801758 seconds for one epoch ---
--- 1.4957613945007324 seconds for one epoch ---
--- 0.2991180419921875 seconds for one epoch ---
--- 1.4604730606079102 seconds for one epoch ---
--- 0.2886519432067871 seconds for one epoch ---
--- 1.4550602436065674 seconds for one epoch ---
--- 0.2793879508972168 seconds for one epoch ---
--- 1.472306489944458 seconds for one epoch ---
--- 0.2887732982635498 seconds for one epoch ---
--- 1.4798872470855713 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28925204277038574 seconds for one epoch ---
463.2545009394289
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2922.5498046875, (1621.941, 2.191439, 1298.4172, 0.0)
   validation loss 1205.05908203125, (808.556, 0.45452958, 396.04858, 0.0)
decoder loss ratio: 31324.864328, decoder SINDy loss  ratio: 0.854927
--- 0.2547299861907959 seconds for one epoch ---
--- 0.2970454692840576 seconds for one epoch ---
--- 1.4861171245574951 seconds for one epoch ---
--- 0.29932498931884766 seconds for one epoch ---
--- 1.4924981594085693 seconds for one epoch ---
--- 0.2971956729888916 seconds for one epoch ---
--- 1.484591007232666 seconds for one epoch ---
--- 0.3069496154785156 seconds for one epoch ---
--- 1.489797830581665 seconds for one epoch ---
--- 0.3117201328277588 seconds for one epoch ---
--- 1.4870193004608154 seconds for one epoch ---
--- 0.2946445941925049 seconds for one epoch ---
--- 1.4959924221038818 seconds for one epoch ---
--- 0.2850303649902344 seconds for one epoch ---
--- 1.543560266494751 seconds for one epoch ---
--- 0.29386401176452637 seconds for one epoch ---
--- 1.4866969585418701 seconds for one epoch ---
--- 0.29140639305114746 seconds for one epoch ---
--- 1.462571382522583 seconds for one epoch ---
--- 0.29833245277404785 seconds for one epoch ---
--- 1.550464391708374 seconds for one epoch ---
--- 0.2958252429962158 seconds for one epoch ---
--- 1.4383282661437988 seconds for one epoch ---
--- 0.2938816547393799 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2566568851470947 seconds for one epoch ---
463.2545009394289
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4032.514892578125, (1564.6895, 6.176812, 2461.6487, 0.0)
   validation loss 1191.5330810546875, (838.8786, 0.51300865, 352.1415, 0.0)
decoder loss ratio: 32499.613363, decoder SINDy loss  ratio: 0.760147
--- 0.2866978645324707 seconds for one epoch ---
--- 1.487182378768921 seconds for one epoch ---
--- 0.3053319454193115 seconds for one epoch ---
--- 1.5377259254455566 seconds for one epoch ---
--- 0.30098962783813477 seconds for one epoch ---
--- 1.4727046489715576 seconds for one epoch ---
--- 0.29313135147094727 seconds for one epoch ---
--- 1.4831418991088867 seconds for one epoch ---
--- 0.3013901710510254 seconds for one epoch ---
--- 1.513406753540039 seconds for one epoch ---
--- 0.289945125579834 seconds for one epoch ---
--- 1.5014772415161133 seconds for one epoch ---
--- 0.2965059280395508 seconds for one epoch ---
--- 1.504946231842041 seconds for one epoch ---
--- 0.2532777786254883 seconds for one epoch ---
--- 1.5124242305755615 seconds for one epoch ---
--- 0.29138684272766113 seconds for one epoch ---
--- 1.5175092220306396 seconds for one epoch ---
--- 0.29292821884155273 seconds for one epoch ---
--- 1.5137255191802979 seconds for one epoch ---
--- 0.15713930130004883 seconds for one epoch ---
--- 1.489088773727417 seconds for one epoch ---
--- 0.2895805835723877 seconds for one epoch ---
--- 1.5081639289855957 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27752232551574707 seconds for one epoch ---
463.2545009394289
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3547.4814453125, (1895.4343, 1.4378558, 1650.6093, 0.0)
   validation loss 974.4959716796875, (650.20636, 0.56318945, 323.72644, 0.0)
decoder loss ratio: 25190.123189, decoder SINDy loss  ratio: 0.698809
--- 0.23738384246826172 seconds for one epoch ---
--- 0.27727460861206055 seconds for one epoch ---
--- 1.4878888130187988 seconds for one epoch ---
--- 0.2920095920562744 seconds for one epoch ---
--- 1.5227646827697754 seconds for one epoch ---
--- 0.29799771308898926 seconds for one epoch ---
--- 1.5087924003601074 seconds for one epoch ---
--- 0.2936224937438965 seconds for one epoch ---
--- 1.5238556861877441 seconds for one epoch ---
--- 0.30347418785095215 seconds for one epoch ---
--- 1.529733419418335 seconds for one epoch ---
--- 0.2938575744628906 seconds for one epoch ---
--- 1.5325038433074951 seconds for one epoch ---
--- 0.2955050468444824 seconds for one epoch ---
--- 1.5369656085968018 seconds for one epoch ---
--- 0.27946019172668457 seconds for one epoch ---
--- 1.5327317714691162 seconds for one epoch ---
--- 0.29362916946411133 seconds for one epoch ---
--- 1.530440092086792 seconds for one epoch ---
--- 0.2858312129974365 seconds for one epoch ---
--- 1.5065126419067383 seconds for one epoch ---
--- 0.18339252471923828 seconds for one epoch ---
--- 1.4914515018463135 seconds for one epoch ---
--- 0.285050630569458 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24679183959960938 seconds for one epoch ---
463.2545009394289
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5235.4736328125, (1925.4934, 1.8005339, 3308.1797, 0.0)
   validation loss 786.4010620117188, (460.48526, 0.6190529, 325.29675, 0.0)
decoder loss ratio: 17839.998410, decoder SINDy loss  ratio: 0.702199
--- 0.28748655319213867 seconds for one epoch ---
--- 1.5207698345184326 seconds for one epoch ---
--- 0.2912731170654297 seconds for one epoch ---
--- 1.532416582107544 seconds for one epoch ---
--- 0.30125927925109863 seconds for one epoch ---
--- 1.51096773147583 seconds for one epoch ---
--- 0.29407763481140137 seconds for one epoch ---
--- 1.5135562419891357 seconds for one epoch ---
--- 0.2879927158355713 seconds for one epoch ---
--- 1.5239055156707764 seconds for one epoch ---
--- 0.23744845390319824 seconds for one epoch ---
--- 1.5220117568969727 seconds for one epoch ---
--- 0.2819633483886719 seconds for one epoch ---
--- 1.5008537769317627 seconds for one epoch ---
--- 0.28765392303466797 seconds for one epoch ---
--- 1.487936019897461 seconds for one epoch ---
--- 0.16390180587768555 seconds for one epoch ---
--- 1.534109354019165 seconds for one epoch ---
--- 0.29421424865722656 seconds for one epoch ---
--- 1.5395739078521729 seconds for one epoch ---
--- 0.2928295135498047 seconds for one epoch ---
--- 1.4684679508209229 seconds for one epoch ---
--- 0.30341005325317383 seconds for one epoch ---
--- 1.5262460708618164 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2685215473175049 seconds for one epoch ---
463.2545009394289
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3530.503662109375, (1514.5424, 4.2301807, 2011.7311, 0.0)
   validation loss 876.4171142578125, (549.72644, 0.62949026, 326.0612, 0.0)
decoder loss ratio: 21297.356669, decoder SINDy loss  ratio: 0.703849
THRESHOLDING: 0 active coefficients
--- 1.5445811748504639 seconds for one epoch ---
--- 0.30700159072875977 seconds for one epoch ---
--- 1.4477214813232422 seconds for one epoch ---
--- 0.28142499923706055 seconds for one epoch ---
--- 1.5239062309265137 seconds for one epoch ---
--- 0.29371023178100586 seconds for one epoch ---
--- 1.5301434993743896 seconds for one epoch ---
--- 0.28920936584472656 seconds for one epoch ---
--- 1.579756736755371 seconds for one epoch ---
--- 0.2871823310852051 seconds for one epoch ---
--- 1.5246479511260986 seconds for one epoch ---
--- 0.291942834854126 seconds for one epoch ---
--- 1.5306415557861328 seconds for one epoch ---
--- 0.29073333740234375 seconds for one epoch ---
--- 1.5404045581817627 seconds for one epoch ---
--- 0.2914142608642578 seconds for one epoch ---
--- 1.5075256824493408 seconds for one epoch ---
--- 0.3018832206726074 seconds for one epoch ---
--- 1.522362470626831 seconds for one epoch ---
--- 0.2980613708496094 seconds for one epoch ---
--- 1.5809433460235596 seconds for one epoch ---
--- 0.29211926460266113 seconds for one epoch ---
--- 1.533205509185791 seconds for one epoch ---
--- 0.2881035804748535 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2522563934326172 seconds for one epoch ---
463.2545009394289
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2144.89990234375, (909.3223, 1.7142848, 1233.8632, 0.0)
   validation loss 968.2647705078125, (624.20856, 0.62740046, 343.42883, 0.0)
decoder loss ratio: 24182.923177, decoder SINDy loss  ratio: 0.741339
--- 0.25389838218688965 seconds for one epoch ---
--- 1.530869722366333 seconds for one epoch ---
--- 0.2905135154724121 seconds for one epoch ---
--- 1.536433458328247 seconds for one epoch ---
--- 0.2891707420349121 seconds for one epoch ---
--- 1.5543529987335205 seconds for one epoch ---
--- 0.2966115474700928 seconds for one epoch ---
--- 1.5436902046203613 seconds for one epoch ---
--- 0.29024648666381836 seconds for one epoch ---
--- 1.551265001296997 seconds for one epoch ---
--- 0.2911808490753174 seconds for one epoch ---
--- 1.5557334423065186 seconds for one epoch ---
--- 0.31356167793273926 seconds for one epoch ---
--- 1.561250925064087 seconds for one epoch ---
--- 0.2901034355163574 seconds for one epoch ---
--- 1.6050927639007568 seconds for one epoch ---
--- 0.2938094139099121 seconds for one epoch ---
--- 1.5356154441833496 seconds for one epoch ---
--- 0.28471946716308594 seconds for one epoch ---
--- 1.547739028930664 seconds for one epoch ---
--- 0.14627718925476074 seconds for one epoch ---
--- 1.538954496383667 seconds for one epoch ---
--- 0.2959749698638916 seconds for one epoch ---
--- 1.5733649730682373 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2915527820587158 seconds for one epoch ---
463.2545009394289
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5467.44384765625, (1403.0221, 4.9912505, 4059.4307, 0.0)
   validation loss 1045.355712890625, (716.54095, 0.6494666, 328.16525, 0.0)
decoder loss ratio: 27760.040551, decoder SINDy loss  ratio: 0.708391
--- 0.23181724548339844 seconds for one epoch ---
--- 0.28711795806884766 seconds for one epoch ---
--- 1.5653131008148193 seconds for one epoch ---
--- 0.2754232883453369 seconds for one epoch ---
--- 1.5570149421691895 seconds for one epoch ---
--- 0.29503417015075684 seconds for one epoch ---
--- 1.5590786933898926 seconds for one epoch ---
--- 0.2863907814025879 seconds for one epoch ---
--- 1.5681521892547607 seconds for one epoch ---
--- 0.302293062210083 seconds for one epoch ---
--- 1.576829195022583 seconds for one epoch ---
--- 0.2855243682861328 seconds for one epoch ---
--- 1.57973313331604 seconds for one epoch ---
--- 0.304337739944458 seconds for one epoch ---
--- 1.6085171699523926 seconds for one epoch ---
--- 0.2998685836791992 seconds for one epoch ---
--- 1.559746265411377 seconds for one epoch ---
--- 0.29429054260253906 seconds for one epoch ---
--- 1.5697815418243408 seconds for one epoch ---
--- 0.29786014556884766 seconds for one epoch ---
--- 1.5650668144226074 seconds for one epoch ---
--- 0.29026293754577637 seconds for one epoch ---
--- 1.56870698928833 seconds for one epoch ---
--- 0.2923431396484375 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2460317611694336 seconds for one epoch ---
463.2545009394289
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4721.24853515625, (1946.2504, 2.939896, 2772.0583, 0.0)
   validation loss 999.3422241210938, (655.4324, 0.6566024, 343.25323, 0.0)
decoder loss ratio: 25392.588012, decoder SINDy loss  ratio: 0.740960
--- 0.29269862174987793 seconds for one epoch ---
--- 1.5751268863677979 seconds for one epoch ---
--- 0.2781789302825928 seconds for one epoch ---
--- 1.5535736083984375 seconds for one epoch ---
--- 0.28394269943237305 seconds for one epoch ---
--- 1.569822072982788 seconds for one epoch ---
--- 0.29935550689697266 seconds for one epoch ---
--- 1.4536333084106445 seconds for one epoch ---
--- 0.23259377479553223 seconds for one epoch ---
--- 1.5764882564544678 seconds for one epoch ---
--- 0.29804205894470215 seconds for one epoch ---
--- 1.576707124710083 seconds for one epoch ---
--- 0.29700684547424316 seconds for one epoch ---
--- 1.622551441192627 seconds for one epoch ---
--- 0.29515624046325684 seconds for one epoch ---
--- 1.5768992900848389 seconds for one epoch ---
--- 0.2932870388031006 seconds for one epoch ---
--- 1.5933837890625 seconds for one epoch ---
--- 0.3052842617034912 seconds for one epoch ---
--- 1.585517406463623 seconds for one epoch ---
--- 0.29366350173950195 seconds for one epoch ---
--- 1.5670452117919922 seconds for one epoch ---
--- 0.2921433448791504 seconds for one epoch ---
--- 1.4923765659332275 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2915492057800293 seconds for one epoch ---
463.2545009394289
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3143.32470703125, (1639.5396, 1.2091675, 1502.576, 0.0)
   validation loss 1050.556884765625, (664.2307, 0.6060536, 385.72006, 0.0)
decoder loss ratio: 25733.450973, decoder SINDy loss  ratio: 0.832631
--- 0.25435352325439453 seconds for one epoch ---
--- 0.28621673583984375 seconds for one epoch ---
--- 1.5430140495300293 seconds for one epoch ---
--- 0.3079197406768799 seconds for one epoch ---
--- 1.6338984966278076 seconds for one epoch ---
--- 0.29999661445617676 seconds for one epoch ---
--- 1.4768648147583008 seconds for one epoch ---
--- 0.28235340118408203 seconds for one epoch ---
--- 1.605823040008545 seconds for one epoch ---
--- 0.293506383895874 seconds for one epoch ---
--- 1.585057258605957 seconds for one epoch ---
--- 0.29444098472595215 seconds for one epoch ---
--- 1.643214464187622 seconds for one epoch ---
--- 0.30097413063049316 seconds for one epoch ---
--- 1.614140272140503 seconds for one epoch ---
--- 0.2976226806640625 seconds for one epoch ---
--- 1.5815620422363281 seconds for one epoch ---
--- 0.29214978218078613 seconds for one epoch ---
--- 1.5878336429595947 seconds for one epoch ---
--- 0.275390625 seconds for one epoch ---
--- 1.5836787223815918 seconds for one epoch ---
--- 0.3063840866088867 seconds for one epoch ---
--- 1.4933416843414307 seconds for one epoch ---
--- 0.28098106384277344 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2504386901855469 seconds for one epoch ---
463.2545009394289
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3711.00830078125, (1981.2863, 1.3727455, 1728.3491, 0.0)
   validation loss 892.6585693359375, (554.2578, 0.616169, 337.78458, 0.0)
decoder loss ratio: 21472.909890, decoder SINDy loss  ratio: 0.729156
--- 0.2877018451690674 seconds for one epoch ---
--- 1.564326524734497 seconds for one epoch ---
--- 0.28694748878479004 seconds for one epoch ---
--- 1.6012353897094727 seconds for one epoch ---
--- 0.29779958724975586 seconds for one epoch ---
--- 1.4802896976470947 seconds for one epoch ---
--- 0.29380083084106445 seconds for one epoch ---
--- 1.5552480220794678 seconds for one epoch ---
--- 0.28713011741638184 seconds for one epoch ---
--- 1.6461706161499023 seconds for one epoch ---
--- 0.28212809562683105 seconds for one epoch ---
--- 1.6113243103027344 seconds for one epoch ---
--- 0.28753089904785156 seconds for one epoch ---
--- 1.6285877227783203 seconds for one epoch ---
--- 0.28752779960632324 seconds for one epoch ---
--- 1.6195578575134277 seconds for one epoch ---
--- 0.2643089294433594 seconds for one epoch ---
--- 1.6018941402435303 seconds for one epoch ---
--- 0.29766082763671875 seconds for one epoch ---
--- 1.6127350330352783 seconds for one epoch ---
--- 0.29299044609069824 seconds for one epoch ---
--- 1.629145860671997 seconds for one epoch ---
--- 0.28759074211120605 seconds for one epoch ---
--- 1.6145520210266113 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2775602340698242 seconds for one epoch ---
463.2545009394289
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3790.96728515625, (1550.6503, 5.6306458, 2234.6865, 0.0)
   validation loss 1138.605224609375, (748.09863, 0.64033604, 389.86627, 0.0)
decoder loss ratio: 28982.639791, decoder SINDy loss  ratio: 0.841581
--- 0.2477123737335205 seconds for one epoch ---
--- 0.29425954818725586 seconds for one epoch ---
--- 1.5972232818603516 seconds for one epoch ---
--- 0.29349637031555176 seconds for one epoch ---
--- 1.6129443645477295 seconds for one epoch ---
--- 0.2886934280395508 seconds for one epoch ---
--- 1.6175968647003174 seconds for one epoch ---
--- 0.2934858798980713 seconds for one epoch ---
--- 1.5771889686584473 seconds for one epoch ---
--- 0.22278356552124023 seconds for one epoch ---
--- 1.565168857574463 seconds for one epoch ---
--- 0.2875337600708008 seconds for one epoch ---
--- 1.6000549793243408 seconds for one epoch ---
--- 0.29209256172180176 seconds for one epoch ---
--- 1.6558489799499512 seconds for one epoch ---
--- 0.28631091117858887 seconds for one epoch ---
--- 1.6219596862792969 seconds for one epoch ---
--- 0.30225634574890137 seconds for one epoch ---
--- 1.600407361984253 seconds for one epoch ---
--- 0.2936208248138428 seconds for one epoch ---
--- 1.6309216022491455 seconds for one epoch ---
--- 0.29313158988952637 seconds for one epoch ---
--- 1.6260261535644531 seconds for one epoch ---
--- 0.2933385372161865 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2467212677001953 seconds for one epoch ---
463.2545009394289
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2850.466064453125, (1322.2272, 2.62203, 1525.6168, 0.0)
   validation loss 957.24755859375, (639.31555, 0.6777367, 317.2543, 0.0)
decoder loss ratio: 24768.194376, decoder SINDy loss  ratio: 0.684838
--- 0.2951028347015381 seconds for one epoch ---
--- 1.6249561309814453 seconds for one epoch ---
--- 0.2914285659790039 seconds for one epoch ---
--- 1.6599915027618408 seconds for one epoch ---
--- 0.2940194606781006 seconds for one epoch ---
--- 1.6177949905395508 seconds for one epoch ---
--- 0.28998684883117676 seconds for one epoch ---
--- 1.5858573913574219 seconds for one epoch ---
--- 0.29409074783325195 seconds for one epoch ---
--- 1.6017143726348877 seconds for one epoch ---
--- 0.27930784225463867 seconds for one epoch ---
--- 1.6201128959655762 seconds for one epoch ---
--- 0.29178762435913086 seconds for one epoch ---
--- 1.6219756603240967 seconds for one epoch ---
--- 0.2892720699310303 seconds for one epoch ---
--- 1.5746328830718994 seconds for one epoch ---
--- 0.2877616882324219 seconds for one epoch ---
--- 1.6220800876617432 seconds for one epoch ---
--- 0.2115938663482666 seconds for one epoch ---
--- 1.636232614517212 seconds for one epoch ---
--- 0.2833676338195801 seconds for one epoch ---
--- 1.615586757659912 seconds for one epoch ---
--- 0.28961682319641113 seconds for one epoch ---
--- 1.6906204223632812 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27133679389953613 seconds for one epoch ---
463.2545009394289
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1668.989990234375, (773.3063, 2.4587252, 893.225, 0.0)
   validation loss 1517.58349609375, (1182.175, 0.78519344, 334.62323, 0.0)
decoder loss ratio: 45799.513738, decoder SINDy loss  ratio: 0.722331
--- 0.24983763694763184 seconds for one epoch ---
--- 0.29276347160339355 seconds for one epoch ---
--- 1.6138062477111816 seconds for one epoch ---
--- 0.284740686416626 seconds for one epoch ---
--- 1.6221923828125 seconds for one epoch ---
--- 0.29300689697265625 seconds for one epoch ---
--- 1.6716947555541992 seconds for one epoch ---
--- 0.28962087631225586 seconds for one epoch ---
--- 1.6139013767242432 seconds for one epoch ---
--- 0.2794203758239746 seconds for one epoch ---
--- 1.6322898864746094 seconds for one epoch ---
--- 0.1669597625732422 seconds for one epoch ---
--- 1.6079113483428955 seconds for one epoch ---
--- 0.30246543884277344 seconds for one epoch ---
--- 1.631809949874878 seconds for one epoch ---
--- 0.3000044822692871 seconds for one epoch ---
--- 1.66847562789917 seconds for one epoch ---
--- 0.2952401638031006 seconds for one epoch ---
--- 1.6246182918548584 seconds for one epoch ---
--- 0.3011481761932373 seconds for one epoch ---
--- 1.6085584163665771 seconds for one epoch ---
--- 0.28826451301574707 seconds for one epoch ---
--- 1.6379380226135254 seconds for one epoch ---
--- 0.2930412292480469 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2499237060546875 seconds for one epoch ---
463.2545009394289
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4179.021484375, (1277.6942, 3.2903428, 2898.037, 0.0)
   validation loss 1174.3846435546875, (837.329, 0.71377057, 336.34192, 0.0)
decoder loss ratio: 32439.578333, decoder SINDy loss  ratio: 0.726041
--- 0.2910187244415283 seconds for one epoch ---
--- 1.5898916721343994 seconds for one epoch ---
--- 0.2921919822692871 seconds for one epoch ---
--- 1.4814989566802979 seconds for one epoch ---
--- 0.25917625427246094 seconds for one epoch ---
--- 1.6225712299346924 seconds for one epoch ---
--- 0.29990386962890625 seconds for one epoch ---
--- 1.6452951431274414 seconds for one epoch ---
--- 0.30596160888671875 seconds for one epoch ---
--- 1.6839213371276855 seconds for one epoch ---
--- 0.29755401611328125 seconds for one epoch ---
--- 1.6831536293029785 seconds for one epoch ---
--- 0.28917837142944336 seconds for one epoch ---
--- 1.6667873859405518 seconds for one epoch ---
--- 0.24599361419677734 seconds for one epoch ---
--- 1.6291658878326416 seconds for one epoch ---
--- 0.284529447555542 seconds for one epoch ---
--- 1.6506774425506592 seconds for one epoch ---
--- 0.29668450355529785 seconds for one epoch ---
--- 1.7146623134613037 seconds for one epoch ---
--- 0.29285621643066406 seconds for one epoch ---
--- 1.6555140018463135 seconds for one epoch ---
--- 0.2972424030303955 seconds for one epoch ---
--- 1.6632630825042725 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3013312816619873 seconds for one epoch ---
463.2545009394289
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3591.69091796875, (1452.3776, 5.798872, 2133.5146, 0.0)
   validation loss 852.666259765625, (478.2791, 0.70991206, 373.67722, 0.0)
decoder loss ratio: 18529.363196, decoder SINDy loss  ratio: 0.806635
--- 0.25264644622802734 seconds for one epoch ---
--- 0.24128961563110352 seconds for one epoch ---
--- 1.7037193775177002 seconds for one epoch ---
--- 0.2876319885253906 seconds for one epoch ---
--- 1.6083059310913086 seconds for one epoch ---
--- 0.3061971664428711 seconds for one epoch ---
--- 1.6430630683898926 seconds for one epoch ---
--- 0.29609251022338867 seconds for one epoch ---
--- 1.6658720970153809 seconds for one epoch ---
--- 0.2921926975250244 seconds for one epoch ---
--- 1.6658999919891357 seconds for one epoch ---
--- 0.29622936248779297 seconds for one epoch ---
--- 1.6587231159210205 seconds for one epoch ---
--- 0.2945399284362793 seconds for one epoch ---
--- 1.658566951751709 seconds for one epoch ---
--- 0.29375219345092773 seconds for one epoch ---
--- 1.6901485919952393 seconds for one epoch ---
--- 0.29031801223754883 seconds for one epoch ---
--- 1.673771619796753 seconds for one epoch ---
--- 0.29468321800231934 seconds for one epoch ---
--- 1.6752979755401611 seconds for one epoch ---
--- 0.30254626274108887 seconds for one epoch ---
--- 1.678929090499878 seconds for one epoch ---
--- 0.31035876274108887 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2707333564758301 seconds for one epoch ---
463.2545009394289
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2843.099609375, (1504.0897, 0.51843727, 1338.4915, 0.0)
   validation loss 1010.863037109375, (658.37396, 0.7566988, 351.73233, 0.0)
decoder loss ratio: 25506.550291, decoder SINDy loss  ratio: 0.759264
--- 0.2994089126586914 seconds for one epoch ---
--- 1.6836390495300293 seconds for one epoch ---
--- 0.2996551990509033 seconds for one epoch ---
--- 1.6701922416687012 seconds for one epoch ---
--- 0.2859940528869629 seconds for one epoch ---
--- 1.6603562831878662 seconds for one epoch ---
--- 0.2975735664367676 seconds for one epoch ---
--- 1.6747379302978516 seconds for one epoch ---
--- 0.2830624580383301 seconds for one epoch ---
--- 1.747032880783081 seconds for one epoch ---
--- 0.2844407558441162 seconds for one epoch ---
--- 1.6900439262390137 seconds for one epoch ---
--- 0.2887287139892578 seconds for one epoch ---
--- 1.5904409885406494 seconds for one epoch ---
--- 0.23964262008666992 seconds for one epoch ---
--- 1.6592233180999756 seconds for one epoch ---
--- 0.3147146701812744 seconds for one epoch ---
--- 1.6721689701080322 seconds for one epoch ---
--- 0.30797386169433594 seconds for one epoch ---
--- 1.7156269550323486 seconds for one epoch ---
--- 0.29676198959350586 seconds for one epoch ---
--- 1.6860980987548828 seconds for one epoch ---
--- 0.2907719612121582 seconds for one epoch ---
--- 1.6588218212127686 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.27647876739501953 seconds for one epoch ---
463.2545009394289
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1578.916015625, (907.4891, 4.5028896, 666.9241, 0.0)
   validation loss 803.06396484375, (451.90036, 0.83764744, 350.326, 0.0)
decoder loss ratio: 17507.404484, decoder SINDy loss  ratio: 0.756228
--- 0.13855195045471191 seconds for one epoch ---
--- 0.20134282112121582 seconds for one epoch ---
--- 1.6891567707061768 seconds for one epoch ---
--- 0.2821688652038574 seconds for one epoch ---
--- 1.6738383769989014 seconds for one epoch ---
--- 0.2914412021636963 seconds for one epoch ---
--- 1.6832003593444824 seconds for one epoch ---
--- 0.2963988780975342 seconds for one epoch ---
--- 1.6828224658966064 seconds for one epoch ---
--- 0.28890371322631836 seconds for one epoch ---
--- 1.6882855892181396 seconds for one epoch ---
--- 0.29625368118286133 seconds for one epoch ---
--- 1.7174432277679443 seconds for one epoch ---
--- 0.29371166229248047 seconds for one epoch ---
--- 1.6932332515716553 seconds for one epoch ---
--- 0.2922790050506592 seconds for one epoch ---
--- 1.731281042098999 seconds for one epoch ---
--- 0.2879810333251953 seconds for one epoch ---
--- 1.710456371307373 seconds for one epoch ---
--- 0.2973606586456299 seconds for one epoch ---
--- 1.679746150970459 seconds for one epoch ---
--- 0.29176974296569824 seconds for one epoch ---
--- 1.7653937339782715 seconds for one epoch ---
--- 0.2769942283630371 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2558441162109375 seconds for one epoch ---
463.2545009394289
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3960.69140625, (1594.6455, 2.6512802, 2363.3945, 0.0)
   validation loss 1235.254638671875, (879.1836, 0.83123964, 355.23975, 0.0)
decoder loss ratio: 34061.098752, decoder SINDy loss  ratio: 0.766835
--- 0.29129576683044434 seconds for one epoch ---
--- 1.6505837440490723 seconds for one epoch ---
--- 0.29120588302612305 seconds for one epoch ---
--- 1.7018516063690186 seconds for one epoch ---
--- 0.3010070323944092 seconds for one epoch ---
--- 1.7001824378967285 seconds for one epoch ---
--- 0.30188655853271484 seconds for one epoch ---
--- 1.7111434936523438 seconds for one epoch ---
--- 0.1498887538909912 seconds for one epoch ---
--- 1.7067527770996094 seconds for one epoch ---
--- 0.28316450119018555 seconds for one epoch ---
--- 1.724888801574707 seconds for one epoch ---
--- 0.3291964530944824 seconds for one epoch ---
--- 1.7406644821166992 seconds for one epoch ---
--- 0.3036048412322998 seconds for one epoch ---
--- 1.7199881076812744 seconds for one epoch ---
--- 0.29800915718078613 seconds for one epoch ---
--- 1.7205030918121338 seconds for one epoch ---
--- 0.22777104377746582 seconds for one epoch ---
--- 1.709916353225708 seconds for one epoch ---
--- 0.29392266273498535 seconds for one epoch ---
--- 1.7447147369384766 seconds for one epoch ---
--- 0.2983510494232178 seconds for one epoch ---
--- 1.7237789630889893 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2854461669921875 seconds for one epoch ---
463.2545009394289
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3041.0498046875, (1466.9727, 2.7022433, 1571.3749, 0.0)
   validation loss 1720.75830078125, (1352.772, 0.75452584, 367.23175, 0.0)
decoder loss ratio: 52408.734736, decoder SINDy loss  ratio: 0.792721
--- 0.25619053840637207 seconds for one epoch ---
--- 0.30118250846862793 seconds for one epoch ---
--- 1.7310662269592285 seconds for one epoch ---
--- 0.2971458435058594 seconds for one epoch ---
--- 1.5927119255065918 seconds for one epoch ---
--- 0.2956826686859131 seconds for one epoch ---
--- 1.6502048969268799 seconds for one epoch ---
--- 0.30216121673583984 seconds for one epoch ---
--- 1.7293293476104736 seconds for one epoch ---
--- 0.3033313751220703 seconds for one epoch ---
--- 1.7913730144500732 seconds for one epoch ---
--- 0.2939589023590088 seconds for one epoch ---
--- 1.7049739360809326 seconds for one epoch ---
--- 0.2889847755432129 seconds for one epoch ---
--- 1.6147162914276123 seconds for one epoch ---
--- 0.2775719165802002 seconds for one epoch ---
--- 1.6888415813446045 seconds for one epoch ---
--- 0.29624104499816895 seconds for one epoch ---
--- 1.7052431106567383 seconds for one epoch ---
--- 0.3019561767578125 seconds for one epoch ---
--- 1.7721583843231201 seconds for one epoch ---
--- 0.29457592964172363 seconds for one epoch ---
--- 1.711838960647583 seconds for one epoch ---
--- 0.3031032085418701 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25520968437194824 seconds for one epoch ---
463.2545009394289
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3342.992919921875, (1221.2529, 1.44141, 2120.2986, 0.0)
   validation loss 862.57470703125, (509.81967, 0.7662504, 351.98877, 0.0)
decoder loss ratio: 19751.299165, decoder SINDy loss  ratio: 0.759817
--- 0.2974255084991455 seconds for one epoch ---
--- 1.7535629272460938 seconds for one epoch ---
--- 0.29607725143432617 seconds for one epoch ---
--- 1.7152252197265625 seconds for one epoch ---
--- 0.29486751556396484 seconds for one epoch ---
--- 1.7312114238739014 seconds for one epoch ---
--- 0.28448915481567383 seconds for one epoch ---
--- 1.757655143737793 seconds for one epoch ---
--- 0.28786468505859375 seconds for one epoch ---
--- 1.6952033042907715 seconds for one epoch ---
--- 0.30866527557373047 seconds for one epoch ---
--- 1.695859432220459 seconds for one epoch ---
--- 0.2888004779815674 seconds for one epoch ---
--- 1.7541608810424805 seconds for one epoch ---
--- 0.2892274856567383 seconds for one epoch ---
--- 1.760422706604004 seconds for one epoch ---
--- 0.20670127868652344 seconds for one epoch ---
--- 1.7659626007080078 seconds for one epoch ---
--- 0.29988718032836914 seconds for one epoch ---
--- 1.7550997734069824 seconds for one epoch ---
--- 0.2895328998565674 seconds for one epoch ---
--- 1.8082733154296875 seconds for one epoch ---
--- 0.3038806915283203 seconds for one epoch ---
--- 1.746645212173462 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29926156997680664 seconds for one epoch ---
463.2545009394289
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5955.90283203125, (2746.6785, 2.7299538, 3206.4944, 0.0)
   validation loss 1151.2147216796875, (795.09186, 0.75187296, 355.371, 0.0)
decoder loss ratio: 30803.238916, decoder SINDy loss  ratio: 0.767118
--- 0.251354455947876 seconds for one epoch ---
--- 0.29717588424682617 seconds for one epoch ---
--- 1.8448386192321777 seconds for one epoch ---
--- 0.3054070472717285 seconds for one epoch ---
--- 1.7495980262756348 seconds for one epoch ---
--- 0.29430603981018066 seconds for one epoch ---
--- 1.645514965057373 seconds for one epoch ---
--- 0.19796085357666016 seconds for one epoch ---
--- 1.7323360443115234 seconds for one epoch ---
--- 0.28815197944641113 seconds for one epoch ---
--- 1.7871265411376953 seconds for one epoch ---
--- 0.3058462142944336 seconds for one epoch ---
--- 1.7195680141448975 seconds for one epoch ---
--- 0.3048243522644043 seconds for one epoch ---
--- 1.7095489501953125 seconds for one epoch ---
--- 0.305908203125 seconds for one epoch ---
--- 1.612257719039917 seconds for one epoch ---
--- 0.27294492721557617 seconds for one epoch ---
--- 1.7710487842559814 seconds for one epoch ---
--- 0.29250574111938477 seconds for one epoch ---
--- 1.7722480297088623 seconds for one epoch ---
--- 0.2916109561920166 seconds for one epoch ---
--- 1.7890892028808594 seconds for one epoch ---
--- 0.29924941062927246 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24685049057006836 seconds for one epoch ---
463.2545009394289
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4036.50048828125, (1902.0385, 2.5858963, 2131.8762, 0.0)
   validation loss 781.961669921875, (453.87775, 0.783486, 327.3004, 0.0)
decoder loss ratio: 17584.011869, decoder SINDy loss  ratio: 0.706524
--- 0.28623104095458984 seconds for one epoch ---
--- 1.7618658542633057 seconds for one epoch ---
--- 0.29293370246887207 seconds for one epoch ---
--- 1.7875230312347412 seconds for one epoch ---
--- 0.2971947193145752 seconds for one epoch ---
--- 1.7289273738861084 seconds for one epoch ---
--- 0.3008601665496826 seconds for one epoch ---
--- 1.6906087398529053 seconds for one epoch ---
--- 0.2087082862854004 seconds for one epoch ---
--- 1.7549364566802979 seconds for one epoch ---
--- 0.2817652225494385 seconds for one epoch ---
--- 1.7508952617645264 seconds for one epoch ---
--- 0.2883574962615967 seconds for one epoch ---
--- 1.7569119930267334 seconds for one epoch ---
--- 0.28852176666259766 seconds for one epoch ---
--- 1.7669520378112793 seconds for one epoch ---
--- 0.29280972480773926 seconds for one epoch ---
--- 1.6458172798156738 seconds for one epoch ---
--- 0.5823352336883545 seconds for one epoch ---
--- 1.7149391174316406 seconds for one epoch ---
--- 0.2855350971221924 seconds for one epoch ---
--- 1.709669828414917 seconds for one epoch ---
--- 0.2924463748931885 seconds for one epoch ---
--- 1.7745451927185059 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.286548376083374 seconds for one epoch ---
463.2545009394289
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4744.73193359375, (1887.5242, 3.8885875, 2853.3193, 0.0)
   validation loss 920.322265625, (586.2428, 0.71218497, 333.3673, 0.0)
decoder loss ratio: 22712.063751, decoder SINDy loss  ratio: 0.719620
--- 0.25241518020629883 seconds for one epoch ---
--- 0.2945742607116699 seconds for one epoch ---
--- 1.7463195323944092 seconds for one epoch ---
--- 0.2909986972808838 seconds for one epoch ---
--- 1.7682340145111084 seconds for one epoch ---
--- 0.3035552501678467 seconds for one epoch ---
--- 1.7620353698730469 seconds for one epoch ---
--- 0.2967185974121094 seconds for one epoch ---
--- 1.7563121318817139 seconds for one epoch ---
--- 0.30359339714050293 seconds for one epoch ---
--- 1.75270414352417 seconds for one epoch ---
--- 0.3034067153930664 seconds for one epoch ---
--- 1.7463023662567139 seconds for one epoch ---
--- 0.21937918663024902 seconds for one epoch ---
--- 1.781219244003296 seconds for one epoch ---
--- 0.2926914691925049 seconds for one epoch ---
--- 1.7583684921264648 seconds for one epoch ---
--- 0.28563785552978516 seconds for one epoch ---
--- 1.7692949771881104 seconds for one epoch ---
--- 0.28977131843566895 seconds for one epoch ---
--- 1.804060459136963 seconds for one epoch ---
--- 0.2965826988220215 seconds for one epoch ---
--- 1.662485122680664 seconds for one epoch ---
--- 0.18967723846435547 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2535831928253174 seconds for one epoch ---
463.2545009394289
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1660.32470703125, (878.7064, 4.355413, 777.26294, 0.0)
   validation loss 899.460205078125, (577.2749, 0.7582741, 321.42697, 0.0)
decoder loss ratio: 22364.631910, decoder SINDy loss  ratio: 0.693845
--- 0.2910749912261963 seconds for one epoch ---
--- 1.7596747875213623 seconds for one epoch ---
--- 0.28601980209350586 seconds for one epoch ---
--- 1.7527103424072266 seconds for one epoch ---
--- 0.2943570613861084 seconds for one epoch ---
--- 1.8104608058929443 seconds for one epoch ---
--- 0.2837696075439453 seconds for one epoch ---
--- 1.7483880519866943 seconds for one epoch ---
--- 0.2801172733306885 seconds for one epoch ---
--- 1.814596176147461 seconds for one epoch ---
--- 0.2841346263885498 seconds for one epoch ---
--- 1.757178544998169 seconds for one epoch ---
--- 0.2930021286010742 seconds for one epoch ---
--- 1.7779426574707031 seconds for one epoch ---
--- 0.19460010528564453 seconds for one epoch ---
--- 1.7873857021331787 seconds for one epoch ---
--- 0.29740238189697266 seconds for one epoch ---
--- 1.7794983386993408 seconds for one epoch ---
--- 0.2911643981933594 seconds for one epoch ---
--- 1.7708120346069336 seconds for one epoch ---
--- 0.28975725173950195 seconds for one epoch ---
--- 1.7586700916290283 seconds for one epoch ---
--- 0.29030942916870117 seconds for one epoch ---
--- 1.7197060585021973 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29985833168029785 seconds for one epoch ---
463.2545009394289
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4414.3857421875, (1985.9073, 1.4930689, 2426.9856, 0.0)
   validation loss 821.81494140625, (448.5712, 0.8573254, 372.3864, 0.0)
decoder loss ratio: 17378.426945, decoder SINDy loss  ratio: 0.803848
THRESHOLDING: 0 active coefficients
--- 0.2539069652557373 seconds for one epoch ---
--- 0.28116369247436523 seconds for one epoch ---
--- 1.8397786617279053 seconds for one epoch ---
--- 0.305422306060791 seconds for one epoch ---
--- 1.832104206085205 seconds for one epoch ---
--- 0.2782106399536133 seconds for one epoch ---
--- 1.8006584644317627 seconds for one epoch ---
--- 0.28868937492370605 seconds for one epoch ---
--- 1.8258464336395264 seconds for one epoch ---
--- 0.29706501960754395 seconds for one epoch ---
--- 1.7991204261779785 seconds for one epoch ---
--- 0.29866647720336914 seconds for one epoch ---
--- 1.8508155345916748 seconds for one epoch ---
--- 0.2882723808288574 seconds for one epoch ---
--- 1.8143792152404785 seconds for one epoch ---
--- 0.29869914054870605 seconds for one epoch ---
--- 1.8491125106811523 seconds for one epoch ---
--- 0.285144567489624 seconds for one epoch ---
--- 1.7944064140319824 seconds for one epoch ---
--- 0.2934303283691406 seconds for one epoch ---
--- 1.7164428234100342 seconds for one epoch ---
--- 0.20983338356018066 seconds for one epoch ---
--- 1.841529369354248 seconds for one epoch ---
--- 0.29456377029418945 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25669050216674805 seconds for one epoch ---
463.2545009394289
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3180.431640625, (1314.2223, 1.182489, 1865.027, 0.0)
   validation loss 844.951904296875, (520.613, 0.8110728, 323.52786, 0.0)
decoder loss ratio: 20169.450517, decoder SINDy loss  ratio: 0.698380
--- 0.2940342426300049 seconds for one epoch ---
--- 1.8289637565612793 seconds for one epoch ---
--- 0.30236339569091797 seconds for one epoch ---
--- 1.8220369815826416 seconds for one epoch ---
--- 0.2916898727416992 seconds for one epoch ---
--- 1.8083992004394531 seconds for one epoch ---
--- 0.20861005783081055 seconds for one epoch ---
--- 1.7861416339874268 seconds for one epoch ---
--- 0.30008697509765625 seconds for one epoch ---
--- 1.820194959640503 seconds for one epoch ---
--- 0.292172908782959 seconds for one epoch ---
--- 1.8331561088562012 seconds for one epoch ---
--- 0.30387187004089355 seconds for one epoch ---
--- 1.8274383544921875 seconds for one epoch ---
--- 0.29807257652282715 seconds for one epoch ---
--- 1.8228483200073242 seconds for one epoch ---
--- 0.2892634868621826 seconds for one epoch ---
--- 1.8414225578308105 seconds for one epoch ---
--- 0.29409265518188477 seconds for one epoch ---
--- 1.7727148532867432 seconds for one epoch ---
--- 0.27376222610473633 seconds for one epoch ---
--- 1.8312187194824219 seconds for one epoch ---
--- 0.28705549240112305 seconds for one epoch ---
--- 1.7913432121276855 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2864372730255127 seconds for one epoch ---
463.2545009394289
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3411.548828125, (1132.4545, 5.6570663, 2273.4373, 0.0)
   validation loss 1038.496337890625, (663.65027, 0.7477979, 374.09827, 0.0)
decoder loss ratio: 25710.963551, decoder SINDy loss  ratio: 0.807544
--- 0.2585139274597168 seconds for one epoch ---
--- 0.16981172561645508 seconds for one epoch ---
--- 1.8158087730407715 seconds for one epoch ---
--- 0.2728142738342285 seconds for one epoch ---
--- 1.8430895805358887 seconds for one epoch ---
--- 0.29310131072998047 seconds for one epoch ---
--- 1.850538969039917 seconds for one epoch ---
--- 0.2873868942260742 seconds for one epoch ---
--- 1.8167757987976074 seconds for one epoch ---
--- 0.29628658294677734 seconds for one epoch ---
--- 1.8062586784362793 seconds for one epoch ---
--- 0.27898740768432617 seconds for one epoch ---
--- 1.8082973957061768 seconds for one epoch ---
--- 0.30908870697021484 seconds for one epoch ---
--- 1.8243286609649658 seconds for one epoch ---
--- 0.28548502922058105 seconds for one epoch ---
--- 1.828869342803955 seconds for one epoch ---
--- 0.2863588333129883 seconds for one epoch ---
--- 1.841369867324829 seconds for one epoch ---
--- 0.29357194900512695 seconds for one epoch ---
--- 1.8613884449005127 seconds for one epoch ---
--- 0.29290246963500977 seconds for one epoch ---
--- 1.8149821758270264 seconds for one epoch ---
--- 0.2888345718383789 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26335811614990234 seconds for one epoch ---
463.2545009394289
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3581.174560546875, (1179.5432, 4.3723555, 2397.259, 0.0)
   validation loss 822.71533203125, (490.07898, 0.8741238, 331.76224, 0.0)
decoder loss ratio: 18986.510480, decoder SINDy loss  ratio: 0.716155
--- 0.3019721508026123 seconds for one epoch ---
--- 1.837937831878662 seconds for one epoch ---
--- 0.3015713691711426 seconds for one epoch ---
--- 1.8330817222595215 seconds for one epoch ---
--- 0.29991579055786133 seconds for one epoch ---
--- 1.827176809310913 seconds for one epoch ---
--- 0.2896687984466553 seconds for one epoch ---
--- 1.8502488136291504 seconds for one epoch ---
--- 0.2955763339996338 seconds for one epoch ---
--- 1.835197925567627 seconds for one epoch ---
--- 0.2789123058319092 seconds for one epoch ---
--- 1.8753974437713623 seconds for one epoch ---
--- 0.2898581027984619 seconds for one epoch ---
--- 1.8385462760925293 seconds for one epoch ---
--- 0.2952437400817871 seconds for one epoch ---
--- 1.8696386814117432 seconds for one epoch ---
--- 0.29618287086486816 seconds for one epoch ---
--- 1.8428916931152344 seconds for one epoch ---
--- 0.29410409927368164 seconds for one epoch ---
--- 1.8835806846618652 seconds for one epoch ---
--- 0.28939247131347656 seconds for one epoch ---
--- 1.8364579677581787 seconds for one epoch ---
--- 0.29773664474487305 seconds for one epoch ---
--- 1.838822603225708 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2935488224029541 seconds for one epoch ---
463.2545009394289
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3914.068359375, (1490.0792, 2.1386275, 2421.8506, 0.0)
   validation loss 860.53759765625, (515.78546, 0.929308, 343.8228, 0.0)
decoder loss ratio: 19982.424219, decoder SINDy loss  ratio: 0.742190
--- 0.2591688632965088 seconds for one epoch ---
--- 0.30209827423095703 seconds for one epoch ---
--- 1.86678147315979 seconds for one epoch ---
--- 0.29030513763427734 seconds for one epoch ---
--- 1.855513095855713 seconds for one epoch ---
--- 0.29723358154296875 seconds for one epoch ---
--- 1.842803716659546 seconds for one epoch ---
--- 0.2878456115722656 seconds for one epoch ---
--- 1.8486928939819336 seconds for one epoch ---
--- 0.2980809211730957 seconds for one epoch ---
--- 1.8935062885284424 seconds for one epoch ---
--- 0.2981235980987549 seconds for one epoch ---
--- 1.8691942691802979 seconds for one epoch ---
--- 0.2928962707519531 seconds for one epoch ---
--- 1.863776445388794 seconds for one epoch ---
--- 0.29630184173583984 seconds for one epoch ---
--- 1.8677964210510254 seconds for one epoch ---
--- 0.29920220375061035 seconds for one epoch ---
--- 1.8622188568115234 seconds for one epoch ---
--- 0.2938194274902344 seconds for one epoch ---
--- 1.8699932098388672 seconds for one epoch ---
--- 0.2965238094329834 seconds for one epoch ---
--- 1.881150245666504 seconds for one epoch ---
--- 0.19282293319702148 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2563929557800293 seconds for one epoch ---
463.2545009394289
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1868.06396484375, (988.3787, 1.0863973, 878.59875, 0.0)
   validation loss 1123.994384765625, (767.611, 1.0372802, 355.34613, 0.0)
decoder loss ratio: 29738.583660, decoder SINDy loss  ratio: 0.767065
--- 0.29329705238342285 seconds for one epoch ---
--- 1.811002254486084 seconds for one epoch ---
--- 0.30259013175964355 seconds for one epoch ---
--- 1.8080072402954102 seconds for one epoch ---
--- 0.28572583198547363 seconds for one epoch ---
--- 1.8432669639587402 seconds for one epoch ---
--- 0.3004941940307617 seconds for one epoch ---
--- 1.850684642791748 seconds for one epoch ---
--- 0.27559781074523926 seconds for one epoch ---
--- 1.8716847896575928 seconds for one epoch ---
--- 0.2925565242767334 seconds for one epoch ---
--- 1.8686950206756592 seconds for one epoch ---
--- 0.2777438163757324 seconds for one epoch ---
--- 1.8569774627685547 seconds for one epoch ---
--- 0.29116010665893555 seconds for one epoch ---
--- 1.8838906288146973 seconds for one epoch ---
--- 0.28960537910461426 seconds for one epoch ---
--- 1.9108412265777588 seconds for one epoch ---
--- 0.30596160888671875 seconds for one epoch ---
--- 1.8600757122039795 seconds for one epoch ---
--- 0.27852702140808105 seconds for one epoch ---
--- 1.8405060768127441 seconds for one epoch ---
--- 0.17982888221740723 seconds for one epoch ---
--- 1.8674871921539307 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28467512130737305 seconds for one epoch ---
463.2545009394289
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4499.1591796875, (1956.6528, 1.9496988, 2540.5566, 0.0)
   validation loss 1145.673583984375, (739.99445, 1.0216252, 404.6576, 0.0)
decoder loss ratio: 28668.669517, decoder SINDy loss  ratio: 0.873510
--- 0.24868106842041016 seconds for one epoch ---
--- 0.2959001064300537 seconds for one epoch ---
--- 1.8429076671600342 seconds for one epoch ---
--- 0.29225945472717285 seconds for one epoch ---
--- 1.8733577728271484 seconds for one epoch ---
--- 0.28925275802612305 seconds for one epoch ---
--- 1.887178659439087 seconds for one epoch ---
--- 0.26712536811828613 seconds for one epoch ---
--- 1.8727471828460693 seconds for one epoch ---
--- 0.2933788299560547 seconds for one epoch ---
--- 1.830916404724121 seconds for one epoch ---
--- 0.28809666633605957 seconds for one epoch ---
--- 1.9141263961791992 seconds for one epoch ---
--- 0.2910799980163574 seconds for one epoch ---
--- 1.927842617034912 seconds for one epoch ---
--- 0.2944297790527344 seconds for one epoch ---
--- 1.9118220806121826 seconds for one epoch ---
--- 0.30381202697753906 seconds for one epoch ---
--- 1.875718593597412 seconds for one epoch ---
--- 0.30004167556762695 seconds for one epoch ---
--- 1.8241031169891357 seconds for one epoch ---
--- 0.17201733589172363 seconds for one epoch ---
--- 1.85994291305542 seconds for one epoch ---
--- 0.295579195022583 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2567024230957031 seconds for one epoch ---
463.2545009394289
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4871.21923828125, (1896.2653, 1.197292, 2973.7566, 0.0)
   validation loss 937.96923828125, (591.8181, 0.89707136, 345.25406, 0.0)
decoder loss ratio: 22928.061226, decoder SINDy loss  ratio: 0.745279
--- 0.2924654483795166 seconds for one epoch ---
--- 1.9250433444976807 seconds for one epoch ---
--- 0.29723334312438965 seconds for one epoch ---
--- 1.8940691947937012 seconds for one epoch ---
--- 0.2929549217224121 seconds for one epoch ---
--- 1.8387928009033203 seconds for one epoch ---
--- 0.18732166290283203 seconds for one epoch ---
--- 1.8682818412780762 seconds for one epoch ---
--- 0.2912025451660156 seconds for one epoch ---
--- 1.8935935497283936 seconds for one epoch ---
--- 0.2883179187774658 seconds for one epoch ---
--- 1.9071905612945557 seconds for one epoch ---
--- 0.29794764518737793 seconds for one epoch ---
--- 1.8601264953613281 seconds for one epoch ---
--- 0.2947690486907959 seconds for one epoch ---
--- 1.872964859008789 seconds for one epoch ---
--- 0.2954874038696289 seconds for one epoch ---
--- 1.8745555877685547 seconds for one epoch ---
--- 0.2982032299041748 seconds for one epoch ---
--- 1.7952120304107666 seconds for one epoch ---
--- 0.22027111053466797 seconds for one epoch ---
--- 1.8826782703399658 seconds for one epoch ---
--- 0.29860377311706543 seconds for one epoch ---
--- 1.8909099102020264 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2935597896575928 seconds for one epoch ---
463.2545009394289
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4717.857421875, (1384.6052, 7.0082655, 3326.2441, 0.0)
   validation loss 938.4954833984375, (580.11017, 0.97085416, 357.41446, 0.0)
decoder loss ratio: 22474.475042, decoder SINDy loss  ratio: 0.771529
--- 0.25786328315734863 seconds for one epoch ---
--- 0.30356717109680176 seconds for one epoch ---
--- 1.886962890625 seconds for one epoch ---
--- 0.3014822006225586 seconds for one epoch ---
--- 1.9306159019470215 seconds for one epoch ---
--- 0.2934257984161377 seconds for one epoch ---
--- 1.8932857513427734 seconds for one epoch ---
--- 0.29395580291748047 seconds for one epoch ---
--- 1.908935785293579 seconds for one epoch ---
--- 0.26813673973083496 seconds for one epoch ---
--- 1.9041926860809326 seconds for one epoch ---
--- 0.29663968086242676 seconds for one epoch ---
--- 1.902740240097046 seconds for one epoch ---
--- 0.2847433090209961 seconds for one epoch ---
--- 1.9182071685791016 seconds for one epoch ---
--- 0.28784704208374023 seconds for one epoch ---
--- 1.9181115627288818 seconds for one epoch ---
--- 0.2936422824859619 seconds for one epoch ---
--- 1.9246702194213867 seconds for one epoch ---
--- 0.29450511932373047 seconds for one epoch ---
--- 1.875359058380127 seconds for one epoch ---
--- 0.29137516021728516 seconds for one epoch ---
--- 1.7665627002716064 seconds for one epoch ---
--- 0.1882176399230957 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26117515563964844 seconds for one epoch ---
463.2545009394289
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2614.51904296875, (1171.8632, 2.4038136, 1440.2522, 0.0)
   validation loss 985.6250610351562, (635.2119, 0.958244, 349.4549, 0.0)
decoder loss ratio: 24609.212327, decoder SINDy loss  ratio: 0.754348
--- 0.30282163619995117 seconds for one epoch ---
--- 1.9065098762512207 seconds for one epoch ---
--- 0.2860252857208252 seconds for one epoch ---
--- 1.906749963760376 seconds for one epoch ---
--- 0.29364657402038574 seconds for one epoch ---
--- 1.9453330039978027 seconds for one epoch ---
--- 0.2916688919067383 seconds for one epoch ---
--- 1.9102752208709717 seconds for one epoch ---
--- 0.29564833641052246 seconds for one epoch ---
--- 1.9277939796447754 seconds for one epoch ---
--- 0.2966032028198242 seconds for one epoch ---
--- 1.9207699298858643 seconds for one epoch ---
--- 0.24942755699157715 seconds for one epoch ---
--- 1.9553630352020264 seconds for one epoch ---
--- 0.2844409942626953 seconds for one epoch ---
--- 1.9297165870666504 seconds for one epoch ---
--- 0.27659106254577637 seconds for one epoch ---
--- 1.9413652420043945 seconds for one epoch ---
--- 0.2837202548980713 seconds for one epoch ---
--- 1.9169397354125977 seconds for one epoch ---
--- 0.2867696285247803 seconds for one epoch ---
--- 1.9351027011871338 seconds for one epoch ---
--- 0.2899024486541748 seconds for one epoch ---
--- 1.9199862480163574 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28785037994384766 seconds for one epoch ---
463.2545009394289
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3147.0966796875, (1154.3655, 4.061828, 1988.6693, 0.0)
   validation loss 931.9490966796875, (578.1303, 0.95264375, 352.86615, 0.0)
decoder loss ratio: 22397.771890, decoder SINDy loss  ratio: 0.761711
--- 0.2733726501464844 seconds for one epoch ---
--- 0.19804811477661133 seconds for one epoch ---
--- 1.9519603252410889 seconds for one epoch ---
--- 0.29177093505859375 seconds for one epoch ---
--- 1.9246740341186523 seconds for one epoch ---
--- 0.29172372817993164 seconds for one epoch ---
--- 1.936281442642212 seconds for one epoch ---
--- 0.29158854484558105 seconds for one epoch ---
--- 1.915334939956665 seconds for one epoch ---
--- 0.29288530349731445 seconds for one epoch ---
--- 1.9467074871063232 seconds for one epoch ---
--- 0.2893679141998291 seconds for one epoch ---
--- 1.9389700889587402 seconds for one epoch ---
--- 0.2913949489593506 seconds for one epoch ---
--- 1.9444539546966553 seconds for one epoch ---
--- 0.29813671112060547 seconds for one epoch ---
--- 1.9841368198394775 seconds for one epoch ---
--- 0.3026144504547119 seconds for one epoch ---
--- 1.9602539539337158 seconds for one epoch ---
--- 0.1582028865814209 seconds for one epoch ---
--- 1.9578912258148193 seconds for one epoch ---
--- 0.28870606422424316 seconds for one epoch ---
--- 1.932748794555664 seconds for one epoch ---
--- 0.2908918857574463 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2529263496398926 seconds for one epoch ---
463.2545009394289
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3239.4658203125, (1218.1306, 1.6191367, 2019.716, 0.0)
   validation loss 898.41455078125, (539.1484, 0.90237945, 358.36377, 0.0)
decoder loss ratio: 20887.544107, decoder SINDy loss  ratio: 0.773579
--- 0.29616236686706543 seconds for one epoch ---
--- 1.8929834365844727 seconds for one epoch ---
--- 0.28253984451293945 seconds for one epoch ---
--- 1.9192626476287842 seconds for one epoch ---
--- 0.28975582122802734 seconds for one epoch ---
--- 1.9634954929351807 seconds for one epoch ---
--- 0.29018115997314453 seconds for one epoch ---
--- 1.9906435012817383 seconds for one epoch ---
--- 0.1780228614807129 seconds for one epoch ---
--- 1.969773292541504 seconds for one epoch ---
--- 0.2886202335357666 seconds for one epoch ---
--- 1.9247381687164307 seconds for one epoch ---
--- 0.2912254333496094 seconds for one epoch ---
--- 1.9710664749145508 seconds for one epoch ---
--- 0.29077982902526855 seconds for one epoch ---
--- 1.9468212127685547 seconds for one epoch ---
--- 0.2851583957672119 seconds for one epoch ---
--- 1.9947867393493652 seconds for one epoch ---
--- 0.2926955223083496 seconds for one epoch ---
--- 1.9524290561676025 seconds for one epoch ---
--- 0.28752613067626953 seconds for one epoch ---
--- 1.9619224071502686 seconds for one epoch ---
--- 0.292142391204834 seconds for one epoch ---
--- 1.9514031410217285 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29001617431640625 seconds for one epoch ---
463.2545009394289
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3639.71337890625, (1379.9479, 0.84212476, 2258.9233, 0.0)
   validation loss 1049.954345703125, (639.28, 0.9931355, 409.6812, 0.0)
decoder loss ratio: 24766.818174, decoder SINDy loss  ratio: 0.884355
--- 0.25420665740966797 seconds for one epoch ---
--- 0.19374918937683105 seconds for one epoch ---
--- 1.9425280094146729 seconds for one epoch ---
--- 0.28562283515930176 seconds for one epoch ---
--- 1.9190359115600586 seconds for one epoch ---
--- 0.2966606616973877 seconds for one epoch ---
--- 1.9241187572479248 seconds for one epoch ---
--- 0.3049044609069824 seconds for one epoch ---
--- 1.9592208862304688 seconds for one epoch ---
--- 0.29607057571411133 seconds for one epoch ---
--- 1.9611022472381592 seconds for one epoch ---
--- 0.28761792182922363 seconds for one epoch ---
--- 1.987013578414917 seconds for one epoch ---
--- 0.27318525314331055 seconds for one epoch ---
--- 1.9992079734802246 seconds for one epoch ---
--- 0.2974734306335449 seconds for one epoch ---
--- 1.9730329513549805 seconds for one epoch ---
--- 0.3041555881500244 seconds for one epoch ---
--- 1.9165966510772705 seconds for one epoch ---
--- 0.2041640281677246 seconds for one epoch ---
--- 1.9787166118621826 seconds for one epoch ---
--- 0.29291296005249023 seconds for one epoch ---
--- 1.910344123840332 seconds for one epoch ---
--- 0.28156352043151855 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25411081314086914 seconds for one epoch ---
463.2545009394289
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4818.01220703125, (1401.1519, 7.263825, 3409.5967, 0.0)
   validation loss 965.6312255859375, (632.35, 0.9954721, 332.28577, 0.0)
decoder loss ratio: 24498.335862, decoder SINDy loss  ratio: 0.717286
--- 0.29632067680358887 seconds for one epoch ---
--- 1.9695191383361816 seconds for one epoch ---
--- 0.2874922752380371 seconds for one epoch ---
--- 1.9930460453033447 seconds for one epoch ---
--- 0.2920198440551758 seconds for one epoch ---
--- 1.9612109661102295 seconds for one epoch ---
--- 0.293581485748291 seconds for one epoch ---
--- 1.977670431137085 seconds for one epoch ---
--- 0.2937493324279785 seconds for one epoch ---
--- 2.0052173137664795 seconds for one epoch ---
--- 0.2913672924041748 seconds for one epoch ---
--- 1.8634033203125 seconds for one epoch ---
--- 0.2199711799621582 seconds for one epoch ---
--- 1.997528076171875 seconds for one epoch ---
--- 0.2918674945831299 seconds for one epoch ---
--- 1.9526596069335938 seconds for one epoch ---
--- 0.2981593608856201 seconds for one epoch ---
--- 1.9700241088867188 seconds for one epoch ---
--- 0.2957167625427246 seconds for one epoch ---
--- 1.9728388786315918 seconds for one epoch ---
--- 0.2891409397125244 seconds for one epoch ---
--- 1.9886083602905273 seconds for one epoch ---
--- 0.2973487377166748 seconds for one epoch ---
--- 1.996899127960205 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.3058152198791504 seconds for one epoch ---
463.2545009394289
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3054.298095703125, (1129.65, 0.41297635, 1924.2351, 0.0)
   validation loss 796.531982421875, (455.73718, 0.84191436, 339.9529, 0.0)
decoder loss ratio: 17656.049649, decoder SINDy loss  ratio: 0.733836
--- 0.21991872787475586 seconds for one epoch ---
--- 0.29121971130371094 seconds for one epoch ---
--- 1.982917070388794 seconds for one epoch ---
--- 0.2930467128753662 seconds for one epoch ---
--- 1.9706149101257324 seconds for one epoch ---
--- 0.17650747299194336 seconds for one epoch ---
--- 1.9924001693725586 seconds for one epoch ---
--- 0.2909116744995117 seconds for one epoch ---
--- 1.9682822227478027 seconds for one epoch ---
--- 0.28931379318237305 seconds for one epoch ---
--- 2.0539534091949463 seconds for one epoch ---
--- 0.2932710647583008 seconds for one epoch ---
--- 2.0058841705322266 seconds for one epoch ---
--- 0.30716800689697266 seconds for one epoch ---
--- 1.9812982082366943 seconds for one epoch ---
--- 0.3040962219238281 seconds for one epoch ---
--- 1.9207303524017334 seconds for one epoch ---
--- 0.2914719581604004 seconds for one epoch ---
--- 1.9641637802124023 seconds for one epoch ---
--- 0.2988557815551758 seconds for one epoch ---
--- 1.9323465824127197 seconds for one epoch ---
--- 0.2950630187988281 seconds for one epoch ---
--- 2.0233571529388428 seconds for one epoch ---
--- 0.2912602424621582 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26328182220458984 seconds for one epoch ---
463.2545009394289
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3792.59814453125, (1463.3129, 3.0784073, 2326.2068, 0.0)
   validation loss 866.250732421875, (519.1399, 0.93012244, 346.18073, 0.0)
decoder loss ratio: 20112.380705, decoder SINDy loss  ratio: 0.747280
--- 0.2999744415283203 seconds for one epoch ---
--- 1.9514732360839844 seconds for one epoch ---
--- 0.20635294914245605 seconds for one epoch ---
--- 2.0467031002044678 seconds for one epoch ---
--- 0.2820460796356201 seconds for one epoch ---
--- 1.9703140258789062 seconds for one epoch ---
--- 0.2964189052581787 seconds for one epoch ---
--- 2.019835948944092 seconds for one epoch ---
--- 0.2932119369506836 seconds for one epoch ---
--- 1.9941210746765137 seconds for one epoch ---
--- 0.2927584648132324 seconds for one epoch ---
--- 2.0136730670928955 seconds for one epoch ---
--- 0.29076719284057617 seconds for one epoch ---
--- 1.9841196537017822 seconds for one epoch ---
--- 0.29183220863342285 seconds for one epoch ---
--- 2.02889347076416 seconds for one epoch ---
--- 0.30144333839416504 seconds for one epoch ---
--- 2.012732744216919 seconds for one epoch ---
--- 0.3017251491546631 seconds for one epoch ---
--- 2.0011470317840576 seconds for one epoch ---
--- 0.298022985458374 seconds for one epoch ---
--- 1.9865362644195557 seconds for one epoch ---
--- 0.29160070419311523 seconds for one epoch ---
--- 1.8642933368682861 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2182915210723877 seconds for one epoch ---
463.2545009394289
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3741.41748046875, (1316.812, 5.31525, 2419.29, 0.0)
   validation loss 913.6739501953125, (570.9755, 1.0066707, 341.69177, 0.0)
decoder loss ratio: 22120.583092, decoder SINDy loss  ratio: 0.737590
--- 0.23181676864624023 seconds for one epoch ---
--- 0.2959554195404053 seconds for one epoch ---
--- 1.9743106365203857 seconds for one epoch ---
--- 0.292238712310791 seconds for one epoch ---
--- 2.0463902950286865 seconds for one epoch ---
--- 0.3047206401824951 seconds for one epoch ---
--- 1.9965887069702148 seconds for one epoch ---
--- 0.29913806915283203 seconds for one epoch ---
--- 2.0243005752563477 seconds for one epoch ---
--- 0.28948974609375 seconds for one epoch ---
--- 2.012575387954712 seconds for one epoch ---
--- 0.30031633377075195 seconds for one epoch ---
--- 2.0396640300750732 seconds for one epoch ---
--- 0.2971000671386719 seconds for one epoch ---
--- 2.018557071685791 seconds for one epoch ---
--- 0.29069042205810547 seconds for one epoch ---
--- 2.0299339294433594 seconds for one epoch ---
--- 0.29303479194641113 seconds for one epoch ---
--- 1.9952168464660645 seconds for one epoch ---
--- 0.29813313484191895 seconds for one epoch ---
--- 1.9692938327789307 seconds for one epoch ---
--- 0.14800095558166504 seconds for one epoch ---
--- 2.0159223079681396 seconds for one epoch ---
--- 0.29328060150146484 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.26567506790161133 seconds for one epoch ---
463.2545009394289
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2866.986572265625, (1266.4344, 1.8702629, 1598.6819, 0.0)
   validation loss 1163.6763916015625, (814.9184, 1.073674, 347.68433, 0.0)
decoder loss ratio: 31571.353421, decoder SINDy loss  ratio: 0.750526
--- 0.29877471923828125 seconds for one epoch ---
--- 2.035648822784424 seconds for one epoch ---
--- 0.29025793075561523 seconds for one epoch ---
--- 2.0102438926696777 seconds for one epoch ---
--- 0.2856001853942871 seconds for one epoch ---
--- 2.0917859077453613 seconds for one epoch ---
--- 0.28870511054992676 seconds for one epoch ---
--- 2.024772882461548 seconds for one epoch ---
--- 0.29489660263061523 seconds for one epoch ---
--- 2.0624072551727295 seconds for one epoch ---
--- 0.2703545093536377 seconds for one epoch ---
--- 2.0015039443969727 seconds for one epoch ---
--- 0.29437923431396484 seconds for one epoch ---
--- 2.017531156539917 seconds for one epoch ---
--- 0.29467105865478516 seconds for one epoch ---
--- 2.003950357437134 seconds for one epoch ---
--- 0.3025856018066406 seconds for one epoch ---
--- 2.034242630004883 seconds for one epoch ---
--- 0.1714949607849121 seconds for one epoch ---
--- 2.0192642211914062 seconds for one epoch ---
--- 0.29314422607421875 seconds for one epoch ---
--- 2.013301372528076 seconds for one epoch ---
--- 0.30464792251586914 seconds for one epoch ---
--- 2.0337719917297363 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2943613529205322 seconds for one epoch ---
463.2545009394289
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4616.17333984375, (2301.8633, 3.3448617, 2310.965, 0.0)
   validation loss 815.4482421875, (462.20755, 1.0200675, 352.22058, 0.0)
decoder loss ratio: 17906.722916, decoder SINDy loss  ratio: 0.760318
--- 0.25483059883117676 seconds for one epoch ---
--- 0.30132460594177246 seconds for one epoch ---
--- 2.0325281620025635 seconds for one epoch ---
--- 0.285001277923584 seconds for one epoch ---
--- 2.0092103481292725 seconds for one epoch ---
--- 0.2868821620941162 seconds for one epoch ---
--- 2.045116901397705 seconds for one epoch ---
--- 0.29198694229125977 seconds for one epoch ---
--- 2.0230488777160645 seconds for one epoch ---
--- 0.2918050289154053 seconds for one epoch ---
--- 2.094210624694824 seconds for one epoch ---
--- 0.2888505458831787 seconds for one epoch ---
--- 2.0431227684020996 seconds for one epoch ---
--- 0.2936723232269287 seconds for one epoch ---
--- 2.083240509033203 seconds for one epoch ---
--- 0.2991187572479248 seconds for one epoch ---
--- 2.0371816158294678 seconds for one epoch ---
--- 0.3004570007324219 seconds for one epoch ---
--- 1.937760353088379 seconds for one epoch ---
--- 0.29657602310180664 seconds for one epoch ---
--- 2.026287078857422 seconds for one epoch ---
--- 0.28795695304870605 seconds for one epoch ---
--- 2.0453274250030518 seconds for one epoch ---
--- 0.2819974422454834 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24406909942626953 seconds for one epoch ---
463.2545009394289
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3565.115234375, (1239.0839, 5.8038387, 2320.2275, 0.0)
   validation loss 944.105712890625, (579.173, 1.0841985, 363.84848, 0.0)
decoder loss ratio: 22438.166487, decoder SINDy loss  ratio: 0.785418
--- 0.2943544387817383 seconds for one epoch ---
--- 2.032437562942505 seconds for one epoch ---
--- 0.2737126350402832 seconds for one epoch ---
--- 2.0840046405792236 seconds for one epoch ---
--- 0.28580760955810547 seconds for one epoch ---
--- 2.0095667839050293 seconds for one epoch ---
--- 0.295513391494751 seconds for one epoch ---
--- 2.034909725189209 seconds for one epoch ---
--- 0.28383326530456543 seconds for one epoch ---
--- 2.025177240371704 seconds for one epoch ---
--- 0.29198312759399414 seconds for one epoch ---
--- 2.0680525302886963 seconds for one epoch ---
--- 0.29052305221557617 seconds for one epoch ---
--- 2.072066307067871 seconds for one epoch ---
--- 0.29305171966552734 seconds for one epoch ---
--- 2.057084560394287 seconds for one epoch ---
--- 0.28402280807495117 seconds for one epoch ---
--- 2.0441648960113525 seconds for one epoch ---
--- 0.2920536994934082 seconds for one epoch ---
--- 2.004518508911133 seconds for one epoch ---
--- 0.18100476264953613 seconds for one epoch ---
--- 2.0385777950286865 seconds for one epoch ---
--- 0.2862265110015869 seconds for one epoch ---
--- 2.0452282428741455 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2568233013153076 seconds for one epoch ---
463.2545009394289
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3881.3681640625, (1120.698, 6.5994678, 2754.0708, 0.0)
   validation loss 825.846435546875, (493.4229, 1.0832253, 331.3403, 0.0)
decoder loss ratio: 19116.060254, decoder SINDy loss  ratio: 0.715245
THRESHOLDING: 0 active coefficients
--- 2.066197633743286 seconds for one epoch ---
--- 0.28692197799682617 seconds for one epoch ---
--- 2.0030267238616943 seconds for one epoch ---
--- 0.2948901653289795 seconds for one epoch ---
--- 2.0674521923065186 seconds for one epoch ---
--- 0.29085683822631836 seconds for one epoch ---
--- 2.003607988357544 seconds for one epoch ---
--- 0.30450868606567383 seconds for one epoch ---
--- 2.126187801361084 seconds for one epoch ---
--- 0.2911713123321533 seconds for one epoch ---
--- 2.047473907470703 seconds for one epoch ---
--- 0.30277228355407715 seconds for one epoch ---
--- 2.0787734985351562 seconds for one epoch ---
--- 0.29737305641174316 seconds for one epoch ---
--- 2.1370644569396973 seconds for one epoch ---
--- 0.2931673526763916 seconds for one epoch ---
--- 2.0717380046844482 seconds for one epoch ---
--- 0.29639458656311035 seconds for one epoch ---
--- 2.1132657527923584 seconds for one epoch ---
--- 0.2949366569519043 seconds for one epoch ---
--- 2.0632498264312744 seconds for one epoch ---
--- 0.29970669746398926 seconds for one epoch ---
--- 2.103879928588867 seconds for one epoch ---
--- 0.2938528060913086 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2478775978088379 seconds for one epoch ---
463.2545009394289
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4019.4814453125, (1298.0809, 4.808583, 2716.592, 0.0)
   validation loss 917.170654296875, (570.16345, 1.1388172, 345.8684, 0.0)
decoder loss ratio: 22089.121984, decoder SINDy loss  ratio: 0.746606
--- 0.2921147346496582 seconds for one epoch ---
--- 1.954355239868164 seconds for one epoch ---
--- 0.2406916618347168 seconds for one epoch ---
--- 2.0621659755706787 seconds for one epoch ---
--- 0.28513646125793457 seconds for one epoch ---
--- 2.114025592803955 seconds for one epoch ---
--- 0.25097084045410156 seconds for one epoch ---
--- 2.148622989654541 seconds for one epoch ---
--- 0.27893567085266113 seconds for one epoch ---
--- 2.098935604095459 seconds for one epoch ---
--- 0.2908923625946045 seconds for one epoch ---
--- 2.1146390438079834 seconds for one epoch ---
--- 0.29967451095581055 seconds for one epoch ---
--- 2.111478567123413 seconds for one epoch ---
--- 0.2872781753540039 seconds for one epoch ---
--- 2.106409788131714 seconds for one epoch ---
--- 0.29682230949401855 seconds for one epoch ---
--- 2.086289167404175 seconds for one epoch ---
--- 0.2846970558166504 seconds for one epoch ---
--- 2.1658074855804443 seconds for one epoch ---
--- 0.29647302627563477 seconds for one epoch ---
--- 2.120681047439575 seconds for one epoch ---
--- 0.29610157012939453 seconds for one epoch ---
--- 2.1163392066955566 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2893490791320801 seconds for one epoch ---
463.2545009394289
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2773.277587890625, (912.8242, 1.5883325, 1858.865, 0.0)
   validation loss 841.034912109375, (489.2199, 0.99850845, 350.81647, 0.0)
decoder loss ratio: 18953.228624, decoder SINDy loss  ratio: 0.757287
--- 0.2636690139770508 seconds for one epoch ---
--- 0.2991065979003906 seconds for one epoch ---
--- 2.1304850578308105 seconds for one epoch ---
--- 0.2907242774963379 seconds for one epoch ---
--- 2.0635948181152344 seconds for one epoch ---
--- 0.2976222038269043 seconds for one epoch ---
--- 2.1075258255004883 seconds for one epoch ---
--- 0.2937781810760498 seconds for one epoch ---
--- 2.072356700897217 seconds for one epoch ---
--- 0.2957041263580322 seconds for one epoch ---
--- 2.1664936542510986 seconds for one epoch ---
--- 0.2864556312561035 seconds for one epoch ---
--- 2.129406690597534 seconds for one epoch ---
--- 0.2967565059661865 seconds for one epoch ---
--- 2.110016107559204 seconds for one epoch ---
--- 0.2851088047027588 seconds for one epoch ---
--- 2.1068968772888184 seconds for one epoch ---
--- 0.2925412654876709 seconds for one epoch ---
--- 2.147125720977783 seconds for one epoch ---
--- 0.3024773597717285 seconds for one epoch ---
--- 2.1278932094573975 seconds for one epoch ---
--- 0.2906174659729004 seconds for one epoch ---
--- 2.0758938789367676 seconds for one epoch ---
--- 0.2882702350616455 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2612736225128174 seconds for one epoch ---
463.2545009394289
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3040.798828125, (1283.9694, 1.6586212, 1755.1708, 0.0)
   validation loss 1318.3331298828125, (976.2262, 1.0814464, 341.0255, 0.0)
decoder loss ratio: 37820.697647, decoder SINDy loss  ratio: 0.736152
--- 0.29666852951049805 seconds for one epoch ---
--- 2.1246745586395264 seconds for one epoch ---
--- 0.21695876121520996 seconds for one epoch ---
--- 2.131437063217163 seconds for one epoch ---
--- 0.28743600845336914 seconds for one epoch ---
--- 2.117706775665283 seconds for one epoch ---
--- 0.29996776580810547 seconds for one epoch ---
--- 2.150829315185547 seconds for one epoch ---
--- 0.29975318908691406 seconds for one epoch ---
--- 2.105461359024048 seconds for one epoch ---
--- 0.30349087715148926 seconds for one epoch ---
--- 2.0961554050445557 seconds for one epoch ---
--- 0.2989511489868164 seconds for one epoch ---
--- 2.0854134559631348 seconds for one epoch ---
--- 0.2860565185546875 seconds for one epoch ---
--- 2.151564598083496 seconds for one epoch ---
--- 0.29040980339050293 seconds for one epoch ---
--- 2.154829978942871 seconds for one epoch ---
--- 0.2985653877258301 seconds for one epoch ---
--- 2.1668272018432617 seconds for one epoch ---
--- 0.2857513427734375 seconds for one epoch ---
--- 2.1891510486602783 seconds for one epoch ---
--- 0.295734167098999 seconds for one epoch ---
--- 2.167816162109375 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2848994731903076 seconds for one epoch ---
463.2545009394289
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3170.381103515625, (946.95654, 4.391091, 2219.0334, 0.0)
   validation loss 915.527099609375, (576.04193, 1.1015974, 338.38354, 0.0)
decoder loss ratio: 22316.864466, decoder SINDy loss  ratio: 0.730448
--- 0.2531087398529053 seconds for one epoch ---
--- 0.2925083637237549 seconds for one epoch ---
--- 2.155656337738037 seconds for one epoch ---
--- 0.28301191329956055 seconds for one epoch ---
--- 2.131405830383301 seconds for one epoch ---
--- 0.29345178604125977 seconds for one epoch ---
--- 2.1684682369232178 seconds for one epoch ---
--- 0.2821378707885742 seconds for one epoch ---
--- 2.1388533115386963 seconds for one epoch ---
--- 0.2749490737915039 seconds for one epoch ---
--- 2.178114175796509 seconds for one epoch ---
--- 0.29421019554138184 seconds for one epoch ---
--- 2.167238712310791 seconds for one epoch ---
--- 0.2967710494995117 seconds for one epoch ---
--- 2.1442720890045166 seconds for one epoch ---
--- 0.2913625240325928 seconds for one epoch ---
--- 2.123410701751709 seconds for one epoch ---
--- 0.297619104385376 seconds for one epoch ---
--- 2.166651964187622 seconds for one epoch ---
--- 0.2936716079711914 seconds for one epoch ---
--- 2.173689603805542 seconds for one epoch ---
--- 0.29874205589294434 seconds for one epoch ---
--- 2.167884349822998 seconds for one epoch ---
--- 0.3002920150756836 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2597188949584961 seconds for one epoch ---
463.2545009394289
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3005.12255859375, (1398.2542, 1.2338942, 1605.6346, 0.0)
   validation loss 857.2627563476562, (536.2301, 1.1243367, 319.90833, 0.0)
decoder loss ratio: 20774.485109, decoder SINDy loss  ratio: 0.690567
--- 0.2956852912902832 seconds for one epoch ---
--- 2.1518349647521973 seconds for one epoch ---
--- 0.2938354015350342 seconds for one epoch ---
--- 2.1574063301086426 seconds for one epoch ---
--- 0.28519535064697266 seconds for one epoch ---
--- 2.166212320327759 seconds for one epoch ---
--- 0.2933506965637207 seconds for one epoch ---
--- 2.1846258640289307 seconds for one epoch ---
--- 0.29468607902526855 seconds for one epoch ---
--- 2.1664371490478516 seconds for one epoch ---
--- 0.28310370445251465 seconds for one epoch ---
--- 2.1559035778045654 seconds for one epoch ---
--- 0.28791189193725586 seconds for one epoch ---
--- 2.150554656982422 seconds for one epoch ---
--- 0.3011178970336914 seconds for one epoch ---
--- 2.1688778400421143 seconds for one epoch ---
--- 0.297290563583374 seconds for one epoch ---
--- 2.1584038734436035 seconds for one epoch ---
--- 0.2913780212402344 seconds for one epoch ---
--- 2.1844115257263184 seconds for one epoch ---
--- 0.2894704341888428 seconds for one epoch ---
--- 2.1133832931518555 seconds for one epoch ---
--- 0.29694437980651855 seconds for one epoch ---
--- 2.118408441543579 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2998325824737549 seconds for one epoch ---
463.2545009394289
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3615.68310546875, (1395.2126, 2.2838888, 2218.1865, 0.0)
   validation loss 925.141357421875, (568.4718, 1.1601105, 355.5095, 0.0)
decoder loss ratio: 22023.584511, decoder SINDy loss  ratio: 0.767417
--- 0.2550778388977051 seconds for one epoch ---
--- 0.2980637550354004 seconds for one epoch ---
--- 2.179089307785034 seconds for one epoch ---
--- 0.3010706901550293 seconds for one epoch ---
--- 2.1993536949157715 seconds for one epoch ---
--- 0.3108406066894531 seconds for one epoch ---
--- 2.164823532104492 seconds for one epoch ---
--- 0.2946457862854004 seconds for one epoch ---
--- 2.258382558822632 seconds for one epoch ---
--- 0.3075871467590332 seconds for one epoch ---
--- 2.1727311611175537 seconds for one epoch ---
--- 0.3014531135559082 seconds for one epoch ---
--- 2.1936113834381104 seconds for one epoch ---
--- 0.29953432083129883 seconds for one epoch ---
--- 2.178396463394165 seconds for one epoch ---
--- 0.3197333812713623 seconds for one epoch ---
--- 2.2064411640167236 seconds for one epoch ---
--- 0.29365015029907227 seconds for one epoch ---
--- 2.1880509853363037 seconds for one epoch ---
--- 0.3053617477416992 seconds for one epoch ---
--- 2.193272352218628 seconds for one epoch ---
--- 0.29395246505737305 seconds for one epoch ---
--- 2.193002700805664 seconds for one epoch ---
--- 0.2927553653717041 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2640378475189209 seconds for one epoch ---
463.2545009394289
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2719.65625, (1256.1731, 1.786642, 1461.6965, 0.0)
   validation loss 1070.69873046875, (743.691, 1.2669388, 325.7408, 0.0)
decoder loss ratio: 28811.879631, decoder SINDy loss  ratio: 0.703157
--- 0.2910885810852051 seconds for one epoch ---
--- 2.23341965675354 seconds for one epoch ---
--- 0.1951766014099121 seconds for one epoch ---
--- 2.141494035720825 seconds for one epoch ---
--- 0.28619813919067383 seconds for one epoch ---
--- 2.164214849472046 seconds for one epoch ---
--- 0.2913038730621338 seconds for one epoch ---
--- 2.1993322372436523 seconds for one epoch ---
--- 0.30711865425109863 seconds for one epoch ---
--- 2.1742517948150635 seconds for one epoch ---
--- 0.2916860580444336 seconds for one epoch ---
--- 2.2090985774993896 seconds for one epoch ---
--- 0.29851698875427246 seconds for one epoch ---
--- 2.161522626876831 seconds for one epoch ---
--- 0.2895998954772949 seconds for one epoch ---
--- 2.190638303756714 seconds for one epoch ---
--- 0.28919053077697754 seconds for one epoch ---
--- 2.181926965713501 seconds for one epoch ---
--- 0.30397915840148926 seconds for one epoch ---
--- 2.158241033554077 seconds for one epoch ---
--- 0.29842305183410645 seconds for one epoch ---
--- 2.1744513511657715 seconds for one epoch ---
--- 0.2788844108581543 seconds for one epoch ---
--- 2.1994755268096924 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28936028480529785 seconds for one epoch ---
463.2545009394289
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4670.67333984375, (1981.5068, 3.907246, 2685.2593, 0.0)
   validation loss 998.6927490234375, (658.10297, 1.1672281, 339.42258, 0.0)
decoder loss ratio: 25496.051432, decoder SINDy loss  ratio: 0.732691
--- 0.2587616443634033 seconds for one epoch ---
--- 0.15567946434020996 seconds for one epoch ---
--- 2.1367807388305664 seconds for one epoch ---
--- 0.27828431129455566 seconds for one epoch ---
--- 2.1843950748443604 seconds for one epoch ---
--- 0.27991390228271484 seconds for one epoch ---
--- 2.2105653285980225 seconds for one epoch ---
--- 0.286517858505249 seconds for one epoch ---
--- 2.1800825595855713 seconds for one epoch ---
--- 0.2915048599243164 seconds for one epoch ---
--- 2.204822540283203 seconds for one epoch ---
--- 0.2904179096221924 seconds for one epoch ---
--- 2.194641351699829 seconds for one epoch ---
--- 0.30431675910949707 seconds for one epoch ---
--- 2.2386341094970703 seconds for one epoch ---
--- 0.29273176193237305 seconds for one epoch ---
--- 2.2096962928771973 seconds for one epoch ---
--- 0.28336048126220703 seconds for one epoch ---
--- 2.236741781234741 seconds for one epoch ---
--- 0.2939765453338623 seconds for one epoch ---
--- 2.1998777389526367 seconds for one epoch ---
--- 0.30145740509033203 seconds for one epoch ---
--- 2.221992254257202 seconds for one epoch ---
--- 0.30290985107421875 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25959181785583496 seconds for one epoch ---
463.2545009394289
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3533.94775390625, (1505.2252, 3.375264, 2025.3474, 0.0)
   validation loss 857.3343505859375, (532.47797, 1.2173915, 323.639, 0.0)
decoder loss ratio: 20629.120837, decoder SINDy loss  ratio: 0.698620
--- 0.29631662368774414 seconds for one epoch ---
--- 2.2323453426361084 seconds for one epoch ---
--- 0.29690098762512207 seconds for one epoch ---
--- 2.194766044616699 seconds for one epoch ---
--- 0.30016613006591797 seconds for one epoch ---
--- 2.1765005588531494 seconds for one epoch ---
--- 0.2883107662200928 seconds for one epoch ---
--- 2.1666266918182373 seconds for one epoch ---
--- 0.30202150344848633 seconds for one epoch ---
--- 2.180250644683838 seconds for one epoch ---
--- 0.2942171096801758 seconds for one epoch ---
--- 2.2191600799560547 seconds for one epoch ---
--- 0.29800939559936523 seconds for one epoch ---
--- 2.234199047088623 seconds for one epoch ---
--- 0.2938039302825928 seconds for one epoch ---
--- 2.2827723026275635 seconds for one epoch ---
--- 0.2870182991027832 seconds for one epoch ---
--- 2.230330467224121 seconds for one epoch ---
--- 0.29961109161376953 seconds for one epoch ---
--- 2.2809102535247803 seconds for one epoch ---
--- 0.29721689224243164 seconds for one epoch ---
--- 2.257413387298584 seconds for one epoch ---
--- 0.2909517288208008 seconds for one epoch ---
--- 2.287503242492676 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29213428497314453 seconds for one epoch ---
463.2545009394289
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3931.239501953125, (1832.7985, 2.2274394, 2096.2136, 0.0)
   validation loss 1182.80419921875, (825.23627, 1.203543, 356.36438, 0.0)
decoder loss ratio: 31971.085660, decoder SINDy loss  ratio: 0.769263
--- 0.25333189964294434 seconds for one epoch ---
--- 0.29260969161987305 seconds for one epoch ---
--- 2.2520077228546143 seconds for one epoch ---
--- 0.292386531829834 seconds for one epoch ---
--- 2.234962224960327 seconds for one epoch ---
--- 0.28524136543273926 seconds for one epoch ---
--- 2.2520363330841064 seconds for one epoch ---
--- 0.3048686981201172 seconds for one epoch ---
--- 2.2525925636291504 seconds for one epoch ---
--- 0.30501651763916016 seconds for one epoch ---
--- 2.2010366916656494 seconds for one epoch ---
--- 0.2926468849182129 seconds for one epoch ---
--- 2.2045555114746094 seconds for one epoch ---
--- 0.294236421585083 seconds for one epoch ---
--- 2.1753506660461426 seconds for one epoch ---
--- 0.288144588470459 seconds for one epoch ---
--- 2.2210538387298584 seconds for one epoch ---
--- 0.3035123348236084 seconds for one epoch ---
--- 2.2475671768188477 seconds for one epoch ---
--- 0.2982800006866455 seconds for one epoch ---
--- 2.2237637042999268 seconds for one epoch ---
--- 0.28478574752807617 seconds for one epoch ---
--- 2.2864694595336914 seconds for one epoch ---
--- 0.2980647087097168 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25455427169799805 seconds for one epoch ---
463.2545009394289
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4609.29833984375, (2028.3956, 0.91123396, 2579.9915, 0.0)
   validation loss 924.23681640625, (557.9254, 1.2038302, 365.1075, 0.0)
decoder loss ratio: 21614.999180, decoder SINDy loss  ratio: 0.788136
--- 0.2926750183105469 seconds for one epoch ---
--- 2.251783609390259 seconds for one epoch ---
--- 0.2951374053955078 seconds for one epoch ---
--- 2.208726167678833 seconds for one epoch ---
--- 0.29203009605407715 seconds for one epoch ---
--- 2.2301883697509766 seconds for one epoch ---
--- 0.29768848419189453 seconds for one epoch ---
--- 2.2683730125427246 seconds for one epoch ---
--- 0.2859952449798584 seconds for one epoch ---
--- 2.2480690479278564 seconds for one epoch ---
--- 0.3041718006134033 seconds for one epoch ---
--- 2.3104517459869385 seconds for one epoch ---
--- 0.29371094703674316 seconds for one epoch ---
--- 2.2744803428649902 seconds for one epoch ---
--- 0.28496265411376953 seconds for one epoch ---
--- 2.198809862136841 seconds for one epoch ---
--- 0.29201555252075195 seconds for one epoch ---
--- 2.1944618225097656 seconds for one epoch ---
--- 0.2879321575164795 seconds for one epoch ---
--- 2.2144722938537598 seconds for one epoch ---
--- 0.2866225242614746 seconds for one epoch ---
--- 2.2441539764404297 seconds for one epoch ---
--- 0.6743679046630859 seconds for one epoch ---
--- 2.2579469680786133 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28814053535461426 seconds for one epoch ---
463.2545009394289
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2916.15576171875, (929.4005, 3.7857475, 1982.9696, 0.0)
   validation loss 870.5511474609375, (510.67496, 1.3626653, 358.51358, 0.0)
decoder loss ratio: 19784.434416, decoder SINDy loss  ratio: 0.773902
--- 0.2595787048339844 seconds for one epoch ---
--- 0.31307339668273926 seconds for one epoch ---
--- 2.2721309661865234 seconds for one epoch ---
--- 0.29315185546875 seconds for one epoch ---
--- 2.2876100540161133 seconds for one epoch ---
--- 0.22332453727722168 seconds for one epoch ---
--- 2.271296262741089 seconds for one epoch ---
--- 0.30794811248779297 seconds for one epoch ---
--- 2.2611300945281982 seconds for one epoch ---
--- 0.20807909965515137 seconds for one epoch ---
--- 2.2730612754821777 seconds for one epoch ---
--- 0.30180811882019043 seconds for one epoch ---
--- 2.2506961822509766 seconds for one epoch ---
--- 0.19057202339172363 seconds for one epoch ---
--- 2.287478446960449 seconds for one epoch ---
--- 0.28261423110961914 seconds for one epoch ---
--- 2.2532451152801514 seconds for one epoch ---
--- 0.1914057731628418 seconds for one epoch ---
--- 2.2941408157348633 seconds for one epoch ---
--- 0.28664278984069824 seconds for one epoch ---
--- 2.234187602996826 seconds for one epoch ---
--- 0.19539141654968262 seconds for one epoch ---
--- 2.2230827808380127 seconds for one epoch ---
--- 0.2928903102874756 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24891233444213867 seconds for one epoch ---
463.2545009394289
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3245.13037109375, (1673.6713, 1.2376686, 1570.2213, 0.0)
   validation loss 911.5904541015625, (552.51874, 1.4626411, 357.6091, 0.0)
decoder loss ratio: 21405.535117, decoder SINDy loss  ratio: 0.771950
--- 0.3153526782989502 seconds for one epoch ---
--- 2.254603862762451 seconds for one epoch ---
--- 0.3054020404815674 seconds for one epoch ---
--- 2.2605319023132324 seconds for one epoch ---
--- 0.2952005863189697 seconds for one epoch ---
--- 2.2722792625427246 seconds for one epoch ---
--- 0.2892334461212158 seconds for one epoch ---
--- 2.319257974624634 seconds for one epoch ---
--- 0.29119277000427246 seconds for one epoch ---
--- 2.2483813762664795 seconds for one epoch ---
--- 0.291736364364624 seconds for one epoch ---
--- 2.282219171524048 seconds for one epoch ---
--- 0.2860891819000244 seconds for one epoch ---
--- 2.2607064247131348 seconds for one epoch ---
--- 0.3027040958404541 seconds for one epoch ---
--- 2.3311502933502197 seconds for one epoch ---
--- 0.2716038227081299 seconds for one epoch ---
--- 2.2721149921417236 seconds for one epoch ---
--- 0.2854444980621338 seconds for one epoch ---
--- 2.2715203762054443 seconds for one epoch ---
--- 0.28801941871643066 seconds for one epoch ---
--- 2.252220392227173 seconds for one epoch ---
--- 0.2875375747680664 seconds for one epoch ---
--- 2.30501389503479 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2818796634674072 seconds for one epoch ---
463.2545009394289
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2330.441162109375, (873.8067, 3.9540472, 1452.6804, 0.0)
   validation loss 986.602783203125, (616.35016, 1.4722179, 368.7804, 0.0)
decoder loss ratio: 23878.475179, decoder SINDy loss  ratio: 0.796064
--- 0.2661752700805664 seconds for one epoch ---
--- 0.2935795783996582 seconds for one epoch ---
--- 2.2401304244995117 seconds for one epoch ---
--- 0.29327392578125 seconds for one epoch ---
--- 2.3333005905151367 seconds for one epoch ---
--- 0.29653358459472656 seconds for one epoch ---
--- 2.261019229888916 seconds for one epoch ---
--- 0.2866404056549072 seconds for one epoch ---
--- 2.3332626819610596 seconds for one epoch ---
--- 0.29613471031188965 seconds for one epoch ---
--- 2.263761281967163 seconds for one epoch ---
--- 0.28809261322021484 seconds for one epoch ---
--- 2.347102403640747 seconds for one epoch ---
--- 0.286529541015625 seconds for one epoch ---
--- 2.2601141929626465 seconds for one epoch ---
--- 0.29784321784973145 seconds for one epoch ---
--- 2.337292194366455 seconds for one epoch ---
--- 0.3042428493499756 seconds for one epoch ---
--- 2.258500099182129 seconds for one epoch ---
--- 0.2992255687713623 seconds for one epoch ---
--- 2.3472211360931396 seconds for one epoch ---
--- 0.30199265480041504 seconds for one epoch ---
--- 2.2909445762634277 seconds for one epoch ---
--- 0.28240370750427246 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.24385762214660645 seconds for one epoch ---
463.2545009394289
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2844.25732421875, (1078.3502, 1.1289215, 1764.7782, 0.0)
   validation loss 964.8049926757812, (610.23663, 1.3892366, 353.17914, 0.0)
decoder loss ratio: 23641.626591, decoder SINDy loss  ratio: 0.762387
--- 0.2956366539001465 seconds for one epoch ---
--- 2.2620937824249268 seconds for one epoch ---
--- 0.30646371841430664 seconds for one epoch ---
--- 2.2378668785095215 seconds for one epoch ---
--- 0.2910335063934326 seconds for one epoch ---
--- 2.3733909130096436 seconds for one epoch ---
--- 0.2966310977935791 seconds for one epoch ---
--- 2.2792537212371826 seconds for one epoch ---
--- 0.29943251609802246 seconds for one epoch ---
--- 2.338932514190674 seconds for one epoch ---
--- 0.2890489101409912 seconds for one epoch ---
--- 2.2982585430145264 seconds for one epoch ---
--- 0.2926924228668213 seconds for one epoch ---
--- 2.335571527481079 seconds for one epoch ---
--- 0.2982914447784424 seconds for one epoch ---
--- 2.2883598804473877 seconds for one epoch ---
--- 0.29261183738708496 seconds for one epoch ---
--- 2.3306567668914795 seconds for one epoch ---
--- 0.2857778072357178 seconds for one epoch ---
--- 2.2977638244628906 seconds for one epoch ---
--- 0.2933990955352783 seconds for one epoch ---
--- 2.3373398780822754 seconds for one epoch ---
--- 0.2900087833404541 seconds for one epoch ---
--- 2.2899956703186035 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.28360486030578613 seconds for one epoch ---
463.2545009394289
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3837.72607421875, (1340.7399, 2.0344474, 2494.952, 0.0)
   validation loss 973.1506958007812, (641.1886, 1.4086676, 330.5534, 0.0)
decoder loss ratio: 24840.759463, decoder SINDy loss  ratio: 0.713546
--- 1.060755968093872 seconds for one epoch ---
--- 0.29466795921325684 seconds for one epoch ---
--- 2.333836078643799 seconds for one epoch ---
--- 0.29552364349365234 seconds for one epoch ---
--- 2.260958433151245 seconds for one epoch ---
--- 0.30240702629089355 seconds for one epoch ---
--- 2.267012357711792 seconds for one epoch ---
--- 0.31131744384765625 seconds for one epoch ---
--- 2.267638921737671 seconds for one epoch ---
--- 0.29734277725219727 seconds for one epoch ---
--- 2.295707941055298 seconds for one epoch ---
--- 0.29860663414001465 seconds for one epoch ---
--- 2.2926504611968994 seconds for one epoch ---
--- 0.30008983612060547 seconds for one epoch ---
--- 2.3696696758270264 seconds for one epoch ---
--- 0.2927842140197754 seconds for one epoch ---
--- 2.31681752204895 seconds for one epoch ---
--- 0.16177797317504883 seconds for one epoch ---
--- 2.271885871887207 seconds for one epoch ---
--- 0.28519153594970703 seconds for one epoch ---
--- 2.2760725021362305 seconds for one epoch ---
--- 0.1828474998474121 seconds for one epoch ---
--- 2.3191046714782715 seconds for one epoch ---
--- 0.2789275646209717 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2634165287017822 seconds for one epoch ---
463.2545009394289
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3380.474609375, (1355.6649, 4.922152, 2019.8875, 0.0)
   validation loss 1255.772705078125, (908.33453, 1.4510416, 345.98715, 0.0)
decoder loss ratio: 35190.456773, decoder SINDy loss  ratio: 0.746862
--- 0.291881799697876 seconds for one epoch ---
--- 2.3001630306243896 seconds for one epoch ---
--- 0.3017387390136719 seconds for one epoch ---
--- 2.3846020698547363 seconds for one epoch ---
--- 0.2955036163330078 seconds for one epoch ---
--- 2.3075835704803467 seconds for one epoch ---
--- 0.2938196659088135 seconds for one epoch ---
--- 2.3818061351776123 seconds for one epoch ---
--- 0.2907567024230957 seconds for one epoch ---
--- 2.3170676231384277 seconds for one epoch ---
--- 0.29697227478027344 seconds for one epoch ---
--- 2.3965065479278564 seconds for one epoch ---
--- 0.2977621555328369 seconds for one epoch ---
--- 2.3310866355895996 seconds for one epoch ---
--- 0.24107789993286133 seconds for one epoch ---
--- 2.3982250690460205 seconds for one epoch ---
--- 0.29480624198913574 seconds for one epoch ---
--- 2.2816951274871826 seconds for one epoch ---
--- 0.14807343482971191 seconds for one epoch ---
--- 2.3146114349365234 seconds for one epoch ---
--- 0.27270054817199707 seconds for one epoch ---
--- 2.2864134311676025 seconds for one epoch ---
--- 0.15143680572509766 seconds for one epoch ---
--- 2.3172171115875244 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.29268360137939453 seconds for one epoch ---
463.2545009394289
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3312.63232421875, (1471.4497, 7.0873547, 1834.0951, 0.0)
   validation loss 1323.0291748046875, (954.9677, 1.4213699, 366.64005, 0.0)
decoder loss ratio: 36997.107075, decoder SINDy loss  ratio: 0.791444
--- 0.26165151596069336 seconds for one epoch ---
--- 0.30113863945007324 seconds for one epoch ---
--- 2.283097982406616 seconds for one epoch ---
--- 0.2967054843902588 seconds for one epoch ---
--- 2.367846965789795 seconds for one epoch ---
--- 0.30009937286376953 seconds for one epoch ---
--- 2.3200411796569824 seconds for one epoch ---
--- 0.3030099868774414 seconds for one epoch ---
--- 2.3222827911376953 seconds for one epoch ---
--- 0.29248642921447754 seconds for one epoch ---
--- 2.3098814487457275 seconds for one epoch ---
--- 0.2938532829284668 seconds for one epoch ---
--- 2.3818888664245605 seconds for one epoch ---
--- 0.29886412620544434 seconds for one epoch ---
--- 2.325266122817993 seconds for one epoch ---
--- 0.24094557762145996 seconds for one epoch ---
--- 2.364344835281372 seconds for one epoch ---
--- 0.29665422439575195 seconds for one epoch ---
--- 2.3162572383880615 seconds for one epoch ---
--- 0.15172362327575684 seconds for one epoch ---
--- 2.3152501583099365 seconds for one epoch ---
--- 0.2862107753753662 seconds for one epoch ---
--- 2.235764741897583 seconds for one epoch ---
--- 0.211320161819458 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.25530076026916504 seconds for one epoch ---
463.2545009394289
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2128.4921875, (653.31757, 1.0631126, 1474.1116, 0.0)
   validation loss 809.1142578125, (468.98734, 1.3884372, 338.73846, 0.0)
decoder loss ratio: 18169.383564, decoder SINDy loss  ratio: 0.731215
--- 0.28850626945495605 seconds for one epoch ---
--- 2.389044761657715 seconds for one epoch ---
--- 0.29590725898742676 seconds for one epoch ---
--- 2.33381724357605 seconds for one epoch ---
--- 0.29692578315734863 seconds for one epoch ---
--- 2.389859437942505 seconds for one epoch ---
--- 0.2891383171081543 seconds for one epoch ---
--- 2.341012477874756 seconds for one epoch ---
--- 0.2722961902618408 seconds for one epoch ---
--- 2.392185926437378 seconds for one epoch ---
--- 0.2871530055999756 seconds for one epoch ---
--- 2.3331875801086426 seconds for one epoch ---
--- 0.15648698806762695 seconds for one epoch ---
--- 2.3189871311187744 seconds for one epoch ---
--- 0.283860445022583 seconds for one epoch ---
--- 2.323601007461548 seconds for one epoch ---
--- 0.14479994773864746 seconds for one epoch ---
--- 2.3780901432037354 seconds for one epoch ---
--- 0.28945302963256836 seconds for one epoch ---
--- 2.2707326412200928 seconds for one epoch ---
--- 0.23593354225158691 seconds for one epoch ---
--- 2.343435525894165 seconds for one epoch ---
--- 0.2929530143737793 seconds for one epoch ---
--- 2.218413829803467 seconds for one epoch ---
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
--- 0.2796046733856201 seconds for one epoch ---
463.2545009394289
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2679.0673828125, (1313.3245, 3.2285004, 1362.5144, 0.0)
   validation loss 939.01123046875, (594.9731, 1.3364556, 342.7017, 0.0)
decoder loss ratio: 23050.290173, decoder SINDy loss  ratio: 0.739770
THRESHOLDING: 0 active coefficients
REFINEMENT
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1186.1927490234375, (571.90106, 1.0566306, 613.23505, 0.0)
   validation loss 825.20751953125, (515.5113, 1.1530429, 308.54318, 0.0)
decoder loss ratio: 19971.802400, decoder SINDy loss  ratio: 0.666034
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.25830078125, (367.49023, 1.4058334, 573.36224, 0.0)
   validation loss 546.6217651367188, (270.65503, 0.3725589, 275.59418, 0.0)
decoder loss ratio: 10485.645713, decoder SINDy loss  ratio: 0.594909
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 863.8265380859375, (306.41855, 0.8577895, 556.5502, 0.0)
   validation loss 508.21649169921875, (236.31665, 0.3135852, 271.58624, 0.0)
decoder loss ratio: 9155.317300, decoder SINDy loss  ratio: 0.586257
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 812.5770263671875, (269.93536, 0.6885799, 541.9531, 0.0)
   validation loss 482.38470458984375, (213.9501, 0.30719116, 268.1274, 0.0)
decoder loss ratio: 8288.798453, decoder SINDy loss  ratio: 0.578791
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.4290771484375, (285.85913, 0.5912639, 534.97864, 0.0)
   validation loss 490.041259765625, (223.22896, 0.31106457, 266.50122, 0.0)
decoder loss ratio: 8648.277380, decoder SINDy loss  ratio: 0.575280
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.183349609375, (260.22403, 0.5310899, 538.4282, 0.0)
   validation loss 473.61865234375, (203.4153, 0.3075509, 269.89578, 0.0)
decoder loss ratio: 7880.661807, decoder SINDy loss  ratio: 0.582608
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 859.0159912109375, (304.52484, 0.4988255, 553.9923, 0.0)
   validation loss 518.139404296875, (242.39934, 0.30971175, 275.43033, 0.0)
decoder loss ratio: 9390.971169, decoder SINDy loss  ratio: 0.594555
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 783.649658203125, (251.96576, 0.49111214, 531.1928, 0.0)
   validation loss 464.98443603515625, (196.06308, 0.31227705, 268.60907, 0.0)
decoder loss ratio: 7595.824093, decoder SINDy loss  ratio: 0.579830
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.71875, (260.7283, 0.4566741, 520.5338, 0.0)
   validation loss 467.7231140136719, (201.67871, 0.31418332, 265.73022, 0.0)
decoder loss ratio: 7813.383391, decoder SINDy loss  ratio: 0.573616
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.3521728515625, (302.5701, 0.43470868, 553.34735, 0.0)
   validation loss 515.2560424804688, (238.69717, 0.31819382, 276.24066, 0.0)
decoder loss ratio: 9247.542920, decoder SINDy loss  ratio: 0.596304
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 827.6689453125, (325.7609, 0.43865576, 501.4694, 0.0)
   validation loss 517.55078125, (255.57724, 0.32408026, 261.64948, 0.0)
decoder loss ratio: 9901.505979, decoder SINDy loss  ratio: 0.564807
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 792.9614868164062, (280.5017, 0.43628773, 512.0235, 0.0)
   validation loss 474.1920471191406, (210.70963, 0.3270908, 263.15533, 0.0)
decoder loss ratio: 8163.256690, decoder SINDy loss  ratio: 0.568058
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1042.552490234375, (548.4321, 0.41951132, 493.70093, 0.0)
   validation loss 682.583251953125, (419.5644, 0.32775912, 262.69107, 0.0)
decoder loss ratio: 16254.652945, decoder SINDy loss  ratio: 0.567056
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1010.341796875, (432.0091, 0.42636362, 577.9064, 0.0)
   validation loss 647.3265991210938, (359.14276, 0.33424926, 287.84958, 0.0)
decoder loss ratio: 13913.814069, decoder SINDy loss  ratio: 0.621364
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.5855712890625, (246.02145, 0.41908157, 521.145, 0.0)
   validation loss 454.5630798339844, (186.91693, 0.3438773, 267.30228, 0.0)
decoder loss ratio: 7241.486415, decoder SINDy loss  ratio: 0.577010
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1139.959228515625, (552.5584, 0.40544334, 586.9954, 0.0)
   validation loss 793.46630859375, (500.25015, 0.33877715, 292.8774, 0.0)
decoder loss ratio: 19380.559384, decoder SINDy loss  ratio: 0.632217
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 936.4619140625, (446.45584, 0.41116688, 489.5949, 0.0)
   validation loss 609.2142333984375, (349.26764, 0.35662493, 259.58994, 0.0)
decoder loss ratio: 13531.234696, decoder SINDy loss  ratio: 0.560361
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 898.11767578125, (345.81238, 0.39683858, 551.90845, 0.0)
   validation loss 577.6927490234375, (296.8226, 0.35060722, 280.5195, 0.0)
decoder loss ratio: 11499.422882, decoder SINDy loss  ratio: 0.605541
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.3900146484375, (269.32687, 0.3937128, 503.6694, 0.0)
   validation loss 464.5741271972656, (201.80626, 0.36094746, 262.40692, 0.0)
decoder loss ratio: 7818.324831, decoder SINDy loss  ratio: 0.566442
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 763.8740844726562, (252.22719, 0.39280102, 511.2541, 0.0)
   validation loss 453.1832580566406, (188.19029, 0.3607008, 264.63226, 0.0)
decoder loss ratio: 7290.818639, decoder SINDy loss  ratio: 0.571246
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.15771484375, (252.67482, 0.39667413, 526.08624, 0.0)
   validation loss 468.761962890625, (198.01866, 0.3663625, 270.37695, 0.0)
decoder loss ratio: 7671.586722, decoder SINDy loss  ratio: 0.583647
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 875.43896484375, (326.7731, 0.39034373, 548.2755, 0.0)
   validation loss 550.34521484375, (271.88913, 0.3700427, 278.086, 0.0)
decoder loss ratio: 10533.456902, decoder SINDy loss  ratio: 0.600288
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.565673828125, (256.27875, 0.39223436, 524.89465, 0.0)
   validation loss 471.2953186035156, (201.21814, 0.37209466, 269.70508, 0.0)
decoder loss ratio: 7795.540060, decoder SINDy loss  ratio: 0.582196
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 816.297119140625, (324.84555, 0.38445714, 491.06708, 0.0)
   validation loss 508.446533203125, (248.88385, 0.38205174, 259.18063, 0.0)
decoder loss ratio: 9642.192434, decoder SINDy loss  ratio: 0.559478
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.8762817382812, (237.64523, 0.38029173, 510.85074, 0.0)
   validation loss 446.40576171875, (180.76025, 0.37632167, 265.2692, 0.0)
decoder loss ratio: 7002.966050, decoder SINDy loss  ratio: 0.572621
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 749.5858154296875, (251.57466, 0.38656425, 497.6246, 0.0)
   validation loss 449.2412109375, (188.68959, 0.3816188, 260.17, 0.0)
decoder loss ratio: 7310.162314, decoder SINDy loss  ratio: 0.561614
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.4485473632812, (257.4542, 0.42216092, 520.5722, 0.0)
   validation loss 478.85540771484375, (209.69841, 0.38481054, 268.7722, 0.0)
decoder loss ratio: 8124.080457, decoder SINDy loss  ratio: 0.580183
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 792.087646484375, (266.49142, 0.37770042, 525.2185, 0.0)
   validation loss 483.443359375, (214.1813, 0.38582474, 268.87622, 0.0)
decoder loss ratio: 8297.755588, decoder SINDy loss  ratio: 0.580407
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 836.58447265625, (298.50024, 0.39303267, 537.69116, 0.0)
   validation loss 520.9937744140625, (244.39365, 0.3867355, 276.21338, 0.0)
decoder loss ratio: 9468.234141, decoder SINDy loss  ratio: 0.596245
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.3622436523438, (258.05682, 0.39580372, 495.9096, 0.0)
   validation loss 454.0606689453125, (193.24881, 0.3981733, 260.4137, 0.0)
decoder loss ratio: 7486.794387, decoder SINDy loss  ratio: 0.562140
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.736083984375, (229.3114, 0.4047837, 507.0199, 0.0)
   validation loss 443.81927490234375, (179.63744, 0.3969527, 263.78488, 0.0)
decoder loss ratio: 6959.466132, decoder SINDy loss  ratio: 0.569417
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 958.4026489257812, (422.98676, 0.43017885, 534.9857, 0.0)
   validation loss 688.687744140625, (405.99103, 0.39616504, 282.30057, 0.0)
decoder loss ratio: 15728.797250, decoder SINDy loss  ratio: 0.609385
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1482.72509765625, (876.7329, 0.41176605, 605.5804, 0.0)
   validation loss 1162.8699951171875, (850.06366, 0.38745272, 312.41885, 0.0)
decoder loss ratio: 32932.941951, decoder SINDy loss  ratio: 0.674400
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 817.01953125, (329.84222, 0.40688965, 486.77045, 0.0)
   validation loss 514.9967041015625, (257.2028, 0.41065252, 257.38324, 0.0)
decoder loss ratio: 9964.482581, decoder SINDy loss  ratio: 0.555598
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.7952880859375, (265.9057, 0.3939363, 492.49564, 0.0)
   validation loss 461.60369873046875, (203.02397, 0.40357673, 258.17615, 0.0)
decoder loss ratio: 7865.501123, decoder SINDy loss  ratio: 0.557310
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.8455200195312, (307.7648, 0.4207042, 485.66, 0.0)
   validation loss 483.38653564453125, (229.01619, 0.41188213, 253.95845, 0.0)
decoder loss ratio: 8872.484774, decoder SINDy loss  ratio: 0.548205
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 956.6802978515625, (400.08063, 0.43079236, 556.1689, 0.0)
   validation loss 634.7783203125, (349.64206, 0.4059723, 284.73032, 0.0)
decoder loss ratio: 13545.740384, decoder SINDy loss  ratio: 0.614630
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.3644409179688, (230.50987, 0.42929307, 501.4253, 0.0)
   validation loss 434.76275634765625, (173.64354, 0.42309427, 260.6961, 0.0)
decoder loss ratio: 6727.252176, decoder SINDy loss  ratio: 0.562749
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 942.6912841796875, (461.52664, 0.41669813, 480.74792, 0.0)
   validation loss 617.7042236328125, (364.54456, 0.41993314, 252.73975, 0.0)
decoder loss ratio: 14123.088964, decoder SINDy loss  ratio: 0.545574
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.5369873046875, (242.78262, 0.49386743, 501.2605, 0.0)
   validation loss 440.30462646484375, (181.42491, 0.43539712, 258.44434, 0.0)
decoder loss ratio: 7028.716039, decoder SINDy loss  ratio: 0.557888
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 944.8875732421875, (388.75607, 0.45462167, 555.6769, 0.0)
   validation loss 622.4945068359375, (339.85376, 0.4136196, 282.22714, 0.0)
decoder loss ratio: 13166.524665, decoder SINDy loss  ratio: 0.609227
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.8361206054688, (287.67432, 0.44779363, 490.71402, 0.0)
   validation loss 469.0286865234375, (215.20796, 0.42690268, 253.39384, 0.0)
decoder loss ratio: 8337.530067, decoder SINDy loss  ratio: 0.546986
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 882.1602172851562, (340.81104, 0.48779365, 540.8614, 0.0)
   validation loss 580.919921875, (305.3997, 0.41898015, 275.10123, 0.0)
decoder loss ratio: 11831.714138, decoder SINDy loss  ratio: 0.593845
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1927.9654541015625, (1281.9325, 0.5060426, 645.52686, 0.0)
   validation loss 1577.4912109375, (1246.6221, 0.41674116, 330.45245, 0.0)
decoder loss ratio: 48296.303235, decoder SINDy loss  ratio: 0.713328
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 820.5179443359375, (281.6202, 0.46919072, 538.4286, 0.0)
   validation loss 502.68560791015625, (231.88869, 0.42074892, 270.3762, 0.0)
decoder loss ratio: 8983.770316, decoder SINDy loss  ratio: 0.583645
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 742.5335693359375, (238.56313, 0.45914388, 503.5113, 0.0)
   validation loss 433.0975341796875, (178.22047, 0.42695576, 254.4501, 0.0)
decoder loss ratio: 6904.570577, decoder SINDy loss  ratio: 0.549266
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.3396606445312, (229.99042, 0.46140867, 509.88785, 0.0)
   validation loss 434.32354736328125, (177.29529, 0.41804668, 256.6102, 0.0)
decoder loss ratio: 6868.727259, decoder SINDy loss  ratio: 0.553929
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 924.0439453125, (431.24826, 0.50710034, 492.28857, 0.0)
   validation loss 566.863525390625, (316.62613, 0.4398651, 249.79758, 0.0)
decoder loss ratio: 12266.645930, decoder SINDy loss  ratio: 0.539223
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 904.78857421875, (414.4265, 0.47574735, 489.88632, 0.0)
   validation loss 574.1854858398438, (325.37692, 0.42880458, 248.37978, 0.0)
decoder loss ratio: 12605.666861, decoder SINDy loss  ratio: 0.536163
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 809.832275390625, (314.70587, 0.48589706, 494.64047, 0.0)
   validation loss 489.29400634765625, (239.0187, 0.43610445, 249.8392, 0.0)
decoder loss ratio: 9259.999675, decoder SINDy loss  ratio: 0.539313
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 732.109130859375, (221.61943, 0.47240776, 510.01727, 0.0)
   validation loss 419.99072265625, (165.18011, 0.4248688, 254.38573, 0.0)
decoder loss ratio: 6399.364411, decoder SINDy loss  ratio: 0.549127
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.9168701171875, (326.4667, 0.45860794, 492.99155, 0.0)
   validation loss 487.44329833984375, (239.23267, 0.43072537, 247.77989, 0.0)
decoder loss ratio: 9268.288808, decoder SINDy loss  ratio: 0.534868
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 922.5100708007812, (432.7016, 0.4602634, 489.3482, 0.0)
   validation loss 578.9387817382812, (331.66678, 0.4264918, 246.8455, 0.0)
decoder loss ratio: 12849.346800, decoder SINDy loss  ratio: 0.532851
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 740.935302734375, (230.5693, 0.4529518, 509.91306, 0.0)
   validation loss 426.4881286621094, (173.16393, 0.42082188, 252.90338, 0.0)
decoder loss ratio: 6708.671087, decoder SINDy loss  ratio: 0.545928
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 930.678466796875, (374.80392, 0.45374593, 555.4208, 0.0)
   validation loss 609.47900390625, (336.24988, 0.40288496, 272.82623, 0.0)
decoder loss ratio: 13026.904026, decoder SINDy loss  ratio: 0.588934
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 794.9833984375, (297.21783, 0.43733552, 497.3282, 0.0)
   validation loss 465.2259216308594, (215.73402, 0.42257017, 249.06932, 0.0)
decoder loss ratio: 8357.910622, decoder SINDy loss  ratio: 0.537651
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 933.006103515625, (444.806, 0.4142456, 487.7859, 0.0)
   validation loss 588.296875, (340.4883, 0.41312066, 247.39545, 0.0)
decoder loss ratio: 13191.108312, decoder SINDy loss  ratio: 0.534038
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.0169677734375, (328.81097, 0.41035995, 492.79565, 0.0)
   validation loss 494.8280334472656, (246.54507, 0.4135494, 247.86942, 0.0)
decoder loss ratio: 9551.584206, decoder SINDy loss  ratio: 0.535061
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 944.1724853515625, (385.26978, 0.43005052, 558.47266, 0.0)
   validation loss 622.77783203125, (347.35776, 0.40070263, 275.0194, 0.0)
decoder loss ratio: 13457.242568, decoder SINDy loss  ratio: 0.593668
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.002197265625, (273.95255, 0.41243875, 499.6372, 0.0)
   validation loss 449.296875, (198.29887, 0.4160954, 250.5819, 0.0)
decoder loss ratio: 7682.442637, decoder SINDy loss  ratio: 0.540916
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 871.3282470703125, (381.63995, 0.39198303, 489.29636, 0.0)
   validation loss 533.8828125, (285.30814, 0.40590888, 248.16873, 0.0)
decoder loss ratio: 11053.332505, decoder SINDy loss  ratio: 0.535707
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.80126953125, (304.552, 0.390763, 493.85852, 0.0)
   validation loss 477.07366943359375, (227.49554, 0.40795672, 249.17017, 0.0)
decoder loss ratio: 8813.572341, decoder SINDy loss  ratio: 0.537869
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1025.3077392578125, (455.98904, 0.41719618, 568.9015, 0.0)
   validation loss 699.2648315429688, (417.73587, 0.39447874, 281.1345, 0.0)
decoder loss ratio: 16183.812839, decoder SINDy loss  ratio: 0.606868
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.8421630859375, (275.97708, 0.38998917, 497.4751, 0.0)
   validation loss 450.9617004394531, (199.50972, 0.4096781, 251.0423, 0.0)
decoder loss ratio: 7729.352911, decoder SINDy loss  ratio: 0.541910
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 889.3707275390625, (403.16245, 0.3690553, 485.83926, 0.0)
   validation loss 549.8866577148438, (300.91052, 0.39791295, 248.57822, 0.0)
decoder loss ratio: 11657.796044, decoder SINDy loss  ratio: 0.536591
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 829.0052490234375, (340.05038, 0.36955208, 488.5853, 0.0)
   validation loss 503.4180908203125, (253.8519, 0.4009176, 249.16527, 0.0)
decoder loss ratio: 9834.663242, decoder SINDy loss  ratio: 0.537858
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1092.64404296875, (515.5051, 0.4076811, 576.73126, 0.0)
   validation loss 765.6183471679688, (478.49777, 0.38868108, 286.7319, 0.0)
decoder loss ratio: 18537.834404, decoder SINDy loss  ratio: 0.618951
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 760.2550048828125, (263.47458, 0.37327644, 496.40717, 0.0)
   validation loss 442.3895263671875, (189.95573, 0.40266228, 252.03111, 0.0)
decoder loss ratio: 7359.214923, decoder SINDy loss  ratio: 0.544045
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 812.18994140625, (323.9265, 0.36139023, 487.902, 0.0)
   validation loss 483.87127685546875, (233.73903, 0.3912251, 249.74101, 0.0)
decoder loss ratio: 9055.455770, decoder SINDy loss  ratio: 0.539101
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 839.860107421875, (354.1506, 0.35813624, 485.35138, 0.0)
   validation loss 512.9607543945312, (263.247, 0.39483362, 249.3189, 0.0)
decoder loss ratio: 10198.646156, decoder SINDy loss  ratio: 0.538190
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1181.259765625, (593.82635, 0.404159, 587.0292, 0.0)
   validation loss 850.1378173828125, (556.8856, 0.38128456, 292.8709, 0.0)
decoder loss ratio: 21574.715719, decoder SINDy loss  ratio: 0.632203
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.4697265625, (224.64978, 0.37893778, 510.44098, 0.0)
   validation loss 434.874755859375, (175.32587, 0.3950272, 259.15384, 0.0)
decoder loss ratio: 6792.428455, decoder SINDy loss  ratio: 0.559420
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 799.11865234375, (312.57068, 0.34992304, 486.19806, 0.0)
   validation loss 475.1592712402344, (224.63817, 0.3819717, 250.13913, 0.0)
decoder loss ratio: 8702.872630, decoder SINDy loss  ratio: 0.539960
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.16845703125, (337.20642, 0.34504429, 483.61703, 0.0)
   validation loss 499.05987548828125, (248.96964, 0.38483474, 249.7054, 0.0)
decoder loss ratio: 9645.515891, decoder SINDy loss  ratio: 0.539024
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1293.3154296875, (694.3089, 0.40034077, 598.60626, 0.0)
   validation loss 959.5223388671875, (659.3578, 0.37391448, 299.79068, 0.0)
decoder loss ratio: 25544.665406, decoder SINDy loss  ratio: 0.647140
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 773.279541015625, (251.20097, 0.3831586, 521.69543, 0.0)
   validation loss 478.3892822265625, (212.4117, 0.38887233, 265.5887, 0.0)
decoder loss ratio: 8229.197920, decoder SINDy loss  ratio: 0.573311
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.5009765625, (226.51463, 0.36204085, 503.6243, 0.0)
   validation loss 423.49163818359375, (166.19412, 0.37424517, 256.92328, 0.0)
decoder loss ratio: 6438.648824, decoder SINDy loss  ratio: 0.554605
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 752.4959716796875, (261.38113, 0.34879974, 490.76602, 0.0)
   validation loss 444.24078369140625, (191.78412, 0.37660888, 252.08005, 0.0)
decoder loss ratio: 7430.049708, decoder SINDy loss  ratio: 0.544150
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.284912109375, (331.73685, 0.33755994, 481.21054, 0.0)
   validation loss 486.655029296875, (236.66968, 0.371982, 249.61336, 0.0)
decoder loss ratio: 9168.994192, decoder SINDy loss  ratio: 0.538826
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.089599609375, (281.68768, 0.39528197, 524.0066, 0.0)
   validation loss 517.4718017578125, (248.4419, 0.38425824, 268.64566, 0.0)
decoder loss ratio: 9625.070308, decoder SINDy loss  ratio: 0.579909
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1059.5355224609375, (490.99557, 0.3848388, 568.15515, 0.0)
   validation loss 751.3575439453125, (464.3484, 0.36337715, 286.6458, 0.0)
decoder loss ratio: 17989.662721, decoder SINDy loss  ratio: 0.618765
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.6163330078125, (223.8443, 0.35728148, 512.41473, 0.0)
   validation loss 440.58062744140625, (178.6097, 0.37638456, 261.59454, 0.0)
decoder loss ratio: 6919.649681, decoder SINDy loss  ratio: 0.564689
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 825.525146484375, (292.84827, 0.3622439, 532.31464, 0.0)
   validation loss 529.1815185546875, (257.4348, 0.36178443, 271.38495, 0.0)
decoder loss ratio: 9973.471638, decoder SINDy loss  ratio: 0.585823
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.474853515625, (318.7182, 0.32960072, 479.4271, 0.0)
   validation loss 481.64031982421875, (231.2595, 0.3716556, 250.00914, 0.0)
decoder loss ratio: 8959.394755, decoder SINDy loss  ratio: 0.539680
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.8922729492188, (220.10806, 0.33880126, 496.4454, 0.0)
   validation loss 415.2801818847656, (158.61273, 0.36108568, 256.30637, 0.0)
decoder loss ratio: 6144.932599, decoder SINDy loss  ratio: 0.553273
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 779.8892822265625, (298.99265, 0.32793477, 480.5687, 0.0)
   validation loss 467.8153076171875, (217.05267, 0.36772928, 250.39491, 0.0)
decoder loss ratio: 8408.997385, decoder SINDy loss  ratio: 0.540513
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1222.190185546875, (637.4503, 0.37296024, 584.3668, 0.0)
   validation loss 912.5001220703125, (615.28076, 0.35821694, 296.86115, 0.0)
decoder loss ratio: 23837.044883, decoder SINDy loss  ratio: 0.640817
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.2386474609375, (283.77982, 0.37564167, 529.0832, 0.0)
   validation loss 527.4479370117188, (255.162, 0.37438777, 271.91153, 0.0)
decoder loss ratio: 9885.418960, decoder SINDy loss  ratio: 0.586959
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 798.9527587890625, (324.21625, 0.3193469, 474.41714, 0.0)
   validation loss 479.07525634765625, (229.7247, 0.36036873, 248.99019, 0.0)
decoder loss ratio: 8899.933734, decoder SINDy loss  ratio: 0.537480
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 741.868408203125, (231.94748, 0.34899145, 509.5719, 0.0)
   validation loss 453.2413330078125, (189.8423, 0.37021336, 263.02884, 0.0)
decoder loss ratio: 7354.820299, decoder SINDy loss  ratio: 0.567785
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 756.62109375, (242.38863, 0.34588856, 513.8866, 0.0)
   validation loss 467.3753662109375, (202.18402, 0.3585199, 264.83282, 0.0)
decoder loss ratio: 7832.959980, decoder SINDy loss  ratio: 0.571679
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.361572265625, (216.23477, 0.33795696, 494.78888, 0.0)
   validation loss 420.0972900390625, (162.73058, 0.36859614, 256.99814, 0.0)
decoder loss ratio: 6304.465010, decoder SINDy loss  ratio: 0.554767
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 753.6889038085938, (240.44524, 0.3676179, 512.87604, 0.0)
   validation loss 462.51922607421875, (198.06525, 0.36274496, 264.09125, 0.0)
decoder loss ratio: 7673.391509, decoder SINDy loss  ratio: 0.570078
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 864.7523193359375, (394.53394, 0.32162914, 469.89673, 0.0)
   validation loss 544.2122192382812, (295.89093, 0.36980203, 247.95148, 0.0)
decoder loss ratio: 11463.328324, decoder SINDy loss  ratio: 0.535238
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.5950927734375, (224.60126, 0.3233041, 497.6705, 0.0)
   validation loss 428.1531982421875, (169.69272, 0.35148212, 258.10898, 0.0)
decoder loss ratio: 6574.190514, decoder SINDy loss  ratio: 0.557165
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 981.91943359375, (516.032, 0.29832572, 465.58908, 0.0)
   validation loss 610.9949951171875, (363.20804, 0.36949375, 247.41748, 0.0)
decoder loss ratio: 14071.309962, decoder SINDy loss  ratio: 0.534085
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.9625854492188, (220.94513, 0.33029652, 488.68716, 0.0)
   validation loss 415.3826904296875, (159.81389, 0.357511, 255.21129, 0.0)
decoder loss ratio: 6191.467492, decoder SINDy loss  ratio: 0.550909
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.4345092773438, (231.63438, 0.32861304, 486.47153, 0.0)
   validation loss 421.226318359375, (167.16708, 0.36551648, 253.69373, 0.0)
decoder loss ratio: 6476.343039, decoder SINDy loss  ratio: 0.547634
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1166.1778564453125, (591.08344, 0.36722612, 574.7272, 0.0)
   validation loss 856.2105712890625, (562.10657, 0.3536479, 293.7504, 0.0)
decoder loss ratio: 21776.984280, decoder SINDy loss  ratio: 0.634102
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.025390625, (222.87325, 0.33103788, 484.82108, 0.0)
   validation loss 416.7430419921875, (162.11035, 0.3665018, 254.26619, 0.0)
decoder loss ratio: 6280.436455, decoder SINDy loss  ratio: 0.548869
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 800.437255859375, (334.48846, 0.3046313, 465.64413, 0.0)
   validation loss 483.6478271484375, (235.6276, 0.35289466, 247.66733, 0.0)
decoder loss ratio: 9128.622059, decoder SINDy loss  ratio: 0.534625
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.617431640625, (348.75912, 0.31234324, 465.54596, 0.0)
   validation loss 500.54327392578125, (252.75565, 0.3609791, 247.42664, 0.0)
decoder loss ratio: 9792.192520, decoder SINDy loss  ratio: 0.534105
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1228.473388671875, (648.2351, 0.3725182, 579.86584, 0.0)
   validation loss 918.1231689453125, (620.185, 0.35396045, 297.58426, 0.0)
decoder loss ratio: 24027.043494, decoder SINDy loss  ratio: 0.642377
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.598388671875, (234.15083, 0.3283428, 481.1192, 0.0)
   validation loss 422.4232177734375, (168.6761, 0.36580107, 253.38132, 0.0)
decoder loss ratio: 6534.805014, decoder SINDy loss  ratio: 0.546959
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.9122924804688, (239.83223, 0.32113945, 475.75894, 0.0)
   validation loss 418.1098327636719, (166.79886, 0.35474196, 250.95624, 0.0)
decoder loss ratio: 6462.077359, decoder SINDy loss  ratio: 0.541724
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 838.9608154296875, (377.32123, 0.31079897, 461.32883, 0.0)
   validation loss 520.1721801757812, (273.13345, 0.36253858, 246.67616, 0.0)
decoder loss ratio: 10581.664164, decoder SINDy loss  ratio: 0.532485
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1046.792236328125, (489.3336, 0.36133742, 557.0973, 0.0)
   validation loss 744.2050170898438, (457.69925, 0.35133263, 286.15445, 0.0)
decoder loss ratio: 17732.063517, decoder SINDy loss  ratio: 0.617705
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.3030395507812, (225.65292, 0.33562222, 479.31448, 0.0)
   validation loss 415.3734130859375, (162.48888, 0.36456105, 252.51997, 0.0)
decoder loss ratio: 6295.101163, decoder SINDy loss  ratio: 0.545100
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 698.6766967773438, (218.09175, 0.32133442, 480.2636, 0.0)
   validation loss 407.099853515625, (153.59193, 0.3528201, 253.1551, 0.0)
decoder loss ratio: 5950.418178, decoder SINDy loss  ratio: 0.546471
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 707.6304321289062, (218.8398, 0.33352804, 488.4571, 0.0)
   validation loss 421.9695129394531, (164.94421, 0.3627314, 256.66257, 0.0)
decoder loss ratio: 6390.225201, decoder SINDy loss  ratio: 0.554042
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 797.52197265625, (276.50934, 0.34469184, 520.6679, 0.0)
   validation loss 494.3707275390625, (226.5, 0.3485718, 267.52216, 0.0)
decoder loss ratio: 8775.003221, decoder SINDy loss  ratio: 0.577484
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1120.2392578125, (665.4323, 0.29453954, 454.5124, 0.0)
   validation loss 746.9974975585938, (500.11337, 0.3655706, 246.51854, 0.0)
decoder loss ratio: 19375.260297, decoder SINDy loss  ratio: 0.532145
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 851.0118408203125, (324.78943, 0.34563115, 525.8768, 0.0)
   validation loss 561.6705322265625, (288.44647, 0.34780228, 272.87625, 0.0)
decoder loss ratio: 11174.917097, decoder SINDy loss  ratio: 0.589042
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 722.6725463867188, (254.59334, 0.31598184, 467.76324, 0.0)
   validation loss 425.47613525390625, (176.17998, 0.35797113, 248.93817, 0.0)
decoder loss ratio: 6825.518187, decoder SINDy loss  ratio: 0.537368
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 977.232421875, (526.07837, 0.29366007, 450.86038, 0.0)
   validation loss 640.2291259765625, (394.47217, 0.3537068, 245.40329, 0.0)
decoder loss ratio: 15282.536621, decoder SINDy loss  ratio: 0.529738
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.5830688476562, (269.8447, 0.31592658, 469.42245, 0.0)
   validation loss 442.20880126953125, (192.69347, 0.35804245, 249.15729, 0.0)
decoder loss ratio: 7465.279411, decoder SINDy loss  ratio: 0.537841
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 804.83935546875, (290.6056, 0.3379933, 513.8958, 0.0)
   validation loss 519.5540161132812, (251.15135, 0.34915298, 268.05353, 0.0)
decoder loss ratio: 9730.039392, decoder SINDy loss  ratio: 0.578631
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.2093505859375, (328.08835, 0.31772202, 459.8033, 0.0)
   validation loss 479.25689697265625, (232.31691, 0.36305395, 246.57693, 0.0)
decoder loss ratio: 9000.360405, decoder SINDy loss  ratio: 0.532271
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 900.2294311523438, (368.9337, 0.34489354, 530.95087, 0.0)
   validation loss 609.9524536132812, (333.5523, 0.34658197, 276.05356, 0.0)
decoder loss ratio: 12922.395450, decoder SINDy loss  ratio: 0.595900
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.9052124023438, (364.9544, 0.3097387, 456.64105, 0.0)
   validation loss 512.6347045898438, (266.1868, 0.36026424, 246.08763, 0.0)
decoder loss ratio: 10312.538679, decoder SINDy loss  ratio: 0.531215
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1172.774169921875, (607.1124, 0.35471082, 565.30695, 0.0)
   validation loss 862.1452026367188, (570.0571, 0.3461246, 291.74194, 0.0)
decoder loss ratio: 22085.002837, decoder SINDy loss  ratio: 0.629766
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.446533203125, (232.65746, 0.33766904, 497.45142, 0.0)
   validation loss 451.49420166015625, (189.76434, 0.36008477, 261.36975, 0.0)
decoder loss ratio: 7351.800103, decoder SINDy loss  ratio: 0.564203
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2146.447265625, (1473.7031, 0.39370432, 672.35034, 0.0)
   validation loss 1760.2532958984375, (1415.2283, 0.34693882, 344.67813, 0.0)
decoder loss ratio: 54828.400182, decoder SINDy loss  ratio: 0.744036
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 902.824951171875, (450.21136, 0.31316206, 452.30038, 0.0)
   validation loss 589.0047607421875, (343.84222, 0.3619127, 244.8006, 0.0)
decoder loss ratio: 13321.044699, decoder SINDy loss  ratio: 0.528437
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1913.002197265625, (1263.2999, 0.3857734, 649.3166, 0.0)
   validation loss 1549.6954345703125, (1216.4478, 0.34431568, 332.90332, 0.0)
decoder loss ratio: 47127.297833, decoder SINDy loss  ratio: 0.718619
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.8896484375, (217.34969, 0.32920107, 485.2108, 0.0)
   validation loss 425.5285949707031, (168.43245, 0.3566077, 256.73953, 0.0)
decoder loss ratio: 6525.365499, decoder SINDy loss  ratio: 0.554208
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 775.9358520507812, (271.57364, 0.3274095, 504.0348, 0.0)
   validation loss 499.78094482421875, (234.1241, 0.34542528, 265.31143, 0.0)
decoder loss ratio: 9070.374081, decoder SINDy loss  ratio: 0.572712
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1099.169189453125, (532.0756, 0.3647137, 566.7288, 0.0)
   validation loss 773.3203125, (483.20917, 0.35151565, 289.75964, 0.0)
decoder loss ratio: 18720.362036, decoder SINDy loss  ratio: 0.625487
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.9210205078125, (275.4752, 0.30549583, 461.14032, 0.0)
   validation loss 438.1648254394531, (190.5532, 0.34257707, 247.26904, 0.0)
decoder loss ratio: 7382.362069, decoder SINDy loss  ratio: 0.533765
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 739.07958984375, (256.48187, 0.33168426, 482.26602, 0.0)
   validation loss 455.91802978515625, (198.82372, 0.358089, 256.73624, 0.0)
decoder loss ratio: 7702.775900, decoder SINDy loss  ratio: 0.554201
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.1558837890625, (313.9357, 0.33602914, 515.88416, 0.0)
   validation loss 548.6055297851562, (277.9393, 0.3416109, 270.32462, 0.0)
decoder loss ratio: 10767.851027, decoder SINDy loss  ratio: 0.583534
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1047.062744140625, (601.31055, 0.29461396, 445.4576, 0.0)
   validation loss 695.5557861328125, (450.17767, 0.3563212, 245.02182, 0.0)
decoder loss ratio: 17440.664608, decoder SINDy loss  ratio: 0.528914
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 767.7506713867188, (262.7509, 0.32787657, 504.6719, 0.0)
   validation loss 484.12213134765625, (219.04297, 0.3422146, 264.73697, 0.0)
decoder loss ratio: 8486.104885, decoder SINDy loss  ratio: 0.571472
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 894.8230590820312, (447.3785, 0.29821226, 447.14633, 0.0)
   validation loss 578.07763671875, (332.97137, 0.35443118, 244.75186, 0.0)
decoder loss ratio: 12899.889112, decoder SINDy loss  ratio: 0.528331
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 819.8717041015625, (305.84174, 0.32838657, 513.7016, 0.0)
   validation loss 537.1400146484375, (267.58276, 0.33962768, 269.2176, 0.0)
decoder loss ratio: 10366.620809, decoder SINDy loss  ratio: 0.581144
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.4581909179688, (234.81706, 0.31940097, 474.32172, 0.0)
   validation loss 416.78558349609375, (164.75131, 0.35211858, 251.68217, 0.0)
decoder loss ratio: 6382.751858, decoder SINDy loss  ratio: 0.543291
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.838134765625, (308.1201, 0.32583964, 513.3922, 0.0)
   validation loss 539.1148681640625, (269.52844, 0.33936557, 269.24704, 0.0)
decoder loss ratio: 10441.999780, decoder SINDy loss  ratio: 0.581208
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 743.3373413085938, (287.19525, 0.30937475, 455.8327, 0.0)
   validation loss 447.881103515625, (201.28494, 0.34851012, 246.24763, 0.0)
decoder loss ratio: 7798.128123, decoder SINDy loss  ratio: 0.531560
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 887.8006591796875, (367.4497, 0.3326663, 520.01825, 0.0)
   validation loss 612.390380859375, (338.88077, 0.33962783, 273.16998, 0.0)
decoder loss ratio: 13128.829268, decoder SINDy loss  ratio: 0.589676
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.363525390625, (210.89946, 0.33008802, 475.13394, 0.0)
   validation loss 410.1441955566406, (156.60117, 0.34526685, 253.19777, 0.0)
decoder loss ratio: 6067.001034, decoder SINDy loss  ratio: 0.546563
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.0047607421875, (403.86176, 0.28593114, 445.8571, 0.0)
   validation loss 533.7584228515625, (289.78717, 0.33639753, 243.63487, 0.0)
decoder loss ratio: 11226.858074, decoder SINDy loss  ratio: 0.525920
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.1404418945312, (240.10822, 0.33384416, 487.6984, 0.0)
   validation loss 457.2532653808594, (196.69319, 0.35149196, 260.2086, 0.0)
decoder loss ratio: 7620.235714, decoder SINDy loss  ratio: 0.561697
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 907.6787109375, (381.6628, 0.32879576, 525.68713, 0.0)
   validation loss 622.7918701171875, (347.37292, 0.33519462, 275.0837, 0.0)
decoder loss ratio: 13457.830173, decoder SINDy loss  ratio: 0.593807
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 709.002685546875, (243.85042, 0.31476492, 464.83752, 0.0)
   validation loss 422.51153564453125, (173.20917, 0.34701005, 248.95537, 0.0)
decoder loss ratio: 6710.423853, decoder SINDy loss  ratio: 0.537405
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.0535888671875, (270.73883, 0.3262522, 502.98853, 0.0)
   validation loss 496.9999694824219, (231.2343, 0.33750582, 265.42816, 0.0)
decoder loss ratio: 8958.418172, decoder SINDy loss  ratio: 0.572964
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 766.170166015625, (315.1242, 0.30283976, 450.74316, 0.0)
   validation loss 466.04571533203125, (220.6622, 0.3459066, 245.03763, 0.0)
decoder loss ratio: 8548.836750, decoder SINDy loss  ratio: 0.528948
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 684.352783203125, (209.20485, 0.31377983, 474.83414, 0.0)
   validation loss 409.7448425292969, (155.63268, 0.33909366, 253.77307, 0.0)
decoder loss ratio: 6029.480026, decoder SINDy loss  ratio: 0.547805
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 812.2601928710938, (362.98334, 0.30149883, 448.97534, 0.0)
   validation loss 510.7073974609375, (265.56543, 0.34776694, 244.7942, 0.0)
decoder loss ratio: 10288.465788, decoder SINDy loss  ratio: 0.528423
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 784.3199462890625, (275.08005, 0.33726597, 508.90265, 0.0)
   validation loss 493.7431640625, (227.88388, 0.3381991, 265.5211, 0.0)
decoder loss ratio: 8828.617159, decoder SINDy loss  ratio: 0.573165
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 930.0048828125, (487.47708, 0.29827896, 442.22952, 0.0)
   validation loss 611.6581420898438, (368.03632, 0.34749517, 243.27432, 0.0)
decoder loss ratio: 14258.365818, decoder SINDy loss  ratio: 0.525142
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.6286010742188, (218.21332, 0.326638, 482.08865, 0.0)
   validation loss 423.7311706542969, (167.0319, 0.3403508, 256.35892, 0.0)
decoder loss ratio: 6471.106024, decoder SINDy loss  ratio: 0.553387
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 913.9918823242188, (468.62546, 0.29965803, 445.06677, 0.0)
   validation loss 569.9117431640625, (325.71085, 0.34773567, 243.85312, 0.0)
decoder loss ratio: 12618.603631, decoder SINDy loss  ratio: 0.526391
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.0362548828125, (208.8149, 0.33115783, 475.8902, 0.0)
   validation loss 413.542236328125, (159.09029, 0.3384662, 254.1135, 0.0)
decoder loss ratio: 6163.433882, decoder SINDy loss  ratio: 0.548540
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 891.94287109375, (449.452, 0.29386476, 442.19702, 0.0)
   validation loss 563.0501708984375, (319.45523, 0.3427875, 243.25214, 0.0)
decoder loss ratio: 12376.250236, decoder SINDy loss  ratio: 0.525094
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 734.7900390625, (246.69003, 0.308322, 487.79166, 0.0)
   validation loss 461.8603515625, (201.95335, 0.333168, 259.57382, 0.0)
decoder loss ratio: 7824.023536, decoder SINDy loss  ratio: 0.560327
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1801.39990234375, (1352.4907, 0.27741966, 448.63174, 0.0)
   validation loss 1331.828857421875, (1073.9998, 0.3533058, 257.47577, 0.0)
decoder loss ratio: 41608.615088, decoder SINDy loss  ratio: 0.555798
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.809814453125, (218.72833, 0.3188358, 480.76266, 0.0)
   validation loss 429.1932067871094, (172.28499, 0.33534682, 256.57288, 0.0)
decoder loss ratio: 6674.619551, decoder SINDy loss  ratio: 0.553849
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1896.867431640625, (1442.7875, 0.26891586, 453.8111, 0.0)
   validation loss 1393.017333984375, (1132.0337, 0.34772104, 260.63593, 0.0)
decoder loss ratio: 43856.950502, decoder SINDy loss  ratio: 0.562619
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.80078125, (222.6989, 0.31472558, 481.78714, 0.0)
   validation loss 435.45159912109375, (177.78212, 0.33410645, 257.33536, 0.0)
decoder loss ratio: 6887.587962, decoder SINDy loss  ratio: 0.555495
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.1444091796875, (224.86635, 0.31306946, 479.96503, 0.0)
   validation loss 426.8998107910156, (171.70872, 0.33957607, 254.85152, 0.0)
decoder loss ratio: 6652.294105, decoder SINDy loss  ratio: 0.550133
=========================
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
[[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 689.717041015625, (213.84254, 0.30740792, 475.56708, 0.0)
   validation loss 419.781494140625, (164.41142, 0.3326456, 255.03745, 0.0)
decoder loss ratio: 6369.583947, decoder SINDy loss  ratio: 0.550534
params['save_name']
pendulum_2023_11_11_05_23_19_072370
