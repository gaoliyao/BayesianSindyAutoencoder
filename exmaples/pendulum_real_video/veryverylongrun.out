nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2022-09-17 00:10:10.401256: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-09-17 00:10:10.427485: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2022-09-17 00:10:10.429634: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563946e60670 executing computations on platform Host. Devices:
2022-09-17 00:10:10.429689: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2022-09-17 00:10:10.433901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2022-09-17 00:10:10.594997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56394456a9c0 executing computations on platform CUDA. Devices:
2022-09-17 00:10:10.595055: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2022-09-17 00:10:10.596070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:67:00.0
2022-09-17 00:10:10.596562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2022-09-17 00:10:10.600547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2022-09-17 00:10:10.603859: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2022-09-17 00:10:10.604498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2022-09-17 00:10:10.608517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2022-09-17 00:10:10.610461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2022-09-17 00:10:10.615987: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2022-09-17 00:10:10.617036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2022-09-17 00:10:10.617096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2022-09-17 00:10:10.617702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-17 00:10:10.617718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2022-09-17 00:10:10.617729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2022-09-17 00:10:10.618743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9917 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)
2022-09-17 00:10:11.712556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/curriculum_pen_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 10001, 'refinement_epochs': 7501, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 1.0, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8547394275665283 seconds for one epoch ---
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 107553.7578125, (100206.055, 0.0051395874, 7330.508, 2.531779)
   validation loss 89745.1171875, (88527.164, 0.004065045, 1200.7559, 2.531779)
decoder loss ratio: 3429696.025697, decoder SINDy loss  ratio: 2.592000
--- 0.23846697807312012 seconds for one epoch ---
--- 0.28626585006713867 seconds for one epoch ---
--- 0.29387593269348145 seconds for one epoch ---
--- 0.28653383255004883 seconds for one epoch ---
--- 0.3186969757080078 seconds for one epoch ---
--- 0.2953603267669678 seconds for one epoch ---
--- 0.31252431869506836 seconds for one epoch ---
--- 0.29654693603515625 seconds for one epoch ---
--- 0.2990760803222656 seconds for one epoch ---
--- 0.29143643379211426 seconds for one epoch ---
--- 0.316725492477417 seconds for one epoch ---
--- 0.2954995632171631 seconds for one epoch ---
--- 0.30035901069641113 seconds for one epoch ---
--- 0.31300902366638184 seconds for one epoch ---
--- 0.30721354484558105 seconds for one epoch ---
--- 0.28935956954956055 seconds for one epoch ---
--- 0.2978940010070801 seconds for one epoch ---
--- 0.2898671627044678 seconds for one epoch ---
--- 0.30306553840637207 seconds for one epoch ---
--- 0.2874176502227783 seconds for one epoch ---
--- 0.30991363525390625 seconds for one epoch ---
--- 0.2961435317993164 seconds for one epoch ---
--- 0.32386183738708496 seconds for one epoch ---
--- 0.29535651206970215 seconds for one epoch ---
=========================
[[0.77708745]
 [0.7766257 ]
 [0.7811698 ]
 [0.77806836]
 [0.7751164 ]
 [0.7802716 ]
 [0.7775473 ]
 [0.77521265]
 [0.7748755 ]
 [0.7889967 ]
 [0.77515346]]
[[ 0.49890345]
 [ 0.41284046]
 [-1.0654825 ]
 [-0.66246796]
 [-0.07313737]
 [-0.96229273]
 [ 0.5785369 ]
 [-0.09825446]
 [ 0.00758289]
 [-1.7201128 ]
 [ 0.08284956]]
--- 0.2505531311035156 seconds for one epoch ---
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 63079.55078125, (57528.695, 15.521465, 5495.988, 2.531745)
   validation loss 59603.88671875, (58329.387, 5.111796, 1230.0391, 2.531745)
decoder loss ratio: 2259781.705753, decoder SINDy loss  ratio: 2.655212
--- 0.2980153560638428 seconds for one epoch ---
--- 0.30784177780151367 seconds for one epoch ---
--- 0.31395983695983887 seconds for one epoch ---
--- 0.32524657249450684 seconds for one epoch ---
--- 0.29413366317749023 seconds for one epoch ---
--- 0.3192903995513916 seconds for one epoch ---
--- 0.29410314559936523 seconds for one epoch ---
--- 0.305910587310791 seconds for one epoch ---
--- 0.2916085720062256 seconds for one epoch ---
--- 0.3226358890533447 seconds for one epoch ---
--- 0.29409265518188477 seconds for one epoch ---
--- 0.31437182426452637 seconds for one epoch ---
--- 0.2943711280822754 seconds for one epoch ---
--- 0.31112217903137207 seconds for one epoch ---
--- 0.29670166969299316 seconds for one epoch ---
--- 0.3137979507446289 seconds for one epoch ---
--- 0.29683423042297363 seconds for one epoch ---
--- 0.32526493072509766 seconds for one epoch ---
--- 0.30109620094299316 seconds for one epoch ---
--- 0.3401811122894287 seconds for one epoch ---
--- 0.29268550872802734 seconds for one epoch ---
--- 0.31495022773742676 seconds for one epoch ---
--- 0.2892913818359375 seconds for one epoch ---
--- 0.33022427558898926 seconds for one epoch ---
=========================
[[0.6265727 ]
 [0.6162635 ]
 [0.62238294]
 [0.61707443]
 [0.61512095]
 [0.6279891 ]
 [0.6182583 ]
 [0.615571  ]
 [0.61486906]
 [0.6217559 ]
 [0.6149087 ]]
[[ 1.125281  ]
 [ 0.21741056]
 [-0.8364907 ]
 [-0.32188958]
 [ 0.0508819 ]
 [-1.2090665 ]
 [ 0.45859364]
 [ 0.11957276]
 [ 0.01046733]
 [-0.7864547 ]
 [-0.01695593]]
--- 0.2941296100616455 seconds for one epoch ---
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 40337.90625, (35146.117, 9.377239, 5126.636, 2.531721)
   validation loss 44920.7265625, (43686.773, 6.253692, 1171.9255, 2.531721)
decoder loss ratio: 1692501.446543, decoder SINDy loss  ratio: 2.529766
--- 0.25428080558776855 seconds for one epoch ---
--- 0.2905287742614746 seconds for one epoch ---
--- 0.3234219551086426 seconds for one epoch ---
--- 0.3120124340057373 seconds for one epoch ---
--- 0.3210585117340088 seconds for one epoch ---
--- 0.3121070861816406 seconds for one epoch ---
--- 0.3081824779510498 seconds for one epoch ---
--- 0.28396105766296387 seconds for one epoch ---
--- 0.3077077865600586 seconds for one epoch ---
--- 0.2944059371948242 seconds for one epoch ---
--- 0.324878454208374 seconds for one epoch ---
--- 0.2915318012237549 seconds for one epoch ---
--- 0.3323187828063965 seconds for one epoch ---
--- 0.28506946563720703 seconds for one epoch ---
--- 0.33690714836120605 seconds for one epoch ---
--- 0.29482173919677734 seconds for one epoch ---
--- 0.3227722644805908 seconds for one epoch ---
--- 0.29347848892211914 seconds for one epoch ---
--- 0.32649683952331543 seconds for one epoch ---
--- 0.2964468002319336 seconds for one epoch ---
--- 0.33862996101379395 seconds for one epoch ---
--- 0.2890956401824951 seconds for one epoch ---
--- 0.34396958351135254 seconds for one epoch ---
--- 0.2913665771484375 seconds for one epoch ---
=========================
[[0.50123626]
 [0.4816137 ]
 [0.49221024]
 [0.4831106 ]
 [0.4815826 ]
 [0.51231295]
 [0.48424327]
 [0.4823507 ]
 [0.48077908]
 [0.48193496]
 [0.48129106]]
[[ 1.3190353 ]
 [ 0.10068263]
 [-0.90639925]
 [-0.25608265]
 [ 0.09719039]
 [-1.6893934 ]
 [ 0.36061454]
 [ 0.17997149]
 [-0.00329492]
 [-0.13596465]
 [-0.06403917]]
--- 0.2560107707977295 seconds for one epoch ---
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 30245.056640625, (23230.518, 12.202538, 6931.5195, 2.5317335)
   validation loss 17050.66015625, (15918.429, 0.48106903, 1060.934, 2.5317335)
decoder loss ratio: 616707.563869, decoder SINDy loss  ratio: 2.290175
--- 0.28711962699890137 seconds for one epoch ---
--- 0.32825350761413574 seconds for one epoch ---
--- 0.2930796146392822 seconds for one epoch ---
--- 0.33373570442199707 seconds for one epoch ---
--- 0.29347729682922363 seconds for one epoch ---
--- 0.33367180824279785 seconds for one epoch ---
--- 0.30408191680908203 seconds for one epoch ---
--- 0.33991551399230957 seconds for one epoch ---
--- 0.31445860862731934 seconds for one epoch ---
--- 0.3339345455169678 seconds for one epoch ---
--- 0.29132771492004395 seconds for one epoch ---
--- 0.3287851810455322 seconds for one epoch ---
--- 0.28907179832458496 seconds for one epoch ---
--- 0.32762980461120605 seconds for one epoch ---
--- 0.29080748558044434 seconds for one epoch ---
--- 0.3462717533111572 seconds for one epoch ---
--- 0.29501819610595703 seconds for one epoch ---
--- 0.3337860107421875 seconds for one epoch ---
--- 0.2957754135131836 seconds for one epoch ---
--- 0.338123083114624 seconds for one epoch ---
--- 0.29529356956481934 seconds for one epoch ---
--- 0.3402993679046631 seconds for one epoch ---
--- 0.3019375801086426 seconds for one epoch ---
--- 0.3603065013885498 seconds for one epoch ---
=========================
[[0.40717664]
 [0.38578737]
 [0.40474057]
 [0.388109  ]
 [0.38567764]
 [0.44302756]
 [0.3882606 ]
 [0.38738555]
 [0.38488546]
 [0.38614023]
 [0.38590038]]
[[ 1.2530158e+00]
 [ 9.0601243e-02]
 [-1.1658496e+00]
 [-2.9162613e-01]
 [ 8.0129363e-02]
 [-2.1236262e+00]
 [ 3.0353898e-01]
 [ 2.3284258e-01]
 [ 1.2564955e-03]
 [ 1.2364308e-01]
 [-1.0128109e-01]]
--- 0.28798699378967285 seconds for one epoch ---
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 26249.203125, (21947.586, 2.8659263, 4214.0923, 2.5317576)
   validation loss 14173.2138671875, (13182.198, 0.4071066, 905.947, 2.5317576)
decoder loss ratio: 510701.245205, decoder SINDy loss  ratio: 1.955614
--- 0.25844597816467285 seconds for one epoch ---
--- 0.29373741149902344 seconds for one epoch ---
--- 0.3459510803222656 seconds for one epoch ---
--- 0.29622650146484375 seconds for one epoch ---
--- 0.33820676803588867 seconds for one epoch ---
--- 0.28627920150756836 seconds for one epoch ---
--- 0.34505534172058105 seconds for one epoch ---
--- 0.2823970317840576 seconds for one epoch ---
--- 0.33623409271240234 seconds for one epoch ---
--- 0.29182910919189453 seconds for one epoch ---
--- 0.36086511611938477 seconds for one epoch ---
--- 0.3043668270111084 seconds for one epoch ---
--- 0.34949660301208496 seconds for one epoch ---
--- 0.365311861038208 seconds for one epoch ---
--- 0.3453376293182373 seconds for one epoch ---
--- 0.29450392723083496 seconds for one epoch ---
--- 0.3508279323577881 seconds for one epoch ---
--- 0.304304838180542 seconds for one epoch ---
--- 0.3483445644378662 seconds for one epoch ---
--- 0.28763580322265625 seconds for one epoch ---
--- 0.35602521896362305 seconds for one epoch ---
--- 0.29675817489624023 seconds for one epoch ---
--- 0.3575427532196045 seconds for one epoch ---
--- 0.2974119186401367 seconds for one epoch ---
=========================
[[0.3215672 ]
 [0.3051715 ]
 [0.33235228]
 [0.30663577]
 [0.30510336]
 [0.403619  ]
 [0.30695552]
 [0.30712318]
 [0.30410266]
 [0.30533063]
 [0.30408263]]
[[ 9.9024653e-01]
 [ 9.5741361e-02]
 [-1.3426118e+00]
 [-2.1178848e-01]
 [ 9.0018250e-02]
 [-2.5860538e+00]
 [ 2.3556963e-01]
 [ 2.4783872e-01]
 [ 2.4150568e-03]
 [ 1.0896355e-01]
 [-5.9620454e-04]]
--- 0.2570157051086426 seconds for one epoch ---
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18347.4296875, (10342.089, 1.1666104, 7905.6006, 2.5317764)
   validation loss 6547.84423828125, (5626.51, 0.18649799, 822.5744, 2.5317764)
decoder loss ratio: 217980.756371, decoder SINDy loss  ratio: 1.775643
--- 0.2931244373321533 seconds for one epoch ---
--- 0.3456079959869385 seconds for one epoch ---
--- 0.2836923599243164 seconds for one epoch ---
--- 0.34401845932006836 seconds for one epoch ---
--- 0.2927873134613037 seconds for one epoch ---
--- 0.34336280822753906 seconds for one epoch ---
--- 0.29359006881713867 seconds for one epoch ---
--- 0.3550097942352295 seconds for one epoch ---
--- 0.2928485870361328 seconds for one epoch ---
--- 0.36700892448425293 seconds for one epoch ---
--- 0.28264307975769043 seconds for one epoch ---
--- 0.3591792583465576 seconds for one epoch ---
--- 0.2989940643310547 seconds for one epoch ---
--- 0.34476518630981445 seconds for one epoch ---
--- 0.28519463539123535 seconds for one epoch ---
--- 0.34803318977355957 seconds for one epoch ---
--- 0.284592866897583 seconds for one epoch ---
--- 0.3559718132019043 seconds for one epoch ---
--- 0.2952873706817627 seconds for one epoch ---
--- 0.3562779426574707 seconds for one epoch ---
--- 0.30383801460266113 seconds for one epoch ---
--- 0.3631105422973633 seconds for one epoch ---
--- 0.28270697593688965 seconds for one epoch ---
--- 0.3649773597717285 seconds for one epoch ---
=========================
[[0.2585804 ]
 [0.24622764]
 [0.282051  ]
 [0.24855913]
 [0.24695052]
 [0.39030963]
 [0.24811068]
 [0.2491273 ]
 [0.24595392]
 [0.24613689]
 [0.24676508]]
[[ 7.4560863e-01]
 [ 2.4135876e-02]
 [-1.4785515e+00]
 [-2.0116396e-01]
 [ 8.2181796e-02]
 [-2.9503915e+00]
 [ 1.6925493e-01]
 [ 2.4026994e-01]
 [-1.3286571e-03]
 [ 1.6613163e-02]
 [ 6.7574896e-02]]
--- 0.29117751121520996 seconds for one epoch ---
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13566.7578125, (8542.358, 4.2594895, 4909.1123, 2.5317948)
   validation loss 6298.1181640625, (5491.3657, 0.08902457, 695.6368, 2.5317948)
decoder loss ratio: 212745.041526, decoder SINDy loss  ratio: 1.501630
--- 0.2510237693786621 seconds for one epoch ---
--- 0.30100226402282715 seconds for one epoch ---
--- 0.35895848274230957 seconds for one epoch ---
--- 0.3044919967651367 seconds for one epoch ---
--- 0.35602283477783203 seconds for one epoch ---
--- 0.2890620231628418 seconds for one epoch ---
--- 0.37157607078552246 seconds for one epoch ---
--- 0.2997732162475586 seconds for one epoch ---
--- 0.3530268669128418 seconds for one epoch ---
--- 0.27724528312683105 seconds for one epoch ---
--- 0.3686861991882324 seconds for one epoch ---
--- 0.2899208068847656 seconds for one epoch ---
--- 0.360889196395874 seconds for one epoch ---
--- 0.2902243137359619 seconds for one epoch ---
--- 0.3556814193725586 seconds for one epoch ---
--- 0.2917213439941406 seconds for one epoch ---
--- 0.36383724212646484 seconds for one epoch ---
--- 0.29050731658935547 seconds for one epoch ---
--- 0.3699309825897217 seconds for one epoch ---
--- 0.2936556339263916 seconds for one epoch ---
--- 0.3639392852783203 seconds for one epoch ---
--- 0.2902388572692871 seconds for one epoch ---
--- 0.3538520336151123 seconds for one epoch ---
--- 0.28969740867614746 seconds for one epoch ---
=========================
[[0.20464075]
 [0.19714369]
 [0.23867236]
 [0.19931322]
 [0.19755653]
 [0.3867045 ]
 [0.19845681]
 [0.20037562]
 [0.19668949]
 [0.1988556 ]
 [0.19850424]]
[[ 4.9878097e-01]
 [-3.8003519e-02]
 [-1.5546088e+00]
 [-1.9231288e-01]
 [ 6.9116063e-02]
 [-3.2405167e+00]
 [ 1.3397616e-01]
 [ 2.6058227e-01]
 [-2.7384514e-03]
 [-1.6153538e-01]
 [ 1.3730033e-01]]
--- 0.25594258308410645 seconds for one epoch ---
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9574.05078125, (5235.755, 0.5112156, 4216.2085, 2.5318134)
   validation loss 4008.178955078125, (3238.23, 0.0821839, 648.2915, 2.5318134)
decoder loss ratio: 125454.651258, decoder SINDy loss  ratio: 1.399428
--- 0.2904958724975586 seconds for one epoch ---
--- 0.36132311820983887 seconds for one epoch ---
--- 0.30164670944213867 seconds for one epoch ---
--- 0.3847799301147461 seconds for one epoch ---
--- 0.2917966842651367 seconds for one epoch ---
--- 0.38814449310302734 seconds for one epoch ---
--- 0.2866244316101074 seconds for one epoch ---
--- 0.36812257766723633 seconds for one epoch ---
--- 0.29193639755249023 seconds for one epoch ---
--- 0.37073397636413574 seconds for one epoch ---
--- 0.29351043701171875 seconds for one epoch ---
--- 0.3694159984588623 seconds for one epoch ---
--- 0.2898292541503906 seconds for one epoch ---
--- 0.3779938220977783 seconds for one epoch ---
--- 0.2895662784576416 seconds for one epoch ---
--- 0.3636808395385742 seconds for one epoch ---
--- 0.2869839668273926 seconds for one epoch ---
--- 0.3840641975402832 seconds for one epoch ---
--- 0.3044426441192627 seconds for one epoch ---
--- 0.38991737365722656 seconds for one epoch ---
--- 0.2858583927154541 seconds for one epoch ---
--- 0.3708329200744629 seconds for one epoch ---
--- 0.28655552864074707 seconds for one epoch ---
--- 0.37647318840026855 seconds for one epoch ---
=========================
[[0.16526836]
 [0.16251953]
 [0.20865138]
 [0.16366307]
 [0.16170217]
 [0.3935942 ]
 [0.1626219 ]
 [0.16513897]
 [0.16100496]
 [0.16624027]
 [0.16435358]]
[[ 2.84088045e-01]
 [-1.10531978e-01]
 [-1.62801921e+00]
 [-1.86105534e-01]
 [ 5.31000420e-02]
 [-3.47623610e+00]
 [ 1.17512785e-01]
 [ 2.76518583e-01]
 [ 1.57634891e-03]
 [-3.39442134e-01]
 [ 2.29337558e-01]]
--- 0.28647541999816895 seconds for one epoch ---
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7385.3515625, (3672.9084, 0.1141351, 3581.0198, 2.5318334)
   validation loss 4319.171875, (3620.9192, 0.07089224, 566.8725, 2.5318334)
decoder loss ratio: 140280.695592, decoder SINDy loss  ratio: 1.223674
--- 0.2520277500152588 seconds for one epoch ---
--- 0.2902705669403076 seconds for one epoch ---
--- 0.3744628429412842 seconds for one epoch ---
--- 0.30087900161743164 seconds for one epoch ---
--- 0.3941037654876709 seconds for one epoch ---
--- 0.29488444328308105 seconds for one epoch ---
--- 0.375413179397583 seconds for one epoch ---
--- 0.2852668762207031 seconds for one epoch ---
--- 0.3739745616912842 seconds for one epoch ---
--- 0.2905106544494629 seconds for one epoch ---
--- 0.38162922859191895 seconds for one epoch ---
--- 0.293292760848999 seconds for one epoch ---
--- 0.37805628776550293 seconds for one epoch ---
--- 0.285449743270874 seconds for one epoch ---
--- 0.369858980178833 seconds for one epoch ---
--- 0.29621005058288574 seconds for one epoch ---
--- 0.38849496841430664 seconds for one epoch ---
--- 0.32141900062561035 seconds for one epoch ---
--- 0.37792348861694336 seconds for one epoch ---
--- 0.2895081043243408 seconds for one epoch ---
--- 0.38463521003723145 seconds for one epoch ---
--- 0.29804420471191406 seconds for one epoch ---
--- 0.3860607147216797 seconds for one epoch ---
--- 0.3006162643432617 seconds for one epoch ---
=========================
[[0.13220213]
 [0.13364862]
 [0.18323295]
 [0.13364324]
 [0.13121751]
 [0.39431983]
 [0.1317774 ]
 [0.1343896 ]
 [0.13058318]
 [0.13935114]
 [0.13479875]]
[[ 1.1315568e-01]
 [-2.0451289e-01]
 [-1.6861939e+00]
 [-2.0418487e-01]
 [ 4.6266254e-02]
 [-3.6185603e+00]
 [ 8.4797032e-02]
 [ 2.4851111e-01]
 [-8.8027620e-04]
 [-5.0513721e-01]
 [ 2.7206683e-01]]
--- 0.2587614059448242 seconds for one epoch ---
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 9214.158203125, (4280.691, 2.1885536, 4792.679, 2.5318472)
   validation loss 3215.808349609375, (2575.7622, 0.06356578, 501.384, 2.5318472)
decoder loss ratio: 99789.499620, decoder SINDy loss  ratio: 1.082308
--- 0.2975606918334961 seconds for one epoch ---
--- 0.39966559410095215 seconds for one epoch ---
--- 0.29868006706237793 seconds for one epoch ---
--- 0.42517614364624023 seconds for one epoch ---
--- 0.28993844985961914 seconds for one epoch ---
--- 0.3962557315826416 seconds for one epoch ---
--- 0.2956428527832031 seconds for one epoch ---
--- 0.38364458084106445 seconds for one epoch ---
--- 0.29518842697143555 seconds for one epoch ---
--- 0.3908238410949707 seconds for one epoch ---
--- 0.28652334213256836 seconds for one epoch ---
--- 0.3915095329284668 seconds for one epoch ---
--- 0.2885122299194336 seconds for one epoch ---
--- 0.40908193588256836 seconds for one epoch ---
--- 0.3042328357696533 seconds for one epoch ---
--- 0.4034159183502197 seconds for one epoch ---
--- 0.3109252452850342 seconds for one epoch ---
--- 0.39275097846984863 seconds for one epoch ---
--- 0.3003408908843994 seconds for one epoch ---
--- 0.38687920570373535 seconds for one epoch ---
--- 0.2880840301513672 seconds for one epoch ---
--- 0.3969128131866455 seconds for one epoch ---
--- 0.30092835426330566 seconds for one epoch ---
--- 0.39153575897216797 seconds for one epoch ---
=========================
[[0.1084656 ]
 [0.1127703 ]
 [0.16524337]
 [0.11185644]
 [0.10874867]
 [0.38409644]
 [0.10955332]
 [0.11280601]
 [0.10845926]
 [0.12059376]
 [0.1136983 ]]
[[ 2.3744958e-03]
 [-2.7223256e-01]
 [-1.7330905e+00]
 [-2.2026724e-01]
 [ 2.2332011e-02]
 [-3.6495724e+00]
 [ 7.7147551e-02]
 [ 2.7422085e-01]
 [-1.9279850e-03]
 [-6.3918078e-01]
 [ 3.2261881e-01]]
--- 0.28679585456848145 seconds for one epoch ---
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 13568.42578125, (9731.642, 3.5135791, 3688.1726, 2.531855)
   validation loss 1952.9013671875, (1273.4022, 0.07177033, 534.3298, 2.531855)
decoder loss ratio: 49333.812791, decoder SINDy loss  ratio: 1.153426
--- 0.2546820640563965 seconds for one epoch ---
--- 0.312453031539917 seconds for one epoch ---
--- 0.3976407051086426 seconds for one epoch ---
--- 0.2945215702056885 seconds for one epoch ---
--- 0.3907639980316162 seconds for one epoch ---
--- 0.28809475898742676 seconds for one epoch ---
--- 0.38243722915649414 seconds for one epoch ---
--- 0.28877806663513184 seconds for one epoch ---
--- 0.3881855010986328 seconds for one epoch ---
--- 0.2905447483062744 seconds for one epoch ---
--- 0.3933589458465576 seconds for one epoch ---
--- 0.2914848327636719 seconds for one epoch ---
--- 0.3855574131011963 seconds for one epoch ---
--- 0.3805403709411621 seconds for one epoch ---
--- 0.41489219665527344 seconds for one epoch ---
--- 0.29503726959228516 seconds for one epoch ---
--- 0.4083597660064697 seconds for one epoch ---
--- 0.29048895835876465 seconds for one epoch ---
--- 0.414034366607666 seconds for one epoch ---
--- 0.2949235439300537 seconds for one epoch ---
--- 0.4109923839569092 seconds for one epoch ---
--- 0.29679417610168457 seconds for one epoch ---
--- 0.4002838134765625 seconds for one epoch ---
--- 0.28866124153137207 seconds for one epoch ---
=========================
[[0.09136206]
 [0.09425581]
 [0.14882185]
 [0.09353273]
 [0.08997434]
 [0.37536445]
 [0.09106153]
 [0.09398897]
 [0.08957196]
 [0.10621131]
 [0.09449568]]
[[-0.12590963]
 [-0.2924617 ]
 [-1.7546247 ]
 [-0.25315163]
 [ 0.03600818]
 [-3.6749706 ]
 [ 0.10706379]
 [ 0.27811924]
 [ 0.00846615]
 [-0.7978329 ]
 [ 0.30519542]]
--- 0.25495052337646484 seconds for one epoch ---
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8470.5751953125, (3526.3635, 5.5207458, 4788.857, 2.5318637)
   validation loss 2020.795166015625, (1358.5944, 0.06352895, 512.3038, 2.5318637)
decoder loss ratio: 52634.304144, decoder SINDy loss  ratio: 1.105880
--- 0.3115990161895752 seconds for one epoch ---
--- 0.39675354957580566 seconds for one epoch ---
--- 0.3091554641723633 seconds for one epoch ---
--- 0.40540099143981934 seconds for one epoch ---
--- 0.28749942779541016 seconds for one epoch ---
--- 0.4174182415008545 seconds for one epoch ---
--- 0.2988917827606201 seconds for one epoch ---
--- 0.4135749340057373 seconds for one epoch ---
--- 0.28586387634277344 seconds for one epoch ---
--- 0.40529727935791016 seconds for one epoch ---
--- 0.28464746475219727 seconds for one epoch ---
--- 0.4165945053100586 seconds for one epoch ---
--- 0.30649685859680176 seconds for one epoch ---
--- 0.4163472652435303 seconds for one epoch ---
--- 0.2837412357330322 seconds for one epoch ---
--- 0.43009185791015625 seconds for one epoch ---
--- 0.2901499271392822 seconds for one epoch ---
--- 0.40691041946411133 seconds for one epoch ---
--- 0.2943382263183594 seconds for one epoch ---
--- 0.4146890640258789 seconds for one epoch ---
--- 0.29308533668518066 seconds for one epoch ---
--- 0.40869879722595215 seconds for one epoch ---
--- 0.30017518997192383 seconds for one epoch ---
--- 0.4129819869995117 seconds for one epoch ---
=========================
[[0.08033931]
 [0.08125564]
 [0.1372819 ]
 [0.07928811]
 [0.07565966]
 [0.36796698]
 [0.07697079]
 [0.08028359]
 [0.07561527]
 [0.09936205]
 [0.08141635]]
[[-0.2874907 ]
 [-0.33487043]
 [-1.7770127 ]
 [-0.23049676]
 [ 0.0072    ]
 [-3.6871042 ]
 [ 0.09327053]
 [ 0.28454188]
 [ 0.0041615 ]
 [-1.0064943 ]
 [ 0.34297737]]
--- 0.2934412956237793 seconds for one epoch ---
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7761.23486328125, (3148.1763, 2.844362, 4455.2993, 2.5318735)
   validation loss 1814.470947265625, (1223.1708, 0.058160845, 436.3274, 2.5318735)
decoder loss ratio: 47387.759394, decoder SINDy loss  ratio: 0.941874
--- 0.25870370864868164 seconds for one epoch ---
--- 0.28827881813049316 seconds for one epoch ---
--- 0.40634918212890625 seconds for one epoch ---
--- 0.296741247177124 seconds for one epoch ---
--- 0.41697168350219727 seconds for one epoch ---
--- 0.2874007225036621 seconds for one epoch ---
--- 0.4136161804199219 seconds for one epoch ---
--- 0.30817508697509766 seconds for one epoch ---
--- 0.41959309577941895 seconds for one epoch ---
--- 0.3009822368621826 seconds for one epoch ---
--- 0.42957615852355957 seconds for one epoch ---
--- 0.29218053817749023 seconds for one epoch ---
--- 0.41668128967285156 seconds for one epoch ---
--- 0.2918968200683594 seconds for one epoch ---
--- 0.4163398742675781 seconds for one epoch ---
--- 0.29052305221557617 seconds for one epoch ---
--- 0.4174532890319824 seconds for one epoch ---
--- 0.2940397262573242 seconds for one epoch ---
--- 0.4245738983154297 seconds for one epoch ---
--- 0.30484461784362793 seconds for one epoch ---
--- 0.42063069343566895 seconds for one epoch ---
--- 0.2904181480407715 seconds for one epoch ---
--- 0.44098615646362305 seconds for one epoch ---
--- 0.2990450859069824 seconds for one epoch ---
=========================
[[0.07129224]
 [0.07042562]
 [0.12754984]
 [0.06725137]
 [0.06380994]
 [0.35999563]
 [0.06461468]
 [0.06854869]
 [0.06361413]
 [0.0952206 ]
 [0.07041351]]
[[-4.2791608e-01]
 [-3.8735697e-01]
 [-1.7987322e+00]
 [-2.2467223e-01]
 [ 1.5822070e-02]
 [-3.6883290e+00]
 [ 6.8379089e-02]
 [ 2.9407912e-01]
 [ 2.6365134e-03]
 [-1.1995076e+00]
 [ 3.8677618e-01]]
--- 0.2539787292480469 seconds for one epoch ---
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5466.546875, (2370.2437, 2.164403, 2934.5312, 2.531884)
   validation loss 1651.1212158203125, (1041.0912, 0.08282153, 450.33966, 2.531884)
decoder loss ratio: 40333.679980, decoder SINDy loss  ratio: 0.972122
--- 0.2952733039855957 seconds for one epoch ---
--- 0.42358899116516113 seconds for one epoch ---
--- 0.2942671775817871 seconds for one epoch ---
--- 0.42505764961242676 seconds for one epoch ---
--- 0.29187512397766113 seconds for one epoch ---
--- 0.42678380012512207 seconds for one epoch ---
--- 0.29316020011901855 seconds for one epoch ---
--- 0.4485793113708496 seconds for one epoch ---
--- 0.3010075092315674 seconds for one epoch ---
--- 0.42768311500549316 seconds for one epoch ---
--- 0.2899041175842285 seconds for one epoch ---
--- 0.42074131965637207 seconds for one epoch ---
--- 0.2991302013397217 seconds for one epoch ---
--- 0.4389655590057373 seconds for one epoch ---
--- 0.29749608039855957 seconds for one epoch ---
--- 0.43851208686828613 seconds for one epoch ---
--- 0.28292202949523926 seconds for one epoch ---
--- 0.4318232536315918 seconds for one epoch ---
--- 0.29668641090393066 seconds for one epoch ---
--- 0.4375286102294922 seconds for one epoch ---
--- 0.31232786178588867 seconds for one epoch ---
--- 0.45237183570861816 seconds for one epoch ---
--- 0.29515957832336426 seconds for one epoch ---
--- 0.4291348457336426 seconds for one epoch ---
=========================
[[0.06564136]
 [0.06198664]
 [0.1203738 ]
 [0.05808968]
 [0.05509225]
 [0.35222682]
 [0.05563841]
 [0.05942284]
 [0.0548165 ]
 [0.09531282]
 [0.06289001]]
[[-0.56061375]
 [-0.4020718 ]
 [-1.813967  ]
 [-0.20372875]
 [ 0.02225696]
 [-3.67865   ]
 [ 0.05766176]
 [ 0.27566656]
 [ 0.00392664]
 [-1.3867633 ]
 [ 0.4433968 ]]
--- 0.2915675640106201 seconds for one epoch ---
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2867.69287109375, (1507.0791, 0.11645195, 1196.0066, 2.5318923)
   validation loss 2455.206298828125, (1887.7794, 0.076165535, 402.86, 2.5318923)
decoder loss ratio: 73135.852019, decoder SINDy loss  ratio: 0.869630
--- 0.26234960556030273 seconds for one epoch ---
--- 0.29643726348876953 seconds for one epoch ---
--- 0.42124295234680176 seconds for one epoch ---
--- 0.2872171401977539 seconds for one epoch ---
--- 0.45442962646484375 seconds for one epoch ---
--- 0.2955322265625 seconds for one epoch ---
--- 0.43479013442993164 seconds for one epoch ---
--- 0.2936389446258545 seconds for one epoch ---
--- 0.4354441165924072 seconds for one epoch ---
--- 0.2796618938446045 seconds for one epoch ---
--- 0.453214168548584 seconds for one epoch ---
--- 0.29241371154785156 seconds for one epoch ---
--- 0.45288872718811035 seconds for one epoch ---
--- 0.29392385482788086 seconds for one epoch ---
--- 0.43233442306518555 seconds for one epoch ---
--- 0.2822854518890381 seconds for one epoch ---
--- 0.46332526206970215 seconds for one epoch ---
--- 0.28591275215148926 seconds for one epoch ---
--- 0.47406458854675293 seconds for one epoch ---
--- 0.2827951908111572 seconds for one epoch ---
--- 0.4378509521484375 seconds for one epoch ---
--- 0.2824974060058594 seconds for one epoch ---
--- 0.441756010055542 seconds for one epoch ---
--- 0.285219669342041 seconds for one epoch ---
=========================
[[0.05961459]
 [0.05549752]
 [0.11367539]
 [0.0505022 ]
 [0.04747492]
 [0.33168608]
 [0.04833231]
 [0.05198934]
 [0.04720308]
 [0.09454957]
 [0.05647965]]
[[-0.62032   ]
 [-0.45155996]
 [-1.8199325 ]
 [-0.20526412]
 [ 0.02370088]
 [-3.5932813 ]
 [ 0.07828008]
 [ 0.28448856]
 [ 0.00580518]
 [-1.5116473 ]
 [ 0.4941684 ]]
--- 0.2510092258453369 seconds for one epoch ---
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5617.001953125, (2136.01, 0.83049726, 3311.557, 2.531894)
   validation loss 4793.00732421875, (4132.5825, 0.080581434, 491.73978, 2.531894)
decoder loss ratio: 160103.421285, decoder SINDy loss  ratio: 1.061489
--- 0.2903621196746826 seconds for one epoch ---
--- 0.4688754081726074 seconds for one epoch ---
--- 0.2900078296661377 seconds for one epoch ---
--- 0.46564388275146484 seconds for one epoch ---
--- 0.2881143093109131 seconds for one epoch ---
--- 0.4448246955871582 seconds for one epoch ---
--- 0.29407167434692383 seconds for one epoch ---
--- 0.4524528980255127 seconds for one epoch ---
--- 0.29612159729003906 seconds for one epoch ---
--- 0.47670412063598633 seconds for one epoch ---
--- 0.29204249382019043 seconds for one epoch ---
--- 0.4531834125518799 seconds for one epoch ---
--- 0.2925844192504883 seconds for one epoch ---
--- 0.4578728675842285 seconds for one epoch ---
--- 0.31189608573913574 seconds for one epoch ---
--- 0.46390295028686523 seconds for one epoch ---
--- 0.29717421531677246 seconds for one epoch ---
--- 0.45087122917175293 seconds for one epoch ---
--- 0.3019533157348633 seconds for one epoch ---
--- 0.44884586334228516 seconds for one epoch ---
--- 0.29738402366638184 seconds for one epoch ---
--- 0.4540560245513916 seconds for one epoch ---
--- 0.2953989505767822 seconds for one epoch ---
--- 0.45543575286865234 seconds for one epoch ---
=========================
[[0.0558363 ]
 [0.05155046]
 [0.10718323]
 [0.04533507]
 [0.04150522]
 [0.31703252]
 [0.042679  ]
 [0.04613397]
 [0.04155849]
 [0.09598448]
 [0.05153917]]
[[-6.8659222e-01]
 [-5.2217799e-01]
 [-1.8021719e+00]
 [-2.3064125e-01]
 [ 2.9258064e-03]
 [-3.5328085e+00]
 [ 7.7924170e-02]
 [ 2.7270076e-01]
 [ 6.4420770e-03]
 [-1.6291016e+00]
 [ 5.2171183e-01]]
--- 0.2829620838165283 seconds for one epoch ---
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6621.0732421875, (2861.6975, 0.56758046, 3586.6238, 2.5318964)
   validation loss 1660.568359375, (1087.1184, 0.07493465, 401.19016, 2.5318964)
decoder loss ratio: 42116.854454, decoder SINDy loss  ratio: 0.866025
--- 0.252730131149292 seconds for one epoch ---
--- 0.29276037216186523 seconds for one epoch ---
--- 0.46254777908325195 seconds for one epoch ---
--- 0.29448747634887695 seconds for one epoch ---
--- 0.46488404273986816 seconds for one epoch ---
--- 0.28805017471313477 seconds for one epoch ---
--- 0.44649434089660645 seconds for one epoch ---
--- 0.29454851150512695 seconds for one epoch ---
--- 0.44779300689697266 seconds for one epoch ---
--- 0.28890013694763184 seconds for one epoch ---
--- 0.49393129348754883 seconds for one epoch ---
--- 0.2910420894622803 seconds for one epoch ---
--- 0.4823141098022461 seconds for one epoch ---
--- 0.2920875549316406 seconds for one epoch ---
--- 0.4496009349822998 seconds for one epoch ---
--- 0.2899448871612549 seconds for one epoch ---
--- 0.4547724723815918 seconds for one epoch ---
--- 0.2867136001586914 seconds for one epoch ---
--- 0.47765159606933594 seconds for one epoch ---
--- 0.2902815341949463 seconds for one epoch ---
--- 0.4524116516113281 seconds for one epoch ---
--- 0.2888071537017822 seconds for one epoch ---
--- 0.48229146003723145 seconds for one epoch ---
--- 0.3046913146972656 seconds for one epoch ---
=========================
[[0.05369577]
 [0.04652805]
 [0.10028778]
 [0.03979693]
 [0.03658386]
 [0.3069776 ]
 [0.03736011]
 [0.04105229]
 [0.03656956]
 [0.10037549]
 [0.0479829 ]]
[[-7.7916551e-01]
 [-5.1610607e-01]
 [-1.7684728e+00]
 [-1.9641861e-01]
 [-3.2682002e-03]
 [-3.4954281e+00]
 [ 5.3178262e-02]
 [ 2.6346976e-01]
 [ 2.3252342e-03]
 [-1.7697703e+00]
 [ 5.7463807e-01]]
--- 0.25479602813720703 seconds for one epoch ---
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3413.1025390625, (1744.6624, 1.6913093, 1492.1544, 2.5318997)
   validation loss 1637.79052734375, (1052.3479, 0.06977318, 410.77838, 2.5318997)
decoder loss ratio: 40769.784617, decoder SINDy loss  ratio: 0.886723
--- 0.28435206413269043 seconds for one epoch ---
--- 0.46258091926574707 seconds for one epoch ---
--- 0.2959105968475342 seconds for one epoch ---
--- 0.4705238342285156 seconds for one epoch ---
--- 0.2822887897491455 seconds for one epoch ---
--- 0.4627828598022461 seconds for one epoch ---
--- 0.3080573081970215 seconds for one epoch ---
--- 0.4625377655029297 seconds for one epoch ---
--- 0.29471898078918457 seconds for one epoch ---
--- 0.48337697982788086 seconds for one epoch ---
--- 0.2865169048309326 seconds for one epoch ---
--- 0.4684770107269287 seconds for one epoch ---
--- 0.27240991592407227 seconds for one epoch ---
--- 0.483919620513916 seconds for one epoch ---
--- 0.28474974632263184 seconds for one epoch ---
--- 0.46700239181518555 seconds for one epoch ---
--- 0.29123735427856445 seconds for one epoch ---
--- 0.5092570781707764 seconds for one epoch ---
--- 0.2957127094268799 seconds for one epoch ---
--- 0.46457481384277344 seconds for one epoch ---
--- 0.29178786277770996 seconds for one epoch ---
--- 0.46420860290527344 seconds for one epoch ---
--- 0.3850250244140625 seconds for one epoch ---
--- 0.47777509689331055 seconds for one epoch ---
=========================
[[0.05256859]
 [0.04296469]
 [0.09409752]
 [0.03573238]
 [0.03290233]
 [0.29447123]
 [0.03400866]
 [0.03714539]
 [0.03292204]
 [0.10614494]
 [0.04498125]]
[[-8.5725403e-01]
 [-5.1870006e-01]
 [-1.7270514e+00]
 [-1.7354435e-01]
 [ 2.1385644e-03]
 [-3.4384260e+00]
 [ 7.2404414e-02]
 [ 2.4998598e-01]
 [ 3.4305274e-03]
 [-1.8988280e+00]
 [ 5.9857494e-01]]
--- 0.2820892333984375 seconds for one epoch ---
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5138.296875, (2095.4534, 0.5128161, 2864.8242, 2.5319011)
   validation loss 1640.6202392578125, (1059.5443, 0.06657153, 403.50256, 2.5319011)
decoder loss ratio: 41048.586078, decoder SINDy loss  ratio: 0.871017
--- 0.2728900909423828 seconds for one epoch ---
--- 0.28963589668273926 seconds for one epoch ---
--- 0.4768989086151123 seconds for one epoch ---
--- 0.2926754951477051 seconds for one epoch ---
--- 0.4619419574737549 seconds for one epoch ---
--- 0.2971491813659668 seconds for one epoch ---
--- 0.48010945320129395 seconds for one epoch ---
--- 0.2979297637939453 seconds for one epoch ---
--- 0.482921838760376 seconds for one epoch ---
--- 0.2934849262237549 seconds for one epoch ---
--- 0.49056220054626465 seconds for one epoch ---
--- 0.2948155403137207 seconds for one epoch ---
--- 0.4885106086730957 seconds for one epoch ---
--- 0.29073023796081543 seconds for one epoch ---
--- 0.495652437210083 seconds for one epoch ---
--- 0.29013609886169434 seconds for one epoch ---
--- 0.4992225170135498 seconds for one epoch ---
--- 0.29505085945129395 seconds for one epoch ---
--- 0.5247266292572021 seconds for one epoch ---
--- 0.2865169048309326 seconds for one epoch ---
--- 0.4821507930755615 seconds for one epoch ---
--- 0.28306055068969727 seconds for one epoch ---
--- 0.49717068672180176 seconds for one epoch ---
--- 0.2822134494781494 seconds for one epoch ---
=========================
[[0.05142568]
 [0.04040451]
 [0.090536  ]
 [0.03185072]
 [0.02966899]
 [0.27916718]
 [0.03053037]
 [0.03438156]
 [0.02967401]
 [0.1120292 ]
 [0.04303968]]
[[-9.1664958e-01]
 [-5.4359370e-01]
 [-1.7186096e+00]
 [-1.3476591e-01]
 [ 5.3618301e-04]
 [-3.3621473e+00]
 [ 5.5537287e-02]
 [ 2.7220923e-01]
 [ 8.6877821e-04]
 [-2.0124106e+00]
 [ 6.4441890e-01]]
--- 0.23865604400634766 seconds for one epoch ---
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7315.4931640625, (1776.8304, 0.8508006, 5357.638, 2.5319035)
   validation loss 1752.889404296875, (1184.8779, 0.079877585, 387.75754, 2.5319035)
decoder loss ratio: 45904.228035, decoder SINDy loss  ratio: 0.837029
--- 0.28600621223449707 seconds for one epoch ---
--- 0.4782068729400635 seconds for one epoch ---
--- 0.29042816162109375 seconds for one epoch ---
--- 0.4952082633972168 seconds for one epoch ---
--- 0.2885308265686035 seconds for one epoch ---
--- 0.4886760711669922 seconds for one epoch ---
--- 0.29139041900634766 seconds for one epoch ---
--- 0.4862232208251953 seconds for one epoch ---
--- 0.2978475093841553 seconds for one epoch ---
--- 0.5069606304168701 seconds for one epoch ---
--- 0.3168466091156006 seconds for one epoch ---
--- 0.5124499797821045 seconds for one epoch ---
--- 0.2942934036254883 seconds for one epoch ---
--- 0.4926631450653076 seconds for one epoch ---
--- 0.2835545539855957 seconds for one epoch ---
--- 0.4939754009246826 seconds for one epoch ---
--- 0.29814624786376953 seconds for one epoch ---
--- 0.5157034397125244 seconds for one epoch ---
--- 0.29619908332824707 seconds for one epoch ---
--- 0.4885563850402832 seconds for one epoch ---
--- 0.2902803421020508 seconds for one epoch ---
--- 0.5004703998565674 seconds for one epoch ---
--- 0.30090880393981934 seconds for one epoch ---
--- 0.5011444091796875 seconds for one epoch ---
=========================
[[0.05230541]
 [0.03830222]
 [0.08662761]
 [0.02978685]
 [0.02738201]
 [0.2700448 ]
 [0.02824571]
 [0.03175212]
 [0.02737747]
 [0.1214216 ]
 [0.04135859]]
[[-1.006291  ]
 [-0.55432206]
 [-1.6931329 ]
 [-0.15363024]
 [ 0.0078244 ]
 [-3.3181434 ]
 [ 0.06247638]
 [ 0.25980687]
 [ 0.00753158]
 [-2.1484716 ]
 [ 0.66915804]]
--- 0.2869679927825928 seconds for one epoch ---
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4743.1162109375, (2018.1785, 1.3656582, 2540.7366, 2.5319095)
   validation loss 2413.387451171875, (1785.1768, 0.084538534, 445.29037, 2.5319095)
decoder loss ratio: 69160.846801, decoder SINDy loss  ratio: 0.961222
THRESHOLDING: 2 active coefficients
--- 0.4864773750305176 seconds for one epoch ---
--- 0.29847097396850586 seconds for one epoch ---
--- 0.4938845634460449 seconds for one epoch ---
--- 0.29465627670288086 seconds for one epoch ---
--- 0.4967029094696045 seconds for one epoch ---
--- 0.2968003749847412 seconds for one epoch ---
--- 0.5033340454101562 seconds for one epoch ---
--- 0.3019709587097168 seconds for one epoch ---
--- 0.5041131973266602 seconds for one epoch ---
--- 0.2869069576263428 seconds for one epoch ---
--- 0.5317649841308594 seconds for one epoch ---
--- 0.2932415008544922 seconds for one epoch ---
--- 0.5161449909210205 seconds for one epoch ---
--- 0.2919924259185791 seconds for one epoch ---
--- 0.5040254592895508 seconds for one epoch ---
--- 0.2901303768157959 seconds for one epoch ---
--- 0.5171024799346924 seconds for one epoch ---
--- 0.2979748249053955 seconds for one epoch ---
--- 0.5031228065490723 seconds for one epoch ---
--- 0.29250144958496094 seconds for one epoch ---
--- 0.5113184452056885 seconds for one epoch ---
--- 0.3132457733154297 seconds for one epoch ---
--- 0.5307018756866455 seconds for one epoch ---
--- 0.29311418533325195 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12377498]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08951866]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-2.1954217]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.766442 ]
 [ 0.       ]]
--- 0.2662208080291748 seconds for one epoch ---
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7956.92041015625, (2701.6953, 1.1852223, 5253.8525, 0.187126)
   validation loss 2627.378173828125, (2215.414, 0.07800177, 411.69913, 0.187126)
decoder loss ratio: 85828.986909, decoder SINDy loss  ratio: 0.888710
--- 0.2939872741699219 seconds for one epoch ---
--- 0.500455379486084 seconds for one epoch ---
--- 0.29711222648620605 seconds for one epoch ---
--- 0.5085186958312988 seconds for one epoch ---
--- 0.29112720489501953 seconds for one epoch ---
--- 0.5080804824829102 seconds for one epoch ---
--- 0.29518890380859375 seconds for one epoch ---
--- 0.5026967525482178 seconds for one epoch ---
--- 0.30792975425720215 seconds for one epoch ---
--- 0.5132081508636475 seconds for one epoch ---
--- 0.29166173934936523 seconds for one epoch ---
--- 0.5232491493225098 seconds for one epoch ---
--- 0.2996089458465576 seconds for one epoch ---
--- 0.5088198184967041 seconds for one epoch ---
--- 0.29171299934387207 seconds for one epoch ---
--- 0.5085108280181885 seconds for one epoch ---
--- 0.2929809093475342 seconds for one epoch ---
--- 0.5128066539764404 seconds for one epoch ---
--- 0.28067994117736816 seconds for one epoch ---
--- 0.5308747291564941 seconds for one epoch ---
--- 0.29689836502075195 seconds for one epoch ---
--- 0.5120177268981934 seconds for one epoch ---
--- 0.2932729721069336 seconds for one epoch ---
--- 0.5108580589294434 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08298584]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07946951]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.6905012]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.6349757]
 [ 0.       ]]
--- 0.297776460647583 seconds for one epoch ---
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4030.88720703125, (1682.167, 0.6950238, 2347.856, 0.16928561)
   validation loss 2219.811767578125, (1778.5957, 0.12867738, 440.91815, 0.16928561)
decoder loss ratio: 68905.885317, decoder SINDy loss  ratio: 0.951784
--- 0.2567927837371826 seconds for one epoch ---
--- 0.3100130558013916 seconds for one epoch ---
--- 0.531123161315918 seconds for one epoch ---
--- 0.28399085998535156 seconds for one epoch ---
--- 0.5321197509765625 seconds for one epoch ---
--- 0.295501708984375 seconds for one epoch ---
--- 0.5228345394134521 seconds for one epoch ---
--- 0.2881584167480469 seconds for one epoch ---
--- 0.5169410705566406 seconds for one epoch ---
--- 0.29187536239624023 seconds for one epoch ---
--- 0.5343937873840332 seconds for one epoch ---
--- 0.2895691394805908 seconds for one epoch ---
--- 0.5375351905822754 seconds for one epoch ---
--- 0.2914774417877197 seconds for one epoch ---
--- 0.5269055366516113 seconds for one epoch ---
--- 0.2835688591003418 seconds for one epoch ---
--- 0.5183804035186768 seconds for one epoch ---
--- 0.2901461124420166 seconds for one epoch ---
--- 0.5250837802886963 seconds for one epoch ---
--- 0.2894301414489746 seconds for one epoch ---
--- 0.5454511642456055 seconds for one epoch ---
--- 0.2888963222503662 seconds for one epoch ---
--- 0.5626516342163086 seconds for one epoch ---
--- 0.310122013092041 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.06460536]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07615134]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.3962909]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.602436 ]
 [ 0.       ]]
--- 0.25930213928222656 seconds for one epoch ---
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3303.04248046875, (1760.0862, 1.0941799, 1541.7012, 0.16076776)
   validation loss 1680.7501220703125, (1256.6893, 0.09719899, 423.80286, 0.16076776)
decoder loss ratio: 48686.326394, decoder SINDy loss  ratio: 0.914838
--- 0.29865193367004395 seconds for one epoch ---
--- 0.531484842300415 seconds for one epoch ---
--- 0.3030993938446045 seconds for one epoch ---
--- 0.5283203125 seconds for one epoch ---
--- 0.3126487731933594 seconds for one epoch ---
--- 0.531153678894043 seconds for one epoch ---
--- 0.29117822647094727 seconds for one epoch ---
--- 0.53733229637146 seconds for one epoch ---
--- 0.29812145233154297 seconds for one epoch ---
--- 0.5347216129302979 seconds for one epoch ---
--- 0.29637575149536133 seconds for one epoch ---
--- 0.5333652496337891 seconds for one epoch ---
--- 0.2920851707458496 seconds for one epoch ---
--- 0.5394387245178223 seconds for one epoch ---
--- 0.2938361167907715 seconds for one epoch ---
--- 0.5644345283508301 seconds for one epoch ---
--- 0.3020484447479248 seconds for one epoch ---
--- 0.532597541809082 seconds for one epoch ---
--- 0.2978394031524658 seconds for one epoch ---
--- 0.5555884838104248 seconds for one epoch ---
--- 0.29413294792175293 seconds for one epoch ---
--- 0.5722053050994873 seconds for one epoch ---
--- 0.3036487102508545 seconds for one epoch ---
--- 0.5409998893737793 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05754272]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.07584192]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2733843]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.613777 ]
 [ 0.       ]]
--- 0.28823399543762207 seconds for one epoch ---
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4403.50634765625, (1698.6027, 0.8656294, 2703.8792, 0.15852623)
   validation loss 1400.3800048828125, (978.3008, 0.108169675, 421.81244, 0.15852623)
decoder loss ratio: 37901.070670, decoder SINDy loss  ratio: 0.910541
--- 0.25511670112609863 seconds for one epoch ---
--- 0.2919490337371826 seconds for one epoch ---
--- 0.539309024810791 seconds for one epoch ---
--- 0.29549074172973633 seconds for one epoch ---
--- 0.5430395603179932 seconds for one epoch ---
--- 0.2919747829437256 seconds for one epoch ---
--- 0.566450834274292 seconds for one epoch ---
--- 0.2911183834075928 seconds for one epoch ---
--- 0.54811692237854 seconds for one epoch ---
--- 0.29286980628967285 seconds for one epoch ---
--- 0.5617654323577881 seconds for one epoch ---
--- 0.29785633087158203 seconds for one epoch ---
--- 0.5546362400054932 seconds for one epoch ---
--- 0.2960512638092041 seconds for one epoch ---
--- 0.5596601963043213 seconds for one epoch ---
--- 0.2931246757507324 seconds for one epoch ---
--- 0.5969898700714111 seconds for one epoch ---
--- 0.30461549758911133 seconds for one epoch ---
--- 0.5531542301177979 seconds for one epoch ---
--- 0.295534610748291 seconds for one epoch ---
--- 0.5640811920166016 seconds for one epoch ---
--- 0.2977566719055176 seconds for one epoch ---
--- 0.5774285793304443 seconds for one epoch ---
--- 0.2946662902832031 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05502468]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08057655]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2385032]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.7025537]
 [ 0.       ]]
--- 0.25916242599487305 seconds for one epoch ---
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4858.53173828125, (1941.4039, 1.3373865, 2915.6301, 0.15997784)
   validation loss 2504.3046875, (2032.1823, 0.06967312, 471.89276, 0.15997784)
decoder loss ratio: 78730.268426, decoder SINDy loss  ratio: 1.018647
--- 0.2916529178619385 seconds for one epoch ---
--- 0.5499215126037598 seconds for one epoch ---
--- 0.2947239875793457 seconds for one epoch ---
--- 0.5539331436157227 seconds for one epoch ---
--- 0.3062145709991455 seconds for one epoch ---
--- 0.5643460750579834 seconds for one epoch ---
--- 0.28993916511535645 seconds for one epoch ---
--- 0.5788059234619141 seconds for one epoch ---
--- 0.2941899299621582 seconds for one epoch ---
--- 0.5792663097381592 seconds for one epoch ---
--- 0.2907123565673828 seconds for one epoch ---
--- 0.5681853294372559 seconds for one epoch ---
--- 0.300168514251709 seconds for one epoch ---
--- 0.5841305255889893 seconds for one epoch ---
--- 0.30822014808654785 seconds for one epoch ---
--- 0.5604445934295654 seconds for one epoch ---
--- 0.2943751811981201 seconds for one epoch ---
--- 0.5850858688354492 seconds for one epoch ---
--- 0.272907018661499 seconds for one epoch ---
--- 0.5666418075561523 seconds for one epoch ---
--- 0.28691601753234863 seconds for one epoch ---
--- 0.5789227485656738 seconds for one epoch ---
--- 0.2891974449157715 seconds for one epoch ---
--- 0.5758092403411865 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05274984]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0839871 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.2032094]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.763428 ]
 [ 0.       ]]
--- 0.28301310539245605 seconds for one epoch ---
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3486.01904296875, (1277.7645, 0.57736826, 2207.5164, 0.16071153)
   validation loss 1426.7825927734375, (987.7727, 0.07704541, 438.77216, 0.16071153)
decoder loss ratio: 38268.029444, decoder SINDy loss  ratio: 0.947151
--- 0.25374507904052734 seconds for one epoch ---
--- 0.2952711582183838 seconds for one epoch ---
--- 0.5754773616790771 seconds for one epoch ---
--- 0.29147791862487793 seconds for one epoch ---
--- 0.559438943862915 seconds for one epoch ---
--- 0.2901332378387451 seconds for one epoch ---
--- 0.5672385692596436 seconds for one epoch ---
--- 0.28835344314575195 seconds for one epoch ---
--- 0.5688607692718506 seconds for one epoch ---
--- 0.28960418701171875 seconds for one epoch ---
--- 0.5746445655822754 seconds for one epoch ---
--- 0.3018481731414795 seconds for one epoch ---
--- 0.5746691226959229 seconds for one epoch ---
--- 0.28862762451171875 seconds for one epoch ---
--- 0.5875759124755859 seconds for one epoch ---
--- 0.29219555854797363 seconds for one epoch ---
--- 0.5566470623016357 seconds for one epoch ---
--- 0.28782200813293457 seconds for one epoch ---
--- 0.5802240371704102 seconds for one epoch ---
--- 0.28635668754577637 seconds for one epoch ---
--- 0.5679953098297119 seconds for one epoch ---
--- 0.28792381286621094 seconds for one epoch ---
--- 0.5535297393798828 seconds for one epoch ---
--- 0.2996847629547119 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05159742]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.08984335]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1910329]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.8543888]
 [ 0.       ]]
--- 0.25487542152404785 seconds for one epoch ---
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3380.50537109375, (1800.3162, 0.50345, 1579.5225, 0.1634345)
   validation loss 1542.7598876953125, (1096.6412, 0.08552634, 445.86963, 0.1634345)
decoder loss ratio: 42485.785310, decoder SINDy loss  ratio: 0.962472
--- 0.40517282485961914 seconds for one epoch ---
--- 0.5690171718597412 seconds for one epoch ---
--- 0.2913813591003418 seconds for one epoch ---
--- 0.5826435089111328 seconds for one epoch ---
--- 0.3028850555419922 seconds for one epoch ---
--- 0.5847141742706299 seconds for one epoch ---
--- 0.29096388816833496 seconds for one epoch ---
--- 0.5776762962341309 seconds for one epoch ---
--- 0.3138892650604248 seconds for one epoch ---
--- 0.5913381576538086 seconds for one epoch ---
--- 0.2967805862426758 seconds for one epoch ---
--- 0.5690417289733887 seconds for one epoch ---
--- 0.2938072681427002 seconds for one epoch ---
--- 0.5802383422851562 seconds for one epoch ---
--- 0.2897627353668213 seconds for one epoch ---
--- 0.5873978137969971 seconds for one epoch ---
--- 0.2924773693084717 seconds for one epoch ---
--- 0.5778286457061768 seconds for one epoch ---
--- 0.2920570373535156 seconds for one epoch ---
--- 0.5923316478729248 seconds for one epoch ---
--- 0.29053211212158203 seconds for one epoch ---
--- 0.5767099857330322 seconds for one epoch ---
--- 0.294358491897583 seconds for one epoch ---
--- 0.5934653282165527 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05126836]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.09827822]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1942122]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-1.9705921]
 [ 0.       ]]
--- 0.29148173332214355 seconds for one epoch ---
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4635.74365234375, (2386.7808, 2.9810488, 2245.8152, 0.16670977)
   validation loss 1261.2857666015625, (855.13586, 0.08447292, 405.89868, 0.16670977)
decoder loss ratio: 33129.447962, decoder SINDy loss  ratio: 0.876189
--- 0.2700047492980957 seconds for one epoch ---
--- 0.3063373565673828 seconds for one epoch ---
--- 0.574974536895752 seconds for one epoch ---
--- 0.2944626808166504 seconds for one epoch ---
--- 0.593256950378418 seconds for one epoch ---
--- 0.2876741886138916 seconds for one epoch ---
--- 0.612865686416626 seconds for one epoch ---
--- 0.29534029960632324 seconds for one epoch ---
--- 0.5905909538269043 seconds for one epoch ---
--- 0.2894892692565918 seconds for one epoch ---
--- 0.5882024765014648 seconds for one epoch ---
--- 0.2890443801879883 seconds for one epoch ---
--- 0.5993125438690186 seconds for one epoch ---
--- 0.3002660274505615 seconds for one epoch ---
--- 0.5790600776672363 seconds for one epoch ---
--- 0.2926361560821533 seconds for one epoch ---
--- 0.598768949508667 seconds for one epoch ---
--- 0.3004496097564697 seconds for one epoch ---
--- 0.6014208793640137 seconds for one epoch ---
--- 0.2941439151763916 seconds for one epoch ---
--- 0.6197819709777832 seconds for one epoch ---
--- 0.3058195114135742 seconds for one epoch ---
--- 0.5941817760467529 seconds for one epoch ---
--- 0.30068087577819824 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.05008662]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.11155673]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1768103]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.1328075]
 [ 0.       ]]
--- 0.2545797824859619 seconds for one epoch ---
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4111.74072265625, (1732.93, 0.7422952, 2377.8967, 0.17127459)
   validation loss 1326.486328125, (970.4749, 0.09447894, 355.7457, 0.17127459)
decoder loss ratio: 37597.883008, decoder SINDy loss  ratio: 0.767927
--- 0.290449857711792 seconds for one epoch ---
--- 0.5901281833648682 seconds for one epoch ---
--- 0.2971479892730713 seconds for one epoch ---
--- 0.6036293506622314 seconds for one epoch ---
--- 0.28890323638916016 seconds for one epoch ---
--- 0.597522497177124 seconds for one epoch ---
--- 0.2922780513763428 seconds for one epoch ---
--- 0.6078147888183594 seconds for one epoch ---
--- 0.29218316078186035 seconds for one epoch ---
--- 0.6120660305023193 seconds for one epoch ---
--- 0.3026449680328369 seconds for one epoch ---
--- 0.6168262958526611 seconds for one epoch ---
--- 0.2903571128845215 seconds for one epoch ---
--- 0.6093490123748779 seconds for one epoch ---
--- 0.2899298667907715 seconds for one epoch ---
--- 0.6016793251037598 seconds for one epoch ---
--- 0.30121922492980957 seconds for one epoch ---
--- 0.6023280620574951 seconds for one epoch ---
--- 0.29121828079223633 seconds for one epoch ---
--- 0.6172535419464111 seconds for one epoch ---
--- 0.29169344902038574 seconds for one epoch ---
--- 0.6251654624938965 seconds for one epoch ---
--- 0.30235862731933594 seconds for one epoch ---
--- 0.6354732513427734 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04938016]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.12028708]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1679293]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.2309139]
 [ 0.       ]]
--- 0.3198051452636719 seconds for one epoch ---
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4538.734375, (2338.316, 0.781456, 2199.4626, 0.1743731)
   validation loss 1300.8212890625, (917.6577, 0.09443607, 382.89484, 0.1743731)
decoder loss ratio: 35551.652997, decoder SINDy loss  ratio: 0.826532
--- 0.25844526290893555 seconds for one epoch ---
--- 0.2985069751739502 seconds for one epoch ---
--- 0.5926070213317871 seconds for one epoch ---
--- 0.291550874710083 seconds for one epoch ---
--- 0.6005721092224121 seconds for one epoch ---
--- 0.29199647903442383 seconds for one epoch ---
--- 0.6174452304840088 seconds for one epoch ---
--- 0.30031394958496094 seconds for one epoch ---
--- 0.6018202304840088 seconds for one epoch ---
--- 0.30506038665771484 seconds for one epoch ---
--- 0.6196770668029785 seconds for one epoch ---
--- 0.28803586959838867 seconds for one epoch ---
--- 0.6177616119384766 seconds for one epoch ---
--- 0.28475308418273926 seconds for one epoch ---
--- 0.6181013584136963 seconds for one epoch ---
--- 0.2912609577178955 seconds for one epoch ---
--- 0.6335470676422119 seconds for one epoch ---
--- 0.29281115531921387 seconds for one epoch ---
--- 0.6186883449554443 seconds for one epoch ---
--- 0.3234124183654785 seconds for one epoch ---
--- 0.6182272434234619 seconds for one epoch ---
--- 0.2949347496032715 seconds for one epoch ---
--- 0.6119179725646973 seconds for one epoch ---
--- 0.30178260803222656 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04944197]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.1315407 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1760563]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.347601 ]
 [ 0.       ]]
--- 0.25153136253356934 seconds for one epoch ---
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4440.81982421875, (1578.282, 1.1933401, 2861.166, 0.17832865)
   validation loss 1795.8114013671875, (1429.717, 0.09943903, 365.8166, 0.17832865)
decoder loss ratio: 55389.720267, decoder SINDy loss  ratio: 0.789667
--- 0.2937734127044678 seconds for one epoch ---
--- 0.6266641616821289 seconds for one epoch ---
--- 0.29341554641723633 seconds for one epoch ---
--- 0.6079413890838623 seconds for one epoch ---
--- 0.2943849563598633 seconds for one epoch ---
--- 0.6251969337463379 seconds for one epoch ---
--- 0.29346323013305664 seconds for one epoch ---
--- 0.6561498641967773 seconds for one epoch ---
--- 0.2897529602050781 seconds for one epoch ---
--- 0.6330201625823975 seconds for one epoch ---
--- 0.2856903076171875 seconds for one epoch ---
--- 0.6438908576965332 seconds for one epoch ---
--- 0.29916906356811523 seconds for one epoch ---
--- 0.6358280181884766 seconds for one epoch ---
--- 0.27370381355285645 seconds for one epoch ---
--- 0.6260035037994385 seconds for one epoch ---
--- 0.30510616302490234 seconds for one epoch ---
--- 0.6401739120483398 seconds for one epoch ---
--- 0.28612852096557617 seconds for one epoch ---
--- 0.6429958343505859 seconds for one epoch ---
--- 0.2986032962799072 seconds for one epoch ---
--- 0.6506016254425049 seconds for one epoch ---
--- 0.2849905490875244 seconds for one epoch ---
--- 0.6585710048675537 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04768774]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.14536953]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1402919]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.4790745]
 [ 0.       ]]
--- 0.28547096252441406 seconds for one epoch ---
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2842.9501953125, (1315.265, 0.43376318, 1527.0692, 0.18210904)
   validation loss 2301.72021484375, (1816.6664, 0.09348531, 484.77826, 0.18210904)
decoder loss ratio: 70380.809504, decoder SINDy loss  ratio: 1.046462
--- 0.2571837902069092 seconds for one epoch ---
--- 0.28881216049194336 seconds for one epoch ---
--- 0.6337311267852783 seconds for one epoch ---
--- 0.29813051223754883 seconds for one epoch ---
--- 0.6561629772186279 seconds for one epoch ---
--- 0.3151729106903076 seconds for one epoch ---
--- 0.6280152797698975 seconds for one epoch ---
--- 0.2908895015716553 seconds for one epoch ---
--- 0.626929759979248 seconds for one epoch ---
--- 0.2876551151275635 seconds for one epoch ---
--- 0.6364760398864746 seconds for one epoch ---
--- 0.29588818550109863 seconds for one epoch ---
--- 0.6393866539001465 seconds for one epoch ---
--- 0.2940957546234131 seconds for one epoch ---
--- 0.6590158939361572 seconds for one epoch ---
--- 0.2981224060058594 seconds for one epoch ---
--- 0.6293394565582275 seconds for one epoch ---
--- 0.29691457748413086 seconds for one epoch ---
--- 0.6162567138671875 seconds for one epoch ---
--- 0.2774696350097656 seconds for one epoch ---
--- 0.6509125232696533 seconds for one epoch ---
--- 0.2891249656677246 seconds for one epoch ---
--- 0.6622977256774902 seconds for one epoch ---
--- 0.28925132751464844 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04756202]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.16218056]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1420943]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.6256008]
 [ 0.       ]]
--- 0.25008153915405273 seconds for one epoch ---
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5596.0703125, (1973.1276, 1.6521009, 3621.1038, 0.18716742)
   validation loss 1446.2869873046875, (1035.5973, 0.103772044, 410.39877, 0.18716742)
decoder loss ratio: 40120.836892, decoder SINDy loss  ratio: 0.885903
--- 0.29941320419311523 seconds for one epoch ---
--- 0.6367006301879883 seconds for one epoch ---
--- 0.3185081481933594 seconds for one epoch ---
--- 0.6359434127807617 seconds for one epoch ---
--- 0.2974076271057129 seconds for one epoch ---
--- 0.6252784729003906 seconds for one epoch ---
--- 0.2982618808746338 seconds for one epoch ---
--- 0.6526660919189453 seconds for one epoch ---
--- 0.299574613571167 seconds for one epoch ---
--- 0.6475017070770264 seconds for one epoch ---
--- 0.2933974266052246 seconds for one epoch ---
--- 0.668154239654541 seconds for one epoch ---
--- 0.3155972957611084 seconds for one epoch ---
--- 0.6414816379547119 seconds for one epoch ---
--- 0.29154300689697266 seconds for one epoch ---
--- 0.6575233936309814 seconds for one epoch ---
--- 0.3016321659088135 seconds for one epoch ---
--- 0.654407262802124 seconds for one epoch ---
--- 0.3073692321777344 seconds for one epoch ---
--- 0.642216682434082 seconds for one epoch ---
--- 0.28756046295166016 seconds for one epoch ---
--- 0.6757280826568604 seconds for one epoch ---
--- 0.31270337104797363 seconds for one epoch ---
--- 0.6656520366668701 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.0463242 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.17504223]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1162233]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.7300205]
 [ 0.       ]]
--- 0.31225061416625977 seconds for one epoch ---
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2884.33154296875, (961.19965, 0.24384254, 1922.6975, 0.19041935)
   validation loss 1218.14208984375, (861.18005, 0.087985486, 356.6836, 0.19041935)
decoder loss ratio: 33363.610355, decoder SINDy loss  ratio: 0.769952
--- 0.2537853717803955 seconds for one epoch ---
--- 0.2924385070800781 seconds for one epoch ---
--- 0.6487627029418945 seconds for one epoch ---
--- 0.2939901351928711 seconds for one epoch ---
--- 0.6546571254730225 seconds for one epoch ---
--- 0.28964877128601074 seconds for one epoch ---
--- 0.691749095916748 seconds for one epoch ---
--- 0.29335594177246094 seconds for one epoch ---
--- 0.6739182472229004 seconds for one epoch ---
--- 0.286487340927124 seconds for one epoch ---
--- 0.6834089756011963 seconds for one epoch ---
--- 0.2983672618865967 seconds for one epoch ---
--- 0.646193265914917 seconds for one epoch ---
--- 0.29649901390075684 seconds for one epoch ---
--- 0.6593520641326904 seconds for one epoch ---
--- 0.28222036361694336 seconds for one epoch ---
--- 0.652928352355957 seconds for one epoch ---
--- 0.29047393798828125 seconds for one epoch ---
--- 0.6691629886627197 seconds for one epoch ---
--- 0.29156017303466797 seconds for one epoch ---
--- 0.6537570953369141 seconds for one epoch ---
--- 0.2895495891571045 seconds for one epoch ---
--- 0.673560380935669 seconds for one epoch ---
--- 0.30542850494384766 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04622023]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.19050929]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1171335]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.8480098]
 [ 0.       ]]
--- 0.2696526050567627 seconds for one epoch ---
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2947.19580078125, (1715.3643, 5.7081833, 1225.9285, 0.19492045)
   validation loss 1361.4697265625, (1013.1962, 0.11336267, 347.9652, 0.19492045)
decoder loss ratio: 39252.980860, decoder SINDy loss  ratio: 0.751132
--- 0.29511117935180664 seconds for one epoch ---
--- 0.6591546535491943 seconds for one epoch ---
--- 0.2930898666381836 seconds for one epoch ---
--- 0.6625792980194092 seconds for one epoch ---
--- 0.29325127601623535 seconds for one epoch ---
--- 0.6696879863739014 seconds for one epoch ---
--- 0.29176950454711914 seconds for one epoch ---
--- 0.6599128246307373 seconds for one epoch ---
--- 0.28581738471984863 seconds for one epoch ---
--- 0.6493003368377686 seconds for one epoch ---
--- 0.29526495933532715 seconds for one epoch ---
--- 0.6531689167022705 seconds for one epoch ---
--- 0.2862234115600586 seconds for one epoch ---
--- 0.6568684577941895 seconds for one epoch ---
--- 0.3191816806793213 seconds for one epoch ---
--- 0.6837384700775146 seconds for one epoch ---
--- 0.28754353523254395 seconds for one epoch ---
--- 0.6496570110321045 seconds for one epoch ---
--- 0.29663515090942383 seconds for one epoch ---
--- 0.6845238208770752 seconds for one epoch ---
--- 0.29796767234802246 seconds for one epoch ---
--- 0.6852684020996094 seconds for one epoch ---
--- 0.28971195220947266 seconds for one epoch ---
--- 0.6625471115112305 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04643647]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.20530859]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1249782]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-2.9545004]
 [ 0.       ]]
--- 0.29398393630981445 seconds for one epoch ---
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3780.082763671875, (1288.0353, 0.6588207, 2491.1897, 0.19896741)
   validation loss 1300.93896484375, (945.95624, 0.10540007, 354.6784, 0.19896741)
decoder loss ratio: 36647.986904, decoder SINDy loss  ratio: 0.765623
--- 0.25775599479675293 seconds for one epoch ---
--- 0.30373096466064453 seconds for one epoch ---
--- 0.6749272346496582 seconds for one epoch ---
--- 0.3002138137817383 seconds for one epoch ---
--- 0.6763947010040283 seconds for one epoch ---
--- 0.28609395027160645 seconds for one epoch ---
--- 0.6844041347503662 seconds for one epoch ---
--- 0.29154324531555176 seconds for one epoch ---
--- 0.6780433654785156 seconds for one epoch ---
--- 0.2962069511413574 seconds for one epoch ---
--- 0.6569883823394775 seconds for one epoch ---
--- 0.2917330265045166 seconds for one epoch ---
--- 0.6696717739105225 seconds for one epoch ---
--- 0.30411434173583984 seconds for one epoch ---
--- 0.6929943561553955 seconds for one epoch ---
--- 0.29293346405029297 seconds for one epoch ---
--- 0.674490213394165 seconds for one epoch ---
--- 0.2907829284667969 seconds for one epoch ---
--- 0.7016899585723877 seconds for one epoch ---
--- 0.2926218509674072 seconds for one epoch ---
--- 0.6917116641998291 seconds for one epoch ---
--- 0.29743146896362305 seconds for one epoch ---
--- 0.7164998054504395 seconds for one epoch ---
--- 0.2964484691619873 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04614627]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.22426994]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1204094]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.0832908]
 [ 0.       ]]
--- 0.28281617164611816 seconds for one epoch ---
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4452.05126953125, (1873.9534, 0.25636753, 2577.6382, 0.20355824)
   validation loss 1476.99658203125, (1095.799, 0.08186291, 380.91205, 0.20355824)
decoder loss ratio: 42453.153721, decoder SINDy loss  ratio: 0.822252
--- 0.2795684337615967 seconds for one epoch ---
--- 0.6737565994262695 seconds for one epoch ---
--- 0.28754138946533203 seconds for one epoch ---
--- 0.6935114860534668 seconds for one epoch ---
--- 0.28961849212646484 seconds for one epoch ---
--- 0.6953892707824707 seconds for one epoch ---
--- 0.29941320419311523 seconds for one epoch ---
--- 0.6987533569335938 seconds for one epoch ---
--- 0.2777276039123535 seconds for one epoch ---
--- 0.7075438499450684 seconds for one epoch ---
--- 0.29888129234313965 seconds for one epoch ---
--- 0.6978251934051514 seconds for one epoch ---
--- 0.29021334648132324 seconds for one epoch ---
--- 0.6826643943786621 seconds for one epoch ---
--- 0.29532861709594727 seconds for one epoch ---
--- 0.6801931858062744 seconds for one epoch ---
--- 0.28925442695617676 seconds for one epoch ---
--- 0.6979799270629883 seconds for one epoch ---
--- 0.3321709632873535 seconds for one epoch ---
--- 0.7135038375854492 seconds for one epoch ---
--- 0.29317808151245117 seconds for one epoch ---
--- 0.6906118392944336 seconds for one epoch ---
--- 0.2959630489349365 seconds for one epoch ---
--- 0.715364933013916 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04595328]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.24475577]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.1176353]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.2145495]
 [ 0.       ]]
--- 0.2864365577697754 seconds for one epoch ---
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3131.591552734375, (1597.7449, 0.4878182, 1533.15, 0.2086345)
   validation loss 1825.374755859375, (1501.3998, 0.14274241, 323.6237, 0.2086345)
decoder loss ratio: 58166.834032, decoder SINDy loss  ratio: 0.698587
--- 0.25510573387145996 seconds for one epoch ---
--- 0.29845237731933594 seconds for one epoch ---
--- 0.720390796661377 seconds for one epoch ---
--- 0.30770087242126465 seconds for one epoch ---
--- 0.7052452564239502 seconds for one epoch ---
--- 0.294830322265625 seconds for one epoch ---
--- 0.6884846687316895 seconds for one epoch ---
--- 0.293165922164917 seconds for one epoch ---
--- 0.7046194076538086 seconds for one epoch ---
--- 0.2989957332611084 seconds for one epoch ---
--- 0.69661545753479 seconds for one epoch ---
--- 0.4373033046722412 seconds for one epoch ---
--- 0.7116672992706299 seconds for one epoch ---
--- 0.29418325424194336 seconds for one epoch ---
--- 0.6937506198883057 seconds for one epoch ---
--- 0.2872474193572998 seconds for one epoch ---
--- 0.7144925594329834 seconds for one epoch ---
--- 0.3081684112548828 seconds for one epoch ---
--- 0.7018129825592041 seconds for one epoch ---
--- 0.29065561294555664 seconds for one epoch ---
--- 0.7087724208831787 seconds for one epoch ---
--- 0.31499743461608887 seconds for one epoch ---
--- 0.7156510353088379 seconds for one epoch ---
--- 0.2939121723175049 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04506252]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.2616396 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0977007]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.3177702]
 [ 0.       ]]
--- 0.25359630584716797 seconds for one epoch ---
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5732.23388671875, (2314.2292, 0.51060456, 3417.2822, 0.21198003)
   validation loss 1389.330322265625, (1001.09766, 0.061621897, 387.95898, 0.21198003)
decoder loss ratio: 38784.261185, decoder SINDy loss  ratio: 0.837464
--- 0.2907567024230957 seconds for one epoch ---
--- 0.6992552280426025 seconds for one epoch ---
--- 0.29268431663513184 seconds for one epoch ---
--- 0.7134222984313965 seconds for one epoch ---
--- 0.2899954319000244 seconds for one epoch ---
--- 0.7042465209960938 seconds for one epoch ---
--- 0.29250144958496094 seconds for one epoch ---
--- 0.7217230796813965 seconds for one epoch ---
--- 0.28958630561828613 seconds for one epoch ---
--- 0.7218766212463379 seconds for one epoch ---
--- 0.298297643661499 seconds for one epoch ---
--- 0.7106795310974121 seconds for one epoch ---
--- 0.3016183376312256 seconds for one epoch ---
--- 0.7105300426483154 seconds for one epoch ---
--- 0.2933626174926758 seconds for one epoch ---
--- 0.743422269821167 seconds for one epoch ---
--- 0.3008415699005127 seconds for one epoch ---
--- 0.6918039321899414 seconds for one epoch ---
--- 0.2974715232849121 seconds for one epoch ---
--- 0.7124574184417725 seconds for one epoch ---
--- 0.2923612594604492 seconds for one epoch ---
--- 0.7125339508056641 seconds for one epoch ---
--- 0.29013991355895996 seconds for one epoch ---
--- 0.7244932651519775 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.04477027]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.28396273]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-1.0918866]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.4483492]
 [ 0.       ]]
--- 0.2847878932952881 seconds for one epoch ---
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3964.1943359375, (1213.4576, 0.9952809, 2749.5261, 0.21534984)
   validation loss 930.3529052734375, (587.8359, 0.13305898, 342.16864, 0.21534984)
decoder loss ratio: 22773.782382, decoder SINDy loss  ratio: 0.738619
THRESHOLDING: 1 active coefficients
--- 0.7088496685028076 seconds for one epoch ---
--- 0.2955286502838135 seconds for one epoch ---
--- 0.7288429737091064 seconds for one epoch ---
--- 0.29111695289611816 seconds for one epoch ---
--- 0.7124254703521729 seconds for one epoch ---
--- 0.29653286933898926 seconds for one epoch ---
--- 0.6991589069366455 seconds for one epoch ---
--- 0.29790568351745605 seconds for one epoch ---
--- 0.7265284061431885 seconds for one epoch ---
--- 0.2868309020996094 seconds for one epoch ---
--- 0.7121155261993408 seconds for one epoch ---
--- 0.2939634323120117 seconds for one epoch ---
--- 0.7121806144714355 seconds for one epoch ---
--- 0.3041512966156006 seconds for one epoch ---
--- 0.7110881805419922 seconds for one epoch ---
--- 0.2941396236419678 seconds for one epoch ---
--- 0.7254312038421631 seconds for one epoch ---
--- 0.29604363441467285 seconds for one epoch ---
--- 0.718280553817749 seconds for one epoch ---
--- 0.2932088375091553 seconds for one epoch ---
--- 0.7547903060913086 seconds for one epoch ---
--- 0.30760908126831055 seconds for one epoch ---
--- 0.7364540100097656 seconds for one epoch ---
--- 0.29798340797424316 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.35093012]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-3.8113995]
 [ 0.       ]]
--- 0.2537693977355957 seconds for one epoch ---
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5220.08203125, (1516.5587, 2.3560414, 3701.0276, 0.1398419)
   validation loss 1206.37109375, (862.0513, 0.21289699, 343.9671, 0.1398419)
decoder loss ratio: 33397.362768, decoder SINDy loss  ratio: 0.742501
--- 0.2870981693267822 seconds for one epoch ---
--- 0.7441718578338623 seconds for one epoch ---
--- 0.2956502437591553 seconds for one epoch ---
--- 0.7347917556762695 seconds for one epoch ---
--- 0.3045976161956787 seconds for one epoch ---
--- 0.7370731830596924 seconds for one epoch ---
--- 0.2955741882324219 seconds for one epoch ---
--- 0.738760232925415 seconds for one epoch ---
--- 0.29248881340026855 seconds for one epoch ---
--- 0.7228579521179199 seconds for one epoch ---
--- 0.29769039154052734 seconds for one epoch ---
--- 0.7441205978393555 seconds for one epoch ---
--- 0.30161476135253906 seconds for one epoch ---
--- 0.7317650318145752 seconds for one epoch ---
--- 0.292360782623291 seconds for one epoch ---
--- 0.735011100769043 seconds for one epoch ---
--- 0.30443620681762695 seconds for one epoch ---
--- 0.7293281555175781 seconds for one epoch ---
--- 0.2944309711456299 seconds for one epoch ---
--- 0.7438287734985352 seconds for one epoch ---
--- 0.2874588966369629 seconds for one epoch ---
--- 0.7380771636962891 seconds for one epoch ---
--- 0.28626465797424316 seconds for one epoch ---
--- 0.7375771999359131 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.42480007]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.182909]
 [ 0.      ]]
--- 0.2856318950653076 seconds for one epoch ---
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3494.99609375, (1519.5923, 0.8595794, 1974.387, 0.15727128)
   validation loss 2855.755859375, (2385.512, 0.14951916, 469.93726, 0.15727128)
decoder loss ratio: 92418.874873, decoder SINDy loss  ratio: 1.014426
--- 0.2622828483581543 seconds for one epoch ---
--- 0.29534339904785156 seconds for one epoch ---
--- 0.7359187602996826 seconds for one epoch ---
--- 0.2905852794647217 seconds for one epoch ---
--- 0.758331298828125 seconds for one epoch ---
--- 0.3156256675720215 seconds for one epoch ---
--- 0.7501466274261475 seconds for one epoch ---
--- 0.2846214771270752 seconds for one epoch ---
--- 0.7580687999725342 seconds for one epoch ---
--- 0.29811930656433105 seconds for one epoch ---
--- 0.7513899803161621 seconds for one epoch ---
--- 0.292313814163208 seconds for one epoch ---
--- 0.7512638568878174 seconds for one epoch ---
--- 0.2918844223022461 seconds for one epoch ---
--- 0.7380743026733398 seconds for one epoch ---
--- 0.29082751274108887 seconds for one epoch ---
--- 0.7558348178863525 seconds for one epoch ---
--- 0.2940819263458252 seconds for one epoch ---
--- 0.7613096237182617 seconds for one epoch ---
--- 0.2893846035003662 seconds for one epoch ---
--- 0.7561500072479248 seconds for one epoch ---
--- 0.2968018054962158 seconds for one epoch ---
--- 0.7459499835968018 seconds for one epoch ---
--- 0.2982933521270752 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.49187776]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-4.5106707]
 [ 0.       ]]
--- 0.2654073238372803 seconds for one epoch ---
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5720.69140625, (1468.8926, 0.89510506, 4250.7314, 0.17240049)
   validation loss 1680.450927734375, (1294.0635, 0.15387478, 386.06113, 0.17240049)
decoder loss ratio: 50134.265675, decoder SINDy loss  ratio: 0.833367
--- 0.2963287830352783 seconds for one epoch ---
--- 0.7604684829711914 seconds for one epoch ---
--- 0.3052706718444824 seconds for one epoch ---
--- 0.7263104915618896 seconds for one epoch ---
--- 0.29931211471557617 seconds for one epoch ---
--- 0.7669894695281982 seconds for one epoch ---
--- 0.29630494117736816 seconds for one epoch ---
--- 0.747776985168457 seconds for one epoch ---
--- 0.2883024215698242 seconds for one epoch ---
--- 0.7511184215545654 seconds for one epoch ---
--- 0.2878873348236084 seconds for one epoch ---
--- 0.7454631328582764 seconds for one epoch ---
--- 0.30010056495666504 seconds for one epoch ---
--- 0.770641565322876 seconds for one epoch ---
--- 0.2937660217285156 seconds for one epoch ---
--- 0.7502522468566895 seconds for one epoch ---
--- 0.29394006729125977 seconds for one epoch ---
--- 0.7795405387878418 seconds for one epoch ---
--- 0.29360485076904297 seconds for one epoch ---
--- 0.7481441497802734 seconds for one epoch ---
--- 0.28423500061035156 seconds for one epoch ---
--- 0.7428102493286133 seconds for one epoch ---
--- 0.28894948959350586 seconds for one epoch ---
--- 0.7579379081726074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.55162215]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-4.805414]
 [-0.      ]]
--- 0.2859838008880615 seconds for one epoch ---
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2312.044921875, (1625.7405, 0.43613347, 685.6825, 0.18569979)
   validation loss 995.5764770507812, (652.5206, 0.16886267, 342.70126, 0.18569979)
decoder loss ratio: 25279.782027, decoder SINDy loss  ratio: 0.739769
--- 0.25658679008483887 seconds for one epoch ---
--- 0.29784059524536133 seconds for one epoch ---
--- 0.7748894691467285 seconds for one epoch ---
--- 0.2909677028656006 seconds for one epoch ---
--- 0.7506623268127441 seconds for one epoch ---
--- 0.29393815994262695 seconds for one epoch ---
--- 0.7718174457550049 seconds for one epoch ---
--- 0.29245567321777344 seconds for one epoch ---
--- 0.765723466873169 seconds for one epoch ---
--- 0.29319095611572266 seconds for one epoch ---
--- 0.7718839645385742 seconds for one epoch ---
--- 0.3034689426422119 seconds for one epoch ---
--- 0.802398681640625 seconds for one epoch ---
--- 0.29642438888549805 seconds for one epoch ---
--- 0.7545685768127441 seconds for one epoch ---
--- 0.29264044761657715 seconds for one epoch ---
--- 0.7847287654876709 seconds for one epoch ---
--- 0.28821682929992676 seconds for one epoch ---
--- 0.7841939926147461 seconds for one epoch ---
--- 0.28244543075561523 seconds for one epoch ---
--- 0.7763030529022217 seconds for one epoch ---
--- 0.2881612777709961 seconds for one epoch ---
--- 0.7549288272857666 seconds for one epoch ---
--- 0.295712947845459 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.61094713]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.1099577]
 [-0.       ]]
--- 0.2566812038421631 seconds for one epoch ---
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4534.419921875, (1921.385, 5.896968, 2606.94, 0.19835036)
   validation loss 1076.1124267578125, (674.428, 0.19694206, 401.28912, 0.19835036)
decoder loss ratio: 26128.510746, decoder SINDy loss  ratio: 0.866239
--- 0.28463077545166016 seconds for one epoch ---
--- 0.7670762538909912 seconds for one epoch ---
--- 0.2945442199707031 seconds for one epoch ---
--- 0.7692134380340576 seconds for one epoch ---
--- 0.29244017601013184 seconds for one epoch ---
--- 0.7642147541046143 seconds for one epoch ---
--- 0.2917306423187256 seconds for one epoch ---
--- 0.7880077362060547 seconds for one epoch ---
--- 0.30702757835388184 seconds for one epoch ---
--- 0.7692506313323975 seconds for one epoch ---
--- 0.30341506004333496 seconds for one epoch ---
--- 0.7907116413116455 seconds for one epoch ---
--- 0.3017096519470215 seconds for one epoch ---
--- 0.772723913192749 seconds for one epoch ---
--- 0.2913057804107666 seconds for one epoch ---
--- 0.7769820690155029 seconds for one epoch ---
--- 0.28920960426330566 seconds for one epoch ---
--- 0.7805359363555908 seconds for one epoch ---
--- 0.2997422218322754 seconds for one epoch ---
--- 0.7838001251220703 seconds for one epoch ---
--- 0.30013132095336914 seconds for one epoch ---
--- 0.7748119831085205 seconds for one epoch ---
--- 0.2933535575866699 seconds for one epoch ---
--- 0.7819600105285645 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.6581802]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-5.367985]
 [ 0.      ]]
--- 0.29453301429748535 seconds for one epoch ---
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4794.58349609375, (2699.9226, 1.8638445, 2092.5889, 0.20854168)
   validation loss 2204.82421875, (1747.8134, 0.15639612, 456.64606, 0.20854168)
decoder loss ratio: 67713.323690, decoder SINDy loss  ratio: 0.985735
--- 0.25177764892578125 seconds for one epoch ---
--- 0.29765915870666504 seconds for one epoch ---
--- 0.796687126159668 seconds for one epoch ---
--- 0.2988879680633545 seconds for one epoch ---
--- 0.8003544807434082 seconds for one epoch ---
--- 0.30150842666625977 seconds for one epoch ---
--- 0.775324821472168 seconds for one epoch ---
--- 0.3026869297027588 seconds for one epoch ---
--- 0.7948179244995117 seconds for one epoch ---
--- 0.29926013946533203 seconds for one epoch ---
--- 0.7742226123809814 seconds for one epoch ---
--- 0.29070377349853516 seconds for one epoch ---
--- 0.7937195301055908 seconds for one epoch ---
--- 0.2971782684326172 seconds for one epoch ---
--- 0.7804183959960938 seconds for one epoch ---
--- 0.2997779846191406 seconds for one epoch ---
--- 0.810194730758667 seconds for one epoch ---
--- 0.2968144416809082 seconds for one epoch ---
--- 0.7846522331237793 seconds for one epoch ---
--- 0.2891683578491211 seconds for one epoch ---
--- 0.8155028820037842 seconds for one epoch ---
--- 0.29404163360595703 seconds for one epoch ---
--- 0.7784442901611328 seconds for one epoch ---
--- 0.2908213138580322 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.70685136]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [ 0.       ]
 [-5.6566167]
 [-0.       ]]
--- 0.2613182067871094 seconds for one epoch ---
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2902.62890625, (1510.4686, 3.5712893, 1388.3693, 0.21960846)
   validation loss 1032.668212890625, (686.5015, 0.14999506, 345.79703, 0.21960846)
decoder loss ratio: 26596.260932, decoder SINDy loss  ratio: 0.746452
--- 0.29302191734313965 seconds for one epoch ---
--- 0.7954733371734619 seconds for one epoch ---
--- 0.29839062690734863 seconds for one epoch ---
--- 0.7991292476654053 seconds for one epoch ---
--- 0.29865479469299316 seconds for one epoch ---
--- 0.7864723205566406 seconds for one epoch ---
--- 0.29674839973449707 seconds for one epoch ---
--- 0.7806169986724854 seconds for one epoch ---
--- 0.29302000999450684 seconds for one epoch ---
--- 0.80118727684021 seconds for one epoch ---
--- 0.2951080799102783 seconds for one epoch ---
--- 0.7993865013122559 seconds for one epoch ---
--- 0.29749035835266113 seconds for one epoch ---
--- 0.8049564361572266 seconds for one epoch ---
--- 0.2886829376220703 seconds for one epoch ---
--- 0.8154044151306152 seconds for one epoch ---
--- 0.2850625514984131 seconds for one epoch ---
--- 0.7962276935577393 seconds for one epoch ---
--- 0.30034422874450684 seconds for one epoch ---
--- 0.8142704963684082 seconds for one epoch ---
--- 0.294344425201416 seconds for one epoch ---
--- 0.8153576850891113 seconds for one epoch ---
--- 0.2872598171234131 seconds for one epoch ---
--- 0.802440881729126 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7477863]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-5.925674]
 [ 0.      ]]
--- 0.299849271774292 seconds for one epoch ---
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2092.3857421875, (1227.6831, 1.6362749, 862.8379, 0.22859578)
   validation loss 1249.4735107421875, (894.9271, 0.17665505, 354.14114, 0.22859578)
decoder loss ratio: 34671.030446, decoder SINDy loss  ratio: 0.764463
--- 0.26314353942871094 seconds for one epoch ---
--- 0.29009342193603516 seconds for one epoch ---
--- 0.7954649925231934 seconds for one epoch ---
--- 0.297344446182251 seconds for one epoch ---
--- 0.7916209697723389 seconds for one epoch ---
--- 0.29006385803222656 seconds for one epoch ---
--- 0.8090627193450928 seconds for one epoch ---
--- 0.2890298366546631 seconds for one epoch ---
--- 0.8072867393493652 seconds for one epoch ---
--- 0.29253458976745605 seconds for one epoch ---
--- 0.8033065795898438 seconds for one epoch ---
--- 0.29188966751098633 seconds for one epoch ---
--- 0.8071866035461426 seconds for one epoch ---
--- 0.3006014823913574 seconds for one epoch ---
--- 0.8204469680786133 seconds for one epoch ---
--- 0.29038453102111816 seconds for one epoch ---
--- 0.8097262382507324 seconds for one epoch ---
--- 0.2999403476715088 seconds for one epoch ---
--- 0.8173243999481201 seconds for one epoch ---
--- 0.300661563873291 seconds for one epoch ---
--- 0.8059873580932617 seconds for one epoch ---
--- 0.295992374420166 seconds for one epoch ---
--- 0.8379127979278564 seconds for one epoch ---
--- 0.2989845275878906 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.7861721]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-6.2098303]
 [-0.       ]]
--- 0.2597343921661377 seconds for one epoch ---
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4264.50927734375, (1718.5804, 1.0466135, 2544.645, 0.23739591)
   validation loss 846.8525390625, (507.2613, 0.14409016, 339.20978, 0.23739591)
decoder loss ratio: 19652.183077, decoder SINDy loss  ratio: 0.732232
--- 0.2906355857849121 seconds for one epoch ---
--- 0.8253097534179688 seconds for one epoch ---
--- 0.2969939708709717 seconds for one epoch ---
--- 0.8135578632354736 seconds for one epoch ---
--- 0.2972099781036377 seconds for one epoch ---
--- 0.8280079364776611 seconds for one epoch ---
--- 0.2954559326171875 seconds for one epoch ---
--- 0.8250415325164795 seconds for one epoch ---
--- 0.3039262294769287 seconds for one epoch ---
--- 0.8416042327880859 seconds for one epoch ---
--- 0.2982332706451416 seconds for one epoch ---
--- 0.8294446468353271 seconds for one epoch ---
--- 0.2922370433807373 seconds for one epoch ---
--- 0.8184423446655273 seconds for one epoch ---
--- 0.28458118438720703 seconds for one epoch ---
--- 0.8480520248413086 seconds for one epoch ---
--- 0.29846715927124023 seconds for one epoch ---
--- 0.829535961151123 seconds for one epoch ---
--- 0.2950911521911621 seconds for one epoch ---
--- 0.8090360164642334 seconds for one epoch ---
--- 0.29966211318969727 seconds for one epoch ---
--- 0.8337206840515137 seconds for one epoch ---
--- 0.29807519912719727 seconds for one epoch ---
--- 0.8374402523040771 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8192841]
 [0.       ]]
[[-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [ 0.     ]
 [-6.49069]
 [ 0.     ]]
--- 0.2794671058654785 seconds for one epoch ---
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3752.71728515625, (1635.3188, 1.243142, 2115.9102, 0.24512914)
   validation loss 1103.67724609375, (776.2703, 0.13066985, 327.03107, 0.24512914)
decoder loss ratio: 30074.060044, decoder SINDy loss  ratio: 0.705943
--- 0.27352046966552734 seconds for one epoch ---
--- 0.29914021492004395 seconds for one epoch ---
--- 0.8384997844696045 seconds for one epoch ---
--- 0.3103976249694824 seconds for one epoch ---
--- 0.8279497623443604 seconds for one epoch ---
--- 0.297163724899292 seconds for one epoch ---
--- 0.8252720832824707 seconds for one epoch ---
--- 0.2979857921600342 seconds for one epoch ---
--- 0.8515510559082031 seconds for one epoch ---
--- 0.3001830577850342 seconds for one epoch ---
--- 0.8214426040649414 seconds for one epoch ---
--- 0.2916076183319092 seconds for one epoch ---
--- 0.8267645835876465 seconds for one epoch ---
--- 0.28691840171813965 seconds for one epoch ---
--- 0.8274984359741211 seconds for one epoch ---
--- 0.288907527923584 seconds for one epoch ---
--- 0.8189141750335693 seconds for one epoch ---
--- 0.3022441864013672 seconds for one epoch ---
--- 0.851923942565918 seconds for one epoch ---
--- 0.294330358505249 seconds for one epoch ---
--- 0.8445084095001221 seconds for one epoch ---
--- 0.29984092712402344 seconds for one epoch ---
--- 0.8381900787353516 seconds for one epoch ---
--- 0.2916085720062256 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8430622]
 [0.       ]]
[[ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-6.721351]
 [ 0.      ]]
--- 0.24982333183288574 seconds for one epoch ---
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2950.60400390625, (1284.1831, 0.43814102, 1665.7317, 0.25108212)
   validation loss 1152.5498046875, (818.15515, 0.17844248, 333.9651, 0.25108212)
decoder loss ratio: 31696.750944, decoder SINDy loss  ratio: 0.720911
--- 0.3080275058746338 seconds for one epoch ---
--- 0.8281829357147217 seconds for one epoch ---
--- 0.29158711433410645 seconds for one epoch ---
--- 0.8559689521789551 seconds for one epoch ---
--- 0.29558539390563965 seconds for one epoch ---
--- 0.8341379165649414 seconds for one epoch ---
--- 0.3163020610809326 seconds for one epoch ---
--- 0.8299386501312256 seconds for one epoch ---
--- 0.2938539981842041 seconds for one epoch ---
--- 0.8560116291046143 seconds for one epoch ---
--- 0.2912259101867676 seconds for one epoch ---
--- 0.845815896987915 seconds for one epoch ---
--- 0.29512810707092285 seconds for one epoch ---
--- 0.8405978679656982 seconds for one epoch ---
--- 0.3131380081176758 seconds for one epoch ---
--- 0.8368780612945557 seconds for one epoch ---
--- 0.29593420028686523 seconds for one epoch ---
--- 0.8403897285461426 seconds for one epoch ---
--- 0.29991817474365234 seconds for one epoch ---
--- 0.8363184928894043 seconds for one epoch ---
--- 0.2900967597961426 seconds for one epoch ---
--- 0.8441638946533203 seconds for one epoch ---
--- 0.318528413772583 seconds for one epoch ---
--- 0.8527829647064209 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.864142]
 [0.      ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-6.953895]
 [-0.      ]]
--- 0.29123735427856445 seconds for one epoch ---
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3344.58349609375, (1181.371, 1.2171147, 2161.7388, 0.25664935)
   validation loss 905.1149291992188, (587.8103, 0.10065586, 316.9473, 0.25664935)
decoder loss ratio: 22772.791611, decoder SINDy loss  ratio: 0.684175
--- 0.2636420726776123 seconds for one epoch ---
--- 0.29505324363708496 seconds for one epoch ---
--- 0.8593969345092773 seconds for one epoch ---
--- 0.32442808151245117 seconds for one epoch ---
--- 0.8221797943115234 seconds for one epoch ---
--- 0.2897145748138428 seconds for one epoch ---
--- 0.8395524024963379 seconds for one epoch ---
--- 0.29187607765197754 seconds for one epoch ---
--- 0.8581781387329102 seconds for one epoch ---
--- 0.29021739959716797 seconds for one epoch ---
--- 0.8645749092102051 seconds for one epoch ---
--- 0.2987053394317627 seconds for one epoch ---
--- 0.8594686985015869 seconds for one epoch ---
--- 0.27947521209716797 seconds for one epoch ---
--- 0.8486337661743164 seconds for one epoch ---
--- 0.45860886573791504 seconds for one epoch ---
--- 0.8559305667877197 seconds for one epoch ---
--- 0.29721856117248535 seconds for one epoch ---
--- 0.8712959289550781 seconds for one epoch ---
--- 0.28267359733581543 seconds for one epoch ---
--- 0.8640518188476562 seconds for one epoch ---
--- 0.291562557220459 seconds for one epoch ---
--- 0.8623390197753906 seconds for one epoch ---
--- 0.29384756088256836 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8811846]
 [0.       ]]
[[-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.1679354]
 [-0.       ]]
--- 0.25333714485168457 seconds for one epoch ---
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3401.979736328125, (1444.0109, 0.8531799, 1956.8544, 0.26146674)
   validation loss 1379.031005859375, (1052.5526, 0.108723804, 326.10815, 0.26146674)
decoder loss ratio: 40777.715512, decoder SINDy loss  ratio: 0.703950
--- 0.29653334617614746 seconds for one epoch ---
--- 0.8415658473968506 seconds for one epoch ---
--- 0.29458069801330566 seconds for one epoch ---
--- 0.8366177082061768 seconds for one epoch ---
--- 0.30065011978149414 seconds for one epoch ---
--- 0.8524215221405029 seconds for one epoch ---
--- 0.3114924430847168 seconds for one epoch ---
--- 0.8678078651428223 seconds for one epoch ---
--- 0.2948729991912842 seconds for one epoch ---
--- 0.8646047115325928 seconds for one epoch ---
--- 0.2894132137298584 seconds for one epoch ---
--- 0.8545832633972168 seconds for one epoch ---
--- 0.2881467342376709 seconds for one epoch ---
--- 0.8422901630401611 seconds for one epoch ---
--- 0.27816057205200195 seconds for one epoch ---
--- 0.8683319091796875 seconds for one epoch ---
--- 0.2831909656524658 seconds for one epoch ---
--- 0.8810019493103027 seconds for one epoch ---
--- 0.3002758026123047 seconds for one epoch ---
--- 0.8794589042663574 seconds for one epoch ---
--- 0.2874171733856201 seconds for one epoch ---
--- 0.8750581741333008 seconds for one epoch ---
--- 0.2961866855621338 seconds for one epoch ---
--- 0.886937141418457 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.8974179]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-7.401018]
 [ 0.      ]]
--- 0.29030776023864746 seconds for one epoch ---
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3117.507080078125, (1801.7292, 1.7108843, 1313.8008, 0.26619804)
   validation loss 1087.85107421875, (744.8126, 0.09404476, 342.67816, 0.26619804)
decoder loss ratio: 28855.334031, decoder SINDy loss  ratio: 0.739719
--- 0.2569844722747803 seconds for one epoch ---
--- 0.29019594192504883 seconds for one epoch ---
--- 0.8696198463439941 seconds for one epoch ---
--- 0.2893822193145752 seconds for one epoch ---
--- 0.8816967010498047 seconds for one epoch ---
--- 0.30019593238830566 seconds for one epoch ---
--- 0.8779795169830322 seconds for one epoch ---
--- 0.2896580696105957 seconds for one epoch ---
--- 0.8757078647613525 seconds for one epoch ---
--- 0.2986176013946533 seconds for one epoch ---
--- 0.864607572555542 seconds for one epoch ---
--- 0.2959480285644531 seconds for one epoch ---
--- 0.8663690090179443 seconds for one epoch ---
--- 0.2930009365081787 seconds for one epoch ---
--- 0.8730366230010986 seconds for one epoch ---
--- 0.29599618911743164 seconds for one epoch ---
--- 0.8825404644012451 seconds for one epoch ---
--- 0.29744911193847656 seconds for one epoch ---
--- 0.8968181610107422 seconds for one epoch ---
--- 0.3170921802520752 seconds for one epoch ---
--- 0.890228271484375 seconds for one epoch ---
--- 0.2977743148803711 seconds for one epoch ---
--- 0.8917572498321533 seconds for one epoch ---
--- 0.29669785499572754 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.90873766]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-7.5859003]
 [-0.       ]]
--- 0.25690174102783203 seconds for one epoch ---
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6646.94873046875, (2818.7407, 5.148093, 3822.79, 0.26989588)
   validation loss 886.811767578125, (559.51996, 0.120501414, 326.90146, 0.26989588)
decoder loss ratio: 21676.774562, decoder SINDy loss  ratio: 0.705663
--- 0.29740452766418457 seconds for one epoch ---
--- 0.8775544166564941 seconds for one epoch ---
--- 0.2853829860687256 seconds for one epoch ---
--- 0.9090375900268555 seconds for one epoch ---
--- 0.3027076721191406 seconds for one epoch ---
--- 0.8785569667816162 seconds for one epoch ---
--- 0.29186320304870605 seconds for one epoch ---
--- 0.8906159400939941 seconds for one epoch ---
--- 0.29112744331359863 seconds for one epoch ---
--- 0.8986482620239258 seconds for one epoch ---
--- 0.2863476276397705 seconds for one epoch ---
--- 0.8986389636993408 seconds for one epoch ---
--- 0.2856602668762207 seconds for one epoch ---
--- 0.9063854217529297 seconds for one epoch ---
--- 0.299513578414917 seconds for one epoch ---
--- 0.9052269458770752 seconds for one epoch ---
--- 0.29191040992736816 seconds for one epoch ---
--- 0.9118204116821289 seconds for one epoch ---
--- 0.2824668884277344 seconds for one epoch ---
--- 0.8754398822784424 seconds for one epoch ---
--- 0.2785181999206543 seconds for one epoch ---
--- 0.9046199321746826 seconds for one epoch ---
--- 0.27898550033569336 seconds for one epoch ---
--- 0.9014267921447754 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.91965157]
 [0.        ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-7.787053]
 [ 0.      ]]
--- 0.2875216007232666 seconds for one epoch ---
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3557.048095703125, (1251.1184, 2.5079823, 2303.1482, 0.27360117)
   validation loss 1376.853759765625, (1024.1088, 0.09926404, 352.37222, 0.27360117)
decoder loss ratio: 39675.751473, decoder SINDy loss  ratio: 0.760645
--- 0.24800467491149902 seconds for one epoch ---
--- 0.29056286811828613 seconds for one epoch ---
--- 0.890540361404419 seconds for one epoch ---
--- 0.29006338119506836 seconds for one epoch ---
--- 0.8737823963165283 seconds for one epoch ---
--- 0.2949330806732178 seconds for one epoch ---
--- 0.9135265350341797 seconds for one epoch ---
--- 0.2882211208343506 seconds for one epoch ---
--- 0.8819336891174316 seconds for one epoch ---
--- 0.29381608963012695 seconds for one epoch ---
--- 0.8988566398620605 seconds for one epoch ---
--- 0.28922200202941895 seconds for one epoch ---
--- 0.9301245212554932 seconds for one epoch ---
--- 0.3010993003845215 seconds for one epoch ---
--- 0.9189388751983643 seconds for one epoch ---
--- 0.28310728073120117 seconds for one epoch ---
--- 0.9033429622650146 seconds for one epoch ---
--- 0.3018639087677002 seconds for one epoch ---
--- 0.9064013957977295 seconds for one epoch ---
--- 0.295011043548584 seconds for one epoch ---
--- 0.908972978591919 seconds for one epoch ---
--- 0.28742218017578125 seconds for one epoch ---
--- 0.9024238586425781 seconds for one epoch ---
--- 0.2853415012359619 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9281206]
 [0.       ]]
[[ 0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-7.9630504]
 [ 0.       ]]
--- 0.2566499710083008 seconds for one epoch ---
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5338.22705078125, (2611.2754, 3.2962902, 2723.3784, 0.27676225)
   validation loss 1328.5689697265625, (944.0252, 0.09888304, 384.1681, 0.27676225)
decoder loss ratio: 36573.175439, decoder SINDy loss  ratio: 0.829281
--- 0.2925913333892822 seconds for one epoch ---
--- 0.9134135246276855 seconds for one epoch ---
--- 0.2966573238372803 seconds for one epoch ---
--- 0.8879115581512451 seconds for one epoch ---
--- 0.28769636154174805 seconds for one epoch ---
--- 0.8992679119110107 seconds for one epoch ---
--- 0.3028116226196289 seconds for one epoch ---
--- 0.9116005897521973 seconds for one epoch ---
--- 0.32064270973205566 seconds for one epoch ---
--- 0.9082047939300537 seconds for one epoch ---
--- 0.29480504989624023 seconds for one epoch ---
--- 0.8907155990600586 seconds for one epoch ---
--- 0.28461670875549316 seconds for one epoch ---
--- 0.8987700939178467 seconds for one epoch ---
--- 0.29166388511657715 seconds for one epoch ---
--- 0.9312632083892822 seconds for one epoch ---
--- 0.2993001937866211 seconds for one epoch ---
--- 0.9034159183502197 seconds for one epoch ---
--- 0.2817051410675049 seconds for one epoch ---
--- 0.9141738414764404 seconds for one epoch ---
--- 0.2885105609893799 seconds for one epoch ---
--- 0.9098591804504395 seconds for one epoch ---
--- 0.28243207931518555 seconds for one epoch ---
--- 0.8986501693725586 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.93603814]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.147774]
 [-0.      ]]
--- 0.28518176078796387 seconds for one epoch ---
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3400.419189453125, (1351.292, 0.44209844, 2048.405, 0.28008845)
   validation loss 894.1994018554688, (573.7902, 0.11766295, 320.01144, 0.28008845)
decoder loss ratio: 22229.629350, decoder SINDy loss  ratio: 0.690790
--- 0.2502424716949463 seconds for one epoch ---
--- 0.29242753982543945 seconds for one epoch ---
--- 0.9130692481994629 seconds for one epoch ---
--- 0.292248010635376 seconds for one epoch ---
--- 0.9112927913665771 seconds for one epoch ---
--- 0.29143500328063965 seconds for one epoch ---
--- 0.919074535369873 seconds for one epoch ---
--- 0.29406118392944336 seconds for one epoch ---
--- 0.930896520614624 seconds for one epoch ---
--- 0.2870364189147949 seconds for one epoch ---
--- 0.9378185272216797 seconds for one epoch ---
--- 0.30554628372192383 seconds for one epoch ---
--- 0.9321846961975098 seconds for one epoch ---
--- 0.2911560535430908 seconds for one epoch ---
--- 0.9221785068511963 seconds for one epoch ---
--- 0.2732229232788086 seconds for one epoch ---
--- 0.9305670261383057 seconds for one epoch ---
--- 0.3040928840637207 seconds for one epoch ---
--- 0.9250695705413818 seconds for one epoch ---
--- 0.29742884635925293 seconds for one epoch ---
--- 0.9165937900543213 seconds for one epoch ---
--- 0.2927854061126709 seconds for one epoch ---
--- 0.9470739364624023 seconds for one epoch ---
--- 0.27524685859680176 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9431901]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-8.336026]
 [-0.      ]]
--- 0.24957585334777832 seconds for one epoch ---
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3647.684814453125, (1790.7225, 1.4883775, 1855.1903, 0.28334904)
   validation loss 1623.4263916015625, (1233.7417, 0.11401024, 389.28738, 0.28334904)
decoder loss ratio: 47797.295298, decoder SINDy loss  ratio: 0.840332
--- 0.28748130798339844 seconds for one epoch ---
--- 0.952263355255127 seconds for one epoch ---
--- 0.31203341484069824 seconds for one epoch ---
--- 0.9465019702911377 seconds for one epoch ---
--- 0.2940244674682617 seconds for one epoch ---
--- 0.9541962146759033 seconds for one epoch ---
--- 0.2884845733642578 seconds for one epoch ---
--- 0.9352695941925049 seconds for one epoch ---
--- 0.28807616233825684 seconds for one epoch ---
--- 0.9558670520782471 seconds for one epoch ---
--- 0.29375529289245605 seconds for one epoch ---
--- 0.9391789436340332 seconds for one epoch ---
--- 0.28870415687561035 seconds for one epoch ---
--- 0.9247992038726807 seconds for one epoch ---
--- 0.28722262382507324 seconds for one epoch ---
--- 0.9259147644042969 seconds for one epoch ---
--- 0.2738783359527588 seconds for one epoch ---
--- 0.947343111038208 seconds for one epoch ---
--- 0.2939949035644531 seconds for one epoch ---
--- 0.9717719554901123 seconds for one epoch ---
--- 0.30118536949157715 seconds for one epoch ---
--- 0.9482421875 seconds for one epoch ---
--- 0.2817871570587158 seconds for one epoch ---
--- 0.9575412273406982 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.94956297]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-8.525705]
 [ 0.      ]]
--- 0.29204368591308594 seconds for one epoch ---
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5262.296875, (1905.7505, 1.5864102, 3354.6736, 0.2863554)
   validation loss 787.2450561523438, (470.365, 0.14981587, 316.44388, 0.2863554)
decoder loss ratio: 18222.756311, decoder SINDy loss  ratio: 0.683089
THRESHOLDING: 1 active coefficients
--- 0.25772976875305176 seconds for one epoch ---
--- 0.2900667190551758 seconds for one epoch ---
--- 0.9540212154388428 seconds for one epoch ---
--- 0.3184230327606201 seconds for one epoch ---
--- 0.9570844173431396 seconds for one epoch ---
--- 0.2958543300628662 seconds for one epoch ---
--- 0.9487104415893555 seconds for one epoch ---
--- 0.29239344596862793 seconds for one epoch ---
--- 0.9338324069976807 seconds for one epoch ---
--- 0.29557156562805176 seconds for one epoch ---
--- 0.9102790355682373 seconds for one epoch ---
--- 0.28959178924560547 seconds for one epoch ---
--- 0.9356601238250732 seconds for one epoch ---
--- 0.2894725799560547 seconds for one epoch ---
--- 0.9632554054260254 seconds for one epoch ---
--- 0.29461121559143066 seconds for one epoch ---
--- 0.9524087905883789 seconds for one epoch ---
--- 0.2907373905181885 seconds for one epoch ---
--- 0.9674935340881348 seconds for one epoch ---
--- 0.285353422164917 seconds for one epoch ---
--- 0.973984956741333 seconds for one epoch ---
--- 0.291609525680542 seconds for one epoch ---
--- 0.9505224227905273 seconds for one epoch ---
--- 0.2777845859527588 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9554173]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-8.723462]
 [-0.      ]]
--- 0.24474191665649414 seconds for one epoch ---
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5069.3896484375, (1644.1926, 7.9178257, 3416.9993, 0.27992332)
   validation loss 927.701416015625, (583.2437, 0.19036545, 343.9874, 0.27992332)
decoder loss ratio: 22595.874012, decoder SINDy loss  ratio: 0.742545
--- 0.29187917709350586 seconds for one epoch ---
--- 0.9236986637115479 seconds for one epoch ---
--- 0.2844064235687256 seconds for one epoch ---
--- 0.9500482082366943 seconds for one epoch ---
--- 0.2959754467010498 seconds for one epoch ---
--- 0.941809892654419 seconds for one epoch ---
--- 0.30701756477355957 seconds for one epoch ---
--- 0.9504282474517822 seconds for one epoch ---
--- 0.29152393341064453 seconds for one epoch ---
--- 0.9584298133850098 seconds for one epoch ---
--- 0.28494811058044434 seconds for one epoch ---
--- 0.9608616828918457 seconds for one epoch ---
--- 0.29593443870544434 seconds for one epoch ---
--- 0.969994068145752 seconds for one epoch ---
--- 0.28603243827819824 seconds for one epoch ---
--- 0.9591398239135742 seconds for one epoch ---
--- 0.28548240661621094 seconds for one epoch ---
--- 0.96234130859375 seconds for one epoch ---
--- 0.2919487953186035 seconds for one epoch ---
--- 0.9586241245269775 seconds for one epoch ---
--- 0.289170503616333 seconds for one epoch ---
--- 0.9749007225036621 seconds for one epoch ---
--- 0.2861487865447998 seconds for one epoch ---
--- 0.9615128040313721 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.960024]
 [0.      ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-8.899347]
 [ 0.      ]]
--- 0.30798864364624023 seconds for one epoch ---
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4868.90576171875, (2188.7532, 0.6910531, 2679.1787, 0.28274423)
   validation loss 994.255859375, (662.3652, 0.16980563, 331.43814, 0.28274423)
decoder loss ratio: 25661.176732, decoder SINDy loss  ratio: 0.715456
--- 0.2590749263763428 seconds for one epoch ---
--- 0.28952598571777344 seconds for one epoch ---
--- 0.9455885887145996 seconds for one epoch ---
--- 0.29001736640930176 seconds for one epoch ---
--- 0.939117431640625 seconds for one epoch ---
--- 0.30460691452026367 seconds for one epoch ---
--- 0.9531652927398682 seconds for one epoch ---
--- 0.27517199516296387 seconds for one epoch ---
--- 0.9600038528442383 seconds for one epoch ---
--- 0.29598522186279297 seconds for one epoch ---
--- 0.9789657592773438 seconds for one epoch ---
--- 0.2858736515045166 seconds for one epoch ---
--- 0.9641246795654297 seconds for one epoch ---
--- 0.30144262313842773 seconds for one epoch ---
--- 0.9856610298156738 seconds for one epoch ---
--- 0.291424036026001 seconds for one epoch ---
--- 0.9886550903320312 seconds for one epoch ---
--- 0.2962517738342285 seconds for one epoch ---
--- 0.9801971912384033 seconds for one epoch ---
--- 0.2941441535949707 seconds for one epoch ---
--- 0.9780759811401367 seconds for one epoch ---
--- 0.30784106254577637 seconds for one epoch ---
--- 0.9660656452178955 seconds for one epoch ---
--- 0.28632640838623047 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9643154]
 [0.       ]]
[[-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-9.083655]
 [ 0.      ]]
--- 0.2543044090270996 seconds for one epoch ---
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3189.61474609375, (1258.027, 2.824717, 1928.4775, 0.28571773)
   validation loss 1556.376953125, (1216.3893, 0.14236926, 339.5596, 0.28571773)
decoder loss ratio: 47125.032538, decoder SINDy loss  ratio: 0.732987
--- 0.29091644287109375 seconds for one epoch ---
--- 0.9636378288269043 seconds for one epoch ---
--- 0.2905106544494629 seconds for one epoch ---
--- 0.9756467342376709 seconds for one epoch ---
--- 0.29358339309692383 seconds for one epoch ---
--- 0.9995937347412109 seconds for one epoch ---
--- 0.29820895195007324 seconds for one epoch ---
--- 0.9785187244415283 seconds for one epoch ---
--- 0.2599215507507324 seconds for one epoch ---
--- 0.9868826866149902 seconds for one epoch ---
--- 0.29319214820861816 seconds for one epoch ---
--- 0.9884326457977295 seconds for one epoch ---
--- 0.289365291595459 seconds for one epoch ---
--- 0.9791355133056641 seconds for one epoch ---
--- 0.27324962615966797 seconds for one epoch ---
--- 0.9830172061920166 seconds for one epoch ---
--- 0.2957162857055664 seconds for one epoch ---
--- 0.9997742176055908 seconds for one epoch ---
--- 0.2849857807159424 seconds for one epoch ---
--- 0.9753201007843018 seconds for one epoch ---
--- 0.27526426315307617 seconds for one epoch ---
--- 1.0047252178192139 seconds for one epoch ---
--- 0.2871129512786865 seconds for one epoch ---
--- 0.9734992980957031 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.96789104]
 [0.        ]]
[[ 0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.256211]
 [-0.      ]]
--- 0.3083817958831787 seconds for one epoch ---
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6056.10693359375, (2177.71, 0.72622997, 3877.3818, 0.2885084)
   validation loss 1091.4420166015625, (750.7212, 0.10766455, 340.32465, 0.2885084)
decoder loss ratio: 29084.242264, decoder SINDy loss  ratio: 0.734639
--- 0.26064181327819824 seconds for one epoch ---
--- 0.2818586826324463 seconds for one epoch ---
--- 1.005735158920288 seconds for one epoch ---
--- 0.28981614112854004 seconds for one epoch ---
--- 0.9831631183624268 seconds for one epoch ---
--- 0.29367756843566895 seconds for one epoch ---
--- 0.9954347610473633 seconds for one epoch ---
--- 0.29671597480773926 seconds for one epoch ---
--- 0.9819395542144775 seconds for one epoch ---
--- 0.28653860092163086 seconds for one epoch ---
--- 0.9982383251190186 seconds for one epoch ---
--- 0.29877138137817383 seconds for one epoch ---
--- 0.9967641830444336 seconds for one epoch ---
--- 0.30844545364379883 seconds for one epoch ---
--- 1.00917649269104 seconds for one epoch ---
--- 0.2939450740814209 seconds for one epoch ---
--- 0.9936597347259521 seconds for one epoch ---
--- 0.2859458923339844 seconds for one epoch ---
--- 1.0031225681304932 seconds for one epoch ---
--- 0.29170966148376465 seconds for one epoch ---
--- 1.0106658935546875 seconds for one epoch ---
--- 0.289470911026001 seconds for one epoch ---
--- 0.9872307777404785 seconds for one epoch ---
--- 0.2878756523132324 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9708139]
 [0.       ]]
[[-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-0.     ]
 [ 0.     ]
 [-0.     ]
 [-0.     ]
 [ 0.     ]
 [ 0.     ]
 [-9.41338]
 [-0.     ]]
--- 0.25545430183410645 seconds for one epoch ---
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3503.0283203125, (1210.217, 1.6896193, 2290.8306, 0.29107657)
   validation loss 947.5208129882812, (629.5023, 0.13307345, 317.59433, 0.29107657)
decoder loss ratio: 24388.012715, decoder SINDy loss  ratio: 0.685572
--- 0.2843635082244873 seconds for one epoch ---
--- 0.9935455322265625 seconds for one epoch ---
--- 0.2893679141998291 seconds for one epoch ---
--- 1.0021953582763672 seconds for one epoch ---
--- 0.28061366081237793 seconds for one epoch ---
--- 0.9989769458770752 seconds for one epoch ---
--- 0.292391300201416 seconds for one epoch ---
--- 0.9896271228790283 seconds for one epoch ---
--- 0.2953183650970459 seconds for one epoch ---
--- 1.007990837097168 seconds for one epoch ---
--- 0.2885282039642334 seconds for one epoch ---
--- 1.028491735458374 seconds for one epoch ---
--- 0.29660606384277344 seconds for one epoch ---
--- 1.0201873779296875 seconds for one epoch ---
--- 0.29156494140625 seconds for one epoch ---
--- 1.0017085075378418 seconds for one epoch ---
--- 0.2872481346130371 seconds for one epoch ---
--- 1.0174946784973145 seconds for one epoch ---
--- 0.2882707118988037 seconds for one epoch ---
--- 1.027494192123413 seconds for one epoch ---
--- 0.29544734954833984 seconds for one epoch ---
--- 1.0040194988250732 seconds for one epoch ---
--- 0.2881505489349365 seconds for one epoch ---
--- 1.0217838287353516 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97356683]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-9.577627]
 [ 0.      ]]
--- 0.28241968154907227 seconds for one epoch ---
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4452.07861328125, (1550.984, 2.4019432, 2898.3992, 0.2937008)
   validation loss 985.554931640625, (657.64496, 0.16030383, 327.45602, 0.2937008)
decoder loss ratio: 25478.307414, decoder SINDy loss  ratio: 0.706860
--- 0.2581520080566406 seconds for one epoch ---
--- 0.2964770793914795 seconds for one epoch ---
--- 1.0070922374725342 seconds for one epoch ---
--- 0.2941756248474121 seconds for one epoch ---
--- 1.0064141750335693 seconds for one epoch ---
--- 0.27815818786621094 seconds for one epoch ---
--- 0.9838032722473145 seconds for one epoch ---
--- 0.29193711280822754 seconds for one epoch ---
--- 1.0008165836334229 seconds for one epoch ---
--- 0.29001784324645996 seconds for one epoch ---
--- 1.028017520904541 seconds for one epoch ---
--- 0.294262170791626 seconds for one epoch ---
--- 1.0188729763031006 seconds for one epoch ---
--- 0.2872486114501953 seconds for one epoch ---
--- 1.0349135398864746 seconds for one epoch ---
--- 0.2689394950866699 seconds for one epoch ---
--- 1.0167994499206543 seconds for one epoch ---
--- 0.2765963077545166 seconds for one epoch ---
--- 1.0227952003479004 seconds for one epoch ---
--- 0.29467058181762695 seconds for one epoch ---
--- 1.0181398391723633 seconds for one epoch ---
--- 0.28423404693603516 seconds for one epoch ---
--- 1.0078766345977783 seconds for one epoch ---
--- 0.28649187088012695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97615016]
 [0.        ]]
[[ 0.      ]
 [-0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-9.749618]
 [-0.      ]]
--- 0.24785780906677246 seconds for one epoch ---
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2931.544677734375, (2097.6902, 1.3480314, 832.2099, 0.2964444)
   validation loss 945.564208984375, (644.9616, 0.12280306, 300.18335, 0.2964444)
decoder loss ratio: 24986.932431, decoder SINDy loss  ratio: 0.647988
--- 0.29082703590393066 seconds for one epoch ---
--- 1.0190978050231934 seconds for one epoch ---
--- 0.3015623092651367 seconds for one epoch ---
--- 1.0154438018798828 seconds for one epoch ---
--- 0.31284523010253906 seconds for one epoch ---
--- 1.037656545639038 seconds for one epoch ---
--- 0.28543615341186523 seconds for one epoch ---
--- 1.0311901569366455 seconds for one epoch ---
--- 0.29368138313293457 seconds for one epoch ---
--- 1.0296428203582764 seconds for one epoch ---
--- 0.2874941825866699 seconds for one epoch ---
--- 1.0078599452972412 seconds for one epoch ---
--- 0.29766273498535156 seconds for one epoch ---
--- 1.0302042961120605 seconds for one epoch ---
--- 0.29627323150634766 seconds for one epoch ---
--- 1.0401582717895508 seconds for one epoch ---
--- 0.288982629776001 seconds for one epoch ---
--- 1.058060884475708 seconds for one epoch ---
--- 0.28243398666381836 seconds for one epoch ---
--- 1.0517621040344238 seconds for one epoch ---
--- 0.295971155166626 seconds for one epoch ---
--- 1.0495781898498535 seconds for one epoch ---
--- 0.29821133613586426 seconds for one epoch ---
--- 1.0636184215545654 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9783948]
 [0.       ]]
[[-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [-0.      ]
 [-0.      ]
 [-9.916316]
 [ 0.      ]]
--- 0.28185224533081055 seconds for one epoch ---
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3157.295166015625, (1602.61, 3.1423492, 1551.2438, 0.29904565)
   validation loss 916.5210571289062, (613.0219, 0.15467775, 303.0454, 0.29904565)
decoder loss ratio: 23749.533109, decoder SINDy loss  ratio: 0.654166
--- 0.25409388542175293 seconds for one epoch ---
--- 0.2941737174987793 seconds for one epoch ---
--- 1.0276718139648438 seconds for one epoch ---
--- 0.2869231700897217 seconds for one epoch ---
--- 1.0412824153900146 seconds for one epoch ---
--- 0.2931804656982422 seconds for one epoch ---
--- 1.0454025268554688 seconds for one epoch ---
--- 0.28937745094299316 seconds for one epoch ---
--- 1.0406184196472168 seconds for one epoch ---
--- 0.26108741760253906 seconds for one epoch ---
--- 1.056593656539917 seconds for one epoch ---
--- 0.2939455509185791 seconds for one epoch ---
--- 1.0682380199432373 seconds for one epoch ---
--- 0.29299283027648926 seconds for one epoch ---
--- 1.0637590885162354 seconds for one epoch ---
--- 0.3154447078704834 seconds for one epoch ---
--- 1.052950382232666 seconds for one epoch ---
--- 0.2943398952484131 seconds for one epoch ---
--- 1.044018030166626 seconds for one epoch ---
--- 0.29752421379089355 seconds for one epoch ---
--- 1.0648901462554932 seconds for one epoch ---
--- 0.29041409492492676 seconds for one epoch ---
--- 1.0743892192840576 seconds for one epoch ---
--- 0.29220104217529297 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9802884]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-10.072385]
 [  0.      ]]
--- 0.25478410720825195 seconds for one epoch ---
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3164.0, (1373.1906, 0.8039424, 1789.704, 0.30157635)
   validation loss 1134.3883056640625, (818.53766, 0.16942713, 315.37952, 0.30157635)
decoder loss ratio: 31711.569942, decoder SINDy loss  ratio: 0.680791
--- 0.2965512275695801 seconds for one epoch ---
--- 1.0321049690246582 seconds for one epoch ---
--- 0.2937324047088623 seconds for one epoch ---
--- 1.03483247756958 seconds for one epoch ---
--- 0.28415989875793457 seconds for one epoch ---
--- 1.0580995082855225 seconds for one epoch ---
--- 0.2943992614746094 seconds for one epoch ---
--- 1.040898084640503 seconds for one epoch ---
--- 0.2856326103210449 seconds for one epoch ---
--- 1.0694937705993652 seconds for one epoch ---
--- 0.28431034088134766 seconds for one epoch ---
--- 1.0621337890625 seconds for one epoch ---
--- 0.31794047355651855 seconds for one epoch ---
--- 1.049213171005249 seconds for one epoch ---
--- 0.28736329078674316 seconds for one epoch ---
--- 1.0293631553649902 seconds for one epoch ---
--- 0.297924280166626 seconds for one epoch ---
--- 1.057220458984375 seconds for one epoch ---
--- 0.2991209030151367 seconds for one epoch ---
--- 1.074110507965088 seconds for one epoch ---
--- 0.2967989444732666 seconds for one epoch ---
--- 1.0605504512786865 seconds for one epoch ---
--- 0.291949987411499 seconds for one epoch ---
--- 1.0792529582977295 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9818609]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.214964]
 [ -0.      ]]
--- 0.28817200660705566 seconds for one epoch ---
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3368.145751953125, (1310.5654, 0.82696754, 2056.4495, 0.3038934)
   validation loss 1145.64306640625, (844.3235, 0.19683655, 300.81888, 0.3038934)
decoder loss ratio: 32710.557670, decoder SINDy loss  ratio: 0.649360
--- 0.24756669998168945 seconds for one epoch ---
--- 0.2941274642944336 seconds for one epoch ---
--- 1.0563039779663086 seconds for one epoch ---
--- 0.29245734214782715 seconds for one epoch ---
--- 1.0564818382263184 seconds for one epoch ---
--- 0.2913215160369873 seconds for one epoch ---
--- 1.0338006019592285 seconds for one epoch ---
--- 0.294813871383667 seconds for one epoch ---
--- 1.0570170879364014 seconds for one epoch ---
--- 0.49437499046325684 seconds for one epoch ---
--- 1.0728676319122314 seconds for one epoch ---
--- 0.29607439041137695 seconds for one epoch ---
--- 1.0700442790985107 seconds for one epoch ---
--- 0.28420424461364746 seconds for one epoch ---
--- 1.0643291473388672 seconds for one epoch ---
--- 0.28300046920776367 seconds for one epoch ---
--- 1.0583198070526123 seconds for one epoch ---
--- 0.2749760150909424 seconds for one epoch ---
--- 1.0758624076843262 seconds for one epoch ---
--- 0.29920029640197754 seconds for one epoch ---
--- 1.0902833938598633 seconds for one epoch ---
--- 0.29744553565979004 seconds for one epoch ---
--- 1.0783076286315918 seconds for one epoch ---
--- 0.298464298248291 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9833385]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.361935]
 [ -0.      ]]
--- 0.26003408432006836 seconds for one epoch ---
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5538.18115234375, (1950.2103, 4.755475, 3582.9094, 0.30632704)
   validation loss 1055.1392822265625, (731.2618, 0.17993182, 323.39127, 0.30632704)
decoder loss ratio: 28330.350875, decoder SINDy loss  ratio: 0.698086
--- 0.2923438549041748 seconds for one epoch ---
--- 1.047415018081665 seconds for one epoch ---
--- 0.29493069648742676 seconds for one epoch ---
--- 1.058471918106079 seconds for one epoch ---
--- 0.28293347358703613 seconds for one epoch ---
--- 1.0649383068084717 seconds for one epoch ---
--- 0.2929210662841797 seconds for one epoch ---
--- 1.076848030090332 seconds for one epoch ---
--- 0.28942155838012695 seconds for one epoch ---
--- 1.0964469909667969 seconds for one epoch ---
--- 0.29169750213623047 seconds for one epoch ---
--- 1.0885486602783203 seconds for one epoch ---
--- 0.29491353034973145 seconds for one epoch ---
--- 1.0933449268341064 seconds for one epoch ---
--- 0.3187832832336426 seconds for one epoch ---
--- 1.070509910583496 seconds for one epoch ---
--- 0.28995704650878906 seconds for one epoch ---
--- 1.0826756954193115 seconds for one epoch ---
--- 0.2832145690917969 seconds for one epoch ---
--- 1.090808391571045 seconds for one epoch ---
--- 0.2997581958770752 seconds for one epoch ---
--- 1.09647798538208 seconds for one epoch ---
--- 0.29653048515319824 seconds for one epoch ---
--- 1.0776338577270508 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9848261]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-10.525109]
 [  0.      ]]
--- 0.28478217124938965 seconds for one epoch ---
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2805.186279296875, (1646.1735, 1.0253724, 1157.6785, 0.30889034)
   validation loss 968.5215454101562, (627.22095, 0.1426776, 340.849, 0.30889034)
decoder loss ratio: 24299.628401, decoder SINDy loss  ratio: 0.735771
--- 0.2666170597076416 seconds for one epoch ---
--- 0.2974824905395508 seconds for one epoch ---
--- 1.063736915588379 seconds for one epoch ---
--- 0.2980012893676758 seconds for one epoch ---
--- 1.089874267578125 seconds for one epoch ---
--- 0.29178404808044434 seconds for one epoch ---
--- 1.0844061374664307 seconds for one epoch ---
--- 0.2980058193206787 seconds for one epoch ---
--- 1.0910205841064453 seconds for one epoch ---
--- 0.29244089126586914 seconds for one epoch ---
--- 1.1036531925201416 seconds for one epoch ---
--- 0.28194308280944824 seconds for one epoch ---
--- 1.1052286624908447 seconds for one epoch ---
--- 0.28937458992004395 seconds for one epoch ---
--- 1.0963504314422607 seconds for one epoch ---
--- 0.2930457592010498 seconds for one epoch ---
--- 1.1292004585266113 seconds for one epoch ---
--- 0.2980198860168457 seconds for one epoch ---
--- 1.1176576614379883 seconds for one epoch ---
--- 0.2937448024749756 seconds for one epoch ---
--- 1.1016101837158203 seconds for one epoch ---
--- 0.2927267551422119 seconds for one epoch ---
--- 1.1033520698547363 seconds for one epoch ---
--- 0.30028223991394043 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9859054]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-10.655165]
 [ -0.      ]]
--- 0.26476097106933594 seconds for one epoch ---
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2121.76220703125, (1032.8298, 1.3048548, 1087.3165, 0.31105205)
   validation loss 1191.9051513671875, (836.3519, 0.13838947, 355.10382, 0.31105205)
decoder loss ratio: 32401.725689, decoder SINDy loss  ratio: 0.766542
--- 0.2874264717102051 seconds for one epoch ---
--- 1.0861897468566895 seconds for one epoch ---
--- 0.29280781745910645 seconds for one epoch ---
--- 1.0984842777252197 seconds for one epoch ---
--- 0.27010536193847656 seconds for one epoch ---
--- 1.1381001472473145 seconds for one epoch ---
--- 0.3027939796447754 seconds for one epoch ---
--- 1.0979456901550293 seconds for one epoch ---
--- 0.2894935607910156 seconds for one epoch ---
--- 1.1086328029632568 seconds for one epoch ---
--- 0.29172444343566895 seconds for one epoch ---
--- 1.117229700088501 seconds for one epoch ---
--- 0.2913680076599121 seconds for one epoch ---
--- 1.1102464199066162 seconds for one epoch ---
--- 0.3026235103607178 seconds for one epoch ---
--- 1.1149787902832031 seconds for one epoch ---
--- 0.2985503673553467 seconds for one epoch ---
--- 1.1137912273406982 seconds for one epoch ---
--- 0.2934088706970215 seconds for one epoch ---
--- 1.1052699089050293 seconds for one epoch ---
--- 0.29201507568359375 seconds for one epoch ---
--- 1.091306209564209 seconds for one epoch ---
--- 0.2967517375946045 seconds for one epoch ---
--- 1.1170687675476074 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9870145]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-10.800555]
 [  0.      ]]
--- 0.28023791313171387 seconds for one epoch ---
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3299.24560546875, (1462.0294, 1.8394575, 1835.0632, 0.31350157)
   validation loss 807.5758056640625, (501.66916, 0.17417578, 305.41904, 0.31350157)
decoder loss ratio: 19435.534153, decoder SINDy loss  ratio: 0.659290
--- 0.25534987449645996 seconds for one epoch ---
--- 0.32468295097351074 seconds for one epoch ---
--- 1.131197214126587 seconds for one epoch ---
--- 0.28839778900146484 seconds for one epoch ---
--- 1.123460292816162 seconds for one epoch ---
--- 0.2907114028930664 seconds for one epoch ---
--- 1.1122081279754639 seconds for one epoch ---
--- 0.2573716640472412 seconds for one epoch ---
--- 1.1011676788330078 seconds for one epoch ---
--- 0.294480562210083 seconds for one epoch ---
--- 1.0711231231689453 seconds for one epoch ---
--- 0.29859113693237305 seconds for one epoch ---
--- 1.1198954582214355 seconds for one epoch ---
--- 0.2915182113647461 seconds for one epoch ---
--- 1.123274564743042 seconds for one epoch ---
--- 0.29053688049316406 seconds for one epoch ---
--- 1.1144797801971436 seconds for one epoch ---
--- 0.2885410785675049 seconds for one epoch ---
--- 1.1340832710266113 seconds for one epoch ---
--- 0.2853875160217285 seconds for one epoch ---
--- 1.1180996894836426 seconds for one epoch ---
--- 0.2852821350097656 seconds for one epoch ---
--- 1.1172962188720703 seconds for one epoch ---
--- 0.2831544876098633 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98785204]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-10.919967]
 [  0.      ]]
--- 0.24016833305358887 seconds for one epoch ---
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2288.431396484375, (1108.4878, 7.9950857, 1171.633, 0.31544146)
   validation loss 855.217041015625, (523.0448, 0.1753739, 331.68143, 0.31544146)
decoder loss ratio: 20263.663590, decoder SINDy loss  ratio: 0.715981
--- 0.2796590328216553 seconds for one epoch ---
--- 1.1050307750701904 seconds for one epoch ---
--- 0.29353976249694824 seconds for one epoch ---
--- 1.1015934944152832 seconds for one epoch ---
--- 0.28743624687194824 seconds for one epoch ---
--- 1.1249570846557617 seconds for one epoch ---
--- 0.2947864532470703 seconds for one epoch ---
--- 1.1208925247192383 seconds for one epoch ---
--- 0.2801218032836914 seconds for one epoch ---
--- 1.1414151191711426 seconds for one epoch ---
--- 0.28546857833862305 seconds for one epoch ---
--- 1.1512696743011475 seconds for one epoch ---
--- 0.2827301025390625 seconds for one epoch ---
--- 1.1284065246582031 seconds for one epoch ---
--- 0.2850620746612549 seconds for one epoch ---
--- 1.123349905014038 seconds for one epoch ---
--- 0.28508424758911133 seconds for one epoch ---
--- 1.1289582252502441 seconds for one epoch ---
--- 0.318448543548584 seconds for one epoch ---
--- 1.1572637557983398 seconds for one epoch ---
--- 0.29233455657958984 seconds for one epoch ---
--- 1.1594371795654297 seconds for one epoch ---
--- 0.2896604537963867 seconds for one epoch ---
--- 1.147169589996338 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98874927]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.058445]
 [ -0.      ]]
--- 0.29796671867370605 seconds for one epoch ---
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2281.56103515625, (1228.262, 1.0072112, 1051.9742, 0.3177387)
   validation loss 1379.6112060546875, (1026.5983, 0.16678025, 352.52844, 0.3177387)
decoder loss ratio: 39772.199101, decoder SINDy loss  ratio: 0.760982
--- 0.2549002170562744 seconds for one epoch ---
--- 0.29182887077331543 seconds for one epoch ---
--- 1.1527886390686035 seconds for one epoch ---
--- 0.28668713569641113 seconds for one epoch ---
--- 1.138577938079834 seconds for one epoch ---
--- 0.29560351371765137 seconds for one epoch ---
--- 1.1335644721984863 seconds for one epoch ---
--- 0.29067397117614746 seconds for one epoch ---
--- 1.158374547958374 seconds for one epoch ---
--- 0.2712364196777344 seconds for one epoch ---
--- 1.1361706256866455 seconds for one epoch ---
--- 0.29171180725097656 seconds for one epoch ---
--- 1.1409273147583008 seconds for one epoch ---
--- 0.29477977752685547 seconds for one epoch ---
--- 1.1404309272766113 seconds for one epoch ---
--- 0.29654455184936523 seconds for one epoch ---
--- 1.1343357563018799 seconds for one epoch ---
--- 0.2859504222869873 seconds for one epoch ---
--- 1.1376969814300537 seconds for one epoch ---
--- 0.29432058334350586 seconds for one epoch ---
--- 1.1395282745361328 seconds for one epoch ---
--- 0.2903635501861572 seconds for one epoch ---
--- 1.143791913986206 seconds for one epoch ---
--- 0.2827792167663574 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9896086]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.203298]
 [ -0.      ]]
--- 0.2636837959289551 seconds for one epoch ---
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2537.22314453125, (1312.529, 0.5681058, 1223.8058, 0.32027096)
   validation loss 2421.23681640625, (1998.9624, 0.1537247, 421.8005, 0.32027096)
decoder loss ratio: 77443.273818, decoder SINDy loss  ratio: 0.910516
--- 0.2932460308074951 seconds for one epoch ---
--- 1.1192612648010254 seconds for one epoch ---
--- 0.28016161918640137 seconds for one epoch ---
--- 1.1423497200012207 seconds for one epoch ---
--- 0.2934567928314209 seconds for one epoch ---
--- 1.1394269466400146 seconds for one epoch ---
--- 0.3007361888885498 seconds for one epoch ---
--- 1.1295244693756104 seconds for one epoch ---
--- 0.3025166988372803 seconds for one epoch ---
--- 1.1578855514526367 seconds for one epoch ---
--- 0.30354809761047363 seconds for one epoch ---
--- 1.1590313911437988 seconds for one epoch ---
--- 0.3012349605560303 seconds for one epoch ---
--- 1.1503334045410156 seconds for one epoch ---
--- 0.29505109786987305 seconds for one epoch ---
--- 1.1465904712677002 seconds for one epoch ---
--- 0.28833818435668945 seconds for one epoch ---
--- 1.139700174331665 seconds for one epoch ---
--- 0.28037571907043457 seconds for one epoch ---
--- 1.151149034500122 seconds for one epoch ---
--- 0.28909969329833984 seconds for one epoch ---
--- 1.1367707252502441 seconds for one epoch ---
--- 0.30660080909729004 seconds for one epoch ---
--- 1.156494379043579 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99028856]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.327758]
 [  0.      ]]
--- 0.2995321750640869 seconds for one epoch ---
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2544.548583984375, (1287.7085, 2.9699385, 1253.5476, 0.32239053)
   validation loss 939.7197265625, (618.521, 0.14731835, 320.72897, 0.32239053)
decoder loss ratio: 23962.577188, decoder SINDy loss  ratio: 0.692339
--- 0.26340436935424805 seconds for one epoch ---
--- 0.28816866874694824 seconds for one epoch ---
--- 1.1605777740478516 seconds for one epoch ---
--- 0.2918686866760254 seconds for one epoch ---
--- 1.1552848815917969 seconds for one epoch ---
--- 0.2878115177154541 seconds for one epoch ---
--- 1.1505982875823975 seconds for one epoch ---
--- 0.28995561599731445 seconds for one epoch ---
--- 1.1550495624542236 seconds for one epoch ---
--- 0.29035091400146484 seconds for one epoch ---
--- 1.1640899181365967 seconds for one epoch ---
--- 0.2915067672729492 seconds for one epoch ---
--- 1.1616077423095703 seconds for one epoch ---
--- 0.2950878143310547 seconds for one epoch ---
--- 1.1532886028289795 seconds for one epoch ---
--- 0.2940373420715332 seconds for one epoch ---
--- 1.1643829345703125 seconds for one epoch ---
--- 0.292858362197876 seconds for one epoch ---
--- 1.1746633052825928 seconds for one epoch ---
--- 0.29204559326171875 seconds for one epoch ---
--- 1.1576697826385498 seconds for one epoch ---
--- 0.28496623039245605 seconds for one epoch ---
--- 1.1618099212646484 seconds for one epoch ---
--- 0.2951395511627197 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99098235]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.465218]
 [ -0.      ]]
--- 0.2556290626525879 seconds for one epoch ---
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3428.8232421875, (1470.973, 1.9271369, 1955.5984, 0.32470542)
   validation loss 1047.942138671875, (734.2061, 0.16897707, 313.2423, 0.32470542)
decoder loss ratio: 28444.419561, decoder SINDy loss  ratio: 0.676178
--- 0.2810802459716797 seconds for one epoch ---
--- 1.150986909866333 seconds for one epoch ---
--- 0.2858583927154541 seconds for one epoch ---
--- 1.162064790725708 seconds for one epoch ---
--- 0.28911447525024414 seconds for one epoch ---
--- 1.1781189441680908 seconds for one epoch ---
--- 0.29378795623779297 seconds for one epoch ---
--- 1.1574687957763672 seconds for one epoch ---
--- 0.29011011123657227 seconds for one epoch ---
--- 1.168518304824829 seconds for one epoch ---
--- 0.27860546112060547 seconds for one epoch ---
--- 1.169799566268921 seconds for one epoch ---
--- 0.2850675582885742 seconds for one epoch ---
--- 1.1817858219146729 seconds for one epoch ---
--- 0.30542898178100586 seconds for one epoch ---
--- 1.1914691925048828 seconds for one epoch ---
--- 0.2755718231201172 seconds for one epoch ---
--- 1.197432279586792 seconds for one epoch ---
--- 0.28571295738220215 seconds for one epoch ---
--- 1.151538372039795 seconds for one epoch ---
--- 0.29067277908325195 seconds for one epoch ---
--- 1.1575467586517334 seconds for one epoch ---
--- 0.2783224582672119 seconds for one epoch ---
--- 1.1760048866271973 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99157387]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-11.592292]
 [  0.      ]]
--- 0.2845926284790039 seconds for one epoch ---
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3039.507568359375, (1410.9065, 1.552085, 1626.722, 0.32690793)
   validation loss 1317.7686767578125, (992.3723, 0.18757261, 324.8819, 0.32690793)
decoder loss ratio: 38446.226296, decoder SINDy loss  ratio: 0.701303
THRESHOLDING: 1 active coefficients
--- 1.172532081604004 seconds for one epoch ---
--- 0.2960045337677002 seconds for one epoch ---
--- 1.1551876068115234 seconds for one epoch ---
--- 0.29090142250061035 seconds for one epoch ---
--- 1.1650090217590332 seconds for one epoch ---
--- 0.2924022674560547 seconds for one epoch ---
--- 1.1755146980285645 seconds for one epoch ---
--- 0.28307175636291504 seconds for one epoch ---
--- 1.1690151691436768 seconds for one epoch ---
--- 0.29350829124450684 seconds for one epoch ---
--- 1.188020944595337 seconds for one epoch ---
--- 0.28510332107543945 seconds for one epoch ---
--- 1.2205109596252441 seconds for one epoch ---
--- 0.2879068851470947 seconds for one epoch ---
--- 1.1949613094329834 seconds for one epoch ---
--- 0.2957491874694824 seconds for one epoch ---
--- 1.1975278854370117 seconds for one epoch ---
--- 0.2942941188812256 seconds for one epoch ---
--- 1.2214131355285645 seconds for one epoch ---
--- 0.3064103126525879 seconds for one epoch ---
--- 1.2033483982086182 seconds for one epoch ---
--- 0.29076075553894043 seconds for one epoch ---
--- 1.188403606414795 seconds for one epoch ---
--- 0.28383708000183105 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9921703]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.730957]
 [  0.      ]]
--- 0.2557249069213867 seconds for one epoch ---
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3411.166259765625, (1482.1763, 0.24615556, 1928.4143, 0.32936952)
   validation loss 1211.95849609375, (866.30725, 0.1581034, 345.16376, 0.32936952)
decoder loss ratio: 33562.246878, decoder SINDy loss  ratio: 0.745085
--- 0.30347657203674316 seconds for one epoch ---
--- 1.1826491355895996 seconds for one epoch ---
--- 0.2965400218963623 seconds for one epoch ---
--- 1.19126558303833 seconds for one epoch ---
--- 0.290327787399292 seconds for one epoch ---
--- 1.1891250610351562 seconds for one epoch ---
--- 0.2862563133239746 seconds for one epoch ---
--- 1.1603491306304932 seconds for one epoch ---
--- 0.29288578033447266 seconds for one epoch ---
--- 1.1896171569824219 seconds for one epoch ---
--- 0.2890286445617676 seconds for one epoch ---
--- 1.1926932334899902 seconds for one epoch ---
--- 0.2963235378265381 seconds for one epoch ---
--- 1.199779748916626 seconds for one epoch ---
--- 0.2999422550201416 seconds for one epoch ---
--- 1.192147970199585 seconds for one epoch ---
--- 0.28573036193847656 seconds for one epoch ---
--- 1.2086095809936523 seconds for one epoch ---
--- 0.28736424446105957 seconds for one epoch ---
--- 1.1702680587768555 seconds for one epoch ---
--- 0.2991025447845459 seconds for one epoch ---
--- 1.1970012187957764 seconds for one epoch ---
--- 0.28874921798706055 seconds for one epoch ---
--- 1.1957676410675049 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9926243]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-11.8450165]
 [ -0.       ]]
--- 0.2925560474395752 seconds for one epoch ---
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4297.23193359375, (2665.961, 0.62801456, 1630.3118, 0.3314459)
   validation loss 2162.11376953125, (1777.2987, 0.18408947, 384.29944, 0.3314459)
decoder loss ratio: 68855.637399, decoder SINDy loss  ratio: 0.829564
--- 0.26072192192077637 seconds for one epoch ---
--- 0.29210686683654785 seconds for one epoch ---
--- 1.2122952938079834 seconds for one epoch ---
--- 0.2916450500488281 seconds for one epoch ---
--- 1.1892790794372559 seconds for one epoch ---
--- 0.289325475692749 seconds for one epoch ---
--- 1.2077975273132324 seconds for one epoch ---
--- 0.2895183563232422 seconds for one epoch ---
--- 1.2222862243652344 seconds for one epoch ---
--- 0.30716776847839355 seconds for one epoch ---
--- 1.209855556488037 seconds for one epoch ---
--- 0.2872958183288574 seconds for one epoch ---
--- 1.215066909790039 seconds for one epoch ---
--- 0.29209017753601074 seconds for one epoch ---
--- 1.215113639831543 seconds for one epoch ---
--- 0.30539631843566895 seconds for one epoch ---
--- 1.214695930480957 seconds for one epoch ---
--- 0.2993659973144531 seconds for one epoch ---
--- 1.2123403549194336 seconds for one epoch ---
--- 0.3034021854400635 seconds for one epoch ---
--- 1.2128126621246338 seconds for one epoch ---
--- 0.303450345993042 seconds for one epoch ---
--- 1.2191264629364014 seconds for one epoch ---
--- 0.29381394386291504 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9931499]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.987255]
 [ -0.      ]]
--- 0.250140905380249 seconds for one epoch ---
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2227.928466796875, (1178.5011, 4.5978427, 1044.4955, 0.33397734)
   validation loss 1273.00634765625, (927.87286, 0.12318215, 344.67633, 0.33397734)
decoder loss ratio: 35947.405601, decoder SINDy loss  ratio: 0.744032
--- 0.2811596393585205 seconds for one epoch ---
--- 1.2020347118377686 seconds for one epoch ---
--- 0.3007209300994873 seconds for one epoch ---
--- 1.2078492641448975 seconds for one epoch ---
--- 0.2901616096496582 seconds for one epoch ---
--- 1.1992144584655762 seconds for one epoch ---
--- 0.2829883098602295 seconds for one epoch ---
--- 1.2165095806121826 seconds for one epoch ---
--- 0.28561902046203613 seconds for one epoch ---
--- 1.23795485496521 seconds for one epoch ---
--- 0.2893178462982178 seconds for one epoch ---
--- 1.2027339935302734 seconds for one epoch ---
--- 0.3013734817504883 seconds for one epoch ---
--- 1.176363468170166 seconds for one epoch ---
--- 0.2909352779388428 seconds for one epoch ---
--- 1.2196292877197266 seconds for one epoch ---
--- 0.29779767990112305 seconds for one epoch ---
--- 1.238304853439331 seconds for one epoch ---
--- 0.2854461669921875 seconds for one epoch ---
--- 1.2088494300842285 seconds for one epoch ---
--- 0.29854726791381836 seconds for one epoch ---
--- 1.2355449199676514 seconds for one epoch ---
--- 0.30562901496887207 seconds for one epoch ---
--- 1.2333459854125977 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9935975]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.118422]
 [  0.      ]]
--- 0.29264187812805176 seconds for one epoch ---
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5258.0673828125, (1236.2173, 8.166917, 4013.347, 0.3362606)
   validation loss 1079.1126708984375, (750.5747, 0.13067304, 328.07104, 0.3362606)
decoder loss ratio: 29078.567205, decoder SINDy loss  ratio: 0.708187
--- 0.2454535961151123 seconds for one epoch ---
--- 0.2938423156738281 seconds for one epoch ---
--- 1.2285547256469727 seconds for one epoch ---
--- 0.29165029525756836 seconds for one epoch ---
--- 1.2403295040130615 seconds for one epoch ---
--- 0.29816174507141113 seconds for one epoch ---
--- 1.2320010662078857 seconds for one epoch ---
--- 0.28621888160705566 seconds for one epoch ---
--- 1.20892333984375 seconds for one epoch ---
--- 0.3077993392944336 seconds for one epoch ---
--- 1.2110092639923096 seconds for one epoch ---
--- 0.29753541946411133 seconds for one epoch ---
--- 1.2335617542266846 seconds for one epoch ---
--- 0.2946038246154785 seconds for one epoch ---
--- 1.2265594005584717 seconds for one epoch ---
--- 0.2937016487121582 seconds for one epoch ---
--- 1.226412296295166 seconds for one epoch ---
--- 0.29192543029785156 seconds for one epoch ---
--- 1.2308480739593506 seconds for one epoch ---
--- 0.2949337959289551 seconds for one epoch ---
--- 1.2280826568603516 seconds for one epoch ---
--- 0.29865217208862305 seconds for one epoch ---
--- 1.2380907535552979 seconds for one epoch ---
--- 0.29905128479003906 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9939492]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.229283]
 [ -0.      ]]
--- 0.258075475692749 seconds for one epoch ---
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5039.51318359375, (1431.0018, 2.1614919, 3606.0112, 0.33827716)
   validation loss 1047.28759765625, (748.7943, 0.20117675, 297.9539, 0.33827716)
decoder loss ratio: 29009.591593, decoder SINDy loss  ratio: 0.643175
--- 0.29069018363952637 seconds for one epoch ---
--- 1.233837604522705 seconds for one epoch ---
--- 0.2913546562194824 seconds for one epoch ---
--- 1.2565653324127197 seconds for one epoch ---
--- 0.29648280143737793 seconds for one epoch ---
--- 1.2306861877441406 seconds for one epoch ---
--- 0.2985529899597168 seconds for one epoch ---
--- 1.2315998077392578 seconds for one epoch ---
--- 0.2966136932373047 seconds for one epoch ---
--- 1.2450685501098633 seconds for one epoch ---
--- 0.2929997444152832 seconds for one epoch ---
--- 1.2112197875976562 seconds for one epoch ---
--- 0.2882387638092041 seconds for one epoch ---
--- 1.2357230186462402 seconds for one epoch ---
--- 0.28830695152282715 seconds for one epoch ---
--- 1.2732677459716797 seconds for one epoch ---
--- 0.2924153804779053 seconds for one epoch ---
--- 1.2457025051116943 seconds for one epoch ---
--- 0.2897653579711914 seconds for one epoch ---
--- 1.2463021278381348 seconds for one epoch ---
--- 0.29483604431152344 seconds for one epoch ---
--- 1.254702091217041 seconds for one epoch ---
--- 0.29251527786254883 seconds for one epoch ---
--- 1.2398350238800049 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99426883]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.336613]
 [  0.      ]]
--- 0.27935290336608887 seconds for one epoch ---
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3316.373779296875, (1147.5269, 2.2075567, 2166.299, 0.34025264)
   validation loss 1289.130859375, (935.6185, 0.12335135, 353.0488, 0.34025264)
decoder loss ratio: 36247.486168, decoder SINDy loss  ratio: 0.762105
--- 0.2518434524536133 seconds for one epoch ---
--- 0.28744029998779297 seconds for one epoch ---
--- 1.2441201210021973 seconds for one epoch ---
--- 0.2822730541229248 seconds for one epoch ---
--- 1.2489981651306152 seconds for one epoch ---
--- 0.29660773277282715 seconds for one epoch ---
--- 1.2510075569152832 seconds for one epoch ---
--- 0.2913994789123535 seconds for one epoch ---
--- 1.2396092414855957 seconds for one epoch ---
--- 0.28914976119995117 seconds for one epoch ---
--- 1.2302789688110352 seconds for one epoch ---
--- 0.29499125480651855 seconds for one epoch ---
--- 1.2905890941619873 seconds for one epoch ---
--- 0.28151798248291016 seconds for one epoch ---
--- 1.2570831775665283 seconds for one epoch ---
--- 0.2941710948944092 seconds for one epoch ---
--- 1.280430555343628 seconds for one epoch ---
--- 0.27865147590637207 seconds for one epoch ---
--- 1.26114821434021 seconds for one epoch ---
--- 0.29587697982788086 seconds for one epoch ---
--- 1.2412004470825195 seconds for one epoch ---
--- 0.2891724109649658 seconds for one epoch ---
--- 1.2721898555755615 seconds for one epoch ---
--- 0.28195714950561523 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99459827]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.454736]
 [  0.      ]]
--- 0.24794864654541016 seconds for one epoch ---
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2570.98095703125, (1232.1696, 1.2326504, 1337.2362, 0.34246364)
   validation loss 852.1737670898438, (552.98627, 0.15974994, 298.68533, 0.34246364)
decoder loss ratio: 21423.648013, decoder SINDy loss  ratio: 0.644754
--- 0.28675150871276855 seconds for one epoch ---
--- 1.2482483386993408 seconds for one epoch ---
--- 0.29227638244628906 seconds for one epoch ---
--- 1.2705597877502441 seconds for one epoch ---
--- 0.2929224967956543 seconds for one epoch ---
--- 1.2726953029632568 seconds for one epoch ---
--- 0.2866535186767578 seconds for one epoch ---
--- 1.2752315998077393 seconds for one epoch ---
--- 0.2922937870025635 seconds for one epoch ---
--- 1.2848691940307617 seconds for one epoch ---
--- 0.29389142990112305 seconds for one epoch ---
--- 1.2579312324523926 seconds for one epoch ---
--- 0.2971010208129883 seconds for one epoch ---
--- 1.2620463371276855 seconds for one epoch ---
--- 0.28255534172058105 seconds for one epoch ---
--- 1.2690961360931396 seconds for one epoch ---
--- 0.2848341464996338 seconds for one epoch ---
--- 1.2951483726501465 seconds for one epoch ---
--- 0.29831814765930176 seconds for one epoch ---
--- 1.2810378074645996 seconds for one epoch ---
--- 0.2817728519439697 seconds for one epoch ---
--- 1.2704572677612305 seconds for one epoch ---
--- 0.2964351177215576 seconds for one epoch ---
--- 1.2928171157836914 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9949204]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.578435]
 [ -0.      ]]
--- 0.28336429595947266 seconds for one epoch ---
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2649.22998046875, (1272.8495, 3.6657295, 1372.37, 0.34464458)
   validation loss 898.5667724609375, (592.9617, 0.2218601, 305.03857, 0.34464458)
decoder loss ratio: 22972.364520, decoder SINDy loss  ratio: 0.658469
--- 0.24816274642944336 seconds for one epoch ---
--- 0.3044013977050781 seconds for one epoch ---
--- 1.2911574840545654 seconds for one epoch ---
--- 0.2981126308441162 seconds for one epoch ---
--- 1.2932937145233154 seconds for one epoch ---
--- 0.30250000953674316 seconds for one epoch ---
--- 1.3063035011291504 seconds for one epoch ---
--- 0.2856628894805908 seconds for one epoch ---
--- 1.2579097747802734 seconds for one epoch ---
--- 0.28551554679870605 seconds for one epoch ---
--- 1.279601812362671 seconds for one epoch ---
--- 0.29065513610839844 seconds for one epoch ---
--- 1.3128743171691895 seconds for one epoch ---
--- 0.28572630882263184 seconds for one epoch ---
--- 1.2793207168579102 seconds for one epoch ---
--- 0.2969059944152832 seconds for one epoch ---
--- 1.299720287322998 seconds for one epoch ---
--- 0.29836153984069824 seconds for one epoch ---
--- 1.3187100887298584 seconds for one epoch ---
--- 0.28392696380615234 seconds for one epoch ---
--- 1.292231559753418 seconds for one epoch ---
--- 0.2837190628051758 seconds for one epoch ---
--- 1.3012313842773438 seconds for one epoch ---
--- 0.2889997959136963 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9952159]
 [0.       ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-12.7003765]
 [ -0.       ]]
--- 0.2619163990020752 seconds for one epoch ---
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2587.746337890625, (1198.5747, 3.798071, 1385.0265, 0.34704277)
   validation loss 768.0400390625, (471.93753, 0.23537016, 295.52008, 0.34704277)
decoder loss ratio: 18283.679252, decoder SINDy loss  ratio: 0.637922
--- 0.2972586154937744 seconds for one epoch ---
--- 1.2842321395874023 seconds for one epoch ---
--- 0.3198096752166748 seconds for one epoch ---
--- 1.2815406322479248 seconds for one epoch ---
--- 0.2924995422363281 seconds for one epoch ---
--- 1.2984142303466797 seconds for one epoch ---
--- 0.29887866973876953 seconds for one epoch ---
--- 1.2985949516296387 seconds for one epoch ---
--- 0.31711721420288086 seconds for one epoch ---
--- 1.2817959785461426 seconds for one epoch ---
--- 0.2893412113189697 seconds for one epoch ---
--- 1.2933423519134521 seconds for one epoch ---
--- 0.2938714027404785 seconds for one epoch ---
--- 1.2764523029327393 seconds for one epoch ---
--- 0.3105340003967285 seconds for one epoch ---
--- 1.3122894763946533 seconds for one epoch ---
--- 0.2916238307952881 seconds for one epoch ---
--- 1.2992908954620361 seconds for one epoch ---
--- 0.2915513515472412 seconds for one epoch ---
--- 1.3184964656829834 seconds for one epoch ---
--- 0.2854335308074951 seconds for one epoch ---
--- 1.2788190841674805 seconds for one epoch ---
--- 0.289215087890625 seconds for one epoch ---
--- 1.3123846054077148 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99548626]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.819635]
 [  0.      ]]
--- 0.2887270450592041 seconds for one epoch ---
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4504.48193359375, (1658.9777, 1.0433763, 2844.1118, 0.34923792)
   validation loss 1410.0155029296875, (1081.2711, 0.22139926, 328.17365, 0.34923792)
decoder loss ratio: 41890.320287, decoder SINDy loss  ratio: 0.708409
--- 0.2596414089202881 seconds for one epoch ---
--- 0.2883124351501465 seconds for one epoch ---
--- 1.2818317413330078 seconds for one epoch ---
--- 0.2883148193359375 seconds for one epoch ---
--- 1.3096890449523926 seconds for one epoch ---
--- 0.29641151428222656 seconds for one epoch ---
--- 1.3144547939300537 seconds for one epoch ---
--- 0.293581485748291 seconds for one epoch ---
--- 1.3141469955444336 seconds for one epoch ---
--- 0.29916834831237793 seconds for one epoch ---
--- 1.2618114948272705 seconds for one epoch ---
--- 0.2928917407989502 seconds for one epoch ---
--- 1.3002517223358154 seconds for one epoch ---
--- 0.2883636951446533 seconds for one epoch ---
--- 1.284717082977295 seconds for one epoch ---
--- 0.30713963508605957 seconds for one epoch ---
--- 1.3059825897216797 seconds for one epoch ---
--- 0.2931382656097412 seconds for one epoch ---
--- 1.3283710479736328 seconds for one epoch ---
--- 0.2963063716888428 seconds for one epoch ---
--- 1.3181812763214111 seconds for one epoch ---
--- 0.27827954292297363 seconds for one epoch ---
--- 1.3222694396972656 seconds for one epoch ---
--- 0.2901632785797119 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9956704]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.905799]
 [ -0.      ]]
--- 0.2548046112060547 seconds for one epoch ---
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5376.64697265625, (2678.48, 2.320158, 2695.4956, 0.35086384)
   validation loss 862.161865234375, (572.12933, 0.20815139, 289.4735, 0.35086384)
decoder loss ratio: 22165.283640, decoder SINDy loss  ratio: 0.624869
--- 0.30373597145080566 seconds for one epoch ---
--- 1.3218677043914795 seconds for one epoch ---
--- 0.2846333980560303 seconds for one epoch ---
--- 1.3262648582458496 seconds for one epoch ---
--- 0.29250502586364746 seconds for one epoch ---
--- 1.3233580589294434 seconds for one epoch ---
--- 0.29689645767211914 seconds for one epoch ---
--- 1.3268632888793945 seconds for one epoch ---
--- 0.29746127128601074 seconds for one epoch ---
--- 1.3068418502807617 seconds for one epoch ---
--- 0.27218174934387207 seconds for one epoch ---
--- 1.3320491313934326 seconds for one epoch ---
--- 0.2892265319824219 seconds for one epoch ---
--- 1.2916972637176514 seconds for one epoch ---
--- 0.2863800525665283 seconds for one epoch ---
--- 1.322173833847046 seconds for one epoch ---
--- 0.29328465461730957 seconds for one epoch ---
--- 1.319077491760254 seconds for one epoch ---
--- 0.3066534996032715 seconds for one epoch ---
--- 1.305901288986206 seconds for one epoch ---
--- 0.29029369354248047 seconds for one epoch ---
--- 1.3398456573486328 seconds for one epoch ---
--- 0.28923535346984863 seconds for one epoch ---
--- 1.329376220703125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99587274]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.005648]
 [  0.      ]]
--- 0.28775501251220703 seconds for one epoch ---
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1832.30908203125, (842.1823, 2.1778471, 987.59607, 0.35279748)
   validation loss 897.9110107421875, (567.44196, 0.1813309, 329.93497, 0.35279748)
decoder loss ratio: 21983.686481, decoder SINDy loss  ratio: 0.712211
--- 0.25948286056518555 seconds for one epoch ---
--- 0.2948801517486572 seconds for one epoch ---
--- 1.3040595054626465 seconds for one epoch ---
--- 0.2935769557952881 seconds for one epoch ---
--- 1.3258719444274902 seconds for one epoch ---
--- 0.29133176803588867 seconds for one epoch ---
--- 1.347459077835083 seconds for one epoch ---
--- 0.29575490951538086 seconds for one epoch ---
--- 1.3115968704223633 seconds for one epoch ---
--- 0.29541945457458496 seconds for one epoch ---
--- 1.3251993656158447 seconds for one epoch ---
--- 0.28812074661254883 seconds for one epoch ---
--- 1.3347275257110596 seconds for one epoch ---
--- 0.29387664794921875 seconds for one epoch ---
--- 1.3350963592529297 seconds for one epoch ---
--- 0.29595255851745605 seconds for one epoch ---
--- 1.3306808471679688 seconds for one epoch ---
--- 0.2787148952484131 seconds for one epoch ---
--- 1.3439075946807861 seconds for one epoch ---
--- 0.5273993015289307 seconds for one epoch ---
--- 1.3494048118591309 seconds for one epoch ---
--- 0.3076653480529785 seconds for one epoch ---
--- 1.3530879020690918 seconds for one epoch ---
--- 0.29396653175354004 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99607635]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-13.11173]
 [  0.     ]]
--- 0.2549891471862793 seconds for one epoch ---
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3056.027099609375, (1177.2871, 3.327329, 1875.058, 0.35474664)
   validation loss 884.9876098632812, (559.2727, 0.20700142, 325.15314, 0.35474664)
decoder loss ratio: 21667.195535, decoder SINDy loss  ratio: 0.701889
--- 0.29819583892822266 seconds for one epoch ---
--- 1.3216242790222168 seconds for one epoch ---
--- 0.2945749759674072 seconds for one epoch ---
--- 1.3209009170532227 seconds for one epoch ---
--- 0.2884187698364258 seconds for one epoch ---
--- 1.3300750255584717 seconds for one epoch ---
--- 0.2985107898712158 seconds for one epoch ---
--- 1.3528897762298584 seconds for one epoch ---
--- 0.29758262634277344 seconds for one epoch ---
--- 1.3402295112609863 seconds for one epoch ---
--- 0.2883024215698242 seconds for one epoch ---
--- 1.3434207439422607 seconds for one epoch ---
--- 0.2906613349914551 seconds for one epoch ---
--- 1.312424659729004 seconds for one epoch ---
--- 0.29630041122436523 seconds for one epoch ---
--- 1.340714693069458 seconds for one epoch ---
--- 0.2903103828430176 seconds for one epoch ---
--- 1.3439056873321533 seconds for one epoch ---
--- 0.30171847343444824 seconds for one epoch ---
--- 1.3439531326293945 seconds for one epoch ---
--- 0.2996692657470703 seconds for one epoch ---
--- 1.338749647140503 seconds for one epoch ---
--- 0.2931091785430908 seconds for one epoch ---
--- 1.3292384147644043 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9962995]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.236246]
 [ -0.      ]]
--- 0.2834632396697998 seconds for one epoch ---
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2336.332763671875, (1367.21, 1.0328398, 967.7327, 0.35723588)
   validation loss 1278.106689453125, (961.9052, 0.33418503, 315.51016, 0.35723588)
decoder loss ratio: 37265.877869, decoder SINDy loss  ratio: 0.681073
--- 0.25080132484436035 seconds for one epoch ---
--- 0.2836313247680664 seconds for one epoch ---
--- 1.310490608215332 seconds for one epoch ---
--- 0.299102783203125 seconds for one epoch ---
--- 1.3398025035858154 seconds for one epoch ---
--- 0.28136563301086426 seconds for one epoch ---
--- 1.3581414222717285 seconds for one epoch ---
--- 0.28993940353393555 seconds for one epoch ---
--- 1.3397130966186523 seconds for one epoch ---
--- 0.2931649684906006 seconds for one epoch ---
--- 1.3451156616210938 seconds for one epoch ---
--- 0.28536295890808105 seconds for one epoch ---
--- 1.3357794284820557 seconds for one epoch ---
--- 0.2896265983581543 seconds for one epoch ---
--- 1.3253726959228516 seconds for one epoch ---
--- 0.2919158935546875 seconds for one epoch ---
--- 1.3590421676635742 seconds for one epoch ---
--- 0.2807955741882324 seconds for one epoch ---
--- 1.3373870849609375 seconds for one epoch ---
--- 0.2948169708251953 seconds for one epoch ---
--- 1.3646183013916016 seconds for one epoch ---
--- 0.2905457019805908 seconds for one epoch ---
--- 1.3816473484039307 seconds for one epoch ---
--- 0.28949904441833496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99645835]
 [0.        ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-13.3299885]
 [ -0.       ]]
--- 0.2443547248840332 seconds for one epoch ---
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2645.51025390625, (1333.3938, 2.06493, 1309.6925, 0.3589525)
   validation loss 911.1873779296875, (604.1597, 0.21147309, 306.4572, 0.3589525)
decoder loss ratio: 23406.196769, decoder SINDy loss  ratio: 0.661531
--- 0.2768418788909912 seconds for one epoch ---
--- 1.3200407028198242 seconds for one epoch ---
--- 0.2855048179626465 seconds for one epoch ---
--- 1.3486781120300293 seconds for one epoch ---
--- 0.2839820384979248 seconds for one epoch ---
--- 1.3617064952850342 seconds for one epoch ---
--- 0.2816123962402344 seconds for one epoch ---
--- 1.3412818908691406 seconds for one epoch ---
--- 0.27844905853271484 seconds for one epoch ---
--- 1.3440768718719482 seconds for one epoch ---
--- 0.2942984104156494 seconds for one epoch ---
--- 1.341665506362915 seconds for one epoch ---
--- 0.29539036750793457 seconds for one epoch ---
--- 1.3439135551452637 seconds for one epoch ---
--- 0.2869555950164795 seconds for one epoch ---
--- 1.3540494441986084 seconds for one epoch ---
--- 0.28496789932250977 seconds for one epoch ---
--- 1.3583345413208008 seconds for one epoch ---
--- 0.3030364513397217 seconds for one epoch ---
--- 1.344048023223877 seconds for one epoch ---
--- 0.28310155868530273 seconds for one epoch ---
--- 1.3648796081542969 seconds for one epoch ---
--- 0.2734715938568115 seconds for one epoch ---
--- 1.3672127723693848 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99663067]
 [0.        ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-13.4378805]
 [  0.       ]]
--- 0.29202699661254883 seconds for one epoch ---
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3641.513427734375, (832.3179, 1.3930215, 2807.4414, 0.3611032)
   validation loss 970.9224243164062, (641.81104, 0.18119965, 328.5691, 0.3611032)
decoder loss ratio: 24864.873735, decoder SINDy loss  ratio: 0.709263
--- 0.24666976928710938 seconds for one epoch ---
--- 0.29349398612976074 seconds for one epoch ---
--- 1.3484387397766113 seconds for one epoch ---
--- 0.291947603225708 seconds for one epoch ---
--- 1.3414585590362549 seconds for one epoch ---
--- 0.2956058979034424 seconds for one epoch ---
--- 1.3714931011199951 seconds for one epoch ---
--- 0.27456188201904297 seconds for one epoch ---
--- 1.3358359336853027 seconds for one epoch ---
--- 0.28891682624816895 seconds for one epoch ---
--- 1.354602575302124 seconds for one epoch ---
--- 0.30414843559265137 seconds for one epoch ---
--- 1.3983933925628662 seconds for one epoch ---
--- 0.2937657833099365 seconds for one epoch ---
--- 1.3987352848052979 seconds for one epoch ---
--- 0.3002471923828125 seconds for one epoch ---
--- 1.378739833831787 seconds for one epoch ---
--- 0.3124384880065918 seconds for one epoch ---
--- 1.3658902645111084 seconds for one epoch ---
--- 0.283951997756958 seconds for one epoch ---
--- 1.4001274108886719 seconds for one epoch ---
--- 0.2936711311340332 seconds for one epoch ---
--- 1.3926570415496826 seconds for one epoch ---
--- 0.292999267578125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99678206]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.537714]
 [ -0.      ]]
--- 0.2541782855987549 seconds for one epoch ---
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3979.260986328125, (2273.4067, 1.130698, 1704.3606, 0.36311015)
   validation loss 1261.007080078125, (911.03577, 0.19164321, 349.41647, 0.36311015)
decoder loss ratio: 35295.107226, decoder SINDy loss  ratio: 0.754265
--- 0.2876594066619873 seconds for one epoch ---
--- 1.3553571701049805 seconds for one epoch ---
--- 0.29343199729919434 seconds for one epoch ---
--- 1.3720190525054932 seconds for one epoch ---
--- 0.2958557605743408 seconds for one epoch ---
--- 1.3638277053833008 seconds for one epoch ---
--- 0.2849099636077881 seconds for one epoch ---
--- 1.3603427410125732 seconds for one epoch ---
--- 0.2912111282348633 seconds for one epoch ---
--- 1.4001471996307373 seconds for one epoch ---
--- 0.28978514671325684 seconds for one epoch ---
--- 1.3845114707946777 seconds for one epoch ---
--- 0.2862553596496582 seconds for one epoch ---
--- 1.3888812065124512 seconds for one epoch ---
--- 0.28864622116088867 seconds for one epoch ---
--- 1.4041080474853516 seconds for one epoch ---
--- 0.2853207588195801 seconds for one epoch ---
--- 1.3754093647003174 seconds for one epoch ---
--- 0.2744140625 seconds for one epoch ---
--- 1.3672099113464355 seconds for one epoch ---
--- 0.31107354164123535 seconds for one epoch ---
--- 1.3980309963226318 seconds for one epoch ---
--- 0.2973020076751709 seconds for one epoch ---
--- 1.4050414562225342 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99692583]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.638159]
 [  0.      ]]
--- 0.29465603828430176 seconds for one epoch ---
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2519.10009765625, (1355.1609, 0.41275385, 1163.1611, 0.36512542)
   validation loss 847.6187133789062, (547.3635, 0.27164248, 299.6184, 0.36512542)
decoder loss ratio: 21205.813239, decoder SINDy loss  ratio: 0.646768
--- 0.2481226921081543 seconds for one epoch ---
--- 0.29305052757263184 seconds for one epoch ---
--- 1.4145123958587646 seconds for one epoch ---
--- 0.32579970359802246 seconds for one epoch ---
--- 1.3713819980621338 seconds for one epoch ---
--- 0.28322601318359375 seconds for one epoch ---
--- 1.4046051502227783 seconds for one epoch ---
--- 0.2995481491088867 seconds for one epoch ---
--- 1.39503812789917 seconds for one epoch ---
--- 0.31700968742370605 seconds for one epoch ---
--- 1.3985531330108643 seconds for one epoch ---
--- 0.2995305061340332 seconds for one epoch ---
--- 1.4107043743133545 seconds for one epoch ---
--- 0.29210400581359863 seconds for one epoch ---
--- 1.3901102542877197 seconds for one epoch ---
--- 0.2944309711456299 seconds for one epoch ---
--- 1.3843772411346436 seconds for one epoch ---
--- 0.29256319999694824 seconds for one epoch ---
--- 1.384610891342163 seconds for one epoch ---
--- 0.2767636775970459 seconds for one epoch ---
--- 1.385159969329834 seconds for one epoch ---
--- 0.2965271472930908 seconds for one epoch ---
--- 1.3899471759796143 seconds for one epoch ---
--- 0.2975766658782959 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.997059]
 [0.      ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-13.7367115]
 [  0.       ]]
--- 0.24448657035827637 seconds for one epoch ---
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2416.723876953125, (1177.0074, 0.800585, 1238.5488, 0.36706242)
   validation loss 1117.952880859375, (810.87665, 0.25451586, 306.45468, 0.36706242)
decoder loss ratio: 31414.769085, decoder SINDy loss  ratio: 0.661526
--- 0.28588008880615234 seconds for one epoch ---
--- 1.3953595161437988 seconds for one epoch ---
--- 0.29190611839294434 seconds for one epoch ---
--- 1.4076497554779053 seconds for one epoch ---
--- 0.295330286026001 seconds for one epoch ---
--- 1.3931512832641602 seconds for one epoch ---
--- 0.31830477714538574 seconds for one epoch ---
--- 1.3981294631958008 seconds for one epoch ---
--- 0.27658867835998535 seconds for one epoch ---
--- 1.409839391708374 seconds for one epoch ---
--- 0.28368687629699707 seconds for one epoch ---
--- 1.4308686256408691 seconds for one epoch ---
--- 0.2851548194885254 seconds for one epoch ---
--- 1.3870484828948975 seconds for one epoch ---
--- 0.2957589626312256 seconds for one epoch ---
--- 1.4028303623199463 seconds for one epoch ---
--- 0.2904360294342041 seconds for one epoch ---
--- 1.4198620319366455 seconds for one epoch ---
--- 0.29077863693237305 seconds for one epoch ---
--- 1.3863649368286133 seconds for one epoch ---
--- 0.2904088497161865 seconds for one epoch ---
--- 1.4048364162445068 seconds for one epoch ---
--- 0.27910351753234863 seconds for one epoch ---
--- 1.3943467140197754 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9971998]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.846632]
 [ -0.      ]]
--- 0.2844829559326172 seconds for one epoch ---
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1567.6351318359375, (727.4799, 1.3035758, 838.4824, 0.36926123)
   validation loss 973.6783447265625, (663.57513, 0.25180465, 309.4821, 0.36926123)
decoder loss ratio: 25708.052719, decoder SINDy loss  ratio: 0.668061
THRESHOLDING: 1 active coefficients
--- 1.3832228183746338 seconds for one epoch ---
--- 0.2967088222503662 seconds for one epoch ---
--- 1.391920804977417 seconds for one epoch ---
--- 0.293198823928833 seconds for one epoch ---
--- 1.4244911670684814 seconds for one epoch ---
--- 0.2940695285797119 seconds for one epoch ---
--- 1.412773609161377 seconds for one epoch ---
--- 0.2922806739807129 seconds for one epoch ---
--- 1.4295704364776611 seconds for one epoch ---
--- 0.2837059497833252 seconds for one epoch ---
--- 1.4370334148406982 seconds for one epoch ---
--- 0.28912997245788574 seconds for one epoch ---
--- 1.4247221946716309 seconds for one epoch ---
--- 0.29574084281921387 seconds for one epoch ---
--- 1.4112024307250977 seconds for one epoch ---
--- 0.2824423313140869 seconds for one epoch ---
--- 1.443854570388794 seconds for one epoch ---
--- 0.29636549949645996 seconds for one epoch ---
--- 1.4236624240875244 seconds for one epoch ---
--- 0.297532320022583 seconds for one epoch ---
--- 1.4434492588043213 seconds for one epoch ---
--- 0.299363374710083 seconds for one epoch ---
--- 1.4132609367370605 seconds for one epoch ---
--- 0.28507161140441895 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99729836]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.927487]
 [ -0.      ]]
--- 0.2554764747619629 seconds for one epoch ---
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3957.40380859375, (1358.8158, 3.3886354, 2594.8284, 0.3709925)
   validation loss 919.4420166015625, (627.2433, 0.23588766, 291.59186, 0.3709925)
decoder loss ratio: 24300.493847, decoder SINDy loss  ratio: 0.629442
--- 0.28239870071411133 seconds for one epoch ---
--- 1.4078078269958496 seconds for one epoch ---
--- 0.29527759552001953 seconds for one epoch ---
--- 1.4405269622802734 seconds for one epoch ---
--- 0.29954004287719727 seconds for one epoch ---
--- 1.4307832717895508 seconds for one epoch ---
--- 0.2885603904724121 seconds for one epoch ---
--- 1.4301860332489014 seconds for one epoch ---
--- 0.2980682849884033 seconds for one epoch ---
--- 1.4234507083892822 seconds for one epoch ---
--- 0.2985708713531494 seconds for one epoch ---
--- 1.3949131965637207 seconds for one epoch ---
--- 0.30176734924316406 seconds for one epoch ---
--- 1.4184420108795166 seconds for one epoch ---
--- 0.29291200637817383 seconds for one epoch ---
--- 1.4253695011138916 seconds for one epoch ---
--- 0.2867593765258789 seconds for one epoch ---
--- 1.4116506576538086 seconds for one epoch ---
--- 0.28908681869506836 seconds for one epoch ---
--- 1.410010814666748 seconds for one epoch ---
--- 0.31147003173828125 seconds for one epoch ---
--- 1.4420757293701172 seconds for one epoch ---
--- 0.28787684440612793 seconds for one epoch ---
--- 1.4414241313934326 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99739766]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.012965]
 [  0.      ]]
--- 0.29930591583251953 seconds for one epoch ---
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3414.889892578125, (1745.5945, 2.0703406, 1666.8522, 0.3727194)
   validation loss 844.4337768554688, (529.37604, 0.24234858, 314.44266, 0.3727194)
decoder loss ratio: 20508.946734, decoder SINDy loss  ratio: 0.678769
--- 0.27695679664611816 seconds for one epoch ---
--- 0.3020172119140625 seconds for one epoch ---
--- 1.412642478942871 seconds for one epoch ---
--- 0.2949702739715576 seconds for one epoch ---
--- 1.4342663288116455 seconds for one epoch ---
--- 0.2880380153656006 seconds for one epoch ---
--- 1.444521188735962 seconds for one epoch ---
--- 0.2953763008117676 seconds for one epoch ---
--- 1.440237283706665 seconds for one epoch ---
--- 0.30046916007995605 seconds for one epoch ---
--- 1.453730583190918 seconds for one epoch ---
--- 0.2945137023925781 seconds for one epoch ---
--- 1.4462835788726807 seconds for one epoch ---
--- 0.29719066619873047 seconds for one epoch ---
--- 1.4356160163879395 seconds for one epoch ---
--- 0.2997307777404785 seconds for one epoch ---
--- 1.4511160850524902 seconds for one epoch ---
--- 0.2908637523651123 seconds for one epoch ---
--- 1.4334123134613037 seconds for one epoch ---
--- 0.2943441867828369 seconds for one epoch ---
--- 1.4454290866851807 seconds for one epoch ---
--- 0.31899476051330566 seconds for one epoch ---
--- 1.4370524883270264 seconds for one epoch ---
--- 0.298999547958374 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.997494]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.099193]
 [ -0.      ]]
--- 0.2500283718109131 seconds for one epoch ---
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2792.90576171875, (1131.1027, 1.1791515, 1660.2494, 0.37458298)
   validation loss 821.3969116210938, (513.97504, 0.20174912, 306.84555, 0.37458298)
decoder loss ratio: 19912.285219, decoder SINDy loss  ratio: 0.662369
--- 0.28774452209472656 seconds for one epoch ---
--- 1.4761888980865479 seconds for one epoch ---
--- 0.2949965000152588 seconds for one epoch ---
--- 1.4100234508514404 seconds for one epoch ---
--- 0.28185510635375977 seconds for one epoch ---
--- 1.4315640926361084 seconds for one epoch ---
--- 0.29370570182800293 seconds for one epoch ---
--- 1.4491548538208008 seconds for one epoch ---
--- 0.2900691032409668 seconds for one epoch ---
--- 1.4325637817382812 seconds for one epoch ---
--- 0.29419827461242676 seconds for one epoch ---
--- 1.4549369812011719 seconds for one epoch ---
--- 0.32512593269348145 seconds for one epoch ---
--- 1.4747302532196045 seconds for one epoch ---
--- 0.28690123558044434 seconds for one epoch ---
--- 1.4868342876434326 seconds for one epoch ---
--- 0.30045032501220703 seconds for one epoch ---
--- 1.4777040481567383 seconds for one epoch ---
--- 0.28957629203796387 seconds for one epoch ---
--- 1.4555859565734863 seconds for one epoch ---
--- 0.2951970100402832 seconds for one epoch ---
--- 1.4682719707489014 seconds for one epoch ---
--- 0.29703712463378906 seconds for one epoch ---
--- 1.4675054550170898 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9975856]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.184894]
 [  0.      ]]
--- 0.28426170349121094 seconds for one epoch ---
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3459.89599609375, (995.8693, 5.0981984, 2458.5522, 0.37629935)
   validation loss 789.948486328125, (499.0361, 0.23971206, 290.2964, 0.37629935)
decoder loss ratio: 19333.524968, decoder SINDy loss  ratio: 0.626646
--- 0.2605764865875244 seconds for one epoch ---
--- 0.27940917015075684 seconds for one epoch ---
--- 1.4566726684570312 seconds for one epoch ---
--- 0.295076847076416 seconds for one epoch ---
--- 1.4765942096710205 seconds for one epoch ---
--- 0.29573512077331543 seconds for one epoch ---
--- 1.4442565441131592 seconds for one epoch ---
--- 0.29421257972717285 seconds for one epoch ---
--- 1.4625062942504883 seconds for one epoch ---
--- 0.3068382740020752 seconds for one epoch ---
--- 1.4371893405914307 seconds for one epoch ---
--- 0.2807285785675049 seconds for one epoch ---
--- 1.4371743202209473 seconds for one epoch ---
--- 0.29843640327453613 seconds for one epoch ---
--- 1.4695086479187012 seconds for one epoch ---
--- 0.2940351963043213 seconds for one epoch ---
--- 1.479097604751587 seconds for one epoch ---
--- 0.3175365924835205 seconds for one epoch ---
--- 1.4646592140197754 seconds for one epoch ---
--- 0.2985363006591797 seconds for one epoch ---
--- 1.4656710624694824 seconds for one epoch ---
--- 0.28237438201904297 seconds for one epoch ---
--- 1.4485795497894287 seconds for one epoch ---
--- 0.29081082344055176 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976765]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.274183]
 [  0.      ]]
--- 0.2411670684814453 seconds for one epoch ---
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3082.647216796875, (1454.2125, 0.5112166, 1627.5454, 0.37806624)
   validation loss 1250.3807373046875, (880.40576, 0.17410165, 369.42285, 0.37806624)
decoder loss ratio: 34108.447661, decoder SINDy loss  ratio: 0.797451
--- 0.2785458564758301 seconds for one epoch ---
--- 1.4497778415679932 seconds for one epoch ---
--- 0.28663086891174316 seconds for one epoch ---
--- 1.4621012210845947 seconds for one epoch ---
--- 0.2890896797180176 seconds for one epoch ---
--- 1.4681825637817383 seconds for one epoch ---
--- 0.28978466987609863 seconds for one epoch ---
--- 1.4875807762145996 seconds for one epoch ---
--- 0.30208635330200195 seconds for one epoch ---
--- 1.4704689979553223 seconds for one epoch ---
--- 0.30069732666015625 seconds for one epoch ---
--- 1.5023233890533447 seconds for one epoch ---
--- 0.3245725631713867 seconds for one epoch ---
--- 1.46174955368042 seconds for one epoch ---
--- 0.3036940097808838 seconds for one epoch ---
--- 1.4944732189178467 seconds for one epoch ---
--- 0.29698777198791504 seconds for one epoch ---
--- 1.5004518032073975 seconds for one epoch ---
--- 0.2922389507293701 seconds for one epoch ---
--- 1.4726614952087402 seconds for one epoch ---
--- 0.30362462997436523 seconds for one epoch ---
--- 1.4794549942016602 seconds for one epoch ---
--- 0.30069541931152344 seconds for one epoch ---
--- 1.4589838981628418 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99775743]
 [0.        ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [-14.3577585]
 [ -0.       ]]
--- 0.2902843952178955 seconds for one epoch ---
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2454.979736328125, (1289.5918, 4.002816, 1161.0052, 0.37989625)
   validation loss 1184.5343017578125, (813.7325, 0.1398316, 370.28214, 0.37989625)
decoder loss ratio: 31525.409090, decoder SINDy loss  ratio: 0.799306
--- 0.25290417671203613 seconds for one epoch ---
--- 0.29291462898254395 seconds for one epoch ---
--- 1.4990017414093018 seconds for one epoch ---
--- 0.2856912612915039 seconds for one epoch ---
--- 1.484675407409668 seconds for one epoch ---
--- 0.2989327907562256 seconds for one epoch ---
--- 1.486283302307129 seconds for one epoch ---
--- 0.29111194610595703 seconds for one epoch ---
--- 1.4630489349365234 seconds for one epoch ---
--- 0.296689510345459 seconds for one epoch ---
--- 1.473038673400879 seconds for one epoch ---
--- 0.2911355495452881 seconds for one epoch ---
--- 1.4894530773162842 seconds for one epoch ---
--- 0.2945270538330078 seconds for one epoch ---
--- 1.4766910076141357 seconds for one epoch ---
--- 0.29514455795288086 seconds for one epoch ---
--- 1.4736912250518799 seconds for one epoch ---
--- 0.2985246181488037 seconds for one epoch ---
--- 1.478501558303833 seconds for one epoch ---
--- 0.2966737747192383 seconds for one epoch ---
--- 1.4961307048797607 seconds for one epoch ---
--- 0.2948734760284424 seconds for one epoch ---
--- 1.5084383487701416 seconds for one epoch ---
--- 0.29161739349365234 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9978234]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.427822]
 [ -0.      ]]
--- 0.25022435188293457 seconds for one epoch ---
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1936.75537109375, (1125.3157, 2.039808, 809.0186, 0.3814049)
   validation loss 781.9450073242188, (475.9089, 0.16242273, 305.4923, 0.3814049)
decoder loss ratio: 18437.537195, decoder SINDy loss  ratio: 0.659448
--- 0.2861480712890625 seconds for one epoch ---
--- 1.5102424621582031 seconds for one epoch ---
--- 0.2822713851928711 seconds for one epoch ---
--- 1.4903991222381592 seconds for one epoch ---
--- 0.2972884178161621 seconds for one epoch ---
--- 1.5201940536499023 seconds for one epoch ---
--- 0.31690096855163574 seconds for one epoch ---
--- 1.495389461517334 seconds for one epoch ---
--- 0.29387974739074707 seconds for one epoch ---
--- 1.4911456108093262 seconds for one epoch ---
--- 0.2971317768096924 seconds for one epoch ---
--- 1.5014612674713135 seconds for one epoch ---
--- 0.30005311965942383 seconds for one epoch ---
--- 1.4800693988800049 seconds for one epoch ---
--- 0.30274486541748047 seconds for one epoch ---
--- 1.4964172840118408 seconds for one epoch ---
--- 0.2989318370819092 seconds for one epoch ---
--- 1.4988818168640137 seconds for one epoch ---
--- 0.29961681365966797 seconds for one epoch ---
--- 1.5103790760040283 seconds for one epoch ---
--- 0.32564210891723633 seconds for one epoch ---
--- 1.5155668258666992 seconds for one epoch ---
--- 0.30034613609313965 seconds for one epoch ---
--- 1.5228476524353027 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9979018]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.514244]
 [  0.      ]]
--- 0.27819228172302246 seconds for one epoch ---
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5868.4462890625, (1262.864, 4.635975, 4600.563, 0.3831497)
   validation loss 969.6569213867188, (630.212, 0.20628144, 338.85547, 0.3831497)
decoder loss ratio: 24415.506011, decoder SINDy loss  ratio: 0.731467
--- 0.25366997718811035 seconds for one epoch ---
--- 0.28865647315979004 seconds for one epoch ---
--- 1.5113205909729004 seconds for one epoch ---
--- 0.2978067398071289 seconds for one epoch ---
--- 1.5279905796051025 seconds for one epoch ---
--- 0.29117774963378906 seconds for one epoch ---
--- 1.5097100734710693 seconds for one epoch ---
--- 0.2877321243286133 seconds for one epoch ---
--- 1.515397071838379 seconds for one epoch ---
--- 0.2993450164794922 seconds for one epoch ---
--- 1.5108637809753418 seconds for one epoch ---
--- 0.29186105728149414 seconds for one epoch ---
--- 1.502556562423706 seconds for one epoch ---
--- 0.30371952056884766 seconds for one epoch ---
--- 1.4964606761932373 seconds for one epoch ---
--- 0.30063295364379883 seconds for one epoch ---
--- 1.4927358627319336 seconds for one epoch ---
--- 0.29909396171569824 seconds for one epoch ---
--- 1.5025122165679932 seconds for one epoch ---
--- 0.2941584587097168 seconds for one epoch ---
--- 1.4968667030334473 seconds for one epoch ---
--- 0.2861168384552002 seconds for one epoch ---
--- 1.5202693939208984 seconds for one epoch ---
--- 0.28890061378479004 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99796396]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.587213]
 [ -0.      ]]
--- 0.257190465927124 seconds for one epoch ---
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2184.237548828125, (1099.7417, 2.3801422, 1081.731, 0.38474104)
   validation loss 1473.182373046875, (1148.2905, 0.21351334, 324.29358, 0.38474104)
decoder loss ratio: 44486.768549, decoder SINDy loss  ratio: 0.700033
--- 0.29701781272888184 seconds for one epoch ---
--- 1.5068607330322266 seconds for one epoch ---
--- 0.2880840301513672 seconds for one epoch ---
--- 1.5030224323272705 seconds for one epoch ---
--- 0.29317235946655273 seconds for one epoch ---
--- 1.529867172241211 seconds for one epoch ---
--- 0.3041038513183594 seconds for one epoch ---
--- 1.518087387084961 seconds for one epoch ---
--- 0.29649877548217773 seconds for one epoch ---
--- 1.5207672119140625 seconds for one epoch ---
--- 0.2933166027069092 seconds for one epoch ---
--- 1.522042989730835 seconds for one epoch ---
--- 0.30075621604919434 seconds for one epoch ---
--- 1.5144164562225342 seconds for one epoch ---
--- 0.29538488388061523 seconds for one epoch ---
--- 1.5220189094543457 seconds for one epoch ---
--- 0.29072046279907227 seconds for one epoch ---
--- 1.5158612728118896 seconds for one epoch ---
--- 0.2850186824798584 seconds for one epoch ---
--- 1.5239834785461426 seconds for one epoch ---
--- 0.3004879951477051 seconds for one epoch ---
--- 1.52842116355896 seconds for one epoch ---
--- 0.29289746284484863 seconds for one epoch ---
--- 1.5469043254852295 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9980356]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.674271]
 [  0.      ]]
--- 0.2798435688018799 seconds for one epoch ---
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2747.149169921875, (1201.1489, 1.4645929, 1544.1493, 0.38657162)
   validation loss 1066.6676025390625, (750.57324, 0.2243205, 315.48352, 0.38657162)
decoder loss ratio: 29078.510455, decoder SINDy loss  ratio: 0.681016
--- 0.26250553131103516 seconds for one epoch ---
--- 0.2922346591949463 seconds for one epoch ---
--- 1.533560037612915 seconds for one epoch ---
--- 0.28699827194213867 seconds for one epoch ---
--- 1.5540821552276611 seconds for one epoch ---
--- 0.29497194290161133 seconds for one epoch ---
--- 1.5269575119018555 seconds for one epoch ---
--- 0.30025315284729004 seconds for one epoch ---
--- 1.5466887950897217 seconds for one epoch ---
--- 0.2919952869415283 seconds for one epoch ---
--- 1.543520212173462 seconds for one epoch ---
--- 0.29252004623413086 seconds for one epoch ---
--- 1.5288479328155518 seconds for one epoch ---
--- 0.28712892532348633 seconds for one epoch ---
--- 1.5146629810333252 seconds for one epoch ---
--- 0.28123950958251953 seconds for one epoch ---
--- 1.537898302078247 seconds for one epoch ---
--- 0.2855641841888428 seconds for one epoch ---
--- 1.5684237480163574 seconds for one epoch ---
--- 0.2865128517150879 seconds for one epoch ---
--- 1.5248925685882568 seconds for one epoch ---
--- 0.292957067489624 seconds for one epoch ---
--- 1.532437801361084 seconds for one epoch ---
--- 0.2924628257751465 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9981111]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.769838]
 [  0.      ]]
--- 0.24521875381469727 seconds for one epoch ---
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3671.155517578125, (1047.322, 3.5019288, 2619.9429, 0.38859597)
   validation loss 1045.9532470703125, (715.50555, 0.24908501, 329.81003, 0.38859597)
decoder loss ratio: 27719.927342, decoder SINDy loss  ratio: 0.711941
--- 0.27863001823425293 seconds for one epoch ---
--- 1.5462913513183594 seconds for one epoch ---
--- 0.2995474338531494 seconds for one epoch ---
--- 1.5401530265808105 seconds for one epoch ---
--- 0.2889077663421631 seconds for one epoch ---
--- 1.5046443939208984 seconds for one epoch ---
--- 0.2987527847290039 seconds for one epoch ---
--- 1.538543939590454 seconds for one epoch ---
--- 0.29291844367980957 seconds for one epoch ---
--- 1.525663137435913 seconds for one epoch ---
--- 0.3063392639160156 seconds for one epoch ---
--- 1.5512444972991943 seconds for one epoch ---
--- 0.27938055992126465 seconds for one epoch ---
--- 1.5548439025878906 seconds for one epoch ---
--- 0.2888936996459961 seconds for one epoch ---
--- 1.5567796230316162 seconds for one epoch ---
--- 0.28882527351379395 seconds for one epoch ---
--- 1.561387538909912 seconds for one epoch ---
--- 0.2926011085510254 seconds for one epoch ---
--- 1.5325372219085693 seconds for one epoch ---
--- 0.2978193759918213 seconds for one epoch ---
--- 1.5333116054534912 seconds for one epoch ---
--- 0.2888054847717285 seconds for one epoch ---
--- 1.5526468753814697 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9981663]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.842234]
 [ -0.      ]]
--- 0.30213046073913574 seconds for one epoch ---
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3846.34814453125, (1396.2819, 2.59618, 2447.08, 0.39022097)
   validation loss 1207.307373046875, (900.151, 0.23615575, 306.52994, 0.39022097)
decoder loss ratio: 34873.412509, decoder SINDy loss  ratio: 0.661688
--- 0.2583470344543457 seconds for one epoch ---
--- 0.2975647449493408 seconds for one epoch ---
--- 1.5525641441345215 seconds for one epoch ---
--- 0.30381321907043457 seconds for one epoch ---
--- 1.524810552597046 seconds for one epoch ---
--- 0.3173410892486572 seconds for one epoch ---
--- 1.5220441818237305 seconds for one epoch ---
--- 0.28145337104797363 seconds for one epoch ---
--- 1.5682368278503418 seconds for one epoch ---
--- 0.31268787384033203 seconds for one epoch ---
--- 1.5650405883789062 seconds for one epoch ---
--- 0.28899073600769043 seconds for one epoch ---
--- 1.6065714359283447 seconds for one epoch ---
--- 0.2987840175628662 seconds for one epoch ---
--- 1.6184709072113037 seconds for one epoch ---
--- 0.3021378517150879 seconds for one epoch ---
--- 1.627074956893921 seconds for one epoch ---
--- 0.29653429985046387 seconds for one epoch ---
--- 1.6266415119171143 seconds for one epoch ---
--- 0.27340173721313477 seconds for one epoch ---
--- 1.6283988952636719 seconds for one epoch ---
--- 0.28400111198425293 seconds for one epoch ---
--- 1.5934624671936035 seconds for one epoch ---
--- 0.29264354705810547 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9982172]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.912205]
 [ -0.      ]]
--- 0.25397682189941406 seconds for one epoch ---
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4424.63037109375, (1298.4202, 4.5269938, 3121.2917, 0.39176)
   validation loss 849.2709350585938, (521.57294, 0.20651813, 327.09964, 0.39176)
decoder loss ratio: 20206.641070, decoder SINDy loss  ratio: 0.706091
--- 0.2866859436035156 seconds for one epoch ---
--- 1.5579233169555664 seconds for one epoch ---
--- 0.29250335693359375 seconds for one epoch ---
--- 1.5551209449768066 seconds for one epoch ---
--- 0.2976658344268799 seconds for one epoch ---
--- 1.5870039463043213 seconds for one epoch ---
--- 0.3024427890777588 seconds for one epoch ---
--- 1.5682849884033203 seconds for one epoch ---
--- 0.2903616428375244 seconds for one epoch ---
--- 1.5859875679016113 seconds for one epoch ---
--- 0.3023808002471924 seconds for one epoch ---
--- 1.5784783363342285 seconds for one epoch ---
--- 0.32703280448913574 seconds for one epoch ---
--- 1.5862257480621338 seconds for one epoch ---
--- 0.2987325191497803 seconds for one epoch ---
--- 1.5582988262176514 seconds for one epoch ---
--- 0.289583683013916 seconds for one epoch ---
--- 1.576524257659912 seconds for one epoch ---
--- 0.2890141010284424 seconds for one epoch ---
--- 1.5665276050567627 seconds for one epoch ---
--- 0.3157920837402344 seconds for one epoch ---
--- 1.5857479572296143 seconds for one epoch ---
--- 0.2801358699798584 seconds for one epoch ---
--- 1.5925862789154053 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99826837]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.98467]
 [  0.     ]]
--- 0.2893714904785156 seconds for one epoch ---
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3596.511474609375, (1236.9044, 3.115818, 2356.098, 0.39322788)
   validation loss 844.9791259765625, (551.91583, 0.21796156, 292.4521, 0.39322788)
decoder loss ratio: 21382.177520, decoder SINDy loss  ratio: 0.631299
--- 0.25911641120910645 seconds for one epoch ---
--- 0.2862114906311035 seconds for one epoch ---
--- 1.5635297298431396 seconds for one epoch ---
--- 0.2890787124633789 seconds for one epoch ---
--- 1.6037428379058838 seconds for one epoch ---
--- 0.2965824604034424 seconds for one epoch ---
--- 1.568366527557373 seconds for one epoch ---
--- 0.30028271675109863 seconds for one epoch ---
--- 1.581435203552246 seconds for one epoch ---
--- 0.2942838668823242 seconds for one epoch ---
--- 1.5783720016479492 seconds for one epoch ---
--- 0.2938251495361328 seconds for one epoch ---
--- 1.5533862113952637 seconds for one epoch ---
--- 0.29146742820739746 seconds for one epoch ---
--- 1.578641653060913 seconds for one epoch ---
--- 0.29831743240356445 seconds for one epoch ---
--- 1.5765738487243652 seconds for one epoch ---
--- 0.3123772144317627 seconds for one epoch ---
--- 1.5816175937652588 seconds for one epoch ---
--- 0.2925741672515869 seconds for one epoch ---
--- 1.5762100219726562 seconds for one epoch ---
--- 0.29244136810302734 seconds for one epoch ---
--- 1.5934300422668457 seconds for one epoch ---
--- 0.2905759811401367 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9983159]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.054716]
 [ -0.      ]]
--- 0.2578694820404053 seconds for one epoch ---
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3489.085693359375, (1424.7141, 1.7715545, 2062.205, 0.39482164)
   validation loss 1320.03759765625, (1004.6084, 0.2288854, 314.80554, 0.39482164)
decoder loss ratio: 38920.273432, decoder SINDy loss  ratio: 0.679552
--- 0.29340362548828125 seconds for one epoch ---
--- 1.5825932025909424 seconds for one epoch ---
--- 0.29716038703918457 seconds for one epoch ---
--- 1.5912625789642334 seconds for one epoch ---
--- 0.2846529483795166 seconds for one epoch ---
--- 1.6302533149719238 seconds for one epoch ---
--- 0.2940237522125244 seconds for one epoch ---
--- 1.6019790172576904 seconds for one epoch ---
--- 0.290355920791626 seconds for one epoch ---
--- 1.5956313610076904 seconds for one epoch ---
--- 0.290924072265625 seconds for one epoch ---
--- 1.5738186836242676 seconds for one epoch ---
--- 0.2825748920440674 seconds for one epoch ---
--- 1.592268943786621 seconds for one epoch ---
--- 0.2977635860443115 seconds for one epoch ---
--- 1.5938773155212402 seconds for one epoch ---
--- 0.293895959854126 seconds for one epoch ---
--- 1.604175329208374 seconds for one epoch ---
--- 0.290241003036499 seconds for one epoch ---
--- 1.6167349815368652 seconds for one epoch ---
--- 0.28243017196655273 seconds for one epoch ---
--- 1.6130447387695312 seconds for one epoch ---
--- 0.28795838356018066 seconds for one epoch ---
--- 1.6323156356811523 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998366]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.130511]
 [  0.      ]]
--- 0.29430079460144043 seconds for one epoch ---
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2310.697509765625, (1574.1685, 1.4101188, 734.7224, 0.39651233)
   validation loss 1279.564697265625, (908.43024, 0.17138013, 370.5666, 0.39651233)
decoder loss ratio: 35194.164479, decoder SINDy loss  ratio: 0.799920
--- 0.257122278213501 seconds for one epoch ---
--- 0.29665184020996094 seconds for one epoch ---
--- 1.58717679977417 seconds for one epoch ---
--- 0.30348658561706543 seconds for one epoch ---
--- 1.5685112476348877 seconds for one epoch ---
--- 0.29296398162841797 seconds for one epoch ---
--- 1.6042299270629883 seconds for one epoch ---
--- 0.2986299991607666 seconds for one epoch ---
--- 1.5983123779296875 seconds for one epoch ---
--- 0.29607105255126953 seconds for one epoch ---
--- 1.6116960048675537 seconds for one epoch ---
--- 0.30166125297546387 seconds for one epoch ---
--- 1.6034049987792969 seconds for one epoch ---
--- 0.30755066871643066 seconds for one epoch ---
--- 1.6069788932800293 seconds for one epoch ---
--- 0.30060625076293945 seconds for one epoch ---
--- 1.6319866180419922 seconds for one epoch ---
--- 0.2991366386413574 seconds for one epoch ---
--- 1.6293177604675293 seconds for one epoch ---
--- 0.3016645908355713 seconds for one epoch ---
--- 1.612257957458496 seconds for one epoch ---
--- 0.29595088958740234 seconds for one epoch ---
--- 1.6247432231903076 seconds for one epoch ---
--- 0.28882837295532227 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99841475]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.208031]
 [  0.      ]]
--- 0.25859570503234863 seconds for one epoch ---
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2790.868408203125, (1223.9397, 1.3418064, 1565.1887, 0.39823207)
   validation loss 1376.10302734375, (1022.6146, 0.25195986, 352.8382, 0.39823207)
decoder loss ratio: 39617.865872, decoder SINDy loss  ratio: 0.761651
--- 0.29085516929626465 seconds for one epoch ---
--- 1.6119468212127686 seconds for one epoch ---
--- 0.2994396686553955 seconds for one epoch ---
--- 1.6270825862884521 seconds for one epoch ---
--- 0.30159854888916016 seconds for one epoch ---
--- 1.646026372909546 seconds for one epoch ---
--- 0.2964174747467041 seconds for one epoch ---
--- 1.6386992931365967 seconds for one epoch ---
--- 0.29657459259033203 seconds for one epoch ---
--- 1.6317877769470215 seconds for one epoch ---
--- 0.29738545417785645 seconds for one epoch ---
--- 1.633204698562622 seconds for one epoch ---
--- 0.29790163040161133 seconds for one epoch ---
--- 1.6388192176818848 seconds for one epoch ---
--- 0.29333972930908203 seconds for one epoch ---
--- 1.5861568450927734 seconds for one epoch ---
--- 0.29532337188720703 seconds for one epoch ---
--- 1.6043708324432373 seconds for one epoch ---
--- 0.29733705520629883 seconds for one epoch ---
--- 1.6461453437805176 seconds for one epoch ---
--- 0.30910253524780273 seconds for one epoch ---
--- 1.606053352355957 seconds for one epoch ---
--- 0.2935950756072998 seconds for one epoch ---
--- 1.6304335594177246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99845123]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.266015]
 [ -0.      ]]
--- 0.29521703720092773 seconds for one epoch ---
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3632.924072265625, (1223.9614, 1.5488007, 2407.0142, 0.3995645)
   validation loss 1415.4874267578125, (1011.44836, 0.20102029, 403.4385, 0.3995645)
decoder loss ratio: 39185.265583, decoder SINDy loss  ratio: 0.870879
--- 0.26409220695495605 seconds for one epoch ---
--- 0.2902848720550537 seconds for one epoch ---
--- 1.6229913234710693 seconds for one epoch ---
--- 0.28484320640563965 seconds for one epoch ---
--- 1.641650676727295 seconds for one epoch ---
--- 0.2852973937988281 seconds for one epoch ---
--- 1.6443743705749512 seconds for one epoch ---
--- 0.2952570915222168 seconds for one epoch ---
--- 1.6450436115264893 seconds for one epoch ---
--- 0.29373812675476074 seconds for one epoch ---
--- 1.6279616355895996 seconds for one epoch ---
--- 0.2878413200378418 seconds for one epoch ---
--- 1.6169037818908691 seconds for one epoch ---
--- 0.2826576232910156 seconds for one epoch ---
--- 1.6555347442626953 seconds for one epoch ---
--- 0.3057246208190918 seconds for one epoch ---
--- 1.6355268955230713 seconds for one epoch ---
--- 0.2796599864959717 seconds for one epoch ---
--- 1.627514362335205 seconds for one epoch ---
--- 0.2864875793457031 seconds for one epoch ---
--- 1.644010066986084 seconds for one epoch ---
--- 0.2944672107696533 seconds for one epoch ---
--- 1.653095006942749 seconds for one epoch ---
--- 0.3301818370819092 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9984871]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.327665]
 [ -0.      ]]
--- 0.25849485397338867 seconds for one epoch ---
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2789.45263671875, (1458.3481, 6.3984857, 1324.305, 0.4008777)
   validation loss 1066.8795166015625, (717.21027, 0.23368125, 349.0347, 0.4008777)
decoder loss ratio: 27785.970841, decoder SINDy loss  ratio: 0.753440
--- 0.28530073165893555 seconds for one epoch ---
--- 1.6318027973175049 seconds for one epoch ---
--- 0.28961801528930664 seconds for one epoch ---
--- 1.6582322120666504 seconds for one epoch ---
--- 0.29564976692199707 seconds for one epoch ---
--- 1.643043041229248 seconds for one epoch ---
--- 0.31256842613220215 seconds for one epoch ---
--- 1.6139616966247559 seconds for one epoch ---
--- 0.29521679878234863 seconds for one epoch ---
--- 1.6403319835662842 seconds for one epoch ---
--- 0.293001651763916 seconds for one epoch ---
--- 1.646867275238037 seconds for one epoch ---
--- 0.2880399227142334 seconds for one epoch ---
--- 1.6404922008514404 seconds for one epoch ---
--- 0.28650808334350586 seconds for one epoch ---
--- 1.6346604824066162 seconds for one epoch ---
--- 0.2834305763244629 seconds for one epoch ---
--- 1.64457106590271 seconds for one epoch ---
--- 0.2828695774078369 seconds for one epoch ---
--- 1.635335922241211 seconds for one epoch ---
--- 0.29332447052001953 seconds for one epoch ---
--- 1.6166107654571533 seconds for one epoch ---
--- 0.2942986488342285 seconds for one epoch ---
--- 1.6394259929656982 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985267]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.395207]
 [  0.      ]]
--- 0.2897224426269531 seconds for one epoch ---
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3841.72216796875, (1643.8434, 1.9390372, 2195.5374, 0.40242806)
   validation loss 1472.3648681640625, (1095.984, 0.20921211, 375.76913, 0.40242806)
decoder loss ratio: 42460.323212, decoder SINDy loss  ratio: 0.811151
THRESHOLDING: 1 active coefficients
--- 0.25596070289611816 seconds for one epoch ---
--- 0.29225826263427734 seconds for one epoch ---
--- 1.630582332611084 seconds for one epoch ---
--- 0.2896261215209961 seconds for one epoch ---
--- 1.6455790996551514 seconds for one epoch ---
--- 0.3035404682159424 seconds for one epoch ---
--- 1.652735948562622 seconds for one epoch ---
--- 0.2958686351776123 seconds for one epoch ---
--- 1.6462626457214355 seconds for one epoch ---
--- 0.2895505428314209 seconds for one epoch ---
--- 1.6743981838226318 seconds for one epoch ---
--- 0.2916834354400635 seconds for one epoch ---
--- 1.6497802734375 seconds for one epoch ---
--- 0.5867490768432617 seconds for one epoch ---
--- 1.6710443496704102 seconds for one epoch ---
--- 0.2912418842315674 seconds for one epoch ---
--- 1.6760337352752686 seconds for one epoch ---
--- 0.29650259017944336 seconds for one epoch ---
--- 1.6754579544067383 seconds for one epoch ---
--- 0.2952735424041748 seconds for one epoch ---
--- 1.6485710144042969 seconds for one epoch ---
--- 0.2865874767303467 seconds for one epoch ---
--- 1.6321487426757812 seconds for one epoch ---
--- 0.28940916061401367 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985643]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.465149]
 [ -0.      ]]
--- 0.25188684463500977 seconds for one epoch ---
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3908.74609375, (1958.5621, 2.6470075, 1947.133, 0.40390465)
   validation loss 962.38037109375, (657.0511, 0.20719127, 304.71817, 0.40390465)
decoder loss ratio: 25455.299779, decoder SINDy loss  ratio: 0.657777
--- 0.29409050941467285 seconds for one epoch ---
--- 1.6449310779571533 seconds for one epoch ---
--- 0.3121364116668701 seconds for one epoch ---
--- 1.6268508434295654 seconds for one epoch ---
--- 0.2937955856323242 seconds for one epoch ---
--- 1.6450579166412354 seconds for one epoch ---
--- 0.28629136085510254 seconds for one epoch ---
--- 1.6532540321350098 seconds for one epoch ---
--- 0.3001883029937744 seconds for one epoch ---
--- 1.6632180213928223 seconds for one epoch ---
--- 0.28165197372436523 seconds for one epoch ---
--- 1.6523351669311523 seconds for one epoch ---
--- 0.30469179153442383 seconds for one epoch ---
--- 1.646132469177246 seconds for one epoch ---
--- 0.2840750217437744 seconds for one epoch ---
--- 1.6556191444396973 seconds for one epoch ---
--- 0.28960633277893066 seconds for one epoch ---
--- 1.6664302349090576 seconds for one epoch ---
--- 0.29111385345458984 seconds for one epoch ---
--- 1.6784465312957764 seconds for one epoch ---
--- 0.2951316833496094 seconds for one epoch ---
--- 1.6696362495422363 seconds for one epoch ---
--- 0.2975766658782959 seconds for one epoch ---
--- 1.6762487888336182 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99859416]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.519559]
 [  0.      ]]
--- 0.28499269485473633 seconds for one epoch ---
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3534.975830078125, (1508.3616, 0.581039, 2025.6279, 0.40518475)
   validation loss 851.6836547851562, (543.1367, 0.24561977, 307.89615, 0.40518475)
decoder loss ratio: 21042.059411, decoder SINDy loss  ratio: 0.664637
--- 0.26503443717956543 seconds for one epoch ---
--- 0.2948458194732666 seconds for one epoch ---
--- 1.6764938831329346 seconds for one epoch ---
--- 0.2938072681427002 seconds for one epoch ---
--- 1.6676819324493408 seconds for one epoch ---
--- 0.29647278785705566 seconds for one epoch ---
--- 1.6893279552459717 seconds for one epoch ---
--- 0.29767346382141113 seconds for one epoch ---
--- 1.6688423156738281 seconds for one epoch ---
--- 0.29134654998779297 seconds for one epoch ---
--- 1.6961474418640137 seconds for one epoch ---
--- 0.30045509338378906 seconds for one epoch ---
--- 1.6813623905181885 seconds for one epoch ---
--- 0.29447412490844727 seconds for one epoch ---
--- 1.6949877738952637 seconds for one epoch ---
--- 0.2943284511566162 seconds for one epoch ---
--- 1.682542324066162 seconds for one epoch ---
--- 0.2962644100189209 seconds for one epoch ---
--- 1.6709554195404053 seconds for one epoch ---
--- 0.2999606132507324 seconds for one epoch ---
--- 1.6670358180999756 seconds for one epoch ---
--- 0.2865917682647705 seconds for one epoch ---
--- 1.676978349685669 seconds for one epoch ---
--- 0.29490184783935547 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986286]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.584532]
 [  0.      ]]
--- 0.258742094039917 seconds for one epoch ---
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3400.80126953125, (1270.7758, 0.30281797, 2129.3162, 0.4065899)
   validation loss 2211.163818359375, (1750.2972, 0.19751301, 460.2627, 0.4065899)
decoder loss ratio: 67809.553774, decoder SINDy loss  ratio: 0.993542
--- 0.28880763053894043 seconds for one epoch ---
--- 1.708195686340332 seconds for one epoch ---
--- 0.3039100170135498 seconds for one epoch ---
--- 1.6121695041656494 seconds for one epoch ---
--- 0.3272430896759033 seconds for one epoch ---
--- 1.6691627502441406 seconds for one epoch ---
--- 0.3321678638458252 seconds for one epoch ---
--- 1.64607572555542 seconds for one epoch ---
--- 0.32668399810791016 seconds for one epoch ---
--- 1.6305608749389648 seconds for one epoch ---
--- 0.333437442779541 seconds for one epoch ---
--- 1.641620397567749 seconds for one epoch ---
--- 0.33952951431274414 seconds for one epoch ---
--- 1.6426303386688232 seconds for one epoch ---
--- 0.33208394050598145 seconds for one epoch ---
--- 1.6427769660949707 seconds for one epoch ---
--- 0.32597851753234863 seconds for one epoch ---
--- 1.6391675472259521 seconds for one epoch ---
--- 0.323502779006958 seconds for one epoch ---
--- 1.640733242034912 seconds for one epoch ---
--- 0.324735164642334 seconds for one epoch ---
--- 1.6318838596343994 seconds for one epoch ---
--- 0.3303811550140381 seconds for one epoch ---
--- 1.6849002838134766 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986608]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.649378]
 [ -0.      ]]
--- 0.31035923957824707 seconds for one epoch ---
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2735.7412109375, (1243.0088, 0.73721063, 1491.587, 0.40812704)
   validation loss 827.7350463867188, (512.8367, 0.23090705, 314.2593, 0.40812704)
decoder loss ratio: 19868.182916, decoder SINDy loss  ratio: 0.678373
--- 0.25087857246398926 seconds for one epoch ---
--- 0.31866908073425293 seconds for one epoch ---
--- 1.6503801345825195 seconds for one epoch ---
--- 0.3322007656097412 seconds for one epoch ---
--- 1.609459400177002 seconds for one epoch ---
--- 0.34122419357299805 seconds for one epoch ---
--- 1.640446424484253 seconds for one epoch ---
--- 0.32564449310302734 seconds for one epoch ---
--- 1.6441409587860107 seconds for one epoch ---
--- 0.32318997383117676 seconds for one epoch ---
--- 1.6505389213562012 seconds for one epoch ---
--- 0.3270590305328369 seconds for one epoch ---
--- 1.6605956554412842 seconds for one epoch ---
--- 0.32406091690063477 seconds for one epoch ---
--- 1.6683979034423828 seconds for one epoch ---
--- 0.3311173915863037 seconds for one epoch ---
--- 1.6526880264282227 seconds for one epoch ---
--- 0.31733107566833496 seconds for one epoch ---
--- 1.6597614288330078 seconds for one epoch ---
--- 0.32537055015563965 seconds for one epoch ---
--- 1.6405510902404785 seconds for one epoch ---
--- 0.3328273296356201 seconds for one epoch ---
--- 1.6360797882080078 seconds for one epoch ---
--- 0.32600831985473633 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99869496]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-15.71832]
 [ -0.     ]]
--- 0.2696566581726074 seconds for one epoch ---
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5657.80615234375, (1266.496, 5.912659, 4384.988, 0.40979204)
   validation loss 773.21533203125, (473.8612, 0.24352536, 298.70078, 0.40979204)
decoder loss ratio: 18358.205782, decoder SINDy loss  ratio: 0.644788
--- 0.311321496963501 seconds for one epoch ---
--- 1.6551463603973389 seconds for one epoch ---
--- 0.32811617851257324 seconds for one epoch ---
--- 1.6655871868133545 seconds for one epoch ---
--- 0.32381463050842285 seconds for one epoch ---
--- 1.6543781757354736 seconds for one epoch ---
--- 0.32013988494873047 seconds for one epoch ---
--- 1.6587562561035156 seconds for one epoch ---
--- 0.3080465793609619 seconds for one epoch ---
--- 1.6447124481201172 seconds for one epoch ---
--- 0.33248138427734375 seconds for one epoch ---
--- 1.6541354656219482 seconds for one epoch ---
--- 0.30621767044067383 seconds for one epoch ---
--- 1.6557085514068604 seconds for one epoch ---
--- 0.32509684562683105 seconds for one epoch ---
--- 1.6938486099243164 seconds for one epoch ---
--- 0.3184521198272705 seconds for one epoch ---
--- 1.6900489330291748 seconds for one epoch ---
--- 0.3265993595123291 seconds for one epoch ---
--- 1.6647202968597412 seconds for one epoch ---
--- 0.332474946975708 seconds for one epoch ---
--- 1.6626670360565186 seconds for one epoch ---
--- 0.3168015480041504 seconds for one epoch ---
--- 1.6898138523101807 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987289]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.789421]
 [  0.      ]]
--- 0.3020205497741699 seconds for one epoch ---
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 10367.763671875, (3433.3906, 26.927437, 6907.0347, 0.41131917)
   validation loss 978.8905029296875, (647.9142, 0.28659993, 330.27838, 0.41131917)
decoder loss ratio: 25101.320339, decoder SINDy loss  ratio: 0.712952
--- 0.2757563591003418 seconds for one epoch ---
--- 0.326566219329834 seconds for one epoch ---
--- 1.6733465194702148 seconds for one epoch ---
--- 0.32559800148010254 seconds for one epoch ---
--- 1.6520416736602783 seconds for one epoch ---
--- 0.3202650547027588 seconds for one epoch ---
--- 1.646735668182373 seconds for one epoch ---
--- 0.32740235328674316 seconds for one epoch ---
--- 1.6716599464416504 seconds for one epoch ---
--- 0.3267350196838379 seconds for one epoch ---
--- 1.6913962364196777 seconds for one epoch ---
--- 0.3187265396118164 seconds for one epoch ---
--- 1.6819744110107422 seconds for one epoch ---
--- 0.32911014556884766 seconds for one epoch ---
--- 1.6783852577209473 seconds for one epoch ---
--- 0.32967543601989746 seconds for one epoch ---
--- 1.6436541080474854 seconds for one epoch ---
--- 0.3289756774902344 seconds for one epoch ---
--- 1.6769073009490967 seconds for one epoch ---
--- 0.3388814926147461 seconds for one epoch ---
--- 1.6801376342773438 seconds for one epoch ---
--- 0.317246675491333 seconds for one epoch ---
--- 1.6838304996490479 seconds for one epoch ---
--- 0.32872772216796875 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987556]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.84814]
 [ -0.     ]]
--- 0.2682325839996338 seconds for one epoch ---
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2847.30615234375, (1752.1212, 0.6883666, 1094.084, 0.41267115)
   validation loss 754.773681640625, (455.6013, 0.23562688, 298.5241, 0.41267115)
decoder loss ratio: 17650.784850, decoder SINDy loss  ratio: 0.644406
--- 0.29662179946899414 seconds for one epoch ---
--- 1.668095350265503 seconds for one epoch ---
--- 0.3278517723083496 seconds for one epoch ---
--- 1.6608469486236572 seconds for one epoch ---
--- 0.326261043548584 seconds for one epoch ---
--- 1.6855897903442383 seconds for one epoch ---
--- 0.32484984397888184 seconds for one epoch ---
--- 1.6487829685211182 seconds for one epoch ---
--- 0.32248449325561523 seconds for one epoch ---
--- 1.660243272781372 seconds for one epoch ---
--- 0.31195592880249023 seconds for one epoch ---
--- 1.702237844467163 seconds for one epoch ---
--- 0.3269839286804199 seconds for one epoch ---
--- 1.6545977592468262 seconds for one epoch ---
--- 0.3302631378173828 seconds for one epoch ---
--- 1.6748478412628174 seconds for one epoch ---
--- 0.3249399662017822 seconds for one epoch ---
--- 1.6631219387054443 seconds for one epoch ---
--- 0.316725492477417 seconds for one epoch ---
--- 1.6655933856964111 seconds for one epoch ---
--- 0.3277091979980469 seconds for one epoch ---
--- 1.6693508625030518 seconds for one epoch ---
--- 0.321561336517334 seconds for one epoch ---
--- 1.6747713088989258 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987803]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.903778]
 [  0.      ]]
--- 0.3030672073364258 seconds for one epoch ---
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2105.005615234375, (889.13257, 3.592142, 1211.8668, 0.41398868)
   validation loss 903.10205078125, (565.69836, 0.21649218, 336.7732, 0.41398868)
decoder loss ratio: 21916.136727, decoder SINDy loss  ratio: 0.726972
--- 0.2845282554626465 seconds for one epoch ---
--- 0.32491254806518555 seconds for one epoch ---
--- 1.6995110511779785 seconds for one epoch ---
--- 0.32018423080444336 seconds for one epoch ---
--- 1.6849353313446045 seconds for one epoch ---
--- 0.3246028423309326 seconds for one epoch ---
--- 1.6656477451324463 seconds for one epoch ---
--- 0.33243870735168457 seconds for one epoch ---
--- 1.6841144561767578 seconds for one epoch ---
--- 0.32236576080322266 seconds for one epoch ---
--- 1.6834053993225098 seconds for one epoch ---
--- 0.321089506149292 seconds for one epoch ---
--- 1.7028748989105225 seconds for one epoch ---
--- 0.3166487216949463 seconds for one epoch ---
--- 1.7018718719482422 seconds for one epoch ---
--- 0.32149243354797363 seconds for one epoch ---
--- 1.656853437423706 seconds for one epoch ---
--- 0.32257652282714844 seconds for one epoch ---
--- 1.7317008972167969 seconds for one epoch ---
--- 0.3248779773712158 seconds for one epoch ---
--- 1.7046387195587158 seconds for one epoch ---
--- 0.3291761875152588 seconds for one epoch ---
--- 1.698307991027832 seconds for one epoch ---
--- 0.30890893936157227 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988035]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.957098]
 [  0.      ]]
--- 0.2673368453979492 seconds for one epoch ---
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2178.833984375, (1087.6145, 1.2306299, 1089.5736, 0.41520414)
   validation loss 998.8444213867188, (646.7453, 0.18585114, 351.49805, 0.41520414)
decoder loss ratio: 25056.035733, decoder SINDy loss  ratio: 0.758758
--- 0.3210258483886719 seconds for one epoch ---
--- 1.7202904224395752 seconds for one epoch ---
--- 0.3244740962982178 seconds for one epoch ---
--- 1.674926996231079 seconds for one epoch ---
--- 0.3308122158050537 seconds for one epoch ---
--- 1.7254724502563477 seconds for one epoch ---
--- 0.32384490966796875 seconds for one epoch ---
--- 1.671375036239624 seconds for one epoch ---
--- 0.32692766189575195 seconds for one epoch ---
--- 1.728454828262329 seconds for one epoch ---
--- 0.31915998458862305 seconds for one epoch ---
--- 1.7125740051269531 seconds for one epoch ---
--- 0.3285946846008301 seconds for one epoch ---
--- 1.728081226348877 seconds for one epoch ---
--- 0.3178279399871826 seconds for one epoch ---
--- 1.6848607063293457 seconds for one epoch ---
--- 0.3251643180847168 seconds for one epoch ---
--- 1.7139060497283936 seconds for one epoch ---
--- 0.3211939334869385 seconds for one epoch ---
--- 1.6907787322998047 seconds for one epoch ---
--- 0.32939672470092773 seconds for one epoch ---
--- 1.6925816535949707 seconds for one epoch ---
--- 0.31645965576171875 seconds for one epoch ---
--- 1.721407175064087 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988289]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.01578]
 [ -0.     ]]
--- 0.301499605178833 seconds for one epoch ---
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2685.314208984375, (1078.388, 3.5248387, 1602.985, 0.41660944)
   validation loss 798.255126953125, (486.27792, 0.21826494, 311.34232, 0.41660944)
decoder loss ratio: 18839.250975, decoder SINDy loss  ratio: 0.672076
--- 0.2690122127532959 seconds for one epoch ---
--- 0.3286559581756592 seconds for one epoch ---
--- 1.7014646530151367 seconds for one epoch ---
--- 0.32618165016174316 seconds for one epoch ---
--- 1.7548274993896484 seconds for one epoch ---
--- 0.32318878173828125 seconds for one epoch ---
--- 1.7367773056030273 seconds for one epoch ---
--- 0.32475733757019043 seconds for one epoch ---
--- 1.6902894973754883 seconds for one epoch ---
--- 0.3220961093902588 seconds for one epoch ---
--- 1.7031538486480713 seconds for one epoch ---
--- 0.32698535919189453 seconds for one epoch ---
--- 1.747318983078003 seconds for one epoch ---
--- 0.3247842788696289 seconds for one epoch ---
--- 1.7012629508972168 seconds for one epoch ---
--- 0.3303208351135254 seconds for one epoch ---
--- 1.731888771057129 seconds for one epoch ---
--- 0.321666955947876 seconds for one epoch ---
--- 1.697396993637085 seconds for one epoch ---
--- 0.31281113624572754 seconds for one epoch ---
--- 1.701192855834961 seconds for one epoch ---
--- 0.3258204460144043 seconds for one epoch ---
--- 1.7261254787445068 seconds for one epoch ---
--- 0.33689284324645996 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988521]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.071873]
 [ -0.      ]]
--- 0.26856350898742676 seconds for one epoch ---
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3947.9423828125, (1168.5836, 1.3414949, 2777.5994, 0.41800776)
   validation loss 1297.67333984375, (931.5845, 0.2630039, 365.4079, 0.41800776)
decoder loss ratio: 36091.199772, decoder SINDy loss  ratio: 0.788784
--- 0.30719542503356934 seconds for one epoch ---
--- 1.7436535358428955 seconds for one epoch ---
--- 0.32901453971862793 seconds for one epoch ---
--- 1.7222239971160889 seconds for one epoch ---
--- 0.323089599609375 seconds for one epoch ---
--- 1.7125072479248047 seconds for one epoch ---
--- 0.33072662353515625 seconds for one epoch ---
--- 1.7296218872070312 seconds for one epoch ---
--- 0.32645654678344727 seconds for one epoch ---
--- 1.7283356189727783 seconds for one epoch ---
--- 0.3242619037628174 seconds for one epoch ---
--- 1.7364280223846436 seconds for one epoch ---
--- 0.3240327835083008 seconds for one epoch ---
--- 1.7420003414154053 seconds for one epoch ---
--- 0.3285222053527832 seconds for one epoch ---
--- 1.721055269241333 seconds for one epoch ---
--- 0.32964110374450684 seconds for one epoch ---
--- 1.758331298828125 seconds for one epoch ---
--- 0.31807827949523926 seconds for one epoch ---
--- 1.7347490787506104 seconds for one epoch ---
--- 0.32480788230895996 seconds for one epoch ---
--- 1.7116479873657227 seconds for one epoch ---
--- 0.3213462829589844 seconds for one epoch ---
--- 1.7323002815246582 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988725]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.12407]
 [  0.     ]]
--- 0.30106544494628906 seconds for one epoch ---
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1653.984619140625, (749.7449, 1.3866011, 902.4339, 0.4191551)
   validation loss 1040.5521240234375, (680.15405, 0.22575197, 359.7531, 0.4191551)
decoder loss ratio: 26350.348802, decoder SINDy loss  ratio: 0.776578
--- 0.27818965911865234 seconds for one epoch ---
--- 0.32565855979919434 seconds for one epoch ---
--- 1.7153992652893066 seconds for one epoch ---
--- 0.3216552734375 seconds for one epoch ---
--- 1.736938238143921 seconds for one epoch ---
--- 0.3299593925476074 seconds for one epoch ---
--- 1.7098479270935059 seconds for one epoch ---
--- 0.32642269134521484 seconds for one epoch ---
--- 1.7004590034484863 seconds for one epoch ---
--- 0.32392191886901855 seconds for one epoch ---
--- 1.7374193668365479 seconds for one epoch ---
--- 0.3250133991241455 seconds for one epoch ---
--- 1.734546422958374 seconds for one epoch ---
--- 0.3268735408782959 seconds for one epoch ---
--- 1.761136531829834 seconds for one epoch ---
--- 0.32079029083251953 seconds for one epoch ---
--- 1.756777286529541 seconds for one epoch ---
--- 0.31898021697998047 seconds for one epoch ---
--- 1.7496705055236816 seconds for one epoch ---
--- 0.32981252670288086 seconds for one epoch ---
--- 1.7474651336669922 seconds for one epoch ---
--- 0.32764291763305664 seconds for one epoch ---
--- 1.773190975189209 seconds for one epoch ---
--- 0.3224785327911377 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988959]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.181145]
 [ -0.      ]]
--- 0.2736210823059082 seconds for one epoch ---
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2944.0888671875, (1607.0212, 4.1836166, 1332.4636, 0.42050734)
   validation loss 1059.6339111328125, (728.03687, 0.26419556, 330.91232, 0.42050734)
decoder loss ratio: 28205.412087, decoder SINDy loss  ratio: 0.714321
--- 0.3190922737121582 seconds for one epoch ---
--- 1.7612826824188232 seconds for one epoch ---
--- 0.33893346786499023 seconds for one epoch ---
--- 1.7271761894226074 seconds for one epoch ---
--- 0.334531307220459 seconds for one epoch ---
--- 1.7358200550079346 seconds for one epoch ---
--- 0.32710742950439453 seconds for one epoch ---
--- 1.7325351238250732 seconds for one epoch ---
--- 0.33431315422058105 seconds for one epoch ---
--- 1.745311975479126 seconds for one epoch ---
--- 0.32541322708129883 seconds for one epoch ---
--- 1.76454758644104 seconds for one epoch ---
--- 0.31790971755981445 seconds for one epoch ---
--- 1.7875075340270996 seconds for one epoch ---
--- 0.32540273666381836 seconds for one epoch ---
--- 1.762453317642212 seconds for one epoch ---
--- 0.3191096782684326 seconds for one epoch ---
--- 1.7562224864959717 seconds for one epoch ---
--- 0.3298978805541992 seconds for one epoch ---
--- 1.762869119644165 seconds for one epoch ---
--- 0.2959766387939453 seconds for one epoch ---
--- 1.7561109066009521 seconds for one epoch ---
--- 0.3337280750274658 seconds for one epoch ---
--- 1.7385823726654053 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989158]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.2332]
 [  0.    ]]
--- 0.3010692596435547 seconds for one epoch ---
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3556.325927734375, (1451.099, 1.2189323, 2103.5864, 0.4216691)
   validation loss 1070.8779296875, (747.96124, 0.21535473, 322.27972, 0.4216691)
decoder loss ratio: 28977.317059, decoder SINDy loss  ratio: 0.695686
--- 0.26813435554504395 seconds for one epoch ---
--- 0.3371891975402832 seconds for one epoch ---
--- 1.7399137020111084 seconds for one epoch ---
--- 0.3211052417755127 seconds for one epoch ---
--- 1.7285215854644775 seconds for one epoch ---
--- 0.3144717216491699 seconds for one epoch ---
--- 1.759345293045044 seconds for one epoch ---
--- 0.3238484859466553 seconds for one epoch ---
--- 1.737720251083374 seconds for one epoch ---
--- 0.3358490467071533 seconds for one epoch ---
--- 1.7407917976379395 seconds for one epoch ---
--- 0.32275891304016113 seconds for one epoch ---
--- 1.7582788467407227 seconds for one epoch ---
--- 0.32433605194091797 seconds for one epoch ---
--- 1.7627415657043457 seconds for one epoch ---
--- 0.320650577545166 seconds for one epoch ---
--- 1.7669639587402344 seconds for one epoch ---
--- 0.32042503356933594 seconds for one epoch ---
--- 1.7422764301300049 seconds for one epoch ---
--- 0.3238210678100586 seconds for one epoch ---
--- 1.762336254119873 seconds for one epoch ---
--- 0.31402111053466797 seconds for one epoch ---
--- 1.797478437423706 seconds for one epoch ---
--- 0.32181429862976074 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989299]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.272352]
 [  0.      ]]
--- 0.27518630027770996 seconds for one epoch ---
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2366.0380859375, (1356.3307, 0.52821815, 1008.75653, 0.4226741)
   validation loss 1019.2835693359375, (692.49603, 0.2765681, 326.08832, 0.4226741)
decoder loss ratio: 26828.498533, decoder SINDy loss  ratio: 0.703908
--- 0.31439805030822754 seconds for one epoch ---
--- 1.754347801208496 seconds for one epoch ---
--- 0.33595800399780273 seconds for one epoch ---
--- 1.7507758140563965 seconds for one epoch ---
--- 0.3287079334259033 seconds for one epoch ---
--- 1.7973065376281738 seconds for one epoch ---
--- 0.32444095611572266 seconds for one epoch ---
--- 1.7775952816009521 seconds for one epoch ---
--- 0.3067610263824463 seconds for one epoch ---
--- 1.8031995296478271 seconds for one epoch ---
--- 0.3320801258087158 seconds for one epoch ---
--- 1.7616796493530273 seconds for one epoch ---
--- 0.32587361335754395 seconds for one epoch ---
--- 1.799232006072998 seconds for one epoch ---
--- 0.3104543685913086 seconds for one epoch ---
--- 1.7573847770690918 seconds for one epoch ---
--- 0.32968592643737793 seconds for one epoch ---
--- 1.8086395263671875 seconds for one epoch ---
--- 0.32734060287475586 seconds for one epoch ---
--- 1.8050806522369385 seconds for one epoch ---
--- 0.3221461772918701 seconds for one epoch ---
--- 1.7562296390533447 seconds for one epoch ---
--- 0.32289862632751465 seconds for one epoch ---
--- 1.7791714668273926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99895024]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.325897]
 [ -0.      ]]
--- 0.31281328201293945 seconds for one epoch ---
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2338.95947265625, (1031.1473, 1.4487386, 1305.9396, 0.42391157)
   validation loss 885.7860717773438, (587.0855, 0.34774455, 297.92896, 0.42391157)
decoder loss ratio: 22744.711893, decoder SINDy loss  ratio: 0.643122
--- 0.27557849884033203 seconds for one epoch ---
--- 0.31264567375183105 seconds for one epoch ---
--- 1.7949061393737793 seconds for one epoch ---
--- 0.33971548080444336 seconds for one epoch ---
--- 1.8015995025634766 seconds for one epoch ---
--- 0.3223228454589844 seconds for one epoch ---
--- 1.7693073749542236 seconds for one epoch ---
--- 0.3231949806213379 seconds for one epoch ---
--- 1.8007841110229492 seconds for one epoch ---
--- 0.3282027244567871 seconds for one epoch ---
--- 1.7877833843231201 seconds for one epoch ---
--- 0.3190171718597412 seconds for one epoch ---
--- 1.7810320854187012 seconds for one epoch ---
--- 0.3296654224395752 seconds for one epoch ---
--- 1.754439115524292 seconds for one epoch ---
--- 0.32413363456726074 seconds for one epoch ---
--- 1.776463270187378 seconds for one epoch ---
--- 0.3086836338043213 seconds for one epoch ---
--- 1.7693040370941162 seconds for one epoch ---
--- 0.32320523262023926 seconds for one epoch ---
--- 1.7638912200927734 seconds for one epoch ---
--- 0.32841014862060547 seconds for one epoch ---
--- 1.798572301864624 seconds for one epoch ---
--- 0.336383581161499 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99896705]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.373123]
 [ -0.      ]]
--- 0.26569676399230957 seconds for one epoch ---
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2651.052734375, (794.70953, 0.8735381, 1855.0447, 0.42504278)
   validation loss 719.4566040039062, (439.89124, 0.30601227, 278.83432, 0.42504278)
decoder loss ratio: 17042.150142, decoder SINDy loss  ratio: 0.601903
--- 0.3093247413635254 seconds for one epoch ---
--- 1.7723169326782227 seconds for one epoch ---
--- 0.32043910026550293 seconds for one epoch ---
--- 1.7938048839569092 seconds for one epoch ---
--- 0.3202991485595703 seconds for one epoch ---
--- 1.7811639308929443 seconds for one epoch ---
--- 0.3244457244873047 seconds for one epoch ---
--- 1.7902500629425049 seconds for one epoch ---
--- 0.32266736030578613 seconds for one epoch ---
--- 1.7805941104888916 seconds for one epoch ---
--- 0.33504390716552734 seconds for one epoch ---
--- 1.7734405994415283 seconds for one epoch ---
--- 0.3197340965270996 seconds for one epoch ---
--- 1.790184736251831 seconds for one epoch ---
--- 0.3297004699707031 seconds for one epoch ---
--- 1.7794432640075684 seconds for one epoch ---
--- 0.32804179191589355 seconds for one epoch ---
--- 1.7878315448760986 seconds for one epoch ---
--- 0.3311893939971924 seconds for one epoch ---
--- 1.789076805114746 seconds for one epoch ---
--- 0.29692554473876953 seconds for one epoch ---
--- 1.772336721420288 seconds for one epoch ---
--- 0.3268702030181885 seconds for one epoch ---
--- 1.8078978061676025 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989822]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.412798]
 [  0.      ]]
--- 0.2953062057495117 seconds for one epoch ---
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2787.801025390625, (1055.6989, 7.826571, 1723.8495, 0.4260132)
   validation loss 1196.5086669921875, (846.24475, 0.37166166, 349.46628, 0.4260132)
decoder loss ratio: 32784.990798, decoder SINDy loss  ratio: 0.754372
--- 0.2657480239868164 seconds for one epoch ---
--- 0.3321375846862793 seconds for one epoch ---
--- 1.780644178390503 seconds for one epoch ---
--- 0.32410764694213867 seconds for one epoch ---
--- 1.8109393119812012 seconds for one epoch ---
--- 0.33624696731567383 seconds for one epoch ---
--- 1.7885456085205078 seconds for one epoch ---
--- 0.3225083351135254 seconds for one epoch ---
--- 1.8045439720153809 seconds for one epoch ---
--- 0.31886982917785645 seconds for one epoch ---
--- 1.7836265563964844 seconds for one epoch ---
--- 0.3188743591308594 seconds for one epoch ---
--- 1.8326654434204102 seconds for one epoch ---
--- 0.327068567276001 seconds for one epoch ---
--- 1.8113939762115479 seconds for one epoch ---
--- 0.3150460720062256 seconds for one epoch ---
--- 1.7745182514190674 seconds for one epoch ---
--- 0.3265869617462158 seconds for one epoch ---
--- 1.7892532348632812 seconds for one epoch ---
--- 0.32944607734680176 seconds for one epoch ---
--- 1.8147249221801758 seconds for one epoch ---
--- 0.3293006420135498 seconds for one epoch ---
--- 1.7998685836791992 seconds for one epoch ---
--- 0.3116109371185303 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899787]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.46031]
 [ -0.     ]]
--- 0.27823925018310547 seconds for one epoch ---
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2963.12451171875, (1139.6982, 0.90608054, 1822.0931, 0.42707068)
   validation loss 895.400634765625, (599.8759, 0.35575485, 294.74188, 0.42707068)
decoder loss ratio: 23240.234398, decoder SINDy loss  ratio: 0.636242
--- 0.31658101081848145 seconds for one epoch ---
--- 1.7949447631835938 seconds for one epoch ---
--- 0.3275301456451416 seconds for one epoch ---
--- 1.7933382987976074 seconds for one epoch ---
--- 0.33286023139953613 seconds for one epoch ---
--- 1.830559492111206 seconds for one epoch ---
--- 0.3202800750732422 seconds for one epoch ---
--- 1.8317911624908447 seconds for one epoch ---
--- 0.314786434173584 seconds for one epoch ---
--- 1.8486075401306152 seconds for one epoch ---
--- 0.3255763053894043 seconds for one epoch ---
--- 1.7930097579956055 seconds for one epoch ---
--- 0.32125020027160645 seconds for one epoch ---
--- 1.8417973518371582 seconds for one epoch ---
--- 0.3224213123321533 seconds for one epoch ---
--- 1.8241033554077148 seconds for one epoch ---
--- 0.31441688537597656 seconds for one epoch ---
--- 1.8177030086517334 seconds for one epoch ---
--- 0.32462596893310547 seconds for one epoch ---
--- 1.760298490524292 seconds for one epoch ---
--- 0.3250570297241211 seconds for one epoch ---
--- 1.8517100811004639 seconds for one epoch ---
--- 0.31828737258911133 seconds for one epoch ---
--- 1.8250930309295654 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99901164]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.502026]
 [  0.      ]]
--- 0.2918522357940674 seconds for one epoch ---
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2799.096435546875, (845.88696, 8.034526, 1944.7468, 0.42806578)
   validation loss 855.1410522460938, (570.9416, 0.34176922, 283.42966, 0.42806578)
decoder loss ratio: 22119.268370, decoder SINDy loss  ratio: 0.611823
THRESHOLDING: 1 active coefficients
--- 1.770293951034546 seconds for one epoch ---
--- 0.3259272575378418 seconds for one epoch ---
--- 1.8278565406799316 seconds for one epoch ---
--- 0.3233668804168701 seconds for one epoch ---
--- 1.803255558013916 seconds for one epoch ---
--- 0.32463765144348145 seconds for one epoch ---
--- 1.8532624244689941 seconds for one epoch ---
--- 0.33114171028137207 seconds for one epoch ---
--- 1.800008773803711 seconds for one epoch ---
--- 0.32596921920776367 seconds for one epoch ---
--- 1.8128974437713623 seconds for one epoch ---
--- 0.327866792678833 seconds for one epoch ---
--- 1.8466124534606934 seconds for one epoch ---
--- 0.31311821937561035 seconds for one epoch ---
--- 1.8258521556854248 seconds for one epoch ---
--- 0.3316771984100342 seconds for one epoch ---
--- 1.8469293117523193 seconds for one epoch ---
--- 0.31435585021972656 seconds for one epoch ---
--- 1.8385674953460693 seconds for one epoch ---
--- 0.3271219730377197 seconds for one epoch ---
--- 1.8860013484954834 seconds for one epoch ---
--- 0.33054447174072266 seconds for one epoch ---
--- 1.8582782745361328 seconds for one epoch ---
--- 0.31745457649230957 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990266]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.549908]
 [  0.      ]]
--- 0.2760143280029297 seconds for one epoch ---
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3193.17041015625, (1174.9426, 2.4085612, 2015.3899, 0.42924508)
   validation loss 1557.3736572265625, (1170.8365, 0.3153102, 385.79263, 0.42924508)
decoder loss ratio: 45360.240525, decoder SINDy loss  ratio: 0.832788
--- 0.3190302848815918 seconds for one epoch ---
--- 1.8470160961151123 seconds for one epoch ---
--- 0.33524513244628906 seconds for one epoch ---
--- 1.825613260269165 seconds for one epoch ---
--- 0.32987475395202637 seconds for one epoch ---
--- 1.8580005168914795 seconds for one epoch ---
--- 0.32883119583129883 seconds for one epoch ---
--- 1.8341569900512695 seconds for one epoch ---
--- 0.33194947242736816 seconds for one epoch ---
--- 1.8652980327606201 seconds for one epoch ---
--- 0.3299887180328369 seconds for one epoch ---
--- 1.8754208087921143 seconds for one epoch ---
--- 0.33367276191711426 seconds for one epoch ---
--- 1.8489584922790527 seconds for one epoch ---
--- 0.3154449462890625 seconds for one epoch ---
--- 1.883955717086792 seconds for one epoch ---
--- 0.3463273048400879 seconds for one epoch ---
--- 1.857130527496338 seconds for one epoch ---
--- 0.3324306011199951 seconds for one epoch ---
--- 1.8399653434753418 seconds for one epoch ---
--- 0.3240797519683838 seconds for one epoch ---
--- 1.9027388095855713 seconds for one epoch ---
--- 0.32183289527893066 seconds for one epoch ---
--- 1.8915855884552002 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904084]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.589134]
 [ -0.      ]]
--- 0.309830904006958 seconds for one epoch ---
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3337.84130859375, (1247.0048, 1.4213402, 2088.9849, 0.43016186)
   validation loss 963.8521118164062, (651.3368, 0.31286713, 311.77228, 0.43016186)
decoder loss ratio: 25233.918092, decoder SINDy loss  ratio: 0.673004
--- 0.27594661712646484 seconds for one epoch ---
--- 0.3240993022918701 seconds for one epoch ---
--- 1.8829481601715088 seconds for one epoch ---
--- 0.3338892459869385 seconds for one epoch ---
--- 1.8724303245544434 seconds for one epoch ---
--- 0.32678818702697754 seconds for one epoch ---
--- 1.8638999462127686 seconds for one epoch ---
--- 0.3400132656097412 seconds for one epoch ---
--- 1.9006469249725342 seconds for one epoch ---
--- 0.324739933013916 seconds for one epoch ---
--- 1.8979828357696533 seconds for one epoch ---
--- 0.3304433822631836 seconds for one epoch ---
--- 1.8567299842834473 seconds for one epoch ---
--- 0.3384561538696289 seconds for one epoch ---
--- 1.855069875717163 seconds for one epoch ---
--- 0.3204357624053955 seconds for one epoch ---
--- 1.8844668865203857 seconds for one epoch ---
--- 0.32199621200561523 seconds for one epoch ---
--- 1.8604538440704346 seconds for one epoch ---
--- 0.32656049728393555 seconds for one epoch ---
--- 1.8914437294006348 seconds for one epoch ---
--- 0.3305511474609375 seconds for one epoch ---
--- 1.8969969749450684 seconds for one epoch ---
--- 0.33423852920532227 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905074]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.622643]
 [ -0.      ]]
--- 0.258237361907959 seconds for one epoch ---
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3667.783203125, (1627.2081, 4.6815357, 2035.4624, 0.4310696)
   validation loss 970.113525390625, (661.7343, 0.32329968, 307.62482, 0.4310696)
decoder loss ratio: 25636.736144, decoder SINDy loss  ratio: 0.664051
--- 0.32651329040527344 seconds for one epoch ---
--- 1.8759958744049072 seconds for one epoch ---
--- 0.32485508918762207 seconds for one epoch ---
--- 1.8871924877166748 seconds for one epoch ---
--- 0.30984926223754883 seconds for one epoch ---
--- 1.8622965812683105 seconds for one epoch ---
--- 0.3344845771789551 seconds for one epoch ---
--- 1.8910996913909912 seconds for one epoch ---
--- 0.32172250747680664 seconds for one epoch ---
--- 1.8682677745819092 seconds for one epoch ---
--- 0.3148612976074219 seconds for one epoch ---
--- 1.889690637588501 seconds for one epoch ---
--- 0.33582639694213867 seconds for one epoch ---
--- 1.9027223587036133 seconds for one epoch ---
--- 0.32980847358703613 seconds for one epoch ---
--- 1.9170010089874268 seconds for one epoch ---
--- 0.3335988521575928 seconds for one epoch ---
--- 1.8832731246948242 seconds for one epoch ---
--- 0.32978248596191406 seconds for one epoch ---
--- 1.8725836277008057 seconds for one epoch ---
--- 0.3307504653930664 seconds for one epoch ---
--- 1.909189224243164 seconds for one epoch ---
--- 0.33640599250793457 seconds for one epoch ---
--- 1.9231669902801514 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990634]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.663557]
 [  0.      ]]
--- 0.3095688819885254 seconds for one epoch ---
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2897.46826171875, (1285.6481, 0.967194, 1610.4209, 0.4320583)
   validation loss 930.0270385742188, (614.2055, 0.33697823, 315.05252, 0.4320583)
decoder loss ratio: 23795.387586, decoder SINDy loss  ratio: 0.680085
--- 0.27739953994750977 seconds for one epoch ---
--- 0.341904878616333 seconds for one epoch ---
--- 1.902968406677246 seconds for one epoch ---
--- 0.3404402732849121 seconds for one epoch ---
--- 1.8836712837219238 seconds for one epoch ---
--- 0.3291738033294678 seconds for one epoch ---
--- 1.8587148189544678 seconds for one epoch ---
--- 0.30556821823120117 seconds for one epoch ---
--- 1.867661714553833 seconds for one epoch ---
--- 0.32996535301208496 seconds for one epoch ---
--- 1.8980419635772705 seconds for one epoch ---
--- 0.3300302028656006 seconds for one epoch ---
--- 1.9092512130737305 seconds for one epoch ---
--- 0.30823302268981934 seconds for one epoch ---
--- 1.8706789016723633 seconds for one epoch ---
--- 0.3302633762359619 seconds for one epoch ---
--- 1.8756256103515625 seconds for one epoch ---
--- 0.32755565643310547 seconds for one epoch ---
--- 1.8721740245819092 seconds for one epoch ---
--- 0.32067227363586426 seconds for one epoch ---
--- 1.9161689281463623 seconds for one epoch ---
--- 0.335599422454834 seconds for one epoch ---
--- 1.8944923877716064 seconds for one epoch ---
--- 0.32129740715026855 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99908024]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.715538]
 [ -0.      ]]
--- 0.268521785736084 seconds for one epoch ---
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1288.2408447265625, (543.79047, 0.44469053, 743.5723, 0.43335614)
   validation loss 779.0092163085938, (497.7287, 0.33509907, 280.51205, 0.43335614)
decoder loss ratio: 19282.873884, decoder SINDy loss  ratio: 0.605525
--- 0.31434035301208496 seconds for one epoch ---
--- 1.8999323844909668 seconds for one epoch ---
--- 0.3207273483276367 seconds for one epoch ---
--- 1.8648314476013184 seconds for one epoch ---
--- 0.3313438892364502 seconds for one epoch ---
--- 1.928743600845337 seconds for one epoch ---
--- 0.3216416835784912 seconds for one epoch ---
--- 1.9072213172912598 seconds for one epoch ---
--- 0.325336217880249 seconds for one epoch ---
--- 1.9076271057128906 seconds for one epoch ---
--- 0.3341798782348633 seconds for one epoch ---
--- 1.924525499343872 seconds for one epoch ---
--- 0.3336663246154785 seconds for one epoch ---
--- 1.9086813926696777 seconds for one epoch ---
--- 0.3329589366912842 seconds for one epoch ---
--- 1.8944549560546875 seconds for one epoch ---
--- 0.3316776752471924 seconds for one epoch ---
--- 1.893582820892334 seconds for one epoch ---
--- 0.3376293182373047 seconds for one epoch ---
--- 1.9275727272033691 seconds for one epoch ---
--- 0.3388054370880127 seconds for one epoch ---
--- 1.8951237201690674 seconds for one epoch ---
--- 0.3253343105316162 seconds for one epoch ---
--- 1.927455186843872 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99909127]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.754097]
 [  0.      ]]
--- 0.31516575813293457 seconds for one epoch ---
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3395.955810546875, (1150.5326, 4.2047205, 2240.7842, 0.43422833)
   validation loss 1004.0487670898438, (720.50867, 0.3484172, 282.7575, 0.43422833)
decoder loss ratio: 27913.756617, decoder SINDy loss  ratio: 0.610372
--- 0.2689943313598633 seconds for one epoch ---
--- 0.3345367908477783 seconds for one epoch ---
--- 1.9077513217926025 seconds for one epoch ---
--- 0.32830357551574707 seconds for one epoch ---
--- 1.8882014751434326 seconds for one epoch ---
--- 0.3375086784362793 seconds for one epoch ---
--- 1.9008829593658447 seconds for one epoch ---
--- 0.32636213302612305 seconds for one epoch ---
--- 1.913672924041748 seconds for one epoch ---
--- 0.3193671703338623 seconds for one epoch ---
--- 1.9137964248657227 seconds for one epoch ---
--- 0.33152103424072266 seconds for one epoch ---
--- 1.9319844245910645 seconds for one epoch ---
--- 0.34252285957336426 seconds for one epoch ---
--- 1.917006015777588 seconds for one epoch ---
--- 0.33087992668151855 seconds for one epoch ---
--- 1.9168665409088135 seconds for one epoch ---
--- 0.31446075439453125 seconds for one epoch ---
--- 1.882528305053711 seconds for one epoch ---
--- 0.33837437629699707 seconds for one epoch ---
--- 1.9046032428741455 seconds for one epoch ---
--- 0.3240935802459717 seconds for one epoch ---
--- 1.9409229755401611 seconds for one epoch ---
--- 0.3345224857330322 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991032]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.793922]
 [  0.      ]]
--- 0.27531886100769043 seconds for one epoch ---
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2253.74560546875, (966.5312, 0.40924573, 1286.3701, 0.4351542)
   validation loss 1059.0653076171875, (739.0793, 0.34795478, 319.20282, 0.4351542)
decoder loss ratio: 28633.214586, decoder SINDy loss  ratio: 0.689044
--- 0.3124411106109619 seconds for one epoch ---
--- 1.923424243927002 seconds for one epoch ---
--- 0.33269572257995605 seconds for one epoch ---
--- 1.9400317668914795 seconds for one epoch ---
--- 0.33219099044799805 seconds for one epoch ---
--- 1.916308879852295 seconds for one epoch ---
--- 0.326890230178833 seconds for one epoch ---
--- 1.9259018898010254 seconds for one epoch ---
--- 0.3175334930419922 seconds for one epoch ---
--- 1.9344556331634521 seconds for one epoch ---
--- 0.32024145126342773 seconds for one epoch ---
--- 1.9482288360595703 seconds for one epoch ---
--- 0.3215663433074951 seconds for one epoch ---
--- 1.9098680019378662 seconds for one epoch ---
--- 0.32308340072631836 seconds for one epoch ---
--- 1.9204604625701904 seconds for one epoch ---
--- 0.3151404857635498 seconds for one epoch ---
--- 1.9437575340270996 seconds for one epoch ---
--- 0.32686495780944824 seconds for one epoch ---
--- 1.9152874946594238 seconds for one epoch ---
--- 0.32150697708129883 seconds for one epoch ---
--- 1.959937572479248 seconds for one epoch ---
--- 0.3201889991760254 seconds for one epoch ---
--- 1.9340035915374756 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99911606]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.834694]
 [ -0.      ]]
--- 0.3099021911621094 seconds for one epoch ---
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2614.056396484375, (1136.7792, 1.2607005, 1475.5801, 0.4362131)
   validation loss 1424.5103759765625, (1102.1511, 0.30797565, 321.61514, 0.4362131)
decoder loss ratio: 42699.247925, decoder SINDy loss  ratio: 0.694252
--- 0.2811446189880371 seconds for one epoch ---
--- 0.3206944465637207 seconds for one epoch ---
--- 1.8927974700927734 seconds for one epoch ---
--- 0.340390682220459 seconds for one epoch ---
--- 1.9417729377746582 seconds for one epoch ---
--- 0.3344764709472656 seconds for one epoch ---
--- 1.9466266632080078 seconds for one epoch ---
--- 0.3316965103149414 seconds for one epoch ---
--- 1.9157209396362305 seconds for one epoch ---
--- 0.3323044776916504 seconds for one epoch ---
--- 1.9288873672485352 seconds for one epoch ---
--- 0.32366347312927246 seconds for one epoch ---
--- 1.9206156730651855 seconds for one epoch ---
--- 0.3319880962371826 seconds for one epoch ---
--- 1.964141607284546 seconds for one epoch ---
--- 0.32977771759033203 seconds for one epoch ---
--- 1.9123785495758057 seconds for one epoch ---
--- 0.3121461868286133 seconds for one epoch ---
--- 1.9766368865966797 seconds for one epoch ---
--- 0.32576966285705566 seconds for one epoch ---
--- 1.921149730682373 seconds for one epoch ---
--- 0.32737112045288086 seconds for one epoch ---
--- 1.9565775394439697 seconds for one epoch ---
--- 0.32133913040161133 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991264]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.874725]
 [ -0.      ]]
--- 0.250624418258667 seconds for one epoch ---
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6891.00439453125, (1782.0149, 13.369176, 5095.183, 0.43715468)
   validation loss 983.8486328125, (681.0014, 0.32590628, 302.08414, 0.43715468)
decoder loss ratio: 26383.176654, decoder SINDy loss  ratio: 0.652091
--- 0.30890417098999023 seconds for one epoch ---
--- 1.9290499687194824 seconds for one epoch ---
--- 0.31511783599853516 seconds for one epoch ---
--- 1.9776008129119873 seconds for one epoch ---
--- 0.32762694358825684 seconds for one epoch ---
--- 1.945326328277588 seconds for one epoch ---
--- 0.32514429092407227 seconds for one epoch ---
--- 1.955110788345337 seconds for one epoch ---
--- 0.3096272945404053 seconds for one epoch ---
--- 1.9592430591583252 seconds for one epoch ---
--- 0.32749128341674805 seconds for one epoch ---
--- 1.948211908340454 seconds for one epoch ---
--- 0.2999563217163086 seconds for one epoch ---
--- 1.9399631023406982 seconds for one epoch ---
--- 0.3262455463409424 seconds for one epoch ---
--- 1.9861664772033691 seconds for one epoch ---
--- 0.3325459957122803 seconds for one epoch ---
--- 1.9275329113006592 seconds for one epoch ---
--- 0.32062745094299316 seconds for one epoch ---
--- 1.974595308303833 seconds for one epoch ---
--- 0.3175172805786133 seconds for one epoch ---
--- 1.9599251747131348 seconds for one epoch ---
--- 0.3197643756866455 seconds for one epoch ---
--- 1.9997236728668213 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99913967]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.923903]
 [  0.      ]]
--- 0.305194616317749 seconds for one epoch ---
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5600.2998046875, (1967.3674, 4.897021, 3627.5972, 0.4383647)
   validation loss 915.2333984375, (610.14246, 0.33996105, 304.31265, 0.4383647)
decoder loss ratio: 23637.978001, decoder SINDy loss  ratio: 0.656902
--- 0.2707686424255371 seconds for one epoch ---
--- 0.33683061599731445 seconds for one epoch ---
--- 1.9332449436187744 seconds for one epoch ---
--- 0.3196077346801758 seconds for one epoch ---
--- 1.994382381439209 seconds for one epoch ---
--- 0.3301267623901367 seconds for one epoch ---
--- 1.9605271816253662 seconds for one epoch ---
--- 0.32840752601623535 seconds for one epoch ---
--- 1.979062557220459 seconds for one epoch ---
--- 0.3340775966644287 seconds for one epoch ---
--- 1.9540650844573975 seconds for one epoch ---
--- 0.3223137855529785 seconds for one epoch ---
--- 1.9825451374053955 seconds for one epoch ---
--- 0.325164794921875 seconds for one epoch ---
--- 1.9600927829742432 seconds for one epoch ---
--- 0.3231391906738281 seconds for one epoch ---
--- 1.95013427734375 seconds for one epoch ---
--- 0.3200705051422119 seconds for one epoch ---
--- 1.9692745208740234 seconds for one epoch ---
--- 0.3232412338256836 seconds for one epoch ---
--- 1.9517087936401367 seconds for one epoch ---
--- 0.3279290199279785 seconds for one epoch ---
--- 1.9487667083740234 seconds for one epoch ---
--- 0.3271656036376953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915147]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.959057]
 [ -0.      ]]
--- 0.2724432945251465 seconds for one epoch ---
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2800.920166015625, (1792.7516, 0.3741809, 1007.35535, 0.43925038)
   validation loss 1057.8251953125, (768.9298, 0.3184804, 288.1377, 0.43925038)
decoder loss ratio: 29789.675744, decoder SINDy loss  ratio: 0.621986
--- 0.31078648567199707 seconds for one epoch ---
--- 1.9345178604125977 seconds for one epoch ---
--- 0.32873058319091797 seconds for one epoch ---
--- 1.9742581844329834 seconds for one epoch ---
--- 0.34150028228759766 seconds for one epoch ---
--- 1.9930849075317383 seconds for one epoch ---
--- 0.33774328231811523 seconds for one epoch ---
--- 1.9505887031555176 seconds for one epoch ---
--- 0.3286004066467285 seconds for one epoch ---
--- 1.9931440353393555 seconds for one epoch ---
--- 0.3303699493408203 seconds for one epoch ---
--- 1.9955849647521973 seconds for one epoch ---
--- 0.32866907119750977 seconds for one epoch ---
--- 1.9783849716186523 seconds for one epoch ---
--- 0.3268239498138428 seconds for one epoch ---
--- 1.9764459133148193 seconds for one epoch ---
--- 0.34066319465637207 seconds for one epoch ---
--- 1.9689228534698486 seconds for one epoch ---
--- 0.3249986171722412 seconds for one epoch ---
--- 2.00028395652771 seconds for one epoch ---
--- 0.31009578704833984 seconds for one epoch ---
--- 1.9632272720336914 seconds for one epoch ---
--- 0.3215606212615967 seconds for one epoch ---
--- 1.95987868309021 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916065]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.998222]
 [  0.      ]]
--- 0.3069779872894287 seconds for one epoch ---
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3867.965576171875, (1822.3756, 0.2804798, 2044.8694, 0.44018862)
   validation loss 1013.2438354492188, (689.08527, 0.32931358, 323.3891, 0.44018862)
decoder loss ratio: 26696.359514, decoder SINDy loss  ratio: 0.698081
--- 0.2723348140716553 seconds for one epoch ---
--- 0.3219590187072754 seconds for one epoch ---
--- 1.9642305374145508 seconds for one epoch ---
--- 0.3409254550933838 seconds for one epoch ---
--- 1.9639644622802734 seconds for one epoch ---
--- 0.3222942352294922 seconds for one epoch ---
--- 1.9705805778503418 seconds for one epoch ---
--- 0.32918381690979004 seconds for one epoch ---
--- 1.9605212211608887 seconds for one epoch ---
--- 0.3130378723144531 seconds for one epoch ---
--- 1.964076042175293 seconds for one epoch ---
--- 0.3226022720336914 seconds for one epoch ---
--- 1.9940993785858154 seconds for one epoch ---
--- 0.3242838382720947 seconds for one epoch ---
--- 1.9847447872161865 seconds for one epoch ---
--- 0.3266794681549072 seconds for one epoch ---
--- 1.9761888980865479 seconds for one epoch ---
--- 0.32674193382263184 seconds for one epoch ---
--- 2.0125887393951416 seconds for one epoch ---
--- 0.3346850872039795 seconds for one epoch ---
--- 1.9631171226501465 seconds for one epoch ---
--- 0.3257730007171631 seconds for one epoch ---
--- 1.982696294784546 seconds for one epoch ---
--- 0.3209950923919678 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991714]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.037748]
 [  0.      ]]
--- 0.2712438106536865 seconds for one epoch ---
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2505.490478515625, (1179.9557, 2.667795, 1322.4258, 0.44118485)
   validation loss 900.3846435546875, (598.7401, 0.35257968, 300.85077, 0.44118485)
decoder loss ratio: 23196.231409, decoder SINDy loss  ratio: 0.649429
--- 0.3142988681793213 seconds for one epoch ---
--- 1.9718279838562012 seconds for one epoch ---
--- 0.3276035785675049 seconds for one epoch ---
--- 2.025719404220581 seconds for one epoch ---
--- 0.33216285705566406 seconds for one epoch ---
--- 1.9695451259613037 seconds for one epoch ---
--- 0.334580659866333 seconds for one epoch ---
--- 2.0066726207733154 seconds for one epoch ---
--- 0.3232917785644531 seconds for one epoch ---
--- 1.974865198135376 seconds for one epoch ---
--- 0.3209500312805176 seconds for one epoch ---
--- 2.0219886302948 seconds for one epoch ---
--- 0.330981969833374 seconds for one epoch ---
--- 2.01424241065979 seconds for one epoch ---
--- 0.3419051170349121 seconds for one epoch ---
--- 1.9880082607269287 seconds for one epoch ---
--- 0.32665324211120605 seconds for one epoch ---
--- 2.0035808086395264 seconds for one epoch ---
--- 0.3344259262084961 seconds for one epoch ---
--- 1.9890894889831543 seconds for one epoch ---
--- 0.33205723762512207 seconds for one epoch ---
--- 1.9874169826507568 seconds for one epoch ---
--- 0.326305627822876 seconds for one epoch ---
--- 2.0052249431610107 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991793]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.070232]
 [ -0.      ]]
--- 0.30861639976501465 seconds for one epoch ---
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2672.15380859375, (928.1787, 4.552967, 1738.9801, 0.44199505)
   validation loss 779.066162109375, (509.90915, 0.41960174, 268.29535, 0.44199505)
decoder loss ratio: 19754.765680, decoder SINDy loss  ratio: 0.579153
--- 0.273423433303833 seconds for one epoch ---
--- 0.32888364791870117 seconds for one epoch ---
--- 2.007356643676758 seconds for one epoch ---
--- 0.32385778427124023 seconds for one epoch ---
--- 1.9927029609680176 seconds for one epoch ---
--- 0.32927846908569336 seconds for one epoch ---
--- 2.0241575241088867 seconds for one epoch ---
--- 0.33190417289733887 seconds for one epoch ---
--- 1.982515811920166 seconds for one epoch ---
--- 0.3283247947692871 seconds for one epoch ---
--- 2.017644166946411 seconds for one epoch ---
--- 0.3233528137207031 seconds for one epoch ---
--- 1.9998703002929688 seconds for one epoch ---
--- 0.3206443786621094 seconds for one epoch ---
--- 2.0092084407806396 seconds for one epoch ---
--- 0.32979321479797363 seconds for one epoch ---
--- 2.0251247882843018 seconds for one epoch ---
--- 0.3254380226135254 seconds for one epoch ---
--- 1.9989042282104492 seconds for one epoch ---
--- 0.32596850395202637 seconds for one epoch ---
--- 2.0100250244140625 seconds for one epoch ---
--- 0.3337209224700928 seconds for one epoch ---
--- 2.0044360160827637 seconds for one epoch ---
--- 0.31937551498413086 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991895]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.10493]
 [ -0.     ]]
--- 0.2743542194366455 seconds for one epoch ---
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3374.5888671875, (2024.5795, 0.8696406, 1348.697, 0.44286296)
   validation loss 1347.6766357421875, (997.5592, 0.336933, 349.33762, 0.44286296)
decoder loss ratio: 38647.175406, decoder SINDy loss  ratio: 0.754094
--- 0.30697202682495117 seconds for one epoch ---
--- 2.055535316467285 seconds for one epoch ---
--- 0.3167433738708496 seconds for one epoch ---
--- 1.989457130432129 seconds for one epoch ---
--- 0.33388590812683105 seconds for one epoch ---
--- 2.0440473556518555 seconds for one epoch ---
--- 0.686161994934082 seconds for one epoch ---
--- 2.0295658111572266 seconds for one epoch ---
--- 0.317058801651001 seconds for one epoch ---
--- 1.9870126247406006 seconds for one epoch ---
--- 0.33492493629455566 seconds for one epoch ---
--- 2.022149085998535 seconds for one epoch ---
--- 0.32553911209106445 seconds for one epoch ---
--- 2.0030336380004883 seconds for one epoch ---
--- 0.3228883743286133 seconds for one epoch ---
--- 2.0022635459899902 seconds for one epoch ---
--- 0.3092830181121826 seconds for one epoch ---
--- 2.0144989490509033 seconds for one epoch ---
--- 0.32967543601989746 seconds for one epoch ---
--- 2.0207135677337646 seconds for one epoch ---
--- 0.32250404357910156 seconds for one epoch ---
--- 2.041877508163452 seconds for one epoch ---
--- 0.31552958488464355 seconds for one epoch ---
--- 2.0092899799346924 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991987]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.146215]
 [  0.      ]]
--- 0.30900073051452637 seconds for one epoch ---
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2821.28173828125, (1389.0168, 0.60441846, 1431.2168, 0.44391844)
   validation loss 888.3309936523438, (572.9289, 0.31259522, 314.64554, 0.44391844)
decoder loss ratio: 22196.260004, decoder SINDy loss  ratio: 0.679207
--- 0.2798140048980713 seconds for one epoch ---
--- 0.3259906768798828 seconds for one epoch ---
--- 2.004152774810791 seconds for one epoch ---
--- 0.322021484375 seconds for one epoch ---
--- 1.9958198070526123 seconds for one epoch ---
--- 0.3305933475494385 seconds for one epoch ---
--- 2.0470011234283447 seconds for one epoch ---
--- 0.3339409828186035 seconds for one epoch ---
--- 2.0490753650665283 seconds for one epoch ---
--- 0.3291442394256592 seconds for one epoch ---
--- 2.032029867172241 seconds for one epoch ---
--- 0.3315999507904053 seconds for one epoch ---
--- 2.028693675994873 seconds for one epoch ---
--- 0.328533411026001 seconds for one epoch ---
--- 2.0505900382995605 seconds for one epoch ---
--- 0.3105294704437256 seconds for one epoch ---
--- 2.0254924297332764 seconds for one epoch ---
--- 0.3253610134124756 seconds for one epoch ---
--- 2.0140960216522217 seconds for one epoch ---
--- 0.32218194007873535 seconds for one epoch ---
--- 2.048635244369507 seconds for one epoch ---
--- 0.33086609840393066 seconds for one epoch ---
--- 2.0272324085235596 seconds for one epoch ---
--- 0.33547329902648926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99920803]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.182224]
 [ -0.      ]]
--- 0.25006675720214844 seconds for one epoch ---
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2916.671875, (1177.7122, 1.6673824, 1736.8475, 0.4447863)
   validation loss 1199.161865234375, (901.36646, 0.3830821, 296.96753, 0.4447863)
decoder loss ratio: 34920.501311, decoder SINDy loss  ratio: 0.641046
--- 0.3226480484008789 seconds for one epoch ---
--- 2.065629005432129 seconds for one epoch ---
--- 0.32636356353759766 seconds for one epoch ---
--- 2.045614719390869 seconds for one epoch ---
--- 0.326906681060791 seconds for one epoch ---
--- 2.033012628555298 seconds for one epoch ---
--- 0.33090639114379883 seconds for one epoch ---
--- 2.0559229850769043 seconds for one epoch ---
--- 0.32250070571899414 seconds for one epoch ---
--- 2.052225112915039 seconds for one epoch ---
--- 0.3258218765258789 seconds for one epoch ---
--- 2.071135997772217 seconds for one epoch ---
--- 0.326369047164917 seconds for one epoch ---
--- 2.0703067779541016 seconds for one epoch ---
--- 0.3301987648010254 seconds for one epoch ---
--- 2.069887638092041 seconds for one epoch ---
--- 0.3176395893096924 seconds for one epoch ---
--- 2.019484043121338 seconds for one epoch ---
--- 0.3235633373260498 seconds for one epoch ---
--- 2.054295301437378 seconds for one epoch ---
--- 0.32146644592285156 seconds for one epoch ---
--- 2.055143356323242 seconds for one epoch ---
--- 0.3229255676269531 seconds for one epoch ---
--- 2.0397980213165283 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992161]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.21717]
 [  0.     ]]
--- 0.30170774459838867 seconds for one epoch ---
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2784.9189453125, (1243.598, 0.95923454, 1539.9158, 0.4457082)
   validation loss 754.39404296875, (473.72803, 0.3561616, 279.86414, 0.4457082)
decoder loss ratio: 18353.046207, decoder SINDy loss  ratio: 0.604126
--- 0.2817506790161133 seconds for one epoch ---
--- 0.32918405532836914 seconds for one epoch ---
--- 2.0935938358306885 seconds for one epoch ---
--- 0.3121938705444336 seconds for one epoch ---
--- 2.0673930644989014 seconds for one epoch ---
--- 0.3284111022949219 seconds for one epoch ---
--- 2.076484441757202 seconds for one epoch ---
--- 0.32857370376586914 seconds for one epoch ---
--- 2.0521464347839355 seconds for one epoch ---
--- 0.30608391761779785 seconds for one epoch ---
--- 2.060089588165283 seconds for one epoch ---
--- 0.32619476318359375 seconds for one epoch ---
--- 2.0773379802703857 seconds for one epoch ---
--- 0.32632899284362793 seconds for one epoch ---
--- 2.070622444152832 seconds for one epoch ---
--- 0.3343625068664551 seconds for one epoch ---
--- 2.0756943225860596 seconds for one epoch ---
--- 0.32984375953674316 seconds for one epoch ---
--- 2.0522642135620117 seconds for one epoch ---
--- 0.3145101070404053 seconds for one epoch ---
--- 2.0583202838897705 seconds for one epoch ---
--- 0.33220624923706055 seconds for one epoch ---
--- 2.0940639972686768 seconds for one epoch ---
--- 0.3177299499511719 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999226]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.254702]
 [  0.      ]]
--- 0.26450681686401367 seconds for one epoch ---
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2620.450439453125, (1306.2837, 0.5481065, 1313.1722, 0.44654074)
   validation loss 761.2118530273438, (488.6961, 0.38528255, 271.68393, 0.44654074)
decoder loss ratio: 18932.935559, decoder SINDy loss  ratio: 0.586468
--- 0.3172309398651123 seconds for one epoch ---
--- 2.0637290477752686 seconds for one epoch ---
--- 0.32950520515441895 seconds for one epoch ---
--- 2.0654847621917725 seconds for one epoch ---
--- 0.3371391296386719 seconds for one epoch ---
--- 2.046452760696411 seconds for one epoch ---
--- 0.3329446315765381 seconds for one epoch ---
--- 2.0799858570098877 seconds for one epoch ---
--- 0.33835911750793457 seconds for one epoch ---
--- 2.0656399726867676 seconds for one epoch ---
--- 0.3182392120361328 seconds for one epoch ---
--- 2.0796139240264893 seconds for one epoch ---
--- 0.3322129249572754 seconds for one epoch ---
--- 2.076106309890747 seconds for one epoch ---
--- 0.33005809783935547 seconds for one epoch ---
--- 2.057579517364502 seconds for one epoch ---
--- 0.31809020042419434 seconds for one epoch ---
--- 2.084463119506836 seconds for one epoch ---
--- 0.3288877010345459 seconds for one epoch ---
--- 2.071171283721924 seconds for one epoch ---
--- 0.3247702121734619 seconds for one epoch ---
--- 2.0511269569396973 seconds for one epoch ---
--- 0.3140225410461426 seconds for one epoch ---
--- 2.1038730144500732 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992328]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.282515]
 [ -0.      ]]
--- 0.3053750991821289 seconds for one epoch ---
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2799.912353515625, (1146.1626, 1.9169267, 1651.3856, 0.44726792)
   validation loss 928.4461669921875, (651.72076, 0.4170735, 275.86105, 0.44726792)
decoder loss ratio: 25248.793841, decoder SINDy loss  ratio: 0.595485
THRESHOLDING: 1 active coefficients
--- 2.010502338409424 seconds for one epoch ---
--- 0.33901453018188477 seconds for one epoch ---
--- 2.0839121341705322 seconds for one epoch ---
--- 0.32539892196655273 seconds for one epoch ---
--- 2.0575456619262695 seconds for one epoch ---
--- 0.31292057037353516 seconds for one epoch ---
--- 2.105942726135254 seconds for one epoch ---
--- 0.33002161979675293 seconds for one epoch ---
--- 2.056304693222046 seconds for one epoch ---
--- 0.32418227195739746 seconds for one epoch ---
--- 2.075484275817871 seconds for one epoch ---
--- 0.3261141777038574 seconds for one epoch ---
--- 2.095135450363159 seconds for one epoch ---
--- 0.33365464210510254 seconds for one epoch ---
--- 2.056180715560913 seconds for one epoch ---
--- 0.3235657215118408 seconds for one epoch ---
--- 2.0962653160095215 seconds for one epoch ---
--- 0.3316614627838135 seconds for one epoch ---
--- 2.0822935104370117 seconds for one epoch ---
--- 0.33957409858703613 seconds for one epoch ---
--- 2.06404185295105 seconds for one epoch ---
--- 0.32608938217163086 seconds for one epoch ---
--- 2.061918258666992 seconds for one epoch ---
--- 0.3255198001861572 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99923706]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.30712]
 [ -0.     ]]
--- 0.2701761722564697 seconds for one epoch ---
Epoch 4025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7092.37841796875, (1157.0028, 5.8891478, 5929.0386, 0.44793805)
   validation loss 1201.4404296875, (903.28326, 0.38525268, 297.3239, 0.44793805)
decoder loss ratio: 34994.761822, decoder SINDy loss  ratio: 0.641815
--- 0.2913072109222412 seconds for one epoch ---
--- 2.065551996231079 seconds for one epoch ---
--- 0.3195323944091797 seconds for one epoch ---
--- 2.067598342895508 seconds for one epoch ---
--- 0.3312344551086426 seconds for one epoch ---
--- 2.0510239601135254 seconds for one epoch ---
--- 0.32938718795776367 seconds for one epoch ---
--- 2.0929534435272217 seconds for one epoch ---
--- 0.33038830757141113 seconds for one epoch ---
--- 2.0583882331848145 seconds for one epoch ---
--- 0.33913636207580566 seconds for one epoch ---
--- 2.0942234992980957 seconds for one epoch ---
--- 0.3223693370819092 seconds for one epoch ---
--- 2.0786967277526855 seconds for one epoch ---
--- 0.31874823570251465 seconds for one epoch ---
--- 2.101400136947632 seconds for one epoch ---
--- 0.33086276054382324 seconds for one epoch ---
--- 2.097524881362915 seconds for one epoch ---
--- 0.31811070442199707 seconds for one epoch ---
--- 2.0583856105804443 seconds for one epoch ---
--- 0.32803821563720703 seconds for one epoch ---
--- 2.0980007648468018 seconds for one epoch ---
--- 0.3233315944671631 seconds for one epoch ---
--- 2.065329074859619 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99924576]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.341675]
 [  0.      ]]
--- 0.3034219741821289 seconds for one epoch ---
Epoch 4050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3073.14111328125, (1312.7599, 2.9371479, 1756.9954, 0.44880086)
   validation loss 894.2567138671875, (574.969, 0.42058495, 318.41833, 0.44880086)
decoder loss ratio: 22275.297023, decoder SINDy loss  ratio: 0.687351
--- 0.27770423889160156 seconds for one epoch ---
--- 0.3388209342956543 seconds for one epoch ---
--- 2.120023727416992 seconds for one epoch ---
--- 0.32936739921569824 seconds for one epoch ---
--- 2.077319860458374 seconds for one epoch ---
--- 0.3315098285675049 seconds for one epoch ---
--- 2.067620277404785 seconds for one epoch ---
--- 0.3246791362762451 seconds for one epoch ---
--- 2.0892021656036377 seconds for one epoch ---
--- 0.32410454750061035 seconds for one epoch ---
--- 2.1183176040649414 seconds for one epoch ---
--- 0.32248449325561523 seconds for one epoch ---
--- 2.10465931892395 seconds for one epoch ---
--- 0.329265832901001 seconds for one epoch ---
--- 2.1440982818603516 seconds for one epoch ---
--- 0.32356858253479004 seconds for one epoch ---
--- 2.12368106842041 seconds for one epoch ---
--- 0.32012939453125 seconds for one epoch ---
--- 2.0782976150512695 seconds for one epoch ---
--- 0.3400146961212158 seconds for one epoch ---
--- 2.095388412475586 seconds for one epoch ---
--- 0.3309314250946045 seconds for one epoch ---
--- 2.0921666622161865 seconds for one epoch ---
--- 0.3133237361907959 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992533]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.375246]
 [ -0.      ]]
--- 0.25864124298095703 seconds for one epoch ---
Epoch 4075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3790.576171875, (1548.0111, 1.4029323, 2240.7124, 0.44963858)
   validation loss 875.3333129882812, (574.99243, 0.40387684, 299.48734, 0.44963858)
decoder loss ratio: 22276.205033, decoder SINDy loss  ratio: 0.646486
--- 0.3148806095123291 seconds for one epoch ---
--- 2.0892324447631836 seconds for one epoch ---
--- 0.3254573345184326 seconds for one epoch ---
--- 2.1192731857299805 seconds for one epoch ---
--- 0.33330869674682617 seconds for one epoch ---
--- 2.1310391426086426 seconds for one epoch ---
--- 0.32549142837524414 seconds for one epoch ---
--- 2.078652858734131 seconds for one epoch ---
--- 0.3318970203399658 seconds for one epoch ---
--- 2.1085762977600098 seconds for one epoch ---
--- 0.3321492671966553 seconds for one epoch ---
--- 2.1491928100585938 seconds for one epoch ---
--- 0.3257763385772705 seconds for one epoch ---
--- 2.147212505340576 seconds for one epoch ---
--- 0.3238866329193115 seconds for one epoch ---
--- 2.1415932178497314 seconds for one epoch ---
--- 0.322037935256958 seconds for one epoch ---
--- 2.1370835304260254 seconds for one epoch ---
--- 0.32875537872314453 seconds for one epoch ---
--- 2.1091182231903076 seconds for one epoch ---
--- 0.32027244567871094 seconds for one epoch ---
--- 2.1507725715637207 seconds for one epoch ---
--- 0.33353114128112793 seconds for one epoch ---
--- 2.0960421562194824 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99926114]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.407108]
 [  0.      ]]
--- 0.31128716468811035 seconds for one epoch ---
Epoch 4100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2835.445068359375, (1158.4304, 1.1757965, 1675.3885, 0.45053726)
   validation loss 1107.9205322265625, (790.2804, 0.44043738, 316.74918, 0.45053726)
decoder loss ratio: 30616.834509, decoder SINDy loss  ratio: 0.683748
--- 0.277233362197876 seconds for one epoch ---
--- 0.33384251594543457 seconds for one epoch ---
--- 2.1440532207489014 seconds for one epoch ---
--- 0.319688081741333 seconds for one epoch ---
--- 2.1226320266723633 seconds for one epoch ---
--- 0.32605695724487305 seconds for one epoch ---
--- 2.1507840156555176 seconds for one epoch ---
--- 0.3286101818084717 seconds for one epoch ---
--- 2.1073501110076904 seconds for one epoch ---
--- 0.3315451145172119 seconds for one epoch ---
--- 2.1455233097076416 seconds for one epoch ---
--- 0.3231852054595947 seconds for one epoch ---
--- 2.157322645187378 seconds for one epoch ---
--- 0.3135862350463867 seconds for one epoch ---
--- 2.1514220237731934 seconds for one epoch ---
--- 0.34034204483032227 seconds for one epoch ---
--- 2.1435022354125977 seconds for one epoch ---
--- 0.33358073234558105 seconds for one epoch ---
--- 2.1509921550750732 seconds for one epoch ---
--- 0.33155369758605957 seconds for one epoch ---
--- 2.1623525619506836 seconds for one epoch ---
--- 0.33294153213500977 seconds for one epoch ---
--- 2.137105703353882 seconds for one epoch ---
--- 0.33434128761291504 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99926776]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.437218]
 [  0.      ]]
--- 0.27138662338256836 seconds for one epoch ---
Epoch 4125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2200.7998046875, (865.70404, 0.59714836, 1334.0474, 0.4511757)
   validation loss 912.33447265625, (613.71265, 0.39797547, 297.7727, 0.4511757)
decoder loss ratio: 23776.293377, decoder SINDy loss  ratio: 0.642784
--- 0.31214451789855957 seconds for one epoch ---
--- 2.1383209228515625 seconds for one epoch ---
--- 0.33692121505737305 seconds for one epoch ---
--- 2.102663516998291 seconds for one epoch ---
--- 0.33124756813049316 seconds for one epoch ---
--- 2.159419536590576 seconds for one epoch ---
--- 0.32384538650512695 seconds for one epoch ---
--- 2.151097297668457 seconds for one epoch ---
--- 0.33452439308166504 seconds for one epoch ---
--- 2.1181893348693848 seconds for one epoch ---
--- 0.3288605213165283 seconds for one epoch ---
--- 2.105534315109253 seconds for one epoch ---
--- 0.3292980194091797 seconds for one epoch ---
--- 2.1463534832000732 seconds for one epoch ---
--- 0.33312535285949707 seconds for one epoch ---
--- 2.1477723121643066 seconds for one epoch ---
--- 0.32831478118896484 seconds for one epoch ---
--- 2.117387056350708 seconds for one epoch ---
--- 0.31589770317077637 seconds for one epoch ---
--- 2.1611106395721436 seconds for one epoch ---
--- 0.33224010467529297 seconds for one epoch ---
--- 2.1226093769073486 seconds for one epoch ---
--- 0.3197476863861084 seconds for one epoch ---
--- 2.1440978050231934 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99927294]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.463728]
 [ -0.      ]]
--- 0.2941093444824219 seconds for one epoch ---
Epoch 4150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2027.662353515625, (928.08655, 0.3735716, 1098.7502, 0.45187536)
   validation loss 765.7626953125, (494.5658, 0.4124444, 270.33255, 0.45187536)
decoder loss ratio: 19160.337537, decoder SINDy loss  ratio: 0.583551
--- 0.2890322208404541 seconds for one epoch ---
--- 0.3330955505371094 seconds for one epoch ---
--- 2.117680072784424 seconds for one epoch ---
--- 0.32697415351867676 seconds for one epoch ---
--- 2.176828384399414 seconds for one epoch ---
--- 0.3255953788757324 seconds for one epoch ---
--- 2.1673669815063477 seconds for one epoch ---
--- 0.33089518547058105 seconds for one epoch ---
--- 2.1730480194091797 seconds for one epoch ---
--- 0.32593607902526855 seconds for one epoch ---
--- 2.1525909900665283 seconds for one epoch ---
--- 0.3276536464691162 seconds for one epoch ---
--- 2.126120090484619 seconds for one epoch ---
--- 0.33866310119628906 seconds for one epoch ---
--- 2.1291470527648926 seconds for one epoch ---
--- 0.3291351795196533 seconds for one epoch ---
--- 2.1628856658935547 seconds for one epoch ---
--- 0.30925631523132324 seconds for one epoch ---
--- 2.1476452350616455 seconds for one epoch ---
--- 0.3393056392669678 seconds for one epoch ---
--- 2.126706123352051 seconds for one epoch ---
--- 0.32340502738952637 seconds for one epoch ---
--- 2.1663310527801514 seconds for one epoch ---
--- 0.33156514167785645 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992779]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.491848]
 [ -0.      ]]
--- 0.2687108516693115 seconds for one epoch ---
Epoch 4175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2841.140625, (1434.1532, 1.0528574, 1405.4818, 0.45257568)
   validation loss 797.0938110351562, (513.2664, 0.4464532, 282.9283, 0.45257568)
decoder loss ratio: 19884.832121, decoder SINDy loss  ratio: 0.610741
--- 0.3092639446258545 seconds for one epoch ---
--- 2.18931245803833 seconds for one epoch ---
--- 0.3301537036895752 seconds for one epoch ---
--- 2.13624906539917 seconds for one epoch ---
--- 0.3245103359222412 seconds for one epoch ---
--- 2.1512603759765625 seconds for one epoch ---
--- 0.3246457576751709 seconds for one epoch ---
--- 2.186304807662964 seconds for one epoch ---
--- 0.32067108154296875 seconds for one epoch ---
--- 2.131047248840332 seconds for one epoch ---
--- 0.32740044593811035 seconds for one epoch ---
--- 2.1765153408050537 seconds for one epoch ---
--- 0.31687307357788086 seconds for one epoch ---
--- 2.1884713172912598 seconds for one epoch ---
--- 0.330155611038208 seconds for one epoch ---
--- 2.1494052410125732 seconds for one epoch ---
--- 0.32947874069213867 seconds for one epoch ---
--- 2.1488828659057617 seconds for one epoch ---
--- 0.32874536514282227 seconds for one epoch ---
--- 2.1770761013031006 seconds for one epoch ---
--- 0.32333922386169434 seconds for one epoch ---
--- 2.1577956676483154 seconds for one epoch ---
--- 0.332988977432251 seconds for one epoch ---
--- 2.1313984394073486 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992841]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.515728]
 [  0.      ]]
--- 0.30140042304992676 seconds for one epoch ---
Epoch 4200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2001.4991455078125, (923.4658, 1.8102373, 1075.7698, 0.453214)
   validation loss 889.8933715820312, (570.15564, 0.36919466, 318.91534, 0.453214)
decoder loss ratio: 22088.819314, decoder SINDy loss  ratio: 0.688424
--- 0.27963995933532715 seconds for one epoch ---
--- 0.33208465576171875 seconds for one epoch ---
--- 2.128887176513672 seconds for one epoch ---
--- 0.3283267021179199 seconds for one epoch ---
--- 2.1853220462799072 seconds for one epoch ---
--- 0.33292412757873535 seconds for one epoch ---
--- 2.163665771484375 seconds for one epoch ---
--- 0.34136009216308594 seconds for one epoch ---
--- 2.1463186740875244 seconds for one epoch ---
--- 0.3252420425415039 seconds for one epoch ---
--- 2.1479439735412598 seconds for one epoch ---
--- 0.33493971824645996 seconds for one epoch ---
--- 2.1809616088867188 seconds for one epoch ---
--- 0.3286628723144531 seconds for one epoch ---
--- 2.127215623855591 seconds for one epoch ---
--- 0.31670379638671875 seconds for one epoch ---
--- 2.1406984329223633 seconds for one epoch ---
--- 0.3211343288421631 seconds for one epoch ---
--- 2.1463961601257324 seconds for one epoch ---
--- 0.32939577102661133 seconds for one epoch ---
--- 2.173548936843872 seconds for one epoch ---
--- 0.31983470916748047 seconds for one epoch ---
--- 2.152404546737671 seconds for one epoch ---
--- 0.3126959800720215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99929166]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.55062]
 [ -0.     ]]
--- 0.23572230339050293 seconds for one epoch ---
Epoch 4225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3351.90380859375, (1622.6396, 0.5527658, 1728.2573, 0.45412895)
   validation loss 820.960205078125, (524.208, 0.4012601, 295.89688, 0.45412895)
decoder loss ratio: 20308.728288, decoder SINDy loss  ratio: 0.638735
--- 0.30274033546447754 seconds for one epoch ---
--- 2.1401941776275635 seconds for one epoch ---
--- 0.32694578170776367 seconds for one epoch ---
--- 2.182346820831299 seconds for one epoch ---
--- 0.3404090404510498 seconds for one epoch ---
--- 2.1856632232666016 seconds for one epoch ---
--- 0.326458215713501 seconds for one epoch ---
--- 2.1548306941986084 seconds for one epoch ---
--- 0.33345746994018555 seconds for one epoch ---
--- 2.200061798095703 seconds for one epoch ---
--- 0.3252232074737549 seconds for one epoch ---
--- 2.1938302516937256 seconds for one epoch ---
--- 0.3295900821685791 seconds for one epoch ---
--- 2.1913740634918213 seconds for one epoch ---
--- 0.3201608657836914 seconds for one epoch ---
--- 2.190295457839966 seconds for one epoch ---
--- 0.3321094512939453 seconds for one epoch ---
--- 2.166733980178833 seconds for one epoch ---
--- 0.33937644958496094 seconds for one epoch ---
--- 2.158170223236084 seconds for one epoch ---
--- 0.33039164543151855 seconds for one epoch ---
--- 2.1687331199645996 seconds for one epoch ---
--- 0.32436132431030273 seconds for one epoch ---
--- 2.1843764781951904 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992976]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.583092]
 [  0.      ]]
--- 0.3045082092285156 seconds for one epoch ---
Epoch 4250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3888.21728515625, (1087.4296, 1.5460825, 2798.7866, 0.45498487)
   validation loss 1572.77001953125, (1166.857, 0.36351392, 405.09445, 0.45498487)
decoder loss ratio: 45206.068089, decoder SINDy loss  ratio: 0.874453
--- 0.2749059200286865 seconds for one epoch ---
--- 0.3290865421295166 seconds for one epoch ---
--- 2.1538050174713135 seconds for one epoch ---
--- 0.3290584087371826 seconds for one epoch ---
--- 2.1647396087646484 seconds for one epoch ---
--- 0.3169698715209961 seconds for one epoch ---
--- 2.156867265701294 seconds for one epoch ---
--- 0.32171058654785156 seconds for one epoch ---
--- 2.19765043258667 seconds for one epoch ---
--- 0.32369017601013184 seconds for one epoch ---
--- 2.21044921875 seconds for one epoch ---
--- 0.3271777629852295 seconds for one epoch ---
--- 2.215259552001953 seconds for one epoch ---
--- 0.33278846740722656 seconds for one epoch ---
--- 2.206421136856079 seconds for one epoch ---
--- 0.33123207092285156 seconds for one epoch ---
--- 2.1840360164642334 seconds for one epoch ---
--- 0.3313305377960205 seconds for one epoch ---
--- 2.1749637126922607 seconds for one epoch ---
--- 0.3216712474822998 seconds for one epoch ---
--- 2.1778171062469482 seconds for one epoch ---
--- 0.3265087604522705 seconds for one epoch ---
--- 2.2235195636749268 seconds for one epoch ---
--- 0.3148312568664551 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993037]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.61016]
 [  0.     ]]
--- 0.27090907096862793 seconds for one epoch ---
Epoch 4275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3349.152587890625, (1370.0955, 0.8212278, 1977.7804, 0.45558342)
   validation loss 1014.9129638671875, (736.18054, 0.42218328, 277.85468, 0.45558342)
decoder loss ratio: 28520.912262, decoder SINDy loss  ratio: 0.599788
--- 0.30841755867004395 seconds for one epoch ---
--- 2.1820359230041504 seconds for one epoch ---
--- 0.31269121170043945 seconds for one epoch ---
--- 2.174288749694824 seconds for one epoch ---
--- 0.323819637298584 seconds for one epoch ---
--- 2.2314538955688477 seconds for one epoch ---
--- 0.32535696029663086 seconds for one epoch ---
--- 2.2292139530181885 seconds for one epoch ---
--- 0.3277268409729004 seconds for one epoch ---
--- 2.204315185546875 seconds for one epoch ---
--- 0.32828521728515625 seconds for one epoch ---
--- 2.2310900688171387 seconds for one epoch ---
--- 0.3308122158050537 seconds for one epoch ---
--- 2.202047348022461 seconds for one epoch ---
--- 0.3336491584777832 seconds for one epoch ---
--- 2.171246290206909 seconds for one epoch ---
--- 0.3253967761993408 seconds for one epoch ---
--- 2.209439992904663 seconds for one epoch ---
--- 0.31427454948425293 seconds for one epoch ---
--- 2.194329261779785 seconds for one epoch ---
--- 0.33000779151916504 seconds for one epoch ---
--- 2.23606014251709 seconds for one epoch ---
--- 0.3305535316467285 seconds for one epoch ---
--- 2.21671724319458 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993101]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.637178]
 [ -0.      ]]
--- 0.3004336357116699 seconds for one epoch ---
Epoch 4300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3468.459228515625, (1160.6382, 0.7541712, 2306.6106, 0.4562953)
   validation loss 771.7681884765625, (496.83426, 0.45409915, 274.02353, 0.4562953)
decoder loss ratio: 19248.221737, decoder SINDy loss  ratio: 0.591518
--- 0.2804880142211914 seconds for one epoch ---
--- 0.3243997097015381 seconds for one epoch ---
--- 2.1938278675079346 seconds for one epoch ---
--- 0.31926774978637695 seconds for one epoch ---
--- 2.2077581882476807 seconds for one epoch ---
--- 0.32953500747680664 seconds for one epoch ---
--- 2.217146635055542 seconds for one epoch ---
--- 0.32703280448913574 seconds for one epoch ---
--- 2.183739185333252 seconds for one epoch ---
--- 0.327207088470459 seconds for one epoch ---
--- 2.2419300079345703 seconds for one epoch ---
--- 0.3258497714996338 seconds for one epoch ---
--- 2.2046077251434326 seconds for one epoch ---
--- 0.32320523262023926 seconds for one epoch ---
--- 2.1864585876464844 seconds for one epoch ---
--- 0.32773780822753906 seconds for one epoch ---
--- 2.193265199661255 seconds for one epoch ---
--- 0.3189544677734375 seconds for one epoch ---
--- 2.2384138107299805 seconds for one epoch ---
--- 0.3318977355957031 seconds for one epoch ---
--- 2.206488847732544 seconds for one epoch ---
--- 0.33360910415649414 seconds for one epoch ---
--- 2.227567672729492 seconds for one epoch ---
--- 0.3309617042541504 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993136]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.660833]
 [ -0.      ]]
--- 0.27153992652893066 seconds for one epoch ---
Epoch 4325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2920.707763671875, (927.67, 4.43611, 1988.1447, 0.45699033)
   validation loss 898.6448974609375, (590.8821, 0.39300525, 306.91284, 0.45699033)
decoder loss ratio: 22891.797599, decoder SINDy loss  ratio: 0.662515
--- 0.2971982955932617 seconds for one epoch ---
--- 2.2120745182037354 seconds for one epoch ---
--- 0.3228871822357178 seconds for one epoch ---
--- 2.203237295150757 seconds for one epoch ---
--- 0.316084623336792 seconds for one epoch ---
--- 2.2399139404296875 seconds for one epoch ---
--- 0.3325619697570801 seconds for one epoch ---
--- 2.1884853839874268 seconds for one epoch ---
--- 0.3252239227294922 seconds for one epoch ---
--- 2.2573935985565186 seconds for one epoch ---
--- 0.32588624954223633 seconds for one epoch ---
--- 2.218618392944336 seconds for one epoch ---
--- 0.3139324188232422 seconds for one epoch ---
--- 2.2394120693206787 seconds for one epoch ---
--- 0.32518887519836426 seconds for one epoch ---
--- 2.258279800415039 seconds for one epoch ---
--- 0.3259904384613037 seconds for one epoch ---
--- 2.236685276031494 seconds for one epoch ---
--- 0.33278393745422363 seconds for one epoch ---
--- 2.2403531074523926 seconds for one epoch ---
--- 0.32742953300476074 seconds for one epoch ---
--- 2.2495169639587402 seconds for one epoch ---
--- 0.31932902336120605 seconds for one epoch ---
--- 2.2073757648468018 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993174]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.684216]
 [  0.      ]]
--- 0.30658745765686035 seconds for one epoch ---
Epoch 4350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1754.910888671875, (722.56616, 1.0398378, 1030.8473, 0.45751414)
   validation loss 768.3126220703125, (486.7717, 0.45872444, 280.62466, 0.45751414)
decoder loss ratio: 18858.380653, decoder SINDy loss  ratio: 0.605768
--- 0.27754998207092285 seconds for one epoch ---
--- 0.3362891674041748 seconds for one epoch ---
--- 2.208184242248535 seconds for one epoch ---
--- 0.31778573989868164 seconds for one epoch ---
--- 2.2275853157043457 seconds for one epoch ---
--- 0.3240172863006592 seconds for one epoch ---
--- 2.2283215522766113 seconds for one epoch ---
--- 0.33452677726745605 seconds for one epoch ---
--- 2.2371010780334473 seconds for one epoch ---
--- 0.3309361934661865 seconds for one epoch ---
--- 2.2605926990509033 seconds for one epoch ---
--- 0.3185274600982666 seconds for one epoch ---
--- 2.2387025356292725 seconds for one epoch ---
--- 0.33028650283813477 seconds for one epoch ---
--- 2.2064270973205566 seconds for one epoch ---
--- 0.3216514587402344 seconds for one epoch ---
--- 2.236963987350464 seconds for one epoch ---
--- 0.3287484645843506 seconds for one epoch ---
--- 2.2056870460510254 seconds for one epoch ---
--- 0.3275723457336426 seconds for one epoch ---
--- 2.2034382820129395 seconds for one epoch ---
--- 0.3334846496582031 seconds for one epoch ---
--- 2.230537176132202 seconds for one epoch ---
--- 0.31712961196899414 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993223]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.704447]
 [ -0.      ]]
--- 0.2707180976867676 seconds for one epoch ---
Epoch 4375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2280.8056640625, (1015.8956, 8.596798, 1255.8551, 0.4580414)
   validation loss 774.2046508789062, (496.9213, 0.4437865, 276.3815, 0.4580414)
decoder loss ratio: 19251.593668, decoder SINDy loss  ratio: 0.596608
--- 0.2944986820220947 seconds for one epoch ---
--- 2.260983943939209 seconds for one epoch ---
--- 0.32824110984802246 seconds for one epoch ---
--- 2.217538595199585 seconds for one epoch ---
--- 0.32675695419311523 seconds for one epoch ---
--- 2.2248966693878174 seconds for one epoch ---
--- 0.322721004486084 seconds for one epoch ---
--- 2.263079881668091 seconds for one epoch ---
--- 0.32492542266845703 seconds for one epoch ---
--- 2.2438597679138184 seconds for one epoch ---
--- 0.33148980140686035 seconds for one epoch ---
--- 2.2661805152893066 seconds for one epoch ---
--- 0.33260178565979004 seconds for one epoch ---
--- 2.2647511959075928 seconds for one epoch ---
--- 0.32875680923461914 seconds for one epoch ---
--- 2.2437286376953125 seconds for one epoch ---
--- 0.33313512802124023 seconds for one epoch ---
--- 2.2933456897735596 seconds for one epoch ---
--- 0.33130812644958496 seconds for one epoch ---
--- 2.2383999824523926 seconds for one epoch ---
--- 0.33007121086120605 seconds for one epoch ---
--- 2.2818048000335693 seconds for one epoch ---
--- 0.30827808380126953 seconds for one epoch ---
--- 2.289536952972412 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993283]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.727133]
 [  0.      ]]
--- 0.2928907871246338 seconds for one epoch ---
Epoch 4400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2283.046630859375, (971.53815, 2.326091, 1308.7238, 0.45863757)
   validation loss 757.4761352539062, (466.47885, 0.38972118, 290.14896, 0.45863757)
decoder loss ratio: 18072.200543, decoder SINDy loss  ratio: 0.626327
--- 0.27658581733703613 seconds for one epoch ---
--- 0.33832383155822754 seconds for one epoch ---
--- 2.226344585418701 seconds for one epoch ---
--- 0.3187251091003418 seconds for one epoch ---
--- 2.2303500175476074 seconds for one epoch ---
--- 0.3256244659423828 seconds for one epoch ---
--- 2.219069719314575 seconds for one epoch ---
--- 0.3283083438873291 seconds for one epoch ---
--- 2.242479085922241 seconds for one epoch ---
--- 0.34140491485595703 seconds for one epoch ---
--- 2.2394888401031494 seconds for one epoch ---
--- 0.3269634246826172 seconds for one epoch ---
--- 2.288785934448242 seconds for one epoch ---
--- 0.3258373737335205 seconds for one epoch ---
--- 2.2901692390441895 seconds for one epoch ---
--- 0.3167281150817871 seconds for one epoch ---
--- 2.247086524963379 seconds for one epoch ---
--- 0.3229482173919678 seconds for one epoch ---
--- 2.2311153411865234 seconds for one epoch ---
--- 0.32929039001464844 seconds for one epoch ---
--- 2.308520555496216 seconds for one epoch ---
--- 0.32455921173095703 seconds for one epoch ---
--- 2.3032288551330566 seconds for one epoch ---
--- 0.31926560401916504 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993319]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.749609]
 [  0.      ]]
--- 0.2652878761291504 seconds for one epoch ---
Epoch 4425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3378.112060546875, (1452.4841, 2.678507, 1922.4901, 0.45921502)
   validation loss 869.078369140625, (584.00507, 0.4597833, 284.15427, 0.45921502)
decoder loss ratio: 22625.370131, decoder SINDy loss  ratio: 0.613387
--- 0.3081088066101074 seconds for one epoch ---
--- 2.2789130210876465 seconds for one epoch ---
--- 0.32081103324890137 seconds for one epoch ---
--- 2.2584078311920166 seconds for one epoch ---
--- 0.32844018936157227 seconds for one epoch ---
--- 2.2692935466766357 seconds for one epoch ---
--- 0.3167400360107422 seconds for one epoch ---
--- 2.2822487354278564 seconds for one epoch ---
--- 0.31723523139953613 seconds for one epoch ---
--- 2.2995402812957764 seconds for one epoch ---
--- 0.31815457344055176 seconds for one epoch ---
--- 2.280888080596924 seconds for one epoch ---
--- 0.3266468048095703 seconds for one epoch ---
--- 2.257982015609741 seconds for one epoch ---
--- 0.32770228385925293 seconds for one epoch ---
--- 2.2617218494415283 seconds for one epoch ---
--- 0.3310279846191406 seconds for one epoch ---
--- 2.2374699115753174 seconds for one epoch ---
--- 0.3245556354522705 seconds for one epoch ---
--- 2.292051315307617 seconds for one epoch ---
--- 0.3194010257720947 seconds for one epoch ---
--- 2.2802648544311523 seconds for one epoch ---
--- 0.3149087429046631 seconds for one epoch ---
--- 2.256800413131714 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993355]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.772427]
 [ -0.      ]]
--- 0.30983495712280273 seconds for one epoch ---
Epoch 4450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2193.210205078125, (904.90753, 0.86852896, 1286.9744, 0.4597604)
   validation loss 1055.3092041015625, (780.7811, 0.4584327, 273.60995, 0.4597604)
decoder loss ratio: 30248.816392, decoder SINDy loss  ratio: 0.590626
--- 0.25693559646606445 seconds for one epoch ---
--- 0.3340644836425781 seconds for one epoch ---
--- 2.2461156845092773 seconds for one epoch ---
--- 0.3247501850128174 seconds for one epoch ---
--- 2.2842864990234375 seconds for one epoch ---
--- 0.331803560256958 seconds for one epoch ---
--- 2.259172201156616 seconds for one epoch ---
--- 0.3218216896057129 seconds for one epoch ---
--- 2.251499652862549 seconds for one epoch ---
--- 0.32982587814331055 seconds for one epoch ---
--- 2.303924560546875 seconds for one epoch ---
--- 0.3356657028198242 seconds for one epoch ---
--- 2.256115198135376 seconds for one epoch ---
--- 0.33775901794433594 seconds for one epoch ---
--- 2.2625038623809814 seconds for one epoch ---
--- 0.33089423179626465 seconds for one epoch ---
--- 2.292384624481201 seconds for one epoch ---
--- 0.3323073387145996 seconds for one epoch ---
--- 2.293619394302368 seconds for one epoch ---
--- 0.32623767852783203 seconds for one epoch ---
--- 2.2772481441497803 seconds for one epoch ---
--- 0.3295283317565918 seconds for one epoch ---
--- 2.3227174282073975 seconds for one epoch ---
--- 0.3259871006011963 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99933934]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.790262]
 [ -0.      ]]
--- 0.26181888580322266 seconds for one epoch ---
Epoch 4475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2231.550537109375, (980.96484, 1.8861613, 1248.2394, 0.46020386)
   validation loss 928.8267822265625, (659.3297, 0.48172894, 268.55508, 0.46020386)
decoder loss ratio: 25543.577686, decoder SINDy loss  ratio: 0.579714
--- 0.32033658027648926 seconds for one epoch ---
--- 2.3205788135528564 seconds for one epoch ---
--- 0.32836031913757324 seconds for one epoch ---
--- 2.2897276878356934 seconds for one epoch ---
--- 0.3263580799102783 seconds for one epoch ---
--- 2.260051965713501 seconds for one epoch ---
--- 0.33744287490844727 seconds for one epoch ---
--- 2.3077609539031982 seconds for one epoch ---
--- 0.33391380310058594 seconds for one epoch ---
--- 2.2802393436431885 seconds for one epoch ---
--- 0.3318779468536377 seconds for one epoch ---
--- 2.3300890922546387 seconds for one epoch ---
--- 0.3338441848754883 seconds for one epoch ---
--- 2.287327766418457 seconds for one epoch ---
--- 0.3255791664123535 seconds for one epoch ---
--- 2.328087568283081 seconds for one epoch ---
--- 0.3312876224517822 seconds for one epoch ---
--- 2.328197717666626 seconds for one epoch ---
--- 0.332913875579834 seconds for one epoch ---
--- 2.2831919193267822 seconds for one epoch ---
--- 0.31273746490478516 seconds for one epoch ---
--- 2.2598631381988525 seconds for one epoch ---
--- 0.3160367012023926 seconds for one epoch ---
--- 2.332472562789917 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99934494]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.812319]
 [  0.      ]]
--- 0.29674601554870605 seconds for one epoch ---
Epoch 4500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3554.509765625, (1564.898, 0.3127578, 1988.838, 0.46086225)
   validation loss 1171.533203125, (847.29645, 0.42909634, 323.34686, 0.46086225)
decoder loss ratio: 32825.735357, decoder SINDy loss  ratio: 0.697990
THRESHOLDING: 1 active coefficients
--- 0.2803473472595215 seconds for one epoch ---
--- 0.34221458435058594 seconds for one epoch ---
--- 2.2938055992126465 seconds for one epoch ---
--- 0.3262460231781006 seconds for one epoch ---
--- 2.3211073875427246 seconds for one epoch ---
--- 0.3474915027618408 seconds for one epoch ---
--- 2.2966673374176025 seconds for one epoch ---
--- 0.3292121887207031 seconds for one epoch ---
--- 2.281263589859009 seconds for one epoch ---
--- 0.3333404064178467 seconds for one epoch ---
--- 2.3263070583343506 seconds for one epoch ---
--- 0.326934814453125 seconds for one epoch ---
--- 2.2786495685577393 seconds for one epoch ---
--- 0.32912588119506836 seconds for one epoch ---
--- 2.329892873764038 seconds for one epoch ---
--- 0.31929540634155273 seconds for one epoch ---
--- 2.287946939468384 seconds for one epoch ---
--- 0.3225393295288086 seconds for one epoch ---
--- 2.317826747894287 seconds for one epoch ---
--- 0.32456064224243164 seconds for one epoch ---
--- 2.3050525188446045 seconds for one epoch ---
--- 0.30834293365478516 seconds for one epoch ---
--- 2.3373303413391113 seconds for one epoch ---
--- 0.32885289192199707 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99934983]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-17.83716]
 [ -0.     ]]
--- 0.2746284008026123 seconds for one epoch ---
Epoch 4525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3085.773193359375, (1752.9097, 1.2557633, 1331.1464, 0.46146628)
   validation loss 1272.473876953125, (954.0368, 0.43390468, 317.54178, 0.46146628)
decoder loss ratio: 36961.042075, decoder SINDy loss  ratio: 0.685459
--- 0.28812503814697266 seconds for one epoch ---
--- 2.2655694484710693 seconds for one epoch ---
--- 0.34328794479370117 seconds for one epoch ---
--- 2.3093924522399902 seconds for one epoch ---
--- 0.3339047431945801 seconds for one epoch ---
--- 2.3282113075256348 seconds for one epoch ---
--- 0.3362302780151367 seconds for one epoch ---
--- 2.311422824859619 seconds for one epoch ---
--- 0.3334383964538574 seconds for one epoch ---
--- 2.303579092025757 seconds for one epoch ---
--- 0.3327341079711914 seconds for one epoch ---
--- 2.308324098587036 seconds for one epoch ---
--- 0.3461143970489502 seconds for one epoch ---
--- 2.3075969219207764 seconds for one epoch ---
--- 0.3243827819824219 seconds for one epoch ---
--- 2.29398512840271 seconds for one epoch ---
--- 0.3188173770904541 seconds for one epoch ---
--- 2.35432505607605 seconds for one epoch ---
--- 0.3304281234741211 seconds for one epoch ---
--- 2.3075978755950928 seconds for one epoch ---
--- 0.32984328269958496 seconds for one epoch ---
--- 2.3300561904907227 seconds for one epoch ---
--- 0.32857513427734375 seconds for one epoch ---
--- 2.361205577850342 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99935406]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.862764]
 [  0.      ]]
--- 0.30826306343078613 seconds for one epoch ---
Epoch 4550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3225.200927734375, (1310.856, 2.9407442, 1910.9419, 0.46212062)
   validation loss 1179.77734375, (840.767, 0.4008917, 338.14734, 0.46212062)
decoder loss ratio: 32572.774332, decoder SINDy loss  ratio: 0.729939
--- 0.27775144577026367 seconds for one epoch ---
--- 0.33284974098205566 seconds for one epoch ---
--- 2.295105218887329 seconds for one epoch ---
--- 0.32415246963500977 seconds for one epoch ---
--- 2.301510810852051 seconds for one epoch ---
--- 0.3427882194519043 seconds for one epoch ---
--- 2.3142855167388916 seconds for one epoch ---
--- 0.3334033489227295 seconds for one epoch ---
--- 2.3126156330108643 seconds for one epoch ---
--- 0.3127779960632324 seconds for one epoch ---
--- 2.3077399730682373 seconds for one epoch ---
--- 0.3376593589782715 seconds for one epoch ---
--- 2.3182213306427 seconds for one epoch ---
--- 0.3334624767303467 seconds for one epoch ---
--- 2.3635151386260986 seconds for one epoch ---
--- 0.32427120208740234 seconds for one epoch ---
--- 2.358017921447754 seconds for one epoch ---
--- 0.32627248764038086 seconds for one epoch ---
--- 2.3227076530456543 seconds for one epoch ---
--- 0.3160817623138428 seconds for one epoch ---
--- 2.3206963539123535 seconds for one epoch ---
--- 0.33984875679016113 seconds for one epoch ---
--- 2.2910518646240234 seconds for one epoch ---
--- 0.3286724090576172 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993564]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.878956]
 [  0.      ]]
--- 0.26395368576049805 seconds for one epoch ---
Epoch 4575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2634.698486328125, (1368.3071, 0.26741567, 1265.6613, 0.46256992)
   validation loss 916.8300170898438, (613.37506, 0.4658855, 302.52652, 0.46256992)
decoder loss ratio: 23763.214730, decoder SINDy loss  ratio: 0.653046
--- 0.30809783935546875 seconds for one epoch ---
--- 2.30605411529541 seconds for one epoch ---
--- 0.3370065689086914 seconds for one epoch ---
--- 2.3082728385925293 seconds for one epoch ---
--- 0.32616472244262695 seconds for one epoch ---
--- 2.3068881034851074 seconds for one epoch ---
--- 0.32791757583618164 seconds for one epoch ---
--- 2.367739200592041 seconds for one epoch ---
--- 0.31716465950012207 seconds for one epoch ---
--- 2.3240387439727783 seconds for one epoch ---
--- 0.3213193416595459 seconds for one epoch ---
--- 2.32989764213562 seconds for one epoch ---
--- 0.30911779403686523 seconds for one epoch ---
--- 2.3257639408111572 seconds for one epoch ---
--- 0.3238098621368408 seconds for one epoch ---
--- 2.3775622844696045 seconds for one epoch ---
--- 0.33089375495910645 seconds for one epoch ---
--- 2.324083089828491 seconds for one epoch ---
--- 0.31622743606567383 seconds for one epoch ---
--- 2.3613944053649902 seconds for one epoch ---
--- 0.3262944221496582 seconds for one epoch ---
--- 2.3319826126098633 seconds for one epoch ---
--- 0.33121681213378906 seconds for one epoch ---
--- 2.3462181091308594 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999359]
 [0.      ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.89679]
 [ -0.     ]]
--- 0.3090646266937256 seconds for one epoch ---
Epoch 4600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4275.07666015625, (1504.0277, 4.431764, 2766.1543, 0.46301547)
   validation loss 1069.4892578125, (751.96515, 0.410228, 316.65088, 0.46301547)
decoder loss ratio: 29132.435338, decoder SINDy loss  ratio: 0.683535
--- 0.2681434154510498 seconds for one epoch ---
--- 0.3282907009124756 seconds for one epoch ---
--- 2.3119239807128906 seconds for one epoch ---
--- 0.31792426109313965 seconds for one epoch ---
--- 2.3563268184661865 seconds for one epoch ---
--- 0.3316986560821533 seconds for one epoch ---
--- 2.3153088092803955 seconds for one epoch ---
--- 0.32640576362609863 seconds for one epoch ---
--- 2.3367886543273926 seconds for one epoch ---
--- 0.31228160858154297 seconds for one epoch ---
--- 2.323076009750366 seconds for one epoch ---
--- 0.33360815048217773 seconds for one epoch ---
--- 2.365654468536377 seconds for one epoch ---
--- 0.3303844928741455 seconds for one epoch ---
--- 2.34765887260437 seconds for one epoch ---
--- 0.33087897300720215 seconds for one epoch ---
--- 2.3141231536865234 seconds for one epoch ---
--- 0.3177206516265869 seconds for one epoch ---
--- 2.331317901611328 seconds for one epoch ---
--- 0.32416319847106934 seconds for one epoch ---
--- 2.391719102859497 seconds for one epoch ---
--- 0.32497334480285645 seconds for one epoch ---
--- 2.390608310699463 seconds for one epoch ---
--- 0.3297116756439209 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99936235]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.913572]
 [ -0.      ]]
--- 0.25948190689086914 seconds for one epoch ---
Epoch 4625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2393.822265625, (875.2233, 0.97789526, 1517.1576, 0.46348104)
   validation loss 742.6722412109375, (473.06927, 0.42357117, 268.7159, 0.46348104)
decoder loss ratio: 18327.524994, decoder SINDy loss  ratio: 0.580061
--- 0.32012343406677246 seconds for one epoch ---
--- 2.3935599327087402 seconds for one epoch ---
--- 0.3173961639404297 seconds for one epoch ---
--- 2.351020097732544 seconds for one epoch ---
--- 0.32764768600463867 seconds for one epoch ---
--- 2.3978421688079834 seconds for one epoch ---
--- 0.3328244686126709 seconds for one epoch ---
--- 2.333879232406616 seconds for one epoch ---
--- 0.3327322006225586 seconds for one epoch ---
--- 2.3745689392089844 seconds for one epoch ---
--- 0.3261985778808594 seconds for one epoch ---
--- 2.365288019180298 seconds for one epoch ---
--- 0.3305654525756836 seconds for one epoch ---
--- 2.3543055057525635 seconds for one epoch ---
--- 0.3269078731536865 seconds for one epoch ---
--- 2.352457284927368 seconds for one epoch ---
--- 0.3249044418334961 seconds for one epoch ---
--- 2.3876538276672363 seconds for one epoch ---
--- 0.3300914764404297 seconds for one epoch ---
--- 2.337045192718506 seconds for one epoch ---
--- 0.31905031204223633 seconds for one epoch ---
--- 2.399944543838501 seconds for one epoch ---
--- 0.31899118423461914 seconds for one epoch ---
--- 2.3935022354125977 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993659]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.937597]
 [  0.      ]]
--- 0.3214986324310303 seconds for one epoch ---
Epoch 4650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2389.21875, (1257.2329, 0.65085536, 1130.8708, 0.46407023)
   validation loss 826.200927734375, (529.019, 0.4113535, 296.30652, 0.46407023)
decoder loss ratio: 20495.113777, decoder SINDy loss  ratio: 0.639619
--- 0.25170397758483887 seconds for one epoch ---
--- 0.3118605613708496 seconds for one epoch ---
--- 2.367255449295044 seconds for one epoch ---
--- 0.3323497772216797 seconds for one epoch ---
--- 2.3450920581817627 seconds for one epoch ---
--- 0.33094310760498047 seconds for one epoch ---
--- 2.3495230674743652 seconds for one epoch ---
--- 0.3330681324005127 seconds for one epoch ---
--- 2.352283239364624 seconds for one epoch ---
--- 0.3363063335418701 seconds for one epoch ---
--- 2.338792562484741 seconds for one epoch ---
--- 0.32663440704345703 seconds for one epoch ---
--- 2.348026752471924 seconds for one epoch ---
--- 0.33263087272644043 seconds for one epoch ---
--- 2.39365816116333 seconds for one epoch ---
--- 0.32793569564819336 seconds for one epoch ---
--- 2.3514044284820557 seconds for one epoch ---
--- 0.3318960666656494 seconds for one epoch ---
--- 2.3524973392486572 seconds for one epoch ---
--- 0.33060455322265625 seconds for one epoch ---
--- 2.3468780517578125 seconds for one epoch ---
--- 0.32172703742980957 seconds for one epoch ---
--- 2.3500473499298096 seconds for one epoch ---
--- 0.3335602283477783 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993694]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.956425]
 [ -0.      ]]
--- 0.28087401390075684 seconds for one epoch ---
Epoch 4675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2112.830322265625, (1139.9597, 2.1248453, 970.281, 0.4645492)
   validation loss 934.0043334960938, (632.85504, 0.43635952, 300.24838, 0.4645492)
decoder loss ratio: 24517.902993, decoder SINDy loss  ratio: 0.648128
--- 0.3177013397216797 seconds for one epoch ---
--- 2.386932373046875 seconds for one epoch ---
--- 0.33222389221191406 seconds for one epoch ---
--- 2.3475875854492188 seconds for one epoch ---
--- 0.3109323978424072 seconds for one epoch ---
--- 2.3732967376708984 seconds for one epoch ---
--- 0.32086634635925293 seconds for one epoch ---
--- 2.4015965461730957 seconds for one epoch ---
--- 0.31907081604003906 seconds for one epoch ---
--- 2.417863607406616 seconds for one epoch ---
--- 0.3298795223236084 seconds for one epoch ---
--- 2.3519973754882812 seconds for one epoch ---
--- 0.32760095596313477 seconds for one epoch ---
--- 2.354916572570801 seconds for one epoch ---
--- 0.32802772521972656 seconds for one epoch ---
--- 2.370042324066162 seconds for one epoch ---
--- 0.3138744831085205 seconds for one epoch ---
--- 2.3575873374938965 seconds for one epoch ---
--- 0.3316941261291504 seconds for one epoch ---
--- 2.429297685623169 seconds for one epoch ---
--- 0.3284647464752197 seconds for one epoch ---
--- 2.426132917404175 seconds for one epoch ---
--- 0.31299710273742676 seconds for one epoch ---
--- 2.3705451488494873 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99937284]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.977936]
 [  0.      ]]
--- 0.30037403106689453 seconds for one epoch ---
Epoch 4700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2860.616455078125, (1106.5634, 1.1954622, 1752.3926, 0.46511576)
   validation loss 875.2303466796875, (581.4432, 0.44860408, 292.87344, 0.46511576)
decoder loss ratio: 22526.118078, decoder SINDy loss  ratio: 0.632209
--- 0.27750396728515625 seconds for one epoch ---
--- 0.32086610794067383 seconds for one epoch ---
--- 2.371497631072998 seconds for one epoch ---
--- 0.33269333839416504 seconds for one epoch ---
--- 2.36159610748291 seconds for one epoch ---
--- 0.32494688034057617 seconds for one epoch ---
--- 2.3620758056640625 seconds for one epoch ---
--- 0.33188366889953613 seconds for one epoch ---
--- 2.4143919944763184 seconds for one epoch ---
--- 0.3378028869628906 seconds for one epoch ---
--- 2.365121841430664 seconds for one epoch ---
--- 0.3275940418243408 seconds for one epoch ---
--- 2.417149066925049 seconds for one epoch ---
--- 0.32990288734436035 seconds for one epoch ---
--- 2.374166965484619 seconds for one epoch ---
--- 0.32778096199035645 seconds for one epoch ---
--- 2.396960973739624 seconds for one epoch ---
--- 0.31601834297180176 seconds for one epoch ---
--- 2.4179344177246094 seconds for one epoch ---
--- 0.3291773796081543 seconds for one epoch ---
--- 2.3905768394470215 seconds for one epoch ---
--- 0.32042932510375977 seconds for one epoch ---
--- 2.3792083263397217 seconds for one epoch ---
--- 0.34655046463012695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99937713]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.99711]
 [  0.     ]]
--- 0.275127649307251 seconds for one epoch ---
Epoch 4725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3329.618896484375, (1498.3986, 4.1082716, 1826.6464, 0.46562004)
   validation loss 808.9393920898438, (530.9563, 0.48236218, 277.0351, 0.46562004)
decoder loss ratio: 20570.168797, decoder SINDy loss  ratio: 0.598019
--- 0.31000518798828125 seconds for one epoch ---
--- 2.4253077507019043 seconds for one epoch ---
--- 0.3278634548187256 seconds for one epoch ---
--- 2.4501404762268066 seconds for one epoch ---
--- 0.32288050651550293 seconds for one epoch ---
--- 2.4091546535491943 seconds for one epoch ---
--- 0.33855533599853516 seconds for one epoch ---
--- 2.379483461380005 seconds for one epoch ---
--- 0.3262150287628174 seconds for one epoch ---
--- 2.447880268096924 seconds for one epoch ---
--- 0.33853840827941895 seconds for one epoch ---
--- 2.4400010108947754 seconds for one epoch ---
--- 0.3320925235748291 seconds for one epoch ---
--- 2.452052354812622 seconds for one epoch ---
--- 0.33266758918762207 seconds for one epoch ---
--- 2.3870861530303955 seconds for one epoch ---
--- 0.33525753021240234 seconds for one epoch ---
--- 2.4378726482391357 seconds for one epoch ---
--- 0.3222482204437256 seconds for one epoch ---
--- 2.4306297302246094 seconds for one epoch ---
--- 0.33362293243408203 seconds for one epoch ---
--- 2.4050354957580566 seconds for one epoch ---
--- 0.33120274543762207 seconds for one epoch ---
--- 2.461897611618042 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993813]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.017199]
 [ -0.      ]]
--- 0.33313465118408203 seconds for one epoch ---
Epoch 4750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2035.254638671875, (715.7861, 0.7187079, 1318.2837, 0.4662318)
   validation loss 668.4071655273438, (401.4398, 0.472232, 266.02887, 0.4662318)
decoder loss ratio: 15552.474349, decoder SINDy loss  ratio: 0.574261
--- 0.2677164077758789 seconds for one epoch ---
--- 0.32810211181640625 seconds for one epoch ---
--- 2.4212396144866943 seconds for one epoch ---
--- 0.3253822326660156 seconds for one epoch ---
--- 2.3754422664642334 seconds for one epoch ---
--- 0.32359957695007324 seconds for one epoch ---
--- 2.44052791595459 seconds for one epoch ---
--- 0.3247654438018799 seconds for one epoch ---
--- 2.422393560409546 seconds for one epoch ---
--- 0.32541537284851074 seconds for one epoch ---
--- 2.3779282569885254 seconds for one epoch ---
--- 0.33246731758117676 seconds for one epoch ---
--- 2.445502519607544 seconds for one epoch ---
--- 0.3183422088623047 seconds for one epoch ---
--- 2.398338556289673 seconds for one epoch ---
--- 0.32828259468078613 seconds for one epoch ---
--- 2.3745076656341553 seconds for one epoch ---
--- 0.3287365436553955 seconds for one epoch ---
--- 2.4319934844970703 seconds for one epoch ---
--- 0.33042216300964355 seconds for one epoch ---
--- 2.397202253341675 seconds for one epoch ---
--- 0.3285229206085205 seconds for one epoch ---
--- 2.404186248779297 seconds for one epoch ---
--- 0.323333740234375 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999385]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.034216]
 [ -0.      ]]
--- 0.27344417572021484 seconds for one epoch ---
Epoch 4775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3267.651611328125, (1291.6863, 1.4306968, 1974.0681, 0.46659467)
   validation loss 759.2388305664062, (488.5429, 0.5138708, 269.71542, 0.46659467)
decoder loss ratio: 18927.000393, decoder SINDy loss  ratio: 0.582219
--- 0.30875229835510254 seconds for one epoch ---
--- 2.4334232807159424 seconds for one epoch ---
--- 0.3223714828491211 seconds for one epoch ---
--- 2.4131076335906982 seconds for one epoch ---
--- 0.3282008171081543 seconds for one epoch ---
--- 2.4523816108703613 seconds for one epoch ---
--- 0.3272585868835449 seconds for one epoch ---
--- 2.4043705463409424 seconds for one epoch ---
--- 0.32537841796875 seconds for one epoch ---
--- 2.416745901107788 seconds for one epoch ---
--- 0.32926273345947266 seconds for one epoch ---
--- 2.3922340869903564 seconds for one epoch ---
--- 0.3253662586212158 seconds for one epoch ---
--- 2.3907296657562256 seconds for one epoch ---
--- 0.3295273780822754 seconds for one epoch ---
--- 2.4537007808685303 seconds for one epoch ---
--- 0.32588768005371094 seconds for one epoch ---
--- 2.4395551681518555 seconds for one epoch ---
--- 0.32033562660217285 seconds for one epoch ---
--- 2.4410903453826904 seconds for one epoch ---
--- 0.32205700874328613 seconds for one epoch ---
--- 2.4435062408447266 seconds for one epoch ---
--- 0.3146326541900635 seconds for one epoch ---
--- 2.4681873321533203 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993864]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.050072]
 [  0.      ]]
--- 0.2929410934448242 seconds for one epoch ---
Epoch 4800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3816.616455078125, (1889.3983, 1.873222, 1924.8778, 0.46701574)
   validation loss 993.67919921875, (692.56995, 0.48224822, 300.15994, 0.46701574)
decoder loss ratio: 26831.362074, decoder SINDy loss  ratio: 0.647937
--- 0.27386927604675293 seconds for one epoch ---
--- 0.32357048988342285 seconds for one epoch ---
--- 2.454366445541382 seconds for one epoch ---
--- 0.32718372344970703 seconds for one epoch ---
--- 2.443305253982544 seconds for one epoch ---
--- 0.32670092582702637 seconds for one epoch ---
--- 2.4676272869110107 seconds for one epoch ---
--- 0.3302443027496338 seconds for one epoch ---
--- 2.4331674575805664 seconds for one epoch ---
--- 0.3366878032684326 seconds for one epoch ---
--- 2.4584386348724365 seconds for one epoch ---
--- 0.3257420063018799 seconds for one epoch ---
--- 2.4213335514068604 seconds for one epoch ---
--- 0.32136058807373047 seconds for one epoch ---
--- 2.471550941467285 seconds for one epoch ---
--- 0.3199770450592041 seconds for one epoch ---
--- 2.4827394485473633 seconds for one epoch ---
--- 0.326754093170166 seconds for one epoch ---
--- 2.4285552501678467 seconds for one epoch ---
--- 0.3258810043334961 seconds for one epoch ---
--- 2.4252572059631348 seconds for one epoch ---
--- 0.3324284553527832 seconds for one epoch ---
--- 2.4596199989318848 seconds for one epoch ---
--- 0.3405904769897461 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993888]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.066042]
 [ -0.      ]]
--- 0.26781558990478516 seconds for one epoch ---
Epoch 4825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4202.7666015625, (1794.4514, 3.4891698, 2404.3586, 0.46742487)
   validation loss 766.25927734375, (492.83295, 0.48666108, 272.47223, 0.46742487)
decoder loss ratio: 19093.203954, decoder SINDy loss  ratio: 0.588170
--- 0.3336966037750244 seconds for one epoch ---
--- 2.43499493598938 seconds for one epoch ---
--- 0.33378100395202637 seconds for one epoch ---
--- 2.4482831954956055 seconds for one epoch ---
--- 0.33287906646728516 seconds for one epoch ---
--- 2.4864890575408936 seconds for one epoch ---
--- 0.3329017162322998 seconds for one epoch ---
--- 2.4735331535339355 seconds for one epoch ---
--- 0.31759142875671387 seconds for one epoch ---
--- 2.498777151107788 seconds for one epoch ---
--- 0.32358717918395996 seconds for one epoch ---
--- 2.4618983268737793 seconds for one epoch ---
--- 0.3258664608001709 seconds for one epoch ---
--- 2.4944119453430176 seconds for one epoch ---
--- 0.3282206058502197 seconds for one epoch ---
--- 2.4909114837646484 seconds for one epoch ---
--- 0.3179144859313965 seconds for one epoch ---
--- 2.4860286712646484 seconds for one epoch ---
--- 0.3316032886505127 seconds for one epoch ---
--- 2.4837589263916016 seconds for one epoch ---
--- 0.3163790702819824 seconds for one epoch ---
--- 2.5115203857421875 seconds for one epoch ---
--- 0.32943201065063477 seconds for one epoch ---
--- 2.518346071243286 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993912]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.082684]
 [  0.      ]]
--- 0.31229496002197266 seconds for one epoch ---
Epoch 4850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3624.7802734375, (1489.7646, 0.93008775, 2133.6177, 0.46788546)
   validation loss 907.293701171875, (621.31396, 0.48037568, 285.03146, 0.46788546)
decoder loss ratio: 24070.781647, decoder SINDy loss  ratio: 0.615281
--- 0.259035587310791 seconds for one epoch ---
--- 0.32178187370300293 seconds for one epoch ---
--- 2.493433713912964 seconds for one epoch ---
--- 0.3267650604248047 seconds for one epoch ---
--- 2.483600616455078 seconds for one epoch ---
--- 0.32935309410095215 seconds for one epoch ---
--- 2.4876809120178223 seconds for one epoch ---
--- 0.3291940689086914 seconds for one epoch ---
--- 2.4696097373962402 seconds for one epoch ---
--- 0.3367002010345459 seconds for one epoch ---
--- 2.471510171890259 seconds for one epoch ---
--- 0.34158849716186523 seconds for one epoch ---
--- 2.4912002086639404 seconds for one epoch ---
--- 0.31902575492858887 seconds for one epoch ---
--- 2.485361337661743 seconds for one epoch ---
--- 0.33191919326782227 seconds for one epoch ---
--- 2.502224922180176 seconds for one epoch ---
--- 0.32822418212890625 seconds for one epoch ---
--- 2.5074827671051025 seconds for one epoch ---
--- 0.3204348087310791 seconds for one epoch ---
--- 2.4544107913970947 seconds for one epoch ---
--- 0.33493733406066895 seconds for one epoch ---
--- 2.4647104740142822 seconds for one epoch ---
--- 0.32654762268066406 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99939334]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.094997]
 [  0.      ]]
--- 0.2652144432067871 seconds for one epoch ---
Epoch 4875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2494.452392578125, (1063.5986, 1.895757, 1428.4897, 0.4681962)
   validation loss 721.6168823242188, (449.09366, 0.4751552, 271.57983, 0.4681962)
decoder loss ratio: 17398.667989, decoder SINDy loss  ratio: 0.586243
--- 0.30127739906311035 seconds for one epoch ---
--- 2.4497272968292236 seconds for one epoch ---
--- 0.3377518653869629 seconds for one epoch ---
--- 2.433579683303833 seconds for one epoch ---
--- 0.32384824752807617 seconds for one epoch ---
--- 2.450932502746582 seconds for one epoch ---
--- 0.3290724754333496 seconds for one epoch ---
--- 2.497114658355713 seconds for one epoch ---
--- 0.32424330711364746 seconds for one epoch ---
--- 2.4621543884277344 seconds for one epoch ---
--- 0.3235633373260498 seconds for one epoch ---
--- 2.5126707553863525 seconds for one epoch ---
--- 0.332836389541626 seconds for one epoch ---
--- 2.5218605995178223 seconds for one epoch ---
--- 0.3300435543060303 seconds for one epoch ---
--- 2.4961867332458496 seconds for one epoch ---
--- 0.3338451385498047 seconds for one epoch ---
--- 2.517876148223877 seconds for one epoch ---
--- 0.3268618583679199 seconds for one epoch ---
--- 2.455165386199951 seconds for one epoch ---
--- 0.3364269733428955 seconds for one epoch ---
--- 2.5181949138641357 seconds for one epoch ---
--- 0.3318026065826416 seconds for one epoch ---
--- 2.5177998542785645 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993974]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.111841]
 [ -0.      ]]
--- 0.3043038845062256 seconds for one epoch ---
Epoch 4900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1705.0225830078125, (867.813, 0.9342744, 835.80676, 0.46865103)
   validation loss 821.86279296875, (535.3718, 0.47482637, 285.54752, 0.46865103)
decoder loss ratio: 20741.233992, decoder SINDy loss  ratio: 0.616394
--- 0.27725648880004883 seconds for one epoch ---
--- 0.3445279598236084 seconds for one epoch ---
--- 2.4462578296661377 seconds for one epoch ---
--- 0.3249242305755615 seconds for one epoch ---
--- 2.469815254211426 seconds for one epoch ---
--- 0.3260176181793213 seconds for one epoch ---
--- 2.5007002353668213 seconds for one epoch ---
--- 0.3228592872619629 seconds for one epoch ---
--- 2.511798620223999 seconds for one epoch ---
--- 0.33004188537597656 seconds for one epoch ---
--- 2.510782241821289 seconds for one epoch ---
--- 0.3321259021759033 seconds for one epoch ---
--- 2.4905805587768555 seconds for one epoch ---
--- 0.32852673530578613 seconds for one epoch ---
--- 2.5293264389038086 seconds for one epoch ---
--- 0.33512425422668457 seconds for one epoch ---
--- 2.535078763961792 seconds for one epoch ---
--- 0.32440686225891113 seconds for one epoch ---
--- 2.49200701713562 seconds for one epoch ---
--- 0.3269684314727783 seconds for one epoch ---
--- 2.4763832092285156 seconds for one epoch ---
--- 0.31568384170532227 seconds for one epoch ---
--- 2.4599809646606445 seconds for one epoch ---
--- 0.3370475769042969 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99940133]
 [0.        ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-18.1296]
 [ -0.    ]]
--- 0.2648303508758545 seconds for one epoch ---
Epoch 4925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2627.9765625, (1087.8363, 3.9727242, 1535.6985, 0.46910173)
   validation loss 879.0103759765625, (588.7167, 0.527992, 289.29657, 0.46910173)
decoder loss ratio: 22807.906039, decoder SINDy loss  ratio: 0.624487
--- 0.3127579689025879 seconds for one epoch ---
--- 2.490797281265259 seconds for one epoch ---
--- 0.3236873149871826 seconds for one epoch ---
--- 2.4965648651123047 seconds for one epoch ---
--- 0.33318567276000977 seconds for one epoch ---
--- 2.5221450328826904 seconds for one epoch ---
--- 0.3190956115722656 seconds for one epoch ---
--- 2.484297275543213 seconds for one epoch ---
--- 0.3257424831390381 seconds for one epoch ---
--- 2.523695468902588 seconds for one epoch ---
--- 0.31578874588012695 seconds for one epoch ---
--- 2.5191667079925537 seconds for one epoch ---
--- 0.3302931785583496 seconds for one epoch ---
--- 2.4867353439331055 seconds for one epoch ---
--- 0.3229100704193115 seconds for one epoch ---
--- 2.5105607509613037 seconds for one epoch ---
--- 0.3232440948486328 seconds for one epoch ---
--- 2.510828971862793 seconds for one epoch ---
--- 0.3263401985168457 seconds for one epoch ---
--- 2.515730142593384 seconds for one epoch ---
--- 0.3335530757904053 seconds for one epoch ---
--- 2.4960508346557617 seconds for one epoch ---
--- 0.3258352279663086 seconds for one epoch ---
--- 2.5218536853790283 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994039]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.144663]
 [  0.      ]]
--- 0.3052337169647217 seconds for one epoch ---
Epoch 4950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2559.48193359375, (1504.805, 1.2131077, 1052.9943, 0.46948758)
   validation loss 785.729736328125, (518.3181, 0.4718141, 266.47034, 0.46948758)
decoder loss ratio: 20080.543624, decoder SINDy loss  ratio: 0.575214
--- 0.269101619720459 seconds for one epoch ---
--- 0.32509851455688477 seconds for one epoch ---
--- 2.5095784664154053 seconds for one epoch ---
--- 0.3269805908203125 seconds for one epoch ---
--- 2.5510594844818115 seconds for one epoch ---
--- 0.3324465751647949 seconds for one epoch ---
--- 2.4693899154663086 seconds for one epoch ---
--- 0.3320887088775635 seconds for one epoch ---
--- 2.5091121196746826 seconds for one epoch ---
--- 0.3209974765777588 seconds for one epoch ---
--- 2.4663515090942383 seconds for one epoch ---
--- 0.3294215202331543 seconds for one epoch ---
--- 2.4891982078552246 seconds for one epoch ---
--- 0.7726104259490967 seconds for one epoch ---
--- 2.4822592735290527 seconds for one epoch ---
--- 0.332395076751709 seconds for one epoch ---
--- 2.487792730331421 seconds for one epoch ---
--- 0.31963253021240234 seconds for one epoch ---
--- 2.4897170066833496 seconds for one epoch ---
--- 0.3315768241882324 seconds for one epoch ---
--- 2.5092504024505615 seconds for one epoch ---
--- 0.3302733898162842 seconds for one epoch ---
--- 2.539287567138672 seconds for one epoch ---
--- 0.33826231956481934 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994057]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.159101]
 [ -0.      ]]
--- 0.2751152515411377 seconds for one epoch ---
Epoch 4975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5410.2138671875, (2073.0645, 1.2874218, 3335.3926, 0.46994883)
   validation loss 855.8041381835938, (592.5037, 0.55334395, 262.2771, 0.46994883)
decoder loss ratio: 22954.622866, decoder SINDy loss  ratio: 0.566162
--- 0.3205375671386719 seconds for one epoch ---
--- 2.4893553256988525 seconds for one epoch ---
--- 0.31945300102233887 seconds for one epoch ---
--- 2.535144090652466 seconds for one epoch ---
--- 0.32915520668029785 seconds for one epoch ---
--- 2.5602972507476807 seconds for one epoch ---
--- 0.323239803314209 seconds for one epoch ---
--- 2.5464115142822266 seconds for one epoch ---
--- 0.31515049934387207 seconds for one epoch ---
--- 2.491830825805664 seconds for one epoch ---
--- 0.3205296993255615 seconds for one epoch ---
--- 2.495249032974243 seconds for one epoch ---
--- 0.32892417907714844 seconds for one epoch ---
--- 2.4914867877960205 seconds for one epoch ---
--- 0.3266606330871582 seconds for one epoch ---
--- 2.5415663719177246 seconds for one epoch ---
--- 0.3229866027832031 seconds for one epoch ---
--- 2.5767345428466797 seconds for one epoch ---
--- 0.3278157711029053 seconds for one epoch ---
--- 2.5119338035583496 seconds for one epoch ---
--- 0.33836817741394043 seconds for one epoch ---
--- 2.578056573867798 seconds for one epoch ---
--- 0.32545018196105957 seconds for one epoch ---
--- 2.5347018241882324 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994078]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.174555]
 [  0.      ]]
--- 0.3009159564971924 seconds for one epoch ---
Epoch 5000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3120.5947265625, (987.1483, 2.626047, 2130.35, 0.47032395)
   validation loss 711.0534057617188, (437.72128, 0.4708202, 272.39096, 0.47032395)
decoder loss ratio: 16958.082419, decoder SINDy loss  ratio: 0.587994
THRESHOLDING: 1 active coefficients
--- 2.469146728515625 seconds for one epoch ---
--- 0.32924437522888184 seconds for one epoch ---
--- 2.5448179244995117 seconds for one epoch ---
--- 0.32748842239379883 seconds for one epoch ---
--- 2.4841718673706055 seconds for one epoch ---
--- 0.32528257369995117 seconds for one epoch ---
--- 2.4958972930908203 seconds for one epoch ---
--- 0.32132387161254883 seconds for one epoch ---
--- 2.496560573577881 seconds for one epoch ---
--- 0.3298184871673584 seconds for one epoch ---
--- 2.534503936767578 seconds for one epoch ---
--- 0.3267018795013428 seconds for one epoch ---
--- 2.5119521617889404 seconds for one epoch ---
--- 0.31693053245544434 seconds for one epoch ---
--- 2.5813651084899902 seconds for one epoch ---
--- 0.325977087020874 seconds for one epoch ---
--- 2.5127341747283936 seconds for one epoch ---
--- 0.32054948806762695 seconds for one epoch ---
--- 2.550957441329956 seconds for one epoch ---
--- 0.33106446266174316 seconds for one epoch ---
--- 2.540320634841919 seconds for one epoch ---
--- 0.31879639625549316 seconds for one epoch ---
--- 2.5244252681732178 seconds for one epoch ---
--- 0.32859063148498535 seconds for one epoch ---
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.99941]
 [0.     ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.194672]
 [  0.      ]]
--- 0.2640538215637207 seconds for one epoch ---
Epoch 5025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3301.865478515625, (1312.849, 1.1763691, 1987.3691, 0.4708446)
   validation loss 778.4830322265625, (499.15945, 0.4971784, 278.3556, 0.4708446)
decoder loss ratio: 19338.303840, decoder SINDy loss  ratio: 0.600870
--- 0.29442739486694336 seconds for one epoch ---
--- 2.5250513553619385 seconds for one epoch ---
--- 0.33176374435424805 seconds for one epoch ---
--- 2.531033754348755 seconds for one epoch ---
--- 0.32873082160949707 seconds for one epoch ---
--- 2.508207321166992 seconds for one epoch ---
--- 0.3309628963470459 seconds for one epoch ---
--- 2.557185649871826 seconds for one epoch ---
--- 0.3327469825744629 seconds for one epoch ---
--- 2.5688998699188232 seconds for one epoch ---
--- 0.3364248275756836 seconds for one epoch ---
--- 2.526609420776367 seconds for one epoch ---
--- 0.3291893005371094 seconds for one epoch ---
--- 2.5370750427246094 seconds for one epoch ---
--- 0.3265385627746582 seconds for one epoch ---
--- 2.529679775238037 seconds for one epoch ---
--- 0.32569122314453125 seconds for one epoch ---
--- 2.593104839324951 seconds for one epoch ---
--- 0.33021974563598633 seconds for one epoch ---
--- 2.535393476486206 seconds for one epoch ---
--- 0.3334364891052246 seconds for one epoch ---
--- 2.5917975902557373 seconds for one epoch ---
--- 0.3294055461883545 seconds for one epoch ---
--- 2.5715129375457764 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99941325]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.210316]
 [ -0.      ]]
--- 0.3079986572265625 seconds for one epoch ---
Epoch 5050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4375.94580078125, (1451.9801, 1.3467051, 2922.1477, 0.47123766)
   validation loss 770.1142578125, (492.95377, 0.45260444, 276.23663, 0.47123766)
decoder loss ratio: 19097.884695, decoder SINDy loss  ratio: 0.596296
--- 0.2795882225036621 seconds for one epoch ---
--- 0.3288609981536865 seconds for one epoch ---
--- 2.5091166496276855 seconds for one epoch ---
--- 0.3341336250305176 seconds for one epoch ---
--- 2.524989604949951 seconds for one epoch ---
--- 0.3268887996673584 seconds for one epoch ---
--- 2.539330244064331 seconds for one epoch ---
--- 0.3322176933288574 seconds for one epoch ---
--- 2.5751664638519287 seconds for one epoch ---
--- 0.3310565948486328 seconds for one epoch ---
--- 2.5709352493286133 seconds for one epoch ---
--- 0.3255503177642822 seconds for one epoch ---
--- 2.5829110145568848 seconds for one epoch ---
--- 0.32660865783691406 seconds for one epoch ---
--- 2.5291988849639893 seconds for one epoch ---
--- 0.33918118476867676 seconds for one epoch ---
--- 2.526451826095581 seconds for one epoch ---
--- 0.329725980758667 seconds for one epoch ---
--- 2.583223342895508 seconds for one epoch ---
--- 0.3301730155944824 seconds for one epoch ---
--- 2.573127269744873 seconds for one epoch ---
--- 0.33314085006713867 seconds for one epoch ---
--- 2.5929296016693115 seconds for one epoch ---
--- 0.3299100399017334 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999416]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.226658]
 [ -0.      ]]
--- 0.2578902244567871 seconds for one epoch ---
Epoch 5075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3619.9970703125, (1444.159, 7.1579804, 2168.2085, 0.47169828)
   validation loss 764.7911376953125, (488.85, 0.44545254, 275.02396, 0.47169828)
decoder loss ratio: 18938.897917, decoder SINDy loss  ratio: 0.593678
--- 0.3083455562591553 seconds for one epoch ---
--- 2.5798425674438477 seconds for one epoch ---
--- 0.32722043991088867 seconds for one epoch ---
--- 2.5368854999542236 seconds for one epoch ---
--- 0.3347146511077881 seconds for one epoch ---
--- 2.566826105117798 seconds for one epoch ---
--- 0.3332831859588623 seconds for one epoch ---
--- 2.59033465385437 seconds for one epoch ---
--- 0.3348860740661621 seconds for one epoch ---
--- 2.5393970012664795 seconds for one epoch ---
--- 0.3251826763153076 seconds for one epoch ---
--- 2.569808006286621 seconds for one epoch ---
--- 0.3346266746520996 seconds for one epoch ---
--- 2.5468130111694336 seconds for one epoch ---
--- 0.3256392478942871 seconds for one epoch ---
--- 2.571086883544922 seconds for one epoch ---
--- 0.33388447761535645 seconds for one epoch ---
--- 2.586219549179077 seconds for one epoch ---
--- 0.33516740798950195 seconds for one epoch ---
--- 2.601686716079712 seconds for one epoch ---
--- 0.32141852378845215 seconds for one epoch ---
--- 2.567822217941284 seconds for one epoch ---
--- 0.3284487724304199 seconds for one epoch ---
--- 2.549610137939453 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994184]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.238182]
 [  0.      ]]
--- 0.3145015239715576 seconds for one epoch ---
Epoch 5100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4159.55078125, (1899.9406, 1.8217233, 2257.3164, 0.47199583)
   validation loss 854.2561645507812, (558.5582, 0.46716738, 294.75882, 0.47199583)
decoder loss ratio: 21639.515435, decoder SINDy loss  ratio: 0.636278
--- 0.284834623336792 seconds for one epoch ---
--- 0.32921648025512695 seconds for one epoch ---
--- 2.544395685195923 seconds for one epoch ---
--- 0.3174734115600586 seconds for one epoch ---
--- 2.556567907333374 seconds for one epoch ---
--- 0.32209038734436035 seconds for one epoch ---
--- 2.61474871635437 seconds for one epoch ---
--- 0.3303253650665283 seconds for one epoch ---
--- 2.6015918254852295 seconds for one epoch ---
--- 0.32589197158813477 seconds for one epoch ---
--- 2.5749592781066895 seconds for one epoch ---
--- 0.33530116081237793 seconds for one epoch ---
--- 2.596390724182129 seconds for one epoch ---
--- 0.3193783760070801 seconds for one epoch ---
--- 2.6067662239074707 seconds for one epoch ---
--- 0.3305180072784424 seconds for one epoch ---
--- 2.602468490600586 seconds for one epoch ---
--- 0.32998228073120117 seconds for one epoch ---
--- 2.611952304840088 seconds for one epoch ---
--- 0.32727479934692383 seconds for one epoch ---
--- 2.5439720153808594 seconds for one epoch ---
--- 0.33066391944885254 seconds for one epoch ---
--- 2.5998787879943848 seconds for one epoch ---
--- 0.33045148849487305 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994216]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.252542]
 [ -0.      ]]
--- 0.26784825325012207 seconds for one epoch ---
Epoch 5125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2625.673095703125, (1629.6279, 0.6002839, 994.9724, 0.47241592)
   validation loss 778.56494140625, (502.419, 0.44089705, 275.2326, 0.47241592)
decoder loss ratio: 19464.584544, decoder SINDy loss  ratio: 0.594128
--- 0.31577515602111816 seconds for one epoch ---
--- 2.5640950202941895 seconds for one epoch ---
--- 0.32642292976379395 seconds for one epoch ---
--- 2.581857681274414 seconds for one epoch ---
--- 0.3326406478881836 seconds for one epoch ---
--- 2.584106683731079 seconds for one epoch ---
--- 0.32216978073120117 seconds for one epoch ---
--- 2.552003860473633 seconds for one epoch ---
--- 0.3199326992034912 seconds for one epoch ---
--- 2.6317265033721924 seconds for one epoch ---
--- 0.3356199264526367 seconds for one epoch ---
--- 2.567225456237793 seconds for one epoch ---
--- 0.33844614028930664 seconds for one epoch ---
--- 2.576139211654663 seconds for one epoch ---
--- 0.3309907913208008 seconds for one epoch ---
--- 2.584425687789917 seconds for one epoch ---
--- 0.32627367973327637 seconds for one epoch ---
--- 2.6268110275268555 seconds for one epoch ---
--- 0.3313760757446289 seconds for one epoch ---
--- 2.574023962020874 seconds for one epoch ---
--- 0.3338751792907715 seconds for one epoch ---
--- 2.640665054321289 seconds for one epoch ---
--- 0.34332942962646484 seconds for one epoch ---
--- 2.588951826095581 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994234]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-18.27047]
 [  0.     ]]
--- 0.31116461753845215 seconds for one epoch ---
Epoch 5150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2938.849365234375, (1071.6815, 3.7039719, 1862.9911, 0.47286367)
   validation loss 823.3428344726562, (532.8636, 0.4411694, 289.56528, 0.47286367)
decoder loss ratio: 20644.060430, decoder SINDy loss  ratio: 0.625067
--- 0.283113956451416 seconds for one epoch ---
--- 0.32237935066223145 seconds for one epoch ---
--- 2.612783670425415 seconds for one epoch ---
--- 0.3283696174621582 seconds for one epoch ---
--- 2.5782582759857178 seconds for one epoch ---
--- 0.3335108757019043 seconds for one epoch ---
--- 2.648143768310547 seconds for one epoch ---
--- 0.32085704803466797 seconds for one epoch ---
--- 2.5824010372161865 seconds for one epoch ---
--- 0.3262975215911865 seconds for one epoch ---
--- 2.6245110034942627 seconds for one epoch ---
--- 0.33160877227783203 seconds for one epoch ---
--- 2.651047706604004 seconds for one epoch ---
--- 0.32960963249206543 seconds for one epoch ---
--- 2.5847227573394775 seconds for one epoch ---
--- 0.32443761825561523 seconds for one epoch ---
--- 2.6245017051696777 seconds for one epoch ---
--- 0.33621859550476074 seconds for one epoch ---
--- 2.5891096591949463 seconds for one epoch ---
--- 0.3215615749359131 seconds for one epoch ---
--- 2.646803617477417 seconds for one epoch ---
--- 0.32857799530029297 seconds for one epoch ---
--- 2.631509780883789 seconds for one epoch ---
--- 0.3211479187011719 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999425]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.286917]
 [  0.      ]]
--- 0.27706384658813477 seconds for one epoch ---
Epoch 5175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2470.50927734375, (1312.3171, 2.866775, 1154.8519, 0.47330496)
   validation loss 1046.77392578125, (752.47565, 0.4673122, 293.35773, 0.47330496)
decoder loss ratio: 29152.212919, decoder SINDy loss  ratio: 0.633254
--- 0.3162574768066406 seconds for one epoch ---
--- 2.5965561866760254 seconds for one epoch ---
--- 0.3390223979949951 seconds for one epoch ---
--- 2.5863168239593506 seconds for one epoch ---
--- 0.34102702140808105 seconds for one epoch ---
--- 2.6540918350219727 seconds for one epoch ---
--- 0.3332667350769043 seconds for one epoch ---
--- 2.6313419342041016 seconds for one epoch ---
--- 0.31804370880126953 seconds for one epoch ---
--- 2.6013829708099365 seconds for one epoch ---
--- 0.32126593589782715 seconds for one epoch ---
--- 2.628890037536621 seconds for one epoch ---
--- 0.32237768173217773 seconds for one epoch ---
--- 2.599087953567505 seconds for one epoch ---
--- 0.3355674743652344 seconds for one epoch ---
--- 2.6306374073028564 seconds for one epoch ---
--- 0.3245666027069092 seconds for one epoch ---
--- 2.6263067722320557 seconds for one epoch ---
--- 0.3237471580505371 seconds for one epoch ---
--- 2.61145281791687 seconds for one epoch ---
--- 0.32657384872436523 seconds for one epoch ---
--- 2.672889471054077 seconds for one epoch ---
--- 0.3292255401611328 seconds for one epoch ---
--- 2.6094775199890137 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99942625]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.297533]
 [ -0.      ]]
--- 0.31084275245666504 seconds for one epoch ---
Epoch 5200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3310.583984375, (1457.9923, 2.2937605, 1849.8242, 0.47361708)
   validation loss 834.349609375, (547.53577, 0.47748613, 285.86276, 0.47361708)
decoder loss ratio: 21212.486162, decoder SINDy loss  ratio: 0.617075
--- 0.27224087715148926 seconds for one epoch ---
--- 0.31807446479797363 seconds for one epoch ---
--- 2.6355948448181152 seconds for one epoch ---
--- 0.33398962020874023 seconds for one epoch ---
--- 2.6399548053741455 seconds for one epoch ---
--- 0.31349682807922363 seconds for one epoch ---
--- 2.6153223514556885 seconds for one epoch ---
--- 0.3131544589996338 seconds for one epoch ---
--- 2.5952582359313965 seconds for one epoch ---
--- 0.32627367973327637 seconds for one epoch ---
--- 2.600581645965576 seconds for one epoch ---
--- 0.3169097900390625 seconds for one epoch ---
--- 2.6520819664001465 seconds for one epoch ---
--- 0.3243269920349121 seconds for one epoch ---
--- 2.6399431228637695 seconds for one epoch ---
--- 0.323793888092041 seconds for one epoch ---
--- 2.6034486293792725 seconds for one epoch ---
--- 0.3253147602081299 seconds for one epoch ---
--- 2.6595661640167236 seconds for one epoch ---
--- 0.32229042053222656 seconds for one epoch ---
--- 2.6584324836730957 seconds for one epoch ---
--- 0.3400275707244873 seconds for one epoch ---
--- 2.6119399070739746 seconds for one epoch ---
--- 0.33072924613952637 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994278]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.310228]
 [ -0.      ]]
--- 0.26686787605285645 seconds for one epoch ---
Epoch 5225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4651.39794921875, (1309.449, 2.2607894, 3339.214, 0.47391102)
   validation loss 846.93505859375, (574.3462, 0.47093144, 271.64398, 0.47391102)
decoder loss ratio: 22251.168564, decoder SINDy loss  ratio: 0.586382
--- 0.312908411026001 seconds for one epoch ---
--- 2.650615692138672 seconds for one epoch ---
--- 0.34383201599121094 seconds for one epoch ---
--- 2.5939736366271973 seconds for one epoch ---
--- 0.33919215202331543 seconds for one epoch ---
--- 2.5954785346984863 seconds for one epoch ---
--- 0.3294966220855713 seconds for one epoch ---
--- 2.657100200653076 seconds for one epoch ---
--- 0.32592225074768066 seconds for one epoch ---
--- 2.6089797019958496 seconds for one epoch ---
--- 0.3341639041900635 seconds for one epoch ---
--- 2.654789686203003 seconds for one epoch ---
--- 0.3178558349609375 seconds for one epoch ---
--- 2.668083906173706 seconds for one epoch ---
--- 0.3285980224609375 seconds for one epoch ---
--- 2.7143006324768066 seconds for one epoch ---
--- 0.34343504905700684 seconds for one epoch ---
--- 2.6211633682250977 seconds for one epoch ---
--- 0.3243377208709717 seconds for one epoch ---
--- 2.680300235748291 seconds for one epoch ---
--- 0.32708740234375 seconds for one epoch ---
--- 2.673548936843872 seconds for one epoch ---
--- 0.3193807601928711 seconds for one epoch ---
--- 2.688753128051758 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994298]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.321991]
 [  0.      ]]
--- 0.31100010871887207 seconds for one epoch ---
Epoch 5250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2875.19873046875, (1722.0278, 2.1788323, 1150.5181, 0.47422227)
   validation loss 960.298095703125, (680.703, 0.4937543, 278.62704, 0.47422227)
decoder loss ratio: 26371.616086, decoder SINDy loss  ratio: 0.601456
--- 0.2814011573791504 seconds for one epoch ---
--- 0.339169979095459 seconds for one epoch ---
--- 2.614490270614624 seconds for one epoch ---
--- 0.32584238052368164 seconds for one epoch ---
--- 2.690062999725342 seconds for one epoch ---
--- 0.32453179359436035 seconds for one epoch ---
--- 2.659417152404785 seconds for one epoch ---
--- 0.34950685501098633 seconds for one epoch ---
--- 2.62556791305542 seconds for one epoch ---
--- 0.34447312355041504 seconds for one epoch ---
--- 2.6271719932556152 seconds for one epoch ---
--- 0.3292536735534668 seconds for one epoch ---
--- 2.619810104370117 seconds for one epoch ---
--- 0.3220362663269043 seconds for one epoch ---
--- 2.611862897872925 seconds for one epoch ---
--- 0.3322000503540039 seconds for one epoch ---
--- 2.6717567443847656 seconds for one epoch ---
--- 0.3254580497741699 seconds for one epoch ---
--- 2.694918632507324 seconds for one epoch ---
--- 0.33115243911743164 seconds for one epoch ---
--- 2.7037172317504883 seconds for one epoch ---
--- 0.3287060260772705 seconds for one epoch ---
--- 2.6823058128356934 seconds for one epoch ---
--- 0.3188655376434326 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994323]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.335724]
 [ -0.      ]]
--- 0.2731473445892334 seconds for one epoch ---
Epoch 5275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2286.1474609375, (1136.681, 0.85712487, 1148.1345, 0.47458574)
   validation loss 802.47216796875, (524.62976, 0.46205556, 276.90573, 0.47458574)
decoder loss ratio: 20325.067728, decoder SINDy loss  ratio: 0.597740
--- 0.324174165725708 seconds for one epoch ---
--- 2.6717395782470703 seconds for one epoch ---
--- 0.3332657814025879 seconds for one epoch ---
--- 2.629483461380005 seconds for one epoch ---
--- 0.3190951347351074 seconds for one epoch ---
--- 2.6781952381134033 seconds for one epoch ---
--- 0.3162813186645508 seconds for one epoch ---
--- 2.683281898498535 seconds for one epoch ---
--- 0.3301064968109131 seconds for one epoch ---
--- 2.6382553577423096 seconds for one epoch ---
--- 0.3221452236175537 seconds for one epoch ---
--- 2.6178770065307617 seconds for one epoch ---
--- 0.34267401695251465 seconds for one epoch ---
--- 2.631742000579834 seconds for one epoch ---
--- 0.3345377445220947 seconds for one epoch ---
--- 2.6542630195617676 seconds for one epoch ---
--- 0.3266768455505371 seconds for one epoch ---
--- 2.7130837440490723 seconds for one epoch ---
--- 0.32166409492492676 seconds for one epoch ---
--- 2.6843268871307373 seconds for one epoch ---
--- 0.3343932628631592 seconds for one epoch ---
--- 2.6476495265960693 seconds for one epoch ---
--- 0.3276398181915283 seconds for one epoch ---
--- 2.6909234523773193 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994348]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.349075]
 [  0.      ]]
--- 0.3079075813293457 seconds for one epoch ---
Epoch 5300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2935.76025390625, (954.41156, 0.42416343, 1980.4497, 0.47493586)
   validation loss 1099.741455078125, (772.74115, 0.47774228, 326.04764, 0.47493586)
decoder loss ratio: 29937.333685, decoder SINDy loss  ratio: 0.703820
--- 0.2751457691192627 seconds for one epoch ---
--- 0.3310720920562744 seconds for one epoch ---
--- 2.6224400997161865 seconds for one epoch ---
--- 0.33141565322875977 seconds for one epoch ---
--- 2.700326442718506 seconds for one epoch ---
--- 0.3245065212249756 seconds for one epoch ---
--- 2.6360292434692383 seconds for one epoch ---
--- 0.32221055030822754 seconds for one epoch ---
--- 2.6999399662017822 seconds for one epoch ---
--- 0.3183012008666992 seconds for one epoch ---
--- 2.7062370777130127 seconds for one epoch ---
--- 0.3246471881866455 seconds for one epoch ---
--- 2.7083606719970703 seconds for one epoch ---
--- 0.31299471855163574 seconds for one epoch ---
--- 2.6958844661712646 seconds for one epoch ---
--- 0.3252096176147461 seconds for one epoch ---
--- 2.710730791091919 seconds for one epoch ---
--- 0.31903839111328125 seconds for one epoch ---
--- 2.7155921459198 seconds for one epoch ---
--- 0.3219113349914551 seconds for one epoch ---
--- 2.6512227058410645 seconds for one epoch ---
--- 0.3237142562866211 seconds for one epoch ---
--- 2.7102737426757812 seconds for one epoch ---
--- 0.32854676246643066 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999437]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.358086]
 [  0.      ]]
--- 0.2607581615447998 seconds for one epoch ---
Epoch 5325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2227.287109375, (994.9388, 2.1422217, 1229.731, 0.47521335)
   validation loss 833.928466796875, (549.377, 0.4871375, 283.58914, 0.47521335)
decoder loss ratio: 21283.819289, decoder SINDy loss  ratio: 0.612167
--- 0.32058095932006836 seconds for one epoch ---
--- 2.6297190189361572 seconds for one epoch ---
--- 0.335573673248291 seconds for one epoch ---
--- 2.7052080631256104 seconds for one epoch ---
--- 0.32780003547668457 seconds for one epoch ---
--- 2.728572368621826 seconds for one epoch ---
--- 0.33252930641174316 seconds for one epoch ---
--- 2.7102231979370117 seconds for one epoch ---
--- 0.32961392402648926 seconds for one epoch ---
--- 2.6598169803619385 seconds for one epoch ---
--- 0.3478379249572754 seconds for one epoch ---
--- 2.6610841751098633 seconds for one epoch ---
--- 0.3293428421020508 seconds for one epoch ---
--- 2.698932647705078 seconds for one epoch ---
--- 0.3235781192779541 seconds for one epoch ---
--- 2.7222023010253906 seconds for one epoch ---
--- 0.3144993782043457 seconds for one epoch ---
--- 2.6674838066101074 seconds for one epoch ---
--- 0.3053290843963623 seconds for one epoch ---
--- 2.713491678237915 seconds for one epoch ---
--- 0.3302478790283203 seconds for one epoch ---
--- 2.7095823287963867 seconds for one epoch ---
--- 0.33357882499694824 seconds for one epoch ---
--- 2.6673049926757812 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99943984]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.371624]
 [ -0.      ]]
--- 0.31305456161499023 seconds for one epoch ---
Epoch 5350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3319.6806640625, (1243.2892, 1.2782907, 2074.6375, 0.47554046)
   validation loss 824.0390625, (533.5277, 0.47594014, 289.55988, 0.47554046)
decoder loss ratio: 20669.789729, decoder SINDy loss  ratio: 0.625056
--- 0.27402400970458984 seconds for one epoch ---
--- 0.33092451095581055 seconds for one epoch ---
--- 2.660973310470581 seconds for one epoch ---
--- 0.32929253578186035 seconds for one epoch ---
--- 2.6916654109954834 seconds for one epoch ---
--- 0.337430477142334 seconds for one epoch ---
--- 2.673550844192505 seconds for one epoch ---
--- 0.33002638816833496 seconds for one epoch ---
--- 2.700308322906494 seconds for one epoch ---
--- 0.33173322677612305 seconds for one epoch ---
--- 2.7073986530303955 seconds for one epoch ---
--- 0.3325364589691162 seconds for one epoch ---
--- 2.704735517501831 seconds for one epoch ---
--- 0.3290731906890869 seconds for one epoch ---
--- 2.7107105255126953 seconds for one epoch ---
--- 0.3186759948730469 seconds for one epoch ---
--- 2.665646553039551 seconds for one epoch ---
--- 0.3279757499694824 seconds for one epoch ---
--- 2.712033271789551 seconds for one epoch ---
--- 0.3318750858306885 seconds for one epoch ---
--- 2.7134764194488525 seconds for one epoch ---
--- 0.3203237056732178 seconds for one epoch ---
--- 2.6871767044067383 seconds for one epoch ---
--- 0.33089613914489746 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99944067]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-18.38056]
 [ -0.     ]]
--- 0.26680898666381836 seconds for one epoch ---
Epoch 5375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1827.5836181640625, (945.94666, 0.36366478, 880.7975, 0.47578642)
   validation loss 779.157470703125, (502.71487, 0.48303798, 275.4838, 0.47578642)
decoder loss ratio: 19476.046981, decoder SINDy loss  ratio: 0.594671
--- 0.30952024459838867 seconds for one epoch ---
--- 2.7303731441497803 seconds for one epoch ---
--- 0.33062052726745605 seconds for one epoch ---
--- 2.7290103435516357 seconds for one epoch ---
--- 0.3181426525115967 seconds for one epoch ---
--- 2.747663736343384 seconds for one epoch ---
--- 0.33025026321411133 seconds for one epoch ---
--- 2.671267509460449 seconds for one epoch ---
--- 0.3292672634124756 seconds for one epoch ---
--- 2.667672634124756 seconds for one epoch ---
--- 0.32292914390563965 seconds for one epoch ---
--- 2.6806046962738037 seconds for one epoch ---
--- 0.33478403091430664 seconds for one epoch ---
--- 2.672938108444214 seconds for one epoch ---
--- 0.31784987449645996 seconds for one epoch ---
--- 2.7202882766723633 seconds for one epoch ---
--- 0.32692623138427734 seconds for one epoch ---
--- 2.7335050106048584 seconds for one epoch ---
--- 0.33621907234191895 seconds for one epoch ---
--- 2.6865274906158447 seconds for one epoch ---
--- 0.3289346694946289 seconds for one epoch ---
--- 2.689364433288574 seconds for one epoch ---
--- 0.333665132522583 seconds for one epoch ---
--- 2.7375681400299072 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994415]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.39043]
 [  0.     ]]
--- 0.2982292175292969 seconds for one epoch ---
Epoch 5400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4054.58447265625, (914.7544, 8.571654, 3130.7822, 0.47606045)
   validation loss 932.132080078125, (623.44946, 0.45470458, 307.7518, 0.47606045)
decoder loss ratio: 24153.514548, decoder SINDy loss  ratio: 0.664326
--- 0.28231263160705566 seconds for one epoch ---
--- 0.34047770500183105 seconds for one epoch ---
--- 2.7258434295654297 seconds for one epoch ---
--- 0.33986449241638184 seconds for one epoch ---
--- 2.6657533645629883 seconds for one epoch ---
--- 0.3287966251373291 seconds for one epoch ---
--- 2.6979832649230957 seconds for one epoch ---
--- 0.33019208908081055 seconds for one epoch ---
--- 2.699892282485962 seconds for one epoch ---
--- 0.32309675216674805 seconds for one epoch ---
--- 2.7024152278900146 seconds for one epoch ---
--- 0.31044816970825195 seconds for one epoch ---
--- 2.693291187286377 seconds for one epoch ---
--- 0.31651926040649414 seconds for one epoch ---
--- 2.692373037338257 seconds for one epoch ---
--- 0.32460999488830566 seconds for one epoch ---
--- 2.7514281272888184 seconds for one epoch ---
--- 0.3312230110168457 seconds for one epoch ---
--- 2.7058911323547363 seconds for one epoch ---
--- 0.31234192848205566 seconds for one epoch ---
--- 2.718778371810913 seconds for one epoch ---
--- 0.3316013813018799 seconds for one epoch ---
--- 2.743594169616699 seconds for one epoch ---
--- 0.3213825225830078 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994428]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.404041]
 [ -0.      ]]
--- 0.27443909645080566 seconds for one epoch ---
Epoch 5425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2829.675537109375, (1261.353, 1.1572473, 1566.6888, 0.47639105)
   validation loss 717.0614624023438, (450.416, 0.46949345, 265.69962, 0.47639105)
decoder loss ratio: 17449.897220, decoder SINDy loss  ratio: 0.573550
--- 0.298231840133667 seconds for one epoch ---
--- 2.72355055809021 seconds for one epoch ---
--- 0.3209211826324463 seconds for one epoch ---
--- 2.696401357650757 seconds for one epoch ---
--- 0.33199214935302734 seconds for one epoch ---
--- 2.702489137649536 seconds for one epoch ---
--- 0.3303694725036621 seconds for one epoch ---
--- 2.738417625427246 seconds for one epoch ---
--- 0.3233675956726074 seconds for one epoch ---
--- 2.7057082653045654 seconds for one epoch ---
--- 0.3400559425354004 seconds for one epoch ---
--- 2.7484467029571533 seconds for one epoch ---
--- 0.3289647102355957 seconds for one epoch ---
--- 2.724379062652588 seconds for one epoch ---
--- 0.34322690963745117 seconds for one epoch ---
--- 2.7510199546813965 seconds for one epoch ---
--- 0.32958078384399414 seconds for one epoch ---
--- 2.7589974403381348 seconds for one epoch ---
--- 0.32807087898254395 seconds for one epoch ---
--- 2.707038402557373 seconds for one epoch ---
--- 0.3144850730895996 seconds for one epoch ---
--- 2.7214584350585938 seconds for one epoch ---
--- 0.3160829544067383 seconds for one epoch ---
--- 2.7520110607147217 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99944395]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.412878]
 [  0.      ]]
--- 0.30779385566711426 seconds for one epoch ---
Epoch 5450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2804.58056640625, (1304.8412, 1.007046, 1498.2557, 0.4766674)
   validation loss 888.5970458984375, (594.0864, 0.4641264, 293.5698, 0.4766674)
decoder loss ratio: 23015.939514, decoder SINDy loss  ratio: 0.633712
--- 0.28311753273010254 seconds for one epoch ---
--- 0.3214879035949707 seconds for one epoch ---
--- 2.687783718109131 seconds for one epoch ---
--- 0.3319084644317627 seconds for one epoch ---
--- 2.7493677139282227 seconds for one epoch ---
--- 0.3203709125518799 seconds for one epoch ---
--- 2.7062623500823975 seconds for one epoch ---
--- 0.3276689052581787 seconds for one epoch ---
--- 2.7629637718200684 seconds for one epoch ---
--- 0.32755422592163086 seconds for one epoch ---
--- 2.728287696838379 seconds for one epoch ---
--- 0.32920098304748535 seconds for one epoch ---
--- 2.690749406814575 seconds for one epoch ---
--- 0.3262453079223633 seconds for one epoch ---
--- 2.766955852508545 seconds for one epoch ---
--- 0.32755184173583984 seconds for one epoch ---
--- 2.7633614540100098 seconds for one epoch ---
--- 0.3303828239440918 seconds for one epoch ---
--- 2.7296478748321533 seconds for one epoch ---
--- 0.32877087593078613 seconds for one epoch ---
--- 2.735384225845337 seconds for one epoch ---
--- 0.32058024406433105 seconds for one epoch ---
--- 2.7734718322753906 seconds for one epoch ---
--- 0.3245429992675781 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994459]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.426367]
 [  0.      ]]
--- 0.26931262016296387 seconds for one epoch ---
Epoch 5475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2790.29443359375, (1357.3956, 1.1969056, 1431.2249, 0.47696716)
   validation loss 784.5079956054688, (513.9269, 0.5073668, 269.5967, 0.47696716)
decoder loss ratio: 19910.419543, decoder SINDy loss  ratio: 0.581962
--- 0.31639933586120605 seconds for one epoch ---
--- 2.7750871181488037 seconds for one epoch ---
--- 0.32689905166625977 seconds for one epoch ---
--- 2.758143186569214 seconds for one epoch ---
--- 0.3336203098297119 seconds for one epoch ---
--- 2.724093437194824 seconds for one epoch ---
--- 0.33001208305358887 seconds for one epoch ---
--- 2.762552261352539 seconds for one epoch ---
--- 0.3365495204925537 seconds for one epoch ---
--- 2.7704265117645264 seconds for one epoch ---
--- 0.3295464515686035 seconds for one epoch ---
--- 2.726494312286377 seconds for one epoch ---
--- 0.33774304389953613 seconds for one epoch ---
--- 2.7154018878936768 seconds for one epoch ---
--- 0.33565711975097656 seconds for one epoch ---
--- 2.770824670791626 seconds for one epoch ---
--- 0.3239881992340088 seconds for one epoch ---
--- 2.747285842895508 seconds for one epoch ---
--- 0.32639646530151367 seconds for one epoch ---
--- 2.785130500793457 seconds for one epoch ---
--- 0.3252284526824951 seconds for one epoch ---
--- 2.79162335395813 seconds for one epoch ---
--- 0.3355977535247803 seconds for one epoch ---
--- 2.7450129985809326 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99944717]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.437128]
 [ -0.      ]]
--- 0.3164496421813965 seconds for one epoch ---
Epoch 5500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3435.246826171875, (1672.5306, 0.6205846, 1761.6182, 0.47728273)
   validation loss 734.478759765625, (471.46786, 0.50370055, 262.02988, 0.47728273)
decoder loss ratio: 18265.483594, decoder SINDy loss  ratio: 0.565628
THRESHOLDING: 1 active coefficients
--- 2.7474539279937744 seconds for one epoch ---
--- 0.33705902099609375 seconds for one epoch ---
--- 2.7280569076538086 seconds for one epoch ---
--- 0.31135058403015137 seconds for one epoch ---
--- 2.7739267349243164 seconds for one epoch ---
--- 0.33055996894836426 seconds for one epoch ---
--- 2.7914185523986816 seconds for one epoch ---
--- 0.3303349018096924 seconds for one epoch ---
--- 2.7229321002960205 seconds for one epoch ---
--- 0.32881617546081543 seconds for one epoch ---
--- 2.736409902572632 seconds for one epoch ---
--- 0.3321654796600342 seconds for one epoch ---
--- 2.7352218627929688 seconds for one epoch ---
--- 0.3166022300720215 seconds for one epoch ---
--- 2.790091037750244 seconds for one epoch ---
--- 0.3265504837036133 seconds for one epoch ---
--- 2.727342128753662 seconds for one epoch ---
--- 0.3333573341369629 seconds for one epoch ---
--- 2.743333101272583 seconds for one epoch ---
--- 0.32685399055480957 seconds for one epoch ---
--- 2.8015379905700684 seconds for one epoch ---
--- 0.32834482192993164 seconds for one epoch ---
--- 2.7477684020996094 seconds for one epoch ---
--- 0.3172626495361328 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99944854]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.445787]
 [ -0.      ]]
--- 0.27318453788757324 seconds for one epoch ---
Epoch 5525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2774.95068359375, (990.0684, 2.1843429, 1782.2203, 0.4775364)
   validation loss 836.3631591796875, (537.2349, 0.455038, 298.1957, 0.4775364)
decoder loss ratio: 20813.413649, decoder SINDy loss  ratio: 0.643697
--- 0.31600093841552734 seconds for one epoch ---
--- 2.7020657062530518 seconds for one epoch ---
--- 0.33332228660583496 seconds for one epoch ---
--- 2.7962698936462402 seconds for one epoch ---
--- 0.34079980850219727 seconds for one epoch ---
--- 2.779132604598999 seconds for one epoch ---
--- 0.32559919357299805 seconds for one epoch ---
--- 2.7354021072387695 seconds for one epoch ---
--- 0.33078908920288086 seconds for one epoch ---
--- 2.807687520980835 seconds for one epoch ---
--- 0.34804582595825195 seconds for one epoch ---
--- 2.7532098293304443 seconds for one epoch ---
--- 0.3339242935180664 seconds for one epoch ---
--- 2.8107519149780273 seconds for one epoch ---
--- 0.33365893363952637 seconds for one epoch ---
--- 2.754650354385376 seconds for one epoch ---
--- 0.3258843421936035 seconds for one epoch ---
--- 2.815859794616699 seconds for one epoch ---
--- 0.3263564109802246 seconds for one epoch ---
--- 2.7581582069396973 seconds for one epoch ---
--- 0.33614444732666016 seconds for one epoch ---
--- 2.7651619911193848 seconds for one epoch ---
--- 0.3319535255432129 seconds for one epoch ---
--- 2.7573771476745605 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99945045]
 [0.        ]]
[[  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-18.4581]
 [  0.    ]]
--- 0.30640220642089844 seconds for one epoch ---
Epoch 5550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3437.210693359375, (1607.2479, 2.8594666, 1826.6254, 0.47785863)
   validation loss 861.3941040039062, (572.8747, 0.4590804, 287.58246, 0.47785863)
decoder loss ratio: 22194.160232, decoder SINDy loss  ratio: 0.620787
--- 0.2606496810913086 seconds for one epoch ---
--- 0.32963109016418457 seconds for one epoch ---
--- 2.7515485286712646 seconds for one epoch ---
--- 0.3357663154602051 seconds for one epoch ---
--- 2.8194942474365234 seconds for one epoch ---
--- 0.3340744972229004 seconds for one epoch ---
--- 2.820916175842285 seconds for one epoch ---
--- 0.3196265697479248 seconds for one epoch ---
--- 2.7806856632232666 seconds for one epoch ---
--- 0.35779666900634766 seconds for one epoch ---
--- 2.8186259269714355 seconds for one epoch ---
--- 0.328472375869751 seconds for one epoch ---
--- 2.8175926208496094 seconds for one epoch ---
--- 0.3308100700378418 seconds for one epoch ---
--- 2.841970682144165 seconds for one epoch ---
--- 0.3294837474822998 seconds for one epoch ---
--- 2.793262243270874 seconds for one epoch ---
--- 0.340132474899292 seconds for one epoch ---
--- 2.78224515914917 seconds for one epoch ---
--- 0.33040666580200195 seconds for one epoch ---
--- 2.838399887084961 seconds for one epoch ---
--- 0.3219151496887207 seconds for one epoch ---
--- 2.756805658340454 seconds for one epoch ---
--- 0.3346364498138428 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994527]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.470934]
 [ -0.      ]]
--- 0.2768585681915283 seconds for one epoch ---
Epoch 5575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4484.13720703125, (1407.4211, 6.4764967, 3069.7617, 0.47823)
   validation loss 838.6755981445312, (542.77, 0.47703427, 294.95032, 0.47823)
decoder loss ratio: 21027.852847, decoder SINDy loss  ratio: 0.636692
--- 0.31328582763671875 seconds for one epoch ---
--- 2.806222915649414 seconds for one epoch ---
--- 0.3269996643066406 seconds for one epoch ---
--- 2.7594525814056396 seconds for one epoch ---
--- 0.3365175724029541 seconds for one epoch ---
--- 2.832852363586426 seconds for one epoch ---
--- 0.3258326053619385 seconds for one epoch ---
--- 2.830275297164917 seconds for one epoch ---
--- 0.32487058639526367 seconds for one epoch ---
--- 2.8268632888793945 seconds for one epoch ---
--- 0.32251596450805664 seconds for one epoch ---
--- 2.774810552597046 seconds for one epoch ---
--- 0.33434009552001953 seconds for one epoch ---
--- 2.7839181423187256 seconds for one epoch ---
--- 0.3255908489227295 seconds for one epoch ---
--- 2.8254430294036865 seconds for one epoch ---
--- 0.3329904079437256 seconds for one epoch ---
--- 2.7951111793518066 seconds for one epoch ---
--- 0.34023451805114746 seconds for one epoch ---
--- 2.783201217651367 seconds for one epoch ---
--- 0.3197643756866455 seconds for one epoch ---
--- 2.7965126037597656 seconds for one epoch ---
--- 0.32042455673217773 seconds for one epoch ---
--- 2.843205690383911 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999455]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.480135]
 [  0.      ]]
--- 0.3170769214630127 seconds for one epoch ---
Epoch 5600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2040.54150390625, (1206.4011, 1.6568148, 832.0051, 0.47844848)
   validation loss 751.5562133789062, (471.88074, 0.497564, 278.69946, 0.47844848)
decoder loss ratio: 18281.478984, decoder SINDy loss  ratio: 0.601612
--- 0.27191734313964844 seconds for one epoch ---
--- 0.33832645416259766 seconds for one epoch ---
--- 2.7874600887298584 seconds for one epoch ---
--- 0.3328266143798828 seconds for one epoch ---
--- 2.825993061065674 seconds for one epoch ---
--- 0.3355104923248291 seconds for one epoch ---
--- 2.7927238941192627 seconds for one epoch ---
--- 0.31309056282043457 seconds for one epoch ---
--- 2.7867352962493896 seconds for one epoch ---
--- 0.3404572010040283 seconds for one epoch ---
--- 2.826329231262207 seconds for one epoch ---
--- 0.33162546157836914 seconds for one epoch ---
--- 2.8378677368164062 seconds for one epoch ---
--- 0.3426523208618164 seconds for one epoch ---
--- 2.784942150115967 seconds for one epoch ---
--- 0.3368968963623047 seconds for one epoch ---
--- 2.8525335788726807 seconds for one epoch ---
--- 0.33457517623901367 seconds for one epoch ---
--- 2.853732109069824 seconds for one epoch ---
--- 0.32161951065063477 seconds for one epoch ---
--- 2.7850892543792725 seconds for one epoch ---
--- 0.3183279037475586 seconds for one epoch ---
--- 2.8129985332489014 seconds for one epoch ---
--- 0.3300333023071289 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994575]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.491661]
 [  0.      ]]
--- 0.2518181800842285 seconds for one epoch ---
Epoch 5625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6115.53173828125, (1474.8585, 4.33275, 4635.8613, 0.4787732)
   validation loss 884.2186279296875, (587.571, 0.50375986, 295.66507, 0.4787732)
decoder loss ratio: 22763.519984, decoder SINDy loss  ratio: 0.638235
--- 0.326371431350708 seconds for one epoch ---
--- 2.779423713684082 seconds for one epoch ---
--- 0.3302309513092041 seconds for one epoch ---
--- 2.854541778564453 seconds for one epoch ---
--- 0.3325235843658447 seconds for one epoch ---
--- 2.810796022415161 seconds for one epoch ---
--- 0.3347916603088379 seconds for one epoch ---
--- 2.792623281478882 seconds for one epoch ---
--- 0.31755781173706055 seconds for one epoch ---
--- 2.783055067062378 seconds for one epoch ---
--- 0.32538723945617676 seconds for one epoch ---
--- 2.8044867515563965 seconds for one epoch ---
--- 0.3308091163635254 seconds for one epoch ---
--- 2.8615384101867676 seconds for one epoch ---
--- 0.3320281505584717 seconds for one epoch ---
--- 2.787656784057617 seconds for one epoch ---
--- 0.3247106075286865 seconds for one epoch ---
--- 2.800524950027466 seconds for one epoch ---
--- 0.3263077735900879 seconds for one epoch ---
--- 2.8477890491485596 seconds for one epoch ---
--- 0.3144257068634033 seconds for one epoch ---
--- 2.8009543418884277 seconds for one epoch ---
--- 0.3296048641204834 seconds for one epoch ---
--- 2.8460512161254883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99945843]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.500322]
 [ -0.      ]]
--- 0.31333136558532715 seconds for one epoch ---
Epoch 5650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2073.73095703125, (1146.1415, 1.0677997, 926.0427, 0.47900128)
   validation loss 828.5474853515625, (539.61426, 0.4968291, 287.95737, 0.47900128)
decoder loss ratio: 20905.593159, decoder SINDy loss  ratio: 0.621596
--- 0.2788233757019043 seconds for one epoch ---
--- 0.3444478511810303 seconds for one epoch ---
--- 2.840620994567871 seconds for one epoch ---
--- 0.33293724060058594 seconds for one epoch ---
--- 2.810089588165283 seconds for one epoch ---
--- 0.32398509979248047 seconds for one epoch ---
--- 2.8107638359069824 seconds for one epoch ---
--- 0.3345930576324463 seconds for one epoch ---
--- 2.8696775436401367 seconds for one epoch ---
--- 0.3316004276275635 seconds for one epoch ---
--- 2.860046625137329 seconds for one epoch ---
--- 0.3109595775604248 seconds for one epoch ---
--- 2.870131015777588 seconds for one epoch ---
--- 0.3253798484802246 seconds for one epoch ---
--- 2.8544375896453857 seconds for one epoch ---
--- 0.317211389541626 seconds for one epoch ---
--- 2.8873744010925293 seconds for one epoch ---
--- 0.3369896411895752 seconds for one epoch ---
--- 2.8033902645111084 seconds for one epoch ---
--- 0.32263708114624023 seconds for one epoch ---
--- 2.861987590789795 seconds for one epoch ---
--- 0.3278377056121826 seconds for one epoch ---
--- 2.81288480758667 seconds for one epoch ---
--- 0.3219170570373535 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994589]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.511564]
 [ -0.      ]]
--- 0.27277565002441406 seconds for one epoch ---
Epoch 5675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2219.822998046875, (999.2637, 0.9658294, 1219.1141, 0.47927675)
   validation loss 826.96630859375, (551.42004, 0.49432683, 274.5727, 0.47927675)
decoder loss ratio: 21362.969810, decoder SINDy loss  ratio: 0.592704
--- 0.3148643970489502 seconds for one epoch ---
--- 2.8232014179229736 seconds for one epoch ---
--- 0.3293943405151367 seconds for one epoch ---
--- 2.8725624084472656 seconds for one epoch ---
--- 0.325453519821167 seconds for one epoch ---
--- 2.8125267028808594 seconds for one epoch ---
--- 0.3307826519012451 seconds for one epoch ---
--- 2.8076066970825195 seconds for one epoch ---
--- 0.32132816314697266 seconds for one epoch ---
--- 2.8746111392974854 seconds for one epoch ---
--- 0.3311948776245117 seconds for one epoch ---
--- 2.8679919242858887 seconds for one epoch ---
--- 0.3318161964416504 seconds for one epoch ---
--- 2.87556791305542 seconds for one epoch ---
--- 0.3296210765838623 seconds for one epoch ---
--- 2.851072072982788 seconds for one epoch ---
--- 0.32314133644104004 seconds for one epoch ---
--- 2.8678388595581055 seconds for one epoch ---
--- 0.3286013603210449 seconds for one epoch ---
--- 2.8225879669189453 seconds for one epoch ---
--- 0.32917094230651855 seconds for one epoch ---
--- 2.8101422786712646 seconds for one epoch ---
--- 0.34052014350891113 seconds for one epoch ---
--- 2.867034673690796 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994602]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.521986]
 [  0.      ]]
--- 0.31815552711486816 seconds for one epoch ---
Epoch 5700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2486.395263671875, (1126.5848, 1.8730607, 1357.4579, 0.47957155)
   validation loss 861.5711059570312, (562.83215, 0.47350106, 297.7859, 0.47957155)
decoder loss ratio: 21805.094739, decoder SINDy loss  ratio: 0.642813
--- 0.28104209899902344 seconds for one epoch ---
--- 0.3275935649871826 seconds for one epoch ---
--- 2.823509454727173 seconds for one epoch ---
--- 0.32883620262145996 seconds for one epoch ---
--- 2.8802778720855713 seconds for one epoch ---
--- 0.3452272415161133 seconds for one epoch ---
--- 2.8781821727752686 seconds for one epoch ---
--- 0.33266186714172363 seconds for one epoch ---
--- 2.7700283527374268 seconds for one epoch ---
--- 0.33466458320617676 seconds for one epoch ---
--- 2.8727853298187256 seconds for one epoch ---
--- 0.3324568271636963 seconds for one epoch ---
--- 2.8437979221343994 seconds for one epoch ---
--- 0.3383066654205322 seconds for one epoch ---
--- 2.890404462814331 seconds for one epoch ---
--- 0.3356819152832031 seconds for one epoch ---
--- 2.9037790298461914 seconds for one epoch ---
--- 0.33278989791870117 seconds for one epoch ---
--- 2.8925976753234863 seconds for one epoch ---
--- 0.3320765495300293 seconds for one epoch ---
--- 2.9120407104492188 seconds for one epoch ---
--- 0.3399488925933838 seconds for one epoch ---
--- 2.832523822784424 seconds for one epoch ---
--- 0.339832067489624 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99946064]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.528816]
 [ -0.      ]]
--- 0.25977516174316406 seconds for one epoch ---
Epoch 5725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2902.66943359375, (1169.9335, 1.5190675, 1730.7372, 0.47975492)
   validation loss 991.592529296875, (674.7296, 0.437505, 315.9457, 0.47975492)
decoder loss ratio: 26140.196638, decoder SINDy loss  ratio: 0.682013
--- 0.30887937545776367 seconds for one epoch ---
--- 2.8994925022125244 seconds for one epoch ---
--- 0.3360328674316406 seconds for one epoch ---
--- 2.8936870098114014 seconds for one epoch ---
--- 0.32654285430908203 seconds for one epoch ---
--- 2.833864450454712 seconds for one epoch ---
--- 0.3317737579345703 seconds for one epoch ---
--- 2.8598098754882812 seconds for one epoch ---
--- 0.32659149169921875 seconds for one epoch ---
--- 2.8803067207336426 seconds for one epoch ---
--- 0.3293266296386719 seconds for one epoch ---
--- 2.889634847640991 seconds for one epoch ---
--- 0.3342752456665039 seconds for one epoch ---
--- 2.8191609382629395 seconds for one epoch ---
--- 0.3229801654815674 seconds for one epoch ---
--- 2.910856008529663 seconds for one epoch ---
--- 0.33156919479370117 seconds for one epoch ---
--- 2.8491599559783936 seconds for one epoch ---
--- 0.3287692070007324 seconds for one epoch ---
--- 2.8459320068359375 seconds for one epoch ---
--- 0.33379483222961426 seconds for one epoch ---
--- 2.8374924659729004 seconds for one epoch ---
--- 0.3248775005340576 seconds for one epoch ---
--- 2.8398985862731934 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99946153]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.536333]
 [  0.      ]]
--- 0.3091559410095215 seconds for one epoch ---
Epoch 5750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2659.25927734375, (909.2664, 0.5213581, 1748.9916, 0.4799571)
   validation loss 785.0892333984375, (498.95673, 0.45544901, 285.19708, 0.4799571)
decoder loss ratio: 19330.449795, decoder SINDy loss  ratio: 0.615638
--- 0.2761421203613281 seconds for one epoch ---
--- 0.3374452590942383 seconds for one epoch ---
--- 2.903106212615967 seconds for one epoch ---
--- 0.31975388526916504 seconds for one epoch ---
--- 2.890326499938965 seconds for one epoch ---
--- 0.33832859992980957 seconds for one epoch ---
--- 2.8736088275909424 seconds for one epoch ---
--- 0.33275651931762695 seconds for one epoch ---
--- 2.899871587753296 seconds for one epoch ---
--- 0.3347358703613281 seconds for one epoch ---
--- 2.8274824619293213 seconds for one epoch ---
--- 0.3385593891143799 seconds for one epoch ---
--- 2.891544818878174 seconds for one epoch ---
--- 0.3356153964996338 seconds for one epoch ---
--- 2.9907453060150146 seconds for one epoch ---
--- 0.32913851737976074 seconds for one epoch ---
--- 2.8544275760650635 seconds for one epoch ---
--- 0.328383207321167 seconds for one epoch ---
--- 2.911822557449341 seconds for one epoch ---
--- 0.3275737762451172 seconds for one epoch ---
--- 2.8506879806518555 seconds for one epoch ---
--- 0.3224613666534424 seconds for one epoch ---
--- 2.848862648010254 seconds for one epoch ---
--- 0.3258392810821533 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994627]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.544096]
 [  0.      ]]
--- 0.26720094680786133 seconds for one epoch ---
Epoch 5775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1567.373779296875, (893.98096, 1.3426317, 671.5699, 0.48021808)
   validation loss 1139.5458984375, (801.73553, 0.45542884, 336.87476, 0.48021808)
decoder loss ratio: 31060.626487, decoder SINDy loss  ratio: 0.727192
--- 0.3151111602783203 seconds for one epoch ---
--- 2.8857979774475098 seconds for one epoch ---
--- 0.32685208320617676 seconds for one epoch ---
--- 2.8771591186523438 seconds for one epoch ---
--- 0.32721662521362305 seconds for one epoch ---
--- 2.8873226642608643 seconds for one epoch ---
--- 0.33183884620666504 seconds for one epoch ---
--- 2.924109697341919 seconds for one epoch ---
--- 0.30974626541137695 seconds for one epoch ---
--- 2.8745765686035156 seconds for one epoch ---
--- 0.32663869857788086 seconds for one epoch ---
--- 2.865281105041504 seconds for one epoch ---
--- 0.33118224143981934 seconds for one epoch ---
--- 2.937140941619873 seconds for one epoch ---
--- 0.33606743812561035 seconds for one epoch ---
--- 2.9365663528442383 seconds for one epoch ---
--- 0.334989070892334 seconds for one epoch ---
--- 2.9270529747009277 seconds for one epoch ---
--- 0.31008100509643555 seconds for one epoch ---
--- 2.9052581787109375 seconds for one epoch ---
--- 0.3332514762878418 seconds for one epoch ---
--- 2.927799701690674 seconds for one epoch ---
--- 0.3444232940673828 seconds for one epoch ---
--- 2.8895835876464844 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994639]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.55251]
 [ -0.     ]]
--- 0.3097808361053467 seconds for one epoch ---
Epoch 5800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2480.36328125, (947.2075, 0.59001285, 1532.0852, 0.480437)
   validation loss 1062.638427734375, (741.18866, 0.44769803, 320.52158, 0.480437)
decoder loss ratio: 28714.935436, decoder SINDy loss  ratio: 0.691891
--- 0.27395200729370117 seconds for one epoch ---
--- 0.3304893970489502 seconds for one epoch ---
--- 2.9118380546569824 seconds for one epoch ---
--- 0.32358312606811523 seconds for one epoch ---
--- 2.9315860271453857 seconds for one epoch ---
--- 0.3291819095611572 seconds for one epoch ---
--- 2.863875150680542 seconds for one epoch ---
--- 0.3292574882507324 seconds for one epoch ---
--- 2.92149019241333 seconds for one epoch ---
--- 0.3317146301269531 seconds for one epoch ---
--- 2.9282031059265137 seconds for one epoch ---
--- 0.32459521293640137 seconds for one epoch ---
--- 2.882885456085205 seconds for one epoch ---
--- 0.3316824436187744 seconds for one epoch ---
--- 2.915992021560669 seconds for one epoch ---
--- 0.3277311325073242 seconds for one epoch ---
--- 2.921067714691162 seconds for one epoch ---
--- 0.32430076599121094 seconds for one epoch ---
--- 2.8781211376190186 seconds for one epoch ---
--- 0.3204960823059082 seconds for one epoch ---
--- 2.883546829223633 seconds for one epoch ---
--- 0.3319544792175293 seconds for one epoch ---
--- 2.9448721408843994 seconds for one epoch ---
--- 0.3182070255279541 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999465]
 [0.      ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-18.55926]
 [ -0.     ]]
--- 0.277202844619751 seconds for one epoch ---
Epoch 5825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2589.7685546875, (966.15686, 1.2855815, 1621.8456, 0.48056665)
   validation loss 902.2685546875, (591.96027, 0.44014472, 309.3876, 0.48056665)
decoder loss ratio: 22933.568397, decoder SINDy loss  ratio: 0.667857
--- 0.3141164779663086 seconds for one epoch ---
--- 2.940260648727417 seconds for one epoch ---
--- 0.3291053771972656 seconds for one epoch ---
--- 2.8644022941589355 seconds for one epoch ---
--- 0.32375311851501465 seconds for one epoch ---
--- 2.941420793533325 seconds for one epoch ---
--- 0.3314962387084961 seconds for one epoch ---
--- 2.9210472106933594 seconds for one epoch ---
--- 0.3315742015838623 seconds for one epoch ---
--- 2.8816535472869873 seconds for one epoch ---
--- 0.32868289947509766 seconds for one epoch ---
--- 2.93979549407959 seconds for one epoch ---
--- 0.33111023902893066 seconds for one epoch ---
--- 2.908113718032837 seconds for one epoch ---
--- 0.33489060401916504 seconds for one epoch ---
--- 2.967092990875244 seconds for one epoch ---
--- 0.3443608283996582 seconds for one epoch ---
--- 2.942472457885742 seconds for one epoch ---
--- 0.32563233375549316 seconds for one epoch ---
--- 2.903719186782837 seconds for one epoch ---
--- 0.33388566970825195 seconds for one epoch ---
--- 2.928915500640869 seconds for one epoch ---
--- 0.33366870880126953 seconds for one epoch ---
--- 2.9591846466064453 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994662]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.567886]
 [  0.      ]]
--- 0.3182058334350586 seconds for one epoch ---
Epoch 5850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3250.5380859375, (1494.8857, 3.643071, 1751.5286, 0.48081723)
   validation loss 851.8314208984375, (545.7734, 0.44624853, 305.131, 0.48081723)
decoder loss ratio: 21144.208108, decoder SINDy loss  ratio: 0.658668
--- 0.2784736156463623 seconds for one epoch ---
--- 0.336212158203125 seconds for one epoch ---
--- 2.931107521057129 seconds for one epoch ---
--- 0.3231515884399414 seconds for one epoch ---
--- 2.878797769546509 seconds for one epoch ---
--- 0.3239560127258301 seconds for one epoch ---
--- 2.8895716667175293 seconds for one epoch ---
--- 0.33382463455200195 seconds for one epoch ---
--- 2.889857769012451 seconds for one epoch ---
--- 0.33933401107788086 seconds for one epoch ---
--- 2.8939950466156006 seconds for one epoch ---
--- 0.3341813087463379 seconds for one epoch ---
--- 2.9579131603240967 seconds for one epoch ---
--- 0.3296220302581787 seconds for one epoch ---
--- 2.886181354522705 seconds for one epoch ---
--- 0.33983922004699707 seconds for one epoch ---
--- 2.916358232498169 seconds for one epoch ---
--- 0.336470365524292 seconds for one epoch ---
--- 2.8780901432037354 seconds for one epoch ---
--- 0.3306701183319092 seconds for one epoch ---
--- 2.9100515842437744 seconds for one epoch ---
--- 0.3191049098968506 seconds for one epoch ---
--- 2.949519634246826 seconds for one epoch ---
--- 0.3268918991088867 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99946797]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.579155]
 [ -0.      ]]
--- 0.26186418533325195 seconds for one epoch ---
Epoch 5875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2449.847412109375, (1022.9595, 3.6949313, 1422.7119, 0.4810948)
   validation loss 933.0372314453125, (627.8743, 0.46442273, 304.21744, 0.4810948)
decoder loss ratio: 24324.941528, decoder SINDy loss  ratio: 0.656696
--- 0.30518031120300293 seconds for one epoch ---
--- 2.957831621170044 seconds for one epoch ---
--- 0.33696508407592773 seconds for one epoch ---
--- 2.9619479179382324 seconds for one epoch ---
--- 0.33350372314453125 seconds for one epoch ---
--- 2.9804210662841797 seconds for one epoch ---
--- 0.32727575302124023 seconds for one epoch ---
--- 2.9502177238464355 seconds for one epoch ---
--- 0.3296976089477539 seconds for one epoch ---
--- 2.9713082313537598 seconds for one epoch ---
--- 0.3421058654785156 seconds for one epoch ---
--- 2.884941816329956 seconds for one epoch ---
--- 0.32645249366760254 seconds for one epoch ---
--- 2.964345932006836 seconds for one epoch ---
--- 0.3233778476715088 seconds for one epoch ---
--- 2.904189109802246 seconds for one epoch ---
--- 0.3172633647918701 seconds for one epoch ---
--- 2.8961169719696045 seconds for one epoch ---
--- 0.32599401473999023 seconds for one epoch ---
--- 2.9095215797424316 seconds for one epoch ---
--- 0.3979489803314209 seconds for one epoch ---
--- 2.9141204357147217 seconds for one epoch ---
--- 0.3292121887207031 seconds for one epoch ---
--- 2.929220199584961 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994692]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.58745]
 [  0.     ]]
--- 0.29803967475891113 seconds for one epoch ---
Epoch 5900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2777.978759765625, (1187.1978, 2.8020136, 1587.4976, 0.48133498)
   validation loss 738.7496337890625, (469.04123, 0.48365, 268.74347, 0.48133498)
decoder loss ratio: 18171.471512, decoder SINDy loss  ratio: 0.580121
--- 0.2785153388977051 seconds for one epoch ---
--- 0.33055806159973145 seconds for one epoch ---
--- 2.9678547382354736 seconds for one epoch ---
--- 0.32596468925476074 seconds for one epoch ---
--- 2.9962432384490967 seconds for one epoch ---
--- 0.3380465507507324 seconds for one epoch ---
--- 2.929713010787964 seconds for one epoch ---
--- 0.33259010314941406 seconds for one epoch ---
--- 2.9227144718170166 seconds for one epoch ---
--- 0.3291447162628174 seconds for one epoch ---
--- 2.9372379779815674 seconds for one epoch ---
--- 0.32738757133483887 seconds for one epoch ---
--- 2.993480920791626 seconds for one epoch ---
--- 0.3218686580657959 seconds for one epoch ---
--- 2.9913532733917236 seconds for one epoch ---
--- 0.33521056175231934 seconds for one epoch ---
--- 2.9413669109344482 seconds for one epoch ---
--- 0.32968783378601074 seconds for one epoch ---
--- 2.9952924251556396 seconds for one epoch ---
--- 0.3400242328643799 seconds for one epoch ---
--- 2.9467759132385254 seconds for one epoch ---
--- 0.33686065673828125 seconds for one epoch ---
--- 2.991456985473633 seconds for one epoch ---
--- 0.3302028179168701 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994705]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.596256]
 [  0.      ]]
--- 0.27326107025146484 seconds for one epoch ---
Epoch 5925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2758.970458984375, (1459.7609, 1.2830125, 1297.4451, 0.48162833)
   validation loss 924.3005981445312, (619.0556, 0.45978972, 304.30356, 0.48162833)
decoder loss ratio: 23983.288789, decoder SINDy loss  ratio: 0.656882
--- 0.32467055320739746 seconds for one epoch ---
--- 2.9711575508117676 seconds for one epoch ---
--- 0.3281083106994629 seconds for one epoch ---
--- 2.9200689792633057 seconds for one epoch ---
--- 0.3271355628967285 seconds for one epoch ---
--- 3.010493040084839 seconds for one epoch ---
--- 0.3382439613342285 seconds for one epoch ---
--- 2.937100887298584 seconds for one epoch ---
--- 0.3289985656738281 seconds for one epoch ---
--- 3.0035626888275146 seconds for one epoch ---
--- 0.32883167266845703 seconds for one epoch ---
--- 2.953653335571289 seconds for one epoch ---
--- 0.32863831520080566 seconds for one epoch ---
--- 3.0299737453460693 seconds for one epoch ---
--- 0.3261284828186035 seconds for one epoch ---
--- 2.9530210494995117 seconds for one epoch ---
--- 0.32241058349609375 seconds for one epoch ---
--- 3.0240042209625244 seconds for one epoch ---
--- 0.336747407913208 seconds for one epoch ---
--- 2.9521543979644775 seconds for one epoch ---
--- 0.32774996757507324 seconds for one epoch ---
--- 2.9450995922088623 seconds for one epoch ---
--- 0.3272714614868164 seconds for one epoch ---
--- 2.9664182662963867 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994719]
 [0.       ]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-18.6023]
 [ -0.    ]]
--- 0.30709052085876465 seconds for one epoch ---
Epoch 5950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2526.1171875, (1130.1093, 1.4188912, 1394.1073, 0.48174235)
   validation loss 785.1129760742188, (504.2262, 0.46031502, 279.94473, 0.48174235)
decoder loss ratio: 19534.598219, decoder SINDy loss  ratio: 0.604300
--- 0.2838304042816162 seconds for one epoch ---
--- 0.3228907585144043 seconds for one epoch ---
--- 2.9509165287017822 seconds for one epoch ---
--- 0.3299734592437744 seconds for one epoch ---
--- 2.946341037750244 seconds for one epoch ---
--- 0.34644174575805664 seconds for one epoch ---
--- 2.9915080070495605 seconds for one epoch ---
--- 0.3296370506286621 seconds for one epoch ---
--- 2.99433970451355 seconds for one epoch ---
--- 0.33547019958496094 seconds for one epoch ---
--- 2.97392201423645 seconds for one epoch ---
--- 0.32603907585144043 seconds for one epoch ---
--- 3.010721206665039 seconds for one epoch ---
--- 0.3333256244659424 seconds for one epoch ---
--- 3.012693166732788 seconds for one epoch ---
--- 0.33263421058654785 seconds for one epoch ---
--- 3.0177040100097656 seconds for one epoch ---
--- 0.32955384254455566 seconds for one epoch ---
--- 2.957260847091675 seconds for one epoch ---
--- 0.329662561416626 seconds for one epoch ---
--- 3.027381658554077 seconds for one epoch ---
--- 0.3275594711303711 seconds for one epoch ---
--- 2.9731006622314453 seconds for one epoch ---
--- 0.33475613594055176 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994726]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.610909]
 [ -0.      ]]
--- 0.2642080783843994 seconds for one epoch ---
Epoch 5975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3052.80615234375, (1190.0864, 0.39244914, 1861.8453, 0.4819849)
   validation loss 944.4122924804688, (640.95154, 0.46710244, 302.5117, 0.4819849)
decoder loss ratio: 24831.575326, decoder SINDy loss  ratio: 0.653014
--- 0.3116621971130371 seconds for one epoch ---
--- 2.955691337585449 seconds for one epoch ---
--- 0.3387026786804199 seconds for one epoch ---
--- 2.9433062076568604 seconds for one epoch ---
--- 0.3335998058319092 seconds for one epoch ---
--- 2.9798190593719482 seconds for one epoch ---
--- 0.33315420150756836 seconds for one epoch ---
--- 2.9722743034362793 seconds for one epoch ---
--- 0.3388710021972656 seconds for one epoch ---
--- 2.968810796737671 seconds for one epoch ---
--- 0.3222084045410156 seconds for one epoch ---
--- 2.963207960128784 seconds for one epoch ---
--- 0.3313479423522949 seconds for one epoch ---
--- 2.963895320892334 seconds for one epoch ---
--- 0.3289909362792969 seconds for one epoch ---
--- 3.0512373447418213 seconds for one epoch ---
--- 0.3214840888977051 seconds for one epoch ---
--- 2.965554714202881 seconds for one epoch ---
--- 0.33037877082824707 seconds for one epoch ---
--- 3.0311248302459717 seconds for one epoch ---
--- 0.31115055084228516 seconds for one epoch ---
--- 3.0311219692230225 seconds for one epoch ---
--- 0.3295743465423584 seconds for one epoch ---
--- 2.995954751968384 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99947304]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.616886]
 [  0.      ]]
--- 0.3252756595611572 seconds for one epoch ---
Epoch 6000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4293.05810546875, (1873.9681, 2.237447, 2416.3708, 0.48215458)
   validation loss 800.0763549804688, (522.51086, 0.5227996, 276.5605, 0.48215458)
decoder loss ratio: 20242.978000, decoder SINDy loss  ratio: 0.596995
THRESHOLDING: 1 active coefficients
--- 0.286592960357666 seconds for one epoch ---
--- 0.3311619758605957 seconds for one epoch ---
--- 2.974510431289673 seconds for one epoch ---
--- 0.3275434970855713 seconds for one epoch ---
--- 2.9674179553985596 seconds for one epoch ---
--- 0.3272418975830078 seconds for one epoch ---
--- 3.0484566688537598 seconds for one epoch ---
--- 0.3263280391693115 seconds for one epoch ---
--- 3.053926706314087 seconds for one epoch ---
--- 0.33702826499938965 seconds for one epoch ---
--- 3.0349628925323486 seconds for one epoch ---
--- 0.3373701572418213 seconds for one epoch ---
--- 3.0405116081237793 seconds for one epoch ---
--- 0.3413267135620117 seconds for one epoch ---
--- 2.969226360321045 seconds for one epoch ---
--- 0.3267650604248047 seconds for one epoch ---
--- 3.041726589202881 seconds for one epoch ---
--- 0.3344385623931885 seconds for one epoch ---
--- 3.0195960998535156 seconds for one epoch ---
--- 0.31905460357666016 seconds for one epoch ---
--- 2.9606785774230957 seconds for one epoch ---
--- 0.32626962661743164 seconds for one epoch ---
--- 3.0516488552093506 seconds for one epoch ---
--- 0.31685757637023926 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999473]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.624943]
 [ -0.      ]]
--- 0.27372050285339355 seconds for one epoch ---
Epoch 6025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3192.907958984375, (1283.7059, 2.6612735, 1906.0583, 0.4823738)
   validation loss 788.2714233398438, (514.199, 0.48682752, 273.1033, 0.4823738)
decoder loss ratio: 19920.960965, decoder SINDy loss  ratio: 0.589532
--- 0.313063383102417 seconds for one epoch ---
--- 2.9508419036865234 seconds for one epoch ---
--- 0.33374547958374023 seconds for one epoch ---
--- 3.053266763687134 seconds for one epoch ---
--- 0.33197522163391113 seconds for one epoch ---
--- 3.0305588245391846 seconds for one epoch ---
--- 0.32637691497802734 seconds for one epoch ---
--- 2.975543737411499 seconds for one epoch ---
--- 0.3286268711090088 seconds for one epoch ---
--- 3.0463438034057617 seconds for one epoch ---
--- 0.33299708366394043 seconds for one epoch ---
--- 3.055121898651123 seconds for one epoch ---
--- 0.3358125686645508 seconds for one epoch ---
--- 3.050706386566162 seconds for one epoch ---
--- 0.31545519828796387 seconds for one epoch ---
--- 2.993366241455078 seconds for one epoch ---
--- 0.3289611339569092 seconds for one epoch ---
--- 3.0612032413482666 seconds for one epoch ---
--- 0.3313119411468506 seconds for one epoch ---
--- 3.0516254901885986 seconds for one epoch ---
--- 0.33028078079223633 seconds for one epoch ---
--- 3.014954090118408 seconds for one epoch ---
--- 0.31943607330322266 seconds for one epoch ---
--- 3.0502641201019287 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99947375]
 [0.        ]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-18.6346]
 [  0.    ]]
--- 0.31796813011169434 seconds for one epoch ---
Epoch 6050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2680.121826171875, (1036.0289, 1.7257023, 1641.8844, 0.48262024)
   validation loss 751.7354736328125, (480.17493, 0.4748993, 270.60303, 0.48262024)
decoder loss ratio: 18602.810283, decoder SINDy loss  ratio: 0.584135
--- 0.28289103507995605 seconds for one epoch ---
--- 0.34836673736572266 seconds for one epoch ---
--- 2.9966232776641846 seconds for one epoch ---
--- 0.31541919708251953 seconds for one epoch ---
--- 2.9949724674224854 seconds for one epoch ---
--- 0.3396594524383545 seconds for one epoch ---
--- 3.0052108764648438 seconds for one epoch ---
--- 0.337705135345459 seconds for one epoch ---
--- 3.0778324604034424 seconds for one epoch ---
--- 0.337874174118042 seconds for one epoch ---
--- 2.9998397827148438 seconds for one epoch ---
--- 0.3237459659576416 seconds for one epoch ---
--- 3.0108420848846436 seconds for one epoch ---
--- 0.3292815685272217 seconds for one epoch ---
--- 3.0249977111816406 seconds for one epoch ---
--- 0.33001160621643066 seconds for one epoch ---
--- 3.078901767730713 seconds for one epoch ---
--- 0.33715105056762695 seconds for one epoch ---
--- 3.07287335395813 seconds for one epoch ---
--- 0.3308427333831787 seconds for one epoch ---
--- 3.0782930850982666 seconds for one epoch ---
--- 0.34012365341186523 seconds for one epoch ---
--- 3.0188915729522705 seconds for one epoch ---
--- 0.3336775302886963 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99947405]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.641941]
 [  0.      ]]
--- 0.26953577995300293 seconds for one epoch ---
Epoch 6075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3676.06103515625, (725.551, 1.1494244, 2948.8777, 0.48281604)
   validation loss 775.4417724609375, (492.7856, 0.47526035, 281.69815, 0.48281604)
decoder loss ratio: 19091.370200, decoder SINDy loss  ratio: 0.608085
--- 0.29827022552490234 seconds for one epoch ---
--- 3.0117287635803223 seconds for one epoch ---
--- 0.32961535453796387 seconds for one epoch ---
--- 2.997157335281372 seconds for one epoch ---
--- 0.3191370964050293 seconds for one epoch ---
--- 3.0800061225891113 seconds for one epoch ---
--- 0.3239107131958008 seconds for one epoch ---
--- 3.0425162315368652 seconds for one epoch ---
--- 0.330949068069458 seconds for one epoch ---
--- 3.0374324321746826 seconds for one epoch ---
--- 0.33743762969970703 seconds for one epoch ---
--- 3.0695550441741943 seconds for one epoch ---
--- 0.3412482738494873 seconds for one epoch ---
--- 3.062695264816284 seconds for one epoch ---
--- 0.32616615295410156 seconds for one epoch ---
--- 3.0144882202148438 seconds for one epoch ---
--- 0.3324618339538574 seconds for one epoch ---
--- 3.0442886352539062 seconds for one epoch ---
--- 0.33821678161621094 seconds for one epoch ---
--- 3.080085277557373 seconds for one epoch ---
--- 0.32622337341308594 seconds for one epoch ---
--- 3.0151631832122803 seconds for one epoch ---
--- 0.34427523612976074 seconds for one epoch ---
--- 3.0857300758361816 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99947405]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.649345]
 [ -0.      ]]
--- 0.31313467025756836 seconds for one epoch ---
Epoch 6100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5159.85595703125, (1075.7887, 1.4169809, 4082.1672, 0.4830334)
   validation loss 868.70458984375, (578.4763, 0.49352068, 289.2517, 0.4830334)
decoder loss ratio: 22411.176852, decoder SINDy loss  ratio: 0.624390
--- 0.2772951126098633 seconds for one epoch ---
--- 0.3414602279663086 seconds for one epoch ---
--- 3.0103721618652344 seconds for one epoch ---
--- 0.33438682556152344 seconds for one epoch ---
--- 3.0617659091949463 seconds for one epoch ---
--- 0.3266611099243164 seconds for one epoch ---
--- 3.0696825981140137 seconds for one epoch ---
--- 0.3223555088043213 seconds for one epoch ---
--- 3.0989913940429688 seconds for one epoch ---
--- 0.32895469665527344 seconds for one epoch ---
--- 3.088900327682495 seconds for one epoch ---
--- 0.3340139389038086 seconds for one epoch ---
--- 3.0856826305389404 seconds for one epoch ---
--- 0.3314642906188965 seconds for one epoch ---
--- 3.044768810272217 seconds for one epoch ---
--- 0.3363919258117676 seconds for one epoch ---
--- 3.093830108642578 seconds for one epoch ---
--- 0.33462023735046387 seconds for one epoch ---
--- 3.0982272624969482 seconds for one epoch ---
--- 0.3295884132385254 seconds for one epoch ---
--- 3.09847354888916 seconds for one epoch ---
--- 0.3299429416656494 seconds for one epoch ---
--- 3.0951385498046875 seconds for one epoch ---
--- 0.33179521560668945 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999475]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.658308]
 [ -0.      ]]
--- 0.2794318199157715 seconds for one epoch ---
Epoch 6125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2810.819091796875, (1147.1249, 1.5956994, 1661.6154, 0.4832428)
   validation loss 869.9963989257812, (575.1829, 0.5125667, 293.8177, 0.4832428)
decoder loss ratio: 22283.584974, decoder SINDy loss  ratio: 0.634247
--- 0.31644439697265625 seconds for one epoch ---
--- 3.014883518218994 seconds for one epoch ---
--- 0.33670854568481445 seconds for one epoch ---
--- 3.038839817047119 seconds for one epoch ---
--- 0.32953667640686035 seconds for one epoch ---
--- 3.0235238075256348 seconds for one epoch ---
--- 0.32385683059692383 seconds for one epoch ---
--- 3.113173007965088 seconds for one epoch ---
--- 0.3255338668823242 seconds for one epoch ---
--- 3.080166816711426 seconds for one epoch ---
--- 0.3270084857940674 seconds for one epoch ---
--- 3.0978879928588867 seconds for one epoch ---
--- 0.3303961753845215 seconds for one epoch ---
--- 3.123523473739624 seconds for one epoch ---
--- 0.3246133327484131 seconds for one epoch ---
--- 3.096101999282837 seconds for one epoch ---
--- 0.31745290756225586 seconds for one epoch ---
--- 3.1190695762634277 seconds for one epoch ---
--- 0.32288265228271484 seconds for one epoch ---
--- 3.1246063709259033 seconds for one epoch ---
--- 0.32480788230895996 seconds for one epoch ---
--- 3.1136314868927 seconds for one epoch ---
--- 0.3163635730743408 seconds for one epoch ---
--- 3.0457708835601807 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994757]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.662909]
 [  0.      ]]
--- 0.2982141971588135 seconds for one epoch ---
Epoch 6150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2922.41455078125, (1154.3624, 4.573489, 1762.9952, 0.4833873)
   validation loss 795.328125, (515.9521, 0.51690465, 278.37576, 0.4833873)
decoder loss ratio: 19988.879598, decoder SINDy loss  ratio: 0.600913
--- 0.2778620719909668 seconds for one epoch ---
--- 0.3310084342956543 seconds for one epoch ---
--- 3.0917680263519287 seconds for one epoch ---
--- 0.3354606628417969 seconds for one epoch ---
--- 3.1222312450408936 seconds for one epoch ---
--- 0.32663822174072266 seconds for one epoch ---
--- 3.074631929397583 seconds for one epoch ---
--- 0.31531691551208496 seconds for one epoch ---
--- 3.041163206100464 seconds for one epoch ---
--- 0.3297410011291504 seconds for one epoch ---
--- 3.1154706478118896 seconds for one epoch ---
--- 0.33199357986450195 seconds for one epoch ---
--- 3.134531259536743 seconds for one epoch ---
--- 0.34015774726867676 seconds for one epoch ---
--- 3.121715784072876 seconds for one epoch ---
--- 0.3159797191619873 seconds for one epoch ---
--- 3.1411263942718506 seconds for one epoch ---
--- 0.34607601165771484 seconds for one epoch ---
--- 3.102336883544922 seconds for one epoch ---
--- 0.3294217586517334 seconds for one epoch ---
--- 3.151358127593994 seconds for one epoch ---
--- 0.33672332763671875 seconds for one epoch ---
--- 3.0637879371643066 seconds for one epoch ---
--- 0.3288857936859131 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99947643]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.669163]
 [ -0.      ]]
--- 0.27262020111083984 seconds for one epoch ---
Epoch 6175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2317.69287109375, (697.84546, 1.2209203, 1618.1428, 0.48356077)
   validation loss 1143.2225341796875, (854.44, 0.4979451, 287.80106, 0.48356077)
decoder loss ratio: 33102.489068, decoder SINDy loss  ratio: 0.621259
--- 0.30845093727111816 seconds for one epoch ---
--- 3.1262948513031006 seconds for one epoch ---
--- 0.3309495449066162 seconds for one epoch ---
--- 3.124969244003296 seconds for one epoch ---
--- 0.31227540969848633 seconds for one epoch ---
--- 3.085374116897583 seconds for one epoch ---
--- 0.3296365737915039 seconds for one epoch ---
--- 3.076293468475342 seconds for one epoch ---
--- 0.3344848155975342 seconds for one epoch ---
--- 3.142519950866699 seconds for one epoch ---
--- 0.3328688144683838 seconds for one epoch ---
--- 3.121593475341797 seconds for one epoch ---
--- 0.33292675018310547 seconds for one epoch ---
--- 3.1027204990386963 seconds for one epoch ---
--- 0.31139516830444336 seconds for one epoch ---
--- 3.078610420227051 seconds for one epoch ---
--- 0.33091187477111816 seconds for one epoch ---
--- 3.072462558746338 seconds for one epoch ---
--- 0.3255136013031006 seconds for one epoch ---
--- 3.0624501705169678 seconds for one epoch ---
--- 0.32530832290649414 seconds for one epoch ---
--- 3.134864330291748 seconds for one epoch ---
--- 0.3275949954986572 seconds for one epoch ---
--- 3.1411123275756836 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999477]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.676466]
 [  0.      ]]
--- 0.31683969497680664 seconds for one epoch ---
Epoch 6200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3325.862548828125, (1332.5103, 2.2831326, 1990.5857, 0.48374996)
   validation loss 758.1517944335938, (484.96796, 0.50217116, 272.1979, 0.48374996)
decoder loss ratio: 18788.500578, decoder SINDy loss  ratio: 0.587577
--- 0.28105950355529785 seconds for one epoch ---
--- 0.33429527282714844 seconds for one epoch ---
--- 3.083200693130493 seconds for one epoch ---
--- 0.3336923122406006 seconds for one epoch ---
--- 3.139564275741577 seconds for one epoch ---
--- 0.3314673900604248 seconds for one epoch ---
--- 3.063913583755493 seconds for one epoch ---
--- 0.33226680755615234 seconds for one epoch ---
--- 3.079286575317383 seconds for one epoch ---
--- 0.3216891288757324 seconds for one epoch ---
--- 3.0815579891204834 seconds for one epoch ---
--- 0.3327341079711914 seconds for one epoch ---
--- 3.1366868019104004 seconds for one epoch ---
--- 0.33228063583374023 seconds for one epoch ---
--- 3.071815013885498 seconds for one epoch ---
--- 0.3346679210662842 seconds for one epoch ---
--- 3.0882568359375 seconds for one epoch ---
--- 0.33246684074401855 seconds for one epoch ---
--- 3.1472556591033936 seconds for one epoch ---
--- 0.3272089958190918 seconds for one epoch ---
--- 3.1330606937408447 seconds for one epoch ---
--- 0.3292546272277832 seconds for one epoch ---
--- 3.096501588821411 seconds for one epoch ---
--- 0.3252427577972412 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994787]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-18.68393]
 [  0.     ]]
--- 0.2699909210205078 seconds for one epoch ---
Epoch 6225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1938.686767578125, (793.0262, 12.009235, 1133.1674, 0.48396483)
   validation loss 745.3141479492188, (477.74918, 0.5168154, 266.56424, 0.48396483)
decoder loss ratio: 18508.832488, decoder SINDy loss  ratio: 0.575416
--- 0.3061530590057373 seconds for one epoch ---
--- 3.144712448120117 seconds for one epoch ---
--- 0.3214864730834961 seconds for one epoch ---
--- 3.061793088912964 seconds for one epoch ---
--- 0.3288125991821289 seconds for one epoch ---
--- 3.1402530670166016 seconds for one epoch ---
--- 0.3329911231994629 seconds for one epoch ---
--- 3.1381218433380127 seconds for one epoch ---
--- 0.3090946674346924 seconds for one epoch ---
--- 3.095454454421997 seconds for one epoch ---
--- 0.3313920497894287 seconds for one epoch ---
--- 3.0797252655029297 seconds for one epoch ---
--- 0.3289339542388916 seconds for one epoch ---
--- 3.1304097175598145 seconds for one epoch ---
--- 0.33401918411254883 seconds for one epoch ---
--- 3.0697364807128906 seconds for one epoch ---
--- 0.3250389099121094 seconds for one epoch ---
--- 3.0801079273223877 seconds for one epoch ---
--- 0.327131986618042 seconds for one epoch ---
--- 3.080829381942749 seconds for one epoch ---
--- 0.33477210998535156 seconds for one epoch ---
--- 3.1349496841430664 seconds for one epoch ---
--- 0.32976484298706055 seconds for one epoch ---
--- 3.0787508487701416 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99948025]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.692064]
 [ -0.      ]]
--- 0.30779337882995605 seconds for one epoch ---
Epoch 6250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2882.5205078125, (1494.1287, 4.338064, 1383.5697, 0.4841989)
   validation loss 995.6228637695312, (691.87115, 0.5089497, 302.75854, 0.4841989)
decoder loss ratio: 26804.289678, decoder SINDy loss  ratio: 0.653547
--- 0.27786850929260254 seconds for one epoch ---
--- 0.32089972496032715 seconds for one epoch ---
--- 3.054800033569336 seconds for one epoch ---
--- 0.327434778213501 seconds for one epoch ---
--- 3.157177448272705 seconds for one epoch ---
--- 0.3430194854736328 seconds for one epoch ---
--- 3.0977725982666016 seconds for one epoch ---
--- 0.33553242683410645 seconds for one epoch ---
--- 3.1557669639587402 seconds for one epoch ---
--- 0.3394324779510498 seconds for one epoch ---
--- 3.1047232151031494 seconds for one epoch ---
--- 0.32951951026916504 seconds for one epoch ---
--- 3.104154586791992 seconds for one epoch ---
--- 0.33053016662597656 seconds for one epoch ---
--- 3.1471478939056396 seconds for one epoch ---
--- 0.3365349769592285 seconds for one epoch ---
--- 3.0843610763549805 seconds for one epoch ---
--- 0.318683385848999 seconds for one epoch ---
--- 3.09366774559021 seconds for one epoch ---
--- 0.3214685916900635 seconds for one epoch ---
--- 3.1517653465270996 seconds for one epoch ---
--- 0.3255124092102051 seconds for one epoch ---
--- 3.1565754413604736 seconds for one epoch ---
--- 0.324115514755249 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99948144]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.699974]
 [ -0.      ]]
--- 0.2758293151855469 seconds for one epoch ---
Epoch 6275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3234.508544921875, (1373.7816, 2.1107497, 1858.1318, 0.4844125)
   validation loss 905.7053833007812, (605.65247, 0.4985497, 299.06998, 0.4844125)
decoder loss ratio: 23464.027985, decoder SINDy loss  ratio: 0.645585
--- 0.3159339427947998 seconds for one epoch ---
--- 3.1330039501190186 seconds for one epoch ---
--- 0.3321342468261719 seconds for one epoch ---
--- 3.090456485748291 seconds for one epoch ---
--- 0.3235793113708496 seconds for one epoch ---
--- 3.0977916717529297 seconds for one epoch ---
--- 0.3302443027496338 seconds for one epoch ---
--- 3.166179656982422 seconds for one epoch ---
--- 0.3371708393096924 seconds for one epoch ---
--- 3.110940933227539 seconds for one epoch ---
--- 0.33456921577453613 seconds for one epoch ---
--- 3.1136538982391357 seconds for one epoch ---
--- 0.32076573371887207 seconds for one epoch ---
--- 3.184025287628174 seconds for one epoch ---
--- 0.32898449897766113 seconds for one epoch ---
--- 3.1221516132354736 seconds for one epoch ---
--- 0.33152222633361816 seconds for one epoch ---
--- 3.167289972305298 seconds for one epoch ---
--- 0.34133148193359375 seconds for one epoch ---
--- 3.1116459369659424 seconds for one epoch ---
--- 0.32763195037841797 seconds for one epoch ---
--- 3.1806445121765137 seconds for one epoch ---
--- 0.3291482925415039 seconds for one epoch ---
--- 3.1185433864593506 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994825]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.706537]
 [  0.      ]]
--- 0.31888675689697266 seconds for one epoch ---
Epoch 6300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3444.342041015625, (1179.7299, 1.8821234, 2262.2456, 0.48458415)
   validation loss 948.5230102539062, (663.74335, 0.52761513, 283.76752, 0.48458415)
decoder loss ratio: 25714.569578, decoder SINDy loss  ratio: 0.612552
--- 0.26317429542541504 seconds for one epoch ---
--- 0.3341522216796875 seconds for one epoch ---
--- 3.153775215148926 seconds for one epoch ---
--- 0.32051563262939453 seconds for one epoch ---
--- 3.121755838394165 seconds for one epoch ---
--- 0.32790207862854004 seconds for one epoch ---
--- 3.109304189682007 seconds for one epoch ---
--- 0.8506855964660645 seconds for one epoch ---
--- 3.1111526489257812 seconds for one epoch ---
--- 0.33414316177368164 seconds for one epoch ---
--- 3.099302053451538 seconds for one epoch ---
--- 0.31070899963378906 seconds for one epoch ---
--- 3.1685121059417725 seconds for one epoch ---
--- 0.3344905376434326 seconds for one epoch ---
--- 3.1686758995056152 seconds for one epoch ---
--- 0.3280909061431885 seconds for one epoch ---
--- 3.152878761291504 seconds for one epoch ---
--- 0.32525014877319336 seconds for one epoch ---
--- 3.195838451385498 seconds for one epoch ---
--- 0.3315999507904053 seconds for one epoch ---
--- 3.1271145343780518 seconds for one epoch ---
--- 0.329876184463501 seconds for one epoch ---
--- 3.158883810043335 seconds for one epoch ---
--- 0.3336610794067383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99948406]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.711779]
 [ -0.      ]]
--- 0.2683396339416504 seconds for one epoch ---
Epoch 6325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2703.6044921875, (1174.1528, 1.8146925, 1527.1523, 0.4847146)
   validation loss 885.6212768554688, (604.2697, 0.5180314, 280.34882, 0.4847146)
decoder loss ratio: 23410.457792, decoder SINDy loss  ratio: 0.605172
--- 0.31098389625549316 seconds for one epoch ---
--- 3.17620849609375 seconds for one epoch ---
--- 0.3337278366088867 seconds for one epoch ---
--- 3.109097480773926 seconds for one epoch ---
--- 0.3200812339782715 seconds for one epoch ---
--- 3.12492299079895 seconds for one epoch ---
--- 0.30922889709472656 seconds for one epoch ---
--- 3.2147064208984375 seconds for one epoch ---
--- 0.3214261531829834 seconds for one epoch ---
--- 3.118631362915039 seconds for one epoch ---
--- 0.3355274200439453 seconds for one epoch ---
--- 3.1967849731445312 seconds for one epoch ---
--- 0.32595276832580566 seconds for one epoch ---
--- 3.1539206504821777 seconds for one epoch ---
--- 0.3216240406036377 seconds for one epoch ---
--- 3.1288645267486572 seconds for one epoch ---
--- 0.3345983028411865 seconds for one epoch ---
--- 3.191110134124756 seconds for one epoch ---
--- 0.32933592796325684 seconds for one epoch ---
--- 3.166578531265259 seconds for one epoch ---
--- 0.3216969966888428 seconds for one epoch ---
--- 3.131497383117676 seconds for one epoch ---
--- 0.3303334712982178 seconds for one epoch ---
--- 3.2124173641204834 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994856]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.717484]
 [  0.      ]]
--- 0.30608510971069336 seconds for one epoch ---
Epoch 6350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1686.4337158203125, (932.265, 0.31812778, 753.3657, 0.48487902)
   validation loss 901.7340087890625, (614.59, 0.52970666, 286.1294, 0.48487902)
decoder loss ratio: 23810.284616, decoder SINDy loss  ratio: 0.617651
--- 0.2839961051940918 seconds for one epoch ---
--- 0.32927989959716797 seconds for one epoch ---
--- 3.1453659534454346 seconds for one epoch ---
--- 0.3314681053161621 seconds for one epoch ---
--- 3.217282295227051 seconds for one epoch ---
--- 0.32433414459228516 seconds for one epoch ---
--- 3.114021062850952 seconds for one epoch ---
--- 0.3176138401031494 seconds for one epoch ---
--- 3.199411630630493 seconds for one epoch ---
--- 0.3210933208465576 seconds for one epoch ---
--- 3.1962621212005615 seconds for one epoch ---
--- 0.33844876289367676 seconds for one epoch ---
--- 3.138598918914795 seconds for one epoch ---
--- 0.3262827396392822 seconds for one epoch ---
--- 3.1920998096466064 seconds for one epoch ---
--- 0.3310098648071289 seconds for one epoch ---
--- 3.166381597518921 seconds for one epoch ---
--- 0.3254225254058838 seconds for one epoch ---
--- 3.1633808612823486 seconds for one epoch ---
--- 0.32816076278686523 seconds for one epoch ---
--- 3.1544766426086426 seconds for one epoch ---
--- 0.33023834228515625 seconds for one epoch ---
--- 3.1939072608947754 seconds for one epoch ---
--- 0.3245885372161865 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999488]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.726238]
 [  0.      ]]
--- 0.26146817207336426 seconds for one epoch ---
Epoch 6375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2773.9501953125, (1399.1427, 0.51712304, 1373.8053, 0.4851306)
   validation loss 1235.9444580078125, (907.93195, 0.5265015, 327.00095, 0.4851306)
decoder loss ratio: 35174.859819, decoder SINDy loss  ratio: 0.705878
--- 0.31954240798950195 seconds for one epoch ---
--- 3.1414897441864014 seconds for one epoch ---
--- 0.33226609230041504 seconds for one epoch ---
--- 3.1802666187286377 seconds for one epoch ---
--- 0.32244300842285156 seconds for one epoch ---
--- 3.156061887741089 seconds for one epoch ---
--- 0.33519983291625977 seconds for one epoch ---
--- 3.152020215988159 seconds for one epoch ---
--- 0.3213386535644531 seconds for one epoch ---
--- 3.1689059734344482 seconds for one epoch ---
--- 0.33794260025024414 seconds for one epoch ---
--- 3.2157857418060303 seconds for one epoch ---
--- 0.33521556854248047 seconds for one epoch ---
--- 3.201406955718994 seconds for one epoch ---
--- 0.32669878005981445 seconds for one epoch ---
--- 3.2200708389282227 seconds for one epoch ---
--- 0.32730865478515625 seconds for one epoch ---
--- 3.2065815925598145 seconds for one epoch ---
--- 0.31968092918395996 seconds for one epoch ---
--- 3.196291446685791 seconds for one epoch ---
--- 0.329927921295166 seconds for one epoch ---
--- 3.245333433151245 seconds for one epoch ---
--- 0.31590986251831055 seconds for one epoch ---
--- 3.1570627689361572 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99948967]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.733772]
 [ -0.      ]]
--- 0.2984938621520996 seconds for one epoch ---
Epoch 6400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3335.63916015625, (1289.8884, 0.955015, 2044.3105, 0.48531505)
   validation loss 789.24560546875, (522.72034, 0.52225584, 265.5177, 0.48531505)
decoder loss ratio: 20251.093334, decoder SINDy loss  ratio: 0.573157
--- 0.2827792167663574 seconds for one epoch ---
--- 0.32962679862976074 seconds for one epoch ---
--- 3.201727867126465 seconds for one epoch ---
--- 0.32893991470336914 seconds for one epoch ---
--- 3.207237482070923 seconds for one epoch ---
--- 0.3285548686981201 seconds for one epoch ---
--- 3.2047274112701416 seconds for one epoch ---
--- 0.3279705047607422 seconds for one epoch ---
--- 3.1586344242095947 seconds for one epoch ---
--- 0.323253870010376 seconds for one epoch ---
--- 3.2001805305480957 seconds for one epoch ---
--- 0.3438124656677246 seconds for one epoch ---
--- 3.1606078147888184 seconds for one epoch ---
--- 0.33108973503112793 seconds for one epoch ---
--- 3.214604139328003 seconds for one epoch ---
--- 0.3251919746398926 seconds for one epoch ---
--- 3.1711981296539307 seconds for one epoch ---
--- 0.3335697650909424 seconds for one epoch ---
--- 3.228879451751709 seconds for one epoch ---
--- 0.32882189750671387 seconds for one epoch ---
--- 3.1879265308380127 seconds for one epoch ---
--- 0.3275947570800781 seconds for one epoch ---
--- 3.184325933456421 seconds for one epoch ---
--- 0.33289361000061035 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994894]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.740042]
 [ -0.      ]]
--- 0.26723241806030273 seconds for one epoch ---
Epoch 6425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2979.689697265625, (1268.3022, 3.8497014, 1707.0522, 0.4854838)
   validation loss 875.4803466796875, (586.7426, 0.53706396, 287.71524, 0.4854838)
decoder loss ratio: 22731.427525, decoder SINDy loss  ratio: 0.621074
--- 0.29910969734191895 seconds for one epoch ---
--- 3.199897050857544 seconds for one epoch ---
--- 0.3203277587890625 seconds for one epoch ---
--- 3.2051894664764404 seconds for one epoch ---
--- 0.3349268436431885 seconds for one epoch ---
--- 3.1623778343200684 seconds for one epoch ---
--- 0.32441139221191406 seconds for one epoch ---
--- 3.1680986881256104 seconds for one epoch ---
--- 0.32550692558288574 seconds for one epoch ---
--- 3.177567958831787 seconds for one epoch ---
--- 0.29306650161743164 seconds for one epoch ---
--- 3.18963885307312 seconds for one epoch ---
--- 0.3263707160949707 seconds for one epoch ---
--- 3.182344436645508 seconds for one epoch ---
--- 0.3303804397583008 seconds for one epoch ---
--- 3.241138219833374 seconds for one epoch ---
--- 0.3201558589935303 seconds for one epoch ---
--- 3.24743390083313 seconds for one epoch ---
--- 0.32789087295532227 seconds for one epoch ---
--- 3.144944429397583 seconds for one epoch ---
--- 0.32131099700927734 seconds for one epoch ---
--- 3.2188620567321777 seconds for one epoch ---
--- 0.33814215660095215 seconds for one epoch ---
--- 3.2257118225097656 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994898]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.746078]
 [  0.      ]]
--- 0.3150625228881836 seconds for one epoch ---
Epoch 6450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1457.236572265625, (839.7614, 0.94022584, 616.04926, 0.48565513)
   validation loss 883.1677856445312, (598.0265, 0.52469724, 284.1309, 0.48565513)
decoder loss ratio: 23168.584413, decoder SINDy loss  ratio: 0.613336
--- 0.2729008197784424 seconds for one epoch ---
--- 0.3301382064819336 seconds for one epoch ---
--- 3.2420520782470703 seconds for one epoch ---
--- 0.3299989700317383 seconds for one epoch ---
--- 3.19966983795166 seconds for one epoch ---
--- 0.332427978515625 seconds for one epoch ---
--- 3.1733455657958984 seconds for one epoch ---
--- 0.3264918327331543 seconds for one epoch ---
--- 3.2369608879089355 seconds for one epoch ---
--- 0.3380284309387207 seconds for one epoch ---
--- 3.1729984283447266 seconds for one epoch ---
--- 0.32273101806640625 seconds for one epoch ---
--- 3.2438559532165527 seconds for one epoch ---
--- 0.33603453636169434 seconds for one epoch ---
--- 3.235316753387451 seconds for one epoch ---
--- 0.3093388080596924 seconds for one epoch ---
--- 3.19526743888855 seconds for one epoch ---
--- 0.3233683109283447 seconds for one epoch ---
--- 3.25382137298584 seconds for one epoch ---
--- 0.329622745513916 seconds for one epoch ---
--- 3.201634168624878 seconds for one epoch ---
--- 0.3337390422821045 seconds for one epoch ---
--- 3.263474702835083 seconds for one epoch ---
--- 0.32944345474243164 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994899]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.750933]
 [ -0.      ]]
--- 0.27181077003479004 seconds for one epoch ---
Epoch 6475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4694.61474609375, (1508.0466, 4.9020915, 3181.1802, 0.48578054)
   validation loss 817.7593994140625, (538.7308, 0.53378403, 278.00903, 0.48578054)
decoder loss ratio: 20871.365460, decoder SINDy loss  ratio: 0.600122
--- 0.3125135898590088 seconds for one epoch ---
--- 3.1752541065216064 seconds for one epoch ---
--- 0.3267221450805664 seconds for one epoch ---
--- 3.238534927368164 seconds for one epoch ---
--- 0.3276071548461914 seconds for one epoch ---
--- 3.2468230724334717 seconds for one epoch ---
--- 0.3386354446411133 seconds for one epoch ---
--- 3.2558484077453613 seconds for one epoch ---
--- 0.33228254318237305 seconds for one epoch ---
--- 3.18176007270813 seconds for one epoch ---
--- 0.3216116428375244 seconds for one epoch ---
--- 3.226979970932007 seconds for one epoch ---
--- 0.3307216167449951 seconds for one epoch ---
--- 3.2666807174682617 seconds for one epoch ---
--- 0.33037781715393066 seconds for one epoch ---
--- 3.252751588821411 seconds for one epoch ---
--- 0.3264808654785156 seconds for one epoch ---
--- 3.1930134296417236 seconds for one epoch ---
--- 0.3418123722076416 seconds for one epoch ---
--- 3.1952133178710938 seconds for one epoch ---
--- 0.3383364677429199 seconds for one epoch ---
--- 3.215460777282715 seconds for one epoch ---
--- 0.3210272789001465 seconds for one epoch ---
--- 3.2003798484802246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99948996]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.756998]
 [  0.      ]]
--- 0.31601500511169434 seconds for one epoch ---
Epoch 6500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2685.285400390625, (1468.4651, 0.62653863, 1215.7078, 0.4859725)
   validation loss 923.194091796875, (615.0243, 0.5035211, 307.1803, 0.4859725)
decoder loss ratio: 23827.108801, decoder SINDy loss  ratio: 0.663092
THRESHOLDING: 1 active coefficients
--- 3.1553030014038086 seconds for one epoch ---
--- 0.3250718116760254 seconds for one epoch ---
--- 3.269822835922241 seconds for one epoch ---
--- 0.327847957611084 seconds for one epoch ---
--- 3.239349126815796 seconds for one epoch ---
--- 0.3349456787109375 seconds for one epoch ---
--- 3.24600887298584 seconds for one epoch ---
--- 0.3259761333465576 seconds for one epoch ---
--- 3.2534937858581543 seconds for one epoch ---
--- 0.3207697868347168 seconds for one epoch ---
--- 3.27677321434021 seconds for one epoch ---
--- 0.32501888275146484 seconds for one epoch ---
--- 3.2580552101135254 seconds for one epoch ---
--- 0.33298635482788086 seconds for one epoch ---
--- 3.237987756729126 seconds for one epoch ---
--- 0.3364527225494385 seconds for one epoch ---
--- 3.2572250366210938 seconds for one epoch ---
--- 0.3309297561645508 seconds for one epoch ---
--- 3.27701473236084 seconds for one epoch ---
--- 0.3230159282684326 seconds for one epoch ---
--- 3.2832674980163574 seconds for one epoch ---
--- 0.3345911502838135 seconds for one epoch ---
--- 3.284503698348999 seconds for one epoch ---
--- 0.333174467086792 seconds for one epoch ---
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.99949]
 [0.     ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.762672]
 [  0.      ]]
--- 0.2685532569885254 seconds for one epoch ---
Epoch 6525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1850.234619140625, (964.84326, 0.27938896, 884.6259, 0.4860959)
   validation loss 792.7919921875, (511.54916, 0.52131, 280.23538, 0.4860959)
decoder loss ratio: 19818.302695, decoder SINDy loss  ratio: 0.604927
--- 0.3138463497161865 seconds for one epoch ---
--- 3.1412134170532227 seconds for one epoch ---
--- 0.313126802444458 seconds for one epoch ---
--- 3.2685961723327637 seconds for one epoch ---
--- 0.3274257183074951 seconds for one epoch ---
--- 3.264296770095825 seconds for one epoch ---
--- 0.3249630928039551 seconds for one epoch ---
--- 3.1978306770324707 seconds for one epoch ---
--- 0.31917357444763184 seconds for one epoch ---
--- 3.2762601375579834 seconds for one epoch ---
--- 0.32571935653686523 seconds for one epoch ---
--- 3.222728729248047 seconds for one epoch ---
--- 0.34359240531921387 seconds for one epoch ---
--- 3.2322237491607666 seconds for one epoch ---
--- 0.3252556324005127 seconds for one epoch ---
--- 3.2305831909179688 seconds for one epoch ---
--- 0.3307211399078369 seconds for one epoch ---
--- 3.3172786235809326 seconds for one epoch ---
--- 0.3404395580291748 seconds for one epoch ---
--- 3.2210187911987305 seconds for one epoch ---
--- 0.3213672637939453 seconds for one epoch ---
--- 3.288130760192871 seconds for one epoch ---
--- 0.33148646354675293 seconds for one epoch ---
--- 3.301879405975342 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994906]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.767834]
 [ -0.      ]]
--- 0.3165130615234375 seconds for one epoch ---
Epoch 6550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3526.903564453125, (1995.3054, 3.0960171, 1528.0157, 0.48625946)
   validation loss 771.1896362304688, (502.32898, 0.53769064, 267.83667, 0.48625946)
decoder loss ratio: 19461.096747, decoder SINDy loss  ratio: 0.578163
--- 0.2751591205596924 seconds for one epoch ---
--- 0.3314523696899414 seconds for one epoch ---
--- 3.2807981967926025 seconds for one epoch ---
--- 0.32901573181152344 seconds for one epoch ---
--- 3.2281503677368164 seconds for one epoch ---
--- 0.33374738693237305 seconds for one epoch ---
--- 3.245514392852783 seconds for one epoch ---
--- 0.3322417736053467 seconds for one epoch ---
--- 3.270578622817993 seconds for one epoch ---
--- 0.3329043388366699 seconds for one epoch ---
--- 3.2843005657196045 seconds for one epoch ---
--- 0.32778215408325195 seconds for one epoch ---
--- 3.297205924987793 seconds for one epoch ---
--- 0.33513498306274414 seconds for one epoch ---
--- 3.2492220401763916 seconds for one epoch ---
--- 0.3343076705932617 seconds for one epoch ---
--- 3.228428602218628 seconds for one epoch ---
--- 0.333615779876709 seconds for one epoch ---
--- 3.288377523422241 seconds for one epoch ---
--- 0.3244049549102783 seconds for one epoch ---
--- 3.2444074153900146 seconds for one epoch ---
--- 0.3271305561065674 seconds for one epoch ---
--- 3.2634382247924805 seconds for one epoch ---
--- 0.3327040672302246 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994911]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-18.77326]
 [ -0.     ]]
--- 0.27509546279907227 seconds for one epoch ---
Epoch 6575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1707.3663330078125, (768.0352, 0.33723694, 938.5074, 0.4864013)
   validation loss 1067.0347900390625, (762.7184, 0.52489686, 303.30502, 0.4864013)
decoder loss ratio: 29549.034325, decoder SINDy loss  ratio: 0.654727
--- 0.3215909004211426 seconds for one epoch ---
--- 3.225658655166626 seconds for one epoch ---
--- 0.3419175148010254 seconds for one epoch ---
--- 3.226595640182495 seconds for one epoch ---
--- 0.3317134380340576 seconds for one epoch ---
--- 3.235685348510742 seconds for one epoch ---
--- 0.3304409980773926 seconds for one epoch ---
--- 3.230654239654541 seconds for one epoch ---
--- 0.3232858180999756 seconds for one epoch ---
--- 3.2477529048919678 seconds for one epoch ---
--- 0.3440239429473877 seconds for one epoch ---
--- 3.2555720806121826 seconds for one epoch ---
--- 0.32243919372558594 seconds for one epoch ---
--- 3.3283302783966064 seconds for one epoch ---
--- 0.3311018943786621 seconds for one epoch ---
--- 3.3016536235809326 seconds for one epoch ---
--- 0.33634114265441895 seconds for one epoch ---
--- 3.268233299255371 seconds for one epoch ---
--- 0.3282794952392578 seconds for one epoch ---
--- 3.244835138320923 seconds for one epoch ---
--- 0.33728456497192383 seconds for one epoch ---
--- 3.3427326679229736 seconds for one epoch ---
--- 0.31444716453552246 seconds for one epoch ---
--- 3.2605650424957275 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949217]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.77813]
 [  0.     ]]
--- 0.2967236042022705 seconds for one epoch ---
Epoch 6600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1968.012939453125, (1004.8585, 1.1298213, 961.538, 0.48653045)
   validation loss 854.0234985351562, (573.786, 0.5543939, 279.19656, 0.48653045)
decoder loss ratio: 22229.466192, decoder SINDy loss  ratio: 0.602685
--- 0.28599119186401367 seconds for one epoch ---
--- 0.3294987678527832 seconds for one epoch ---
--- 3.2275688648223877 seconds for one epoch ---
--- 0.32518434524536133 seconds for one epoch ---
--- 3.2366671562194824 seconds for one epoch ---
--- 0.32584524154663086 seconds for one epoch ---
--- 3.251192808151245 seconds for one epoch ---
--- 0.326890230178833 seconds for one epoch ---
--- 3.3078911304473877 seconds for one epoch ---
--- 0.33196282386779785 seconds for one epoch ---
--- 3.3170933723449707 seconds for one epoch ---
--- 0.33414411544799805 seconds for one epoch ---
--- 3.261913299560547 seconds for one epoch ---
--- 0.334458589553833 seconds for one epoch ---
--- 3.3256430625915527 seconds for one epoch ---
--- 0.34104418754577637 seconds for one epoch ---
--- 3.331153392791748 seconds for one epoch ---
--- 0.33965182304382324 seconds for one epoch ---
--- 3.24021315574646 seconds for one epoch ---
--- 0.3343851566314697 seconds for one epoch ---
--- 3.3017396926879883 seconds for one epoch ---
--- 0.3382248878479004 seconds for one epoch ---
--- 3.2596070766448975 seconds for one epoch ---
--- 0.3244974613189697 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994926]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.782038]
 [ -0.      ]]
--- 0.2693610191345215 seconds for one epoch ---
Epoch 6625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3065.00537109375, (1186.6758, 4.0270557, 1873.8159, 0.4866539)
   validation loss 745.5527954101562, (483.94055, 0.5665559, 260.55908, 0.4866539)
decoder loss ratio: 18748.697133, decoder SINDy loss  ratio: 0.562453
--- 0.3207077980041504 seconds for one epoch ---
--- 3.2418911457061768 seconds for one epoch ---
--- 0.33428096771240234 seconds for one epoch ---
--- 3.318502426147461 seconds for one epoch ---
--- 0.3224050998687744 seconds for one epoch ---
--- 3.258749485015869 seconds for one epoch ---
--- 0.3321988582611084 seconds for one epoch ---
--- 3.2848339080810547 seconds for one epoch ---
--- 0.32363414764404297 seconds for one epoch ---
--- 3.280639886856079 seconds for one epoch ---
--- 0.32565879821777344 seconds for one epoch ---
--- 3.3263158798217773 seconds for one epoch ---
--- 0.3322029113769531 seconds for one epoch ---
--- 3.273514986038208 seconds for one epoch ---
--- 0.3251032829284668 seconds for one epoch ---
--- 3.3358817100524902 seconds for one epoch ---
--- 0.33905887603759766 seconds for one epoch ---
--- 3.265589475631714 seconds for one epoch ---
--- 0.3362119197845459 seconds for one epoch ---
--- 3.334491491317749 seconds for one epoch ---
--- 0.3315157890319824 seconds for one epoch ---
--- 3.2778990268707275 seconds for one epoch ---
--- 0.32782983779907227 seconds for one epoch ---
--- 3.2725512981414795 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994931]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.786928]
 [  0.      ]]
--- 0.3067929744720459 seconds for one epoch ---
Epoch 6650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2602.745849609375, (1102.6409, 5.5713477, 1494.0469, 0.4867712)
   validation loss 844.0179443359375, (558.6928, 0.5393869, 284.299, 0.4867712)
decoder loss ratio: 21644.729395, decoder SINDy loss  ratio: 0.613699
--- 0.28594470024108887 seconds for one epoch ---
--- 0.3309297561645508 seconds for one epoch ---
--- 3.2599449157714844 seconds for one epoch ---
--- 0.3345208168029785 seconds for one epoch ---
--- 3.2685494422912598 seconds for one epoch ---
--- 0.31879115104675293 seconds for one epoch ---
--- 3.3382205963134766 seconds for one epoch ---
--- 0.3235747814178467 seconds for one epoch ---
--- 3.275583267211914 seconds for one epoch ---
--- 0.33368539810180664 seconds for one epoch ---
--- 3.270641565322876 seconds for one epoch ---
--- 0.3393561840057373 seconds for one epoch ---
--- 3.260544538497925 seconds for one epoch ---
--- 0.3282735347747803 seconds for one epoch ---
--- 3.340151309967041 seconds for one epoch ---
--- 0.32848119735717773 seconds for one epoch ---
--- 3.2683539390563965 seconds for one epoch ---
--- 0.3378307819366455 seconds for one epoch ---
--- 3.2910079956054688 seconds for one epoch ---
--- 0.3229959011077881 seconds for one epoch ---
--- 3.3593931198120117 seconds for one epoch ---
--- 0.3335542678833008 seconds for one epoch ---
--- 3.306990385055542 seconds for one epoch ---
--- 0.32924723625183105 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994937]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-18.79168]
 [  0.     ]]
--- 0.2766757011413574 seconds for one epoch ---
Epoch 6675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1515.8397216796875, (751.45087, 0.36572498, 763.5362, 0.48688728)
   validation loss 804.0765991210938, (537.0537, 0.5393836, 265.99664, 0.48688728)
decoder loss ratio: 20806.393128, decoder SINDy loss  ratio: 0.574191
--- 0.31688404083251953 seconds for one epoch ---
--- 3.2710723876953125 seconds for one epoch ---
--- 0.3260960578918457 seconds for one epoch ---
--- 3.2695558071136475 seconds for one epoch ---
--- 0.3274219036102295 seconds for one epoch ---
--- 3.357525587081909 seconds for one epoch ---
--- 0.3329646587371826 seconds for one epoch ---
--- 3.298537492752075 seconds for one epoch ---
--- 0.3215601444244385 seconds for one epoch ---
--- 3.301870107650757 seconds for one epoch ---
--- 0.33055806159973145 seconds for one epoch ---
--- 3.383451461791992 seconds for one epoch ---
--- 0.33364176750183105 seconds for one epoch ---
--- 3.351475954055786 seconds for one epoch ---
--- 0.3266153335571289 seconds for one epoch ---
--- 3.282087802886963 seconds for one epoch ---
--- 0.3106212615966797 seconds for one epoch ---
--- 3.3478376865386963 seconds for one epoch ---
--- 0.32934021949768066 seconds for one epoch ---
--- 3.3400840759277344 seconds for one epoch ---
--- 0.3298153877258301 seconds for one epoch ---
--- 3.3468222618103027 seconds for one epoch ---
--- 0.3311738967895508 seconds for one epoch ---
--- 3.2923333644866943 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949455]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.795729]
 [ -0.      ]]
--- 0.3143737316131592 seconds for one epoch ---
Epoch 6700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2424.659423828125, (1233.8864, 0.9900977, 1189.296, 0.48699626)
   validation loss 841.1799926757812, (560.0977, 0.5264569, 280.06888, 0.48699626)
decoder loss ratio: 21699.157940, decoder SINDy loss  ratio: 0.604568
--- 0.27487897872924805 seconds for one epoch ---
--- 0.3293266296386719 seconds for one epoch ---
--- 3.282926082611084 seconds for one epoch ---
--- 0.3334038257598877 seconds for one epoch ---
--- 3.3386640548706055 seconds for one epoch ---
--- 0.3377101421356201 seconds for one epoch ---
--- 3.362523317337036 seconds for one epoch ---
--- 0.3305339813232422 seconds for one epoch ---
--- 3.332566499710083 seconds for one epoch ---
--- 0.3299562931060791 seconds for one epoch ---
--- 3.3727059364318848 seconds for one epoch ---
--- 0.3343536853790283 seconds for one epoch ---
--- 3.378159999847412 seconds for one epoch ---
--- 0.3280041217803955 seconds for one epoch ---
--- 3.3025763034820557 seconds for one epoch ---
--- 0.31885814666748047 seconds for one epoch ---
--- 3.322725534439087 seconds for one epoch ---
--- 0.3323225975036621 seconds for one epoch ---
--- 3.360853433609009 seconds for one epoch ---
--- 0.33382296562194824 seconds for one epoch ---
--- 3.298375368118286 seconds for one epoch ---
--- 0.3315434455871582 seconds for one epoch ---
--- 3.372232437133789 seconds for one epoch ---
--- 0.335512638092041 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949527]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.802132]
 [ -0.      ]]
--- 0.26935458183288574 seconds for one epoch ---
Epoch 6725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1965.5526123046875, (882.34174, 1.5993118, 1081.1244, 0.4871891)
   validation loss 716.2837524414062, (449.9763, 0.5492681, 265.27103, 0.4871891)
decoder loss ratio: 17432.862584, decoder SINDy loss  ratio: 0.572625
--- 0.29931092262268066 seconds for one epoch ---
--- 3.2807223796844482 seconds for one epoch ---
--- 0.33591628074645996 seconds for one epoch ---
--- 3.3007194995880127 seconds for one epoch ---
--- 0.3272871971130371 seconds for one epoch ---
--- 3.3127033710479736 seconds for one epoch ---
--- 0.33236145973205566 seconds for one epoch ---
--- 3.301482915878296 seconds for one epoch ---
--- 0.322986364364624 seconds for one epoch ---
--- 3.296912670135498 seconds for one epoch ---
--- 0.32964181900024414 seconds for one epoch ---
--- 3.361649990081787 seconds for one epoch ---
--- 0.3345766067504883 seconds for one epoch ---
--- 3.3025546073913574 seconds for one epoch ---
--- 0.3241894245147705 seconds for one epoch ---
--- 3.3064041137695312 seconds for one epoch ---
--- 0.3295450210571289 seconds for one epoch ---
--- 3.3900439739227295 seconds for one epoch ---
--- 0.32247447967529297 seconds for one epoch ---
--- 3.3092246055603027 seconds for one epoch ---
--- 0.33185720443725586 seconds for one epoch ---
--- 3.3733837604522705 seconds for one epoch ---
--- 0.3250579833984375 seconds for one epoch ---
--- 3.301424741744995 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949586]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.806395]
 [  0.      ]]
--- 0.28848934173583984 seconds for one epoch ---
Epoch 6750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3514.9423828125, (1811.6431, 0.5391794, 1702.2728, 0.48730594)
   validation loss 769.5376586914062, (505.202, 0.55164707, 263.29672, 0.48730594)
decoder loss ratio: 19572.402388, decoder SINDy loss  ratio: 0.568363
--- 0.2792694568634033 seconds for one epoch ---
--- 0.33145809173583984 seconds for one epoch ---
--- 3.391805648803711 seconds for one epoch ---
--- 0.31493353843688965 seconds for one epoch ---
--- 3.3365914821624756 seconds for one epoch ---
--- 0.3320963382720947 seconds for one epoch ---
--- 3.385589361190796 seconds for one epoch ---
--- 0.3246877193450928 seconds for one epoch ---
--- 3.3744616508483887 seconds for one epoch ---
--- 0.333742618560791 seconds for one epoch ---
--- 3.311336040496826 seconds for one epoch ---
--- 0.3195183277130127 seconds for one epoch ---
--- 3.3206543922424316 seconds for one epoch ---
--- 0.34371066093444824 seconds for one epoch ---
--- 3.3191115856170654 seconds for one epoch ---
--- 0.3309512138366699 seconds for one epoch ---
--- 3.369356632232666 seconds for one epoch ---
--- 0.3256804943084717 seconds for one epoch ---
--- 3.327204465866089 seconds for one epoch ---
--- 0.33007383346557617 seconds for one epoch ---
--- 3.4014766216278076 seconds for one epoch ---
--- 0.3296194076538086 seconds for one epoch ---
--- 3.3869316577911377 seconds for one epoch ---
--- 0.32825136184692383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949646]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.810667]
 [ -0.      ]]
--- 0.2622029781341553 seconds for one epoch ---
Epoch 6775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5945.0517578125, (2364.6526, 1.7094162, 3578.2026, 0.48742533)
   validation loss 821.6243896484375, (544.1093, 0.54179645, 276.48587, 0.48742533)
decoder loss ratio: 21079.739438, decoder SINDy loss  ratio: 0.596834
--- 0.3173832893371582 seconds for one epoch ---
--- 3.382303476333618 seconds for one epoch ---
--- 0.33258628845214844 seconds for one epoch ---
--- 3.3890068531036377 seconds for one epoch ---
--- 0.33214473724365234 seconds for one epoch ---
--- 3.3434395790100098 seconds for one epoch ---
--- 0.3190577030181885 seconds for one epoch ---
--- 3.309748888015747 seconds for one epoch ---
--- 0.32689857482910156 seconds for one epoch ---
--- 3.3098456859588623 seconds for one epoch ---
--- 0.32305049896240234 seconds for one epoch ---
--- 3.318430185317993 seconds for one epoch ---
--- 0.3231699466705322 seconds for one epoch ---
--- 3.39825701713562 seconds for one epoch ---
--- 0.3280971050262451 seconds for one epoch ---
--- 3.3945155143737793 seconds for one epoch ---
--- 0.3286173343658447 seconds for one epoch ---
--- 3.33140230178833 seconds for one epoch ---
--- 0.3188292980194092 seconds for one epoch ---
--- 3.328829288482666 seconds for one epoch ---
--- 0.3256957530975342 seconds for one epoch ---
--- 3.398557186126709 seconds for one epoch ---
--- 0.3009824752807617 seconds for one epoch ---
--- 3.3341903686523438 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994974]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.815998]
 [  0.      ]]
--- 0.3230128288269043 seconds for one epoch ---
Epoch 6800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2341.5458984375, (766.8951, 1.3768891, 1572.7864, 0.48754475)
   validation loss 889.65576171875, (607.4047, 0.54986393, 281.21365, 0.48754475)
decoder loss ratio: 23531.913513, decoder SINDy loss  ratio: 0.607039
--- 0.2731752395629883 seconds for one epoch ---
--- 0.3297727108001709 seconds for one epoch ---
--- 3.3882863521575928 seconds for one epoch ---
--- 0.32804298400878906 seconds for one epoch ---
--- 3.3990375995635986 seconds for one epoch ---
--- 0.33035993576049805 seconds for one epoch ---
--- 3.3437845706939697 seconds for one epoch ---
--- 0.3391733169555664 seconds for one epoch ---
--- 3.338848352432251 seconds for one epoch ---
--- 0.33103299140930176 seconds for one epoch ---
--- 3.395456075668335 seconds for one epoch ---
--- 0.31583380699157715 seconds for one epoch ---
--- 3.3491508960723877 seconds for one epoch ---
--- 0.3274364471435547 seconds for one epoch ---
--- 3.427107572555542 seconds for one epoch ---
--- 0.3242378234863281 seconds for one epoch ---
--- 3.400022268295288 seconds for one epoch ---
--- 0.3228578567504883 seconds for one epoch ---
--- 3.3453524112701416 seconds for one epoch ---
--- 0.33514833450317383 seconds for one epoch ---
--- 3.419569253921509 seconds for one epoch ---
--- 0.3322887420654297 seconds for one epoch ---
--- 3.3794467449188232 seconds for one epoch ---
--- 0.3309183120727539 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994982]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.821125]
 [  0.      ]]
--- 0.26142120361328125 seconds for one epoch ---
Epoch 6825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2273.84765625, (1260.181, 0.7324958, 1012.44617, 0.4876864)
   validation loss 722.38623046875, (461.54736, 0.57221025, 259.77902, 0.4876864)
decoder loss ratio: 17881.146135, decoder SINDy loss  ratio: 0.560770
--- 0.3123905658721924 seconds for one epoch ---
--- 3.3613574504852295 seconds for one epoch ---
--- 0.3339507579803467 seconds for one epoch ---
--- 3.3663811683654785 seconds for one epoch ---
--- 0.3305180072784424 seconds for one epoch ---
--- 3.408491849899292 seconds for one epoch ---
--- 0.32820582389831543 seconds for one epoch ---
--- 3.3737642765045166 seconds for one epoch ---
--- 0.33635592460632324 seconds for one epoch ---
--- 3.3581831455230713 seconds for one epoch ---
--- 0.3299686908721924 seconds for one epoch ---
--- 3.3424220085144043 seconds for one epoch ---
--- 0.3287353515625 seconds for one epoch ---
--- 3.424417495727539 seconds for one epoch ---
--- 0.3187227249145508 seconds for one epoch ---
--- 3.396047353744507 seconds for one epoch ---
--- 0.33454275131225586 seconds for one epoch ---
--- 3.425858736038208 seconds for one epoch ---
--- 0.3294565677642822 seconds for one epoch ---
--- 3.3809564113616943 seconds for one epoch ---
--- 0.3281412124633789 seconds for one epoch ---
--- 3.412306070327759 seconds for one epoch ---
--- 0.32233452796936035 seconds for one epoch ---
--- 3.356924533843994 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994985]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-18.82431]
 [ -0.     ]]
--- 0.31786322593688965 seconds for one epoch ---
Epoch 6850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2840.490966796875, (1296.7291, 1.7877688, 1541.4863, 0.48780057)
   validation loss 823.1700439453125, (548.76227, 0.54637235, 273.3736, 0.48780057)
decoder loss ratio: 21260.002958, decoder SINDy loss  ratio: 0.590115
--- 0.2686634063720703 seconds for one epoch ---
--- 0.33077454566955566 seconds for one epoch ---
--- 3.370743751525879 seconds for one epoch ---
--- 0.30912017822265625 seconds for one epoch ---
--- 3.3586089611053467 seconds for one epoch ---
--- 0.3306305408477783 seconds for one epoch ---
--- 3.436161756515503 seconds for one epoch ---
--- 0.32714319229125977 seconds for one epoch ---
--- 3.365767240524292 seconds for one epoch ---
--- 0.3204216957092285 seconds for one epoch ---
--- 3.4249982833862305 seconds for one epoch ---
--- 0.32354164123535156 seconds for one epoch ---
--- 3.3743226528167725 seconds for one epoch ---
--- 0.33142805099487305 seconds for one epoch ---
--- 3.4173760414123535 seconds for one epoch ---
--- 0.3222789764404297 seconds for one epoch ---
--- 3.3677070140838623 seconds for one epoch ---
--- 0.3275902271270752 seconds for one epoch ---
--- 3.373657464981079 seconds for one epoch ---
--- 0.3215785026550293 seconds for one epoch ---
--- 3.355457305908203 seconds for one epoch ---
--- 0.32314395904541016 seconds for one epoch ---
--- 3.4404826164245605 seconds for one epoch ---
--- 0.3294658660888672 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99949986]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-18.82996]
 [ -0.     ]]
--- 0.27672338485717773 seconds for one epoch ---
Epoch 6875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3888.87451171875, (1362.4788, 2.1677344, 2523.74, 0.48793936)
   validation loss 831.106201171875, (546.9299, 0.5361083, 283.15225, 0.48793936)
decoder loss ratio: 21189.012699, decoder SINDy loss  ratio: 0.611224
--- 0.3131382465362549 seconds for one epoch ---
--- 3.3687679767608643 seconds for one epoch ---
--- 0.3323025703430176 seconds for one epoch ---
--- 3.4271278381347656 seconds for one epoch ---
--- 0.31815218925476074 seconds for one epoch ---
--- 3.444866895675659 seconds for one epoch ---
--- 0.3432331085205078 seconds for one epoch ---
--- 3.3712213039398193 seconds for one epoch ---
--- 0.318434476852417 seconds for one epoch ---
--- 3.399332046508789 seconds for one epoch ---
--- 0.3146553039550781 seconds for one epoch ---
--- 3.3724145889282227 seconds for one epoch ---
--- 0.33203768730163574 seconds for one epoch ---
--- 3.3895227909088135 seconds for one epoch ---
--- 0.3316657543182373 seconds for one epoch ---
--- 3.4469642639160156 seconds for one epoch ---
--- 0.3333127498626709 seconds for one epoch ---
--- 3.363208055496216 seconds for one epoch ---
--- 0.3323502540588379 seconds for one epoch ---
--- 3.36517333984375 seconds for one epoch ---
--- 0.32277488708496094 seconds for one epoch ---
--- 3.446350336074829 seconds for one epoch ---
--- 0.3115239143371582 seconds for one epoch ---
--- 3.3758704662323 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950063]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.832655]
 [  0.      ]]
--- 0.30285048484802246 seconds for one epoch ---
Epoch 6900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2489.897216796875, (1466.0792, 3.2048292, 1020.12506, 0.4880356)
   validation loss 804.2409057617188, (527.39044, 0.5348153, 275.82764, 0.4880356)
decoder loss ratio: 20432.021309, decoder SINDy loss  ratio: 0.595413
--- 0.2775599956512451 seconds for one epoch ---
--- 0.3271644115447998 seconds for one epoch ---
--- 3.367328643798828 seconds for one epoch ---
--- 0.3334987163543701 seconds for one epoch ---
--- 3.3882477283477783 seconds for one epoch ---
--- 0.31633543968200684 seconds for one epoch ---
--- 3.45361590385437 seconds for one epoch ---
--- 0.34238624572753906 seconds for one epoch ---
--- 3.389146089553833 seconds for one epoch ---
--- 0.32223987579345703 seconds for one epoch ---
--- 3.4036412239074707 seconds for one epoch ---
--- 0.3425920009613037 seconds for one epoch ---
--- 3.3957674503326416 seconds for one epoch ---
--- 0.33044958114624023 seconds for one epoch ---
--- 3.393324136734009 seconds for one epoch ---
--- 0.3033485412597656 seconds for one epoch ---
--- 3.469444513320923 seconds for one epoch ---
--- 0.31174159049987793 seconds for one epoch ---
--- 3.3806896209716797 seconds for one epoch ---
--- 0.3290865421295166 seconds for one epoch ---
--- 3.4486896991729736 seconds for one epoch ---
--- 0.3334770202636719 seconds for one epoch ---
--- 3.4059181213378906 seconds for one epoch ---
--- 0.3327617645263672 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950194]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.838257]
 [ -0.      ]]
--- 0.2680671215057373 seconds for one epoch ---
Epoch 6925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3332.515625, (1380.6448, 0.3506095, 1951.0319, 0.48817596)
   validation loss 770.6035766601562, (496.5061, 0.5305107, 273.0788, 0.48817596)
decoder loss ratio: 19235.508423, decoder SINDy loss  ratio: 0.589479
--- 0.3220977783203125 seconds for one epoch ---
--- 3.404768705368042 seconds for one epoch ---
--- 0.33589935302734375 seconds for one epoch ---
--- 3.38108229637146 seconds for one epoch ---
--- 0.342268705368042 seconds for one epoch ---
--- 3.390669584274292 seconds for one epoch ---
--- 0.3356351852416992 seconds for one epoch ---
--- 3.3987131118774414 seconds for one epoch ---
--- 0.33694982528686523 seconds for one epoch ---
--- 3.4423129558563232 seconds for one epoch ---
--- 0.3410005569458008 seconds for one epoch ---
--- 3.3894169330596924 seconds for one epoch ---
--- 0.3284766674041748 seconds for one epoch ---
--- 3.3967714309692383 seconds for one epoch ---
--- 0.32839465141296387 seconds for one epoch ---
--- 3.458181142807007 seconds for one epoch ---
--- 0.3342311382293701 seconds for one epoch ---
--- 3.4191999435424805 seconds for one epoch ---
--- 0.3291304111480713 seconds for one epoch ---
--- 3.409519910812378 seconds for one epoch ---
--- 0.3311648368835449 seconds for one epoch ---
--- 3.464949607849121 seconds for one epoch ---
--- 0.33480215072631836 seconds for one epoch ---
--- 3.4068546295166016 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950325]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-18.84384]
 [  0.     ]]
--- 0.30474853515625 seconds for one epoch ---
Epoch 6950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2146.498779296875, (1056.583, 1.035226, 1088.3922, 0.48834744)
   validation loss 798.3773803710938, (520.7557, 0.5552182, 276.5781, 0.48834744)
decoder loss ratio: 20174.978970, decoder SINDy loss  ratio: 0.597033
--- 0.26185011863708496 seconds for one epoch ---
--- 0.3379509449005127 seconds for one epoch ---
--- 3.3896851539611816 seconds for one epoch ---
--- 0.32583022117614746 seconds for one epoch ---
--- 3.4598186016082764 seconds for one epoch ---
--- 0.3252675533294678 seconds for one epoch ---
--- 3.462423086166382 seconds for one epoch ---
--- 0.33534717559814453 seconds for one epoch ---
--- 3.4634792804718018 seconds for one epoch ---
--- 0.3400304317474365 seconds for one epoch ---
--- 3.410778045654297 seconds for one epoch ---
--- 0.3222024440765381 seconds for one epoch ---
--- 3.4153237342834473 seconds for one epoch ---
--- 0.3261528015136719 seconds for one epoch ---
--- 3.475055456161499 seconds for one epoch ---
--- 0.33608555793762207 seconds for one epoch ---
--- 3.4221558570861816 seconds for one epoch ---
--- 0.32213449478149414 seconds for one epoch ---
--- 3.4147555828094482 seconds for one epoch ---
--- 0.33081722259521484 seconds for one epoch ---
--- 3.4779558181762695 seconds for one epoch ---
--- 0.3338923454284668 seconds for one epoch ---
--- 3.4148998260498047 seconds for one epoch ---
--- 0.32462000846862793 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995045]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.849264]
 [  0.      ]]
--- 0.26397705078125 seconds for one epoch ---
Epoch 6975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2745.421630859375, (1022.02704, 0.5085201, 1722.3975, 0.4884734)
   validation loss 887.27685546875, (596.5795, 0.54945296, 289.65942, 0.4884734)
decoder loss ratio: 23112.526654, decoder SINDy loss  ratio: 0.625271
--- 0.3081676959991455 seconds for one epoch ---
--- 3.4969406127929688 seconds for one epoch ---
--- 0.34461426734924316 seconds for one epoch ---
--- 3.4214775562286377 seconds for one epoch ---
--- 0.33091139793395996 seconds for one epoch ---
--- 3.4160499572753906 seconds for one epoch ---
--- 0.3288705348968506 seconds for one epoch ---
--- 3.394174575805664 seconds for one epoch ---
--- 0.32573485374450684 seconds for one epoch ---
--- 3.4185330867767334 seconds for one epoch ---
--- 0.32775378227233887 seconds for one epoch ---
--- 3.419081211090088 seconds for one epoch ---
--- 0.32967281341552734 seconds for one epoch ---
--- 3.416802406311035 seconds for one epoch ---
--- 0.3292272090911865 seconds for one epoch ---
--- 3.4862358570098877 seconds for one epoch ---
--- 0.3350179195404053 seconds for one epoch ---
--- 3.478985071182251 seconds for one epoch ---
--- 0.33112430572509766 seconds for one epoch ---
--- 3.4878623485565186 seconds for one epoch ---
--- 0.32541966438293457 seconds for one epoch ---
--- 3.457479238510132 seconds for one epoch ---
--- 0.3408973217010498 seconds for one epoch ---
--- 3.5049471855163574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950564]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.851616]
 [ -0.      ]]
--- 0.3077690601348877 seconds for one epoch ---
Epoch 7000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2173.15234375, (1228.8511, 0.77164346, 943.0412, 0.4885354)
   validation loss 932.990478515625, (663.6714, 0.5333111, 268.29724, 0.4885354)
decoder loss ratio: 25711.781706, decoder SINDy loss  ratio: 0.579157
THRESHOLDING: 1 active coefficients
--- 3.3934199810028076 seconds for one epoch ---
--- 0.32138752937316895 seconds for one epoch ---
--- 3.42020320892334 seconds for one epoch ---
--- 0.33398938179016113 seconds for one epoch ---
--- 3.475170612335205 seconds for one epoch ---
--- 0.3274071216583252 seconds for one epoch ---
--- 3.4566738605499268 seconds for one epoch ---
--- 0.3289642333984375 seconds for one epoch ---
--- 3.4397623538970947 seconds for one epoch ---
--- 0.3461575508117676 seconds for one epoch ---
--- 3.4851014614105225 seconds for one epoch ---
--- 0.3303408622741699 seconds for one epoch ---
--- 3.4897305965423584 seconds for one epoch ---
--- 0.3319993019104004 seconds for one epoch ---
--- 3.4559383392333984 seconds for one epoch ---
--- 0.3375434875488281 seconds for one epoch ---
--- 3.4260332584381104 seconds for one epoch ---
--- 0.32954978942871094 seconds for one epoch ---
--- 3.437998056411743 seconds for one epoch ---
--- 0.333052396774292 seconds for one epoch ---
--- 3.5114471912384033 seconds for one epoch ---
--- 0.32950806617736816 seconds for one epoch ---
--- 3.436340808868408 seconds for one epoch ---
--- 0.32903432846069336 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950564]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.858093]
 [ -0.      ]]
--- 0.26097989082336426 seconds for one epoch ---
Epoch 7025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2844.017578125, (1260.3132, 0.5929037, 1582.6228, 0.48872328)
   validation loss 949.2730102539062, (650.20184, 0.52405334, 298.05838, 0.48872328)
decoder loss ratio: 25189.948208, decoder SINDy loss  ratio: 0.643401
--- 0.3210031986236572 seconds for one epoch ---
--- 3.382985830307007 seconds for one epoch ---
--- 0.3328120708465576 seconds for one epoch ---
--- 3.4357571601867676 seconds for one epoch ---
--- 0.32663869857788086 seconds for one epoch ---
--- 3.4645774364471436 seconds for one epoch ---
--- 0.3237583637237549 seconds for one epoch ---
--- 3.4294631481170654 seconds for one epoch ---
--- 0.331301212310791 seconds for one epoch ---
--- 3.4958977699279785 seconds for one epoch ---
--- 0.3289802074432373 seconds for one epoch ---
--- 3.4445834159851074 seconds for one epoch ---
--- 0.3210906982421875 seconds for one epoch ---
--- 3.517789125442505 seconds for one epoch ---
--- 0.33185839653015137 seconds for one epoch ---
--- 3.5195133686065674 seconds for one epoch ---
--- 0.3381352424621582 seconds for one epoch ---
--- 3.523665428161621 seconds for one epoch ---
--- 0.327800989151001 seconds for one epoch ---
--- 3.467499017715454 seconds for one epoch ---
--- 0.33745741844177246 seconds for one epoch ---
--- 3.463071823120117 seconds for one epoch ---
--- 0.3350803852081299 seconds for one epoch ---
--- 3.5411782264709473 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995048]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.863342]
 [  0.      ]]
--- 0.30660390853881836 seconds for one epoch ---
Epoch 7050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2111.995849609375, (831.5876, 5.892202, 1274.0272, 0.48888063)
   validation loss 971.9765625, (670.6435, 0.54295915, 300.3012, 0.48888063)
decoder loss ratio: 25981.893232, decoder SINDy loss  ratio: 0.648242
--- 0.2709040641784668 seconds for one epoch ---
--- 0.3431997299194336 seconds for one epoch ---
--- 3.4553210735321045 seconds for one epoch ---
--- 0.3235046863555908 seconds for one epoch ---
--- 3.53117036819458 seconds for one epoch ---
--- 0.3386878967285156 seconds for one epoch ---
--- 3.450026273727417 seconds for one epoch ---
--- 0.33827877044677734 seconds for one epoch ---
--- 3.541778802871704 seconds for one epoch ---
--- 0.33226871490478516 seconds for one epoch ---
--- 3.4682810306549072 seconds for one epoch ---
--- 0.3266942501068115 seconds for one epoch ---
--- 3.4627294540405273 seconds for one epoch ---
--- 0.32773423194885254 seconds for one epoch ---
--- 3.4685840606689453 seconds for one epoch ---
--- 0.32912516593933105 seconds for one epoch ---
--- 3.5364558696746826 seconds for one epoch ---
--- 0.33034825325012207 seconds for one epoch ---
--- 3.5417070388793945 seconds for one epoch ---
--- 0.3269045352935791 seconds for one epoch ---
--- 3.5313916206359863 seconds for one epoch ---
--- 0.3321533203125 seconds for one epoch ---
--- 3.545776128768921 seconds for one epoch ---
--- 0.33102989196777344 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995047]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.868546]
 [ -0.      ]]
--- 0.2752230167388916 seconds for one epoch ---
Epoch 7075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3413.108154296875, (1852.5278, 0.78761584, 1559.3036, 0.4889803)
   validation loss 845.4603881835938, (583.4574, 0.5473529, 260.9667, 0.4889803)
decoder loss ratio: 22604.152504, decoder SINDy loss  ratio: 0.563333
--- 0.31133174896240234 seconds for one epoch ---
--- 3.5192885398864746 seconds for one epoch ---
--- 0.33959007263183594 seconds for one epoch ---
--- 3.523077964782715 seconds for one epoch ---
--- 0.3304932117462158 seconds for one epoch ---
--- 3.5345170497894287 seconds for one epoch ---
--- 0.32033610343933105 seconds for one epoch ---
--- 3.470289945602417 seconds for one epoch ---
--- 0.33498215675354004 seconds for one epoch ---
--- 3.549344062805176 seconds for one epoch ---
--- 0.3339560031890869 seconds for one epoch ---
--- 3.5560736656188965 seconds for one epoch ---
--- 0.3302645683288574 seconds for one epoch ---
--- 3.548847198486328 seconds for one epoch ---
--- 0.33867931365966797 seconds for one epoch ---
--- 3.481046438217163 seconds for one epoch ---
--- 0.33103346824645996 seconds for one epoch ---
--- 3.543964385986328 seconds for one epoch ---
--- 0.3267247676849365 seconds for one epoch ---
--- 3.5468013286590576 seconds for one epoch ---
--- 0.3311281204223633 seconds for one epoch ---
--- 3.5424139499664307 seconds for one epoch ---
--- 0.31824755668640137 seconds for one epoch ---
--- 3.5520966053009033 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995048]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.87403]
 [  0.     ]]
--- 0.30579519271850586 seconds for one epoch ---
Epoch 7100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5405.197265625, (1953.9617, 0.8506741, 3449.8958, 0.4891462)
   validation loss 877.12158203125, (587.28784, 0.5413505, 288.80328, 0.4891462)
decoder loss ratio: 22752.550568, decoder SINDy loss  ratio: 0.623423
--- 0.27723169326782227 seconds for one epoch ---
--- 0.3298070430755615 seconds for one epoch ---
--- 3.4504432678222656 seconds for one epoch ---
--- 0.33287930488586426 seconds for one epoch ---
--- 3.528660774230957 seconds for one epoch ---
--- 0.3334639072418213 seconds for one epoch ---
--- 3.5701684951782227 seconds for one epoch ---
--- 0.336315393447876 seconds for one epoch ---
--- 3.4887595176696777 seconds for one epoch ---
--- 0.3328995704650879 seconds for one epoch ---
--- 3.520831346511841 seconds for one epoch ---
--- 0.3374295234680176 seconds for one epoch ---
--- 3.4843366146087646 seconds for one epoch ---
--- 0.31865406036376953 seconds for one epoch ---
--- 3.4819893836975098 seconds for one epoch ---
--- 0.32932353019714355 seconds for one epoch ---
--- 3.452662706375122 seconds for one epoch ---
--- 0.3224165439605713 seconds for one epoch ---
--- 3.5383341312408447 seconds for one epoch ---
--- 0.33423805236816406 seconds for one epoch ---
--- 3.4837870597839355 seconds for one epoch ---
--- 0.33269786834716797 seconds for one epoch ---
--- 3.4758551120758057 seconds for one epoch ---
--- 0.32419729232788086 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995048]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.877583]
 [  0.      ]]
--- 0.2669229507446289 seconds for one epoch ---
Epoch 7125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3054.68603515625, (1346.0298, 0.9906649, 1707.1764, 0.48925686)
   validation loss 814.08203125, (544.66425, 0.53571886, 268.3928, 0.48925686)
decoder loss ratio: 21101.238453, decoder SINDy loss  ratio: 0.579364
--- 0.3077530860900879 seconds for one epoch ---
--- 3.4685747623443604 seconds for one epoch ---
--- 0.33906078338623047 seconds for one epoch ---
--- 3.471341371536255 seconds for one epoch ---
--- 0.33351778984069824 seconds for one epoch ---
--- 3.5393686294555664 seconds for one epoch ---
--- 0.3391880989074707 seconds for one epoch ---
--- 3.5376927852630615 seconds for one epoch ---
--- 0.3265187740325928 seconds for one epoch ---
--- 3.5472588539123535 seconds for one epoch ---
--- 0.33856654167175293 seconds for one epoch ---
--- 3.494677782058716 seconds for one epoch ---
--- 0.3231923580169678 seconds for one epoch ---
--- 3.482090473175049 seconds for one epoch ---
--- 0.33385634422302246 seconds for one epoch ---
--- 3.5403294563293457 seconds for one epoch ---
--- 0.32703542709350586 seconds for one epoch ---
--- 3.5671117305755615 seconds for one epoch ---
--- 0.33292102813720703 seconds for one epoch ---
--- 3.5934829711914062 seconds for one epoch ---
--- 0.326340913772583 seconds for one epoch ---
--- 3.569741725921631 seconds for one epoch ---
--- 0.33152055740356445 seconds for one epoch ---
--- 3.5116310119628906 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995048]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.881382]
 [ -0.      ]]
--- 0.3244304656982422 seconds for one epoch ---
Epoch 7150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1434.8221435546875, (738.53766, 1.6311485, 694.1639, 0.4893693)
   validation loss 847.5355224609375, (566.8116, 0.5313499, 279.7032, 0.4893693)
decoder loss ratio: 21959.264811, decoder SINDy loss  ratio: 0.603779
--- 0.27453088760375977 seconds for one epoch ---
--- 0.334700345993042 seconds for one epoch ---
--- 3.5615179538726807 seconds for one epoch ---
--- 0.31983494758605957 seconds for one epoch ---
--- 3.492229700088501 seconds for one epoch ---
--- 0.33547139167785645 seconds for one epoch ---
--- 3.4947197437286377 seconds for one epoch ---
--- 0.33222222328186035 seconds for one epoch ---
--- 3.572469472885132 seconds for one epoch ---
--- 0.3413875102996826 seconds for one epoch ---
--- 3.506990909576416 seconds for one epoch ---
--- 0.32201457023620605 seconds for one epoch ---
--- 3.4971139430999756 seconds for one epoch ---
--- 0.3202502727508545 seconds for one epoch ---
--- 3.5028469562530518 seconds for one epoch ---
--- 0.3339352607727051 seconds for one epoch ---
--- 3.512690782546997 seconds for one epoch ---
--- 0.33876466751098633 seconds for one epoch ---
--- 3.5934014320373535 seconds for one epoch ---
--- 0.3308675289154053 seconds for one epoch ---
--- 3.5174057483673096 seconds for one epoch ---
--- 0.3215367794036865 seconds for one epoch ---
--- 3.578947067260742 seconds for one epoch ---
--- 0.33527350425720215 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995048]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.887445]
 [ -0.      ]]
--- 0.2507784366607666 seconds for one epoch ---
Epoch 7175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2272.21337890625, (1059.9172, 1.0037832, 1210.8029, 0.4895009)
   validation loss 786.424072265625, (510.73135, 0.54092056, 274.6623, 0.4895009)
decoder loss ratio: 19786.619313, decoder SINDy loss  ratio: 0.592897
--- 0.3267805576324463 seconds for one epoch ---
--- 3.562366008758545 seconds for one epoch ---
--- 0.3243381977081299 seconds for one epoch ---
--- 3.623588800430298 seconds for one epoch ---
--- 0.333843469619751 seconds for one epoch ---
--- 3.567054510116577 seconds for one epoch ---
--- 0.3354909420013428 seconds for one epoch ---
--- 3.548997163772583 seconds for one epoch ---
--- 0.3288300037384033 seconds for one epoch ---
--- 3.6461377143859863 seconds for one epoch ---
--- 0.33027148246765137 seconds for one epoch ---
--- 3.6205966472625732 seconds for one epoch ---
--- 0.3342115879058838 seconds for one epoch ---
--- 3.5928707122802734 seconds for one epoch ---
--- 0.34274768829345703 seconds for one epoch ---
--- 3.5714704990386963 seconds for one epoch ---
--- 0.3325662612915039 seconds for one epoch ---
--- 3.5611305236816406 seconds for one epoch ---
--- 0.32733726501464844 seconds for one epoch ---
--- 3.6425771713256836 seconds for one epoch ---
--- 0.32626819610595703 seconds for one epoch ---
--- 3.560828924179077 seconds for one epoch ---
--- 0.33524203300476074 seconds for one epoch ---
--- 3.642380475997925 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995045]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.889343]
 [  0.      ]]
--- 0.3096740245819092 seconds for one epoch ---
Epoch 7200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3782.970458984375, (1612.0005, 0.89214206, 2169.5884, 0.48957467)
   validation loss 860.1425170898438, (574.8982, 0.5429017, 284.21188, 0.48957467)
decoder loss ratio: 22272.554078, decoder SINDy loss  ratio: 0.613511
--- 0.2745819091796875 seconds for one epoch ---
--- 0.33014702796936035 seconds for one epoch ---
--- 3.6303625106811523 seconds for one epoch ---
--- 0.3209850788116455 seconds for one epoch ---
--- 3.550360679626465 seconds for one epoch ---
--- 0.33397459983825684 seconds for one epoch ---
--- 3.635164260864258 seconds for one epoch ---
--- 0.3337235450744629 seconds for one epoch ---
--- 3.6232314109802246 seconds for one epoch ---
--- 0.32930636405944824 seconds for one epoch ---
--- 3.6552774906158447 seconds for one epoch ---
--- 0.3368062973022461 seconds for one epoch ---
--- 3.6428048610687256 seconds for one epoch ---
--- 0.3266761302947998 seconds for one epoch ---
--- 3.5841593742370605 seconds for one epoch ---
--- 0.33153867721557617 seconds for one epoch ---
--- 3.587993621826172 seconds for one epoch ---
--- 0.3303251266479492 seconds for one epoch ---
--- 3.636423349380493 seconds for one epoch ---
--- 0.32821059226989746 seconds for one epoch ---
--- 3.644710063934326 seconds for one epoch ---
--- 0.32913923263549805 seconds for one epoch ---
--- 3.570753574371338 seconds for one epoch ---
--- 0.3185586929321289 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995049]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.894651]
 [ -0.      ]]
--- 0.26631760597229004 seconds for one epoch ---
Epoch 7225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6514.90380859375, (2332.357, 3.3162186, 4178.7407, 0.48973265)
   validation loss 825.2732543945312, (544.53406, 0.5437836, 279.7057, 0.48973265)
decoder loss ratio: 21096.194745, decoder SINDy loss  ratio: 0.603784
--- 0.3126232624053955 seconds for one epoch ---
--- 3.641287088394165 seconds for one epoch ---
--- 0.3293313980102539 seconds for one epoch ---
--- 3.6102094650268555 seconds for one epoch ---
--- 0.33238649368286133 seconds for one epoch ---
--- 3.5596766471862793 seconds for one epoch ---
--- 0.3306429386138916 seconds for one epoch ---
--- 3.6180367469787598 seconds for one epoch ---
--- 0.3222193717956543 seconds for one epoch ---
--- 3.6199936866760254 seconds for one epoch ---
--- 0.3298487663269043 seconds for one epoch ---
--- 3.6267850399017334 seconds for one epoch ---
--- 0.32035136222839355 seconds for one epoch ---
--- 3.5764365196228027 seconds for one epoch ---
--- 0.3271522521972656 seconds for one epoch ---
--- 3.6498312950134277 seconds for one epoch ---
--- 0.33020997047424316 seconds for one epoch ---
--- 3.5597317218780518 seconds for one epoch ---
--- 0.3300135135650635 seconds for one epoch ---
--- 3.641951322555542 seconds for one epoch ---
--- 0.3300609588623047 seconds for one epoch ---
--- 3.6435484886169434 seconds for one epoch ---
--- 0.3218576908111572 seconds for one epoch ---
--- 3.571915626525879 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995045]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.898176]
 [  0.      ]]
--- 0.3002026081085205 seconds for one epoch ---
Epoch 7250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1319.5286865234375, (691.2477, 1.477732, 626.3135, 0.48983297)
   validation loss 839.6657104492188, (567.42175, 0.5541792, 271.19998, 0.48983297)
decoder loss ratio: 21982.903796, decoder SINDy loss  ratio: 0.585423
--- 0.2739267349243164 seconds for one epoch ---
--- 0.3326997756958008 seconds for one epoch ---
--- 3.597830295562744 seconds for one epoch ---
--- 0.33803749084472656 seconds for one epoch ---
--- 3.6559669971466064 seconds for one epoch ---
--- 0.32849669456481934 seconds for one epoch ---
--- 3.6103334426879883 seconds for one epoch ---
--- 0.32639312744140625 seconds for one epoch ---
--- 3.5655195713043213 seconds for one epoch ---
--- 0.3349454402923584 seconds for one epoch ---
--- 3.6530256271362305 seconds for one epoch ---
--- 0.3290750980377197 seconds for one epoch ---
--- 3.6268417835235596 seconds for one epoch ---
--- 0.33032894134521484 seconds for one epoch ---
--- 3.604952335357666 seconds for one epoch ---
--- 0.326188325881958 seconds for one epoch ---
--- 3.668497323989868 seconds for one epoch ---
--- 0.32361912727355957 seconds for one epoch ---
--- 3.6040878295898438 seconds for one epoch ---
--- 0.3266880512237549 seconds for one epoch ---
--- 3.6709413528442383 seconds for one epoch ---
--- 0.3337571620941162 seconds for one epoch ---
--- 3.592273712158203 seconds for one epoch ---
--- 0.3330252170562744 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995047]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.902205]
 [  0.      ]]
--- 0.26494717597961426 seconds for one epoch ---
Epoch 7275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3653.521240234375, (1616.0972, 5.2413626, 2031.6927, 0.48992425)
   validation loss 817.68310546875, (545.20667, 0.55409527, 271.43243, 0.48992425)
decoder loss ratio: 21122.252724, decoder SINDy loss  ratio: 0.585925
--- 0.3143584728240967 seconds for one epoch ---
--- 3.6628875732421875 seconds for one epoch ---
--- 0.31646227836608887 seconds for one epoch ---
--- 3.6533267498016357 seconds for one epoch ---
--- 0.3342111110687256 seconds for one epoch ---
--- 3.575888156890869 seconds for one epoch ---
--- 0.3308570384979248 seconds for one epoch ---
--- 3.6131069660186768 seconds for one epoch ---
--- 0.3360438346862793 seconds for one epoch ---
--- 3.646190643310547 seconds for one epoch ---
--- 0.3349580764770508 seconds for one epoch ---
--- 3.5969622135162354 seconds for one epoch ---
--- 0.3299446105957031 seconds for one epoch ---
--- 3.6705918312072754 seconds for one epoch ---
--- 0.3327820301055908 seconds for one epoch ---
--- 3.600181818008423 seconds for one epoch ---
--- 0.33791661262512207 seconds for one epoch ---
--- 3.638939380645752 seconds for one epoch ---
--- 0.33963799476623535 seconds for one epoch ---
--- 3.6018338203430176 seconds for one epoch ---
--- 0.3316648006439209 seconds for one epoch ---
--- 3.6681220531463623 seconds for one epoch ---
--- 0.32755303382873535 seconds for one epoch ---
--- 3.66867995262146 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995053]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.907831]
 [ -0.      ]]
--- 0.3162729740142822 seconds for one epoch ---
Epoch 7300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4199.556640625, (1936.3634, 1.5376382, 2261.1655, 0.49006978)
   validation loss 953.1954956054688, (661.0366, 0.52943116, 291.13937, 0.49006978)
decoder loss ratio: 25609.706311, decoder SINDy loss  ratio: 0.628465
--- 0.2909884452819824 seconds for one epoch ---
--- 0.3394021987915039 seconds for one epoch ---
--- 3.6672205924987793 seconds for one epoch ---
--- 0.3342776298522949 seconds for one epoch ---
--- 3.6744656562805176 seconds for one epoch ---
--- 0.3277878761291504 seconds for one epoch ---
--- 3.6657345294952393 seconds for one epoch ---
--- 0.33585166931152344 seconds for one epoch ---
--- 3.613461971282959 seconds for one epoch ---
--- 0.3352069854736328 seconds for one epoch ---
--- 3.685436725616455 seconds for one epoch ---
--- 0.3265101909637451 seconds for one epoch ---
--- 3.6255245208740234 seconds for one epoch ---
--- 0.3251020908355713 seconds for one epoch ---
--- 3.6922614574432373 seconds for one epoch ---
--- 0.3176717758178711 seconds for one epoch ---
--- 3.684551477432251 seconds for one epoch ---
--- 0.321779727935791 seconds for one epoch ---
--- 3.6864490509033203 seconds for one epoch ---
--- 0.32871079444885254 seconds for one epoch ---
--- 3.6862494945526123 seconds for one epoch ---
--- 0.3332490921020508 seconds for one epoch ---
--- 3.69650936126709 seconds for one epoch ---
--- 0.32638001441955566 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995054]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.911938]
 [ -0.      ]]
--- 0.260089635848999 seconds for one epoch ---
Epoch 7325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2882.45947265625, (1078.7107, 1.6358976, 1801.6228, 0.49018022)
   validation loss 918.1350708007812, (648.6644, 0.5582203, 268.4222, 0.49018022)
decoder loss ratio: 25130.386099, decoder SINDy loss  ratio: 0.579427
--- 0.2929999828338623 seconds for one epoch ---
--- 3.6177964210510254 seconds for one epoch ---
--- 0.32869482040405273 seconds for one epoch ---
--- 3.6141469478607178 seconds for one epoch ---
--- 0.3331151008605957 seconds for one epoch ---
--- 3.7106213569641113 seconds for one epoch ---
--- 0.32557106018066406 seconds for one epoch ---
--- 3.6262640953063965 seconds for one epoch ---
--- 0.32799625396728516 seconds for one epoch ---
--- 3.6420035362243652 seconds for one epoch ---
--- 0.3301231861114502 seconds for one epoch ---
--- 3.6908419132232666 seconds for one epoch ---
--- 0.3277294635772705 seconds for one epoch ---
--- 3.7079110145568848 seconds for one epoch ---
--- 0.3260486125946045 seconds for one epoch ---
--- 3.63875675201416 seconds for one epoch ---
--- 0.3312954902648926 seconds for one epoch ---
--- 3.6314857006073 seconds for one epoch ---
--- 0.3139510154724121 seconds for one epoch ---
--- 3.710494041442871 seconds for one epoch ---
--- 0.3243732452392578 seconds for one epoch ---
--- 3.7062058448791504 seconds for one epoch ---
--- 0.326509952545166 seconds for one epoch ---
--- 3.630781888961792 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950576]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.916306]
 [  0.      ]]
--- 0.2936549186706543 seconds for one epoch ---
Epoch 7350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2541.34423828125, (1325.044, 0.6464329, 1215.1636, 0.49034563)
   validation loss 810.9212646484375, (532.7054, 0.5497365, 277.17575, 0.49034563)
decoder loss ratio: 20637.931366, decoder SINDy loss  ratio: 0.598323
--- 0.2808818817138672 seconds for one epoch ---
--- 0.32506227493286133 seconds for one epoch ---
--- 3.6217572689056396 seconds for one epoch ---
--- 0.3240690231323242 seconds for one epoch ---
--- 3.7033298015594482 seconds for one epoch ---
--- 0.33308887481689453 seconds for one epoch ---
--- 3.6452436447143555 seconds for one epoch ---
--- 0.3322136402130127 seconds for one epoch ---
--- 3.71783709526062 seconds for one epoch ---
--- 0.33395910263061523 seconds for one epoch ---
--- 3.6255691051483154 seconds for one epoch ---
--- 0.3445467948913574 seconds for one epoch ---
--- 3.6447551250457764 seconds for one epoch ---
--- 0.33048439025878906 seconds for one epoch ---
--- 3.705993413925171 seconds for one epoch ---
--- 0.3254389762878418 seconds for one epoch ---
--- 3.649195909500122 seconds for one epoch ---
--- 0.335036039352417 seconds for one epoch ---
--- 3.6439385414123535 seconds for one epoch ---
--- 0.3396580219268799 seconds for one epoch ---
--- 3.7268247604370117 seconds for one epoch ---
--- 0.3292515277862549 seconds for one epoch ---
--- 3.722971200942993 seconds for one epoch ---
--- 0.3258070945739746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995065]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.920538]
 [ -0.      ]]
--- 0.2749335765838623 seconds for one epoch ---
Epoch 7375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2484.910400390625, (1538.26, 2.079467, 944.0803, 0.49042922)
   validation loss 806.0368041992188, (528.709, 0.5508538, 276.2866, 0.49042922)
decoder loss ratio: 20483.103934, decoder SINDy loss  ratio: 0.596403
--- 0.307941198348999 seconds for one epoch ---
--- 3.6342804431915283 seconds for one epoch ---
--- 0.3338479995727539 seconds for one epoch ---
--- 3.6282126903533936 seconds for one epoch ---
--- 0.3289663791656494 seconds for one epoch ---
--- 3.6396820545196533 seconds for one epoch ---
--- 0.33351564407348633 seconds for one epoch ---
--- 3.6401748657226562 seconds for one epoch ---
--- 0.3298768997192383 seconds for one epoch ---
--- 3.7083117961883545 seconds for one epoch ---
--- 0.3231790065765381 seconds for one epoch ---
--- 3.718766212463379 seconds for one epoch ---
--- 0.3298459053039551 seconds for one epoch ---
--- 3.656193971633911 seconds for one epoch ---
--- 0.3244197368621826 seconds for one epoch ---
--- 3.6438395977020264 seconds for one epoch ---
--- 0.3211338520050049 seconds for one epoch ---
--- 3.7216532230377197 seconds for one epoch ---
--- 0.31516313552856445 seconds for one epoch ---
--- 3.6519479751586914 seconds for one epoch ---
--- 0.3326990604400635 seconds for one epoch ---
--- 3.6633107662200928 seconds for one epoch ---
--- 0.317124605178833 seconds for one epoch ---
--- 3.7421300411224365 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995066]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.924318]
 [  0.      ]]
--- 0.30519676208496094 seconds for one epoch ---
Epoch 7400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2457.297607421875, (1265.3402, 0.5130121, 1190.954, 0.49052873)
   validation loss 985.6834106445312, (686.6664, 0.54891485, 297.97763, 0.49052873)
decoder loss ratio: 26602.647738, decoder SINDy loss  ratio: 0.643227
--- 0.2600722312927246 seconds for one epoch ---
--- 0.32910895347595215 seconds for one epoch ---
--- 3.7072947025299072 seconds for one epoch ---
--- 0.3192284107208252 seconds for one epoch ---
--- 3.702191114425659 seconds for one epoch ---
--- 0.3284580707550049 seconds for one epoch ---
--- 3.6490485668182373 seconds for one epoch ---
--- 0.32503795623779297 seconds for one epoch ---
--- 3.646409749984741 seconds for one epoch ---
--- 0.3295104503631592 seconds for one epoch ---
--- 3.720672130584717 seconds for one epoch ---
--- 0.33136987686157227 seconds for one epoch ---
--- 3.7086195945739746 seconds for one epoch ---
--- 0.3349928855895996 seconds for one epoch ---
--- 3.743410348892212 seconds for one epoch ---
--- 0.330585241317749 seconds for one epoch ---
--- 3.6443376541137695 seconds for one epoch ---
--- 0.32715272903442383 seconds for one epoch ---
--- 3.723646402359009 seconds for one epoch ---
--- 0.3258650302886963 seconds for one epoch ---
--- 3.715337038040161 seconds for one epoch ---
--- 0.3450145721435547 seconds for one epoch ---
--- 3.6689441204071045 seconds for one epoch ---
--- 0.32232069969177246 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995069]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.928638]
 [  0.      ]]
--- 0.2720916271209717 seconds for one epoch ---
Epoch 7425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2606.483642578125, (1267.9215, 1.2323111, 1336.8391, 0.49065143)
   validation loss 839.9982299804688, (555.42896, 0.54701555, 283.53165, 0.49065143)
decoder loss ratio: 21518.281987, decoder SINDy loss  ratio: 0.612043
--- 0.31876039505004883 seconds for one epoch ---
--- 3.6590688228607178 seconds for one epoch ---
--- 0.32091569900512695 seconds for one epoch ---
--- 3.647113800048828 seconds for one epoch ---
--- 0.32384228706359863 seconds for one epoch ---
--- 3.7514777183532715 seconds for one epoch ---
--- 0.3403818607330322 seconds for one epoch ---
--- 3.729846239089966 seconds for one epoch ---
--- 0.32582521438598633 seconds for one epoch ---
--- 3.6639838218688965 seconds for one epoch ---
--- 0.32390666007995605 seconds for one epoch ---
--- 3.6530661582946777 seconds for one epoch ---
--- 0.33263731002807617 seconds for one epoch ---
--- 3.653764009475708 seconds for one epoch ---
--- 0.32857799530029297 seconds for one epoch ---
--- 3.7247140407562256 seconds for one epoch ---
--- 0.33414435386657715 seconds for one epoch ---
--- 3.757810354232788 seconds for one epoch ---
--- 0.31804728507995605 seconds for one epoch ---
--- 3.7582733631134033 seconds for one epoch ---
--- 0.3272559642791748 seconds for one epoch ---
--- 3.761976718902588 seconds for one epoch ---
--- 0.3283553123474121 seconds for one epoch ---
--- 3.751044511795044 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995072]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.931795]
 [ -0.      ]]
--- 0.3122215270996094 seconds for one epoch ---
Epoch 7450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2003.826171875, (1007.4153, 4.539516, 991.3807, 0.49074575)
   validation loss 1025.144775390625, (713.0137, 0.53905636, 311.10126, 0.49074575)
decoder loss ratio: 27623.387495, decoder SINDy loss  ratio: 0.671556
--- 0.2783331871032715 seconds for one epoch ---
--- 0.3162379264831543 seconds for one epoch ---
--- 3.739225387573242 seconds for one epoch ---
--- 0.32569313049316406 seconds for one epoch ---
--- 3.6805474758148193 seconds for one epoch ---
--- 0.324007511138916 seconds for one epoch ---
--- 3.752641201019287 seconds for one epoch ---
--- 0.31507015228271484 seconds for one epoch ---
--- 3.7540829181671143 seconds for one epoch ---
--- 0.3305940628051758 seconds for one epoch ---
--- 3.7017030715942383 seconds for one epoch ---
--- 0.32296156883239746 seconds for one epoch ---
--- 3.7630672454833984 seconds for one epoch ---
--- 0.32915592193603516 seconds for one epoch ---
--- 3.7087981700897217 seconds for one epoch ---
--- 0.32437849044799805 seconds for one epoch ---
--- 3.7819881439208984 seconds for one epoch ---
--- 0.3212249279022217 seconds for one epoch ---
--- 3.7132554054260254 seconds for one epoch ---
--- 0.32925844192504883 seconds for one epoch ---
--- 3.7512569427490234 seconds for one epoch ---
--- 0.3234703540802002 seconds for one epoch ---
--- 3.688811779022217 seconds for one epoch ---
--- 0.33109164237976074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950755]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.935051]
 [ -0.      ]]
--- 0.257293701171875 seconds for one epoch ---
Epoch 7475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2376.07470703125, (984.1504, 1.2473599, 1390.1863, 0.49083605)
   validation loss 766.9392700195312, (496.71454, 0.56506485, 269.16882, 0.49083605)
decoder loss ratio: 19243.583559, decoder SINDy loss  ratio: 0.581039
--- 0.31711411476135254 seconds for one epoch ---
--- 3.7465648651123047 seconds for one epoch ---
--- 0.3280525207519531 seconds for one epoch ---
--- 3.68522047996521 seconds for one epoch ---
--- 0.3370249271392822 seconds for one epoch ---
--- 3.6855602264404297 seconds for one epoch ---
--- 0.3274197578430176 seconds for one epoch ---
--- 3.7499821186065674 seconds for one epoch ---
--- 0.331057071685791 seconds for one epoch ---
--- 3.7638964653015137 seconds for one epoch ---
--- 0.31752705574035645 seconds for one epoch ---
--- 3.708963394165039 seconds for one epoch ---
--- 0.31731152534484863 seconds for one epoch ---
--- 3.7725656032562256 seconds for one epoch ---
--- 0.3245885372161865 seconds for one epoch ---
--- 3.7822329998016357 seconds for one epoch ---
--- 0.33293986320495605 seconds for one epoch ---
--- 3.6952779293060303 seconds for one epoch ---
--- 0.3391118049621582 seconds for one epoch ---
--- 3.702463388442993 seconds for one epoch ---
--- 0.3317840099334717 seconds for one epoch ---
--- 3.7772581577301025 seconds for one epoch ---
--- 0.3257327079772949 seconds for one epoch ---
--- 3.7871367931365967 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995082]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.939869]
 [  0.      ]]
--- 0.2745234966278076 seconds for one epoch ---
Epoch 7500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2136.56298828125, (1113.6802, 0.8490829, 1021.54266, 0.49096966)
   validation loss 864.863525390625, (576.89764, 0.54748523, 286.9274, 0.49096966)
decoder loss ratio: 22350.016269, decoder SINDy loss  ratio: 0.619373
THRESHOLDING: 1 active coefficients
--- 0.26943349838256836 seconds for one epoch ---
--- 0.32665205001831055 seconds for one epoch ---
--- 3.682541847229004 seconds for one epoch ---
--- 0.312485933303833 seconds for one epoch ---
--- 3.7539212703704834 seconds for one epoch ---
--- 0.3288872241973877 seconds for one epoch ---
--- 3.7645130157470703 seconds for one epoch ---
--- 0.3316044807434082 seconds for one epoch ---
--- 3.68530011177063 seconds for one epoch ---
--- 0.31307220458984375 seconds for one epoch ---
--- 3.7330234050750732 seconds for one epoch ---
--- 0.33367371559143066 seconds for one epoch ---
--- 3.7135536670684814 seconds for one epoch ---
--- 0.3269479274749756 seconds for one epoch ---
--- 3.787214517593384 seconds for one epoch ---
--- 0.3309037685394287 seconds for one epoch ---
--- 3.7120156288146973 seconds for one epoch ---
--- 0.33147764205932617 seconds for one epoch ---
--- 3.7271335124969482 seconds for one epoch ---
--- 0.33331799507141113 seconds for one epoch ---
--- 3.7846455574035645 seconds for one epoch ---
--- 0.3299548625946045 seconds for one epoch ---
--- 3.7090437412261963 seconds for one epoch ---
--- 0.32916712760925293 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99950916]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.942886]
 [ -0.      ]]
--- 0.27623963356018066 seconds for one epoch ---
Epoch 7525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3588.6904296875, (1440.017, 2.9566598, 2145.2258, 0.491057)
   validation loss 744.7149047851562, (482.23578, 0.56318605, 261.42496, 0.491057)
decoder loss ratio: 18682.651269, decoder SINDy loss  ratio: 0.564323
--- 0.3121356964111328 seconds for one epoch ---
--- 3.6650710105895996 seconds for one epoch ---
--- 0.3268873691558838 seconds for one epoch ---
--- 3.711699962615967 seconds for one epoch ---
--- 0.34502267837524414 seconds for one epoch ---
--- 3.692220449447632 seconds for one epoch ---
--- 0.32846617698669434 seconds for one epoch ---
--- 3.7822024822235107 seconds for one epoch ---
--- 0.33826565742492676 seconds for one epoch ---
--- 3.7013955116271973 seconds for one epoch ---
--- 0.3287043571472168 seconds for one epoch ---
--- 3.773752450942993 seconds for one epoch ---
--- 0.3317427635192871 seconds for one epoch ---
--- 3.751154661178589 seconds for one epoch ---
--- 0.32848644256591797 seconds for one epoch ---
--- 3.7429165840148926 seconds for one epoch ---
--- 0.33943605422973633 seconds for one epoch ---
--- 3.796569585800171 seconds for one epoch ---
--- 0.3280515670776367 seconds for one epoch ---
--- 3.717285633087158 seconds for one epoch ---
--- 0.33057141304016113 seconds for one epoch ---
--- 3.8048789501190186 seconds for one epoch ---
--- 0.33553409576416016 seconds for one epoch ---
--- 3.806955099105835 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995096]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.948236]
 [  0.      ]]
--- 0.319610595703125 seconds for one epoch ---
Epoch 7550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4318.568359375, (1067.998, 4.6227417, 3245.4565, 0.49118787)
   validation loss 794.607177734375, (519.0671, 0.5521068, 274.4968, 0.49118787)
decoder loss ratio: 20109.559728, decoder SINDy loss  ratio: 0.592540
--- 0.27959680557250977 seconds for one epoch ---
--- 0.3291921615600586 seconds for one epoch ---
--- 3.7906720638275146 seconds for one epoch ---
--- 0.3304729461669922 seconds for one epoch ---
--- 3.778076648712158 seconds for one epoch ---
--- 0.3390982151031494 seconds for one epoch ---
--- 3.7950544357299805 seconds for one epoch ---
--- 0.3273007869720459 seconds for one epoch ---
--- 3.8261239528656006 seconds for one epoch ---
--- 0.3258397579193115 seconds for one epoch ---
--- 3.752279758453369 seconds for one epoch ---
--- 0.32817769050598145 seconds for one epoch ---
--- 3.8155813217163086 seconds for one epoch ---
--- 0.31729626655578613 seconds for one epoch ---
--- 3.8118584156036377 seconds for one epoch ---
--- 0.32866811752319336 seconds for one epoch ---
--- 3.798105239868164 seconds for one epoch ---
--- 0.33049917221069336 seconds for one epoch ---
--- 3.7546987533569336 seconds for one epoch ---
--- 0.3250601291656494 seconds for one epoch ---
--- 3.824045181274414 seconds for one epoch ---
--- 0.33373165130615234 seconds for one epoch ---
--- 3.746382474899292 seconds for one epoch ---
--- 0.34908008575439453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951035]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.952106]
 [  0.      ]]
--- 0.2704734802246094 seconds for one epoch ---
Epoch 7575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1907.886962890625, (929.95026, 1.2416966, 976.2037, 0.4912924)
   validation loss 778.9472045898438, (503.49945, 0.5512052, 274.40524, 0.4912924)
decoder loss ratio: 19506.442833, decoder SINDy loss  ratio: 0.592342
--- 0.30031466484069824 seconds for one epoch ---
--- 3.7502763271331787 seconds for one epoch ---
--- 0.33112263679504395 seconds for one epoch ---
--- 3.812152624130249 seconds for one epoch ---
--- 0.32140517234802246 seconds for one epoch ---
--- 3.8189480304718018 seconds for one epoch ---
--- 0.3435502052307129 seconds for one epoch ---
--- 3.7654449939727783 seconds for one epoch ---
--- 0.33115053176879883 seconds for one epoch ---
--- 3.7466156482696533 seconds for one epoch ---
--- 0.3292348384857178 seconds for one epoch ---
--- 3.7527427673339844 seconds for one epoch ---
--- 0.3241093158721924 seconds for one epoch ---
--- 3.820971727371216 seconds for one epoch ---
--- 0.33034467697143555 seconds for one epoch ---
--- 3.8374760150909424 seconds for one epoch ---
--- 0.32972264289855957 seconds for one epoch ---
--- 3.748289108276367 seconds for one epoch ---
--- 0.32509732246398926 seconds for one epoch ---
--- 3.8360538482666016 seconds for one epoch ---
--- 0.33008432388305664 seconds for one epoch ---
--- 3.765838384628296 seconds for one epoch ---
--- 0.33034706115722656 seconds for one epoch ---
--- 3.8149375915527344 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995109]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.953936]
 [ -0.      ]]
--- 0.31939053535461426 seconds for one epoch ---
Epoch 7600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2741.102294921875, (1088.921, 0.84410924, 1650.8456, 0.49136668)
   validation loss 1008.0657348632812, (700.93787, 0.5501053, 306.08633, 0.49136668)
decoder loss ratio: 27155.549819, decoder SINDy loss  ratio: 0.660730
--- 0.2691459655761719 seconds for one epoch ---
--- 0.32503223419189453 seconds for one epoch ---
--- 3.8000428676605225 seconds for one epoch ---
--- 0.30605149269104004 seconds for one epoch ---
--- 3.7566418647766113 seconds for one epoch ---
--- 0.3260228633880615 seconds for one epoch ---
--- 3.773230791091919 seconds for one epoch ---
--- 0.33381104469299316 seconds for one epoch ---
--- 3.746652126312256 seconds for one epoch ---
--- 0.3239259719848633 seconds for one epoch ---
--- 3.7792890071868896 seconds for one epoch ---
--- 0.32835865020751953 seconds for one epoch ---
--- 3.8449199199676514 seconds for one epoch ---
--- 0.31281566619873047 seconds for one epoch ---
--- 3.754667043685913 seconds for one epoch ---
--- 0.3300282955169678 seconds for one epoch ---
--- 3.842257261276245 seconds for one epoch ---
--- 0.32241106033325195 seconds for one epoch ---
--- 3.7410666942596436 seconds for one epoch ---
--- 0.3279867172241211 seconds for one epoch ---
--- 3.8352015018463135 seconds for one epoch ---
--- 0.3286857604980469 seconds for one epoch ---
--- 3.7793362140655518 seconds for one epoch ---
--- 0.3338940143585205 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951196]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.957636]
 [ -0.      ]]
--- 0.2663383483886719 seconds for one epoch ---
Epoch 7625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5169.759765625, (2402.7688, 2.1340346, 2764.3652, 0.491464)
   validation loss 925.21923828125, (630.85077, 0.55806476, 293.319, 0.491464)
decoder loss ratio: 24440.253998, decoder SINDy loss  ratio: 0.633170
--- 0.31502723693847656 seconds for one epoch ---
--- 3.7652697563171387 seconds for one epoch ---
--- 0.3253145217895508 seconds for one epoch ---
--- 3.7575690746307373 seconds for one epoch ---
--- 0.3221709728240967 seconds for one epoch ---
--- 3.857445001602173 seconds for one epoch ---
--- 0.3133425712585449 seconds for one epoch ---
--- 3.749485731124878 seconds for one epoch ---
--- 0.3205389976501465 seconds for one epoch ---
--- 3.851759672164917 seconds for one epoch ---
--- 0.32414889335632324 seconds for one epoch ---
--- 3.8413772583007812 seconds for one epoch ---
--- 0.32506728172302246 seconds for one epoch ---
--- 3.847632646560669 seconds for one epoch ---
--- 0.33667445182800293 seconds for one epoch ---
--- 3.761277198791504 seconds for one epoch ---
--- 0.3198208808898926 seconds for one epoch ---
--- 3.8513684272766113 seconds for one epoch ---
--- 0.3354175090789795 seconds for one epoch ---
--- 3.862712860107422 seconds for one epoch ---
--- 0.32894229888916016 seconds for one epoch ---
--- 3.7627451419830322 seconds for one epoch ---
--- 0.3276546001434326 seconds for one epoch ---
--- 3.789370536804199 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951226]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-18.96007]
 [  0.     ]]
--- 0.31095218658447266 seconds for one epoch ---
Epoch 7650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2854.403564453125, (1219.5685, 2.1338704, 1632.2098, 0.491515)
   validation loss 1031.86474609375, (723.61945, 0.55168235, 307.20212, 0.491515)
decoder loss ratio: 28034.273589, decoder SINDy loss  ratio: 0.663139
--- 0.28455090522766113 seconds for one epoch ---
--- 0.33597493171691895 seconds for one epoch ---
--- 3.8541696071624756 seconds for one epoch ---
--- 0.32509303092956543 seconds for one epoch ---
--- 3.8368968963623047 seconds for one epoch ---
--- 0.33141636848449707 seconds for one epoch ---
--- 3.7491090297698975 seconds for one epoch ---
--- 0.32514238357543945 seconds for one epoch ---
--- 3.781237840652466 seconds for one epoch ---
--- 0.3320906162261963 seconds for one epoch ---
--- 3.865993022918701 seconds for one epoch ---
--- 0.3285195827484131 seconds for one epoch ---
--- 3.8496315479278564 seconds for one epoch ---
--- 0.33263564109802246 seconds for one epoch ---
--- 3.7843523025512695 seconds for one epoch ---
--- 0.3276784420013428 seconds for one epoch ---
--- 3.8522589206695557 seconds for one epoch ---
--- 0.3227427005767822 seconds for one epoch ---
--- 3.848605155944824 seconds for one epoch ---
--- 0.330211877822876 seconds for one epoch ---
--- 3.768977403640747 seconds for one epoch ---
--- 0.34004950523376465 seconds for one epoch ---
--- 3.8566946983337402 seconds for one epoch ---
--- 0.3287088871002197 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999513]
 [0.      ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-18.96384]
 [ -0.     ]]
--- 0.28004908561706543 seconds for one epoch ---
Epoch 7675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2202.51171875, (970.15894, 2.143306, 1229.7178, 0.49162802)
   validation loss 797.7743530273438, (522.99207, 0.56275743, 273.72794, 0.49162802)
decoder loss ratio: 20261.620569, decoder SINDy loss  ratio: 0.590880
--- 0.30420780181884766 seconds for one epoch ---
--- 3.787198305130005 seconds for one epoch ---
--- 0.3245511054992676 seconds for one epoch ---
--- 3.8327441215515137 seconds for one epoch ---
--- 0.3413727283477783 seconds for one epoch ---
--- 3.794926643371582 seconds for one epoch ---
--- 0.3291904926300049 seconds for one epoch ---
--- 3.8693737983703613 seconds for one epoch ---
--- 0.31394290924072266 seconds for one epoch ---
--- 3.8630807399749756 seconds for one epoch ---
--- 0.3324010372161865 seconds for one epoch ---
--- 3.7620158195495605 seconds for one epoch ---
--- 0.31243896484375 seconds for one epoch ---
--- 3.846513271331787 seconds for one epoch ---
--- 0.33416152000427246 seconds for one epoch ---
--- 3.84727144241333 seconds for one epoch ---
--- 0.33249735832214355 seconds for one epoch ---
--- 3.777958393096924 seconds for one epoch ---
--- 0.33266258239746094 seconds for one epoch ---
--- 3.871884346008301 seconds for one epoch ---
--- 0.32850050926208496 seconds for one epoch ---
--- 3.80058217048645 seconds for one epoch ---
--- 0.3276989459991455 seconds for one epoch ---
--- 3.7804267406463623 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995134]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.965681]
 [  0.      ]]
--- 0.2847933769226074 seconds for one epoch ---
Epoch 7700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3894.288330078125, (880.6935, 2.3060172, 3010.797, 0.49169445)
   validation loss 912.3843383789062, (620.2407, 0.55434746, 291.0976, 0.49169445)
decoder loss ratio: 24029.202381, decoder SINDy loss  ratio: 0.628375
--- 0.2806103229522705 seconds for one epoch ---
--- 0.33692169189453125 seconds for one epoch ---
--- 3.853888750076294 seconds for one epoch ---
--- 0.3132469654083252 seconds for one epoch ---
--- 3.781860828399658 seconds for one epoch ---
--- 0.3332250118255615 seconds for one epoch ---
--- 3.799834728240967 seconds for one epoch ---
--- 0.33867335319519043 seconds for one epoch ---
--- 3.882038116455078 seconds for one epoch ---
--- 0.3299369812011719 seconds for one epoch ---
--- 3.886165142059326 seconds for one epoch ---
--- 0.32967686653137207 seconds for one epoch ---
--- 3.794684886932373 seconds for one epoch ---
--- 0.33049654960632324 seconds for one epoch ---
--- 3.7874181270599365 seconds for one epoch ---
--- 0.339508056640625 seconds for one epoch ---
--- 3.874993324279785 seconds for one epoch ---
--- 0.33298468589782715 seconds for one epoch ---
--- 3.7821402549743652 seconds for one epoch ---
--- 0.31004977226257324 seconds for one epoch ---
--- 3.811988353729248 seconds for one epoch ---
--- 0.3340282440185547 seconds for one epoch ---
--- 3.8049843311309814 seconds for one epoch ---
--- 0.32965660095214844 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995142]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.969683]
 [  0.      ]]
--- 0.2684340476989746 seconds for one epoch ---
Epoch 7725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2243.5244140625, (1148.5061, 0.5475748, 1093.979, 0.49177906)
   validation loss 1042.8673095703125, (739.6563, 0.5479837, 302.17123, 0.49177906)
decoder loss ratio: 28655.569589, decoder SINDy loss  ratio: 0.652279
--- 0.32320189476013184 seconds for one epoch ---
--- 3.8005707263946533 seconds for one epoch ---
--- 0.3275482654571533 seconds for one epoch ---
--- 3.8019869327545166 seconds for one epoch ---
--- 0.3258333206176758 seconds for one epoch ---
--- 3.807966709136963 seconds for one epoch ---
--- 0.3275594711303711 seconds for one epoch ---
--- 3.8819539546966553 seconds for one epoch ---
--- 0.32912707328796387 seconds for one epoch ---
--- 3.8701260089874268 seconds for one epoch ---
--- 0.31837964057922363 seconds for one epoch ---
--- 3.7964186668395996 seconds for one epoch ---
--- 0.33376121520996094 seconds for one epoch ---
--- 3.8196802139282227 seconds for one epoch ---
--- 0.34183716773986816 seconds for one epoch ---
--- 3.812323808670044 seconds for one epoch ---
--- 0.32979559898376465 seconds for one epoch ---
--- 3.8191211223602295 seconds for one epoch ---
--- 0.3306872844696045 seconds for one epoch ---
--- 3.8418588638305664 seconds for one epoch ---
--- 0.3269200325012207 seconds for one epoch ---
--- 3.8371098041534424 seconds for one epoch ---
--- 0.337723970413208 seconds for one epoch ---
--- 3.8638548851013184 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995157]
 [0.       ]]
[[  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [-18.9734]
 [ -0.    ]]
--- 0.3124098777770996 seconds for one epoch ---
Epoch 7750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4377.26806640625, (1592.7084, 6.7672725, 2777.3008, 0.49191308)
   validation loss 859.77197265625, (569.92523, 0.5541812, 288.80057, 0.49191308)
decoder loss ratio: 22079.892919, decoder SINDy loss  ratio: 0.623417
--- 0.2859048843383789 seconds for one epoch ---
--- 0.339139461517334 seconds for one epoch ---
--- 3.9319560527801514 seconds for one epoch ---
--- 0.3452136516571045 seconds for one epoch ---
--- 3.8522260189056396 seconds for one epoch ---
--- 0.33666157722473145 seconds for one epoch ---
--- 3.909108877182007 seconds for one epoch ---
--- 0.3210713863372803 seconds for one epoch ---
--- 3.9211196899414062 seconds for one epoch ---
--- 0.3344287872314453 seconds for one epoch ---
--- 3.9112389087677 seconds for one epoch ---
--- 0.338726282119751 seconds for one epoch ---
--- 3.874484062194824 seconds for one epoch ---
--- 0.33185839653015137 seconds for one epoch ---
--- 3.8593904972076416 seconds for one epoch ---
--- 0.34011006355285645 seconds for one epoch ---
--- 3.8617541790008545 seconds for one epoch ---
--- 0.3377079963684082 seconds for one epoch ---
--- 3.856168746948242 seconds for one epoch ---
--- 0.3348667621612549 seconds for one epoch ---
--- 3.937494993209839 seconds for one epoch ---
--- 0.3325388431549072 seconds for one epoch ---
--- 3.930565595626831 seconds for one epoch ---
--- 0.33565735816955566 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951637]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.976252]
 [ -0.      ]]
--- 0.2698485851287842 seconds for one epoch ---
Epoch 7775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3881.00927734375, (1904.9491, 1.0393695, 1974.5288, 0.4919736)
   validation loss 811.385009765625, (533.9404, 0.5705833, 276.3821, 0.4919736)
decoder loss ratio: 20685.779207, decoder SINDy loss  ratio: 0.596610
--- 0.3139803409576416 seconds for one epoch ---
--- 3.870891571044922 seconds for one epoch ---
--- 0.3307175636291504 seconds for one epoch ---
--- 3.9336891174316406 seconds for one epoch ---
--- 0.31711721420288086 seconds for one epoch ---
--- 3.943695068359375 seconds for one epoch ---
--- 0.3309357166290283 seconds for one epoch ---
--- 3.951833963394165 seconds for one epoch ---
--- 0.3367347717285156 seconds for one epoch ---
--- 3.95766282081604 seconds for one epoch ---
--- 0.328693151473999 seconds for one epoch ---
--- 3.888469934463501 seconds for one epoch ---
--- 0.32360124588012695 seconds for one epoch ---
--- 3.889702796936035 seconds for one epoch ---
--- 0.32422327995300293 seconds for one epoch ---
--- 3.8722753524780273 seconds for one epoch ---
--- 0.3387789726257324 seconds for one epoch ---
--- 3.929866313934326 seconds for one epoch ---
--- 0.32923436164855957 seconds for one epoch ---
--- 3.866814613342285 seconds for one epoch ---
--- 0.3300948143005371 seconds for one epoch ---
--- 3.9462711811065674 seconds for one epoch ---
--- 0.32763099670410156 seconds for one epoch ---
--- 3.9526355266571045 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995172]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.97876]
 [  0.     ]]
--- 0.31320881843566895 seconds for one epoch ---
Epoch 7800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2234.906494140625, (944.13855, 1.9933839, 1288.2826, 0.49201408)
   validation loss 753.2987670898438, (483.7559, 0.56625026, 268.48465, 0.49201408)
decoder loss ratio: 18741.543012, decoder SINDy loss  ratio: 0.579562
--- 0.27756619453430176 seconds for one epoch ---
--- 0.3268120288848877 seconds for one epoch ---
--- 3.932828664779663 seconds for one epoch ---
--- 0.32814669609069824 seconds for one epoch ---
--- 3.8722479343414307 seconds for one epoch ---
--- 0.32050633430480957 seconds for one epoch ---
--- 3.8592872619628906 seconds for one epoch ---
--- 0.33063793182373047 seconds for one epoch ---
--- 3.8950388431549072 seconds for one epoch ---
--- 0.33357858657836914 seconds for one epoch ---
--- 3.927990674972534 seconds for one epoch ---
--- 0.3240480422973633 seconds for one epoch ---
--- 3.942328929901123 seconds for one epoch ---
--- 0.3316783905029297 seconds for one epoch ---
--- 3.939366340637207 seconds for one epoch ---
--- 0.32526612281799316 seconds for one epoch ---
--- 3.9352164268493652 seconds for one epoch ---
--- 0.33602118492126465 seconds for one epoch ---
--- 3.872072458267212 seconds for one epoch ---
--- 0.3145880699157715 seconds for one epoch ---
--- 3.977602243423462 seconds for one epoch ---
--- 0.32210755348205566 seconds for one epoch ---
--- 3.9507360458374023 seconds for one epoch ---
--- 0.3386495113372803 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951804]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-18.980137]
 [ -0.      ]]
--- 0.2689650058746338 seconds for one epoch ---
Epoch 7825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1659.3409423828125, (862.6197, 1.2849349, 794.9443, 0.49209824)
   validation loss 786.8154296875, (508.4555, 0.57125926, 277.29654, 0.49209824)
decoder loss ratio: 19698.448996, decoder SINDy loss  ratio: 0.598584
--- 0.3158271312713623 seconds for one epoch ---
--- 3.8951303958892822 seconds for one epoch ---
--- 0.3317580223083496 seconds for one epoch ---
--- 3.865100860595703 seconds for one epoch ---
--- 0.32503819465637207 seconds for one epoch ---
--- 3.944822311401367 seconds for one epoch ---
--- 0.3319582939147949 seconds for one epoch ---
--- 3.864276647567749 seconds for one epoch ---
--- 0.3266022205352783 seconds for one epoch ---
--- 3.955082654953003 seconds for one epoch ---
--- 0.32405591011047363 seconds for one epoch ---
--- 3.9363555908203125 seconds for one epoch ---
--- 0.322063684463501 seconds for one epoch ---
--- 3.87337327003479 seconds for one epoch ---
--- 0.33362793922424316 seconds for one epoch ---
--- 3.9000117778778076 seconds for one epoch ---
--- 0.33823513984680176 seconds for one epoch ---
--- 3.890198230743408 seconds for one epoch ---
--- 0.3290698528289795 seconds for one epoch ---
--- 3.9034414291381836 seconds for one epoch ---
--- 0.32736968994140625 seconds for one epoch ---
--- 3.968050718307495 seconds for one epoch ---
--- 0.32086682319641113 seconds for one epoch ---
--- 3.980259656906128 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951905]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.984953]
 [  0.      ]]
--- 0.3234720230102539 seconds for one epoch ---
Epoch 7850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4245.462890625, (1603.8511, 3.205552, 2637.9143, 0.49221775)
   validation loss 924.2642822265625, (628.10834, 0.5586634, 295.10513, 0.49221775)
decoder loss ratio: 24334.007435, decoder SINDy loss  ratio: 0.637026
--- 0.288135290145874 seconds for one epoch ---
--- 0.3266587257385254 seconds for one epoch ---
--- 3.952932834625244 seconds for one epoch ---
--- 0.32819104194641113 seconds for one epoch ---
--- 3.89540696144104 seconds for one epoch ---
--- 0.33342957496643066 seconds for one epoch ---
--- 3.957442283630371 seconds for one epoch ---
--- 0.3366847038269043 seconds for one epoch ---
--- 3.9068665504455566 seconds for one epoch ---
--- 0.33367490768432617 seconds for one epoch ---
--- 4.009890794754028 seconds for one epoch ---
--- 0.3383321762084961 seconds for one epoch ---
--- 3.9834256172180176 seconds for one epoch ---
--- 0.3352851867675781 seconds for one epoch ---
--- 3.987837791442871 seconds for one epoch ---
--- 0.3288142681121826 seconds for one epoch ---
--- 3.892334461212158 seconds for one epoch ---
--- 0.33098626136779785 seconds for one epoch ---
--- 3.8901889324188232 seconds for one epoch ---
--- 0.337963342666626 seconds for one epoch ---
--- 3.8957018852233887 seconds for one epoch ---
--- 0.3236677646636963 seconds for one epoch ---
--- 3.9815220832824707 seconds for one epoch ---
--- 0.33939409255981445 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952006]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.987198]
 [  0.      ]]
--- 0.2689054012298584 seconds for one epoch ---
Epoch 7875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3201.061279296875, (1126.9408, 3.137623, 2070.4907, 0.49229524)
   validation loss 1173.1981201171875, (849.70154, 0.5640724, 322.4402, 0.49229524)
decoder loss ratio: 32918.912732, decoder SINDy loss  ratio: 0.696032
--- 0.304107666015625 seconds for one epoch ---
--- 4.000767230987549 seconds for one epoch ---
--- 0.326444149017334 seconds for one epoch ---
--- 3.887707233428955 seconds for one epoch ---
--- 0.3384895324707031 seconds for one epoch ---
--- 3.89939284324646 seconds for one epoch ---
--- 0.32077479362487793 seconds for one epoch ---
--- 3.969745635986328 seconds for one epoch ---
--- 0.31552958488464355 seconds for one epoch ---
--- 3.887326717376709 seconds for one epoch ---
--- 0.33487749099731445 seconds for one epoch ---
--- 3.9154317378997803 seconds for one epoch ---
--- 0.33745503425598145 seconds for one epoch ---
--- 3.9318528175354004 seconds for one epoch ---
--- 0.3346843719482422 seconds for one epoch ---
--- 3.9666147232055664 seconds for one epoch ---
--- 0.32798290252685547 seconds for one epoch ---
--- 3.912691354751587 seconds for one epoch ---
--- 0.3257467746734619 seconds for one epoch ---
--- 3.959487199783325 seconds for one epoch ---
--- 0.3276500701904297 seconds for one epoch ---
--- 3.9938995838165283 seconds for one epoch ---
--- 0.3265872001647949 seconds for one epoch ---
--- 3.917045831680298 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952096]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.990597]
 [ -0.      ]]
--- 0.31122350692749023 seconds for one epoch ---
Epoch 7900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1249.607177734375, (784.6766, 0.46669883, 463.97165, 0.49236202)
   validation loss 861.8109741210938, (591.1254, 0.5597801, 269.6334, 0.49236202)
decoder loss ratio: 22901.225290, decoder SINDy loss  ratio: 0.582042
--- 0.26662230491638184 seconds for one epoch ---
--- 0.33071064949035645 seconds for one epoch ---
--- 3.9673075675964355 seconds for one epoch ---
--- 0.3356318473815918 seconds for one epoch ---
--- 3.9838082790374756 seconds for one epoch ---
--- 0.33113622665405273 seconds for one epoch ---
--- 3.9195668697357178 seconds for one epoch ---
--- 0.3350639343261719 seconds for one epoch ---
--- 3.9015843868255615 seconds for one epoch ---
--- 0.3389856815338135 seconds for one epoch ---
--- 3.92618727684021 seconds for one epoch ---
--- 0.32943153381347656 seconds for one epoch ---
--- 4.001446008682251 seconds for one epoch ---
--- 0.34436464309692383 seconds for one epoch ---
--- 3.9276719093322754 seconds for one epoch ---
--- 0.34533166885375977 seconds for one epoch ---
--- 3.9317102432250977 seconds for one epoch ---
--- 0.3461737632751465 seconds for one epoch ---
--- 3.927004337310791 seconds for one epoch ---
--- 0.32155370712280273 seconds for one epoch ---
--- 3.9936296939849854 seconds for one epoch ---
--- 0.32997775077819824 seconds for one epoch ---
--- 3.938668966293335 seconds for one epoch ---
--- 0.332446813583374 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952173]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.992416]
 [ -0.      ]]
--- 0.26210522651672363 seconds for one epoch ---
Epoch 7925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3652.74365234375, (1218.8505, 3.353171, 2430.0476, 0.4924179)
   validation loss 849.966064453125, (565.15753, 0.55843896, 283.7577, 0.4924179)
decoder loss ratio: 21895.183936, decoder SINDy loss  ratio: 0.612531
--- 0.2951502799987793 seconds for one epoch ---
--- 3.918050527572632 seconds for one epoch ---
--- 0.3341348171234131 seconds for one epoch ---
--- 3.9960432052612305 seconds for one epoch ---
--- 0.33364176750183105 seconds for one epoch ---
--- 4.01902437210083 seconds for one epoch ---
--- 0.3114359378814697 seconds for one epoch ---
--- 3.941521644592285 seconds for one epoch ---
--- 0.34685420989990234 seconds for one epoch ---
--- 4.020555734634399 seconds for one epoch ---
--- 0.3290255069732666 seconds for one epoch ---
--- 4.0101237297058105 seconds for one epoch ---
--- 0.32303404808044434 seconds for one epoch ---
--- 4.016470670700073 seconds for one epoch ---
--- 0.32331132888793945 seconds for one epoch ---
--- 4.017152309417725 seconds for one epoch ---
--- 0.3306739330291748 seconds for one epoch ---
--- 4.032212734222412 seconds for one epoch ---
--- 0.33135294914245605 seconds for one epoch ---
--- 3.9318416118621826 seconds for one epoch ---
--- 0.32652974128723145 seconds for one epoch ---
--- 4.032887935638428 seconds for one epoch ---
--- 0.33247828483581543 seconds for one epoch ---
--- 4.032026529312134 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995228]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.994415]
 [  0.      ]]
--- 0.31080198287963867 seconds for one epoch ---
Epoch 7950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2365.546630859375, (908.3011, 1.4836103, 1455.2695, 0.4924902)
   validation loss 1019.1658325195312, (722.53253, 0.55912995, 295.5817, 0.4924902)
decoder loss ratio: 27992.164651, decoder SINDy loss  ratio: 0.638055
--- 0.2834606170654297 seconds for one epoch ---
--- 0.3358330726623535 seconds for one epoch ---
--- 4.008625030517578 seconds for one epoch ---
--- 0.332277774810791 seconds for one epoch ---
--- 3.940553903579712 seconds for one epoch ---
--- 0.33333683013916016 seconds for one epoch ---
--- 3.92333722114563 seconds for one epoch ---
--- 0.3331263065338135 seconds for one epoch ---
--- 4.025236368179321 seconds for one epoch ---
--- 0.3437016010284424 seconds for one epoch ---
--- 3.9518380165100098 seconds for one epoch ---
--- 0.33298325538635254 seconds for one epoch ---
--- 4.022165775299072 seconds for one epoch ---
--- 0.340177059173584 seconds for one epoch ---
--- 3.954683303833008 seconds for one epoch ---
--- 0.33542943000793457 seconds for one epoch ---
--- 3.955317974090576 seconds for one epoch ---
--- 0.3370540142059326 seconds for one epoch ---
--- 4.023496866226196 seconds for one epoch ---
--- 0.3261861801147461 seconds for one epoch ---
--- 4.0444910526275635 seconds for one epoch ---
--- 0.3334078788757324 seconds for one epoch ---
--- 3.958949089050293 seconds for one epoch ---
--- 0.3344097137451172 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995225]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.997654]
 [ -0.      ]]
--- 0.2711296081542969 seconds for one epoch ---
Epoch 7975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3443.503173828125, (1787.5112, 1.2666492, 1654.233, 0.49255165)
   validation loss 760.146240234375, (490.7627, 0.5618705, 268.32916, 0.49255165)
decoder loss ratio: 19012.998818, decoder SINDy loss  ratio: 0.579226
--- 0.31205320358276367 seconds for one epoch ---
--- 3.9541540145874023 seconds for one epoch ---
--- 0.3320944309234619 seconds for one epoch ---
--- 4.026843070983887 seconds for one epoch ---
--- 0.3167579174041748 seconds for one epoch ---
--- 4.017024993896484 seconds for one epoch ---
--- 0.3398113250732422 seconds for one epoch ---
--- 4.003517150878906 seconds for one epoch ---
--- 0.9748759269714355 seconds for one epoch ---
--- 3.954991579055786 seconds for one epoch ---
--- 0.3239428997039795 seconds for one epoch ---
--- 4.024889945983887 seconds for one epoch ---
--- 0.3229515552520752 seconds for one epoch ---
--- 3.9602673053741455 seconds for one epoch ---
--- 0.31983280181884766 seconds for one epoch ---
--- 3.984938859939575 seconds for one epoch ---
--- 0.33726978302001953 seconds for one epoch ---
--- 3.9685099124908447 seconds for one epoch ---
--- 0.32677125930786133 seconds for one epoch ---
--- 4.039641618728638 seconds for one epoch ---
--- 0.33730483055114746 seconds for one epoch ---
--- 4.023618221282959 seconds for one epoch ---
--- 0.33484530448913574 seconds for one epoch ---
--- 4.046151399612427 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999522]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.999277]
 [  0.      ]]
--- 0.31353759765625 seconds for one epoch ---
Epoch 8000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2915.538818359375, (1506.4535, 3.9631112, 1404.6295, 0.4926159)
   validation loss 867.9135131835938, (584.3983, 0.56254554, 282.46002, 0.4926159)
decoder loss ratio: 22640.605300, decoder SINDy loss  ratio: 0.609730
THRESHOLDING: 1 active coefficients
--- 3.9050471782684326 seconds for one epoch ---
--- 0.32752394676208496 seconds for one epoch ---
--- 3.9629580974578857 seconds for one epoch ---
--- 0.3286857604980469 seconds for one epoch ---
--- 3.975778102874756 seconds for one epoch ---
--- 0.3297910690307617 seconds for one epoch ---
--- 3.9607667922973633 seconds for one epoch ---
--- 0.32721686363220215 seconds for one epoch ---
--- 4.031571626663208 seconds for one epoch ---
--- 0.32584452629089355 seconds for one epoch ---
--- 3.953517198562622 seconds for one epoch ---
--- 0.3409614562988281 seconds for one epoch ---
--- 4.032809495925903 seconds for one epoch ---
--- 0.3194897174835205 seconds for one epoch ---
--- 3.959479808807373 seconds for one epoch ---
--- 0.3274087905883789 seconds for one epoch ---
--- 4.037595272064209 seconds for one epoch ---
--- 0.3264930248260498 seconds for one epoch ---
--- 4.054450988769531 seconds for one epoch ---
--- 0.33176279067993164 seconds for one epoch ---
--- 3.984957218170166 seconds for one epoch ---
--- 0.32376742362976074 seconds for one epoch ---
--- 4.001516819000244 seconds for one epoch ---
--- 0.32649707794189453 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995215]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.001755]
 [  0.      ]]
--- 0.28022003173828125 seconds for one epoch ---
Epoch 8025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3574.30419921875, (1492.9348, 1.3007176, 2079.576, 0.49267006)
   validation loss 744.6136474609375, (480.8875, 0.57071817, 262.66275, 0.49267006)
decoder loss ratio: 18630.417080, decoder SINDy loss  ratio: 0.566994
--- 0.30988645553588867 seconds for one epoch ---
--- 3.8963375091552734 seconds for one epoch ---
--- 0.32634782791137695 seconds for one epoch ---
--- 3.9622464179992676 seconds for one epoch ---
--- 0.3335075378417969 seconds for one epoch ---
--- 4.017651796340942 seconds for one epoch ---
--- 0.3376882076263428 seconds for one epoch ---
--- 4.038914442062378 seconds for one epoch ---
--- 0.32943272590637207 seconds for one epoch ---
--- 4.014149188995361 seconds for one epoch ---
--- 0.319943904876709 seconds for one epoch ---
--- 3.972857713699341 seconds for one epoch ---
--- 0.3323824405670166 seconds for one epoch ---
--- 4.052719354629517 seconds for one epoch ---
--- 0.3186178207397461 seconds for one epoch ---
--- 4.05954909324646 seconds for one epoch ---
--- 0.33187031745910645 seconds for one epoch ---
--- 4.001312017440796 seconds for one epoch ---
--- 0.3265230655670166 seconds for one epoch ---
--- 4.016858339309692 seconds for one epoch ---
--- 0.3319730758666992 seconds for one epoch ---
--- 3.9930672645568848 seconds for one epoch ---
--- 0.3267796039581299 seconds for one epoch ---
--- 3.990929365158081 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995215]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-19.00344]
 [ -0.     ]]
--- 0.31069469451904297 seconds for one epoch ---
Epoch 8050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1620.43359375, (900.31555, 0.15357901, 719.47174, 0.4927306)
   validation loss 874.5919799804688, (587.44916, 0.5651886, 286.08487, 0.4927306)
decoder loss ratio: 22758.800226, decoder SINDy loss  ratio: 0.617554
--- 0.27239108085632324 seconds for one epoch ---
--- 0.3128628730773926 seconds for one epoch ---
--- 4.062992334365845 seconds for one epoch ---
--- 0.3256220817565918 seconds for one epoch ---
--- 4.054660081863403 seconds for one epoch ---
--- 0.3287639617919922 seconds for one epoch ---
--- 4.052527904510498 seconds for one epoch ---
--- 0.3374209403991699 seconds for one epoch ---
--- 4.003993272781372 seconds for one epoch ---
--- 0.33057713508605957 seconds for one epoch ---
--- 3.9999399185180664 seconds for one epoch ---
--- 0.3235945701599121 seconds for one epoch ---
--- 4.001138925552368 seconds for one epoch ---
--- 0.3262045383453369 seconds for one epoch ---
--- 4.092155933380127 seconds for one epoch ---
--- 0.33516740798950195 seconds for one epoch ---
--- 4.06813907623291 seconds for one epoch ---
--- 0.34192991256713867 seconds for one epoch ---
--- 4.07820987701416 seconds for one epoch ---
--- 0.3297879695892334 seconds for one epoch ---
--- 4.06039834022522 seconds for one epoch ---
--- 0.32525014877319336 seconds for one epoch ---
--- 4.08755087852478 seconds for one epoch ---
--- 0.31566882133483887 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999522]
 [0.      ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-19.00669]
 [ -0.     ]]
--- 0.27205753326416016 seconds for one epoch ---
Epoch 8075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2440.75732421875, (1093.3973, 3.594832, 1343.2722, 0.49280652)
   validation loss 721.0643310546875, (453.85986, 0.56770056, 266.144, 0.49280652)
decoder loss ratio: 17583.319039, decoder SINDy loss  ratio: 0.574509
--- 0.30566883087158203 seconds for one epoch ---
--- 4.065274238586426 seconds for one epoch ---
--- 0.3304588794708252 seconds for one epoch ---
--- 4.073893070220947 seconds for one epoch ---
--- 0.32140159606933594 seconds for one epoch ---
--- 4.000280857086182 seconds for one epoch ---
--- 0.3112497329711914 seconds for one epoch ---
--- 4.004909515380859 seconds for one epoch ---
--- 0.32376837730407715 seconds for one epoch ---
--- 3.986602544784546 seconds for one epoch ---
--- 0.33119821548461914 seconds for one epoch ---
--- 4.086174488067627 seconds for one epoch ---
--- 0.32892441749572754 seconds for one epoch ---
--- 4.0281524658203125 seconds for one epoch ---
--- 0.3499460220336914 seconds for one epoch ---
--- 4.08366060256958 seconds for one epoch ---
--- 0.3213062286376953 seconds for one epoch ---
--- 3.968587636947632 seconds for one epoch ---
--- 0.30475807189941406 seconds for one epoch ---
--- 4.096897602081299 seconds for one epoch ---
--- 0.32791996002197266 seconds for one epoch ---
--- 4.097443342208862 seconds for one epoch ---
--- 0.3278927803039551 seconds for one epoch ---
--- 4.1226301193237305 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995215]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.008486]
 [  0.      ]]
--- 0.3027801513671875 seconds for one epoch ---
Epoch 8100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2119.675048828125, (1646.5986, 1.3373399, 471.24622, 0.4928525)
   validation loss 773.5516967773438, (502.49963, 0.5638379, 269.99536, 0.4928525)
decoder loss ratio: 19467.708191, decoder SINDy loss  ratio: 0.582823
--- 0.27281880378723145 seconds for one epoch ---
--- 0.324878454208374 seconds for one epoch ---
--- 3.997955083847046 seconds for one epoch ---
--- 0.3204634189605713 seconds for one epoch ---
--- 4.013980388641357 seconds for one epoch ---
--- 0.32941460609436035 seconds for one epoch ---
--- 4.067929029464722 seconds for one epoch ---
--- 0.32792091369628906 seconds for one epoch ---
--- 4.087552547454834 seconds for one epoch ---
--- 0.33026814460754395 seconds for one epoch ---
--- 4.105718612670898 seconds for one epoch ---
--- 0.3268420696258545 seconds for one epoch ---
--- 4.082520484924316 seconds for one epoch ---
--- 0.3339383602142334 seconds for one epoch ---
--- 4.10117244720459 seconds for one epoch ---
--- 0.3354330062866211 seconds for one epoch ---
--- 4.081189870834351 seconds for one epoch ---
--- 0.33826708793640137 seconds for one epoch ---
--- 4.035473346710205 seconds for one epoch ---
--- 0.32595109939575195 seconds for one epoch ---
--- 4.007760524749756 seconds for one epoch ---
--- 0.319049596786499 seconds for one epoch ---
--- 4.088864803314209 seconds for one epoch ---
--- 0.3307797908782959 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952126]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-19.01062]
 [ -0.     ]]
--- 0.27205348014831543 seconds for one epoch ---
Epoch 8125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1788.559326171875, (925.50226, 0.35633245, 862.20776, 0.49292484)
   validation loss 822.01025390625, (546.6244, 0.57011324, 274.3228, 0.49292484)
decoder loss ratio: 21177.177837, decoder SINDy loss  ratio: 0.592164
--- 0.30776262283325195 seconds for one epoch ---
--- 4.095131158828735 seconds for one epoch ---
--- 0.3279590606689453 seconds for one epoch ---
--- 4.095498085021973 seconds for one epoch ---
--- 0.32869505882263184 seconds for one epoch ---
--- 4.0349366664886475 seconds for one epoch ---
--- 0.3283042907714844 seconds for one epoch ---
--- 4.065131664276123 seconds for one epoch ---
--- 0.3324270248413086 seconds for one epoch ---
--- 4.031664848327637 seconds for one epoch ---
--- 0.3356807231903076 seconds for one epoch ---
--- 4.115505218505859 seconds for one epoch ---
--- 0.3282780647277832 seconds for one epoch ---
--- 4.099529266357422 seconds for one epoch ---
--- 0.32985377311706543 seconds for one epoch ---
--- 4.097428798675537 seconds for one epoch ---
--- 0.3366239070892334 seconds for one epoch ---
--- 4.0341572761535645 seconds for one epoch ---
--- 0.32025766372680664 seconds for one epoch ---
--- 4.031749248504639 seconds for one epoch ---
--- 0.3373281955718994 seconds for one epoch ---
--- 4.032468795776367 seconds for one epoch ---
--- 0.32273173332214355 seconds for one epoch ---
--- 4.0418736934661865 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995212]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.013317]
 [  0.      ]]
--- 0.30594515800476074 seconds for one epoch ---
Epoch 8150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4149.90087890625, (1608.8506, 3.5381417, 2537.019, 0.4929915)
   validation loss 779.8423461914062, (507.14117, 0.56470597, 271.64352, 0.4929915)
decoder loss ratio: 19647.529529, decoder SINDy loss  ratio: 0.586381
--- 0.2833728790283203 seconds for one epoch ---
--- 0.32705235481262207 seconds for one epoch ---
--- 4.090506553649902 seconds for one epoch ---
--- 0.33457207679748535 seconds for one epoch ---
--- 4.08901047706604 seconds for one epoch ---
--- 0.3367900848388672 seconds for one epoch ---
--- 4.0223588943481445 seconds for one epoch ---
--- 0.3256795406341553 seconds for one epoch ---
--- 4.1113600730896 seconds for one epoch ---
--- 0.34314846992492676 seconds for one epoch ---
--- 4.096300363540649 seconds for one epoch ---
--- 0.3275105953216553 seconds for one epoch ---
--- 4.057499647140503 seconds for one epoch ---
--- 0.32973790168762207 seconds for one epoch ---
--- 4.140306234359741 seconds for one epoch ---
--- 0.3412902355194092 seconds for one epoch ---
--- 4.113085746765137 seconds for one epoch ---
--- 0.33286356925964355 seconds for one epoch ---
--- 4.046871900558472 seconds for one epoch ---
--- 0.3198726177215576 seconds for one epoch ---
--- 4.028141498565674 seconds for one epoch ---
--- 0.3192005157470703 seconds for one epoch ---
--- 4.05854344367981 seconds for one epoch ---
--- 0.33461952209472656 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952066]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.015177]
 [  0.      ]]
--- 0.2620062828063965 seconds for one epoch ---
Epoch 8175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2442.791259765625, (1172.6587, 2.3802116, 1267.2593, 0.49304095)
   validation loss 777.751220703125, (505.92947, 0.55797833, 270.77075, 0.49304095)
decoder loss ratio: 19600.586150, decoder SINDy loss  ratio: 0.584497
--- 0.3032245635986328 seconds for one epoch ---
--- 4.125401496887207 seconds for one epoch ---
--- 0.3385426998138428 seconds for one epoch ---
--- 4.039407253265381 seconds for one epoch ---
--- 0.3212728500366211 seconds for one epoch ---
--- 4.048090219497681 seconds for one epoch ---
--- 0.32585906982421875 seconds for one epoch ---
--- 4.0589118003845215 seconds for one epoch ---
--- 0.31976318359375 seconds for one epoch ---
--- 4.121585369110107 seconds for one epoch ---
--- 0.32952404022216797 seconds for one epoch ---
--- 4.054999351501465 seconds for one epoch ---
--- 0.33167171478271484 seconds for one epoch ---
--- 4.124325752258301 seconds for one epoch ---
--- 0.3220083713531494 seconds for one epoch ---
--- 4.054847955703735 seconds for one epoch ---
--- 0.32423853874206543 seconds for one epoch ---
--- 4.043341159820557 seconds for one epoch ---
--- 0.3284304141998291 seconds for one epoch ---
--- 4.110968351364136 seconds for one epoch ---
--- 0.32948875427246094 seconds for one epoch ---
--- 4.122484445571899 seconds for one epoch ---
--- 0.317826509475708 seconds for one epoch ---
--- 4.115748167037964 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952024]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-19.01721]
 [ -0.     ]]
--- 0.3133113384246826 seconds for one epoch ---
Epoch 8200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2796.970947265625, (1163.5818, 0.5535252, 1632.3425, 0.49309787)
   validation loss 791.4248657226562, (517.4751, 0.5724798, 272.8842, 0.49309787)
decoder loss ratio: 20047.883659, decoder SINDy loss  ratio: 0.589059
--- 0.27505016326904297 seconds for one epoch ---
--- 0.3462207317352295 seconds for one epoch ---
--- 4.116477966308594 seconds for one epoch ---
--- 0.3281092643737793 seconds for one epoch ---
--- 4.076139450073242 seconds for one epoch ---
--- 0.3294413089752197 seconds for one epoch ---
--- 4.1382036209106445 seconds for one epoch ---
--- 0.3296494483947754 seconds for one epoch ---
--- 4.073479413986206 seconds for one epoch ---
--- 0.31841468811035156 seconds for one epoch ---
--- 4.058250665664673 seconds for one epoch ---
--- 0.3264808654785156 seconds for one epoch ---
--- 4.125627517700195 seconds for one epoch ---
--- 0.3322598934173584 seconds for one epoch ---
--- 4.04166841506958 seconds for one epoch ---
--- 0.32143568992614746 seconds for one epoch ---
--- 4.159634113311768 seconds for one epoch ---
--- 0.3341383934020996 seconds for one epoch ---
--- 4.077533483505249 seconds for one epoch ---
--- 0.34650540351867676 seconds for one epoch ---
--- 4.0664684772491455 seconds for one epoch ---
--- 0.32958340644836426 seconds for one epoch ---
--- 4.070928573608398 seconds for one epoch ---
--- 0.3293452262878418 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995198]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.018322]
 [ -0.      ]]
--- 0.26982784271240234 seconds for one epoch ---
Epoch 8225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2687.1337890625, (1608.798, 2.0972385, 1075.7454, 0.49312425)
   validation loss 785.136962890625, (520.71356, 0.56875694, 263.3615, 0.49312425)
decoder loss ratio: 20173.347391, decoder SINDy loss  ratio: 0.568503
--- 0.3149144649505615 seconds for one epoch ---
--- 4.14040732383728 seconds for one epoch ---
--- 0.3373439311981201 seconds for one epoch ---
--- 4.049102067947388 seconds for one epoch ---
--- 0.3361937999725342 seconds for one epoch ---
--- 4.1410956382751465 seconds for one epoch ---
--- 0.3322784900665283 seconds for one epoch ---
--- 4.0753583908081055 seconds for one epoch ---
--- 0.33412742614746094 seconds for one epoch ---
--- 4.140973091125488 seconds for one epoch ---
--- 0.33080410957336426 seconds for one epoch ---
--- 4.1387939453125 seconds for one epoch ---
--- 0.32761216163635254 seconds for one epoch ---
--- 4.074361801147461 seconds for one epoch ---
--- 0.3051798343658447 seconds for one epoch ---
--- 4.166819334030151 seconds for one epoch ---
--- 0.32750582695007324 seconds for one epoch ---
--- 4.092221260070801 seconds for one epoch ---
--- 0.31326889991760254 seconds for one epoch ---
--- 4.144484281539917 seconds for one epoch ---
--- 0.3205130100250244 seconds for one epoch ---
--- 4.0855326652526855 seconds for one epoch ---
--- 0.32822299003601074 seconds for one epoch ---
--- 4.149579048156738 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995198]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.020948]
 [  0.      ]]
--- 0.31664538383483887 seconds for one epoch ---
Epoch 8250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2002.254638671875, (1230.4182, 1.6758587, 769.6673, 0.4931987)
   validation loss 792.6205444335938, (521.9156, 0.5780983, 269.63364, 0.4931987)
decoder loss ratio: 20219.915979, decoder SINDy loss  ratio: 0.582042
--- 0.2693607807159424 seconds for one epoch ---
--- 0.34386610984802246 seconds for one epoch ---
--- 4.079629898071289 seconds for one epoch ---
--- 0.3400111198425293 seconds for one epoch ---
--- 4.157959222793579 seconds for one epoch ---
--- 0.3333895206451416 seconds for one epoch ---
--- 4.134706020355225 seconds for one epoch ---
--- 0.33789515495300293 seconds for one epoch ---
--- 4.163252592086792 seconds for one epoch ---
--- 0.32073545455932617 seconds for one epoch ---
--- 4.179299592971802 seconds for one epoch ---
--- 0.33326101303100586 seconds for one epoch ---
--- 4.0939414501190186 seconds for one epoch ---
--- 0.3284754753112793 seconds for one epoch ---
--- 4.082797050476074 seconds for one epoch ---
--- 0.32959628105163574 seconds for one epoch ---
--- 4.166325807571411 seconds for one epoch ---
--- 0.33522534370422363 seconds for one epoch ---
--- 4.059161901473999 seconds for one epoch ---
--- 0.3308742046356201 seconds for one epoch ---
--- 4.175750970840454 seconds for one epoch ---
--- 0.31731104850769043 seconds for one epoch ---
--- 4.104985237121582 seconds for one epoch ---
--- 0.3209114074707031 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995196]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.022497]
 [ -0.      ]]
--- 0.26300859451293945 seconds for one epoch ---
Epoch 8275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2217.607421875, (1319.4537, 0.83214796, 896.8284, 0.49324974)
   validation loss 798.7147827148438, (535.59827, 0.58153605, 262.04172, 0.49324974)
decoder loss ratio: 20750.006688, decoder SINDy loss  ratio: 0.565654
--- 0.31818342208862305 seconds for one epoch ---
--- 4.171748161315918 seconds for one epoch ---
--- 0.34148144721984863 seconds for one epoch ---
--- 4.153167009353638 seconds for one epoch ---
--- 0.3265645503997803 seconds for one epoch ---
--- 4.0864598751068115 seconds for one epoch ---
--- 0.3302319049835205 seconds for one epoch ---
--- 4.157487869262695 seconds for one epoch ---
--- 0.3387157917022705 seconds for one epoch ---
--- 4.168917179107666 seconds for one epoch ---
--- 0.33235645294189453 seconds for one epoch ---
--- 4.15344762802124 seconds for one epoch ---
--- 0.32250356674194336 seconds for one epoch ---
--- 4.167396545410156 seconds for one epoch ---
--- 0.3315713405609131 seconds for one epoch ---
--- 4.109289884567261 seconds for one epoch ---
--- 0.3329153060913086 seconds for one epoch ---
--- 4.179484844207764 seconds for one epoch ---
--- 0.3329803943634033 seconds for one epoch ---
--- 4.1077821254730225 seconds for one epoch ---
--- 0.32461118698120117 seconds for one epoch ---
--- 4.1208367347717285 seconds for one epoch ---
--- 0.33075451850891113 seconds for one epoch ---
--- 4.090291738510132 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995196]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-19.02583]
 [  0.     ]]
--- 0.30159926414489746 seconds for one epoch ---
Epoch 8300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2146.227294921875, (852.3636, 0.47551033, 1292.8948, 0.4933323)
   validation loss 747.2042236328125, (483.20584, 0.59250635, 262.91254, 0.4933323)
decoder loss ratio: 18720.233165, decoder SINDy loss  ratio: 0.567534
--- 0.2667372226715088 seconds for one epoch ---
--- 0.34075403213500977 seconds for one epoch ---
--- 4.169387578964233 seconds for one epoch ---
--- 0.3401069641113281 seconds for one epoch ---
--- 4.104845762252808 seconds for one epoch ---
--- 0.33090806007385254 seconds for one epoch ---
--- 4.096638202667236 seconds for one epoch ---
--- 0.32253456115722656 seconds for one epoch ---
--- 4.124465465545654 seconds for one epoch ---
--- 0.3305330276489258 seconds for one epoch ---
--- 4.103801012039185 seconds for one epoch ---
--- 0.32572507858276367 seconds for one epoch ---
--- 4.1118857860565186 seconds for one epoch ---
--- 0.3241307735443115 seconds for one epoch ---
--- 4.2085254192352295 seconds for one epoch ---
--- 0.3325183391571045 seconds for one epoch ---
--- 4.188931941986084 seconds for one epoch ---
--- 0.35173964500427246 seconds for one epoch ---
--- 4.1214141845703125 seconds for one epoch ---
--- 0.3398475646972656 seconds for one epoch ---
--- 4.194487571716309 seconds for one epoch ---
--- 0.3362128734588623 seconds for one epoch ---
--- 4.188776016235352 seconds for one epoch ---
--- 0.3358447551727295 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995191]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.028072]
 [  0.      ]]
--- 0.27513599395751953 seconds for one epoch ---
Epoch 8325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2467.875244140625, (1049.2847, 2.4018335, 1415.6952, 0.493398)
   validation loss 829.3052978515625, (563.02094, 0.5920964, 265.19882, 0.493398)
decoder loss ratio: 21812.408471, decoder SINDy loss  ratio: 0.572469
--- 0.31165027618408203 seconds for one epoch ---
--- 4.162423372268677 seconds for one epoch ---
--- 0.3349418640136719 seconds for one epoch ---
--- 4.117168426513672 seconds for one epoch ---
--- 0.3310568332672119 seconds for one epoch ---
--- 4.208488702774048 seconds for one epoch ---
--- 0.32263994216918945 seconds for one epoch ---
--- 4.184900999069214 seconds for one epoch ---
--- 0.3222379684448242 seconds for one epoch ---
--- 4.18336820602417 seconds for one epoch ---
--- 0.34001994132995605 seconds for one epoch ---
--- 4.106130838394165 seconds for one epoch ---
--- 0.33733129501342773 seconds for one epoch ---
--- 4.139869689941406 seconds for one epoch ---
--- 0.3382449150085449 seconds for one epoch ---
--- 4.1177966594696045 seconds for one epoch ---
--- 0.3373100757598877 seconds for one epoch ---
--- 4.118519306182861 seconds for one epoch ---
--- 0.33008646965026855 seconds for one epoch ---
--- 4.125808477401733 seconds for one epoch ---
--- 0.33159375190734863 seconds for one epoch ---
--- 4.125989675521851 seconds for one epoch ---
--- 0.3448166847229004 seconds for one epoch ---
--- 4.140866041183472 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995189]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.029182]
 [ -0.      ]]
--- 0.318495512008667 seconds for one epoch ---
Epoch 8350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3276.198486328125, (1618.7335, 2.4666913, 1654.5049, 0.49342704)
   validation loss 740.769775390625, (479.91492, 0.58647174, 259.77493, 0.49342704)
decoder loss ratio: 18592.737053, decoder SINDy loss  ratio: 0.560761
--- 0.2802135944366455 seconds for one epoch ---
--- 0.33690738677978516 seconds for one epoch ---
--- 4.213112831115723 seconds for one epoch ---
--- 0.33974313735961914 seconds for one epoch ---
--- 4.120604515075684 seconds for one epoch ---
--- 0.3309049606323242 seconds for one epoch ---
--- 4.2130653858184814 seconds for one epoch ---
--- 0.33580875396728516 seconds for one epoch ---
--- 4.1271140575408936 seconds for one epoch ---
--- 0.33341050148010254 seconds for one epoch ---
--- 4.194006443023682 seconds for one epoch ---
--- 0.31723546981811523 seconds for one epoch ---
--- 4.1316094398498535 seconds for one epoch ---
--- 0.3327338695526123 seconds for one epoch ---
--- 4.206903696060181 seconds for one epoch ---
--- 0.3364584445953369 seconds for one epoch ---
--- 4.138847351074219 seconds for one epoch ---
--- 0.3295586109161377 seconds for one epoch ---
--- 4.139747381210327 seconds for one epoch ---
--- 0.34564208984375 seconds for one epoch ---
--- 4.155917167663574 seconds for one epoch ---
--- 0.32999253273010254 seconds for one epoch ---
--- 4.142024278640747 seconds for one epoch ---
--- 0.32784461975097656 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951893]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.030672]
 [ -0.      ]]
--- 0.25601792335510254 seconds for one epoch ---
Epoch 8375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2753.762451171875, (1360.5321, 1.9477093, 1390.7893, 0.49346682)
   validation loss 738.4185180664062, (474.40695, 0.57924104, 262.93887, 0.49346682)
decoder loss ratio: 18379.348923, decoder SINDy loss  ratio: 0.567591
--- 0.3316209316253662 seconds for one epoch ---
--- 4.150319576263428 seconds for one epoch ---
--- 0.31972455978393555 seconds for one epoch ---
--- 4.116270065307617 seconds for one epoch ---
--- 0.3343851566314697 seconds for one epoch ---
--- 4.173888921737671 seconds for one epoch ---
--- 0.31378650665283203 seconds for one epoch ---
--- 4.203354358673096 seconds for one epoch ---
--- 0.3385884761810303 seconds for one epoch ---
--- 4.226526975631714 seconds for one epoch ---
--- 0.3546757698059082 seconds for one epoch ---
--- 4.139024019241333 seconds for one epoch ---
--- 0.33853745460510254 seconds for one epoch ---
--- 4.160771131515503 seconds for one epoch ---
--- 0.33211493492126465 seconds for one epoch ---
--- 4.215681076049805 seconds for one epoch ---
--- 0.3453238010406494 seconds for one epoch ---
--- 4.1561362743377686 seconds for one epoch ---
--- 0.31865692138671875 seconds for one epoch ---
--- 4.206600904464722 seconds for one epoch ---
--- 0.32868051528930664 seconds for one epoch ---
--- 4.22599983215332 seconds for one epoch ---
--- 0.32573866844177246 seconds for one epoch ---
--- 4.146175384521484 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995189]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.033804]
 [  0.      ]]
--- 0.3043491840362549 seconds for one epoch ---
Epoch 8400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2471.486083984375, (1256.8102, 0.36198583, 1213.8203, 0.49354854)
   validation loss 865.392333984375, (578.46893, 0.5686501, 285.86118, 0.49354854)
decoder loss ratio: 22410.890735, decoder SINDy loss  ratio: 0.617072
--- 0.28514766693115234 seconds for one epoch ---
--- 0.34248924255371094 seconds for one epoch ---
--- 4.135885715484619 seconds for one epoch ---
--- 0.31731605529785156 seconds for one epoch ---
--- 4.154578924179077 seconds for one epoch ---
--- 0.32787513732910156 seconds for one epoch ---
--- 4.149778604507446 seconds for one epoch ---
--- 0.33373475074768066 seconds for one epoch ---
--- 4.152640104293823 seconds for one epoch ---
--- 0.33022332191467285 seconds for one epoch ---
--- 4.164242506027222 seconds for one epoch ---
--- 0.3414742946624756 seconds for one epoch ---
--- 4.247190475463867 seconds for one epoch ---
--- 0.3503108024597168 seconds for one epoch ---
--- 4.169482231140137 seconds for one epoch ---
--- 0.3206312656402588 seconds for one epoch ---
--- 4.178192615509033 seconds for one epoch ---
--- 0.3367464542388916 seconds for one epoch ---
--- 4.227854251861572 seconds for one epoch ---
--- 0.3316328525543213 seconds for one epoch ---
--- 4.248661279678345 seconds for one epoch ---
--- 0.33083605766296387 seconds for one epoch ---
--- 4.190583944320679 seconds for one epoch ---
--- 0.3401501178741455 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995185]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-19.035961]
 [ -0.      ]]
--- 0.27652621269226074 seconds for one epoch ---
Epoch 8425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3371.6669921875, (1349.894, 1.6344329, 2019.645, 0.49361187)
   validation loss 747.7422485351562, (481.2614, 0.5786838, 265.40857, 0.49361187)
decoder loss ratio: 18644.902668, decoder SINDy loss  ratio: 0.572922
--- 0.3069424629211426 seconds for one epoch ---
--- 4.229510545730591 seconds for one epoch ---
--- 0.32732057571411133 seconds for one epoch ---
--- 4.1460652351379395 seconds for one epoch ---
--- 0.32903504371643066 seconds for one epoch ---
--- 4.245467185974121 seconds for one epoch ---
--- 0.33810901641845703 seconds for one epoch ---
--- 4.264478445053101 seconds for one epoch ---
--- 0.3242671489715576 seconds for one epoch ---
--- 4.159107685089111 seconds for one epoch ---
--- 0.3384888172149658 seconds for one epoch ---
--- 4.165825605392456 seconds for one epoch ---
--- 0.33378028869628906 seconds for one epoch ---
--- 4.249546051025391 seconds for one epoch ---
--- 0.3322598934173584 seconds for one epoch ---
--- 4.256004810333252 seconds for one epoch ---
--- 0.32703661918640137 seconds for one epoch ---
--- 4.167923927307129 seconds for one epoch ---
--- 0.32049012184143066 seconds for one epoch ---
--- 4.25045371055603 seconds for one epoch ---
--- 0.33590030670166016 seconds for one epoch ---
--- 4.248487949371338 seconds for one epoch ---
--- 0.3259389400482178 seconds for one epoch ---
--- 4.261669397354126 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951845]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.038162]
 [  0.      ]]
--- 0.31242823600769043 seconds for one epoch ---
Epoch 8450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2412.40283203125, (1320.0872, 2.4304965, 1089.3914, 0.49368134)
   validation loss 813.37646484375, (531.8047, 0.5700492, 280.5081, 0.49368134)
decoder loss ratio: 20603.036847, decoder SINDy loss  ratio: 0.605516
--- 0.26915645599365234 seconds for one epoch ---
--- 0.34639811515808105 seconds for one epoch ---
--- 4.251364469528198 seconds for one epoch ---
--- 0.31337666511535645 seconds for one epoch ---
--- 4.167036294937134 seconds for one epoch ---
--- 0.324277400970459 seconds for one epoch ---
--- 4.189680099487305 seconds for one epoch ---
--- 0.32312679290771484 seconds for one epoch ---
--- 4.2640111446380615 seconds for one epoch ---
--- 0.3400869369506836 seconds for one epoch ---
--- 4.247379302978516 seconds for one epoch ---
--- 0.32915163040161133 seconds for one epoch ---
--- 4.27762770652771 seconds for one epoch ---
--- 0.34081578254699707 seconds for one epoch ---
--- 4.191582918167114 seconds for one epoch ---
--- 0.33523035049438477 seconds for one epoch ---
--- 4.27037501335144 seconds for one epoch ---
--- 0.3415412902832031 seconds for one epoch ---
--- 4.192481517791748 seconds for one epoch ---
--- 0.33079051971435547 seconds for one epoch ---
--- 4.181564807891846 seconds for one epoch ---
--- 0.3317418098449707 seconds for one epoch ---
--- 4.185455322265625 seconds for one epoch ---
--- 0.32517004013061523 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995183]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.040438]
 [  0.      ]]
--- 0.2720954418182373 seconds for one epoch ---
Epoch 8475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1528.1761474609375, (768.2829, 0.62963533, 758.76984, 0.49374637)
   validation loss 788.128662109375, (512.3827, 0.58046794, 274.67178, 0.49374637)
decoder loss ratio: 19850.594963, decoder SINDy loss  ratio: 0.592918
--- 0.311859130859375 seconds for one epoch ---
--- 4.270720958709717 seconds for one epoch ---
--- 0.33187341690063477 seconds for one epoch ---
--- 4.1515679359436035 seconds for one epoch ---
--- 0.317899227142334 seconds for one epoch ---
--- 4.15639591217041 seconds for one epoch ---
--- 0.33028316497802734 seconds for one epoch ---
--- 4.1767261028289795 seconds for one epoch ---
--- 0.3281421661376953 seconds for one epoch ---
--- 4.243234872817993 seconds for one epoch ---
--- 0.3250086307525635 seconds for one epoch ---
--- 4.170345783233643 seconds for one epoch ---
--- 0.3231692314147949 seconds for one epoch ---
--- 4.18834114074707 seconds for one epoch ---
--- 0.33387064933776855 seconds for one epoch ---
--- 4.187042474746704 seconds for one epoch ---
--- 0.3268754482269287 seconds for one epoch ---
--- 4.179023504257202 seconds for one epoch ---
--- 0.3241868019104004 seconds for one epoch ---
--- 4.256075382232666 seconds for one epoch ---
--- 0.3369319438934326 seconds for one epoch ---
--- 4.193572759628296 seconds for one epoch ---
--- 0.3392026424407959 seconds for one epoch ---
--- 4.254612684249878 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999519]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.042852]
 [ -0.      ]]
--- 0.3081092834472656 seconds for one epoch ---
Epoch 8500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2342.645751953125, (765.90735, 1.0883105, 1575.1561, 0.49381724)
   validation loss 827.0670776367188, (543.6744, 0.5778403, 282.32104, 0.49381724)
decoder loss ratio: 21062.889242, decoder SINDy loss  ratio: 0.609430
THRESHOLDING: 1 active coefficients
--- 4.129332065582275 seconds for one epoch ---
--- 0.3314518928527832 seconds for one epoch ---
--- 4.263139247894287 seconds for one epoch ---
--- 0.32245445251464844 seconds for one epoch ---
--- 4.246700286865234 seconds for one epoch ---
--- 0.32180309295654297 seconds for one epoch ---
--- 4.2473461627960205 seconds for one epoch ---
--- 0.33471131324768066 seconds for one epoch ---
--- 4.170390367507935 seconds for one epoch ---
--- 0.3137490749359131 seconds for one epoch ---
--- 4.273407697677612 seconds for one epoch ---
--- 0.3406693935394287 seconds for one epoch ---
--- 4.285584926605225 seconds for one epoch ---
--- 0.3313024044036865 seconds for one epoch ---
--- 4.262352466583252 seconds for one epoch ---
--- 0.33017635345458984 seconds for one epoch ---
--- 4.219166994094849 seconds for one epoch ---
--- 0.33551955223083496 seconds for one epoch ---
--- 4.172875881195068 seconds for one epoch ---
--- 0.33350706100463867 seconds for one epoch ---
--- 4.195756912231445 seconds for one epoch ---
--- 0.32805299758911133 seconds for one epoch ---
--- 4.287771940231323 seconds for one epoch ---
--- 0.326200008392334 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951893]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-19.04468]
 [ -0.     ]]
--- 0.2642638683319092 seconds for one epoch ---
Epoch 8525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2460.281494140625, (1135.6871, 0.37045705, 1323.7299, 0.4938635)
   validation loss 731.2777709960938, (468.69702, 0.5845244, 261.5024, 0.4938635)
decoder loss ratio: 18158.136306, decoder SINDy loss  ratio: 0.564490
--- 0.31435537338256836 seconds for one epoch ---
--- 4.126180171966553 seconds for one epoch ---
--- 0.32898592948913574 seconds for one epoch ---
--- 4.192726135253906 seconds for one epoch ---
--- 0.33646440505981445 seconds for one epoch ---
--- 4.26261830329895 seconds for one epoch ---
--- 0.33389925956726074 seconds for one epoch ---
--- 4.229677200317383 seconds for one epoch ---
--- 0.3367621898651123 seconds for one epoch ---
--- 4.198763847351074 seconds for one epoch ---
--- 0.33431077003479004 seconds for one epoch ---
--- 4.19147515296936 seconds for one epoch ---
--- 0.3344407081604004 seconds for one epoch ---
--- 4.210656642913818 seconds for one epoch ---
--- 0.341372013092041 seconds for one epoch ---
--- 4.299322843551636 seconds for one epoch ---
--- 0.33244895935058594 seconds for one epoch ---
--- 4.230423927307129 seconds for one epoch ---
--- 0.33121347427368164 seconds for one epoch ---
--- 4.304065704345703 seconds for one epoch ---
--- 0.346238374710083 seconds for one epoch ---
--- 4.233684539794922 seconds for one epoch ---
--- 0.3344380855560303 seconds for one epoch ---
--- 4.258166790008545 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995191]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.047415]
 [  0.      ]]
--- 0.30522680282592773 seconds for one epoch ---
Epoch 8550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3006.194091796875, (1323.0748, 0.41084388, 1682.2145, 0.49393606)
   validation loss 737.4862670898438, (473.30826, 0.58478236, 263.09927, 0.49393606)
decoder loss ratio: 18336.783616, decoder SINDy loss  ratio: 0.567937
--- 0.2752053737640381 seconds for one epoch ---
--- 0.3352365493774414 seconds for one epoch ---
--- 4.200866460800171 seconds for one epoch ---
--- 0.3213214874267578 seconds for one epoch ---
--- 4.209814548492432 seconds for one epoch ---
--- 0.3206369876861572 seconds for one epoch ---
--- 4.309061288833618 seconds for one epoch ---
--- 0.3285212516784668 seconds for one epoch ---
--- 4.21653151512146 seconds for one epoch ---
--- 0.33278822898864746 seconds for one epoch ---
--- 4.270045518875122 seconds for one epoch ---
--- 0.3268160820007324 seconds for one epoch ---
--- 4.306964874267578 seconds for one epoch ---
--- 0.33318209648132324 seconds for one epoch ---
--- 4.3156750202178955 seconds for one epoch ---
--- 0.3239891529083252 seconds for one epoch ---
--- 4.2308220863342285 seconds for one epoch ---
--- 0.33579158782958984 seconds for one epoch ---
--- 4.323983907699585 seconds for one epoch ---
--- 0.332808256149292 seconds for one epoch ---
--- 4.245785236358643 seconds for one epoch ---
--- 0.3326418399810791 seconds for one epoch ---
--- 4.331476211547852 seconds for one epoch ---
--- 0.32239294052124023 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995194]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-19.04964]
 [ -0.     ]]
--- 0.2624175548553467 seconds for one epoch ---
Epoch 8575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3034.397216796875, (819.39886, 2.8844762, 2211.6199, 0.49399087)
   validation loss 746.54638671875, (479.03665, 0.5798185, 266.43594, 0.49399087)
decoder loss ratio: 18558.711528, decoder SINDy loss  ratio: 0.575139
--- 0.31647229194641113 seconds for one epoch ---
--- 4.237577199935913 seconds for one epoch ---
--- 0.33264756202697754 seconds for one epoch ---
--- 4.237297058105469 seconds for one epoch ---
--- 0.3265812397003174 seconds for one epoch ---
--- 4.220239877700806 seconds for one epoch ---
--- 0.3168454170227051 seconds for one epoch ---
--- 4.227966785430908 seconds for one epoch ---
--- 0.3321094512939453 seconds for one epoch ---
--- 4.307300567626953 seconds for one epoch ---
--- 0.3216707706451416 seconds for one epoch ---
--- 4.244114637374878 seconds for one epoch ---
--- 0.332289457321167 seconds for one epoch ---
--- 4.3627541065216064 seconds for one epoch ---
--- 0.3262670040130615 seconds for one epoch ---
--- 4.255302667617798 seconds for one epoch ---
--- 0.3208644390106201 seconds for one epoch ---
--- 4.26650595664978 seconds for one epoch ---
--- 0.32812047004699707 seconds for one epoch ---
--- 4.356647491455078 seconds for one epoch ---
--- 0.3407881259918213 seconds for one epoch ---
--- 4.237870454788208 seconds for one epoch ---
--- 0.33116722106933594 seconds for one epoch ---
--- 4.257416725158691 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995196]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.051487]
 [  0.      ]]
--- 0.30237555503845215 seconds for one epoch ---
Epoch 8600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3514.781494140625, (1420.2058, 6.2992992, 2087.7822, 0.49405375)
   validation loss 792.076416015625, (523.58057, 0.58481246, 267.41693, 0.49405375)
decoder loss ratio: 20284.420118, decoder SINDy loss  ratio: 0.577257
--- 0.27486276626586914 seconds for one epoch ---
--- 0.3328709602355957 seconds for one epoch ---
--- 4.2340943813323975 seconds for one epoch ---
--- 0.32602572441101074 seconds for one epoch ---
--- 4.218138933181763 seconds for one epoch ---
--- 0.32390379905700684 seconds for one epoch ---
--- 4.320106744766235 seconds for one epoch ---
--- 0.3272712230682373 seconds for one epoch ---
--- 4.2273640632629395 seconds for one epoch ---
--- 0.3287217617034912 seconds for one epoch ---
--- 4.230604887008667 seconds for one epoch ---
--- 0.33416104316711426 seconds for one epoch ---
--- 4.333278656005859 seconds for one epoch ---
--- 0.32518744468688965 seconds for one epoch ---
--- 4.240579128265381 seconds for one epoch ---
--- 0.3242795467376709 seconds for one epoch ---
--- 4.33492636680603 seconds for one epoch ---
--- 0.33643484115600586 seconds for one epoch ---
--- 4.247252941131592 seconds for one epoch ---
--- 0.329819917678833 seconds for one epoch ---
--- 4.2450995445251465 seconds for one epoch ---
--- 0.3325533866882324 seconds for one epoch ---
--- 4.358139753341675 seconds for one epoch ---
--- 0.3267643451690674 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995197]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.053099]
 [  0.      ]]
--- 0.2485370635986328 seconds for one epoch ---
Epoch 8625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3438.9658203125, (1831.5375, 0.66231847, 1606.2719, 0.49409562)
   validation loss 749.5547485351562, (487.6585, 0.5913267, 260.81085, 0.49409562)
decoder loss ratio: 18892.737224, decoder SINDy loss  ratio: 0.562997
--- 0.3038508892059326 seconds for one epoch ---
--- 4.338209629058838 seconds for one epoch ---
--- 0.33489274978637695 seconds for one epoch ---
--- 4.237901210784912 seconds for one epoch ---
--- 0.3223292827606201 seconds for one epoch ---
--- 4.358110666275024 seconds for one epoch ---
--- 0.3372213840484619 seconds for one epoch ---
--- 4.262088298797607 seconds for one epoch ---
--- 0.32805800437927246 seconds for one epoch ---
--- 4.260518550872803 seconds for one epoch ---
--- 0.32395315170288086 seconds for one epoch ---
--- 4.33725380897522 seconds for one epoch ---
--- 0.33892083168029785 seconds for one epoch ---
--- 4.255162715911865 seconds for one epoch ---
--- 0.33121585845947266 seconds for one epoch ---
--- 4.2774107456207275 seconds for one epoch ---
--- 0.32301998138427734 seconds for one epoch ---
--- 4.351500511169434 seconds for one epoch ---
--- 0.31978774070739746 seconds for one epoch ---
--- 4.354470252990723 seconds for one epoch ---
--- 0.3317258358001709 seconds for one epoch ---
--- 4.36547589302063 seconds for one epoch ---
--- 0.3343517780303955 seconds for one epoch ---
--- 4.256288290023804 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995198]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.054785]
 [ -0.      ]]
--- 0.314450740814209 seconds for one epoch ---
Epoch 8650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3178.178955078125, (1855.1448, 1.0539346, 1321.4861, 0.49413916)
   validation loss 777.7594604492188, (512.1734, 0.5926925, 264.4992, 0.49413916)
decoder loss ratio: 19842.486722, decoder SINDy loss  ratio: 0.570959
--- 0.28566741943359375 seconds for one epoch ---
--- 0.3341987133026123 seconds for one epoch ---
--- 4.252499103546143 seconds for one epoch ---
--- 0.33302927017211914 seconds for one epoch ---
--- 4.340659141540527 seconds for one epoch ---
--- 0.32697319984436035 seconds for one epoch ---
--- 4.271695852279663 seconds for one epoch ---
--- 0.3329432010650635 seconds for one epoch ---
--- 4.339291095733643 seconds for one epoch ---
--- 0.3329329490661621 seconds for one epoch ---
--- 4.263503074645996 seconds for one epoch ---
--- 0.3284742832183838 seconds for one epoch ---
--- 4.291207551956177 seconds for one epoch ---
--- 0.32905149459838867 seconds for one epoch ---
--- 4.271665811538696 seconds for one epoch ---
--- 0.3341822624206543 seconds for one epoch ---
--- 4.362995862960815 seconds for one epoch ---
--- 0.31938958168029785 seconds for one epoch ---
--- 4.381871938705444 seconds for one epoch ---
--- 0.3424198627471924 seconds for one epoch ---
--- 4.3135764598846436 seconds for one epoch ---
--- 0.335712194442749 seconds for one epoch ---
--- 4.27201509475708 seconds for one epoch ---
--- 0.32850074768066406 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995198]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.055883]
 [ -0.      ]]
--- 0.2762746810913086 seconds for one epoch ---
Epoch 8675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2093.862548828125, (1006.4241, 0.9779674, 1085.9663, 0.494176)
   validation loss 728.9513549804688, (469.26706, 0.5855329, 258.60458, 0.494176)
decoder loss ratio: 18180.220562, decoder SINDy loss  ratio: 0.558234
--- 0.29419827461242676 seconds for one epoch ---
--- 4.25931978225708 seconds for one epoch ---
--- 0.33220362663269043 seconds for one epoch ---
--- 4.365157127380371 seconds for one epoch ---
--- 0.33237671852111816 seconds for one epoch ---
--- 4.362576723098755 seconds for one epoch ---
--- 0.3312206268310547 seconds for one epoch ---
--- 4.265450954437256 seconds for one epoch ---
--- 0.32636570930480957 seconds for one epoch ---
--- 4.366183757781982 seconds for one epoch ---
--- 0.3304905891418457 seconds for one epoch ---
--- 4.278041362762451 seconds for one epoch ---
--- 0.33559393882751465 seconds for one epoch ---
--- 4.378164768218994 seconds for one epoch ---
--- 0.3278191089630127 seconds for one epoch ---
--- 4.365773439407349 seconds for one epoch ---
--- 0.3269009590148926 seconds for one epoch ---
--- 4.352494239807129 seconds for one epoch ---
--- 0.32327747344970703 seconds for one epoch ---
--- 4.298672676086426 seconds for one epoch ---
--- 0.3236865997314453 seconds for one epoch ---
--- 4.284127473831177 seconds for one epoch ---
--- 0.32850050926208496 seconds for one epoch ---
--- 4.382559776306152 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99951994]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.057943]
 [  0.      ]]
--- 0.30765867233276367 seconds for one epoch ---
Epoch 8700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4772.337890625, (2299.2908, 2.7271245, 2469.8262, 0.49423122)
   validation loss 753.0346069335938, (486.8253, 0.5847201, 265.13037, 0.49423122)
decoder loss ratio: 18860.456779, decoder SINDy loss  ratio: 0.572321
--- 0.26763248443603516 seconds for one epoch ---
--- 0.33080029487609863 seconds for one epoch ---
--- 4.30667781829834 seconds for one epoch ---
--- 0.32773375511169434 seconds for one epoch ---
--- 4.310696125030518 seconds for one epoch ---
--- 0.32546448707580566 seconds for one epoch ---
--- 4.294485330581665 seconds for one epoch ---
--- 0.33208489418029785 seconds for one epoch ---
--- 4.372284173965454 seconds for one epoch ---
--- 0.3339695930480957 seconds for one epoch ---
--- 4.304269552230835 seconds for one epoch ---
--- 0.3323969841003418 seconds for one epoch ---
--- 4.380773305892944 seconds for one epoch ---
--- 0.325411319732666 seconds for one epoch ---
--- 4.329673767089844 seconds for one epoch ---
--- 0.328782320022583 seconds for one epoch ---
--- 4.365347862243652 seconds for one epoch ---
--- 0.3310401439666748 seconds for one epoch ---
--- 4.29389214515686 seconds for one epoch ---
--- 0.32448887825012207 seconds for one epoch ---
--- 4.403993129730225 seconds for one epoch ---
--- 0.3297715187072754 seconds for one epoch ---
--- 4.376019477844238 seconds for one epoch ---
--- 0.3467750549316406 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952006]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-19.059843]
 [ -0.      ]]
--- 0.2644529342651367 seconds for one epoch ---
Epoch 8725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6196.04833984375, (2000.206, 8.0028, 4187.345, 0.49428716)
   validation loss 745.1025390625, (475.92645, 0.5835396, 268.09833, 0.49428716)
decoder loss ratio: 18438.217020, decoder SINDy loss  ratio: 0.578728
--- 0.3163580894470215 seconds for one epoch ---
--- 4.378208160400391 seconds for one epoch ---
--- 0.33326172828674316 seconds for one epoch ---
--- 4.3698976039886475 seconds for one epoch ---
--- 0.33398008346557617 seconds for one epoch ---
--- 4.305784225463867 seconds for one epoch ---
--- 0.31089162826538086 seconds for one epoch ---
--- 4.307107925415039 seconds for one epoch ---
--- 0.3295323848724365 seconds for one epoch ---
--- 4.322787284851074 seconds for one epoch ---
--- 0.3313865661621094 seconds for one epoch ---
--- 4.395707607269287 seconds for one epoch ---
--- 0.31606173515319824 seconds for one epoch ---
--- 4.299865484237671 seconds for one epoch ---
--- 0.3243677616119385 seconds for one epoch ---
--- 4.3200531005859375 seconds for one epoch ---
--- 0.33426403999328613 seconds for one epoch ---
--- 4.3159990310668945 seconds for one epoch ---
--- 0.32289624214172363 seconds for one epoch ---
--- 4.3913023471832275 seconds for one epoch ---
--- 0.3319721221923828 seconds for one epoch ---
--- 4.321442127227783 seconds for one epoch ---
--- 0.33260560035705566 seconds for one epoch ---
--- 4.3996970653533936 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995202]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.061447]
 [  0.      ]]
--- 0.3059267997741699 seconds for one epoch ---
Epoch 8750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2387.294189453125, (1285.3318, 1.6683216, 1099.7996, 0.4943183)
   validation loss 787.8411865234375, (516.3747, 0.57384044, 270.39832, 0.4943183)
decoder loss ratio: 20005.252143, decoder SINDy loss  ratio: 0.583693
--- 0.28565526008605957 seconds for one epoch ---
--- 0.32921385765075684 seconds for one epoch ---
--- 4.375845432281494 seconds for one epoch ---
--- 0.333477258682251 seconds for one epoch ---
--- 4.32674765586853 seconds for one epoch ---
--- 0.33767008781433105 seconds for one epoch ---
--- 4.3369646072387695 seconds for one epoch ---
--- 0.3203909397125244 seconds for one epoch ---
--- 4.3086864948272705 seconds for one epoch ---
--- 0.3261709213256836 seconds for one epoch ---
--- 4.313147306442261 seconds for one epoch ---
--- 0.32689905166625977 seconds for one epoch ---
--- 4.406034469604492 seconds for one epoch ---
--- 0.3329508304595947 seconds for one epoch ---
--- 4.321033477783203 seconds for one epoch ---
--- 0.33533620834350586 seconds for one epoch ---
--- 4.31851601600647 seconds for one epoch ---
--- 0.3289358615875244 seconds for one epoch ---
--- 4.392469882965088 seconds for one epoch ---
--- 0.3283424377441406 seconds for one epoch ---
--- 4.3990702629089355 seconds for one epoch ---
--- 0.32964587211608887 seconds for one epoch ---
--- 4.424219608306885 seconds for one epoch ---
--- 0.3299117088317871 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995203]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.062635]
 [  0.      ]]
--- 0.2624678611755371 seconds for one epoch ---
Epoch 8775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3986.88427734375, (2169.5137, 3.4256968, 1813.4504, 0.49437076)
   validation loss 886.6038818359375, (599.17834, 0.56818146, 286.36295, 0.49437076)
decoder loss ratio: 23213.209294, decoder SINDy loss  ratio: 0.618155
--- 0.29719114303588867 seconds for one epoch ---
--- 4.376480340957642 seconds for one epoch ---
--- 0.32764554023742676 seconds for one epoch ---
--- 4.322481393814087 seconds for one epoch ---
--- 0.332688570022583 seconds for one epoch ---
--- 4.403159856796265 seconds for one epoch ---
--- 0.33475208282470703 seconds for one epoch ---
--- 4.334966659545898 seconds for one epoch ---
--- 0.3233466148376465 seconds for one epoch ---
--- 4.330815315246582 seconds for one epoch ---
--- 0.3234436511993408 seconds for one epoch ---
--- 4.405996799468994 seconds for one epoch ---
--- 0.31989622116088867 seconds for one epoch ---
--- 4.354176998138428 seconds for one epoch ---
--- 0.2930424213409424 seconds for one epoch ---
--- 4.328773260116577 seconds for one epoch ---
--- 0.3249533176422119 seconds for one epoch ---
--- 4.4382429122924805 seconds for one epoch ---
--- 0.33414554595947266 seconds for one epoch ---
--- 4.420461416244507 seconds for one epoch ---
--- 0.32740044593811035 seconds for one epoch ---
--- 4.4058592319488525 seconds for one epoch ---
--- 0.3323945999145508 seconds for one epoch ---
--- 4.349194288253784 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952066]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.064703]
 [ -0.      ]]
--- 0.30922436714172363 seconds for one epoch ---
Epoch 8800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3578.380615234375, (1470.6578, 1.4317093, 2105.7966, 0.49441034)
   validation loss 779.6727294921875, (511.6743, 0.56862, 266.93546, 0.49441034)
decoder loss ratio: 19823.150141, decoder SINDy loss  ratio: 0.576218
--- 0.27677083015441895 seconds for one epoch ---
--- 0.3331749439239502 seconds for one epoch ---
--- 4.407207727432251 seconds for one epoch ---
--- 0.3470733165740967 seconds for one epoch ---
--- 4.338095664978027 seconds for one epoch ---
--- 0.3311190605163574 seconds for one epoch ---
--- 4.334954500198364 seconds for one epoch ---
--- 0.3345787525177002 seconds for one epoch ---
--- 4.34063196182251 seconds for one epoch ---
--- 0.3271007537841797 seconds for one epoch ---
--- 4.328381538391113 seconds for one epoch ---
--- 0.3199946880340576 seconds for one epoch ---
--- 4.425107002258301 seconds for one epoch ---
--- 0.3284780979156494 seconds for one epoch ---
--- 4.404282331466675 seconds for one epoch ---
--- 0.3370513916015625 seconds for one epoch ---
--- 4.346659421920776 seconds for one epoch ---
--- 0.3352024555206299 seconds for one epoch ---
--- 4.436895847320557 seconds for one epoch ---
--- 0.3222067356109619 seconds for one epoch ---
--- 4.33754563331604 seconds for one epoch ---
--- 0.3271024227142334 seconds for one epoch ---
--- 4.360918045043945 seconds for one epoch ---
--- 0.34038352966308594 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952084]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.065573]
 [ -0.      ]]
--- 0.2771339416503906 seconds for one epoch ---
Epoch 8825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1680.7398681640625, (804.3288, 0.5084864, 875.408, 0.49445412)
   validation loss 740.6803588867188, (477.95328, 0.57329834, 261.65936, 0.49445412)
decoder loss ratio: 18516.739737, decoder SINDy loss  ratio: 0.564829
--- 0.3040752410888672 seconds for one epoch ---
--- 4.411404848098755 seconds for one epoch ---
--- 0.32724881172180176 seconds for one epoch ---
--- 4.324203014373779 seconds for one epoch ---
--- 0.3213183879852295 seconds for one epoch ---
--- 4.4344305992126465 seconds for one epoch ---
--- 0.3156604766845703 seconds for one epoch ---
--- 4.357864856719971 seconds for one epoch ---
--- 0.322751522064209 seconds for one epoch ---
--- 4.441730499267578 seconds for one epoch ---
--- 0.32937026023864746 seconds for one epoch ---
--- 4.325397491455078 seconds for one epoch ---
--- 0.3303232192993164 seconds for one epoch ---
--- 4.4609534740448 seconds for one epoch ---
--- 0.3283231258392334 seconds for one epoch ---
--- 4.4177565574646 seconds for one epoch ---
--- 0.319566011428833 seconds for one epoch ---
--- 4.409381151199341 seconds for one epoch ---
--- 0.3191370964050293 seconds for one epoch ---
--- 4.369999647140503 seconds for one epoch ---
--- 0.3337256908416748 seconds for one epoch ---
--- 4.430915355682373 seconds for one epoch ---
--- 0.32932424545288086 seconds for one epoch ---
--- 4.3892316818237305 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995214]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.067434]
 [  0.      ]]
--- 0.3226337432861328 seconds for one epoch ---
Epoch 8850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2997.449951171875, (1051.9845, 4.2891583, 1940.6819, 0.49449635)
   validation loss 729.5786743164062, (465.7848, 0.5761124, 262.72327, 0.49449635)
decoder loss ratio: 18045.311404, decoder SINDy loss  ratio: 0.567125
--- 0.26823854446411133 seconds for one epoch ---
--- 0.3292579650878906 seconds for one epoch ---
--- 4.434946298599243 seconds for one epoch ---
--- 0.3367323875427246 seconds for one epoch ---
--- 4.367330074310303 seconds for one epoch ---
--- 0.3308262825012207 seconds for one epoch ---
--- 4.438135623931885 seconds for one epoch ---
--- 0.3269972801208496 seconds for one epoch ---
--- 4.362844705581665 seconds for one epoch ---
--- 0.3252859115600586 seconds for one epoch ---
--- 4.352388381958008 seconds for one epoch ---
--- 0.3453683853149414 seconds for one epoch ---
--- 4.426197052001953 seconds for one epoch ---
--- 0.33749866485595703 seconds for one epoch ---
--- 4.370948791503906 seconds for one epoch ---
--- 0.3197624683380127 seconds for one epoch ---
--- 4.45592474937439 seconds for one epoch ---
--- 0.33818721771240234 seconds for one epoch ---
--- 4.360171556472778 seconds for one epoch ---
--- 0.3289165496826172 seconds for one epoch ---
--- 4.368961572647095 seconds for one epoch ---
--- 0.3332042694091797 seconds for one epoch ---
--- 4.367516756057739 seconds for one epoch ---
--- 0.32639312744140625 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995215]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.068947]
 [ -0.      ]]
--- 0.2612941265106201 seconds for one epoch ---
Epoch 8875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3669.529296875, (1813.8597, 4.8801785, 1850.2948, 0.49453458)
   validation loss 753.9791259765625, (492.7276, 0.57580656, 260.1812, 0.49453458)
decoder loss ratio: 19089.122641, decoder SINDy loss  ratio: 0.561638
--- 0.3347320556640625 seconds for one epoch ---
--- 4.357558965682983 seconds for one epoch ---
--- 0.3158276081085205 seconds for one epoch ---
--- 4.420007705688477 seconds for one epoch ---
--- 0.3292539119720459 seconds for one epoch ---
--- 4.398628234863281 seconds for one epoch ---
--- 0.3356316089630127 seconds for one epoch ---
--- 4.369108200073242 seconds for one epoch ---
--- 0.32781386375427246 seconds for one epoch ---
--- 4.361650705337524 seconds for one epoch ---
--- 0.3323392868041992 seconds for one epoch ---
--- 4.3602118492126465 seconds for one epoch ---
--- 0.3085904121398926 seconds for one epoch ---
--- 4.404283285140991 seconds for one epoch ---
--- 0.3303804397583008 seconds for one epoch ---
--- 4.462857246398926 seconds for one epoch ---
--- 0.32395195960998535 seconds for one epoch ---
--- 4.444397926330566 seconds for one epoch ---
--- 0.3335902690887451 seconds for one epoch ---
--- 4.450873851776123 seconds for one epoch ---
--- 0.32701849937438965 seconds for one epoch ---
--- 4.481309413909912 seconds for one epoch ---
--- 0.3335592746734619 seconds for one epoch ---
--- 4.385014772415161 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995221]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.071375]
 [  0.      ]]
--- 0.31450748443603516 seconds for one epoch ---
Epoch 8900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3495.4345703125, (1774.4504, 0.8202588, 1719.6693, 0.49458963)
   validation loss 788.5928344726562, (521.0375, 0.5774671, 266.48334, 0.49458963)
decoder loss ratio: 20185.896365, decoder SINDy loss  ratio: 0.575242
--- 0.2846336364746094 seconds for one epoch ---
--- 0.3320486545562744 seconds for one epoch ---
--- 4.368383884429932 seconds for one epoch ---
--- 0.3374450206756592 seconds for one epoch ---
--- 4.472251653671265 seconds for one epoch ---
--- 0.3416781425476074 seconds for one epoch ---
--- 4.382656097412109 seconds for one epoch ---
--- 0.3243374824523926 seconds for one epoch ---
--- 4.389782905578613 seconds for one epoch ---
--- 0.3376133441925049 seconds for one epoch ---
--- 4.462082147598267 seconds for one epoch ---
--- 0.33355021476745605 seconds for one epoch ---
--- 4.3857643604278564 seconds for one epoch ---
--- 0.32735419273376465 seconds for one epoch ---
--- 4.3730151653289795 seconds for one epoch ---
--- 0.3325777053833008 seconds for one epoch ---
--- 4.393209934234619 seconds for one epoch ---
--- 0.3373241424560547 seconds for one epoch ---
--- 4.405336141586304 seconds for one epoch ---
--- 0.33462071418762207 seconds for one epoch ---
--- 4.379276752471924 seconds for one epoch ---
--- 0.32877492904663086 seconds for one epoch ---
--- 4.404667139053345 seconds for one epoch ---
--- 0.3290128707885742 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995222]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.072748]
 [  0.      ]]
--- 0.27912020683288574 seconds for one epoch ---
Epoch 8925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1369.0267333984375, (755.528, 0.90592647, 612.09814, 0.4946413)
   validation loss 805.624755859375, (526.1093, 0.5710112, 278.44986, 0.4946413)
decoder loss ratio: 20382.388189, decoder SINDy loss  ratio: 0.601073
--- 0.31826257705688477 seconds for one epoch ---
--- 4.373994827270508 seconds for one epoch ---
--- 0.33327174186706543 seconds for one epoch ---
--- 4.449089765548706 seconds for one epoch ---
--- 0.3180205821990967 seconds for one epoch ---
--- 4.467096567153931 seconds for one epoch ---
--- 0.32465124130249023 seconds for one epoch ---
--- 4.374892473220825 seconds for one epoch ---
--- 0.33159923553466797 seconds for one epoch ---
--- 4.4480555057525635 seconds for one epoch ---
--- 0.3231346607208252 seconds for one epoch ---
--- 4.459093332290649 seconds for one epoch ---
--- 0.32381629943847656 seconds for one epoch ---
--- 4.473159551620483 seconds for one epoch ---
--- 0.3330075740814209 seconds for one epoch ---
--- 4.461627960205078 seconds for one epoch ---
--- 0.3326570987701416 seconds for one epoch ---
--- 4.4026007652282715 seconds for one epoch ---
--- 0.32584595680236816 seconds for one epoch ---
--- 4.474325656890869 seconds for one epoch ---
--- 0.3144519329071045 seconds for one epoch ---
--- 4.38879132270813 seconds for one epoch ---
--- 0.33037877082824707 seconds for one epoch ---
--- 4.503304958343506 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995227]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.074196]
 [ -0.      ]]
--- 0.3111386299133301 seconds for one epoch ---
Epoch 8950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2254.81591796875, (1454.4551, 0.6499372, 799.2164, 0.49468166)
   validation loss 748.8576049804688, (479.93845, 0.5763094, 267.84818, 0.49468166)
decoder loss ratio: 18593.648610, decoder SINDy loss  ratio: 0.578188
--- 0.272890567779541 seconds for one epoch ---
--- 0.3367774486541748 seconds for one epoch ---
--- 4.381676197052002 seconds for one epoch ---
--- 0.3250732421875 seconds for one epoch ---
--- 4.496872901916504 seconds for one epoch ---
--- 0.334972620010376 seconds for one epoch ---
--- 4.492389678955078 seconds for one epoch ---
--- 0.3272724151611328 seconds for one epoch ---
--- 4.4034929275512695 seconds for one epoch ---
--- 0.3295125961303711 seconds for one epoch ---
--- 4.477789640426636 seconds for one epoch ---
--- 0.32506775856018066 seconds for one epoch ---
--- 4.494130611419678 seconds for one epoch ---
--- 0.33330440521240234 seconds for one epoch ---
--- 4.4833784103393555 seconds for one epoch ---
--- 0.3245275020599365 seconds for one epoch ---
--- 4.516303300857544 seconds for one epoch ---
--- 0.32860326766967773 seconds for one epoch ---
--- 4.43657922744751 seconds for one epoch ---
--- 0.32117247581481934 seconds for one epoch ---
--- 4.5043933391571045 seconds for one epoch ---
--- 0.32784533500671387 seconds for one epoch ---
--- 4.519697189331055 seconds for one epoch ---
--- 0.3222677707672119 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952304]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.075958]
 [ -0.      ]]
--- 0.27985548973083496 seconds for one epoch ---
Epoch 8975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3278.06640625, (1115.8574, 2.7077405, 2159.0066, 0.4947302)
   validation loss 785.190673828125, (512.4182, 0.58231837, 271.6954, 0.4947302)
decoder loss ratio: 19851.971165, decoder SINDy loss  ratio: 0.586493
--- 0.3158245086669922 seconds for one epoch ---
--- 4.516948699951172 seconds for one epoch ---
--- 0.3323183059692383 seconds for one epoch ---
--- 4.385076284408569 seconds for one epoch ---
--- 0.3140406608581543 seconds for one epoch ---
--- 4.515800476074219 seconds for one epoch ---
--- 0.3322904109954834 seconds for one epoch ---
--- 4.437873840332031 seconds for one epoch ---
--- 0.3319821357727051 seconds for one epoch ---
--- 4.427220582962036 seconds for one epoch ---
--- 0.33433008193969727 seconds for one epoch ---
--- 4.51662278175354 seconds for one epoch ---
--- 0.3317141532897949 seconds for one epoch ---
--- 4.5311439037323 seconds for one epoch ---
--- 0.3334329128265381 seconds for one epoch ---
--- 4.440603971481323 seconds for one epoch ---
--- 0.3360707759857178 seconds for one epoch ---
--- 4.545172929763794 seconds for one epoch ---
--- 0.32704663276672363 seconds for one epoch ---
--- 4.510310888290405 seconds for one epoch ---
--- 0.32984042167663574 seconds for one epoch ---
--- 4.527872323989868 seconds for one epoch ---
--- 0.3334169387817383 seconds for one epoch ---
--- 4.481939792633057 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995233]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-19.07753]
 [  0.     ]]
--- 0.31523966789245605 seconds for one epoch ---
Epoch 9000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1731.9559326171875, (676.4344, 0.8103073, 1054.2164, 0.49477196)
   validation loss 787.0347900390625, (519.77264, 0.5962107, 266.1712, 0.49477196)
decoder loss ratio: 20136.894595, decoder SINDy loss  ratio: 0.574568
THRESHOLDING: 1 active coefficients
--- 0.2746922969818115 seconds for one epoch ---
--- 0.32967400550842285 seconds for one epoch ---
--- 4.45014214515686 seconds for one epoch ---
--- 0.32985734939575195 seconds for one epoch ---
--- 4.48638916015625 seconds for one epoch ---
--- 0.3336367607116699 seconds for one epoch ---
--- 4.498428583145142 seconds for one epoch ---
--- 0.3313577175140381 seconds for one epoch ---
--- 4.443751335144043 seconds for one epoch ---
--- 0.32515573501586914 seconds for one epoch ---
--- 4.524759531021118 seconds for one epoch ---
--- 0.3345170021057129 seconds for one epoch ---
--- 4.462871551513672 seconds for one epoch ---
--- 0.3305344581604004 seconds for one epoch ---
--- 4.4462854862213135 seconds for one epoch ---
--- 0.33300042152404785 seconds for one epoch ---
--- 4.545085430145264 seconds for one epoch ---
--- 0.3295743465423584 seconds for one epoch ---
--- 4.463316202163696 seconds for one epoch ---
--- 0.31970977783203125 seconds for one epoch ---
--- 4.547734022140503 seconds for one epoch ---
--- 0.32669758796691895 seconds for one epoch ---
--- 4.51598334312439 seconds for one epoch ---
--- 0.32488512992858887 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995235]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-19.078714]
 [ -0.      ]]
--- 0.2690615653991699 seconds for one epoch ---
Epoch 9025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3571.96435546875, (1119.9673, 1.721166, 2449.781, 0.49480477)
   validation loss 774.4959106445312, (503.16357, 0.5943189, 270.2432, 0.49480477)
decoder loss ratio: 19493.430396, decoder SINDy loss  ratio: 0.583358
--- 0.3175837993621826 seconds for one epoch ---
--- 4.481502056121826 seconds for one epoch ---
--- 0.3495755195617676 seconds for one epoch ---
--- 4.507583856582642 seconds for one epoch ---
--- 0.34511280059814453 seconds for one epoch ---
--- 4.499823570251465 seconds for one epoch ---
--- 0.3343040943145752 seconds for one epoch ---
--- 4.437522888183594 seconds for one epoch ---
--- 0.33226704597473145 seconds for one epoch ---
--- 4.529762029647827 seconds for one epoch ---
--- 0.331712007522583 seconds for one epoch ---
--- 4.434298515319824 seconds for one epoch ---
--- 0.32914137840270996 seconds for one epoch ---
--- 4.53459095954895 seconds for one epoch ---
--- 0.32479429244995117 seconds for one epoch ---
--- 4.538083553314209 seconds for one epoch ---
--- 0.33168697357177734 seconds for one epoch ---
--- 4.484610080718994 seconds for one epoch ---
--- 0.3367295265197754 seconds for one epoch ---
--- 4.522447109222412 seconds for one epoch ---
--- 0.3286910057067871 seconds for one epoch ---
--- 4.566817760467529 seconds for one epoch ---
--- 0.32535457611083984 seconds for one epoch ---
--- 4.495312690734863 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952364]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-19.08016]
 [  0.     ]]
--- 0.3126790523529053 seconds for one epoch ---
Epoch 9050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2720.349365234375, (1397.7562, 7.856558, 1314.2417, 0.49483973)
   validation loss 780.4212036132812, (519.0971, 0.5936088, 260.23566, 0.49483973)
decoder loss ratio: 20110.723115, decoder SINDy loss  ratio: 0.561755
--- 0.28131842613220215 seconds for one epoch ---
--- 0.3326985836029053 seconds for one epoch ---
--- 4.461133241653442 seconds for one epoch ---
--- 0.325939416885376 seconds for one epoch ---
--- 4.476206064224243 seconds for one epoch ---
--- 0.32535839080810547 seconds for one epoch ---
--- 4.495108366012573 seconds for one epoch ---
--- 0.3342132568359375 seconds for one epoch ---
--- 4.4725658893585205 seconds for one epoch ---
--- 0.3297433853149414 seconds for one epoch ---
--- 4.544798851013184 seconds for one epoch ---
--- 0.33541011810302734 seconds for one epoch ---
--- 4.453582286834717 seconds for one epoch ---
--- 0.33136558532714844 seconds for one epoch ---
--- 4.481722354888916 seconds for one epoch ---
--- 0.3373279571533203 seconds for one epoch ---
--- 4.473138809204102 seconds for one epoch ---
--- 0.33458733558654785 seconds for one epoch ---
--- 4.500481843948364 seconds for one epoch ---
--- 0.3265378475189209 seconds for one epoch ---
--- 4.488368034362793 seconds for one epoch ---
--- 0.33283162117004395 seconds for one epoch ---
--- 4.492153882980347 seconds for one epoch ---
--- 0.33449482917785645 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999524]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.081781]
 [  0.      ]]
--- 0.2699098587036133 seconds for one epoch ---
Epoch 9075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3959.593017578125, (1702.3568, 1.4951205, 2255.246, 0.49489084)
   validation loss 797.5665283203125, (529.5819, 0.59323096, 266.8965, 0.49489084)
decoder loss ratio: 20516.922556, decoder SINDy loss  ratio: 0.576134
--- 0.31477856636047363 seconds for one epoch ---
--- 4.466147184371948 seconds for one epoch ---
--- 0.33261871337890625 seconds for one epoch ---
--- 4.565808296203613 seconds for one epoch ---
--- 0.33481311798095703 seconds for one epoch ---
--- 4.5667033195495605 seconds for one epoch ---
--- 0.3256552219390869 seconds for one epoch ---
--- 4.464595556259155 seconds for one epoch ---
--- 0.3250243663787842 seconds for one epoch ---
--- 4.570979595184326 seconds for one epoch ---
--- 0.32523488998413086 seconds for one epoch ---
--- 4.4878151416778564 seconds for one epoch ---
--- 0.33083653450012207 seconds for one epoch ---
--- 4.5790910720825195 seconds for one epoch ---
--- 0.3271923065185547 seconds for one epoch ---
--- 4.505221128463745 seconds for one epoch ---
--- 0.32375407218933105 seconds for one epoch ---
--- 4.483640193939209 seconds for one epoch ---
--- 0.3361318111419678 seconds for one epoch ---
--- 4.5045483112335205 seconds for one epoch ---
--- 0.3355062007904053 seconds for one epoch ---
--- 4.497244119644165 seconds for one epoch ---
--- 0.33687663078308105 seconds for one epoch ---
--- 4.576455593109131 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995246]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.082977]
 [ -0.      ]]
--- 0.31545209884643555 seconds for one epoch ---
Epoch 9100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3928.513427734375, (1234.4606, 2.7993984, 2690.7585, 0.49492732)
   validation loss 800.8475952148438, (526.8692, 0.5775414, 272.90594, 0.49492732)
decoder loss ratio: 20411.827557, decoder SINDy loss  ratio: 0.589106
--- 0.2835080623626709 seconds for one epoch ---
--- 0.3223590850830078 seconds for one epoch ---
--- 4.54837965965271 seconds for one epoch ---
--- 0.31603384017944336 seconds for one epoch ---
--- 4.554260730743408 seconds for one epoch ---
--- 0.31154465675354004 seconds for one epoch ---
--- 4.48598051071167 seconds for one epoch ---
--- 0.3244743347167969 seconds for one epoch ---
--- 4.585998773574829 seconds for one epoch ---
--- 0.3225576877593994 seconds for one epoch ---
--- 4.490113019943237 seconds for one epoch ---
--- 0.32796502113342285 seconds for one epoch ---
--- 4.4974493980407715 seconds for one epoch ---
--- 0.3149125576019287 seconds for one epoch ---
--- 4.495872735977173 seconds for one epoch ---
--- 0.33212900161743164 seconds for one epoch ---
--- 4.58592677116394 seconds for one epoch ---
--- 0.3271627426147461 seconds for one epoch ---
--- 4.558771133422852 seconds for one epoch ---
--- 0.32248759269714355 seconds for one epoch ---
--- 4.582453727722168 seconds for one epoch ---
--- 0.32535433769226074 seconds for one epoch ---
--- 4.48734974861145 seconds for one epoch ---
--- 0.3297879695892334 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999525]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.084051]
 [ -0.      ]]
--- 0.267681360244751 seconds for one epoch ---
Epoch 9125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2606.846435546875, (1331.0839, 3.6604342, 1271.6074, 0.49494982)
   validation loss 786.7586669921875, (514.41003, 0.579292, 271.2744, 0.49494982)
decoder loss ratio: 19929.137779, decoder SINDy loss  ratio: 0.585584
--- 0.31270885467529297 seconds for one epoch ---
--- 4.555039167404175 seconds for one epoch ---
--- 0.32200121879577637 seconds for one epoch ---
--- 4.450300216674805 seconds for one epoch ---
--- 0.31806373596191406 seconds for one epoch ---
--- 4.608501434326172 seconds for one epoch ---
--- 0.33262038230895996 seconds for one epoch ---
--- 4.601288080215454 seconds for one epoch ---
--- 0.33589911460876465 seconds for one epoch ---
--- 4.571021556854248 seconds for one epoch ---
--- 0.3260807991027832 seconds for one epoch ---
--- 4.479035139083862 seconds for one epoch ---
--- 0.33534812927246094 seconds for one epoch ---
--- 4.541992425918579 seconds for one epoch ---
--- 0.3163626194000244 seconds for one epoch ---
--- 4.511724948883057 seconds for one epoch ---
--- 0.3292112350463867 seconds for one epoch ---
--- 4.507623672485352 seconds for one epoch ---
--- 0.32922935485839844 seconds for one epoch ---
--- 4.590559482574463 seconds for one epoch ---
--- 0.32756710052490234 seconds for one epoch ---
--- 4.510948419570923 seconds for one epoch ---
--- 0.32476258277893066 seconds for one epoch ---
--- 4.61542820930481 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952555]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.086113]
 [  0.      ]]
--- 0.3243982791900635 seconds for one epoch ---
Epoch 9150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3432.4853515625, (1367.0839, 1.0368592, 2063.8694, 0.4950164)
   validation loss 819.099609375, (541.5791, 0.5857728, 276.4398, 0.4950164)
decoder loss ratio: 20981.714617, decoder SINDy loss  ratio: 0.596734
--- 0.2845916748046875 seconds for one epoch ---
--- 0.3282747268676758 seconds for one epoch ---
--- 4.499949216842651 seconds for one epoch ---
--- 0.3313419818878174 seconds for one epoch ---
--- 4.6119773387908936 seconds for one epoch ---
--- 0.3382289409637451 seconds for one epoch ---
--- 4.61864161491394 seconds for one epoch ---
--- 0.3325684070587158 seconds for one epoch ---
--- 4.607080459594727 seconds for one epoch ---
--- 0.3315250873565674 seconds for one epoch ---
--- 4.538374423980713 seconds for one epoch ---
--- 0.33160996437072754 seconds for one epoch ---
--- 4.598245620727539 seconds for one epoch ---
--- 0.31815099716186523 seconds for one epoch ---
--- 4.603713035583496 seconds for one epoch ---
--- 0.3359651565551758 seconds for one epoch ---
--- 4.60504937171936 seconds for one epoch ---
--- 0.3352184295654297 seconds for one epoch ---
--- 4.4979026317596436 seconds for one epoch ---
--- 0.3182823657989502 seconds for one epoch ---
--- 4.623678207397461 seconds for one epoch ---
--- 0.3345179557800293 seconds for one epoch ---
--- 4.632936954498291 seconds for one epoch ---
--- 0.3376607894897461 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952614]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-19.08664]
 [ -0.     ]]
--- 0.25966739654541016 seconds for one epoch ---
Epoch 9175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2738.521484375, (1590.4766, 0.72539335, 1146.8246, 0.495037)
   validation loss 783.2344360351562, (510.19412, 0.5827759, 271.96246, 0.495037)
decoder loss ratio: 19765.806034, decoder SINDy loss  ratio: 0.587069
--- 0.305614709854126 seconds for one epoch ---
--- 4.528196811676025 seconds for one epoch ---
--- 0.33943915367126465 seconds for one epoch ---
--- 4.500136137008667 seconds for one epoch ---
--- 0.3304619789123535 seconds for one epoch ---
--- 4.616316556930542 seconds for one epoch ---
--- 0.3329291343688965 seconds for one epoch ---
--- 4.53752589225769 seconds for one epoch ---
--- 0.325101375579834 seconds for one epoch ---
--- 4.552629709243774 seconds for one epoch ---
--- 0.3364396095275879 seconds for one epoch ---
--- 4.610526084899902 seconds for one epoch ---
--- 0.31831789016723633 seconds for one epoch ---
--- 4.521207571029663 seconds for one epoch ---
--- 0.3187553882598877 seconds for one epoch ---
--- 4.54035496711731 seconds for one epoch ---
--- 0.3269014358520508 seconds for one epoch ---
--- 4.6228625774383545 seconds for one epoch ---
--- 0.3314473628997803 seconds for one epoch ---
--- 4.5336997509002686 seconds for one epoch ---
--- 0.32530713081359863 seconds for one epoch ---
--- 4.60942268371582 seconds for one epoch ---
--- 0.3183863162994385 seconds for one epoch ---
--- 4.537235736846924 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995265]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.088415]
 [  0.      ]]
--- 0.2999875545501709 seconds for one epoch ---
Epoch 9200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2232.3486328125, (1092.4191, 0.8720228, 1138.5623, 0.49508092)
   validation loss 743.3217163085938, (476.7123, 0.57949656, 265.53482, 0.49508092)
decoder loss ratio: 18468.662529, decoder SINDy loss  ratio: 0.573194
--- 0.26803016662597656 seconds for one epoch ---
--- 0.33391618728637695 seconds for one epoch ---
--- 4.529839754104614 seconds for one epoch ---
--- 0.3197627067565918 seconds for one epoch ---
--- 4.535069942474365 seconds for one epoch ---
--- 0.3229489326477051 seconds for one epoch ---
--- 4.546191215515137 seconds for one epoch ---
--- 0.32129335403442383 seconds for one epoch ---
--- 4.610306262969971 seconds for one epoch ---
--- 0.3264145851135254 seconds for one epoch ---
--- 4.603461503982544 seconds for one epoch ---
--- 0.3375515937805176 seconds for one epoch ---
--- 4.636790752410889 seconds for one epoch ---
--- 0.3243529796600342 seconds for one epoch ---
--- 4.534351110458374 seconds for one epoch ---
--- 0.3174607753753662 seconds for one epoch ---
--- 4.614925384521484 seconds for one epoch ---
--- 0.3305084705352783 seconds for one epoch ---
--- 4.626455307006836 seconds for one epoch ---
--- 0.3308267593383789 seconds for one epoch ---
--- 4.631891250610352 seconds for one epoch ---
--- 0.33155345916748047 seconds for one epoch ---
--- 4.652960300445557 seconds for one epoch ---
--- 0.33367443084716797 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995269]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-19.08965]
 [  0.     ]]
--- 0.2607734203338623 seconds for one epoch ---
Epoch 9225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5020.2197265625, (1731.8323, 6.8316255, 3281.0608, 0.49510947)
   validation loss 747.4280395507812, (482.28137, 0.58589125, 264.06567, 0.49510947)
decoder loss ratio: 18684.417631, decoder SINDy loss  ratio: 0.570023
--- 0.3265876770019531 seconds for one epoch ---
--- 4.538515090942383 seconds for one epoch ---
--- 0.3287060260772705 seconds for one epoch ---
--- 4.526870012283325 seconds for one epoch ---
--- 0.33347082138061523 seconds for one epoch ---
--- 4.6255738735198975 seconds for one epoch ---
--- 0.33825230598449707 seconds for one epoch ---
--- 4.6273863315582275 seconds for one epoch ---
--- 0.3353877067565918 seconds for one epoch ---
--- 4.6140077114105225 seconds for one epoch ---
--- 0.34615182876586914 seconds for one epoch ---
--- 4.562087535858154 seconds for one epoch ---
--- 0.32509589195251465 seconds for one epoch ---
--- 4.641617059707642 seconds for one epoch ---
--- 0.3313615322113037 seconds for one epoch ---
--- 4.552016258239746 seconds for one epoch ---
--- 0.3220207691192627 seconds for one epoch ---
--- 4.631690263748169 seconds for one epoch ---
--- 0.3221428394317627 seconds for one epoch ---
--- 4.570343494415283 seconds for one epoch ---
--- 0.3287632465362549 seconds for one epoch ---
--- 4.585726022720337 seconds for one epoch ---
--- 0.32254767417907715 seconds for one epoch ---
--- 4.582204580307007 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952734]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.091415]
 [ -0.      ]]
--- 0.3052399158477783 seconds for one epoch ---
Epoch 9250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1887.349365234375, (807.6363, 3.4038656, 1075.8141, 0.49515086)
   validation loss 804.9840698242188, (527.6066, 0.57848966, 276.30377, 0.49515086)
decoder loss ratio: 20440.396750, decoder SINDy loss  ratio: 0.596441
--- 0.24837589263916016 seconds for one epoch ---
--- 0.33303356170654297 seconds for one epoch ---
--- 4.625264883041382 seconds for one epoch ---
--- 0.3347127437591553 seconds for one epoch ---
--- 4.658963441848755 seconds for one epoch ---
--- 0.3295009136199951 seconds for one epoch ---
--- 4.55291485786438 seconds for one epoch ---
--- 0.3403754234313965 seconds for one epoch ---
--- 4.57470440864563 seconds for one epoch ---
--- 0.3358640670776367 seconds for one epoch ---
--- 4.622958660125732 seconds for one epoch ---
--- 0.3340907096862793 seconds for one epoch ---
--- 4.6645636558532715 seconds for one epoch ---
--- 0.3303537368774414 seconds for one epoch ---
--- 4.686685085296631 seconds for one epoch ---
--- 0.33127450942993164 seconds for one epoch ---
--- 4.574281930923462 seconds for one epoch ---
--- 0.32708168029785156 seconds for one epoch ---
--- 4.663181304931641 seconds for one epoch ---
--- 0.32348155975341797 seconds for one epoch ---
--- 4.586135625839233 seconds for one epoch ---
--- 0.32164835929870605 seconds for one epoch ---
--- 4.586267709732056 seconds for one epoch ---
--- 0.3280050754547119 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995278]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.092344]
 [ -0.      ]]
--- 0.28372931480407715 seconds for one epoch ---
Epoch 9275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2208.455322265625, (819.5338, 2.699301, 1385.727, 0.49519253)
   validation loss 742.7423706054688, (475.56693, 0.58734107, 266.0929, 0.49519253)
decoder loss ratio: 18424.288297, decoder SINDy loss  ratio: 0.574399
--- 0.3131074905395508 seconds for one epoch ---
--- 4.578152418136597 seconds for one epoch ---
--- 0.33098578453063965 seconds for one epoch ---
--- 4.642501354217529 seconds for one epoch ---
--- 0.33298325538635254 seconds for one epoch ---
--- 4.645941257476807 seconds for one epoch ---
--- 0.32538557052612305 seconds for one epoch ---
--- 4.6376564502716064 seconds for one epoch ---
--- 0.32671093940734863 seconds for one epoch ---
--- 4.568385362625122 seconds for one epoch ---
--- 0.3373260498046875 seconds for one epoch ---
--- 4.669179201126099 seconds for one epoch ---
--- 0.3313596248626709 seconds for one epoch ---
--- 4.587480545043945 seconds for one epoch ---
--- 0.3401651382446289 seconds for one epoch ---
--- 4.587043762207031 seconds for one epoch ---
--- 0.33908700942993164 seconds for one epoch ---
--- 4.690082550048828 seconds for one epoch ---
--- 0.3290128707885742 seconds for one epoch ---
--- 4.689677715301514 seconds for one epoch ---
--- 0.33513545989990234 seconds for one epoch ---
--- 4.590778589248657 seconds for one epoch ---
--- 0.31253600120544434 seconds for one epoch ---
--- 4.6746826171875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952835]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.093935]
 [  0.      ]]
--- 0.31485414505004883 seconds for one epoch ---
Epoch 9300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3448.84130859375, (1521.9677, 1.336697, 1925.0417, 0.4952223)
   validation loss 804.551025390625, (531.80316, 0.572308, 271.68033, 0.4952223)
decoder loss ratio: 20602.977732, decoder SINDy loss  ratio: 0.586460
--- 0.27620363235473633 seconds for one epoch ---
--- 0.3260464668273926 seconds for one epoch ---
--- 4.655872583389282 seconds for one epoch ---
--- 0.3298001289367676 seconds for one epoch ---
--- 4.677945852279663 seconds for one epoch ---
--- 0.33597445487976074 seconds for one epoch ---
--- 4.659683465957642 seconds for one epoch ---
--- 0.32147669792175293 seconds for one epoch ---
--- 4.66021990776062 seconds for one epoch ---
--- 0.3301990032196045 seconds for one epoch ---
--- 4.602766036987305 seconds for one epoch ---
--- 0.31681370735168457 seconds for one epoch ---
--- 4.67905068397522 seconds for one epoch ---
--- 0.33570241928100586 seconds for one epoch ---
--- 4.591686010360718 seconds for one epoch ---
--- 0.3298916816711426 seconds for one epoch ---
--- 4.612631320953369 seconds for one epoch ---
--- 0.3082561492919922 seconds for one epoch ---
--- 4.694910049438477 seconds for one epoch ---
--- 0.3175022602081299 seconds for one epoch ---
--- 4.675727367401123 seconds for one epoch ---
--- 0.3198740482330322 seconds for one epoch ---
--- 4.591609239578247 seconds for one epoch ---
--- 0.33643317222595215 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995288]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-19.094746]
 [ -0.      ]]
--- 0.27530527114868164 seconds for one epoch ---
Epoch 9325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3317.861083984375, (1275.539, 1.9624218, 2039.8645, 0.4952552)
   validation loss 774.311279296875, (505.59998, 0.5706074, 267.64542, 0.4952552)
decoder loss ratio: 19587.820814, decoder SINDy loss  ratio: 0.577750
--- 0.314058780670166 seconds for one epoch ---
--- 4.702218770980835 seconds for one epoch ---
--- 0.34281015396118164 seconds for one epoch ---
--- 4.676858186721802 seconds for one epoch ---
--- 0.33524084091186523 seconds for one epoch ---
--- 4.693788290023804 seconds for one epoch ---
--- 0.33315157890319824 seconds for one epoch ---
--- 4.598961591720581 seconds for one epoch ---
--- 0.32991600036621094 seconds for one epoch ---
--- 4.686577081680298 seconds for one epoch ---
--- 0.33931875228881836 seconds for one epoch ---
--- 4.607821464538574 seconds for one epoch ---
--- 0.3275430202484131 seconds for one epoch ---
--- 4.67375636100769 seconds for one epoch ---
--- 0.33089494705200195 seconds for one epoch ---
--- 4.602445125579834 seconds for one epoch ---
--- 0.32888150215148926 seconds for one epoch ---
--- 4.613282680511475 seconds for one epoch ---
--- 0.31413912773132324 seconds for one epoch ---
--- 4.681744813919067 seconds for one epoch ---
--- 0.3366568088531494 seconds for one epoch ---
--- 4.670044660568237 seconds for one epoch ---
--- 0.32778286933898926 seconds for one epoch ---
--- 4.689843416213989 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995295]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.096853]
 [  0.      ]]
--- 0.3112452030181885 seconds for one epoch ---
Epoch 9350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3400.588623046875, (957.7007, 0.839988, 2441.5527, 0.49530768)
   validation loss 807.2151489257812, (526.49524, 0.57566774, 279.64896, 0.49530768)
decoder loss ratio: 20397.339605, decoder SINDy loss  ratio: 0.603662
--- 0.2698824405670166 seconds for one epoch ---
--- 0.33365535736083984 seconds for one epoch ---
--- 4.574948310852051 seconds for one epoch ---
--- 0.3099532127380371 seconds for one epoch ---
--- 4.695707082748413 seconds for one epoch ---
--- 0.32483887672424316 seconds for one epoch ---
--- 4.683136224746704 seconds for one epoch ---
--- 0.3242456912994385 seconds for one epoch ---
--- 4.686141490936279 seconds for one epoch ---
--- 0.3334054946899414 seconds for one epoch ---
--- 4.685759544372559 seconds for one epoch ---
--- 0.32785916328430176 seconds for one epoch ---
--- 4.69403600692749 seconds for one epoch ---
--- 0.32970118522644043 seconds for one epoch ---
--- 4.6863861083984375 seconds for one epoch ---
--- 0.33353257179260254 seconds for one epoch ---
--- 4.616723299026489 seconds for one epoch ---
--- 0.32287001609802246 seconds for one epoch ---
--- 4.696370601654053 seconds for one epoch ---
--- 0.3247051239013672 seconds for one epoch ---
--- 4.6194679737091064 seconds for one epoch ---
--- 0.32950401306152344 seconds for one epoch ---
--- 4.70861291885376 seconds for one epoch ---
--- 0.32813143730163574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952996]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.098076]
 [  0.      ]]
--- 0.27637600898742676 seconds for one epoch ---
Epoch 9375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4509.505859375, (2704.2688, 4.6259437, 1800.1161, 0.49534026)
   validation loss 796.60888671875, (520.6897, 0.578062, 274.84576, 0.49534026)
decoder loss ratio: 20172.422829, decoder SINDy loss  ratio: 0.593293
--- 0.3116798400878906 seconds for one epoch ---
--- 4.678752660751343 seconds for one epoch ---
--- 0.32846522331237793 seconds for one epoch ---
--- 4.6807098388671875 seconds for one epoch ---
--- 0.33096861839294434 seconds for one epoch ---
--- 4.595863103866577 seconds for one epoch ---
--- 0.33806729316711426 seconds for one epoch ---
--- 4.715585947036743 seconds for one epoch ---
--- 0.32403016090393066 seconds for one epoch ---
--- 4.62389874458313 seconds for one epoch ---
--- 0.33128786087036133 seconds for one epoch ---
--- 4.590743064880371 seconds for one epoch ---
--- 0.32715821266174316 seconds for one epoch ---
--- 4.70767879486084 seconds for one epoch ---
--- 0.3370351791381836 seconds for one epoch ---
--- 4.689694881439209 seconds for one epoch ---
--- 0.32486820220947266 seconds for one epoch ---
--- 4.624736070632935 seconds for one epoch ---
--- 0.3244819641113281 seconds for one epoch ---
--- 4.646260738372803 seconds for one epoch ---
--- 0.34082627296447754 seconds for one epoch ---
--- 4.728961706161499 seconds for one epoch ---
--- 0.32293248176574707 seconds for one epoch ---
--- 4.728935718536377 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995303]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-19.09883]
 [ -0.     ]]
--- 0.30037426948547363 seconds for one epoch ---
Epoch 9400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2651.544189453125, (797.7584, 6.4310293, 1846.8594, 0.49536714)
   validation loss 758.4052734375, (489.61, 0.57998323, 267.7199, 0.49536714)
decoder loss ratio: 18968.340833, decoder SINDy loss  ratio: 0.577911
--- 0.2646214962005615 seconds for one epoch ---
--- 0.3276960849761963 seconds for one epoch ---
--- 4.643835783004761 seconds for one epoch ---
--- 0.3381614685058594 seconds for one epoch ---
--- 4.62841272354126 seconds for one epoch ---
--- 0.3345050811767578 seconds for one epoch ---
--- 4.7328197956085205 seconds for one epoch ---
--- 0.3245358467102051 seconds for one epoch ---
--- 4.737068176269531 seconds for one epoch ---
--- 0.3307321071624756 seconds for one epoch ---
--- 4.630388021469116 seconds for one epoch ---
--- 0.33344507217407227 seconds for one epoch ---
--- 4.645007848739624 seconds for one epoch ---
--- 0.3375256061553955 seconds for one epoch ---
--- 4.737754583358765 seconds for one epoch ---
--- 0.32732391357421875 seconds for one epoch ---
--- 4.74247932434082 seconds for one epoch ---
--- 0.32770323753356934 seconds for one epoch ---
--- 4.722160816192627 seconds for one epoch ---
--- 0.326099157333374 seconds for one epoch ---
--- 4.725108861923218 seconds for one epoch ---
--- 0.3309903144836426 seconds for one epoch ---
--- 4.645385026931763 seconds for one epoch ---
--- 0.32526397705078125 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99953127]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.099735]
 [ -0.      ]]
--- 0.27830004692077637 seconds for one epoch ---
Epoch 9425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2196.5654296875, (1034.6926, 1.6748867, 1159.7025, 0.49538365)
   validation loss 742.7366333007812, (477.30154, 0.58059824, 264.35913, 0.49538365)
decoder loss ratio: 18491.490454, decoder SINDy loss  ratio: 0.570656
--- 0.32091403007507324 seconds for one epoch ---
--- 4.736192226409912 seconds for one epoch ---
--- 0.3284921646118164 seconds for one epoch ---
--- 4.710306406021118 seconds for one epoch ---
--- 0.3436427116394043 seconds for one epoch ---
--- 4.641817569732666 seconds for one epoch ---
--- 0.3321044445037842 seconds for one epoch ---
--- 4.645169973373413 seconds for one epoch ---
--- 0.3293743133544922 seconds for one epoch ---
--- 4.652032375335693 seconds for one epoch ---
--- 0.33038902282714844 seconds for one epoch ---
--- 4.628169536590576 seconds for one epoch ---
--- 0.31015682220458984 seconds for one epoch ---
--- 4.747117280960083 seconds for one epoch ---
--- 0.33326220512390137 seconds for one epoch ---
--- 4.644640684127808 seconds for one epoch ---
--- 0.33127307891845703 seconds for one epoch ---
--- 4.753357887268066 seconds for one epoch ---
--- 0.33751678466796875 seconds for one epoch ---
--- 4.728882074356079 seconds for one epoch ---
--- 0.32674694061279297 seconds for one epoch ---
--- 4.638468265533447 seconds for one epoch ---
--- 0.32696986198425293 seconds for one epoch ---
--- 4.7318079471588135 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999532]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.100435]
 [  0.      ]]
--- 0.31618571281433105 seconds for one epoch ---
Epoch 9450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2508.183349609375, (1047.3383, 0.44091487, 1459.9089, 0.4954105)
   validation loss 751.8983764648438, (489.5215, 0.58031434, 261.30112, 0.4954105)
decoder loss ratio: 18964.913334, decoder SINDy loss  ratio: 0.564055
--- 0.28397607803344727 seconds for one epoch ---
--- 0.3368253707885742 seconds for one epoch ---
--- 4.7264087200164795 seconds for one epoch ---
--- 0.32758212089538574 seconds for one epoch ---
--- 4.665582895278931 seconds for one epoch ---
--- 0.3184638023376465 seconds for one epoch ---
--- 4.709243535995483 seconds for one epoch ---
--- 0.34381103515625 seconds for one epoch ---
--- 4.646815538406372 seconds for one epoch ---
--- 0.3351764678955078 seconds for one epoch ---
--- 4.683019161224365 seconds for one epoch ---
--- 0.3281576633453369 seconds for one epoch ---
--- 4.63703727722168 seconds for one epoch ---
--- 0.343644380569458 seconds for one epoch ---
--- 4.734790325164795 seconds for one epoch ---
--- 0.33309221267700195 seconds for one epoch ---
--- 4.739153861999512 seconds for one epoch ---
--- 0.33911657333374023 seconds for one epoch ---
--- 4.659139633178711 seconds for one epoch ---
--- 0.3426973819732666 seconds for one epoch ---
--- 4.646331071853638 seconds for one epoch ---
--- 0.33057117462158203 seconds for one epoch ---
--- 4.751847982406616 seconds for one epoch ---
--- 0.3327600955963135 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995327]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.101923]
 [ -0.      ]]
--- 0.27272534370422363 seconds for one epoch ---
Epoch 9475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2094.21484375, (1033.1841, 0.29995188, 1060.2355, 0.49544945)
   validation loss 737.5870971679688, (474.94183, 0.57979476, 261.57007, 0.49544945)
decoder loss ratio: 18400.071165, decoder SINDy loss  ratio: 0.564636
--- 0.3102142810821533 seconds for one epoch ---
--- 4.730562925338745 seconds for one epoch ---
--- 0.34592413902282715 seconds for one epoch ---
--- 4.654253959655762 seconds for one epoch ---
--- 0.3450508117675781 seconds for one epoch ---
--- 4.760184288024902 seconds for one epoch ---
--- 0.32517313957214355 seconds for one epoch ---
--- 4.725977897644043 seconds for one epoch ---
--- 0.32085132598876953 seconds for one epoch ---
--- 4.65735125541687 seconds for one epoch ---
--- 0.33368515968322754 seconds for one epoch ---
--- 4.7068963050842285 seconds for one epoch ---
--- 0.3278014659881592 seconds for one epoch ---
--- 4.6451499462127686 seconds for one epoch ---
--- 0.32517099380493164 seconds for one epoch ---
--- 4.6447765827178955 seconds for one epoch ---
--- 0.3329637050628662 seconds for one epoch ---
--- 4.6603076457977295 seconds for one epoch ---
--- 0.347764253616333 seconds for one epoch ---
--- 4.654181957244873 seconds for one epoch ---
--- 0.33581995964050293 seconds for one epoch ---
--- 4.736580848693848 seconds for one epoch ---
--- 0.34319114685058594 seconds for one epoch ---
--- 4.635844945907593 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995331]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.103313]
 [  0.      ]]
--- 0.3066582679748535 seconds for one epoch ---
Epoch 9500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2377.314453125, (1069.3037, 1.6114492, 1305.9038, 0.49548656)
   validation loss 837.5177001953125, (555.3422, 0.5766398, 281.10333, 0.49548656)
decoder loss ratio: 21514.921879, decoder SINDy loss  ratio: 0.606801
THRESHOLDING: 1 active coefficients
--- 4.648908615112305 seconds for one epoch ---
--- 0.329571008682251 seconds for one epoch ---
--- 4.722955226898193 seconds for one epoch ---
--- 0.33075785636901855 seconds for one epoch ---
--- 4.708631277084351 seconds for one epoch ---
--- 0.3110196590423584 seconds for one epoch ---
--- 4.756080389022827 seconds for one epoch ---
--- 0.33028292655944824 seconds for one epoch ---
--- 4.671658277511597 seconds for one epoch ---
--- 0.33527112007141113 seconds for one epoch ---
--- 4.747063636779785 seconds for one epoch ---
--- 0.33941006660461426 seconds for one epoch ---
--- 4.71509051322937 seconds for one epoch ---
--- 0.33487629890441895 seconds for one epoch ---
--- 4.7809157371521 seconds for one epoch ---
--- 0.33196496963500977 seconds for one epoch ---
--- 4.685492515563965 seconds for one epoch ---
--- 0.3323049545288086 seconds for one epoch ---
--- 4.6758928298950195 seconds for one epoch ---
--- 0.33045172691345215 seconds for one epoch ---
--- 4.68927001953125 seconds for one epoch ---
--- 0.33122992515563965 seconds for one epoch ---
--- 4.753089427947998 seconds for one epoch ---
--- 0.33107638359069824 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995337]
 [0.       ]]
[[  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-19.1037]
 [  0.    ]]
--- 0.26673245429992676 seconds for one epoch ---
Epoch 9525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2326.690673828125, (1067.6077, 1.1363943, 1257.451, 0.49550128)
   validation loss 769.2669677734375, (499.2438, 0.57976866, 268.94794, 0.49550128)
decoder loss ratio: 19341.571728, decoder SINDy loss  ratio: 0.580562
--- 0.31319403648376465 seconds for one epoch ---
--- 4.698400974273682 seconds for one epoch ---
--- 0.32187676429748535 seconds for one epoch ---
--- 4.742612361907959 seconds for one epoch ---
--- 0.3318305015563965 seconds for one epoch ---
--- 4.746137619018555 seconds for one epoch ---
--- 0.33597326278686523 seconds for one epoch ---
--- 4.753539323806763 seconds for one epoch ---
--- 0.3243379592895508 seconds for one epoch ---
--- 4.645341396331787 seconds for one epoch ---
--- 0.33297085762023926 seconds for one epoch ---
--- 4.777632713317871 seconds for one epoch ---
--- 0.3359661102294922 seconds for one epoch ---
--- 4.714262247085571 seconds for one epoch ---
--- 0.3129143714904785 seconds for one epoch ---
--- 4.757927179336548 seconds for one epoch ---
--- 0.3287522792816162 seconds for one epoch ---
--- 4.78401780128479 seconds for one epoch ---
--- 0.32542872428894043 seconds for one epoch ---
--- 4.787749528884888 seconds for one epoch ---
--- 0.3279099464416504 seconds for one epoch ---
--- 4.810428857803345 seconds for one epoch ---
--- 0.3281111717224121 seconds for one epoch ---
--- 4.6899800300598145 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995345]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.105114]
 [ -0.      ]]
--- 0.31473708152770996 seconds for one epoch ---
Epoch 9550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1673.5333251953125, (771.72406, 3.9262824, 897.3875, 0.49553385)
   validation loss 780.6084594726562, (508.95374, 0.5850833, 270.57413, 0.49553385)
decoder loss ratio: 19717.751290, decoder SINDy loss  ratio: 0.584072
--- 0.2784452438354492 seconds for one epoch ---
--- 0.3253140449523926 seconds for one epoch ---
--- 4.729062080383301 seconds for one epoch ---
--- 0.33374929428100586 seconds for one epoch ---
--- 4.768686294555664 seconds for one epoch ---
--- 0.34162473678588867 seconds for one epoch ---
--- 4.729310512542725 seconds for one epoch ---
--- 0.33443784713745117 seconds for one epoch ---
--- 4.727579832077026 seconds for one epoch ---
--- 0.31871771812438965 seconds for one epoch ---
--- 4.771928548812866 seconds for one epoch ---
--- 0.3324146270751953 seconds for one epoch ---
--- 4.711060523986816 seconds for one epoch ---
--- 0.33223676681518555 seconds for one epoch ---
--- 4.79813027381897 seconds for one epoch ---
--- 0.32000088691711426 seconds for one epoch ---
--- 4.801078796386719 seconds for one epoch ---
--- 0.331834077835083 seconds for one epoch ---
--- 4.794961452484131 seconds for one epoch ---
--- 0.3307943344116211 seconds for one epoch ---
--- 4.736670255661011 seconds for one epoch ---
--- 0.3268871307373047 seconds for one epoch ---
--- 4.751519203186035 seconds for one epoch ---
--- 0.33762264251708984 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995351]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.106173]
 [ -0.      ]]
--- 0.2809109687805176 seconds for one epoch ---
Epoch 9575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3720.267822265625, (2238.4854, 2.4066646, 1478.8801, 0.49556738)
   validation loss 755.7235107421875, (489.4005, 0.58596563, 265.2415, 0.49556738)
decoder loss ratio: 18960.225498, decoder SINDy loss  ratio: 0.572561
--- 0.33006787300109863 seconds for one epoch ---
--- 4.774645566940308 seconds for one epoch ---
--- 0.31572723388671875 seconds for one epoch ---
--- 4.783520221710205 seconds for one epoch ---
--- 0.33063387870788574 seconds for one epoch ---
--- 4.717714071273804 seconds for one epoch ---
--- 0.3196449279785156 seconds for one epoch ---
--- 4.726475715637207 seconds for one epoch ---
--- 0.3337979316711426 seconds for one epoch ---
--- 4.695818185806274 seconds for one epoch ---
--- 0.3255040645599365 seconds for one epoch ---
--- 4.740011215209961 seconds for one epoch ---
--- 0.34096193313598633 seconds for one epoch ---
--- 4.804064512252808 seconds for one epoch ---
--- 0.33487772941589355 seconds for one epoch ---
--- 4.815628528594971 seconds for one epoch ---
--- 0.33969616889953613 seconds for one epoch ---
--- 4.709216833114624 seconds for one epoch ---
--- 0.31966161727905273 seconds for one epoch ---
--- 4.815172433853149 seconds for one epoch ---
--- 0.3395655155181885 seconds for one epoch ---
--- 4.823845148086548 seconds for one epoch ---
--- 0.33155107498168945 seconds for one epoch ---
--- 4.700950622558594 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995356]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.107464]
 [  0.      ]]
--- 0.3309299945831299 seconds for one epoch ---
Epoch 9600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2044.950927734375, (1089.4487, 2.2133825, 952.7933, 0.49560428)
   validation loss 774.0948486328125, (505.1114, 0.5885746, 267.89926, 0.49560428)
decoder loss ratio: 19568.892128, decoder SINDy loss  ratio: 0.578298
--- 0.2811155319213867 seconds for one epoch ---
--- 0.3365440368652344 seconds for one epoch ---
--- 4.6985626220703125 seconds for one epoch ---
--- 0.3252146244049072 seconds for one epoch ---
--- 4.805758953094482 seconds for one epoch ---
--- 0.3293747901916504 seconds for one epoch ---
--- 4.719423294067383 seconds for one epoch ---
--- 0.3265414237976074 seconds for one epoch ---
--- 4.8133385181427 seconds for one epoch ---
--- 0.3164989948272705 seconds for one epoch ---
--- 4.8089680671691895 seconds for one epoch ---
--- 0.3167538642883301 seconds for one epoch ---
--- 4.802539110183716 seconds for one epoch ---
--- 0.3346700668334961 seconds for one epoch ---
--- 4.825619697570801 seconds for one epoch ---
--- 0.33791279792785645 seconds for one epoch ---
--- 4.737240552902222 seconds for one epoch ---
--- 0.32617807388305664 seconds for one epoch ---
--- 4.793069124221802 seconds for one epoch ---
--- 0.3187999725341797 seconds for one epoch ---
--- 4.716983795166016 seconds for one epoch ---
--- 0.3334488868713379 seconds for one epoch ---
--- 4.824298620223999 seconds for one epoch ---
--- 0.3320772647857666 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99953604]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-19.107994]
 [ -0.      ]]
--- 0.27220630645751953 seconds for one epoch ---
Epoch 9625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2149.29345703125, (1004.37415, 0.87481636, 1143.549, 0.4956162)
   validation loss 768.0894775390625, (495.3476, 0.5841079, 271.6622, 0.4956162)
decoder loss ratio: 19190.625800, decoder SINDy loss  ratio: 0.586421
--- 0.3209700584411621 seconds for one epoch ---
--- 4.801954984664917 seconds for one epoch ---
--- 0.32741665840148926 seconds for one epoch ---
--- 4.801548957824707 seconds for one epoch ---
--- 0.3294820785522461 seconds for one epoch ---
--- 4.730902910232544 seconds for one epoch ---
--- 0.32733798027038574 seconds for one epoch ---
--- 4.7282843589782715 seconds for one epoch ---
--- 0.33209681510925293 seconds for one epoch ---
--- 4.708513498306274 seconds for one epoch ---
--- 0.32056164741516113 seconds for one epoch ---
--- 4.835758447647095 seconds for one epoch ---
--- 0.3315417766571045 seconds for one epoch ---
--- 4.721252679824829 seconds for one epoch ---
--- 0.32492756843566895 seconds for one epoch ---
--- 4.748162031173706 seconds for one epoch ---
--- 0.33788514137268066 seconds for one epoch ---
--- 4.809952259063721 seconds for one epoch ---
--- 0.3330352306365967 seconds for one epoch ---
--- 4.850364446640015 seconds for one epoch ---
--- 0.33318519592285156 seconds for one epoch ---
--- 4.81331467628479 seconds for one epoch ---
--- 0.32963037490844727 seconds for one epoch ---
--- 4.824077606201172 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99953663]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-19.10871]
 [  0.     ]]
--- 0.30081868171691895 seconds for one epoch ---
Epoch 9650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4017.4560546875, (1595.4227, 3.4939291, 2418.0437, 0.4956424)
   validation loss 731.9774780273438, (466.37863, 0.5817608, 264.52145, 0.4956424)
decoder loss ratio: 18068.317857, decoder SINDy loss  ratio: 0.571007
--- 0.2719130516052246 seconds for one epoch ---
--- 0.3315713405609131 seconds for one epoch ---
--- 4.726339817047119 seconds for one epoch ---
--- 0.3252139091491699 seconds for one epoch ---
--- 4.803632974624634 seconds for one epoch ---
--- 0.3199748992919922 seconds for one epoch ---
--- 4.759512662887573 seconds for one epoch ---
--- 0.33080482482910156 seconds for one epoch ---
--- 4.813589811325073 seconds for one epoch ---
--- 0.33472132682800293 seconds for one epoch ---
--- 4.826249837875366 seconds for one epoch ---
--- 0.32536959648132324 seconds for one epoch ---
--- 4.82958722114563 seconds for one epoch ---
--- 0.32550907135009766 seconds for one epoch ---
--- 4.742668151855469 seconds for one epoch ---
--- 0.33565711975097656 seconds for one epoch ---
--- 4.816524505615234 seconds for one epoch ---
--- 0.32515740394592285 seconds for one epoch ---
--- 4.740921258926392 seconds for one epoch ---
--- 0.33039402961730957 seconds for one epoch ---
--- 4.835193395614624 seconds for one epoch ---
--- 0.32723069190979004 seconds for one epoch ---
--- 4.788980484008789 seconds for one epoch ---
--- 0.322127103805542 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995376]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-19.11045]
 [  0.     ]]
--- 0.26930785179138184 seconds for one epoch ---
Epoch 9675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2402.53466796875, (1437.7709, 0.19409841, 964.07404, 0.49568722)
   validation loss 777.0405883789062, (506.804, 0.583308, 269.15762, 0.49568722)
decoder loss ratio: 19634.466252, decoder SINDy loss  ratio: 0.581015
--- 0.3170795440673828 seconds for one epoch ---
--- 4.8471839427948 seconds for one epoch ---
--- 0.3335578441619873 seconds for one epoch ---
--- 4.759948968887329 seconds for one epoch ---
--- 0.34070730209350586 seconds for one epoch ---
--- 4.830416202545166 seconds for one epoch ---
--- 0.34046435356140137 seconds for one epoch ---
--- 4.854730129241943 seconds for one epoch ---
--- 0.32944679260253906 seconds for one epoch ---
--- 4.768260955810547 seconds for one epoch ---
--- 0.3298461437225342 seconds for one epoch ---
--- 4.74694037437439 seconds for one epoch ---
--- 0.3343350887298584 seconds for one epoch ---
--- 4.749845743179321 seconds for one epoch ---
--- 0.32324910163879395 seconds for one epoch ---
--- 4.862988710403442 seconds for one epoch ---
--- 0.3408663272857666 seconds for one epoch ---
--- 4.7612409591674805 seconds for one epoch ---
--- 0.3293294906616211 seconds for one epoch ---
--- 4.8503663539886475 seconds for one epoch ---
--- 0.32768821716308594 seconds for one epoch ---
--- 4.775561809539795 seconds for one epoch ---
--- 0.33321189880371094 seconds for one epoch ---
--- 4.7756664752960205 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995384]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.111929]
 [ -0.      ]]
--- 0.31308555603027344 seconds for one epoch ---
Epoch 9700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4051.405029296875, (1745.537, 0.3470288, 2305.0251, 0.49572945)
   validation loss 842.862548828125, (561.71216, 0.58630407, 280.06833, 0.49572945)
decoder loss ratio: 21761.704184, decoder SINDy loss  ratio: 0.604567
--- 0.28035855293273926 seconds for one epoch ---
--- 0.3316068649291992 seconds for one epoch ---
--- 4.7738196849823 seconds for one epoch ---
--- 0.32825517654418945 seconds for one epoch ---
--- 4.858906030654907 seconds for one epoch ---
--- 0.3259861469268799 seconds for one epoch ---
--- 4.846286058425903 seconds for one epoch ---
--- 0.334399938583374 seconds for one epoch ---
--- 4.838104724884033 seconds for one epoch ---
--- 0.34024763107299805 seconds for one epoch ---
--- 4.837264776229858 seconds for one epoch ---
--- 0.32287096977233887 seconds for one epoch ---
--- 4.848299026489258 seconds for one epoch ---
--- 0.3253746032714844 seconds for one epoch ---
--- 4.758199691772461 seconds for one epoch ---
--- 0.3137192726135254 seconds for one epoch ---
--- 4.867805242538452 seconds for one epoch ---
--- 0.32370615005493164 seconds for one epoch ---
--- 4.761816501617432 seconds for one epoch ---
--- 0.3348872661590576 seconds for one epoch ---
--- 4.784622669219971 seconds for one epoch ---
--- 0.32781553268432617 seconds for one epoch ---
--- 4.875839471817017 seconds for one epoch ---
--- 0.32231879234313965 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99953926]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.112396]
 [ -0.      ]]
--- 0.2710256576538086 seconds for one epoch ---
Epoch 9725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2926.467041015625, (1270.586, 3.0812483, 1652.3037, 0.49574324)
   validation loss 751.1090087890625, (483.4029, 0.5914046, 266.619, 0.49574324)
decoder loss ratio: 18727.867302, decoder SINDy loss  ratio: 0.575535
--- 0.31716012954711914 seconds for one epoch ---
--- 4.775202512741089 seconds for one epoch ---
--- 0.32648229598999023 seconds for one epoch ---
--- 4.762777328491211 seconds for one epoch ---
--- 0.32781291007995605 seconds for one epoch ---
--- 4.847801923751831 seconds for one epoch ---
--- 0.3280308246612549 seconds for one epoch ---
--- 4.884230852127075 seconds for one epoch ---
--- 0.32683777809143066 seconds for one epoch ---
--- 4.794921398162842 seconds for one epoch ---
--- 0.3419671058654785 seconds for one epoch ---
--- 4.776163578033447 seconds for one epoch ---
--- 0.3350346088409424 seconds for one epoch ---
--- 4.8489251136779785 seconds for one epoch ---
--- 0.3285791873931885 seconds for one epoch ---
--- 4.880872011184692 seconds for one epoch ---
--- 0.3267555236816406 seconds for one epoch ---
--- 4.8103108406066895 seconds for one epoch ---
--- 0.3289363384246826 seconds for one epoch ---
--- 4.875365972518921 seconds for one epoch ---
--- 0.32262682914733887 seconds for one epoch ---
--- 4.869778633117676 seconds for one epoch ---
--- 0.3278188705444336 seconds for one epoch ---
--- 4.839170217514038 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995399]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.113289]
 [  0.      ]]
--- 0.31238603591918945 seconds for one epoch ---
Epoch 9750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2373.128173828125, (724.24994, 1.5741298, 1646.8081, 0.49576837)
   validation loss 762.1104125976562, (499.01205, 0.5946817, 262.00784, 0.49576837)
decoder loss ratio: 19332.593312, decoder SINDy loss  ratio: 0.565581
--- 0.2690091133117676 seconds for one epoch ---
--- 0.33740687370300293 seconds for one epoch ---
--- 4.850161552429199 seconds for one epoch ---
--- 0.33203864097595215 seconds for one epoch ---
--- 4.780870676040649 seconds for one epoch ---
--- 0.33145737648010254 seconds for one epoch ---
--- 4.85646390914917 seconds for one epoch ---
--- 0.31735897064208984 seconds for one epoch ---
--- 4.778844118118286 seconds for one epoch ---
--- 0.3275930881500244 seconds for one epoch ---
--- 4.871906757354736 seconds for one epoch ---
--- 0.33261728286743164 seconds for one epoch ---
--- 4.782031297683716 seconds for one epoch ---
--- 0.3345484733581543 seconds for one epoch ---
--- 4.866180896759033 seconds for one epoch ---
--- 0.3250727653503418 seconds for one epoch ---
--- 4.8011391162872314 seconds for one epoch ---
--- 0.3289070129394531 seconds for one epoch ---
--- 4.787496566772461 seconds for one epoch ---
--- 0.33432483673095703 seconds for one epoch ---
--- 4.8819708824157715 seconds for one epoch ---
--- 0.3282599449157715 seconds for one epoch ---
--- 4.787704229354858 seconds for one epoch ---
--- 0.327223539352417 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954045]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.115015]
 [ -0.      ]]
--- 0.28337812423706055 seconds for one epoch ---
Epoch 9775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1784.955078125, (693.6761, 0.6907568, 1090.0924, 0.49581662)
   validation loss 801.0755615234375, (526.74976, 0.5950818, 273.23492, 0.49581662)
decoder loss ratio: 20407.200020, decoder SINDy loss  ratio: 0.589816
--- 0.31179022789001465 seconds for one epoch ---
--- 4.877387523651123 seconds for one epoch ---
--- 0.3356146812438965 seconds for one epoch ---
--- 4.839717626571655 seconds for one epoch ---
--- 0.33075785636901855 seconds for one epoch ---
--- 4.794326543807983 seconds for one epoch ---
--- 0.3262817859649658 seconds for one epoch ---
--- 4.865142345428467 seconds for one epoch ---
--- 0.3286714553833008 seconds for one epoch ---
--- 4.784942865371704 seconds for one epoch ---
--- 0.3363618850708008 seconds for one epoch ---
--- 4.872292757034302 seconds for one epoch ---
--- 0.3168790340423584 seconds for one epoch ---
--- 4.808252811431885 seconds for one epoch ---
--- 0.32418394088745117 seconds for one epoch ---
--- 4.887390375137329 seconds for one epoch ---
--- 0.33124804496765137 seconds for one epoch ---
--- 4.80739426612854 seconds for one epoch ---
--- 0.3248465061187744 seconds for one epoch ---
--- 4.894310712814331 seconds for one epoch ---
--- 0.32556986808776855 seconds for one epoch ---
--- 4.828991889953613 seconds for one epoch ---
--- 0.3274567127227783 seconds for one epoch ---
--- 4.809182167053223 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995411]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.115576]
 [  0.      ]]
--- 0.30725550651550293 seconds for one epoch ---
Epoch 9800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2077.43359375, (1021.07574, 2.9614637, 1052.9005, 0.49582872)
   validation loss 780.9283447265625, (508.87292, 0.59540665, 270.96414, 0.49582872)
decoder loss ratio: 19714.620549, decoder SINDy loss  ratio: 0.584914
--- 0.28373193740844727 seconds for one epoch ---
--- 0.3373851776123047 seconds for one epoch ---
--- 4.880392789840698 seconds for one epoch ---
--- 0.32231807708740234 seconds for one epoch ---
--- 4.81162691116333 seconds for one epoch ---
--- 0.3347611427307129 seconds for one epoch ---
--- 4.8883583545684814 seconds for one epoch ---
--- 0.3139021396636963 seconds for one epoch ---
--- 4.883482217788696 seconds for one epoch ---
--- 0.3389451503753662 seconds for one epoch ---
--- 4.795309543609619 seconds for one epoch ---
--- 0.3350343704223633 seconds for one epoch ---
--- 4.9059364795684814 seconds for one epoch ---
--- 0.33318424224853516 seconds for one epoch ---
--- 4.920215129852295 seconds for one epoch ---
--- 0.3301694393157959 seconds for one epoch ---
--- 4.805588006973267 seconds for one epoch ---
--- 0.32849669456481934 seconds for one epoch ---
--- 4.854295015335083 seconds for one epoch ---
--- 0.32985687255859375 seconds for one epoch ---
--- 4.892158269882202 seconds for one epoch ---
--- 0.33323144912719727 seconds for one epoch ---
--- 4.924088001251221 seconds for one epoch ---
--- 0.3168957233428955 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995421]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.116587]
 [  0.      ]]
--- 0.2697184085845947 seconds for one epoch ---
Epoch 9825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2617.836181640625, (1295.4382, 2.9292996, 1318.9728, 0.49586007)
   validation loss 799.0675048828125, (524.72766, 0.588013, 273.25595, 0.49586007)
decoder loss ratio: 20328.860560, decoder SINDy loss  ratio: 0.589861
--- 0.304058313369751 seconds for one epoch ---
--- 4.813853025436401 seconds for one epoch ---
--- 0.33774399757385254 seconds for one epoch ---
--- 4.8814146518707275 seconds for one epoch ---
--- 0.3286874294281006 seconds for one epoch ---
--- 4.796605348587036 seconds for one epoch ---
--- 0.323455810546875 seconds for one epoch ---
--- 4.914530992507935 seconds for one epoch ---
--- 0.337078332901001 seconds for one epoch ---
--- 4.912639379501343 seconds for one epoch ---
--- 0.32219648361206055 seconds for one epoch ---
--- 4.804475545883179 seconds for one epoch ---
--- 0.33274292945861816 seconds for one epoch ---
--- 4.820776462554932 seconds for one epoch ---
--- 0.3284926414489746 seconds for one epoch ---
--- 4.822591304779053 seconds for one epoch ---
--- 0.3334474563598633 seconds for one epoch ---
--- 4.912539720535278 seconds for one epoch ---
--- 0.32460451126098633 seconds for one epoch ---
--- 4.814011812210083 seconds for one epoch ---
--- 0.33145833015441895 seconds for one epoch ---
--- 4.9238951206207275 seconds for one epoch ---
--- 0.3227968215942383 seconds for one epoch ---
--- 4.823354482650757 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954283]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-19.11796]
 [ -0.     ]]
--- 0.30968570709228516 seconds for one epoch ---
Epoch 9850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2433.384521484375, (966.298, 1.444709, 1465.146, 0.49589607)
   validation loss 802.0138549804688, (525.7965, 0.5871294, 275.13428, 0.49589607)
decoder loss ratio: 20370.269573, decoder SINDy loss  ratio: 0.593916
--- 0.2768127918243408 seconds for one epoch ---
--- 0.32368040084838867 seconds for one epoch ---
--- 4.898484706878662 seconds for one epoch ---
--- 0.33305954933166504 seconds for one epoch ---
--- 4.913128852844238 seconds for one epoch ---
--- 0.33344221115112305 seconds for one epoch ---
--- 4.9287755489349365 seconds for one epoch ---
--- 0.32829880714416504 seconds for one epoch ---
--- 4.934640407562256 seconds for one epoch ---
--- 0.32730531692504883 seconds for one epoch ---
--- 4.815464496612549 seconds for one epoch ---
--- 0.32999348640441895 seconds for one epoch ---
--- 4.910297870635986 seconds for one epoch ---
--- 0.339113712310791 seconds for one epoch ---
--- 4.813213348388672 seconds for one epoch ---
--- 0.3311038017272949 seconds for one epoch ---
--- 4.950184345245361 seconds for one epoch ---
--- 0.33631157875061035 seconds for one epoch ---
--- 4.926645994186401 seconds for one epoch ---
--- 0.3213512897491455 seconds for one epoch ---
--- 4.830739736557007 seconds for one epoch ---
--- 0.3311190605163574 seconds for one epoch ---
--- 4.919666528701782 seconds for one epoch ---
--- 0.3252851963043213 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954355]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.118408]
 [ -0.      ]]
--- 0.27137255668640137 seconds for one epoch ---
Epoch 9875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1938.426025390625, (741.0541, 2.59606, 1194.2799, 0.49591094)
   validation loss 758.1987915039062, (492.78073, 0.5903363, 264.3318, 0.49591094)
decoder loss ratio: 19091.181032, decoder SINDy loss  ratio: 0.570597
--- 0.32172060012817383 seconds for one epoch ---
--- 4.8534698486328125 seconds for one epoch ---
--- 0.32009196281433105 seconds for one epoch ---
--- 4.839859962463379 seconds for one epoch ---
--- 0.3311789035797119 seconds for one epoch ---
--- 4.819841384887695 seconds for one epoch ---
--- 0.31594085693359375 seconds for one epoch ---
--- 4.848544597625732 seconds for one epoch ---
--- 0.3211503028869629 seconds for one epoch ---
--- 4.844732284545898 seconds for one epoch ---
--- 0.3229849338531494 seconds for one epoch ---
--- 4.861117362976074 seconds for one epoch ---
--- 0.3293182849884033 seconds for one epoch ---
--- 4.945384979248047 seconds for one epoch ---
--- 0.3226766586303711 seconds for one epoch ---
--- 4.831562042236328 seconds for one epoch ---
--- 0.3208591938018799 seconds for one epoch ---
--- 4.849969387054443 seconds for one epoch ---
--- 0.33187365531921387 seconds for one epoch ---
--- 4.840494871139526 seconds for one epoch ---
--- 0.33476805686950684 seconds for one epoch ---
--- 4.951598882675171 seconds for one epoch ---
--- 0.32303524017333984 seconds for one epoch ---
--- 4.855014324188232 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954414]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.119642]
 [  0.      ]]
--- 0.3022575378417969 seconds for one epoch ---
Epoch 9900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2155.93212890625, (797.3569, 2.1816008, 1355.8978, 0.49593973)
   validation loss 757.397705078125, (493.7367, 0.59065664, 262.57443, 0.49593973)
decoder loss ratio: 19128.216703, decoder SINDy loss  ratio: 0.566804
--- 1.9779510498046875 seconds for one epoch ---
--- 0.3175666332244873 seconds for one epoch ---
--- 4.843116044998169 seconds for one epoch ---
--- 0.3253486156463623 seconds for one epoch ---
--- 4.9327404499053955 seconds for one epoch ---
--- 0.323946475982666 seconds for one epoch ---
--- 4.960974216461182 seconds for one epoch ---
--- 0.31851768493652344 seconds for one epoch ---
--- 4.873846530914307 seconds for one epoch ---
--- 0.32977294921875 seconds for one epoch ---
--- 4.938634872436523 seconds for one epoch ---
--- 0.3222994804382324 seconds for one epoch ---
--- 4.967304944992065 seconds for one epoch ---
--- 0.3266868591308594 seconds for one epoch ---
--- 4.878782749176025 seconds for one epoch ---
--- 0.33532142639160156 seconds for one epoch ---
--- 4.943421840667725 seconds for one epoch ---
--- 0.3305659294128418 seconds for one epoch ---
--- 4.863007307052612 seconds for one epoch ---
--- 0.32547521591186523 seconds for one epoch ---
--- 4.9663245677948 seconds for one epoch ---
--- 0.33251166343688965 seconds for one epoch ---
--- 4.9601287841796875 seconds for one epoch ---
--- 0.3365590572357178 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995451]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-19.120695]
 [ -0.      ]]
--- 0.2699403762817383 seconds for one epoch ---
Epoch 9925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2733.2490234375, (1079.1151, 0.9275356, 1652.7103, 0.49597198)
   validation loss 725.375, (461.54486, 0.58806306, 262.7461, 0.49597198)
decoder loss ratio: 17881.049186, decoder SINDy loss  ratio: 0.567174
--- 0.31334590911865234 seconds for one epoch ---
--- 4.8516552448272705 seconds for one epoch ---
--- 0.32271289825439453 seconds for one epoch ---
--- 4.9360129833221436 seconds for one epoch ---
--- 0.3171985149383545 seconds for one epoch ---
--- 4.862460613250732 seconds for one epoch ---
--- 0.3362705707550049 seconds for one epoch ---
--- 4.94008731842041 seconds for one epoch ---
--- 0.3281400203704834 seconds for one epoch ---
--- 4.968716382980347 seconds for one epoch ---
--- 0.3329300880432129 seconds for one epoch ---
--- 4.958898305892944 seconds for one epoch ---
--- 0.33472609519958496 seconds for one epoch ---
--- 4.976756572723389 seconds for one epoch ---
--- 0.3318295478820801 seconds for one epoch ---
--- 4.864714860916138 seconds for one epoch ---
--- 0.33245348930358887 seconds for one epoch ---
--- 4.960585117340088 seconds for one epoch ---
--- 0.3191828727722168 seconds for one epoch ---
--- 4.8685142993927 seconds for one epoch ---
--- 0.329420804977417 seconds for one epoch ---
--- 4.975034475326538 seconds for one epoch ---
--- 0.32556962966918945 seconds for one epoch ---
--- 4.879710912704468 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999546]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-19.121754]
 [  0.      ]]
--- 0.3138577938079834 seconds for one epoch ---
Epoch 9950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2284.355712890625, (872.73535, 1.4109716, 1409.7133, 0.49600777)
   validation loss 764.5249633789062, (492.0919, 0.5873378, 271.3497, 0.49600777)
decoder loss ratio: 19064.494067, decoder SINDy loss  ratio: 0.585746
--- 0.28289246559143066 seconds for one epoch ---
--- 0.33161187171936035 seconds for one epoch ---
--- 4.910979986190796 seconds for one epoch ---
--- 0.3345062732696533 seconds for one epoch ---
--- 4.894076585769653 seconds for one epoch ---
--- 0.3335299491882324 seconds for one epoch ---
--- 4.876504898071289 seconds for one epoch ---
--- 0.3311164379119873 seconds for one epoch ---
--- 4.961379766464233 seconds for one epoch ---
--- 0.33798813819885254 seconds for one epoch ---
--- 4.983147621154785 seconds for one epoch ---
--- 0.3304901123046875 seconds for one epoch ---
--- 4.879158973693848 seconds for one epoch ---
--- 0.34207987785339355 seconds for one epoch ---
--- 4.952318429946899 seconds for one epoch ---
--- 0.33777499198913574 seconds for one epoch ---
--- 4.877959251403809 seconds for one epoch ---
--- 0.3350493907928467 seconds for one epoch ---
--- 4.9078192710876465 seconds for one epoch ---
--- 0.3314080238342285 seconds for one epoch ---
--- 4.89018988609314 seconds for one epoch ---
--- 0.3303384780883789 seconds for one epoch ---
--- 4.99601411819458 seconds for one epoch ---
--- 0.32533740997314453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954677]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-19.122976]
 [  0.      ]]
--- 0.27528882026672363 seconds for one epoch ---
Epoch 9975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1996.31591796875, (719.2833, 0.61689234, 1275.9196, 0.49603304)
   validation loss 767.2186279296875, (502.4814, 0.584216, 263.65695, 0.49603304)
decoder loss ratio: 19467.002355, decoder SINDy loss  ratio: 0.569141
--- 0.3054637908935547 seconds for one epoch ---
--- 4.968329191207886 seconds for one epoch ---
--- 0.33631372451782227 seconds for one epoch ---
--- 4.862806081771851 seconds for one epoch ---
--- 0.33655405044555664 seconds for one epoch ---
--- 4.874944448471069 seconds for one epoch ---
--- 0.34337782859802246 seconds for one epoch ---
--- 4.888499975204468 seconds for one epoch ---
--- 0.3314192295074463 seconds for one epoch ---
--- 4.988802909851074 seconds for one epoch ---
--- 0.3290402889251709 seconds for one epoch ---
--- 4.881717681884766 seconds for one epoch ---
--- 0.32220983505249023 seconds for one epoch ---
--- 5.000740051269531 seconds for one epoch ---
--- 0.32507777214050293 seconds for one epoch ---
--- 4.907998561859131 seconds for one epoch ---
--- 0.3347041606903076 seconds for one epoch ---
--- 4.883225440979004 seconds for one epoch ---
--- 0.32751011848449707 seconds for one epoch ---
--- 4.975062131881714 seconds for one epoch ---
--- 0.3342132568359375 seconds for one epoch ---
--- 4.9020750522613525 seconds for one epoch ---
--- 0.33513331413269043 seconds for one epoch ---
--- 5.004347801208496 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954754]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.123657]
 [ -0.      ]]
--- 0.31264734268188477 seconds for one epoch ---
Epoch 10000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3155.79052734375, (1187.2098, 0.5351573, 1967.5494, 0.49605188)
   validation loss 752.8923950195312, (484.99762, 0.58449715, 266.8142, 0.49605188)
decoder loss ratio: 18789.649777, decoder SINDy loss  ratio: 0.575956
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99954766]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-19.123617]
 [  0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1064.38720703125, (547.78455, 0.6080188, 515.9947, 0.49617204)
   validation loss 712.4034423828125, (447.79333, 0.46151385, 264.1486, 0.49617204)
decoder loss ratio: 17348.291200, decoder SINDy loss  ratio: 0.570202
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99955356]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.199516]
 [ -0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2150.43603515625, (1640.7247, 0.14741546, 509.56372, 0.49751472)
   validation loss 2014.853759765625, (1718.0009, 0.31212875, 296.5408, 0.49751472)
decoder loss ratio: 66558.335684, decoder SINDy loss  ratio: 0.640125
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995433]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-19.095814]
 [  0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 976.9576416015625, (489.2046, 0.12850527, 487.62454, 0.49491557)
   validation loss 631.0514526367188, (401.1237, 0.15157267, 229.7762, 0.49491557)
decoder loss ratio: 15540.228045, decoder SINDy loss  ratio: 0.496004
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99952537]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.951172]
 [ -0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 864.096923828125, (385.9382, 0.16837221, 477.9904, 0.4910029)
   validation loss 554.846435546875, (328.85916, 0.11245373, 225.87485, 0.4910029)
decoder loss ratio: 12740.574836, decoder SINDy loss  ratio: 0.487583
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9995053]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.795477]
 [  0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 744.0440063476562, (279.24268, 0.19683789, 464.6045, 0.486878)
   validation loss 455.8464660644531, (230.21233, 0.09393557, 225.5402, 0.486878)
decoder loss ratio: 8918.825177, decoder SINDy loss  ratio: 0.486860
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99948233]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-18.672363]
 [  0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1549.21240234375, (1022.7195, 0.21490893, 526.2781, 0.482915)
   validation loss 1188.88720703125, (942.10376, 0.07731072, 246.70613, 0.482915)
decoder loss ratio: 36498.735217, decoder SINDy loss  ratio: 0.532550
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994627]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-18.492989]
 [  0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.9164428710938, (277.4759, 0.20978622, 459.23077, 0.47912416)
   validation loss 434.40704345703125, (212.48508, 0.07657363, 221.84541, 0.47912416)
decoder loss ratio: 8232.040770, decoder SINDy loss  ratio: 0.478885
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99944204]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-18.376434]
 [  0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 806.9935302734375, (337.74774, 0.22114132, 469.02466, 0.47564077)
   validation loss 499.28155517578125, (277.46896, 0.07059596, 221.742, 0.47564077)
decoder loss ratio: 10749.629358, decoder SINDy loss  ratio: 0.478661
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994215]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.276955]
 [ -0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 757.3309326171875, (306.618, 0.23104216, 450.48187, 0.4724516)
   validation loss 463.6874084472656, (239.72632, 0.06469065, 223.8964, 0.4724516)
decoder loss ratio: 9287.413756, decoder SINDy loss  ratio: 0.483312
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9994024]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-18.14288]
 [  0.     ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 728.3294067382812, (275.28262, 0.23701118, 452.80978, 0.46952772)
   validation loss 439.78753662109375, (220.29173, 0.05611488, 219.43967, 0.46952772)
decoder loss ratio: 8534.484171, decoder SINDy loss  ratio: 0.473691
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993862]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-18.039013]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.583740234375, (455.38205, 0.21782121, 447.98383, 0.4669082)
   validation loss 616.1929931640625, (379.89597, 0.05649431, 236.24051, 0.4669082)
decoder loss ratio: 14717.829235, decoder SINDy loss  ratio: 0.509958
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993694]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.963629]
 [ -0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.7625122070312, (256.195, 0.23130007, 445.3362, 0.46459356)
   validation loss 413.99505615234375, (194.694, 0.058588177, 219.24248, 0.46459356)
decoder loss ratio: 7542.783573, decoder SINDy loss  ratio: 0.473266
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99935347]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.857595]
 [  0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.8797607421875, (341.0219, 0.24194582, 440.61588, 0.46245074)
   validation loss 487.91107177734375, (265.0718, 0.05874586, 222.78052, 0.46245074)
decoder loss ratio: 10269.342021, decoder SINDy loss  ratio: 0.480903
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993392]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.800636]
 [ -0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.5986938476562, (235.08525, 0.25103223, 442.26242, 0.46050507)
   validation loss 403.42205810546875, (187.89569, 0.056021545, 215.47034, 0.46050507)
decoder loss ratio: 7279.405267, decoder SINDy loss  ratio: 0.465123
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9993249]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.72711]
 [ -0.     ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 765.20947265625, (310.7487, 0.25192803, 454.20883, 0.45876828)
   validation loss 493.552978515625, (277.5836, 0.05041036, 215.91898, 0.45876828)
decoder loss ratio: 10754.070092, decoder SINDy loss  ratio: 0.466091
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99931157]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.688215]
 [ -0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 857.8419189453125, (398.90445, 0.2286517, 458.70883, 0.45711103)
   validation loss 580.9088134765625, (362.58078, 0.052828696, 218.2752, 0.45711103)
decoder loss ratio: 14047.008886, decoder SINDy loss  ratio: 0.471178
=========================
[[0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.    ]
 [0.9993]
 [0.    ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.600315]
 [ -0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.980224609375, (353.14398, 0.23219366, 432.60403, 0.45573354)
   validation loss 494.7080993652344, (274.1605, 0.05481447, 220.4928, 0.45573354)
decoder loss ratio: 10621.453421, decoder SINDy loss  ratio: 0.475965
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99928975]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.598467]
 [  0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.8294677734375, (301.0797, 0.23509179, 430.51465, 0.45446816)
   validation loss 445.80255126953125, (228.66159, 0.05665562, 217.08432, 0.45446816)
decoder loss ratio: 8858.746993, decoder SINDy loss  ratio: 0.468607
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99928164]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.526936]
 [  0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 697.922119140625, (268.5512, 0.23920263, 429.1317, 0.45333806)
   validation loss 415.26947021484375, (200.44264, 0.056699093, 214.77011, 0.45333806)
decoder loss ratio: 7765.495943, decoder SINDy loss  ratio: 0.463611
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992734]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.495077]
 [  0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1492.25244140625, (1052.5474, 0.23031816, 439.4747, 0.4524064)
   validation loss 1152.099365234375, (901.90186, 0.06237216, 250.1351, 0.4524064)
decoder loss ratio: 34941.243651, decoder SINDy loss  ratio: 0.539952
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992656]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.454008]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 714.8868408203125, (277.2498, 0.20472471, 437.43237, 0.45148736)
   validation loss 431.6861572265625, (219.0487, 0.057343457, 212.58012, 0.45148736)
decoder loss ratio: 8486.327158, decoder SINDy loss  ratio: 0.458884
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992609]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.436134]
 [  0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.4302978515625, (295.84006, 0.19948137, 424.39078, 0.45085582)
   validation loss 441.3394775390625, (222.74852, 0.058963675, 218.53198, 0.45085582)
decoder loss ratio: 8629.664369, decoder SINDy loss  ratio: 0.471732
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99925643]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.394274]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 655.05322265625, (228.21637, 0.22683701, 426.61, 0.45033476)
   validation loss 391.44140625, (180.15529, 0.059912927, 211.22621, 0.45033476)
decoder loss ratio: 6979.528647, decoder SINDy loss  ratio: 0.455961
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992513]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.398674]
 [  0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1246.45849609375, (767.72095, 0.21888088, 478.51874, 0.4497161)
   validation loss 982.741943359375, (754.4053, 0.054470733, 228.2822, 0.4497161)
decoder loss ratio: 29226.969998, decoder SINDy loss  ratio: 0.492779
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99924606]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.361616]
 [  0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 801.8242797851562, (383.16653, 0.21360198, 418.44415, 0.4491787)
   validation loss 519.8202514648438, (300.4949, 0.060875732, 219.26445, 0.4491787)
decoder loss ratio: 11641.694246, decoder SINDy loss  ratio: 0.473313
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992414]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.338799]
 [ -0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 706.0933227539062, (289.13568, 0.22017817, 416.73746, 0.4487279)
   validation loss 429.9665832519531, (216.31088, 0.06181522, 213.59389, 0.4487279)
decoder loss ratio: 8380.259123, decoder SINDy loss  ratio: 0.461072
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99923694]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.323616]
 [  0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.8743286132812, (229.6853, 0.23314074, 418.9559, 0.44831267)
   validation loss 387.1825256347656, (178.67422, 0.060583178, 208.44772, 0.44831267)
decoder loss ratio: 6922.149663, decoder SINDy loss  ratio: 0.449964
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99923366]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.310064]
 [ -0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.3045043945312, (309.058, 0.19909206, 418.0474, 0.4479293)
   validation loss 445.73919677734375, (238.20647, 0.07069701, 207.46202, 0.4479293)
decoder loss ratio: 9228.532064, decoder SINDy loss  ratio: 0.447836
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99923056]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.29654]
 [  0.     ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 817.9857788085938, (405.0051, 0.21228594, 412.7684, 0.44759065)
   validation loss 533.751953125, (316.24933, 0.06022212, 217.44244, 0.44759065)
decoder loss ratio: 12252.048023, decoder SINDy loss  ratio: 0.469380
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992277]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.26526]
 [  0.     ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 708.2255859375, (296.5798, 0.21745649, 411.42834, 0.44728398)
   validation loss 431.4642028808594, (220.247, 0.060296606, 211.1569, 0.44728398)
decoder loss ratio: 8532.750914, decoder SINDy loss  ratio: 0.455812
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999226]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.258224]
 [ -0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.6017456054688, (229.69609, 0.2264082, 413.67923, 0.44702274)
   validation loss 382.97998046875, (176.40518, 0.058441143, 206.51636, 0.44702274)
decoder loss ratio: 6834.242999, decoder SINDy loss  ratio: 0.445795
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992238]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.265303]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.3318481445312, (316.25247, 0.19646385, 433.8829, 0.4467329)
   validation loss 453.7638854980469, (244.5153, 0.059436105, 209.18915, 0.4467329)
decoder loss ratio: 9472.947396, decoder SINDy loss  ratio: 0.451564
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99922204]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.263304]
 [ -0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.362060546875, (248.74352, 0.20244822, 412.41608, 0.4465273)
   validation loss 388.496337890625, (181.03252, 0.057837747, 207.406, 0.4465273)
decoder loss ratio: 7013.513975, decoder SINDy loss  ratio: 0.447715
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99921995]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.261866]
 [  0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 737.8739013671875, (331.16638, 0.21007632, 406.49747, 0.44633612)
   validation loss 459.44940185546875, (248.4445, 0.05803129, 210.94688, 0.44633612)
decoder loss ratio: 9625.171395, decoder SINDy loss  ratio: 0.455359
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992186]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-17.24609]
 [  0.     ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 772.9391479492188, (337.37595, 0.21930686, 435.3439, 0.44621244)
   validation loss 519.6038818359375, (310.61218, 0.051885277, 208.93979, 0.44621244)
decoder loss ratio: 12033.655201, decoder SINDy loss  ratio: 0.451026
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992168]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.203964]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.850341796875, (279.84375, 0.19121668, 407.81537, 0.44599637)
   validation loss 414.02374267578125, (205.89388, 0.05603046, 208.07385, 0.44599637)
decoder loss ratio: 7976.686170, decoder SINDy loss  ratio: 0.449157
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992162]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.225513]
 [  0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 650.6297607421875, (240.74084, 0.19997685, 409.68896, 0.44588032)
   validation loss 381.9981689453125, (176.44061, 0.05455876, 205.50299, 0.44588032)
decoder loss ratio: 6835.615654, decoder SINDy loss  ratio: 0.443607
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992144]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.233578]
 [  0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 793.6522216796875, (390.23303, 0.187717, 403.23145, 0.44576693)
   validation loss 515.3754272460938, (299.51834, 0.05543128, 215.80165, 0.44576693)
decoder loss ratio: 11603.860520, decoder SINDy loss  ratio: 0.465838
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99921405]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.214998]
 [ -0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 634.3117065429688, (222.64679, 0.20505324, 411.45987, 0.44570395)
   validation loss 386.05242919921875, (182.62927, 0.052066002, 203.37108, 0.44570395)
decoder loss ratio: 7075.375073, decoder SINDy loss  ratio: 0.439005
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99921215]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.20457]
 [  0.     ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1015.8424072265625, (562.7675, 0.18677458, 452.88815, 0.44553834)
   validation loss 749.8636474609375, (534.8437, 0.052318335, 214.96764, 0.44553834)
decoder loss ratio: 20720.773040, decoder SINDy loss  ratio: 0.464038
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99921215]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.225979]
 [ -0.      ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 820.7836303710938, (388.00638, 0.17714098, 432.6001, 0.44555417)
   validation loss 531.9005126953125, (325.13754, 0.05709432, 206.70586, 0.44555417)
decoder loss ratio: 12596.392869, decoder SINDy loss  ratio: 0.446204
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992113]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.20874]
 [ -0.     ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 750.30029296875, (349.21765, 0.18788543, 400.89474, 0.44549742)
   validation loss 477.2567138671875, (265.89362, 0.05323962, 211.30984, 0.44549742)
decoder loss ratio: 10301.180285, decoder SINDy loss  ratio: 0.456142
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992099]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.185486]
 [  0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.4127197265625, (327.308, 0.19222578, 399.9125, 0.44539076)
   validation loss 456.0956115722656, (246.54153, 0.05249837, 209.50157, 0.44539076)
decoder loss ratio: 9551.447059, decoder SINDy loss  ratio: 0.452239
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992092]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.20285]
 [ -0.     ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 721.3042602539062, (322.04605, 0.17844868, 399.07977, 0.4453178)
   validation loss 451.792724609375, (241.47375, 0.052297205, 210.2667, 0.4453178)
decoder loss ratio: 9355.112481, decoder SINDy loss  ratio: 0.453890
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992088]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.188637]
 [  0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.0035400390625, (246.5213, 0.19529533, 401.28693, 0.4452609)
   validation loss 386.379638671875, (181.19043, 0.049402755, 205.13982, 0.4452609)
decoder loss ratio: 7019.631807, decoder SINDy loss  ratio: 0.442823
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992084]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.205599]
 [ -0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 627.32470703125, (222.68259, 0.20838073, 404.43372, 0.44519988)
   validation loss 374.39215087890625, (172.38937, 0.049227793, 201.95357, 0.44519988)
decoder loss ratio: 6678.663621, decoder SINDy loss  ratio: 0.435945
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99920654]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.18102]
 [  0.     ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2134.026611328125, (1708.2827, 0.19194677, 425.55206, 0.4451081)
   validation loss 1761.5260009765625, (1496.7896, 0.05292257, 264.6835, 0.4451081)
decoder loss ratio: 57988.225738, decoder SINDy loss  ratio: 0.571357
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99920523]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.200247]
 [  0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1546.494140625, (1124.7046, 0.19166404, 421.59784, 0.44501182)
   validation loss 1186.550048828125, (934.1633, 0.046153456, 252.34064, 0.44501182)
decoder loss ratio: 36191.109186, decoder SINDy loss  ratio: 0.544713
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99920547]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.197815]
 [ -0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.34375, (250.04268, 0.18037623, 407.1207, 0.44494972)
   validation loss 384.189697265625, (181.53023, 0.04868947, 202.61076, 0.44494972)
decoder loss ratio: 7032.796170, decoder SINDy loss  ratio: 0.437364
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992051]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.179749]
 [ -0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 796.224853515625, (400.0129, 0.19279516, 396.01913, 0.4448962)
   validation loss 513.2904663085938, (303.37454, 0.048265796, 209.86763, 0.4448962)
decoder loss ratio: 11753.256448, decoder SINDy loss  ratio: 0.453029
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992047]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.183596]
 [ -0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 813.2566528320312, (418.11432, 0.17304276, 394.9693, 0.4448081)
   validation loss 537.6351318359375, (324.7704, 0.049544618, 212.81522, 0.4448081)
decoder loss ratio: 12582.168570, decoder SINDy loss  ratio: 0.459392
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992043]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.168865]
 [ -0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.5179443359375, (234.79668, 0.19999027, 411.52124, 0.44478947)
   validation loss 398.7765808105469, (196.98558, 0.045215998, 201.74579, 0.44478947)
decoder loss ratio: 7631.563368, decoder SINDy loss  ratio: 0.435497
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992032]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.180786]
 [ -0.      ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1084.72265625, (628.12, 0.1787649, 456.42395, 0.4446376)
   validation loss 802.499755859375, (587.09143, 0.045595895, 215.36276, 0.4446376)
decoder loss ratio: 22744.941259, decoder SINDy loss  ratio: 0.464891
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992022]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [-17.1757]
 [ -0.    ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 761.569091796875, (366.3863, 0.17350465, 395.00928, 0.44458133)
   validation loss 488.3010559082031, (276.358, 0.045476846, 211.89758, 0.44458133)
decoder loss ratio: 10706.588765, decoder SINDy loss  ratio: 0.457411
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9992022]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.157484]
 [  0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 633.5452880859375, (226.40466, 0.19427755, 406.94638, 0.4445695)
   validation loss 385.63983154296875, (184.1855, 0.04417449, 201.41017, 0.4445695)
decoder loss ratio: 7135.666073, decoder SINDy loss  ratio: 0.434772
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99920166]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.167246]
 [  0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 644.2742919921875, (233.87976, 0.20525791, 410.18927, 0.44449064)
   validation loss 393.4930419921875, (192.57545, 0.04310536, 200.87448, 0.44449064)
decoder loss ratio: 7460.707441, decoder SINDy loss  ratio: 0.433616
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991991]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.168955]
 [ -0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 840.376220703125, (417.71573, 0.19780461, 422.4627, 0.4442919)
   validation loss 615.2020263671875, (410.3229, 0.041109577, 204.83804, 0.4442919)
decoder loss ratio: 15896.621749, decoder SINDy loss  ratio: 0.442172
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99919796]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.176867]
 [ -0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.1915283203125, (270.4785, 0.18186635, 397.5312, 0.44413596)
   validation loss 397.2354736328125, (194.391, 0.04364973, 202.80083, 0.44413596)
decoder loss ratio: 7531.045068, decoder SINDy loss  ratio: 0.437774
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991965]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.163961]
 [ -0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.0556640625, (240.9366, 0.1719293, 406.94714, 0.4439822)
   validation loss 385.21844482421875, (184.54561, 0.04316885, 200.62968, 0.4439822)
decoder loss ratio: 7149.617259, decoder SINDy loss  ratio: 0.433087
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991955]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.122316]
 [ -0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.28125, (239.4052, 0.17339908, 397.70264, 0.44394445)
   validation loss 373.62420654296875, (170.98772, 0.04294033, 202.59354, 0.44394445)
decoder loss ratio: 6624.360992, decoder SINDy loss  ratio: 0.437327
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991951]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.140543]
 [  0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.8263549804688, (377.04697, 0.16598283, 391.6134, 0.44390517)
   validation loss 495.37078857421875, (284.91125, 0.04457995, 210.41496, 0.44390517)
decoder loss ratio: 11037.956642, decoder SINDy loss  ratio: 0.454210
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99919474]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.147749]
 [ -0.      ]]
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.1738891601562, (230.86682, 0.19349289, 406.11356, 0.44386792)
   validation loss 389.5711669921875, (189.14508, 0.041760743, 200.38432, 0.44386792)
decoder loss ratio: 7327.808791, decoder SINDy loss  ratio: 0.432558
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999194]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.150019]
 [  0.      ]]
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 988.65283203125, (549.3257, 0.17566629, 439.15152, 0.44372407)
   validation loss 713.771240234375, (506.73087, 0.04472995, 206.99564, 0.44372407)
decoder loss ratio: 19631.633452, decoder SINDy loss  ratio: 0.446829
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991923]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.122375]
 [  0.      ]]
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.036865234375, (229.28494, 0.17554687, 400.57635, 0.44361034)
   validation loss 374.4825439453125, (174.29071, 0.041545287, 200.15028, 0.44361034)
decoder loss ratio: 6752.324705, decoder SINDy loss  ratio: 0.432053
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99919176]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.141144]
 [ -0.      ]]
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.5543212890625, (256.3662, 0.16626465, 398.02188, 0.44356155)
   validation loss 382.8909912109375, (181.0859, 0.04404549, 201.76102, 0.44356155)
decoder loss ratio: 7015.582415, decoder SINDy loss  ratio: 0.435530
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991913]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.141497]
 [ -0.      ]]
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1112.484619140625, (717.1389, 0.16888064, 395.17676, 0.4435466)
   validation loss 810.5067749023438, (582.62933, 0.043402437, 227.83405, 0.4435466)
decoder loss ratio: 22572.071869, decoder SINDy loss  ratio: 0.491812
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991907]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.144026]
 [ -0.      ]]
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 640.987060546875, (234.79951, 0.19129787, 405.99622, 0.44346914)
   validation loss 392.8062438964844, (192.70004, 0.040700488, 200.0655, 0.44346914)
decoder loss ratio: 7465.534197, decoder SINDy loss  ratio: 0.431870
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991896]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.14523]
 [ -0.     ]]
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.8759765625, (220.28874, 0.19649723, 403.39072, 0.44334984)
   validation loss 380.00958251953125, (181.39542, 0.040248815, 198.57393, 0.44334984)
decoder loss ratio: 7027.573342, decoder SINDy loss  ratio: 0.428650
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991887]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.121021]
 [ -0.      ]]
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.4861450195312, (236.23808, 0.20419535, 407.04388, 0.4432335)
   validation loss 391.408203125, (192.26048, 0.040267732, 199.10745, 0.4432335)
decoder loss ratio: 7448.504882, decoder SINDy loss  ratio: 0.429801
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991862]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.132875]
 [ -0.      ]]
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 868.0286254882812, (476.9205, 0.1816442, 390.92648, 0.44306812)
   validation loss 576.8849487304688, (366.22186, 0.040420543, 210.62263, 0.44306812)
decoder loss ratio: 14188.070754, decoder SINDy loss  ratio: 0.454659
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99918497]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.121092]
 [ -0.      ]]
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1063.520263671875, (671.00885, 0.16309214, 392.34833, 0.4429141)
   validation loss 766.6751708984375, (542.15375, 0.042967394, 224.47842, 0.4429141)
decoder loss ratio: 21003.977401, decoder SINDy loss  ratio: 0.484568
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99918413]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-17.11942]
 [ -0.     ]]
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.8823852539062, (230.40219, 0.16414388, 401.31607, 0.4428315)
   validation loss 376.4638366699219, (177.07208, 0.041851413, 199.3499, 0.4428315)
decoder loss ratio: 6860.079887, decoder SINDy loss  ratio: 0.430325
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99918437]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.104223]
 [  0.      ]]
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1201.8460693359375, (741.7469, 0.18412691, 459.91507, 0.4429029)
   validation loss 934.5476684570312, (717.3365, 0.042013153, 217.16919, 0.4429029)
decoder loss ratio: 27790.860850, decoder SINDy loss  ratio: 0.468790
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99918365]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.087692]
 [ -0.      ]]
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 940.4029541015625, (548.0919, 0.17377548, 392.13724, 0.44280455)
   validation loss 648.441650390625, (430.28024, 0.041760765, 218.11963, 0.44280455)
decoder loss ratio: 16669.803610, decoder SINDy loss  ratio: 0.470842
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991822]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.070223]
 [ -0.      ]]
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 920.0379638671875, (530.15625, 0.18079382, 389.70096, 0.44264966)
   validation loss 630.6275634765625, (416.43753, 0.040736478, 214.14929, 0.44264966)
decoder loss ratio: 16133.512900, decoder SINDy loss  ratio: 0.462271
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99918056]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.10933]
 [  0.     ]]
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.8931884765625, (260.7089, 0.185522, 392.99878, 0.4424719)
   validation loss 387.16412353515625, (186.4119, 0.03953039, 200.71268, 0.4424719)
decoder loss ratio: 7221.920467, decoder SINDy loss  ratio: 0.433267
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999179]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.064302]
 [  0.      ]]
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 662.2811279296875, (269.9754, 0.1839341, 392.12177, 0.44228745)
   validation loss 392.9393310546875, (191.87665, 0.03948055, 201.02322, 0.44228745)
decoder loss ratio: 7433.634454, decoder SINDy loss  ratio: 0.433937
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991764]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.07633]
 [  0.     ]]
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 668.1558837890625, (276.39316, 0.18652865, 391.57623, 0.44210863)
   validation loss 396.6845703125, (195.60844, 0.03894976, 201.03717, 0.44210863)
decoder loss ratio: 7578.210720, decoder SINDy loss  ratio: 0.433967
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991745]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.083212]
 [ -0.      ]]
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.4952392578125, (280.0923, 0.18911989, 391.21384, 0.4419398)
   validation loss 399.8319091796875, (199.00227, 0.038401406, 200.79121, 0.4419398)
decoder loss ratio: 7709.693561, decoder SINDy loss  ratio: 0.433436
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991729]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.051249]
 [ -0.      ]]
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 905.534912109375, (517.0989, 0.16818097, 388.26785, 0.44176847)
   validation loss 611.8494262695312, (399.23343, 0.04223504, 212.57375, 0.44176847)
decoder loss ratio: 15466.996137, decoder SINDy loss  ratio: 0.458870
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991711]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.039713]
 [ -0.      ]]
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 814.6951904296875, (426.6609, 0.1619357, 387.8724, 0.44162154)
   validation loss 532.6832885742188, (321.95, 0.041146215, 210.69212, 0.44162154)
decoder loss ratio: 12472.902403, decoder SINDy loss  ratio: 0.454809
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916923]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.049147]
 [  0.      ]]
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 627.209716796875, (230.1595, 0.1652322, 396.885, 0.44148403)
   validation loss 368.94732666015625, (170.04459, 0.041122045, 198.86163, 0.44148403)
decoder loss ratio: 6587.822479, decoder SINDy loss  ratio: 0.429271
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991687]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.054955]
 [ -0.      ]]
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.5441284179688, (230.05406, 0.18434481, 393.30573, 0.44145036)
   validation loss 367.5906066894531, (168.47247, 0.039332032, 199.0788, 0.44145036)
decoder loss ratio: 6526.916091, decoder SINDy loss  ratio: 0.429740
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991671]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.056429]
 [  0.      ]]
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 643.4369506835938, (239.08403, 0.19219807, 404.1607, 0.44129258)
   validation loss 400.4275817871094, (202.56888, 0.03870296, 197.82, 0.44129258)
decoder loss ratio: 7847.870015, decoder SINDy loss  ratio: 0.427022
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991659]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.042572]
 [  0.      ]]
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.6647338867188, (213.47466, 0.19348772, 396.99658, 0.44115478)
   validation loss 363.6229248046875, (167.09544, 0.038282286, 196.4892, 0.44115478)
decoder loss ratio: 6473.567580, decoder SINDy loss  ratio: 0.424150
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916446]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.02925]
 [ -0.     ]]
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 685.333251953125, (295.26675, 0.17736012, 389.88916, 0.4409891)
   validation loss 416.19317626953125, (214.28477, 0.0397919, 201.8686, 0.4409891)
decoder loss ratio: 8301.764190, decoder SINDy loss  ratio: 0.435762
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999163]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.992746]
 [  0.      ]]
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 615.294921875, (218.40192, 0.16652314, 396.7265, 0.44087908)
   validation loss 366.5094299316406, (168.60413, 0.03963093, 197.86568, 0.44087908)
decoder loss ratio: 6532.016550, decoder SINDy loss  ratio: 0.427121
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991621]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.028122]
 [ -0.      ]]
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 653.5776977539062, (264.8633, 0.16518563, 388.5492, 0.44078207)
   validation loss 392.9424743652344, (191.28181, 0.04077891, 201.61989, 0.44078207)
decoder loss ratio: 7410.589576, decoder SINDy loss  ratio: 0.435225
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991607]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.027048]
 [ -0.      ]]
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 958.0194702148438, (570.8267, 0.15876594, 387.034, 0.4407269)
   validation loss 672.657958984375, (454.92084, 0.041621357, 217.6955, 0.4407269)
decoder loss ratio: 17624.423018, decoder SINDy loss  ratio: 0.469926
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916136]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.022701]
 [ -0.      ]]
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.32568359375, (220.43658, 0.18645129, 397.70267, 0.44074342)
   validation loss 371.6823425292969, (173.85141, 0.040134136, 197.7908, 0.44074342)
decoder loss ratio: 6735.305439, decoder SINDy loss  ratio: 0.426959
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915946]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.998035]
 [ -0.      ]]
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 630.5921630859375, (240.52335, 0.17637947, 389.89243, 0.44062087)
   validation loss 367.75616455078125, (167.66199, 0.03804364, 200.05614, 0.44062087)
decoder loss ratio: 6495.516462, decoder SINDy loss  ratio: 0.431849
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915814]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.005371]
 [  0.      ]]
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 762.7157592773438, (347.0203, 0.17811285, 415.51736, 0.44047472)
   validation loss 524.0841064453125, (323.4067, 0.039475366, 200.63791, 0.44047472)
decoder loss ratio: 12529.337318, decoder SINDy loss  ratio: 0.433105
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991571]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.010267]
 [  0.      ]]
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.8878173828125, (232.41391, 0.18822692, 391.2857, 0.44038916)
   validation loss 365.6623840332031, (167.16869, 0.038367983, 198.45534, 0.44038916)
decoder loss ratio: 6476.405110, decoder SINDy loss  ratio: 0.428394
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991551]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.016367]
 [ -0.      ]]
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.4756469726562, (236.78033, 0.19593449, 402.49936, 0.44019657)
   validation loss 397.6190185546875, (200.43973, 0.03795501, 197.14133, 0.44019657)
decoder loss ratio: 7765.383033, decoder SINDy loss  ratio: 0.425557
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991525]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.993698]
 [ -0.      ]]
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 636.880615234375, (247.60532, 0.17685512, 389.09848, 0.44003078)
   validation loss 372.21856689453125, (172.23285, 0.036892753, 199.9488, 0.44003078)
decoder loss ratio: 6672.599584, decoder SINDy loss  ratio: 0.431618
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991511]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.004354]
 [ -0.      ]]
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 618.318115234375, (227.82509, 0.16738608, 390.32562, 0.43988734)
   validation loss 361.32830810546875, (161.8208, 0.038743347, 199.46878, 0.43988734)
decoder loss ratio: 6269.218756, decoder SINDy loss  ratio: 0.430581
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991497]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.011778]
 [ -0.      ]]
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.049072265625, (243.7937, 0.16995381, 401.0854, 0.43975708)
   validation loss 401.7762451171875, (203.91553, 0.039325017, 197.82138, 0.43975708)
decoder loss ratio: 7900.041542, decoder SINDy loss  ratio: 0.427025
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914855]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.976202]
 [ -0.      ]]
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 627.8072509765625, (237.7102, 0.18080701, 389.91623, 0.4397212)
   validation loss 373.259521484375, (174.76686, 0.037471343, 198.4552, 0.4397212)
decoder loss ratio: 6770.771602, decoder SINDy loss  ratio: 0.428393
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914724]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.990614]
 [  0.      ]]
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1041.719482421875, (606.3105, 0.18857889, 435.22034, 0.43962178)
   validation loss 810.7921142578125, (602.97144, 0.03928571, 207.78134, 0.43962178)
decoder loss ratio: 23360.160218, decoder SINDy loss  ratio: 0.448525
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914575]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.97673]
 [ -0.     ]]
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 702.14794921875, (314.18802, 0.17714402, 387.7828, 0.43946782)
   validation loss 427.99981689453125, (226.02998, 0.040044434, 201.92978, 0.43946782)
decoder loss ratio: 8756.793967, decoder SINDy loss  ratio: 0.435894
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991443]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.975948]
 [  0.      ]]
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.0767211914062, (223.09224, 0.18406568, 395.8004, 0.43930984)
   validation loss 360.76336669921875, (163.67542, 0.038427632, 197.04955, 0.43930984)
decoder loss ratio: 6341.069732, decoder SINDy loss  ratio: 0.425359
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914235]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.952076]
 [ -0.      ]]
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 780.105224609375, (394.11124, 0.18089096, 385.81314, 0.4391575)
   validation loss 494.7728271484375, (290.929, 0.03823385, 203.80562, 0.4391575)
decoder loss ratio: 11271.093977, decoder SINDy loss  ratio: 0.439943
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914086]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.957575]
 [ -0.      ]]
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 692.8867797851562, (307.26443, 0.16706167, 385.4553, 0.43899345)
   validation loss 422.10894775390625, (220.1953, 0.040204633, 201.87343, 0.43899345)
decoder loss ratio: 8530.748091, decoder SINDy loss  ratio: 0.435772
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991391]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.94731]
 [ -0.     ]]
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 613.730224609375, (223.25885, 0.17992875, 390.2914, 0.43886778)
   validation loss 363.019287109375, (166.24074, 0.038771562, 196.73979, 0.43886778)
decoder loss ratio: 6440.454793, decoder SINDy loss  ratio: 0.424691
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991377]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.939175]
 [ -0.      ]]
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.84375, (456.7827, 0.17115706, 384.8899, 0.43875214)
   validation loss 563.0203857421875, (355.02362, 0.040223114, 207.95657, 0.43875214)
decoder loss ratio: 13754.231410, decoder SINDy loss  ratio: 0.448904
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99913514]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.93668]
 [  0.     ]]
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 693.1290283203125, (307.27563, 0.17766616, 385.6757, 0.43860874)
   validation loss 413.2021789550781, (211.47565, 0.037420984, 201.68912, 0.43860874)
decoder loss ratio: 8192.933702, decoder SINDy loss  ratio: 0.435374
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991337]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.932898]
 [  0.      ]]
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1208.385009765625, (759.95776, 0.19022356, 448.23697, 0.43841258)
   validation loss 980.8392333984375, (767.5299, 0.04027636, 213.26904, 0.43841258)
decoder loss ratio: 29735.441096, decoder SINDy loss  ratio: 0.460371
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991323]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.92363]
 [  0.     ]]
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 844.6138916015625, (459.88443, 0.17167756, 384.55777, 0.43823034)
   validation loss 562.3712158203125, (356.05258, 0.03970587, 206.27895, 0.43823034)
decoder loss ratio: 13794.095153, decoder SINDy loss  ratio: 0.445282
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991303]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.947767]
 [ -0.      ]]
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.3287353515625, (232.40224, 0.17848612, 389.74802, 0.43806934)
   validation loss 363.64227294921875, (166.74567, 0.039335508, 196.85728, 0.43806934)
decoder loss ratio: 6460.016604, decoder SINDy loss  ratio: 0.424944
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912906]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.888937]
 [  0.      ]]
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1746.7052001953125, (1342.0375, 0.16164717, 404.50613, 0.43798876)
   validation loss 1382.54638671875, (1137.09, 0.04028552, 245.4161, 0.43798876)
decoder loss ratio: 44052.839351, decoder SINDy loss  ratio: 0.529765
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991269]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.920404]
 [ -0.      ]]
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 690.4188842773438, (307.42776, 0.16249092, 382.8286, 0.43779927)
   validation loss 421.6154479980469, (217.90126, 0.039117612, 203.67506, 0.43779927)
decoder loss ratio: 8441.873120, decoder SINDy loss  ratio: 0.439661
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912524]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.890642]
 [ -0.      ]]
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.6568603515625, (224.69261, 0.18779173, 396.7765, 0.4376875)
   validation loss 382.86138916015625, (187.22823, 0.03891827, 195.59422, 0.4376875)
decoder loss ratio: 7253.546506, decoder SINDy loss  ratio: 0.422218
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991236]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.894356]
 [  0.      ]]
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 606.5430908203125, (215.02011, 0.18698573, 391.33603, 0.43752685)
   validation loss 360.58477783203125, (166.02666, 0.03814321, 194.51999, 0.43752685)
decoder loss ratio: 6432.160931, decoder SINDy loss  ratio: 0.419899
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912137]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.883636]
 [  0.      ]]
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 607.035888671875, (217.23262, 0.18394949, 389.6193, 0.43735895)
   validation loss 355.857666015625, (160.87935, 0.038420293, 194.93988, 0.43735895)
decoder loss ratio: 6232.745270, decoder SINDy loss  ratio: 0.420805
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991201]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.872097]
 [ -0.      ]]
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.733154296875, (213.86324, 0.18469074, 391.6852, 0.4372026)
   validation loss 359.2047119140625, (164.42212, 0.03857334, 194.744, 0.4372026)
decoder loss ratio: 6369.998345, decoder SINDy loss  ratio: 0.420382
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999118]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.839758]
 [  0.      ]]
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.2540893554688, (229.50256, 0.18706262, 396.56445, 0.4370037)
   validation loss 383.9739685058594, (189.02682, 0.038650658, 194.9085, 0.4370037)
decoder loss ratio: 7323.227364, decoder SINDy loss  ratio: 0.420737
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99911666]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.862158]
 [  0.      ]]
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 604.225341796875, (214.41734, 0.18363567, 389.6244, 0.4368576)
   validation loss 354.42779541015625, (159.93231, 0.038599826, 194.4569, 0.4368576)
decoder loss ratio: 6196.055422, decoder SINDy loss  ratio: 0.419763
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99911475]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.857147]
 [  0.      ]]
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.2153930664062, (213.34923, 0.18323329, 391.68295, 0.43666872)
   validation loss 360.1599426269531, (165.63495, 0.038934898, 194.48605, 0.43666872)
decoder loss ratio: 6416.985469, decoder SINDy loss  ratio: 0.419826
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991126]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.86365]
 [ -0.     ]]
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 603.1813354492188, (213.3758, 0.18170501, 389.62384, 0.43651697)
   validation loss 355.5787353515625, (160.81453, 0.038944375, 194.72527, 0.43651697)
decoder loss ratio: 6230.234056, decoder SINDy loss  ratio: 0.420342
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991108]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.855219]
 [  0.      ]]
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 604.8431396484375, (216.70154, 0.18157555, 387.96005, 0.43634072)
   validation loss 354.01361083984375, (159.10309, 0.03870246, 194.87183, 0.43634072)
decoder loss ratio: 6163.929859, decoder SINDy loss  ratio: 0.420658
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991088]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.853369]
 [  0.      ]]
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.7625122070312, (218.27168, 0.18076353, 387.31006, 0.43616158)
   validation loss 353.71142578125, (158.82312, 0.0387525, 194.84956, 0.43616158)
decoder loss ratio: 6153.083402, decoder SINDy loss  ratio: 0.420610
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910694]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.824362]
 [ -0.      ]]
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 648.4620971679688, (265.13818, 0.17684984, 383.14706, 0.43598825)
   validation loss 383.85467529296875, (187.00984, 0.038959753, 196.8059, 0.43598825)
decoder loss ratio: 7245.085939, decoder SINDy loss  ratio: 0.424833
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910533]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.799946]
 [  0.      ]]
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.4090576171875, (275.6883, 0.17352168, 382.5472, 0.43582526)
   validation loss 389.31695556640625, (191.5426, 0.039253946, 197.73508, 0.43582526)
decoder loss ratio: 7420.692955, decoder SINDy loss  ratio: 0.426839
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991032]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.81355]
 [  0.     ]]
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 705.8306274414062, (324.36212, 0.17269222, 381.2958, 0.43565398)
   validation loss 429.9001770019531, (230.66699, 0.039168335, 199.19402, 0.43565398)
decoder loss ratio: 8936.439733, decoder SINDy loss  ratio: 0.429988
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999102]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.827997]
 [ -0.      ]]
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 829.7285766601562, (448.86975, 0.1692222, 380.6896, 0.43552223)
   validation loss 539.110107421875, (334.6218, 0.04004676, 204.44826, 0.43552223)
decoder loss ratio: 12963.829293, decoder SINDy loss  ratio: 0.441330
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991002]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.81029]
 [ -0.     ]]
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 748.82568359375, (368.9046, 0.15891457, 379.7622, 0.43537036)
   validation loss 470.00726318359375, (267.42316, 0.04111087, 202.54301, 0.43537036)
decoder loss ratio: 10360.437359, decoder SINDy loss  ratio: 0.437218
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99909914]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.811527]
 [ -0.      ]]
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.2259521484375, (442.28558, 0.16109389, 379.77927, 0.4352849)
   validation loss 536.44921875, (329.16788, 0.040279735, 207.24106, 0.4352849)
decoder loss ratio: 12752.535023, decoder SINDy loss  ratio: 0.447359
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999098]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.783703]
 [ -0.      ]]
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1714.7220458984375, (1316.159, 0.15606338, 398.40695, 0.43517357)
   validation loss 1364.8519287109375, (1121.5907, 0.04329108, 243.21791, 0.43517357)
decoder loss ratio: 43452.370817, decoder SINDy loss  ratio: 0.525020
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99909735]
 [0.        ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [-16.7925]
 [ -0.    ]]
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.1268310546875, (226.45155, 0.18059291, 395.49472, 0.4350589)
   validation loss 378.38153076171875, (182.98949, 0.041450787, 195.3506, 0.4350589)
decoder loss ratio: 7089.330398, decoder SINDy loss  ratio: 0.421692
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990951]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.789806]
 [  0.      ]]
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 616.906982421875, (232.34605, 0.16968325, 384.39124, 0.43495676)
   validation loss 363.18902587890625, (167.53061, 0.03959715, 195.61884, 0.43495676)
decoder loss ratio: 6490.426644, decoder SINDy loss  ratio: 0.422271
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99909335]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.784794]
 [  0.      ]]
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 859.080322265625, (478.67072, 0.16070358, 380.24887, 0.43481895)
   validation loss 567.2699584960938, (355.8436, 0.04023277, 211.38614, 0.43481895)
decoder loss ratio: 13785.998735, decoder SINDy loss  ratio: 0.456307
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990914]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.773869]
 [  0.      ]]
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.2691650390625, (239.4284, 0.16255525, 385.6782, 0.43469277)
   validation loss 388.7489929199219, (193.57077, 0.039678376, 195.13855, 0.43469277)
decoder loss ratio: 7499.267694, decoder SINDy loss  ratio: 0.421234
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990924]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.774225]
 [ -0.      ]]
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1166.4368896484375, (783.46014, 0.16809566, 382.80862, 0.4347156)
   validation loss 861.1428833007812, (641.08936, 0.040731046, 220.01282, 0.4347156)
decoder loss ratio: 24836.914611, decoder SINDy loss  ratio: 0.474929
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99909055]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.766666]
 [  0.      ]]
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 965.404296875, (536.5132, 0.18220042, 428.70895, 0.43459126)
   validation loss 734.4861450195312, (528.9021, 0.041433457, 205.5426, 0.43459126)
decoder loss ratio: 20490.585553, decoder SINDy loss  ratio: 0.443693
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990898]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.760107]
 [  0.      ]]
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.3622436523438, (237.99152, 0.17173512, 387.19897, 0.43444282)
   validation loss 366.7708740234375, (171.38484, 0.04023471, 195.34581, 0.43444282)
decoder loss ratio: 6639.746313, decoder SINDy loss  ratio: 0.421681
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990879]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.760778]
 [ -0.      ]]
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 613.5132446289062, (226.8172, 0.18518989, 386.51086, 0.4343512)
   validation loss 366.3455810546875, (172.0929, 0.039633125, 194.21306, 0.4343512)
decoder loss ratio: 6667.177538, decoder SINDy loss  ratio: 0.419236
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990854]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.776096]
 [  0.      ]]
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.3777465820312, (243.01616, 0.1704066, 380.1912, 0.4341041)
   validation loss 365.6192626953125, (169.32985, 0.03924917, 196.25017, 0.4341041)
decoder loss ratio: 6560.132329, decoder SINDy loss  ratio: 0.423634
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99908316]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.741621]
 [ -0.      ]]
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 601.6118774414062, (214.801, 0.16763039, 386.64325, 0.43390432)
   validation loss 366.6961975097656, (173.47118, 0.04114238, 193.18388, 0.43390432)
decoder loss ratio: 6720.574523, decoder SINDy loss  ratio: 0.417015
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990806]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.743319]
 [  0.      ]]
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1939.0279541015625, (1433.1035, 0.18675625, 505.73767, 0.433671)
   validation loss 1640.9852294921875, (1401.4606, 0.04302734, 239.48174, 0.433671)
decoder loss ratio: 54295.015574, decoder SINDy loss  ratio: 0.516955
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99907935]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.730396]
 [ -0.      ]]
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1576.9935302734375, (1087.671, 0.18507601, 489.13748, 0.43357754)
   validation loss 1263.646240234375, (1032.5028, 0.0439099, 231.09949, 0.43357754)
decoder loss ratio: 40000.951271, decoder SINDy loss  ratio: 0.498861
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99907804]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.719805]
 [ -0.      ]]
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1690.32421875, (1297.1284, 0.16121358, 393.03452, 0.43353358)
   validation loss 1342.034423828125, (1105.131, 0.042080596, 236.86139, 0.43353358)
decoder loss ratio: 42814.692813, decoder SINDy loss  ratio: 0.511299
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99907583]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.728073]
 [  0.      ]]
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 597.6925048828125, (211.5047, 0.17571345, 386.01205, 0.4333867)
   validation loss 358.2427978515625, (165.125, 0.039595857, 193.07819, 0.4333867)
decoder loss ratio: 6397.229170, decoder SINDy loss  ratio: 0.416786
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99907416]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.71836]
 [  0.     ]]
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.24658203125, (236.39348, 0.17542996, 382.6777, 0.43331823)
   validation loss 366.0181884765625, (171.00546, 0.03995158, 194.9728, 0.43331823)
decoder loss ratio: 6625.048501, decoder SINDy loss  ratio: 0.420876
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990725]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.745594]
 [ -0.      ]]
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1176.78271484375, (792.8588, 0.15641125, 383.7675, 0.43317658)
   validation loss 855.076171875, (633.6338, 0.040126268, 221.40228, 0.43317658)
decoder loss ratio: 24548.073025, decoder SINDy loss  ratio: 0.477928
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990705]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.688171]
 [ -0.      ]]
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.8241577148438, (263.1105, 0.16831356, 396.54535, 0.4330209)
   validation loss 398.3514709472656, (202.6919, 0.041044727, 195.61853, 0.4330209)
decoder loss ratio: 7852.635883, decoder SINDy loss  ratio: 0.422270
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99906856]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.708231]
 [ -0.      ]]
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 624.1196899414062, (238.28702, 0.17226565, 385.6604, 0.43290216)
   validation loss 396.01080322265625, (202.88683, 0.039746966, 193.08423, 0.43290216)
decoder loss ratio: 7860.187849, decoder SINDy loss  ratio: 0.416799
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990671]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.676275]
 [ -0.      ]]
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 607.208984375, (222.34312, 0.16808408, 384.69775, 0.43279)
   validation loss 367.51470947265625, (173.66399, 0.040425334, 193.81032, 0.43279)
decoder loss ratio: 6728.044320, decoder SINDy loss  ratio: 0.418367
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990646]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.694347]
 [ -0.      ]]
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.663330078125, (231.00221, 0.17324479, 388.48788, 0.4326313)
   validation loss 388.54150390625, (195.19374, 0.040065102, 193.30768, 0.4326313)
decoder loss ratio: 7562.144392, decoder SINDy loss  ratio: 0.417282
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990632]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.707008]
 [  0.      ]]
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.712158203125, (245.7323, 0.18281943, 391.79703, 0.4324665)
   validation loss 404.9114990234375, (211.48703, 0.039986283, 193.38448, 0.4324665)
decoder loss ratio: 8193.374701, decoder SINDy loss  ratio: 0.417448
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990605]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.663387]
 [  0.      ]]
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1369.3558349609375, (915.04395, 0.19141747, 454.1205, 0.43230867)
   validation loss 1152.74267578125, (934.56616, 0.042841367, 218.13368, 0.43230867)
decoder loss ratio: 36206.715598, decoder SINDy loss  ratio: 0.470872
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905854]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.69159]
 [  0.     ]]
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.0731201171875, (248.11066, 0.16711289, 376.79538, 0.4321538)
   validation loss 369.30682373046875, (174.6809, 0.040219557, 194.58572, 0.4321538)
decoder loss ratio: 6767.441052, decoder SINDy loss  ratio: 0.420041
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990566]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.694914]
 [  0.      ]]
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 603.7821044921875, (217.81062, 0.17478545, 385.79666, 0.43199006)
   validation loss 367.46807861328125, (174.56682, 0.0403039, 192.86096, 0.43199006)
decoder loss ratio: 6763.021600, decoder SINDy loss  ratio: 0.416318
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990547]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.662735]
 [  0.      ]]
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 594.7002563476562, (211.96873, 0.16903201, 382.5625, 0.4318492)
   validation loss 357.5047607421875, (164.88896, 0.040614933, 192.57518, 0.4318492)
decoder loss ratio: 6388.084640, decoder SINDy loss  ratio: 0.415701
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905276]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.65215]
 [  0.     ]]
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1556.20947265625, (1088.2935, 0.1816605, 467.73434, 0.43163797)
   validation loss 1307.6962890625, (1085.0394, 0.042820334, 222.614, 0.43163797)
decoder loss ratio: 42036.311180, decoder SINDy loss  ratio: 0.480544
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905115]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.638348]
 [ -0.      ]]
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1907.657470703125, (1411.0039, 0.18273897, 496.4709, 0.43150926)
   validation loss 1641.4508056640625, (1403.8569, 0.044081565, 237.54979, 0.43150926)
decoder loss ratio: 54387.854810, decoder SINDy loss  ratio: 0.512785
=========================
[[0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.     ]
 [0.99905]
 [0.     ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.646357]
 [ -0.      ]]
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1256.2623291015625, (811.4616, 0.17402951, 444.62674, 0.431413)
   validation loss 1025.6436767578125, (812.8158, 0.04337949, 212.78445, 0.431413)
decoder loss ratio: 31489.895043, decoder SINDy loss  ratio: 0.459325
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904764]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.638462]
 [ -0.      ]]
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 718.2568969726562, (344.55695, 0.15979503, 373.54016, 0.4313387)
   validation loss 450.9212646484375, (253.24028, 0.04111177, 197.63988, 0.4313387)
decoder loss ratio: 9810.968098, decoder SINDy loss  ratio: 0.426633
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904585]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.623302]
 [  0.      ]]
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 593.4647216796875, (214.56497, 0.15843092, 378.7413, 0.43119392)
   validation loss 354.99603271484375, (162.68962, 0.0415297, 192.26488, 0.43119392)
decoder loss ratio: 6302.878358, decoder SINDy loss  ratio: 0.415031
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990462]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.640242]
 [ -0.      ]]
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.2527465820312, (277.78348, 0.15718256, 374.31207, 0.43121368)
   validation loss 400.63018798828125, (203.82085, 0.041452326, 196.76787, 0.43121368)
decoder loss ratio: 7896.373444, decoder SINDy loss  ratio: 0.424751
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990448]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.630821]
 [  0.      ]]
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1055.042724609375, (619.25085, 0.18508925, 435.60675, 0.4311715)
   validation loss 800.6664428710938, (592.07, 0.04503036, 208.55139, 0.4311715)
decoder loss ratio: 22937.819962, decoder SINDy loss  ratio: 0.450188
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904275]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.610699]
 [ -0.      ]]
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 958.24755859375, (581.77563, 0.15118396, 376.32077, 0.4310628)
   validation loss 655.8658447265625, (443.55316, 0.04099082, 212.2717, 0.4310628)
decoder loss ratio: 17184.019523, decoder SINDy loss  ratio: 0.458218
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904275]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.617208]
 [  0.      ]]
Epoch 4025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.3187866210938, (244.70464, 0.16016053, 380.454, 0.43100244)
   validation loss 365.160888671875, (170.73709, 0.041736055, 194.38205, 0.43100244)
decoder loss ratio: 6614.651320, decoder SINDy loss  ratio: 0.419601
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904156]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.63029]
 [ -0.     ]]
Epoch 4050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.64208984375, (251.14519, 0.16834572, 386.32858, 0.43094015)
   validation loss 415.912109375, (223.30481, 0.040803142, 192.56648, 0.43094015)
decoder loss ratio: 8651.215997, decoder SINDy loss  ratio: 0.415682
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990406]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.592619]
 [  0.      ]]
Epoch 4075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 774.4036865234375, (402.79236, 0.15536703, 371.45593, 0.43083048)
   validation loss 493.6318664550781, (290.34808, 0.04020097, 203.24359, 0.43083048)
decoder loss ratio: 11248.588821, decoder SINDy loss  ratio: 0.438730
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99903965]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.615873]
 [ -0.      ]]
Epoch 4100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1186.228271484375, (808.04407, 0.14716725, 378.03708, 0.43071753)
   validation loss 873.0421142578125, (652.69446, 0.041783992, 220.30583, 0.43071753)
decoder loss ratio: 25286.516431, decoder SINDy loss  ratio: 0.475561
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990381]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.625786]
 [ -0.      ]]
Epoch 4125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.1658935546875, (246.642, 0.15882227, 372.36508, 0.43059483)
   validation loss 368.05682373046875, (172.77486, 0.040194795, 195.24176, 0.43059483)
decoder loss ratio: 6693.597894, decoder SINDy loss  ratio: 0.421457
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990369]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.58928]
 [  0.     ]]
Epoch 4150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 833.9420166015625, (463.01, 0.15254743, 370.77945, 0.43049422)
   validation loss 562.219970703125, (357.7901, 0.041600555, 204.3883, 0.43049422)
decoder loss ratio: 13861.409629, decoder SINDy loss  ratio: 0.441201
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99903506]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.608023]
 [  0.      ]]
Epoch 4175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 594.9485473632812, (221.01283, 0.16369122, 373.772, 0.4303339)
   validation loss 352.60723876953125, (159.56406, 0.039928943, 193.00327, 0.4303339)
decoder loss ratio: 6181.788560, decoder SINDy loss  ratio: 0.416625
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99903345]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.600655]
 [  0.      ]]
Epoch 4200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 599.4801635742188, (218.63664, 0.1667804, 380.67676, 0.4301981)
   validation loss 369.718505859375, (177.91635, 0.040131878, 191.76201, 0.4301981)
decoder loss ratio: 6892.788326, decoder SINDy loss  ratio: 0.413945
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99903286]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.607853]
 [  0.      ]]
Epoch 4225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1472.172119140625, (1086.4766, 0.14640866, 385.5492, 0.43014804)
   validation loss 1129.5301513671875, (898.4281, 0.042350993, 231.05968, 0.43014804)
decoder loss ratio: 34806.664356, decoder SINDy loss  ratio: 0.498775
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990319]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.598463]
 [ -0.      ]]
Epoch 4250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 593.0322265625, (215.85793, 0.16465363, 377.0096, 0.43003616)
   validation loss 351.4695739746094, (158.90845, 0.040470667, 192.52066, 0.43003616)
decoder loss ratio: 6156.389124, decoder SINDy loss  ratio: 0.415583
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990298]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.574251]
 [ -0.      ]]
Epoch 4275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 939.141845703125, (565.9172, 0.1479729, 373.0767, 0.42991447)
   validation loss 635.9006958007812, (425.19046, 0.04099262, 210.66924, 0.42991447)
decoder loss ratio: 16472.616591, decoder SINDy loss  ratio: 0.454759
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990293]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [-16.5851]
 [ -0.    ]]
Epoch 4300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 605.560791015625, (230.66417, 0.16241242, 374.73422, 0.42982197)
   validation loss 360.384033203125, (168.34587, 0.040821757, 191.99736, 0.42982197)
decoder loss ratio: 6522.011303, decoder SINDy loss  ratio: 0.414453
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990276]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.579775]
 [  0.      ]]
Epoch 4325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.0941162109375, (299.74408, 0.16402282, 370.18604, 0.4297308)
   validation loss 414.4710998535156, (219.06506, 0.040614348, 195.36542, 0.4297308)
decoder loss ratio: 8486.960873, decoder SINDy loss  ratio: 0.421724
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990263]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.559433]
 [  0.      ]]
Epoch 4350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 607.0767211914062, (235.8977, 0.16137454, 371.01764, 0.42961702)
   validation loss 359.5934143066406, (166.73276, 0.040590357, 192.82007, 0.42961702)
decoder loss ratio: 6459.516489, decoder SINDy loss  ratio: 0.416229
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99902475]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.57271]
 [ -0.     ]]
Epoch 4375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 596.0472412109375, (224.32033, 0.16097453, 371.56595, 0.42950374)
   validation loss 354.3937683105469, (162.05309, 0.040787358, 192.2999, 0.42950374)
decoder loss ratio: 6278.217862, decoder SINDy loss  ratio: 0.415106
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99902296]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.556818]
 [  0.      ]]
Epoch 4400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 588.5123291015625, (210.9647, 0.16855258, 377.3791, 0.42934904)
   validation loss 359.35345458984375, (168.69339, 0.040155485, 190.61992, 0.42934904)
decoder loss ratio: 6535.474789, decoder SINDy loss  ratio: 0.411480
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990219]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.565403]
 [  0.      ]]
Epoch 4425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 589.179931640625, (214.44029, 0.15962139, 374.58005, 0.4292483)
   validation loss 351.44622802734375, (159.94913, 0.041133072, 191.45596, 0.4292483)
decoder loss ratio: 6196.706872, decoder SINDy loss  ratio: 0.413285
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990208]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.536873]
 [  0.      ]]
Epoch 4450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 591.9336547851562, (215.22084, 0.16005768, 376.55276, 0.42916828)
   validation loss 357.8858947753906, (166.82368, 0.04149155, 191.02072, 0.42916828)
decoder loss ratio: 6463.039164, decoder SINDy loss  ratio: 0.412345
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990201]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.527485]
 [ -0.      ]]
Epoch 4475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.93896484375, (290.55893, 0.16863509, 392.2114, 0.42912036)
   validation loss 455.95831298828125, (262.4016, 0.04197673, 193.51472, 0.42912036)
decoder loss ratio: 10165.893972, decoder SINDy loss  ratio: 0.417729
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99901867]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.551104]
 [ -0.      ]]
Epoch 4500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1078.1201171875, (644.20056, 0.18436058, 433.7352, 0.4290243)
   validation loss 829.7265625, (620.74194, 0.044807922, 208.93982, 0.4290243)
decoder loss ratio: 24048.620541, decoder SINDy loss  ratio: 0.451026
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990175]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.554153]
 [ -0.      ]]
Epoch 4525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 686.8238525390625, (319.46927, 0.15367107, 367.2009, 0.42890224)
   validation loss 420.61767578125, (223.21422, 0.040765435, 197.3627, 0.42890224)
decoder loss ratio: 8647.706328, decoder SINDy loss  ratio: 0.426035
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999017]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.531967]
 [ -0.      ]]
Epoch 4550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 661.14990234375, (293.24716, 0.15950643, 367.74326, 0.4288375)
   validation loss 406.21136474609375, (211.6183, 0.040656827, 194.5524, 0.4288375)
decoder loss ratio: 8198.460381, decoder SINDy loss  ratio: 0.419969
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990149]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.537876]
 [  0.      ]]
Epoch 4575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.957275390625, (300.68765, 0.1507631, 367.1189, 0.42873454)
   validation loss 414.5578308105469, (218.48427, 0.04177586, 196.03178, 0.42873454)
decoder loss ratio: 8464.459855, decoder SINDy loss  ratio: 0.423162
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990127]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.528976]
 [ -0.      ]]
Epoch 4600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 608.7693481445312, (241.25351, 0.15054499, 367.3653, 0.42862186)
   validation loss 365.824462890625, (172.11449, 0.04138164, 193.6686, 0.42862186)
decoder loss ratio: 6668.014018, decoder SINDy loss  ratio: 0.418061
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999011]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.554827]
 [  0.      ]]
Epoch 4625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 600.6480712890625, (232.1666, 0.15312268, 368.32834, 0.42848808)
   validation loss 358.98382568359375, (166.20177, 0.041050464, 192.74103, 0.42848808)
decoder loss ratio: 6438.944991, decoder SINDy loss  ratio: 0.416059
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900925]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.532843]
 [  0.      ]]
Epoch 4650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 669.234375, (282.60745, 0.1619121, 386.46497, 0.4283528)
   validation loss 443.037109375, (251.03027, 0.04079797, 191.96605, 0.4283528)
decoder loss ratio: 9725.348601, decoder SINDy loss  ratio: 0.414386
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990085]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.514122]
 [ -0.      ]]
Epoch 4675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 581.464599609375, (210.42831, 0.15847535, 370.8778, 0.42831317)
   validation loss 349.04315185546875, (158.36064, 0.04058059, 190.64194, 0.42831317)
decoder loss ratio: 6135.166177, decoder SINDy loss  ratio: 0.411527
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900687]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.482412]
 [  0.      ]]
Epoch 4700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 580.0371704101562, (209.06946, 0.15902027, 370.8087, 0.42820057)
   validation loss 348.05322265625, (157.42213, 0.040244274, 190.59084, 0.42820057)
decoder loss ratio: 6098.806783, decoder SINDy loss  ratio: 0.411417
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900603]
 [0.        ]]
[[ -0.   ]
 [ -0.   ]
 [  0.   ]
 [ -0.   ]
 [  0.   ]
 [ -0.   ]
 [ -0.   ]
 [ -0.   ]
 [  0.   ]
 [-16.492]
 [  0.   ]]
Epoch 4725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 579.81103515625, (209.03232, 0.15683119, 370.62186, 0.42808262)
   validation loss 346.5767822265625, (155.76588, 0.040803276, 190.77011, 0.42808262)
decoder loss ratio: 6034.640783, decoder SINDy loss  ratio: 0.411804
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900526]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.481138]
 [  0.      ]]
Epoch 4750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 601.9741821289062, (231.93129, 0.15574864, 369.88715, 0.42804614)
   validation loss 360.0314025878906, (168.65506, 0.04114758, 191.33519, 0.42804614)
decoder loss ratio: 6533.989815, decoder SINDy loss  ratio: 0.413024
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900377]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.499352]
 [  0.      ]]
Epoch 4775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 604.6571044921875, (236.60051, 0.16208334, 367.89453, 0.4279255)
   validation loss 362.5066223144531, (171.45335, 0.04013503, 191.01314, 0.4279255)
decoder loss ratio: 6642.400585, decoder SINDy loss  ratio: 0.412329
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990021]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.50042]
 [ -0.     ]]
Epoch 4800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1712.44189453125, (1326.6554, 0.14170416, 385.64474, 0.4278472)
   validation loss 1373.924560546875, (1137.4532, 0.04399585, 236.4274, 0.4278472)
decoder loss ratio: 44066.913497, decoder SINDy loss  ratio: 0.510362
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900043]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.492216]
 [  0.      ]]
Epoch 4825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 666.5206298828125, (301.82678, 0.14621994, 364.5476, 0.4277353)
   validation loss 410.287841796875, (213.80573, 0.04150678, 196.44061, 0.4277353)
decoder loss ratio: 8283.204973, decoder SINDy loss  ratio: 0.424045
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899936]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.472042]
 [ -0.      ]]
Epoch 4850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 822.911865234375, (423.8764, 0.1604271, 398.87503, 0.42758617)
   validation loss 585.28857421875, (389.8882, 0.04213821, 195.35822, 0.42758617)
decoder loss ratio: 15104.946290, decoder SINDy loss  ratio: 0.421708
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899846]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.493664]
 [ -0.      ]]
Epoch 4875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.5823364257812, (313.29883, 0.14957269, 365.13394, 0.42755967)
   validation loss 429.356201171875, (234.29372, 0.042077977, 195.02042, 0.42755967)
decoder loss ratio: 9076.945326, decoder SINDy loss  ratio: 0.420979
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989971]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.47763]
 [  0.     ]]
Epoch 4900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 682.498291015625, (319.04282, 0.15050527, 363.30493, 0.42746925)
   validation loss 423.1679992675781, (226.31845, 0.041047405, 196.8085, 0.42746925)
decoder loss ratio: 8767.969695, decoder SINDy loss  ratio: 0.424839
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899584]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.461512]
 [  0.      ]]
Epoch 4925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.6401977539062, (340.1249, 0.1618929, 385.3534, 0.42735296)
   validation loss 522.5789794921875, (330.42648, 0.04113579, 192.11133, 0.42735296)
decoder loss ratio: 12801.295603, decoder SINDy loss  ratio: 0.414699
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899507]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.484064]
 [ -0.      ]]
Epoch 4950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.3162231445312, (245.37387, 0.15749358, 374.78488, 0.427289)
   validation loss 399.806396484375, (210.48561, 0.04191705, 189.27888, 0.427289)
decoder loss ratio: 8154.577988, decoder SINDy loss  ratio: 0.408585
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899364]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.46037]
 [  0.     ]]
Epoch 4975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 852.8115234375, (457.44513, 0.15234968, 395.21402, 0.42721754)
   validation loss 642.4369506835938, (446.7091, 0.04005234, 195.68782, 0.42721754)
decoder loss ratio: 17306.286305, decoder SINDy loss  ratio: 0.422420
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989922]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.47252]
 [  0.     ]]
Epoch 5000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 590.64453125, (225.37605, 0.14784671, 365.12064, 0.4271264)
   validation loss 353.1904296875, (162.18417, 0.040168457, 190.96611, 0.4271264)
decoder loss ratio: 6283.296449, decoder SINDy loss  ratio: 0.412227
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989914]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.468304]
 [ -0.      ]]
Epoch 5025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1621.1505126953125, (1238.5671, 0.13641232, 382.447, 0.42709062)
   validation loss 1282.8255615234375, (1047.8425, 0.043902192, 234.9391, 0.42709062)
decoder loss ratio: 40595.238720, decoder SINDy loss  ratio: 0.507149
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989908]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.47203]
 [  0.     ]]
Epoch 5050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 589.10009765625, (217.2577, 0.1590584, 371.68335, 0.426991)
   validation loss 362.9310607910156, (173.38959, 0.03998885, 189.50148, 0.426991)
decoder loss ratio: 6717.413634, decoder SINDy loss  ratio: 0.409066
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989892]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.469543]
 [ -0.      ]]
Epoch 5075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.2460327148438, (257.98242, 0.14979322, 363.11383, 0.42690063)
   validation loss 382.31719970703125, (189.17776, 0.041680522, 193.09773, 0.42690063)
decoder loss ratio: 7329.075039, decoder SINDy loss  ratio: 0.416829
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989889]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.44614]
 [ -0.     ]]
Epoch 5100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.924560546875, (260.56274, 0.15915495, 382.2027, 0.42683655)
   validation loss 398.322998046875, (206.28104, 0.039758023, 192.00218, 0.42683655)
decoder loss ratio: 7991.685469, decoder SINDy loss  ratio: 0.414464
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989871]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.465658]
 [  0.      ]]
Epoch 5125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1742.022216796875, (1357.0137, 0.13694549, 384.8716, 0.42677155)
   validation loss 1391.71142578125, (1154.4303, 0.043066405, 237.238, 0.42677155)
decoder loss ratio: 44724.633918, decoder SINDy loss  ratio: 0.512112
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989859]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.45552]
 [  0.     ]]
Epoch 5150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 588.4554443359375, (218.8059, 0.15229051, 369.49722, 0.42660943)
   validation loss 351.97491455078125, (161.63942, 0.040226225, 190.29529, 0.42660943)
decoder loss ratio: 6262.191732, decoder SINDy loss  ratio: 0.410779
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99898356]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.425625]
 [ -0.      ]]
Epoch 5175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 616.180908203125, (244.37936, 0.15520824, 371.64633, 0.4264833)
   validation loss 407.203369140625, (218.27052, 0.039969463, 188.8929, 0.4264833)
decoder loss ratio: 8456.178998, decoder SINDy loss  ratio: 0.407752
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989828]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.430609]
 [ -0.      ]]
Epoch 5200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 733.04833984375, (337.67093, 0.1625356, 395.21487, 0.42641068)
   validation loss 478.6292419433594, (283.81384, 0.04048825, 194.7749, 0.42641068)
decoder loss ratio: 10995.440992, decoder SINDy loss  ratio: 0.420449
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989813]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.409346]
 [ -0.      ]]
Epoch 5225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 587.6631469726562, (218.37547, 0.15195566, 369.1357, 0.4263323)
   validation loss 351.739990234375, (161.39395, 0.039812542, 190.30623, 0.4263323)
decoder loss ratio: 6252.681870, decoder SINDy loss  ratio: 0.410803
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989792]
 [0.       ]]
[[  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [-16.4217]
 [ -0.    ]]
Epoch 5250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 639.96923828125, (279.96133, 0.14663033, 359.8613, 0.4261847)
   validation loss 392.1252136230469, (198.02629, 0.040030207, 194.0589, 0.4261847)
decoder loss ratio: 7671.882298, decoder SINDy loss  ratio: 0.418903
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989774]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.42704]
 [ -0.     ]]
Epoch 5275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 625.3500366210938, (264.2743, 0.14883964, 360.9269, 0.42605782)
   validation loss 378.08587646484375, (185.2849, 0.03987312, 192.7611, 0.42605782)
decoder loss ratio: 7178.258573, decoder SINDy loss  ratio: 0.416102
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989749]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.427858]
 [ -0.      ]]
Epoch 5300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 845.3590087890625, (484.912, 0.14338765, 360.3036, 0.42593154)
   validation loss 585.97412109375, (383.79785, 0.041248392, 202.13501, 0.42593154)
decoder loss ratio: 14868.995072, decoder SINDy loss  ratio: 0.436337
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99897337]
 [0.        ]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [-16.4044]
 [ -0.    ]]
Epoch 5325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 650.3653564453125, (288.1299, 0.14963602, 362.0858, 0.4257718)
   validation loss 407.11712646484375, (213.70982, 0.04035192, 193.36694, 0.4257718)
decoder loss ratio: 8279.489583, decoder SINDy loss  ratio: 0.417410
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99897134]
 [0.        ]]
[[ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.4218]
 [ -0.    ]]
Epoch 5350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 622.0509033203125, (244.69073, 0.15807733, 377.2021, 0.42561564)
   validation loss 380.6052551269531, (189.70468, 0.03968152, 190.86089, 0.42561564)
decoder loss ratio: 7349.488699, decoder SINDy loss  ratio: 0.412000
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989693]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.372665]
 [ -0.      ]]
Epoch 5375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 776.0558471679688, (416.21893, 0.14802733, 359.68887, 0.425517)
   validation loss 521.0648803710938, (322.95926, 0.040922817, 198.06471, 0.425517)
decoder loss ratio: 12512.002377, decoder SINDy loss  ratio: 0.427551
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99896705]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.386946]
 [ -0.      ]]
Epoch 5400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 671.124755859375, (311.7937, 0.14756806, 359.18347, 0.4253522)
   validation loss 419.3704833984375, (224.89035, 0.040270794, 194.43987, 0.4253522)
decoder loss ratio: 8712.642599, decoder SINDy loss  ratio: 0.419726
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989644]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.372139]
 [ -0.      ]]
Epoch 5425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 637.41796875, (278.94574, 0.14355855, 358.32864, 0.42522255)
   validation loss 393.58172607421875, (200.26883, 0.04064493, 193.27226, 0.42522255)
decoder loss ratio: 7758.762131, decoder SINDy loss  ratio: 0.417205
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989629]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.388292]
 [ -0.      ]]
Epoch 5450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 577.1967163085938, (216.88434, 0.14468, 360.1677, 0.4251143)
   validation loss 344.9186096191406, (154.5676, 0.03990635, 190.31111, 0.4251143)
decoder loss ratio: 5988.217027, decoder SINDy loss  ratio: 0.410813
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989612]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.360312]
 [  0.      ]]
Epoch 5475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1040.679931640625, (678.6856, 0.14028089, 361.854, 0.42502943)
   validation loss 762.0567626953125, (551.5985, 0.041314673, 210.41693, 0.42502943)
decoder loss ratio: 21369.883923, decoder SINDy loss  ratio: 0.454215
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989594]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.373352]
 [  0.      ]]
Epoch 5500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 571.24658203125, (208.22113, 0.14833353, 362.87714, 0.42490172)
   validation loss 345.99237060546875, (156.98134, 0.040002644, 188.97104, 0.42490172)
decoder loss ratio: 6081.729585, decoder SINDy loss  ratio: 0.407921
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989586]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.38452]
 [ -0.     ]]
Epoch 5525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 576.9444580078125, (216.58185, 0.14771704, 360.2149, 0.42486343)
   validation loss 348.1832275390625, (158.412, 0.039738476, 189.73148, 0.42486343)
decoder loss ratio: 6137.155995, decoder SINDy loss  ratio: 0.409562
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99895734]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.364473]
 [ -0.      ]]
Epoch 5550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 571.3201904296875, (210.17441, 0.15055835, 360.99524, 0.42474538)
   validation loss 344.22454833984375, (155.45242, 0.039634068, 188.73251, 0.42474538)
decoder loss ratio: 6022.496748, decoder SINDy loss  ratio: 0.407406
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989566]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.360615]
 [ -0.      ]]
Epoch 5575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 572.5517578125, (212.59386, 0.14985813, 359.80807, 0.42468396)
   validation loss 346.79132080078125, (157.22661, 0.0398227, 189.52489, 0.42468396)
decoder loss ratio: 6091.231762, decoder SINDy loss  ratio: 0.409116
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989552]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.34849]
 [ -0.     ]]
Epoch 5600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 587.8082275390625, (227.24902, 0.1595211, 360.39966, 0.42456904)
   validation loss 354.9380798339844, (166.15717, 0.038092807, 188.74283, 0.42456904)
decoder loss ratio: 6437.217054, decoder SINDy loss  ratio: 0.407428
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99895406]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.355965]
 [ -0.      ]]
Epoch 5625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 592.0185546875, (227.05997, 0.15069367, 364.8079, 0.42449576)
   validation loss 365.1010437011719, (176.26634, 0.038025998, 188.79668, 0.42449576)
decoder loss ratio: 6828.864107, decoder SINDy loss  ratio: 0.407544
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989519]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.364796]
 [  0.      ]]
Epoch 5650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 619.9775390625, (253.40688, 0.15389685, 366.41678, 0.42436576)
   validation loss 408.24468994140625, (220.58101, 0.039598692, 187.62407, 0.42436576)
decoder loss ratio: 8545.691231, decoder SINDy loss  ratio: 0.405013
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99895227]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.337547]
 [ -0.      ]]
Epoch 5675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1002.549072265625, (643.2135, 0.13608608, 359.19946, 0.42435607)
   validation loss 736.1088256835938, (525.7718, 0.04137287, 210.29564, 0.42435607)
decoder loss ratio: 20369.311907, decoder SINDy loss  ratio: 0.453953
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989506]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.340141]
 [  0.      ]]
Epoch 5700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 585.7444458007812, (223.15434, 0.14863007, 362.44147, 0.42421046)
   validation loss 354.790771484375, (165.39183, 0.038684197, 189.36028, 0.42421046)
decoder loss ratio: 6407.566644, decoder SINDy loss  ratio: 0.408761
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99894845]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.344547]
 [  0.      ]]
Epoch 5725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 727.46826171875, (370.76227, 0.14423007, 356.56177, 0.4240976)
   validation loss 487.12139892578125, (289.4258, 0.040109884, 197.65549, 0.4240976)
decoder loss ratio: 11212.858413, decoder SINDy loss  ratio: 0.426667
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989473]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.348825]
 [  0.      ]]
Epoch 5750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 570.2644653320312, (208.93553, 0.14815558, 361.1808, 0.42398763)
   validation loss 347.0441589355469, (158.09631, 0.038190603, 188.90965, 0.42398763)
decoder loss ratio: 6124.925651, decoder SINDy loss  ratio: 0.407788
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989464]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.342182]
 [  0.      ]]
Epoch 5775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 755.8375244140625, (399.62833, 0.1381407, 356.071, 0.42391855)
   validation loss 497.6513977050781, (297.3579, 0.040432446, 200.25305, 0.42391855)
decoder loss ratio: 11520.161675, decoder SINDy loss  ratio: 0.432274
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989463]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.321148]
 [ -0.      ]]
Epoch 5800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 962.40673828125, (553.3411, 0.1617935, 408.90384, 0.42383552)
   validation loss 710.0955200195312, (510.26028, 0.039029315, 199.79622, 0.42383552)
decoder loss ratio: 19768.369269, decoder SINDy loss  ratio: 0.431288
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989456]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.34384]
 [ -0.     ]]
Epoch 5825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.7017822265625, (242.8517, 0.15104768, 367.699, 0.4237934)
   validation loss 398.08477783203125, (208.88474, 0.039251227, 189.1608, 0.4237934)
decoder loss ratio: 8092.557278, decoder SINDy loss  ratio: 0.408330
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99894416]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.341831]
 [ -0.      ]]
Epoch 5850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 996.0126953125, (633.98895, 0.13539717, 361.88834, 0.4237504)
   validation loss 728.242919921875, (515.38605, 0.040294353, 212.8166, 0.4237504)
decoder loss ratio: 19966.950224, decoder SINDy loss  ratio: 0.459395
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989424]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.323025]
 [  0.      ]]
Epoch 5875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 627.0205078125, (255.81516, 0.15423867, 371.05115, 0.42361352)
   validation loss 404.1408386230469, (215.1594, 0.03852575, 188.94292, 0.42361352)
decoder loss ratio: 8335.648430, decoder SINDy loss  ratio: 0.407860
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99894154]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.314678]
 [  0.      ]]
Epoch 5900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 581.1048583984375, (222.70056, 0.14580487, 358.2585, 0.4236016)
   validation loss 347.4558410644531, (157.66797, 0.03797106, 189.74991, 0.4236016)
decoder loss ratio: 6108.330833, decoder SINDy loss  ratio: 0.409602
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989401]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.333145]
 [  0.      ]]
Epoch 5925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 613.8597412109375, (251.99196, 0.15280828, 361.71497, 0.4234769)
   validation loss 373.3393859863281, (182.08122, 0.03853248, 191.21964, 0.4234769)
decoder loss ratio: 7054.142668, decoder SINDy loss  ratio: 0.412774
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99893856]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.299858]
 [  0.      ]]
Epoch 5950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.3223266601562, (347.49844, 0.14326201, 353.68063, 0.4234108)
   validation loss 446.48419189453125, (250.30852, 0.037748218, 196.13791, 0.4234108)
decoder loss ratio: 9697.386521, decoder SINDy loss  ratio: 0.423391
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989368]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.286362]
 [  0.      ]]
Epoch 5975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1683.8170166015625, (1310.6534, 0.13435054, 373.0292, 0.42331743)
   validation loss 1378.8382568359375, (1143.4628, 0.04326032, 235.33232, 0.42331743)
decoder loss ratio: 44299.732792, decoder SINDy loss  ratio: 0.507998
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989348]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.290697]
 [ -0.      ]]
Epoch 6000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 687.1796875, (334.0088, 0.14186114, 353.029, 0.42320505)
   validation loss 439.20263671875, (243.36429, 0.038047425, 195.8003, 0.42320505)
decoder loss ratio: 9428.355029, decoder SINDy loss  ratio: 0.422662
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99893194]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.292072]
 [  0.      ]]
Epoch 6025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 610.3458251953125, (257.05008, 0.1443079, 353.15146, 0.4230239)
   validation loss 374.6932373046875, (183.04503, 0.038691264, 191.60951, 0.4230239)
decoder loss ratio: 7091.482191, decoder SINDy loss  ratio: 0.413616
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989303]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.286772]
 [ -0.      ]]
Epoch 6050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 567.6123046875, (211.12854, 0.14778584, 356.336, 0.42292976)
   validation loss 342.25201416015625, (153.75761, 0.037492298, 188.4569, 0.42292976)
decoder loss ratio: 5956.836907, decoder SINDy loss  ratio: 0.406811
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989284]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.283373]
 [ -0.      ]]
Epoch 6075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 691.28662109375, (338.66672, 0.14099056, 352.47894, 0.42283422)
   validation loss 444.98919677734375, (249.13303, 0.038848642, 195.81732, 0.42283422)
decoder loss ratio: 9651.845946, decoder SINDy loss  ratio: 0.422699
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99892735]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.237425]
 [ -0.      ]]
Epoch 6100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.8624267578125, (302.96378, 0.14055072, 351.75806, 0.4227391)
   validation loss 413.8457336425781, (219.51862, 0.038668793, 194.28845, 0.4227391)
decoder loss ratio: 8504.532274, decoder SINDy loss  ratio: 0.419399
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989245]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.27729]
 [  0.     ]]
Epoch 6125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 715.9234619140625, (340.23337, 0.15463707, 375.53543, 0.42255813)
   validation loss 514.8850708007812, (324.8194, 0.038510624, 190.02718, 0.42255813)
decoder loss ratio: 12584.067350, decoder SINDy loss  ratio: 0.410200
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99892426]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.279501]
 [  0.      ]]
Epoch 6150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 577.3397827148438, (218.2604, 0.14463595, 358.93475, 0.42251107)
   validation loss 352.15789794921875, (163.55223, 0.0385176, 188.56715, 0.42251107)
decoder loss ratio: 6336.297362, decoder SINDy loss  ratio: 0.407049
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99892306]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.27052]
 [  0.     ]]
Epoch 6175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 745.50537109375, (362.49188, 0.15353581, 382.86, 0.42243463)
   validation loss 511.8291931152344, (319.3061, 0.037183143, 192.48593, 0.42243463)
decoder loss ratio: 12370.472317, decoder SINDy loss  ratio: 0.415508
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989209]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.256712]
 [  0.      ]]
Epoch 6200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 720.8909301757812, (334.1864, 0.16273054, 386.5418, 0.42229828)
   validation loss 469.3084716796875, (275.95258, 0.038609125, 193.31729, 0.42229828)
decoder loss ratio: 10690.881857, decoder SINDy loss  ratio: 0.417303
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99891865]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.26635]
 [ -0.     ]]
Epoch 6225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1009.4732055664062, (654.6441, 0.13972332, 354.6894, 0.42224827)
   validation loss 744.8629760742188, (536.30023, 0.040244788, 208.52254, 0.42224827)
decoder loss ratio: 20777.202043, decoder SINDy loss  ratio: 0.450125
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989172]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.272827]
 [  0.      ]]
Epoch 6250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 631.3675537109375, (267.06018, 0.15796192, 364.14938, 0.42206842)
   validation loss 384.11248779296875, (193.39761, 0.0382511, 190.67664, 0.42206842)
decoder loss ratio: 7492.559301, decoder SINDy loss  ratio: 0.411602
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99891555]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.242983]
 [  0.      ]]
Epoch 6275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 846.6614990234375, (492.80542, 0.14066523, 353.71542, 0.42196402)
   validation loss 580.267333984375, (378.00662, 0.038948644, 202.22179, 0.42196402)
decoder loss ratio: 14644.632797, decoder SINDy loss  ratio: 0.436524
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99891293]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.23973]
 [ -0.     ]]
Epoch 6300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 711.741943359375, (359.30637, 0.14723785, 352.28833, 0.42180195)
   validation loss 476.9230651855469, (282.016, 0.03868961, 194.86838, 0.42180195)
decoder loss ratio: 10925.789101, decoder SINDy loss  ratio: 0.420651
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99891067]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.23213]
 [ -0.     ]]
Epoch 6325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1009.9301147460938, (620.7998, 0.15741265, 388.9729, 0.42165223)
   validation loss 839.6616821289062, (644.67285, 0.037097216, 194.95172, 0.42165223)
decoder loss ratio: 24975.745471, decoder SINDy loss  ratio: 0.420831
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989098]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.239182]
 [  0.      ]]
Epoch 6350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 576.1551513671875, (217.70955, 0.15089731, 358.29474, 0.42159677)
   validation loss 360.353515625, (173.56163, 0.03628236, 186.7556, 0.42159677)
decoder loss ratio: 6724.078872, decoder SINDy loss  ratio: 0.403138
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989083]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.192266]
 [  0.      ]]
Epoch 6375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 571.104248046875, (213.37437, 0.14820613, 357.5817, 0.42146164)
   validation loss 358.91717529296875, (172.44356, 0.038200267, 186.43542, 0.42146164)
decoder loss ratio: 6680.762802, decoder SINDy loss  ratio: 0.402447
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989069]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.227665]
 [ -0.      ]]
Epoch 6400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 559.7041015625, (204.3831, 0.14972687, 355.1713, 0.42137027)
   validation loss 345.166748046875, (157.96881, 0.036716785, 187.16121, 0.42137027)
decoder loss ratio: 6119.985985, decoder SINDy loss  ratio: 0.404014
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989054]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.206274]
 [ -0.      ]]
Epoch 6425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 597.0084228515625, (235.33719, 0.1522104, 361.51904, 0.42125502)
   validation loss 388.1683044433594, (201.11978, 0.037291445, 187.01123, 0.42125502)
decoder loss ratio: 7791.729494, decoder SINDy loss  ratio: 0.403690
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99890393]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.216377]
 [  0.      ]]
Epoch 6450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.3577270507812, (403.04108, 0.13389447, 351.18277, 0.4211904)
   validation loss 499.71771240234375, (299.60638, 0.038760923, 200.07257, 0.4211904)
decoder loss ratio: 11607.271466, decoder SINDy loss  ratio: 0.431885
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989029]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.209671]
 [  0.      ]]
Epoch 6475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 571.26953125, (214.61569, 0.14317927, 356.51065, 0.42113885)
   validation loss 349.4760437011719, (161.31432, 0.03714725, 188.12459, 0.42113885)
decoder loss ratio: 6249.596648, decoder SINDy loss  ratio: 0.406093
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99890214]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.169857]
 [ -0.      ]]
Epoch 6500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1245.2777099609375, (886.9507, 0.13576548, 358.19125, 0.42109212)
   validation loss 976.8816528320312, (759.5352, 0.040026385, 217.30638, 0.42109212)
decoder loss ratio: 29425.712929, decoder SINDy loss  ratio: 0.469086
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989013]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.212862]
 [ -0.      ]]
Epoch 6525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 778.9576416015625, (428.92957, 0.14058578, 349.88745, 0.4210144)
   validation loss 526.6072998046875, (327.81335, 0.03724472, 198.75671, 0.4210144)
decoder loss ratio: 12700.058462, decoder SINDy loss  ratio: 0.429044
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988991]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.223246]
 [ -0.      ]]
Epoch 6550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 564.1114501953125, (209.7172, 0.14934993, 354.2449, 0.42089295)
   validation loss 343.054931640625, (155.73743, 0.03537434, 187.28215, 0.42089295)
decoder loss ratio: 6033.538285, decoder SINDy loss  ratio: 0.404275
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99889743]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.20494]
 [  0.     ]]
Epoch 6575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 704.9940185546875, (355.47607, 0.1408275, 349.37708, 0.42079496)
   validation loss 458.5345458984375, (262.98853, 0.037543535, 195.50848, 0.42079496)
decoder loss ratio: 10188.632042, decoder SINDy loss  ratio: 0.422033
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99889624]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.195658]
 [ -0.      ]]
Epoch 6600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 604.502197265625, (254.10497, 0.1463621, 350.25085, 0.42074028)
   validation loss 368.41845703125, (178.71835, 0.03594621, 189.66414, 0.42074028)
decoder loss ratio: 6923.859274, decoder SINDy loss  ratio: 0.409417
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988946]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.163155]
 [  0.      ]]
Epoch 6625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.3529052734375, (506.1044, 0.17495452, 397.07358, 0.4206235)
   validation loss 686.4849853515625, (489.08408, 0.034267627, 197.36662, 0.4206235)
decoder loss ratio: 18947.966189, decoder SINDy loss  ratio: 0.426044
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99889326]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.194372]
 [ -0.      ]]
Epoch 6650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 581.48095703125, (230.57993, 0.15145108, 350.74957, 0.42052016)
   validation loss 353.5994873046875, (166.33858, 0.036611054, 187.2243, 0.42052016)
decoder loss ratio: 6444.245260, decoder SINDy loss  ratio: 0.404150
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988931]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.16629]
 [ -0.     ]]
Epoch 6675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 896.2186279296875, (544.5986, 0.13943312, 351.48062, 0.42048416)
   validation loss 634.8038940429688, (432.02676, 0.03837787, 202.73874, 0.42048416)
decoder loss ratio: 16737.466866, decoder SINDy loss  ratio: 0.437640
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99888957]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.174252]
 [  0.      ]]
Epoch 6700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1339.837646484375, (911.30396, 0.17655282, 428.35712, 0.4203433)
   validation loss 1110.2459716796875, (900.33795, 0.035071447, 209.87294, 0.4203433)
decoder loss ratio: 34880.655303, decoder SINDy loss  ratio: 0.453040
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988886]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.163542]
 [  0.      ]]
Epoch 6725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 849.306640625, (497.39044, 0.13796341, 351.7782, 0.42025194)
   validation loss 583.8173217773438, (381.22516, 0.037259046, 202.55489, 0.42025194)
decoder loss ratio: 14769.324484, decoder SINDy loss  ratio: 0.437243
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998888]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.170433]
 [ -0.      ]]
Epoch 6750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 657.4653930664062, (291.12857, 0.1546523, 366.18216, 0.42014274)
   validation loss 434.9137878417969, (247.98518, 0.037309166, 186.8913, 0.42014274)
decoder loss ratio: 9607.376538, decoder SINDy loss  ratio: 0.403431
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988873]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.173697]
 [  0.      ]]
Epoch 6775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1135.8623046875, (781.21857, 0.13157767, 354.5121, 0.42017326)
   validation loss 869.7592163085938, (655.98346, 0.041087348, 213.7347, 0.42017326)
decoder loss ratio: 25413.938057, decoder SINDy loss  ratio: 0.461376
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99888563]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.186905]
 [  0.      ]]
Epoch 6800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1164.030517578125, (801.81396, 0.13030353, 362.08624, 0.4201114)
   validation loss 856.2483520507812, (637.86475, 0.039547052, 218.34404, 0.4201114)
decoder loss ratio: 24711.987646, decoder SINDy loss  ratio: 0.471326
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99888486]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.145535]
 [  0.      ]]
Epoch 6825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1045.0079345703125, (687.536, 0.13486198, 357.33707, 0.42004487)
   validation loss 756.78759765625, (545.04266, 0.03928633, 211.7056, 0.42004487)
decoder loss ratio: 21115.899023, decoder SINDy loss  ratio: 0.456996
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99888206]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.147596]
 [ -0.      ]]
Epoch 6850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 725.452392578125, (371.39377, 0.13607158, 353.92252, 0.4198638)
   validation loss 454.2012023925781, (256.17444, 0.03693936, 197.98984, 0.4198638)
decoder loss ratio: 9924.642485, decoder SINDy loss  ratio: 0.427389
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988817]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.16791]
 [ -0.     ]]
Epoch 6875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 566.0816040039062, (212.35106, 0.1480762, 353.5825, 0.41978645)
   validation loss 346.45782470703125, (158.66203, 0.035397828, 187.76039, 0.41978645)
decoder loss ratio: 6146.842611, decoder SINDy loss  ratio: 0.405307
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99888015]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.106102]
 [ -0.      ]]
Epoch 6900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 558.7791748046875, (207.40569, 0.1464938, 351.22702, 0.41967812)
   validation loss 339.7332763671875, (152.71812, 0.033937506, 186.98123, 0.41967812)
decoder loss ratio: 5916.565269, decoder SINDy loss  ratio: 0.403625
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988786]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.149586]
 [ -0.      ]]
Epoch 6925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.763671875, (304.13605, 0.14498875, 347.4826, 0.4195682)
   validation loss 416.30120849609375, (224.24738, 0.03574133, 192.0181, 0.4195682)
decoder loss ratio: 8687.732637, decoder SINDy loss  ratio: 0.414498
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99887633]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.15155]
 [ -0.     ]]
Epoch 6950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 574.3538818359375, (225.527, 0.14240582, 348.68445, 0.41945204)
   validation loss 353.0128479003906, (164.69899, 0.036816422, 188.27704, 0.41945204)
decoder loss ratio: 6380.724798, decoder SINDy loss  ratio: 0.406422
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988755]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.121588]
 [ -0.      ]]
Epoch 6975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 701.1639404296875, (329.23996, 0.1520686, 371.77194, 0.41934815)
   validation loss 489.4398193359375, (300.0424, 0.035114057, 189.36229, 0.41934815)
decoder loss ratio: 11624.163043, decoder SINDy loss  ratio: 0.408765
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988736]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.091509]
 [  0.      ]]
Epoch 7000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 821.295166015625, (470.64233, 0.13767567, 350.51514, 0.4192523)
   validation loss 571.6741943359375, (369.35553, 0.036982365, 202.28171, 0.4192523)
decoder loss ratio: 14309.474453, decoder SINDy loss  ratio: 0.436654
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988727]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-16.14344]
 [ -0.     ]]
Epoch 7025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 621.0345458984375, (259.99896, 0.15430735, 360.88132, 0.4191493)
   validation loss 402.592041015625, (216.23537, 0.035134614, 186.32152, 0.4191493)
decoder loss ratio: 8377.333512, decoder SINDy loss  ratio: 0.402201
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988698]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.131512]
 [ -0.      ]]
Epoch 7050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 563.0433349609375, (208.2889, 0.15714, 354.5973, 0.41907835)
   validation loss 356.30419921875, (170.58437, 0.033650916, 185.68619, 0.41907835)
decoder loss ratio: 6608.734480, decoder SINDy loss  ratio: 0.400830
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998868]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.115896]
 [ -0.      ]]
Epoch 7075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 574.9708251953125, (218.93042, 0.15493707, 355.88547, 0.4189283)
   validation loss 367.7049560546875, (181.9553, 0.033816606, 185.71582, 0.4189283)
decoder loss ratio: 7049.264482, decoder SINDy loss  ratio: 0.400894
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99886584]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.097198]
 [  0.      ]]
Epoch 7100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 576.9359741210938, (221.29024, 0.1526646, 355.49307, 0.41882262)
   validation loss 370.85943603515625, (184.847, 0.03432898, 185.97809, 0.41882262)
decoder loss ratio: 7161.293693, decoder SINDy loss  ratio: 0.401460
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988648]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.117369]
 [ -0.      ]]
Epoch 7125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 555.024658203125, (205.09633, 0.14527452, 349.78308, 0.4187354)
   validation loss 338.9964294433594, (152.6578, 0.034866843, 186.30376, 0.4187354)
decoder loss ratio: 5914.228445, decoder SINDy loss  ratio: 0.402163
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988632]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.107847]
 [ -0.      ]]
Epoch 7150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 677.8424072265625, (332.1982, 0.139522, 345.50464, 0.41865712)
   validation loss 440.8052978515625, (247.10396, 0.036283918, 193.66507, 0.41865712)
decoder loss ratio: 9573.236329, decoder SINDy loss  ratio: 0.418053
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988613]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.094965]
 [  0.      ]]
Epoch 7175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 559.8770751953125, (209.60077, 0.14726059, 350.12906, 0.41852313)
   validation loss 341.868896484375, (155.67526, 0.033643235, 186.15997, 0.41852313)
decoder loss ratio: 6031.129931, decoder SINDy loss  ratio: 0.401852
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99885905]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.091532]
 [  0.      ]]
Epoch 7200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 635.423095703125, (289.78128, 0.14258543, 345.49927, 0.41839656)
   validation loss 397.590576171875, (206.65941, 0.034980297, 190.8962, 0.41839656)
decoder loss ratio: 8006.344264, decoder SINDy loss  ratio: 0.412076
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988582]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.120745]
 [ -0.      ]]
Epoch 7225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 575.54443359375, (227.15921, 0.15192898, 348.2333, 0.4183174)
   validation loss 350.5758361816406, (164.2328, 0.034162544, 186.30887, 0.4183174)
decoder loss ratio: 6362.663922, decoder SINDy loss  ratio: 0.402174
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988545]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.069012]
 [ -0.      ]]
Epoch 7250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 596.3167724609375, (250.38078, 0.14345291, 345.79257, 0.41817018)
   validation loss 367.4947204589844, (178.80019, 0.03539433, 188.65913, 0.41817018)
decoder loss ratio: 6927.029623, decoder SINDy loss  ratio: 0.407247
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988539]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.083548]
 [  0.      ]]
Epoch 7275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 566.5361938476562, (219.23978, 0.14443155, 347.152, 0.41808173)
   validation loss 341.43408203125, (154.69006, 0.033533305, 186.71046, 0.41808173)
decoder loss ratio: 5992.961613, decoder SINDy loss  ratio: 0.403041
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988507]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.080929]
 [  0.      ]]
Epoch 7300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 566.2525634765625, (213.84976, 0.15336132, 352.24945, 0.4179247)
   validation loss 358.2931823730469, (172.92395, 0.0349367, 185.33429, 0.4179247)
decoder loss ratio: 6699.374040, decoder SINDy loss  ratio: 0.400070
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988503]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.06499]
 [  0.     ]]
Epoch 7325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 635.9102783203125, (273.6417, 0.15448453, 362.1141, 0.4179046)
   validation loss 430.7142333984375, (244.34169, 0.033136237, 186.3394, 0.4179046)
decoder loss ratio: 9466.221269, decoder SINDy loss  ratio: 0.402240
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99884844]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.057676]
 [  0.      ]]
Epoch 7350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 954.9285888671875, (562.51575, 0.16746904, 392.24533, 0.41783032)
   validation loss 748.6419677734375, (552.7159, 0.033635035, 195.89244, 0.41783032)
decoder loss ratio: 21413.172800, decoder SINDy loss  ratio: 0.422861
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988483]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.052887]
 [  0.      ]]
Epoch 7375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1101.31884765625, (749.33826, 0.13433523, 351.8462, 0.4177671)
   validation loss 828.9314575195312, (618.3104, 0.03803858, 210.58301, 0.4177671)
decoder loss ratio: 23954.419291, decoder SINDy loss  ratio: 0.454573
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988478]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.053698]
 [  0.      ]]
Epoch 7400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 646.7872924804688, (302.09775, 0.13644446, 344.5531, 0.41772184)
   validation loss 405.88397216796875, (215.23409, 0.035890814, 190.614, 0.41772184)
decoder loss ratio: 8338.542119, decoder SINDy loss  ratio: 0.411467
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988458]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.058475]
 [  0.      ]]
Epoch 7425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 561.23486328125, (209.33781, 0.14920619, 351.74783, 0.41761333)
   validation loss 350.50830078125, (165.30225, 0.03348892, 185.17255, 0.41761333)
decoder loss ratio: 6404.095991, decoder SINDy loss  ratio: 0.399721
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99884474]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.05861]
 [ -0.     ]]
Epoch 7450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 554.7724609375, (204.59187, 0.14834903, 350.03226, 0.41756612)
   validation loss 346.2676696777344, (161.00327, 0.033764463, 185.23064, 0.41756612)
decoder loss ratio: 6237.546015, decoder SINDy loss  ratio: 0.399846
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988432]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.056993]
 [  0.      ]]
Epoch 7475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 570.3228149414062, (217.46855, 0.14945087, 352.70483, 0.41747102)
   validation loss 359.76763916015625, (174.63318, 0.03282651, 185.10165, 0.41747102)
decoder loss ratio: 6765.592520, decoder SINDy loss  ratio: 0.399568
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99884176]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.054134]
 [ -0.      ]]
Epoch 7500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 572.8652954101562, (227.57082, 0.14432555, 345.15015, 0.41738063)
   validation loss 347.78289794921875, (161.09007, 0.033535816, 186.65927, 0.41738063)
decoder loss ratio: 6240.909078, decoder SINDy loss  ratio: 0.402930
params['save_name']
pendulum_2022_09_17_00_10_08_603481
